{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nshow the menu for this view widget.", "response": "def showMenu(self, point=None):\n        \"\"\"\n        Displays the menu for this view widget.\n        \n        :param      point | <QPoint>\n        \"\"\"\n        menu = self.createMenu(self)\n        menu.exec_(QtGui.QCursor.pos())\n        menu.deleteLater()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef showPanelMenu(self, panel, point=None):\n        if not self._panelMenu:\n            self._panelMenu = XViewPanelMenu(self)\n        \n        if point is None:\n            point = QtGui.QCursor.pos()\n        \n        self._panelMenu.setCurrentPanel(panel)\n        self._panelMenu.exec_(point)", "response": "Show the panel menu for this view widget."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef showPluginMenu(self, panel, point=None):\n        if not self._pluginMenu:\n            self._pluginMenu = XViewPluginMenu(self)\n        \n        if point is None:\n            point = QtGui.QCursor.pos()\n        \n        self._pluginMenu.setCurrentPanel(panel)\n        self._pluginMenu.exec_(point)", "response": "Shows the plugin menu for this view widget."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef showTabMenu(self, panel, point=None):\n        if not self._tabMenu:\n            self._tabMenu = XViewTabMenu(self)\n\n        if point is None:\n            point = QtGui.QCursor.pos()\n\n        self._tabMenu.setCurrentPanel(panel)\n        self._tabMenu.exec_(point)", "response": "Show the tab menu for this view widget."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating the current view widget.", "response": "def updateCurrentView(self, oldWidget, newWidget):\n        \"\"\"\n        Updates the current view widget.\n        \n        :param      oldWidget | <QtGui.QWidget>\n                    newWidget | <QtGui.QWidget>\n        \"\"\"\n        view = projexui.ancestor(newWidget, XView)\n        if view is not None:\n            view.setCurrent()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef viewAt(self, point):\n        widget = self.childAt(point)\n        if widget:\n            return projexui.ancestor(widget, XView)\n        else:\n            return None", "response": "Look up the view at the inputed point."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef viewType(self, name):\n        for view in self._viewTypes:\n            if view.viewName() == name:\n                return view\n        return None", "response": "Returns the view class based on the inputd name."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndraw the atom structure image.", "response": "def draw(canvas, mol):\n    \"\"\"Draw molecule structure image.\n\n    Args:\n        canvas: draw.drawable.Drawable\n        mol: model.graphmol.Compound\n    \"\"\"\n    mol.require(\"ScaleAndCenter\")\n    mlb = mol.size2d[2]\n    if not mol.atom_count():\n        return\n    bond_type_fn = {\n        1: {\n            0: single_bond,\n            1: wedged_single,\n            2: dashed_wedged_single,\n            3: wave_single,\n        }, 2: {\n            0: cw_double,\n            1: counter_cw_double,\n            2: double_bond,\n            3: cross_double\n        }, 3: {\n            0: triple_bond\n        }\n    }\n    # Draw bonds\n    for u, v, bond in mol.bonds_iter():\n        if not bond.visible:\n            continue\n        if (u < v) == bond.is_lower_first:\n            f, s = (u, v)\n        else:\n            s, f = (u, v)\n        p1 = mol.atom(f).coords\n        p2 = mol.atom(s).coords\n        if p1 == p2:\n            continue  # avoid zero division\n        if mol.atom(f).visible:\n            p1 = gm.t_seg(p1, p2, F_AOVL, 2)[0]\n        if mol.atom(s).visible:\n            p2 = gm.t_seg(p1, p2, F_AOVL, 1)[1]\n        color1 = mol.atom(f).color\n        color2 = mol.atom(s).color\n        bond_type_fn[bond.order][bond.type](\n            canvas, p1, p2, color1, color2, mlb)\n\n    # Draw atoms\n    for n, atom in mol.atoms_iter():\n        if not atom.visible:\n            continue\n        p = atom.coords\n        color = atom.color\n        # Determine text direction\n        if atom.H_count:\n            cosnbrs = []\n            hrzn = (p[0] + 1, p[1])\n            for nbr in mol.graph.neighbors(n):\n                pnbr = mol.atom(nbr).coords\n                try:\n                    cosnbrs.append(gm.dot_product(hrzn, pnbr, p) /\n                                   gm.distance(p, pnbr))\n                except ZeroDivisionError:\n                    pass\n            if not cosnbrs or min(cosnbrs) > 0:\n                # [atom]< or isolated node(ex. H2O, HCl)\n                text = atom.formula_html(True)\n                canvas.draw_text(p, text, color, \"right\")\n                continue\n            elif max(cosnbrs) < 0:\n                # >[atom]\n                text = atom.formula_html()\n                canvas.draw_text(p, text, color, \"left\")\n                continue\n        # -[atom]- or no hydrogens\n        text = atom.formula_html()\n        canvas.draw_text(p, text, color, \"center\")"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert a SMILES text to a compound object", "response": "def smiles_to_compound(smiles, assign_descriptors=True):\n    \"\"\"Convert SMILES text to compound object\n\n    Raises:\n        ValueError: SMILES with unsupported format\n    \"\"\"\n    it = iter(smiles)\n    mol = molecule()\n    try:\n        for token in it:\n                mol(token)\n        result, _ = mol(None)\n    except KeyError as err:\n        raise ValueError(\"Unsupported Symbol: {}\".format(err))\n    result.graph.remove_node(0)\n    logger.debug(result)\n    if assign_descriptors:\n        molutil.assign_descriptors(result)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ind_lm(index, lmax):\n    import numpy as np\n    lm = np.empty(2, dtype=np.float64)\n    _ind_lm(index, lmax, lm)\n    return lm", "response": "Convert single index to corresponding ( ell m ) pair"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting mode weights of spin - weighted function on a grid of points.", "response": "def salm2map(salm, s, lmax, Ntheta, Nphi):\n    \"\"\"Convert mode weights of spin-weighted function to values on a grid\n\n    Parameters\n    ----------\n    salm : array_like, complex, shape (..., (lmax+1)**2)\n        Input array representing mode weights of the spin-weighted function.  This array may be\n        multi-dimensional, where initial dimensions may represent different times, for example, or\n        separate functions on the sphere.  The final dimension should give the values of the mode\n        weights, in the order described below in the 'Notes' section.\n    s : int or array, int, shape (...)\n        Spin weight of the function.  If `salm` is multidimensional and this is an array, its\n        dimensions must match the first dimensions of `salm`, and the different values are the spin\n        weights of the different functions represented by those dimensions.  Otherwise, if `salm` is\n        multidimensional and `s` is a single integer, all functions are assumed to have the same\n        spin weight.\n    lmax : int\n        The largest `ell` value present in the input array.\n    Ntheta : int\n        Number of points in the output grid along the polar angle.\n    Nphi : int\n        Number of points in the output grid along the azimuthal angle.\n\n\n    Returns\n    -------\n    map : ndarray, complex, shape (..., Ntheta, Nphi)\n        Values of the spin-weighted function on grid points of the sphere.  This array is shaped\n        like the input `salm` array, but has one extra dimension.  The final two dimensions describe\n        the values of the function on the sphere.\n\n\n    See also\n    --------\n    spinsfast.map2salm : Roughly the inverse of this function.\n\n\n    Notes\n    -----\n\n    The input `salm` data should be given in increasing order of `ell` value, always starting with\n    (ell, m) = (0, 0) even if `s` is nonzero, proceeding to (1, -1), (1, 0), (1, 1), etc.\n    Explicitly, the ordering should match this:\n\n        [f_lm(ell, m) for ell in range(lmax+1) for m in range(-ell, ell+1)]\n\n    The input is converted to a contiguous complex numpy array if necessary.\n\n    The output data are presented on this grid of spherical coordinates:\n\n        np.array([[f(theta, phi)\n                   for phi in np.linspace(0.0, 2*np.pi, num=2*lmax+1, endpoint=False)]\n                  for theta in np.linspace(0.0, np.pi, num=2*lmax+1, endpoint=True)])\n\n    Note that `map2salm` and `salm2map` are not true inverses of each other for several reasons.\n    First, modes with `ell < |s|` should always be zero; they are simply assumed to be zero on input\n    to `salm2map`.  It is also possible to define a `map` function that violates this assumption --\n    for example, having a nonzero average value over the sphere, if the function has nonzero spin\n    `s`, this is impossible.  Also, it is possible to define a map of a function with so much\n    angular dependence that it cannot be captured with the given `lmax` value.  For example, a\n    discontinuous function will never be perfectly resolved.\n\n\n    Example\n    -------\n    >>> s = -2\n    >>> lmax = 8\n    >>> Ntheta = Nphi = 2*lmax + 1\n    >>> modes = np.zeros(spinsfast.N_lm(lmax), dtype=np.complex128)\n    >>> modes[spinsfast.lm_ind(2, 2, 8)] = 1.0\n    >>> values = spinsfast.salm2map(modes, s, lmax, Ntheta, Nphi)\n\n    \"\"\"\n    if Ntheta < 2 or Nphi < 1:\n        raise ValueError(\"Input values of Ntheta={0} and Nphi={1} \".format(Ntheta, Nphi)\n                         + \"are not allowed; they must be greater than 1 and 0, respectively.\")\n    if lmax < 1:\n        raise ValueError(\"Input value of lmax={0} \".format(lmax)\n                         + \"is not allowed; it must be greater than 0 and should be greater \"\n                         + \"than |s|={0}.\".format(abs(s)))\n    import numpy as np\n    salm = np.ascontiguousarray(salm, dtype=np.complex128)\n    if salm.shape[-1] < N_lm(lmax):\n        raise ValueError(\"The input `salm` array of shape {0} is too small for the stated `lmax` of {1}.  \".format(salm.shape, lmax)\n                         + \"Perhaps you forgot to include the (zero) modes with ell<|s|.\")\n    map = np.empty(salm.shape[:-1]+(Ntheta, Nphi), dtype=np.complex128)\n    if salm.ndim>1:\n        s = np.ascontiguousarray(s, dtype=np.intc)\n        if s.ndim != salm.ndim-1 or np.product(s.shape) != np.product(salm.shape[:-1]):\n            s = s*np.ones(salm.shape[:-1], dtype=np.intc)\n        _multi_salm2map(salm, map, s, lmax, Ntheta, Nphi)\n    else:\n        _salm2map(salm, map, s, lmax, Ntheta, Nphi)\n    return map"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert values of spin - weighted function on a grid point to mode weights on a sphere.", "response": "def map2salm(map, s, lmax):\n    \"\"\"Convert values of spin-weighted function on a grid to mode weights\n\n    Parameters\n    ----------\n    map : array_like, complex, shape (..., Ntheta, Nphi)\n        Values of the spin-weighted function on grid points of the sphere.  This array may have more\n        than two dimensions, where initial dimensions may represent different times, for example, or\n        separate functions on the sphere.  The final two dimensions should give the values of the\n        function, in the order described below in the 'Notes' section.\n    s : int or array, int, shape (...)\n        Spin weight of the function.  If `amp` is multidimensional and this is an array, its\n        dimensions must match the first dimensions of `map`, and the different values are the spin\n        weights of the different functions represented by those dimensions.  Otherwise, if `map` is\n        multidimensional and `s` is a single integer, all functions are assumed to have the same\n        spin weight.\n    lmax : int\n        The largest `ell` value present in the input array.\n\n\n    Returns\n    -------\n    salm : ndarray, complex, shape (..., (lmax+1)**2)\n        Mode weights of the spin-weighted function.  This array is shaped like the input `map` array,\n        but has one less dimension.  The final dimension describes the values of the mode weights on\n        the corresponding sphere, as described below in the 'Notes' section.\n\n\n    See also\n    --------\n    spinsfast.map2salm : Roughly the inverse of this function.\n\n\n    Notes\n    -----\n\n    The input data represent the values on this grid of spherical coordinates:\n\n        np.array([[map(theta, phi)\n                   for phi in np.linspace(0.0, 2*np.pi, num=2*lmax+1, endpoint=False)]\n                  for theta in np.linspace(0.0, np.pi, num=2*lmax+1, endpoint=True)])\n\n    The input is converted to a contiguous complex numpy array if necessary.\n\n    The output `salm` data are given in increasing order of `ell` value, always starting with\n    (ell, m) = (0, 0) even if `s` is nonzero, proceeding to (1, -1), (1, 0), (1, 1), etc.\n    Explicitly, the ordering matches this:\n\n        [map_lm(ell, m) for ell in range(lmax+1) for m in range(-ell, ell+1)]\n\n    Note that `map2salm` and `salm2map` are not true inverses of each other for several reasons.\n    First, modes with `ell < |s|` should always be zero; they are simply assumed to be zero on input\n    to `salm2map`.  It is possible to define a `map` function that violates this assumption -- for\n    example, having a nonzero average value over the sphere, if the function has nonzero spin `s`,\n    this is impossible.  Also, it is possible to define a map of a function with so much angular\n    dependence that it cannot be captured with the given `lmax` value.  For example, a discontinuous\n    function will never be perfectly resolved.\n\n\n    Example\n    -------\n    >>> s = -2\n    >>> lmax = 8\n    >>> theta_phi = np.array([[[theta, phi]\n                               for phi in np.linspace(0.0, 2*np.pi, num=2*lmax+1, endpoint=False)]\n                              for theta in np.linspace(0.0, np.pi, num=2*lmax+1, endpoint=True)])\n    >>> map = np.array([[np.sqrt(3/(8*np.pi)) * np.sin(tp[0]) for tp in _] for _ in theta_phi])\n    >>> salm = spinsfast.map2salm(map, s, lmax)\n\n    \"\"\"\n    import numpy as np\n    map = np.ascontiguousarray(map, dtype=np.complex128)\n    salm = np.empty(map.shape[:-2]+(N_lm(lmax),), dtype=np.complex128)\n    if map.ndim>2:\n        s = np.ascontiguousarray(s, dtype=np.intc)\n        if s.ndim != map.ndim-2 or np.product(s.shape) != np.product(map.shape[:-2]):\n            s = s*np.ones(map.shape[:-2], dtype=np.intc)\n        _multi_map2salm(map, salm, s, lmax)\n    else:\n        _map2salm(map, salm, s, lmax)\n    return salm"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nextend map of function to cover sphere twice up to theta = 2pi", "response": "def f_extend_MW(map, s):\n    \"\"\"Extend map of function to cover sphere \"twice\" up to theta=2pi\n\n    This introduces new points when Nphi is odd, and duplicates values when Nphi is even, making it\n    easier to perform certain transformation operations.\n\n    This is mostly an internal function, included here for backwards compatibility.  See map2salm\n    and salm2map for more useful functions.\n\n    \"\"\"\n    import numpy as np\n    map = np.ascontiguousarray(map, dtype=np.complex128)\n    extended_map = np.empty((2*(map.shape[0]-1), map.shape[1],), dtype=np.complex128)\n    _f_extend_MW(map, extended_map, s)\n    return extended_map"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef f_extend_old(map, s):\n    import numpy as np\n    map = np.ascontiguousarray(map, dtype=np.complex128)\n    extended_map = np.empty((2*(map.shape[0]-1), map.shape[1],), dtype=np.complex128)\n    _f_extend_old(map, extended_map, s)\n    return extended_map", "response": "Extend map of function to cover sphere twice up to theta = 2pi"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntaking the fft of the theta extended map then zero pad and reorganize it", "response": "def Imm(extended_map, s, lmax):\n    \"\"\"Take the fft of the theta extended map, then zero pad and reorganize it\n\n    This is mostly an internal function, included here for backwards compatibility.  See map2salm\n    and salm2map for more useful functions.\n\n    \"\"\"\n    import numpy as np\n    extended_map = np.ascontiguousarray(extended_map, dtype=np.complex128)\n    NImm = (2*lmax + 1)**2\n    imm = np.empty(NImm, dtype=np.complex128)\n    _Imm(extended_map, imm, s, lmax)\n    return imm"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nbases query for an url and xpath", "response": "def _query(self, url, xpath):\n        \"\"\"Base query for an url and xpath\n\n        Args:\n            url (str): URL to search\n            xpath (str): xpath to search (may be ``None``)\n        \"\"\"\n        return self.session.query(CachedRequest).filter(CachedRequest.url == url).filter(CachedRequest.xpath == xpath)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get(self, url, store_on_error=False, xpath=None, rate_limit=None, log_hits=True, log_misses=True):\n\n        try:\n            # get cached request - if none is found, this throws a NoResultFound exception\n            cached = self._query(url, xpath).one()\n            if log_hits:\n                config.logger.info(\"Request cache hit: \" + url)\n\n            # if the cached value is from a request that resulted in an error, throw an exception\n            if cached.status_code != requests.codes.ok:\n                raise RuntimeError(\"Cached request returned an error, code \" + str(cached.status_code))\n        except NoResultFound:\n            if log_misses:\n                config.logger.info(\"Request cache miss: \" + url)\n\n            # perform the request\n            try:\n\n                # rate limit\n                if rate_limit is not None and self.last_query is not None:\n                    to_sleep = rate_limit - (datetime.datetime.now() - self.last_query).total_seconds()\n                    if to_sleep > 0:\n                        time.sleep(to_sleep)\n\n                self.last_query = datetime.datetime.now()\n\n                response = requests.get(url)\n                status_code = response.status_code\n                # get 'text', not 'content', because then we are sure to get unicode\n                content = response.text\n                response.close()\n\n                if xpath is not None:\n                    doc = html.fromstring(content)\n                    nodes = doc.xpath(xpath)\n                    if len(nodes) == 0:\n                        # xpath not found; set content and status code, exception is raised below\n                        content = \"xpath not found: \" + xpath\n                        status_code = ERROR_XPATH_NOT_FOUND\n                    else:\n                        # extract desired node only\n                        content = html.tostring(nodes[0], encoding='unicode')\n\n            except requests.ConnectionError as e:\n                # on a connection error, write exception information to a response object\n                status_code = ERROR_CONNECTION_ERROR\n                content = str(e)\n\n            # a new request cache object\n            cached = CachedRequest(url=str(url),\n                                   content=content,\n                                   status_code=status_code,\n                                   xpath=xpath,\n                                   queried_on=datetime.datetime.now())\n\n            # if desired, store the response even if an error occurred\n            if status_code == requests.codes.ok or store_on_error:\n                self.session.add(cached)\n                self.session.commit()\n\n            if status_code != requests.codes.ok:\n                raise RuntimeError(\"Error processing the request, \" + str(status_code) + \": \" + content)\n\n        return cached.content", "response": "Get a URL via the cache."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef clear(self, url=None, xpath=None):\n        if url is not None:\n            query = self._query(url, xpath)\n            if query.count() > 0:\n                query.delete()\n                self.session.commit()\n            else:\n                raise KeyError(\"Cannot clear URL, not in cache: \" + str(url) + \" xpath:\" + str(xpath))\n        else:\n            # remove the DB file\n            self.close()\n            if path.exists(self.db_path):\n                remove(self.db_path)", "response": "Clear the cache with the given URL and xpath."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if a URL and xpath exists in the cache.", "response": "def has(self, url, xpath=None):\n        \"\"\"Check if a URL (and xpath) exists in the cache\n\n        If DB has not been initialized yet, returns ``False`` for any URL.\n\n        Args:\n            url (str): If given, clear specific item only. Otherwise remove the DB file.\n            xpath (str): xpath to search (may be ``None``)\n\n        Returns:\n            bool: ``True`` if URL exists, ``False`` otherwise\n        \"\"\"\n        if not path.exists(self.db_path):\n            return False\n\n        return self._query(url, xpath).count() > 0"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_timestamp(self, url, xpath=None):\n        if not path.exists(self.db_path):\n            return None\n\n        if self._query(url, xpath).count() > 0:\n            return self._query(url, xpath).one().queried_on", "response": "Get time stamp of cached query result."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef indicator_summary_table():\n    # a database client/session to run queries in\n    cl = client.get_client()\n    session = cl.create_session()\n\n    # Query regions and indicators separately, join them in pandas\n\n    query = session.query(models.NUTS2Region.name,\n                          models.NUTS2Region.key,\n                          models.NUTS2Region.id)\n    df = cl.df_query(query).set_index('id')\n\n    # For each EuroStat indicator, query latest available data year (varies between indicators)\n    indicators = session.query(models.EuroStatIndicator.description,\n                               models.EuroStatIndicator.id).all()\n    for description, indicator_id in indicators:\n        latest_year = session.query(sa.func.max(models.EuroStatValue.year)) \\\n            .filter(models.EuroStatValue.indicator_id == indicator_id) \\\n            .scalar()\n\n        query = session.query(models.EuroStatValue.value,\n                              models.EuroStatValue.region_id) \\\n            .filter(models.EuroStatValue.indicator_id == indicator_id) \\\n            .filter(models.EuroStatValue.year == latest_year)\n        values = cl.df_query(query).set_index('region_id')['value']\n\n        # rename series to description + year, join to data table\n        values.name = description + ' ' + str(latest_year)\n        df = df.join(values, how='left')\n\n    # Query and join in weather indicators\n    query = session.query(models.ClimateValue.region_id,\n                          models.ClimateValue.value,\n                          models.ClimateIndicator.description) \\\n        .join(models.ClimateIndicator)\n    weather = cl.df_query(query).dropna(how='any')\n\n    # pivot different indicators to columns, join to data table\n    weather = weather.set_index(['region_id', 'description'])['value'].unstack()\n    df = df.join(weather, how='left')\n\n    # write output as both CSV and Excel; do not include index column\n    df.to_csv(path.join(out_dir, \"nuts2_values.csv\"), encoding='utf-8', index=False)\n    df.to_excel(path.join(out_dir, \"nuts2_values.xlsx\"), encoding='utf-8', index=False)\n\n    session.close()", "response": "Export a table listing all NUTS2 regions and indicators and their data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate interactive data exploration tool", "response": "def eurominder_explorer():\n    \"\"\"Generate interactive data exploration tool\n\n    Output is an html page, rendered to 'eurominder_explorer.html' in the output directory.\n\n    Data structure (only relevant items are shown below):\n\n    .. code-block:: none\n\n        {\n            \"nuts2Features\": [{\"geometry\": [<boundary geometry>],\n                               \"properties\": { \"NUTS_ID\": \"AT11\" } },\n                              {\"geometry\": [<boundary geometry>],\n                               \"properties\": { \"NUTS_ID\": \"AT12\" } },\n                              ...],\n\n            \"regionNames\": {\"AT11\": \"Burgenland\",\n                            \"AT13\": \"Wien\",\n                            ...\n                           },\n\n            \"indicatorDescriptions\": {\"000005\": \"some description\",\n                                      \"000010\": \"another description\",\n                                      ...},\n\n            \"indicators\": [ {\"key\": \"AT11\",\n                             \"000005 2010\": 37.0\n                             \"000005 2011\": 38.0\n                             ...\n                             \"000010 2010\": 1234.0\n                             \"000010 2011\": 1235.0\n                             ...\n                             \"Mean temperature (C) Apr-Sep\": 16.0,\n                             \"Mean temperature (C) Oct-Mar\": 9.0,\n                             ...\n                             },\n                            {\"key\": \"AT12\",\n                             \"000005 2010: 19.0,\n                             ..\n                            },\n                            ...\n                         ]\n\n            \"ranges\": {\"000005\": [10, 20],\n                       \"000010\": [1234, 5678],\n                       ...,\n                       \"Mean temperature (C) Apr-Sep\": 16.0,\n                       \"Mean temperature (C) Oct-Mar\": 9.0,\n                       ...\n                       },\n\n            \"years\": [\"1999\", \"2000\", ...],\n\n        }\n    \"\"\"\n    # switch off some pandas warnings\n    import pandas as pd\n    pd.options.mode.chained_assignment = None\n\n    # page template\n    template = jenv.get_template(\"eurominder_explorer.html\")\n\n    # container for template context\n    context = dict()\n\n    # plot data\n    data = dict()\n\n    # a database client/session to run queries in\n    cl = client.get_client()\n    session = cl.create_session()\n\n    #\n    # query data\n    #\n\n    # get region names and keys\n    query = session.query(models.NUTS2Region.key,\n                          models.NUTS2Region.name).all()\n    data['regionNames'] = {t[0]: t[1] for t in query}\n\n    # get indicator descriptions\n    query = session.query(models.EuroStatIndicator.number,\n                          models.EuroStatIndicator.description)\n    data['indicatorDescriptions'] = {t[0]: t[1] for t in query}\n\n    # build options for HTML selector for selecting which indicator to show\n    context['y_field_selector_options'] = ''\n    context['x_field_selector_options'] = ''\n    for i_field, number in enumerate(sorted(data['indicatorDescriptions'].keys())):\n        description = data['indicatorDescriptions'][number]\n\n        # first field is default option for y selector, second field for x selector\n        y_selected = \" selected=\\\"selected\\\"\" if i_field == 0 else \"\"\n        x_selected = \" selected=\\\"selected\\\"\" if i_field == 1 else \"\"\n\n        context['y_field_selector_options'] += \"<option value=\\\"{:s}\\\" {:s}>{:s}</option>\" \\\n                                               \"\".format(number, y_selected, description)\n        context['x_field_selector_options'] += \"<option value=\\\"{:s}\\\" {:s}>{:s}</option>\" \\\n                                               \"\".format(number, x_selected, description)\n\n    # get all eurostats data\n    query = session.query(models.EuroStatValue.value,\n                          models.EuroStatValue.year,\n                          models.EuroStatIndicator.number,\n                          models.NUTS2Region.key) \\\n        .join(models.EuroStatIndicator) \\\n        .join(models.NUTS2Region)\n    eurostat = cl.df_query(query)\n\n    # reformat to list of value dicts per region, as described above\n    data['indicators'] = []\n    for region_key, region_data in eurostat.groupby('key'):\n        region_data['str_id'] = region_data['number'] + ' ' + region_data['year'].apply(lambda x: str(x))\n        value_dict = region_data.set_index('str_id')['value'].to_dict()\n        value_dict['key'] = region_key\n        data['indicators'].append(value_dict)\n\n    # store min/max values per indicator across all years, to keep plot scales fixed on playback\n    data['ranges'] = dict()\n    for number, indicator_data in eurostat.groupby('number'):\n        data['ranges'][number] = [indicator_data['value'].min(), indicator_data['value'].max()]\n\n    # build options for year selector (also store options in a list, for playback control)\n    data['years'] = sorted([str(y) for y in eurostat['year'].unique()])\n    context['year_selector_options'] = ''\n    for year in data['years']:\n        year_selected = \" selected=\\\"selected\\\"\" if year == \"2010\" else \"\"\n        context['year_selector_options'] += \"<option {:s}>{:s}</option>\".format(year_selected, year)\n\n    # query climate data\n    query = session.query(models.ClimateValue.value,\n                          models.ClimateIndicator.description,\n                          models.NUTS2Region.key) \\\n        .join(models.ClimateIndicator) \\\n        .join(models.NUTS2Region)\n    climate = cl.df_query(query).set_index('key')\n\n    # inject data into 'indicators' records\n    for record in data['indicators']:\n        try:\n            # index by a list of keys to be sure to get back a DataFrame even for one matching record\n            cdata = climate.loc[[record['key']]]\n        except KeyError:\n            # no data available\n            continue\n\n        for description, value in cdata.set_index('description')['value'].iteritems():\n            record[description] = value\n\n    # sorted list of climate descriptions\n    data['climateDescriptions'] = sorted(list(climate['description'].unique()))\n\n    # store ranges of climate indicators, lump summer and winter together (by stripping season indicator)\n    # to get comparable scales\n    climate['variable_description'] = climate['description'].map(lambda s: ' '.join(s.split()[:-1]))\n    for variable_description, indicator_data in climate.groupby('variable_description'):\n        r = [indicator_data['value'].min(), indicator_data['value'].max()]\n        data['ranges'][variable_description + pipeline.CLIMATE_SEASON_SUFFIXES['winter']] = r\n        data['ranges'][variable_description + pipeline.CLIMATE_SEASON_SUFFIXES['summer']] = r\n\n    # inject GeoJSON polygons\n    with open(pipeline.NUTS2GeoJSONInputFile().input_file) as in_file:\n        nuts2_boundaries = json.load(in_file)\n    data['nuts2Features'] = nuts2_boundaries['features']\n\n    #\n    # render template\n    #\n\n    # inject data\n    context['data'] = json.dumps(data, indent=4)\n\n    out_file = path.join(out_dir, \"eurominder_explorer.html\")\n    html_content = template.render(**context)\n    with open(out_file, 'w') as f:\n        f.write(html_content)\n\n    # done, clean up\n    session.close()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_response(self):\r\n        request = getattr(requests, self.request_method, None)\r\n        if request is None and self._request_method is None:\r\n            raise ValueError(\"A effective http request method must be set\")\r\n        if self.request_url is None:\r\n            raise ValueError(\r\n                \"Fatal error occurred, the class property \\\"request_url\\\" is\"\r\n                \"set to None, reset it with an effective url of dingtalk api.\"\r\n            )\r\n        response = request(self.request_url, **self.kwargs)\r\n        self.response = response\r\n        return response", "response": "Get the original response of requests"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the JSON response from the API call.", "response": "def get_json_response(self):\r\n        \"\"\"This method aims at catching the exception of ValueError, detail:\r\n        http://docs.python-requests.org/zh_CN/latest/user/quickstart.html#json\r\n        \"\"\"\r\n        self.json_response = self.get_response().json()\r\n        if self.json_response is not None:\r\n            error_code = self.json_response.get(\"errcode\", None)\r\n            self.call_status = True if error_code == 0 else False\r\n        return self.json_response"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsends a raw command to the Slack server.", "response": "def sendCommand(self, **msg):\n\t\t\"\"\"\n\t\tSends a raw command to the Slack server, generating a message ID automatically.\n\t\t\"\"\"\n\t\tassert 'type' in msg, 'Message type is required.'\n\n\t\tmsg['id'] = self.next_message_id\n\t\tself.next_message_id += 1\n\n\t\tif self.next_message_id >= maxint:\n\t\t\tself.next_message_id = 1\n\n\t\tself.sendMessage(json.dumps(msg))\n\t\treturn msg['id']"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsending a chat message to a given id, user, group or channel. If the API token is not a bot token (xoxb), ``send_with_api`` may be set to True. This will send messages using ``chat.postMessage`` in the Slack API, instead of using the WebSockets channel. This makes the message sending process a little bit slower, however permits writing of messages containing hyperlinks, like what can be done with Incoming and Outgoing Webhooks integrations. Bots are not permitted by Slack to use ``chat.postMessage`` so this will result in an error. Note: channel names must **not** be preceeded with ``#``.", "response": "def sendChatMessage(self, text, id=None, user=None, group=None, channel=None, parse='none', link_names=True, unfurl_links=True, unfurl_media=False, send_with_api=False, icon_emoji=None, icon_url=None, username=None, attachments=None, thread_ts=None, reply_broadcast=False):\n\t\t\"\"\"\n\t\tSends a chat message to a given id, user, group or channel.\n\n\t\tIf the API token is not a bot token (xoxb), ``send_with_api`` may be set\n\t\tto True.  This will send messages using ``chat.postMessage`` in the Slack\n\t\tAPI, instead of using the WebSockets channel.\n\n\t\tThis makes the message sending process a little bit slower, however\n\t\tpermits writing of messages containing hyperlinks, like what can be done\n\t\twith Incoming and Outgoing Webhooks integrations.\n\n\t\tBots are not permitted by Slack to use ``chat.postMessage`` so this will\n\t\tresult in an error.\n\n\t\tNote: channel names must **not** be preceeded with ``#``.\n\t\t\"\"\"\n\t\tif id is not None:\n\t\t\tassert user is None, 'id and user cannot both be set.'\n\t\t\tassert group is None, 'id and group cannot both be set.'\n\t\t\tassert channel is None, 'id and channel cannot both be set.'\n\t\telif user is not None:\n\t\t\tassert group is None, 'user and group cannot both be set.'\n\t\t\tassert channel is None, 'user and channel cannot both be set.'\n\n\t\t\t# Private message to user, get the IM name\n\t\t\tid = self.meta.find_im_by_user_name(user, auto_create=True)[0]\n\t\telif group is not None:\n\t\t\tassert channel is None, 'group and channel cannot both be set.'\n\n\t\t\t# Message to private group, get the group name.\n\t\t\tid = self.meta.find_group_by_name(group)[0]\n\t\telif channel is not None:\n\t\t\t# Message sent to a channel\n\t\t\tid = self.meta.find_channel_by_name(channel)[0]\n\t\telse:\n\t\t\traise Exception, 'Should not reach here.'\n\n\t\tif send_with_api:\n\t\t\treturn self.meta.api.chat.postMessage(\n\t\t\t\ttoken=self.meta.token,\n\t\t\t\tchannel=id,\n\t\t\t\ttext=text,\n\t\t\t\tparse=parse,\n\t\t\t\tlink_names=link_names,\n\t\t\t\tunfurl_links=unfurl_links,\n\t\t\t\tunfurl_media=unfurl_media,\n\t\t\t\ticon_url=icon_url,\n\t\t\t\ticon_emoji=icon_emoji,\n\t\t\t\tusername=username,\n\t\t\t\tattachments=attachments,\n\t\t\t\tthread_ts=thread_ts,\n\t\t\t\treply_broadcast=reply_broadcast,\n\t\t\t)\n\t\telse:\n\t\t\tassert icon_url is None, 'icon_url can only be set if send_with_api is True'\n\t\t\tassert icon_emoji is None, 'icon_emoji can only be set if send_with_api is True'\n\t\t\tassert username is None, 'username can only be set if send_with_api is True'\n\n\t\t\treturn self.sendCommand(\n\t\t\t\ttype='message',\n\t\t\t\tchannel=id,\n\t\t\t\ttext=text,\n\t\t\t\tparse=parse,\n\t\t\t\tlink_names=link_names,\n\t\t\t\tunfurl_links=unfurl_links,\n\t\t\t\tunfurl_media=unfurl_media,\n\t\t\t\tthread_ts=thread_ts,\n\t\t\t\treply_broadcast=reply_broadcast,\n\t\t\t)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef wcparams(mol, type_):\n    try:\n        assign_wctype(mol)\n    except:\n        return \"N/A\"\n    scores = []\n    for i, atom in mol.atoms_iter():\n        scores.append(float(DATA[type_][atom.wctype]))\n        if atom.H_count:\n            if atom.symbol == \"C\":\n                scores.append(DATA[type_][\"H1\"] * atom.H_count)\n            elif atom.symbol == \"N\":\n                scores.append(DATA[type_][\"H3\"] * atom.H_count)\n            elif atom.wctype == \"O2a\":\n                scores.append(DATA[type_][\"H4\"] * atom.H_count)\n            else:\n                scores.append(DATA[type_][\"H2\"] * atom.H_count)\n    return round(sum(scores), 2)", "response": "Calculate Wildman - Crippen logP\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef assign_wctype(mol):\n    mol.require(\"Aromatic\")\n    p_block = [\"Al\", \"B\", \"Si\", \"Ga\", \"Ge\", \"As\", \"Se\", \"Sn\", \"Te\", \"Pb\",\n               \"Ne\", \"Ar\", \"Kr\", \"Xe\", \"Rn\"]\n    d_block = [\"Fe\", \"Co\", \"Cu\", \"Zn\", \"Tc\", \"Cd\", \"Pt\", \"Au\", \"Hg\", \"Gd\"]\n    for i, atom in mol.atoms_iter():\n        nbrs = mol.neighbors(i)\n        nbrcnt = len(nbrs)\n        nbratms = [mol.atom(i) for i, _ in nbrs.items()]\n        isnbrarm = any([mol.atom(i).aromatic for i, _ in nbrs.items()])\n\n        if atom.symbol == \"C\":\n            if atom.aromatic:  # Aromatic carbon\n                ex = [(mol.atom(i), b) for i, b in nbrs.items()\n                      if not b.aromatic]\n                if ex:\n                    sbst, sbstb = ex[0]\n                    cnosx = {\"C\": \"C21\", \"N\": \"C22\", \"O\": \"C23\", \"S\": \"C24\",\n                             \"F\": \"C14\", \"Cl\": \"C15\", \"Br\": \"C16\", \"I\": \"C17\"}\n                    if sbst.symbol not in cnosx:\n                        atom.wctype = \"C13\"\n                    elif sbst.aromatic:\n                        atom.wctype = \"C20\"\n                    elif sbst.symbol in (\"C\", \"N\", \"O\") and sbstb.order == 2:\n                        atom.wctype = \"C25\"\n                    else:\n                        atom.wctype = cnosx[sbst.symbol]\n                else:\n                    if nbrcnt == 2:  # No substituent\n                        atom.wctype = \"C18\"\n                    elif nbrcnt == 3:  # Bridgehead\n                        atom.wctype = \"C19\"\n            elif atom.pi == 0:  # Aliphatic carbon\n                hcnopsx = [\"H\", \"C\", \"N\", \"O\", \"P\", \"S\", \"F\", \"Cl\", \"Br\", \"I\"]\n                if not all([a.symbol in hcnopsx for a in nbratms]):\n                    atom.wctype = \"C27\"\n                elif isnbrarm:  # Adjacent to aromatic\n                    if atom.H_count == 3:\n                        if nbratms[0].symbol == \"C\":\n                            atom.wctype = \"C8\"\n                        else:\n                            atom.wctype = \"C9\"\n                    else:\n                        numh = {0: \"C12\", 1: \"C11\", 2: \"C10\"}\n                        atom.wctype = numh[atom.H_count]\n                elif all([a.symbol == \"C\" for a in nbratms]):\n                    if atom.H_count >= 2:\n                        atom.wctype = \"C1\"\n                    else:\n                        atom.wctype = \"C2\"\n                else:\n                    if atom.H_count >= 2:\n                        atom.wctype = \"C3\"\n                    else:\n                        atom.wctype = \"C4\"\n            elif atom.pi == 1:\n                dbi = [i for i, b in nbrs.items() if b.order == 2][0]\n                dba = mol.atom(dbi)\n                if dba.symbol == \"C\":\n                    if isnbrarm:  # C=C adjacent to aromatic\n                        atom.wctype = \"C26\"\n                    else:  # C=C\n                        atom.wctype = \"C6\"\n                else:  # C=(!C)\n                    atom.wctype = \"C5\"\n                    # Overwrite carbonyl oxygens\n                    if dba.symbol == \"O\":\n                        if all(a.symbol != \"C\" for a in nbratms):\n                            mol.atom(dbi).wctype = \"O11\"\n                        elif any(a.aromatic for a in nbratms):\n                            mol.atom(dbi).wctype = \"O10\"\n                        else:\n                            mol.atom(dbi).wctype = \"O9\"\n            elif atom.pi == 2:\n                od = max([b.order for _, b in nbrs.items()])\n                if od == 3:  # Alkyne\n                    atom.wctype = \"C7\"\n                elif od == 2:  # Allene\n                    atom.wctype = \"C6\"\n            if atom.wctype is None:\n                atom.wctype = \"CS\"\n\n        elif atom.symbol == \"N\":\n            if atom.charge == 0:\n                if atom.aromatic:\n                    atom.wctype = \"N11\"\n                elif atom.pi == 0:  # amine\n                    amines = {\n                        0: {0: \"N7\", 1: \"N2\", 2: \"N1\"},\n                        1: {0: \"N8\", 1: \"N4\", 2: \"N3\"}\n                    }\n                    atom.wctype = amines[isnbrarm][atom.H_count]\n                elif atom.pi == 1:  # imine\n                    if atom.H_count:\n                        atom.wctype = \"N5\"\n                    else:\n                        atom.wctype = \"N6\"\n                elif atom.pi == 2:  # nitrile\n                    atom.wctype = \"N9\"\n            elif atom.charge > 0:\n                if atom.aromatic:\n                    atom.wctype = \"N12\"\n                elif atom.pi == 0:  # ammonium\n                    if atom.H_count:\n                        atom.wctype = \"N10\"\n                    else:\n                        atom.wctype = \"N13\"\n                elif atom.pi == 1:  # iminium\n                    atom.wctype = \"N13\"\n                elif atom.pi == 2:\n                    if any(a.charge < 1 for a in nbratms):  # 1,3-dipole\n                        if all(a.symbol == \"N\" for a in nbratms):  # azide\n                            atom.wctype = \"N14\"\n                        else:  # diazo\n                            atom.wctype = \"N13\"\n                    else:  # nitrilium\n                        atom.wctype = \"N14\"\n            else:  # nitride\n                atom.wctype = \"N14\"\n            if atom.wctype is None:\n                atom.wctype = \"NS\"\n\n        elif atom.symbol == \"O\":\n            if atom.wctype:  # skip if already assigned by carbonyl C\n                continue\n            if atom.aromatic:\n                atom.wctype = \"O1\"\n            elif atom.pi == 0 and atom.charge == 0:\n                if atom.H_count == 1:\n                    if nbratms[0].symbol in (\"O\", \"S\"):  # ROOH, RSOH\n                        atom.wctype = \"O2a\"\n                    elif nbratms[0].carbonyl_C:  # Carboxylic acid\n                        atom.wctype = \"O2a\"\n                    else:  # Alcohol\n                        atom.wctype = \"O2\"\n                elif atom.H_count == 2:  # Water\n                    atom.wctype = \"O2\"\n                elif isnbrarm:  # Ether adjacent to aromatic\n                    atom.wctype = \"O4\"\n                else:  # Ether\n                    atom.wctype = \"O3\"\n            elif nbrcnt == 1:\n                nbr = nbratms[0]\n                if nbr.aromatic:  # O=Aromatic\n                    atom.wctype = \"O8\"\n                elif nbr.symbol in (\"N\", \"O\"):  # N-oxide, O2, NO\n                    atom.wctype = \"O5\"\n                elif nbr.symbol == \"S\":  # S-oxide\n                    atom.wctype = \"O6\"\n                elif nbr.carbonyl_C and atom.charge < 0:  # Carboxylate anion\n                    atom.wctype = \"O12\"\n                else:  # ex. Phosphine oxide\n                    atom.wctype = \"O7\"\n            if atom.wctype is None:\n                atom.wctype = \"OS\"\n\n        elif atom.symbol in (\"F\", \"Cl\", \"Br\", \"I\"):\n            if atom.charge:\n                atom.wctype = \"Hal\"\n            else:\n                atom.wctype = atom.symbol\n        elif atom.symbol == \"P\":\n            atom.wctype = \"P\"\n        elif atom.symbol == \"S\":\n            if atom.aromatic:\n                atom.wctype = \"S3\"\n            elif atom.charge:\n                atom.wctype = \"S2\"\n            else:\n                atom.wctype = \"S1\"\n        elif atom.symbol in p_block:\n            atom.wctype = \"Me1\"\n        elif atom.symbol in d_block:\n            atom.wctype = \"Me2\"\n        elif atom.symbol == \"H\":  # Explicit hydrogen\n            nbr = nbratms[0]\n            if nbr.symbol == \"C\":\n                atom.wctype = \"H1\"\n            elif nbr.symbol == \"N\":\n                atom.wctype = \"H3\"\n            else:\n                atom.wctype = \"H2\"\n        else:\n            raise ValueError(\"Undefined atom symbol: {}\".format(atom.symbol))\n    mol.descriptors.add(\"Wildman-Crippen\")", "response": "Assign atom type of Wildman - Crippen logP to all atoms in the current molecule."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run():\n    options = btoptions.Options()\n    btlog.initialize_logging(options.log_level, options.log_file)\n    app = btapp.get_application()\n    app.run()", "response": "Entry point for the bolt executable."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsaving a list of molecules to the SDFile format file", "response": "def mols_to_file(mols, path):\n    \"\"\"Save molecules to the SDFile format file\n\n    Args:\n        mols: list of molecule objects\n        path: file path to save\n    \"\"\"\n    with open(path, 'w') as f:\n        f.write(mols_to_text(mols))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef listen(self):\n\n        logger.info(\"Listening on port \" + str(self.listener.listen_port))\n        self.listener.listen()", "response": "Starts the client listener to listen for server responses."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef retransmit(self, data):\n\n        # Handle retransmitting REGISTER requests if we don't hear back from\n        # the server.\n        if data[\"method\"] == \"REGISTER\":\n            if not self.registered and self.register_retries < self.max_retries:\n                logger.debug(\"<%s> Timeout exceeded. \" % str(self.cuuid) + \\\n                              \"Retransmitting REGISTER request.\")\n                self.register_retries += 1\n                self.register(data[\"address\"], retry=False)\n            else:\n                logger.debug(\"<%s> No need to retransmit.\" % str(self.cuuid))\n\n        if data[\"method\"] == \"EVENT\":\n            if data[\"euuid\"] in self.event_uuids:\n                # Increment the current retry count of the euuid\n                self.event_uuids[data[\"euuid\"]][\"retry\"] += 1\n\n                if self.event_uuids[data[\"euuid\"]][\"retry\"] > self.max_retries:\n                    logger.debug(\"<%s> Max retries exceeded. Timed out waiting \"\n                                  \"for server for event: %s\" % (data[\"cuuid\"],\n                                                                data[\"euuid\"]))\n                    logger.debug(\"<%s> <euuid:%s> Deleting event from currently \"\n                                  \"processing event uuids\" % (data[\"cuuid\"],\n                                                              str(data[\"euuid\"])))\n                    del self.event_uuids[data[\"euuid\"]]\n                else:\n                    # Retransmit that shit\n                    self.listener.send_datagram(\n                        serialize_data(data, self.compression,\n                                       self.encryption, self.server_key),\n                        self.server)\n\n                    # Then we set another schedule to check again\n                    logger.debug(\"<%s> <euuid:%s> Scheduling to retry in %s \"\n                                  \"seconds\" % (data[\"cuuid\"],\n                                               str(data[\"euuid\"]),\n                                               str(self.timeout)))\n                    self.listener.call_later(\n                        self.timeout, self.retransmit, data)\n            else:\n                logger.debug(\"<%s> <euuid:%s> No need to \"\n                              \"retransmit.\" % (str(self.cuuid),\n                                               str(data[\"euuid\"])))", "response": "Processes messages that have been delivered from the transport\n        protocol."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprocess a message from the server and return the response.", "response": "def handle_message(self, msg, host):\n        \"\"\"Processes messages that have been delivered from the transport\n        protocol\n\n        Args:\n          msg (string): The raw packet data delivered from the transport\n            protocol.\n          host (tuple): A tuple containing the (address, port) combination of\n            the message's origin.\n\n        Returns:\n          A formatted response to the client with the results of the processed\n          message.\n\n        Examples:\n          >>> msg\n          {\"method\": \"OHAI Client\", \"version\": \"1.0\"}\n          >>> host\n          ('192.168.0.20', 36545)\n\n        \"\"\"\n\n        logger.debug(\"Executing handle_message method.\")\n        response = None\n\n        # Unserialize the data packet\n        # If encryption is enabled, and we've receive the server's public key\n        # already, try to decrypt\n        if self.encryption and self.server_key:\n            msg_data = unserialize_data(msg, self.compression, self.encryption)\n        else:\n            msg_data = unserialize_data(msg, self.compression)\n\n        # Log the packet\n        logger.debug(\"Packet received: \" + pformat(msg_data))\n\n        # If the message data is blank, return none\n        if not msg_data:\n            return response\n\n        if \"method\" in msg_data:\n            if msg_data[\"method\"] == \"OHAI Client\":\n                logger.debug(\"<%s> Autodiscover response from server received \"\n                              \"from: %s\" % (self.cuuid, host[0]))\n                self.discovered_servers[host]= [msg_data[\"version\"], msg_data[\"server_name\"]]\n                # Try to register with the discovered server\n                if self.autoregistering:\n                    self.register(host)\n                    self.autoregistering = False\n\n            elif msg_data[\"method\"] == \"NOTIFY\":\n                self.event_notifies[msg_data[\"euuid\"]] = msg_data[\"event_data\"]\n                logger.debug(\"<%s> Notify received\" % self.cuuid)\n                logger.debug(\"<%s> Notify event buffer: %s\" % (self.cuuid,\n                    pformat(self.event_notifies)))\n\n                # Send an OK NOTIFY to the server confirming we got the message\n                response = serialize_data(\n                    {\"cuuid\": str(self.cuuid),\n                     \"method\": \"OK NOTIFY\",\n                     \"euuid\": msg_data[\"euuid\"]},\n                    self.compression, self.encryption, self.server_key)\n\n            elif msg_data[\"method\"] == \"OK REGISTER\":\n                logger.debug(\"<%s> Ok register received\" % self.cuuid)\n                self.registered = True\n                self.server = host\n\n                # If the server sent us their public key, store it\n                if \"encryption\" in msg_data and self.encryption:\n                    self.server_key = PublicKey(\n                        msg_data[\"encryption\"][0], msg_data[\"encryption\"][1])\n\n            elif (msg_data[\"method\"] == \"LEGAL\" or\n                  msg_data[\"method\"] == \"ILLEGAL\"):\n                logger.debug(\"<%s> Legality message received\" % str(self.cuuid))\n                self.legal_check(msg_data)\n\n                # Send an OK EVENT response to the server confirming we\n                # received the message\n                response = serialize_data(\n                    {\"cuuid\": str(self.cuuid),\n                     \"method\": \"OK EVENT\",\n                     \"euuid\": msg_data[\"euuid\"]},\n                    self.compression, self.encryption, self.server_key)\n\n        logger.debug(\"Packet processing completed\")\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef autodiscover(self, autoregister=True):\n\n        logger.debug(\"<%s> Sending autodiscover message to broadcast \"\n                      \"address\" % str(self.cuuid))\n        if not self.listener.listening:\n            logger.warning(\"Neteria client is not listening. The client \"\n                   \"will not be able to process responses from the server\")\n        message = serialize_data(\n            {\"method\": \"OHAI\",\n             \"version\": self.version,\n             \"cuuid\": str(self.cuuid)},\n            self.compression, encryption=False)\n        if autoregister:\n            self.autoregistering = True\n\n        self.listener.send_datagram(\n            message, (\"<broadcast>\", self.server_port), message_type=\"broadcast\")", "response": "This function will send out an autodiscover broadcast to find a specific Neteria server."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef register(self, address, retry=True):\n\n        logger.debug(\"<%s> Sending REGISTER request to: %s\" % (str(self.cuuid),\n                                                                str(address)))\n        if not self.listener.listening:\n            logger.warning(\"Neteria client is not listening.\")\n\n        # Construct the message to send\n        message = {\"method\": \"REGISTER\", \"cuuid\": str(self.cuuid)}\n\n        # If we have encryption enabled, send our public key with our REGISTER\n        # request\n        if self.encryption:\n            message[\"encryption\"] = [self.encryption.n, self.encryption.e]\n\n        # Send a REGISTER to the server\n        self.listener.send_datagram(\n            serialize_data(message, self.compression,\n                           encryption=False), address)\n\n        if retry:\n            # Reset the current number of REGISTER retries\n            self.register_retries = 0\n\n        # Schedule a task to run in x seconds to check to see if we've timed\n        # out in receiving a response from the server\n        self.listener.call_later(\n            self.timeout, self.retransmit, {\"method\": \"REGISTER\",\n                                            \"address\": address})", "response": "This function will send a REGISTER packet to the server."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef event(self, event_data, priority=\"normal\", event_method=\"EVENT\"):\n\n        logger.debug(\"event: \" + str(event_data))\n\n        # Generate an event UUID for this event\n        euuid = uuid.uuid1()\n        logger.debug(\"<%s> <euuid:%s> Sending event data to server: \"\n               \"%s\" % (str(self.cuuid), str(euuid), str(self.server)))\n        if not self.listener.listening:\n            logger.warning(\"Neteria client is not listening.\")\n\n        # If we're not even registered, don't even bother.\n        if not self.registered:\n            logger.warning(\"<%s> <euuid:%s> Client is currently not registered. \"\n                            \"Event not sent.\" % (str(self.cuuid), str(euuid)))\n            return False\n\n        # Send the event data to the server\n        packet = {\"method\": event_method,\n                  \"cuuid\": str(self.cuuid),\n                  \"euuid\": str(euuid),\n                  \"event_data\": event_data,\n                  \"timestamp\": str(datetime.now()),\n                  \"retry\": 0,\n                  \"priority\": priority}\n\n        self.listener.send_datagram(\n            serialize_data(packet, self.compression,\n                           self.encryption, self.server_key),\n            self.server)\n\n        logger.debug(\"<%s> Sending EVENT Packet: %s\" % (str(self.cuuid),\n                                                         pformat(packet)))\n\n        # Set the sent event to our event buffer to see if we need to roll back\n        # or anything\n        self.event_uuids[str(euuid)] = packet\n\n        # Now we need to reschedule a timeout/retransmit check\n        logger.debug(\"<%s> Scheduling retry in %s seconds\" % (str(self.cuuid),\n                                                               str(self.timeout)))\n        self.listener.call_later(self.timeout, self.retransmit, packet)\n\n        return euuid", "response": "This function sends an event to the server."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run(self):\n        env = self.state.document.settings.env\n\n        try:\n            class_name = self.arguments[0]\n        except IndexError:\n            raise SphinxError(\n                '{0} directive requires a class name as an '\n                'argument'.format(self.directive_name)\n            )\n        self._logger.debug('%s using class %s',\n                           self.directive_name, class_name)\n\n        summary_node = self._create_summary_node(class_name)\n\n        # target_id = format_task_id(class_name)\n        target_id = self.get_target_id(class_name)\n        target_node = nodes.target('', '', ids=[target_id])\n\n        # Store these task/configurable topic nodes in the environment for\n        # later cross referencing.\n        if not hasattr(env, 'lsst_task_topics'):\n            env.lsst_task_topics = {}\n        env.lsst_task_topics[target_id] = {\n            'docname': env.docname,\n            'lineno': self.lineno,\n            'target': target_node,\n            'summary_node': summary_node,\n            'fully_qualified_name': class_name,\n            'type': self.get_type(class_name)\n        }\n\n        return [target_node]", "response": "Main entrypoint method.\n\n        Returns\n        -------\n        new_nodes : `list`\n            Nodes to add to the doctree."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef y_score(estimator, X):\n    try:\n        y = estimator.predict_proba(X)\n        return y[:, 1]\n    except(AttributeError):\n        return estimator.decision_function(X)", "response": "Returns the score examples from a new matrix X"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef perturb(estimator, X, bins, columns=None):\n    if columns is None:\n        if len(bins) != X.shape[1]:\n            raise ValueError(\"Must specify columns when not perturbing all columns\")\n        else:\n            columns = X.columns\n\n    n = np.concatenate(([0], np.cumsum([len(b) for b in bins])))\n\n    X_test = np.empty((n[-1]*X.shape[0], X.shape[1]))\n    r = pd.DataFrame(columns=['value', 'feature', 'index'], index=np.arange(n[-1]*X.shape[0]))\n    for j, index in enumerate(X.index):\n        X_test[j*n[-1]:(j+1)*n[-1], :] = X.values[j, :]\n        for i, c in enumerate(columns):\n            s = slice(j*n[-1] + n[i], j*n[-1] + n[i+1])\n            r['value'].values[s] = bins[i]\n            r['feature'].values[s] = c\n            r['index'].values[s] = [index]*(n[i+1]-n[i])\n            X_test[s, (X.columns == c).argmax()] = bins[i]\n\n    y = estimator.predict_proba(X_test)[:, 1]\n    r['y'] = y\n    return r", "response": "Predict on peturbations of a feature vector X."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef destroy_digidoc_session(self):\n\n        # cleanup data too\n        self.destroy_digidoc_session_data()\n\n        try:\n            session = self.request.session[self.DIGIDOC_SESSION_KEY]\n\n            if session:\n                try:\n                    service = self.flat_service()\n                    service.session_code = session\n                    service.close_session()\n\n                except DigiDocError:\n                    pass\n\n            del self.request.session[self.DIGIDOC_SESSION_KEY]\n\n        except KeyError:\n            pass", "response": "Closes DigiDocService session and clears request. session [ I { DIGIDOC_SESSION_KEY } ]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nperform an HTTP Request using base_url and parameters", "response": "def _http_request(self, service_type, **kwargs):\n        \"\"\"\n        Perform an HTTP Request using base_url and parameters\n        given by kwargs.\n        Results are expected to be given in JSON format\n        and are parsed to python data structures.\n        \"\"\"\n        request_params = urlencode(kwargs)\n        request_params = request_params.replace('%28', '').replace('%29', '')\n\n        uri = '%s%s?api_key=%s&%s' % \\\n            (self.base_url, service_type, self.api_key, request_params)\n        header, response = self.conn.request(uri, method='GET')\n        return header, response"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsearching for venue in the specified category cuisine location radius and return the list of venue objects", "response": "def search(self, category = None, cuisine = None, location = (None, None), radius = None, tl_coord = (None, None), \\\n                   br_coord = (None, None), name = None, country = None, locality = None, \\\n                   region = None, postal_code = None, street_address = None,\\\n                   website_url = None, has_menu = None, open_at = None):\n        \"\"\"\n        Locu Venue Search API Call Wrapper\n\n        \n        Args: \n        *Note that none of the arguments are required\n          category         : List of category types that need to be filtered by: ['restaurant', 'spa', 'beauty salon', 'gym', 'laundry', 'hair care',  'other']\n            type : [string]\n          cuisine          : List of cuisine types that need to be filtered by: ['american', 'italian', ...]\n            type : [string]\n          location          : Tuple that consists of (latitude, longtitude) coordinates\n            type : tuple(float, float)\n          radius            : Radius around the given lat, long\n            type : float\n          tl_coord          : Tuple that consists of (latitude, longtitude) for bounding box top left coordinates  \n            type : tuple(float, float)\n          br_coord          : Tuple that consists of (latitude, longtitude) for bounding box bottom right coordinates  \n            type : tuple(float, float)\n          name              : Name of the venue\n            type : string\n          country           : Country where venue is located\n            type : string\n          locality          : Locality. Ex 'San Francisco'\n            type : string\n          region            : Region/state. Ex. 'CA'\n            type : string\n          postal_code       : Postal code\n            type : string\n          street_address    : Address\n            type : string\n          open_at           : Search for venues open at the specified time\n            type : datetime\n          website_url       : Filter by the a website url\n            type : string\n          has_menu          : Filter venues that have menus in them\n            type : boolean\n        Returns:\n          A dictionary with a data returned by the server\n\n        Raises:\n          HttpException with the error message from the server\n        \"\"\"\n\n        params = self._get_params(category = category, cuisine = cuisine, location = location, radius = radius, tl_coord = tl_coord, \\\n                                      br_coord = br_coord, name = name, country = country, locality = locality, \\\n                                      region = region, postal_code = postal_code, street_address = street_address, \\\n                                      website_url = website_url, has_menu = has_menu, open_at = open_at)\n\n        return self._create_query('search', params)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef search_next(self, obj):\n        if 'meta' in obj and 'next' in obj['meta'] and obj['meta']['next'] != None:\n            uri = self.api_url % obj['meta']['next']\n            header, content = self._http_uri_request(uri)\n            resp = json.loads(content)\n            if not self._is_http_response_ok(header):\n                error = resp.get('error_message', 'Unknown Error')\n                raise HttpException(header.status, header.reason, error) \n            return resp\n        return {}", "response": "Returns the next batch of results from the server"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_details(self, ids):\n        if isinstance(ids, list):\n            if len(ids) > 5:\n                ids = ids[:5]\n            id_param = ';'.join(ids) + '/'\n        else:\n            ids = str(ids)\n            id_param = ids + '/'\n\n        header, content = self._http_request(id_param)\n        resp = json.loads(content)\n        if not self._is_http_response_ok(header):\n            error = resp.get('error_message', 'Unknown Error')\n            raise HttpException(header.status, header.reason, error) \n        return resp", "response": "Wrapper for the Locu Venue Details API call Wrapper for the get_details API call."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngiving a venue id returns a list of menus associated with a venue", "response": "def get_menus(self, id):\n        \"\"\"\n        Given a venue id returns a list of menus associated with a venue\n\n        \"\"\"\n        resp = self.get_details([id])\n        menus = []\n        for obj in resp['objects']:\n            if obj['has_menu']:\n                menus += obj['menus']\n        return menus"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_open(self,id,time,day):\n      details = self.get_details(id)\n      has_data = False\n\n      for obj in details[\"objects\"]:\n        hours = obj[\"open_hours\"][day]\n        if hours:\n          has_data = True\n          for interval in hours:\n            interval = interval.replace(' ','').split('-')\n            open_time = interval[0]\n            close_time = interval[1]\n            if open_time < time < close_time:\n              return True\n\n\n      if has_data:\n        return False\n      else:\n        return None", "response": "Checks if a venue is open at the time of day given a venue id."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef search(self, name = None, category = None, description = None, price = None, \\\n                   price__gt = None, price__gte = None, price__lt = None, price__lte = None, \\\n                   location = (None, None), radius = None, tl_coord = (None, None), \\\n                   br_coord = (None, None), country = None, locality = None, \\\n                   region = None, postal_code = None, street_address = None, \\\n                   website_url = None):\n        \"\"\"\n        Locu Menu Item Search API Call Wrapper\n\n        \n        Args: \n        *Note that none of the arguments are required\n          category          : List of category types that need to be filtered by: ['restaurant', 'spa', 'beauty salon', 'gym', 'laundry', 'hair care',  'other']\n            type : [string]\n          location          : Tuple that consists of (latitude, longtitude) coordinates\n            type : tuple(float, float)\n          radius            : Radius around the given lat, long\n            type : float\n          tl_coord          : Tuple that consists of (latitude, longtitude) for bounding box top left coordinates  \n            type : tuple(float, float)\n          br_coord          : Tuple that consists of (latitude, longtitude) for bounding box bottom right coordinates  \n            type : tuple(float, float)\n          name              : Name of the venue\n            type : string\n          country           : Country where venue is located\n            type : string\n          locality          : Locality. Ex 'San Francisco'\n            type : string\n          region            : Region/state. Ex. 'CA'\n            type : string\n          postal_code       : Postal code\n            type : string\n          street_address    : Address\n            type : string\n          website_url       : Filter by the a website url\n            type : string\n          description       : Filter by description of the menu item\n            type : string\n          price             : get menu items with a particular price value\n            type : float\n          price__gt         : get menu items with a value greater than particular\n            type : float\n          price__gte        : greater than or equal\n            type : float\n          price__lt         : less than\n            type : float\n          price__lte        : less than or equal\n            type : float\n\n        Returns:\n          A dictionary with a data returned by the server\n\n        Raises:\n          HttpException with the error message from the server\n        \"\"\"\n\n        params =  self._get_params( name = name, description = description, price = price, \\\n                                       price__gt = price__gt, price__gte = price__gte, price__lt = price__lt, price__lte = price__lte, \\\n                                       location = location, radius = radius, tl_coord = tl_coord, \\\n                                       br_coord = br_coord, country = country, locality = locality, \\\n                                       region = region, postal_code = postal_code, street_address = street_address,\\\n                                       website_url = website_url)\n        return self._create_query('search', params)", "response": "Search for menu items in the specified location."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nshow help for any command.", "response": "def help(ctx, topic, **kw):\n    \"\"\"Show help for any command.\n    \"\"\"\n    # The help command implementation is taken from\n    # https://www.burgundywall.com/post/having-click-help-subcommand\n    if topic is None:\n        click.echo(ctx.parent.get_help())\n    else:\n        click.echo(main.commands[topic].get_help(ctx))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef build(ctx, skip):\n    return_code = build_stack_docs(\n        ctx.obj['root_project_dir'],\n        skippedNames=skip)\n    if return_code > 0:\n        sys.exit(return_code)", "response": "Build documentation as HTML."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncleans Sphinx build products.", "response": "def clean(ctx):\n    \"\"\"Clean Sphinx build products.\n\n    Use this command to clean out build products after a failed build, or\n    in preparation for running a build from a clean state.\n\n    This command removes the following directories from the\n    ``pipelines_lsst_io`` directory:\n\n    - ``_build`` (the Sphinx build itself)\n    - ``modules`` (symlinks to the module doc directories of Stack packages)\n    - ``packages`` (symlinks to the package doc directories of Stack packages)\n    - ``py-api`` (pages created by automodapi for the Python API reference)\n    \"\"\"\n    logger = logging.getLogger(__name__)\n\n    dirnames = ['py-api', '_build', 'modules', 'packages']\n    dirnames = [os.path.join(ctx.obj['root_project_dir'], dirname)\n                for dirname in dirnames]\n    for dirname in dirnames:\n        if os.path.isdir(dirname):\n            shutil.rmtree(dirname)\n            logger.debug('Cleaned up %r', dirname)\n        else:\n            logger.debug('Did not clean up %r (missing)', dirname)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nqueries all entities of a specific type with their attributes as columns", "response": "def query_with_attributes(type_to_query, client):\n        \"\"\"Query all entities of a specific type, with their attributes\n\n        Args:\n            type_to_query (str): type of entity to query\n            client: DB client to perform query with\n\n        Returns:\n            pandas.DataFrame: table of entities, with attributes as columns\n        \"\"\"\n        session = client.create_session()\n\n        # query all data\n        query = session.query(Attribute.name,\n                              Attribute.value,\n                              Entity.id) \\\n            .join(Entity) \\\n            .filter(Entity.type == type_to_query)\n\n        df = client.df_query(query)\n\n        session.close()\n\n        # don't store NaN values\n        df = df.dropna(how='any')\n\n        # pivot attribute names to columns, drop column names to one level\n        # ('unstack' generated multi-level names)\n        df = df.set_index(['id', 'name']).unstack().reset_index()\n        # noinspection PyUnresolvedReferences\n        df.columns = ['id'] + list(df.columns.get_level_values(1)[1:])\n\n        return df"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef recognize_nx(mol):\n    mol.rings = nx.cycle_basis(mol.graph)\n    mol.isolated = sorted(nx.connected_components(mol.graph),\n                          key=len, reverse=True)[1:]\n    mol.scaffolds = [x for x in nx.biconnected_components(mol.graph)\n                     if len(x) > 2]", "response": "NetworkX implementation (for comparison)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef recognize(mol):\n    g = set(i for i, _ in mol.atoms_iter())\n    bccs = {}  # BiConnected Components\n    isoc = []  # ISOlated Components\n    while g:\n        start = g.pop()\n        stack = [start]\n        pred = {start: start}\n        used = {start: set()}\n        root = {start: start}\n        while stack:\n            tail = stack.pop()\n            for nbr in mol.neighbors(tail):\n                if nbr not in used:  # New node\n                    pred[nbr] = tail\n                    stack.append(nbr)\n                    used[nbr] = {tail}\n                    root[nbr] = nbr\n                elif nbr in stack:  # Cycle found\n                    pn = used[nbr]\n                    cyc = [nbr, tail]\n                    p = pred[tail]\n                    end = pred[nbr]\n                    root[nbr] = root[tail] = root[end]\n                    while p not in pn:  # Backtrack\n                        cyc.append(p)\n                        root[p] = root[end]\n                        if p in bccs:  # Append scaffold to new cycle\n                            if root[end] not in bccs:\n                                bccs[root[end]] = []\n                            bccs[root[end]].extend(bccs[p])\n                            del bccs[p]\n                        p = pred[p]\n                    cyc.append(p)\n                    if root[end] not in bccs:  # Append new cycle to scaffold\n                        bccs[root[end]] = []\n                    bccs[root[end]].append(cyc)\n                    used[nbr].add(tail)\n        isoc.append(list(pred.keys()))\n        # print(pred)\n        g -= set(pred)\n    mol.rings = []\n    mol.scaffolds = []\n    for cycles in bccs.values():\n        rcnt = len(mol.rings)\n        mol.rings.extend(cycles)\n        mol.scaffolds.append(list(range(rcnt, rcnt + len(cycles))))\n    mol.isolated = list(sorted(isoc, key=len, reverse=True))[1:]\n    mol.descriptors.add(\"Topology\")", "response": "Detect cycle basis biconnected and isolated components."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef minify_ring(mol, verbose=False):\n    mol.require(\"Topology\")\n    for cyc_idx in mol.scaffolds:\n        rings = deque(sorted([mol.rings[c] for c in cyc_idx], key=len))\n        minified = []\n        cnt = 0\n        while rings:\n            cnt += 1\n            if cnt > 100:\n                mol.descriptors.add(\"MinifiedRing\")\n                raise RuntimeError(\"Ring minimization failed\")\n            r = rings.popleft()\n            init_r = r\n            if verbose:\n                print(len(r), \"Ring:{}\".format(r))\n            for m in minified:\n                if verbose:\n                    print(len(m), \"Minified:{}\".format(m))\n                resolved = resolve_inclusion(r, m)\n                if resolved:\n                    if verbose:\n                        print(len(resolved[0]), len(resolved[1]),\n                              \"Resolved:{}\".format(resolved))\n                    r = resolved[0]\n            if verbose:\n                print(len(r), \"New ring:{}\\n\".format(r))\n            if len(r) == len(init_r):  # no longer be able to minified\n                minified.append(r)\n            else:  # further minification required\n                rings.append(r)\n        for c in cyc_idx:\n            mol.rings[c] = minified.pop()\n    mol.descriptors.add(\"MinifiedRing\")", "response": "Minifies the minimum rings in a single SSSR graph."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning True if t1 and t2 are of equivalent types.", "response": "def same_type(t1, t2):\n    \"\"\"\n    :return bool: True if 't1' and 't2' are of equivalent types\n    \"\"\"\n    if isinstance(t1, string_type) and isinstance(t2, string_type):\n        return True\n\n    return type(t1) == type(t2)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read_json(path, default=None, fatal=True, logger=None):\n    path = resolved_path(path)\n    if not path or not os.path.exists(path):\n        if default is None:\n            return abort(\"No file %s\", short(path), fatal=(fatal, default))\n        return default\n\n    try:\n        with io.open(path, \"rt\") as fh:\n            data = json.load(fh)\n            if default is not None and type(data) != type(default):\n                return abort(\"Wrong type %s for %s, expecting %s\", type(data), short(path), type(default), fatal=(fatal, default))\n\n            if logger:\n                logger(\"Read %s\", short(path))\n\n            return data\n\n    except Exception as e:\n        return abort(\"Couldn't read %s: %s\", short(path), e, fatal=(fatal, default))", "response": "Reads the json file at the specified path and returns the dict or list of dicts"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsaves the data to a JSON file.", "response": "def save_json(data, path, fatal=True, logger=None, sort_keys=True, indent=2, **kwargs):\n    \"\"\"\n    Args:\n        data (object | None): Data to serialize and save\n        path (str | None): Path to file where to save\n        fatal (bool | None): Abort execution on failure if True\n        logger (callable | None): Logger to use\n        sort_keys (bool): Save json with sorted keys\n        indent (int): Indentation to use\n        **kwargs: Passed through to `json.dump()`\n\n    Returns:\n        (int): 1 if saved, -1 if failed (when `fatal` is False)\n    \"\"\"\n    if data is None or not path:\n        return abort(\"No file %s\", short(path), fatal=fatal)\n\n    try:\n        path = resolved_path(path)\n        ensure_folder(path, fatal=fatal, logger=None)\n        if is_dryrun():\n            LOG.info(\"Would save %s\", short(path))\n            return 1\n\n        if hasattr(data, \"to_dict\"):\n            data = data.to_dict()\n\n        if indent:\n            kwargs.setdefault(\"separators\", (\",\", ': '))\n\n        with open(path, \"wt\") as fh:\n            json.dump(data, fh, sort_keys=sort_keys, indent=indent, **kwargs)\n            fh.write(\"\\n\")\n\n        if logger:\n            logger(\"Saved %s\", short(path))\n\n        return 1\n\n    except Exception as e:\n        return abort(\"Couldn't save %s: %s\", short(path), e, fatal=(fatal, -1))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_json(cls, path, fatal=True, logger=None):\n        result = cls()\n        result.load(path, fatal=fatal, logger=logger)\n        return result", "response": "Deserializes a set of key - value pairs from a json file."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets this object from deserialized dictionary data.", "response": "def set_from_dict(self, data, source=None):\n        \"\"\"\n        :param dict data: Set this object from deserialized 'dict'\n        :param source: Source where 'data' came from (optional)\n        \"\"\"\n        if source:\n            self._source = source\n\n        if not data:\n            return\n\n        for key, value in data.items():\n            key = key.replace(\"-\", \"_\")\n            if not hasattr(self, key):\n                LOG.debug(\"%s is not an attribute of %s\", key, self.__class__.__name__)\n                continue\n\n            attr = getattr(self, key)\n            if attr is not None and not same_type(value, attr):\n                source = getattr(self, \"_source\", None)\n                origin = \" in %s\" % source if source else \"\"\n                LOG.debug(\"Wrong type '%s' for %s.%s%s, expecting '%s'\", type_name(value), type_name(self), key, origin, type_name(attr))\n                continue\n\n            setattr(self, key, value)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreset all the fields of this object to class defaults", "response": "def reset(self):\n        \"\"\"\n        Reset all fields of this object to class defaults\n        \"\"\"\n        for name in self.__dict__:\n            if name.startswith(\"_\"):\n                continue\n\n            attr = getattr(self, name)\n            setattr(self, name, attr and attr.__class__())"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_dict(self):\n        result = {}\n        for name in self.__dict__:\n            if name.startswith(\"_\"):\n                continue\n\n            key = name.replace(\"_\", \"-\")\n            attr = getattr(self, name)\n            result[key] = attr.to_dict() if hasattr(attr, \"to_dict\") else attr\n\n        return result", "response": "Returns a dict representation of this object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load(self, path=None, fatal=True, logger=None):\n        self.reset()\n        if path:\n            self._path = path\n            self._source = short(path)\n\n        else:\n            path = getattr(self, \"_path\", None)\n\n        if path:\n            self.set_from_dict(read_json(path, default={}, fatal=fatal, logger=logger))", "response": "Load this object from file with path."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef save(self, path=None, fatal=True, logger=None, sort_keys=True, indent=2):\n        path = path or getattr(self, \"_path\", None)\n        if path:\n            return save_json(self.to_dict(), path, fatal=fatal, logger=logger, sort_keys=sort_keys, indent=indent)", "response": "Save this object to file with path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert a GeoJSON polygon feature to a numpy array containing a mask", "response": "def geojson_polygon_to_mask(feature, shape, lat_idx, lon_idx):\n    \"\"\"Convert a GeoJSON polygon feature to a numpy array\n\n    Args:\n        feature (pygeoj.Feature): polygon feature to draw\n        shape (tuple(int, int)): shape of 2D target numpy array to draw polygon in\n        lat_idx (func): function converting a latitude to the (fractional) row index in the map\n        lon_idx (func): function converting a longitude to the (fractional) column index in the map\n\n    Returns:\n        np.array: mask, background is zero, foreground is one\n    \"\"\"\n    import matplotlib\n\n    # specify 'agg' renderer, Mac renderer does not support what we want to do below\n    matplotlib.use('agg')\n\n    import matplotlib.pyplot as plt\n    from matplotlib import patches\n    import numpy as np\n\n    # we can only do polygons right now\n    if feature.geometry.type not in ('Polygon', 'MultiPolygon'):\n        raise ValueError(\"Cannot handle feature of type \" + feature.geometry.type)\n\n    # fictional dpi - don't matter in the end\n    dpi = 100\n\n    # -- start documentation include: poly-setup\n    # make a new figure with no frame, no axes, with the correct size, black background\n    fig = plt.figure(frameon=False, dpi=dpi, )\n    fig.set_size_inches(shape[1] / float(dpi), shape[0] / float(dpi))\n    ax = plt.Axes(fig, [0., 0., 1., 1.])\n    ax.set_axis_off()\n    # noinspection PyTypeChecker\n    ax.set_xlim([0, shape[1]])\n    # noinspection PyTypeChecker\n    ax.set_ylim([0, shape[0]])\n    fig.add_axes(ax)\n    # -- end documentation include: poly-setup\n\n    # for normal polygons make coordinates iterable\n    if feature.geometry.type == 'Polygon':\n        coords = [feature.geometry.coordinates]\n    else:\n        coords = feature.geometry.coordinates\n\n    for poly_coords in coords:\n        # the polygon may contain multiple outlines; the first is\n        # always the outer one, the others are 'holes'\n        for i, outline in enumerate(poly_coords):\n            # inside/outside fill value: figure background is white by\n            # default, draw inverted polygon and invert again later\n            value = 0. if i == 0 else 1.\n\n            # convert lats/lons to row/column indices in the array\n            outline = np.array(outline)\n            xs = lon_idx(outline[:, 0])\n            ys = lat_idx(outline[:, 1])\n\n            # draw the polygon\n            poly = patches.Polygon(list(zip(xs, ys)),\n                                   facecolor=(value, value, value),\n                                   edgecolor='none',\n                                   antialiased=True)\n            ax.add_patch(poly)\n\n    # -- start documentation include: poly-extract\n    # extract the figure to a numpy array,\n    fig.canvas.draw()\n    data = np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep='')\n    # reshape to a proper numpy array, keep one channel only\n    data = data.reshape(fig.canvas.get_width_height()[::-1] + (3,))[:, :, 0]\n    # -- end documentation include: poly-extract\n\n    # make sure we get the right shape back\n    assert data.shape[0] == shape[0]\n    assert data.shape[1] == shape[1]\n\n    # convert from uints back to floats and invert to get black background\n    data = 1. - data.astype(float) / 255.  # type: np.array\n\n    # image is flipped horizontally w.r.t. map\n    data = data[::-1, :]\n\n    # done, clean up\n    plt.close('all')\n\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load(self):\n        # read file, keep all values as strings\n        df = pd.read_csv(self.input_file,\n                         sep=',',\n                         quotechar='\"',\n                         encoding='utf-8',\n                         dtype=object)\n\n        # wer are only interested in the NUTS code and description, rename them also\n        df = df[['NUTS-Code', 'Description']]\n        df.columns = ['key', 'name']\n\n        # we only want NUTS2 regions (4-digit codes)\n        df = df[df['key'].str.len() == 4]\n\n        # drop 'Extra Regio' codes ending in 'ZZ'\n        df = df[df['key'].str[2:] != 'ZZ']\n\n        return df", "response": "Load data from default location and return as pandas. DataFrame"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef input_file(self):\n        return path.join(path.dirname(__file__), 'data', 'tgs{:s}.tsv'.format(self.number))", "response": "Returns the input file name with a default relative path\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading data table from tsv file from default location", "response": "def load(self, key_filter=None, header_preproc=None):\n        \"\"\"Load data table from tsv file, from default location\n\n        Args:\n            key_filter (str): additional filter for key column - regex matching\n                key values to include; None for no filter\n\n            header_preproc (func): function to apply to column headers to extract year numbers (as strings)\n\n        Returns:\n            pd.DataFrame: data\n        \"\"\"\n        # read file, keep all values as strings\n        df = pd.read_csv(self.input_file,\n                         sep='\\t',\n                         dtype=object)\n\n        if key_filter is not None:\n            # filter on key column (first column)\n            df = df[df[df.columns[0]].str.match(key_filter)]\n\n        # first column contains metadata, with NUTS2 region key as last (comma-separated) value\n        meta_col = df.columns[0]\n        df[meta_col] = df[meta_col].str.split(',').str[-1]\n\n        # convert columns to numbers, skip first column (containing metadata)\n        for col_name in df.columns[1:]:\n            # some values have lower-case characters indicating footnotes, strip them\n            stripped = df[col_name].str.replace(r'[a-z]', '')\n\n            # convert to numbers, convert any remaining empty values (indicated by ':' in the input table) to NaN\n            df[col_name] = pd.to_numeric(stripped, errors='coerce')\n\n        # preprocess headers\n        if header_preproc is not None:\n            df.columns = list(df.columns[:1]) + [header_preproc(c) for c in df.columns[1:]]\n\n        # rename columns, convert years to integers\n        # noinspection PyTypeChecker\n        df.columns = ['key'] + [int(y) for y in df.columns[1:]]\n\n        return df"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef clear(self):\n        # mark this task as incomplete\n        self.mark_incomplete()\n\n        # Delete the indicator metadata, this also deletes values by cascading.\n        #\n        # NOTE: calling 'delete()' on the query (instead of on the queried object,\n        # as done here), would NOT work! For a query, there is no in-Python cascading\n        # of delete statements in sqlalchemy, so the associated values would not\n        # be deleted e.g. for SQLite databases.\n        try:\n            indicator = self.session.query(models.EuroStatIndicator) \\\n                .filter(models.EuroStatIndicator.number == self.number) \\\n                .one()\n            self.session.delete(indicator)\n        except NoResultFound:\n            # Data didn't exist yet, no problem\n            pass\n\n        self.close_session()", "response": "Clear the output from one class loader\n       "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef run(self):\n        # -- start documentation include: eurostats-run-1\n        # create a new indicator metadata object\n        indicator = models.EuroStatIndicator(\n            number=self.number,\n            description=self.description,\n            url=\"http://ec.europa.eu/eurostat/web/products-datasets/-/tgs\" + self.number)\n\n        # add/commit to get the object ID filled\n        self.session.add(indicator)\n        self.session.commit()\n        # -- end documentation include: eurostats-run-1\n\n        # -- start documentation include: eurostats-run-2\n        # load data from input file task\n        df = next(self.requires()).load(key_filter=self.key_filter,\n                                        header_preproc=self.header_preproc)\n\n        # Transform data: DataFrame from loading has NUTS2 key and years as columns.\n        # Index by key, then stack years as second level of index. Reset the index\n        # to get year and key as regular columns, with one value column left.\n        values = df.set_index('key').stack()\n        values.index.levels[1].name = 'year'\n        values.name = 'value'\n        df = values.reset_index()\n        # -- end documentation include: eurostats-run-2\n\n        # -- start documentation include: eurostats-run-3\n        # get current max ID for EuroStatValue objects, for manual ID generation\n        max_id = models.EuroStatValue.get_max_id(self.session)\n\n        # append an ID column, starting with the current max ID of the object class plus one\n        df['id'] = list(range(max_id + 1, max_id + 1 + len(df)))\n        # -- end documentation include: eurostats-run-3\n\n        # -- start documentation include: eurostats-run-4\n        # append indicator ID (constant)\n        df['indicator_id'] = indicator.id\n\n        # append region ID column, by mapping NUTS2 region keys to DB object IDs\n        regions = self.client.df_query(self.session.query(models.NUTS2Region)) \\\n            .set_index('key')['id']\n        df['region_id'] = df['key'].map(regions)\n\n        # drop columns that are not part of the data model\n        df = df.drop(['key'], axis=1)  # type: pd.DataFrame\n        # -- end documentation include: eurostats-run-4\n\n        # -- start documentation include: eurostats-run-5\n        # store, done\n        df.to_sql(name=models.EuroStatValue.__tablename__,\n                  con=client.get_client().engine,\n                  if_exists='append',\n                  index=False)\n\n        self.done()", "response": "Load table data to objects of the specified class"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading the climate data as a map containing the climate data per month", "response": "def load(self):\n        \"\"\"Load the climate data as a map\n\n        Returns:\n            dict: {data: masked 3D numpy array containing climate data per month (first axis),\n                   lat_idx: function converting a latitude to the (fractional) row index in the map,\n                   lon_idx: function converting a longitude to the (fractional) column index in the map}\n        \"\"\"\n        from scipy.io import netcdf_file\n        from scipy import interpolate\n        import numpy as np\n\n        # load file\n        f = netcdf_file(self.input_file)\n\n        # extract data, make explicity copies of data\n        out = dict()\n        lats = f.variables['lat'][:].copy()\n        lons = f.variables['lon'][:].copy()\n\n        # lons start at 0, this is bad for working with data in Europe because the map border runs right through;\n        # roll array by half its width to get Europe into the map center\n        out['data'] = np.roll(f.variables[self.variable_name][:, :, :].copy(), shift=len(lons) // 2, axis=2)\n        lons = np.roll(lons, shift=len(lons) // 2)\n\n        # avoid wraparound problems around zero by setting lon range to -180...180, this is\n        # also the format used in the GeoJSON NUTS2 polygons\n        lons[lons > 180] -= 360\n\n        # data contains some very negative value (~ -9e36) as 'invalid data' flag, convert this to a masked array\n        out['data'] = np.ma.array(out['data'])\n        out['data'][out['data'] < -1.e6] = np.ma.masked\n\n        # -- start documentation include: climate-input-interp\n        # build interpolators to convert lats/lons to row/column indices\n        out['lat_idx'] = interpolate.interp1d(x=lats, y=np.arange(len(lats)))\n        out['lon_idx'] = interpolate.interp1d(x=lons, y=np.arange(len(lons)))\n        # -- end documentation include: climate-input-interp\n\n        # clean up\n        f.close()\n\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef clear(self):\n        # mark this task as incomplete\n        self.mark_incomplete()\n\n        # Delete the indicator metadata, this also deletes values by cascading.\n        for suffix in list(CLIMATE_SEASON_SUFFIXES.values()):\n            try:\n                # noinspection PyUnresolvedReferences\n                indicator = self.session.query(models.ClimateIndicator) \\\n                    .filter(models.ClimateIndicator.description == self.description + suffix) \\\n                    .one()\n                self.session.delete(indicator)\n            except NoResultFound:\n                # Data didn't exist yet, no problem\n                pass\n\n        self.close_session()", "response": "Clear the output of one climate variable."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads climate data and convert to indicator objects", "response": "def run(self):\n        \"\"\"Load climate data and convert to indicator objects\n        \"\"\"\n        import numpy as np\n\n        # get all NUTS region IDs, for linking values to region objects\n        query = self.session.query(models.NUTS2Region.key,\n                                   models.NUTS2Region.id)\n        region_ids = self.client.df_query(query).set_index('key')['id'].to_dict()\n\n        # load climate data and NUTS2 polygons\n        data = next(self.requires()).load()\n        nuts = NUTS2GeoJSONInputFile().load()\n\n        # generated indicator IDs, keyed by season\n        indicator_ids = dict()\n\n        # climate data by season\n        t_data = dict()\n\n        # create new indicator objects for summer and winter, create averaged climate data\n        for season, suffix in CLIMATE_SEASON_SUFFIXES.items():\n            # noinspection PyUnresolvedReferences\n            indicator = models.ClimateIndicator(description=self.description + suffix)\n            self.session.add(indicator)\n\n            # commit, to get indicator ID filled\n            self.session.commit()\n            indicator_ids[season] = indicator.id\n\n            # select winter or summer data by month index, average over time range\n            if season == 'summer':\n                t_data[season] = np.ma.average(data['data'][3:9, :, :], axis=0)\n            else:\n                # noinspection PyTypeChecker\n                t_data[season] = np.ma.average(0.5 * (data['data'][0:3, :, :] + data['data'][9:12, :, :]), axis=0)\n\n        # container for output objects, for bulk saving\n        objects = []\n\n        # start value for manual object id generation\n        current_value_id = models.ClimateValue.get_max_id(self.session)\n\n        # for each region, get a mask, average climate variable over the mask and store the indicator value;\n        # loop over features first, then over seasons, because mask generation is expensive\n        for feature in nuts:\n\n            # draw region mask (doesn't matter for which season we take the map shape)\n            mask = geojson_polygon_to_mask(feature=feature,\n                                           shape=t_data['summer'].shape,\n                                           lat_idx=data['lat_idx'],\n                                           lon_idx=data['lon_idx'])\n\n            # create indicator values for summer and winter\n            for season in list(CLIMATE_SEASON_SUFFIXES.keys()):\n                # weighted average from region mask\n                value = np.ma.average(t_data[season], weights=mask)\n\n                # region ID must be cast to int (DBs don't like numpy dtypes from pandas)\n                region_id = region_ids.get(feature.properties['NUTS_ID'], None)\n                if region_id is not None:\n                    region_id = int(region_id)\n\n                # append an indicator value, manually generate object IDs for bulk saving\n                current_value_id += 1\n                objects.append(models.ClimateValue(id=current_value_id,\n                                                   value=value,\n                                                   region_id=region_id,\n                                                   indicator_id=indicator_ids[season]))\n\n                # # print some debugging output\n                # print self.variable_name + ' ' + season, feature.properties['NUTS_ID'], value\n\n                # # generate some plots for debugging\n                # from matplotlib import pyplot as plt\n                # plt.subplot(211)\n                # plt.imshow(0.02 * t_data + mask * t_data, interpolation='none')\n                # plt.subplot(212)\n                # plt.imshow(t_data, interpolation='none')\n                # plt.savefig('/tmp/' + feature.properties['NUTS_ID'] + '.png')\n\n        # bulk-save all objects\n        self.session.bulk_save_objects(objects)\n        self.session.commit()\n\n        self.done()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncloses TCP connection and unregister the current Spin instance from untwisted reactor.", "response": "def lose(spin):\n    \"\"\"\n    It is used to close TCP connection and unregister\n    the Spin instance from untwisted reactor.\n\n    Diagram:\n\n    lose -> (int:err | socket.error:err) -> CLOSE_ERR\n    \"\"\"\n\n    try:\n        spin.close()\n    except Exception as excpt:\n        err = excpt.args[0]\n        spin.drive(CLOSE_ERR, err)\n    finally:\n        spin.destroy()\n        spin.drive(LOST)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_server(addr, port, backlog):\n\n    server = Spin()\n    server.bind((addr, port))\n    server.listen(backlog)\n    Server(server)\n    server.add_map(ACCEPT, lambda server, spin: install_basic_handles(spin))\n    return server", "response": "Create a TCP server and installs basic handles."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_client(addr, port):\n    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n\n    # First attempt to connect otherwise it leaves\n    # an unconnected spin instance in the reactor.\n    sock.connect_ex((addr, port))\n\n    spin = Spin(sock)\n    Client(spin)\n    spin.add_map(CONNECT, install_basic_handles)\n    spin.add_map(CONNECT_ERR, lambda con, err: lose(con))\n    return spin", "response": "Create a new client and installs the basic handles."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nexecutes the main bit of the application.", "response": "def main(argv=None):\n    # type: (Union[NoneType, List[str]]) -> NoneType\n    \"\"\"Execute the main bit of the application.\n\n    This handles the creation of an instance of :class:`Application`, runs it,\n    and then exits the application.\n\n    :param list argv:\n        The arguments to be passed to the application for parsing.\n    \"\"\"\n    app = application.Application()\n    app.run(argv)\n    app.exit()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_indigo(idgmol, assign_descriptor=True):\n    mol = Compound()\n    for atom in idgmol.iterateAtoms():\n        key = atom.index()\n        a = Atom(atom.symbol())\n        a.coords = list(atom.xyz())\n        mol.add_atom(key, a)\n    for bond in idgmol.iterateBonds():\n        u = bond.source()\n        v = bond.destination()\n        b = Bond()\n        b.order = int(bond.bondOrder())\n        mol.add_bond(u.index(), v.index(), b)\n    if assign_descriptor:\n        molutil.assign_descriptors(mol)\n    return mol", "response": "Convert an indigo IDG Molecule to a Molecule object"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fingerprint_similarity(mol1, mol2):\n    idmol1 = to_real_mol(mol1)\n    idmol2 = to_real_mol(mol2)\n    fp1 = idmol1.fingerprint(\"sim\")\n    fp2 = idmol2.fingerprint(\"sim\")\n    return round(idg.similarity(fp1, fp2, \"tanimoto\"), 2)", "response": "Calculate Indigo fingerprint similarity between two Molecules."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef assign_category(salts):\n    if \"name-cation\" in salts.columns:\n        label = \"name-cation\"\n    elif \"Molecular Relative\" in salts.columns:\n        label = \"Molecular Relative\"\n    else:\n        print(\"No salt-name column found in DataFrame\")\n    category = []\n    missed = []\n    for i in range(salts.shape[0]):\n        if (\"imidazol\" in salts[label].iloc[i]):\n            category.append(\"Imidazolium\")\n        elif (\"pyridin\" in salts[label].iloc[i]):\n            category.append(\"Pyridinium\")\n        elif (\"pyrrolidin\" in salts[label].iloc[i]):\n            category.append(\"Pyrrolidinium\")\n        elif (\"piperidin\" in salts[label].iloc[i]):\n            category.append(\"Piperidinium\")\n        elif (\"phosphon\" in salts[label].iloc[i]):\n            category.append(\"Phosphonium\")\n        elif (\"quinol\" in salts[label].iloc[i]):\n            category.append(\"Quinolinium\")\n        elif (\"ammon\" in salts[label].iloc[i]):\n            category.append(\"Ammonium\")\n        elif (\"amin\" in salts[label].iloc[i]):\n            category.append(\"Aminium\")\n        else:\n            category.append(\"Other\")\n            missed.append(salts[label].iloc[i])\n    print(\"ILs labeled as other: {}\\n{}\".format(len(missed), missed))\n    salts[\"category\"] = category\n    return salts", "response": "Assign a category to the IL type based on the name of the IL."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef merge_duplicates(model_name, keep_descriptors=False):\n    model_outputs = -6 + model_name.Data_summary.shape[0]\n    devmodel = model_name\n    cols = devmodel.Data.columns\n    if (devmodel.Data.iloc[:, -(4 + model_outputs):-4].max() < 700).all():\n        for output_index in range(model_outputs):\n            devmodel.Data.iloc[:, -(5 + output_index)] = \\\n                devmodel.Data.iloc[:, -(5 + output_index)].apply(\n                lambda x: exp(float(x)))\n    output_val = pd.DataFrame()\n    output_xtd = pd.DataFrame()\n    for output_index in range(model_outputs):\n        val = devmodel.Data.groupby(['smiles-cation', 'smiles-anion']\n                                    )[cols[-(5 + output_index)]].mean().\\\n            reset_index()\n        xtd = devmodel.Data.groupby(['smiles-cation', 'smiles-anion']\n                                    )[cols[-(5 + output_index)]].std().\\\n            reset_index()\n        if output_index == 0:\n            output_val = val\n            output_xtd = xtd\n        else:\n            output_val = pd.merge(output_val, val)\n            output_xtd = pd.merge(output_xtd, xtd)\n    size = devmodel.Data.groupby(['smiles-cation', 'smiles-anion']\n                                 )[cols[-(5 + output_index)]].count().\\\n        reset_index()\n    cations = devmodel.Data.groupby(['smiles-cation', 'smiles-anion']\n                                    )['name-cation'].first().reset_index()\n    anions = devmodel.Data.groupby(['smiles-cation', 'smiles-anion']\n                                   )['name-anion'].first().reset_index()\n\n    size.columns.values[2] = \"count\"\n\n    salts = (devmodel.Data[\"smiles-cation\"] + \".\" + devmodel.\n             Data[\"smiles-anion\"]).unique()\n    print(\"Identified {} unique salts in {} datapoints\".\n          format(len(salts), devmodel.Data.shape[0]))\n    out = pd.merge(output_val, output_xtd,\n                   on=['smiles-cation', 'smiles-anion'],\n                   suffixes=['_mean', '_std'])\n    out = pd.merge(out, size)\n    out = pd.merge(out, cations)\n    out = pd.merge(out, anions)\n    if keep_descriptors:\n        cationDescriptors = load_data(\"cationDescriptors.csv\")\n        cationDescriptors.columns = [str(col) + '-cation' for\n                                     col in cationDescriptors.columns]\n        anionDescriptors = load_data(\"anionDescriptors.csv\")\n        anionDescriptors.columns = [str(col) + '-anion' for\n                                    col in anionDescriptors.columns]\n        new_df = pd.merge(cationDescriptors, out,\n                          on=[\"name-cation\", \"smiles-cation\"], how=\"right\")\n        new_df = pd.merge(anionDescriptors, new_df,\n                          on=[\"name-anion\", \"smiles-anion\"], how=\"right\")\n        out = new_df\n    return out", "response": "This function merges the repeated experimental values and returns mean values along with their standard deviation."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\naggregates molecular data for a single model training and a single model training and a single model training and a single model training and a single model training and a single model training.", "response": "def aggregate_data(data, T=[0, inf], P=[0, inf], data_ranges=None,\n                   merge=\"overlap\", feature_type=None, impute=False,\n                   scale_center=True):\n    \"\"\"\n    Aggregates molecular data for model training\n\n    Parameters\n    ----------\n    data: list\n        density, cpt, and/or viscosity\n    T: array\n        desired min and max of temperature distribution\n    P: array\n        desired min and max of pressure distribution\n    data_ranges: array\n        desired min and max of property distribution(s)\n    merge: str\n        overlap or union, defaults to overlap. Merge type of property sets\n    feature_type: str\n        desired feature set, defaults to RDKit's 2D descriptor set\n\n    Returns\n    -----------\n    devmodel: dev_model obj\n        returns dev_model object containing scale/center information,\n        data summary, and the data frame\n    \"\"\"\n    data_files = []\n    for i, string in enumerate(data):\n        data_files.append(load_data(\"%s_premodel.csv\" % string))\n        if i == 0:\n            merged = data_files[0]\n        if i == 1:\n            merged = pd.merge(data_files[0], data_files[1], sort=False,\n                              how='outer')\n        elif i > 1:\n            merged = pd.merge(merged, data_files[-1], sort=False, how='outer')\n    if merge == \"overlap\":\n        merged.dropna(inplace=True)\n    # select state variable and data ranges\n    merged = merged.loc[merged[\"Temperature, K\"] < T[1]]\n    merged = merged.loc[merged[\"Temperature, K\"] > T[0]]\n    merged = merged.loc[merged[\"Pressure, kPa\"] < P[1]]\n    merged = merged.loc[merged[\"Pressure, kPa\"] > P[0]]\n    for i in range(1, len(data) + 1):\n        merged = merged[merged.iloc[:, -i] != 0]  # avoid log(0) error\n        if data_ranges:\n            merged = merged[merged.iloc[:, -i] < data_ranges[::-1][i - 1][1]]\n            merged = merged[merged.iloc[:, -i] > data_ranges[::-1][i - 1][0]]\n    merged.reset_index(drop=True, inplace=True)\n    # Create summary of dataset\n    unique_salts = merged[\"smiles-cation\"] + merged[\"smiles-anion\"]\n    unique_cations = repr(merged[\"smiles-cation\"].unique())\n    unique_anions = repr(merged[\"smiles-anion\"].unique())\n    actual_data_ranges = []\n    for i in range(1, len(data) + 3):\n        actual_data_ranges.append(\"{} - {}\".format(\n            str(merged.iloc[:, -i].min()), str(merged.iloc[:, -i].max())))\n    a = np.array([len(unique_salts.unique()), unique_cations, unique_anions,\n                 len(unique_salts)])\n    a = np.concatenate((a, actual_data_ranges))\n    cols1 = [\"Unique salts\", \"Cations\", \"Anions\", \"Total datapoints\"]\n    cols2 = [\"Temperature range (K)\", \"Pressure range (kPa)\"]\n    cols = cols1 + data[::-1] + cols2\n    data_summary = pd.DataFrame(a, cols)\n    # scale and center\n    metaDf = merged.select_dtypes(include=[\"object\"])\n    dataDf = merged.select_dtypes(include=[np.number])\n    cols = dataDf.columns.tolist()\n    if impute:\n        imp = Imputer(missing_values='NaN', strategy=\"median\", axis=0)\n        X = imp.fit_transform(dataDf)\n        dataDf = pd.DataFrame(X, columns=cols)\n    instance = StandardScaler()\n    if scale_center:\n        for i in range(1, len(data) + 1):\n            dataDf.is_copy = False\n            dataDf.iloc[:, -i] = dataDf.iloc[:, -i].apply(lambda x:\n                                                          log(float(x)))\n        scaled_data = pd.DataFrame(instance.\n                                   fit_transform(dataDf.iloc[:, :-len(data)]),\n                                   columns=cols[:-len(data)])\n        df = pd.concat([scaled_data, dataDf.iloc[:, -len(data):], metaDf],\n                       axis=1)\n        mean_std_of_coeffs = pd.DataFrame([instance.mean_, instance.scale_],\n                                          columns=cols[:-len(data)])\n    else:\n        instance.fit(dataDf.iloc[:, :-len(data)])\n        df = pd.concat([dataDf, metaDf], axis=1)\n        mean_std_of_coeffs = pd.DataFrame([instance.mean_, instance.scale_],\n                                          columns=cols[:-len(data)])\n    devmodel = dev_model(mean_std_of_coeffs, data_summary, df)\n    return devmodel"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload data from a file in the data directory.", "response": "def load_data(data_file_name, dillFile=False):\n    \"\"\"Loads data from module_path/data/data_file_name.\n    Parameters\n    ----------\n    data_file_name : String. Name of csv or dill file to be loaded from\n    module_path/data/data_file_name. For example 'salt_info.csv'.\n    Returns\n    -------\n    data : Pandas DataFrame\n        A data frame. For example with each row representing one\n        salt and each column representing the features of a given\n        salt.\n    \"\"\"\n    module_path = dirname(__file__)\n    if dillFile:\n        with open(join(module_path, 'data', data_file_name), 'rb') as \\\n                dill_file:\n            data = dill.load(dill_file)\n    else:\n        with open(join(module_path, 'data', data_file_name), 'rb') as csv_file:\n            data = pd.read_csv(csv_file, encoding='latin1')\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef dapply(self, fn, pairwise=False, symmetric=True, diagonal=False, block=None, **kwargs):\n    search_keys = [k for k, v in kwargs.items() if isinstance(v, list) and len(v) > 1]\n    functions = util.make_list(fn)\n    search = list(product(functions, util.dict_product(kwargs)))\n\n    results = []\n    for fn, kw in search:\n        if not pairwise:\n            r = self.index.to_series().apply(lambda step: fn(step, **kw))\n        else:\n            r = apply_pairwise(self, fn,\n                               symmetric=symmetric, diagonal=diagonal, block=block,\n                               **kw)\n\n        name = [] if len(functions) == 1 else [fn.__name__]\n        name += util.dict_subset(kw, search_keys).values()\n\n        if isinstance(r, pd.DataFrame):\n            columns = pd.MultiIndex.from_tuples(\n                    [tuple(name + util.make_list(c)) for c in r.columns])\n            r.columns = columns\n        else:\n            r.name = tuple(name)\n        results.append(r)\n\n    if len(results) > 1:\n        result = pd.concat(results, axis=1)\n        # get subset of parameters that were searched over\n        column_names = [] if len(functions) == 1 else [None]\n        column_names += search_keys\n        column_names += [None]*(len(result.columns.names)-len(column_names))\n        result.columns.names = column_names\n\n        return StepFrame(result)\n    else:\n        result = results[0]\n        if isinstance(result, pd.DataFrame):\n            return StepFrame(result)\n        else:\n            result.name = functions[0].__name__\n            return StepSeries(result)", "response": "Apply a function to each step object in the index."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef apply_pairwise(self, function, symmetric=True, diagonal=False, block=None, **kwargs):\n    steps = self.index\n    r = pd.DataFrame(index=steps, columns=steps)\n    for i, s1 in enumerate(steps):\n        j = range(i+1 if symmetric else len(steps))\n        if not diagonal:\n            j.remove(i)\n        other = set(steps[j])\n        if block is not None:\n            df = self.reset_index()\n            df = df.merge(df, on=block)\n            other &= set(df[df.index_x == s1].index_y)\n\n        for s2 in other:\n            r.ix[s1, s2] = function(s1, s2, **kwargs)\n    return r", "response": "Helper function for pairwise apply."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreplaces unhashable values in a DataFrame with their string repr Inviteables", "response": "def _print_unhashable(df, columns=None):\n    \"\"\"\n    Replace unhashable values in a DataFrame with their string repr\n    Args:\n        df: DataFrame\n        columns: columns to replace, if necessary. Default None replaces all columns.\n    \"\"\"\n    for c in df.columns if columns is None else columns:\n        if df.dtypes[c] == object:\n            try:\n                df[c].apply(hash)\n            except TypeError:\n                df[c] = df[c].dropna().apply(pformat).ix[df.index]\n\n    return df"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreset internal storage containers to empty state.", "response": "def reset(self):\n        \"\"\"\n            Empties all internal storage containers\n        \"\"\"\n        super(ContourTree, self).reset()\n        self.edges = []\n        self.augmentedEdges = {}\n        self.sortedNodes = []\n        self.branches = set()\n        self.superNodes = []\n        self.superArcs = []"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nbuild the Morse - Smale complexcluster tree.", "response": "def build(self, X, Y, w=None, edges=None):\n        \"\"\" Assigns data to this object and builds the Morse-Smale\n            Complex\n            @ In, X, an m-by-n array of values specifying m\n            n-dimensional samples\n            @ In, Y, a m vector of values specifying the output\n            responses corresponding to the m samples specified by X\n            @ In, w, an optional m vector of values specifying the\n            weights associated to each of the m samples used. Default of\n            None means all points will be equally weighted\n            @ In, edges, an optional list of custom edges to use as a\n            starting point for pruning, or in place of a computed graph.\n        \"\"\"\n        super(ContourTree, self).build(X, Y, w, edges)\n\n        # Build the join and split trees that we will merge into the\n        # contour tree\n        joinTree = MergeTree(debug=self.debug)\n        splitTree = MergeTree(debug=self.debug)\n\n        joinTree.build_for_contour_tree(self, True)\n        splitTree.build_for_contour_tree(self, False)\n\n        self.augmentedEdges = dict(joinTree.augmentedEdges)\n        self.augmentedEdges.update(dict(splitTree.augmentedEdges))\n\n        if self.short_circuit:\n            jt = self._construct_nx_tree(joinTree, splitTree)\n            st = self._construct_nx_tree(splitTree, joinTree)\n        else:\n            jt = self._construct_nx_tree(joinTree)\n            st = self._construct_nx_tree(splitTree)\n\n        self._process_tree(jt, st)\n        self._process_tree(st, jt)\n\n        # Now we have a fully augmented contour tree stored in nodes and\n        # edges The rest is some convenience stuff for querying later\n\n        self._identifyBranches()\n        self._identifySuperGraph()\n\n        if self.debug:\n            sys.stdout.write(\"Sorting Nodes: \")\n            start = time.clock()\n\n        self.sortedNodes = sorted(enumerate(self.Y),\n                                  key=operator.itemgetter(1))\n\n        if self.debug:\n            end = time.clock()\n            sys.stdout.write(\"%f s\\n\" % (end - start))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_seeds(self, threshold):\n        seeds = []\n        for e1, e2 in self.superArcs:\n            # Because we did some extra work in _process_tree, we can\n            # safely assume e1 is lower than e2\n            if self.Y[e1] <= threshold <= self.Y[e2]:\n                if (e1, e2) in self.augmentedEdges:\n                    # These should be sorted\n                    edgeList = self.augmentedEdges[(e1, e2)]\n                elif (e2, e1) in self.augmentedEdges:\n                    e1, e2 = e2, e1\n                    # These should be reverse sorted\n                    edgeList = list(reversed(self.augmentedEdges[(e1, e2)]))\n                else:\n                    continue\n\n                startNode = e1\n                for endNode in edgeList + [e2]:\n                    if self.Y[endNode] >= threshold:\n                        # Stop when you find the first point above the\n                        # threshold\n                        break\n                    startNode = endNode\n\n                seeds.append(startNode)\n                seeds.append(endNode)\n        return seeds", "response": "Returns a list of seed points for which we want to be identified by a threshold value."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _construct_nx_tree(self, thisTree, thatTree=None):\n        if self.debug:\n            sys.stdout.write(\"Networkx Tree construction: \")\n            start = time.clock()\n\n        nxTree = nx.DiGraph()\n        nxTree.add_edges_from(thisTree.edges)\n\n        nodesOfThatTree = []\n        if thatTree is not None:\n            nodesOfThatTree = thatTree.nodes.keys()\n\n        # Fully or partially augment the join tree\n        for (superNode, _), nodes in thisTree.augmentedEdges.items():\n            superNodeEdge = list(nxTree.out_edges(superNode))\n            if len(superNodeEdge) > 1:\n                warnings.warn(\n                    \"The supernode {} should have only a single \"\n                    \"emanating edge. Merge tree is invalidly \"\n                    \"structured\".format(superNode)\n                )\n            endNode = superNodeEdge[0][1]\n            startNode = superNode\n            nxTree.remove_edge(startNode, endNode)\n            for node in nodes:\n                if thatTree is None or node in nodesOfThatTree:\n                    nxTree.add_edge(startNode, node)\n                    startNode = node\n\n            # Make sure this is not the root node trying to connect to\n            # itself\n            if startNode != endNode:\n                nxTree.add_edge(startNode, endNode)\n\n        if self.debug:\n            end = time.clock()\n            sys.stdout.write(\"%f s\\n\" % (end - start))\n\n        return nxTree", "response": "A function for creating a networkx graph that can be used to create a MergeTree instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nobtains the current branch name from the Git repository.", "response": "def read_git_branch():\n    \"\"\"Obtain the current branch name from the Git repository. If on Travis CI,\n    use the ``TRAVIS_BRANCH`` environment variable.\n    \"\"\"\n    if os.getenv('TRAVIS'):\n        return os.getenv('TRAVIS_BRANCH')\n    else:\n        try:\n            repo = git.repo.base.Repo(search_parent_directories=True)\n            return repo.active_branch.name\n        except Exception:\n            return ''"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read_git_commit_timestamp(repo_path=None):\n    repo = git.repo.base.Repo(path=repo_path, search_parent_directories=True)\n    head_commit = repo.head.commit\n    return head_commit.committed_datetime", "response": "Obtain the timestamp from the current head commit of a Git repository."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nobtains the timestamp for the most recent commit to a given file in a Git repository.", "response": "def read_git_commit_timestamp_for_file(filepath, repo_path=None):\n    \"\"\"Obtain the timestamp for the most recent commit to a given file in a\n    Git repository.\n\n    Parameters\n    ----------\n    filepath : `str`\n        Repository-relative path for a file.\n    repo_path : `str`, optional\n        Path to the Git repository. Leave as `None` to use the current working\n        directory.\n\n    Returns\n    -------\n    commit_timestamp : `datetime.datetime`\n        The datetime of a the most recent commit to the given file.\n\n    Raises\n    ------\n    IOError\n        Raised if the ``filepath`` does not exist in the Git repository.\n    \"\"\"\n    repo = git.repo.base.Repo(path=repo_path, search_parent_directories=True)\n    head_commit = repo.head.commit\n\n    # most recent commit datetime of the given file\n    for commit in head_commit.iter_parents(filepath):\n        return commit.committed_datetime\n\n    # Only get here if git could not find the file path in the history\n    raise IOError('File {} not found'.format(filepath))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget relative filepaths of files in a directory and sub - directories and sub - directories with the given extension.", "response": "def get_filepaths_with_extension(extname, root_dir='.'):\n    \"\"\"Get relative filepaths of files in a directory, and sub-directories,\n    with the given extension.\n\n    Parameters\n    ----------\n    extname : `str`\n        Extension name (e.g. 'txt', 'rst'). Extension comparison is\n        case-insensitive.\n    root_dir : `str`, optional\n        Root directory. Current working directory by default.\n\n    Returns\n    -------\n    filepaths : `list` of `str`\n        File paths, relative to ``root_dir``, with the given extension.\n    \"\"\"\n    # needed for comparison with os.path.splitext\n    if not extname.startswith('.'):\n        extname = '.' + extname\n\n    # for case-insensitivity\n    extname = extname.lower()\n\n    root_dir = os.path.abspath(root_dir)\n\n    selected_filenames = []\n    for dirname, sub_dirnames, filenames in os.walk(root_dir):\n        for filename in filenames:\n            if os.path.splitext(filename)[-1].lower() == extname:\n                full_filename = os.path.join(dirname, filename)\n                selected_filenames.append(\n                    os.path.relpath(full_filename, start=root_dir))\n    return selected_filenames"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the datetime for the most recent commit to a project that affected Sphinx content.", "response": "def get_project_content_commit_date(root_dir='.', exclusions=None):\n    \"\"\"Get the datetime for the most recent commit to a project that\n    affected Sphinx content.\n\n    *Content* is considered any file with one of these extensions:\n\n    - ``rst`` (README.rst and LICENSE.rst are excluded)\n    - ``ipynb``\n    - ``png``\n    - ``jpeg``\n    - ``jpg``\n    - ``svg``\n    - ``gif``\n\n    This function allows project infrastructure and configuration files to be\n    updated without changing the timestamp.\n\n    Parameters\n    ----------\n    root_dir : `str`, optional\n        Root directory. This is the current working directory by default.\n    exclusions : `list` of `str`, optional\n        List of file paths or directory paths to ignore.\n\n    Returns\n    -------\n    commit_date : `datetime.datetime`\n        Datetime of the most recent content commit.\n\n    Raises\n    ------\n    RuntimeError\n        Raised if no content files are found.\n    \"\"\"\n    logger = logging.getLogger(__name__)\n\n    # Supported 'content' extensions\n    extensions = ('rst', 'ipynb', 'png', 'jpeg', 'jpg', 'svg', 'gif')\n\n    content_paths = []\n    for extname in extensions:\n        content_paths += get_filepaths_with_extension(\n            extname,\n            root_dir=root_dir)\n\n    # Known files that should be excluded; lower case for comparison\n    exclude = Matcher(exclusions if exclusions\n                      else ['readme.rst', 'license.rst'])\n\n    # filter out excluded files\n    content_paths = [p for p in content_paths\n                     if not (exclude(p) or exclude(p.split(os.path.sep)[0]))]\n    logger.debug('Found content paths: {}'.format(', '.join(content_paths)))\n\n    if not content_paths:\n        raise RuntimeError('No content files found in {}'.format(root_dir))\n\n    commit_datetimes = []\n    for filepath in content_paths:\n        try:\n            datetime = read_git_commit_timestamp_for_file(\n                filepath,\n                repo_path=root_dir)\n            commit_datetimes.append(datetime)\n        except IOError:\n            logger.warning(\n                'Could not get commit for {}, skipping'.format(filepath))\n\n    if not commit_datetimes:\n        raise RuntimeError('No content commits could be found')\n\n    latest_datetime = max(commit_datetimes)\n\n    return latest_datetime"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef form_ltd_edition_name(git_ref_name=None):\n    if git_ref_name is None:\n        name = read_git_branch()\n    else:\n        name = git_ref_name\n\n    # First, try to use the JIRA ticket number\n    m = TICKET_BRANCH_PATTERN.match(name)\n    if m is not None:\n        return m.group(1)\n\n    # Or use a tagged version\n    m = TAG_PATTERN.match(name)\n    if m is not None:\n        return name\n\n    if name == 'master':\n        # using this terminology for LTD Dasher\n        name = 'Current'\n\n    # Otherwise, reproduce the LTD slug\n    name = name.replace('/', '-')\n    name = name.replace('_', '-')\n    name = name.replace('.', '-')\n    return name", "response": "Form the LSST the Docs edition name for this branch using the same logic as LTD Keeper does."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\niterates over the worksheets in the book and sets the active_worksheet to the current one before yielding.", "response": "def itersheets(self):\n        \"\"\"\n        Iterates over the worksheets in the book, and sets the active\n        worksheet as the current one before yielding.\n        \"\"\"\n        for ws in self.worksheets:\n            # Expression with no explicit table specified will use None\n            # when calling get_table, which should return the current worksheet/table\n            prev_ws = self.active_worksheet\n            self.active_worksheet = ws\n            try:\n                yield ws\n            finally:\n                self.active_worksheet = prev_ws"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef to_xlsx(self, **kwargs):\n        from xlsxwriter.workbook import Workbook as _Workbook\n        self.workbook_obj = _Workbook(**kwargs)\n        self.workbook_obj.set_calc_mode(self.calc_mode)\n\n        for worksheet in self.itersheets():\n            worksheet.to_xlsx(workbook=self)\n\n        self.workbook_obj.filename = self.filename\n        if self.filename:\n            self.workbook_obj.close()\n        return self.workbook_obj", "response": "Write the workbook to a. xlsx file using xlsxwriter. Workbook."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a table and worksheet pair for the named table.", "response": "def get_table(self, name):\n        \"\"\"\n        Return a table, worksheet pair for the named table\n        \"\"\"\n        if name is None:\n            assert self.active_table, \"Can't get table without name unless an active table is set\"\n            name = self.active_table.name\n\n            if self.active_worksheet:\n                table = self.active_worksheet.get_table(name)\n                assert table is self.active_table, \"Active table is not from the active sheet\"\n                return table, self.active_worksheet\n\n            for ws in self.worksheets:\n                try:\n                    table = ws.get_table(name)\n                    if table is self.active_table:\n                        return table, ws\n                except KeyError:\n                    pass\n\n            raise RuntimeError(\"Active table not found in any sheet\")\n\n        # if the tablename explicitly uses the sheetname find the right sheet\n        if \"!\" in name:\n            ws_name, table_name = map(lambda x: x.strip(\"'\"), name.split(\"!\", 1))\n            for ws in self.worksheets:\n                if ws.name == ws_name:\n                    table = ws.get_table(table_name)\n                    return table, ws\n            raise KeyError(name)\n\n        # otherwise look in the current table\n        if self.active_worksheet:\n            table = self.active_worksheet.get_table(name)\n            return table, self.active_worksheet\n\n        # or fallback to the first matching name in any table\n        for ws in self.worksheets:\n            try:\n                table = ws.get_table(name)\n                return table, ws\n            except KeyError:\n                pass\n\n        raise KeyError(name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsends a message to the socket", "response": "def send_message(self, output):\n        \"\"\"\n        Send a message to the socket\n        \"\"\"\n\n        file_system_event = None\n        if self.my_action_input:\n            file_system_event = self.my_action_input.file_system_event or None\n\n        output_action = ActionInput(file_system_event,\n                                    output,\n                                    self.name,\n                                    \"*\")\n\n        Global.MESSAGE_DISPATCHER.send_message(output_action)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef stop(self):\n        ''' Stop the current action '''\n        Global.LOGGER.debug(f\"action {self.name} stopped\")\n        self.is_running = False\n        self.on_stop()", "response": "Stop the current action."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_action_for_code(cls, action_code, name, configuration, managed_input):\n        Global.LOGGER.debug(f\"creating action {name} for code {action_code}\")\n        Global.LOGGER.debug(f\"configuration length: {len(configuration)}\")\n        Global.LOGGER.debug(f\"input: {managed_input}\")\n\n        # get the actions catalog\n        my_actions_file = Action.search_actions()\n\n        # load custom actions to find the right one\n        for filename in my_actions_file:\n            module_name = os.path.basename(os.path.normpath(filename))[:-3]\n\n            # garbage collect all the modules you load if they are not necessary\n            context = {}\n            Action.load_module(module_name, filename)\n            for subclass in Action.__subclasses__():\n                if subclass.type == action_code:\n                    action_class = subclass\n                    action = action_class(name, configuration, managed_input)\n                    return action\n            subclass = None\n            gc.collect()", "response": "Create an instance of an action from an input code."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nextract a LinkableClass from a jar.", "response": "def extract_class(jar, name):\n    \"\"\"Extracts a LinkableClass from a jar.\n\n    Args:\n        jar: An open ZipFile instance.\n        name: A string containing the binary name of a class.\n\n    Raises:\n        KeyError: The class does not exist in the jar.\n    \"\"\"\n\n    with jar.open(name) as entry:\n        return LinkableClass(javatools.unpack_class(entry))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _format_summary_node(self, task_class):\n        modulename = task_class.__module__\n        classname = task_class.__name__\n        nodes = []\n\n        nodes.append(\n            self._format_class_nodes(task_class))\n\n        nodes.append(\n            self._format_config_nodes(modulename, classname)\n        )\n\n        methods = ('run', 'runDataRef')\n        for method in methods:\n            if hasattr(task_class, method):\n                method_obj = getattr(task_class, method)\n                nodes.append(\n                    self._format_method_nodes(method_obj,\n                                              modulename,\n                                              classname))\n        return nodes", "response": "Format a section node containg a summary of a Task class s key APIs."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _format_class_nodes(self, task_class):\n        # Patterned after PyObject.handle_signature in Sphinx.\n        # https://github.com/sphinx-doc/sphinx/blob/3e57ea0a5253ac198c1bff16c40abe71951bb586/sphinx/domains/python.py#L246\n\n        modulename = task_class.__module__\n        classname = task_class.__name__\n        fullname = '.'.join((modulename, classname))\n\n        # The signature term\n        signature = Signature(task_class, bound_method=False)\n        desc_sig_node = self._format_signature(\n            signature, modulename, classname, fullname, 'py:class')\n\n        # The content is the one-sentence summary.\n        content_node = desc_content()\n        content_node += self._create_doc_summary(task_class, fullname,\n                                                 'py:class')\n\n        desc_node = desc()\n        desc_node['noindex'] = True\n        desc_node['domain'] = 'py'\n        desc_node['objtype'] = 'class'\n        desc_node += desc_sig_node\n        desc_node += content_node\n        return desc_node", "response": "Create a desc node summarizing the class docstring."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _format_method_nodes(self, task_method, modulename, classname):\n        methodname = task_method.__name__\n        fullname = '.'.join((modulename, classname, methodname))\n\n        # The signature term\n        signature = Signature(task_method, bound_method=True)\n        desc_sig_node = self._format_signature(\n            signature, modulename, classname, fullname, 'py:meth')\n\n        # The content is the one-sentence summary.\n        content_node = desc_content()\n        content_node += self._create_doc_summary(task_method, fullname,\n                                                 'py:meth')\n\n        desc_node = desc()\n        desc_node['noindex'] = True\n        desc_node['domain'] = 'py'\n        desc_node['objtype'] = 'method'\n        desc_node += desc_sig_node\n        desc_node += content_node\n        return desc_node", "response": "Create a desc node summarizing a method docstring."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a paragraph containing the object s one - sentence docstring containing the object s summary with a link to further documentation.", "response": "def _create_doc_summary(self, obj, fullname, refrole):\n        \"\"\"Create a paragraph containing the object's one-sentence docstring\n        summary with a link to further documentation.\n\n        The paragrah should be inserted into the ``desc`` node's\n        ``desc_content``.\n        \"\"\"\n        summary_text = extract_docstring_summary(get_docstring(obj))\n        summary_text = summary_text.strip()\n        # Strip the last \".\" because the linked ellipses take its place\n        if summary_text.endswith('.'):\n            summary_text = summary_text.rstrip('.')\n        content_node_p = nodes.paragraph(text=summary_text)\n        content_node_p += self._create_api_details_link(fullname, refrole)\n        return content_node_p"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a link to the API documentation.", "response": "def _create_api_details_link(self, fullname, refrole):\n        \"\"\"Appends a link to the API docs, labelled as \"...\", that is appended\n        to the content paragraph of an API description.\n\n        This affordance indicates that more documentation is available, and\n        that by clicking on the ellipsis the user can find that documentation.\n        \"\"\"\n        ref_text = '... <{}>'.format(fullname)\n        xref = PyXRefRole()\n        xref_nodes, _ = xref(\n            refrole, ref_text, ref_text,\n            self.lineno,\n            self.state.inliner)\n        return xref_nodes"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a desc node summarizing the config attribute.", "response": "def _format_config_nodes(self, modulename, classname):\n        \"\"\"Create a ``desc`` node summarizing the config attribute\n\n        The ``config`` attribute is not statically available from a task class.\n        This method manually creates a signature and docstring for the\n        config attribute.\n        \"\"\"\n        fullname = '{0}.{1}.config'.format(modulename, classname)\n\n        # The signature term\n        desc_sig_node = desc_signature()\n        desc_sig_node['module'] = modulename\n        desc_sig_node['class'] = classname\n        desc_sig_node['fullname'] = fullname\n\n        prefix = 'attribute'\n        desc_sig_node += desc_annotation(prefix, prefix)\n        desc_sig_name_node = desc_addname('config', 'config')\n        # Fakes the look of a cross reference.\n        desc_sig_name_node['classes'].extend(['xref', 'py'])\n        desc_sig_node += desc_sig_name_node\n\n        # The content is the one-sentence summary.\n        summary_text = (\n            'Access configuration fields and retargetable subtasks.'\n        )\n        content_node_p = nodes.paragraph(text=summary_text)\n        content_node = desc_content()\n        content_node += content_node_p\n\n        desc_node = desc()\n        desc_node['noindex'] = True\n        desc_node['domain'] = 'py'\n        desc_node['objtype'] = 'attribute'\n        desc_node += desc_sig_node\n        desc_node += content_node\n        return desc_node"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _format_import_example(self, task_class):\n        code = 'from {0.__module__} import {0.__name__}'.format(task_class)\n\n        # This is a bare-bones version of what Sphinx's code-block directive\n        # does. The 'language' attr triggers the pygments treatment.\n        literal_node = nodes.literal_block(code, code)\n        literal_node['language'] = 'py'\n\n        return [literal_node]", "response": "Generate nodes that show a code sample demonstrating how to import\n            the task class."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nformat a message that referring the reader to the full API docs.", "response": "def _format_api_docs_link_message(self, task_class):\n        \"\"\"Format a message referring the reader to the full API docs.\n\n        Parameters\n        ----------\n        task_class : ``lsst.pipe.base.Task``-type\n            The Task class.\n\n        Returns\n        -------\n        nodes : `list` of docutils nodes\n            Docutils nodes showing a link to the full API docs.\n        \"\"\"\n        fullname = '{0.__module__}.{0.__name__}'.format(task_class)\n\n        p_node = nodes.paragraph()\n\n        _ = 'See the '\n        p_node += nodes.Text(_, _)\n\n        xref = PyXRefRole()\n        xref_nodes, _ = xref(\n            'py:class',\n            '~' + fullname,\n            '~' + fullname,\n            self.lineno,\n            self.state.inliner)\n\n        p_node += xref_nodes\n\n        _ = ' API reference for complete details.'\n        p_node += nodes.Text(_, _)\n\n        seealso_node = seealso()\n        seealso_node += p_node\n\n        return [seealso_node]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nstart a manhole server on a given TCP and UNIX address.", "response": "def start_manhole(banner=None, host='127.0.0.1', port=None, path=None,\n        namespace=None, loop=None, threaded=False, command_timeout=5,\n        shared=False):\n\n    \"\"\"Starts a manhole server on a given TCP and/or UNIX address.\n\n    Keyword arguments:\n        banner - Text to display when client initially connects.\n        host - interface to bind on.\n        port - port to listen on over TCP. Default is disabled.\n        path - filesystem path to listen on over UNIX sockets. Deafult is disabled.\n        namespace - dictionary namespace to provide to connected clients.\n        threaded - if True, use a threaded interpreter. False, run them in the\n                   middle of the event loop. See ThreadedInteractiveInterpreter\n                   for details.\n        command_timeout - timeout in seconds for commands. Only applies if\n                          `threaded` is True.\n        shared - If True, share a single namespace between all clients.\n\n    Returns a Future for starting the server(s).\n    \"\"\"\n\n    loop = loop or asyncio.get_event_loop()\n\n    if (port, path) == (None, None):\n        raise ValueError('At least one of port or path must be given')\n\n    if threaded:\n        interpreter_class = functools.partial(\n            ThreadedInteractiveInterpreter, command_timeout=command_timeout)\n    else:\n        interpreter_class = InteractiveInterpreter\n\n    client_cb = InterpreterFactory(\n        interpreter_class, shared=shared, namespace=namespace, banner=banner,\n        loop=loop)\n\n    coros = []\n\n    if path:\n        f = asyncio.ensure_future(\n            asyncio.start_unix_server(client_cb, path=path, loop=loop))\n        coros.append(f)\n\n    if port:\n        f = asyncio.ensure_future(asyncio.start_server(\n            client_cb, host=host, port=port, loop=loop), loop=loop)\n        coros.append(f)\n\n    return asyncio.gather(*coros, loop=loop)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef handle_one_command(self):\n\n        while True:\n            yield from self.write_prompt()\n            codeobj = yield from self.read_command()\n\n            if codeobj is not None:\n                yield from self.run_command(codeobj)", "response": "Process a single command. May have many lines."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nexecutes a compiled code object and write the output back to the client.", "response": "def run_command(self, codeobj):\n        \"\"\"Execute a compiled code object, and write the output back to the client.\"\"\"\n        try:\n            value, stdout = yield from self.attempt_exec(codeobj, self.namespace)\n        except Exception:\n            yield from self.send_exception()\n            return\n        else:\n            yield from self.send_output(value, stdout)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread a command from the user line by line. Returns a code object suitable for execution.", "response": "def read_command(self):\n        \"\"\"Read a command from the user line by line.\n\n        Returns a code object suitable for execution.\n        \"\"\"\n\n        reader = self.reader\n\n        line = yield from reader.readline()\n        if line == b'':  # lost connection\n            raise ConnectionResetError()\n\n        try:\n            # skip the newline to make CommandCompiler work as advertised\n            codeobj = self.attempt_compile(line.rstrip(b'\\n'))\n        except SyntaxError:\n            yield from self.send_exception()\n            return\n\n        return codeobj"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrite the output or value of the expression back to user.", "response": "def send_output(self, value, stdout):\n        \"\"\"Write the output or value of the expression back to user.\n\n        >>> 5\n        5\n        >>> print('cash rules everything around me')\n        cash rules everything around me\n        \"\"\"\n\n        writer = self.writer\n\n        if value is not None:\n            writer.write('{!r}\\n'.format(value).encode('utf8'))\n\n        if stdout:\n            writer.write(stdout.encode('utf8'))\n\n        yield from writer.drain()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlists all products in the", "response": "def list(context, sort, limit, where, verbose):\n    \"\"\"list(context, sort, limit, where, verbose)\n\n    List all products.\n\n    >>> dcictl product list\n\n    :param string sort: Field to apply sort\n    :param integer limit: Max number of rows to return\n    :param string where: An optional filter criteria\n    :param boolean verbose: Display verbose output\n    \"\"\"\n    result = product.list(context, sort=sort, limit=limit, where=where)\n    utils.format_output(result, context.format, verbose=verbose)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a new product in the available order", "response": "def create(context, name, label, description, active, team_id):\n    \"\"\"create(context, name, label, description, active, team_id)\n\n    Create a product.\n\n    >>> dcictl product-create [OPTIONS]\n\n    :param string name: Name of the product [required]\n    :param string label: Label of the product [optional]\n    :param string description: Description of the product [optional]\n    :param boolean active: Set the product in the (in)active state\n    :param string team_id: Team the product belongs to [required]\n    \"\"\"\n\n    state = utils.active_string(active)\n    result = product.create(context, name=name, team_id=team_id,\n                            label=label, description=description, state=state)\n    utils.format_output(result, context.format)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update(context, id, etag, name, description, active, team_id):\n\n    result = product.update(context, id=id, etag=etag, name=name,\n                            description=description,\n                            state=utils.active_string(active),\n                            team_id=team_id)\n\n    utils.format_output(result, context.format)", "response": "Update a specific product in a node"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef call(self, method, *args):\n        try:\n            response = getattr(self.client.service, method)(*args)\n        except (URLError, SSLError) as e:\n            log.exception('Failed to connect to responsys service')\n            raise ConnectError(\"Request to service timed out\")\n        except WebFault as web_fault:\n            fault_name = getattr(web_fault.fault, 'faultstring', None)\n            error = str(web_fault.fault.detail)\n\n            if fault_name == 'TableFault':\n                raise TableFault(error)\n            if fault_name == 'ListFault':\n                raise ListFault(error)\n            if fault_name == 'API_LIMIT_EXCEEDED':\n                raise ApiLimitError(error)\n            if fault_name == 'AccountFault':\n                raise AccountFault(error)\n\n            raise ServiceError(web_fault.fault, web_fault.document)\n        return response", "response": "Calls the service method with the arguments provided"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconnect to the Responsys soap service.", "response": "def connect(self):\n        \"\"\" Connects to the Responsys soap service\n\n        Uses the credentials passed to the client init to login and setup the session id returned.\n        Returns True on successful connection, otherwise False.\n        \"\"\"\n\n        if self.session and self.session.is_expired:\n            # Close the session to avoid max concurrent session errors\n            self.disconnect(abandon_session=True)\n\n        if not self.session:\n\n            try:\n                login_result = self.login(self.username, self.password)\n            except AccountFault:\n                log.error('Login failed, invalid username or password')\n                raise\n            else:\n                self.session = login_result.session_id\n\n        self.connected = time()\n        return self.connected"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef disconnect(self, abandon_session=False):\n        self.connected = False\n        if (self.session and self.session.is_expired) or abandon_session:\n            try:\n                self.logout()\n            except:\n                log.warning(\n                    'Logout call to responsys failed, session may have not been terminated',\n                    exc_info=True\n                )\n            del self.session\n        return True", "response": "Disconnects from the Responsys soap service. Returns True on success False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete_list_members(self, list_, query_column, ids_to_delete):\n        list_ = list_.get_soap_object(self.client)\n        result = self.call('deleteListMembers', list_, query_column, ids_to_delete)\n        if hasattr(result, '__iter__'):\n            return [DeleteResult(delete_result) for delete_result in result]\n        return [DeleteResult(result)]", "response": "Responsys.deleteListMembers call\n\n        Accepts:\n            InteractObject list_\n            string query_column\n                possible values: 'RIID'|'EMAIL_ADDRESS'|'CUSTOMER_ID'|'MOBILE_NUMBER'\n            list ids_to_delete\n\n        Returns a list of DeleteResult instances"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef retrieve_profile_extension_records(self, profile_extension, field_list, ids_to_retrieve,\n                                           query_column='RIID'):\n        \"\"\" Responsys.retrieveProfileExtensionRecords call\n\n        Accepts:\n            InteractObject profile_extension\n            list field_list\n            list ids_to_retrieve\n            string query_column\n                default: 'RIID'\n\n        Returns RecordData\n        \"\"\"\n        profile_extension = profile_extension.get_soap_object(self.client)\n        return RecordData.from_soap_type(\n            self.call('retrieveProfileExtensionRecords',\n                      profile_extension, query_column, field_list, ids_to_retrieve))", "response": "This method returns the list of records associated with a profile extension."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef delete_table_records(self, table, query_column, ids_to_delete):\n        table = table.get_soap_object(self.client)\n        result = self.call('deleteTableRecords', table, query_column, ids_to_delete)\n        if hasattr(result, '__iter__'):\n            return [DeleteResult(delete_result) for delete_result in result]\n        return [DeleteResult(result)]", "response": "Responsys.deleteTableRecords call\n\n        Accepts:\n            InteractObject table\n            string query_column\n                possible values: 'RIID'|'EMAIL_ADDRESS'|'CUSTOMER_ID'|'MOBILE_NUMBER'\n            list ids_to_delete\n\n        Returns a list of DeleteResult instances"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef retrieve_table_records(self, table, query_column, field_list, ids_to_retrieve):\n        table = table.get_soap_object(self.client)\n        return RecordData.from_soap_type(self.call(\n            'retrieveTableRecords', table, query_column, field_list, ids_to_retrieve))", "response": "This method returns a list of records from a table."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef normalize_docroot(app, root):\n\n    srcdir = app.env.srcdir\n    default_version = app.config.javalink_default_version\n\n    if isinstance(root, basestring):\n        (url, base) = _parse_docroot_str(srcdir, root)\n        return {'root': url, 'base': base, 'version': default_version}\n    else:\n        normalized = {}\n        normalized['root'] = _parse_docroot_str(srcdir, root['root'])[0]\n\n        if 'base' in root:\n            normalized['base'] = _parse_docroot_str(srcdir, root['base'])[1]\n        else:\n            normalized['base'] = _parse_docroot_str(srcdir, root['root'])[1]\n\n        if 'version' in root:\n            normalized['version'] = root['version']\n        else:\n            normalized['version'] = default_version\n\n        return normalized", "response": "Normalizes a docroot element."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nassign pi electron and hydrogens to all the species.", "response": "def assign_valence(mol):\n    \"\"\"Assign pi electron and hydrogens\"\"\"\n    for u, v, bond in mol.bonds_iter():\n        if bond.order == 2:\n            mol.atom(u).pi = 1\n            mol.atom(v).pi = 1\n            if mol.atom(u).symbol == \"O\" and not mol.atom(u).charge:\n                mol.atom(v).carbonyl_C = 1\n            if mol.atom(v).symbol == \"O\" and not mol.atom(v).charge:\n                mol.atom(u).carbonyl_C = 1\n        elif bond.order == 3:\n            mol.atom(u).pi = mol.atom(v).pi = 2\n    max_nbr = {\"C\": 4, \"Si\": 4, \"N\": 3, \"P\": 3, \"As\": 3,\n               \"O\": 2, \"S\": 2, \"Se\": 2, \"F\": 1, \"Cl\": 1, \"Br\": 1, \"I\": 1}\n    for i, nbrs in mol.neighbors_iter():\n        atom = mol.atom(i)\n        if len(nbrs) == 2 and all(bond.order == 2 for bond in nbrs.values()):\n            atom.pi = 2  # sp (allene, ketene)\n        if atom.symbol in max_nbr:\n            h_cnt = max_nbr[atom.symbol] - len(nbrs) - atom.pi + atom.charge\n            if h_cnt > 0:\n                mol.atom(i).add_hydrogen(h_cnt)\n    mol.descriptors.add(\"Valence\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef assign_rotatable(mol):\n    mol.require(\"Valence\")\n    mol.require(\"Topology\")\n    bs = set([(u, v) for u, v, _ in mol.bonds_iter()])\n    for r in mol.rings:\n        for a, b in iterator.consecutive(r + [r[0]], 2):\n            bs -= {(a, b)}\n            bs -= {(b, a)}\n    for u, v in bs:\n        unc = mol.neighbor_count(u)\n        vnc = mol.neighbor_count(v)\n        bc = mol.bond(u, v).order\n        if bc == 1 and (unc > 1 and vnc > 1):\n            mol.bond(u, v).rotatable = True\n    mol.descriptors.add(\"Rotatable\")", "response": "Assign rotatable bonds to the next non - terminal one."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nassigns aromatic ring to aromatic molecule.", "response": "def assign_aromatic(mol):\n    \"\"\"Assign aromatic ring\n    sp2 atom:\n    pi=1 -> +1\n    N, O, S, C- -> +2\n    >C=O, B, C+ -> 0\n    sp3 atom -> not aromatic\n    sum of the score satisfies 4n+2 -> aromatic\n    \"\"\"\n    mol.require(\"Valence\")\n    mol.require(\"MinifiedRing\")\n    for ring in mol.rings:\n        pi_cnt = 0\n        for r in ring:\n            if mol.atom(r).pi == 0:\n                if mol.atom(r).symbol == \"C\":\n                    if mol.atom(r).charge == 1:\n                        pass\n                    elif mol.atom(r).charge == -1:\n                        pi_cnt += 2\n                    else:\n                        break\n                elif mol.atom(r).charge == 0:\n                    if mol.atom(r).symbol in (\"N\", \"O\", \"S\"):\n                        pi_cnt += 2\n                    elif mol.atom(r).symbol == \"B\":\n                        pass\n                    else:\n                        break\n                else:\n                    break\n            elif mol.atom(r).pi == 1:\n                if mol.atom(r).carbonyl_C:\n                    pass\n                else:\n                    pi_cnt += 1\n            else:\n                break\n        else:\n            if pi_cnt % 4 == 2:\n                for u, v in iterator.consecutive(ring + [ring[0]], 2):\n                    mol.atom(u).aromatic = True\n                    mol.bond(u, v).aromatic = True\n    mol.descriptors.add(\"Aromatic\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nassigning charges in physiological condition", "response": "def assign_charge(mol, force_recalc=False):\n    \"\"\"Assign charges in physiological condition\"\"\"\n    # TODO: not implemented yet\n    mol.require(\"Aromatic\")\n    for i, nbrs in mol.neighbors_iter():\n        atom = mol.atom(i)\n        nbrcnt = len(nbrs)\n        if atom.symbol == \"N\":\n            if not atom.pi:\n                # non-conjugated amines are anion\n                mol.atom(i).charge_phys = 1\n            elif nbrcnt == 1 and atom.pi == 2:\n                # amidine, guanidine are conjugated cation\n                ni = list(nbrs.keys())[0]\n                conj = False\n                sp2n = None\n                for nni, nnb in mol.neighbors(ni).items():\n                    if mol.atom(nni).symbol == \"N\" and nnb.order == 2 \\\n                            and not mol.atom(nni).aromatic:\n                        mol.atom(nni).charge_conj = 1\n                        conj = True\n                    elif mol.atom(nni).symbol == \"N\" and nni != i:\n                        sp2n = nni\n                if conj:\n                    mol.atom(i).charge_phys = 1\n                    if sp2n is not None:\n                        mol.atom(sp2n).charge_conj = 1\n        elif atom.symbol == \"O\" and nbrcnt == 1 and atom.pi == 2:\n            # oxoacid are conjugated anion\n            ni = list(nbrs.keys())[0]\n            conj = False\n            if mol.atom(ni).symbol == \"N\":\n                mol.atom(i).n_oxide = True\n                mol.atom(ni).n_oxide = True\n            for nni, nnb in mol.neighbors(ni).items():\n                if mol.atom(nni).symbol in (\"O\", \"S\") \\\n                        and nnb.order == 2 and not mol.atom(ni).n_oxide:\n                    mol.atom(nni).charge_conj = -1\n                    conj = True\n            if conj:\n                mol.atom(i).charge_phys = -1\n        elif atom.symbol == \"S\" and nbrcnt == 1:\n            # thiophenols are anion\n            ni = list(nbrs.keys())[0]\n            if mol.atom(ni).aromatic:\n                mol.atom(i).charge_phys = -1\n    mol.charge_assigned = True\n    mol.descriptors.add(\"Phys_charge\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a type given its importable name.", "response": "def get_type(type_name):\n    \"\"\"Get a type given its importable name.\n\n    Parameters\n    ----------\n    task_name : `str`\n        Name of the Python type, such as ``mypackage.MyClass``.\n\n    Returns\n    -------\n    object\n        The object.\n    \"\"\"\n    parts = type_name.split('.')\n    if len(parts) < 2:\n        raise SphinxError(\n            'Type must be fully-qualified, '\n            'of the form ``module.MyClass``. Got: {}'.format(type_name)\n        )\n    module_name = \".\".join(parts[0:-1])\n    name = parts[-1]\n    return getattr(import_module(module_name), name)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_task_config_fields(config_class):\n    from lsst.pex.config import Field\n\n    def is_config_field(obj):\n        return isinstance(obj, Field)\n\n    return _get_alphabetical_members(config_class, is_config_field)", "response": "Get all configuration Fields from a Config class."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget all configurable subtask fields from a Config class.", "response": "def get_subtask_fields(config_class):\n    \"\"\"Get all configurable subtask fields from a Config class.\n\n    Parameters\n    ----------\n    config_class : ``lsst.pipe.base.Config``-type\n        The configuration class (not an instance) corresponding to a Task.\n\n    Returns\n    -------\n    subtask_fields : `dict`\n        Mapping where keys are the config attribute names and values are\n        subclasses of ``lsst.pex.config.ConfigurableField`` or\n        ``RegistryField``). The mapping is alphabetically ordered by\n        attribute name.\n    \"\"\"\n    from lsst.pex.config import ConfigurableField, RegistryField\n\n    def is_subtask_field(obj):\n        return isinstance(obj, (ConfigurableField, RegistryField))\n\n    return _get_alphabetical_members(config_class, is_subtask_field)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_alphabetical_members(obj, predicate):\n    fields = dict(inspect.getmembers(obj, predicate))\n    keys = list(fields.keys())\n    keys.sort()\n    return {k: fields[k] for k in keys}", "response": "Get members of an object sorted alphabetically."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmake a string for the object s type.", "response": "def typestring(obj):\n    \"\"\"Make a string for the object's type\n\n    Parameters\n    ----------\n    obj : obj\n        Python object.\n\n    Returns\n    -------\n    `str`\n        String representation of the object's type. This is the type's\n        importable namespace.\n\n    Examples\n    --------\n    >>> import docutils.nodes\n    >>> para = docutils.nodes.paragraph()\n    >>> typestring(para)\n    'docutils.nodes.paragraph'\n    \"\"\"\n    obj_type = type(obj)\n    return '.'.join((obj_type.__module__, obj_type.__name__))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_docstring(obj):\n    docstring = getdoc(obj, allow_inherited=True)\n    if docstring is None:\n        logger = getLogger(__name__)\n        logger.warning(\"Object %s doesn't have a docstring.\", obj)\n        docstring = 'Undocumented'\n    # ignore is simply the number of initial lines to ignore when determining\n    # the docstring's baseline indent level. We really want \"1\" here.\n    return prepare_docstring(docstring, ignore=1)", "response": "Extract the docstring from an object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef extract_docstring_summary(docstring):\n    summary_lines = []\n    for line in docstring:\n        if line == '':\n            break\n        else:\n            summary_lines.append(line)\n    return ' '.join(summary_lines)", "response": "Extract the first summary sentence from a docstring."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing the attribute data from a wiki html document", "response": "def get_attribute_data(doc):\n    \"\"\"Helper function: parse attribute data from a wiki html doc\n\n    Args:\n        doc (document parsed with lxml.html): parsed wiki page\n\n    Returns:\n        dict: attributes values and listed links, format ``{<key>: {'value': <value>, 'link': <link>}}``;\n              only the first hyperlink listed in each attribute value is included\n    \"\"\"\n    attributes = dict()\n    for attribute_node in doc.xpath(\"//div[contains(@class, 'pi-data ')]\"):\n        # label node\n        node = attribute_node.xpath(\".//*[contains(@class, 'pi-data-label')]\")[0]\n        label = \" \".join(node.itertext()).strip()\n\n        # value node\n        node = attribute_node.xpath(\".//*[contains(@class, 'pi-data-value')]\")[0]\n\n        # get value, first link, and the link text\n        value = \" \".join(node.itertext()).strip()\n        link_node = node.find('a')\n        if link_node is not None:\n            link = link_node.get('href')\n            link_text = link_node.text\n        else:\n            link = None\n            link_text = None\n\n        # store result\n        attributes[label] = dict(value=value,\n                                 link=link,\n                                 link_text=link_text)\n\n    return attributes"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nruns loading of movie appearances.", "response": "def run(self):\n        \"\"\"Run loading of movie appearances.\n\n        The wiki page structure for this part cannot be easily handled by simple xpath queries.\n        We need to iterate over the respective portion of the page and parse appearances.\n        \"\"\"\n\n        # make all requests via a cache instance\n        request_cache = cache.get_request_cache()\n\n        # DB session to operate in\n        session = client.get_client().create_session()\n\n        # clear completion flag for this task\n        self.mark_incomplete()\n\n        # list of universes seen in character appearances\n        universes = []\n\n        # don't auto-flush the session for queries, this causes issues with the 'id' field of newly\n        # created MovieAppearance instances\n        with session.no_autoflush:\n\n            # get all movies\n            movies = session.query(models.Movie).all()\n\n            # iterate over all movies and build appearance objects\n            for movie in movies:\n\n                # retrieve movie article, keep main article content only, parse\n                article = request_cache.get(\"http://marvel.wikia.com\" + movie.url,\n                                            xpath=\"//article[@id='WikiaMainContent']\",\n                                            rate_limit=0.5)\n                doc = html.fromstring(article)\n\n                # find heading for appearances, this is a span inside an h2; go to the h2\n                node = doc.xpath(\"//span[@id='Appearances']\")[0]\n                node = node.getparent()\n\n                # Appearance type is given by <p><b>... some text ...</b></p> tags. Sometimes the first\n                # group of appearances carries no such label, assume it's the featured characters.\n                appearance_type = \"Featured Characters\"\n\n                # walk along the tree; character lists are in <ul>s, labels in <p>s;\n                # the next h2 ends the character listing\n                node = node.getnext()\n                while node is not None and node.tag != 'h2':\n                    if node.tag == 'ul' and ('characters' in appearance_type.lower() or\n                                                     'villains' in appearance_type.lower()):\n                        # starts a new list of stuff; only enter here if the previous label was for characters;\n                        # use iter() to iterate over all 'li' items (also those of nested lists)\n                        for li in node.iter('li'):\n                            # inside the list element, find all 'a's; iterate over child nodes, don't use iter(),\n                            # since we want don't want to find 'a's of sub-elements in a nested list here\n                            for a in li:\n                                if a.tag != 'a':\n                                    continue\n\n                                # there are 'a's in the list that wrap imags, don't use these; also don't use\n                                # links that lead to somewhere else than the wiki\n                                if \"image\" in a.get(\"class\", \"\") or not a.get(\"href\").startswith(\"/wiki/\"):\n                                    continue\n\n                                match = re.search(r'\\(.*?\\)', a.get('href'))\n                                if match:\n                                    universes.append(match.group()[1:-1])\n\n                                # accept the first matching href, build a new appearance object, then skip to next li\n                                try:\n                                    character = session.query(models.Character) \\\n                                        .filter(models.Character.url == a.get(\"href\")) \\\n                                        .one()\n\n                                    # -- start documentation include: many-to-many-generation\n                                    appearance = models.MovieAppearance(movie_id=movie.id,\n                                                                        character_id=character.id,\n                                                                        appearance_type=appearance_type)\n                                    session.add(appearance)\n                                    # -- end documentation include: many-to-many-generation\n\n                                except NoResultFound:\n                                    # none found, ignore\n                                    pass\n\n                                # break looping over 'a's once we have found one, go to next 'li'\n                                break\n\n                    elif node.tag == 'p':\n                        # new character class (or label for locations, items, ...)\n                        appearance_type = \" \".join(node.itertext()).strip().strip(':').strip()\n                    node = node.getnext()\n\n        print(\"\\nNumber of character appearances per universe: \")\n        print(pd.Series(data=universes).value_counts())\n\n        # done, save all data, finalize task\n        session.commit()\n        session.close()\n        self.mark_complete()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload table pandas. DataFrame", "response": "def load(self):\n        \"\"\"Load table\n\n        Keeps only rows with annual average defined (full year data available).\n\n        Returns:\n            pandas.DataFrame: loaded data\n        \"\"\"\n        df = pd.read_excel(self.input_file, skiprows=11)\n        df = df.dropna(subset=['Annual'])\n        return df"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nclearing task output: remove value ``budget_inflation_adjusted`` from all :class:`Movie` objects.", "response": "def clear(self):\n        \"\"\"Clear task output: remove value ``budget_inflation_adjusted`` from all :class:`Movie` objects.\n        \"\"\"\n        self.mark_incomplete()\n        session = client.get_client().create_session()\n\n        movies = session.query(models.Movie)\n        movies.update({'budget_inflation_adjusted': None})\n\n        session.commit()\n        session.close()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run(self):\n        self.mark_incomplete()\n        session = client.get_client().create_session()\n\n        # load CPI data\n        cpi = ConsumerPriceIndexFile().load()\n\n        # max year we have CPI data for\n        max_cpi_year = cpi['Year'].max()\n\n        # extract annual average only, index by year\n        cpi = cpi.set_index('Year')['Annual']\n\n        # process all movies\n        for movie in session.query(models.Movie).all():\n            # we can only compute an inflation-adjusted budget if we know the year and budget\n            if movie.year is not None and movie.budget is not None:\n                if movie.year > max_cpi_year:\n                    # if movie is too new, don't inflation-adjust\n                    movie.budget_inflation_adjusted = movie.budget\n                else:\n                    movie.budget_inflation_adjusted = movie.budget * cpi.loc[max_cpi_year] / cpi.loc[movie.year]\n\n        # done, save all data, finalize task\n        session.commit()\n        session.close()\n        self.mark_complete()", "response": "Compute and store inflation - adjusted movie budgets\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the indexes in descending order of the top k score or all scores if k is None", "response": "def _argsort(y_score, k=None):\n    \"\"\"\n    Returns the indexes in descending order of the top k score\n        or all scores if k is None\n    \"\"\"\n    ranks = y_score.argsort()\n    argsort = ranks[::-1]\n    if k is not None:\n        argsort = argsort[0:k]\n\n    return argsort"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _argtop(y_score, k=None):\n    # avoid sorting when just want the top all\n    if k is None:\n        return slice(0, len(y_score))\n    else:\n        return _argsort(y_score, k)", "response": "Returns the indexes of the top k scores"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef count(y_true, y_score=None, countna=False):\n    if not countna:\n        return (~np.isnan(to_float(y_true))).sum()\n    else:\n        return len(y_true)", "response": "Counts the number of examples in a single resource set."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef count_series(y_true, y_score, countna=False):\n    y_true, y_score = to_float(y_true, y_score)\n    top = _argsort(y_score)\n\n    if not countna:\n        a = (~np.isnan(y_true[top])).cumsum()\n    else:\n        a = range(1, len(y_true)+1)\n\n    return pd.Series(a, index=range(1, len(a)+1))", "response": "Returns series whose i - th entry is the number of examples in the top i\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef baseline(y_true, y_score=None):\n    if len(y_true) > 0:\n        return np.nansum(y_true)/count(y_true, countna=False)\n    else:\n        return 0.0", "response": "Calculate the baseline of the log - likelihood of a set of positive labels."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef roc_auc(y_true, y_score):\n    notnull = ~np.isnan(y_true)\n    fpr, tpr, thresholds = sklearn.metrics.roc_curve(y_true[notnull], y_score[notnull])\n    return sklearn.metrics.auc(fpr, tpr)", "response": "Returns are under the ROC curve"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the precision of the labeled examples in the top k.", "response": "def precision(y_true, y_score, k=None, return_bounds=False):\n    \"\"\"\n    If return_bounds is False then returns precision on the\n        labeled examples in the top k.\n    If return_bounds is True the returns a tuple containing:\n        - precision on the labeled examples in the top k\n        - number of labeled examples in the top k\n        - lower bound of precision in the top k, assuming all\n            unlabaled examples are False\n        - upper bound of precision in the top k, assuming all\n            unlabaled examples are True\n    \"\"\"\n    y_true, y_score = to_float(y_true, y_score)\n    top = _argtop(y_score, k)\n\n    n = np.nan_to_num(y_true[top]).sum()    # fill missing labels with 0\n    d = (~np.isnan(y_true[top])).sum()      # count number of labels\n    p = n/d\n\n    if return_bounds:\n        k = len(y_true) if k is None else k\n        bounds = (n/k, (n+k-d)/k) if k != 0 else (np.nan, np.nan)\n        return p, d, bounds[0], bounds[1]\n    else:\n        return p"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef precision_series(y_true, y_score, k=None):\n    y_true, y_score = to_float(y_true, y_score)\n    top = _argsort(y_score, k)\n\n    n = np.nan_to_num(y_true[top]).cumsum()  # fill missing labels with 0\n    d = (~np.isnan(y_true[top])).cumsum()    # count number of labels\n    return pd.Series(n/d, index=np.arange(1, len(n)+1))", "response": "Returns a Pandas series of length k whose i - th entry is the precision in the top i - th entry."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef recall(y_true, y_score, k=None, value=True):\n    y_true, y_score = to_float(y_true, y_score)\n    top = _argtop(y_score, k)\n\n    if not value:\n        y_true = 1-y_true\n\n    r = np.nan_to_num(y_true[top]).sum()\n\n    return r", "response": "Returns the recall of positive examples in the top k\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef recall_series(y_true, y_score, k=None, value=True):\n    y_true, y_score = to_float(y_true, y_score)\n    top = _argsort(y_score, k)\n\n    if not value:\n        y_true = 1-y_true\n\n    a = np.nan_to_num(y_true[top]).cumsum()\n    return pd.Series(a, index=np.arange(1, len(a)+1))", "response": "Returns a pandas Series of length k whose i - th entry is the recall in the top i\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef autorotate(image, orientation=None):\n    orientation_value = orientation if orientation else \\\n        image._getexif().get(EXIF_KEYS.get('Orientation'))\n    if orientation_value is None:\n        raise ImDirectException(\"No orientation available in Exif \"\n                                \"tag or given explicitly.\")\n\n    if orientation_value in (1, 2):\n        i = image\n    elif orientation_value in (3, 4):\n        i = image.transpose(Image.ROTATE_180)\n    elif orientation_value in (5, 6):\n        i = image.transpose(Image.ROTATE_270)\n    elif orientation_value in (7, 8):\n        i = image.transpose(Image.ROTATE_90)\n    else:\n        i = image\n\n    if orientation_value in (2, 4, 5, 7):\n        i = i.transpose(Image.FLIP_LEFT_RIGHT)\n\n    return i", "response": "Rotate and return an image according to its Exif information."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupdate the exif dict with the new values for the image rotation.", "response": "def update_exif_for_rotated_image(exif):\n    \"\"\"Modifies the Exif tag if rotation has been performed.\n\n    0th, 1st\n    --------\n    ImageWidth = 256\n    ImageLength = 257\n    XResolution = 282\n    YResolution = 283\n    TileWidth = 322\n    TileLength = 323\n\n    Exif\n    ----\n    PixelXDimension = 40962\n    PixelYDimension = 40963\n\n    Args:\n        exif (dict): The parsed Exif tag\n\n    Returns:\n        The modified Exif dict.\n\n    \"\"\"\n    orientation_value = exif.get('0th', ).get(\n        piexif.ImageIFD.Orientation, exif.get('1st', ).get(\n            piexif.ImageIFD.Orientation, None))\n\n    if orientation_value is not None:\n        # Update orientation.\n        exif['0th'][piexif.ImageIFD.Orientation] = 1\n        if exif.get('1st', {}).get(piexif.ImageIFD.Orientation) is not None:\n            exif['1st'][piexif.ImageIFD.Orientation] = 1\n\n        # If 90 or 270 degree rotation, x dimensions are now y dimensions,\n        # so flip all such properties.\n        if orientation_value > 4:\n            for exif_tag in ['0th', '1st']:\n                if exif.get(exif_tag) is not None:\n                    x, y = (exif.get(exif_tag).get(piexif.ImageIFD.ImageWidth),\n                            exif.get(exif_tag).get(piexif.ImageIFD.ImageLength))\n                    if x is not None and y is not None:\n                        exif[exif_tag][piexif.ImageIFD.ImageWidth] = y\n                        exif[exif_tag][piexif.ImageIFD.ImageLength] = x\n\n                    x, y = (exif.get(exif_tag).get(piexif.ImageIFD.XResolution),\n                            exif.get(exif_tag).get(piexif.ImageIFD.YResolution))\n                    if x is not None and y is not None:\n                        exif[exif_tag][piexif.ImageIFD.XResolution] = y\n                        exif[exif_tag][piexif.ImageIFD.YResolution] = x\n\n                    x, y = (exif.get(exif_tag).get(piexif.ImageIFD.TileWidth),\n                            exif.get(exif_tag).get(piexif.ImageIFD.TileLength))\n                    if x is not None and y is not None:\n                        exif[exif_tag][piexif.ImageIFD.TileWidth] = y\n                        exif[exif_tag][piexif.ImageIFD.TileLength] = x\n            if exif.get('Exif') is not None:\n                x, y = (exif.get('Exif').get(piexif.ExifIFD.PixelXDimension),\n                        exif.get('Exif').get(piexif.ExifIFD.PixelYDimension))\n                if x is not None and y is not None:\n                    exif['Exif'][piexif.ExifIFD.PixelXDimension] = y\n                    exif['Exif'][piexif.ExifIFD.PixelYDimension] = x\n        if exif.get('thumbnail') is not None:\n            try:\n                thumbnail = pil_open(io.BytesIO(exif.get('thumbnail')))\n                thumbnail = autorotate(thumbnail, orientation=orientation_value)\n                with io.BytesIO() as bio:\n                    thumbnail.save(bio, format='jpeg')\n                    bio.seek(0)\n                    exif['thumbnail'] = bio.read()\n            except Exception as e:\n                warnings.warn(\"deprecated\", DeprecationWarning)\n\n    return exif"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nopen identifies the given image file and rotates it if it is a JPEG.", "response": "def imdirect_open(fp):\n    \"\"\"Opens, identifies the given image file, and rotates it if it is a JPEG.\n\n    Note that this method does NOT employ the lazy loading methodology that\n    the PIL Images otherwise use. This is done to avoid having to save new\n\n    Args:\n        fp: A filename (string), pathlib.Path object or a file-like object.\n\n    Returns:\n        The image as an :py:class:`~PIL.Image.Image` object.\n\n    Raises:\n        IOError: If the file cannot be found, or the image cannot be\n            opened and identified.\n\n    \"\"\"\n\n    img = pil_open(fp, 'r')\n    if img.format == 'JPEG':\n        # Read Exif tag on image.\n        if isinstance(fp, string_types):\n            exif = piexif.load(text_type_to_use(fp))\n        else:\n            fp.seek(0)\n            exif = piexif.load(fp.read())\n\n        # If orientation field is missing or equal to 1, nothing needs to be done.\n        orientation_value = exif.get('0th', {}).get(piexif.ImageIFD.Orientation)\n        if orientation_value is None or orientation_value == 1:\n            return img\n        # Otherwise, rotate the image and update the exif accordingly.\n        img_rot = autorotate(img)\n        exif = update_exif_for_rotated_image(exif)\n\n        # Now, lets restore the output image to\n        # PIL.JpegImagePlugin.JpegImageFile class with the correct,\n        # updated Exif information.\n        # Save image as JPEG to get a correct byte representation of\n        # the image and then read it back.\n        with io.BytesIO() as bio:\n            img_rot.save(bio, format='jpeg', exif=piexif.dump(exif))\n            bio.seek(0)\n            img_rot_new = pil_open(bio, 'r')\n            # Since we use a BytesIO we need to avoid the lazy\n            # loading of the PIL image. Therefore, we explicitly\n            # load the data here.\n            img_rot_new.load()\n        img = img_rot_new\n\n    return img"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmonkey patching PIL. Image. open method.", "response": "def monkey_patch(enabled=True):\n    \"\"\"Monkey patching PIL.Image.open method\n\n    Args:\n        enabled (bool): If the monkey patch should be activated or deactivated.\n\n    \"\"\"\n\n    if enabled:\n        Image.open = imdirect_open\n    else:\n        Image.open = pil_open"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef save_with_exif_info(img, *args, **kwargs):\n    if 'exif' in kwargs:\n        exif = kwargs.pop('exif')\n    else:\n        exif = img.info.get('exif')\n    img.save(*args, exif=exif, **kwargs)", "response": "Saves an image using PIL preserving the exif information."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef list(context, resource, **kwargs):\n    data = utils.sanitize_kwargs(**kwargs)\n    id = data.pop('id', None)\n    subresource = data.pop('subresource', None)\n\n    if subresource:\n        uri = '%s/%s/%s/%s' % (context.dci_cs_api, resource, id, subresource)\n    else:\n        uri = '%s/%s' % (context.dci_cs_api, resource)\n\n    return context.session.get(uri, timeout=HTTP_TIMEOUT, params=data)", "response": "List all resources in a resource."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef iter(context, resource, **kwargs):\n    data = utils.sanitize_kwargs(**kwargs)\n    id = data.pop('id', None)\n    subresource = data.pop('subresource', None)\n    data['limit'] = data.get('limit', 20)\n\n    if subresource:\n        uri = '%s/%s/%s/%s' % (context.dci_cs_api, resource, id, subresource)\n        resource = subresource\n    else:\n        uri = '%s/%s' % (context.dci_cs_api, resource)\n\n    data['offset'] = 0\n    while True:\n        j = context.session.get(uri, timeout=HTTP_TIMEOUT, params=data).json()\n        if len(j[resource]):\n            for i in j[resource]:\n                yield i\n        else:\n            break\n        data['offset'] += data['limit']", "response": "List all resources in a resource"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get(context, resource, **kwargs):\n    uri = '%s/%s/%s' % (context.dci_cs_api, resource, kwargs.pop('id'))\n    r = context.session.get(uri, timeout=HTTP_TIMEOUT, params=kwargs)\n    return r", "response": "List a specific resource"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nretrieve data field from a resource", "response": "def get_data(context, resource, **kwargs):\n    \"\"\"Retrieve data field from a resource\"\"\"\n\n    url_suffix = ''\n    if 'keys' in kwargs and kwargs['keys']:\n        url_suffix = '/?keys=%s' % ','.join(kwargs.pop('keys'))\n\n    uri = '%s/%s/%s/data%s' % (context.dci_cs_api, resource,\n                               kwargs.pop('id'), url_suffix)\n\n    r = context.session.get(uri, timeout=HTTP_TIMEOUT, params=kwargs)\n    return r"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update(context, resource, **kwargs):\n    etag = kwargs.pop('etag')\n    id = kwargs.pop('id')\n    data = utils.sanitize_kwargs(**kwargs)\n    uri = '%s/%s/%s' % (context.dci_cs_api, resource, id)\n    r = context.session.put(uri, timeout=HTTP_TIMEOUT,\n                            headers={'If-match': etag},\n                            json=data)\n    return r", "response": "Update a specific resource"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndeleting a specific resource", "response": "def delete(context, resource, id, **kwargs):\n    \"\"\"Delete a specific resource\"\"\"\n\n    etag = kwargs.pop('etag', None)\n    id = id\n    subresource = kwargs.pop('subresource', None)\n    subresource_id = kwargs.pop('subresource_id', None)\n\n    uri = '%s/%s/%s' % (context.dci_cs_api, resource, id)\n    if subresource:\n        uri = '%s/%s/%s' % (uri, subresource, subresource_id)\n\n    r = context.session.delete(uri, timeout=HTTP_TIMEOUT,\n                               headers={'If-match': etag})\n    return r"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef purge(context, resource, **kwargs):\n    uri = '%s/%s/purge' % (context.dci_cs_api, resource)\n    if 'force' in kwargs and kwargs['force']:\n        r = context.session.post(uri, timeout=HTTP_TIMEOUT)\n    else:\n        r = context.session.get(uri, timeout=HTTP_TIMEOUT)\n    return r", "response": "Purge the resource type."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse the rST - formatted string content into docutils nodes.", "response": "def parse_rst_content(content, state):\n    \"\"\"Parse rST-formatted string content into docutils nodes\n\n    Parameters\n    ----------\n    content : `str`\n        ReStructuredText-formatted content\n    state : ``docutils.statemachine.State``\n        Usually the directive's ``state`` attribute.\n\n    Returns\n    -------\n    instance from ``docutils.nodes``\n        Docutils node representing the ``content``.\n    \"\"\"\n    # http://www.sphinx-doc.org/en/master/extdev/markupapi.html\n    # #parsing-directive-content-as-rest\n    container_node = nodes.section()\n    container_node.document = state.document\n\n    viewlist = ViewList()\n    for i, line in enumerate(content.splitlines()):\n        viewlist.append(line, source='', offset=i)\n\n    with switch_source_input(state, viewlist):\n        state.nested_parse(viewlist, 0, container_node)\n\n    return container_node.children"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmake docutils nodes containing a cross - reference to a Python object.", "response": "def make_python_xref_nodes(py_typestr, state, hide_namespace=False):\n    \"\"\"Make docutils nodes containing a cross-reference to a Python object.\n\n    Parameters\n    ----------\n    py_typestr : `str`\n        Name of the Python object. For example\n        ``'mypackage.mymodule.MyClass'``. If you have the object itself, or\n        its type, use the `make_python_xref_nodes_for_type` function instead.\n    state : ``docutils.statemachine.State``\n        Usually the directive's ``state`` attribute.\n    hide_namespace : `bool`, optional\n        If `True`, the namespace of the object is hidden in the rendered\n        cross reference. Internally, this uses ``:py:obj:`~{py_obj}` (note\n        tilde).\n\n    Returns\n    -------\n    instance from ``docutils.nodes``\n        Docutils node representing the cross reference.\n\n    Examples\n    --------\n    If called from within a directive:\n\n    .. code-block:: python\n\n       make_python_xref_nodes('numpy.sin', self.state)\n\n    See also\n    --------\n    `make_python_xref_nodes_for_type`\n    \"\"\"\n    if hide_namespace:\n        template = ':py:obj:`~{}`\\n'\n    else:\n        template = ':py:obj:`{}`\\n'\n    xref_text = template.format(py_typestr)\n\n    return parse_rst_content(xref_text, state)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef make_python_xref_nodes_for_type(py_type, state, hide_namespace=False):\n    if py_type.__module__ == 'builtins':\n        typestr = py_type.__name__\n    else:\n        typestr = '.'.join((py_type.__module__,\n                            py_type.__name__))\n    return make_python_xref_nodes(typestr,\n                                  state,\n                                  hide_namespace=hide_namespace)", "response": "Make docutils nodes containing a cross - reference to a Python object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a new section node.", "response": "def make_section(section_id=None, contents=None):\n    \"\"\"Make a docutils section node.\n\n    Parameters\n    ----------\n    section_id : `str`\n        Section identifier, which is appended to both the ``ids`` and ``names``\n        attributes.\n    contents : `list` of ``docutils.nodes``\n        List of docutils nodes that are inserted into the section.\n\n    Returns\n    -------\n    ``docutils.nodes.section``\n        Docutils section node.\n    \"\"\"\n    section = nodes.section()\n    section['ids'].append(nodes.make_id(section_id))\n    section['names'].append(section_id)\n    if contents is not None:\n        section.extend(contents)\n    return section"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsplitting the rawsource of a role into standard components.", "response": "def split_role_content(role_rawsource):\n    \"\"\"Split the ``rawsource`` of a role into standard components.\n\n    Parameters\n    ----------\n    role_rawsource : `str`\n        The content of the role: its ``rawsource`` attribute.\n\n    Returns\n    -------\n    parts : `dict`\n        Dictionary with keys:\n\n        ``last_component`` (`bool`)\n           If `True`, the display should show only the last component of a\n           namespace. The user signals this by prefixing the role's content\n           with a ``~`` character.\n\n        ``display`` (`str`)\n           Custom display content. See Examples.\n\n        ``ref`` (`str`)\n           The reference content. If the role doesn't have a custom display,\n           the reference will be the role's content. The ``ref`` never\n           includes a ``~`` prefix.\n\n    Examples\n    --------\n    >>> split_role_role('Tables <lsst.afw.table.Table>')\n    {'last_component': False, 'display': 'Tables',\n    'ref': 'lsst.afw.table.Table'}\n\n    >>> split_role_role('~lsst.afw.table.Table')\n    {'last_component': True, 'display': None, 'ref': 'lsst.afw.table.Table'}\n    \"\"\"\n    parts = {\n        'last_component': False,\n        'display': None,\n        'ref': None\n    }\n\n    if role_rawsource.startswith('~'):\n        # Only the last part of a namespace should be shown.\n        parts['last_component'] = True\n        # Strip that marker off\n        role_rawsource = role_rawsource.lstrip('~')\n\n    match = ROLE_DISPLAY_PATTERN.match(role_rawsource)\n    if match:\n        parts['display'] = match.group('display').strip()\n        parts['ref'] = match.group('reference').strip()\n    else:\n        # No suggested display\n        parts['display'] = None\n        parts['ref'] = role_rawsource.strip()\n\n    return parts"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef assign_descriptors(mol):\n    topology.recognize(mol)\n    descriptor.assign_valence(mol)\n    descriptor.assign_rotatable(mol)\n    topology.minify_ring(mol)\n    descriptor.assign_aromatic(mol)", "response": "Assign descriptors to the topology."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns molecule that explicit hydrogens removed", "response": "def make_Hs_implicit(original_mol, keep_stereo=True):\n    \"\"\"Return molecule that explicit hydrogens removed\n    TODO: this query function should be renamed to \"explicitHs_removed\"\n    \"\"\"\n    mol = clone(original_mol)\n    mol.descriptors.clear()  # Reset descriptor\n    to_remove = set()\n    for i, nbrs in mol.neighbors_iter():\n        if mol.atom(i).symbol == \"H\":  # do not remove H2\n            continue\n        for nbr, bond in nbrs.items():\n            if mol.atom(nbr).symbol == \"H\" and \\\n                    not (bond.order == 1 and bond.type and keep_stereo):\n                to_remove.add(nbr)\n    for r in to_remove:\n        mol.remove_atom(r)\n    assign_descriptors(mol)\n    return mol"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a molecule which has largest graph in the compound Passing single molecule object will results as same as molutil. clone", "response": "def largest_graph(mol):\n    \"\"\"Return a molecule which has largest graph in the compound\n    Passing single molecule object will results as same as molutil.clone\n    \"\"\"\n    mol.require(\"Valence\")\n    mol.require(\"Topology\")\n    m = clone(mol)  # Avoid modification of original object\n    if m.isolated:\n        for k in itertools.chain.from_iterable(m.isolated):\n            m.remove_atom(k)\n    return m"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn standard molecular weight", "response": "def mw(mol, ndigits=2):\n    \"\"\"Return standard molecular weight\n    :param ndigits: number of digits\n    \"\"\"\n    mol.require(\"Valence\")\n    return round(sum(a.mw() for _, a in mol.atoms_iter()), ndigits)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef H_donor_count(mol):\n    mol.require(\"Valence\")\n    return sum(1 for _, a in mol.atoms_iter() if a.H_donor)", "response": "Hydrogen bond donor count"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the number of hydrogen bond acceptor atoms in a molecule.", "response": "def H_acceptor_count(mol):\n    \"\"\"Hydrogen bond acceptor count \"\"\"\n    mol.require(\"Valence\")\n    return sum(1 for _, a in mol.atoms_iter() if a.H_acceptor)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef rotatable_count(mol):\n    mol.require(\"Rotatable\")\n    return sum(1 for _, _, b in mol.bonds_iter() if b.rotatable)", "response": "Count the number of rotatable bonds in a single molecule."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef formula(mol):\n    mol.require(\"Valence\")\n    mol.require(\"Topology\")\n    total_cntr = Counter()\n    for m in sorted(mols_iter(mol), key=len, reverse=True):\n        cntr = Counter()\n        for i in m:\n            cntr += mol.atom(i).composition()\n        text = []\n        Cs = cntr.pop(\"C\", 0)\n        if Cs:\n            text.append(\"C\")\n            if Cs > 1:\n                text.append(str(Cs))\n        Hs = cntr.pop(\"H\", 0)\n        if Hs:\n            text.append(\"H\")\n            if Hs > 1:\n                text.append(str(Hs))\n        heteros = sorted(cntr.items(), key=lambda x: atom_number(x[0]))\n        for k, v in heteros:\n            text.append(k)\n            if v > 1:\n                text.append(str(v))\n        total_cntr[\"\".join(text)] += 1\n    total = sorted(total_cntr.items(), key=lambda x: len(x[0]), reverse=True)\n    total_text = []\n    for k, v in total:\n        if v > 1:\n            total_text.append(str(v) + k)\n        else:\n            total_text.append(k)\n    return \".\".join(total_text)", "response": "Chemical formula.\n    Atoms should be arranged in order of C, H and other atoms.\n    Molecules should be arranged in order of length of formula text."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef group(epilog=None, help=None, width=140, **attrs):\n    if epilog is None:\n        epilog = _get_caller_doc()\n    attrs = settings(epilog=epilog, help=help, width=width, **attrs)\n    return click.group(**attrs)", "response": "Same as click. group but with common settings"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\noverriding log file location.", "response": "def log(*args, **attrs):\n    \"\"\"Override log file location.\"\"\"\n    attrs.setdefault(\"metavar\", \"PATH\")\n    attrs.setdefault(\"show_default\", False)\n    return option(log, *args, **attrs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nshows the version and exit.", "response": "def version(*args, **attrs):\n    \"\"\"Show the version and exit.\"\"\"\n    if hasattr(sys, \"_getframe\"):\n        package = attrs.pop(\"package\", sys._getframe(1).f_globals.get(\"__package__\"))\n        if package:\n            attrs.setdefault(\"version\", get_version(package))\n    return click.version_option(*args, **attrs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef settings(epilog=None, help=None, width=140, **attrs):\n    if epilog is None:\n        epilog = _get_caller_doc()\n\n    if help is None:\n        help = [\"-h\", \"--help\"]\n\n    context_settings = attrs.pop(\"context_settings\", {})\n    context_settings[\"help_option_names\"] = flattened(help, split=\" \")\n    context_settings[\"max_content_width\"] = width\n\n    return dict(\n        epilog=epilog,\n        context_settings=context_settings,\n        **attrs\n    )", "response": "Return a dictionary of context settings for the current module."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert a molecule to RDMol", "response": "def to_rdmol(mol):\n    \"\"\"Convert molecule to RDMol\"\"\"\n    rwmol = Chem.RWMol(Chem.MolFromSmiles(''))\n    key_to_idx = {}\n    bond_type = {1: Chem.BondType.SINGLE,\n                 2: Chem.BondType.DOUBLE,\n                 3: Chem.BondType.TRIPLE}\n    conf = Chem.Conformer(rwmol.GetNumAtoms())\n    for k, a in mol.atoms_iter():\n        i = rwmol.AddAtom(Chem.Atom(atom_number(a.symbol)))\n        key_to_idx[k] = i\n        conf.SetAtomPosition(i, a.coords)\n    rwmol.AddConformer(conf)\n    for u, v, b in mol.bonds_iter():\n        ui = key_to_idx[u]\n        vi = key_to_idx[v]\n        rwmol.AddBond(ui, vi, bond_type[b.order])\n    Chem.GetSSSR(rwmol)  # Ring recognition is required for fingerprint\n    rwmol.UpdatePropertyCache(strict=False)\n    return rwmol.GetMol()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_rdmol(rdmol, assign_descriptor=True):\n    mol = Compound()\n    conf = rdmol.GetConformer()\n    Chem.Kekulize(rdmol)\n    for atom in rdmol.GetAtoms():\n        key = atom.GetIdx()\n        a = Atom(atom.GetSymbol())\n        a.coords = conf.GetAtomPosition(key)\n        mol.add_atom(key, a)\n    for bond in rdmol.GetBonds():\n        u = bond.GetBeginAtomIdx()\n        v = bond.GetEndAtomIdx()\n        b = Bond()\n        b.order = int(bond.GetBondTypeAsDouble())\n        mol.add_bond(u, v, b)\n    if assign_descriptor:\n        molutil.assign_descriptors(mol)\n    return mol", "response": "Convert a RDMol to a Molecule object"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef morgan_sim(mol1, mol2, radius=2, digit=3):\n    rdmol1 = to_rdmol(mol1)\n    rdmol2 = to_rdmol(mol2)\n    fp1 = AllChem.GetMorganFingerprint(rdmol1, radius)\n    fp2 = AllChem.GetMorganFingerprint(rdmol2, radius)\n    return round(DataStructs.DiceSimilarity(fp1, fp2), digit)", "response": "Calculate morgan fingerprint similarity by using RDKit\n    radius = 2 roughly equivalent to ECFP4\n    digit = 3"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef build(self, X, Y, w=None, edges=None):\n        super(MergeTree, self).build(X, Y, w, edges)\n\n        if self.debug:\n            sys.stdout.write(\"Merge Tree Computation: \")\n            start = time.clock()\n\n        self.__tree = MergeTreeFloat(\n            vectorFloat(self.Xnorm.flatten()),\n            vectorFloat(self.Y),\n            str(self.gradient),\n            self.graph_rep.full_graph(),\n            self.debug,\n        )\n\n        self._internal_build()\n\n        if self.debug:\n            end = time.clock()\n            sys.stdout.write(\"%f s\\n\" % (end - start))", "response": "Assigns data to this object and builds the Merge Tree object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef scale(p, factor, o=(0, 0)):\n    v = vector(o, p)\n    sv = v[0] * factor, v[1] * factor\n    return translate(sv, o)", "response": "Scale vector by a factor"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef rotate(p, rad, o=(0, 0)):\n    v = vector(o, p)\n    fx = lambda x, y, d: x * cos(d) - y * sin(d)\n    fy = lambda x, y, d: x * sin(d) + y * cos(d)\n    rv = fx(v[0], v[1], rad), fy(v[0], v[1], rad)\n    return translate(rv, o)", "response": "rotate vector\n    Args:\n      p: point (x, y)\n      rad: angle(radian)\n      o: origin (x, y)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the cross product of two points.", "response": "def cross_product(p1, p2, o=(0, 0)):\n    \"\"\" Returns cross product\n    Args:\n      p1, p2: point (x, y)\n      o: origin\n    \"\"\"\n    v1 = vector(o, p1)\n    v2 = vector(o, p2)\n    return v1[0] * v2[1] - v1[1] * v2[0]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dot_product(p1, p2, o=(0, 0)):\n    v1 = vector(o, p1)\n    v2 = vector(o, p2)\n    return v1[0] * v2[0] + v1[1] * v2[1]", "response": "Returns the dot product of two points."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef interior_angle(p1, p2, o=(0, 0)):\n    v1 = vector(o, p1)\n    v2 = vector(o, p2)\n    len1 = distance(o, p1)\n    len2 = distance(o, p2)\n    try:\n        return acos(dot_product(v1, v2) / (len1 * len2))\n    except ZeroDivisionError:\n        raise ValueError(\"p1 or p2 is overlapped with origin\")", "response": "Returns the interior angle of two points."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef m_seg(p1, p2, rad, dist):\n    v = vector(p1, p2)\n    m = unit(rotate(v, rad), dist)\n    return translate(p1, m), translate(p2, m)", "response": "Move segment by distance"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntrimming segment Args: p1, p2: point(x, y) t: scaling factor (1 - trimed segment / original segment) align: 1: trim p2, 2: trim p1, 0: both side Return: trimmed segment(p1, p2)", "response": "def t_seg(p1, p2, t, align=0):\n    \"\"\" trim segment\n    Args:\n      p1, p2: point(x, y)\n      t: scaling factor (1 - trimed segment / original segment)\n      align: 1: trim p2, 2: trim p1, 0: both side\n    Return:\n      trimmed segment(p1, p2)\n    \"\"\"\n    v = vector(p1, p2)\n    result = {\n        1: lambda a, b: (a, translate(b, scale(v, -t))),\n        2: lambda a, b: (translate(a, scale(v, t)), b),\n        0: lambda a, b: (translate(a, scale(v, t / 2)),\n                         translate(b, scale(v, -t / 2)))\n    }\n    return result[align](p1, p2)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef p_seg(p1, p2, cw, interval, trim=0, align=0):\n    case = {True: pi / -2, False: pi / 2}\n    p1m, p2m = m_seg(p1, p2, case[cw], interval)\n    return t_seg(p1m, p2m, trim, align)", "response": "parallel segment\n    Args:\n      p1, p2: point(x, y)\n      cw: m_seg rad True: -\u03c0/2, False: \u03c0/2\n      interval: m_seg dist\n      trim: t_seg trim\n      align: t_seg align"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nevaluate whether the given list of vertices are in clockwise order.", "response": "def is_clockwise(vertices):\n    \"\"\" Evaluate whether vertices are in clockwise order.\n    Args:\n      vertices: list of vertices (x, y) in polygon.\n    Returns:\n      True: clockwise, False: counter-clockwise\n    Raises:\n      ValueError: the polygon is complex or overlapped.\n    \"\"\"\n    it = iterator.consecutive(cycle(vertices), 3)\n    clockwise = 0\n    counter = 0\n    for _ in range(len(vertices)):\n        p0, p1, p2 = next(it)\n        cross = cross_product(p1, p2, p0)\n        int_angle = interior_angle(p0, p2, p1)  # raises ValueError\n        if cross < 0:\n            clockwise += int_angle\n            counter += 2 * pi - int_angle\n        else:\n            clockwise += 2 * pi - int_angle\n            counter += int_angle\n    if round(clockwise / pi) == len(vertices) - 2:\n        return True\n    elif round(counter / pi) == len(vertices) - 2:\n        return False\n    else:\n        raise ValueError(\"the polygon is complex or overlapped\")"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pop(self, strip=False):\n        r = self.contents()\n        self.clear()\n        if r and strip:\n            r = r.strip()\n        return r", "response": "Pop the current content from the list."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef contents(self):\n        c = self._header[:]\n        c.append(' font-weight=\"{}\"'.format(self.font_weight))\n        c.append(' font-family=\"{}\"'.format(self.font_family))\n        c.append(' width=\"{}\" height=\"{}\"'.format(*self.screen_size))\n        sclw = self.original_size[0] * self.scale_factor\n        sclh = self.original_size[1] * self.scale_factor\n        longside = max([sclw, sclh])\n        width = round(longside + self.margin * 2, 2)\n        height = round(longside + self.margin * 2, 2)\n        xleft = round(-self.margin - (longside - sclw) / 2, 2)\n        ytop = round(-self.margin - (longside - sclh) / 2, 2)\n        c.append(' viewBox=\"{} {} {} {}\">\\n'.format(\n            xleft, ytop, width, height))\n        if self.bgcolor is not None:\n            c.append('<rect x=\"{}\", y=\"{}\" width=\"{}\" height=\"{}\" fill=\"{}\" \\\n                />\\n'.format(xleft, ytop, width, height, self.bgcolor))\n        c.extend(self._elems)\n        c.append(\"</svg>\")\n        return \"\".join(c)", "response": "Get the contents of the image."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting svg in Data URL Scheme format.", "response": "def data_url_scheme(self):\n        \"\"\"Get svg in Data URL Scheme format.\n        \"\"\"\n        # TODO: move to web.app or make it function\n        # remove #svg from dataframe\n        encoded = base64.b64encode(self.contents().encode())\n        return \"data:image/svg+xml;base64,\" + encoded.decode()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsave the current object as file.", "response": "def save(self, path):\n        \"\"\"Save svg as file(.svg)\n\n        Args:\n            path (str): destination to save file\n        \"\"\"\n        with open(path, 'w') as f:\n            f.write(self.contents())"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting from pixel coordinates to pixel coordinates", "response": "def _coords_conv(self, pos):\n        \"\"\"For Svg coordinate system, reflect over X axis and\n        translate from center to top-left\n        \"\"\"\n        px = (self.original_size[0] / 2 + pos[0]) * self.scale_factor\n        py = (self.original_size[1] / 2 - pos[1]) * self.scale_factor\n        return round(px, 2), round(py, 2)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the default instance of FlowsLogger.", "response": "def default_instance(cls):\n        \"\"\"\n        For use like a singleton, return the existing instance of the object\n        or a new instance\n        \"\"\"\n        if cls._instance is None:\n            with cls._instance_lock:\n                if cls._instance is None:\n                    cls._instance = FlowsLogger()\n\n        return cls._instance"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_logger(self):\n        if Global.LOGGER:\n            Global.LOGGER.debug('configuring a logger')\n        if self._logger_instance is not None:\n            return self._logger_instance\n\n        self._logger_instance = logging.getLogger(\"flowsLogger\")\n        self._logger_instance.setLevel(logging.DEBUG)\n\n        log_format = '%(asctime)s - [%(levelname)s]|%(thread)d\\t%(message)s'\n        log_date_format = '%Y-%m-%d %H:%M:%S'\n        formatter = logging.Formatter(log_format, log_date_format)\n\n        new_log_stream_handler = logging.StreamHandler()\n        new_log_stream_handler.setFormatter(formatter)\n        new_log_stream_handler.setLevel(logging.INFO)\n\n        self._logger_instance.addHandler(new_log_stream_handler)\n\n        return self._logger_instance", "response": "Returns the standard logger instance"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreconfiguring the log level of all handlers.", "response": "def reconfigure_log_level(self):\n        \"\"\"\n        Returns a new standard logger instance\n        \"\"\"\n        if Global.LOGGER:\n            Global.LOGGER.debug('reconfiguring logger level')\n        stream_handlers = filter(lambda x: type(x) is logging.StreamHandler,\n                                 self._logger_instance.handlers)\n\n        for x in stream_handlers:\n            x.level = Global.CONFIG_MANAGER.log_level\n\n        return self.get_logger()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfiltering docnames to only yield index pages.", "response": "def _filter_index_pages(docnames, base_dir):\n    \"\"\"Filter docnames to only yield paths of the form\n    ``<base_dir>/<name>/index``\n\n    Parameters\n    ----------\n    docnames : `list` of `str`\n        List of document names (``env.found_docs``).\n    base_dir : `str`\n        Base directory of all sub-directories containing index pages.\n\n    Yields\n    ------\n    docname : `str`\n        Document name that meets the pattern.\n    \"\"\"\n    for docname in docnames:\n        parts = docname.split('/')\n        if len(parts) == 3 and parts[0] == base_dir and parts[2] == 'index':\n            yield docname"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _build_toctree_node(parent=None, entries=None, includefiles=None,\n                        caption=None):\n    \"\"\"Factory for a toctree node.\n    \"\"\"\n    # Add the toctree's node itself\n    subnode = sphinx.addnodes.toctree()\n    subnode['parent'] = parent\n    subnode['entries'] = entries\n    subnode['includefiles'] = includefiles\n    subnode['caption'] = caption\n    # These values are needed for toctree node types. We don't need/want\n    # these to be configurable for module-toctree.\n    subnode['maxdepth'] = 1\n    subnode['hidden'] = False\n    subnode['glob'] = None\n    subnode['hidden'] = False\n    subnode['includehidden'] = False\n    subnode['numbered'] = 0\n    subnode['titlesonly'] = False\n    return subnode", "response": "Build a toctree node."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing the skip option of skipped module names.", "response": "def _parse_skip_option(self):\n        \"\"\"Parse the ``skip`` option of skipped module names.\n        \"\"\"\n        try:\n            skip_text = self.options['skip']\n        except KeyError:\n            return []\n\n        modules = [module.strip() for module in skip_text.split(',')]\n        return modules"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing the skip option of skipped package names.", "response": "def _parse_skip_option(self):\n        \"\"\"Parse the ``skip`` option of skipped package names.\n        \"\"\"\n        try:\n            skip_text = self.options['skip']\n        except KeyError:\n            return []\n\n        packages = [package.strip() for package in skip_text.split(',')]\n        return packages"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _set_command_line_arguments(self, args):\n        Global.LOGGER.debug(\"setting command line arguments\")\n\n        if args.VERBOSE:\n            Global.LOGGER.debug(\"verbose mode active\")\n            Global.CONFIG_MANAGER.log_level = logging.DEBUG\n            Global.LOGGER_INSTANCE.reconfigure_log_level()\n\n        if args.STATS > 0:\n            Global.LOGGER.debug(f\"stats requested every {args.STATS} seconds\")\n            Global.CONFIG_MANAGER.show_stats = True\n            Global.CONFIG_MANAGER.stats_timeout = args.STATS\n\n        if args.INTERVAL > 0:\n            Global.LOGGER.debug(f\"setting sleep interval to {args.INTERVAL} milliseconds\")\n            Global.CONFIG_MANAGER.sleep_interval = float(args.INTERVAL)/1000\n\n        if args.TRACE:\n            Global.LOGGER.debug(\"tracing mode active\")\n            Global.CONFIG_MANAGER.tracing_mode = True\n            Global.CONFIG_MANAGER.log_level = logging.DEBUG\n            Global.LOGGER_INSTANCE.reconfigure_log_level()\n\n        if  args.MESSAGEINTERVAL is not None and args.MESSAGEINTERVAL > 0:\n            Global.LOGGER.debug(f\"setting message fetcher sleep interval to {args.MESSAGEINTERVAL/10} milliseconds\")\n            Global.CONFIG_MANAGER.message_fetcher_sleep_interval =  float(args.MESSAGEINTERVAL)/10000\n            Global.CONFIG_MANAGER.fixed_message_fetcher_interval = True\n\n        Global.LOGGER.debug(f\"recipes to be parsed: {args.FILENAME}\")\n        Global.CONFIG_MANAGER.recipes = (args.FILENAME)", "response": "Set internal configuration variables according to \n        the input parameters"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef start(self):\n        Global.LOGGER.info(\"starting the flow manager\")\n        self._start_actions()\n        self._start_message_fetcher()\n        Global.LOGGER.debug(\"flow manager started\")", "response": "Start all the processes and message fetcher"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstops all the processes and stop the flow manager.", "response": "def stop(self):\n        \"\"\"\n        Stop all the processes\n        \"\"\"\n        Global.LOGGER.info(\"stopping the flow manager\")\n        self._stop_actions()\n        self.isrunning = False\n        Global.LOGGER.debug(\"flow manager stopped\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nrestarts all the processes and actions.", "response": "def restart(self):\n        \"\"\"\n        Restart all the processes\n        \"\"\"\n        Global.LOGGER.info(\"restarting the flow manager\")\n        self._stop_actions()    # stop the old actions\n        self.actions = []       # clear the action list\n        self._start_actions()   # start the configured actions\n        Global.LOGGER.debug(\"flow manager restarted\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nstarts all the actions for all the recipes in the current locale.", "response": "def _start_actions(self):\n        \"\"\"\n        Start all the actions for the recipes\n        \"\"\"\n        Global.LOGGER.info(\"starting actions\")\n\n        for recipe in Global.CONFIG_MANAGER.recipes:\n            Global.CONFIG_MANAGER.read_recipe(recipe)\n\n        list(map(lambda section: self._start_action_for_section(\n            section), Global.CONFIG_MANAGER.sections))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _start_action_for_section(self, section):\n        if section == \"configuration\":\n            return\n\n        Global.LOGGER.debug(\"starting actions for section \" + section)\n\n        # read the configuration of the action\n        action_configuration = Global.CONFIG_MANAGER.sections[\n            section]\n\n        if len(action_configuration) == 0:\n            Global.LOGGER.warn(f\"section {section} has no configuration, skipping\")\n            return\n\n        action_type = None\n        # action_input = None\n        new_managed_input = []\n\n        if \"type\" in action_configuration:\n            action_type = action_configuration[\"type\"]\n\n        if \"input\" in action_configuration:\n            action_input = action_configuration[\"input\"]\n            new_managed_input = (item.strip()\n                                    for item in action_input.split(\",\"))\n\n        my_action = Action.create_action_for_code(action_type,\n                                                    section,\n                                                    action_configuration,\n                                                    list(new_managed_input))\n\n        if not my_action:\n            Global.LOGGER.warn(f\"can't find a type for action {section}, the action will be skipped\")\n            return\n\n        self.actions.append(my_action)\n\n        Global.LOGGER.debug(\"updating the subscriptions table\")\n        for my_input in my_action.monitored_input:\n            self.subscriptions.setdefault(\n                my_input, []).append(my_action)", "response": "Start all the actions for a particular section."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _stop_actions(self):\n        Global.LOGGER.info(\"stopping actions\")\n\n        list(map(lambda x: x.stop(), self.actions))\n\n        Global.LOGGER.info(\"actions stopped\")", "response": "Stop all the actions in the current thread."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nperforming a system check for all incoming messages in the current page.", "response": "def _perform_system_check(self):\n        \"\"\"\n        Perform a system check to define if we need to throttle to handle \n        all the incoming messages \n        \"\"\"\n        if Global.CONFIG_MANAGER.tracing_mode:\n            Global.LOGGER.debug(\"performing a system check\")\n\n        now = datetime.datetime.now()\n        sent = Global.MESSAGE_DISPATCHER.dispatched\n        received = self.fetched\n        queue_length = sent - received\n        message_sleep_interval = Global.CONFIG_MANAGER.message_fetcher_sleep_interval\n\n        if Global.CONFIG_MANAGER.show_stats:\n            if (now - self.last_stats_check_date).total_seconds() > Global.CONFIG_MANAGER.stats_timeout:\n                self.last_stats_check_date = now\n                stats_string = f\"showing stats\\n--- [STATS] ---\\nMessage Sent: {sent}\\nMessage Received: {received}\\nMessage Sleep Interval = {message_sleep_interval}\\nQueue length = {queue_length}\\n--- [ END ] ---\"\n                Global.LOGGER.info(stats_string)\n\n        # if we are accumulating messages, or we have processed at least 5000 messages\n        # since last check, we need to speed up the process\n        messages_limit_reached = sent - self.last_queue_check_count > Global.CONFIG_MANAGER.messages_dispatched_for_system_check\n        queue_limit_reached = queue_length > Global.CONFIG_MANAGER.queue_length_for_system_check\n        time_limit_since_last_check_is_over = (now - self.last_queue_check_date).total_seconds() > Global.CONFIG_MANAGER.seconds_between_queue_check\n\n        if not Global.CONFIG_MANAGER.fixed_message_fetcher_interval:\n            if (messages_limit_reached) or (queue_limit_reached and time_limit_since_last_check_is_over):\n                cause = \"messages limit reached\" if messages_limit_reached else \"queue limit reached\"\n                Global.LOGGER.debug(f\"triggering the throttle function due to {cause}\")\n                self._adapt_sleep_interval(sent, received, queue_length, now)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndelivering the message to the subscripted actions.", "response": "def _deliver_message(self, msg):\n        \"\"\"\n        Deliver the message to the subscripted actions\n        \"\"\"\n        my_subscribed_actions = self.subscriptions.get(msg.sender, [])\n        for action in my_subscribed_actions:\n            if Global.CONFIG_MANAGER.tracing_mode:\n                Global.LOGGER.debug(f\"delivering message to {action.name}\")\n            action.on_input_received(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfetch a message from the socket and deliver it to the manager.", "response": "def _fetch_messages(self):\n        \"\"\"\n        Get an input message from the socket\n        \"\"\"\n        try:\n            [_, msg] = self.socket.recv_multipart(flags=zmq.NOBLOCK)\n            if Global.CONFIG_MANAGER.tracing_mode:\n                Global.LOGGER.debug(\"fetched a new message\")\n\n            self.fetched = self.fetched + 1\n            obj = pickle.loads(msg)\n            self._deliver_message(obj)\n            return obj\n        except zmq.error.Again:\n            return None\n        except Exception as new_exception:\n            Global.LOGGER.error(new_exception)\n            raise new_exception"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nregister callback for message fetcher coroutines", "response": "async def message_fetcher_coroutine(self, loop):\n        \"\"\"\n        Register callback for message fetcher coroutines\n        \"\"\"\n        Global.LOGGER.debug('registering callbacks for message fetcher coroutine')\n        self.isrunning = True\n        while self.isrunning:\n            loop.call_soon(self._fetch_messages)\n            loop.call_soon(self._perform_system_check)\n            await asyncio.sleep(Global.CONFIG_MANAGER.message_fetcher_sleep_interval)\n\n        Global.LOGGER.debug('message fetcher stopped')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _start_message_fetcher(self):\n        Global.LOGGER.debug('starting the message fetcher')\n        event_loop = asyncio.get_event_loop()\n        try:\n            Global.LOGGER.debug('entering event loop for message fetcher coroutine')\n            event_loop.run_until_complete(self.message_fetcher_coroutine(event_loop))\n        finally:\n            Global.LOGGER.debug('closing the event loop')\n            event_loop.close()", "response": "Start the message fetcher."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadapt sleep time based on the number of messages in queue and now.", "response": "def _adapt_sleep_interval(self, sent, received, queue, now):\n        \"\"\"\n        Adapt sleep time based on the number of the messages in queue\n        \"\"\"\n        Global.LOGGER.debug(\"adjusting sleep interval\")\n\n        dispatched_since_last_check = sent - self.last_queue_check_count\n        seconds_since_last_check = (\n            now - self.last_queue_check_date).total_seconds()\n\n        Global.LOGGER.debug(\n            str(dispatched_since_last_check) + \" dispatched in the last \" + str(seconds_since_last_check))\n        sleep_time = (seconds_since_last_check /\n                      (dispatched_since_last_check + queue + 1)) * 0.75\n\n        if sleep_time > 0.5:\n            sleep_time = 0.5\n\n        if sleep_time < 0.0001:\n            sleep_time = 0.0001\n\n        self.last_queue_check_date = now\n        self.last_queue_check_count = sent\n\n        Global.CONFIG_MANAGER.message_fetcher_sleep_interval = sleep_time\n\n        sleep_interval_log_string = f\"new sleep_interval = {sleep_time}\"\n        Global.LOGGER.debug(sleep_interval_log_string)\n\n        if Global.CONFIG_MANAGER.show_stats:\n            Global.LOGGER.info(sleep_interval_log_string)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _parse_input_parameters(self):\n        Global.LOGGER.debug(\"define and parsing command line arguments\")\n        parser = argparse.ArgumentParser(\n            description='A workflow engine for Pythonistas', formatter_class=argparse.RawTextHelpFormatter)\n        parser.add_argument('FILENAME', nargs='+',help='name of the recipe file(s)')\n        parser.add_argument('-i', '--INTERVAL', type=int, default=500,\n                            metavar=('MS'),\n                            help='perform a cycle each [MS] milliseconds. (default = 500)')\n\n        parser.add_argument('-m', '--MESSAGEINTERVAL', type=int, \n                            metavar=('X'),\n                            help='dequeue a message each [X] tenth of milliseconds. (default = auto)')\n        parser.add_argument('-s', '--STATS', type=int, default=0,\n                            metavar=('SEC'),\n                            help='show stats each [SEC] seconds. (default = NO STATS)')\n        parser.add_argument('-t', '--TRACE', action='store_true',help='enable super verbose output, only useful for tracing')                            \n        parser.add_argument('-v', '--VERBOSE', action='store_true',help='enable verbose output')\n        parser.add_argument('-V', '--VERSION',\n                            action=\"version\", version=__version__)\n\n        args = parser.parse_args()\n        return args", "response": "Parse the command line arguments and return the parsed arguments."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmigrate all flagged Videos to 050 and 505 timesheet entries to Null.", "response": "def migrate_050_to_051(session):\n    \"\"\"Set time_out field of all flagged\n    timesheet entries to Null.\n    \"\"\"\n    entries_to_update = session.query(Entry).filter(\n            Entry.forgot_sign_out.is_(True)).filter(\n            Entry.time_out.isnot(None))\n\n    for entry in entries_to_update:\n        entry.time_out = None\n        logging.info('Entry updated {}'.format(entry.uuid))\n        logging.debug(entry.uuid)\n        session.add(entry)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a Remote CI", "response": "def create(context, name, team_id, data, active):\n    \"\"\"create(context, name, team_id, data, active)\n\n    Create a Remote CI\n\n    >>> dcictl remoteci-create [OPTIONS]\n\n    :param string name: Name of the Remote CI [required]\n    :param string team_id: ID of the team to associate this remote CI with\n        [required]\n    :param string data: JSON data to pass during remote CI creation\n    :param boolean active: Mark remote CI active\n    :param boolean no-active: Mark remote CI inactive\n    \"\"\"\n\n    state = utils.active_string(active)\n    team_id = team_id or identity.my_team_id(context)\n    result = remoteci.create(context, name=name, team_id=team_id,\n                             data=data, state=state)\n    utils.format_output(result, context.format)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nretrieve data field from a remote CI", "response": "def get_data(context, id, keys):\n    \"\"\"get_data(context, id, keys)\n\n    Retrieve data field from a remoteci.\n\n    >>> dcictl remoteci-get-data [OPTIONS]\n\n    :param string id: ID of the remote CI to show [required]\n    :param string id: Keys of the data field to retrieve [optional]\n    \"\"\"\n\n    if keys:\n        keys = keys.split(',')\n    result = remoteci.get_data(context, id=id, keys=keys)\n    utils.format_output(result, context.format, keys)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrefreshing a remote key pair.", "response": "def refresh_keys(context, id, etag):\n    \"\"\"refresh_keys(context, id, etag)\n\n    Refresh a remoteci key pair.\n\n    >>> dcictl remoteci-refresh-keys [OPTIONS]\n\n    :param string id: ID of the remote CI [required]\n    :param string etag: Entity tag of the remote CI resource [required]\n    \"\"\"\n    result = remoteci.refresh_keys(context, id=id, etag=etag)\n    utils.format_output(result, context.format)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nattach a user to a remoteci.", "response": "def attach_user(context, id, user_id):\n    \"\"\"attach_user(context, id, user_id)\n\n    Attach a user to a remoteci.\n\n    >>> dcictl remoteci-attach-user [OPTIONS]\n\n    :param string id: ID of the remoteci to attach the user to [required]\n    :param string user_id: ID of the user to attach [required]\n    \"\"\"\n    result = remoteci.add_user(context, id=id,\n                               user_id=user_id)\n    utils.format_output(result, context.format, ['remoteci_id', 'user_id'])"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlists users attached to a remoteci.", "response": "def list_user(context, id, sort, limit, where, verbose):\n    \"\"\"list_user(context, id, sort, limit, where, verbose)\n\n    List users attached to a remoteci.\n\n    >>> dcictl remoteci-list-user [OPTIONS]\n\n    :param string id: ID of the remoteci to list the user from\n                      [required]\n    :param string sort: Field to apply sort\n    :param integer limit: Max number of rows to return\n    :param string where: An optional filter criteria\n    :param boolean verbose: Display verbose output\n    \"\"\"\n    result = remoteci.list_users(context, id=id, sort=sort, limit=limit,\n                                 where=where)\n    utils.format_output(result, context.format, verbose=verbose)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef attach_rconfiguration(context, id, name, topic_id, component_types, data):\n\n    result = remoteci.add_rconfiguration(context, id, name, topic_id,\n                                         component_types, data)\n    utils.format_output(result, context.format)", "response": "This function will attach an rconfiguration to a Remote CI\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlists rconfigurations attached to a remoteci.", "response": "def list_rconfigurations(context, id, sort, limit, where, verbose):\n    \"\"\"list_rconfigurations(context, id, sort, limit, where, verbose)\n\n    List rconfigurations attached to a remoteci.\n\n    >>> dcictl remoteci-list-rconfigurations ID [OPTIONS]\n\n    :param string id: ID of the remoteci to list the rconfigurations from\n                      [required]\n    :param string sort: Field to apply sort\n    :param integer limit: Max number of rows to return\n    :param string where: An optional filter criteria\n    :param boolean verbose: Display verbose output\n    \"\"\"\n    result = remoteci.list_rconfigurations(context, id=id, sort=sort,\n                                           limit=limit, where=where)\n    utils.format_output(result, context.format, verbose=verbose)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_task_param_string(task):\n    # get dict str -> str from luigi\n    param_dict = task.to_str_params()\n\n    # sort keys, serialize\n    items = []\n    for key in sorted(param_dict.keys()):\n        items.append(\"'{:s}': '{:s}'\".format(key, param_dict[key]))\n\n    return \"{\" + \", \".join(items) + \"}\"", "response": "Get all parameters of a task as one string\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _check_completion(task, mark_incomplete, clear, stats, visited, to_clear):\n    # is this task (recursively) complete?\n    task_complete = task.complete()\n    is_complete = task_complete\n\n    # task identification: task name plus parameters\n    task_id = get_task_name(task) + ' ' + get_task_param_string(task)\n\n    # check any requirements\n    for req in task.requires():\n\n        # task/parameter ID string to identify this task instance\n        req_id = get_task_name(req) + ' ' + get_task_param_string(req)\n\n        # skip recursion on already visited tasks, get completion status from cache\n        if req_id in visited:\n            req_complete = visited[req_id]\n        else:\n            req_complete, _ = _check_completion(task=req,\n                                                mark_incomplete=mark_incomplete,\n                                                clear=clear,\n                                                stats=stats,\n                                                visited=visited,\n                                                to_clear=to_clear)\n            visited[req_id] = req_complete\n\n        # add any incomplete requirements to the list of tasks to clear, noting the current task as parent (required by)\n        if clear and not req_complete:\n            clear_entry = to_clear.setdefault(req_id, dict(task=req, required_by=set()))\n            clear_entry['required_by'].add(task_id)\n\n        is_complete &= req_complete\n\n    if not is_complete:\n        if task_complete:\n            config.logger.info(\"Task complete but requirements incomplete: \" + task_id)\n        else:\n            config.logger.info(\"Task incomplete: \" + task_id)\n        _increment_stats(stats, 'Incomplete tasks')\n\n        if mark_incomplete:\n            if isinstance(task, ORMTask):\n                task.mark_incomplete()\n                _increment_stats(stats, 'Marked incomplete')\n                config.logger.info(\"Marked task incomplete: \" + task_id)\n            else:\n                config.logger.info('Cannot mark task incomplete, not an ORMTask: ' + task_id)\n\n    else:\n        _increment_stats(stats, 'Complete tasks')\n        config.logger.debug(\"Task complete: \" + task_id)\n\n    # if we want to clear and the current task is not in the dict of tasks to clear,\n    # it is the root task, add it with no parent (required by) tasks\n    if clear and not is_complete and task_id not in to_clear:\n        to_clear[task_id] = dict(task=task, required_by=set())\n\n    return is_complete, stats", "response": "Recursive function to check the completion of a task instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the DB client associated with the task", "response": "def client(self):\n        \"\"\"Get the DB client associated with the task (open a new one if necessary)\n\n        Returns:\n            ozelot.client.Client: DB client\n        \"\"\"\n        if self._client is None:\n            self._client = client.get_client()\n\n        return self._client"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the DB session associated with the task", "response": "def session(self):\n        \"\"\"Get the DB session associated with the task (open a new one if necessary)\n\n        Returns:\n            sqlalchemy.orm.session.Session: DB session\n        \"\"\"\n        if self._session is None:\n            self._session = self.client.create_session()\n\n        return self._session"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef close_session(self, commit=True):\n        if self._session is not None:\n            if commit:\n                self._session.commit()\n            self._session.close()\n            self._session = None", "response": "Commit and close the DB session associated with this task."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef clear(\n            self  # type: ORMTask\n    ):\n        \"\"\"Delete all objects created by this task.\n\n        Iterate over `self.object_classes` and delete all objects of the listed classes.\n        \"\"\"\n        # mark this task as incomplete\n        self.mark_incomplete()\n\n        # delete objects\n        for object_class in self.object_classes:\n            self.session.query(object_class).delete()\n\n        self.close_session()", "response": "Clears all objects created by this task."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntasking is complete if completion marker is set and all requirements are complete", "response": "def complete(self):\n        \"\"\"Task is complete if completion marker is set and all requirements are complete\n        \"\"\"\n        is_complete = super(ORMWrapperTask, self).complete()\n        for req in self.requires():\n            is_complete &= req.complete()\n\n        return is_complete"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nresetting internal storage containers to empty state.", "response": "def reset(self):\n        \"\"\"\n            Empties all internal storage containers\n        \"\"\"\n        super(MorseSmaleComplex, self).reset()\n\n        self.base_partitions = {}\n        self.merge_sequence = {}\n\n        self.persistences = []\n        self.min_indices = []\n        self.max_indices = []\n\n        # State properties\n        self.persistence = 0."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef build(self, X, Y, w=None, edges=None):\n        super(MorseSmaleComplex, self).build(X, Y, w, edges)\n\n        if self.debug:\n            sys.stdout.write(\"Decomposition: \")\n            start = time.clock()\n\n        stableManifolds = MorseComplex(debug=self.debug)\n        unstableManifolds = MorseComplex(debug=self.debug)\n\n        stableManifolds.build_for_morse_smale_complex(self, False)\n        unstableManifolds.build_for_morse_smale_complex(self, True)\n\n        self.min_indices = unstableManifolds.max_indices\n        self.max_indices = stableManifolds.max_indices\n\n        # If a degenerate point is both a minimum and a maximum, it\n        # could potentially appear twice, but would be masked by the\n        # minimum key which would wipe the maximum merge\n        self.merge_sequence = stableManifolds.merge_sequence.copy()\n        self.merge_sequence.update(unstableManifolds.merge_sequence)\n        self.persistences = sorted(\n            stableManifolds.persistences + unstableManifolds.persistences\n        )\n\n        self.base_partitions = {}\n        base = np.array([[None, None]] * len(Y))\n        for key, items in unstableManifolds.base_partitions.items():\n            base[np.array(items), 0] = key\n        for key, items in stableManifolds.base_partitions.items():\n            base[np.array(items), 1] = key\n\n        keys = set(map(tuple, base))\n        for key in keys:\n            self.base_partitions[key] = np.where(\n                np.logical_and(base[:, 0] == key[0], base[:, 1] == key[1])\n            )[0]\n\n        if self.debug:\n            end = time.clock()\n            sys.stdout.write(\"%f s\\n\" % (end - start))", "response": "Assigns data to this object and builds the Morse - Smale complex object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef save(self, filename=None):\n        if filename is None:\n            filename = \"morse_smale_complex.json\"\n        with open(filename, \"w\") as fp:\n            fp.write(self.to_json())", "response": "Saves the Morse - Smale Complex in json file containing the hierarchical Morse - Smale Complex data."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the partitions of the base sequence based on a specified persistence level.", "response": "def get_partitions(self, persistence=None):\n        \"\"\" Returns the partitioned data based on a specified\n            persistence level.\n            @ In, persistence, a floating point value specifying the\n            size of the smallest feature we want to track.\n            Default = None means consider all features.\n            @ Out, a dictionary lists where each key is a min-max tuple\n            specifying the index of the minimum and maximum,\n            respectively. Each entry will hold a list of indices\n            specifying points that are associated to this min-max pair.\n        \"\"\"\n        if persistence is None:\n            persistence = self.persistence\n        partitions = {}\n        # TODO: Possibly cache at the critical persistence values,\n        # previously caching was done at every query level, but that\n        # does not make sense as the partitions will only change once\n        # the next value in self.persistences is attained. Honestly,\n        # this is probably not a necessary optimization that needs to\n        # be made. Consider instead, Yarden's way of storing the points\n        # such that merged arrays will be adjacent.\n        for key, items in self.base_partitions.items():\n            min_index = key[0]\n            max_index = key[1]\n            while (\n                self.merge_sequence[min_index][0] < persistence\n                and self.merge_sequence[min_index][1] != min_index\n            ):\n                min_index = self.merge_sequence[min_index][1]\n            while (\n                self.merge_sequence[max_index][0] < persistence\n                and self.merge_sequence[max_index][1] != max_index\n            ):\n                max_index = self.merge_sequence[max_index][1]\n            new_key = (min_index, max_index)\n            if new_key not in partitions:\n                partitions[new_key] = []\n            partitions[new_key].extend(items.tolist())\n\n        for key in partitions:\n            partitions[key] = sorted(list(set(partitions[key])))\n        return partitions"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the label pair indices requested by the user.", "response": "def get_label(self, indices=None):\n        \"\"\" Returns the label pair indices requested by the user\n            @ In, indices, a list of non-negative integers specifying\n            the row indices to return\n            @ Out, a list of integer 2-tuples specifying the minimum and\n            maximum index of the specified rows.\n        \"\"\"\n        if indices is None:\n            indices = list(range(0, self.get_sample_size()))\n        elif isinstance(indices, collections.Iterable):\n            indices = sorted(list(set(indices)))\n        else:\n            indices = [indices]\n\n        if len(indices) == 0:\n            return []\n        partitions = self.get_partitions(self.persistence)\n        labels = self.X.shape[0] * [None]\n        for label, partition_indices in partitions.items():\n            for idx in np.intersect1d(partition_indices, indices):\n                labels[idx] = label\n\n        labels = np.array(labels)\n        if len(indices) == 1:\n            return labels[indices][0]\n        return labels[indices]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_sample_size(self, key=None):\n        if key is None:\n            return len(self.Y)\n        else:\n            return len(self.get_partitions(self.persistence)[key])", "response": "Returns the number of samples in the input data\n           ."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrite the complete Morse - Smale merge hierarchy to a string object.", "response": "def to_json(self):\n        \"\"\" Writes the complete Morse-Smale merge hierarchy to a string\n            object.\n            @ Out, a string object storing the entire merge hierarchy of\n            all minima and maxima.\n        \"\"\"\n        capsule = {}\n        capsule[\"Hierarchy\"] = []\n        for (\n            dying,\n            (persistence, surviving, saddle),\n        ) in self.merge_sequence.items():\n            capsule[\"Hierarchy\"].append(\n                {\n                    \"Dying\": dying,\n                    \"Persistence\": persistence,\n                    \"Surviving\": surviving,\n                    \"Saddle\": saddle,\n                }\n            )\n        capsule[\"Partitions\"] = []\n        base = np.array([None, None] * len(self.Y)).reshape(-1, 2)\n        for (min_index, max_index), items in self.base_partitions.items():\n            base[items, :] = [min_index, max_index]\n        capsule[\"Partitions\"] = base.tolist()\n\n        return json.dumps(capsule)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dict_to_numpy_array(d):\n    return fromarrays(d.values(), np.dtype([(str(k), v.dtype) for k, v in d.items()]))", "response": "Convert a dict of 1d array to a numpy recarray\n   "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef concatenate_1d(arrays):\n    if len(arrays) == 0:\n        return np.array([])\n    if len(arrays) == 1:\n        return np.asanyarray(arrays[0])\n    if any(map(np.ma.is_masked, arrays)):\n        return np.ma.concatenate(arrays)\n    return np.concatenate(arrays)", "response": "Concatenate 1D numpy arrays."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_hydrogen(self, num):\n        self.H_count = num\n        if num > 0 and self.symbol in (\"N\", \"O\"):\n            self.H_donor = 1\n        else:\n            self.H_donor = 0", "response": "Adds hydrogens to the log."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef formula_html(self, reversed_=False):\n        if self.H_count == 1:\n            text = \"H\"\n        elif self.H_count > 1:\n            text = \"H<sub>{}</sub>\".format(self.H_count)\n        else:\n            text = \"\"\n        seq = [self.symbol, text, self.charge_sign_html()]\n        if reversed_:\n            seq = reversed(seq)\n        return \"\".join(seq)", "response": "Chemical formula HTML for the current object"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning True if the given molecule is exactly same structure as the query.", "response": "def equal(mol, query, largest_only=True, ignore_hydrogen=True):\n    \"\"\" if mol is exactly same structure as the query, return True\n    Args:\n      mol: Compound\n      query: Compound\n    \"\"\"\n    m = molutil.clone(mol)\n    q = molutil.clone(query)\n    if largest_only:\n        m = molutil.largest_graph(m)\n        q = molutil.largest_graph(q)\n    if ignore_hydrogen:\n        m = molutil.make_Hs_implicit(m)\n        q = molutil.make_Hs_implicit(q)\n    if molutil.mw(m) == molutil.mw(q):\n        gm = GraphMatcher(q.graph, m.graph, node_match=atom_match)\n        return gm.is_isomorphic()\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef substructure(mol, query, largest_only=True, ignore_hydrogen=True):\n    def subset_filter(cnt1, cnt2):\n        diff = cnt2\n        diff.subtract(cnt1)\n        if any(v < 0 for v in diff.values()):\n            return True\n\n    if not (len(mol) and len(query)):\n        return False  # two blank molecules are not isomorphic\n    m = molutil.clone(mol)\n    q = molutil.clone(query)\n    if largest_only:\n        m = molutil.largest_graph(m)\n        q = molutil.largest_graph(q)\n    if ignore_hydrogen:\n        m = molutil.make_Hs_implicit(m)\n        q = molutil.make_Hs_implicit(q)\n    if filter_(m, q, f=subset_filter):\n        gm = GraphMatcher(q.graph, m.graph, node_match=atom_match)\n        return gm.subgraph_is_isomorphic()\n    return False", "response": "Returns True if the molecule is a substructure of the query."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef default_instance(cls):\n        if cls._instance is None:\n            with cls._instance_lock:\n                if cls._instance is None:\n                    cls._instance = MessageDispatcher()\n\n        return cls._instance", "response": "Returns the default instance of the class."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndispatch a message using 0mq", "response": "def send_message(self, message):\n        \"\"\"\n        Dispatch a message using 0mq\n        \"\"\"\n        with self._instance_lock:\n            if message is None:\n                Global.LOGGER.error(\"can't deliver a null messages\")\n                return\n\n            if message.sender is None:\n                Global.LOGGER.error(f\"can't deliver anonymous messages with body {message.body}\")\n                return\n\n            if message.receiver is None:\n                Global.LOGGER.error(\n                    f\"can't deliver message from {message.sender}: recipient not specified\")\n                return\n\n            if message.message is None:\n                Global.LOGGER.error(f\"can't deliver message with no body from {message.sender}\")\n                return\n\n            sender = \"*\" + message.sender + \"*\"\n            self.socket.send_multipart(\n                [bytes(sender, 'utf-8'), pickle.dumps(message)])\n\n            if Global.CONFIG_MANAGER.tracing_mode:\n                Global.LOGGER.debug(\"dispatched : \"\n                                    + message.sender\n                                    + \"-\"\n                                    + message.message\n                                    + \"-\"\n                                    + message.receiver)\n\n            self.dispatched = self.dispatched + 1"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_properties_cache(sender, instance, action, reverse, model, pk_set, **kwargs):\n    \"Property cache actualization at POI save. It will not work yet after property removal.\"\n    if action == 'post_add':\n        instance.save_properties_cache()", "response": "Property cache actualization at POI save. It will not work yet after property removal."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreset internal storage containers to empty state.", "response": "def reset(self):\n        \"\"\"\n            Empties all internal storage containers\n        \"\"\"\n        super(MorseComplex, self).reset()\n\n        self.base_partitions = {}\n        self.merge_sequence = {}\n\n        self.persistences = []\n        self.max_indices = []\n\n        # State properties\n        self.persistence = 0."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nassigning data to this object and builds the Morse - Smale complex object.", "response": "def build(self, X, Y, w=None, edges=None):\n        \"\"\" Assigns data to this object and builds the Morse-Smale\n            Complex\n            @ In, X, an m-by-n array of values specifying m\n            n-dimensional samples\n            @ In, Y, a m vector of values specifying the output\n            responses corresponding to the m samples specified by X\n            @ In, w, an optional m vector of values specifying the\n            weights associated to each of the m samples used. Default of\n            None means all points will be equally weighted\n            @ In, edges, an optional list of custom edges to use as a\n            starting point for pruning, or in place of a computed graph.\n        \"\"\"\n        super(MorseComplex, self).build(X, Y, w, edges)\n\n        if self.debug:\n            sys.stdout.write(\"Decomposition: \")\n            start = time.clock()\n\n        morse_complex = MorseComplexFloat(\n            vectorFloat(self.Xnorm.flatten()),\n            vectorFloat(self.Y),\n            str(self.gradient),\n            str(self.simplification),\n            vectorFloat(self.w),\n            self.graph_rep.full_graph(),\n            self.debug,\n        )\n        self.__amc = morse_complex\n\n        self.persistences = []\n        self.merge_sequence = {}\n        morse_complex_json = json.loads(morse_complex.to_json())\n        hierarchy = morse_complex_json[\"Hierarchy\"]\n        for merge in hierarchy:\n            self.persistences.append(merge[\"Persistence\"])\n            self.merge_sequence[merge[\"Dying\"]] = (\n                merge[\"Persistence\"],\n                merge[\"Surviving\"],\n                merge[\"Saddle\"],\n            )\n        self.persistences = sorted(list(set(self.persistences)))\n\n        partitions = morse_complex_json[\"Partitions\"]\n        self.base_partitions = {}\n        for i, label in enumerate(partitions):\n            if label not in self.base_partitions:\n                self.base_partitions[label] = []\n            self.base_partitions[label].append(i)\n\n        self.max_indices = list(self.base_partitions.keys())\n\n        if self.debug:\n            end = time.clock()\n            sys.stdout.write(\"%f s\\n\" % (end - start))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_partitions(self, persistence=None):\n        if persistence is None:\n            persistence = self.persistence\n        partitions = {}\n        # TODO: Possibly cache at the critical persistence values,\n        # previously caching was done at every query level, but that\n        # does not make sense as the partitions will only change once\n        # the next value in self.persistences is attained. Honestly,\n        # this is probably not a necessary optimization that needs to\n        # be made. Consider instead, Yarden's way of storing the points\n        # such that merged arrays will be adjacent.\n        for key, items in self.base_partitions.items():\n            new_key = key\n            while (\n                self.merge_sequence[new_key][0] < persistence\n                and self.merge_sequence[new_key][1] != new_key\n            ):\n                new_key = self.merge_sequence[new_key][1]\n            if new_key not in partitions:\n                partitions[new_key] = []\n            partitions[new_key].extend(items)\n\n        for key in partitions:\n            partitions[key] = sorted(list(set(partitions[key])))\n\n        return partitions", "response": "Returns the partitions of the base_partitions based on a specified persistence level."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwriting the complete Morse complex merge hierarchy to a string object.", "response": "def to_json(self):\n        \"\"\" Writes the complete Morse complex merge hierarchy to a\n            string object.\n            @ Out, a string object storing the entire merge hierarchy of\n            all maxima.\n        \"\"\"\n        capsule = {}\n        capsule[\"Hierarchy\"] = []\n        for (\n            dying,\n            (persistence, surviving, saddle),\n        ) in self.merge_sequence.items():\n            capsule[\"Hierarchy\"].append(\n                {\n                    \"Persistence\": persistence,\n                    \"Dying\": dying,\n                    \"Surviving\": surviving,\n                    \"Saddle\": saddle,\n                }\n            )\n        capsule[\"Partitions\"] = []\n        base = np.array([None] * len(self.Y))\n        for label, items in self.base_partitions.items():\n            base[items] = label\n        capsule[\"Partitions\"] = base.tolist()\n\n        return json.dumps(capsule, separators=(\",\", \":\"))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef iter(context, sequence, limit=10):\n    params = {'limit': limit,\n              'offset': 0}\n    uri = '%s/%s/%s' % (context.dci_cs_api, RESOURCE, sequence)\n\n    while True:\n        j = context.session.get(uri, params=params).json()\n        if len(j['jobs_events']):\n            for i in j['jobs_events']:\n                yield i\n        else:\n            break\n        params['offset'] += params['limit']", "response": "Iter to list all the jobs events in a sequence."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete(context, sequence):\n    uri = '%s/%s/%s' % (context.dci_cs_api, RESOURCE, sequence)\n    return context.session.delete(uri)", "response": "Delete jobs events from a given sequence"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the ldap module.", "response": "def get_ldap(cls, global_options=None):\n        \"\"\"\n        Returns the ldap module. The unit test harness will assign a mock object\n        to _LDAPConfig.ldap. It is imperative that the ldap module not be\n        imported anywhere else so that the unit tests will pass in the absence\n        of python-ldap.\n        \"\"\"\n        if cls.ldap is None:\n            import ldap.filter\n\n            # Support for python-ldap < 2.0.6\n            try:\n                import ldap.dn\n            except ImportError:\n                from django_auth_ldap import dn\n                ldap.dn = dn\n\n            cls.ldap = ldap\n\n        # Apply global LDAP options once\n        if (not cls._ldap_configured) and (global_options is not None):\n            for opt, value in global_options.items():\n                cls.ldap.set_option(opt, value)\n\n            cls._ldap_configured = True\n\n        return cls.ldap"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_logger(cls):\n        if cls.logger is None:\n            class NullHandler(logging.Handler):\n                def emit(self, record):\n                    pass\n\n            cls.logger = logging.getLogger('django_auth_ldap')\n            cls.logger.addHandler(NullHandler())\n\n        return cls.logger", "response": "Returns our logger instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef search_with_additional_term_string(self, filterstr):\n        filterstr = u'(&%s%s)' % (self.filterstr, filterstr)\n\n        return self.__class__(self.base_dn, self.scope, filterstr)", "response": "Returns a new search object with filterstr and - ed to the original filter\n        string."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nexecuting the search on the given connection.", "response": "def execute(self, connection, filterargs=(), escape=True):\n        \"\"\"\n        Executes the search on the given connection (an LDAPObject). filterargs\n        is an object that will be used for expansion of the filter string.\n        If escape is True, values in filterargs will be escaped.\n\n        The python-ldap library returns utf8-encoded strings. For the sake of\n        sanity, this method will decode all result strings and return them as\n        Unicode.\n        \"\"\"\n        if escape:\n            filterargs = self._escape_filterargs(filterargs)\n\n        try:\n            filterstr = self.filterstr % filterargs\n            results = connection.search_s(force_str(self.base_dn),\n                                          self.scope,\n                                          force_str(filterstr))\n        except ldap.LDAPError as e:\n            results = []\n            logger.error(u\"search_s('%s', %d, '%s') raised %s\" %\n                         (self.base_dn, self.scope, filterstr, pprint.pformat(e)))\n\n        return self._process_results(results)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nstart an asynchronous search and returns the message id to retrieve the results.", "response": "def _begin(self, connection, filterargs=(), escape=True):\n        \"\"\"\n        Begins an asynchronous search and returns the message id to retrieve\n        the results.\n\n        filterargs is an object that will be used for expansion of the filter\n        string. If escape is True, values in filterargs will be escaped.\n\n        \"\"\"\n        if escape:\n            filterargs = self._escape_filterargs(filterargs)\n\n        try:\n            filterstr = self.filterstr % filterargs\n            msgid = connection.search(force_str(self.base_dn),\n                                      self.scope, force_str(filterstr))\n        except ldap.LDAPError as e:\n            msgid = None\n            logger.error(u\"search('%s', %d, '%s') raised %s\" %\n                         (self.base_dn, self.scope, filterstr, pprint.pformat(e)))\n\n        return msgid"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the result of a previous asynchronous query.", "response": "def _results(self, connection, msgid):\n        \"\"\"\n        Returns the result of a previous asynchronous query.\n        \"\"\"\n        try:\n            kind, results = connection.result(msgid)\n            if kind != ldap.RES_SEARCH_RESULT:\n                results = []\n        except ldap.LDAPError as e:\n            results = []\n            logger.error(u\"result(%d) raised %s\" % (msgid, pprint.pformat(e)))\n\n        return self._process_results(results)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nescape values in filterargs.", "response": "def _escape_filterargs(self, filterargs):\n        \"\"\"\n        Escapes values in filterargs.\n\n        filterargs is a value suitable for Django's string formatting operator\n        (%), which means it's either a tuple or a dict. This return a new tuple\n        or dict with all values escaped for use in filter strings.\n\n        \"\"\"\n        if isinstance(filterargs, tuple):\n            filterargs = tuple(self.ldap.filter.escape_filter_chars(value)\n                               for value in filterargs)\n        elif isinstance(filterargs, dict):\n            filterargs = dict((key, self.ldap.filter.escape_filter_chars(value))\n                              for key, value in filterargs.items())\n        else:\n            raise TypeError(\"filterargs must be a tuple or dict.\")\n\n        return filterargs"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _process_results(self, results):\n        results = [r for r in results if r[0] is not None]\n        results = _DeepStringCoder('utf-8').decode(results)\n\n        # The normal form of a DN is lower case.\n        results = [(r[0].lower(), r[1]) for r in results]\n\n        result_dns = [result[0] for result in results]\n        logger.debug(u\"search_s('%s', %d, '%s') returned %d objects: %s\" %\n                     (self.base_dn, self.scope, self.filterstr, len(result_dns),\n                      \"; \".join(result_dns)))\n\n        return results", "response": "Returns a sanitized copy of raw LDAP results. This scrubs out\n        references decodes utf8 normalizes DNs and normalizes DNs etc."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef store_password(params, password):\n        user_name = params['user']\n        service_name = params['host'] + ':' + params['driver']\n        keyring.set_password(service_name=service_name,\n                             username=user_name,\n                             password=password)", "response": "Store the password for a database connection using the keyring."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the password for a database connection from keyring", "response": "def _get_password(params):\n        \"\"\"Get the password for a database connection from :mod:`keyring`\n\n        Args:\n            params (dict): database configuration, as defined in :mod:`ozelot.config`\n\n        Returns:\n            str: password\n        \"\"\"\n        user_name = params['user']\n        service_name = params['host'] + ':' + params['driver']\n        return keyring.get_password(service_name=service_name,\n                                    username=user_name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget a database connection string from a dictionary of parameters.", "response": "def get_connection_string(params, hide_password=True):\n        \"\"\"Get a database connection string\n\n        Args:\n            params (dict): database configuration, as defined in :mod:`ozelot.config`\n            hide_password (bool): if True, the password is hidden in the returned string\n                (use this for logging purposes).\n\n        Returns:\n            str: connection string\n        \"\"\"\n        connection_string = params['driver'] + '://'\n\n        user = params.get('user', None)\n        password = params.get('password', None)\n        host = params.get('host', None)\n        port = params.get('port', None)\n        database = params.get('database', None)\n\n        if database is None:\n            raise ValueError(\"Field 'database' of connection parameters cannot be None.\")\n\n        # if password is not set, try to get it from keyring\n        if password is None and user is not None:\n            # noinspection PyTypeChecker\n            password = Client._get_password(params)\n\n            if password is None:\n                raise RuntimeError(\"Password not defined and not available in keyring.\")\n\n        # don't add host/port/user/password if no host given\n        if host is not None:\n\n            # don't add user/password if user not given\n            if user is not None:\n                connection_string += user\n\n                # omit zero-length passwords\n                if len(password) > 0:\n                    if hide_password:\n                        connection_string += \":[password hidden]\"\n                    else:\n                        connection_string += \":\" + password\n\n                connection_string += \"@\"\n\n            connection_string += host\n\n            if port is not None:\n                connection_string += ':' + str(port)\n\n        # noinspection PyTypeChecker\n        connection_string += '/' + database\n\n        return connection_string"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef df_query(self, query, with_labels=False):\n        import pandas as pd\n\n        if with_labels:\n            query = query.with_labels()\n\n        # compile sql statement, including arguments\n        statement = query.statement.compile(self.engine)\n\n        # run query\n        return pd.read_sql_query(sql=statement, con=self.engine)", "response": "Run a sqlalchemy query and return a pandas. DataFrame"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef basename(path, extension_marker=\".\"):\n    result = os.path.basename(path or \"\")\n    if extension_marker:\n        pre, _, post = result.rpartition(extension_marker)\n        return pre or post\n\n    return result", "response": "Returns the basename of the path without the extension."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ensure_folder(path, folder=False, fatal=True, logger=LOG.debug, dryrun=None):\n    if not path:\n        return 0\n\n    if folder:\n        folder = resolved_path(path)\n\n    else:\n        folder = parent_folder(path)\n\n    if os.path.isdir(folder):\n        if not os.access(folder, os.W_OK):\n            return abort(\"Folder %s is not writable\", folder, fatal=(fatal, -1), logger=logger)\n        return 0\n\n    if dryrun is None:\n        dryrun = is_dryrun()\n\n    if dryrun:\n        LOG.debug(\"Would create %s\", short(folder))\n        return 1\n\n    try:\n        os.makedirs(folder)\n        if logger:\n            logger(\"Created folder %s\", short(folder))\n\n        return 1\n\n    except Exception as e:\n        return abort(\"Can't create folder %s: %s\", short(folder), e, fatal=(fatal, -1), logger=logger)", "response": "Ensures that the given path refers to a folder."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the absolute path of the parent folder of path.", "response": "def parent_folder(path, base=None):\n    \"\"\"\n    :param str|None path: Path to file or folder\n    :param str|None base: Base folder to use for relative paths (default: current working dir)\n    :return str: Absolute path of parent folder of 'path'\n    \"\"\"\n    return path and os.path.dirname(resolved_path(path, base=base))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsends a request for latest ticker info return the response.", "response": "def pubticker(self, symbol='btcusd'):\n        \"\"\"Send a request for latest ticker info, return the response.\"\"\"\n        url = self.base_url + '/v1/pubticker/' + symbol\n\n        return requests.get(url)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsends a request to get the public order book", "response": "def book(self, symbol='btcusd', limit_bids=0, limit_asks=0):\n        \"\"\"\n        Send a request to get the public order book, return the response.\n\n        Arguments:\n        symbol -- currency symbol (default 'btcusd')\n        limit_bids -- limit the number of bids returned (default 0)\n        limit_asks -- limit the number of asks returned (default 0)\n        \"\"\"\n        url = self.base_url + '/v1/book/' + symbol\n        params = {\n            'limit_bids': limit_bids,\n            'limit_asks': limit_asks\n        }\n\n        return requests.get(url, params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef trades(self, symbol='btcusd', since=0, limit_trades=50,\n               include_breaks=0):\n        \"\"\"\n        Send a request to get all public trades, return the response.\n\n        Arguments:\n        symbol -- currency symbol (default 'btcusd')\n        since -- only return trades after this unix timestamp (default 0)\n        limit_trades -- maximum number of trades to return (default 50).\n        include_breaks -- whether to display broken trades (default False)\n        \"\"\"\n        url = self.base_url + '/v1/trades/' + symbol\n        params = {\n            'since': since,\n            'limit_trades': limit_trades,\n            'include_breaks': include_breaks\n        }\n\n        return requests.get(url, params)", "response": "Send a request to get all public trades"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsend a request for latest auction info return the response", "response": "def auction(self, symbol='btcusd'):\n        \"\"\"Send a request for latest auction info, return the response.\"\"\"\n        url = self.base_url + '/v1/auction/' + symbol\n\n        return requests.get(url)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef auction_history(self, symbol='btcusd', since=0,\n                        limit_auction_results=50, include_indicative=1):\n        \"\"\"\n        Send a request for auction history info, return the response.\n\n        Arguments:\n        symbol -- currency symbol (default 'btcusd')\n        since -- only return auction events after this timestamp (default 0)\n        limit_auction_results -- maximum number of auction events to return\n                                 (default 50).\n        include_indicative -- whether to include publication of indicative\n                              prices and quantities. (default True)\n        \"\"\"\n        url = self.base_url + '/v1/auction/' + symbol + '/history'\n        params = {\n            'since': since,\n            'limit_auction_results': limit_auction_results,\n            'include_indicative': include_indicative\n        }\n\n        return requests.get(url, params)", "response": "Send a request to get auction history info"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef new_order(self, amount, price, side, client_order_id=None,\n                  symbol='btcusd', type='exchange limit', options=None):\n        \"\"\"\n        Send a request to place an order, return the response.\n\n        Arguments:\n        amount -- quoted decimal amount of BTC to purchase\n        price -- quoted decimal amount of USD to spend per BTC\n        side -- 'buy' or 'sell'\n        client_order_id -- an optional client-specified order id (default None)\n        symbol -- currency symbol (default 'btcusd')\n        type -- the order type (default 'exchange limit')\n        \"\"\"\n        request = '/v1/order/new'\n        url = self.base_url + request\n        params = {\n            'request': request,\n            'nonce': self.get_nonce(),\n            'symbol': symbol,\n            'amount': amount,\n            'price': price,\n            'side': side,\n            'type': type\n        }\n\n        if client_order_id is not None:\n            params['client_order_id'] = client_order_id\n\n        if options is not None:\n            params['options'] = options\n\n        return requests.post(url, headers=self.prepare(params))", "response": "Send a request to place an order"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsend a request to cancel an order", "response": "def cancel_order(self, order_id):\n        \"\"\"\n        Send a request to cancel an order, return the response.\n\n        Arguments:\n        order_id - the order id to cancel\n        \"\"\"\n        request = '/v1/order/cancel'\n        url = self.base_url + request\n        params = {\n            'request': request,\n            'nonce': self.get_nonce(),\n            'order_id': order_id\n        }\n\n        return requests.post(url, headers=self.prepare(params))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef past_trades(self, symbol='btcusd', limit_trades=50, timestamp=0):\n        request = '/v1/mytrades'\n        url = self.base_url + request\n        params = {\n            'request': request,\n            'nonce': self.get_nonce(),\n            'symbol': symbol,\n            'limit_trades': limit_trades,\n            'timestamp': timestamp\n        }\n\n        return requests.post(url, headers=self.prepare(params))", "response": "Send a trade history request to get the next set of trades."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef tradevolume(self):\n        request = '/v1/tradevolume'\n        url = self.base_url + request\n        params = {\n            'request': request,\n            'nonce': self.get_nonce()\n        }\n\n        return requests.post(url, headers=self.prepare(params))", "response": "Send a request to get your trade volume return the response."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsends a request to create a new cryptocurrency deposit address", "response": "def newAddress(self, currency='btc', label=''):\n        \"\"\"\n        Send a request for a new cryptocurrency deposit address\n        with an optional label. Return the response.\n\n        Arguements:\n        currency -- a Gemini supported cryptocurrency (btc, eth)\n        label -- optional label for the deposit address\n        \"\"\"\n        request = '/v1/deposit/' + currency + '/newAddress'\n        url = self.base_url + request\n        params = {\n            'request': request,\n            'nonce': self.get_nonce()\n        }\n\n        if label != '':\n            params['label'] = label\n\n        return requests.post(url, headers=self.prepare(params))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef prepare(self, params):\n        jsonparams = json.dumps(params)\n        payload = base64.b64encode(jsonparams.encode())\n        signature = hmac.new(self.secret_key.encode(), payload,\n                             hashlib.sha384).hexdigest()\n\n        return {'X-GEMINI-APIKEY': self.api_key,\n                'X-GEMINI-PAYLOAD': payload,\n                'X-GEMINI-SIGNATURE': signature}", "response": "Prepare the parameters and return the required HTTP headers."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef merge(cls, source_blocks):\n\n        if len(source_blocks) == 1:\n            return source_blocks[0]\n\n        source_blocks.sort(key=operator.attrgetter('start_line_number'))\n        main_block = source_blocks[0]\n        boot_lines = main_block.boot_lines\n        source_lines = [source_line for source_block in source_blocks for source_line in source_block.source_lines]\n\n        return cls(boot_lines, source_lines, directive=main_block.directive,\n                   language=main_block.language, roles=main_block.roles)", "response": "Merge multiple SourceBlocks together"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef complete_block(self):\n        return \"\".join(line[SOURCE] for line in self._boot_lines + self._source_lines)", "response": "Return code lines with bootstrap and source lines"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef character_summary_table():\n    # a database client/session to run queries in\n    cl = client.get_client()\n    session = cl.create_session()\n\n    # Define the query. Note that we need to rename the two joined-in name columns,\n    # to make the labels intelligible and to not have two identical column names in the output.\n    # Also, we need a left outer join on the place of birth (instead of the default left inner join)\n    # if we want results for characters that have no place of birth set.\n    query = session.query(models.Character,\n                          models.Universe.name.label('universe'),\n                          models.Place.name.label('place_of_birth')) \\\n        .join(models.Character.universe) \\\n        .outerjoin(models.Character.place_of_birth)\n\n    # download all data as a pandas DataFrame, index it by the character ID\n    characters = cl.df_query(query).set_index('id')\n\n    # query the number of movie appearances per character\n    query = session.query(sa.func.count(models.MovieAppearance.id).label('movie_appearances'),\n                          models.MovieAppearance.character_id) \\\n        .group_by(models.MovieAppearance.character_id)\n\n    appearances = cl.df_query(query).set_index('character_id')\n\n    # join both tables, sort by name\n    df = characters.join(appearances, how='left').sort_values(by='name')\n\n    # drop the foreign key columns (have no meaning outside our DB)\n    df = df.drop(['universe_id', 'place_of_birth_id'], axis=1)\n\n    # write output as both CSV and Excel; do not include index column\n    df.to_csv(path.join(out_dir, \"characters.csv\"), encoding='utf-8', index=False)\n    df.to_excel(path.join(out_dir, \"characters.xlsx\"), encoding='utf-8', index=False)\n\n    session.close()", "response": "Export a table listing all characters and their data"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates general statistics of the current language.", "response": "def plots_html_page():\n    \"\"\"Generate general statistics\n\n    Output is an html page, rendered to 'plots_html_page.html' in the output directory.\n    \"\"\"\n    # page template\n    template = jenv.get_template(\"plots_html_page.html\")\n\n    # container for template context\n    context = dict()\n\n    # a database client/session to run queries in\n    cl = client.get_client()\n    session = cl.create_session()\n\n    # general styling\n    seaborn.set_style('whitegrid')\n\n    #\n    #  plot: number of superheroes, by year of first appearance\n    #\n\n    # just query all character data, do analysis in pandas\n    query = session.query(models.Character)\n    character_data = cl.df_query(query)\n\n    # plot character appearances per year\n    fig = plt.figure(figsize=pixels_to_inches((400, 300)))\n    plt.plot(character_data.groupby('first_apperance_year')['id'].count(), '-o', c=seaborn.color_palette()[0])\n    # labels and title\n    plt.xlabel('Year')\n    plt.ylabel('Number of first appearances')\n    plt.title('Number of first character appearances per year')\n    # render to svg string, store in template context\n    context['first_appearances_per_year_svg'] = fig_to_svg(fig)\n    plt.close(fig)\n\n    #\n    #  plot: number of movies, by year of publication\n    #\n\n    # just query all movie data, do analysis in pandas\n    query = session.query(models.Movie)\n    movie_data = cl.df_query(query)\n\n    # plot movie publications per year\n    fig = plt.figure(figsize=pixels_to_inches((400, 300)))\n    plt.plot(movie_data.groupby('year')['id'].count(), '-o', c=seaborn.color_palette()[1])\n    plt.xlabel('Year')\n    plt.ylabel('Number of movies')\n    plt.title('Number of movies per year')\n    context['movies_per_year_svg'] = fig_to_svg(fig)\n    plt.close(fig)\n\n    #\n    #  plot: average character appearances per movie per year\n    #\n\n    # query number of character appearances for each movie, together with the movie year\n    query = session.query(sa.func.count(models.MovieAppearance.character_id).label('n_characters'),\n                          models.Movie.id,\n                          models.Movie.year) \\\n        .join(models.Movie) \\\n        .group_by(models.Movie.id, models.Movie.year)\n    appearance_counts = cl.df_query(query)\n\n    fig = plt.figure(figsize=pixels_to_inches((400, 300)))\n    plt.plot(appearance_counts.groupby('year')['n_characters'].mean(), '-o', c=seaborn.color_palette()[2])\n    plt.xlabel('Year')\n    plt.ylabel('Average number of characters')\n    plt.title('Average number of characters in a movie, per year')\n    context['average_appearances_per_movie_svg'] = fig_to_svg(fig)\n\n    #\n    #  plots: average movie budget per year, with and without inflation adjustment\n    #\n\n    fig = plt.figure(figsize=pixels_to_inches((400, 300)))\n    plt.plot(movie_data.groupby('year')['budget'].mean() / 1e6, '-o', c=seaborn.color_palette()[3])\n    plt.xlabel('Year')\n    plt.ylabel('Average budget in Mio Euro')\n    plt.title('Average movie budget per year')\n    plt.xlim(1980, plt.xlim()[1])\n    context['budget_per_year_svg'] = fig_to_svg(fig)\n    plt.close(fig)\n\n    fig = plt.figure(figsize=pixels_to_inches((400, 300)))\n    plt.plot(movie_data.groupby('year')['budget_inflation_adjusted'].mean() / 1e6, '-o', c=seaborn.color_palette()[4])\n    plt.xlabel('Year')\n    plt.ylabel('Average budget in Mio Euro')\n    plt.title('Average movie budget per year, adjusted for inflation')\n    plt.xlim(1980, plt.xlim()[1])\n    context['budget_adjusted_per_year_svg'] = fig_to_svg(fig)\n    plt.close(fig)\n\n    #\n    # render template\n    #\n\n    # add additional context data:\n    # - html code for list of imported universes\n    # noinspection PyUnresolvedReferences\n    context['universes_list'] = ', '.join(config.UNIVERSES)\n\n    out_file = path.join(out_dir, \"plots_html_page.html\")\n    html_content = template.render(**context)\n    with open(out_file, 'w') as f:\n        f.write(html_content)\n\n    # done, clean up\n    plt.close('all')\n    session.close()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef movie_network():\n    # page template\n    template = jenv.get_template(\"movie_network.html\")\n\n    # container for template context\n    context = dict()\n\n    # a database client/session to run queries in\n    cl = client.get_client()\n    session = cl.create_session()\n\n    #\n    # query data\n    #\n\n    # get all Movies\n    query = session.query(models.Movie.id,\n                          models.Movie.name,\n                          models.Movie.url,\n                          models.Movie.budget_inflation_adjusted,\n                          models.Movie.imdb_rating)\n    movies = cl.df_query(query)\n\n    # get all Movie Appearances\n    query = session.query(models.MovieAppearance.movie_id,\n                          models.MovieAppearance.character_id)\n    appearances = cl.df_query(query)\n\n    # get all Characters that have movie appearances\n    query = session.query(models.Character.id,\n                          models.Character.url,\n                          models.Character.name) \\\n        .filter(models.Character.id.in_([int(i) for i in appearances['character_id'].unique()]))\n    characters = cl.df_query(query)\n\n    #\n    # transform to network graph\n    #\n\n    graph = dict(nodes=[],\n                 graph=[],  # this stays empty\n                 links=[],\n                 directed=False,\n                 multigraph=True)\n\n    # containers for lookups from movie/character IDs to node IDs\n    movie_node_id = dict()\n    character_node_id = dict()\n\n    # normalization for movie node size: 100 = max budget\n    movie_size_factor = 100. / movies['budget_inflation_adjusted'].max()\n\n    # nodes for movies\n    for _, data in movies.iterrows():\n        movie_node_id[data['id']] = len(graph['nodes'])\n        # noinspection PyTypeChecker\n        graph['nodes'].append(dict(id=data['name'],\n                                   size=max(5., data['budget_inflation_adjusted'] * movie_size_factor),\n                                   score=data['imdb_rating'] / 10.,\n                                   type='square',\n                                   url=\"http://marvel.wikia.com\" + data['url']))\n\n    # nodes for characters\n    for _, data in characters.iterrows():\n        character_node_id[data['id']] = len(graph['nodes'])\n        # noinspection PyTypeChecker\n        graph['nodes'].append(dict(id=data['name'],\n                                   size=10,\n                                   type='circle',\n                                   url=\"http://marvel.wikia.com\" + data['url']))\n\n    # links: movie appearances\n    for _, data in appearances.iterrows():\n        # noinspection PyTypeChecker\n        graph['links'].append(dict(source=movie_node_id[data['movie_id']],\n                                   target=character_node_id[data['character_id']]))\n\n    context['graph'] = json.dumps(graph, indent=4)\n\n    #\n    # render template\n    #\n\n    out_file = path.join(out_dir, \"movie_network.html\")\n    html_content = template.render(**context)\n    with open(out_file, 'w') as f:\n        f.write(html_content)\n\n    # done, clean up\n    plt.close('all')\n    session.close()", "response": "Generate interactive network of movie appearances"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfollow a graph to find the nodes connected to a given node.", "response": "def follow(id, edges, directed=False, _visited=None):\n    \"\"\"\n    Follow the a graph to find the nodes connected to a given node.\n    Args:\n        id: the id of the starting node\n        edges: a pandas DataFrame of edges. Each row is an edge with two columns containing\n            the ids of the vertices.\n        directed: If True, edges are directed from first column to second column.\n              Otherwise edges are undirected.\n        _visited: used internally for recursion\n    Returns: the set of all nodes connected to the starting node.\n\n    \"\"\"\n    if _visited is None:\n        _visited = set()\n    _visited.add(id)\n\n    for row in edges[edges.ix[:, 0] == id].values:\n        if(row[1] not in _visited):\n            follow(row[1], edges, directed, _visited)\n\n    if not directed:\n        for row in edges[edges.ix[:, 1] == id].values:\n            if(row[0] not in _visited):\n                follow(row[0], edges, directed, _visited)\n\n    return _visited"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_components(edges, vertices=None):\n    if vertices is None:\n        vertices = set(chain(edges.ix[:, 0], edges.ix[:, 1]))\n\n    visited = set()\n    components = []\n\n    for id in vertices:\n        if id not in visited:\n            c = follow(id, edges)\n            visited.update(c)\n            components.append(c)\n\n    return components", "response": "Returns connected components from graph determined by edges matrix\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting a collection of components into a dataframe with columns id1 and id2.", "response": "def components_to_df(components, id_func=None):\n    \"\"\"\n    Convert components to a join table with columns id1, id2\n    Args:\n        components: A collection of components, each of which is a set of vertex ids.\n            If a dictionary, then the key is the id for the component. Otherwise,\n            the component id is determined by applying id_func to the component.\n        id_func: If components is a dictionary, this should be None. Otherwise,\n            this is a callable that, given a set of vertices, deermines the id.\n            If components is not a dict and id_func is None, it defaults to `min`.\n    Returns: A dataframe representing the one-to-many relationship between\n            component names (id1) and their members (id2).\n    \"\"\"\n    deduped = np.empty((0, 2), dtype=int)\n\n    if id_func is None:\n        if isinstance(components, dict):\n            raise ValueError(\"If components is a dict, id_func should be None.\")\n        else:\n            id_func = min\n\n    for c in components:\n        if id_func is None:\n            id1 = c\n            c = components[c]\n        else:\n            id1 = id_func(c)\n\n        deduped = np.append(deduped, [[id1, id2] for id2 in c], axis=0)\n\n    deduped = pd.DataFrame(deduped, columns=['id1', 'id2'])\n    return deduped"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nunpacks a 2D array into x and y components.", "response": "def unpack2D(_x):\n    \"\"\"\n        Helper function for splitting 2D data into x and y component to make\n        equations simpler\n    \"\"\"\n    _x = np.atleast_2d(_x)\n    x = _x[:, 0]\n    y = _x[:, 1]\n    return x, y"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_pkg_info(fn):\n    res = {}\n    for ln in open(fn).read().splitlines():\n        if not ln or not ln[:1].strip():\n            continue\n        key, value = ln.split(\": \", 1)\n        res[key] = value\n    return res", "response": "Parse pkg_info file into a dict"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_py_statement(line):\n    state = 0\n    cur_token = \"\"\n    spaces = \" \\t\\n\"\n    ops = \".,;:+-*/%&!=|(){}[]^<>\"\n    i = 0\n\n    def _escape_char(_c):\n        if _c == \"n\":\n            return \"\\n\"\n        elif _c == \"t\":\n            return \"\\t\"\n        else:\n            return _c\n\n    while i < len(line):\n        c = line[i]\n        i += 1\n        if state == 0:\n            if c in spaces:\n                pass\n            elif c in ops:\n                yield (\"op\", c)\n            elif c == \"#\":\n                state = 6\n            elif c == \"\\\"\":\n                state = 1\n            elif c == \"'\":\n                state = 2\n            else:\n                cur_token = c\n                state = 3\n        elif state == 1:  # string via \"\n            if c == \"\\\\\":\n                state = 4\n            elif c == \"\\\"\":\n                yield (\"str\", cur_token)\n                cur_token = \"\"\n                state = 0\n            else:\n                cur_token += c\n        elif state == 2:  # string via '\n            if c == \"\\\\\":\n                state = 5\n            elif c == \"'\":\n                yield (\"str\", cur_token)\n                cur_token = \"\"\n                state = 0\n            else:\n                cur_token += c\n        elif state == 3:  # identifier\n            if c in spaces + ops + \"#\\\"'\":\n                yield (\"id\", cur_token)\n                cur_token = \"\"\n                state = 0\n                i -= 1\n            else:\n                cur_token += c\n        elif state == 4:  # escape in \"\n            cur_token += _escape_char(c)\n            state = 1\n        elif state == 5:  # escape in '\n            cur_token += _escape_char(c)\n            state = 2\n        elif state == 6:  # comment\n            cur_token += c\n    if state == 3:\n        yield (\"id\", cur_token)\n    elif state == 6:\n        yield (\"comment\", cur_token)", "response": "Parse a single line of text into a list of types and values."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef grep_full_py_identifiers(tokens):\n    global py_keywords\n    tokens = list(tokens)\n    i = 0\n    while i < len(tokens):\n        token_type, token = tokens[i]\n        i += 1\n        if token_type != \"id\":\n            continue\n        while i+1 < len(tokens) and tokens[i] == (\"op\", \".\") and tokens[i+1][0] == \"id\":\n            token += \".\" + tokens[i+1][1]\n            i += 2\n        if token == \"\":\n            continue\n        if token in py_keywords:\n            continue\n        if token[0] in \".0123456789\":\n            continue\n        yield token", "response": "Yields all the full python identifiers in a single resource tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef debug_shell(user_ns, user_global_ns, traceback=None, execWrapper=None):\n    ipshell = None\n    try:\n        # noinspection PyPackageRequirements\n        import IPython\n        have_ipython = True\n    except ImportError:\n        have_ipython = False\n\n    if not ipshell and traceback and have_ipython:\n        # noinspection PyBroadException\n        try:\n            # noinspection PyPackageRequirements,PyUnresolvedReferences\n            from IPython.core.debugger import Pdb\n            # noinspection PyPackageRequirements,PyUnresolvedReferences\n            from IPython.terminal.debugger import TerminalPdb\n            # noinspection PyPackageRequirements,PyUnresolvedReferences\n            from IPython.terminal.ipapp import TerminalIPythonApp\n            ipapp = TerminalIPythonApp.instance()\n            ipapp.interact = False  # Avoid output (banner, prints)\n            ipapp.initialize(argv=[])\n            def_colors = ipapp.shell.colors\n            pdb_obj = TerminalPdb(def_colors)\n            pdb_obj.botframe = None  # not sure. exception otherwise at quit\n\n            def ipshell():\n                \"\"\"\n                Run the IPython shell.\n                \"\"\"\n                pdb_obj.interaction(None, traceback=traceback)\n\n        except Exception:\n            print(\"IPython Pdb exception:\")\n            better_exchook(*sys.exc_info(), autodebugshell=False)\n\n    if not ipshell and have_ipython:\n        # noinspection PyBroadException\n        try:\n            # noinspection PyPackageRequirements,PyUnresolvedReferences\n            import IPython\n            # noinspection PyPackageRequirements,PyUnresolvedReferences\n            import IPython.terminal.embed\n\n            class DummyMod(object):\n                \"\"\"Dummy module\"\"\"\n            module = DummyMod()\n            module.__dict__ = user_global_ns\n            module.__name__ = \"_DummyMod\"\n            if \"__name__\" not in user_ns:\n                user_ns = user_ns.copy()\n                user_ns[\"__name__\"] = \"_DummyUserNsMod\"\n            ipshell = IPython.terminal.embed.InteractiveShellEmbed.instance(\n                user_ns=user_ns, user_module=module)\n        except Exception:\n            print(\"IPython not available:\")\n            better_exchook(*sys.exc_info(), autodebugshell=False)\n        else:\n            if execWrapper:\n                old = ipshell.run_code\n                ipshell.run_code = lambda code: execWrapper(lambda: old(code))\n    if ipshell:\n        ipshell()\n    else:\n        print(\"Use simple debug shell:\")\n        if traceback:\n            import pdb\n            pdb.post_mortem(traceback)\n        else:\n            simple_debug_shell(user_global_ns, user_ns)", "response": "Runs some interactive shell."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fallback_findfile(filename):\n    mods = [m for m in sys.modules.values() if m and hasattr(m, \"__file__\") and filename in m.__file__]\n    if len(mods) == 0:\n        return None\n    alt_fn = mods[0].__file__\n    if alt_fn[-4:-1] == \".py\":\n        alt_fn = alt_fn[:-1]  # *.pyc or whatever\n    if not os.path.exists(alt_fn) and alt_fn.startswith(\"./\"):\n        # Maybe current dir changed.\n        alt_fn2 = _cur_pwd + alt_fn[1:]\n        if os.path.exists(alt_fn2):\n            return alt_fn2\n        # Try dirs of some other mods.\n        for m in [\"__main__\", \"better_exchook\"]:\n            if hasattr(sys.modules.get(m), \"__file__\"):\n                alt_fn2 = os.path.dirname(sys.modules[m].__file__) + alt_fn[1:]\n                if os.path.exists(alt_fn2):\n                    return alt_fn2\n    return alt_fn", "response": "Try to find the full filename in sys. modules."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_source_code_missing_open_brackets(source_code):\n    open_brackets = \"[{(\"\n    close_brackets = \"]})\"\n    last_close_bracket = [-1]  # stack\n    counters = [0] * len(open_brackets)\n    # Go in reverse order through the tokens.\n    # Thus, we first should see the closing brackets, and then the matching opening brackets.\n    for t_type, t_content in reversed(list(parse_py_statements(source_code))):\n        if t_type != \"op\":\n            continue  # we are from now on only interested in ops (including brackets)\n        if t_content in open_brackets:\n            idx = open_brackets.index(t_content)\n            if last_close_bracket[-1] == idx:  # ignore if we haven't seen the closing one\n                counters[idx] -= 1\n                del last_close_bracket[-1]\n        elif t_content in close_brackets:\n            idx = close_brackets.index(t_content)\n            counters[idx] += 1\n            last_close_bracket += [idx]\n    return not all([c == 0 for c in counters])", "response": "Check if source code snippet is complete and even w. r. t. opening brackets are not found."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the source code of a line.", "response": "def get_source_code(filename, lineno, module_globals):\n    \"\"\"\n    :param str filename:\n    :param int lineno:\n    :param dict[str] module_globals:\n    :return: source code of that line\n    :rtype: str\n    \"\"\"\n    import linecache\n    linecache.checkcache(filename)\n    source_code = linecache.getline(filename, lineno, module_globals)\n    # In case of a multi-line statement, lineno is usually the last line.\n    # We are checking for missing open brackets and add earlier code lines.\n    while is_source_code_missing_open_brackets(source_code):\n        if lineno <= 0:\n            break\n        lineno -= 1\n        source_code = \"\".join([linecache.getline(filename, lineno, module_globals), source_code])\n    return source_code"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_indent_lines(prefix, s):\n    if not s:\n        return prefix\n    prefix_len = str_visible_len(prefix)\n    lines = s.splitlines(True)\n    return \"\".join([prefix + lines[0]] + [\" \" * prefix_len + l for l in lines[1:]])", "response": "Adds prefix to all lines of the ndata xml file"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the prefix of the first line of the n - tuple that is the same as the indent prefix of the first line.", "response": "def get_same_indent_prefix(lines):\n    \"\"\"\n    :param list[] lines:\n    :rtype: str|None\n    \"\"\"\n    if not lines:\n        return \"\"\n    prefix = get_indent_prefix(lines[0])\n    if not prefix:\n        return \"\"\n    if all([l.startswith(prefix) for l in lines]):\n        return prefix\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef remove_indent_lines(s):\n    if not s:\n        return \"\"\n    lines = s.splitlines(True)\n    prefix = get_same_indent_prefix(lines)\n    if prefix is None:  # not in expected format. just lstrip all lines\n        return \"\".join([l.lstrip() for l in lines])\n    return \"\".join([l[len(prefix):] for l in lines])", "response": "remove indentation from a string"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef replace_tab_indent(s, replace=\"    \"):\n    prefix = get_indent_prefix(s)\n    return prefix.replace(\"\\t\", replace) + s[len(prefix):]", "response": "Returns a string with tabs replaced with spaces."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a multi - line string with tabs replaced by spaces.", "response": "def replace_tab_indents(s, replace=\"    \"):\n    \"\"\"\n    :param str s: multi-line string with tabs\n    :param str replace: e.g. 4 spaces\n    :rtype: str\n    \"\"\"\n    lines = s.splitlines(True)\n    return \"\".join([replace_tab_indent(l, replace) for l in lines])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef to_bool(s, fallback=None):\n    if not s:\n        return fallback\n    s = s.lower()\n    if s in [\"1\", \"true\", \"yes\", \"y\"]:\n        return True\n    if s in [\"0\", \"false\", \"no\", \"n\"]:\n        return False\n    return fallback", "response": "Converts a string to a boolean value."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of lines of source code from a traceback.", "response": "def format_tb(tb=None, limit=None, allLocals=None, allGlobals=None, withTitle=False, with_color=None, with_vars=None):\n    \"\"\"\n    :param types.TracebackType|types.FrameType|StackSummary tb: traceback. if None, will use sys._getframe\n    :param int|None limit: limit the traceback to this number of frames. by default, will look at sys.tracebacklimit\n    :param dict[str]|None allLocals: if set, will update it with all locals from all frames\n    :param dict[str]|None allGlobals: if set, will update it with all globals from all frames\n    :param bool withTitle:\n    :param bool|None with_color: output with ANSI escape codes for color\n    :param bool with_vars: will print var content which are referenced in the source code line. by default enabled.\n    :return: list of strings (line-based)\n    :rtype: list[str]\n    \"\"\"\n    color = Color(enable=with_color)\n    output = _Output(color=color)\n\n    def format_filename(s):\n        \"\"\"\n        :param str s:\n        :rtype: str\n        \"\"\"\n        base = os.path.basename(s)\n        return (\n            color('\"' + s[:-len(base)], color.fg_colors[2]) +\n            color(base, color.fg_colors[2], bold=True) +\n            color('\"', color.fg_colors[2]))\n\n    format_py_obj = output.pretty_print\n    if tb is None:\n        # noinspection PyBroadException\n        try:\n            tb = get_current_frame()\n            assert tb\n        except Exception:\n            output(color(\"format_tb: tb is None and sys._getframe() failed\", color.fg_colors[1], bold=True))\n            return output.lines\n\n    def is_stack_summary(_tb):\n        \"\"\"\n        :param StackSummary|object _tb:\n        :rtype: bool\n        \"\"\"\n        return isinstance(_tb, StackSummary)\n\n    isframe = inspect.isframe\n    if withTitle:\n        if isframe(tb) or is_stack_summary(tb):\n            output(color('Traceback (most recent call first):', color.fg_colors[0]))\n        else:  # expect traceback-object (or compatible)\n            output(color('Traceback (most recent call last):', color.fg_colors[0]))\n    if with_vars is None and is_at_exit():\n        # Better to not show __repr__ of some vars, as this might lead to crashes\n        # when native extensions are involved.\n        with_vars = False\n        if withTitle:\n            output(\"(Exclude vars because we are exiting.)\")\n    if with_vars is None:\n        if any([f.f_code.co_name == \"__del__\" for f in iter_traceback()]):\n            # __del__ is usually called via the Python garbage collector (GC).\n            # This can happen and very random / non-deterministic places.\n            # There are cases where it is not safe to access some of the vars on the stack\n            # because they might be in a non-well-defined state, thus calling their __repr__ is not safe.\n            # See e.g. this bug:\n            # https://github.com/tensorflow/tensorflow/issues/22770\n            with_vars = False\n            if withTitle:\n                output(\"(Exclude vars because we are on a GC stack.)\")\n    if with_vars is None:\n        with_vars = True\n    # noinspection PyBroadException\n    try:\n        if limit is None:\n            if hasattr(sys, 'tracebacklimit'):\n                limit = sys.tracebacklimit\n        n = 0\n        _tb = tb\n\n        class NotFound(Exception):\n            \"\"\"\n            Identifier not found.\n            \"\"\"\n\n        def _resolve_identifier(namespace, keys):\n            \"\"\"\n            :param dict[str] namespace:\n            :param tuple[str] keys:\n            :return: namespace[name[0]][name[1]]...\n            \"\"\"\n            if keys[0] not in namespace:\n                raise NotFound()\n            obj = namespace[keys[0]]\n            for part in keys[1:]:\n                obj = getattr(obj, part)\n            return obj\n\n        # noinspection PyShadowingNames\n        def _try_set(old, prefix, func):\n            \"\"\"\n            :param None|str old:\n            :param str prefix:\n            :param func:\n            :return: old\n            \"\"\"\n            if old is not None:\n                return old\n            try:\n                return add_indent_lines(prefix, func())\n            except NotFound:\n                return old\n            except Exception as e:\n                return prefix + \"!\" + e.__class__.__name__ + \": \" + str(e)\n\n        while _tb is not None and (limit is None or n < limit):\n            if isframe(_tb):\n                f = _tb\n            elif is_stack_summary(_tb):\n                if isinstance(_tb[0], ExtendedFrameSummary):\n                    f = _tb[0].tb_frame\n                else:\n                    f = DummyFrame.from_frame_summary(_tb[0])\n            else:\n                f = _tb.tb_frame\n            if allLocals is not None:\n                allLocals.update(f.f_locals)\n            if allGlobals is not None:\n                allGlobals.update(f.f_globals)\n            if hasattr(_tb, \"tb_lineno\"):\n                lineno = _tb.tb_lineno\n            elif is_stack_summary(_tb):\n                lineno = _tb[0].lineno\n            else:\n                lineno = f.f_lineno\n            co = f.f_code\n            filename = co.co_filename\n            name = co.co_name\n            file_descr = \"\".join([\n                '  ',\n                color(\"File \", color.fg_colors[0], bold=True), format_filename(filename), \", \",\n                color(\"line \", color.fg_colors[0]), color(\"%d\" % lineno, color.fg_colors[4]), \", \",\n                color(\"in \", color.fg_colors[0]), name])\n            with output.fold_text_ctx(file_descr):\n                if not os.path.isfile(filename):\n                    alt_fn = fallback_findfile(filename)\n                    if alt_fn:\n                        output(\n                            color(\"    -- couldn't find file, trying this instead: \", color.fg_colors[0]) +\n                            format_filename(alt_fn))\n                        filename = alt_fn\n                source_code = get_source_code(filename, lineno, f.f_globals)\n                if source_code:\n                    source_code = remove_indent_lines(replace_tab_indents(source_code)).rstrip()\n                    output(\"    line: \", color.py_syntax_highlight(source_code), color=color.fg_colors[0])\n                    if not with_vars:\n                        pass\n                    elif isinstance(f, DummyFrame) and not f.have_vars_available:\n                        pass\n                    else:\n                        with output.fold_text_ctx(color('    locals:', color.fg_colors[0])):\n                            already_printed_locals = set()  # type: typing.Set[typing.Tuple[str,...]]\n                            for token_str in grep_full_py_identifiers(parse_py_statement(source_code)):\n                                splitted_token = tuple(token_str.split(\".\"))\n                                for token in [splitted_token[0:i] for i in range(1, len(splitted_token) + 1)]:\n                                    if token in already_printed_locals:\n                                        continue\n                                    token_value = None\n                                    token_value = _try_set(\n                                        token_value, color(\"<local> \", color.fg_colors[0]),\n                                        lambda: format_py_obj(_resolve_identifier(f.f_locals, token)))\n                                    token_value = _try_set(\n                                        token_value, color(\"<global> \", color.fg_colors[0]),\n                                        lambda: format_py_obj(_resolve_identifier(f.f_globals, token)))\n                                    token_value = _try_set(\n                                        token_value, color(\"<builtin> \", color.fg_colors[0]),\n                                        lambda: format_py_obj(_resolve_identifier(f.f_builtins, token)))\n                                    token_value = token_value or color(\"<not found>\", color.fg_colors[0])\n                                    prefix = (\n                                        '      %s ' % color(\".\", color.fg_colors[0], bold=True).join(token) +\n                                        color(\"= \", color.fg_colors[0], bold=True))\n                                    output(prefix, token_value)\n                                    already_printed_locals.add(token)\n                            if len(already_printed_locals) == 0:\n                                output(color(\"       no locals\", color.fg_colors[0]))\n                else:\n                    output(color('    -- code not available --', color.fg_colors[0]))\n            if isframe(_tb):\n                _tb = _tb.f_back\n            elif is_stack_summary(_tb):\n                _tb = StackSummary.from_list(_tb[1:])\n                if not _tb:\n                    _tb = None\n            else:\n                _tb = _tb.tb_next\n            n += 1\n\n    except Exception:\n        output(color(\"ERROR: cannot get more detailed exception info because:\", color.fg_colors[1], bold=True))\n        import traceback\n        for l in traceback.format_exc().split(\"\\n\"):\n            output(\"   \" + l)\n\n    return output.lines"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprints a traceback to file", "response": "def print_tb(tb, file=None, **kwargs):\n    \"\"\"\n    :param types.TracebackType|types.FrameType|StackSummary tb:\n    :param io.TextIOBase|io.StringIO|None file: stderr by default\n    :return: nothing, prints to ``file``\n    \"\"\"\n    if file is None:\n        file = sys.stderr\n    for l in format_tb(tb=tb, **kwargs):\n        file.write(l)\n    file.flush()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprinting the traceback of all threads.", "response": "def dump_all_thread_tracebacks(exclude_thread_ids=None, file=None):\n    \"\"\"\n    Prints the traceback of all threads.\n\n    :param set[int]|list[int]|None exclude_thread_ids: threads to exclude\n    :param io.TextIOBase|io.StringIO file: output stream\n    \"\"\"\n    if exclude_thread_ids is None:\n        exclude_thread_ids = []\n    if not file:\n        file = sys.stdout\n    import threading\n\n    if hasattr(sys, \"_current_frames\"):\n        print(\"\", file=file)\n        threads = {t.ident: t for t in threading.enumerate()}\n        # noinspection PyProtectedMember\n        for tid, stack in sys._current_frames().items():\n            if tid in exclude_thread_ids:\n                continue\n            # This is a bug in earlier Python versions.\n            # http://bugs.python.org/issue17094\n            # Note that this leaves out all threads not created via the threading module.\n            if tid not in threads:\n                continue\n            tags = []\n            thread = threads.get(tid)\n            if thread:\n                assert isinstance(thread, threading.Thread)\n                if thread is threading.currentThread():\n                    tags += [\"current\"]\n                # noinspection PyProtectedMember,PyUnresolvedReferences\n                if isinstance(thread, threading._MainThread):\n                    tags += [\"main\"]\n                tags += [str(thread)]\n            else:\n                tags += [\"unknown with id %i\" % tid]\n            print(\"Thread %s:\" % \", \".join(tags), file=file)\n            print_tb(stack, file=file)\n            print(\"\", file=file)\n        print(\"That were all threads.\", file=file)\n    else:\n        print(\"Does not have sys._current_frames, cannot get thread tracebacks.\", file=file)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the current frame object.", "response": "def get_current_frame():\n    \"\"\"\n    :return: current frame object (excluding this function call)\n    :rtype: types.FrameType\n\n    Uses sys._getframe if available, otherwise some trickery with sys.exc_info and a dummy exception.\n    \"\"\"\n    if hasattr(sys, \"_getframe\"):\n        # noinspection PyProtectedMember\n        return sys._getframe(1)\n    try:\n        raise ZeroDivisionError\n    except ZeroDivisionError:\n        return sys.exc_info()[2].tb_frame.f_back"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\niterate over the tracebacks in a list of basic types.", "response": "def iter_traceback(tb=None, enforce_most_recent_call_first=False):\n    \"\"\"\n    Iterates a traceback of various formats:\n      - traceback (types.TracebackType)\n      - frame object (types.FrameType)\n      - stack summary (traceback.StackSummary)\n\n    :param types.TracebackType|types.FrameType|StackSummary|None tb: traceback. if None, will use sys._getframe\n    :param bool enforce_most_recent_call_first:\n        Frame or stack summery: most recent call first (top of the stack is the first entry in the result)\n        Traceback: most recent call last\n        If True, and we get traceback, will unroll and reverse, such that we have always the most recent call first.\n    :return: yields the frames (types.FrameType)\n    :rtype: list[types.FrameType|DummyFrame]\n    \"\"\"\n    if tb is None:\n        tb = get_current_frame()\n\n    def is_stack_summary(_tb):\n        \"\"\"\n        :param StackSummary|object _tb:\n        :rtype: bool\n        \"\"\"\n        return isinstance(_tb, StackSummary)\n\n    is_frame = inspect.isframe\n    is_traceback = inspect.istraceback\n    assert is_traceback(tb) or is_frame(tb) or is_stack_summary(tb)\n    # Frame or stack summery: most recent call first\n    # Traceback: most recent call last\n    if is_traceback(tb) and enforce_most_recent_call_first:\n        frames = list(iter_traceback(tb))\n        for frame in frames[::-1]:\n            yield frame\n        return\n\n    _tb = tb\n    while _tb is not None:\n        if is_frame(_tb):\n            frame = _tb\n        elif is_stack_summary(_tb):\n            if isinstance(_tb[0], ExtendedFrameSummary):\n                frame = _tb[0].tb_frame\n            else:\n                frame = DummyFrame.from_frame_summary(_tb[0])\n        else:\n            frame = _tb.tb_frame\n        yield frame\n        if is_frame(_tb):\n            _tb = _tb.f_back\n        elif is_stack_summary(_tb):\n            _tb = StackSummary.from_list(_tb[1:])\n            if not _tb:\n                _tb = None\n        else:\n            _tb = _tb.tb_next"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreplace the original StackSummary. extract method with extendedFrameSummary.", "response": "def _StackSummary_extract(frame_gen, limit=None, lookup_lines=True, capture_locals=False):\n    \"\"\"\n    Replacement for :func:`StackSummary.extract`.\n\n    Create a StackSummary from a traceback or stack object.\n    Very simplified copy of the original StackSummary.extract().\n    We want always to capture locals, that is why we overwrite it.\n    Additionally, we also capture the frame.\n    This is a bit hacky and also not like this is originally intended (to not keep refs).\n\n    :param frame_gen: A generator that yields (frame, lineno) tuples to\n        include in the stack.\n    :param limit: None to include all frames or the number of frames to\n        include.\n    :param lookup_lines: If True, lookup lines for each frame immediately,\n        otherwise lookup is deferred until the frame is rendered.\n    :param capture_locals: If True, the local variables from each frame will\n        be captured as object representations into the FrameSummary.\n    \"\"\"\n    result = StackSummary()\n    for f, lineno in frame_gen:\n        co = f.f_code\n        filename = co.co_filename\n        name = co.co_name\n        result.append(ExtendedFrameSummary(\n            frame=f, filename=filename, lineno=lineno, name=name, lookup_line=False))\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef replace_traceback_format_tb():\n    import traceback\n    traceback.format_tb = format_tb\n    if hasattr(traceback, \"StackSummary\"):\n        traceback.StackSummary.format = format_tb\n        traceback.StackSummary.extract = _StackSummary_extract", "response": "Replace the format_tb and extract functions in the traceback module by our own."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _main():\n\n    if sys.argv[1:] == [\"test\"]:\n        for k, v in sorted(globals().items()):\n            if not k.startswith(\"test_\"):\n                continue\n            print(\"running: %s()\" % k)\n            v()\n        print(\"ok.\")\n        sys.exit()\n\n    elif sys.argv[1:] == [\"debug_shell\"]:\n        debug_shell(locals(), globals())\n        sys.exit()\n\n    elif sys.argv[1:] == [\"debug_shell_exception\"]:\n        try:\n            raise Exception(\"demo exception\")\n        except Exception:\n            better_exchook(*sys.exc_info(), debugshell=True)\n        sys.exit()\n\n    elif sys.argv[1:]:\n        print(\"Usage: %s (test|...)\" % sys.argv[0])\n        sys.exit(1)\n\n    # some examples\n    # this code produces this output: https://gist.github.com/922622\n\n    try:\n        x = {1: 2, \"a\": \"b\"}\n\n        # noinspection PyMissingOrEmptyDocstring\n        def f():\n            y = \"foo\"\n            # noinspection PyUnresolvedReferences,PyStatementEffect\n            x, 42, sys.stdin.__class__, sys.exc_info, y, z\n        f()\n    except Exception:\n        better_exchook(*sys.exc_info())\n\n    try:\n        # noinspection PyArgumentList\n        (lambda _x: None)(__name__,\n                          42)  # multiline\n    except Exception:\n        better_exchook(*sys.exc_info())\n\n    try:\n        class Obj:\n            def __repr__(self):\n                return (\n                    \"<Obj multi-\\n\" +\n                    \"     line repr>\")\n        obj = Obj()\n        assert not obj\n    except Exception:\n        better_exchook(*sys.exc_info())\n\n    # noinspection PyMissingOrEmptyDocstring\n    def f1(a):\n        f2(a + 1, 2)\n\n    # noinspection PyMissingOrEmptyDocstring\n    def f2(a, b):\n        f3(a + b)\n\n    # noinspection PyMissingOrEmptyDocstring\n    def f3(a):\n        b = (\"abc\" * 100) + \"-interesting\"  # some long demo str\n        a(b)  # error, not callable\n\n    try:\n        f1(13)\n    except Exception:\n        better_exchook(*sys.exc_info())\n\n    # use this to overwrite the global exception handler\n    install()\n    # and fail\n    # noinspection PyUnresolvedReferences\n    finalfail(sys)", "response": "This is the main function for the demo."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning True if we have a dark terminal background color or False if unknown.", "response": "def is_dark_terminal_background(cls):\n        \"\"\"\n        :return: Whether we have a dark Terminal background color, or None if unknown.\n            We currently just check the env var COLORFGBG,\n            which some terminals define like \"<foreground-color>:<background-color>\",\n            and if <background-color> in {0,1,2,3,4,5,6,8}, then we have some dark background.\n            There are many other complex heuristics we could do here, which work in some cases but not in others.\n            See e.g. `here <https://stackoverflow.com/questions/2507337/terminals-background-color>`__.\n            But instead of adding more heuristics, we think that explicitly setting COLORFGBG would be the best thing,\n            in case it's not like you want it.\n        :rtype: bool|None\n        \"\"\"\n        if os.environ.get(\"COLORFGBG\", None):\n            parts = os.environ[\"COLORFGBG\"].split(\";\")\n            try:\n                last_number = int(parts[-1])\n                if 0 <= last_number <= 6 or last_number == 8:\n                    return True\n                else:\n                    return False\n            except ValueError:  # not an integer?\n                pass\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncolor the log entry.", "response": "def color(self, s, color=None, bold=False):\n        \"\"\"\n        :param str s:\n        :param str|None color: sth in self.ColorIdxTable\n        :param bool bold:\n        :return: s optionally wrapped with ansi escape codes\n        :rtype: str\n        \"\"\"\n        if not self.enable:\n            return s\n        code_seq = []\n        if color:\n            code_seq += [30 + self.ColorIdxTable[color]]  # foreground color\n        if bold:\n            code_seq += [1]\n        if not code_seq:\n            return s\n        start = \"\\x1b[%sm\" % \";\".join(map(str, code_seq))\n        end = \"\\x1b[0m\"\n        while s[:1] == \" \":  # move prefix spaces outside\n            start = \" \" + start\n            s = s[1:]\n        while s[-1:] == \" \":  # move postfix spaces outside\n            end += \" \"\n            s = s[:-1]\n        return start + s + end"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nhighlights the syntax of the current locale.", "response": "def py_syntax_highlight(self, s):\n        \"\"\"\n        :param str s:\n        :rtype: str\n        \"\"\"\n        if not self.enable:\n            return s\n        state = 0\n        spaces = \" \\t\\n\"\n        ops = \".,;:+-*/%&!=|(){}[]^<>\"\n        i = 0\n        cur_token = \"\"\n        color_args = {0: {}, len(s): {}}  # type: typing.Dict[int,typing.Dict[str]]  # pos in s -> color kwargs\n\n        def finish_identifier():\n            \"\"\"\n            Reset color to standard for current identifier.\n            \"\"\"\n            if cur_token in py_keywords:\n                color_args[max([k for k in color_args.keys() if k < i])] = {\"color\": self.fg_colors[0]}\n\n        while i < len(s):\n            c = s[i]\n            i += 1\n            if c == \"\\n\":\n                if state == 3:\n                    finish_identifier()\n                color_args[i] = {}\n                state = 0\n            elif state == 0:\n                if c in spaces:\n                    pass\n                elif c in ops:\n                    color_args[i - 1] = {\"color\": self.fg_colors[0]}\n                    color_args[i] = {}\n                elif c == \"#\":\n                    color_args[i - 1] = {\"color\": self.fg_colors[3]}\n                    state = 6\n                elif c == '\"':\n                    color_args[i - 1] = {\"color\": self.fg_colors[2]}\n                    state = 1\n                elif c == \"'\":\n                    color_args[i - 1] = {\"color\": self.fg_colors[2]}\n                    state = 2\n                else:\n                    cur_token = c\n                    color_args[i - 1] = {}\n                    state = 3\n            elif state == 1:  # string via \"\n                if c == \"\\\\\":\n                    state = 4\n                elif c == \"\\\"\":\n                    color_args[i] = {}\n                    state = 0\n            elif state == 2:  # string via '\n                if c == \"\\\\\":\n                    state = 5\n                elif c == \"'\":\n                    color_args[i] = {}\n                    state = 0\n            elif state == 3:  # identifier\n                if c in spaces + ops + \"#\\\"'\":\n                    finish_identifier()\n                    color_args[i] = {}\n                    state = 0\n                    i -= 1\n                else:\n                    cur_token += c\n            elif state == 4:  # escape in \"\n                state = 1\n            elif state == 5:  # escape in '\n                state = 2\n            elif state == 6:  # comment\n                pass\n        if state == 3:\n            finish_identifier()\n        out = \"\"\n        i = 0\n        while i < len(s):\n            j = min([k for k in color_args.keys() if k > i])\n            out += self.color(s[i:j], **color_args[i])\n            i = j\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning True if we are inside DomTerm otherwise False.", "response": "def is_domterm(cls):\n        \"\"\"\n        :return: whether we are inside DomTerm\n        :rtype: bool\n        \"\"\"\n        import os\n        if cls._is_domterm is not None:\n            return cls._is_domterm\n        if not os.environ.get(\"DOMTERM\"):\n            cls._is_domterm = False\n            return False\n        cls._is_domterm = True\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fold_text_stream(self, prefix, postfix=\"\", hidden_stream=None, **kwargs):\n        import io\n        if hidden_stream is None:\n            hidden_stream = sys.stdout\n        assert isinstance(hidden_stream, io.IOBase)\n        assert hidden_stream is sys.stdout, \"currently not supported otherwise\"\n        hidden_buf = io.StringIO()\n        with self._temp_replace_attrib(sys, \"stdout\", hidden_buf):\n            yield\n        self.fold_text(prefix=prefix, postfix=postfix, hidden=hidden_buf.getvalue(), **kwargs)", "response": "A context manager that folds the text of the current process into a stream."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfolding text in the context of the current element.", "response": "def fold_text(self, prefix, hidden, postfix=\"\", file=None, align=0):\n        \"\"\"\n        :param str prefix: always visible\n        :param str hidden: hidden\n            If this is sys.stdout, it will replace that stream,\n            and collect the data during the context (in the `with` block).\n        :param str postfix: always visible, right after. \"\" by default.\n        :param io.TextIOBase|io.StringIO file: sys.stdout by default.\n        :param int align: remove this number of initial chars from hidden\n        \"\"\"\n        if file is None:\n            file = sys.stdout\n        # Extra logic: Multi-line hidden. Add initial \"\\n\" if not there.\n        if \"\\n\" in hidden:\n            if hidden[:1] != \"\\n\":\n                hidden = \"\\n\" + hidden\n        # Extra logic: A final \"\\n\" of hidden, make it always visible such that it looks nicer.\n        if hidden[-1:] == \"\\n\":\n            hidden = hidden[:-1]\n            postfix += \"\\n\"\n        if self.is_domterm():\n            with self.logical_block(file=file):\n                self.indentation(file=file)\n                self.hide_button(file=file)\n                file.write(prefix)\n                if prefix.endswith(\"\\x1b[0m\"):\n                    file.write(\" \")  # bug in DomTerm?\n                with self.hide_button_span(2, file=file):\n                    hidden_ls = hidden.split(\"\\n\")\n                    hidden_ls = [s[align:] for s in hidden_ls]\n                    hidden = \"\\033]118\\007\".join(hidden_ls)\n                    file.write(hidden)\n        else:\n            file.write(prefix)\n            file.write(hidden.replace(\"\\n\", \"\\n \"))\n        file.write(postfix)\n        file.flush()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfolds the text of the current locale into a string.", "response": "def fold_text_string(self, prefix, hidden, **kwargs):\n        \"\"\"\n        :param str prefix:\n        :param str hidden:\n        :param kwargs: passed to :func:`fold_text`\n        :rtype: str\n        \"\"\"\n        import io\n        output_buf = io.StringIO()\n        self.fold_text(prefix=prefix, hidden=hidden, file=output_buf, **kwargs)\n        return output_buf.getvalue()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfold text via domterm.", "response": "def fold_text_ctx(self, line):\n        \"\"\"\n        Folds text, via :class:`DomTerm`, if available.\n        Notes that this temporarily overwrites self.lines.\n\n        :param str line: always visible\n        \"\"\"\n        if not self.dom_term:\n            self.__call__(line)\n            yield\n            return\n        self.lines, old_lines = [], self.lines  # overwrite self.lines\n        yield  # collect output (in new self.lines)\n        self.lines, new_lines = old_lines, self.lines  # recover self.lines\n        hidden_text = \"\".join(new_lines)\n        import io\n        output_buf = io.StringIO()\n        prefix = \"\"\n        while line[:1] == \" \":\n            prefix += \" \"\n            line = line[1:]\n        self.dom_term.fold_text(line, hidden=hidden_text, file=output_buf, align=len(prefix))\n        output_text = prefix[1:] + output_buf.getvalue()\n        self.lines.append(output_text)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new object from a FrameSummary.", "response": "def from_frame_summary(cls, f):\n        \"\"\"\n        :param FrameSummary f:\n        :rtype: DummyFrame\n        \"\"\"\n        return cls(filename=f.filename, lineno=f.lineno, name=f.name, f_locals=f.locals)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef verify_mid_signature(certificate_data, sp_challenge, response_challenge, signature):\n\n    if not response_challenge.startswith(sp_challenge):\n        return False\n\n    try:\n        key = RSA.importKey(certificate_data)\n        verifier = PKCS1_v1_5.new(key)\n\n    except ValueError:\n        key = ECC.import_key(certificate_data)\n        verifier = DSS.new(key, 'deterministic-rfc6979')\n\n    digest = PrehashedMessageData(response_challenge)\n\n    try:\n        verifier.verify(digest, signature)\n\n        return True\n\n    except ValueError:\n        return False", "response": "Verify mobile id Authentication signature is valid"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmaking a single image request.", "response": "def make_request(self, image, *features):\n        \"\"\"\n        Makes single image request\n        :param image: One of file object, path, or URL\n        :param features: Recognition features\n        :return:\n        \"\"\"\n        return {\n            \"image\": {\n                \"content\": self.image_to_base64(image)\n            },\n            \"features\": [{\n                             \"type\": feature.type_,\n                             \"maxResults\": feature.max_results\n                         } for feature in features]\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert an image to base64", "response": "def image_to_base64(self, image):\n        \"\"\"\n        :param image: One of file object, path, or URL\n        :return: Base64 of image\n        \"\"\"\n        if isinstance(image, file_):\n            return base64.b64encode(image.read())\n        elif isinstance(image, basestring):\n            if image.startswith(\"http\"):\n                # it's URL\n                return base64.b64encode(requests.get(image).content)\n            # it's path\n            with open(image) as f:\n                return base64.b64encode(f.read())\n\n        raise ValueError(\"Unrecognizable image param: it must one of\"\n                         \" file object, path or URL, not %s\" % type(image))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nannotating the image with the features.", "response": "def annotate(self, image, *features):\n        \"\"\"\n        :param image: One of file object, path, or URL\n        :param features: list of Vision Features\n        :return: GoogleCloudVisionResponse\n        \"\"\"\n        body = self.make_body(image, *features)\n        try:\n            response = requests.post(self.api_url, json.dumps(body), headers=self.HEADERS)\n        except requests.RequestException as exc:\n            raise GoogleCloudVisionException(exc)\n        else:\n            return GoogleCloudVisionResponse(response.content)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nuse to dispatch events.", "response": "def drive(self, event, *args):\n        \"\"\"\n        Used to dispatch events.\n        \"\"\"\n\n        maps = self.base.get(event, self.step)\n        for handle, data in maps[:]:\n            params = args + data\n            try:\n                handle(self, *params)\n            except Stop:\n                break\n            except StopIteration:\n                pass\n            except Kill as Root:\n                raise\n            except Erase:\n                maps.remove((handle, data))\n            except Exception as e:\n                debug(event, params)\n\n        for handle in self.pool:\n            handle(self, event, args)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a mapping like event - handle - arg0 arg1 arg2...", "response": "def add_map(self, event, handle, *args):\n        \"\"\"\n        Add a mapping like event -(arg0, arg1, arg2, ...)-> handle.\n        \"\"\"\n\n        item = self.base.setdefault(event, list())\n        item.append((handle, args))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef del_map(self, event, handle, *args):\n        if args:\n            self.base[event].remove((handle, args))\n        else:\n            self.base[event] = [ind for ind in self.base[event] if ind[0] != handle]", "response": "Removes a mapping like event - arg0 arg1 arg2..."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef send(self, data):\n        self.stdin.write(data)\n        self.stdin.flush()", "response": "Send data to the child process through."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef destroy(self):\n        core.gear.pool.remove(self)    \n        self.base.clear()", "response": "Unregister up from untwisted reactor. It is needed to terminate the process."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load(steps, reload=False):\n    # work on collections by default for fewer isinstance() calls per call to load()\n    if reload:\n        _STEP_CACHE.clear()\n\n    if callable(steps):\n        steps = steps()\n\n    if not isinstance(steps, collections.Iterable):\n        return load([steps])[0]\n\n    loaded = []\n    for s in steps:\n        digest = s._digest\n        if digest in _STEP_CACHE:\n            loaded.append(_STEP_CACHE[digest])\n        else:\n            try:\n                s.load()\n                _STEP_CACHE[digest] = s\n                loaded.append(s)\n            except(Exception):\n                logging.warn('Error during step load:\\n%s' %\n                             util.indent(traceback.format_exc()))\n\n    return loaded", "response": "Load a list of items from a list of steps into a list of items."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _simplify_arguments(arguments):\n    if len(arguments.args) == 0:\n        return arguments.kwargs\n    elif len(arguments.kwargs) == 0:\n        return arguments.args\n    else:\n        return arguments", "response": "If positional or keyword arguments are empty return only one or the other."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmerges the results of a list of inputs into a single Arguments object.", "response": "def merge_results(inputs, arguments=None):\n        \"\"\"\n        Merges results to form arguments to run(). There are two cases for each result:\n         - dictionary: dictionaries get merged and passed as keyword arguments\n         - list: lists get concatenated to positional arguments\n         - Arguments: kwargs gets merged and args gets appended\n         - else: concatenated and passed as postitional arguments\n        Args:\n            inputs: the inputs whose results to merge\n            arguments: an optional existing Arguments object to merge into\n        \"\"\"\n        if arguments is None:\n            arguments = Arguments()\n\n        args = arguments.args\n        kwargs = arguments.kwargs\n\n        for i in inputs:\n            # without a mapping we handle two cases\n            # when the result is a dict merge it with a global dict\n            if isinstance(i.result, dict):\n                # but do not override\n                kwargs.update({k: v for k, v in i.result.items() if k not in kwargs})\n            elif isinstance(i.result, list):\n                args.extend(i.result)\n            elif isinstance(i.result, Arguments):\n                args.extend(i.result.args)\n                kwargs.update({k: v for k, v in i.result.kwargs.items() if k not in kwargs})\n            # otherwise use it as a positional argument\n            else:\n                args.append(i.result)\n\n        return arguments"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the set of this step and all steps passed to the constructor (recursively).", "response": "def _expand_inputs(step, steps=None):\n    \"\"\"\n    Returns the set of this step and all steps passed to the constructor (recursively).\n    \"\"\"\n    if steps is None:\n        steps = set()\n\n    for arg in step._kwargs.values():\n        if isinstance(arg, Step):\n            _expand_inputs(arg, steps=steps)\n        elif util.is_instance_collection(arg, Step):\n            for s in util.get_collection_values(arg):\n                _expand_inputs(s, steps=steps)\n\n    steps.add(step)\n    return steps"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncollecting the kwargs of this step and inputs passed to the constructor.", "response": "def _collect_kwargs(step, drop_duplicate_names=True):\n    \"\"\"\n    Collect the kwargs of this step and inputs passed to the constructor (recursively)\n    Returns: dictionary of name: kwargs pairs where name is the name of\n        a step and kwargs is its kwargs minus inputs. If the step doesn't have\n        a name __class__.__name__ is used.\n    \"\"\"\n    dicts = {}\n    duplicates = set()\n\n    for s in _expand_inputs(step):\n        name = s.name if s.name is not None else s.__class__.__name__\n        if name in dicts.keys():\n            if drop_duplicate_names:\n                duplicates.add(name)\n            else:\n                raise ValueError(\"Duplicate step names: %s\" % name)\n\n        d = dict(s._kwargs)\n        d = {k: v for k, v in d.items()\n             if not (isinstance(v, Step) or util.is_instance_collection(v, Step))}\n        dicts[name] = d\n\n    dicts = {k: v for k, v in dicts.items() if k not in duplicates}\n    return dicts"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a set of output directories for all target steps in the workflow.", "response": "def _output_dirnames(workflow=None, leaf=False):\n    \"\"\"\n    Args:\n        workflow: optional collection of steps\n        leaf: only include leaves of the workflow\n\n    Returns: If workflow is specified, returns output directories for all target\n        steps in the workflow. If no workflow specified, returns all extant\n        output directories in drain.PATH.\n    \"\"\"\n    if workflow is None:\n        dirs = set()\n        for cls in os.listdir(drain.PATH):\n            for step in os.listdir(os.path.join(drain.PATH, cls)):\n                dirs.add(os.path.join(drain.PATH, cls, step))\n        return dirs\n    else:\n        if leaf:\n            steps = [step for step in workflow if step.target]\n        else:\n            steps = util.union(step.get_inputs() for step in workflow if step.target)\n\n        return set(step._output_dirname for step in steps)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nexecute this step recursively loading inputs and dumping the results.", "response": "def execute(self, inputs=None, output=None, load_targets=False):\n        \"\"\"\n        Run this step, recursively running or loading inputs.\n        Used in bin/run_step.py which is run by drake.\n        Args:\n            inputs: collection of steps that should be loaded\n            output: step that should be dumped after it is run\n            load_targets (boolean): load all steps which are targets.\n                This argument is not used by run_step.py because target\n                does not get serialized. But it can be useful for\n                running steps directly.\n        \"\"\"\n        if self == output:\n            if os.path.exists(self._dump_dirname):\n                shutil.rmtree(self._dump_dirname)\n            if os.path.exists(self._target_filename):\n                os.remove(self._target_filename)\n            os.makedirs(self._dump_dirname)\n\n        if inputs is None:\n            inputs = []\n\n        if not hasattr(self, 'result'):\n            if self in inputs or (load_targets and self.target):\n                logging.info('Loading\\n%s' % util.indent(str(self)))\n                self.load()\n            else:\n                for i in self.inputs:\n                    i.execute(inputs=inputs, output=output,\n                              load_targets=load_targets)\n\n                args = merge_results(self.inputs)\n                logging.info('Running\\n%s' % util.indent(str(self)))\n                self.result = self.run(*args.args, **args.kwargs)\n\n        if self == output:\n            logging.info('Dumping\\n%s' % util.indent(str(self)))\n            self.dump()\n            util.touch(self._target_filename)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsearching the tree for a step with the given value.", "response": "def get_input(self, value, _search=None):\n        \"\"\"\n        Searches the tree for a step\n        Args:\n            value: The value to search for. If value is a string then the search looks for\n                a step of that name. If the value is a type, it looks for a step\n                of that type.\n        Returns: The first step found via a depth-first search.\n        \"\"\"\n        if _search is None:\n            if isinstance(value, string_types):\n                _search = lambda s: s.name  # noqa: E731\n            elif isinstance(value, type):\n                _search = type\n\n        for i in self.inputs:\n            step = i.get_input(value, _search)\n            if step is not None:\n                return step\n\n        if _search(self) == value:\n            return self"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_inputs(self, _visited=None):\n        if _visited is None:\n            _visited = set()\n\n        _visited.add(self)\n\n        for i in self.inputs:\n            if i not in _visited:\n                i.get_inputs(_visited)\n\n        return _visited", "response": "Returns the set of all input steps that are in the same order as this one."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_arguments(self, **include):\n        d = dict(self._kwargs)\n\n        for k in include:\n            if not include[k] and k in d:\n                d.pop(k)\n        return d", "response": "Returns a shallow copy of self. _kwargs\n        except inputs\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load(self):\n        hdf_filename = os.path.join(self._dump_dirname, 'result.h5')\n        if os.path.isfile(hdf_filename):\n            store = pd.HDFStore(hdf_filename, mode='r')\n            keys = store.keys()\n            if keys == ['/df']:\n                self.result = store['df']\n            else:\n                if set(keys) == set(map(lambda i: '/%s' % i, range(len(keys)))):\n                    # keys are not necessarily ordered\n                    self.result = [store[str(k)] for k in range(len(keys))]\n                else:\n                    self.result = {k[1:]: store[k] for k in keys}\n\n        else:\n            self.result = joblib.load(\n                    os.path.join(self._output_dirname, 'dump', 'result.pkl'))", "response": "Load this step s result from its dump directory"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset up dump, creating directories and writing step.yaml file containing yaml dump of this step. {drain.PATH}/{self._digest}/ step.yaml dump/", "response": "def setup_dump(self):\n        \"\"\"\n        Set up dump, creating directories and writing step.yaml file\n        containing yaml dump of this step.\n\n        {drain.PATH}/{self._digest}/\n            step.yaml\n            dump/\n        \"\"\"\n        dumpdir = self._dump_dirname\n        if not os.path.isdir(dumpdir):\n            os.makedirs(dumpdir)\n\n        dump = False\n        yaml_filename = self._yaml_filename\n\n        if not os.path.isfile(yaml_filename):\n            dump = True\n        else:\n            with open(yaml_filename) as f:\n                if f.read() != yaml.dump(self):\n                    logging.warning('Existing step.yaml does not match hash, regenerating')\n                    dump = True\n\n        if dump:\n            with open(yaml_filename, 'w') as f:\n                yaml.dump(self, f)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload the data file and do some basic type conversions", "response": "def load(self):\n        \"\"\"Load the data file, do some basic type conversions\n        \"\"\"\n\n        df = pd.read_csv(self.input_file,\n                         encoding='utf8')\n\n        df['wiki_id'] = df['artist'].str.split('/').str[-1]\n\n        # some years of birth are given as timestamps with prefix 't', convert to string\n        timestamps = df['dob'].str.startswith('t')\n        df.loc[timestamps, 'dob'] = df.loc[timestamps, 'dob'].str[1:].apply(\n            lambda s: str(datetime.datetime.fromtimestamp(float(s))))\n\n        df['year_of_birth'] = df['dob'].str[:4].astype(int)\n\n        return df"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading the data file and do some basic type conversions", "response": "def load(self):\n        \"\"\"Load the data file, do some basic type conversions\n        \"\"\"\n\n        df = pd.read_csv(self.input_file,\n                         encoding='utf8')\n\n        df['wiki_id'] = df['painting'].str.split('/').str[-1]\n        df['creator_wiki_id'] = df['creator'].str.split('/').str[-1]\n        df['decade'] = (df['inception'].str[:4].astype(float) / 10.).astype(int) * 10\n        df['area'] = df['width'] * df['height']\n\n        return df"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef main(ctx, root_dir, verbose):\n    root_dir = discover_package_doc_dir(root_dir)\n\n    # Subcommands should use the click.pass_obj decorator to get this\n    # ctx.obj object as the first argument.\n    ctx.obj = {'root_dir': root_dir,\n               'verbose': verbose}\n\n    # Set up application logging. This ensures that only documenteer's\n    # logger is activated. If necessary, we can add other app's loggers too.\n    if verbose:\n        log_level = logging.DEBUG\n    else:\n        log_level = logging.INFO\n    logger = logging.getLogger('documenteer')\n    logger.addHandler(logging.StreamHandler())\n    logger.setLevel(log_level)", "response": "This is the main function for the command line interface."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef build(ctx):\n    return_code = run_sphinx(ctx.obj['root_dir'])\n    if return_code > 0:\n        sys.exit(return_code)", "response": "Build documentation as HTML."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef days(date1, date2):\n    return lambda df, date1=date1, date2=date2: _days(df, date1, date2)", "response": "Returns a lambda that determines the number of days between two dates."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfetching the row - aggregated input columns for this ColumnFunction and returns a reduced dataframe with the names of the columns that were created by this ColumnFunction.", "response": "def apply_and_name(self, aggregator):\n        \"\"\"Fetches the row-aggregated input columns for this ColumnFunction.\n\n        Args:\n            aggregator (Aggregator)\n\n        Returns:\n            pd.DataFrame: The dataframe has columns with names self.names\n                that were created by this ColumnFunction,\n                and is indexed by the index that was passed to\n                aggregator.aggregate(index).\n        \"\"\"\n        reduced_df = self._apply(aggregator)\n        if len(self.names) != len(reduced_df.columns):\n            raise IndexError(\"ColumnFunction creates more columns than it has names for.\")\n        reduced_df.columns = self.names\n        return reduced_df"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef aggregate(self, index):\n\n        # deal with index as a string vs index as a index/MultiIndex\n        if isinstance(index, string_types):\n            col_df_grouped = self.col_df.groupby(self.df[index])\n        else:\n            self.col_df.index = pd.MultiIndex.from_arrays([self.df[i] for i in index])\n            col_df_grouped = self.col_df.groupby(level=index)\n            self.col_df.index = self.df.index\n\n        # perform the actual aggregation\n        self.reduced_df = pd.DataFrame({\n            colred: col_df_grouped[colred.column].agg(colred.agg_func)\n            for colred in self.column_reductions\n            })\n\n        # then apply the functions to produce the final dataframe\n        reduced_dfs = []\n        for cf in self.column_functions:\n            # each apply_and_name() calls get_reduced() with the column reductions it wants\n            reduced_dfs.append(cf.apply_and_name(self))\n\n        return pd.concat(reduced_dfs, axis=1)", "response": "Performs a groupby of the unique Columns by index and returns a dataframe that contains the result of the column functions and named accordingly."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _apply(self, aggregator):\n\n        reduced_dfs = []\n        if self.include_fraction:\n            n_df = self.numerator.apply_and_name(aggregator)\n            d_df = self.denominator.apply_and_name(aggregator)\n            reduced_dfs.extend([n_df[cn]/d_df[cd]\n                                for cn, cd in product(n_df.columns, d_df.columns)])\n\n        if self.include_numerator:\n            reduced_dfs.append(self.numerator.apply_and_name(aggregator))\n\n        if self.include_denominator:\n            reduced_dfs.append(self.denominator.apply_and_name(aggregator))\n\n        return pd.concat(reduced_dfs, axis=1)", "response": "Returns a dataframe with the requested ColumnReductions."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a clone of the Table optionally with some properties changed", "response": "def clone(self, **kwargs):\n        \"\"\"Create a clone of the Table, optionally with some properties changed\"\"\"\n        init_kwargs = {\n            \"name\": self.__name,\n            \"dataframe\": self.__df,\n            \"include_columns\": self.__include_columns,\n            \"include_index\": self.__include_index,\n            \"style\": self.__style,\n            \"column_styles\": self.__col_styles,\n            \"column_widths\": self.__column_widths,\n            \"row_styles\": self.__row_styles,\n            \"header_style\": self.header_style,\n            \"index_style\": self.index_style\n        }\n        init_kwargs.update(kwargs)\n        return self.__class__(**init_kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cell_styles(self):\n        styles = {}\n        for colname, col in self.dataframe.items():\n            for rowname, value in col.items():\n                if isinstance(value, Value) and value.style is not None:\n                    style = value.style\n                    if not isinstance(style, CellStyle):\n                        style = self._named_styles[style]\n                    styles[(rowname, colname)] = style\n        return styles", "response": "dict of cell styles"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_data(self, workbook, row, col, formula_values={}):\n        if workbook:\n            prev_table = workbook.active_table\n            workbook.active_table = self\n        try:\n            return self._get_data_impl(workbook, row, col, formula_values)\n        finally:\n            if workbook:\n                workbook.active_table = prev_table", "response": "Get the data for this table with any formulas resolved to the final\n                 excel formula."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninspects SDFile list of string Returns tuple of data label list and number of records", "response": "def inspect(lines):\n    \"\"\"Inspect SDFile list of string\n\n    Returns:\n        tuple: (data label list, number of records)\n    \"\"\"\n    labels = set()\n    count = 0\n    exp = re.compile(r\">.*?<([\\w ]+)>\")  # Space should be accepted\n    valid = False\n    for line in lines:\n        if line.startswith(\"M  END\\n\"):\n            valid = True\n        elif line.startswith(\"$$$$\"):\n            count += 1\n            valid = False\n        else:\n            result = exp.match(line)\n            if result:\n                labels.add(result.group(1))\n    if valid:\n        count += 1\n    return list(labels), count"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef inspect_file(path):\n    with open(path, 'rb') as f:\n        labels, count = inspect(tx.decode(line) for line in f)\n    return labels, count", "response": "Inspect SDFile structure\n\n    Returns:\n        tuple: (data label list, number of records)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse SDFile data part into dict", "response": "def optional_data(lines):\n    \"\"\"Parse SDFile data part into dict\"\"\"\n    data = {}\n    exp = re.compile(r\">.*?<([\\w ]+)>\")  # Space should be accepted\n    for i, line in enumerate(lines):\n        result = exp.match(line)\n        if result:\n            data[result.group(1)] = lines[i + 1]\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse atom block into atom objects", "response": "def atoms(lines):\n    \"\"\"Parse atom block into atom objects\n\n    Returns:\n        dict: networkx nodes\n    \"\"\"\n    # Convert sdf style charge to actual charge\n    conv_charge_table = {0: 0, 1: 3, 2: 2, 3: 1, 4: 0, 5: -1, 6: -2, 7: -3}\n    results = {}\n    for i, line in enumerate(lines):\n        symbol = line[31:34].rstrip()\n        try:\n            atom = Atom(symbol)\n        except KeyError:\n            raise ValueError(symbol)\n        xpos = float(line[0:10])\n        ypos = float(line[10:20])\n        zpos = float(line[20:30])\n        atom.coords = (xpos, ypos, zpos)\n        atom.mass_diff = int(line[34:37])\n        old_sdf_charge = int(line[37:40])\n        atom.charge = conv_charge_table[old_sdf_charge]\n        if old_sdf_charge == 4:\n            atom.radical = 1\n        # atom.stereo_flag = int(line[40:43])  # Not used\n        # valence = int(line[46:49])\n        # if valence:\n        #     atom.valence = valence\n        results[i + 1] = {\"atom\": atom}\n    return results"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef bonds(lines, atoms):\n    # Convert sdf style stereobond (see chem.model.bond.Bond)\n    conv_stereo_table = {0: 0, 1: 1, 3: 3, 4: 3, 6: 2}\n    results = {a: {} for a in atoms}\n    for line in lines:\n        bond = Bond()\n        first = int(line[0:3])\n        second = int(line[3:6])\n        if first > second:\n            bond.is_lower_first = 0\n        order = int(line[6:9])\n        if order < 4:\n            bond.order = order\n        bond.type = conv_stereo_table[int(line[9:12])]\n        results[first][second] = {\"bond\": bond}\n        results[second][first] = {\"bond\": bond}\n    return results", "response": "Parse bond block into bond objects\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef properties(lines):\n    results = {}\n    for i, line in enumerate(lines):\n        type_ = line[3:6]\n        if type_ not in [\"CHG\", \"RAD\", \"ISO\"]:\n            continue  # Other properties are not supported yet\n        count = int(line[6:9])\n        results[type_] = []\n        for j in range(count):\n            idx = int(line[10 + j * 8: 13 + j * 8])\n            val = int(line[14 + j * 8: 17 + j * 8])\n            results[type_].append((idx, val))\n    return results", "response": "Parse properties block\n\n    Returns:\n        dict: {property_type: (atom_index, value)}"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_properties(props, mol):\n    if not props:\n        return\n    # The properties supersedes all charge and radical values in the atom block\n    for _, atom in mol.atoms_iter():\n        atom.charge = 0\n        atom.multi = 1\n        atom.mass = None\n    for prop in props.get(\"CHG\", []):\n        mol.atom(prop[0]).charge = prop[1]\n    for prop in props.get(\"RAD\", []):\n        mol.atom(prop[0]).multi = prop[1]\n    for prop in props.get(\"ISO\", []):\n        mol.atom(prop[0]).mass = prop[1]", "response": "apply properties to the molecule object\n    Returns None if the properties are not set"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses a molecule part into a new object", "response": "def molecule(lines):\n    \"\"\"Parse molfile part into molecule object\n\n    Args:\n        lines (list): lines of molfile part\n\n    Raises:\n        ValueError: Symbol not defined in periodictable.yaml\n                    (Polymer expression not supported yet)\n    \"\"\"\n    count_line = lines[3]\n    num_atoms = int(count_line[0:3])\n    num_bonds = int(count_line[3:6])\n    # chiral_flag = int(count_line[12:15])  # Not used\n    # num_prop = int(count_line[30:33])  # \"No longer supported\"\n    compound = Compound()\n    compound.graph._node = atoms(lines[4: num_atoms+4])\n    compound.graph._adj = bonds(lines[num_atoms+4: num_atoms+num_bonds+4],\n                                compound.graph._node.keys())\n    props = properties(lines[num_atoms+num_bonds+4:])\n    add_properties(props, compound)\n    return compound"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef mol_supplier(lines, no_halt, assign_descriptors):\n    def sdf_block(lns):\n        mol = []\n        opt = []\n        is_mol = True\n        for line in lns:\n            if line.startswith(\"$$$$\"):\n                yield mol[:], opt[:]\n                is_mol = True\n                mol.clear()\n                opt.clear()\n            elif line.startswith(\"M  END\"):\n                is_mol = False\n            elif is_mol:\n                mol.append(line.rstrip())\n            else:\n                opt.append(line.rstrip())\n        if mol:\n            yield mol, opt\n\n    for i, (mol, opt) in enumerate(sdf_block(lines)):\n        try:\n            c = molecule(mol)\n            if assign_descriptors:\n                molutil.assign_descriptors(c)\n        except ValueError as err:\n            if no_halt:\n                print(\"Unsupported symbol: {} (#{} in v2000reader)\".format(\n                      err, i + 1))\n                c = molutil.null_molecule(assign_descriptors)\n            else:\n                raise ValueError(\"Unsupported symbol: {}\".format(err))\n        except RuntimeError as err:\n            if no_halt:\n                print(\n                    \"Failed to minimize ring: {} (#{} in v2000reader)\".format(\n                        err, i + 1)\n                )\n            else:\n                raise RuntimeError(\"Failed to minimize ring: {}\".format(err))\n        except:\n            if no_halt:\n                print(\"Unexpected error (#{} in v2000reader)\".format(i + 1))\n                c = molutil.null_molecule(assign_descriptors)\n                c.data = optional_data(opt)\n                yield c\n                continue\n            else:\n                print(traceback.format_exc())\n                raise Exception(\"Unsupported Error\")\n        c.data = optional_data(opt)\n        yield c", "response": "Yields molecules generated from CTAB text lines."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a generator of molecules generated from the given text.", "response": "def mols_from_text(text, no_halt=True, assign_descriptors=True):\n    \"\"\"Returns molecules generated from sdfile text\n\n    Throws:\n        StopIteration: if the text does not have molecule\n        ValueError: if Unsupported symbol is found\n    \"\"\"\n    if isinstance(text, bytes):\n        t = tx.decode(text)\n    else:\n        t = text\n    # Lazy line splitter. More efficient memory usage than str.split.\n    exp = re.compile(r\"[^\\n]*\\n|.\")\n    sp = (x.group(0) for x in re.finditer(exp, t))\n    for c in mol_supplier(sp, no_halt, assign_descriptors):\n        yield c"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses CTAB text and return first one as a Compound object.", "response": "def mol_from_text(text, assign_descriptors=True):\n    \"\"\"Parse CTAB text and return first one as a Compound object.\n\n    Throws:\n        StopIteration: if the text does not have molecule\n        ValueError: if Unsupported symbol is found\n    \"\"\"\n    cg = mols_from_text(text, False, assign_descriptors)\n    return next(cg)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nyield all Molecules from CTAB text file.", "response": "def mols_from_file(path, no_halt=True, assign_descriptors=True):\n    \"\"\"Compound supplier from CTAB text file (.mol, .sdf)\"\"\"\n    with open(path, 'rb') as f:\n        fd = (tx.decode(line) for line in f)\n        for c in mol_supplier(fd, no_halt, assign_descriptors):\n            yield c"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef mol_from_file(path, assign_descriptors=True):\n    cs = mols_from_file(path, False, assign_descriptors)\n    return next(cs)", "response": "Parse CTAB file and return first one as a Compound object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load_from_resource(name):\n  filepath = Path(USER_DIR) / name\n  if filepath.exists():\n    with filepath.open() as fh:\n      return fh.read()\n  else:\n    return resource_string('wdiffhtml', 'data/' + name).decode('utf-8')", "response": "Load a resource from the users data directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef connect(token, protocol=RtmProtocol, factory=WebSocketClientFactory, factory_kwargs=None, api_url=None, debug=False):\n\tif factory_kwargs is None:\n\t\tfactory_kwargs = dict()\n\n\tmetadata = request_session(token, api_url)\n\twsfactory = factory(metadata.url, **factory_kwargs)\n\tif debug:\n\t\twarnings.warn('debug=True has been deprecated in autobahn 0.14.0')\n\n\twsfactory.protocol = lambda *a,**k: protocol(*a,**k)._seedMetadata(metadata)\n\tconnection = connectWS(wsfactory)\n\treturn connection", "response": "Creates a new connection to the Slack Real - Time API."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_args():\n    parser = argparse.ArgumentParser(\n        prog=__title__,\n        description=__description__,\n    )\n    parser.add_argument(\n        '--testdb', action='store_true',\n        help='create and use a database with test users'\n    )\n    parser.add_argument(\n        '-v', '--verbose', action='store_true',\n        help='print a detailed log'\n    )\n    parser.add_argument(\n        '--debug', action='store_true',\n        help='print debug log'\n    )\n    parser.add_argument(\n        '--log-sql', action='store_true',\n        help='log sql transactions'\n    )\n    parser.add_argument(\n        '-V', '--version', action='store_true',\n        help='print version info and exit'\n    )\n    parser.add_argument(\n        '--tk', action='store_true',\n        help='use old tk interface'\n    )\n    return parser.parse_args()", "response": "Parse command line arguments."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_up_logging(log_file, console_log_level):\n    logger = logging.getLogger()\n    logger.setLevel(logging.DEBUG)\n    fh = logging.FileHandler(str(log_file))\n    fh.setLevel(logging.DEBUG)\n    ch = logging.StreamHandler()\n    ch.setLevel(console_log_level)\n    formatter = logging.Formatter(\n        \"{asctime} {levelname} ({name}): {message}\", style='{'\n    )\n    fh.setFormatter(formatter)\n    ch.setFormatter(formatter)\n    logger.addHandler(fh)\n    logger.addHandler(ch)\n\n    return logger", "response": "Configure logging settings and return a logger object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrun Chronophore based on the command line arguments.", "response": "def main():\n    \"\"\"Run Chronophore based on the command line arguments.\"\"\"\n    args = get_args()\n\n    # Make Chronophore's directories and files in $HOME\n    DATA_DIR = pathlib.Path(appdirs.user_data_dir(__title__))\n    LOG_FILE = pathlib.Path(appdirs.user_log_dir(__title__), 'debug.log')\n    os.makedirs(str(DATA_DIR), exist_ok=True)\n    os.makedirs(str(LOG_FILE.parent), exist_ok=True)\n\n    if args.version:\n        print('{} {}'.format(__title__, __version__))\n        raise SystemExit\n\n    if args.debug:\n        CONSOLE_LOG_LEVEL = logging.DEBUG\n    elif args.verbose:\n        CONSOLE_LOG_LEVEL = logging.INFO\n    else:\n        CONSOLE_LOG_LEVEL = logging.WARNING\n\n    logger = set_up_logging(LOG_FILE, CONSOLE_LOG_LEVEL)\n    logger.debug('-'*80)\n    logger.info('{} {}'.format(__title__, __version__))\n    logger.debug('Log File: {}'.format(LOG_FILE))\n    logger.debug('Data Directory: {}'.format(DATA_DIR))\n\n    if args.testdb:\n        DATABASE_FILE = DATA_DIR.joinpath('test.sqlite')\n        logger.info('Using test database.')\n    else:\n        DATABASE_FILE = DATA_DIR.joinpath('chronophore.sqlite')\n\n    logger.debug('Database File: {}'.format(DATABASE_FILE))\n    engine = create_engine('sqlite:///{}'.format(str(DATABASE_FILE)))\n    Base.metadata.create_all(engine)\n    Session.configure(bind=engine)\n\n    if args.log_sql:\n        logging.getLogger('sqlalchemy.engine').setLevel(logging.INFO)\n\n    if args.testdb:\n        add_test_users(session=Session())\n\n    controller.flag_forgotten_entries(session=Session())\n\n    if args.tk:\n        from chronophore.tkview import TkChronophoreUI\n        TkChronophoreUI()\n    else:\n        try:\n            from PyQt5.QtWidgets import QApplication\n        except ImportError:\n            print(\n                'Error: PyQt5, which chronophore uses for its'\n                + ' graphical interface, is not installed.'\n                + \"\\nInstall it with 'pip install PyQt5'\"\n                + \" or use the old Tk ui with 'chronophore --tk'.\"\n            )\n            raise SystemExit\n        else:\n            from chronophore.qtview import QtChronophoreUI\n            app = QApplication(sys.argv)\n            chrono_ui = QtChronophoreUI()\n            chrono_ui.show()\n            sys.exit(app.exec_())\n\n    logger.debug('{} stopping'.format(__title__))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreplacing marker in a string with replacement.", "response": "def _replace_and_pad(fmt, marker, replacement):\n    \"\"\"\n    Args:\n        fmt (str | unicode): Format to tweak\n        marker (str | unicode): Marker to replace\n        replacement (str | unicode): What to replace marker with\n\n    Returns:\n        (str): Resulting format, with marker replaced\n    \"\"\"\n    if marker not in fmt:\n        return fmt\n    if replacement:\n        return fmt.replace(marker, replacement)\n    # Remove mention of 'marker' in 'fmt', including leading space (if present)\n    fmt = fmt.replace(\"%s \" % marker, marker)\n    return fmt.replace(marker, \"\")"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a new formatter object for the given format specification.", "response": "def _get_formatter(fmt):\n    \"\"\"\n    Args:\n        fmt (str | unicode): Format specification\n\n    Returns:\n        (logging.Formatter): Associated logging formatter\n    \"\"\"\n    fmt = _replace_and_pad(fmt, \"%(timezone)s\", LogManager.spec.timezone)\n    return logging.Formatter(fmt)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_file_handler(location, rotate, rotate_count):\n    if not rotate:\n        return logging.FileHandler(location)\n\n    kind, _, mode = rotate.partition(\":\")\n\n    if not mode:\n        raise ValueError(\"Invalid 'rotate' (missing kind): %s\" % rotate)\n\n    if kind == \"time\":\n        if mode == \"midnight\":\n            return TimedRotatingFileHandler(location, when=\"midnight\", backupCount=rotate_count)\n\n        timed = \"shd\"\n        if mode[-1].lower() not in timed:\n            raise ValueError(\"Invalid 'rotate' (unknown time spec): %s\" % rotate)\n\n        interval = to_int(mode[:-1])\n        if interval is None:\n            raise ValueError(\"Invalid 'rotate' (time range not an int): %s\" % rotate)\n\n        return TimedRotatingFileHandler(location, when=mode[-1], interval=interval, backupCount=rotate_count)\n\n    if kind == \"size\":\n        size = to_bytesize(mode)\n        if size is None:\n            raise ValueError(\"Invalid 'rotate' (size not a bytesize): %s\" % rotate)\n\n        return RotatingFileHandler(location, maxBytes=size, backupCount=rotate_count)\n\n    raise ValueError(\"Invalid 'rotate' (unknown type): %s\" % rotate)", "response": "Returns a handler for the log file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef usable_location(self):\n        if self.file_location is not None:\n            # Custom location typically provided via --config CLI flag\n            return self._auto_complete_filename(self.file_location)\n        if self.locations:\n            for location in self.locations:\n                path = self._auto_complete_filename(location)\n                if path:\n                    return path", "response": "Returns the first available usable location for the current user."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns True if we should log to a file.", "response": "def should_log_to_file(self):\n        \"\"\"\n        Returns:\n            bool: As per the spec, should we be logging to a file?\n        \"\"\"\n        if not self.file_format:\n            return False\n        if self.file_location is not None:\n            return bool(self.file_location)\n        return bool(self.locations)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the auto - complete filename for a specific resource.", "response": "def _auto_complete_filename(self, location):\n        \"\"\"\n        Args:\n            location (str | unicode | None): Location to auto-complete with {basename}, if it points to a folder\n\n        Returns:\n            str | None: {location}/{basename}\n        \"\"\"\n        path = formatted(location, self)\n        if path:\n            if os.path.isdir(path):\n                filename = formatted(self.basename, self)\n                if not filename:\n                    return None\n                path = os.path.join(path, filename)\n            if path and ensure_folder(path, fatal=False, logger=LOG.debug, dryrun=False) >= 0:\n                return path"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndetermines if the record should be logged and injects context info into the record. Always returns True", "response": "def filter(self, record):\n        \"\"\"Determines if the record should be logged and injects context info into the record. Always returns True\"\"\"\n        fmt = LogManager.spec.context_format\n        if fmt:\n            data = self.context.to_dict()\n            if data:\n                record.context = fmt % \",\".join(\"%s=%s\" % (key, val) for key, val in sorted(data.items()) if key and val)\n            else:\n                record.context = \"\"\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreset logging as it was before setup", "response": "def reset(cls):\n        \"\"\"Reset logging as it was before setup(), no need to call this outside of testing, or some very special cases\"\"\"\n        cls._disable_faulthandler()\n        if cls.handlers is not None:\n            for handler in cls.handlers:\n                logging.root.removeHandler(handler)\n            cls.handlers = None\n        cls._logging_snapshot.restore()\n        cls.context.reset()\n        cls.spec = LogSpec(cls._default_spec)\n        cls.debug = None\n        cls.actual_location = None\n        cls.console_handler = None\n        cls.file_handler = None\n        cls.used_formats = None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef silence(cls, *modules, **kwargs):\n        level = kwargs.pop(\"level\", logging.WARNING)\n        for mod in modules:\n            name = mod.__name__ if hasattr(mod, \"__name__\") else mod\n            logging.getLogger(name).setLevel(level)", "response": "A method to silence the log messages for the specified modules."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_using_format(cls, markers, used_formats=None):\n        if used_formats is None:\n            used_formats = cls.used_formats\n        if not markers or not used_formats:\n            return False\n        return any(marker in used_formats for marker in flattened(markers, split=(\" \", UNIQUE)))", "response": "Returns True if any of the markers in used_formats is seen in the cache otherwise False."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef enable_faulthandler(cls, signum=signal.SIGUSR1):\n        with cls._lock:\n            if not signum:\n                cls._disable_faulthandler()\n                return\n            if not cls.file_handler or faulthandler is None:\n                return\n            cls.faulthandler_signum = signum\n            dump_file = cls.file_handler.stream\n            faulthandler.enable(file=dump_file, all_threads=True)\n            faulthandler.register(signum, file=dump_file, all_threads=True, chain=False)", "response": "Enable dumping thread stack traces when specified signals are received."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\noverride the spec and _default_spec with given values", "response": "def override_spec(cls, **kwargs):\n        \"\"\"OVerride 'spec' and '_default_spec' with given values\"\"\"\n        cls._default_spec.set(**kwargs)\n        cls.spec.set(**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding a handler to the log.", "response": "def _add_handler(cls, handler, fmt, level):\n        \"\"\"\n        Args:\n            handler (logging.Handler): Handler to decorate\n            fmt (str | unicode): Format to use\n        \"\"\"\n        handler.setFormatter(_get_formatter(fmt))\n        if level:\n            handler.setLevel(level)\n        logging.root.addHandler(handler)\n        cls.used_formats = (\"%s %s\" % (cls.used_formats or \"\", fmt)).strip()\n        cls.handlers.append(handler)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfixes standard logging shortcuts to correctly report logging module.", "response": "def _fix_logging_shortcuts(cls):\n        \"\"\"\n        Fix standard logging shortcuts to correctly report logging module.\n\n        This is only useful if you:\n        - actually use %(name) and care about it being correct\n        - you would still like to use the logging.info() etc shortcuts\n\n        So basically you'd like to write this:\n            import logging\n            logging.info(\"hello\")\n\n        Instead of this:\n            import logging\n            LOG = logging.getLogger(__name__)\n            LOG.info(\"hello\")\n        \"\"\"\n        if cls.is_using_format(\"%(pathname)s %(filename)s %(funcName)s %(module)s\"):\n            logging._srcfile = cls._logging_snapshot._srcfile\n        else:\n            logging._srcfile = None\n\n        logging.logProcesses = cls.is_using_format(\"%(process)d\")\n        logging.logThreads = cls.is_using_format(\"%(thread)d %(threadName)s\")\n\n        def getframe():\n            return sys._getframe(4)\n\n        def log(level, msg, *args, **kwargs):\n            \"\"\"Wrapper to make logging.info() etc report the right module %(name)\"\"\"\n            name = get_caller_name()\n            logger = logging.getLogger(name)\n            try:\n                logging.currentframe = getframe\n                logger.log(level, msg, *args, **kwargs)\n            finally:\n                logging.currentframe = ORIGINAL_CF\n\n        def wrap(level, **kwargs):\n            \"\"\"Wrap corresponding logging shortcut function\"\"\"\n            original = getattr(logging, logging.getLevelName(level).lower())\n            f = partial(log, level, **kwargs)\n            f.__doc__ = original.__doc__\n            return f\n\n        logging.critical = wrap(logging.CRITICAL)\n        logging.fatal = logging.critical\n        logging.error = wrap(logging.ERROR)\n        logging.exception = partial(logging.error, exc_info=True)\n        logging.warning = wrap(logging.WARNING)\n        logging.info = wrap(logging.INFO)\n        logging.debug = wrap(logging.DEBUG)\n        logging.log = log"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconstructs and submit a structured request to the server.", "response": "def _send_request(self, job_type, params={}):\n        \"\"\"\n        Construct and submit a structured/authenticated request.\n\n        ## Arguments\n\n        * `job_type` (str): The job type identifier to use.\n\n        ## Keyword Arguments\n\n        * `params` (dict): Any additional entries to include in the POST\n          request.\n\n        ## Returns\n\n        * `r` (requests.Response): The response from the server.\n\n        \"\"\"\n        params[\"wsid\"] = params.get(\"wsid\", self.userid)\n        params[\"pw\"]   = params.get(\"pw\", self.password)\n\n        path = os.path.join(self.base_url, job_type)\n        if self.request_type == 'GET':\n            r = requests.get(path, params=params)\n        elif self.request_type == 'POST':\n            r = requests.post(path, data=params)\n        else:\n            raise ValueError('`resest_type` is invalid!')\n\n        code = r.status_code\n        if code != 200:\n            raise Exception(\"%s failed with status: %d\"%(job_type, code))\n\n        return r"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef quick(self, q, context=None, task_name=\"quickie\", system=False):\n        if not context:\n            context = self.context\n        params = {\"qry\": q, \"context\": context, \"taskname\": task_name,\n                \"isSystem\": system}\n        r = self._send_request(\"ExecuteQuickJob\", params=params)\n        return self._parse_single(r.text, \"string\")", "response": "Run a quick job."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsubmitting a job to CasJobs.", "response": "def submit(self, q, context=None, task_name=\"casjobs\", estimate=30):\n        \"\"\"\n        Submit a job to CasJobs.\n\n        ## Arguments\n\n        * `q` (str): The SQL query.\n\n        ## Keyword Arguments\n\n        * `context` (str): Casjobs context used for this query.\n        * `task_name` (str): The task name.\n        * `estimate` (int): Estimate of the time this job will take (in minutes).\n\n        ## Returns\n\n        * `job_id` (int): The submission ID.\n\n        \"\"\"\n        if not context:\n            context = self.context\n        params = {\"qry\": q, \"context\": context, \"taskname\": task_name,\n                  \"estimate\": estimate}\n        r = self._send_request(\"SubmitJob\", params=params)\n        job_id = int(self._parse_single(r.text, \"long\"))\n        return job_id"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef status(self, job_id):\n        params = {\"jobid\": job_id}\n        r = self._send_request(\"GetJobStatus\", params=params)\n        status = int(self._parse_single(r.text, \"int\"))\n        return status, self.status_codes[status]", "response": "Check the status of a job."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef monitor(self, job_id, timeout=5):\n        while True:\n            status = self.status(job_id)\n            logging.info(\"Monitoring job: %d - Status: %d, %s\"\n                    %(job_id, status[0], status[1]))\n            if status[0] in [3, 4, 5]:\n                return status\n            time.sleep(timeout)", "response": "Monitor the status of a job."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the information about the jobs returned by a particular search.", "response": "def job_info(self, **kwargs):\n        \"\"\"\n        Get the information about the jobs returned by a particular search.\n        See the [GetJobs][] documentation for more info.\n\n        [GetJobs]: http://casjobs.sdss.org/casjobs/services/jobs.asmx?op=GetJobs\n\n        \"\"\"\n        search = \";\".join([\"%s : %s\"%(k, str(kwargs[k])) for k in kwargs])\n        params = {\"owner_wsid\": self.userid, \"owner_pw\": self.password,\n                \"conditions\": search, \"includeSystem\": False}\n        r = self._send_request(\"GetJobs\", params=params)\n        results = []\n        for n in minidom.parseString(r.text).getElementsByTagName(\"CJJob\"):\n            results.append({})\n            for e in n.childNodes:\n                if e.nodeType != e.TEXT_NODE:\n                    results[-1][e.tagName] = e.firstChild.data\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef request_output(self, table, outtype):\n        job_types = [\"CSV\", \"DataSet\", \"FITS\", \"VOTable\"]\n        assert outtype in job_types\n        params = {\"tableName\": table, \"type\": outtype}\n        r = self._send_request(\"SubmitExtractJob\", params=params)\n        job_id = int(self._parse_single(r.text, \"long\"))\n        return job_id", "response": "Request the output for a given table."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndownloads an output file given the id of the output request job.", "response": "def get_output(self, job_id, outfn):\n        \"\"\"\n        Download an output file given the id of the output request job.\n\n        ## Arguments\n\n        * `job_id` (int): The id of the _output_ job.\n        * `outfn` (str): The file where the output should be stored.\n            May also be a file-like object with a 'write' method.\n\n        \"\"\"\n        job_info = self.job_info(jobid=job_id)[0]\n\n        # Make sure that the job is finished.\n        status = int(job_info[\"Status\"])\n        if status != 5:\n            raise Exception(\"The status of job %d is %d (%s)\"\n                    %(job_id, status, self.status_codes[status]))\n\n        # Try to download the output file.\n        remotefn = job_info[\"OutputLoc\"]\n        r = requests.get(remotefn)\n\n        # Make sure that the request went through.\n        code = r.status_code\n        if code != 200:\n            raise Exception(\"Getting file %s yielded status: %d\"\n                    %(remotefn, code))\n\n        # Save the data to a file.\n        try:\n            outfn.write(r.content)\n        except AttributeError:\n            f = open(outfn, \"wb\")\n            f.write(r.content)\n            f.close()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef request_and_get_output(self, table, outtype, outfn):\n        job_id = self.request_output(table, outtype)\n        status = self.monitor(job_id)\n        if status[0] != 5:\n            raise Exception(\"Output request failed.\")\n        self.get_output(job_id, outfn)", "response": "Request an output file and then download it when it is ready."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndrop a table from the MyDB context.", "response": "def drop_table(self, table):\n        \"\"\"\n        Drop a table from the MyDB context.\n\n        ## Arguments\n\n        * `table` (str): The name of the table to drop.\n\n        \"\"\"\n        job_id = self.submit(\"DROP TABLE %s\"%table, context=\"MYDB\")\n        status = self.monitor(job_id)\n        if status[0] != 5:\n            raise Exception(\"Couldn't drop table %s\"%table)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef count(self, q):\n        q = \"SELECT COUNT(*) %s\"%q\n        return int(self.quick(q).split(\"\\n\")[1])", "response": "Returns the number of results that match the query."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef list_tables(self):\n        q = 'SELECT Distinct TABLE_NAME FROM information_schema.TABLES'\n        res = self.quick(q, context='MYDB', task_name='listtables', system=True)\n        # the first line is a header and the last is always empty\n        # also, the table names have \" as the first and last characters\n        return [l[1:-1]for l in res.split('\\n')[1:-1]]", "response": "Lists the tables in mydb."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmultiplying the given number n by some configured multiplier and and then add a configured offset.", "response": "def multiply_and_add(n):\n    '''Multiply the given number n by some configured multiplier, and\n    then add a configured offset.'''\n    multiplier, offset = di.resolver.unpack(multiply_and_add)\n    return (multiplier * n) + offset"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef segment(self, document):\n        # ensure document is not empty and every element is an instance of str\n        assert(len(document) > 0 and len([d for d in document if not isinstance(d, str)]) == 0)\n        # step 1, do preprocessing\n        n = len(document)\n        self.window = max(min(self.window, n / 3), 1)\n        cnts = [Counter(self.tokenizer.tokenize(document[i])) for i in range(n)]\n\n        # step 2, calculate gap score\n        gap_score = [0 for _ in range(n)]\n        for i in range(n):\n            sz = min(min(i + 1, n - i - 1), self.window)\n            lcnt, rcnt = Counter(), Counter()\n            for j in range(i - sz + 1, i + 1):\n                lcnt += cnts[j]\n            for j in range(i + 1, i + sz + 1):\n                rcnt += cnts[j]\n            gap_score[i] = cosine_sim(lcnt, rcnt)\n\n        # step 3, calculate depth score\n        depth_score = [0 for _ in range(n)]\n        for i in range(n):\n            if i < self.window or i + self.window >= n:\n                continue\n            ptr = i - 1\n            while ptr >= 0 and gap_score[ptr] >= gap_score[ptr + 1]:\n                ptr -= 1\n            lval = gap_score[ptr + 1]\n            ptr = i + 1\n            while ptr < n and gap_score[ptr] >= gap_score[ptr - 1]:\n                ptr += 1\n            rval = gap_score[ptr - 1]\n            depth_score[i] = lval + rval - 2 * gap_score[i]\n\n        # step 4, smooth depth score with fixed window size 3\n        smooth_dep_score = [0 for _ in range(n)]\n        for i in range(n):\n            if i - 1 < 0 or i + 1 >= n:\n                smooth_dep_score[i] = depth_score[i]\n            else:\n                smooth_dep_score[i] = np.average(depth_score[(i - 1):(i + 2)])\n\n        # step 5, determine boundaries\n        boundaries = [0 for _ in range(n)]\n        avg = np.average(smooth_dep_score)\n        stdev = np.std(smooth_dep_score)\n        cutoff = avg - stdev / 2.0\n\n        depth_tuples = list(zip(smooth_dep_score, list(range(len(smooth_dep_score)))))\n        depth_tuples.sort()\n        depth_tuples.reverse()\n        hp = [x for x in depth_tuples if (x[0] > cutoff)]\n        for dt in hp:\n            boundaries[dt[1]] = 1\n            for i in range(dt[1] - 4, dt[1] + 4 + 1):\n                if i != dt[1] and i >= 0 and i < n and boundaries[i] == 1:\n                    boundaries[dt[1]] = 0\n                    break\n        return [1] + boundaries[:-1]", "response": "segment a document into a list of unique identifiers"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntrying to open the input file", "response": "def try_opening_file(self):\n        '''Try to open the input file'''\n        # read all the file to tail til the end...\n        if os.path.isfile(self.path):\n            self.my_log_file = tyler.Tyler(self.path)\n            try:\n                for line in self.my_log_file:\n                    pass\n            except StopIteration:\n                pass\n\n            self.file_is_opened = True"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nflushes the buffer of the tail", "response": "def flush_buffer(self):\n        ''' Flush the buffer of the tail '''\n        if len(self.buffer) > 0:\n            return_value = ''.join(self.buffer)\n            self.buffer.clear()\n            self.send_message(return_value)\n            self.last_flush_date = datetime.datetime.now()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\npiping many commands:: >>> noop = pipe(['gzip'], ['gzip'], ['zcat'], ['zcat']) >>> _ = noop.stdin.write('foo'.encode()) # Ignore output in Python 3 >>> noop.stdin.close() >>> print(noop.stdout.read().decode()) foo Returns a Subprocess.", "response": "def pipe(cmd, *arguments, **kwargs):\n    \"\"\"\n    Pipe many commands::\n\n        >>> noop = pipe(['gzip'], ['gzip'], ['zcat'], ['zcat'])\n        >>> _ = noop.stdin.write('foo'.encode())  # Ignore output in Python 3\n        >>> noop.stdin.close()\n        >>> print(noop.stdout.read().decode())\n        foo\n\n    Returns a Subprocess.\n    \"\"\"\n    acc = run(*cmd, **kwargs)\n    for cmd in arguments:\n        if isinstance(cmd, Subprocess):\n            acc = acc.pipe(cmd)\n        else:\n            acc = acc.pipe(*cmd, **kwargs)\n    return acc"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef decode(value, strip=False):\n    if value is None:\n        return None\n    if isinstance(value, bytes) and not isinstance(value, unicode):\n        value = value.decode(\"utf-8\")\n    if strip:\n        return unicode(value).strip()\n    return unicode(value)", "response": "Python 2. 3 friendly decoding of output."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the value of the named attribute in the object.", "response": "def _set(self, name, value):\n        \"\"\"\n        Args:\n            name (str | unicode): Name of slot to set.\n            value: Associated value\n        \"\"\"\n        if value is not UNSET:\n            if isinstance(value, Slotted):\n                current = getattr(self, name, UNSET)\n                if current is None or current is UNSET:\n                    current = value.__class__()\n                    current.set(value)\n                    setattr(self, name, current)\n                    return\n                if isinstance(current, Slotted):\n                    current.set(value)\n                    return\n            setattr(self, name, value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set(self, *args, **kwargs):\n        if args:\n            for arg in args:\n                if arg is not None:\n                    for name in self.__slots__:\n                        self._set(name, getattr(arg, name, UNSET))\n        for name in kwargs:\n            self._set(name, kwargs.get(name, UNSET))", "response": "Conveniently set one or more fields at a time."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove all applicable fields from a set of items from the set.", "response": "def pop(self, settings):\n        \"\"\"\n        Args:\n            settings (dict): Dict to pop applicable fields from\n        \"\"\"\n        if settings:\n            for name in self.__slots__:\n                self._set(name, settings.pop(name, UNSET))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nenables contextual logging for this instance.", "response": "def enable(self):\n        \"\"\"Enable contextual logging\"\"\"\n        with self._lock:\n            if self.filter is None:\n                self.filter = self._filter_type(self)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_threadlocal(self, **values):\n        with self._lock:\n            self._ensure_threadlocal()\n            self._tpayload.context = values", "response": "Set current thread s logging context to specified values"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_threadlocal(self, **values):\n        with self._lock:\n            self._ensure_threadlocal()\n            self._tpayload.context.update(**values)", "response": "Add values to current thread s logging context"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving a thread local entry with the given name from current thread s context.", "response": "def remove_threadlocal(self, name):\n        \"\"\"\n        Args:\n            name (str | unicode): Remove entry with `name` from current thread's context\n        \"\"\"\n        with self._lock:\n            if self._tpayload is not None:\n                if name in self._tpayload.context:\n                    del self._tpayload.context[name]\n                if not self._tpayload.context:\n                    self._tpayload = None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd values to global logging context", "response": "def add_global(self, **values):\n        \"\"\"Add `values` to global logging context\"\"\"\n        with self._lock:\n            self._ensure_global()\n            self._gpayload.update(**values)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nremoves a global entry with the given name from the global context.", "response": "def remove_global(self, name):\n        \"\"\"\n        Args:\n            name (str | unicode): Remove entry with `name` from global context\n        \"\"\"\n        with self._lock:\n            if self._gpayload is not None:\n                if name in self._gpayload:\n                    del self._gpayload[name]\n                if not self._gpayload:\n                    self._gpayload = None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_dict(self):\n        with self._lock:\n            result = {}\n            if self._gpayload:\n                result.update(self._gpayload)\n            if self._tpayload:\n                result.update(getattr(self._tpayload, \"context\", {}))\n            return result", "response": "Returns a dict representation of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nensure internal global tracking dict is created", "response": "def _ensure_global(self, values=None):\n        \"\"\"\n        Args:\n            values (dict): Ensure internal global tracking dict is created, seed it with `values` when provided (Default value = None)\n        \"\"\"\n        if self._gpayload is None:\n            self._gpayload = values or {}\n        self.enable()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef segment(self, document):\n        assert(len(document) > 0 and len([d for d in document if not isinstance(d, str)]) == 0)\n        if len(document) < 3:\n            return [1] + [0 for _ in range(len(document) - 1)]\n        # step 1, preprocessing\n        n = len(document)\n        self.window = min(self.window, n)\n        cnts = [Counter(self.tokenizer.tokenize(document[i])) for i in range(n)]\n\n        # step 2, compute similarity matrix\n        self.sim = np.zeros((n, n))\n        for i in range(n):\n            for j in range(i, n):\n                self.sim[i][j] = cosine_sim(cnts[i], cnts[j])\n                self.sim[j][i] = self.sim[i][j]\n\n        # step 3, compute rank matrix & sum matrix\n        self.rank = np.zeros((n, n))\n        for i in range(n):\n            for j in range(i, n):\n                r1 = max(0, i - self.window + 1)\n                r2 = min(n - 1, i + self.window - 1)\n                c1 = max(0, j - self.window + 1)\n                c2 = min(n - 1, j + self.window - 1)\n                sublist = self.sim[r1:(r2 + 1), c1:(c2+1)].flatten()\n                lowlist = [x for x in sublist if x < self.sim[i][j]]\n                self.rank[i][j] = 1.0 * len(lowlist) / ((r2 - r1 + 1) * (c2 - c1 + 1))\n                self.rank[j][i] = self.rank[i][j]\n\n        self.sm = np.zeros((n, n))\n        # O(n^4) solution\n        # for i in xrange(n):\n        #     for j in xrange(i, n):\n        #         self.sm[i][j] = sum(self.rank[i:(j + 1), i:(j + 1)].flatten())\n        #         self.sm[j][i] = self.sm[i][j]\n        # O(n^2) solution\n        prefix_sm = np.zeros((n, n))\n        for i in range(n):\n            for j in range(n):\n                prefix_sm[i][j] = self.rank[i][j]\n                if i - 1 >= 0: prefix_sm[i][j] += prefix_sm[i - 1][j]\n                if j - 1 >= 0: prefix_sm[i][j] += prefix_sm[i][j - 1]\n                if i - 1 >= 0 and j - 1 >= 0: prefix_sm[i][j] -= prefix_sm[i - 1][j - 1]\n        for i in range(n):\n            for j in range(i, n):\n                if i == 0:\n                    self.sm[i][j] = prefix_sm[j][j]\n                else:\n                    self.sm[i][j] = prefix_sm[j][j] - prefix_sm[i - 1][j] \\\n                                    - prefix_sm[j][i - 1] + prefix_sm[i - 1][i - 1]\n                self.sm[j][i] = self.sm[i][j]\n\n        # step 4, determine boundaries\n        D = 1.0 * self.sm[0][n - 1] / (n * n)\n        darr, region_arr, idx = [D], [Region(0, n - 1, self.sm)], []\n        sum_region, sum_area = float(self.sm[0][n - 1]), float(n * n)\n        for i in range(n - 1):\n            mx, pos = -1e9, -1\n            for j, region in enumerate(region_arr):\n                if region.l == region.r:\n                    continue\n                region.split(self.sm)\n                den = sum_area - region.area + region.lch.area + region.rch.area\n                cur = (sum_region - region.tot + region.lch.tot + region.rch.tot) / den\n                if cur > mx:\n                    mx, pos = cur, j\n            assert(pos >= 0)\n            tmp = region_arr[pos]\n            region_arr[pos] = tmp.rch\n            region_arr.insert(pos, tmp.lch)\n            sum_region += tmp.lch.tot + tmp.rch.tot - tmp.tot\n            sum_area += tmp.lch.area + tmp.rch.area - tmp.area\n            darr.append(sum_region / sum_area)\n            idx.append(tmp.best_pos)\n\n        dgrad = [(darr[i + 1] - darr[i]) for i in range(len(darr) - 1)]\n\n        # optional step, smooth gradient\n        smooth_dgrad = [dgrad[i] for i in range(len(dgrad))]\n        if len(dgrad) > 1:\n            smooth_dgrad[0] = (dgrad[0] * 2 + dgrad[1]) / 3.0\n            smooth_dgrad[-1] = (dgrad[-1] * 2 + dgrad[-2]) / 3.0\n        for i in range(1, len(dgrad) - 1):\n            smooth_dgrad[i] = (dgrad[i - 1] + 2 * dgrad[i] + dgrad[i + 1]) / 4.0\n        dgrad = smooth_dgrad\n\n        avg, stdev = np.average(dgrad), np.std(dgrad)\n        cutoff = avg + self.std_coeff * stdev\n        assert(len(idx) == len(dgrad))\n        above_cutoff_idx = [i for i in range(len(dgrad)) if dgrad[i] >= cutoff]\n        if len(above_cutoff_idx) == 0: boundary = []\n        else: boundary = idx[:max(above_cutoff_idx) + 1]\n        ret = [0 for _ in range(n)]\n        for i in boundary:\n            ret[i] = 1\n            # boundary should not be too close\n            for j in range(i - 1, i + 2):\n                if j >= 0 and j < n and j != i and ret[j] == 1:\n                    ret[i] = 0\n                    break\n        return [1] + ret[:-1]", "response": "This function computes the similarity matrix and sum matrix of the words in the document."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create(context, name, team_id, data, active):\n\n    state = utils.active_string(active)\n    team_id = team_id\n    result = feeder.create(context, name=name, team_id=team_id, data=data,\n                           state=state)\n    utils.format_output(result, context.format)", "response": "Create a new feeder"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate a specific object in a specific feeder", "response": "def update(context, id, etag, name, team_id, data, active):\n    \"\"\"update(context, id, etag, name, team_id, data, active)\n\n    Update a Feeder.\n\n    >>> dcictl feeder-update [OPTIONS]\n\n    :param string id: ID of the feeder [required]\n    :param string etag: Entity tag of the feeder resource [required]\n    :param string name: Name of the feeder\n    :param string team_id: ID of the team to associate this feeder with\n    :param string data: JSON data to pass during feeder update\n    :param boolean active: Mark feeder active\n    \"\"\"\n\n    result = feeder.update(context, id=id, etag=etag, name=name,\n                           team_id=team_id, data=data,\n                           state=utils.active_string(active))\n    utils.format_output(result, context.format)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete(context, id, etag):\n    result = feeder.delete(context, id=id, etag=etag)\n\n    if result.status_code == 204:\n        utils.print_json({'id': id, 'message': 'Feeder deleted.'})\n    else:\n        utils.format_output(result, context.format)", "response": "Delete a specific resource of a specific resource"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef show(context, id):\n    result = feeder.get(context, id=id)\n    utils.format_output(result, context.format)", "response": "Show a specific n - item feeder"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreset API Secret of a specific resource", "response": "def reset_api_secret(context, id, etag):\n    \"\"\"reset_api_secret(context, id, etag)\n\n    Reset a Feeder api_secret.\n\n    >>> dcictl feeder-reset-api-secret [OPTIONS]\n\n    :param string id: ID of the feeder [required]\n    :param string etag: Entity tag of the feeder resource [required]\n    \"\"\"\n    result = feeder.reset_api_secret(context, id=id, etag=etag)\n    utils.format_output(result, context.format,\n                        headers=['id', 'api_secret', 'etag'])"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets visible = True to the terminal carbon atoms.", "response": "def display_terminal_carbon(mol):\n    \"\"\"Set visible=True to the terminal carbon atoms.\n    \"\"\"\n    for i, a in mol.atoms_iter():\n        if mol.neighbor_count(i) == 1:\n            a.visible = True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef equalize_terminal_double_bond(mol):\n    for i, a in mol.atoms_iter():\n        if mol.neighbor_count(i) == 1:\n            nb = list(mol.neighbors(i).values())[0]\n            if nb.order == 2:\n                nb.type = 2", "response": "Show equalized double bond if it is connected to terminal atom."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef spine_to_terminal_wedge(mol):\n    for i, a in mol.atoms_iter():\n        if mol.neighbor_count(i) == 1:\n            ni, nb = list(mol.neighbors(i).items())[0]\n            if nb.order == 1 and nb.type in (1, 2) \\\n                    and ni > i != nb.is_lower_first:\n                nb.is_lower_first = not nb.is_lower_first\n                nb.type = {1: 2, 2: 1}[nb.type]", "response": "Arrange stereo wedge direction from spine to terminal atom\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting double bonds around the ring.", "response": "def format_ring_double_bond(mol):\n    \"\"\"Set double bonds around the ring.\n    \"\"\"\n    mol.require(\"Topology\")\n    mol.require(\"ScaleAndCenter\")\n    for r in sorted(mol.rings, key=len, reverse=True):\n        vertices = [mol.atom(n).coords for n in r]\n        try:\n            if geometry.is_clockwise(vertices):\n                cpath = iterator.consecutive(itertools.cycle(r), 2)\n            else:\n                cpath = iterator.consecutive(itertools.cycle(reversed(r)), 2)\n        except ValueError:\n            continue\n        for _ in r:\n            u, v = next(cpath)\n            b = mol.bond(u, v)\n            if b.order == 2:\n                b.type = int((u > v) == b.is_lower_first)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncenter and Scale molecule 2D coordinates.", "response": "def scale_and_center(mol):\n    \"\"\"Center and Scale molecule 2D coordinates.\n    This method changes mol coordinates directly to center but not scale.\n    This method returns width, height and MLB(median length of bond)\n    and scaling will be done by drawer method with these values.\n\n    Returns:\n        width: float\n        height: float\n        mlb: median length of bond\n    \"\"\"\n    cnt = mol.atom_count()\n    if cnt < 2:\n        mol.size2d = (0, 0, 1)\n        mol.descriptors.add(\"ScaleAndCenter\")\n        return\n    xs = []\n    ys = []\n    for _, atom in mol.atoms_iter():\n        xs.append(atom.coords[0])\n        ys.append(atom.coords[1])\n    xmin, xmax = (min(xs), max(xs))\n    ymin, ymax = (min(ys), max(ys))\n    width = xmax - xmin\n    height = ymax - ymin\n    x_offset = width / 2 + xmin\n    y_offset = height / 2 + ymin\n    dists = []\n    for u, v, _ in mol.bonds_iter():\n        dists.append(geometry.distance(mol.atom(u).coords, mol.atom(v).coords))\n    try:\n        mlb = statistics.median(dists)\n    except statistics.StatisticsError:\n        # No connection\n        mlb = math.sqrt(max([width, height]) / cnt)  # empirical\n    if not mlb:  # Many of connected atoms are overlapped\n        mol.size2d = (0, 0, 1)\n        mol.descriptors.add(\"ScaleAndCenter\")\n        return\n    # Centering\n    for _, atom in mol.atoms_iter():\n        atom.coords = (atom.coords[0] - x_offset, atom.coords[1] - y_offset)\n    mol.size2d = (width, height, mlb)\n    mol.descriptors.add(\"ScaleAndCenter\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update_from_object(self, obj, criterion=lambda key: key.isupper()):\n        log.debug('Loading config from {0}'.format(obj))\n        if isinstance(obj, basestring):\n            if '.' in obj:\n                path, name = obj.rsplit('.', 1)\n                mod = __import__(path, globals(), locals(), [name], 0)\n                obj = getattr(mod, name)\n            else:\n                obj = __import__(obj, globals(), locals(), [], 0)\n        self.update(\n            (key, getattr(obj, key))\n            for key in filter(criterion, dir(obj))\n        )", "response": "Update the dict with the contents of the object obj."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_from_env_namespace(self, namespace):\n        self.update(ConfigLoader(os.environ).namespace(namespace))", "response": "Update the dictionary with the values from any environment variables that have a given prefix."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupdate the internal dictionary with the values from the specified sources.", "response": "def update_from(\n            self,\n            obj=None,\n            yaml_env=None,\n            yaml_file=None,\n            json_env=None,\n            json_file=None,\n            env_namespace=None,\n            ):\n        \"\"\"\n        Update dict from several sources at once.\n\n        This is simply a convenience method that can be used as an alternative\n        to making several calls to the various\n        :meth:`~ConfigLoader.update_from_*` methods.\n\n        Updates will be applied in the order that the parameters are listed\n        below, with each source taking precedence over those before it.\n\n        :arg obj: Object or name of object, e.g. 'myapp.settings'.\n        :arg yaml_env: Name of an environment variable containing the path to\n            a YAML config file.\n        :arg yaml_file: Path to a YAML config file, or a file-like object.\n        :arg json_env: Name of an environment variable containing the path to\n            a JSON config file.\n        :arg json_file: Path to a JSON config file, or a file-like object.\n        :arg env_namespace: Common prefix of the environment variables\n            containing the desired config.\n        \"\"\"\n        if obj:\n            self.update_from_object(obj)\n        if yaml_env:\n            self.update_from_yaml_env(yaml_env)\n        if yaml_file:\n            self.update_from_yaml_file(yaml_file)\n        if json_env:\n            self.update_from_json_env(json_env)\n        if json_file:\n            self.update_from_json_file(json_file)\n        if env_namespace:\n            self.update_from_env_namespace(env_namespace)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a copy of the config dictionary with only the keys from a given namespace.", "response": "def namespace(self, namespace, key_transform=lambda key: key):\n        \"\"\"\n        Return a copy with only the keys from a given namespace.\n\n        The common prefix will be removed in the returned dict. Example::\n\n            >>> from configloader import ConfigLoader\n            >>> config = ConfigLoader(\n            ...     MY_APP_SETTING1='a',\n            ...     EXTERNAL_LIB_SETTING1='b',\n            ...     EXTERNAL_LIB_SETTING2='c',\n            ... )\n            >>> config.namespace('EXTERNAL_LIB')\n            ConfigLoader({'SETTING1': 'b', 'SETTING2': 'c'})\n\n        :arg namespace: Common prefix.\n        :arg key_transform: Function through which to pass each key when\n            creating the new dictionary.\n\n        :return: New config dict.\n        :rtype: :class:`ConfigLoader`\n        \"\"\"\n        namespace = namespace.rstrip('_') + '_'\n        return ConfigLoader(\n            (key_transform(key[len(namespace):]), value)\n            for key, value in self.items()\n            if key[:len(namespace)] == namespace\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef namespace_lower(self, namespace):\n        return self.namespace(namespace, key_transform=lambda key: key.lower())", "response": "Return a copy with only the keys from a given namespace lower - cased."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef list(context, sort, limit, offset, where, verbose):\n    result = user.list(\n        context,\n        sort=sort,\n        limit=limit,\n        offset=offset,\n        where=where\n    )\n    utils.format_output(result, context.format, verbose=verbose)", "response": "list - List all users in the system"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a user in the nova user list", "response": "def create(context, name, password, team_id, active, email, fullname):\n    \"\"\"create(context, name, password, team_id, active, email, fullname)\n\n    Create a user.\n\n    >>> dcictl user-create [OPTIONS]\n\n    :param string name: Name of the user [required]\n    :param string password: Password for the user [required]\n    :param string email: Email of the user [required]\n    :param string fullname: Full name of the user [optional]\n    :param string team_id: ID of the team to attach this user to [optional]\n    :param boolean active: Set the user in the (in)active state\n    \"\"\"\n    team_id = team_id or identity.my_team_id(context)\n    fullname = fullname or name\n    result = user.create(context, name=name, password=password,\n                         team_id=team_id, state=utils.active_string(active),\n                         email=email, fullname=fullname)\n    utils.format_output(result, context.format)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating a user in a node.", "response": "def update(context, id, etag, name, password, email, fullname,\n           team_id, active):\n    \"\"\"update(context, id, etag, name, password, email, fullname, team_id,\n              active)\n\n    Update a user.\n\n    >>> dcictl user-update [OPTIONS]\n\n    :param string id: ID of the user to update [required]\n    :param string etag: Entity tag of the user resource [required]\n    :param string name: Name of the user\n    :param string password: Password of the user\n    :param string email: Email of the user\n    :param string fullname: Full name of the user\n    :param boolean active: Set the user in the active state\n    \"\"\"\n\n    result = user.update(context, id=id, etag=etag, name=name,\n                         password=password, team_id=team_id,\n                         state=utils.active_string(active),\n                         email=email, fullname=fullname)\n\n    utils.format_output(result, context.format)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef render_diagram(root_task, out_base, max_param_len=20, horizontal=False, colored=False):\n    import re\n    import codecs\n    import subprocess\n    from ozelot import config\n    from ozelot.etl.tasks import get_task_name, get_task_param_string\n\n    # the graph - lines in dot file\n    lines = [u\"digraph G {\"]\n\n    if horizontal:\n        lines.append(u\"rankdir=LR;\")\n\n    # helper function: make unique task id from task name and parameters:\n    # task name + parameter string, with spaces replaced with _ and all non-alphanumerical characters stripped\n    def get_id(task):\n        s = get_task_name(task) + \"_\" + get_task_param_string(task)\n        return re.sub(r'\\W+', '', re.sub(' ', '_', s))\n\n    # node names of tasks that have already been added to the graph\n    existing_nodes = set()\n\n    # edge sets (tuples of two node names) that have already been added\n    existing_edges = set()\n\n    # recursion function for generating the pipeline graph\n    def _build(task, parent_id=None):\n        tid = get_id(task)\n\n        # add node if it's not already there\n        if tid not in existing_nodes:\n            # build task label: task name plus dictionary of parameters as table\n\n            params = task.to_str_params()\n            param_list = \"\"\n            for k, v in params.items():\n                # truncate param value if necessary, and add \"...\"\n                if len(v) > max_param_len:\n                    v = v[:max_param_len] + \"...\"\n                param_list += \"<TR><TD ALIGN=\\\"LEFT\\\">\" \\\n                              \"<FONT POINT-SIZE=\\\"10\\\">{:s}</FONT>\" \\\n                              \"</TD><TD ALIGN=\\\"LEFT\\\">\" \\\n                              \"<FONT POINT-SIZE=\\\"10\\\">{:s}</FONT>\" \\\n                              \"</TD></TR>\".format(k, v)\n\n            label = \"<TABLE BORDER=\\\"0\\\" CELLSPACING=\\\"1\\\" CELLPADDING=\\\"1\\\">\" \\\n                    \"<TR><TD COLSPAN=\\\"2\\\" ALIGN=\\\"CENTER\\\">\" \\\n                    \"<FONT POINT-SIZE=\\\"12\\\">{:s}</FONT>\" \\\n                    \"</TD></TR>\" \\\n                    \"\".format(get_task_name(task)) + param_list + \"</TABLE>\"\n\n            style = getattr(task, 'diagram_style', [])\n\n            if colored:\n                color = ', color=\"{:s}\"'.format(\"green\" if task.complete() else \"red\")\n            else:\n                color = ''\n\n            # add a node for the task\n            lines.append(u\"{name:s} [label=< {label:s} >, shape=\\\"rect\\\" {color:s}, style=\\\"{style:s}\\\"];\\n\"\n                         u\"\".format(name=tid,\n                                    label=label,\n                                    color=color,\n                                    style=','.join(style)))\n\n            existing_nodes.add(tid)\n\n            # recurse over requirements\n            for req in task.requires():\n                _build(req, parent_id=tid)\n\n        # add edge from current node to (upstream) parent, if it doesn't already exist\n        if parent_id is not None and (tid, parent_id) not in existing_edges:\n            lines.append(u\"{source:s} -> {target:s};\\n\".format(source=tid, target=parent_id))\n\n    # generate pipeline graph\n    _build(root_task)\n\n    # close the graph definition\n    lines.append(u\"}\")\n\n    # write description in DOT format\n    with codecs.open(out_base + '.dot', 'w', encoding='utf-8') as f:\n        f.write(u\"\\n\".join(lines))\n\n    # check existence of DOT_EXECUTABLE variable and file\n    if not hasattr(config, 'DOT_EXECUTABLE'):\n        raise RuntimeError(\"Please configure the 'DOT_EXECUTABLE' variable in your 'project_config.py'\")\n    if not os.path.exists(config.DOT_EXECUTABLE):\n        raise IOError(\"Could not find file pointed to by 'DOT_EXECUTABLE': \" + str(config.DOT_EXECUTABLE))\n\n    # render to image using DOT\n    # noinspection PyUnresolvedReferences\n    subprocess.check_call([\n        config.DOT_EXECUTABLE,\n        '-T', 'png',\n        '-o', out_base + '.png',\n              out_base + '.dot'\n    ])", "response": "Render a diagram of the ETL pipeline."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nnormalize a string containing a unicode string containing only whitespace and unicode characters.", "response": "def sanitize(s,\n             normalize_whitespace=True,\n             normalize_unicode=True,\n             form='NFKC',\n             enforce_encoding=True,\n             encoding='utf-8'):\n    \"\"\"Normalize a string\n\n    Args:\n        s (unicode string): input unicode string\n        normalize_whitespace (bool): if True, normalize all whitespace to single spaces (including newlines),\n                                     strip whitespace at start/end\n        normalize_unicode (bool): if True, normalize unicode form to 'form'\n        form (str): unicode form\n        enforce_encoding (bool): if True, encode string to target encoding and re-decode, ignoring errors\n                                 and stripping all characters not part of the encoding\n        encoding (str): target encoding for the above\n\n    Returns:\n        str: unicode output string\n    \"\"\"\n\n    if enforce_encoding:\n        s = s.encode(encoding, errors='ignore').decode(encoding, errors='ignore')\n\n    if normalize_unicode:\n        s = unicodedata.normalize(form, s)\n\n    if normalize_whitespace:\n        s = re.sub(r'\\s+', ' ', s).strip()\n\n    return s"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload a single step from a file", "response": "def load(filename):\n    \"\"\"\n    Load step from yaml file\n    Args:\n        filename: a target or step.yaml filename\n    \"\"\"\n    yaml_filename = os.path.join(os.path.dirname(filename), 'step.yaml')\n    with open(yaml_filename) as f:\n        return yaml.load(f)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconfigure YAML parser for Step serialization and deserialization Called in drain. py", "response": "def configure():\n    \"\"\"\n    Configures YAML parser for Step serialization and deserialization\n    Called in drain/__init__.py\n    \"\"\"\n    yaml.add_multi_representer(Step, step_multi_representer)\n    yaml.add_multi_constructor('!step', step_multi_constructor)\n    yaml.Dumper.ignore_aliases = lambda *args: True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef compute_control_digit(clabe: str) -> str:\n    clabe = [int(i) for i in clabe]\n    weighted = [c * w % 10 for c, w in\n                zip(clabe[:CLABE_LENGTH - 1], CLABE_WEIGHTS)]\n    summed = sum(weighted) % 10\n    control_digit = (10 - summed) % 10\n    return str(control_digit)", "response": "Compute CLABE control digit according to\n    https://es. wikidoc. org / wiki / CLABE#D. C3. ADgito_control\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nvalidate CLABE according to Agito Control - digit.", "response": "def validate_clabe(clabe: str) -> bool:\n    \"\"\"\n    Validate CLABE according to\n    https://es.wikipedia.org/wiki/CLABE#D.C3.ADgito_control\n    \"\"\"\n    return (clabe.isdigit() and\n            len(clabe) == CLABE_LENGTH and\n            clabe[:3] in BANKS.keys() and\n            clabe[-1] == compute_control_digit(clabe))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the bank name for a given clabe", "response": "def get_bank_name(clabe: str) -> str:\n    \"\"\"\n    Regresa el nombre del banco basado en los primeros 3 digitos\n    https://es.wikipedia.org/wiki/CLABE#D.C3.ADgito_control\n    \"\"\"\n    code = clabe[:3]\n    try:\n        bank_name = BANK_NAMES[BANKS[code]]\n    except KeyError:\n        raise ValueError(f\"Ning\u00fan banco tiene c\u00f3digo '{code}'\")\n    else:\n        return bank_name"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nselecting a subset of arguments from the DataFrame", "response": "def select(self, df, args, inplace=False):\n        \"\"\"\n        After joining, selects a subset of arguments\n        df: the result of a call to self.join(left)\n        args: a collcetion of arguments to select, as accepted by drain.util.list_expand:\n            - a tuple corresponding to concat_args,\n                e.g. [('District', '12h'), ('Distict', '24h')]\n            - a dict to be exanded into the above,\n                e.g. {'District': ['12h', '24h']}\n        \"\"\"\n        if self.prefix is None:\n            raise ValueError('Cannot do selection on an Aggregation without a prefix')\n\n        # run list_expand and ensure all args to tuples for validation\n        args = [tuple(i) for i in util.list_expand(args)]\n\n        # check that the args passed are valid\n        for a in args:\n            has_arg = False\n            for argument in self.arguments:\n                if a == tuple(argument[k] for k in self.concat_args):\n                    has_arg = True\n                    break\n            if not has_arg:\n                raise ValueError('Invalid argument for selection: %s' % str(a))\n\n        df = data.select_features(\n                df, exclude=[self.prefix + '_.*'],\n                include=map(lambda a: self.args_prefix(a) + '.*', args), inplace=inplace)\n\n        return df"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef reinitialize():\n    from ozelot import client\n\n    # import all additional models needed in this project\n    # noinspection PyUnresolvedReferences\n    from ozelot.orm.target import ORMTargetMarker\n\n    client = client.get_client()\n    base.Base.drop_all(client)\n    base.Base.create_all(client)", "response": "Drop all tables for all models then create them\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates comparison graph using Python.", "response": "def comparison_graph_py(arr1, arr2):\n    \"\"\" DEPRECATED: Generate comparison graph\n    Comparison graph is a modular product of molecule edges\n    \"\"\"\n    # timeout is not implemented\n    u1, v1, c1 = zip(*arr1)\n    u2, v2, c2 = zip(*arr2)\n    c1 = np.array(c1, dtype=int)\n    c2 = np.array(c2, dtype=int)\n    product = nx.Graph()\n    c1 = c1[:, np.newaxis]  # transpose\n    if NUMEXPR_AVAILABLE:\n        m = ne.evaluate(\"c2 == c1\")\n    else:\n        m = c2 == c1\n    edges = []\n    for x, y in zip(*np.nonzero(m)):\n        edges.append({\"u1\": u1[x], \"v1\": v1[x], \"u2\": u2[y], \"v2\": v2[y]})\n    # Graph.add_edges is expensive. Add adjacency dict manually.\n    node = {}\n    for e in edges:\n        node[(e[\"u1\"], e[\"u2\"])] = {}\n        node[(e[\"v1\"], e[\"v2\"])] = {}\n    adj = node.copy()\n    for e in edges:\n        adj[(e[\"u1\"], e[\"u2\"])][(e[\"v1\"], e[\"v2\"])] = {}\n        adj[(e[\"v1\"], e[\"v2\"])][(e[\"u1\"], e[\"u2\"])] = {}\n    product = nx.Graph()\n    product.node = node\n    product.adj = adj\n    return product"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef node_desc(self, atoms):\n        a1 = self.mol.atom(atoms[0])\n        a2 = self.mol.atom(atoms[1])\n        a1t = a1.number << 2 | a1.pi\n        a2t = a2.number << 2 | a2.pi\n        pair = sorted((a1t, a2t))\n        return pair[0] << 9 | pair[1]", "response": "get node_desc - returns node_desc for given atoms"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _unwrap_func(cls, decorated_func):\n        '''\n        This unwraps a decorated func, returning the inner wrapped func.\n\n        This may become unnecessary with Python 3.4's inspect.unwrap().\n        '''\n        if click is not None:\n            # Workaround for click.command() decorator not setting\n            # __wrapped__\n            if isinstance(decorated_func, click.Command):\n                return cls._unwrap_func(decorated_func.callback)\n\n        if hasattr(decorated_func, '__wrapped__'):\n            # Recursion: unwrap more if needed\n            return cls._unwrap_func(decorated_func.__wrapped__)\n        else:\n            # decorated_func isn't actually decorated, no more\n            # unwrapping to do\n            return decorated_func", "response": "This unwraps a decorated function returning the inner wrapped function."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _register_dependent(self, dependent, resource_name):\n        '''\n        Register a mapping of the dependent to resource name.\n\n        After calling, dependency_register.dependents[dependent] should\n        contain resource_name.\n        '''\n        if dependent not in self.dependents:\n            self.dependents[dependent] = []\n        self.dependents[dependent].insert(0, resource_name)", "response": "Register a mapping of the dependent to resource name."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef register(self, resource_name, dependent=None):\n        '''\n        Register the given dependent as depending on the \"resource\"\n        named by resource_name.\n        '''\n        if dependent is None:\n            # Give a partial usable as a decorator\n            return partial(self.register, resource_name)\n\n        dependent = self._unwrap_dependent(dependent)\n        self._register_dependent(dependent, resource_name)\n        self._register_resource_dependency(resource_name, dependent)\n\n        # Return dependent to ease use as decorator\n        return dependent", "response": "Register the given dependent as depending on the resource_name."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef header(text, border=\"--\"):\n    if not text or not border:\n        return text\n\n    if border.endswith(\" \"):\n        decorated = \"%s%s\" % (border, text)\n        fmt = \"{decorated}\\n{hr}\"\n\n    else:\n        decorated = \"%s %s %s\" % (border, text, border)\n        fmt = \"{hr}\\n{decorated}\\n{hr}\"\n\n    return fmt.format(decorated=decorated, hr=border[0] * len(decorated))", "response": "Return a string that is a header of the current node."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a requests. Session that handles errors by retrying.", "response": "def requests_retry_session(\n        retries=3,\n        backoff_factor=0.3,\n        status_forcelist=(500, 502, 504),\n        session=None):\n    \"\"\"Create a requests session that handles errors by retrying.\n\n    Parameters\n    ----------\n    retries : `int`, optional\n        Number of retries to attempt.\n    backoff_factor : `float`, optional\n        Backoff factor.\n    status_forcelist : sequence of `str`, optional\n        Status codes that must be retried.\n    session : `requests.Session`\n        An existing requests session to configure.\n\n    Returns\n    -------\n    session : `requests.Session`\n        Requests session that can take ``get`` and ``post`` methods, for\n        example.\n\n    Notes\n    -----\n    This function is based on\n    https://www.peterbe.com/plog/best-practice-with-retries-with-requests\n    by Peter Bengtsson.\n    \"\"\"\n    session = session or requests.Session()\n    retry = Retry(\n        total=retries,\n        read=retries,\n        connect=retries,\n        backoff_factor=backoff_factor,\n        status_forcelist=status_forcelist,\n    )\n    adapter = HTTPAdapter(max_retries=retry)\n    session.mount('http://', adapter)\n    session.mount('https://', adapter)\n    return session"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrunning a shell line", "response": "def run(line):\n    \"\"\"\n    Run a shell line: run('ls /tmp') will execv('/usr/bin/ls', ['ls', '/tmp'])\n    \"\"\"\n    arguments = shlex.split(line)\n    path = lookup(arguments[0])  # Lookup the first arguments in PATH\n    execute(path, arguments)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef execute(path, arguments):\n    pid = os.fork()\n    if pid == 0:\n        try:\n            os.execv(path, arguments)\n        finally:\n            sys.exit(1)  # In case path is not executable\n    else:\n        try:\n            # Wait for subprocess to finish\n            os.waitpid(pid, NORMAL_PIDWAIT)\n        except OSError:\n            pass  # The subprocess was already finish\n        return", "response": "Execute a command in a new process."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nbuild a ``dict`` of Sphinx configuration variables given a central configuration for LSST Design Documents and a metadata YAML file. This function refactors the common Sphinx ``conf.py`` script so that basic configurations are managed centrally in this module, while author-updatable metadata is stored in a ``metadata.yaml`` file in the document's repository. To use this function, a ``conf.py`` need only look like .. code:: python import os from documenteer.sphinxconfig.technoteconf import configure_technote metadata_path = os.path.join(os.path.dirname(__file__), 'metadata.yaml') with open(metadata_path, 'r') as f: confs = configure_technote(f) _g = global() _g.update(confs) And ``metadata.yaml`` looks like: .. code-block:: yaml doc_id: 'LDM-152' doc_title: 'Data Management Middleware Design' copyright: '2015, AURA/LSST' authors: - 'Kian-Tat Lim' - 'Ray Plante' - 'Gregory Dubois-Felsmann' # Current document version last_revised: 'October 10, 2013' version: '10.0' # dev_version_suffix: None # e.g. 'alpha'/'beta'/'rc' if necessary Parameters ---------- meta_stream : file handle A file stream (e.g., from :func:`open`) for the ``metadata.yaml`` document in a design document's repository. Returns ------- confs : `dict` Dictionary of configurations that should be added to the ``conf.py`` global namespace.", "response": "def configure_technote(meta_stream):\n    \"\"\"Builds a ``dict`` of Sphinx configuration variables given a central\n    configuration for LSST Design Documents and a metadata YAML file.\n\n    This function refactors the common Sphinx ``conf.py`` script so that basic\n    configurations are managed centrally in this module, while author-updatable\n    metadata is stored in a ``metadata.yaml`` file in the document's\n    repository.  To use this function, a ``conf.py`` need only look like\n\n    .. code:: python\n\n       import os\n       from documenteer.sphinxconfig.technoteconf import configure_technote\n\n       metadata_path = os.path.join(os.path.dirname(__file__), 'metadata.yaml')\n       with open(metadata_path, 'r') as f:\n           confs = configure_technote(f)\n       _g = global()\n       _g.update(confs)\n\n    And ``metadata.yaml`` looks like:\n\n    .. code-block:: yaml\n\n       doc_id: 'LDM-152'\n       doc_title: 'Data Management Middleware Design'\n       copyright: '2015, AURA/LSST'\n       authors:\n           - 'Kian-Tat Lim'\n           - 'Ray Plante'\n           - 'Gregory Dubois-Felsmann'\n       # Current document version\n       last_revised: 'October 10, 2013'\n       version: '10.0'\n       # dev_version_suffix: None  # e.g. 'alpha'/'beta'/'rc' if necessary\n\n    Parameters\n    ----------\n    meta_stream : file handle\n        A file stream (e.g., from :func:`open`) for the ``metadata.yaml``\n        document in a design document's repository.\n\n    Returns\n    -------\n    confs : `dict`\n        Dictionary of configurations that should be added to the ``conf.py``\n        global namespace.\n    \"\"\"\n    _metadata = yaml.load(meta_stream)\n    confs = _build_confs(_metadata)\n    return confs"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ocsp_responder_certificate_path():\n    certificate_path = getattr(settings, 'ESTEID_OCSP_RESPONDER_CERTIFICATE_PATH', 'TEST_of_SK_OCSP_RESPONDER_2011.pem')\n\n    if certificate_path in ['TEST_of_SK_OCSP_RESPONDER_2011.pem', 'sk-ocsp-responder-certificates.pem']:\n        return os.path.join(os.path.dirname(__file__), 'certs', certificate_path)\n\n    return certificate_path", "response": "Get ocsp responder certificate path"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef render_template(self, plain, rich = None, **context):\n        '''Render the body of the message from a template. The plain\n        body will be rendered from a template named ``plain`` or \n        ``plain + '.txt'`` (in that order of preference). The rich \n        body will be rendered from ``rich`` if given, or else from \n        ``plain + '.html'``. If neither exists, then the message will\n        have no rich body.'''\n        self.plain = render_template([plain, plain + '.txt'], **context)\n        if rich is not None:\n            self.rich = render_template(rich, **context)\n        else:\n            try:\n                self.rich = render_template(plain + '.html', **context)\n            except TemplateNotFound:\n                pass", "response": "Render the body of the message from a template named plain or rich."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrendering the body of the message from a string.", "response": "def render_template_string(self, plain, rich = None, **context):\n        '''Render the body of the message from a string. If ``rich`` isn\u2019t \n        provided then the message will not have a rich body.'''\n        self.plain = render_template_string(plain, **context)\n        if rich is not None:\n            self.rich = render_template_string(rich, **context)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef init_app(self, app):\n        '''Initialize the extension. Configuration will be \n        obtained from ``app.config['MARROWMAILER_CONFIG']``. If no \n        configuration is found the mailer will be configured to \n        send emails asynchrously via SMTP on localhost without \n        authentication. The created ``Mailer`` instance is written\n        to ``app.marrowmailer``.'''\n        if not hasattr(app, 'extensions'):\n            app.extensions = {}\n        mailer = BaseMailer(app.config.get('MARROWMAILER_CONFIG') or self.default_config)\n        app.extensions['marrowmailer'] = mailer\n        app.marrowmailer = self", "response": "Initialize the extension. Configuration will be \n        obtained from ``app.config['MARROWMAILER_CONFIG']``. If no \n        configuration is found the mailer will be configured to \n        send emails asynchrously via SMTP on localhost without \n        authentication. The created ``Mailer`` instance is written\n        to ``app.marrowmailer``."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a new Message instance. The arguments are passed to the MARCLE_MESSAGE constructor.", "response": "def new(self, **kwargs):\n        '''Return a new ``Message`` instance. The arguments are \n        passed to the ``marrow.mailer.Message`` constructor.'''\n        app = self.app or current_app\n        mailer = app.extensions['marrowmailer']\n        msg = mailer.new(**kwargs)\n        msg.__class__ = Message\n        return msg"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef send(self, msg):\n        '''Send the message. If message is an iterable, then send \n        all the messages.'''\n        app = self.app or current_app\n        mailer = app.extensions['marrowmailer']\n        mailer.start()\n        if not hasattr(msg, '__iter__'):\n            result = mailer.send(msg)\n        else:\n            result = map(lambda message: mailer.send(message), msg)\n        mailer.stop()\n        return result", "response": "Send the message. If message is an iterable then send \n        all the messages."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef wdiff(\n  settings, wrap_with_html=False, fold_breaks=False, hard_breaks=False\n):\n  \"\"\"\n  Returns the results of `wdiff` in a HTML compatible format.\n\n  Needs a :cls:`settings.Settings` object.\n\n  If *wrap_with_html* is set, the *diff* is returned in a full HTML document\n  structure.\n\n  If *fold_breaks* is set, `<ins>` and `<del>` tags are allowed to span line\n  breaks\n\n  If *hard_breaks* is set, line breaks are replaced with `<br />` tags.\n\n  \"\"\"\n  diff = generate_wdiff(settings.org_file, settings.new_file, fold_breaks)\n  if wrap_with_html:\n    return wrap_content(diff, settings, hard_breaks)\n  else:\n    return diff", "response": "Returns the diff of the current file and the new file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload settings from config file and return them as a dict.", "response": "def _load_config(config_file):\n    \"\"\"Load settings from config file and return them as a dict.  If the\n    config file is not found, or if it is invalid, create and use a\n    default config file.\n\n    :param config_file: `pathlib.Path` object. Path to config file.\n    :return: Dictionary of config options.\n    \"\"\"\n    logger.debug('Config file: {}'.format(config_file))\n\n    parser = configparser.ConfigParser()\n    try:\n        with config_file.open('r') as f:\n            parser.read_file(f)\n\n    except FileNotFoundError as e:\n        logger.warning('Config file not found')\n        parser = _use_default(config_file)\n\n    except configparser.ParsingError as e:\n        logger.warning('Error in config file: {}'.format(e))\n        parser = _use_default(config_file)\n\n    finally:\n        try:\n            config = _load_options(parser)\n        except (configparser.NoOptionError):\n            parser = _use_default(config_file)\n            config = _load_options(parser)\n\n        logger.debug('Config loaded: {}'.format(config_file))\n        return config"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _load_options(parser):\n    config = dict(\n        MESSAGE_DURATION=parser.getint('gui', 'message_duration'),\n        GUI_WELCOME_LABLE=parser.get('gui', 'gui_welcome_label'),\n        FULL_USER_NAMES=parser.getboolean('gui', 'full_user_names'),\n        LARGE_FONT_SIZE=parser.getint('gui', 'large_font_size'),\n        MEDIUM_FONT_SIZE=parser.getint('gui', 'medium_font_size'),\n        SMALL_FONT_SIZE=parser.getint('gui', 'small_font_size'),\n        TINY_FONT_SIZE=parser.getint('gui', 'tiny_font_size'),\n        MAX_INPUT_LENGTH=parser.getint('gui', 'max_input_length'),\n    )\n    return config", "response": "Load config options from parser and return them as a dict."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrite default values to a config file.", "response": "def _use_default(config_file):\n    \"\"\"Write default values to a config file. If another config file\n    already exists, back it up before replacing it with the new file.\n\n    :param config_file: `pathlib.Path` object. Path to config file.\n    :return: `ConfigParser` object with the values loaded.\n    \"\"\"\n    default_config = OrderedDict((\n        (\n            'gui',\n            OrderedDict(\n                (\n                    ('message_duration', 5),\n                    ('gui_welcome_label', 'Welcome to the STEM Learning Center!'),\n                    ('full_user_names', True),\n                    ('large_font_size', 30),\n                    ('medium_font_size', 18),\n                    ('small_font_size', 15),\n                    ('tiny_font_size', 10),\n                    ('max_input_length', 9),\n                )\n            ),\n        ),\n    ))\n\n    parser = configparser.ConfigParser()\n    parser.read_dict(default_config)\n\n    if config_file.exists():\n        backup = config_file.with_suffix('.bak')\n        os.rename(str(config_file), str(backup))\n        logger.info('{} moved to {}.'.format(config_file, backup))\n\n    with config_file.open('w') as f:\n        parser.write(f)\n\n    logger.info('Default config file created.')\n\n    return parser"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets an atom. Existing atom will be overwritten.", "response": "def add_atom(self, key, atom):\n        \"\"\"Set an atom. Existing atom will be overwritten.\"\"\"\n        self.graph.add_node(key, atom=atom)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets a bond. Existing bond will be overwritten.", "response": "def add_bond(self, key1, key2, bond):\n        \"\"\"Set a bond. Existing bond will be overwritten.\"\"\"\n        self.graph.add_edge(key1, key2, bond=bond)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef neighbors(self, key):\n        return {n: attr[\"bond\"] for n, attr in self.graph[key].items()}", "response": "Return dict of neighbor atom index and connecting bond."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef neighbors_iter(self):\n        for n, adj in self.graph.adj.items():\n            yield n, {n: attr[\"bond\"] for n, attr in adj.items()}", "response": "Iterate over atoms and return its neighbors."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef clear(self):\n        # self.graph = nx.Graph()\n        self.graph.clear()\n        self.data.clear()\n        self.descriptors.clear()\n        self.size2d = None\n        self.rings = None\n        self.scaffolds = None\n        self.isolated = None", "response": "Clear the instance of the current object"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a molecule to the atom group", "response": "def add_molecule(self, mol, bond=None, base=None, target=None):\n        \"\"\"connect atom group (for SMILES parser)\n\n        May requires recalculation of 2D coordinate for drawing\n\n        Args:\n            mol: graphmol.Compound()\n                the original object will be copied.\n            bond: Bond object to be connected.\n                the original will not be copied so be careful.\n            base: index of atom in self to connect\n            target: index of atom in group to be connected\n        Raises:\n            TypeError\n        \"\"\"\n        ai = self.available_idx()\n        mapping = {n: n + ai - 1 for n, _ in mol.atoms_iter()}\n        relabeled = nx.relabel_nodes(mol.graph, mapping)  # copy=True\n        self.graph.add_nodes_from(relabeled.nodes(data=True))\n        self.graph.add_edges_from(relabeled.edges(data=True))\n        if bond:\n            self.add_bond(base, mapping[target], bond)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef save_png_bytes_io(self):\n        bytearr = QtCore.QByteArray()\n        buf = QtCore.QBuffer(bytearr)\n        buf.open(QtCore.QIODevice.WriteOnly)\n        self.contents.save(buf, \"PNG\")\n        bio = io.BytesIO(bytearr.data())\n        # DPI correction\n        img = Image.open(bio)\n        img = img.resize((self.screen_size[0], self.screen_size[1]),\n                         Image.ANTIALIAS)\n        img.info[\"dpi\"] = (96, 96)\n        converted = io.BytesIO()\n        img.save(converted, format='png')\n        return converted", "response": "Save the contents as PNG format file and return a bytesIO object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _convert(self, pos):\n        px = pos[0] + self.logical_size.width() / 2\n        py = self.logical_size.height() / 2 - pos[1]\n        return px, py", "response": "Convert from X axis to Y axis"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run_sphinx(root_dir):\n    logger = logging.getLogger(__name__)\n\n    # This replicates what Sphinx's internal command line hander does in\n    # https://github.com/sphinx-doc/sphinx/blob/master/sphinx/cmd/build.py\n    # build_main()\n\n    # configuration\n    root_dir = os.path.abspath(root_dir)\n    srcdir = root_dir  # root directory of Sphinx content\n    confdir = root_dir  # directory where conf.py is located\n    outdir = os.path.join(root_dir, '_build', 'html')\n    doctreedir = os.path.join(root_dir, '_build', 'doctree')\n    builder = 'html'\n    confoverrides = {}\n    status = sys.stdout  # set to None for 'quiet' mode\n    warning = sys.stderr\n    error = sys.stderr\n    freshenv = False  # attempt to re-use existing build artificats\n    warningiserror = False\n    tags = []\n    verbosity = 0\n    jobs = 1  # number of processes\n    force_all = True\n    filenames = []\n\n    logger.debug('Sphinx config: srcdir={0}'.format(srcdir))\n    logger.debug('Sphinx config: confdir={0}'.format(confdir))\n    logger.debug('Sphinx config: outdir={0}'.format(outdir))\n    logger.debug('Sphinx config: doctreedir={0}'.format(doctreedir))\n    logger.debug('Sphinx config: builder={0}'.format(builder))\n    logger.debug('Sphinx config: freshenv={0:b}'.format(freshenv))\n    logger.debug('Sphinx config: warningiserror={0:b}'.format(warningiserror))\n    logger.debug('Sphinx config: verbosity={0:d}'.format(verbosity))\n    logger.debug('Sphinx config: jobs={0:d}'.format(jobs))\n    logger.debug('Sphinx config: force_all={0:b}'.format(force_all))\n\n    app = None\n    try:\n        with patch_docutils(), docutils_namespace():\n            app = Sphinx(\n                srcdir, confdir, outdir, doctreedir, builder,\n                confoverrides, status, warning, freshenv,\n                warningiserror, tags, verbosity, jobs)\n            app.build(force_all, filenames)\n            return app.statuscode\n    except (Exception, KeyboardInterrupt) as exc:\n        args = MockSphinxNamespace(verbosity=verbosity, traceback=True)\n        handle_exception(app, args, exc, error)\n        return 1", "response": "Run the Sphinx build process."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run(self):\n\n        df = ArtistsInputData().load()\n\n        # get base model instances, merge ID column via the unique wiki ID\n        # (base and derived model instances must have the same ID values)\n        base_data = self.client.df_query(self.session.query(models.ArtistBase))\n        df = df.merge(base_data, on='wiki_id')\n\n        # rename columns\n        df.rename(columns={'artistLabel': 'name',\n                           'genderLabel': 'gender'},\n                  inplace=True)\n\n        # columns that exist in the data model\n        columns = ['name', 'id']\n\n        # the extended model also stores the date of birth and gender\n        if config.EXTENDED:\n            columns += ['gender', 'year_of_birth']\n\n        # keep only columns that exist in the data model\n        df = df[columns]\n\n        # store everything, done\n        df.to_sql(name=models.Artist.__tablename__,\n                  con=self.client.engine,\n                  if_exists='append',\n                  index=False)\n\n        self.done()", "response": "Load all artists into the database"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsearch and load a configuration file.", "response": "def get_settings(config_file):\n    \"\"\"Search and load a configuration file.\"\"\"\n    default_settings = {\n        'general': {\n            'endpoint': 'http://guacamole.antojitos.io/files/',\n            'shortener': 'http://t.antojitos.io/api/v1/urls',\n        }\n    }\n\n    settings = configparser.ConfigParser()\n    try:\n        settings.read_dict(default_settings)\n    except AttributeError:\n        # using python 2.7\n        for section, options in default_settings.items():\n            settings.add_section(section)\n            for option, value in options.items():\n                settings.set(section, option, value)\n\n    if config_file is not None and os.path.exists(config_file):\n        settings.read(config_file)\n        return settings\n    if os.path.exists(CONFIG_FILE):\n        settings.read(CONFIG_FILE)\n        return settings\n    return settings"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef encrypt(self, message, public_key):\n        # Get the maximum message length based on the key\n        max_str_len = rsa.common.byte_size(public_key.n) - 11\n\n        # If the message is longer than the key size, split it into a list to\n        # be encrypted\n        if len(message) > max_str_len:\n            message = textwrap.wrap(message, width=max_str_len)\n        else:\n            message = [message]\n\n        # Create a list for the encrypted message to send\n        enc_msg = []\n\n        # If we have a long message, loop through and encrypt each part of the\n        # string\n        for line in message:\n\n            # Encrypt the line in the message into a bytestring\n            enc_line = rsa.encrypt(line, public_key)\n\n            # Convert the encrypted bytestring into ASCII, so we can send it\n            # over the network\n            enc_line_converted = binascii.b2a_base64(enc_line)\n\n            enc_msg.append(enc_line_converted)\n\n        # Serialize the encrypted message again with json\n        enc_msg = json.dumps(enc_msg)\n\n        # Return the list of encrypted strings\n        return enc_msg", "response": "Encrypts a string using a given rsa. PublicKey object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef decrypt(self, message):\n\n        # Unserialize the encrypted message\n        message = json.loads(message)\n\n        # Set up a list for the unencrypted lines of the message\n        unencrypted_msg = []\n\n        for line in message:\n\n            # Convert from ascii back to bytestring\n            enc_line = binascii.a2b_base64(line)\n\n            # Decrypt the line using our private key\n            unencrypted_line = rsa.decrypt(enc_line, self.private_key)\n\n            unencrypted_msg.append(unencrypted_line)\n\n        # Convert the message from a list back into a string\n        unencrypted_msg = \"\".join(unencrypted_msg)\n\n        return unencrypted_msg", "response": "Decrypts a string using our own private key object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef on_any_event(self, event):\n        for delegate in self.delegates:\n            if hasattr(delegate, \"on_any_event\"):\n                delegate.on_any_event(event)", "response": "On any event method"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfire when something s been created", "response": "def on_created(self, event):\n        '''Fired when something's been created'''\n        if self.trigger != \"create\":\n            return\n        action_input = ActionInput(event, \"\", self.name)\n        flows.Global.MESSAGE_DISPATCHER.send_message(action_input)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstarts background thread if not already started", "response": "def start(cls):\n        \"\"\"Start background thread if not already started\"\"\"\n        if cls._thread is None:\n            cls._thread = threading.Thread(target=cls._run, name=\"Heartbeat\")\n            cls._thread.daemon = True\n            cls._thread.start()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_task(cls, task, frequency=None):\n        with cls._lock:\n            if not isinstance(task, Task):\n                t = Task(name=task.__name__, frequency=frequency)\n                t.execute, task = task, t\n\n            if frequency:\n                task.frequency = frequency\n\n            cls.tasks.append(task)\n            cls.tasks.sort()", "response": "Add a task to the list of tasks to run periodically"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the task instance representing task.", "response": "def resolved_task(cls, task):\n        \"\"\"Task instance representing 'task', if any\"\"\"\n        for t in cls.tasks:\n            if t is task or t.execute is task:\n                return t"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef remove_task(cls, task):\n        with cls._lock:\n            if not isinstance(task, Task):\n                task = cls.resolved_task(task)\n\n            if task:\n                cls.tasks.remove(task)\n\n            cls.tasks.sort()", "response": "Removes the task from the list of tasks to run periodically"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _run(cls):\n        if cls._thread:\n            with cls._lock:\n                # First run: execute each task once to get it started\n                for task in cls.tasks:\n                    cls._execute_task(task)\n                cls.tasks.sort()\n                cls._last_execution = time.time()\n\n        while cls._thread:\n            with cls._lock:\n                if cls.tasks:\n                    for task in cls.tasks:\n                        if task.next_execution - cls._last_execution < 0.5:\n                            cls._execute_task(task)\n                        else:\n                            break\n                    cls.tasks.sort()\n                    cls._last_execution = time.time()\n                    cls._sleep_delay = cls.tasks[0].next_execution - cls._last_execution\n\n                else:\n                    cls._sleep_delay = 1\n\n                sleep_delay = max(0.1, cls._sleep_delay)\n\n            # Don't hold cls._lock while sleeping, sleep delay should be 1 second when no tasks are present\n            time.sleep(sleep_delay)", "response": "This function is called by the background thread when the thread is running."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a parity plot between predicted and experimental values for trained models.", "response": "def parity_plot(X, Y, model, devmodel, axes_labels=None):\n    \"\"\"\n    A standard method of creating parity plots between predicted and\n    experimental values for trained models.\n\n    Parameters\n    ----------\n    X: array\n        experimental input data\n    Y: array\n        experimental output data\n    model: model object\n        either sklearn or keras ML model\n    devmodel: dev_model object\n        salty dev_model\n    axes_labels: dict\n        optional. Default behavior is to use the labels in the dev_model\n        object.\n\n    Returns\n    ------------------\n    plt: matplotlib object\n        parity plot of predicted vs experimental values\n    \"\"\"\n    model_outputs = Y.shape[1]\n    with plt.style.context('seaborn-whitegrid'):\n        fig = plt.figure(figsize=(2.5 * model_outputs, 2.5), dpi=300)\n        for i in range(model_outputs):\n            ax = fig.add_subplot(1, model_outputs, i + 1)\n            minval = np.min([np.exp(model.predict(X)[:, i]), np.exp(Y)[:, i]])\n            maxval = np.max([np.exp(model.predict(X)[:, i]), np.exp(Y)[:, i]])\n            buffer = (maxval - minval) / 100 * 2\n            minval = minval - buffer\n            maxval = maxval + buffer\n            ax.plot([minval, maxval], [minval, maxval], linestyle=\"-\",\n                    label=None, c=\"black\", linewidth=1)\n            ax.plot(np.exp(Y)[:, i], np.exp(model.predict(X))[:, i],\n                    marker=\"*\", linestyle=\"\", alpha=0.4)\n            if axes_labels:\n                ax.set_ylabel(\"Predicted {}\".format(\n                              axes_labels['{}'.format(i)]))\n                ax.set_xlabel(\"Actual {}\".format(\n                              axes_labels['{}'.format(i)]))\n            else:\n                ax.set_ylabel(\"Predicted {}\".format(\n                    devmodel.Data.columns[-(6 - i)].split(\"<\")[0]),\n                    wrap=True, fontsize=5)\n                ax.set_xlabel(\"Actual {}\".format(\n                    devmodel.Data.columns[-(6 - i)].split(\"<\")[0]),\n                    wrap=True, fontsize=5)\n            plt.xlim(minval, maxval)\n            plt.ylim(minval, maxval)\n            ax.grid()\n        plt.tight_layout()\n    return plt"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __perform_request(self, url, type=GET, params=None):\n        if params is None:\n            params = {}\n\n        # check we have a token\n        if not self.token:\n            raise SetupError(\"No token provided.\")\n\n        # check we have an endpoint\n        if not self.endpoint:\n            raise SetupError(\"No endpoint provided.\")\n\n        # don't show warning about self-signed certificate in dev mode\n        if self.dev:\n            requests.packages.urllib3.disable_warnings()\n\n        url = urljoin(self.endpoint, url)\n\n        # lookup table to find out the apropriate requests method,\n        # headers and payload type (json or query parameters)\n        identity = lambda x: x\n        json_dumps = lambda x: json.dumps(x)\n        lookup = {\n            GET: (requests.get, {}, 'params', identity),\n            POST: (requests.post, {'Content-type': 'application/json'}, 'data',\n                   json_dumps),\n            PUT: (requests.put, {'Content-type': 'application/json'}, 'data',\n                  json_dumps),\n            DELETE: (requests.delete,\n                     {'content-type': 'application/json'},\n                     'data', json_dumps),\n        }\n\n        requests_method, headers, payload, transform = lookup[type]\n        headers.update({'Authorization': self.token})\n        kwargs = {'headers': headers, payload: transform(params)}\n\n        # remove token from log\n        headers_str = str(headers).replace(self.token.strip(), 'TOKEN')\n        self._log.debug('%s %s %s:%s %s' %\n                        (type, url, payload, params, headers_str))\n\n        return requests_method(url, verify=False, **kwargs)", "response": "This method will perform the real request by calling the API method with the given url and params."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nposts some stuff to change title date body or create experiment", "response": "def post_data(self, url, params):\n        \"\"\"\n            POST some stuff to change title/date/body or create experiment\n        \"\"\"\n        url = urljoin(self.endpoint, url)\n        headers = {'Authorization': self.token}\n        req = requests.post(url, headers=headers, data=params, verify=False)\n\n        if req.status_code == 204:\n            return True\n\n        if req.status_code == 404:\n            raise NotFoundError()\n\n        try:\n            data = req.json()\n        except ValueError as e:\n            raise JSONReadError(\n                'Read failed from API: %s' % str(e)\n            )\n\n        if not req.ok:\n            msg = [data[m] for m in (\"id\", \"message\") if m in data][1]\n            raise DataReadError(msg)\n\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate year month day features from specified date features", "response": "def expand_dates(df, columns=[]):\n    \"\"\"\n    generate year, month, day features from specified date features\n    \"\"\"\n    columns = df.columns.intersection(columns)\n    df2 = df.reindex(columns=set(df.columns).difference(columns))\n    for column in columns:\n        df2[column + '_year'] = df[column].apply(lambda x: x.year)\n        df2[column + '_month'] = df[column].apply(lambda x: x.month)\n        df2[column + '_day'] = df[column].apply(lambda x: x.day)\n    return df2"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef binarize_sets(df, columns, cast=False, drop=True, min_freq=None):\n    for column in columns:\n        d = df[column].dropna()  # avoid nulls\n        if cast:\n            d = d.apply(set)\n\n        values = columns[column] if isinstance(columns, dict) else util.union(d)\n        for value in values:\n            name = values[value] if type(values) is dict else str(value)\n            column_name = column + '_' + name.replace(' ', '_')\n            series = d.apply(lambda c: value in c)\n            series.fillna(0, inplace=True)\n            if not min_freq or series.sum() >= min_freq:\n                df[column_name] = series\n\n    if drop:\n        # list(columns) will return keys if columns was dict\n        df.drop(list(columns), axis=1, inplace=True)\n\n    return df", "response": "Binarize a set of items into a set of items."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts counts as returned by aggregate. aggregate_counts to dicts makes expand_counts much faster", "response": "def counts_to_dicts(df, column):\n    \"\"\"\n    convert (values, counts) as returned by aggregate.aggregate_counts() to dicts\n    makes expand_counts much faster\n    \"\"\"\n    # index where there are counts and they aren't null\n    d = df[column].apply(lambda c: pd.notnull(c) and len(c[0]) > 0)\n    return df.loc[d, column].apply(lambda c: {k: v for k, v in zip(*c)})"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef expand_counts(df, column, values=None):\n    d = counts_to_dicts(df, column)\n    if len(d) > 0:\n        if values is None:\n            values = set(np.concatenate(d.apply(lambda c: c.keys()).values))\n        for value in values:\n            name = values[value] if type(values) is dict else str(value)\n            df[column + '_' + name.replace(' ', '_')] =\\\n                d.apply(lambda c: c[value] if value in c else 0)\n    df.drop(column, axis=1, inplace=True)", "response": "expand a column containing value : count dictionaries"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nperforming mean imputation on a pandas dataframe.", "response": "def impute(X, value=None, train=None, dropna=True, inplace=True):\n    \"\"\"\n    Performs mean imputation on a pandas dataframe.\n    Args:\n        train: an optional training mask with which to compute the mean\n        value: instead of computing the mean, use this as the value argument to fillna\n        dropna: whether to drop all null columns\n        inplace: whether to perform the imputation inplace\n    Returns: the imputed DataFrame\n    \"\"\"\n    if value is None:\n        Xfit = X[train] if train is not None else X\n        value = Xfit.mean()\n    else:\n        if train is not None:\n            raise ValueError(\"Cannot pass both train and value arguments\")\n\n    if dropna:\n        null_columns = value.index[value.isnull()]\n        if len(null_columns) > 0:\n            logging.info('Dropping null columns: \\n\\t%s' % null_columns)\n            if inplace:\n                X.drop(null_columns, axis=1, inplace=True)\n            else:\n                X = X.drop(null_columns, axis=1, inplace=False)\n\n    if inplace:\n        X.fillna(value.dropna(), inplace=True)\n    else:\n        X = X.fillna(value.dropna(), inplace=False)\n\n    return X"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nselect subset of strings matching a regex treats strings as a set", "response": "def select_regexes(strings, regexes):\n    \"\"\"\n    select subset of strings matching a regex\n    treats strings as a set\n    \"\"\"\n    strings = set(strings)\n    select = set()\n    if isinstance(strings, collections.Iterable):\n        for r in regexes:\n            s = set(filter(re.compile('^' + r + '$').search, strings))\n            strings -= s\n            select |= s\n        return select\n    else:\n        raise ValueError(\"exclude should be iterable\")"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef date_censor_sql(date_column, today, column=None):\n    if column is None:\n        column = date_column\n\n    if today is None:\n        return column\n    else:\n        return \"(CASE WHEN {date_column} < '{today}' THEN {column} ELSE null END)\".format(\n                date_column=date_column, today=today, column=column)", "response": "Return a SQL statement that can be used to censor the log entries for a given date."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngive sql containing a \"CREATE TABLE {table_name} AS ({query})\" returns table_name, query", "response": "def revise_helper(query):\n    \"\"\"\n    given sql containing a \"CREATE TABLE {table_name} AS ({query})\"\n    returns table_name, query\n    \"\"\"\n    match = re.search(extract_sql_regex, query, re.DOTALL | re.I)\n    return match.group(1), match.group(2)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef revise_sql(query, id_column, output_table, max_date_column,\n               min_date_column, date_column, date, source_id_column=None):\n    \"\"\"\n    Given an expensive query that aggregates temporal data,\n    Revise the results to censor before a particular date\n    \"\"\"\n    if source_id_column is None:\n        source_id_column = id_column\n\n    if hasattr(id_column, '__iter__'):\n        id_column = str.join(', ', id_column)\n    if hasattr(source_id_column, '__iter__'):\n        source_id_column = str.join(', ', source_id_column)\n\n    sql_vars = dict(query=query, id_column=id_column, output_table=output_table,\n                    max_date_column=max_date_column, min_date_column=min_date_column,\n                    date_column=date_column, date=date, source_id_column=source_id_column)\n\n    sql_vars['ids_query'] = \"\"\"\n    SELECT {id_column} FROM {output_table}\n    WHERE {max_date_column} >= '{date}' AND {min_date_column} < '{date}'\"\"\" .format(**sql_vars)\n\n    sql_vars['revised_query'] = query.replace(\n            '1=1',\n            \"(({source_id_column}) in (select * from ids_query) and {date_column} < '{date}')\"\n            .format(**sql_vars))\n\n    new_query = \"\"\"\n    with ids_query as ({ids_query})\n    select * from ({revised_query}) t\n    \"\"\".format(**sql_vars)\n\n    return new_query", "response": "Given an expensive query that aggregates temporal data and a particular date revise the results to censor before a particular date."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef date_select(df, date_column, date, delta, max_date_column=None):\n    delta = parse_delta(delta)\n    if delta:\n        start_date = date - delta\n\n    if not max_date_column:\n        df = df.query(\"%s < '%s'\" % (date_column, date))\n        if delta:\n            df = df.query(\"%s >= '%s'\" % (date_column, start_date))\n    else:\n        # event not entirely after\n        df = df.query(\"not ({min} >= '{end}' and {max} >= '{end}')\".format(\n                          min=date_column, max=max_date_column, end=date))\n        if delta:\n            # event not entirely before\n            df = df.query(\"not ({min} < '{start}' and {max} < '{start}')\".format(\n                          min=date_column, max=max_date_column, start=start_date))\n\n    return df", "response": "return subset of the date range\n    given a series an end date and number of days"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncensors the censored items in a dataframe that are before a given date", "response": "def date_censor(df, date_columns, date):\n    \"\"\"\n    a dictionary of date_column: [dependent_column1, ...] pairs\n    censor the dependent columns when the date column is before the given end_date\n    then censor the date column itself\n    \"\"\"\n    for date_column, censor_columns in date_columns.items():\n        for censor_column in censor_columns:\n            df[censor_column] = df[censor_column].where(df[date_column] < date)\n\n        df[date_column] = df[date_column].where(df[date_column] < date)\n\n    return df"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_delta(s):\n    if s == 'all':\n        return None\n    else:\n        ls = delta_regex.findall(s)\n        if len(ls) == 1:\n            return relativedelta(**{delta_chars[ls[0][1]]: int(ls[0][0])})\n        else:\n            raise ValueError('Invalid delta string: %s' % s)", "response": "parse a string to a delta\n elastic elastic"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntake a pd. DataFrame and returns the newly defined column i. e. a pd. Series that has the same index as df.", "response": "def apply(self, df):\n        \"\"\"Takes a pd.DataFrame and returns the newly defined column, i.e.\n        a pd.Series that has the same index as `df`.\n        \"\"\"\n        if hasattr(self.definition, '__call__'):\n            r = self.definition(df)\n        elif self.definition in df.columns:\n            r = df[self.definition]\n        elif not isinstance(self.definition, string_types):\n            r = pd.Series(self.definition, index=df.index)\n        else:\n            raise ValueError(\"Invalid column definition: %s\" % str(self.definition))\n        return r.astype(self.astype) if self.astype else r"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef phonex(word, language=\"english\"):\n    phone_variants = phoneticize(word)\n    mappings = cluster_phones(language)\n    results = []\n    for phone_variant in phone_variants:\n        try:\n            phonex_variant = tuple([mappings[phone] for phone in\n                                    phone_variant])\n            results.append(phonex_variant)\n        except:\n            print('Error:', word, phone_variant)\n            exit(1)\n    return results", "response": "Short for phone index maps a word onto a sequence of phone clusters."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting an ip address to a network byte order 32 - bit integer.", "response": "def ip_to_long (ip):\n    \"\"\"\n    Convert ip address to a network byte order 32-bit integer.\n   \"\"\"\n    quad = ip.split('.')\n    if len(quad) == 1:\n        quad = quad + [0, 0, 0]\n    elif len(quad) < 4:\n        host = quad[-1:]\n        quad = quad[:-1] + [0,] * (4 - len(quad)) + host\n\n    lip = 0\n    for q in quad:\n        lip = (lip << 8) | int(q)\n    return lip"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlink to LSST documents given their handle using LSST s ls. st link shortener.", "response": "def lsst_doc_shortlink_role(name, rawtext, text, lineno, inliner,\n                            options=None, content=None):\n    \"\"\"Link to LSST documents given their handle using LSST's ls.st link\n    shortener.\n\n    Example::\n\n        :ldm:`151`\n    \"\"\"\n    options = options or {}\n    content = content or []\n    node = nodes.reference(\n        text='{0}-{1}'.format(name.upper(), text),\n        refuri='https://ls.st/{0}-{1}'.format(name, text),\n        **options)\n    return [node], []"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nlink to LSST documents given their handle using LSST s ls. st link shortener with the document handle displayed in title case.", "response": "def lsst_doc_shortlink_titlecase_display_role(\n        name, rawtext, text, lineno, inliner, options=None, content=None):\n    \"\"\"Link to LSST documents given their handle using LSST's ls.st link\n    shortener with the document handle displayed in title case.\n\n    This role is useful for Document, Report, Minutes, and Collection\n    DocuShare handles.\n\n    Example::\n\n        :document:`1`\n    \"\"\"\n    options = options or {}\n    content = content or []\n    node = nodes.reference(\n        text='{0}-{1}'.format(name.title(), text),\n        refuri='https://ls.st/{0}-{1}'.format(name, text),\n        **options)\n    return [node], []"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncommand line entrypoint for the refresh - lsst - bib program.", "response": "def run():\n    \"\"\"Command line entrypoint for the ``refresh-lsst-bib`` program.\n    \"\"\"\n    args = parse_args()\n\n    if args.verbose:\n        log_level = logging.DEBUG\n    else:\n        log_level = logging.INFO\n    logging.basicConfig(\n        level=log_level,\n        format='%(asctime)s %(levelname)s %(name)s: %(message)s')\n    if not args.verbose:\n        # Manage third-party loggers\n        req_logger = logging.getLogger('requests')\n        req_logger.setLevel(logging.WARNING)\n\n    logger = logging.getLogger(__name__)\n\n    logger.info('refresh-lsst-bib version {}'.format(__version__))\n\n    error_count = process_bib_files(args.dir)\n\n    sys.exit(error_count)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef process_bib_files(local_dir):\n    logger = logging.getLogger(__name__)\n\n    # check the output directory exists\n    if not os.path.isdir(local_dir):\n        logger.error('Output directory \"{}\" does not exist'.format(local_dir))\n        sys.exit(1)\n\n    root_blob_url = ('https://raw.githubusercontent.com/lsst/lsst-texmf/'\n                     'master/texmf/bibtex/bib/')\n    bib_filenames = ['books.bib', 'lsst-dm.bib', 'lsst.bib', 'refs.bib',\n                     'refs_ads.bib']\n\n    error_count = 0\n    for bib_filename in bib_filenames:\n        url = urllib.parse.urljoin(root_blob_url, bib_filename)\n        logger.info('Downloading {}'.format(url))\n        try:\n            content = _get_content(url)\n        except requests.HTTPError as e:\n            logger.exception(str(e))\n            logger.warning('Could not download {}'.format(url))\n            error_count += 1\n            continue\n\n        local_filename = os.path.join(local_dir, bib_filename)\n        with open(local_filename, 'w') as f:\n            f.write(content)\n\n    return error_count", "response": "Download and process the bib files from GitHub and write them to a local directory."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncommand line entrypoint for the build - stack - docs program.", "response": "def run_build_cli():\n    \"\"\"Command line entrypoint for the ``build-stack-docs`` program.\n    \"\"\"\n    args = parse_args()\n\n    if args.verbose:\n        log_level = logging.DEBUG\n    else:\n        log_level = logging.INFO\n    logging.basicConfig(\n        level=log_level,\n        format='%(asctime)s %(levelname)s %(name)s: %(message)s')\n\n    logger = logging.getLogger(__name__)\n\n    logger.info('build-stack-docs version {0}'.format(__version__))\n\n    return_code = build_stack_docs(args.root_project_dir)\n    if return_code == 0:\n        logger.info('build-stack-docs succeeded')\n        sys.exit(0)\n    else:\n        logger.error('Sphinx errored: code {0:d}'.format(return_code))\n        sys.exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nbuild the stack Sphinx documentation for the given project.", "response": "def build_stack_docs(root_project_dir, skippedNames=None):\n    \"\"\"Build stack Sphinx documentation (main entrypoint).\n\n    Parameters\n    ----------\n    root_project_dir : `str`\n        Path to the root directory of the main documentation project. This\n        is the directory containing the ``conf.py`` file.\n    skippedNames : `list`, optional\n        Optional list of packages to skip while creating symlinks.\n    \"\"\"\n    logger = logging.getLogger(__name__)\n\n    # Create the directory where module content is symlinked\n    # NOTE: this path is hard-wired in for pipelines.lsst.io, but could be\n    # refactored as a configuration.\n    root_modules_dir = os.path.join(root_project_dir, 'modules')\n    if os.path.isdir(root_modules_dir):\n        logger.info('Deleting any existing modules/ symlinks')\n        remove_existing_links(root_modules_dir)\n    else:\n        logger.info('Creating modules/ dir at {0}'.format(root_modules_dir))\n        os.makedirs(root_modules_dir)\n\n    # Create directory for package content\n    root_packages_dir = os.path.join(root_project_dir, 'packages')\n    if os.path.isdir(root_packages_dir):\n        # Clear out existing module links\n        logger.info('Deleting any existing packages/ symlinks')\n        remove_existing_links(root_packages_dir)\n    else:\n        logger.info('Creating packages/ dir at {0}'.format(root_packages_dir))\n        os.makedirs(root_packages_dir)\n\n    # Ensure _static directory exists (but do not delete any existing\n    # directory contents)\n    root_static_dir = os.path.join(root_project_dir, '_static')\n    if os.path.isdir(root_static_dir):\n        # Clear out existing directory links\n        logger.info('Deleting any existing _static/ symlinks')\n        remove_existing_links(root_static_dir)\n    else:\n        logger.info('Creating _static/ at {0}'.format(root_static_dir))\n        os.makedirs(root_static_dir)\n\n    # Find package setup by EUPS\n    packages = discover_setup_packages()\n\n    # Get packages explicitly required in the table file to filter out\n    # implicit dependencies later.\n    table_path = find_table_file(root_project_dir)\n    with open(table_path) as fp:\n        table_data = fp.read()\n    listed_packages = list_packages_in_eups_table(table_data)\n\n    # Link to documentation directories of packages from the root project\n    for package_name, package_info in packages.items():\n        if package_name not in listed_packages:\n            logger.debug(\n                'Filtering %s from build since it is not explictly '\n                'required by the %s table file.',\n                package_name, table_path)\n            continue\n        try:\n            package_docs = find_package_docs(\n                package_info['dir'],\n                skippedNames=skippedNames)\n        except NoPackageDocs as e:\n            logger.debug(\n                'Skipping {0} doc linking. {1}'.format(package_name,\n                                                       str(e)))\n            continue\n\n        link_directories(root_modules_dir, package_docs.module_dirs)\n        link_directories(root_packages_dir, package_docs.package_dirs)\n        link_directories(root_static_dir, package_docs.static_dirs)\n\n    # Trigger the Sphinx build\n    return_code = run_sphinx(root_project_dir)\n    return return_code"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_args():\n    parser = argparse.ArgumentParser(\n        description=\"Build a Sphinx documentation site for an EUPS stack, \"\n                    \"such as pipelines.lsst.io.\",\n        epilog=\"Version {0}\".format(__version__)\n    )\n    parser.add_argument(\n        '-d', '--dir',\n        dest='root_project_dir',\n        help=\"Root Sphinx project directory\")\n    parser.add_argument(\n        '-v', '--verbose',\n        dest='verbose',\n        action='store_true', default=False,\n        help='Enable Verbose output (debug level logging)'\n    )\n    return parser.parse_args()", "response": "Create an argument parser for the build - stack - docs program."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a dictionary with keys that are set up by EUPS listing theirir ridge set up directories and EUPS version names.", "response": "def discover_setup_packages():\n    \"\"\"Summarize packages currently set up by EUPS, listing their\n    set up directories and EUPS version names.\n\n    Returns\n    -------\n    packages : `dict`\n       Dictionary with keys that are EUPS package names. Values are\n       dictionaries with fields:\n\n       - ``'dir'``: absolute directory path of the set up package.\n       - ``'version'``: EUPS version string for package.\n\n    Notes\n    -----\n    This function imports the ``eups`` Python package, which is assumed to\n    be available in the build environmen. This function is designed to\n    encapsulate all direct EUPS interactions need by the stack documentation\n    build process.\n    \"\"\"\n    logger = logging.getLogger(__name__)\n\n    # Not a PyPI dependency; assumed to be available in the build environment.\n    import eups\n\n    eups_client = eups.Eups()\n    products = eups_client.getSetupProducts()\n\n    packages = {}\n    for package in products:\n        name = package.name\n        info = {\n            'dir': package.dir,\n            'version': package.version\n        }\n        packages[name] = info\n        logger.debug('Found setup package: {name} {version} {dir}'.format(\n            name=name, **info))\n\n    return packages"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfinds the EUPS table file for a project.", "response": "def find_table_file(root_project_dir):\n    \"\"\"Find the EUPS table file for a project.\n\n    Parameters\n    ----------\n    root_project_dir : `str`\n        Path to the root directory of the main documentation project. This\n        is the directory containing the ``conf.py`` file and a ``ups``\n        directory.\n\n    Returns\n    -------\n    table_path : `str`\n        Path to the EUPS table file.\n    \"\"\"\n    ups_dir_path = os.path.join(root_project_dir, 'ups')\n    table_path = None\n    for name in os.listdir(ups_dir_path):\n        if name.endswith('.table'):\n            table_path = os.path.join(ups_dir_path, name)\n            break\n    if not os.path.exists(table_path):\n        raise RuntimeError(\n            'Could not find the EUPS table file at {}'.format(table_path))\n    return table_path"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlists the names of packages that are required by an EUPS table file.", "response": "def list_packages_in_eups_table(table_text):\n    \"\"\"List the names of packages that are required by an EUPS table file.\n\n    Parameters\n    ----------\n    table_text : `str`\n        The text content of an EUPS table file.\n\n    Returns\n    -------\n    names : `list` [`str`]\n        List of package names that are required byy the EUPS table file.\n    \"\"\"\n    logger = logging.getLogger(__name__)\n    # This pattern matches required product names in EUPS table files.\n    pattern = re.compile(r'setupRequired\\((?P<name>\\w+)\\)')\n    listed_packages = [m.group('name') for m in pattern.finditer(table_text)]\n    logger.debug('Packages listed in the table file: %r', listed_packages)\n    return listed_packages"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef find_package_docs(package_dir, skippedNames=None):\n    logger = logging.getLogger(__name__)\n\n    if skippedNames is None:\n        skippedNames = []\n\n    doc_dir = os.path.join(package_dir, 'doc')\n    modules_yaml_path = os.path.join(doc_dir, 'manifest.yaml')\n\n    if not os.path.exists(modules_yaml_path):\n        raise NoPackageDocs(\n            'Manifest YAML not found: {0}'.format(modules_yaml_path))\n\n    with open(modules_yaml_path) as f:\n        manifest_data = yaml.safe_load(f)\n\n    module_dirs = {}\n    package_dirs = {}\n    static_dirs = {}\n\n    if 'modules' in manifest_data:\n        for module_name in manifest_data['modules']:\n            if module_name in skippedNames:\n                logger.debug('Skipping module {0}'.format(module_name))\n                continue\n            module_dir = os.path.join(doc_dir, module_name)\n\n            # validate that the module's documentation directory does exist\n            if not os.path.isdir(module_dir):\n                message = 'module doc dir not found: {0}'.format(module_dir)\n                logger.warning(message)\n                continue\n\n            module_dirs[module_name] = module_dir\n            logger.debug('Found module doc dir {0}'.format(module_dir))\n\n    if 'package' in manifest_data:\n        package_name = manifest_data['package']\n\n        full_package_dir = os.path.join(doc_dir, package_name)\n\n        # validate the directory exists\n        if os.path.isdir(full_package_dir) \\\n                and package_name not in skippedNames:\n            package_dirs[package_name] = full_package_dir\n            logger.debug('Found package doc dir {0}'.format(full_package_dir))\n        else:\n            logger.warning('package doc dir excluded or not found: {0}'.format(\n                full_package_dir))\n\n    if 'statics' in manifest_data:\n        for static_dirname in manifest_data['statics']:\n            full_static_dir = os.path.join(doc_dir, static_dirname)\n\n            # validate the directory exists\n            if not os.path.isdir(full_static_dir):\n                message = '_static doc dir not found: {0}'.format(\n                    full_static_dir)\n                logger.warning(message)\n                continue\n\n            # Make a relative path to `_static` that's used as the\n            # link source in the root docproject's _static/ directory\n            relative_static_dir = os.path.relpath(\n                full_static_dir,\n                os.path.join(doc_dir, '_static'))\n\n            static_dirs[relative_static_dir] = full_static_dir\n            logger.debug('Found _static doc dir: {0}'.format(full_static_dir))\n\n    Dirs = namedtuple('Dirs', ['module_dirs', 'package_dirs', 'static_dirs'])\n    return Dirs(module_dirs=module_dirs,\n                package_dirs=package_dirs,\n                static_dirs=static_dirs)", "response": "Find documentation directories in a package using manifest. yaml."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate symlinks to package and module documentation directories from the base documentation project.", "response": "def link_directories(root_dir, package_doc_dirs):\n    \"\"\"Create symlinks to package/module documentation directories from the\n    root documentation project.\n\n    Parameters\n    ----------\n    root_dir : `str`\n        Directory in the main documentation project where links will be\n        created. For example, this could be a ``'modules'`` directory\n        in the ``pipelines_lsst_io`` project directory.\n    package_doc_dirs : `dict`\n        Dictionary that maps symlinks to be made in ``root_dir`` with\n        source directories in the packages.\n\n    Notes\n    -----\n    If the link already exists in the ``root_dir`` it will be automatically\n    replaced.\n    \"\"\"\n    logger = logging.getLogger(__name__)\n\n    for dirname, source_dirname in package_doc_dirs.items():\n        link_name = os.path.join(root_dir, dirname)\n        if os.path.islink(link_name):\n            os.remove(link_name)\n        os.symlink(source_dirname, link_name)\n\n        message = 'Linking {0} -> {1}'.format(link_name, source_dirname)\n        logger.info(message)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef remove_existing_links(root_dir):\n    logger = logging.getLogger(__name__)\n\n    for name in os.listdir(root_dir):\n        full_name = os.path.join(root_dir, name)\n        if os.path.islink(full_name):\n            logger.debug('Deleting existing symlink {0}'.format(full_name))\n            os.remove(full_name)", "response": "Delete any symlinks present at the root of a directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef render_diagram(out_base):\n    import codecs\n    import subprocess\n    import sadisplay\n\n    # generate class descriptions\n    desc = sadisplay.describe(list(model_registry.values()),\n                              show_methods=False,\n                              show_properties=True,\n                              show_indexes=True,\n                              )\n\n    # write description in DOT format\n    with codecs.open(out_base + '.dot', 'w', encoding='utf-8') as f:\n        f.write(sadisplay.dot(desc))\n\n    # check existence of DOT_EXECUTABLE variable and file\n    if not hasattr(config, 'DOT_EXECUTABLE'):\n        raise RuntimeError(\"Please configure the 'DOT_EXECUTABLE' variable in your 'project_config.py'\")\n    if not os.path.exists(config.DOT_EXECUTABLE):\n        raise IOError(\"Could not find file pointed to by 'DOT_EXECUTABLE': \" + str(config.DOT_EXECUTABLE))\n\n    # render to image using DOT\n    # noinspection PyUnresolvedReferences\n    subprocess.check_call([\n        config.DOT_EXECUTABLE,\n        '-T', 'png',\n        '-o', out_base + '.png',\n              out_base + '.dot'\n    ])", "response": "Render a data model diagram in a small script that imports all models that you want to be included in the diagram."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_max_id(cls, session):\n        # sqlalchemy allows only one level of inheritance, so just check this class and all its bases\n        id_base = None\n        for c in [cls] + list(cls.__bases__):\n            for base_class in c.__bases__:\n                if base_class.__name__ == 'Base':\n                    if id_base is None:\n                        # we found our base class for determining the ID\n                        id_base = c\n                    else:\n                        raise RuntimeError(\"Multiple base object classes for class \" + cls.__name__)\n\n        # this should never happen\n        if id_base is None:\n            raise RuntimeError(\"Error searching for base class of \" + cls.__name__)\n\n        # get its max ID\n        max_id = session.query(func.max(id_base.id)).scalar()\n\n        # if no object is present, None is returned\n        if max_id is None:\n            max_id = 0\n\n        return max_id", "response": "Get the current max value of the id column."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef truncate_to_field_length(self, field, value):\n        max_len = getattr(self.__class__, field).prop.columns[0].type.length\n        if value and len(value) > max_len:\n            return value[:max_len]\n        else:\n            return value", "response": "Truncate the value of a string field to the field s max length."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninstalling a hook to process untnwisted event loop.", "response": "def extern(obj, timeout=200):\n    \"\"\"\n    Tell Tkinter to process untnwisted event loop.\n    It registers just once the update handle.\n    \"\"\"\n    global installed\n\n    # Register it just once.\n    if not installed: \n        install_hook(obj, timeout)\n    installed = True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef intern(obj, timeout):\n\n    core.gear.timeout = timeout\n    core.gear.pool.append(obj)", "response": "Intern a new object into the internal pool."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _make_ticket_node(ticket_id, config, options=None):\n    options = options or {}\n    ref = config.jira_uri_template.format(ticket=ticket_id)\n    link = nodes.reference(text=ticket_id, refuri=ref, **options)\n    return link", "response": "Construct a reference node for a JIRA ticket."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _oxford_comma_separator(i, length):\n    if length == 1:\n        return None\n    elif length < 3 and i == 0:\n        return ' and '\n    elif i < length - 2:\n        return ', '\n    elif i == length - 2:\n        return ', and '\n    else:\n        return None", "response": "Make a comma - separated list with between items except\n    for and after the last item."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef jira_bracket_role(name, rawtext, text, lineno, inliner,\n                      options=None, content=None,\n                      open_symbol='[', close_symbol=']'):\n    \"\"\"Sphinx role for referencing a JIRA ticket with ticket numbers\n    enclosed in braces. Useful for changelogs.\n\n    Examples::\n\n        :jirab:`DM-6181` -> [DM-6181]\n        :jirab:`DM-6181,DM-6181` -> [DM-6180, DM-6181]\n        :jirab:`DM-6181,DM-6181,DM-6182` -> [DM-6180, DM-6181, DM-6182]\n    \"\"\"\n    node_list, _ = jira_role(name, rawtext, text, lineno, inliner,\n                             options=options, content=None, oxford_comma=False)\n    node_list = nodes.raw(text=open_symbol, format='html') \\\n        + node_list + nodes.raw(text=close_symbol, format='html')\n    return node_list, []", "response": "Sphinx role for referencing a JIRA ticket with ticket numbers enclosed in braces."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_inputs_helper(step, ignore, target):\n    outputs = set()\n    if not ignore and step.target == target:\n        outputs.add(step)\n\n    if ignore or not step.target:\n        for i in step.inputs:\n            outputs.update(get_inputs_helper(i, ignore=False, target=target))\n\n    return outputs", "response": "Recursive helper used by get_inputs"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_drake_data(steps):\n    output_inputs = {}\n    if len(steps) == 0:\n        return output_inputs\n\n    for step in steps:\n        output_inputs[step] = get_inputs(step, target=True)\n\n    # recursively do the same for all the inputs\n    inputs = set(itertools.chain(*output_inputs.values()))\n    o = get_drake_data(inputs)\n    output_inputs.update(o)\n\n    return output_inputs", "response": "Returns a dictionary of outputs mapped to inputs\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a string of the drake step for the given inputs and output.", "response": "def to_drake_step(inputs, output):\n    \"\"\"\n    Args:\n        inputs: collection of input Steps\n        output: output Step\n\n    Returns: a string of the drake step for the given inputs and output\n    \"\"\"\n    i = [output._yaml_filename]\n    i.extend(map(lambda i: i._target_filename, list(inputs)))\n    i.extend(output.dependencies)\n\n    # add source file of output and its non-target inputs\n    # if they're not in the drain library\n    objects = get_inputs(output, target=False)\n    objects.add(output)\n    sources = set([os.path.abspath(inspect.getsourcefile(o.__class__)) for o in objects])\n    i.extend([s for s in sources if not s.startswith(os.path.dirname(__file__))])\n\n    output_str = '%' + output.__class__.__name__\n    if output.name:\n        output_str += ', %' + output.name\n    if output.target:\n        output_str += ', ' + os.path.join(output._target_filename)\n    return '{output} <- {inputs} [method:drain]\\n\\n'.format(\n            output=output_str, inputs=str.join(', ', i))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate a drakefile from a collection of drain. step. Step objects.", "response": "def to_drakefile(steps, preview=True, debug=False, input_drakefile=None, bindir=None):\n    \"\"\"\n    Args:\n        steps: collection of drain.step.Step objects for which to\n            generate a drakefile\n        preview: boolean, when False will create directories for output\n            steps.  When True do not touch filesystem.\n        debug: run python with '-m pdb'\n        drakefile: path to drakefile to include\n        bindir: path to drake binaries, defaults to ../bin/\n    Returns:\n        a string representation of the drakefile\n    \"\"\"\n    data = get_drake_data(steps)\n    drakefile = StringIO()\n\n    if input_drakefile:\n        drakefile.write('%context {}\\n\\n'.format(input_drakefile))\n\n    if bindir is None:\n        bindir = os.path.join(os.path.dirname(__file__), '..', 'bin')\n\n    # if the step has a $OUTPUT, write drain.log to its directory\n    drakefile.write(\"\"\"drain()\n    if [ $OUTPUT ]; then LOGFILE=$(dirname $OUTPUT)/drain.log; fi\n    python %s %s/run_step.py $OUTPUT $INPUTS 2>&1 | tee $LOGFILE\n\n\n\"\"\" % ('-m pdb' if debug else '', bindir))\n    for output, inputs in data.items():\n        if not preview:\n            output.setup_dump()\n\n        drakefile.write(to_drake_step(inputs, output))\n\n    return drakefile.getvalue()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _method_call(self, method, category, **kwargs):\n        session = requests.Session()\n        try:\n            response = session.get(\"http://\" + self._api_address)\n        except requests.exceptions.ConnectionError:\n            raise FantasyDataError('Error: Cannot connect to the FantasyData API')\n\n        method = method.format(format=self._response_format, **kwargs)\n        request_url = \"/v3/{game_type}/{category}/{format}/{method}?{get_params}\".format(\n            game_type=self.game_type,\n            category=category,\n            format=self._response_format,\n            method=method,\n            get_params=self._get_params)\n        response = session.get(self._api_schema + self._api_address + request_url,\n                               headers=self._headers)\n        result = response.json()\n\n        if isinstance(result, dict) and response.status_code:\n            if response.status_code == 401:\n                raise FantasyDataError('Error: Invalid API key')\n            elif response.status_code == 200:\n                # for NBA everything is ok here.\n                pass\n            else:\n                raise FantasyDataError('Error: Failed to get response')\n\n        return result", "response": "Method call for the FantasyData API."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the game schedule for a specified season.", "response": "def get_schedules_for_season(self, season, season_type=\"REG\"):\n        \"\"\"\n        Game schedule for a specified season.\n        \"\"\"\n        try:\n            season = int(season)\n            if season_type not in [\"REG\", \"PRE\", \"POST\"]:\n                raise ValueError\n        except (ValueError, TypeError):\n            raise FantasyDataError('Error: Invalid method parameters')\n\n        season_param = \"{0}{1}\".format(season, season_type)\n        result = self._method_call(\"Schedules/{season}\", \"stats\", season=season_param)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_players_game_stats_for_season_for_week(self, season, week, season_type=\"REG\"):\n        try:\n            season = int(season)\n            week = int(week)\n            if season_type not in [\"REG\", \"PRE\", \"POST\"]:\n                raise ValueError\n        except (TypeError, ValueError):\n            raise FantasyDataError('Error: Invalid method parameters')\n\n        season_param = \"{0}{1}\".format(season, season_type)\n        result = self._method_call(\"PlayerGameStatsByWeek/{season}/{week}\", \"stats\", season=season_param, week=week)\n        return result", "response": "This method returns the game stats for a specified season and week."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_projected_player_game_stats_by_player(self, season, week, player_id):\n        result = self._method_call(\"PlayerGameProjectionStatsByPlayerID/{season}/{week}/{player_id}\", \"projections\", season=season, week=week, player_id=player_id)\n        return result", "response": "Get Projected Player Game Stats by Player"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting Player Game Stats by Team", "response": "def get_projected_player_game_stats_by_team(self, season, week, team_id):\n        \"\"\"\n        Projected Player Game Stats by Team\n        \"\"\"\n        result = self._method_call(\"PlayerGameProjectionStatsByTeam/{season}/{week}/{team_id}\", \"projections\", season=season, week=week, team_id=team_id)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_projected_player_game_stats_by_week(self, season, week):\n        result = self._method_call(\"PlayerGameProjectionStatsByWeek/{season}/{week}\", \"projections\", season=season, week=week)\n        return result", "response": "Get Player Game Stats by Week"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_projected_fantasy_defense_game_stats_by_week(self, season, week):\n        result = self._method_call(\"FantasyDefenseProjectionsByGame/{season}/{week}\", \"projections\", season=season, week=week)\n        return result", "response": "Get Projected Fantasy Defense Game Stats by Week"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_injuries(self, season, week):\n        result = self._method_call(\"Injuries/{season}/{week}\", \"stats\", season=season, week=week)\n        return result", "response": "Get the injuries for a given season and week."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_injuries_by_team(self, season, week, team_id):\n        result = self._method_call(\"Injuries/{season}/{week}/{team_id}\", \"stats\", season=season, week=week, team_id=team_id)\n        return result", "response": "Get the injuries by week and team"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_box_score_by_team(self, season, week, team_id):\n        result = self._method_call(\"BoxScoreV3/{season}/{week}/{team_id}\", \"stats\", season=season, week=week, team_id=team_id)\n        return result", "response": "Get the box score by week and team"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_games_by_season(self, season):\n        try:\n            season = int(season)\n        except ValueError:\n            raise FantasyDataError('Error: Invalid method parameters')\n\n        result = self._method_call(\"Games/{season}\", \"stats\", season=season)\n        return result", "response": "Get a list of games in a specified season."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef list(context, sort, limit, where, verbose):\n    result = job.list(\n        context, sort=sort, limit=limit, where=where,\n        embed='topic,remoteci,team')\n    headers = ['id', 'status', 'topic/name', 'remoteci/name',\n               'team/name', 'etag', 'created_at', 'updated_at']\n\n    utils.format_output(result, context.format, headers, verbose=verbose)", "response": "list - List all jobs in the cluster"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef list_results(context, id, sort, limit):\n\n    headers = ['filename', 'name', 'total', 'success', 'failures', 'errors',\n               'skips', 'time']\n    result = job.list_results(context, id=id, sort=sort, limit=limit)\n    utils.format_output(result, context.format, headers)", "response": "List all job results for a specific job"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef attach_issue(context, id, url):\n\n    result = job.attach_issue(context, id=id, url=url)\n    utils.format_output(result, context.format)", "response": "Attach an issue to a job."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef list_issues(context, id, sort, limit, where):\n\n    result = job.list_issues(context, id=id, sort=sort, limit=limit,\n                             where=where)\n    headers = ['id', 'status', 'product', 'component', 'title', 'url']\n    utils.format_output(result, context.format, headers)", "response": "List all issues attached to a job"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nshowing a job output.", "response": "def output(context, id):\n    \"\"\"output(context, id)\n\n    Show a job output.\n\n    >>> dcictl job-output [OPTIONS]\n\n    :param string id: ID of the job to show [required]\n    \"\"\"\n\n    colors = {\n        'pre-run': '\\x1b[6;30;44m',\n        'running': '\\x1b[6;30;42m',\n        'post-run': '\\x1b[6;30;44m',\n        'failure': '\\x1b[6;30;41m'}\n    result = job.list_jobstates(context, id=id, sort='created_at')\n    jobstates = result.json()['jobstates']\n\n    for js in jobstates:\n        color = colors.get(js['status'], '')\n        click.echo('%s[%s]\\x1b[0m %s' % (\n            color,\n            js['status'],\n            js['comment']))\n        f_l = job.list_files(\n            context,\n            id=id,\n            where='jobstate_id:' + js['id'],\n            sort='created_at')\n        for f in f_l.json()['files']:\n            click.echo(dci_file.content(context, id=f['id']).text)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_tag(context, id, name):\n\n    result = job.add_tag(context, id=id, name=name)\n    utils.format_output(result, context.format)", "response": "Add a tag to a\n   "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef delete_tag(context, id, tag_id):\n\n    result = job.delete_tag(context, id=id, tag_id=tag_id)\n    if result.status_code == 204:\n        utils.print_json({'id': id, 'message': 'Tag removed.'})\n    else:\n        utils.format_output(result, context.format)", "response": "Delete a tag from a node."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlist all tags of a job", "response": "def list_tags(context, id):\n    \"\"\"list_tags(context, id)\n\n    List all tags of a job.\n\n    >>> dcictl job-list-tags [OPTIONS]\n\n    :param string id: ID of the job to retrieve tags from [required]\n    \"\"\"\n\n    result = job.list_tags(context, id)\n    utils.format_output(result, context.format)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndownloads a file from the specified file_id to the specified path", "response": "def file_download(context, id, file_id, target):\n    \"\"\"file_download(context, id, path)\n\n    Download a job file\n\n    >>> dcictl job-download-file [OPTIONS]\n\n    :param string id: ID of the job to download file [required]\n    :param string file_id: ID of the job file to download [required]\n    :param string target: Destination file [required]\n    \"\"\"\n    dci_file.download(context, id=id, file_id=file_id, target=target)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nshowing a file in a bunch of work items", "response": "def file_show(context, id, file_id):\n    \"\"\"file_show(context, id, path)\n\n    Show a job file\n\n    >>> dcictl job-show-file [OPTIONS]\n\n    :param string id: ID of the component to show files [required]\n    :param string file_id: ID of the file to show up [required]\n    \"\"\"\n    result = dci_file.get(context, id=file_id)\n    utils.format_output(result, context.format)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndeletes a file in the", "response": "def file_delete(context, id, file_id):\n    \"\"\"file_delete(context, id, path)\n\n    Delete a job file\n\n    >>> dcictl job-delete-file [OPTIONS]\n\n    :param string id: ID of the job to delete file [required]\n    :param string file_id: ID for the file to delete [required]\n    \"\"\"\n    dci_file.delete(context, id=file_id)\n    result = dci_file.delete(context, id=file_id)\n    utils.format_output(result, context.format)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef authenticate(self, password):\n        user = None\n\n        try:\n            self._authenticate_user_dn(password)\n            self._check_requirements()\n            self._get_or_create_user()\n\n            user = self._user\n        except self.AuthenticationFailed as e:\n            logger.debug(u\"Authentication failed for %s: %s\" % (self._username, e))\n        except ldap.LDAPError as e:\n            results = ldap_error.send(self.backend.__class__,\n                                      context='authenticate', exception=e)\n            if len(results) == 0:\n                logger.warning(u\"Caught LDAPError while authenticating %s: %s\",\n                               self._username, pprint.pformat(e))\n        except Exception:\n            logger.exception(u\"Caught Exception while authenticating %s\",\n                             self._username)\n            raise\n\n        return user", "response": "Authenticates against the LDAP directory and returns the corresponding User object if successful. Returns None on failure."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_group_permissions(self):\n        if self._group_permissions is None:\n            self._group_permissions = set()\n\n            if self.settings.FIND_GROUP_PERMS:\n                try:\n                    self._load_group_permissions()\n                except ldap.LDAPError as e:\n                    results = ldap_error.send(self.backend.__class__,\n                                              context='get_group_permissions',\n                                              exception=e)\n                    if len(results) == 0:\n                        logger.warning(\"Caught LDAPError loading group permissions: %s\",\n                                       pprint.pformat(e))\n\n        return self._group_permissions", "response": "Returns the set of permissions that are allowed by the user s LDAP group memberships."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\npopulate the user object with the default bind credentials.", "response": "def populate_user(self):\n        \"\"\"\n        Populates the Django user object using the default bind credentials.\n        \"\"\"\n        user = None\n\n        try:\n            # self.attrs will only be non-None if we were able to load this user\n            # from the LDAP directory, so this filters out nonexistent users.\n            if self.attrs is not None:\n                self._get_or_create_user(force_populate=True)\n\n            user = self._user\n        except ldap.LDAPError as e:\n            results = ldap_error.send(self.backend.__class__,\n                                      context='populate_user', exception=e)\n            if len(results) == 0:\n                logger.warning(u\"Caught LDAPError while authenticating %s: %s\",\n                               self._username, pprint.pformat(e))\n        except Exception as e:\n            logger.error(u\"Caught Exception while authenticating %s: %s\",\n                         self._username, pprint.pformat(e))\n            logger.error(''.join(traceback.format_tb(sys.exc_info()[2])))\n            raise\n\n        return user"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _check_required_group(self):\n        required_group_dn = self.settings.REQUIRE_GROUP\n\n        if required_group_dn is not None:\n            is_member = self._get_groups().is_member_of(required_group_dn)\n            if not is_member:\n                raise self.AuthenticationFailed(\"user is not a member of AUTH_LDAP_REQUIRE_GROUP\")\n\n        return True", "response": "Checks if the group requirement is met."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_or_create_user(self, force_populate=False):\n        save_user = False\n\n        username = self.backend.ldap_to_django_username(self._username)\n\n        self._user, created = self.backend.get_or_create_user(username, self)\n        self._user.ldap_user = self\n        self._user.ldap_username = self._username\n\n        should_populate = force_populate or self.settings.ALWAYS_UPDATE_USER or created\n\n        if created:\n            logger.debug(\"Created Django user %s\", username)\n            self._user.set_unusable_password()\n            save_user = True\n\n        if should_populate:\n            logger.debug(\"Populating Django user %s\", username)\n            self._populate_user()\n            save_user = True\n\n        if self.settings.MIRROR_GROUPS:\n            self._mirror_groups()\n\n        # Give the client a chance to finish populating the user just before\n        # saving.\n        if should_populate:\n            signal_responses = populate_user.send(self.backend.__class__, user=self._user, ldap_user=self)\n            if len(signal_responses) > 0:\n                save_user = True\n\n        if save_user:\n            self._user.save()\n\n        # We populate the profile after the user model is saved to give the\n        # client a chance to create the profile. Custom user models in Django\n        # 1.5 probably won't have a get_profile method.\n        if should_populate and self._should_populate_profile():\n            self._populate_and_save_user_profile()", "response": "Loads the User model object from the database or creates it if it doesn t exist."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _populate_user(self):\n        self._populate_user_from_attributes()\n        self._populate_user_from_group_memberships()\n        self._populate_user_from_dn_regex()\n        self._populate_user_from_dn_regex_negation()", "response": "Populates our User object with information from the LDAP directory."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\npopulate the user object with the values from the LDAP profile flags from AUTH_LDAP_PROFILE_FLAGS_BY_DN_REGEX.", "response": "def _populate_user_from_dn_regex(self):\n        \"\"\"\n        Populate the given profile object flags from AUTH_LDAP_PROFILE_FLAGS_BY_DN_REGEX.\n        Returns True if the profile was modified\n        \"\"\"\n        for field, regex in self.settings.USER_FLAGS_BY_DN_REGEX.items():\n            field_value = False\n            if re.search(regex, self._get_user_dn(), re.IGNORECASE):\n                field_value = True\n            setattr(self._user, field, field_value)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _populate_user_from_dn_regex_negation(self):\n        for field, regex in self.settings.USER_FLAGS_BY_DN_REGEX_NEGATION.items():\n            field_value = True\n            if re.search(regex, self._get_user_dn(), re.IGNORECASE):\n                field_value = False\n            setattr(self._user, field, field_value)", "response": "Populate the user object with the values from LDAP_PROFILE_FLAGS_BY_DN_REGEX."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _populate_and_save_user_profile(self):\n        try:\n            app_label, class_name = django.conf.settings.AUTH_PROFILE_MODULE.split('.')\n            profile_model = apps.get_model(app_label, class_name)\n            profile, created = profile_model.objects.get_or_create(user=self._user)\n            save_profile = False\n\n            logger.debug(\"Populating Django user profile for %s\", get_user_username(self._user))\n\n            save_profile = self._populate_profile_from_attributes(profile) or save_profile\n            save_profile = self._populate_profile_flags_from_dn_regex(profile) or save_profile\n            save_profile = self._populate_profile_from_group_memberships(profile) or save_profile\n\n            signal_responses = populate_user_profile.send(self.backend.__class__, profile=profile, ldap_user=self)\n            if len(signal_responses) > 0:\n                save_profile = True\n\n            if save_profile:\n                profile.save()\n        except ObjectDoesNotExist:\n            logger.debug(\"Django user %s does not have a profile to populate\", get_user_username(self._user))\n        except LookupError:\n            logger.debug('User Profile model defined in settings.AUTH_PROFILE_MODULE is invalid')", "response": "Populates a User profile object with fields from the LDAP directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\npopulates the given profile object from AUTH_LDAP_PROFILE_ATTR_MAP.", "response": "def _populate_profile_from_attributes(self, profile):\n        \"\"\"\n        Populate the given profile object from AUTH_LDAP_PROFILE_ATTR_MAP.\n        Returns True if the profile was modified.\n        \"\"\"\n        save_profile = False\n\n        for field, attr in self.settings.PROFILE_ATTR_MAP.items():\n            try:\n                # user_attrs is a hash of lists of attribute values\n                setattr(profile, field, self.attrs[attr][0])\n                save_profile = True\n            except Exception:\n                logger.warning(\"%s does not have a value for the attribute %s\", self.dn, attr)\n\n        return save_profile"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _populate_profile_flags_from_dn_regex(self, profile):\n        save_profile = True\n        for field, regex in self.settings.PROFILE_FLAGS_BY_DN_REGEX.items():\n            field_value = False\n            if re.search(regex, self._get_user_dn(), re.IGNORECASE):\n                field_value = True\n            setattr(profile, field, field_value)\n            save_profile = True\n\n        return save_profile", "response": "Populate the given profile object flags from AUTH_LDAP_PROFILE_FLAGS_BY_DN_REGEX."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _populate_profile_from_group_memberships(self, profile):\n        save_profile = False\n\n        for field, group_dns in self.settings.PROFILE_FLAGS_BY_GROUP.items():\n            if isinstance(group_dns, six.string_types):\n                group_dns = [group_dns]\n            value = any(self._get_groups().is_member_of(dn) for dn in group_dns)\n            setattr(profile, field, value)\n            save_profile = True\n\n        return save_profile", "response": "Populate the given profile object from AUTH_LDAP_PROFILE_FLAGS_BY_GROUP. Returns True if the profile was modified."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _mirror_groups(self):\n        target_group_names = frozenset(self._get_groups().get_group_names())\n        current_group_names = frozenset(self._user.groups.values_list('name', flat=True).iterator())\n\n        if target_group_names != current_group_names:\n            existing_groups = list(Group.objects.filter(name__in=target_group_names).iterator())\n            existing_group_names = frozenset(group.name for group in existing_groups)\n\n            new_groups = [Group.objects.get_or_create(name=name)[0] for name\n                          in target_group_names if name not in existing_group_names]\n\n            self._user.groups = existing_groups + new_groups", "response": "Mirrors the LDAP groups in the Django database and updates the user s membership."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading the group permissions for the LDAP group.", "response": "def _load_group_permissions(self):\n        \"\"\"\n        Populates self._group_permissions based on LDAP group membership and\n        Django group permissions.\n        \"\"\"\n        group_names = self._get_groups().get_group_names()\n\n        perms = Permission.objects.filter(group__name__in=group_names)\n        perms = perms.values_list('content_type__app_label', 'codename')\n        perms = perms.order_by()\n\n        self._group_permissions = set([\"%s.%s\" % (ct, name) for ct, name in perms])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_connection(self):\n        if self._connection is None:\n            uri = self.settings.SERVER_URI\n            if callable(uri):\n                uri = uri()\n\n            self._connection = self.backend.ldap.initialize(uri)\n\n            for opt, value in self.settings.CONNECTION_OPTIONS.items():\n                self._connection.set_option(opt, value)\n\n            if self.settings.START_TLS:\n                logger.debug(\"Initiating TLS\")\n                self._connection.start_tls_s()\n\n        return self._connection", "response": "Returns our LDAPObject which may or may not be bound."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_group_dns(self):\n        if self._group_dns is None:\n            group_infos = self._get_group_infos()\n            self._group_dns = set(group_info[0] for group_info in group_infos)\n\n        return self._group_dns", "response": "Returns a set of the distinguished names in the group."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the key for the cache entry for the given attribute name.", "response": "def _cache_key(self, attr_name):\n        \"\"\"\n        Memcache keys can't have spaces in them, so we'll remove them from the\n        DN for maximum compatibility.\n        \"\"\"\n        dn = self._ldap_user.dn.replace(' ', '%20')\n        key = u'auth_ldap.%s.%s.%s' % (self.__class__.__name__, attr_name, dn)\n\n        return key"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_task_id(self):\r\n        task_id = self.json_response.get(\"task_id\", None)\r\n        self.logger.info(\"%s\\t%s\" % (self.request_method, self.request_url))\r\n        return task_id", "response": "Method to get all department members."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_send_result(self):\r\n        send_result = self.json_response.get(\"send_result\", None)\r\n        self.logger.info(\"%s\\t%s\" % (self.request_method, self.request_url))\r\n        return send_result", "response": "Method to get the progress of work notice sending."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_read_user_ids(self):\r\n        read_user_ids = self.json_response.get(\"readUserIdList\", None)\r\n        self.logger.info(\"%s\\t%s\" % (self.request_method, self.request_url))\r\n        return read_user_ids", "response": "Method to get chatid of group created."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef __type2js(cls, value):\n        if value is None:\n            return 'null'\n        elif isinstance(value, bool):\n            return 'false' if not value else 'true'\n        elif isinstance(value, (int, float)):\n            return '%s' % value\n        elif isinstance(value, dict):\n            return json.dumps(dict)\n        return '\"%s\"' % value", "response": "Converts python value by type to executable javascript value by type."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert javascript value by type.", "response": "def __type2python(cls, value):\n        \"\"\"\n        :Description: Convert javascript value to python value by type.\n        :param value: Value to transform.\n        :type value: None, bool, int, float, string\n        :return: None, bool, int, float, string\n        \"\"\"\n        if isinstance(value, string_types):\n            if value is 'null':\n                return None\n            elif value in ('true', 'false'):\n                return False if value == 'false' else True\n            elif value.replace('.', '', 1).isdigit():\n                return eval(value)\n            elif value.startswith('{') and value.endswidth('}'):\n                try:\n                    return json.loads(value)\n                except ValueError:\n                    return value\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef wait(self, condition, interval, *args):\n        hid = lambda: '$' + str(uuid.uuid1())[:8]\n        handle = hid()\n        if len(args):\n            element_handle = hid()\n            self.browser.execute_script(\n                'window[\"{}\"] = [];'.format(element_handle)\n            )  # create element container in window scope\n            for el in args:\n                if isinstance(el, string_types):\n                    # assume selector\n                    self.browser.execute_script('window[\"{}\"].push({});'.format(\n                        element_handle, 'function() { return document.querySelector(\"%s\") }' % el))\n                else:\n                    # assume web element\n                    self.browser.execute_script(\n                        'window[\"{}\"].push(arguments[0]);'.format(element_handle), el)\n            if len(args) == 1:\n                condition = condition.replace('$el', 'window[\"{}\"][0]{}'.format(\n                    element_handle, '()' if isinstance(args[0], string_types) else ''))\n            else:\n                regex = r'(\\$el\\[([0-9]{0,3})\\])'\n                results = re.findall(regex, condition)  # [('$el[0]', '0'), ('$el[1]', '1'), ...]\n                for result in results:\n                    pos = eval(result[1])\n                    if pos + 1 <= len(args):\n                        condition = condition.replace(result[0], 'window[\"{}\"][{}]{}'.format(\n                            element_handle, pos, '()' if isinstance(args[pos], string_types) else ''))\n\n            self.browser.execute_script(\n                'window[\"%s\"]=window.setInterval(function(){if(%s){ \\\n                (window.clearInterval(window[\"%s\"])||true)&&(window[\"%s\"]=-1); \\\n                delete window[\"%s\"];}}, %s)' % (handle, condition, handle, handle, \\\n                element_handle, interval))  # create interval\n        else:\n            self.browser.execute_script(\n                'window[\"%s\"]=window.setInterval(function(){if(%s){ \\\n                (window.clearInterval(window[\"%s\"])||true)&&(window[\"%s\"]=-1);}}, %s)' % (\n                handle, condition, handle, handle, interval))  # create interval\n\n        return handle", "response": "This method will create an interval in vm. window and will clear the interval after condition met."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_attribute(self, element, attribute, convert_type=True):\n        attribute = self.browser.execute_script(\n            'return arguments[0].getAttribute(\"%s\");' % attribute, element)\n\n        return self.__type2python(attribute) if convert_type else attribute", "response": "This method returns the given attribute of the given element."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_attribute(self, element, attribute, value):\n        self.browser.execute_script('arguments[0].setAttribute(\"%s\", %s);' % (\n            attribute, self.__type2js(value=value)), element)", "response": "Modify the given attribute of the given element."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmodifies the given property of the given element.", "response": "def set_property(self, element, prop, value):\n        \"\"\"\n        :Description: Modify the given attribute of the target element.\n        :param element: Element for browser instance to target.\n        :type element: WebElement\n        :param prop: Property of target element to modify.\n        :type prop: string\n        :param value: Value of target element's property to modify.\n        :type value: None, bool, int float, string\n        \"\"\"\n        self.browser.execute_script(\n            'arguments[0][\"%s\"] = %s' % (prop, self.__type2js(value=value)), element)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef trigger_event(self, element, event, event_type=None, options=None):\n        if not isinstance(element, (tuple, list)):\n            element = [element]\n        if not isinstance(event, (tuple, list)):\n            event = [event]\n        for el in element:\n            for e in event:\n                self.browser.execute_script(\n                    'e = new %s(\"%s\"); ops = %s; if (ops) {for(key in ops) { \\\n                        Object.defineProperty(e, key, { value: ops[key], configurable: true }) \\\n                    }} arguments[0].dispatchEvent(e)' % (\n                        event_type if event_type else 'Event',\n                        e, json.dumps(options) if options else 'undefined'\n                    ), el)", "response": "Trigger specified event of the given element."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntransforms javascript dot notation to bracket notation.", "response": "def __d2b_notation(prop):\n        \"\"\"\n        :Description: Transform javascript dot notation to bracket notation.\n        :param prop: Property to transform.\n        :type prop: string\n        :example: 'messages.total' >> someObject['messages']['total']\n        :return: string\n        \"\"\"\n        results = re.compile('[[$a-zA-Z]{0,}.').findall(prop)\n        for i in range(0, len(results)):\n            results[i] = (\"['%s']\" % results[i]).replace('.', '')\n        return ''.join(results)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ng_call_ctrl_function(self, element, func, params='', return_out=False):\n        if isinstance(params, string_types):\n            param_str = params\n        elif isinstance(params, (tuple, list)):\n            param_str = self.__serialize_params(params)\n        else:\n            raise ValueError('Invalid type specified for function parameters')\n        exec_str = 'angular.element(arguments[0]).controller().%s(%s);' % (func, param_str)\n        if return_out:\n            return self.__type2python(\n                self.browser.execute_script('return {}'.format(exec_str), element))\n        else:\n            self.browser.execute_script(exec_str, element)", "response": "This will execute a controller function with provided parameters."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ng2_get_component_property(self, element, prop):\n        return self.browser.execute_script(\n            'return ng.probe(arguments[0]).componentInstance%s;' % self.__d2b_notation(prop=prop),\n            element)", "response": "This method will get value of property of element s component instance."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef change_dir(directory):\n  def cd_decorator(func):\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n      org_path = os.getcwd()\n      os.chdir(directory)\n      func(*args, **kwargs)\n      os.chdir(org_path)\n    return wrapper\n  return cd_decorator", "response": "Decorator to change the working directory of a function."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbuilds CSS from SASS.", "response": "def build_css(minimize=True):\n  \"\"\"\n  Builds CSS from SASS.\n\n  \"\"\"\n  print('Build CSS')\n  args = {}\n  args['style'] = 'compressed' if minimize else 'nested'\n  cmd = CMD_SASS.format(**args)\n  run(cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef profile(func):\n    def _f(*args, **kwargs):\n        print(\"\\n<<<---\")\n        pr = cProfile.Profile()\n        pr.enable()\n        res = func(*args, **kwargs)\n        p = pstats.Stats(pr)\n        p.strip_dirs().sort_stats('cumtime').print_stats(20)\n        print(\"\\n--->>>\")\n        return res\n    return _f", "response": "Decorator for cProfile. Profile"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef total_size(obj, verbose=False):\n    seen = set()\n\n    def sizeof(o):\n        if id(o) in seen:\n            return 0\n        seen.add(id(o))\n        s = sys.getsizeof(o, default=0)\n        if verbose:\n            print(s, type(o), repr(o))\n        if isinstance(o, (tuple, list, set, frozenset, deque)):\n            s += sum(map(sizeof, iter(o)))\n        elif isinstance(o, dict):\n            s += sum(map(sizeof, chain.from_iterable(o.items())))\n        elif \"__dict__\" in dir(o):\n            s += sum(map(sizeof, chain.from_iterable(o.__dict__.items())))\n        return s\n\n    return sizeof(obj)", "response": "Returns approximate memory size of an object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef try_opening_file(self):\n        '''Try to open the input file'''\n        if os.path.isfile(self.path):\n            self.file = open(self.path, 'r')\n            self.file_is_opened = True", "response": "Try to open the input file if it is not already opened."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninserts HTML theme configurations.", "response": "def _insert_html_configs(c, *, project_name, short_project_name):\n    \"\"\"Insert HTML theme configurations.\n    \"\"\"\n    # Use the lsst-sphinx-bootstrap-theme\n    c['templates_path'] = [\n        '_templates',\n        lsst_sphinx_bootstrap_theme.get_html_templates_path()]\n    c['html_theme'] = 'lsst_sphinx_bootstrap_theme'\n    c['html_theme_path'] = [lsst_sphinx_bootstrap_theme.get_html_theme_path()]\n\n    # Theme options are theme-specific and customize the look and feel of a\n    # theme further.  For a list of options available for each theme, see the\n    # documentation.\n    c['html_theme_options'] = {'logotext': short_project_name}\n\n    # The name for this set of Sphinx documents.  If None, it defaults to\n    # \"<project> v<release> documentation\".\n    c['html_title'] = project_name\n\n    # A shorter title for the navigation bar.  Default is the same as\n    # html_title.\n    c['html_short_title'] = short_project_name\n\n    # The name of an image file (relative to this directory) to place at the\n    # top of the sidebar.\n    c['html_logo'] = None\n\n    # The name of an image file (within the static path) to use as favicon of\n    # the docs.  This file should be a Windows icon file (.ico) being 16x16 or\n    # 32x32 pixels large.\n    c['html_favicon'] = None\n\n    # Add any paths that contain custom static files (such as style sheets)\n    # here, relative to this directory. They are copied after the builtin\n    # static files, so a file named \"default.css\" will overwrite the builtin\n    # \"default.css\".\n    if os.path.isdir('_static'):\n        c['html_static_path'] = ['_static']\n    else:\n        # If a project does not have a _static/ directory, don't list it\n        # so that there isn't a warning.\n        c['html_static_path'] = []\n\n    # Add any extra paths that contain custom files (such as robots.txt or\n    # .htaccess) here, relative to this directory. These files are copied\n    # directly to the root of the documentation.\n    # html_extra_path = []\n\n    # If not '', a 'Last updated on:' timestamp is inserted at every page\n    # bottom, using the given strftime format.\n    c['html_last_updated_fmt'] = '%b %d, %Y'\n\n    # If true, SmartyPants will be used to convert quotes and dashes to\n    # typographically correct entities.\n    c['html_use_smartypants'] = True\n\n    # If false, no module index is generated.\n    c['html_domain_indices'] = False\n\n    # If false, no index is generated.\n    c['html_use_index'] = False\n\n    # If true, the index is split into individual pages for each letter.\n    c['html_split_index'] = False\n\n    # If true, links to the reST sources are added to the pages.\n    c['html_show_sourcelink'] = True\n\n    # If true, \"Created using Sphinx\" is shown in the HTML footer. Default is\n    # True.\n    c['html_show_sphinx'] = True\n\n    # If true, \"(C) Copyright ...\" is shown in the HTML footer. Default is\n    # True.\n    c['html_show_copyright'] = True\n\n    # If true, an OpenSearch description file will be output, and all pages\n    # will contain a <link> tag referring to it.  The value of this option must\n    # be the base URL from which the finished HTML is served.\n    # html_use_opensearch = ''\n\n    # This is the file name suffix for HTML files (e.g. \".xhtml\").\n    c['html_file_suffix'] = '.html'\n\n    # Language to be used for generating the HTML full-text search index.\n    c['html_search_language'] = 'en'\n\n    # A dictionary with options for the search language support, empty by\n    # default.  Now only 'ja' uses this config value\n    # html_search_options = {'type': 'default'}\n\n    # The name of a javascript file (relative to the configuration directory)\n    # that implements a search results scorer. If empty, the default will be\n    # used.\n    # html_search_scorer = 'scorer.js'\n\n    return c"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding common Sphinx configurations to the state.", "response": "def _insert_common_sphinx_configs(c, *, project_name):\n    \"\"\"Add common core Sphinx configurations to the state.\n    \"\"\"\n    c['project'] = project_name\n\n    # The suffix(es) of source filenames.\n    # You can specify multiple suffix as a list of string:\n    c['source_suffix'] = '.rst'\n\n    # The encoding of source files.\n    c['source_encoding'] = 'utf-8-sig'\n\n    # The master toctree document.\n    c['master_doc'] = 'index'\n\n    # Configure figure numbering\n    c['numfig'] = True\n    c['numfig_format'] = {'figure': 'Figure %s',\n                          'table': 'Table %s',\n                          'code-block': 'Listing %s'}\n\n    # The reST default role (used for this markup: `text`)\n    c['default_role'] = 'obj'\n\n    # This is added to the end of RST files - a good place to put substitutions\n    # to be used globally.\n    c['rst_epilog'] = \"\"\"\n.. _Astropy: http://astropy.org\n    \"\"\"\n\n    # A list of warning types to suppress arbitrary warning messages. We mean\n    # to override directives in\n    # astropy_helpers.sphinx.ext.autodoc_enhancements, thus need to ignore\n    # those warning. This can be removed once the patch gets released in\n    # upstream Sphinx (https://github.com/sphinx-doc/sphinx/pull/1843).\n    # Suppress the warnings requires Sphinx v1.4.2\n    c['suppress_warnings'] = ['app.add_directive', ]\n\n    return c"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninserts breathe extension configurations into the state.", "response": "def _insert_breathe_configs(c, *, project_name, doxygen_xml_dirname):\n    \"\"\"Add breathe extension configurations to the state.\n    \"\"\"\n    if doxygen_xml_dirname is not None:\n        c['breathe_projects'] = {project_name: doxygen_xml_dirname}\n        c['breathe_default_project'] = project_name\n    return c"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninserts configuration related to automodapi autodoc numpydoc.", "response": "def _insert_automodapi_configs(c):\n    \"\"\"Add configurations related to automodapi, autodoc, and numpydoc to the\n    state.\n    \"\"\"\n    # Don't show summaries of the members in each class along with the\n    # class' docstring\n    c['numpydoc_show_class_members'] = False\n\n    c['autosummary_generate'] = True\n\n    c['automodapi_toctreedirnm'] = 'py-api'\n    c['automodsumm_inherited_members'] = True\n\n    # Docstrings for classes and methods are inherited from parents.\n    c['autodoc_inherit_docstrings'] = True\n\n    # Class documentation should only contain the class docstring and\n    # ignore the __init__ docstring, account to LSST coding standards.\n    # c['autoclass_content'] = \"both\"\n    c['autoclass_content'] = \"class\"\n\n    # Default flags for automodapi directives. Special members are dunder\n    # methods.\n    # NOTE: We want to used `inherited-members`, but it seems to be causing\n    # documentation duplication in the automodapi listings. We're leaving\n    # this out for now. See https://jira.lsstcorp.org/browse/DM-14782 for\n    # additional notes.\n    # NOTE: Without inherited members set, special-members doesn't need seem\n    # to have an effect (even for special members where the docstrings are\n    # directly written in the class, not inherited.\n    # c['autodoc_default_flags'] = ['inherited-members']\n    c['autodoc_default_flags'] = ['show-inheritance',\n                                  'special-members']\n\n    return c"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _insert_matplotlib_configs(c):\n    if 'extensions' not in c:\n        c['extensions'] = []\n\n    try:\n        import matplotlib.sphinxext.plot_directive\n        c['extensions'] += [matplotlib.sphinxext.plot_directive.__name__]\n    except (ImportError, AttributeError):\n        # AttributeError is checked here in case matplotlib is installed but\n        # Sphinx isn't.  Note that this module is imported by the config file\n        # generator, even if we're not building the docs.\n        warnings.warn(\n            \"matplotlib's plot_directive could not be imported. \"\n            \"Inline plots will not be included in the output.\")\n\n    return c", "response": "Add configurations related to matplotlib s plot directive to the state."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _insert_single_package_eups_version(c, eups_version):\n    c['release_eups_tag'] = 'current'\n    c['release_git_ref'] = 'master'\n    c['version'] = eups_version\n    c['release'] = eups_version\n    c['scipipe_conda_ref'] = 'master'\n    c['pipelines_demo_ref'] = 'master'\n    c['newinstall_ref'] = 'master'\n    return c", "response": "Insert version information into the configuration namespace."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _insert_eups_version(c):\n    # Attempt to get the eups tag from the build environment\n    eups_tag = os.getenv('EUPS_TAG')\n    if eups_tag is None:\n        eups_tag = 'd_latest'\n\n    # Try to guess the git ref that corresponds to this tag\n    if eups_tag in ('d_latest', 'w_latest', 'current'):\n        git_ref = 'master'\n    elif eups_tag.startswith('d_'):\n        # Daily EUPS tags are not tagged on git\n        git_ref = 'master'\n    elif eups_tag.startswith('v'):\n        # Major version or release candidate tag\n        git_ref = eups_tag.lstrip('v').replace('_', '.')\n    elif eups_tag.startswith('w_'):\n        # Regular weekly tag\n        git_ref = eups_tag.replace('_', '.')\n    else:\n        # Ideally shouldn't get to this point\n        git_ref = 'master'\n\n    # Now set variables for the Jinja context\n    c['release_eups_tag'] = eups_tag\n    c['release_git_ref'] = git_ref\n    c['version'] = eups_tag\n    c['release'] = eups_tag\n    c['scipipe_conda_ref'] = git_ref\n    c['pipelines_demo_ref'] = git_ref\n    c['newinstall_ref'] = git_ref\n\n    return c", "response": "Insert information about the current EUPS tag into the configuration\n    namespace."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef build_package_configs(project_name,\n                          version=None,\n                          copyright=None,\n                          doxygen_xml_dirname=None):\n    \"\"\"Builds a `dict` of Sphinx configurations useful for the ``doc/conf.py``\n    files of individual LSST Stack packages.\n\n    The ``doc/conf.py`` of packages can ingest these configurations via::\n\n       from documenteer.sphinxconfig.stackconf import build_package_configs\n\n       _g = globals()\n       _g.update(build_package_configs(\n           project_name='afw',\n           version=lsst.afw.version.__version__))\n\n    You can subsequently customize the Sphinx configuration by directly\n    assigning global variables, as usual in a Sphinx ``config.py``, e.g.:\n\n    .. code:: python\n\n       copyright = '2016 Association of Universities for '\n                   'Research in Astronomy, Inc.'\n\n    Parameters\n    ----------\n    project_name : str\n        Name of the package.\n    copyright : str, optional\n        Copyright statement. Do not include the 'Copyright (c)' string; it'll\n        be added automatically.\n    version : str\n        Version string. Use the ``__version__`` member in a package's\n        ``version`` module.\n    doxygen_xml_dirname : str\n        Path to doxygen-generated XML, allowing C++ APIs to be documented\n        through breathe. If not set, the breathe sphinx extension will not be\n        enabled.\n\n    Returns\n    -------\n    c : dict\n        Dictionary of configurations that should be added to the ``conf.py``\n        global namespace via::\n\n            _g = global()\n            _g.update(c)\n    \"\"\"\n    c = {}\n\n    c = _insert_common_sphinx_configs(\n        c,\n        project_name=project_name)\n\n    # HTML theme\n    c = _insert_html_configs(\n        c,\n        project_name=project_name,\n        short_project_name=project_name)\n\n    # Sphinx extension modules\n    c = _insert_extensions(c)\n\n    # Intersphinx configuration\n    c = _insert_intersphinx_mapping(c)\n\n    # Breathe extension configuration\n    c = _insert_breathe_configs(\n        c,\n        project_name=project_name,\n        doxygen_xml_dirname=doxygen_xml_dirname)\n\n    # Automodapi and numpydoc configurations\n    c = _insert_automodapi_configs(c)\n\n    # Matplotlib configurations\n    c = _insert_matplotlib_configs(c)\n\n    # Graphviz configurations\n    c = _insert_graphviz_configs(c)\n\n    # Add versioning information\n    c = _insert_single_package_eups_version(c, version)\n\n    try:\n        date = read_git_commit_timestamp()\n    except Exception:\n        date = datetime.datetime.now()\n\n    if copyright is not None:\n        c['copyright'] = copyright\n    else:\n        c['copyright'] = '{:s} LSST contributors'.format(\n            date.strftime('%Y'))\n\n    c['today'] = date.strftime('%Y-%m-%d')\n\n    # List of patterns, relative to source directory, that match files and\n    # directories to ignore when looking for source files.\n    c['exclude_patterns'] = [\n        '_build',\n        'README.rst',\n    ]\n\n    # Show rendered todo directives in package docs since they're developer\n    # facing.\n    c['todo_include_todos'] = True\n\n    # Insert rst_epilog configuration\n    c = _insert_rst_epilog(c)\n\n    # Set up the context for the sphinx-jinja extension\n    c = _insert_jinja_configuration(c)\n\n    return c", "response": "Builds a dict of Sphinx configuration files useful for the documentation of the LSST Stack packages."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef build_pipelines_lsst_io_configs(*, project_name, copyright=None):\n    # Work around Sphinx bug related to large and highly-nested source files\n    sys.setrecursionlimit(2000)\n\n    c = {}\n\n    c = _insert_common_sphinx_configs(\n        c,\n        project_name=project_name)\n\n    # HTML theme\n    c = _insert_html_configs(\n        c,\n        project_name=project_name,\n        short_project_name=project_name)\n\n    # Sphinx extension modules\n    c = _insert_extensions(c)\n\n    # Intersphinx configuration\n    c = _insert_intersphinx_mapping(c)\n\n    # Breathe extension configuration\n    # FIXME configure this for multiple sites\n\n    # Automodapi and numpydoc configurations\n    c = _insert_automodapi_configs(c)\n\n    # Matplotlib configurations\n    c = _insert_matplotlib_configs(c)\n\n    # Graphviz configurations\n    c = _insert_graphviz_configs(c)\n\n    # Add versioning information\n    c = _insert_eups_version(c)\n\n    # Always use \"now\" as the date for the main site's docs because we can't\n    # look at the Git history of each stack package.\n    date = datetime.datetime.now()\n    c['today'] = date.strftime('%Y-%m-%d')\n\n    # Use this copyright for now. Ultimately we want to gather COPYRIGHT files\n    # and build an integrated copyright that way.\n    c['copyright'] = '2015-{year} LSST contributors'.format(\n        year=date.year)\n\n    # Hide todo directives in the \"published\" documentation on the main site.\n    c['todo_include_todos'] = False\n\n    # List of patterns, relative to source directory, that match files and\n    # directories to ignore when looking for source files.\n    c['exclude_patterns'] = [\n        'README.rst',\n        # Build products\n        '_build',\n        # Source for release notes (contents are included in built pages)\n        'releases/note-source/*.rst',\n        'releases/tickets-source/*.rst',\n        # EUPS configuration directory\n        'ups',\n        # Recommended directory for pip installing doc eng Python packages\n        '.pyvenv',\n        # GitHub templates\n        '.github',\n        # This 'home' directory is created by the docubase image for the\n        # sqre/infra/documenteer ci.lsst.codes Jenkins job. Ideally this\n        # shouldn't be in the directory at all, but we certainly need to\n        # ignore it while its here.\n        'home',\n    ]\n\n    # Insert rst_epilog configuration\n    c = _insert_rst_epilog(c)\n\n    # Set up the context for the sphinx-jinja extension\n    c = _insert_jinja_configuration(c)\n\n    return c", "response": "Build a dict of Sphinx configurations that populate the conf. py file for LSST Science Pipelines."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nclose all connections and terminate the connection.", "response": "async def cleanup(self, app):\n        \"\"\"Close self connections.\"\"\"\n        self.conn.close()\n        if self.pubsub_conn:\n            self.pubsub_reader.cancel()\n            self.pubsub_conn.close()\n        # give connections a chance to actually terminate\n        # TODO: use better method once it will be added,\n        # see https://github.com/jonathanslenders/asyncio-redis/issues/56\n        await asyncio.sleep(0)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstores the given value into Redis.", "response": "def set(self, key, value, *args, **kwargs):\n        \"\"\"Store the given value into Redis.\n\n        :returns: a coroutine\n        \"\"\"\n        if self.cfg.jsonpickle:\n            value = jsonpickle.encode(value)\n        return self.conn.set(key, value, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef publish(self, channel, message):\n        if self.cfg.jsonpickle:\n            message = jsonpickle.encode(message)\n        return self.conn.publish(channel, message)", "response": "Publish a message to a channel."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef start_subscribe(self):\n        if not self.conn:\n            raise ValueError('Not connected')\n        elif not self.pubsub_conn:\n            raise ValueError('PubSub not enabled')\n\n        # creates a new context manager\n        return Subscription(self)", "response": "Create a new Subscription context manager."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def _subscribe(self, channels, is_mask):\n        news = []\n        for channel in channels:\n            key = channel, is_mask\n            self._channels.append(key)\n            if key in self._plugin._subscriptions:\n                self._plugin._subscriptions[key].append(self._queue)\n            else:\n                self._plugin._subscriptions[key] = [self._queue]\n                news.append(channel)\n        if news:\n            await getattr(self._sub, 'psubscribe' if is_mask else 'subscribe')(news)", "response": "Subscribe to given channels."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def _unsubscribe(self, channels, is_mask):\n        vanished = []\n        if channels:\n            for channel in channels:\n                key = channel, is_mask\n                self._channels.remove(key)\n                self._plugin._subscriptions[key].remove(self._queue)\n                if not self._plugin._subscriptions[key]:  # we were last sub?\n                    vanished.append(channel)\n                    del self._plugin._subscriptions[key]\n        else:\n            while self._channels:\n                channel, is_mask = key = self._channels.pop()\n                self._plugin._subscriptions[key].remove(self._queue)\n                if not self._plugin._subscriptions[key]:\n                    vanished.append(channel)\n                    del self._plugin._subscriptions[key]\n        if vanished:\n            await getattr(self._sub, 'punsubscribe' if is_mask else 'unsubscribe')(vanished)", "response": "Unsubscribe from given channel."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting a 0 based coordinate to an excel address", "response": "def _to_addr(worksheet, row, col, row_fixed=False, col_fixed=False):\n    \"\"\"converts a (0,0) based coordinate to an excel address\"\"\"\n    addr = \"\"\n    A = ord('A')\n    col += 1\n    while col > 0:\n        addr = chr(A + ((col - 1) % 26)) + addr\n        col = (col - 1) // 26\n\n    prefix = (\"'%s'!\" % worksheet) if worksheet else \"\"\n    col_modifier = \"$\" if col_fixed else \"\"\n    row_modifier = \"$\" if row_fixed else \"\"\n    return prefix + \"%s%s%s%d\" % (col_modifier, addr, row_modifier, row+1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef value(self):\n        try:\n            if isinstance(self.__value, Expression):\n                return self.__value.value\n            return self.__value\n        except AttributeError:\n            return 0", "response": "Set a calculated value for this Expression."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns True if value has been set", "response": "def has_value(self):\n        \"\"\"return True if value has been set\"\"\"\n        try:\n            if isinstance(self.__value, Expression):\n                return self.__value.has_value\n            return True\n        except AttributeError:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncopies source file to destination file.", "response": "def copy(source, destination, ignore=None, adapter=None, fatal=True, logger=LOG.debug):\n    \"\"\"Copy source -> destination\n\n    Args:\n        source (str | None): Source file or folder\n        destination (str | None): Destination file or folder\n        ignore (callable | list | str | None): Names to be ignored\n        adapter (callable | None): Optional function to call on 'source' before copy\n        fatal (bool | None): Abort execution on failure if True\n        logger (callable | None): Logger to use\n\n    Returns:\n        (int): 1 if effectively done, 0 if no-op, -1 on failure\n    \"\"\"\n    return _file_op(source, destination, _copy, adapter, fatal, logger, ignore=ignore)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndeletes a node from the tree.", "response": "def delete(path, fatal=True, logger=LOG.debug):\n    \"\"\"\n    :param str|None path: Path to file or folder to delete\n    :param bool|None fatal: Abort execution on failure if True\n    :param callable|None logger: Logger to use\n    :return int: 1 if effectively done, 0 if no-op, -1 on failure\n    \"\"\"\n    islink = path and os.path.islink(path)\n    if not islink and (not path or not os.path.exists(path)):\n        return 0\n\n    if is_dryrun():\n        LOG.debug(\"Would delete %s\", short(path))\n        return 1\n\n    if logger:\n        logger(\"Deleting %s\", short(path))\n\n    try:\n        if islink or os.path.isfile(path):\n            os.unlink(path)\n        else:\n            shutil.rmtree(path)\n        return 1\n\n    except Exception as e:\n        return abort(\"Can't delete %s: %s\", short(path), e, fatal=(fatal, -1))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn first line of file", "response": "def first_line(path):\n    \"\"\"\n    :param str|None path: Path to file\n    :return str|None: First line of file, if any\n    \"\"\"\n    try:\n        with io.open(path, \"rt\", errors=\"ignore\") as fh:\n            return fh.readline().strip()\n\n    except (IOError, TypeError):\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading the configuration file at the specified path.", "response": "def get_conf(path, fatal=True, keep_empty=False, default=None):\n    \"\"\"\n    :param str|list|None path: Path to file, or lines to parse\n    :param bool|None fatal: Abort execution on failure if True\n    :param bool keep_empty: If True, keep definitions with empty values\n    :param dict|list|None default: Object to return if conf couldn't be read\n    :return dict: Dict of section -> key -> value\n    \"\"\"\n    if not path:\n        return default\n\n    lines = path if isinstance(path, list) else get_lines(path, fatal=fatal, default=default)\n\n    result = default\n    if lines is not None:\n        result = {}\n        section_key = None\n        section = None\n        for line in lines:\n            line = decode(line).strip()\n            if \"#\" in line:\n                i = line.index(\"#\")\n                line = line[:i].strip()\n\n            if not line:\n                continue\n\n            if line.startswith(\"[\") and line.endswith(\"]\"):\n                section_key = line.strip(\"[]\").strip()\n                section = result.get(section_key)\n                continue\n\n            if \"=\" not in line:\n                continue\n\n            if section is None:\n                section = result[section_key] = {}\n\n            key, _, value = line.partition(\"=\")\n            key = key.strip()\n            value = value.strip()\n            if keep_empty or (key and value):\n                section[key] = value\n\n        if not keep_empty:\n            result = dict((k, v) for k, v in result.items() if k and v)\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread lines from a file.", "response": "def get_lines(path, max_size=TEXT_THRESHOLD_SIZE, fatal=True, default=None):\n    \"\"\"\n    :param str|None path: Path of text file to return lines from\n    :param int|None max_size: Return contents only for files smaller than 'max_size' bytes\n    :param bool|None fatal: Abort execution on failure if True\n    :param list|None default: Object to return if lines couldn't be read\n    :return list|None: Lines from file contents\n    \"\"\"\n    if not path or not os.path.isfile(path) or (max_size and os.path.getsize(path) > max_size):\n        # Intended for small text files, pretend no contents for binaries\n        return default\n\n    try:\n        with io.open(path, \"rt\", errors=\"ignore\") as fh:\n            return fh.readlines()\n\n    except Exception as e:\n        return abort(\"Can't read %s: %s\", short(path), e, fatal=(fatal, default))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef move(source, destination, adapter=None, fatal=True, logger=LOG.debug):\n    return _file_op(source, destination, _move, adapter, fatal, logger)", "response": "Move source to destination"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a new file in the current working directory.", "response": "def touch(path, fatal=True, logger=None):\n    \"\"\"\n    :param str|None path: Path to file to touch\n    :param bool|None fatal: Abort execution on failure if True\n    :param callable|None logger: Logger to use\n    \"\"\"\n    return write(path, \"\", fatal=fatal, logger=logger)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef write(path, contents, fatal=True, logger=None):\n    if not path:\n        return 0\n\n    if is_dryrun():\n        action = \"write %s bytes to\" % len(contents) if contents else \"touch\"\n        LOG.debug(\"Would %s %s\", action, short(path))\n        return 1\n\n    ensure_folder(path, fatal=fatal, logger=logger)\n    if logger and contents:\n        logger(\"Writing %s bytes to %s\", len(contents), short(path))\n\n    try:\n        with io.open(path, \"wt\") as fh:\n            if contents:\n                fh.write(decode(contents))\n            else:\n                os.utime(path, None)\n        return 1\n\n    except Exception as e:\n        return abort(\"Can't write to %s: %s\", short(path), e, fatal=(fatal, -1))", "response": "Writes the contents of the contents to the file at the specified path."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _file_op(source, destination, func, adapter, fatal, logger, must_exist=True, ignore=None):\n    if not source or not destination or source == destination:\n        return 0\n\n    action = func.__name__[1:]\n    indicator = \"<-\" if action == \"symlink\" else \"->\"\n    psource = parent_folder(source)\n    pdest = resolved_path(destination)\n    if psource != pdest and psource.startswith(pdest):\n        return abort(\n            \"Can't %s %s %s %s: source contained in destination\", action, short(source), indicator, short(destination), fatal=(fatal, -1)\n        )\n\n    if is_dryrun():\n        LOG.debug(\"Would %s %s %s %s\", action, short(source), indicator, short(destination))\n        return 1\n\n    if must_exist and not os.path.exists(source):\n        return abort(\"%s does not exist, can't %s to %s\", short(source), action.title(), short(destination), fatal=(fatal, -1))\n\n    try:\n        # Delete destination, but ensure that its parent folder exists\n        delete(destination, fatal=fatal, logger=None)\n        ensure_folder(destination, fatal=fatal, logger=None)\n\n        if logger:\n            note = adapter(source, destination, fatal=fatal, logger=logger) if adapter else \"\"\n            if logger:\n                logger(\"%s %s %s %s%s\", action.title(), short(source), indicator, short(destination), note)\n\n        if ignore is not None:\n            if callable(ignore):\n                func(source, destination, ignore=ignore)\n\n            else:\n                func(source, destination, ignore=lambda *_: ignore)\n\n        else:\n            func(source, destination)\n\n        return 1\n\n    except Exception as e:\n        return abort(\"Can't %s %s %s %s: %s\", action, short(source), indicator, short(destination), e, fatal=(fatal, -1))", "response": "Internal function to call a function on source and destination files."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload all artists into the database and store them in the database", "response": "def run(self):\n        \"\"\"Load all artists into the database\n        \"\"\"\n\n        df = ArtistsInputData().load()\n\n        # rename columns\n        df.rename(columns={'artistLabel': 'name',\n                           'year_of_birth': 'extra_1',\n                           'genderLabel': 'extra_2'},\n                  inplace=True)\n\n        # columns that exist in the data model\n        columns = ['name', 'wiki_id']\n\n        # the extended model also stores the date of birth and gender, as strings\n        if config.EXTENDED:\n            columns.append('extra_1')\n            columns.append('extra_2')\n            df['extra_1'] = df['extra_1'].astype(str)\n            df['extra_2'] = df['extra_2'].astype(str)\n\n        # keep only columns that exist in the data model\n        df = df[columns]\n\n        # append an ID column\n        df['id'] = range(len(df))\n\n        # store everything, done\n        df.to_sql(name=models.Artist.__tablename__,\n                  con=self.client.engine,\n                  if_exists='append',\n                  index=False)\n\n        self.done()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlist all topics in the", "response": "def list(context, sort, limit, where, verbose):\n    \"\"\"list(context, sort, limit. where. verbose)\n\n    List all topics.\n\n    >>> dcictl topic-list\n\n    :param string sort: Field to apply sort\n    :param integer limit: Max number of rows to return\n    :param string where: An optional filter criteria\n    :param boolean verbose: Display verbose output\n    \"\"\"\n    topics = topic.list(context, sort=sort, limit=limit, where=where)\n    utils.format_output(topics, context.format, verbose=verbose)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate a specific topic in a specific node", "response": "def update(context, id, etag, name, component_types,\n           label, next_topic_id, active, product_id, data):\n    \"\"\"update(context, id, etag, name, label, next_topic_id, active,\n              product_id, data)\n\n    Update a Topic.\n\n    >>> dcictl topic-update [OPTIONS]\n\n    :param string id: ID of the Topic [required]\n    :param string etag: Entity tag of the Topic resource [required]\n    :param string name: Name of the Topic\n    :param string component_types: list of component types separated by commas\n    :param string label: Label of the Topic\n    :param string data: JSON data to pass during remote CI update\n    :param boolean active: Set the topic in the active state\n    :param string product_id: The product the topic belongs to\n    :param string next_topic_id: The ID of the next topic for upgrades\n    \"\"\"\n\n    if component_types:\n        component_types = component_types.split(',')\n\n    result = topic.update(context, id=id, etag=etag, name=name,\n                          component_types=component_types,\n                          label=label, next_topic_id=next_topic_id,\n                          state=utils.active_string(active),\n                          product_id=product_id, data=data)\n    utils.format_output(result, context.format)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef attach_team(context, id, team_id):\n    team_id = team_id or identity.my_team_id(context)\n    result = topic.attach_team(context, id=id, team_id=team_id)\n    utils.format_output(result, context.format)", "response": "Attach a team to a topic"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef unattach_team(context, id, team_id):\n    team_id = team_id or identity.my_team_id(context)\n    result = topic.unattach_team(context, id=id, team_id=team_id)\n    if result.status_code == 204:\n        utils.print_json({'id': id, 'message': 'Teams has been unattached.'})\n    else:\n        utils.format_output(result, context.format)", "response": "Unattach a team from a topic"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef list_attached_team(context, id, sort, limit, where, verbose):\n    result = topic.list_teams(context, id=id, sort=sort, limit=limit,\n                              where=where)\n    utils.format_output(result, context.format, verbose=verbose)", "response": "List the teams attached to a topic."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\npurges soft - deleted resources.", "response": "def purge(context, resource, force):\n    \"\"\"purge(context, resource, force)\n\n    Purge soft-deleted resources.\n\n    >>> dcictl purge --resource remotecis\n    \"\"\"\n\n    resources = ['components', 'topics', 'tests', 'teams', 'feeders',\n                 'remotecis', 'jobs', 'files', 'users', 'products']\n\n    l_resources = resources if resource is None else resource.split(',')\n\n    wrong_resources = [res for res in l_resources if res not in resources]\n    test_auth = base.purge(context, 'users', **{'force': False})\n\n    if len(wrong_resources) > 0:\n        msg = 'Unkown resource have been specified: %s' % wrong_resources\n        if context.format == 'json':\n            utils.print_json(msg)\n        else:\n            click.echo(msg)\n\n    elif test_auth.status_code == 401:\n        utils.format_output(test_auth, context.format)\n\n    else:\n        purged = {}\n        if force:\n            # If in force mode. First we retrieve the number of items to be\n            # purged and then we purge them. This allows to presents meaningful\n            # informations to the user that used this command.\n\n            for res in l_resources:\n                item_purged = base.purge(context, res, **{'force': False}) \\\n                                  .json()['_meta']['count']\n                if item_purged and \\\n                   base.purge(context, res,\n                              **{'force': True}).status_code == 204:\n                    purged[res] = '%s item(s) purged' % item_purged\n            if len(purged.keys()):\n                utils.print_json(purged)\n            else:\n                utils.print_json({'message': 'No item to be purged'})\n        else:\n            # If not in force mode. The various endpoints are queried for the\n            # informations about the resources to be purged and displayed.\n            for res in l_resources:\n                resource_to_delete = base.purge(context, res,\n                                                **{'force': force})\n                if resource_to_delete.json()['_meta']['count'] > 0:\n                    purged[res] = resource_to_delete.json()\n            if len(purged.keys()):\n                for item in purged.keys():\n                    if len(l_resources) > 1:\n                        click.echo('\\n%s:\\n' % item)\n                    utils.format_output(purged[item][item], context.format)\n            else:\n                utils.format_output({}, context.format)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate an analytic. analytic.", "response": "def create(context, job_id, name, type, url, data):\n    \"\"\"create(context, job_id, name, type, url, data)\n\n    Create an analytic.\n\n    >>> dcictl analytic-create [OPTIONS]\n\n    :param string job-id: The job on which to attach the analytic\n    :param string name: Name of the analytic [required]\n    :param string type: Type of the analytic [required]\n    :param string url: Url of the bug [optional]\n    :param string data: JSON data of the analytic\n    \"\"\"\n\n    result = analytic.create(context, job_id=job_id, name=name, type=type,\n                             url=url, data=data)\n    utils.format_output(result, context.format)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlist all analytics of a job.", "response": "def list(context, job_id):\n    \"\"\"list(context, job_id)\n\n    List all analytics of a job.\n\n    >>> dcictl analytic-list [OPTIONS]\n\n    :param string job-id: The job on which to attach the analytic\n    \"\"\"\n\n    result = analytic.list(context, job_id=job_id)\n    utils.format_output(result, context.format)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update(context, id, job_id, name, type, url, data):\n\n    analytic_info = analytic.get(context, id=id, job_id=job_id)\n\n    etag = analytic_info.json()['analytic']['etag']\n\n    result = analytic.put(context, id=id, job_id=job_id, etag=etag,\n                          name=name, type=type, url=url, data=data)\n\n    utils.format_output(result, context.format)", "response": "Update an analytic node"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef show(context, id, job_id):\n\n    result = analytic.get(context, id, job_id=job_id)\n    utils.format_output(result, context.format)", "response": "show(context, id, job_id)\n\n    Show an analytic.\n\n    >>> dcictl analytic-show [OPTIONS] id\n\n    :param string id: The id of the analytic\n    :param string job-id: The job on which to show the analytic"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef substitute(dict_, source):\n    d_esc = (re.escape(k) for k in dict_.keys())\n    pattern = re.compile('|'.join(d_esc))\n    return pattern.sub(lambda x: dict_[x.group()], source)", "response": "Perform re. sub with the patterns in the given dict\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef soap_attribute(self, name, value):\n        setattr(self, name, value)\n        self._attributes.add(name)", "response": "Mark an attribute as being part of the data defined by the soap datatype"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_soap_object(self, client):\n        def to_soap_attribute(attr):\n            words = attr.split('_')\n            words = words[:1] + [word.capitalize() for word in words[1:]]\n            return ''.join(words)\n\n        soap_object = client.factory.create(self.soap_name)\n        for attr in self._attributes:\n            value = getattr(self, attr)\n            setattr(soap_object, to_soap_attribute(attr), value)\n\n        return soap_object", "response": "Create and return a soap service type defined for this instance"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_soap_object(self, client):\n        record_data = super().get_soap_object(client)\n        record_data.records = [Record(r).get_soap_object(client) for r in record_data.records]\n        return record_data", "response": "Override default get_soap_object behavior to account for child Record types"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprocess messages that have been delivered from the listener and retransmits them to the client.", "response": "def retransmit(self, data):\n        \"\"\"Processes messages that have been delivered from the listener.\n\n        Args:\n          data (dict): A dictionary containing the uuid, euuid, and message\n            response. E.g. {\"cuuid\": x, \"euuid\": y, \"response\": z}.\n\n        Returns:\n          None\n\n        \"\"\"\n\n        # If that shit is still in self.event_uuids, then that means we STILL\n        # haven't gotten a response from the client. Then we resend that shit\n        # and WAIT\n        if data[\"euuid\"] in self.event_uuids:\n            # Increment the current retry count of the euuid\n            self.event_uuids[data[\"euuid\"]] += 1\n\n            # If we've tried more than the maximum, just log an error\n            # and stahap.\n            if (self.event_uuids[data[\"euuid\"]] > self.max_retries or\n                    data[\"cuuid\"] not in self.registry):\n                logger.warning(\"<%s> Retry limit exceeded. \"\n                               \"Timed out waiting for client for \"\n                               \"event: %s\" % (data[\"cuuid\"], data[\"euuid\"]))\n                logger.warning(\"<%s> Deleting event from currently processing \"\n                               \"event uuids\" % data[\"cuuid\"])\n                del self.event_uuids[data[\"euuid\"]]\n            else:\n                # Retransmit that shit\n                logger.debug(\"<%s> Timed out waiting for response. Retry %s. \"\n                             \"Retransmitting message: \"\n                             \"%s\" % (data[\"cuuid\"],\n                                     pformat(self.event_uuids[data[\"euuid\"]]),\n                                     data[\"response\"]))\n\n                # Look up the host and port based on cuuid\n                host = self.registry[data[\"cuuid\"]][\"host\"]\n                port = self.registry[data[\"cuuid\"]][\"port\"]\n\n                # Send the packet to the client\n                self.listener.send_datagram(data[\"response\"], (host, port))\n\n                # Then we set another schedule to check again\n                logger.debug(\"<%s> Scheduling to retry in %s \"\n                             \"seconds\" % (data[\"cuuid\"], str(self.timeout)))\n                self.listener.call_later(self.timeout, self.retransmit, data)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nhandling a single message from the listener.", "response": "def handle_message(self, msg, host):\n        \"\"\"Processes messages that have been delivered from the listener.\n\n        Args:\n          msg (string): The raw packet data delivered from the listener. This\n            data will be unserialized and then processed based on the packet's\n            method.\n          host (tuple): The (address, host) tuple of the source message.\n\n        Returns:\n          A response that will be sent back to the client via the listener.\n\n        \"\"\"\n\n        response = None\n\n        # Unserialize the packet, and decrypt if the host has encryption enabled\n        if host in self.encrypted_hosts:\n            msg_data = unserialize_data(msg, self.compression, self.encryption)\n        else:\n            msg_data = unserialize_data(msg, self.compression)\n\n        logger.debug(\"Packet received: \" + pformat(msg_data))\n\n        # If the message data is blank, return none\n        if not msg_data: return response\n\n        # For debug purposes, check if the client is registered or not\n        if self.is_registered(msg_data[\"cuuid\"], host[0]):\n            logger.debug(\"<%s> Client is currently registered\" % msg_data[\"cuuid\"])\n        else:\n            logger.debug(\"<%s> Client is not registered\"  % msg_data[\"cuuid\"])\n\n        if \"method\" in msg_data:\n            if msg_data[\"method\"] == \"REGISTER\":\n                logger.debug(\"<%s> Register packet received\" % msg_data[\"cuuid\"])\n                response = self.register(msg_data, host)\n\n            elif msg_data[\"method\"] == \"OHAI\":\n                if not self.discoverable:\n                    return False\n                logger.debug(\"<%s> Autodiscover packet received\" % msg_data[\"cuuid\"])\n                response = self.autodiscover(msg_data)\n\n            elif msg_data[\"method\"] == \"AUTH\":\n                logger.debug(\"<%s> Authentication packet recieved\" % msg_data[\"cuuid\"])\n                response = self.auth_server.verify_login(msg_data)\n                if response:\n                    self.registry[host][\"authenticated\"] = True\n\n            else:\n                if self.auth_server:\n                    if self.registry[host][\"authenticated\"]:\n                        response = self.handle_message_registered(msg_data, host)\n                else:\n                    response = self.handle_message_registered(msg_data, host)\n\n        logger.debug(\"Packet processing completed\")\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprocess a message that has been delivered by a registered client.", "response": "def handle_message_registered(self, msg_data, host):\n        \"\"\"Processes messages that have been delivered by a registered client.\n\n        Args:\n          msg (string): The raw packet data delivered from the listener. This\n            data will be unserialized and then processed based on the packet's\n            method.\n          host (tuple): The (address, host) tuple of the source message.\n\n        Returns:\n          A response that will be sent back to the client via the listener.\n\n        \"\"\"\n        response = None\n\n        if msg_data[\"method\"] == \"EVENT\":\n            logger.debug(\"<%s> <euuid:%s> Event message \"\n                         \"received\" % (msg_data[\"cuuid\"], msg_data[\"euuid\"]))\n            response = self.event(msg_data[\"cuuid\"],\n                                  host,\n                                  msg_data[\"euuid\"],\n                                  msg_data[\"event_data\"],\n                                  msg_data[\"timestamp\"],\n                                  msg_data[\"priority\"])\n\n        elif msg_data[\"method\"] == \"OK EVENT\":\n            logger.debug(\"<%s> <euuid:%s> Event confirmation message \"\n                         \"received\" % (msg_data[\"cuuid\"], msg_data[\"euuid\"]))\n            try:\n                del self.event_uuids[msg_data[\"euuid\"]]\n            except KeyError:\n                logger.warning(\"<%s> <euuid:%s> Euuid does not exist in event \"\n                               \"buffer. Key was removed before we could process \"\n                               \"it.\" % (msg_data[\"cuuid\"], msg_data[\"euuid\"]))\n\n        elif msg_data[\"method\"] == \"OK NOTIFY\":\n            logger.debug(\"<%s> <euuid:%s> Ok notify \"\n                         \"received\" % (msg_data[\"cuuid\"], msg_data[\"euuid\"]))\n            try:\n                del self.event_uuids[msg_data[\"euuid\"]]\n            except KeyError:\n                logger.warning(\"<%s> <euuid:%s> Euuid does not exist in event \"\n                               \"buffer. Key was removed before we could process \"\n                               \"it.\" % (msg_data[\"cuuid\"], msg_data[\"euuid\"]))\n\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef autodiscover(self, message):\n        # Check to see if the client's version is the same as our own.\n        if message[\"version\"] in self.allowed_versions:\n            logger.debug(\"<%s> Client version matches server \"\n                         \"version.\" % message[\"cuuid\"])\n            response = serialize_data({\"method\": \"OHAI Client\",\n                                       \"version\": self.version,\n                                       \"server_name\": self.server_name},\n                                      self.compression,\n                                      encryption=False)\n        else:\n            logger.warning(\"<%s> Client version %s does not match allowed server \"\n                           \"versions %s\" % (message[\"cuuid\"],\n                                            message[\"version\"],\n                                            self.version))\n            response = serialize_data({\"method\": \"BYE REGISTER\"},\n                                      self.compression,\n                                      encryption=False)\n\n        return response", "response": "This function returns the server s version number as a response to the client."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef event(self, cuuid, host, euuid, event_data, timestamp, priority):\n\n        # Set the initial response to none\n        response = None\n\n        # If the host we're sending to is using encryption, get their key to\n        # encrypt.\n        if host in self.encrypted_hosts:\n            logger.debug(\"Encrypted!\")\n            client_key = self.registry[cuuid][\"encryption\"]\n        else:\n            logger.debug(\"Not encrypted :<\")\n            client_key = None\n\n        # Get the port and host\n        port = host[1]\n        host = host[0]\n\n        # First, we need to check if the request is coming from a registered\n        # client. If it's not coming from a registered client, we tell them to\n        # fuck off and register first.\n        if not self.is_registered(cuuid, host):\n            logger.warning(\"<%s> Sending BYE EVENT: Client not registered.\" % cuuid)\n            response = serialize_data({\"method\": \"BYE EVENT\",\n                                       \"data\": \"Not registered\"},\n                                      self.compression,\n                                      self.encryption, client_key)\n            return response\n\n        # Check our stored event uuid's to see if we're already processing\n        # this event.\n        if euuid in self.event_uuids:\n            logger.warning(\"<%s> Event ID is already being processed: %s\" % (cuuid,\n                                                                             euuid))\n            # If we're already working on this event, return none so we do not\n            # reply to the client\n            return response\n\n        # If we're not already processing this event, store the event uuid\n        # until we receive a confirmation from the client that it received our\n        # judgement.\n        self.event_uuids[euuid] = 0\n        logger.debug(\"<%s> <euuid:%s> Currently processing events: \"\n                     \"%s\" % (cuuid, euuid, str(self.event_uuids)))\n        logger.debug(\"<%s> <euuid:%s> New event being processed\" % (cuuid, euuid))\n        logger.debug(\"<%s> <euuid:%s> Event Data: %s\" % (cuuid,\n                                                         euuid,\n                                                         pformat(event_data)))\n\n        # Send the event to the game middleware to determine if the event is\n        # legal or not and to process the event in the Game Server if it is\n        # legal.\n        if self.middleware.event_legal(cuuid, euuid, event_data):\n            logger.debug(\"<%s> <euuid:%s> Event LEGAL. Sending judgement \"\n                         \"to client.\" % (cuuid, euuid))\n            response = serialize_data({\"method\": \"LEGAL\",\n                                       \"euuid\": euuid,\n                                       \"priority\": priority},\n                                      self.compression,\n                                      self.encryption, client_key)\n            # Execute the event\n            thread = threading.Thread(target=self.middleware.event_execute,\n                                      args=(cuuid, euuid, event_data)\n                                      )\n            thread.start()\n\n        else:\n            logger.debug(\"<%s> <euuid:%s> Event ILLEGAL. Sending judgement \"\n                         \"to client.\" % (cuuid, euuid))\n            response = serialize_data({\"method\": \"ILLEGAL\",\n                                       \"euuid\": euuid,\n                                       \"priority\": priority},\n                                      self.compression,\n                                      self.encryption, client_key)\n\n        # Schedule a task to run in x seconds to check to see if we've timed\n        # out in receiving a response from the client.\n        self.listener.call_later(self.timeout, self.retransmit,\n                                 {\"euuid\": euuid,\n                                  \"response\": response, \"cuuid\": cuuid})\n\n        return response", "response": "This function will process the event packets and send them to the appropriate handler."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef once(dispatcher, event, handle, *args):\n\n    def shell(dispatcher, *args):\n        try:\n            handle(dispatcher, *args)\n        except Exception as e:\n            raise e\n        finally:\n            dispatcher.del_map(event, shell)\n    dispatcher.add_map(event, shell, *args)", "response": "Used to do a mapping like event - > handle"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef mainloop(self):\n            \n        while True:\n        # It calls repeteadly the reactor\n        # update method.\n            try:\n                self.update()\n            except Kill:\n        # It breaks the loop\n        # silently.\n        # people implementing reactors from other mainloop\n        # should implement this try: catch\n        # suitably to their needs.\n\n                break\n            except KeyboardInterrupt:\n                print(self.base)\n                raise", "response": "Main loop for the reactor."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nstarts a DigidocService session", "response": "def start_session(self, b_hold_session, sig_doc_xml=None, datafile=None):\n        \"\"\"Start a DigidocService session\n\n        :return: True if session was started and session code was stored in I{session_code}\n        \"\"\"\n        response = self.__invoke('StartSession', {\n            'bHoldSession': b_hold_session,\n            'SigDocXML': sig_doc_xml or SkipValue,\n            'datafile': datafile or SkipValue,\n\n            # This parameter is deprecated and exists only due to historical reasons. We need to specify it as\n            #  SkipValue to keep zeep happy\n            'SigningProfile': SkipValue,\n        })\n\n        if response['Sesscode']:\n            self.data_files = []\n            self.session_code = response['Sesscode']\n\n            if sig_doc_xml:\n                self.container = PreviouslyCreatedContainer()\n\n            return True\n\n        # If b_hold_session is set to False, response will not contain a session\n        # in case of errors, exceptions are raised from __invoke anyway\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef check_candidate(a, d, n, s):\n    if pow(a, d, n) == 1:\n        return False\n    for i in range(s):\n        if pow(a, 2 ** i * d, n) == n - 1:\n            return False\n    return True", "response": "Part of the Miller - Rabin primality test in is_prime ()."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_prime(n, k=64):\n    if n == 2:\n        return True\n    if n < 2 or n % 2 == 0:\n        return False\n    for i in range(3, 2048):  # performace optimisation\n        if n % i == 0:\n            return False\n    s = 0\n    d = n - 1\n    while True:\n        q, r = divmod(d, 2)\n        if r == 1:\n            break\n        s += 1\n        d = q\n    for i in range(k):\n        a = random.randint(2, n - 1)\n        if check_candidate(a, d, n, s):\n            return False\n    return True", "response": "Test whether n is prime probabilisticly."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a random prime up to a certain length.", "response": "def get_prime(bits, k=64):\n    \"\"\"\n    Return a random prime up to a certain length.\n\n    This function uses random.SystemRandom.\n\n    \"\"\"\n    if bits % 8 != 0 or bits == 0:\n        raise ValueError(\"bits must be >= 0 and divisible by 8\")\n    while True:\n        n = int.from_bytes(os.urandom(bits // 8), \"big\")\n        if is_prime(n, k):\n            return n"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncalculate the multiplicative inverse of a and b.", "response": "def mult_inv(a, b):\n    \"\"\"\n    Calculate the multiplicative inverse a**-1 % b.\n\n    This function works for n >= 5 where n is prime.\n    \"\"\"\n    # in addition to the normal setup, we also remember b\n    last_b, x, last_x, y, last_y = b, 0, 1, 1, 0\n    while b != 0:\n        q = a // b\n        a, b = b, a % b\n        x, last_x = last_x - q * x, x\n        y, last_y = last_y - q * y, y\n    # and add b to x if x is negative\n    if last_x < 0:\n        return last_x + last_b\n    return last_x"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef make_rsa_keys(bits=2048, e=65537, k=64):\n    p, q = None, None\n    while p == q:\n        p, q = get_prime(bits // 2), get_prime(bits // 2)\n    n = p * q\n    phi_n = phi(n, p, q)\n    d = mult_inv(e, phi_n)\n    return n, e, d", "response": "Create RSA key pair."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing the command line arguments and return them as a namespace.", "response": "def parse_commandline(argv):\n  \"\"\"\n  Returns the arguments parsed from *argv* as a namespace.\n\n  \"\"\"\n  ap = ArgumentParser(\n    prog='wdiffhtml',\n    description=DESCRIPTION,\n    epilog=EPILOG,\n  )\n  ap.add_argument(\n    '--version', action='version', version='wdiffhtml v{}'.format(version),\n    help=\"shows version and exits\"\n  )\n  ap.add_argument(\n    'org_file', metavar='FILENAME',\n    help=\"original file\"\n  )\n  ap.add_argument(\n    'new_file', metavar='FILENAME',\n    help=\"changed file\"\n  )\n  g_html = ap.add_argument_group(\n    'Wrapper',\n    \"Without these settings, only the `wdiff` output is returned (with INS \"\n    \"and DEL tags). Here are some options to wrap the output in a HTML \"\n    \"document.\"\n  )\n  g_html.add_argument(\n    '-w', '--wrap-with-html', action='store_true',\n    help=\"wrap the diff with a HTML document\"\n  )\n  g_html.add_argument(\n    '-f', '--fold-tags', action='store_true',\n    help=\"allow INS and DEL tags to span linebraks\"\n  )\n  g_html.add_argument(\n    '-b', '--hard-breaks', action='store_true',\n    help=\"replace line breaks with BR tags\"\n  )\n  g_context = ap.add_argument_group(\n    'Context',\n    \"With these options you can add additional information to the HTML \"\n    \"output (means these only work alongside the `--wrap-with-html` option).\"\n  )\n  g_context.add_argument(\n    '-r', '--revision', metavar='STRING',\n    help=\"add a revision tag or version number to the output\"\n  )\n  x_stamp = g_context.add_mutually_exclusive_group()\n  x_stamp.add_argument(\n    '-d', '--datestamp', action='store_true',\n    help=\"add a date to the output (UTC now)\"\n  )\n  x_stamp.add_argument(\n    '-D', '--timestamp', action='store_true',\n    help=\"add date and time to the output (UTC now)\"\n  )\n  g_files = ap.add_argument_group(\n    'Files',\n    \"Instead of using the default templates, you can use your own files. \"\n    \"These only work alongside the `--wrap-with-html` option\"\n  )\n  g_files.add_argument(\n    '-t', '--template', type=FileType('r'), metavar='FILE',\n    help=\"load the Jinja2 template from this file\"\n  )\n  g_files.add_argument(\n    '-c', '--css', type=FileType('r'), metavar='FILE',\n    help=\"load CSS from this file\"\n  )\n  g_files.add_argument(\n    '-j', '--js', type=FileType('r'), metavar='FILE',\n    help=\"load Javascript from this file\"\n  )\n  g_files.add_argument(\n    '-J', '--js2', type=FileType('r'), metavar='FILE',\n    help=\"load another Javascript from this file (like Zepto)\"\n  )\n  # parse args\n  args = ap.parse_args(argv)\n  # check for wrapper\n  if not args.wrap_with_html:\n    # check context arguments and file arguments\n    for group in (g_context, g_files):\n      args_to_check = [opt.dest for opt in group._group_actions]\n      if any([getattr(args, attr) for attr in args_to_check]):\n        msg = \"the options require that `--wrap-with-html` is used\"\n        ap.error(msg)\n  return args"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_context(args):\n  context = {}\n  if args.revision:\n    context['version'] = args.revision\n  if args.datestamp:\n    context['timestamp'] = \"{:%Y-%m-%d}\".format(datetime.utcnow())\n  if args.timestamp:\n    context['timestamp'] = \"{:%Y-%m-%d %H:%M}\".format(datetime.utcnow())\n  if args.template:\n    context['template'] = args.template.read()\n  if args.css:\n    context['css'] = args.css.read()\n  if args.js:\n    context['js'] = args.js.read()\n  return context", "response": "Returns a context from the namespace args."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncall :func:`wdiff` and prints the results to STDERR. Parses the options for :meth:`wdiff` with :func:`parse_commandline`. If *argv* is supplied, it is used as command line, else the actual one is used. Return Codes ------------ 0: okay 1: error with arguments 2: `wdiff` not found 3: error running `wdiff`", "response": "def run_cli(argv=None):\n  \"\"\"\n  Calls :func:`wdiff` and prints the results to STDERR.\n\n  Parses the options for :meth:`wdiff` with :func:`parse_commandline`. If\n  *argv* is supplied, it is used as command line, else the actual one is used.\n\n  Return Codes\n  ------------\n\n  0: okay\n  1: error with arguments\n  2: `wdiff` not found\n  3: error running `wdiff`\n\n  \"\"\"\n  args = parse_commandline(argv)\n  try:\n    context = get_context(args)\n    settings = Settings(args.org_file, args.new_file, **context)\n    results = wdiff(\n      settings, args.wrap_with_html, args.fold_tags, args.hard_breaks\n    )\n    print(results)\n    return 0\n  except ContextError as err:\n    print(\"ERROR: {}.\".format(err), file=sys.stderr)\n    return 1\n  except WdiffNotFoundError as err:\n    print(\"ERROR: {}.\".format(err), file=sys.stderr)\n    return 2\n  except sub.CalledProcessError as err:\n    print(\"ERROR: {}.\".format(err), file=sys.stderr)\n    return 3"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nregisters the extension with Sphinx.", "response": "def setup(app):\n    \"\"\"Register the extension with Sphinx.\n\n    Args:\n        app: The Sphinx application.\n    \"\"\"\n\n    for name, (default, rebuild, _) in ref.CONFIG_VALUES.iteritems():\n        app.add_config_value(name, default, rebuild)\n\n    app.add_directive('javaimport', ref.JavarefImportDirective)\n    app.add_role('javaref', ref.JavarefRole(app))\n\n    app.connect('builder-inited', initialize_env)\n    app.connect('env-purge-doc', ref.purge_imports)\n    app.connect('env-merge-info', ref.merge_imports)\n    app.connect('build-finished', ref.cleanup)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef validate_env(app):\n\n    if not hasattr(app.env, 'javalink_config_cache'):\n        app.env.javalink_config_cache = {}\n\n    for conf_attr, (_, _, env_attr) in ref.CONFIG_VALUES.iteritems():\n        if not env_attr:\n            continue\n\n        value = getattr(app.config, conf_attr)\n        cached = app.env.javalink_config_cache.get(conf_attr, value)\n\n        app.env.javalink_config_cache[conf_attr] = value\n        if value != cached:\n            app.verbose('[javalink] config.%s has changed, clearing related env', conf_attr)\n            delattr(app.env, env_attr)", "response": "Purge expired values from the environment."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfinds the path to the Java standard library jar.", "response": "def find_rt_jar(javahome=None):\n    \"\"\"Find the path to the Java standard library jar.\n\n    The jar is expected to exist at the path 'jre/lib/rt.jar' inside a\n    standard Java installation directory. The directory is found using\n    the following procedure:\n\n    1. If the javehome argument is provided, use the value as the\n       directory.\n    2. If the JAVA_HOME environment variable is set, use the value as\n       the directory.\n    3. Find the location of the ``java`` binary in the current PATH and\n       compute the installation directory from this location.\n\n    Args:\n        javahome: A path to a Java installation directory (optional).\n    \"\"\"\n\n    if not javahome:\n        if 'JAVA_HOME' in os.environ:\n            javahome = os.environ['JAVA_HOME']\n        elif sys.platform == 'darwin':\n            # The default java binary on OS X is not part of a standard Oracle\n            # install, so building paths relative to it does not work like it\n            # does on other platforms.\n            javahome = _find_osx_javahome()\n        else:\n            javahome = _get_javahome_from_java(_find_java_binary())\n\n    rtpath = os.path.join(javahome, 'jre', 'lib', 'rt.jar')\n    if not os.path.isfile(rtpath):\n        msg = 'Could not find rt.jar: {} is not a file'.format(rtpath)\n        raise ExtensionError(msg)\n\n    return rtpath"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef filter(self, record):\n        found = self._pattern.search(record.getMessage())\n        return not found", "response": "Returns True if the record shall be logged False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a tuple of the version and documentation of the modul.", "response": "def get_meta(path=None):\n  \"\"\"\n  Returns a tuple of `__version__` and `__doc__` form the modul.\n\n  If *path* is set, it is temporarily added to `sys.path`.\n\n  \"\"\"\n  if path:\n    sys.path.insert(1, path)\n  from wdiffhtml import __version__, __doc__\n  if path:\n    del(sys.path[0])\n  return __version__, __doc__"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of items in the specified order from the specified value.", "response": "def flattened(value, split=None):\n    \"\"\"\n    Args:\n        value: Possibly nested arguments (sequence of lists, nested lists)\n        split (int | str | unicode | (str | unicode, int) | None): How to split values:\n            - None: simply flatten, no further processing\n            - one char string: split() on specified char\n            - SANITIZED: discard all None items\n            - UNIQUE: each value will appear only once\n            - SHELL:  filter out sequences of the form [\"-f\", None] (handy for simplified cmd line specification)\n\n    Returns:\n        list: 'value' flattened out (leaves from all involved lists/tuples)\n    \"\"\"\n    result = []\n    separator = None\n    mode = 0\n    if isinstance(split, tuple):\n        separator, mode = split\n    elif isinstance(split, int):\n        mode = split\n    else:\n        separator = split\n    _flatten(result, value, separator, mode)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the text formatted with the specified attributes.", "response": "def formatted(text, *args, **kwargs):\n    \"\"\"\n    Args:\n        text (str | unicode): Text to format\n        *args: Objects to extract values from (as attributes)\n        **kwargs: Optional values provided as named args\n\n    Returns:\n        (str): Attributes from this class are expanded if mentioned\n    \"\"\"\n    if not text or \"{\" not in text:\n        return text\n    strict = kwargs.pop(\"strict\", True)\n    max_depth = kwargs.pop(\"max_depth\", 3)\n    objects = list(args) + [kwargs] if kwargs else args[0] if len(args) == 1 else args\n    if not objects:\n        return text\n    definitions = {}\n    markers = RE_FORMAT_MARKERS.findall(text)\n    while markers:\n        key = markers.pop()\n        if key in definitions:\n            continue\n        val = _find_value(key, objects)\n        if strict and val is None:\n            return None\n        val = str(val) if val is not None else \"{%s}\" % key\n        markers.extend(m for m in RE_FORMAT_MARKERS.findall(val) if m not in definitions)\n        definitions[key] = val\n    if not max_depth or not isinstance(max_depth, int) or max_depth <= 0:\n        return text\n    expanded = dict((k, _rformat(k, v, definitions, max_depth)) for k, v in definitions.items())\n    return text.format(**expanded)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef quoted(text):\n    if text and \" \" in text:\n        sep = \"'\" if '\"' in text else '\"'\n        return \"%s%s%s\" % (sep, text, sep)\n    return text", "response": "Quote the given text if it contains spaces."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef represented_args(args, separator=\" \"):\n    result = []\n    if args:\n        for text in args:\n            result.append(quoted(short(text)))\n    return separator.join(result)", "response": "Returns a textual representation of the arguments."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef resolved_path(path, base=None):\n    if not path or path.startswith(SYMBOLIC_TMP):\n        return path\n\n    path = os.path.expanduser(path)\n    if base and not os.path.isabs(path):\n        return os.path.join(resolved_path(base), path)\n\n    return os.path.abspath(path)", "response": "Resolves the path to a base directory and returns the absolute path."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nshortens text to at most size chars.", "response": "def shortened(text, size=120):\n    \"\"\"\n    Args:\n        text (str | unicode): Text to shorten\n        size (int): Max chars\n\n    Returns:\n        (str): Leading part of 'text' with at most 'size' chars\n    \"\"\"\n    if text:\n        text = text.strip()\n        if len(text) > size:\n            return \"%s...\" % text[:size - 3].strip()\n    return text"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _flatten(result, value, separator, mode):\n    if value is None or value is UNSET:\n        if mode & SHELL:\n            # Convenience: allow to filter out [\"--switch\", None] easily\n            if result and result[-1].startswith(\"-\"):\n                result.pop(-1)\n            return\n\n        if mode & SANITIZED:\n            return\n\n    if value is not None:\n        if isinstance(value, (list, tuple, set)):\n            for item in value:\n                _flatten(result, item, separator, mode)\n            return\n\n        if separator and hasattr(value, \"split\") and separator in value:\n            _flatten(result, value.split(separator), separator, mode)\n            return\n\n    if (mode & UNIQUE == 0) or value not in result:\n        result.append(value)", "response": "Flatten the list of items in the key - value pair into a single item."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets a value for key from obj", "response": "def _get_value(obj, key):\n    \"\"\"Get a value for 'key' from 'obj', if possible\"\"\"\n    if isinstance(obj, (list, tuple)):\n        for item in obj:\n            v = _find_value(key, item)\n            if v is not None:\n                return v\n        return None\n    if isinstance(obj, dict):\n        return obj.get(key)\n    if obj is not None:\n        return getattr(obj, key, None)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _find_value(key, *args):\n    for arg in args:\n        v = _get_value(arg, key)\n        if v is not None:\n            return v", "response": "Find a value for key in any of the objects given as args."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set(cls, *anchors):\n        cls.paths = sorted(flattened(anchors, split=SANITIZED | UNIQUE), reverse=True)", "response": "Sets the base class s paths to use as anchors for short ("}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pop(cls, anchors):\n        for anchor in flattened(anchors, split=SANITIZED | UNIQUE):\n            if anchor in cls.paths:\n                cls.paths.remove(anchor)", "response": "Removes an anchor from the set of anchors."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the short form of a path.", "response": "def short(cls, path):\n        \"\"\"\n        Example:\n            short(\"examined /Users/joe/foo\") => \"examined ~/foo\"\n\n        Args:\n            path: Path to represent in its short form\n\n        Returns:\n            (str): Short form, using '~' if applicable\n        \"\"\"\n        if not path:\n            return path\n\n        path = str(path)\n        if cls.paths:\n            for p in cls.paths:\n                if p:\n                    path = path.replace(p + \"/\", \"\")\n\n        path = path.replace(cls.home, \"~\")\n        return path"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_search_path(*path_tokens):\n    full_path = os.path.join(*path_tokens)\n    if full_path not in sys.path:\n        sys.path.insert(0, os.path.abspath(full_path))", "response": "Adds a new search path from where modules can be loaded."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load_script(filename):\n    path, module_name, ext = _extract_script_components(filename)\n    add_search_path(path)\n    return _load_module(module_name)", "response": "Loads a python script as a module."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_dates(df, inplace=True, *args, **kwargs):\n    if not inplace:\n        df = df.copy()\n\n    for c in df.columns:\n        i = df[c].first_valid_index()\n        if i is not None and type(df[c].ix[i]) in (date, datetime):\n            df[c] = pd.to_datetime(df[c], *args, **kwargs)\n\n    if not inplace:\n        return df", "response": "Parse all datetime. date and datetime. datetime columns"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of subdirectories of the given directory", "response": "def get_subdirs(directory):\n    \"\"\"\n    Returns: a list of subdirectories of the given directory\n    \"\"\"\n    return [os.path.join(directory, name)\n            for name in os.listdir(directory)\n            if os.path.isdir(os.path.join(directory, name))]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef to_float(*args):\n    floats = [np.array(a, dtype=np.float32) for a in args]\n    return floats[0] if len(floats) == 1 else floats", "response": "cast numpy arrays to float32"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a class or function by name", "response": "def get_attr(name):\n    \"\"\"\n    get a class or function by name\n    \"\"\"\n    i = name.rfind('.')\n    cls = str(name[i+1:])\n    module = str(name[:i])\n\n    mod = __import__(module, fromlist=[cls])\n    return getattr(mod, cls)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef list_expand(d, prefix=None):\n    if prefix is None:\n        prefix = tuple()\n    for k in d:\n        if isinstance(d, dict):\n            for i in list_expand(d[k], prefix=tuple(chain(prefix, (k,)))):\n                yield i\n        else:\n            yield tuple(chain(prefix, make_list(k)))", "response": "Recursively expands a dictionary into lists of lists."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dict_diff(dicts):\n    diff_keys = set()\n\n    for k in union(set(d.keys()) for d in dicts):\n        values = []\n        for d in dicts:\n            if k not in d:\n                diff_keys.add(k)\n                break\n            else:\n                values.append(d[k])\n                if nunique(values) > 1:\n                    diff_keys.add(k)\n                    break\n\n    return [dict_subset(d, diff_keys) for d in dicts]", "response": "Returns a list of dicts which are not in the list of dicts."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dict_product(*d, **kwargs):\n    d = dict(dict_merge(*d), **kwargs)\n    holdout = {k: d[k] for k in d if not isinstance(d[k], list)}\n    d = {k: d[k] for k in d if k not in holdout}\n\n    items = d.items()\n    if len(items) == 0:\n        dicts = [{}]\n    else:\n        keys, values = zip(*items)\n        dicts = [dict_filter_none(dict(zip(keys, v))) for v in product(*values)]\n\n    for d in dicts:\n        d.update(holdout)\n\n    return dicts", "response": "Returns a list of dicts with the same keys as d and kwargs as kwargs\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dict_update_union(d1, d2):\n    for k in d2:\n        if k in d1:\n            d1[k].update(d2[k])\n        else:\n            d1[k] = d2[k]", "response": "update a set - valued dictionary d1 when key exists union sets\n   "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef indent(s, n_spaces=2, initial=True):\n    i = ' '*n_spaces\n    t = s.replace('\\n', '\\n%s' % i)\n    if initial:\n        t = i + t\n    return t", "response": "Indent all new lines in a string"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_instance_collection(c, cls):\n    if not (hasattr(c, '__iter__') and len(c) > 0):\n        # make sure it's iterable and not empty\n        return False\n\n    cls = make_list(cls)\n    for i in get_collection_values(c):\n        instance = False\n        for cl in cls:\n            if isinstance(i, cl):\n                instance = True\n                break\n        if not instance:\n            return False\n\n    return True", "response": "Checks if a collection of objects is an instance of one of the specified classes."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_sql(self, frame, name, if_exists='fail', index=True,\n               index_label=None, schema=None, chunksize=None,\n               dtype=None, pk=None, prefixes=None, raise_on_error=True):\n        \"\"\"\n        Write records stored in a DataFrame to a SQL database.\n\n        Parameters\n        ----------\n        frame : DataFrame\n        name : string\n            Name of SQL table\n        if_exists : {'fail', 'replace', 'append'}, default 'fail'\n            - fail: If table exists, do nothing.\n            - replace: If table exists, drop it, recreate it, and insert data.\n            - append: If table exists, insert data. Create if does not exist.\n        index : boolean, default True\n            Write DataFrame index as a column\n        index_label : string or sequence, default None\n            Column label for index column(s). If None is given (default) and\n            `index` is True, then the index names are used.\n            A sequence should be given if the DataFrame uses MultiIndex.\n        schema : string, default None\n            Name of SQL schema in database to write to (if database flavor\n            supports this). If specified, this overwrites the default\n            schema of the SQLDatabase object.\n        chunksize : int, default None\n            If not None, then rows will be written in batches of this size at a\n            time.  If None, all rows will be written at once.\n        dtype : dict of column name to SQL type, default None\n            Optional specifying the datatype for columns. The SQL type should\n            be a SQLAlchemy type.\n        pk: name of column(s) to set as primary keys\n        \"\"\"\n        table = pandas.io.sql.SQLTable(name, self, frame=frame, index=index,\n                                       if_exists=if_exists, index_label=index_label,\n                                       schema=schema, dtype=dtype)\n        existed = table.exists()\n        table.create()\n        replaced = existed and if_exists == 'replace'\n\n        table_name = name\n        if schema is not None:\n            table_name = schema + '.' + table_name\n\n        if pk is not None and ((not existed) or replaced):\n            if isinstance(pk, str):\n                pks = pk\n            else:\n                pks = \", \".join(pk)\n            sql = \"ALTER TABLE {table_name} ADD PRIMARY KEY ({pks})\".format(\n                    table_name=table_name, pks=pks)\n            self.execute(sql)\n\n        from subprocess import Popen, PIPE, STDOUT\n\n        columns = frame.index.names + list(frame.columns) if index else frame.columns\n        columns = str.join(\",\", map(lambda c: '\"' + c + '\"', columns))\n\n        sql = \"COPY {table_name} ({columns}) FROM STDIN WITH (FORMAT CSV, HEADER TRUE)\".format(\n                table_name=table_name, columns=columns)\n        p = Popen(['psql', '-c', sql], stdout=PIPE, stdin=PIPE, stderr=STDOUT,\n                  universal_newlines=True)\n        frame.to_csv(p.stdin, index=index)\n\n        psql_out = p.communicate()[0]\n        logging.info(psql_out),\n\n        r = p.wait()\n        if raise_on_error and (r > 0):\n            sys.exit(r)\n\n        return r", "response": "Write records stored in a DataFrame to a SQL database."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_task(cls, task):\n        target = cls(name=task.get_name(),\n                     params=task.get_param_string())\n\n        return target", "response": "Create a new target representing a task and its parameters"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbasing query for a target.", "response": "def _base_query(self, session):\n        \"\"\"Base query for a target.\n\n        Args:\n            session: database session to query in\n        \"\"\"\n        return session.query(ORMTargetMarker) \\\n            .filter(ORMTargetMarker.name == self.name) \\\n            .filter(ORMTargetMarker.params == self.params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef exists(self):\n        # get DB connection\n        session = client.get_client().create_session()\n\n        # query for target existence\n        ret = self._base_query(session).count() > 0\n\n        session.close()\n\n        return ret", "response": "Check if a target exists in the database."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create(self):\n        session = client.get_client().create_session()\n\n        if not self._base_query(session).count() > 0:\n            # store a new target instance to the database\n            marker = ORMTargetMarker(name=self.name,\n                                     params=self.params)\n            session.add(marker)\n            session.commit()\n\n        session.close()", "response": "Create an instance of the current target in the database\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef remove(self):\n        session = client.get_client().create_session()\n\n        if not self._base_query(session).count() > 0:\n            session.close()\n            raise RuntimeError(\"Target does not exist, name={:s}, params={:s}\"\n                               \"\".format(self.name, self.params))\n\n        # remove the target from the database\n        self._base_query(session).delete()\n        session.commit()\n\n        session.close()", "response": "Removes a target from the database. Raises a RuntimeError if the target does not exist."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nextending the table with uppercase options", "response": "def add_uppercase(table):\n    \"\"\"\n    Extend the table with uppercase options\n\n    >>> print(\"\u0430\" in add_uppercase({\"\u0430\": \"a\"}))\n    True\n    >>> print(add_uppercase({\"\u0430\": \"a\"})[\"\u0430\"] == \"a\")\n    True\n    >>> print(\"\u0410\" in add_uppercase({\"\u0430\": \"a\"}))\n    True\n    >>> print(add_uppercase({\"\u0430\": \"a\"})[\"\u0410\"] == \"A\")\n    True\n    >>> print(len(add_uppercase({\"\u0430\": \"a\"}).keys()))\n    2\n    >>> print(\"\u0410\u0430\" in add_uppercase({\"\u0430\u0430\": \"aa\"}))\n    True\n    >>> print(add_uppercase({\"\u0430\u0430\": \"aa\"})[\"\u0410\u0430\"] == \"Aa\")\n    True\n    \"\"\"\n    orig = table.copy()\n    orig.update(\n        dict((k.capitalize(), v.capitalize()) for k, v in table.items()))\n\n    return orig"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef convert_table(table):\n\n    return dict((ord(k), v) for k, v in table.items())", "response": "Convert a table to a sequence of alphabetical characters."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nstore entities and attributes in the database.", "response": "def store(self, df, attribute_columns):\n        \"\"\"Store entities and their attributes\n\n        Args:\n            df (pandas.DataFrame): data to store (storing appends 'id' and 'type' columns!)\n            attribute_columns (list(str)): list of column labels that define attributes\n        \"\"\"\n\n        # ID start values depend on currently stored entities/attributes!\n        entity_id_start = models.Entity.get_max_id(self.session) + 1\n        attribute_id_start = models.Attribute.get_max_id(self.session) + 1\n\n        # append ID and type columns\n        df['id'] = range(entity_id_start, entity_id_start + len(df))\n        df['type'] = self.type\n\n        # store entities\n        df[['id', 'type']].to_sql(name=models.Entity.__tablename__,\n                                  con=self.client.engine,\n                                  if_exists='append',\n                                  index=False)\n\n        # store attributes\n        for col in attribute_columns:\n            # ID column of df is the entity ID of the attribute\n            attr_df = df[[col, 'id']].rename(columns={'id': 'entity_id',\n                                                      col: 'value'})\n            attr_df['name'] = col\n\n            # add entity ID column, need to respect already existing entities\n            attr_df['id'] = range(attribute_id_start, attribute_id_start + len(df))\n            attribute_id_start += len(df)\n\n            # store\n            attr_df.to_sql(name=models.Attribute.__tablename__,\n                           con=self.client.engine,\n                           if_exists='append',\n                           index=False)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading all artists into the database and store them into the database", "response": "def run(self):\n        \"\"\"Load all artists into the database\n        \"\"\"\n\n        df = ArtistsInputData().load()\n\n        # rename columns\n        df.rename(columns={'artistLabel': 'name',\n                           'genderLabel': 'gender'},\n                  inplace=True)\n\n        # attribute columns that exist in the data model\n        attribute_columns = ['name', 'wiki_id']\n\n        # the extended model also stores the date of birth and gender\n        if config.EXTENDED:\n            attribute_columns += ['gender', 'year_of_birth']\n\n        # store entities and attributes\n        self.store(df, attribute_columns)\n\n        self.done()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload all paintings into the database and store them in the database", "response": "def run(self):\n        \"\"\"Load all paintings into the database\n        \"\"\"\n\n        df = PaintingsInputData().load()\n\n        # rename columns\n        df.rename(columns={'paintingLabel': 'name'}, inplace=True)\n\n        # get artist IDs, map via artist wiki ID\n        artists = models.Entity.query_with_attributes('artist', self.client)\n        df['artist_id'] = df['creator_wiki_id'].map(artists.set_index('wiki_id')['id'])\n\n        # define attributes to create\n        attribute_columns = ['name', 'wiki_id', 'area', 'decade', 'artist_id']\n\n        # store entities and attributes\n        self.store(df, attribute_columns)\n\n        self.done()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nserializes normal Python datatypes into plaintext using json.", "response": "def serialize_data(data, compression=False, encryption=False, public_key=None):\n    \"\"\"Serializes normal Python datatypes into plaintext using json.\n\n    You may also choose to enable compression and encryption when serializing\n    data to send over the network. Enabling one or both of these options will\n    incur additional overhead.\n\n    Args:\n      data (dict): The data to convert into plain text using json.\n      compression (boolean): True or False value on whether or not to compress\n        the serialized data.\n      encryption (rsa.encryption): An encryption instance used to encrypt the\n        message if encryption is desired.\n      public_key (str): The public key to use to encrypt if encryption is\n        enabled.\n\n    Returns:\n      The string message serialized using json.\n\n    \"\"\"\n\n    message = json.dumps(data)\n\n    if compression:\n        message = zlib.compress(message)\n        message = binascii.b2a_base64(message)\n\n    if encryption and public_key:\n        message = encryption.encrypt(message, public_key)\n\n    encoded_message = str.encode(message)\n\n    return encoded_message"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef listen(self):\n\n        self.listening = True\n        if self.threading:\n            from threading import Thread\n            self.listen_thread = Thread(target=self.listen_loop)\n            self.listen_thread.daemon = True\n            self.listen_thread.start()\n\n            self.scheduler_thread = Thread(target=self.scheduler)\n            self.scheduler_thread.daemon = True\n            self.scheduler_thread.start()\n\n        else:\n            self.listen_loop()", "response": "Starts the listen loop. If threading is enabled then the listen loop will be started in its own thread. If scheduler is enabled then the listen loop will be started in its own thread."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nstart the listen loop and executes the receive_datagram method .", "response": "def listen_loop(self):\n        \"\"\"Starts the listen loop and executes the receieve_datagram method\n        whenever a packet is receieved.\n\n        Args:\n          None\n\n        Returns:\n          None\n\n        \"\"\"\n\n        while self.listening:\n            try:\n                data, address = self.sock.recvfrom(self.bufsize)\n                self.receive_datagram(data, address)\n                if self.stats_enabled:\n                    self.stats['bytes_recieved'] += len(data)\n            except socket.error as error:\n                if error.errno == errno.WSAECONNRESET:\n                    logger.info(\"connection reset\")\n                else:\n                    raise\n\n        logger.info(\"Shutting down the listener...\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef scheduler(self, sleep_time=0.2):\n\n        while self.listening:\n            # If we have any scheduled calls, execute them and remove them from\n            # our list of scheduled calls.\n            if self.scheduled_calls:\n                timestamp = time.time()\n                self.scheduled_calls[:] = [item for item in self.scheduled_calls\n                                           if not self.time_reached(timestamp, item)]\n            time.sleep(sleep_time)\n\n        logger.info(\"Shutting down the call scheduler...\")", "response": "Starts the scheduler to check for scheduled calls and execute them at the correct time."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef call_later(self, time_seconds, callback, arguments):\n\n        scheduled_call = {'ts': time.time() + time_seconds,\n                          'callback': callback,\n                          'args': arguments}\n        self.scheduled_calls.append(scheduled_call)", "response": "Schedules a function to be run at the time of the given time_seconds."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck to see if the current time is reached by the scheduled call.", "response": "def time_reached(self, current_time, scheduled_call):\n        \"\"\"Checks to see if it's time to run a scheduled call or not.\n\n        If it IS time to run a scheduled call, this function will execute the\n        method associated with that call.\n\n        Args:\n          current_time (float): Current timestamp from time.time().\n          scheduled_call (dict): A scheduled call dictionary that contains the\n            timestamp to execute the call, the method to execute, and the\n            arguments used to call the method.\n\n        Returns:\n          None\n\n        Examples:\n\n        >>> scheduled_call\n        {'callback': <function foo at 0x7f022c42cf50>,\n                 'args': {'k': 'v'},\n                 'ts': 1415066599.769509}\n\n        \"\"\"\n\n        if current_time >= scheduled_call['ts']:\n            scheduled_call['callback'](scheduled_call['args'])\n            return True\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef send_datagram(self, message, address, message_type=\"unicast\"):\n\n        if self.bufsize is not 0 and len(message) > self.bufsize:\n            raise Exception(\"Datagram is too large. Messages should be \" +\n                            \"under \" + str(self.bufsize) + \" bytes in size.\")\n\n        if message_type == \"broadcast\":\n            self.sock.setsockopt(socket.SOL_SOCKET, socket.SO_BROADCAST, 1)\n        elif message_type == \"multicast\":\n            self.sock.setsockopt(socket.IPPROTO_IP, socket.IP_MULTICAST_TTL, 2)\n\n        try:\n            logger.debug(\"Sending packet\")\n            self.sock.sendto(message, address)\n            if self.stats_enabled:\n                self.stats['bytes_sent'] += len(message)\n        except socket.error:\n            logger.error(\"Failed to send, [Errno 101]: Network is unreachable.\")", "response": "Sends a datagram to the requested address."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef receive_datagram(self, data, address):\n\n        # If we do not specify an application, just print the data.\n        if not self.app:\n            logger.debug(\"Packet received\", address, data)\n            return False\n\n        # Send the data we've recieved from the network and send it\n        # to our application for processing.\n        try:\n            response = self.app.handle_message(data, address)\n        except Exception as err:\n            logger.error(\"Error processing message from \" + str(address) +\n                          \":\" + str(data))\n            logger.error(traceback.format_exc())\n            return False\n\n        # If our application generated a response to this message,\n        # send it to the original sender.\n        if response:\n            self.send_datagram(response, address)", "response": "Executes when UDP data has been received and sends the packet to the application to process the request."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make_application():\n    settings = {}\n    application = web.Application([web.url('/', SimpleHandler)], **settings)\n    statsd.install(application, **{'namespace': 'testing'})\n    return application", "response": "Create a web application configured to send metrics."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef plots_html_page(query_module):\n\n    # page template\n    template = jenv.get_template(\"analysis.html\")\n\n    # container for template context\n    context = dict(extended=config.EXTENDED)\n\n    # a database client/session to run queries in\n    cl = client.get_client()\n    session = cl.create_session()\n\n    # general styling\n    seaborn.set_style('whitegrid')\n\n    #\n    #  plot: painting area by decade, with linear regression\n    #\n\n    decade_df = query_module.decade_query()\n\n    pix_size = pixels_to_inches((600, 400))\n    ax = seaborn.lmplot(x='decade', y='area', data=decade_df,\n                        size=pix_size[1], aspect=pix_size[0] / pix_size[1],\n                        scatter_kws={\"s\": 30, \"alpha\": 0.3})\n    ax.set(xlabel='Decade', ylabel='Area, m^2')\n    context['area_by_decade_svg'] = fig_to_svg(plt.gcf())\n    plt.close('all')\n\n    #\n    #  plot: painting area by gender, with logistic regression\n    #\n\n    if config.EXTENDED:\n        gender_df = query_module.gender_query()\n\n        pix_size = pixels_to_inches((600, 400))\n        g = seaborn.FacetGrid(gender_df, hue=\"gender\", margin_titles=True,\n                              size=pix_size[1], aspect=pix_size[0] / pix_size[1])\n        bins = np.linspace(0, 5, 30)\n        g.map(plt.hist, \"area\", bins=bins, lw=0, alpha=0.5, normed=True)\n        g.axes[0, 0].set_xlabel('Area, m^2')\n        g.axes[0, 0].set_ylabel('Percentage of paintings')\n        context['area_by_gender_svg'] = fig_to_svg(plt.gcf())\n        plt.close('all')\n\n    #\n    # render template\n    #\n\n    out_file = path.join(out_dir, \"analysis.html\")\n    html_content = template.render(**context)\n    with open(out_file, 'w') as f:\n        f.write(html_content)\n\n    # done, clean up\n    plt.close('all')\n    session.close()", "response": "Generate analysis output as html page"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts values in a row to types accepted by excel", "response": "def _to_pywintypes(row):\n    \"\"\"convert values in a row to types accepted by excel\"\"\"\n    def _pywintype(x):\n        if isinstance(x, dt.date):\n            return dt.datetime(x.year, x.month, x.day, tzinfo=dt.timezone.utc)\n\n        elif isinstance(x, (dt.datetime, pa.Timestamp)):\n            if x.tzinfo is None:\n                return x.replace(tzinfo=dt.timezone.utc)\n\n        elif isinstance(x, str):\n            if re.match(\"^\\d{4}-\\d{2}-\\d{2}$\", x):\n                return \"'\" + x\n            return x\n\n        elif isinstance(x, np.integer):\n            return int(x)\n\n        elif isinstance(x, np.floating):\n            return float(x)\n\n        elif x is not None and not isinstance(x, (str, int, float, bool)):\n            return str(x)\n\n        return x\n\n    return [_pywintype(x) for x in row]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a table to the worksheet at the specified row and column.", "response": "def add_table(self, table, row=None, col=0, row_spaces=1):\n        \"\"\"\n        Adds a table to the worksheet at (row, col).\n        Return the (row, col) where the table has been put.\n\n        :param xltable.Table table: Table to add to the worksheet.\n        :param int row: Row to start the table at (defaults to the next free row).\n        :param int col: Column to start the table at.\n        :param int row_spaces: Number of rows to leave between this table and the next.\n        \"\"\"\n        name = table.name\n        assert name is not None, \"Tables must have a name\"\n        assert name not in self.__tables, \"Table %s already exists in this worksheet\" % name\n        if row is None:\n            row = self.__next_row\n        self.__next_row = max(row + table.height + row_spaces, self.__next_row)\n        self.__tables[name] = (table, (row, col))\n        return row, col"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_value(self, value, row, col):\n        self.__values[(row, col)] = value", "response": "Adds a single value to a worksheet at the specified row and column."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding a chart to the worksheet at the specified row and col.", "response": "def add_chart(self, chart, row, col):\n        \"\"\"\n        Adds a chart to the worksheet at (row, col).\n\n        :param xltable.Chart Chart: chart to add to the workbook.\n        :param int row: Row to add the chart at.\n        \"\"\"\n        self.__charts.append((chart, (row, col)))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_row_group(self, tables, collapsed=True):\n        self.__groups.append((tables, collapsed))", "response": "Adds a group over all the given tables."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_table_pos(self, tablename):\n        _table, (row, col) = self.__tables[tablename]\n        return (row, col)", "response": "Get the upper left coordinate of the named table."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_table(self, tablename):\n        table, (_row, _col) = self.__tables[tablename]\n        return table", "response": "Returns the table instance for the given table name."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef iterrows(self, workbook=None):\n        resolved_tables = []\n        max_height = 0\n        max_width = 0\n\n        # while yielding rows __formula_values is updated with any formula values set on Expressions\n        self.__formula_values = {}\n\n        for name, (table, (row, col)) in list(self.__tables.items()):\n            # get the resolved 2d data array from the table\n            #\n            # expressions with no explicit table will use None when calling\n            # get_table/get_table_pos, which should return the current table.\n            #\n            self.__tables[None] = (table, (row, col))\n            data = table.get_data(workbook, row, col, self.__formula_values)\n            del self.__tables[None]\n\n            height, width = data.shape\n            upper_left = (row, col)\n            lower_right = (row + height - 1, col + width - 1)\n\n            max_height = max(max_height, lower_right[0] + 1)\n            max_width = max(max_width, lower_right[1] + 1)\n            \n            resolved_tables.append((name, data, upper_left, lower_right))\n\n        for row, col in self.__values.keys():\n            max_width = max(max_width, row+1)\n            max_height = max(max_height, col+1)\n\n        # Build the whole table up-front. Doing it row by row is too slow.\n        table = [[None] * max_width for i in range(max_height)]\n        for name, data, upper_left, lower_right in resolved_tables:\n            for i, r in enumerate(range(upper_left[0], lower_right[0]+1)):\n                for j, c in enumerate(range(upper_left[1], lower_right[1]+1)):\n                    table[r][c] = data[i][j]\n\n        for (r, c), value in self.__values.items():\n            if isinstance(value, Value):\n                value = value.value\n            if isinstance(value, Expression):\n                if value.has_value:\n                    self.__formula_values[(r, c)] = value.value\n                value = value.get_formula(workbook, r, c)\n            table[r][c] = value\n\n        for row in table:\n            yield row", "response": "Yields the rows of the table in the source pandas DataFrames and returns a list of tuples of data. Each tuple contains the name data the upper left and right data and the formula values."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_column_widths(self):\n        col_widths = {}\n        for table, (row, col) in self.__tables.values():\n            for colname, width in table.column_widths.items():\n                ic = col + table.get_column_offset(colname)\n                current_width = col_widths.setdefault(ic, width)\n                col_widths[ic] = max(width, current_width)\n        return col_widths", "response": "return a dictionary of column - > width"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_all_styles(self):\n        _styles = {}\n        def _get_style(bold=False, bg_col=None, border=None):\n            if (bold, bg_col, border) not in _styles:\n                _styles[(bold, bg_col, border)] = CellStyle(bold=bold,\n                                                            bg_color=bg_col,\n                                                            border=border)\n            return _styles[(bold, bg_col, border)]\n\n        ws_styles = {}\n        for table, (row, col) in self.__tables.values():\n            for r in range(row, row + table.header_height):\n                for c in range(col, col + table.width):\n                    if isinstance(table.header_style, dict):\n                        col_name = table.dataframe.columns[c - col]\n                        style = table.header_style.get(col_name, _get_style(bold=True))\n                    else:\n                        style = table.header_style or _get_style(bold=True)\n                    ws_styles[(r, c)] = style\n\n            for c in range(col, col + table.row_labels_width):\n                for r in range(row + table.header_height, row + table.height):\n                    if isinstance(table.index_style, dict):\n                        row_name = table.dataframe.index[r - row]\n                        style = table.index_style.get(row_name, _get_style(bold=True))\n                    else:\n                        style = table.index_style or _get_style(bold=True)\n                    ws_styles[(r, c)] = style\n\n            if table.style.stripe_colors or table.style.border:\n                num_bg_cols = len(table.style.stripe_colors) if \\\n                    table.style.stripe_colors else 1\n                bg_cols = table.style.stripe_colors if \\\n                    table.style.stripe_colors else None\n\n                for i, row_offset in enumerate(range(table.header_height,\n                                                     table.height)):\n                    for c in range(col, col + table.width):\n                        bg_col = bg_cols[i % num_bg_cols] if bg_cols else None\n                        style = _get_style(bold=None, bg_col=bg_col, border=table.style.border)\n                        if (row + row_offset, c) in ws_styles:\n                            style = style + ws_styles[(row + row_offset, c)]\n                        ws_styles[(row + row_offset, c)] = style\n\n            for col_name, col_style in table.column_styles.items():\n                try:\n                    col_offset = table.get_column_offset(col_name)\n                except KeyError:\n                    continue\n                for i, r in enumerate(range(row + table.header_height, row + table.height)):\n                    style = col_style\n                    if (r, col + col_offset) in ws_styles:\n                        style = ws_styles[(r, col + col_offset)] + style\n                    ws_styles[(r, col + col_offset)] = style\n\n            for row_name, row_style in table.row_styles.items():\n                try:\n                    row_offset = table.get_row_offset(row_name)\n                except KeyError:\n                    continue\n                for i, c in enumerate(range(col + table.row_labels_width, col + table.width)):\n                    style = row_style\n                    if (row + row_offset, c) in ws_styles:\n                        style = ws_styles[(row + row_offset, c)] + style\n                    ws_styles[(row + row_offset, c)] = style\n\n            for (row_name, col_name), cell_style in table.cell_styles.items():\n                try:\n                    col_offset = table.get_column_offset(col_name)\n                    row_offset = table.get_row_offset(row_name)\n                except KeyError:\n                    continue\n                style = cell_style\n                if (row + row_offset, col + col_offset) in ws_styles:\n                    style = ws_styles[(row + row_offset, col + col_offset)] + style\n                ws_styles[(row + row_offset, col + col_offset)] = style\n\n        for (row, col), value in self.__values.items():\n            if isinstance(value, Value):\n                style = value.style\n                if style:\n                    if (row, col) in ws_styles:\n                        style = style + ws_styles[(row, col)]\n                    ws_styles[(row, col)] = style\n\n        return ws_styles", "response": "Returns a dictionary of all cells that use a non - default style."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwriting this object to an Excel Worksheet COM object.", "response": "def to_excel(self,\n                 workbook=None,\n                 worksheet=None,\n                 xl_app=None,\n                 clear=True,\n                 rename=True,\n                 resize_columns=True):\n        \"\"\"\n        Writes worksheet to an Excel Worksheet COM object.\n        Requires :py:module:`pywin32` to be installed.\n\n        :param workbook: xltable.Workbook this sheet belongs to.\n        :param worksheet: Excel COM Worksheet instance to write to.\n        :param xl_app: Excel COM Excel Application to write to.\n        :param bool clear: If a worksheet is provided, clear worksheet before writing.\n        :param bool rename: If a worksheet is provided, rename self to match the worksheet.\n        :param bool resize_columns: Resize sheet columns after writing.\n        \"\"\"\n        from win32com.client import Dispatch, constants, gencache\n\n        if xl_app is None:\n            if worksheet is not None:\n                xl_app = worksheet.Parent.Application\n            elif workbook is not None and hasattr(workbook.workbook_obj, \"Application\"):\n                xl_app = workbook.workbook_obj.Application\n            else:\n                xl_app = Dispatch(\"Excel.Application\")\n\n        xl = xl_app = gencache.EnsureDispatch(xl_app)\n\n        # Create a workbook if there isn't one already\n        if not workbook:\n            from .workbook import Workbook\n            workbook = Workbook(worksheets=[self])\n\n        if worksheet is None:\n            # If there's no worksheet then call Workbook.to_excel which will create one\n            return workbook.to_excel(xl_app=xl_app, resize_columns=resize_columns)\n\n        if rename:\n            self.__name = worksheet.Name\n\n        # set manual calculation and turn off screen updating while we update the cells\n        calculation = xl.Calculation\n        screen_updating = xl.ScreenUpdating\n        xl.Calculation = constants.xlCalculationManual\n        xl.ScreenUpdating = False\n        try:\n            # clear the worksheet and reset the styles\n            if clear:\n                worksheet.Cells.ClearContents()\n                worksheet.Cells.Font.Bold = False\n                worksheet.Cells.Font.Size = 11\n                worksheet.Cells.Font.Color = 0x000000\n                worksheet.Cells.Interior.ColorIndex = 0\n                worksheet.Cells.NumberFormat = \"General\"\n\n            # get any array formula tables\n            array_formula_tables = []\n            for table, (row, col) in self.__tables.values():\n                if isinstance(table, ArrayFormula):\n                    array_formula_tables.append((row, col, row + table.height, col + table.width))\n\n            def _is_in_array_formula_table(row, col):\n                \"\"\"returns True if this formula cell is part of an array formula table\"\"\"\n                for top, left, bottom, right in array_formula_tables:\n                    if bottom >= row >= top and left <= col <= right:\n                        return True\n                return False\n\n            origin = worksheet.Range(\"A1\")\n            xl_cell = origin\n            for r, row in enumerate(self.iterrows(workbook)):\n                row = _to_pywintypes(row)\n\n                # set the value and formulae to the excel range (it's much quicker to\n                # write a row at a time and update the formula than it is it do it\n                # cell by cell)\n                if clear:\n                    xl_row = worksheet.Range(xl_cell, xl_cell.Offset(1, len(row)))\n                    xl_row.Value = row\n                else:\n                    for c, value in enumerate(row):\n                        if value is not None:\n                            xl_cell.Offset(1, 1 + c).Value = value\n\n                for c, value in enumerate(row):\n                    if isinstance(value, str):\n                        if value.startswith(\"=\"):\n                            formula_value = self.__formula_values.get((r, c), 0)\n                            xl_cell.Offset(1, 1 + c).Value = formula_value\n                            xl_cell.Offset(1, 1 + c).Formula = value\n                        elif value.startswith(\"{=\") \\\n                        and not _is_in_array_formula_table(r, c):\n                            formula_value = self.__formula_values.get((r, c), 0)\n                            xl_cell.Offset(1, 1 + c).Value = formula_value\n                            xl_cell.Offset(1, 1 + c).FormulaArray = value\n\n                # move to the next row\n                xl_cell = xl_cell.Offset(2, 1)\n\n            # set any array formulas\n            for table, (row, col) in self.__tables.values():\n                if isinstance(table, ArrayFormula):\n                    data = table.get_data(workbook, row, col)\n                    height, width = data.shape\n                    upper_left = origin.Offset(row+1, col+1)\n                    lower_right = origin.Offset(row + height, col + width)\n\n                    xl_range = worksheet.Range(upper_left, lower_right)\n                    xl_range.FormulaArray = table.formula.get_formula(workbook, row, col)\n\n            # set any formatting\n            for (row, col), style in self._get_all_styles().items():\n                r = origin.Offset(1 + row, 1 + col)\n                if style.bold:\n                    r.Font.Bold = True\n                if style.excel_number_format is not None:\n                    r.NumberFormat = style.excel_number_format\n                if style.size is not None:\n                    r.Font.Size = style.size\n                if style.text_color is not None:\n                    r.Font.Color = _to_bgr(style.text_color)\n                if style.bg_color is not None:\n                    r.Interior.Color = _to_bgr(style.bg_color)\n                if style.text_wrap or style.border:\n                    raise Exception(\"text wrap and border not implemented\")\n\n            # add any charts\n            for chart, (row, col) in self.__charts:\n                top_left = origin.Offset(1 + row, 1 + col)\n                xl_chart = worksheet.ChartObjects().Add(top_left.Left, top_left.Top, 360, 220).Chart\n                xl_chart.ChartType = _to_excel_chart_type(chart.type, chart.subtype)\n                if chart.title:\n                    xl_chart.ChartTitle = chart.title\n                for series in chart.iter_series(self, row, col):\n                    xl_series = xl_chart.SeriesCollection().NewSeries()\n                    xl_series.Values = \"=%s!%s\" % (self.name, series[\"values\"].lstrip(\"=\"))\n                    if \"categories\" in series:\n                        xl_series.XValues = \"=%s!%s\" % (self.name, series[\"categories\"].lstrip(\"=\"))\n                    if \"name\" in series:\n                        xl_series.Name = series[\"name\"]\n\n        finally:\n            xl.ScreenUpdating = screen_updating\n            xl.Calculation = calculation\n\n        if resize_columns:\n            try:\n                worksheet.Cells.EntireColumn.AutoFit()\n            except:\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwrites this worksheet to a. xlsx file using xlsxwriter.", "response": "def to_xlsx(self, filename=None, workbook=None):\n        \"\"\"\n        Write worksheet to a .xlsx file using xlsxwriter.\n\n        :param str filename: Filename to write to. If None no file is written.\n        :param xltable.Workbook: Workbook this sheet belongs to. If None a new workbook\n        will be created with this worksheet as the only sheet.\n        :return: :py:class:`xlsxwriter.workbook.Workbook` instance.\n        \"\"\"\n        from .workbook import Workbook\n        if not workbook:\n            workbook = Workbook(filename=filename)\n            workbook.append(self)\n            return workbook.to_xlsx()\n        ws = workbook.add_xlsx_worksheet(self, self.name)\n\n        _styles = {}\n        def _get_xlsx_style(cell_style):\n            \"\"\"\n            convert rb.excel style to xlsx writer style\n            \"\"\"\n            style_args = (\n                cell_style.bold,\n                cell_style.excel_number_format,\n                cell_style.text_color,\n                cell_style.bg_color,\n                cell_style.size,\n                cell_style.text_wrap,\n                cell_style.text_wrap,\n                cell_style.border,\n                cell_style.align,\n                cell_style.valign\n            )\n            if (style_args) not in _styles:\n                style = workbook.add_format()\n                if cell_style.bold:\n                    style.set_bold()\n                if cell_style.excel_number_format is not None:\n                    style.set_num_format(cell_style.excel_number_format)\n                if cell_style.text_color is not None:\n                    style.set_font_color(\"#%06x\" % cell_style.text_color)\n                if cell_style.bg_color is not None:\n                    style.set_bg_color(\"#%06x\" % cell_style.bg_color)\n                if cell_style.size is not None:\n                    style.set_font_size(cell_style.size)\n                if cell_style.text_wrap:\n                    style.set_text_wrap()\n                if cell_style.border:\n                    if isinstance(cell_style.border, frozenset):\n                        for border_position, border_style in cell_style.border:\n                            if border_position == \"bottom\":\n                                style.set_bottom(border_style)\n                            elif border_position == \"top\":\n                                style.set_top(border_style)\n                            elif border_position == \"left\":\n                                style.set_left(border_style)\n                            elif border_position == \"right\":\n                                style.set_right(border_style)\n                            else:\n                                raise AssertionError(\"Unknown border position '%s'.\" % border_position)\n                    else:\n                        style.set_border(cell_style.border)\n                if cell_style.align:\n                    style.set_align(cell_style.align)\n                if cell_style.valign:\n                    style.set_valign(cell_style.valign)\n\n                _styles[style_args] = style\n\n            return _styles[style_args]\n\n        # pre-compute the cells with non-default styles\n        ws_styles = self._get_all_styles()\n        ws_styles = {(r, c): _get_xlsx_style(s) for ((r, c), s) in ws_styles.items()}\n        plain_style = _get_xlsx_style(CellStyle())\n\n        # get any array formula tables\n        array_formula_tables = []\n        for table, (row, col) in self.__tables.values():\n            if isinstance(table, ArrayFormula):\n                array_formula_tables.append((row, col, row + table.height, col + table.width))\n\n        def _is_in_array_formula_table(row, col):\n            \"\"\"returns True if this formula cell is part of an array formula table\"\"\"\n            for top, left, bottom, right in array_formula_tables:\n                if bottom >= row >= top and left <= col <= right:\n                    return True\n            return False\n\n        # write the rows to the worksheet\n        for ir, row in enumerate(self.iterrows(workbook)):\n            for ic, cell in enumerate(row):\n                style = ws_styles.get((ir, ic), plain_style)\n                if isinstance(cell, str):\n                    if cell.startswith(\"=\"):\n                        formula_value = self.__formula_values.get((ir, ic), 0)\n                        ws.write_formula(ir, ic, cell, style, value=formula_value)\n                    elif cell.startswith(\"{=\"):\n                        # array formulas tables are written after everything else,\n                        # but individual cells can also be array formulas\n                        if not _is_in_array_formula_table(ir, ic):\n                            formula_value = self.__formula_values.get((ir, ic), 0)\n                            ws.write_array_formula(ir, ic, ir, ic,\n                                                   cell, style,\n                                                   value=formula_value)\n                    else:\n                        ws.write(ir, ic, cell, style)\n                else:\n                    if isinstance(cell, self._xlsx_unsupported_types):\n                        ws.write(ir, ic, str(cell), style)\n                    else:\n                        try:\n                            ws.write(ir, ic, cell, style)\n                        except TypeError:\n                            ws.write(ir, ic, str(cell), style)\n                            unsupported_types = set(self._xlsx_unsupported_types)\n                            unsupported_types.add(type(cell))\n                            self.__class__._xlsx_unsupported_types = tuple(unsupported_types)\n\n        # set any array formulas\n        for table, (row, col) in self.__tables.values():\n            if isinstance(table, ArrayFormula):\n                style = ws_styles.get((row, col), plain_style)\n                data = table.get_data(workbook, row, col)\n                height, width = data.shape\n                bottom, right = (row + height - 1, col + width -1)\n                formula = table.formula.get_formula(workbook, row, col)\n                ws.write_array_formula(row, col, bottom, right, formula, style, value=data[0][0])\n\n                for y in range(height):\n                    for x in range(width):\n                        if y == 0 and x == 0:\n                            continue\n                        ir, ic = row + y, col + x\n                        style = ws_styles.get((ir, ic), plain_style)\n                        cell = data[y][x]\n                        if isinstance(cell, str):\n                            cell_str = cell.encode(\"ascii\", \"xmlcharrefreplace\").decode(\"ascii\")\n                            ws.write_formula(ir, ic, cell_str, style)\n                        else:\n                            ws.write(ir, ic, cell, style)\n\n        # set any non-default column widths\n        for ic, width in self._get_column_widths().items():\n            ws.set_column(ic, ic, width)\n\n        # add any charts\n        for chart, (row, col) in self.__charts:\n            kwargs = {\"type\": chart.type}\n            if chart.subtype:\n                kwargs[\"subtype\"] = chart.subtype\n            xl_chart = workbook.workbook_obj.add_chart(kwargs)\n\n            if chart.show_blanks:\n                xl_chart.show_blanks_as(chart.show_blanks)\n\n            for series in chart.iter_series(workbook, row, col):\n                # xlsxwriter expects the sheetname in the formula\n                values = series.get(\"values\")\n                if isinstance(values, str) and values.startswith(\"=\") and \"!\" not in values:\n                    series[\"values\"] = \"='%s'!%s\" % (self.name, values.lstrip(\"=\"))\n                    \n                categories = series.get(\"categories\")\n                if isinstance(categories, str) and categories.startswith(\"=\") and \"!\" not in categories:\n                    series[\"categories\"] = \"='%s'!%s\" % (self.name, categories.lstrip(\"=\"))\n\n                xl_chart.add_series(series)\n\n            xl_chart.set_size({\"width\": chart.width, \"height\": chart.height})\n\n            if chart.title:\n                xl_chart.set_title({\"name\": chart.title})\n\n            if chart.legend_position:\n                xl_chart.set_legend({\"position\": chart.legend_position})\n\n            if chart.x_axis:\n                xl_chart.set_x_axis(chart.x_axis)\n\n            if chart.y_axis:\n                xl_chart.set_y_axis(chart.y_axis)\n\n            ws.insert_chart(row, col, xl_chart)\n\n        # add any groups\n        for tables, collapsed in self.__groups:\n            min_row, max_row = 1000000, -1\n\n            for table, (row, col) in self.__tables.values():\n                if table in tables:\n                    min_row = min(min_row, row)\n                    max_row = max(max_row, row + table.height)\n            for i in range(min_row, max_row+1):\n                ws.set_row(i, None, None, {'level': 1, 'hidden': collapsed})\n\n        if filename:\n            workbook.close()\n        return workbook"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndecorates a configuration field formatter function to register it with the `get_field_formatter` accessor. This decorator also performs common helpers for the formatter functions: - Does type checking on the field argument passed to a formatter. - Assembles a section node from the nodes returned by the formatter.", "response": "def register_formatter(field_typestr):\n    \"\"\"Decorate a configuration field formatter function to register it with\n    the `get_field_formatter` accessor.\n\n    This decorator also performs common helpers for the formatter functions:\n\n    - Does type checking on the field argument passed to a formatter.\n    - Assembles a section node from the nodes returned by the formatter.\n    \"\"\"\n    def decorator_register(formatter):\n\n        @functools.wraps(formatter)\n        def wrapped_formatter(*args, **kwargs):\n            field_name = args[0]\n            field = args[1]\n            field_id = args[2]\n\n            # Before running the formatter, do type checking\n            field_type = get_type(field_typestr)\n            if not isinstance(field, field_type):\n                message = ('Field {0} ({1!r}) is not an '\n                           '{2} type. It is an {3}.')\n                raise ValueError(\n                    message.format(field_name, field, field_typestr,\n                                   typestring(field)))\n\n            # Run the formatter itself\n            nodes = formatter(*args, **kwargs)\n\n            # Package nodes from the formatter into a section\n            section = make_section(\n                section_id=field_id + '-section',\n                contents=nodes)\n            return section\n\n        FIELD_FORMATTERS[field_typestr] = wrapped_formatter\n\n        return wrapped_formatter\n    return decorator_register"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef format_configurablefield_nodes(field_name, field, field_id, state, lineno):\n    # Custom default target definition list that links to Task topics\n    default_item = nodes.definition_list_item()\n    default_item.append(nodes.term(text=\"Default\"))\n    default_item_content = nodes.definition()\n    para = nodes.paragraph()\n    name = '.'.join((field.target.__module__, field.target.__name__))\n    para += pending_task_xref(rawsource=name)\n    default_item_content += para\n    default_item += default_item_content\n\n    # Definition list for key-value metadata\n    dl = nodes.definition_list()\n    dl += default_item\n    dl += create_field_type_item_node(field, state)\n\n    # Doc for this ConfigurableField, parsed as rst\n    desc_node = create_description_node(field, state)\n\n    # Title for configuration field\n    title = create_title_node(field_name, field, field_id, state, lineno)\n\n    return [title, dl, desc_node]", "response": "Create a section node that documents a ConfigurableField."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a section node that documents a ListField config field.", "response": "def format_listfield_nodes(field_name, field, field_id, state, lineno):\n    \"\"\"Create a section node that documents a ListField config field.\n\n    Parameters\n    ----------\n    field_name : `str`\n        Name of the configuration field (the attribute name of on the config\n        class).\n    field : ``lsst.pex.config.ListField``\n        A configuration field.\n    field_id : `str`\n        Unique identifier for this field. This is used as the id and name of\n        the section node. with a -section suffix\n    state : ``docutils.statemachine.State``\n        Usually the directive's ``state`` attribute.\n    lineno (`int`)\n        Usually the directive's ``lineno`` attribute.\n\n    Returns\n    -------\n    ``docutils.nodes.section``\n        Section containing documentation nodes for the ListField.\n    \"\"\"\n    # ListField's store their item types in the itemtype attribute\n    itemtype_node = nodes.definition_list_item()\n    itemtype_node += nodes.term(text='Item type')\n    itemtype_def = nodes.definition()\n    itemtype_def += make_python_xref_nodes_for_type(\n        field.itemtype,\n        state,\n        hide_namespace=False)\n    itemtype_node += itemtype_def\n\n    minlength_node = None\n    if field.minLength:\n        minlength_node = nodes.definition_list_item()\n        minlength_node += nodes.term(text='Minimum length')\n        minlength_def = nodes.definition()\n        minlength_def += nodes.paragraph(text=str(field.minLength))\n        minlength_node += minlength_def\n\n    maxlength_node = None\n    if field.maxLength:\n        maxlength_node = nodes.definition_list_item()\n        maxlength_node += nodes.term(text='Maximum length')\n        maxlength_def = nodes.definition()\n        maxlength_def += nodes.paragraph(text=str(field.maxLength))\n        maxlength_node += maxlength_def\n\n    length_node = None\n    if field.length:\n        length_node = nodes.definition_list_item()\n        length_node += nodes.term(text='Required length')\n        length_def = nodes.definition()\n        length_def += nodes.paragraph(text=str(field.length))\n        length_node += length_def\n\n    # Type description\n    field_type_item = nodes.definition_list_item()\n    field_type_item.append(nodes.term(text=\"Field type\"))\n    field_type_item_content = nodes.definition()\n    field_type_item_content_p = nodes.paragraph()\n    field_type_item_content_p += make_python_xref_nodes_for_type(\n        field.itemtype,\n        state,\n        hide_namespace=False)[0].children[0]\n    field_type_item_content_p += nodes.Text(' ', ' ')\n    field_type_item_content_p += make_python_xref_nodes_for_type(\n        type(field),\n        state,\n        hide_namespace=True)[0].children[0]\n    if field.optional:\n        field_type_item_content_p += nodes.Text(' (optional)', ' (optional)')\n    field_type_item_content += field_type_item_content_p\n    field_type_item += field_type_item_content\n\n    # Reference target\n    env = state.document.settings.env\n    ref_target = create_configfield_ref_target_node(field_id, env, lineno)\n\n    # Title is the field's attribute name\n    title = nodes.title(text=field_name)\n    title += ref_target\n\n    # Definition list for key-value metadata\n    dl = nodes.definition_list()\n    dl += create_default_item_node(field, state)\n    dl += field_type_item\n    if minlength_node:\n        dl += minlength_node\n    if maxlength_node:\n        dl += maxlength_node\n    if length_node:\n        dl += length_node\n\n    # Doc for this ConfigurableField, parsed as rst\n    desc_node = create_description_node(field, state)\n\n    # Title for configuration field\n    title = create_title_node(field_name, field, field_id, state, lineno)\n\n    return [title, dl, desc_node]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef format_choicefield_nodes(field_name, field, field_id, state, lineno):\n    # Create a definition list for the choices\n    choice_dl = nodes.definition_list()\n    for choice_value, choice_doc in field.allowed.items():\n        item = nodes.definition_list_item()\n        item_term = nodes.term()\n        item_term += nodes.literal(text=repr(choice_value))\n        item += item_term\n        item_definition = nodes.definition()\n        item_definition.append(nodes.paragraph(text=choice_doc))\n        item += item_definition\n        choice_dl.append(item)\n\n    choices_node = nodes.definition_list_item()\n    choices_node.append(nodes.term(text='Choices'))\n    choices_definition = nodes.definition()\n    choices_definition.append(choice_dl)\n    choices_node.append(choices_definition)\n\n    # Field type\n    field_type_item = nodes.definition_list_item()\n    field_type_item.append(nodes.term(text=\"Field type\"))\n    field_type_item_content = nodes.definition()\n    field_type_item_content_p = nodes.paragraph()\n    field_type_item_content_p += make_python_xref_nodes_for_type(\n        field.dtype,\n        state,\n        hide_namespace=False)[0].children[0]\n    field_type_item_content_p += nodes.Text(' ', ' ')\n    field_type_item_content_p += make_python_xref_nodes_for_type(\n        type(field),\n        state,\n        hide_namespace=True)[0].children[0]\n    if field.optional:\n        field_type_item_content_p += nodes.Text(' (optional)', ' (optional)')\n    field_type_item_content += field_type_item_content_p\n    field_type_item += field_type_item_content\n\n    # Definition list for key-value metadata\n    dl = nodes.definition_list()\n    dl += create_default_item_node(field, state)\n    dl += field_type_item\n    dl += choices_node\n\n    # Doc for this ConfigurableField, parsed as rst\n    desc_node = create_description_node(field, state)\n\n    # Title for configuration field\n    title = create_title_node(field_name, field, field_id, state, lineno)\n\n    return [title, dl, desc_node]", "response": "Create a section node that documents a ChoiceField config field."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a section node that documents a RangeField config field.", "response": "def format_rangefield_nodes(field_name, field, field_id, state, lineno):\n    \"\"\"Create a section node that documents a RangeField config field.\n\n    Parameters\n    ----------\n    field_name : `str`\n        Name of the configuration field (the attribute name of on the config\n        class).\n    field : ``lsst.pex.config.RangeField``\n        A configuration field.\n    field_id : `str`\n        Unique identifier for this field. This is used as the id and name of\n        the section node. with a -section suffix\n    state : ``docutils.statemachine.State``\n        Usually the directive's ``state`` attribute.\n    lineno (`int`)\n        Usually the directive's ``lineno`` attribute.\n\n    Returns\n    -------\n    ``docutils.nodes.section``\n        Section containing documentation nodes for the RangeField.\n    \"\"\"\n    # Field type\n    field_type_item = nodes.definition_list_item()\n    field_type_item.append(nodes.term(text=\"Field type\"))\n    field_type_item_content = nodes.definition()\n    field_type_item_content_p = nodes.paragraph()\n    field_type_item_content_p += make_python_xref_nodes_for_type(\n        field.dtype,\n        state,\n        hide_namespace=False)[0].children[0]\n    field_type_item_content_p += nodes.Text(' ', ' ')\n    field_type_item_content_p += make_python_xref_nodes_for_type(\n        type(field),\n        state,\n        hide_namespace=True)[0].children[0]\n    if field.optional:\n        field_type_item_content_p += nodes.Text(' (optional)', ' (optional)')\n    field_type_item_content += field_type_item_content_p\n    field_type_item += field_type_item_content\n\n    # Format definition list item for the range\n    range_node = nodes.definition_list_item()\n    range_node += nodes.term(text='Range')\n    range_node_def = nodes.definition()\n    range_node_def += nodes.paragraph(text=field.rangeString)\n    range_node += range_node_def\n\n    # Definition list for key-value metadata\n    dl = nodes.definition_list()\n    dl += create_default_item_node(field, state)\n    dl += field_type_item\n    dl += range_node\n\n    # Doc for this field, parsed as rst\n    desc_node = create_description_node(field, state)\n\n    # Title for configuration field\n    title = create_title_node(field_name, field, field_id, state, lineno)\n\n    return [title, dl, desc_node]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a section node that documents a DictField config field.", "response": "def format_dictfield_nodes(field_name, field, field_id, state, lineno):\n    \"\"\"Create a section node that documents a DictField config field.\n\n    Parameters\n    ----------\n    field_name : `str`\n        Name of the configuration field (the attribute name of on the config\n        class).\n    field : ``lsst.pex.config.DictField``\n        A configuration field.\n    field_id : `str`\n        Unique identifier for this field. This is used as the id and name of\n        the section node. with a -section suffix\n    state : ``docutils.statemachine.State``\n        Usually the directive's ``state`` attribute.\n    lineno (`int`)\n        Usually the directive's ``lineno`` attribute.\n\n    Returns\n    -------\n    ``docutils.nodes.section``\n        Section containing documentation nodes for the DictField.\n    \"\"\"\n    # Custom value type field for definition list\n    valuetype_item = nodes.definition_list_item()\n    valuetype_item = nodes.term(text='Value type')\n    valuetype_def = nodes.definition()\n    valuetype_def += make_python_xref_nodes_for_type(\n        field.itemtype,\n        state,\n        hide_namespace=False)\n    valuetype_item += valuetype_def\n\n    # Definition list for key-value metadata\n    dl = nodes.definition_list()\n    dl += create_default_item_node(field, state)\n    dl += create_field_type_item_node(field, state)\n    dl += create_keytype_item_node(field, state)\n    dl += valuetype_item\n\n    # Doc for this field, parsed as rst\n    desc_node = create_description_node(field, state)\n\n    # Title for configuration field\n    title = create_title_node(field_name, field, field_id, state, lineno)\n\n    return [title, dl, desc_node]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a section node that documents a ConfigField config field.", "response": "def format_configfield_nodes(field_name, field, field_id, state, lineno):\n    \"\"\"Create a section node that documents a ConfigField config field.\n\n    Parameters\n    ----------\n    field_name : `str`\n        Name of the configuration field (the attribute name of on the config\n        class).\n    field : ``lsst.pex.config.ConfigField``\n        A configuration field.\n    field_id : `str`\n        Unique identifier for this field. This is used as the id and name of\n        the section node. with a -section suffix\n    state : ``docutils.statemachine.State``\n        Usually the directive's ``state`` attribute.\n    lineno (`int`)\n        Usually the directive's ``lineno`` attribute.\n\n    Returns\n    -------\n    ``docutils.nodes.section``\n        Section containing documentation nodes for the ConfigField.\n    \"\"\"\n    # Default data type node\n    dtype_node = nodes.definition_list_item()\n    dtype_node = nodes.term(text='Data type')\n    dtype_def = nodes.definition()\n    dtype_def_para = nodes.paragraph()\n    name = '.'.join((field.dtype.__module__, field.dtype.__name__))\n    dtype_def_para += pending_config_xref(rawsource=name)\n    dtype_def += dtype_def_para\n    dtype_node += dtype_def\n\n    # Definition list for key-value metadata\n    dl = nodes.definition_list()\n    dl += dtype_node\n    dl += create_field_type_item_node(field, state)\n\n    # Doc for this field, parsed as rst\n    desc_node = create_description_node(field, state)\n\n    # Title for configuration field\n    title = create_title_node(field_name, field, field_id, state, lineno)\n\n    return [title, dl, desc_node]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef format_configchoicefield_nodes(field_name, field, field_id, state, lineno):\n    # Create a definition list for the choices\n    choice_dl = nodes.definition_list()\n    for choice_value, choice_class in field.typemap.items():\n        item = nodes.definition_list_item()\n        item_term = nodes.term()\n        item_term += nodes.literal(text=repr(choice_value))\n        item += item_term\n        item_definition = nodes.definition()\n        def_para = nodes.paragraph()\n        name = '.'.join((choice_class.__module__, choice_class.__name__))\n        def_para += pending_config_xref(rawsource=name)\n        item_definition += def_para\n        item += item_definition\n        choice_dl.append(item)\n\n    choices_node = nodes.definition_list_item()\n    choices_node.append(nodes.term(text='Choices'))\n    choices_definition = nodes.definition()\n    choices_definition.append(choice_dl)\n    choices_node.append(choices_definition)\n\n    # Field type\n    field_type_item = nodes.definition_list_item()\n    field_type_item.append(nodes.term(text=\"Field type\"))\n    field_type_item_content = nodes.definition()\n    field_type_item_content_p = nodes.paragraph()\n    if field.multi:\n        multi_text = \"Multi-selection \"\n    else:\n        multi_text = \"Single-selection \"\n    field_type_item_content_p += nodes.Text(multi_text, multi_text)\n    field_type_item_content_p += make_python_xref_nodes_for_type(\n        type(field),\n        state,\n        hide_namespace=True)[0].children[0]\n    if field.optional:\n        field_type_item_content_p += nodes.Text(' (optional)', ' (optional)')\n    field_type_item_content += field_type_item_content_p\n    field_type_item += field_type_item_content\n\n    dl = nodes.definition_list()\n    dl += create_default_item_node(field, state)\n    dl += field_type_item\n    dl += choices_node\n\n    # Doc for this field, parsed as rst\n    desc_node = create_description_node(field, state)\n\n    # Title for configuration field\n    title = create_title_node(field_name, field, field_id, state, lineno)\n\n    return [title, dl, desc_node]", "response": "Create a section node that documents a ConfigChoiceField config field."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef format_configdictfield_nodes(field_name, field, field_id, state, lineno):\n    # Valuetype links to a Config task topic\n    value_item = nodes.definition_list_item()\n    value_item += nodes.term(text=\"Value type\")\n    value_item_def = nodes.definition()\n    value_item_def_para = nodes.paragraph()\n    name = '.'.join((field.itemtype.__module__, field.itemtype.__name__))\n    value_item_def_para += pending_config_xref(rawsource=name)\n    value_item_def += value_item_def_para\n    value_item += value_item_def\n\n    dl = nodes.definition_list()\n    dl += create_default_item_node(field, state)\n    dl += create_field_type_item_node(field, state)\n    dl += create_keytype_item_node(field, state)\n    dl += value_item\n\n    # Doc for this field, parsed as rst\n    desc_node = create_description_node(field, state)\n\n    # Title for configuration field\n    title = create_title_node(field_name, field, field_id, state, lineno)\n\n    return [title, dl, desc_node]", "response": "Create a section node that documents a ConfigDictField."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a section node that documents a RegistryField config field.", "response": "def format_registryfield_nodes(field_name, field, field_id, state, lineno):\n    \"\"\"Create a section node that documents a RegistryField config field.\n\n    Parameters\n    ----------\n    field_name : `str`\n        Name of the configuration field (the attribute name of on the config\n        class).\n    field : ``lsst.pex.config.RegistryField``\n        A configuration field.\n    field_id : `str`\n        Unique identifier for this field. This is used as the id and name of\n        the section node. with a -section suffix\n    state : ``docutils.statemachine.State``\n        Usually the directive's ``state`` attribute.\n    lineno (`int`)\n        Usually the directive's ``lineno`` attribute.\n\n    Returns\n    -------\n    ``docutils.nodes.section``\n        Section containing documentation nodes for the RegistryField.\n    \"\"\"\n    from lsst.pex.config.registry import ConfigurableWrapper\n\n    # Create a definition list for the choices\n    # This iteration is over field.registry.items(), not field.items(), so\n    # that the directive shows the configurables, not their ConfigClasses.\n    choice_dl = nodes.definition_list()\n    for choice_value, choice_class in field.registry.items():\n        # Introspect the class name from item in the registry. This is harder\n        # than it should be. Most registry items seem to fall in the first\n        # category. Some are ConfigurableWrapper types that expose the\n        # underlying task class through the _target attribute.\n        if hasattr(choice_class, '__module__') \\\n                and hasattr(choice_class, '__name__'):\n            name = '.'.join((choice_class.__module__, choice_class.__name__))\n        elif isinstance(choice_class, ConfigurableWrapper):\n            name = '.'.join((choice_class._target.__class__.__module__,\n                             choice_class._target.__class__.__name__))\n        else:\n            name = '.'.join((choice_class.__class__.__module__,\n                             choice_class.__class__.__name__))\n\n        item = nodes.definition_list_item()\n        item_term = nodes.term()\n        item_term += nodes.literal(text=repr(choice_value))\n        item += item_term\n        item_definition = nodes.definition()\n        def_para = nodes.paragraph()\n        def_para += pending_task_xref(rawsource=name)\n        item_definition += def_para\n        item += item_definition\n        choice_dl.append(item)\n\n    choices_node = nodes.definition_list_item()\n    choices_node.append(nodes.term(text='Choices'))\n    choices_definition = nodes.definition()\n    choices_definition.append(choice_dl)\n    choices_node.append(choices_definition)\n\n    # Field type\n    field_type_item = nodes.definition_list_item()\n    field_type_item.append(nodes.term(text=\"Field type\"))\n    field_type_item_content = nodes.definition()\n    field_type_item_content_p = nodes.paragraph()\n    if field.multi:\n        multi_text = \"Multi-selection \"\n    else:\n        multi_text = \"Single-selection \"\n    field_type_item_content_p += nodes.Text(multi_text, multi_text)\n    field_type_item_content_p += make_python_xref_nodes_for_type(\n        type(field),\n        state,\n        hide_namespace=True)[0].children[0]\n    if field.optional:\n        field_type_item_content_p += nodes.Text(' (optional)', ' (optional)')\n    field_type_item_content += field_type_item_content_p\n    field_type_item += field_type_item_content\n\n    dl = nodes.definition_list()\n    dl += create_default_item_node(field, state)\n    dl += field_type_item\n    dl += choices_node\n\n    # Doc for this field, parsed as rst\n    desc_node = create_description_node(field, state)\n\n    # Title for configuration field\n    title = create_title_node(field_name, field, field_id, state, lineno)\n\n    return [title, dl, desc_node]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_field_type_item_node(field, state):\n    type_item = nodes.definition_list_item()\n    type_item.append(nodes.term(text=\"Field type\"))\n    type_item_content = nodes.definition()\n    type_item_content_p = nodes.paragraph()\n    type_item_content_p += make_python_xref_nodes_for_type(\n        type(field),\n        state,\n        hide_namespace=True)[0].children\n    if field.optional:\n        type_item_content_p += nodes.Text(' (optional)', ' (optional)')\n    type_item_content += type_item_content_p\n    type_item += type_item_content\n    return type_item", "response": "Create a definition list item node that describes a field s type."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_default_item_node(field, state):\n    default_item = nodes.definition_list_item()\n    default_item.append(nodes.term(text=\"Default\"))\n    default_item_content = nodes.definition()\n    default_item_content.append(\n        nodes.literal(text=repr(field.default))\n    )\n    default_item.append(default_item_content)\n    return default_item", "response": "Create a definition list item node that describes the default value of a ConfigurableField config."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a definition list item node that describes the key type for the given field.", "response": "def create_keytype_item_node(field, state):\n    \"\"\"Create a definition list item node that describes the key type\n    of a dict-type config field.\n\n    Parameters\n    ----------\n    field : ``lsst.pex.config.Field``\n        A ``lsst.pex.config.DictField`` or ``lsst.pex.config.DictConfigField``.\n    state : ``docutils.statemachine.State``\n        Usually the directive's ``state`` attribute.\n\n    Returns\n    -------\n    ``docutils.nodes.definition_list_item``\n        Definition list item that describes the key type for the field.\n    \"\"\"\n    keytype_node = nodes.definition_list_item()\n    keytype_node = nodes.term(text='Key type')\n    keytype_def = nodes.definition()\n    keytype_def += make_python_xref_nodes_for_type(\n        field.keytype,\n        state,\n        hide_namespace=False)\n    keytype_node += keytype_def\n    return keytype_node"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_description_node(field, state):\n    doc_container_node = nodes.container()\n    doc_container_node += parse_rst_content(field.doc, state)\n\n    return doc_container_node", "response": "Creates a node that represents the description of the given field."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_title_node(field_name, field, field_id, state, lineno):\n    # Reference target\n    env = state.document.settings.env\n    ref_target = create_configfield_ref_target_node(field_id, env, lineno)\n\n    # Title is the field's attribute name\n    title = nodes.title(text=field_name)\n    title += ref_target\n\n    return title", "response": "Create docutils nodes for the configuration field s title and reference target node."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a target node that marks a configuration field.", "response": "def create_configfield_ref_target_node(target_id, env, lineno):\n    \"\"\"Create a ``target`` node that marks a configuration field.\n\n    Internally, this also adds to the ``lsst_configfields`` attribute of the\n    environment that is consumed by `documenteer.sphinxext.lssttasks.\n    crossrefs.process_pending_configfield_xref_nodes`.\n\n    See also\n    --------\n    `documenteer.sphinxext.lssttasks.crossrefs.process_pending_configfield_xref_nodes`\n    \"\"\"\n    target_node = nodes.target('', '', ids=[target_id])\n\n    # Store these task/configurable topic nodes in the environment for later\n    # cross referencing.\n    if not hasattr(env, 'lsst_configfields'):\n        env.lsst_configfields = {}\n    env.lsst_configfields[target_id] = {\n        'docname': env.docname,\n        'lineno': lineno,\n        'target': target_node,\n    }\n\n    return target_node"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef run(self):\n        logger = getLogger(__name__)\n\n        try:\n            task_class_name = self.arguments[0]\n        except IndexError:\n            raise SphinxError(\n                '{} directive requires a Task class name as an '\n                'argument'.format(self.directive_name))\n        logger.debug('%s using Task class %s', self.directive_name,\n                     task_class_name)\n\n        task_config_class = get_task_config_class(task_class_name)\n        subtask_fields = get_subtask_fields(task_config_class)\n\n        all_nodes = []\n        for field_name, field in subtask_fields.items():\n            field_id = format_configfield_id(\n                '.'.join((task_config_class.__module__,\n                          task_config_class.__name__)),\n                field_name)\n            try:\n                format_field_nodes = get_field_formatter(field)\n            except ValueError:\n                logger.debug('Skipping unknown config field type, '\n                             '{0!r}'.format(field))\n                continue\n\n            all_nodes.append(\n                format_field_nodes(field_name, field, field_id, self.state,\n                                   self.lineno)\n            )\n\n        # Fallback if no configuration items are present\n        if len(all_nodes) == 0:\n            message = 'No subtasks.'\n            return [nodes.paragraph(text=message)]\n\n        return all_nodes", "response": "Main entrypoint method.\n\n        Returns\n        -------\n        new_nodes : `list`\n            Nodes to add to the doctree."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef run(self):\n        logger = getLogger(__name__)\n\n        try:\n            config_class_name = self.arguments[0]\n        except IndexError:\n            raise SphinxError(\n                '{} directive requires a Config class '\n                'name as an argument'.format(self.directive_name))\n        logger.debug('%s using Config class %s', self.directive_name,\n                     config_class_name)\n\n        config_class = get_type(config_class_name)\n\n        config_fields = get_task_config_fields(config_class)\n\n        all_nodes = []\n\n        for field_name, field in config_fields.items():\n            field_id = format_configfield_id(\n                '.'.join((config_class.__module__,\n                          config_class.__name__)),\n                field_name)\n\n            try:\n                format_field_nodes = get_field_formatter(field)\n            except ValueError:\n                logger.debug('Skipping unknown config field type, '\n                             '{0!r}'.format(field))\n                continue\n\n            all_nodes.append(\n                format_field_nodes(field_name, field, field_id, self.state,\n                                   self.lineno)\n            )\n\n        # Fallback if no configuration items are present\n        if len(all_nodes) == 0:\n            message = 'No configuration fields.'\n            return [nodes.paragraph(text=message)]\n\n        return all_nodes", "response": "Main entrypoint method.\n\n        Returns\n        -------\n        new_nodes : `list`\n            Nodes to add to the doctree."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nassign type to all atoms in the current molecule.", "response": "def assign_type(mol, force_recalc=False):\n    \"\"\" PATTY [Bush et al. J. Inf. Comput. Sci 33 (1993) 756-762]\n    TODO: not yet implemented\n\n    1:cation 2:anion 3:donor 4:acceptor\n    5:polar 6:hydrophobe 7:others\n    \"\"\"\n    if \"PATTY\" in mol.descriptors and not force_recalc:\n        return\n    mol.require(\"Phys_charge\")\n    for i, atom in mol.atoms_iter():\n        # default is 7 (others)\n        nbrcnt = mol.neighbor_count(i)\n        if atom.charge > 0 or atom.charge_phys > 0 or \\\n                atom.charge_conj > 0 and not atom.n_oxide:\n            atom.type = 1  # cation\n        elif atom.charge < 0 or atom.charge_phys < 0 or \\\n                atom.charge_conj < 0 and not atom.n_oxide:\n            atom.type = 2  # anion\n        elif atom.symbol == \"N\":\n            if nbrcnt in (1, 2):\n                if atom.pi == 2:\n                    atom.type = 3  # donor\n                elif atom.pi == 1:\n                    atom.type = 4  # acceptor\n        elif atom.symbol == \"O\":\n            if nbrcnt == 1 and not atom.pi:\n                atom.type = 5  # polar\n            else:\n                atom.type = 4  # acceptor\n        elif atom.symbol in (\"C\", \"Si\", \"S\", \"Se\", \"P\", \"As\"):\n            ewg = False\n            for n, bond in mol.neighbors(i).items():\n                natom = mol.atom(n)\n                if natom.symbol in (\"N\", \"O\", \"S\") and atom.pi \\\n                        and not (natom.pi == 2 and mol.neighbor_count(n) == 3):\n                    # the sp2 adjacent to neg (but not conj tert amine) is 7\n                    ewg = True\n                    break\n            if not ewg:\n                atom.type = 6  # hydrophobes\n        elif atom.symbol in (\"F\", \"Cl\", \"Br\", \"I\") and nbrcnt == 1:\n            atom.type = 6  # typical halogens are hydrophobic\n    mol.descriptors.add(\"PATTY\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"-o\", \"--out\", help=\"Output results to a file instead of stdout\", default=None)\n    parser.add_argument(\"-p\", \"--path\", help=\"Specifies the target directory to search in\", default=os.getcwd())\n    options = parser.parse_args()\n\n    try:\n        scanner = Scanner(path=options.path, output=options.out)\n        scanner.run()\n        scanner.output()\n        \n    except ScannerException as e:\n        print(\"[!] Error, %s\" % str(e))\n        exit(1)", "response": "Entry point of the scanner\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nenable conversion from system arguments.", "response": "def translate_argv(raw_args):\n    \"\"\"Enables conversion from system arguments.\n\n    Parameters\n    ----------\n    raw_args : list\n        Arguments taken raw from the system input.\n\n    Returns\n    -------\n    kwargs : dict\n        The input arguments formatted as a kwargs dict.\n        To use as input, simply use `KQMLModule(**kwargs)`.\n    \"\"\"\n    kwargs = {}\n\n    def get_parameter(param_str):\n        for i, a in enumerate(raw_args):\n            if a == param_str:\n                assert len(raw_args) == i+2 and raw_args[i+1][0] != '-', \\\n                    'All arguments must have a value, e.g. `-testing true`'\n                return raw_args[i+1]\n        return None\n\n    value = get_parameter('-testing')\n    if value is not None and value.lower() in ('true', 't', 'yes'):\n            kwargs['testing'] = True\n\n    value = get_parameter('-connect')\n    if value is not None:\n        colon = value.find(':')\n        if colon > -1:\n            kwargs['host'] = value[0:colon]\n            kwargs['port'] = int(value[colon+1:])\n        else:\n            kwargs['host'] = value\n\n    value = get_parameter('-name')\n    if value is not None:\n        kwargs['name'] = value\n\n    value = get_parameter('-group')\n    if value is not None:\n        kwargs['group_name'] = value\n\n    value = get_parameter('-scan')\n    if value in ('true', 't', 'yes'):\n        kwargs['scan_for_port'] = True\n\n    value = get_parameter('-debug')\n    if value in ('true', 't', 'yes'):\n        kwargs['debug'] = True\n\n    return kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef process_task_topic_list(app, doctree, fromdocname):\n    logger = getLogger(__name__)\n    logger.debug('Started process_task_list')\n\n    env = app.builder.env\n\n    for node in doctree.traverse(task_topic_list):\n        try:\n            topics = env.lsst_task_topics\n        except AttributeError:\n            message = (\n                \"Environment does not have 'lsst_task_topics', \"\n                \"can't process the listing.\"\n            )\n            logger.warning(message)\n            node.replace_self(nodes.paragraph(text=message))\n            continue\n\n        root = node['root_namespace']\n\n        # Sort tasks by the topic's class name.\n        # NOTE: if the presentation of the link is changed to the fully\n        # qualified name, with full Python namespace, then the topic_names\n        # should be changed to match that.\n        topic_keys = [k for k, topic in topics.items()\n                      if topic['type'] in node['types']\n                      if topic['fully_qualified_name'].startswith(root)]\n        topic_names = [topics[k]['fully_qualified_name'].split('.')[-1]\n                       for k in topic_keys]\n        topic_keys = [\n            k for k, _ in\n            sorted(zip(topic_keys, topic_names), key=lambda pair: pair[1])]\n\n        if len(topic_keys) == 0:\n            # Fallback if no topics are found\n            p = nodes.paragraph(text='No topics.')\n            node.replace_self(p)\n            continue\n\n        dl = nodes.definition_list()\n        for key in topic_keys:\n            topic = topics[key]\n            class_name = topic['fully_qualified_name'].split('.')[-1]\n            summary_text = topic['summary_node'][0].astext()\n\n            # Each topic in the listing is a definition list item. The term is\n            # the linked class name and the description is the summary\n            # sentence from the docstring _or_ the content of the\n            # topic directive\n            dl_item = nodes.definition_list_item()\n\n            # Can insert an actual reference since the doctree is resolved.\n            ref_node = nodes.reference('', '')\n            ref_node['refdocname'] = topic['docname']\n            ref_node['refuri'] = app.builder.get_relative_uri(\n                fromdocname, topic['docname'])\n            # NOTE: Not appending an anchor to the URI because task topics\n            # are designed to occupy an entire page.\n            link_label = nodes.Text(class_name, class_name)\n            ref_node += link_label\n\n            term = nodes.term()\n            term += ref_node\n            dl_item += term\n\n            # We're degrading the summary to plain text to avoid syntax issues\n            # and also because it may be distracting\n            def_node = nodes.definition()\n            def_node += nodes.paragraph(text=summary_text)\n            dl_item += def_node\n            dl += dl_item\n\n        # Replace the task_list node (a placeholder) with this renderable\n        # content\n        node.replace_self(dl)", "response": "Processes the task_topic_list node and generates a rendered listing of all the tasks that are defined by the topics in the task_topic_list environment attribute."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _build_toctree(self):\n        dirname = posixpath.dirname(self._env.docname)\n        tree_prefix = self.options['toctree'].strip()\n        root = posixpath.normpath(posixpath.join(dirname, tree_prefix))\n        docnames = [docname for docname in self._env.found_docs\n                    if docname.startswith(root)]\n\n        # Sort docnames alphabetically based on **class** name.\n        # The standard we assume is that task doc pages are named after\n        # their Python namespace.\n        # NOTE: this ordering only applies to the toctree; the visual ordering\n        # is set by `process_task_topic_list`.\n        # NOTE: docnames are **always** POSIX-like paths\n        class_names = [docname.split('/')[-1].split('.')[-1]\n                       for docname in docnames]\n        docnames = [docname for docname, _ in\n                    sorted(zip(docnames, class_names),\n                           key=lambda pair: pair[1])]\n\n        tocnode = sphinx.addnodes.toctree()\n        tocnode['includefiles'] = docnames\n        tocnode['entries'] = [(None, docname) for docname in docnames]\n        tocnode['maxdepth'] = -1\n        tocnode['glob'] = None\n        tocnode['hidden'] = True\n\n        return tocnode", "response": "Create a hidden toctree node with the contents of a directory\n        prefixed by the directory name specified by the toctree directive\n        option."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets consecutive sequence of objects", "response": "def consecutive(iterable, n):\n    \"\"\"\n    consecutive('ABCDEF', 3) --> ABC BCD CDE DEF\n    consecutive(itertools.cycle(iter), n) to get looped sequence\n    \"\"\"\n    iterators = itertools.tee(iterable, n)\n    for i, it in enumerate(iterators):\n        for _ in range(i):\n            next(it, None)\n    return zip(*iterators)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nyield size elements from iterable", "response": "def chunk(iterable, size):\n    \"\"\"\n    chunk('ABCDEFG', 3) --> ABC DEF G\n    \"\"\"\n    # TODO: only used in gui.mainwindow(deprecated)\n    iterator = iter(iterable)\n    while size:\n        result = []\n        try:\n            for i in range(size):\n                elem = next(iterator)\n                result.append(elem)\n            yield tuple(result)\n        except StopIteration:\n            if result:\n                yield tuple(result)\n            return"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef chunk_fill(iterable, size, fillvalue=None):\n    # TODO: not used\n    args = [iter(iterable)] * size\n    return itertools.zip_longest(*args, fillvalue=fillvalue)", "response": "Returns a generator that yields a chunk of size with fillvalue."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef serve_forever(self, poll_interval=0.5):\n        while self.is_alive:\n            self.handle_request()\n            time.sleep(poll_interval)", "response": "Start serving for the current request."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck if scalar_dict satisfy query", "response": "def check_scalar(self, scalar_dict):\n        \"\"\"\n        check if `scalar_dict` satisfy query\n        \"\"\"\n        table = {k: np.array([v]) for k, v in scalar_dict.items()}\n        return self.mask(table)[0]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dumpfile(self, fd):\n\n        self.start()\n        dump = DumpFile(fd)\n        self.queue.append(dump)", "response": "Dump a file through a Spin instance."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrun the remote - code - block directive.", "response": "def run(self):\n        \"\"\"Run the ``remote-code-block`` directive.\n        \"\"\"\n        document = self.state.document\n        if not document.settings.file_insertion_enabled:\n            return [document.reporter.warning('File insertion disabled',\n                                              line=self.lineno)]\n\n        try:\n            location = self.state_machine.get_source_and_line(self.lineno)\n\n            # Customized for RemoteCodeBlock\n            url = self.arguments[0]\n            reader = RemoteCodeBlockReader(url, self.options, self.config)\n            text, lines = reader.read(location=location)\n\n            retnode = nodes.literal_block(text, text)\n            set_source_info(self, retnode)\n            if self.options.get('diff'):  # if diff is set, set udiff\n                retnode['language'] = 'udiff'\n            elif 'language' in self.options:\n                retnode['language'] = self.options['language']\n            retnode['linenos'] = ('linenos' in self.options or\n                                  'lineno-start' in self.options or\n                                  'lineno-match' in self.options)\n            retnode['classes'] += self.options.get('class', [])\n            extra_args = retnode['highlight_args'] = {}\n            if 'emphasize-lines' in self.options:\n                hl_lines = parselinenos(self.options['emphasize-lines'], lines)\n                if any(i >= lines for i in hl_lines):\n                    logger.warning(\n                        'line number spec is out of range(1-%d): %r' %\n                        (lines, self.options['emphasize-lines']),\n                        location=location)\n                extra_args['hl_lines'] = [x + 1 for x in hl_lines if x < lines]\n            extra_args['linenostart'] = reader.lineno_start\n\n            if 'caption' in self.options:\n                caption = self.options['caption'] or self.arguments[0]\n                retnode = container_wrapper(self, retnode, caption)\n\n            # retnode will be note_implicit_target that is linked from caption\n            # and numref.  when options['name'] is provided, it should be\n            # primary ID.\n            self.add_name(retnode)\n\n            return [retnode]\n\n        except Exception as exc:\n            return [document.reporter.warning(str(exc), line=self.lineno)]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef read_file(self, url, location=None):\n        response = requests_retry_session().get(url, timeout=10.0)\n        response.raise_for_status()\n        text = response.text\n        if 'tab-width' in self.options:\n            text = text.expandtabs(self.options['tab-width'])\n\n        return text.splitlines(True)", "response": "Read content from the web by overriding\n           . read_file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreset all internal storage containers to their initial state.", "response": "def reset(self):\n        \"\"\"\n            Empties all internal storage containers\n        \"\"\"\n        self.X = []\n        self.Y = []\n        self.w = []\n\n        self.Xnorm = []\n\n        self.graph_rep = None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __set_data(self, X, Y, w=None):\n        self.X = X\n        self.Y = Y\n        self.check_duplicates()\n\n        if w is not None:\n            self.w = np.array(w)\n        else:\n            self.w = np.ones(len(Y)) * 1.0 / float(len(Y))\n\n        if self.normalization == \"feature\":\n            # This doesn't work with one-dimensional arrays on older\n            # versions of sklearn\n            min_max_scaler = sklearn.preprocessing.MinMaxScaler()\n            self.Xnorm = min_max_scaler.fit_transform(np.atleast_2d(self.X))\n        elif self.normalization == \"zscore\":\n            self.Xnorm = sklearn.preprocessing.scale(\n                self.X, axis=0, with_mean=True, with_std=True, copy=True\n            )\n        else:\n            self.Xnorm = np.array(self.X)", "response": "Internally assigns the input data and normalizes the output data according to the user s specifications."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nbuild the topological sequence of a single entry in the database.", "response": "def build(self, X, Y, w=None, edges=None):\n        \"\"\" Assigns data to this object and builds the requested topological\n            structure\n            @ In, X, an m-by-n array of values specifying m\n            n-dimensional samples\n            @ In, Y, a m vector of values specifying the output\n            responses corresponding to the m samples specified by X\n            @ In, w, an optional m vector of values specifying the\n            weights associated to each of the m samples used. Default of\n            None means all points will be equally weighted\n            @ In, edges, an optional list of custom edges to use as a\n            starting point for pruning, or in place of a computed graph.\n        \"\"\"\n        self.reset()\n\n        if X is None or Y is None:\n            return\n\n        self.__set_data(X, Y, w)\n\n        if self.debug:\n            sys.stdout.write(\"Graph Preparation: \")\n            start = time.clock()\n\n        self.graph_rep = nglpy.Graph(\n            self.Xnorm,\n            self.graph,\n            self.max_neighbors,\n            self.beta,\n            connect=self.connect,\n        )\n\n        if self.debug:\n            end = time.clock()\n            sys.stdout.write(\"%f s\\n\" % (end - start))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load_data_and_build(self, filename, delimiter=\",\"):\n        data = np.genfromtxt(\n            filename, dtype=float, delimiter=delimiter, names=True\n        )\n        data = data.view(np.float64).reshape(data.shape + (-1,))\n\n        X = data[:, 0:-1]\n        Y = data[:, -1]\n\n        self.build(X=X, Y=Y)", "response": "This method is used to load the data from a file and build the object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the normalized input data requested by the user .", "response": "def get_normed_x(self, rows=None, cols=None):\n        \"\"\" Returns the normalized input data requested by the user\n            @ In, rows, a list of non-negative integers specifying the\n            row indices to return\n            @ In, cols, a list of non-negative integers specifying the\n            column indices to return\n            @ Out, a matrix of floating point values specifying the\n            normalized data values used in internal computations\n            filtered by the three input parameters.\n        \"\"\"\n        if rows is None:\n            rows = list(range(0, self.get_sample_size()))\n        if cols is None:\n            cols = list(range(0, self.get_dimensionality()))\n\n        if not hasattr(rows, \"__iter__\"):\n            rows = [rows]\n        rows = sorted(list(set(rows)))\n\n        retValue = self.Xnorm[rows, :]\n        return retValue[:, cols]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_x(self, rows=None, cols=None):\n        if rows is None:\n            rows = list(range(0, self.get_sample_size()))\n        if cols is None:\n            cols = list(range(0, self.get_dimensionality()))\n\n        if not hasattr(rows, \"__iter__\"):\n            rows = [rows]\n        rows = sorted(list(set(rows)))\n\n        retValue = self.X[rows, :]\n        if len(rows) == 0:\n            return []\n        return retValue[:, cols]", "response": "Returns the input data requested by the user\n           "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the output data requested by the user .", "response": "def get_y(self, indices=None):\n        \"\"\" Returns the output data requested by the user\n            @ In, indices, a list of non-negative integers specifying\n            the row indices to return\n            @ Out, an nparray of floating point values specifying the output\n            data values filtered by the indices input parameter.\n        \"\"\"\n        if indices is None:\n            indices = list(range(0, self.get_sample_size()))\n        else:\n            if not hasattr(indices, \"__iter__\"):\n                indices = [indices]\n            indices = sorted(list(set(indices)))\n\n        if len(indices) == 0:\n            return []\n        return self.Y[indices]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the weights requested by the user", "response": "def get_weights(self, indices=None):\n        \"\"\" Returns the weights requested by the user\n            @ In, indices, a list of non-negative integers specifying\n            the row indices to return\n            @ Out, a list of floating point values specifying the\n            weights associated to the input data rows filtered by the\n            indices input parameter.\n        \"\"\"\n        if indices is None:\n            indices = list(range(0, self.get_sample_size()))\n        else:\n            indices = sorted(list(set(indices)))\n\n        if len(indices) == 0:\n            return []\n        return self.w[indices]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfunctions to test whether duplicates exist in the input or the output domain space.", "response": "def check_duplicates(self):\n        \"\"\" Function to test whether duplicates exist in the input or\n            output space. First, if an aggregator function has been\n            specified, the domain space duplicates will be consolidated\n            using the function to generate a new range value for that\n            shared point. Otherwise, it will raise a ValueError.\n            The function will raise a warning if duplicates exist in the\n            output space\n            @Out, None\n        \"\"\"\n\n        if self.aggregator is not None:\n            X, Y = TopologicalObject.aggregate_duplicates(\n                self.X, self.Y, self.aggregator\n            )\n            self.X = X\n            self.Y = Y\n\n        temp_x = self.X.round(decimals=TopologicalObject.precision)\n        unique_xs = len(np.unique(temp_x, axis=0))\n\n        # unique_ys = len(np.unique(self.Y, axis=0))\n        # if len(self.Y) != unique_ys:\n        #     warnings.warn('Range space has duplicates. Simulation of '\n        #                   'simplicity may help, but artificial noise may '\n        #                   'occur in flat regions of the domain. Sample size:'\n        #                   '{} vs. Unique Records: {}'.format(len(self.Y),\n        #                                                      unique_ys))\n\n        if len(self.X) != unique_xs:\n            raise ValueError(\n                \"Domain space has duplicates. Try using an \"\n                \"aggregator function to consolidate duplicates \"\n                \"into a single sample with one range value. \"\n                \"e.g., \" + self.__class__.__name__ + \"(aggregator='max'). \"\n                \"\\n\\tNumber of \"\n                \"Records: {}\\n\\tNumber of Unique Records: {}\\n\".format(\n                    len(self.X), unique_xs\n                )\n            )"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nperforms column - stacking on a list of 2d data blocks.", "response": "def column_stack_2d(data):\n    \"\"\"Perform column-stacking on a list of 2d data blocks.\"\"\"\n    return list(list(itt.chain.from_iterable(_)) for _ in zip(*data))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef discover_package_doc_dir(initial_dir):\n    # Create an absolute Path to work with\n    initial_dir = pathlib.Path(initial_dir).resolve()\n\n    # Check if this is the doc/ dir already with a conf.py\n    if _has_conf_py(initial_dir):\n        return str(initial_dir)\n\n    # Search for a doc/ directory in cwd (this covers the case of running\n    # the CLI from the root of a repository).\n    test_dir = initial_dir / 'doc'\n    if test_dir.exists() and test_dir.is_dir():\n        if _has_conf_py(test_dir):\n            return str(test_dir)\n\n    # Search upwards until a conf.py is found\n    try:\n        return str(_search_parents(initial_dir))\n    except FileNotFoundError:\n        raise", "response": "Discover the doc dir of a package given an initial directory."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef discover_conf_py_directory(initial_dir):\n    # Create an absolute Path to work with\n    initial_dir = pathlib.Path(initial_dir).resolve()\n\n    # Search upwards until a conf.py is found\n    try:\n        return str(_search_parents(initial_dir))\n    except FileNotFoundError:\n        raise", "response": "Discover the directory containing the conf. py file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _search_parents(initial_dir):\n    root_paths = ('.', '/')\n    parent = pathlib.Path(initial_dir)\n    while True:\n        if _has_conf_py(parent):\n            return parent\n        if str(parent) in root_paths:\n            break\n        parent = parent.parent\n    msg = (\n        \"Cannot detect a conf.py Sphinx configuration file from {!s}. \"\n        \"Are you inside a Sphinx documenation repository?\"\n    ).format(initial_dir)\n    raise FileNotFoundError(msg)", "response": "Search the initial and parent directories for a conf. py Sphinx\n    configuration file that represents the root of a Sphinx project."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef abort(*args, **kwargs):\n    code = kwargs.pop(\"code\", 1)\n    logger = kwargs.pop(\"logger\", LOG.error if code else LOG.info)\n    fatal = kwargs.pop(\"fatal\", True)\n    return_value = fatal\n\n    if isinstance(fatal, tuple) and len(fatal) == 2:\n        fatal, return_value = fatal\n\n    if logger and fatal is not None and args:\n        if logging.root.handlers:\n            logger(*args, **kwargs)\n\n        else:\n            sys.stderr.write(\"%s\\n\" % formatted_string(*args))\n\n    if fatal:\n        if isinstance(fatal, type) and issubclass(fatal, BaseException):\n            raise fatal(code)\n\n        if AbortException is not None:\n            if isinstance(AbortException, type) and issubclass(AbortException, BaseException):\n                raise AbortException(code)\n\n            return AbortException(code)\n\n    return return_value", "response": "This function will return a value that indicates failure to the current user."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_version(mod, default=\"0.0.0\"):\n    name = mod\n    if hasattr(mod, \"__name__\"):\n        name = mod.__name__\n\n    try:\n        import pkg_resources\n\n        return pkg_resources.get_distribution(name).version\n\n    except Exception as e:\n        LOG.warning(\"Can't determine version for %s: %s\", name, e, exc_info=e)\n        return default", "response": "Get version of the current version of the current module."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset dryrun flag for the node.", "response": "def set_dryrun(dryrun):\n    \"\"\"\n    :param bool dryrun: New value for runez.DRYRUN\n    :return bool: Old value\n    \"\"\"\n    r = _get_runez()\n    old = r.DRYRUN\n    r.DRYRUN = bool(dryrun)\n    return old"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef transform_metadata(blob):\n\to = {}\n\tfor e in blob:\n\t\ti = e[u'id']\n\t\to[i] = e\n\treturn o", "response": "Transforms metadata types about channels users and bots into a dict that can be used to lookup the metadata."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef request_session(token, url=None):\n\tif url is None:\n\t\tapi = SlackApi()\n\telse:\n\t\tapi = SlackApi(url)\n\n\tresponse = api.rtm.start(token=token)\n\treturn SessionMetadata(response, api, token)", "response": "Requests a WebSocket session for the Real - Time Messaging API."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _find_resource_by_key(self, resource_list, key, value):\n\t\toriginal = value\n\t\tvalue = unicode(value.upper())\n\t\tfor k, resource in resource_list.iteritems():\n\t\t\tif key in resource and resource[key].upper() == value:\n\t\t\t\treturn k, resource\n\n\t\traise KeyError, original", "response": "Find a resource by key first case insensitive match."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfind the ID of the IM with a particular user by name.", "response": "def find_im_by_user_name(self, name, auto_create=True):\n\t\t\"\"\"\n\t\tFinds the ID of the IM with a particular user by name, with the option\n\t\tto automatically create a new channel if it doesn't exist.\n\t\t\"\"\"\n\t\tuid = self.find_user_by_name(name)[0]\n\t\ttry:\n\t\t\treturn self.find_im_by_user_id(uid)\n\t\texcept KeyError:\n\t\t\t# IM does not exist, create it?\n\t\t\tif auto_create:\n\t\t\t\tresponse = self.api.im.open(token=self.token, user=uid)\n\t\t\t\treturn response[u'channel'][u'id']\n\t\t\telse:\n\t\t\t\traise"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a series to the chart.", "response": "def add_series(self, values, **kwargs):\n        \"\"\"\n        Adds a series to the chart.\n        \n        :param values: A :py:class:`xltable.Expression` object that evaluates to the data series.\n        :param categories: A :py:class:`xltable.Expression` object that evaluates to the data series.\n        :param name: Name to show in the legend for the series\n        :param line: Line style, eg {'color': 'blue', 'width': 3.25} or {'none': True}\n        :param marker: dict specifying how the markers should look, eg {type: square}.\n        :param trendline: dict specifying how the trendline should be drawn, eg {type: linear}.\n        \"\"\"\n        series = {\"values\": values}\n        series.update(kwargs)\n        self.__series.append(series)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef iter_series(self, workbook, row, col):\n        for series in self.__series:\n            series = dict(series)\n            series[\"values\"] = series[\"values\"].get_formula(workbook, row, col)\n            if \"categories\" in series:\n                series[\"categories\"] = series[\"categories\"].get_formula(workbook, row, col)\n            yield series", "response": "Yields series dictionaries with values resolved to the final excel formulas."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_userinfo(self):\r\n        wanted_fields = [\"name\", \"mobile\", \"orgEmail\", \"position\", \"avatar\"]\r\n        userinfo = {k: self.json_response.get(k, None) for k in wanted_fields}\r\n        return userinfo", "response": "Method to get current user s name mobile email and position."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef list(context, topic_id, sort, limit, where, verbose):\n    components = topic.list_components(context, id=topic_id,\n                                       sort=sort, limit=limit, where=where)\n    utils.format_output(components, context.format, verbose=verbose)", "response": "list - List all components in a topic"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a new component.", "response": "def create(context, name, type, canonical_project_name, data,\n           title, message, url, topic_id, export_control, active):\n    \"\"\"create(context, name, type, canonical_project_name, data, title, message, url, topic_id, export_control, active)  # noqa\n\n    Create a component.\n\n    >>> dcictl component-create [OPTIONS]\n\n    :param string name: Name of the component [required]\n    :param string type: Type of the component [required]\n    :param string topic_id: ID of the topic to associate with [required]\n    :param string canonical_project_name: Project name\n    :param json data: JSON to pass to the component\n    :param string title: Title of the component\n    :param string message: Message for the component\n    :param string url: URL resource to monitor\n    :param boolean export_control: Set the component visible for users\n    :param boolean active: Set the component in the (in)active state\n    \"\"\"\n\n    state = utils.active_string(active)\n    result = component.create(\n        context, name=name, type=type,\n        canonical_project_name=canonical_project_name,\n        data=data,\n        title=title, message=message, url=url,\n        topic_id=topic_id, export_control=export_control,\n        state=state\n    )\n    utils.format_output(result, context.format)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delete(context, id):\n    result = component.delete(context, id=id)\n    if result.status_code == 204:\n        utils.print_json({'id': id, 'message': 'Component deleted.'})\n    else:\n        utils.format_output(result, context.format)", "response": "Delete a node from the hierarchy"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef file_upload(context, id, path):\n    result = component.file_upload(context, id=id, file_path=path)\n    utils.format_output(result, context.format)", "response": "Upload a file in a availabe tree"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef file_show(context, id, file_id):\n    result = component.file_get(context, id=id, file_id=file_id)\n    utils.format_output(result, context.format)", "response": "Show a file in a availabe tree"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef file_download(context, id, file_id, target):\n    component.file_download(context, id=id, file_id=file_id, target=target)", "response": "File download a file in a node"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef file_list(context, id, sort, limit, where, verbose):\n    result = component.file_list(context, id=id, sort=sort, limit=limit,\n                                 where=where)\n    utils.format_output(result, context.format, verbose=verbose)", "response": "File list of a single file"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfile delete a file", "response": "def file_delete(context, id, file_id):\n    \"\"\"file_delete(context, id, path)\n\n    Delete a component file\n\n    >>> dcictl component-file-delete [OPTIONS]\n\n    :param string id: ID of the component to delete file [required]\n    :param string file_id: ID for the file to delete [required]\n    \"\"\"\n    component.file_delete(context, id=id, file_id=file_id)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates a component in the nationale", "response": "def update(context, id, export_control, active):\n    \"\"\"update(context, id, export_control, active)\n\n    Update a component\n\n    >>> dcictl component-update [OPTIONS]\n\n    :param string id: ID of the component [required]\n    :param boolean export-control: Set the component visible for users\n    :param boolean active: Set the component in the active state\n    \"\"\"\n\n    component_info = component.get(context, id=id)\n\n    etag = component_info.json()['component']['etag']\n\n    result = component.update(context, id=id, etag=etag,\n                              export_control=export_control,\n                              state=utils.active_string(active))\n\n    utils.format_output(result, context.format)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef attach_issue(context, id, url):\n\n    result = component.attach_issue(context, id=id, url=url)\n    if result.status_code == 201:\n        utils.print_json({'id': id, 'message': 'Issue attached.'})\n    else:\n        utils.format_output(result, context.format)", "response": "Attach an issue to a base component"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlists all issues attached to a specific component", "response": "def list_issues(context, id, sort, limit):\n    \"\"\"list_issues(context, id)\n\n    List all component attached issues.\n\n    >>> dcictl component-list-issue [OPTIONS]\n\n    :param string id: ID of the component to retrieve issues from [required]\n    \"\"\"\n\n    result = component.list_issues(context, id=id, sort=sort, limit=limit)\n    headers = ['id', 'status', 'product', 'component', 'title', 'url']\n    utils.format_output(result, context.format, headers)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_dev_folder(path=sys.prefix):\n    if not path or len(path) <= 4:\n        return None\n    dirpath, basename = os.path.split(path)\n    if basename in DEV_FOLDERS:\n        return path\n    return get_dev_folder(dirpath)", "response": "Get the path to the development build folder."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_younger(path, age):\n    try:\n        return time.time() - os.path.getmtime(path) < age\n\n    except (OSError, TypeError):\n        return False", "response": "Check if a file is younger than age seconds"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make_executable(path, fatal=True):\n    if is_executable(path):\n        return 0\n\n    if is_dryrun():\n        LOG.debug(\"Would make %s executable\", short(path))\n        return 1\n\n    if not os.path.exists(path):\n        return abort(\"%s does not exist, can't make it executable\", short(path), fatal=(fatal, -1))\n\n    try:\n        os.chmod(path, 0o755)  # nosec\n        return 1\n\n    except Exception as e:\n        return abort(\"Can't chmod %s: %s\", short(path), e, fatal=(fatal, -1))", "response": "Make a new executable file with the given path."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef run(program, *args, **kwargs):\n    args = flattened(args, split=SHELL)\n    full_path = which(program)\n\n    logger = kwargs.pop(\"logger\", LOG.debug)\n    fatal = kwargs.pop(\"fatal\", True)\n    dryrun = kwargs.pop(\"dryrun\", is_dryrun())\n    include_error = kwargs.pop(\"include_error\", False)\n\n    message = \"Would run\" if dryrun else \"Running\"\n    message = \"%s: %s %s\" % (message, short(full_path or program), represented_args(args))\n    if logger:\n        logger(message)\n\n    if dryrun:\n        return message\n\n    if not full_path:\n        return abort(\"%s is not installed\", short(program), fatal=fatal)\n\n    stdout = kwargs.pop(\"stdout\", subprocess.PIPE)\n    stderr = kwargs.pop(\"stderr\", subprocess.PIPE)\n    args = [full_path] + args\n    try:\n        path_env = kwargs.pop(\"path_env\", None)\n        if path_env:\n            kwargs[\"env\"] = added_env_paths(path_env, env=kwargs.get(\"env\"))\n        p = subprocess.Popen(args, stdout=stdout, stderr=stderr, **kwargs)  # nosec\n        output, err = p.communicate()\n        output = decode(output, strip=True)\n        err = decode(err, strip=True)\n\n        if p.returncode and fatal is not None:\n            note = \": %s\\n%s\" % (err, output) if output or err else \"\"\n            message = \"%s exited with code %s%s\" % (short(program), p.returncode, note.strip())\n            return abort(message, fatal=fatal)\n\n        if include_error and err:\n            output = \"%s\\n%s\" % (output, err)\n        return output and output.strip()\n\n    except Exception as e:\n        return abort(\"%s failed: %s\", short(program), e, exc_info=e, fatal=fatal)", "response": "Run a program with the given arguments and return the output of the process."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef which(program, ignore_own_venv=False):\n    if not program:\n        return None\n    if os.path.isabs(program):\n        return program if is_executable(program) else None\n    for p in os.environ.get(\"PATH\", \"\").split(\":\"):\n        fp = os.path.join(p, program)\n        if (not ignore_own_venv or not fp.startswith(sys.prefix)) and is_executable(fp):\n            return fp\n    return None", "response": "Find the full path to a program in the current virtualenv."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a dict with the added environment paths.", "response": "def added_env_paths(env_vars, env=None):\n    \"\"\"\n    :param dict|None env_vars: Env vars to customize\n    :param dict env: Original env vars\n    \"\"\"\n    if not env_vars:\n        return None\n\n    if not env:\n        env = dict(os.environ)\n\n    result = dict(env)\n    for env_var, paths in env_vars.items():\n        separator = paths[0]\n        paths = paths[1:]\n        current = env.get(env_var, \"\")\n        current = [x for x in current.split(separator) if x]\n\n        added = 0\n        for path in paths.split(separator):\n            if path not in current:\n                added += 1\n                current.append(path)\n\n        if added:\n            result[env_var] = separator.join(current)\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_sub_dept_ids(self):\r\n        self.logger.info(\"%s\\t%s\" % (self.request_method, self.request_url))\r\n        return self.json_response.get(\"sub_dept_id_list\", None)", "response": "Method to get the department list"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrap for the setup functions of each individual extension module.", "response": "def setup(app):\n    \"\"\"Wrapper for the `setup` functions of each individual extension module.\n    \"\"\"\n    jira.setup(app)\n    lsstdocushare.setup(app)\n    mockcoderefs.setup(app)\n    packagetoctree.setup(app)\n    remotecodeblock.setup(app)\n\n    try:\n        __version__ = get_distribution('documenteer').version\n    except DistributionNotFound:\n        # package is not installed\n        __version__ = 'unknown'\n    return {'version': __version__,\n            'parallel_read_safe': True,\n            'parallel_write_safe': True}"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprocesses a role that references the target nodes created by the lsst - task directive.", "response": "def task_ref_role(name, rawtext, text, lineno, inliner,\n                  options=None, content=None):\n    \"\"\"Process a role that references the target nodes created by the\n    ``lsst-task`` directive.\n\n    Parameters\n    ----------\n    name\n        The role name used in the document.\n    rawtext\n        The entire markup snippet, with role.\n    text\n        The text marked with the role.\n    lineno\n        The line number where ``rawtext`` appears in the input.\n    inliner\n        The inliner instance that called us.\n    options\n        Directive options for customization.\n    content\n        The directive content for customization.\n\n    Returns\n    -------\n    nodes : `list`\n        List of nodes to insert into the document.\n    messages : `list`\n        List of system messages.\n    \"\"\"\n    # app = inliner.document.settings.env.app\n    node = pending_task_xref(rawsource=text)\n    return [node], []"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nprocessing the pending_task_xref nodes during the doctree - resolved event.", "response": "def process_pending_task_xref_nodes(app, doctree, fromdocname):\n    \"\"\"Process the ``pending_task_xref`` nodes during the ``doctree-resolved``\n    event to insert links to the locations of ``lsst-task-topic`` directives.\n    \"\"\"\n    logger = getLogger(__name__)\n    env = app.builder.env\n\n    for node in doctree.traverse(pending_task_xref):\n        content = []\n\n        # The source of the node is the class name the user entered via the\n        # lsst-task-topic role. For example:\n        # lsst.pipe.tasks.processCcd.ProcessCcdTask\n        role_parts = split_role_content(node.rawsource)\n        task_id = format_task_id(role_parts['ref'])\n        if role_parts['display']:\n            # user's custom display text\n            display_text = role_parts['display']\n        elif role_parts['last_component']:\n            # just the name of the class\n            display_text = role_parts['ref'].split('.')[-1]\n        else:\n            display_text = role_parts['ref']\n        link_label = nodes.literal()\n        link_label += nodes.Text(display_text, display_text)\n\n        if hasattr(env, 'lsst_task_topics') and \\\n                task_id in env.lsst_task_topics:\n            # A task topic, marked up with the lsst-task-topic directive is\n            # available\n            task_data = env.lsst_task_topics[task_id]\n\n            ref_node = nodes.reference('', '')\n            ref_node['refdocname'] = task_data['docname']\n            ref_node['refuri'] = app.builder.get_relative_uri(\n                fromdocname, task_data['docname'])\n            ref_node['refuri'] += '#' + task_data['target']['refid']\n\n            ref_node += link_label\n\n            content.append(ref_node)\n\n        else:\n            # Fallback if the task topic isn't known. Just print the label text\n            content.append(link_label)\n\n            message = 'lsst-task could not find a reference to %s'\n            logger.warning(message, role_parts['ref'], location=node)\n\n        # replacing the pending_task_xref node with this reference\n        node.replace_self(content)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprocessing a role that references the target nodes created by the lsst - config - topic directive.", "response": "def config_ref_role(name, rawtext, text, lineno, inliner,\n                    options=None, content=None):\n    \"\"\"Process a role that references the target nodes created by the\n    ``lsst-config-topic`` directive.\n\n    Parameters\n    ----------\n    name\n        The role name used in the document.\n    rawtext\n        The entire markup snippet, with role.\n    text\n        The text marked with the role.\n    lineno\n        The line number where ``rawtext`` appears in the input.\n    inliner\n        The inliner instance that called us.\n    options\n        Directive options for customization.\n    content\n        The directive content for customization.\n\n    Returns\n    -------\n    nodes : `list`\n        List of nodes to insert into the document.\n    messages : `list`\n        List of system messages.\n\n    See also\n    --------\n    `format_config_id`\n    `ConfigTopicTargetDirective`\n    `pending_config_xref`\n    \"\"\"\n    node = pending_config_xref(rawsource=text)\n    return [node], []"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprocesses the pending_config_xref nodes during the doctree - resolved event.", "response": "def process_pending_config_xref_nodes(app, doctree, fromdocname):\n    \"\"\"Process the ``pending_config_xref`` nodes during the ``doctree-resolved``\n    event to insert links to the locations of ``lsst-config-topic`` directives.\n\n    See also\n    --------\n    `config_ref_role`\n    `ConfigTopicTargetDirective`\n    `pending_config_xref`\n    \"\"\"\n    logger = getLogger(__name__)\n    env = app.builder.env\n\n    for node in doctree.traverse(pending_config_xref):\n        content = []\n\n        # The source of the node is the content the authored entered in the\n        # lsst-config role\n        role_parts = split_role_content(node.rawsource)\n        config_id = format_config_id(role_parts['ref'])\n        if role_parts['display']:\n            # user's custom display text\n            display_text = role_parts['display']\n        elif role_parts['last_component']:\n            # just the name of the class\n            display_text = role_parts['ref'].split('.')[-1]\n        else:\n            display_text = role_parts['ref']\n        link_label = nodes.literal()\n        link_label += nodes.Text(display_text, display_text)\n\n        if hasattr(env, 'lsst_task_topics') and \\\n                config_id in env.lsst_task_topics:\n            # A config topic, marked up with the lsst-task directive is\n            # available\n            config_data = env.lsst_task_topics[config_id]\n\n            ref_node = nodes.reference('', '')\n            ref_node['refdocname'] = config_data['docname']\n            ref_node['refuri'] = app.builder.get_relative_uri(\n                fromdocname, config_data['docname'])\n            ref_node['refuri'] += '#' + config_data['target']['refid']\n\n            ref_node += link_label\n\n            content.append(ref_node)\n\n        else:\n            # Fallback if the config topic isn't known. Just print the\n            # role's formatted content.\n            content.append(link_label)\n\n            message = 'lsst-config could not find a reference to %s'\n            logger.warning(message, role_parts['ref'], location=node)\n\n        # replacing the pending_config_xref node with this reference\n        node.replace_self(content)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprocess a role that references the Task configuration field nodes.", "response": "def configfield_ref_role(name, rawtext, text, lineno, inliner,\n                         options=None, content=None):\n    \"\"\"Process a role that references the Task configuration field nodes\n    created by the ``lsst-config-fields``, ``lsst-task-config-subtasks``,\n    and ``lsst-task-config-subtasks`` directives.\n\n    Parameters\n    ----------\n    name\n        The role name used in the document.\n    rawtext\n        The entire markup snippet, with role.\n    text\n        The text marked with the role.\n    lineno\n        The line number where ``rawtext`` appears in the input.\n    inliner\n        The inliner instance that called us.\n    options\n        Directive options for customization.\n    content\n        The directive content for customization.\n\n    Returns\n    -------\n    nodes : `list`\n        List of nodes to insert into the document.\n    messages : `list`\n        List of system messages.\n\n    See also\n    --------\n    `format_configfield_id`\n    `pending_configfield_xref`\n    `process_pending_configfield_xref_nodes`\n    \"\"\"\n    node = pending_configfield_xref(rawsource=text)\n    return [node], []"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef process_pending_configfield_xref_nodes(app, doctree, fromdocname):\n    logger = getLogger(__name__)\n    env = app.builder.env\n\n    for node in doctree.traverse(pending_configfield_xref):\n        content = []\n\n        # The source is the text the user entered into the role, which is\n        # the importable name of the config class's and the attribute\n        role_parts = split_role_content(node.rawsource)\n        namespace_components = role_parts['ref'].split('.')\n        field_name = namespace_components[-1]\n        class_namespace = namespace_components[:-1]\n        configfield_id = format_configfield_id(class_namespace, field_name)\n        if role_parts['display']:\n            # user's custom display text\n            display_text = role_parts['display']\n        elif role_parts['last_component']:\n            # just the name of the class\n            display_text = role_parts['ref'].split('.')[-1]\n        else:\n            display_text = role_parts['ref']\n        link_label = nodes.literal()\n        link_label += nodes.Text(display_text, display_text)\n\n        if hasattr(env, 'lsst_configfields') \\\n                and configfield_id in env.lsst_configfields:\n            # A config field topic is available\n            configfield_data = env.lsst_configfields[configfield_id]\n\n            ref_node = nodes.reference('', '')\n            ref_node['refdocname'] = configfield_data['docname']\n            ref_node['refuri'] = app.builder.get_relative_uri(\n                fromdocname, configfield_data['docname'])\n            ref_node['refuri'] += '#' + configfield_id\n\n            ref_node += link_label\n\n            content.append(ref_node)\n\n        else:\n            # Fallback if the config field isn't known. Just print the Config\n            # field attribute name\n            literal_node = nodes.literal()\n            link_label = nodes.Text(field_name, field_name)\n            literal_node += link_label\n\n            content.append(literal_node)\n\n            message = 'lsst-config-field could not find a reference to %s'\n            logger.warning(message, role_parts['ref'], location=node)\n\n        # replacing the pending_configfield_xref node with this reference\n        node.replace_self(content)", "response": "Process the pending_configfield_xref nodes during the doctree - resolved event."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef run(self):\n\n        # Normalize path\n        self.path = os.path.expanduser(self.path)\n\n        # Start scanning\n        if os.path.isdir(self.path):\n            self.search_script_directory(self.path)\n            return self\n        else:\n            raise ScannerException(\"Unknown directory: %s\" % self.path)", "response": "Runs the scanner\n        :return: self"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef output(self):\n        if not self.path_output:\n            self.output_to_fd(sys.stdout)\n        else:\n            with open(self.path_output, \"w\") as out:\n                self.output_to_fd(out)", "response": "Output the results to either STDOUT or the file descriptor."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef output_to_fd(self, fd):\n        for library in self.libraries_found:\n            fd.write(\"%s==%s\\n\" % (library.key, library.version))", "response": "Outputs the results of the scanner to a file descriptor"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef search_script_directory(self, path):\n        for subdir, dirs, files in os.walk(path):\n            for file_name in files:\n                if file_name.endswith(\".py\"):\n                    self.search_script_file(subdir, file_name)", "response": "Recursively search a directory for all python\n        script files."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsearch a script file and search it for library references", "response": "def search_script_file(self, path, file_name):\n        \"\"\"\n        Open a script file and search it for library references\n        :param path:\n        :param file_name:\n        :return: void\n        \"\"\"\n        with open(os.path.join(path, file_name), \"r\") as script:\n            self.search_script(script.read())"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsearch a script s contents for import statements and check pip modules.", "response": "def search_script(self, script):\n        \"\"\"\n        Search a script's contents for import statements and check\n        if they're currently prevent in the list of all installed\n        pip modules.\n        :param script: string\n        :return: void\n        \"\"\"\n        if self.import_statement.search(script):\n            for installed in self.libraries_installed:\n                for found in set(self.import_statement.findall(script)):\n                    if found == installed.key:\n                        self.libraries_installed.remove(installed)\n                        self.libraries_found.append(installed)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create(context, name, country, active, parent_id):\n\n    state = utils.active_string(active)\n    result = team.create(context, name=name, country=country, state=state,\n                         parent_id=parent_id)\n    utils.format_output(result, context.format)", "response": "Create a new NCBI team."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the value capped to the specified minimum and maximum.", "response": "def capped(value, minimum=None, maximum=None):\n    \"\"\"\n    Args:\n        value: Value to cap\n        minimum: If specified, value should not be lower than this minimum\n        maximum: If specified, value should not be higher than this maximum\n\n    Returns:\n        `value` capped to `minimum` and `maximum` (if it is outside of those bounds)\n    \"\"\"\n    if minimum is not None and value < minimum:\n        return minimum\n\n    if maximum is not None and value > maximum:\n        return maximum\n\n    return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts value to boolean", "response": "def to_boolean(value):\n    \"\"\"\n    Args:\n        value (str | unicode | None): Value to convert to bool\n\n    Returns:\n        (bool): Deduced boolean value\n    \"\"\"\n    if value is not None:\n        if str(value).lower() in TRUE_TOKENS:\n            return True\n\n        vfloat = to_number(float, value)\n        if vfloat is not None:\n            return bool(vfloat)\n\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts value to bytes", "response": "def to_bytesize(value, default_unit=None, base=DEFAULT_BASE):\n    \"\"\"Convert `value` to bytes, accepts notations such as \"4k\" to mean 4096 bytes\n\n    Args:\n        value (str | unicode | int | None): Number of bytes optionally suffixed by a char from UNITS\n        default_unit (str | unicode | None): Default unit to use for unqualified values\n        base (int): Base to use (usually 1024)\n\n    Returns:\n        (int | None): Deduced bytesize value, if possible\n    \"\"\"\n    if isinstance(value, (int, float)):\n        return unitized(value, default_unit, base)\n\n    if value is None:\n        return None\n\n    try:\n        if value[-1].lower() == \"b\":\n            # Accept notations such as \"1mb\", as they get used out of habit\n            value = value[:-1]\n\n        unit = value[-1:].lower()\n        if unit.isdigit():\n            unit = default_unit\n\n        else:\n            value = value[:-1]\n\n        return unitized(to_number(float, value), unit, base)\n\n    except (IndexError, TypeError, ValueError):\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting a value to a dict.", "response": "def to_dict(value, prefix=None, separators=\"=,\"):\n    \"\"\"\n    Args:\n        value: Value to turn into a dict\n        prefix (str | unicode | None): Optional prefix for keys (if provided, `prefix.` is added to all keys)\n        separators (str | unicode): 2 chars: 1st is assignment separator, 2nd is key-value pair separator\n\n    Returns:\n        (dict): Parse key/values\n    \"\"\"\n    if not value or isinstance(value, dict):\n        return value or {}\n\n    result = {}\n    for val in flattened(value, split=(separators[1], SANITIZED)):\n        if not val:\n            continue\n\n        if hasattr(val, \"partition\"):\n            k, _, v = val.partition(separators[0])\n            k = k.strip()\n            if k:\n                v = v.strip()\n                if prefix and not k.startswith(prefix):\n                    k = \"%s.%s\" % (prefix, k)\n                result[k] = v\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_int(value, default=None, minimum=None, maximum=None):\n    return to_number(int, value, default=default, minimum=minimum, maximum=maximum)", "response": "Converts a value to an integer value in the\n    format."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef to_number(result_type, value, default=None, minimum=None, maximum=None):\n    try:\n        return capped(result_type(value), minimum, maximum)\n\n    except (TypeError, ValueError):\n        return default", "response": "Cast value to numeric result_type if possible\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nexpanding a value to a given unit", "response": "def unitized(value, unit, base=DEFAULT_BASE):\n    \"\"\"\n    Args:\n        value (int | float): Value to expand\n        unit (str | unicode): Given unit (see UNITS)\n        base (int): Base to use (usually 1024)\n\n    Returns:\n        Deduced value (example: \"1k\" becomes 1000)\n    \"\"\"\n    exponent = 0 if not unit else UNITS.index(unit) + 1\n    return int(value * (base ** exponent))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreplaces current providers with given ones", "response": "def set_providers(self, *providers):\n        \"\"\"Replace current providers with given ones\"\"\"\n        if self.providers:\n            self.clear()\n        for provider in providers:\n            self.add(provider)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the index of existing provider with same id or None if no such provider exists.", "response": "def provider_id_slot(self, other):\n        \"\"\"\n        Args:\n            other (ConfigProvider): Provider to examine\n\n        Returns:\n            (int | None): Index of existing provider with same id, if any\n        \"\"\"\n        if other:\n            pid = other.provider_id()\n            for i, provider in enumerate(self.providers):\n                if provider.provider_id() == pid:\n                    return i\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef use_propsfs(self, folder=None, front=False):\n        if folder is None:\n            folder = \"/%s/props\" % (\"Volumes\" if platform.system().lower() == \"darwin\" else \"mnt\")\n        self.add(PropsfsProvider(folder), front=front)", "response": "Add a new provider to list of propertiesfs providers."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd provider to list of keys available in CLI", "response": "def use_cli(self, config, prefix=None, name=\"--config\", front=True):\n        \"\"\"\n        Args:\n            config: Multi-value option, typically tuple from click CLI flag such as --config\n            prefix (str | unicode | None): Prefix to add to all parsed keys\n            name (str | unicode): Name of cli flag\n            front (bool): If True, add provider to front of list\n        \"\"\"\n        if config:\n            provider = DictProvider(to_dict(config, prefix=prefix), name=name)\n            self.add(provider, front=front)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a DictProvider - s to the cache", "response": "def use_json(self, *paths):\n        \"\"\"\n        Args:\n            *paths (str | unicode): Paths to files to add as static DictProvider-s, only existing files are added\n        \"\"\"\n        for path in paths:\n            if path:\n                fpath = os.path.expanduser(path)\n                if os.path.exists(fpath):\n                    with open(fpath) as fh:\n                        provider = DictProvider(json.load(fh), name=path)\n                        self.add(provider)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a provider to the list of available providers.", "response": "def add(self, provider, front=False):\n        \"\"\"\n        Args:\n            provider (ConfigProvider): Provider to add\n            front (bool): If True, add provider to front of list\n        \"\"\"\n        if provider:\n            i = self.provider_id_slot(provider)\n            if i is not None:\n                self.providers[i] = provider\n\n            elif front:\n                self.providers.insert(0, provider)\n\n            else:\n                self.providers.append(provider)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_str(self, key, default=None):\n        if key:\n            for provider in self.providers:\n                value = provider.get_str(key)\n                if value is not None:\n                    return value\n\n        return default", "response": "Returns the string value of a key if it exists otherwise returns default"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_int(self, key, default=None, minimum=None, maximum=None):\n        return to_number(int, self.get_str(key), default=default, minimum=minimum, maximum=maximum)", "response": "Returns the value of a key in the cache as an integer."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_float(self, key, default=None, minimum=None, maximum=None):\n        return to_number(float, self.get_str(key), default=default, minimum=minimum, maximum=maximum)", "response": "Returns the value of a key in the national system if it exists otherwise returns default."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_bool(self, key, default=None):\n        value = self.get_str(key)\n        if value is not None:\n            return to_boolean(value)\n\n        return default", "response": "Returns the boolean value of the specified key if it exists otherwise returns default"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_bytesize(self, key, default=None, minimum=None, maximum=None, default_unit=None, base=DEFAULT_BASE):\n        value = to_bytesize(self.get_str(key), default_unit, base)\n        if value is None:\n            return to_bytesize(default, default_unit, base)\n        return capped(value, to_bytesize(minimum, default_unit, base), to_bytesize(maximum, default_unit, base))", "response": "Returns the size in bytes expressed by value configured under key."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the json value for the specified key", "response": "def get_json(self, key, default=None):\n        \"\"\"\n        Args:\n            key (str | unicode): Key to lookup\n            default (str | unicode | dict | list | None): Default to use if key is not configured\n\n        Returns:\n            (dict | list | str | int | None): Deserialized json, if any\n        \"\"\"\n        value = self.get_str(key)\n        if value is not None:\n            value = from_json(value)\n            if value is not None:\n                return value\n\n        if isinstance(default, (dict, list)):\n            return default\n\n        return from_json(default)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a sequence of key - value pairs for the specified key.", "response": "def pbkdf2(digestmod, password, salt, count, dk_length):\n    \"\"\"\n    PBKDF2, from PKCS #5 v2.0[1].\n\n    [1]: http://tools.ietf.org/html/rfc2898\n\n    For proper usage, see NIST Special Publication 800-132:\n        http://csrc.nist.gov/publications/PubsSPs.html\n\n    The arguments for this function are:\n\n        digestmod\n            a crypographic hash constructor, such as hashlib.sha256\n            which will be used as an argument to the hmac function.\n            Note that the performance difference between sha1 and\n            sha256 is not very big. New applications should choose\n            sha256 or better.\n\n        password\n            The arbitrary-length password (passphrase) (bytes)\n\n        salt\n            A bunch of random bytes, generated using a cryptographically\n            strong random number generator (such as os.urandom()). NIST\n            recommend the salt be _at least_ 128bits (16 bytes) long.\n\n        count\n            The iteration count. Set this value as large as you can\n            tolerate. NIST recommend that the absolute minimum value\n            be 1000. However, it should generally be in the range of\n            tens of thousands, or however many cause about a half-second\n            delay to the user.\n\n        dk_length\n            The lenght of the desired key in bytes. This doesn't need\n            to be the same size as the hash functions digest size, but\n            it makes sense to use a larger digest hash function if your\n            key size is large.\n\n\n    \"\"\"\n    def pbkdf2_function(pw, salt, count, i):\n        # in the first iteration, the hmac message is the salt\n        # concatinated with the block number in the form of \\x00\\x00\\x00\\x01\n        r = u = hmac.new(pw, salt + struct.pack(\">i\", i), digestmod).digest()\n        for i in range(2, count + 1):\n            # in subsequent iterations, the hmac message is the\n            # previous hmac digest. The key is always the users password\n            # see the hmac specification for notes on padding and stretching\n            u = hmac.new(pw, u, digestmod).digest()\n            # this is the exclusive or of the two byte-strings\n            r = bytes(i ^ j for i, j in zip(r, u))\n        return r\n    dk, h_length = b'', digestmod().digest_size\n    # we generate as many blocks as are required to\n    # concatinate to the desired key size:\n    blocks = (dk_length // h_length) + (1 if dk_length % h_length else 0)\n    for i in range(1, blocks + 1):\n        dk += pbkdf2_function(password, salt, count, i)\n    # The length of the key wil be dk_length to the nearest\n    # hash block size, i.e. larger than or equal to it. We\n    # slice it to the desired length befor returning it.\n    return dk[:dk_length]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef install(application, **kwargs):\n    if getattr(application, 'statsd', None) is not None:\n        LOGGER.warning('Statsd collector is already installed')\n        return False\n\n    if 'host' not in kwargs:\n        kwargs['host'] = os.environ.get('STATSD_HOST', '127.0.0.1')\n    if 'port' not in kwargs:\n        kwargs['port'] = os.environ.get('STATSD_PORT', '8125')\n\n    if 'protocol' not in kwargs:\n        kwargs['protocol'] = os.environ.get('STATSD_PROTOCOL', 'udp')\n\n    setattr(application, 'statsd', StatsDCollector(**kwargs))\n    return True", "response": "Installs StatsD for the Tornado application."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef record_timing(self, duration, *path):\n        self.application.statsd.send(path, duration * 1000.0, 'ms')", "response": "Record a timing to the application s namespace\n        followed by a calculated path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nincrease a counter within the application s namespace.", "response": "def increase_counter(self, *path, **kwargs):\n        \"\"\"Increase a counter.\n\n        This method increases a counter within the application's\n        namespace.  Each element of `path` is converted to a string\n        and normalized before joining the elements by periods.  The\n        normalization process is little more than replacing periods\n        with dashes.\n\n        :param path: elements of the metric path to incr\n        :keyword int amount: amount to increase the counter by.  If\n            omitted, the counter is increased by one.\n\n        \"\"\"\n        self.application.statsd.send(path, kwargs.get('amount', '1'), 'c')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef execution_timer(self, *path):\n        start = time.time()\n        try:\n            yield\n        finally:\n            self.record_timing(max(start, time.time()) - start, *path)", "response": "A context manager that records the time spent inside of the context and submits a timing metric\n        to the specified path."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncall by the server when the request has finished processing.", "response": "def on_finish(self):\n        \"\"\"\n        Records the time taken to process the request.\n\n        This method records the amount of time taken to process the request\n        (as reported by\n        :meth:`~tornado.httputil.HTTPServerRequest.request_time`) under the\n        path defined by the class's module, it's name, the request method,\n        and the status code.  The :meth:`.record_timing` method is used\n        to send the metric, so the configured namespace is used as well.\n\n        \"\"\"\n        super().on_finish()\n        self.record_timing(self.request.request_time(),\n                           self.__class__.__name__, self.request.method,\n                           self.get_status())"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconnects to statsd via TCP and return the IOStream handle.", "response": "def _tcp_socket(self):\n        \"\"\"Connect to statsd via TCP and return the IOStream handle.\n        :rtype: iostream.IOStream\n        \"\"\"\n        sock = iostream.IOStream(socket.socket(\n                    socket.AF_INET, socket.SOCK_STREAM, socket.IPPROTO_TCP))\n        sock.connect(self._address, self._tcp_on_connected)\n        sock.set_close_callback(self._tcp_on_closed)\n        return sock"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def _tcp_on_closed(self):\n        LOGGER.warning('Not connected to statsd, connecting in %s seconds',\n                       self._tcp_reconnect_sleep)\n        await asyncio.sleep(self._tcp_reconnect_sleep)\n        self._sock = self._tcp_socket()", "response": "Invoked when the socket is closed."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef send(self, path, value, metric_type):\n        msg = self._msg_format.format(\n            path=self._build_path(path, metric_type),\n            value=value,\n            metric_type=metric_type)\n\n        LOGGER.debug('Sending %s to %s:%s', msg.encode('ascii'),\n                     self._host, self._port)\n\n        try:\n            if self._tcp:\n                if self._sock.closed():\n                    return\n                return self._sock.write(msg.encode('ascii'))\n\n            self._sock.sendto(msg.encode('ascii'), (self._host, self._port))\n        except iostream.StreamClosedError as error:  # pragma: nocover\n            LOGGER.warning('Error sending TCP statsd metric: %s', error)\n        except (OSError, socket.error) as error:  # pragma: nocover\n            LOGGER.exception('Error sending statsd metric: %s', error)", "response": "Send a metric to Statsd."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbuilding a normalized path.", "response": "def _build_path(self, path, metric_type):\n        \"\"\"Return a normalized path.\n\n        :param list path: elements of the metric path to record\n        :param str metric_type: The metric type\n        :rtype: str\n\n        \"\"\"\n        path = self._get_prefixes(metric_type) + list(path)\n        return '{}.{}'.format(self._namespace,\n                              '.'.join(str(p).replace('.', '-') for p in path))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_prefixes(self, metric_type):\n        prefixes = []\n        if self._prepend_metric_type:\n            prefixes.append(self.METRIC_TYPES[metric_type])\n        return prefixes", "response": "Get the list of prefixes where applicable\n        is a list of metric prefixes."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _set_signed_in(self):\n        names = [\n            controller.get_user_name(user, full_name=CONFIG['FULL_USER_NAMES'])\n            for user in controller.signed_in_users()\n        ]\n        self.lbl_signedin_list.setText('\\n'.join(sorted(names)))", "response": "Populate the signed_in list with the names of currently\n            signed in users."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _show_feedback_label(self, message, seconds=None):\n        if seconds is None:\n            seconds = CONFIG['MESSAGE_DURATION']\n\n        logger.debug('Label feedback: \"{}\"'.format(message))\n\n        self.feedback_label_timer.timeout.connect(self._hide_feedback_label)\n        self.lbl_feedback.setText(str(message))\n        self.lbl_feedback.show()\n        self.feedback_label_timer.start(1000 * seconds)", "response": "Display a message in lbl_feedback which times out after some\n        number of seconds."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nvalidating input from ent_id then sign in to the Timesheet.", "response": "def _sign_button_press(self):\n        \"\"\"Validate input from ent_id, then sign in to the Timesheet.\"\"\"\n        user_id = self.ent_id.text().strip()\n\n        try:\n            status = controller.sign(user_id)\n\n        # ERROR: User type is unknown (!student and !tutor)\n        except ValueError as e:\n            logger.error(e, exc_info=True)\n            QMessageBox.critical(\n                self,\n                __title__ + ' Error',\n                str(e),\n                buttons=QMessageBox.Ok,\n                defaultButton=QMessageBox.Ok,\n            )\n\n        # ERROR: User is unregistered\n        except controller.UnregisteredUser as e:\n            logger.debug(e)\n            QMessageBox.warning(\n                self,\n                'Unregistered User',\n                str(e),\n                buttons=QMessageBox.Ok,\n                defaultButton=QMessageBox.Ok,\n            )\n\n        # User needs to select type\n        except controller.AmbiguousUserType as e:\n            logger.debug(e)\n            u = QtUserTypeSelectionDialog('Select User Type: ', self)\n            if u.exec_() == QDialog.Accepted:\n                status = controller.sign(user_id, user_type=u.user_type)\n                self._show_feedback_label(\n                    'Signed {}: {} ({})'.format(\n                        status.in_or_out, status.user_name, status.user_type\n                    )\n                )\n\n        # User has signed in or out normally\n        else:\n            sign_choice_confirmed = QMessageBox.question(\n                self,\n                'Confirm Sign-{}'.format(status.in_or_out),\n                'Sign {}: {}?'.format(status.in_or_out, status.user_name),\n                buttons=QMessageBox.Yes | QMessageBox.No,\n                defaultButton=QMessageBox.Yes,\n            )\n\n            logger.debug('Sign {} confirmed: {}'.format(\n                status.in_or_out, sign_choice_confirmed\n            ))\n\n            if sign_choice_confirmed == QMessageBox.No:\n                # Undo sign-in or sign-out\n                if status.in_or_out == 'in':\n                    controller.undo_sign_in(status.entry)\n                elif status.in_or_out == 'out':\n                    controller.undo_sign_out(status.entry)\n            else:\n                self._show_feedback_label(\n                    'Signed {}: {}'.format(status.in_or_out, status.user_name)\n                )\n\n        finally:\n            self._set_signed_in()\n            self.ent_id.clear()\n            self.ent_id.setFocus()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating user type based on which radio is selected.", "response": "def update_user_type(self):\n        \"\"\"Return either 'tutor' or 'student' based on which radio\n        button is selected.\n        \"\"\"\n        if self.rb_tutor.isChecked():\n            self.user_type = 'tutor'\n        elif self.rb_student.isChecked():\n            self.user_type = 'student'\n        self.accept()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef calc2dcoords(mol):\n    topology.recognize(mol)\n    g = set(i for i, _ in mol.atoms_iter())\n    # 1: get nodes in scaffolds\n    scaffolds = []\n    belongs = {}\n    for i, rkeys in enumerate(sorted(mol.scaffolds, key=len)):\n        scf = []\n        for rkey in rkeys:\n            ring = mol.rings[rkey]\n            for r in ring:\n                belongs[r] = i\n            scf.append(ring)\n            g -= set(ring)\n        scaffolds.append(scf)\n    # 2: traverse nodes and scaffolds\n    # the node and scaffold graph should be a tree (no cycles)\n    f = True\n    # print(scaffolds)\n    coords = {}\n    while g:\n        if f and scaffolds:  # largest scaffold is first\n            stack = [scaffolds[-1][0][0]]\n            f = False\n        else:\n            stack = [g.pop()]\n        pred = {}\n        branch = {}\n        while stack:\n            # print(\"stack: {}\".format(stack))\n            tail = stack.pop()\n            # print(\"tail: {}\".format(tail))\n            if tail in belongs:  # scaffolds\n                scf = scaffold_coords(scaffolds[belongs[tail]])\n                # print(scf.keys())\n                # rotate and translate\n                if not coords:\n                    coords = scf\n                else:\n                    u = coords[pred[tail]]\n                    v = scf[tail]\n                    op = [u[0] + math.cos(u[2]), u[1] + math.sin(u[2])]\n                    translate(scf, gm.vector(v[:2], op))\n                    rotate(scf, op, gm.rad(u[2] + math.pi - v[2]))\n                    coords.update(scf)\n                # stack nbrs of scaffold\n                for k in scf.keys():\n                    pred[k] = None\n                    for nbr in mol.neighbors(k):\n                        if nbr not in scf.keys():\n                            stack.append(nbr)\n                            pred[nbr] = k\n            else:  # append linker\n                if tail not in pred:  # isolated\n                    coords[tail] = [0, 0, 0, 1]\n                    continue\n                p = pred[tail]\n                x, y, ang, d = coords[p]\n                # TODO: ring configuration\n                coords[tail] = [x + math.cos(ang), y + math.sin(ang),\n                                ang + d * math.pi / 3, d * -1]\n                if p not in branch:\n                    coords[p][2] = gm.rad(coords[p][2] + math.pi * 2 / 3 * d)\n                    branch[p] = 1\n                elif branch[p] == 1:\n                    coords[p][2] = gm.rad(coords[p][2] + math.pi * d)\n                    branch[p] += 1\n                elif branch[p] == 2:\n                    coords[p][2] = gm.rad(coords[p][2] + math.pi * 2 / 3 * d)\n                    branch[p] += 1\n                for nbr in mol.neighbors(tail):\n                    if nbr not in pred:\n                        stack.append(nbr)\n                        pred[nbr] = tail\n        g -= set(pred)\n    resolve_overlap(coords)\n    for i, a in mol.atoms_iter():\n        mol.atom(i).coords = coords[i][:2]", "response": "Calculate optimal 2D coordinates of chemical structure"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nassign scaffold coordinate and angle to the tree", "response": "def scaffold_coords(rings):\n    \"\"\" assign scaffold coordinate and angle\n    {node: (coords, angle)}\n    \"\"\"\n    rs = deque(sorted(rings, key=len, reverse=True))\n    base = rs.popleft()\n    first = base[0]\n    coords = {first: [0, 0, 0, 1]}\n    attach_spiro(coords, base, first)\n    # display(coords)\n    while rs:\n        r = rs.popleft()\n        isec = list(set(coords) & set(r))\n        if not isec:\n            rs.append(r)\n        elif len(isec) == 1:  # spiro\n            attach_spiro(coords, r, isec)\n        elif len(isec) == 2:  # fuse\n            attach_fused(coords, r, isec)\n        else:  # bridge or append\n            bridge(coords, r, isec)\n        # display(coords)\n    return coords"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef shuffle_sattolo(items):\n    _randrange = random.randrange\n    for i in reversed(range(1, len(items))):\n        j = _randrange(i)  # 0 <= j < i\n        items[j], items[i] = items[i], items[j]", "response": "Shuffle items in place using Sattolo s algorithm."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nvalidate and convert comma - separated list of column numbers.", "response": "def column_list(string):\n    \"\"\"Validate and convert comma-separated list of column numbers.\"\"\"\n    try:\n        columns = list(map(int, string.split(',')))\n    except ValueError as e:\n        raise argparse.ArgumentTypeError(*e.args)\n    for column in columns:\n        if column < 1:\n            raise argparse.ArgumentTypeError(\n                'Invalid column {!r}: column numbers start at 1.'\n                .format(column))\n    return columns"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the first row and use it as column headers", "response": "def main():\n    parser = argparse.ArgumentParser(description='Shuffle columns in a CSV file')\n    parser.add_argument(metavar=\"FILE\", dest='input_file', type=argparse.FileType('r'), nargs='?',\n                        default=sys.stdin, help='Input CSV file. If omitted, read standard input.')\n    parser.add_argument('-s', '--sattolo',\n                        action='store_const', const=shuffle_sattolo,\n                        dest='shuffle', default=random.shuffle,\n                        help=\"Use Sattolo's shuffle algorithm.\")\n    col_group = parser.add_mutually_exclusive_group()\n    col_group.add_argument('-c', '--columns', type=column_list,\n                           help='Comma-separated list of columns to include.')\n    col_group.add_argument('-C', '--no-columns', type=column_list,\n                           help='Comma-separated list of columns to exclude.')\n    delim_group = parser.add_mutually_exclusive_group()\n    delim_group.add_argument('-d', '--delimiter', type=str, default=',',\n                             help='Input column delimiter.')\n    delim_group.add_argument('-t', '--tabbed', dest='delimiter',\n                             action='store_const', const='\\t',\n                             help='Delimit input with tabs.')\n    parser.add_argument('-q', '--quotechar', type=str, default='\"',\n                        help='Quote character.')\n    parser.add_argument('-o', '--output-delimiter', type=str, default=',',\n                        help='Output column delimiter.')\n    parser.add_argument('-v', '--version', action='version',\n                        version='%(prog)s {version}'.format(version=__version__))\n    args = parser.parse_args()\n\n    reader = csv.reader(args.input_file, delimiter=args.delimiter, quotechar=args.quotechar)\n\n    \"\"\"Get the first row and use it as column headers\"\"\"\n    headers = next(reader)\n\n    \"\"\"Create a matrix of lists of columns\"\"\"\n    table = []\n    for c in range(len(headers)):\n        table.append([])\n    for row in reader:\n        for c in range(len(headers)):\n            table[c].append(row[c])\n\n    cols = args.columns\n    if args.no_columns:\n        \"\"\"If columns to exclude are provided, get a list of all other columns\"\"\"\n        cols = list(set(range(len(headers))) - set(args.no_columns))\n    elif not cols:\n        \"\"\"If no columns are provided all columns will be shuffled\"\"\"\n        cols = range(len(headers))\n\n    for c in cols:\n        if c > len(headers):\n            sys.stderr.write('Invalid column {0}. Last column is {1}.\\n'.format(c, len(headers)))\n            exit(1)\n        args.shuffle(table[c - 1])\n\n    \"\"\"Transpose the matrix\"\"\"\n    table = zip(*table)\n\n    writer = csv.writer(sys.stdout, delimiter=args.output_delimiter)\n    writer.writerow(headers)\n    for row in table:\n        writer.writerow(row)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nlisting - List all files in a node", "response": "def list(context, job_id, sort, limit, where, verbose):\n    \"\"\"list(context, sort, limit, where, verbose)\n\n    List all files.\n\n    >>> dcictl file-list\u00a0job-id [OPTIONS]\n\n    :param string sort: Field to apply sort\n    :param integer limit: Max number of rows to return\n    :param string where: An optional filter criteria\n    :param boolean verbose: Display verbose output\n    \"\"\"\n    result = job.list_files(context, id=job_id, sort=sort, limit=limit,\n                            verbose=verbose, where=where)\n    utils.format_output(result, context.format, verbose=verbose)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef show(context, id):\n    content = file.content(context, id=id)\n    click.echo(content.text)", "response": "show(context, id)\n\n    Show a file.\n\n    >>> dcictl file-show [OPTIONS]\n\n    :param string id: ID of the file to show [required]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the element of the list after the given keyword.", "response": "def get(self, keyword):\n        \"\"\"Return the element of the list after the given keyword.\n\n        Parameters\n        ----------\n        keyword : str\n            The keyword parameter to find in the list.\n            Putting a colon before the keyword is optional, if no colon is\n            given, it is added automatically (e.g. \"keyword\" will be found as\n            \":keyword\" in the list).\n\n        Returns\n        -------\n        obj : KQMLObject\n            The object corresponding to the keyword parameter\n\n        Example:\n            kl = KQMLList.from_string('(FAILURE :reason INVALID_PARAMETER)')\n            kl.get('reason') # KQMLToken('INVALID_PARAMETER')\n        \"\"\"\n        if not keyword.startswith(':'):\n            keyword = ':' + keyword\n        for i, s in enumerate(self.data):\n            if s.to_string().upper() == keyword.upper():\n                if i < len(self.data)-1:\n                    return self.data[i+1]\n                else:\n                    return None\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef gets(self, keyword):\n        param = self.get(keyword)\n        if param is not None:\n            return safe_decode(param.string_value())\n        return None", "response": "Returns the element of the list after the given keyword as string."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nappend an element to the end of the list.", "response": "def append(self, obj):\n        \"\"\"Append an element to the end of the list.\n\n        Parameters\n        ----------\n        obj : KQMLObject or str\n            If a string is passed, it is instantiated as a\n            KQMLToken before being added to the list.\n        \"\"\"\n        if isinstance(obj, str):\n            obj = KQMLToken(obj)\n        self.data.append(obj)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef push(self, obj):\n        if isinstance(obj, str):\n            obj = KQMLToken(obj)\n        self.data.insert(0, obj)", "response": "Push an element to the beginning of the list."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set(self, keyword, value):\n        if not keyword.startswith(':'):\n            keyword = ':' + keyword\n        if isinstance(value, str):\n            value = KQMLToken(value)\n        if isinstance(keyword, str):\n            keyword = KQMLToken(keyword)\n        found = False\n        for i, key in enumerate(self.data):\n            if key.to_string().lower() == keyword.lower():\n                found = True\n                if i < len(self.data)-1:\n                    self.data[i+1] = value\n                break\n        if not found:\n            self.data.append(keyword)\n            self.data.append(value)", "response": "Set the element of the list after the given keyword."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the element of the list after the given keyword as string.", "response": "def sets(self, keyword, value):\n        \"\"\"Set the element of the list after the given keyword as string.\n\n        Parameters\n        ----------\n        keyword : str\n            The keyword parameter to find in the list.\n            Putting a colon before the keyword is optional, if no colon is\n            given, it is added automatically (e.g. \"keyword\" will be found as\n            \":keyword\" in the list).\n\n        value : str\n            The value is instantiated as KQMLString and added to the list.\n\n        Example:\n            kl = KQMLList.from_string('(FAILURE)')\n            kl.sets('reason', 'this is a custom string message, not a token')\n        \"\"\"\n        if isinstance(value, str):\n            value = KQMLString(value)\n        self.set(keyword, value)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the default instance of ConfigManager.", "response": "def default_instance():\n        \"\"\"\n        For use like a singleton, return the existing instance\n        of the object or a new instance\n        \"\"\"\n        if ConfigManager._instance is None:\n            with threading.Lock():\n                if ConfigManager._instance is None:\n                    ConfigManager._instance = ConfigManager()\n\n        return ConfigManager._instance"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read_recipe(self, filename):\n        Global.LOGGER.debug(f\"reading recipe {filename}\")\n        if not os.path.isfile(filename):\n            Global.LOGGER.error(filename + \" recipe not found, skipping\")\n            return\n\n        config = configparser.ConfigParser(allow_no_value=True,\n                                           delimiters=\"=\")\n\n        config.read(filename)\n\n        for section in config.sections():\n            self.sections[section] = config[section]\n\n        Global.LOGGER.debug(\"Read recipe \" + filename)", "response": "Read a recipe file from disk and store it in self. sections."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset a random port to be used by zmq", "response": "def set_socket_address(self):\n        \"\"\"\n        Set a random port to be used by zmq\n        \"\"\"\n        Global.LOGGER.debug('defining socket addresses for zmq')        \n        random.seed()\n        default_port = random.randrange(5001, 5999)\n\n        internal_0mq_address = \"tcp://127.0.0.1\"\n        internal_0mq_port_subscriber = str(default_port)\n        internal_0mq_port_publisher = str(default_port)\n\n        Global.LOGGER.info(str.format(\n            f\"zmq subsystem subscriber on {internal_0mq_port_subscriber} port\"))\n        Global.LOGGER.info(str.format(\n            f\"zmq subsystem publisher on {internal_0mq_port_publisher} port\"))\n\n        self.subscriber_socket_address = f\"{internal_0mq_address}:{internal_0mq_port_subscriber}\"\n        self.publisher_socket_address = f\"{internal_0mq_address}:{internal_0mq_port_publisher}\""}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_quantities(self, quantities, filters=None, native_filters=None, return_iterator=False):\n\n        quantities = self._preprocess_requested_quantities(quantities)\n        filters = self._preprocess_filters(filters)\n        native_filters = self._preprocess_native_filters(native_filters)\n\n        it = self._get_quantities_iter(quantities, filters, native_filters)\n\n        if return_iterator:\n            return it\n\n        data_all = defaultdict(list)\n        for data in it:\n            for q in quantities:\n                data_all[q].append(data[q])\n        return {q: concatenate_1d(data_all[q]) for q in quantities}", "response": "Fetch the requested quantities from this catalog."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if quantity is available in this catalog.", "response": "def has_quantity(self, quantity, include_native=True):\n        \"\"\"\n        Check if *quantity* is available in this catalog\n\n        Parameters\n        ----------\n        quantity : str\n            a quantity name to check\n\n        include_native : bool, optional\n            whether or not to include native quantity names when checking\n\n        Returns\n        -------\n        has_quantity : bool\n            True if the quantities are all available; otherwise False\n        \"\"\"\n\n        if include_native:\n            return all(q in self._native_quantities for q in self._translate_quantities({quantity}))\n\n        return quantity in self._quantity_modifiers"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef has_quantities(self, quantities, include_native=True):\n        quantities = set(quantities)\n\n        if include_native:\n            return all(q in self._native_quantities for q in self._translate_quantities(quantities))\n\n        return all(q in self._quantity_modifiers for q in quantities)", "response": "Checks if ALL quantities specified are available in this catalog."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef list_all_quantities(self, include_native=False, with_info=False):\n        q = set(self._quantity_modifiers)\n        if include_native:\n            q.update(self._native_quantities)\n        return {k: self.get_quantity_info(k) for k in q} if with_info else list(q)", "response": "Return a list of all available quantities in this catalog."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of all available native quantities in this catalog.", "response": "def list_all_native_quantities(self, with_info=False):\n        \"\"\"\n        Return a list of all available native quantities in this catalog.\n\n        If *with_info* is `True`, return a dict with quantity info.\n\n        See also: list_all_quantities\n        \"\"\"\n        q = self._native_quantities\n        return {k: self.get_quantity_info(k) for k in q} if with_info else list(q)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef first_available(self, *quantities):\n        for i, q in enumerate(quantities):\n            if self.has_quantity(q):\n                if i:\n                    warnings.warn('{} not available; using {} instead'.format(quantities[0], q))\n                return q", "response": "Return the first available quantity in the input arguments."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_input_kwargs(self, key=None, default=None):\n        warnings.warn(\"`get_input_kwargs` is deprecated; use `get_catalog_info` instead.\", DeprecationWarning)\n        return self.get_catalog_info(key, default)", "response": "Deprecated. Use get_catalog_info instead."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets information from the catalog config file.", "response": "def get_catalog_info(self, key=None, default=None):\n        \"\"\"\n        Get information from the catalog config file.\n        If *key* is `None`, return the full dict.\n        \"\"\"\n        if key is None:\n            return self._init_kwargs\n\n        return self._init_kwargs.get(key, default)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets information of a certain quantity.", "response": "def get_quantity_info(self, quantity, key=None, default=None):\n        \"\"\"\n        Get information of a certain quantity.\n        If *key* is `None`, return the full dict for that quantity.\n        \"\"\"\n        d = self._get_quantity_info_dict(quantity, default if key is None else dict())\n\n        if key is None:\n            return d\n\n        return d.get(key, default)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_quantity_modifier(self, quantity, modifier, overwrite=False):\n        if quantity in self._quantity_modifiers and not overwrite:\n            raise ValueError('quantity `{}` already exists'.format(quantity))\n        self._quantity_modifiers[quantity] = modifier\n        self._check_quantities_exist([quantity], raise_exception=False)", "response": "Add a quantity modifier to the internal quantity list."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_normalized_quantity_modifier(self, quantity):\n        modifier = self._quantity_modifiers.get(quantity, self._default_quantity_modifier)\n        if modifier is None:\n            return (trivial_callable, quantity)\n\n        if callable(modifier):\n            return (modifier, quantity)\n\n        if isinstance(modifier, (tuple, list)) and len(modifier) > 1 and callable(modifier[0]):\n            return modifier\n\n        return (trivial_callable, modifier)", "response": "Retrive a quantify modifier"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_derived_quantity(self, derived_quantity, func, *quantities):\n        if derived_quantity in self._quantity_modifiers:\n            raise ValueError('quantity name `{}` already exists'.format(derived_quantity))\n\n        if set(quantities).issubset(self._native_quantities):\n            new_modifier = (func,) + quantities\n\n        else:\n            functions = []\n            quantities_needed = []\n            quantity_count = []\n            for q in quantities:\n                modifier = self.get_normalized_quantity_modifier(q)\n                functions.append(modifier[0])\n                quantities_needed.extend(modifier[1:])\n                quantity_count.append(len(modifier)-1)\n\n            def _new_func(*x):\n                assert len(x) == sum(quantity_count)\n                count_current = 0\n                new_args = []\n                for func_this, count in zip(functions, quantity_count):\n                    new_args.append(func_this(*x[count_current:count_current+count]))\n                    count_current += count\n                return func(*new_args)\n\n            new_modifier = (_new_func,) + tuple(quantities_needed)\n\n        self.add_quantity_modifier(derived_quantity, new_modifier)", "response": "Adds a derived quantity modifier to the internal list of related items."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_modifier_on_derived_quantities(self, new_quantity, func, *quantities):\n        warnings.warn(\"Use `add_derived_quantity` instead.\", DeprecationWarning)\n        self.add_derived_quantity(new_quantity, func, *quantities)", "response": "Add a modifier to the derived quantity list."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check_for_wdiff():\n  cmd = ['which', CMD_WDIFF]\n  DEVNULL = open(os.devnull, 'wb')\n  proc = sub.Popen(cmd, stdout=DEVNULL)\n  proc.wait()\n  DEVNULL.close()\n  if proc.returncode != 0:\n    msg = \"the `{}` command can't be found\".format(CMD_WDIFF)\n    raise WdiffNotFoundError(msg)", "response": "Checks if the wdiff command can be found."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating a WDIFF file from the given org_file and new_file.", "response": "def generate_wdiff(org_file, new_file, fold_tags=False, html=True):\n  \"\"\"\n  Returns the results from the `wdiff` command as a string.\n\n  HTML `<ins>` and `<del>` tags will be used instead of the default markings,\n  unless *html* is set to `False`.\n\n  If *fold_tags* is set, `<ins>` and `<del>` tags are allowed to span line\n  breaks (option `-n` is not used).\n\n  Raises:\n\n    subrocess.CalledProcessError: on any `wdiff` process errors\n\n  \"\"\"\n  check_for_wdiff()\n  cmd = [CMD_WDIFF]\n  if html:\n    cmd.extend(OPTIONS_OUTPUT)\n  if not fold_tags:\n    cmd.extend(OPTIONS_LINEBREAK)\n  cmd.extend([org_file, new_file])\n  proc = sub.Popen(cmd, stdout=sub.PIPE)\n  diff, _ = proc.communicate()\n  return diff.decode('utf-8')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef build_paragraph(content, hard_breaks=False):\n  lines = list(filter(None, [line.strip() for line in content.split('\\n')]))\n  if hard_breaks:\n    for line_number in range(len(lines) - 1):\n      lines[line_number] = \"{}<br />\".format(lines[line_number])\n  return \"<p>{}</p>\".format('\\n'.join(lines))", "response": "Build a paragraph from a string."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwraps paragraphs in a string.", "response": "def wrap_paragraphs(content, hard_breaks=False):\n  \"\"\"\n  Returns *content* with all paragraphs wrapped in `<p>` tags.\n\n  If *hard_breaks* is set, line breaks are converted to `<br />` tags.\n\n  \"\"\"\n  paras = filter(None, [para.strip() for para in content.split('\\n\\n')])\n  paras = [build_paragraph(para, hard_breaks) for para in paras]\n  return '\\n'.join(paras)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef wrap_content(content, settings, hard_breaks=False):\n  settings.context['content'] = wrap_paragraphs(content, hard_breaks)\n  template = Template(settings.template)\n  try:\n    return template.render(**settings.context)\n  except KeyError as error:\n    msg = \"missing context setting: {}\".format(error)\n    raise ContextError(msg)", "response": "Wrap content in a HTML structure."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\npopulates the signed_in list with the names of currently signed in users.", "response": "def _set_signed_in(self):\n        \"\"\"Populate the signed_in list with the names of currently\n        signed in users.\n        \"\"\"\n        names = [\n            controller.get_user_name(user, full_name=CONFIG['FULL_USER_NAMES'])\n            for user in controller.signed_in_users()\n        ]\n        self.signed_in.set('\\n'.join(sorted(names)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndisplays a message in lbl_feedback which then times out after some number of seconds.", "response": "def _show_feedback_label(self, message, seconds=None):\n        \"\"\"Display a message in lbl_feedback, which then times out after\n        some number of seconds. Use after() to schedule a callback to\n        hide the feedback message. This works better than using threads,\n        which can cause problems in Tk.\n        \"\"\"\n        if seconds is None:\n            seconds = CONFIG['MESSAGE_DURATION']\n\n        # cancel any existing callback to clear the feedback\n        # label. this prevents flickering and inconsistent\n        # timing during rapid input.\n        with contextlib.suppress(AttributeError):\n            self.root.after_cancel(self.clear_feedback)\n\n        logger.debug('Label feedback: \"{}\"'.format(message))\n        self.feedback.set(message)\n        self.clear_feedback = self.root.after(\n            1000 * seconds, lambda: self.feedback.set(\"\")\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsign in to the Timesheet.", "response": "def _sign_button_press(self, *args):\n        \"\"\"Validate input from ent_id, then sign in to the Timesheet.\"\"\"\n        user_id = self.ent_id.get().strip()\n\n        try:\n            status = controller.sign(user_id)\n\n        # ERROR: User type is unknown (!student and !tutor)\n        except ValueError as e:\n            logger.error(e, exc_info=True)\n            messagebox.showerror(message=e)\n\n        # ERROR: User is unregistered\n        except controller.UnregisteredUser as e:\n            logger.debug(e)\n            messagebox.showwarning(message=e)\n\n        # User needs to select type\n        except controller.AmbiguousUserType as e:\n            logger.debug(e)\n            u = TkUserTypeSelectionDialog(\n                    parent=self.root,\n                    title='User Type Selection',\n                    entry_to_clear=self.ent_id)\n            if u.result:\n                logger.debug('User type selected: {}'.format(u.result))\n                status = controller.sign(user_id, user_type=u.result)\n                self._show_feedback_label(\n                    'Signed {}: {} ({})'.format(\n                        status.in_or_out, status.user_name, status.user_type\n                    )\n                )\n\n        # User has signed in or out normally\n        else:\n            sign_choice_confirmed = self._show_confirm_window(\n                'Sign {}: {}?'.format(status.in_or_out, status.user_name),\n                'Confirm Sign-{}'.format(status.in_or_out)\n            )\n\n            logger.debug('Sign {} confirmed: {}'.format(\n                status.in_or_out, sign_choice_confirmed\n            ))\n\n            if not sign_choice_confirmed:\n                # Undo sign-in or sign-out\n                if status.in_or_out == 'in':\n                    controller.undo_sign_in(status.entry)\n                elif status.in_or_out == 'out':\n                    controller.undo_sign_out(status.entry)\n            else:\n                self._show_feedback_label(\n                    'Signed {}: {}'.format(status.in_or_out, status.user_name)\n                )\n\n        finally:\n            self._set_signed_in()\n            self.ent_id.delete(0, 'end')\n            self.ent_id.focus()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef body(self, master):\n        self.frame = ttk.Frame(master, padding=(5, 5, 10, 10))\n\n        self.lbl_message = ttk.Label(\n            self.frame,\n            text='Select User Type: ',\n        )\n        self.rb_student = ttk.Radiobutton(\n            self.frame,\n            text='Student',\n            variable=self.rb_choice,\n            value='student',\n        )\n        self.rb_tutor = ttk.Radiobutton(\n            self.frame,\n            text='Tutor',\n            variable=self.rb_choice,\n            value='tutor',\n        )\n        self.btn_ok = ttk.Button(\n            self.frame,\n            text='OK',\n            command=self.ok,\n        )\n        self.btn_cancel = ttk.Button(\n            self.frame,\n            text='Cancel',\n            command=self.cancel,\n        )\n        # assemble grid\n        self.frame.grid(column=0, row=0, sticky=(N, S, E, W))\n        self.lbl_message.grid(column=0, row=0, columnspan=2, sticky=(W, E))\n        self.rb_student.grid(column=0, row=1, columnspan=2, sticky=W)\n        self.rb_tutor.grid(column=0, row=2, columnspan=2, sticky=W)\n        self.btn_ok.grid(column=0, row=3)\n        self.btn_cancel.grid(column=1, row=3)\n\n        # key bindings\n        self.bind('<Return>', self.ok)\n        self.bind('<KP_Enter>', self.ok)\n        self.bind('<Escape>', self.cancel)\n\n        self.rb_tutor.invoke()\n\n        return self.btn_ok", "response": "Create dialog body. Return widget that should have initial\n        focus."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ok(self, event=None):\n        if not self.validate():\n            self.initial_focus.focus_set()  # put focus back\n            return\n\n        # NOTE(amin): Using self.withdraw() here causes the\n        # ui to hang until the window loses and regains\n        # focus. There must be some blocking operation going\n        # on, but after some digging, I haven't been able to\n        # get any leads.\n\n        # NOTE(amin): We must clear the main window's entry\n        # before returning focus to it. Otherwise, rapid\n        # pressing of the enter key will open multiple dialogs.\n        self.entry_to_clear.delete(0, 'end')\n\n        self.update_idletasks()\n\n        try:\n            self.apply()\n        finally:\n            self.cancel()", "response": "This method is identical to tkinter. simpledialog. Dialog. ok but with the focus back to the entry."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninherits from tkinter. simpledialog. Dialog", "response": "def apply(self):\n        \"\"\"Inherited from tkinter.simpledialog.Dialog\"\"\"\n        user_type = self.rb_choice.get()\n        if user_type == 'student' or user_type == 'tutor':\n            self.result = user_type"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nflagging any entries from previous days where users forgot to sign_out out.", "response": "def flag_forgotten_entries(session, today=None):\n    \"\"\"Flag any entries from previous days where users forgot to sign\n    out.\n\n    :param session: SQLAlchemy session through which to access the database.\n    :param today: (optional) The current date as a `datetime.date` object. Used for testing.\n    \"\"\" # noqa\n    today = date.today() if today is None else today\n\n    forgotten = (\n        session\n        .query(Entry)\n        .filter(Entry.time_out.is_(None))\n        .filter(Entry.forgot_sign_out.is_(False))\n        .filter(Entry.date < today)\n    )\n\n    for entry in forgotten:\n        e = sign_out(entry, forgot=True)\n        logger.debug('Signing out forgotten entry: {}'.format(e))\n        session.add(e)\n\n    session.commit()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning list of currently signed in users.", "response": "def signed_in_users(session=None, today=None, full_name=True):\n    \"\"\"Return list of names of currently signed in users.\n\n    :param session: SQLAlchemy session through which to access the database.\n    :param today: (optional) The current date as a `datetime.date` object. Used for testing.\n    :param full_name: (optional) Whether to display full user names, or just first names.\n    :return: List of currently signed in users.\n    \"\"\" # noqa\n    if session is None:\n        session = Session()\n    else:\n        session = session\n\n    if today is None:\n        today = date.today()\n    else:\n        today = today\n\n    signed_in_users = (\n        session\n        .query(User)\n        .filter(Entry.date == today)\n        .filter(Entry.time_out.is_(None))\n        .filter(User.user_id == Entry.user_id)\n        .all()\n    )\n\n    session.close()\n    return signed_in_users"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_user_name(user, full_name=True):\n    try:\n        if full_name:\n            name = ' '.join([user.first_name, user.last_name])\n        else:\n            name = user.first_name\n    except AttributeError:\n        name = None\n\n    return name", "response": "Return the user s name as a string."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a new entry to the timesheet.", "response": "def sign_in(user, user_type=None, date=None, time_in=None):\n    \"\"\"Add a new entry to the timesheet.\n\n    :param user: `models.User` object. The user to sign in.\n    :param user_type: (optional) Specify whether user is signing in as a `'student'` or `'tutor'`.\n    :param date: (optional) `datetime.date` object. Specify the entry date.\n    :param time_in: (optional) `datetime.time` object. Specify the sign in time.\n    :return: The new entry.\n    \"\"\" # noqa\n    now = datetime.today()\n    if date is None:\n        date = now.date()\n    if time_in is None:\n        time_in = now.time()\n    if user_type is None:\n        if user.is_student and user.is_tutor:\n            raise AmbiguousUserType('User is both a student and a tutor.')\n        elif user.is_student:\n            user_type = 'student'\n        elif user.is_tutor:\n            user_type = 'tutor'\n        else:\n            raise ValueError('Unknown user type.')\n\n    new_entry = Entry(\n        uuid=str(uuid.uuid4()),\n        date=date,\n        time_in=time_in,\n        time_out=None,\n        user_id=user.user_id,\n        user_type=user_type,\n        user=user,\n    )\n\n    logger.info('{} ({}) signed in.'.format(new_entry.user_id, new_entry.user_type))\n    return new_entry"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sign_out(entry, time_out=None, forgot=False):\n    if time_out is None:\n        time_out = datetime.today().time()\n\n    if forgot:\n        entry.forgot_sign_out = True\n        logger.info(\n            '{} forgot to sign out on {}.'.format(entry.user_id, entry.date)\n        )\n\n    else:\n        entry.time_out = time_out\n\n    logger.info('{} ({}) signed out.'.format(entry.user_id, entry.user_type))\n    return entry", "response": "Sign out of an existing entry in the timesheet."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndelete a signed in entry.", "response": "def undo_sign_in(entry, session=None):\n    \"\"\"Delete a signed in entry.\n\n    :param entry: `models.Entry` object. The entry to delete.\n    :param session: (optional) SQLAlchemy session through which to access the database.\n    \"\"\" # noqa\n    if session is None:\n        session = Session()\n    else:\n        session = session\n\n    entry_to_delete = (\n        session\n        .query(Entry)\n        .filter(Entry.uuid == entry.uuid)\n        .one_or_none()\n    )\n\n    if entry_to_delete:\n        logger.info('Undo sign in: {}'.format(entry_to_delete.user_id))\n        logger.debug('Undo sign in: {}'.format(entry_to_delete))\n        session.delete(entry_to_delete)\n        session.commit()\n    else:\n        error_message = 'Entry not found: {}'.format(entry)\n        logger.error(error_message)\n        raise ValueError(error_message)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef undo_sign_out(entry, session=None):\n    if session is None:\n        session = Session()\n    else:\n        session = session\n\n    entry_to_sign_in = (\n        session\n        .query(Entry)\n        .filter(Entry.uuid == entry.uuid)\n        .one_or_none()\n    )\n\n    if entry_to_sign_in:\n        logger.info('Undo sign out: {}'.format(entry_to_sign_in.user_id))\n        logger.debug('Undo sign out: {}'.format(entry_to_sign_in))\n        entry_to_sign_in.time_out = None\n        session.add(entry_to_sign_in)\n        session.commit()\n    else:\n        error_message = 'Entry not found: {}'.format(entry)\n        logger.error(error_message)\n        raise ValueError(error_message)", "response": "Sign in a signed out entry."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sign(user_id, user_type=None, today=None, session=None):\n    if session is None:\n        session = Session()\n    else:\n        session = session\n\n    if today is None:\n        today = date.today()\n    else:\n        today = today\n\n    user = (\n        session\n        .query(User)\n        .filter(User.user_id == user_id)\n        .one_or_none()\n    )\n\n    if user:\n        signed_in_entries = (\n            user\n            .entries\n            .filter(Entry.date == today)\n            .filter(Entry.time_out.is_(None))\n            .all()\n        )\n\n        if not signed_in_entries:\n            new_entry = sign_in(user, user_type=user_type)\n            session.add(new_entry)\n            status = Status(\n                valid=True,\n                in_or_out='in',\n                user_name=get_user_name(user),\n                user_type=new_entry.user_type,\n                entry=new_entry\n            )\n\n        else:\n            for entry in signed_in_entries:\n                signed_out_entry = sign_out(entry)\n                session.add(signed_out_entry)\n                status = Status(\n                    valid=True,\n                    in_or_out='out',\n                    user_name=get_user_name(user),\n                    user_type=signed_out_entry.user_type,\n                    entry=signed_out_entry\n                )\n\n        session.commit()\n\n    else:\n        raise UnregisteredUser(\n            '{} not registered. Please register at the front desk.'.format(\n                user_id\n            )\n        )\n\n    logger.debug(status)\n    return status", "response": "Signs a user in or out if they are signed in or out."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the genotypes from a well formed variant.", "response": "def get_variant_genotypes(self, variant):\n        \"\"\"Get the genotypes from a well formed variant instance.\n\n        Args:\n            marker (Variant): A Variant instance.\n\n        Returns:\n            A list of Genotypes instance containing a pointer to the variant as\n            well as a vector of encoded genotypes.\n\n        \"\"\"\n        # The chromosome to search for (if a general one is set, that's the one\n        # we need to search for)\n        chrom = variant.chrom.name\n        if self.chrom is not None and chrom == self.chrom:\n            chrom = \"NA\"\n\n        # Getting the results\n        results = []\n        iterator = self._bgen.iter_variants_in_region(\n            CHROM_STR_DECODE.get(chrom, chrom), variant.pos, variant.pos,\n        )\n        for info, dosage in iterator:\n            if (variant.alleles is None or\n                    variant.iterable_alleles_eq([info.a1, info.a2])):\n                results.append(Genotypes(\n                    Variant(\n                        info.name,\n                        CHROM_STR_ENCODE.get(info.chrom, info.chrom),\n                        info.pos, [info.a1, info.a2],\n                    ),\n                    dosage,\n                    reference=info.a1,\n                    coded=info.a2,\n                    multiallelic=True,\n                ))\n\n        # If there are no results\n        if not results:\n            logging.variant_name_not_found(variant)\n\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\niterating on available markers and yields Genotypes instances.", "response": "def iter_genotypes(self):\n        \"\"\"Iterates on available markers.\n\n        Returns:\n            Genotypes instances.\n\n        \"\"\"\n        for info, dosage in self._bgen.iter_variants():\n            yield Genotypes(\n                Variant(\n                    info.name, CHROM_STR_ENCODE.get(info.chrom, info.chrom),\n                    info.pos, [info.a1, info.a2],\n                ),\n                dosage,\n                reference=info.a1,\n                coded=info.a2,\n                multiallelic=True,\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\niterate over the variants in the marker information.", "response": "def iter_variants(self):\n        \"\"\"Iterate over marker information.\"\"\"\n        for variant in self._bgen.iter_variant_info():\n            yield Variant(\n                variant.name,\n                CHROM_STR_ENCODE.get(variant.chrom, variant.chrom),\n                variant.pos, [variant.a1, variant.a2],\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\niterates over variants in a region.", "response": "def get_variants_in_region(self, chrom, start, end):\n        \"\"\"Iterate over variants in a region.\"\"\"\n        if self.chrom is not None and chrom == self.chrom:\n            # We are going to search for 'NA' since the chromosome was set\n            chrom = \"NA\"\n\n        iterator = self._bgen.iter_variants_in_region(\n            CHROM_STR_DECODE.get(chrom, chrom), start, end,\n        )\n        for info, dosage in iterator:\n            yield Genotypes(\n                Variant(\n                    info.name, CHROM_STR_ENCODE.get(info.chrom, info.chrom),\n                    info.pos, [info.a1, info.a2],\n                ),\n                dosage,\n                reference=info.a1,\n                coded=info.a2,\n                multiallelic=True,\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef iter_variants_by_names(self, names):\n        if not self.is_parallel:\n            yield from super().iter_variants_by_names(names)\n\n        else:\n            for info, dosage in self._bgen.iter_variants_by_names(names):\n                yield Genotypes(\n                    Variant(info.name,\n                            CHROM_STR_ENCODE.get(info.chrom, info.chrom),\n                            info.pos, [info.a1, info.a2]),\n                    dosage,\n                    reference=info.a1,\n                    coded=info.a2,\n                    multiallelic=True,\n                )", "response": "Iterates over the genotypes for variants using a list of names."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_variant_by_name(self, name):\n        results = []\n\n        try:\n            for info, dosage in self._bgen.get_variant(name):\n                results.append(Genotypes(\n                    Variant(\n                        info.name,\n                        CHROM_STR_ENCODE.get(info.chrom, info.chrom),\n                        info.pos,\n                        [info.a1, info.a2],\n                    ),\n                    dosage,\n                    reference=info.a1,\n                    coded=info.a2,\n                    multiallelic=False,\n                ))\n\n        except ValueError:\n            logging.variant_name_not_found(name)\n\n        return results", "response": "Get the genotype of a specific variant using it s name."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef format_request(self):\n        fmt = '{now} {status} {requestline} ({client_address}) {response_length} {delta}ms'\n\n        requestline = getattr(self, 'requestline')\n        if requestline:\n            # Original \"GET / HTTP/1.1\", remove the \"HTTP/1.1\"\n            requestline = ' '.join(requestline.split(' ')[:-1])\n        else:\n            requestline = '???'\n\n        if self.time_finish:\n            delta = '%.2f' % ((self.time_finish - self.time_start) * 1000)\n        else:\n            delta = '-'\n\n        data = dict(\n            now=datetime.datetime.now().replace(microsecond=0),\n            response_length=self.response_length or '-',\n            client_address=self.client_address[0] if isinstance(self.client_address, tuple) else self.client_address,\n            status=str(self._get_status_int()),\n            requestline=requestline,\n            delta=delta,\n        )\n\n        return fmt.format(**data)", "response": "Override for better log format\n           "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving all measurements from self. measurements. Reset the measurement counter. All ID is invalidated.", "response": "def clear_measurements(self):\n        \"\"\"Remove all measurements from self.measurements. Reset the\n        measurement counter. All ID are invalidated.\n        \"\"\"\n        keys = list(self.measurements.keys())\n        for key in keys:\n            del(self.measurements[key])\n        self.meas_counter = -1"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd new measurements to this instance.", "response": "def add_measurements(self, measurements):\n        \"\"\"Add new measurements to this instance\n\n        Parameters\n        ----------\n        measurements: numpy.ndarray\n            one or more measurement sets. It must either be 1D or 2D, with the\n            first dimension the number of measurement sets (K), and the second\n            the number of measurements (N): K x N\n\n        Returns\n        -------\n        mid: int\n            measurement ID used to extract the measurements later on\n\n        Examples\n        --------\n        >>> import numpy as np\n            import crtomo.configManager as CRconfig\n            config = CRconfig.ConfigManager(nr_of_electrodes=10)\n            config.gen_dipole_dipole(skipc=0)\n            # generate some random noise\n            random_measurements = np.random.random(config.nr_of_configs)\n            mid = config.add_measurements(random_measurements)\n            # retrieve using mid\n            print(config.measurements[mid])\n\n        \"\"\"\n        subdata = np.atleast_2d(measurements)\n\n        if self.configs is None:\n            raise Exception(\n                'must read in configuration before measurements can be stored'\n            )\n\n        # we try to accommodate transposed input\n        if subdata.shape[1] != self.configs.shape[0]:\n            if subdata.shape[0] == self.configs.shape[0]:\n                subdata = subdata.T\n            else:\n                raise Exception(\n                    'Number of measurements does not match number of configs'\n                )\n\n        return_ids = []\n        for dataset in subdata:\n            cid = self._get_next_index()\n            self.measurements[cid] = dataset.copy()\n            return_ids.append(cid)\n\n        if len(return_ids) == 1:\n            return return_ids[0]\n        else:\n            return return_ids"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef gen_all_voltages_for_injections(self, injections_raw):\n        injections = injections_raw.astype(int)\n\n        N = self.nr_electrodes\n        all_quadpoles = []\n        for idipole in injections:\n            # sort current electrodes and convert to array indices\n            Icurrent = np.sort(idipole) - 1\n\n            # voltage electrodes\n            velecs = list(range(1, N + 1))\n\n            # remove current electrodes\n            del(velecs[Icurrent[1]])\n            del(velecs[Icurrent[0]])\n\n            # permutate remaining\n            voltages = itertools.permutations(velecs, 2)\n            for voltage in voltages:\n                all_quadpoles.append(\n                    (idipole[0], idipole[1], voltage[0], voltage[1])\n                )\n        configs_unsorted = np.array(all_quadpoles)\n        # sort AB and MN\n        configs_sorted = np.hstack((\n            np.sort(configs_unsorted[:, 0:2], axis=1),\n            np.sort(configs_unsorted[:, 2:4], axis=1),\n        ))\n        configs = self.remove_duplicates(configs_sorted)\n\n        self.add_to_configs(configs)\n        self.remove_duplicates()\n        return configs", "response": "This function generates all possible measurements for a given set of current injections. This function generates all possible measurements for the given set of current injections."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef gen_wenner(self, a):\n        configs = []\n        for i in range(1, self.nr_electrodes - 3 * a + 1):\n            configs.append(\n                (i, i + a, i + 2 * a, i + 3 * a),\n            )\n        configs = np.array(configs)\n        self.add_to_configs(configs)\n        return configs", "response": "Generate the Wenner measurement configurations."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate and return the reciprocals for a given set of quadrupoles", "response": "def gen_reciprocals(self, quadrupoles):\n        \"\"\"For a given set of quadrupoles, generate and return reciprocals\n        \"\"\"\n        reciprocals = quadrupoles[:, ::-1].copy()\n        reciprocals[:, 0:2] = np.sort(reciprocals[:, 0:2], axis=1)\n        reciprocals[:, 2:4] = np.sort(reciprocals[:, 2:4], axis=1)\n        return reciprocals"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef plot_error_pars(self, mid):\n        fig, axes = plt.subplots(1, 2, figsize=(10, 6))\n\n        def plot_error_pars(axes, a, b, R, label=''):\n            dR = a * R + b\n            dlogR = np.abs(a + b / R)\n            ax = axes[0]\n            ax.scatter(R, dR / R * 100, label=label)\n            ax = axes[1]\n            ax.scatter(R, dlogR / np.abs(np.log(R)) * 100, label=label)\n            ax.set_xscale('log')\n            ax.set_yscale('log')\n\n        for b in np.linspace(R.min(), np.percentile(R, 10), 5):\n            plot_error_pars(axes, 0.05, b, R, label='b={0:.4f}'.format(b))\n        axes[0].set_xlabel(r'$R [\\Omega]$')\n        axes[0].set_ylabel(r'$(\\Delta R/R) \\cdot 100 [\\%]$')\n        axes[1].set_xlabel(r'$log_{10}(R [\\Omega])$')\n        axes[1].set_ylabel(\n            r'$log_{10}(R) / \\Delta log_{10}(R) \\cdot 100 [\\%]$'\n        )\n        axes[0].axhline(y=100)\n        axes[1].axhline(y=100)\n        fig.tight_layout()\n        fig.subplots_adjust(bottom=0.2)\n        axes[0].legend(\n            loc=\"lower center\",\n            ncol=4,\n            bbox_to_anchor=(0, 0, 1, 1),\n            bbox_transform=fig.transFigure\n        )\n\n        # fig.savefig('out.png', dpi=300)\n        return fig", "response": "Plot error parameters for a single object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef compute_K_factors(self, spacing=None, configs=None, numerical=False,\n                          elem_file=None, elec_file=None):\n        \"\"\"Compute analytical geometrical factors.\n\n        TODO: use real electrode positions from self.grid\n        \"\"\"\n        if configs is None:\n            use_configs = self.configs\n        else:\n            use_configs = configs\n\n        if numerical:\n            settings = {\n                'elem': elem_file,\n                'elec': elec_file,\n                'rho': 100,\n            }\n            K = edfK.compute_K_numerical(use_configs, settings)\n        else:\n            K = edfK.compute_K_analytical(use_configs, spacing=spacing)\n        return K", "response": "Compute analytical geometrical factors."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef plot_pseudosection_type2(self, mid, **kwargs):\n        c = self.configs\n\n        AB_ids = self._get_unique_identifiers(c[:, 0:2])\n        MN_ids = self._get_unique_identifiers(c[:, 2:4])\n\n        ab_sorted = np.sort(c[:, 0:2], axis=1)\n        mn_sorted = np.sort(c[:, 2:4], axis=1)\n\n        AB_coords = [\n            AB_ids[x] for x in\n            (ab_sorted[:, 0] * 1e5 + ab_sorted[:, 1]).astype(int)\n        ]\n        MN_coords = [\n            MN_ids[x] for x in\n            (mn_sorted[:, 0] * 1e5 + mn_sorted[:, 1]).astype(int)\n        ]\n\n        # check for duplicate positions\n        ABMN_coords = np.vstack((AB_coords, MN_coords)).T.copy()\n        _, counts = np.unique(\n            ABMN_coords.view(\n                ABMN_coords.dtype.descr * 2\n            ),\n            return_counts=True,\n        )\n        if np.any(counts > 1):\n            print('found duplicate coordinates!')\n            duplicate_configs = np.where(counts > 1)[0]\n            print('duplicate configs:')\n            print('A B M N')\n            for i in duplicate_configs:\n                print(c[i, :])\n\n        # prepare matrix\n        if isinstance(mid, int):\n            plot_values = self.measurements[mid]\n        elif isinstance(mid, np.ndarray):\n            plot_values = np.squeeze(mid)\n        else:\n            raise Exception('Data in parameter \"mid\" not understood')\n\n        if kwargs.get('log10', False):\n            plot_values = np.log10(plot_values)\n\n        C = np.zeros((len(MN_ids.items()), len(AB_ids))) * np.nan\n        C[MN_coords, AB_coords] = plot_values\n\n        # for display purposes, reverse the first dimension\n        C = C[::-1, :]\n\n        ax = kwargs.get('ax', None)\n        if ax is None:\n            fig, ax = plt.subplots(1, 1, figsize=(15 / 2.54, 10 / 2.54))\n        fig = ax.get_figure()\n\n        cmap = mpl.cm.get_cmap('viridis')\n        if kwargs.get('do_not_saturate', False):\n            cmap.set_over(\n                color='r'\n            )\n            cmap.set_under(\n                color='c'\n            )\n        im = ax.matshow(\n            C,\n            interpolation='none',\n            cmap=cmap,\n            aspect='auto',\n            vmin=kwargs.get('cbmin', None),\n            vmax=kwargs.get('cbmax', None),\n            extent=[\n                0, max(AB_coords),\n                0, max(MN_coords),\n            ],\n        )\n\n        max_xy = max((max(AB_coords), max(MN_coords)))\n        ax.plot(\n            (0, max_xy),\n            (0, max_xy),\n            '-',\n            color='k',\n            linewidth=1.0,\n        )\n\n        if not kwargs.get('nocb', False):\n            cb = fig.colorbar(im, ax=ax)\n            cb.set_label(\n                kwargs.get('cblabel', '')\n            )\n\n        ax.set_xlabel(\n            kwargs.get('xlabel', 'current dipoles')\n        )\n        ax.set_ylabel(\n            kwargs.get('ylabel', 'voltage dipoles')\n        )\n\n        return fig, ax", "response": "Create a pseudosection plot of type 2 for a given measurement data set."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef gen_voltage_dipoles_skip(self, cinj, skip=0):\n        new_configs = []\n        for ab in cinj:\n            for i in range(1, self.nr_electrodes + 1):\n                m = i\n                n = i + skip + 1\n                if m in ab or n in ab:\n                    continue\n                if n > self.nr_electrodes:\n                    continue\n                new_configs.append((ab[0], ab[1], m, n))\n        configs = np.array(new_configs)\n        self.add_to_configs(configs)\n        return configs", "response": "Generate all possible voltage dipoles for given current injections."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking if this rule applies to the given src and dst paths based on the src pattern and dst pattern given in the constructor.", "response": "def applies(self, src, dst):\n        \"\"\"Checks if this rule applies to the given src and dst paths, based on the src pattern and\n        dst pattern given in the constructor.\n\n        If src pattern was None, this rule will apply to any given src path (same for dst).\n        \"\"\"\n        if self._src_pattern and (src is None or re.search(self._src_pattern, src) is None):\n            return False\n        elif self._dst_pattern and (dst is None or re.search(self._dst_pattern, dst) is None):\n            return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef recv(self, size):\n        try:\n            start = datetime.now()\n            while len(self.buffer) < size:\n                if self.timeout is not None:\n                    elapsed = (datetime.now() - start).microseconds\n                    timeout = self.timeout * 1000 * 1000  # to microseconds\n                    if elapsed >= timeout:\n                        raise socket.timeout()\n                r, w, x = select([self.process.stdout], [], [], 0.0)\n                if r and r[0] == self.process.stdout:\n                    b = os.read(self.process.stdout.fileno(), 1)\n                    # Store in class-level buffer for persistence across\n                    # timeouts; this makes us act more like a real socket\n                    # (where timeouts don't actually drop data.)\n                    self.buffer.append(b)\n            result = ''.join(self.buffer)\n            self.buffer = []\n            return result\n        except socket.timeout:\n            raise  # socket.timeout is a subclass of IOError\n        except IOError as e:\n            raise ProxyCommandFailure(' '.join(self.cmd), e.strerror)", "response": "Read from the forked program and return the length of the read content."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a new UnboundNode representing a given class.", "response": "def _createunbound(kls, **info):\n    \"\"\"Create a new UnboundNode representing a given class.\"\"\"\n    \n    if issubclass(kls, Bitfield):\n        nodetype = UnboundBitfieldNode\n    elif hasattr(kls, '_fields_'):\n        nodetype = UnboundStructureNode\n    elif issubclass(kls, ctypes.Array):\n        nodetype = UnboundArrayNode\n    else:\n        nodetype = UnboundSimpleNode        \n    return nodetype(type=kls, **info)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _createbound(obj):\n    # Start by allowing objects to define custom unbound reference hooks\n    try:\n        kls = obj._unboundreference_()\n    except AttributeError:\n        kls = type(obj)\n    \n    unbound = _createunbound(kls)\n    def valueget():\n        return obj\n    for t in (BoundBitfieldNode, BoundStructureNode, BoundArrayNode):\n        if isinstance(unbound, t._unboundtype):\n            kls = t\n            break\n    else:\n        kls = BoundSimpleNode\n    \n    child = kls(unbound, valueget)\n    return child", "response": "Create a new BoundNode representing a given object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef findnode(obj, path=''):\n    if isclass(obj):\n        node = _createunbound(obj)\n    else:\n        node = _createbound(obj)\n    \n    # And walk it down.\n    pathparts = re.split(r'\\]?(?:[[.]|$)', path)\n    for part in pathparts:\n        if not part:    continue\n        try:\n            idx = int(part)\n            node = node[idx]\n        except ValueError:\n            node = node[part]\n    return node", "response": "Returns a Node pointing to obj."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef display(obj, skiphidden=True, **printargs):\n    \n    top = findnode(obj)\n\n    #-------------------------------------------------------------------\n    # Iterate through the entire structure turning all the nodes into\n    # tuples of strings for display.\n    \n    maxhex = len(hex(ctypes.sizeof(top.type))) - 2\n    def addrformat(addr):\n        if isinstance(addr, int):\n            return \"0x{0:0{1}X}\".format(addr, maxhex)\n        else:\n            intpart = int(addr)\n            fracbits = int((addr - intpart) * 8)\n            return \"0x{0:0{1}X}'{2}\".format(intpart, maxhex, fracbits)\n    \n    def formatval(here):\n        if isinstance(here, BoundSimpleNode):\n            return \"{0}({1})\".format(here.type.__name__, here.value)\n        else:\n            return str(here.value)\n\n    if isinstance(top, UnboundNode):\n        headers = ['Path', 'Addr', 'Type']\n        results = [\n            (('  ' * n.depth) + n.name, addrformat(n.baseoffset), n.type.__name__)\n                for n in walknode(top, skiphidden)\n        ]\n    else:\n        headers = ['Path', 'Addr', 'Value']\n        results = [\n            (('  ' * n.depth) + n.name, addrformat(n.baseoffset), formatval(n))\n                for n in walknode(top, skiphidden)\n        ]\n        \n    #-------------------------------------------------------------------\n    # Determine the maximum width of the text in each column, make the\n    # column always that wide.\n        \n    widths = [\n        max(max(len(d[col]) for d in results), len(h))\n            for col, h in enumerate(headers)\n    ]\n    \n    #-------------------------------------------------------------------\n    # Print out the tabular data.\n    \n    def lp(args):\n        print(*args, **printargs)\n        \n    lp(d.center(w) for d, w in zip(headers, widths))\n    lp('-' * w for w in widths)\n    for r in results:\n        lp(d.ljust(w) for d, w in zip(r, widths))", "response": "Print a view of obj."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef walknode(top, skiphidden=True):\n    if skiphidden and top.name.startswith('._'):\n        return\n        \n    yield top\n    for child in top:\n        for c in walknode(child):\n            yield c", "response": "Returns an iterator over all Nodes under top."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a recursive iterator over all Nodes starting from the given path.", "response": "def walk(obj, path='', skiphidden=True):\n    \"\"\"Returns a recursive iterator over all Nodes starting from\n    findnode(obj, path).\n    \n    If skiphidden is True (the default) then structure branches starting with\n    an underscore will be ignored.\n    \"\"\"\n    \n    node = findnode(obj, path)\n    return walknode(node, skiphidden)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pathparts(self):\n        try:\n            parts = self.parent.pathparts()\n            parts.append(self.name)\n            return parts\n        except AttributeError:\n            return []", "response": "A list of the parts of the path returning the root node returning\n        an empty list."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef baseoffset(self):\n        try:\n            return self.parent.baseoffset + self.offset\n        except AttributeError:\n            return self.offset", "response": "The offset of this node from the root node."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks if two numbers are almost equal.", "response": "def _almost_equal(a, b):\n    \"\"\"Check if the two numbers are almost equal\n    \"\"\"\n    # arbitrary small number!!!\n    threshold = 1e-9\n    diff = np.abs(a - b)\n    return (diff < threshold)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncomplement the alleles of this variant.", "response": "def complement_alleles(self):\n        \"\"\"Complement the alleles of this variant.\n\n        This will call this module's `complement_alleles` function.\n\n        Note that this will not create a new object, but modify the state of\n        the current instance.\n\n        \"\"\"\n        self.alleles = self._encode_alleles(\n            [complement_alleles(i) for i in self.alleles]\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef flip_coded(self):\n        self.genotypes = 2 - self.genotypes\n        self.reference, self.coded = self.coded, self.reference", "response": "Flips the coding of the alleles."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nflips the strand of the alleles.", "response": "def flip_strand(self):\n        \"\"\"Flips the strand of the alleles.\"\"\"\n        self.reference = complement_alleles(self.reference)\n        self.coded = complement_alleles(self.coded)\n        self.variant.complement_alleles()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\niterating over the genotypes for variants using a list of names.", "response": "def iter_variants_by_names(self, names):\n        \"\"\"Iterates over the genotypes for variants using a list of names.\n\n        Args:\n            names (list): The list of names for variant extraction.\n\n        \"\"\"\n        for name in names:\n            for result in self.get_variant_by_name(name):\n                yield result"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts rotation from axis and angle to matrix representation", "response": "def rotvec2mat(u, phi):\n    \"\"\"Convert rotation from axis and angle to matrix representation\"\"\"\n\n    phi = np.squeeze(phi)\n    norm_u = np.linalg.norm(u)\n\n    if norm_u < 1e-12:\n        raise Exception(\"the rotation vector is equal to zero\")\n\n    u = u / norm_u\n    # http://en.wikipedia.org/wiki/Rotation_matrix\n    s = np.sin(phi)\n    c = np.cos(phi)\n    t = 1 - c\n\n    ux = u[0]\n    uy = u[1]\n    uz = u[2]\n    res = np.array([[t * ux * ux + c, t * ux * uy - s * uz, t * ux * uz + s * uy],\n                    [t * ux * uy + s * uz, t * uy * uy + c, t * uy * uz - s * ux],\n                    [t * ux * uz - s * uy, t * uy * uz + s * ux, t * uz * uz + c]])\n\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts the pixel coordinates from the frame into lab - vector.", "response": "def det2lab_xds(\n        pixels_coord, frame_number,\n        starting_frame, starting_angle, oscillation_angle,\n        rotation_axis,\n        wavelength, wavevector,\n        NX, NY, pixelsize_x, pixelsize_y,\n        distance_to_detector, x_center, y_center,\n        detector_x, detector_y, detector_normal, **kwargs):\n    \"\"\"Converts pixels coordinates from the frame into q-vector\"\"\"\n\n    array_shape = (1, 3)\n\n    if detector_x.shape == array_shape:\n        detector_x = detector_x.T\n        detector_y = detector_y.T\n        detector_normal = detector_normal.T\n    if wavevector.shape == array_shape:\n        wavevector = wavevector.T\n    if rotation_axis.shape == array_shape:\n        rotation_axis = rotation_axis.T\n    xmm = (pixels_coord[:, [0]] - x_center) * pixelsize_x\n    ymm = (pixels_coord[:, [1]] - y_center) * pixelsize_y\n    # find scattering vector of each pixel\n    scattering_vector_mm = np.outer(xmm, detector_x) + \\\n                           np.outer(ymm, detector_y) + \\\n                           distance_to_detector * np.outer(np.ones(shape=xmm.shape),\n                                                           detector_normal)\n    scattering_vector_mm = scattering_vector_mm.T\n    phi = (frame_number - starting_frame) * oscillation_angle + \\\n          starting_angle\n    # calculating norm for each column\n    norms = np.sum(scattering_vector_mm ** 2., axis=0) ** (1. / 2)\n    #deviding scattering vector by its own norm\n    unit_scattering_vector = scattering_vector_mm / norms\n    #subtracting incident beam vector\n\n    h = unit_scattering_vector / wavelength - \\\n        np.tile(wavevector, (unit_scattering_vector.shape[1], 1)).T\n    #rotating\n    if phi.size == 1:\n        h = np.dot(rotvec2mat(rotation_axis.T, -2 * np.pi * phi / 360), h)\n    else:\n        for i in range(phi.size):\n            h[:, [i]] = np.dot(\n                rotvec2mat(rotation_axis.T, -2 * np.pi * phi[i] / 360), h[:, [i]])\n\n    return h, scattering_vector_mm, unit_scattering_vector"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating a new private DSS key. This factory function can be used to generate a new host key or authentication key. :param int bits: number of bits the generated key should be. :param function progress_func: an optional function to call at key points in key generation (used by ``pyCrypto.PublicKey``). :return: new `.DSSKey` private key", "response": "def generate(bits=1024, progress_func=None):\n        \"\"\"\n        Generate a new private DSS key.  This factory function can be used to\n        generate a new host key or authentication key.\n\n        :param int bits: number of bits the generated key should be.\n        :param function progress_func:\n            an optional function to call at key points in key generation (used\n            by ``pyCrypto.PublicKey``).\n        :return: new `.DSSKey` private key\n        \"\"\"\n        dsa = DSA.generate(bits, os.urandom, progress_func)\n        key = DSSKey(vals=(dsa.p, dsa.q, dsa.g, dsa.y))\n        key.x = dsa.x\n        return key"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_table_frame(self, prefix=\"\", table_id=\"sspdtable\", *args, **kwargs):\n        if not table_id:\n            raise ValueError(\"table_id parameter can not be an empty string.\")\n        table_key = prefix + \"sspdtable\"\n        context = {\n            table_key: {\n                \"id\": table_id,\n                \"frame\": self.frame\n            }\n        }\n        if self.form:\n            context[table_key]['footer_form'] = self.footer_form(*args, **kwargs)\n        return context", "response": "Render the structure and an instance of the footer form"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_query_dict(self, **kwargs):\n        total_cols = ensure(int, kwargs.get('total_cols', [0])[0], 0)\n        mapping = self.mapping\n        filter_dict = defaultdict(dict)\n\n        # set up the starter, since sometimes we start the enumeration from '1'\n        starter = mapping.keys()[0]\n        for i in range(starter, total_cols):\n            key = 'columns[{index}]'.format(index=i)\n            if kwargs.get(key + '[searchable]', [0])[0] != 'true':\n                continue\n            search_value = kwargs.get(key + '[search][value]', [''])[0].strip()\n            if not search_value:\n                continue\n            enum_item = mapping.from_key(i)\n            filter_obj = enum_item.extra\n            if type(filter_obj) is tuple and len(filter_obj) == 2:\n                filter_func, filter_key = filter_obj\n                filter_dict[filter_func][filter_key] = search_value\n            elif type(filter_obj) is str:\n                filter_dict['filter'][filter_obj] = search_value\n            else:\n                raise ValueError(\"Invalid filter key.\")\n        return filter_dict", "response": "function to generate a filter dictionary from the keyword arguments passed to the filter function."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef filtering(queryset, query_dict):\n        # apply pre_search_condition\n        for key, value in query_dict.items():\n            assert hasattr(queryset, key), \"Parameter 'query_dict' contains\"\\\n                                           \" non-existent attribute.\"\n            if isinstance(value, list):\n                queryset = getattr(queryset, key)(*value)\n            elif isinstance(value, dict):\n                queryset = getattr(queryset, key)(**value)\n            else:\n                queryset = getattr(queryset, key)(value)\n        return queryset", "response": "function to narrow the queryset down the queryset s size by applying the pre search condition to the queryset s size by applying the pre search condition to the queryset s size by narrowing the queryset s size by the query_dict s size."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef slicing(queryset, **kwargs):\n        # if the length is -1, we need to display all the records\n        # otherwise, just slicing the queryset\n        length = ensure(int, kwargs.get('length', [0])[0], 0)\n        start = ensure(int, kwargs.get('start', [0])[0], 0)\n        if length >= 0:\n            queryset = queryset[start:start + length]\n        return queryset", "response": "function to slice the queryset according to the display length\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef query_by_args(self, pre_search_condition=None, **kwargs):\n        if pre_search_condition and not isinstance(pre_search_condition, OrderedDict):\n            raise TypeError(\n                \"Parameter 'pre_search_condition' must be an OrderedDict.\")\n        # extract requisite parameters from kwargs\n        draw = ensure(int, kwargs.get('draw', [0])[0], 0)\n\n        # just implement the get_query_dict function\n        query_dict = self.get_query_dict(**kwargs)\n        order_key = self.get_order_key(**kwargs)\n\n        # get the model from the serializer parameter\n        model_class = self.serializer.Meta.model\n        # get the objects\n        queryset = model_class.objects\n\n        # apply the pre search condition if it exists\n        if pre_search_condition:\n            queryset = self.filtering(queryset, pre_search_condition)\n        else:\n            queryset = queryset.all()\n\n        # number of the total records\n        total = queryset.count()\n\n        # if the query dict not empty, then apply the query dict\n        if query_dict:\n            queryset = self.filtering(queryset, query_dict)\n\n        # number of the records after applying the query\n        count = queryset.count()\n\n        # order the queryset\n        queryset = queryset.order_by(order_key)\n\n        # slice the queryset\n        queryset = self.slicing(queryset, **kwargs)\n        return {'items': queryset, 'count': count, 'total': total, 'draw': draw}", "response": "This function is used to process the query_by_args method of the data tables package in frontend."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef process(self, pre_search_condition=None, **kwargs):\n        records = self.query_by_args(pre_search_condition=pre_search_condition,\n                                     **kwargs)\n        serializer = self.serializer(records['items'], many=True)\n        result = {\n            'data': serializer.data,\n            'draw': records['draw'],\n            'recordsTotal': records['total'],\n            'recordsFiltered': records['count'],\n        }\n        return result", "response": "This function is called outside to get the footer search condition apply the search in DB and render the serialized result."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts plain dictionary to MutationDict", "response": "def coerce(cls, key, value):\n        \"\"\"Convert plain dictionary to MutationDict\"\"\"\n        self = MutationDict((k,MutationObj.coerce(key, v)) for (k, v) in value.items())\n        self._key = key\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef coerce(cls, key, value):\n        self = MutationList((MutationObj.coerce(key, v) for v in value))\n        self._key = key\n        return self", "response": "Convert plain list to MutationList"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load_post_webhook(request):\n    try:\n        wp_post_id = int(request.POST[\"ID\"])\n    except:\n        raise Http404(\"Post does not exist\")\n\n    # load this asynchronously so that the webhook gets a fast response\n    load_post.after_response(wp_post_id)\n    return JsonResponse({\"status\": \"Refreshing wp_post_id: {}\".format(wp_post_id)})", "response": "Load a WordPress post from the local Django site."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load_post(wp_post_id):\n\n    # wait a bit to give WordPress REST API a chance to catch up\n    time.sleep(1)\n\n    loader = WPAPILoader()\n    post = loader.load_post(wp_post_id)\n\n    if post:\n        logger.info(\"Successfully loaded post wp_post_id=%s, pk=%s\", wp_post_id, post.pk)\n    else:\n        logger.warning(\"Error loading post wp_post_id=%s\", wp_post_id)", "response": "Loads a WordPress post from WordPress REST API."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_authenticated_user(self, redirect_uri, callback, scope=None, **args):\n\n        code = self.get_argument('code', None)\n        if not code:\n            self.authorize_redirect(redirect_uri, scope=scope, **args)\n            return\n        self.get_access_token(\n            code, callback=(yield gen.Callback('_RenrenGraphMixin.get_authenticated_user')),\n            redirect_uri=redirect_uri)\n\n        response = yield gen.Wait('_RenrenGraphMixin.get_authenticated_user')\n        if not response:\n            callback(None)\n            return\n        try:\n            user = json_decode(response.body)\n        except:\n            logging.warning(\"Error response %s fetching %s\",\n                            response.body, response.request.url)\n            callback(None)\n            return\n        if 'error' in user:\n            logging.warning(\"Error response %s fetching %s\",\n                            user['error_description'], response.request.url)\n            callback(None)\n            return\n\n        #{{{ get session key\n        self.renren_request('renren_api/session_key', user['access_token'],\n                            callback=(yield gen.Callback('_RenrenGraphMixin._session_key')))\n        response = yield gen.Wait('_RenrenGraphMixin._session_key')\n        if response.error and not response.body:\n            logging.warning(\"Error response %s fetching %s\",\n                            response.error, response.request.url)\n        elif response.error:\n            logging.warning(\"Error response %s fetching %s: %s\",\n                            response.error, response.request.url, response.body)\n        else:\n            try:\n                user['session'] = json_decode(response.body)\n            except:\n                pass\n        #}}} #TODO delete when renren graph api released\n        callback(user)\n        return", "response": "class RenrenHandler(tornado.web.RequestHandler, RenrenGraphMixin):\n            @tornado.web.asynchronous\n            @gen.engine\n            def get(self):\n                self.get_authenticated_user(\n                    callback=(yield gen.Callback('key')),\n                    redirect_uri=url)\n                user = yield gen.Wait('key')\n                if not user:\n                    raise web.HTTPError(500, \"Renren auth failed\")\n                # do something else\n                self.finish()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef authenticate_redirect(self, callback_uri=None, cancel_uri=None,\n                              extended_permissions=None):\n        \"\"\"Authenticates/installs this app for the current user.\"\"\"\n        self.require_setting(\"facebook_api_key\", \"Facebook Connect\")\n        callback_uri = callback_uri or self.request.uri\n        args = {\n            \"api_key\": self.settings[\"facebook_api_key\"],\n            \"v\": \"1.0\",\n            \"fbconnect\": \"true\",\n            \"display\": \"page\",\n            \"next\": urljoin(self.request.full_url(), callback_uri),\n            \"return_session\": \"true\",\n        }\n        if cancel_uri:\n            args[\"cancel_url\"] = urljoin(\n                self.request.full_url(), cancel_uri)\n        if extended_permissions:\n            if isinstance(extended_permissions, (str, bytes_type)):\n                extended_permissions = [extended_permissions]\n            args[\"req_perms\"] = \",\".join(extended_permissions)\n        self.redirect(\"http://www.facebook.com/login.php?\" +\n                      urlencode(args))", "response": "Redirect to Facebook login. php."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the vector structure as a DNA regex pattern.", "response": "def structure(cls):\n        # type: () -> Text\n        \"\"\"Get the vector structure, as a DNA regex pattern.\n\n        Warning:\n            If overloading this method, the returned pattern must include 3\n            capture groups to capture the following features:\n\n            1. The downstream (3') overhang sequence\n            2. The vector placeholder sequence\n            3. The upstream (5') overhang sequence\n\n        \"\"\"\n        downstream = cls.cutter.elucidate()\n        upstream = str(Seq(downstream).reverse_complement())\n        return \"\".join(\n            [\n                upstream.replace(\"^\", \")(\").replace(\"_\", \"(\"),\n                \"N*\",\n                downstream.replace(\"^\", \")(\").replace(\"_\", \")\"),\n            ]\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef placeholder_sequence(self):\n        # type: () -> SeqRecord\n        \"\"\"Get the placeholder sequence in the vector.\n\n        The placeholder sequence is replaced by the concatenation of modules\n        during the assembly. It often contains a dropout sequence, such as a\n        GFP expression cassette that can be used to measure the progress of\n        the assembly.\n        \"\"\"\n        if self.cutter.is_3overhang():\n            return self._match.group(2) + self.overhang_end()\n        else:\n            return self.overhang_start() + self._match.group(2)", "response": "Get the placeholder sequence in the vector."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef target_sequence(self):\n        # type: () -> SeqRecord\n        \"\"\"Get the target sequence in the vector.\n\n        The target sequence if the part of the plasmid that is not discarded\n        during the assembly (everything except the placeholder sequence).\n        \"\"\"\n        if self.cutter.is_3overhang():\n            start, end = self._match.span(2)[0], self._match.span(3)[1]\n        else:\n            start, end = self._match.span(1)[0], self._match.span(2)[1]\n        return add_as_source(self.record, (self.record << start)[end - start :])", "response": "Get the target sequence in the vector."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nassembling the provided modules into the vector.", "response": "def assemble(self, module, *modules, **kwargs):\n        # type: (AbstractModule, *AbstractModule, **Any) -> SeqRecord\n        \"\"\"Assemble the provided modules into the vector.\n\n        Arguments:\n            module (`~moclo.base.modules.AbstractModule`): a module to insert\n                in the vector.\n            modules (`~moclo.base.modules.AbstractModule`, optional): additional\n                modules to insert in the vector. The order of the parameters\n                is not important, since modules will be sorted by their start\n                overhang in the function.\n\n        Returns:\n            `~Bio.SeqRecord.SeqRecord`: the assembled sequence with sequence\n            annotations inherited from the vector and the modules.\n\n        Raises:\n            `~moclo.errors.DuplicateModules`: when two different modules share\n                the same start overhang, leading in possibly non-deterministic\n                constructs.\n            `~moclo.errors.MissingModule`: when a module has an end overhang\n                that is not shared by any other module, leading to a partial\n                construct only\n            `~moclo.errors.InvalidSequence`: when one of the modules does not\n                match the required module structure (missing site, wrong\n                overhang, etc.).\n            `~moclo.errors.UnusedModules`: when some modules were not used\n                during the assembly (mostly caused by duplicate parts).\n\n        \"\"\"\n\n        mgr = AssemblyManager(\n            vector=self,\n            modules=[module] + list(modules),\n            name=kwargs.get(\"name\", \"assembly\"),\n            id_=kwargs.get(\"id\", \"assembly\"),\n        )\n        return mgr.assemble()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncall when the connection is established.", "response": "async def onConnect(self):\n        \"\"\"\n        Configure the component\n        \"\"\"\n        # Add extra attribute\n        # This allows for following crossbar/autobahn spec\n        # without changing legacy configuration\n        if not hasattr(self.config, 'extra'):\n            original_config = {'config': self.config}\n            self.config = objdict(self.config)\n            setattr(self.config, 'extra', original_config)\n            self.config.extra['handlers'] = self.handlers\n\n        # setup transport host\n        self.transport_host = self.config.extra['config']['transport_host']\n\n        # subscription setup\n        self.subscribe_options = SubscribeOptions(**self.config.extra['config']['sub_options'])\n        self.replay_events = self.config.extra['config']['replay_events']\n\n        # publishing setup\n        self.publish_topic = self.config.extra['config']['publish_topic']['topic']\n        self.publish_options = PublishOptions(**self.config.extra['config']['pub_options'])\n\n        # setup callback\n        self.handlers = self.config.extra['handlers']\n\n        # optional subscribed topics from config.json\n        self.subscribed_topics = self.config.extra['config']['subscribed_topics']\n\n        # put name on session\n        self.name = self.config.extra['config']['name']\n\n        # setup db pool - optionally\n        if self.config.extra['config']['pub_options']['retain'] is True:\n            self.pool = await asyncpg.create_pool(\n                user=EVENT_DB_USER,\n                password=EVENT_DB_PASS,\n                host=EVENT_DB_HOST,\n                database=EVENT_DB_NAME\n            )\n\n        # Handle non crossbar drivers\n        try:\n            self.join(self.config.realm)\n        except AttributeError:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef setRpms(self, package, build, build_ts, rpms):\n\t\tself._builds[package] = {\"build\": build, \"build_ts\": build_ts, \"rpms\": rpms}", "response": "Add or update build to rpm\n\t"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef clone(self):\n\t\tsnapshot = DistributionSnapshot(self.distribution(), self.go_version)\n\t\tfor package in self.builds:\n\t\t\tsnapshot.setRpms(package, self.builds[package][\"build\"], self.builds[package][\"build_ts\"], self.builds[package][\"rpms\"])\n\n\t\treturn snapshot", "response": "Clone this distribution snapshot"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncompares two snapshots: - return a list of new packages in this snapshot - return a list of new builds in this snapshot :param snapshot: distribution snapshot :type snapshot: DistributionSnapshot", "response": "def compare(self, snapshot):\n\t\t\"\"\"Compare two snapshots:\n\t\t- return a list of new packages in this snapshot\n\t\t- return a list of new builds in this snapshot\n\n\t\t:param snapshot: distribution snapshot\n\t\t:type  snapshot: DistributionSnapshot\n\t\t\"\"\"\n\t\tbuilds = snapshot.builds()\n\n\t\tdiff_snapshot = DistributionSnapshot(self.distribution(), self.go_version)\n\n\t\tfor package in list(set(self._builds.keys()) - set(builds.keys())):\n\t\t\tdiff_snapshot.setRpms(package, self._builds[package][\"build\"], self._builds[package][\"build_ts\"], self._builds[package][\"rpms\"])\n\n\t\tfor package in list(set(self._builds.keys()) & set(builds.keys())):\n\t\t\tif self._builds[package][\"build\"] != builds[package][\"build\"]:\n\t\t\t\tdiff_snapshot.setRpms(package, self._builds[package][\"build\"], self._builds[package][\"build_ts\"], self._builds[package][\"rpms\"])\n\n\t\t# Assuming no package get ever removed (even if retired)\n\t\treturn diff_snapshot"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngoing back to the master branch deletes the current branch locally and remotely.", "response": "def getback(config, force=False):\n    \"\"\"Goes back to the master branch, deletes the current branch locally\n    and remotely.\"\"\"\n    repo = config.repo\n\n    active_branch = repo.active_branch\n    if active_branch.name == \"master\":\n        error_out(\"You're already on the master branch.\")\n\n    if repo.is_dirty():\n        error_out(\n            'Repo is \"dirty\". ({})'.format(\n                \", \".join([repr(x.b_path) for x in repo.index.diff(None)])\n            )\n        )\n\n    branch_name = active_branch.name\n\n    state = read(config.configfile)\n    origin_name = state.get(\"ORIGIN_NAME\", \"origin\")\n    upstream_remote = None\n    fork_remote = None\n    for remote in repo.remotes:\n        if remote.name == origin_name:\n            # remote.pull()\n            upstream_remote = remote\n            break\n    if not upstream_remote:\n        error_out(\"No remote called {!r} found\".format(origin_name))\n\n    # Check out master\n    repo.heads.master.checkout()\n    upstream_remote.pull(repo.heads.master)\n\n    # Is this one of the merged branches?!\n    # XXX I don't know how to do this \"natively\" with GitPython.\n    merged_branches = [\n        x.strip()\n        for x in repo.git.branch(\"--merged\").splitlines()\n        if x.strip() and not x.strip().startswith(\"*\")\n    ]\n    was_merged = branch_name in merged_branches\n    certain = was_merged or force\n    if not certain:\n        # Need to ask the user.\n        # XXX This is where we could get smart and compare this branch\n        # with the master.\n        certain = (\n            input(\"Are you certain {} is actually merged? [Y/n] \".format(branch_name))\n            .lower()\n            .strip()\n            != \"n\"\n        )\n    if not certain:\n        return 1\n\n    if was_merged:\n        repo.git.branch(\"-d\", branch_name)\n    else:\n        repo.git.branch(\"-D\", branch_name)\n\n    fork_remote = None\n    for remote in repo.remotes:\n        if remote.name == state.get(\"FORK_NAME\"):\n            fork_remote = remote\n            break\n    if fork_remote:\n        fork_remote.push(\":\" + branch_name)\n        info_out(\"Remote branch on fork deleted too.\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a Bus object for a certain vehicle ID.", "response": "def get(_class, api, vid):\n        \"\"\"\n        Return a Bus object for a certain vehicle ID `vid` using API\n        instance `api`.\n        \"\"\"\n        busses = api.vehicles(vid=vid)['vehicle']   \n        return _class.fromapi(api, api.vehicles(vid=vid)['vehicle'])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fromapi(_class, api, apiresponse):\n        bus = apiresponse\n        return _class(\n            api = api,\n            vid = bus['vid'],\n            timeupdated = datetime.strptime(bus['tmstmp'], api.STRPTIME),\n            lat = float(bus['lat']),\n            lng = float(bus['lon']),\n            heading = bus['hdg'],\n            pid = bus['pid'],\n            intotrip = bus['pdist'],\n            route = bus['rt'],\n            destination = bus['des'],\n            speed = bus['spd'],\n            delay = bus.get('dly') or False\n        )", "response": "Return a Bus object from an API response dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update(self):\n        vehicle = self.api.vehicles(vid=self.vid)['vehicle']\n        newbus = self.fromapi(self.api, vehicle)\n        self.__dict__ = newbus.__dict__\n        del newbus", "response": "Update this bus by creating a new one and transplanting dictionaries."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef predictions(self):\n        for prediction in self.api.predictions(vid=self.vid)['prd']:\n            pobj = Prediction.fromapi(self.api, prediction)\n            pobj._busobj = self\n            yield pobj", "response": "Generator that yields prediction objects from an API response."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the next stop for this bus.", "response": "def next_stop(self):\n        \"\"\"Return the next stop for this bus.\"\"\"\n        p = self.api.predictions(vid=self.vid)['prd']\n        pobj = Prediction.fromapi(self.api, p[0])\n        pobj._busobj = self\n        return pobj"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get(_class, api, rt):\n             \n        if not _class.all_routes:\n            _class.all_routes = _class.update_list(api, api.routes()['route'])\n\n        return _class.all_routes[str(rt)]", "response": "Get a Route object for a given route rt using API instance api."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find_stop(self, query, direction=\"\"):\n        _directions = [\"inbound\", \"outbound\", \"\"]\n        direction = direction.lower()\n        if direction == \"inbound\":\n            stops = self.inbound_stops\n        elif direction == \"outbound\":\n            stops = self.outbound_stops\n        else:\n            stops = self.inbound_stops + self.outbound_stops\n        \n        found = []\n        for stop in stops:\n            q = str(query).lower()\n            if q in stop.name.lower() or q in str(stop.id).lower():\n                found.append(stop)\n        return found", "response": "Search the list of stops optionally in a direction"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef predictions(self, route=''):\n        apiresponse = self.api.predictions(stpid=self.id, rt=route)['prd']\n        if type(apiresponse) is list:        \n            for prediction in apiresponse:\n                try:\n                    pobj = Prediction.fromapi(self.api, prediction)\n                    pobj._stopobj = self\n                    yield pobj\n                except:\n                    continue    \n        else:\n            pobj = Prediction.fromapi(self.api, apiresponse)\n            pobj._stopobj = self\n            yield pobj", "response": "Yields predicted bus ETAs for this stop."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fromapi(_class, apiresponse):\n        for resp in apiresponse['sb']:\n            # Extract details from dict\n            _id = \"n/a\" or resp.get(\"nm\")\n            subject = resp.get(\"sbj\")\n            text = resp.get('dtl') + \"\\n\" + resp.get('brf')\n            priority = \"n/a\" or resp.get('prty')\n            for_stops, for_routes = [], []\n            svc = resp.get('srvc')\n        \n            # Create list of affected routes/stops, if there are any\n            if svc:\n                has_stop = 'stpid' in svc or 'stpnm' in svc\n                has_rt = 'rt' in svc or 'rtdir' in svc\n            \n                if has_stop: \n                    aff = _class.affected_service('stop', svc.get('stpid'), svc.get('stpnm'))\n                    for_stops.append(aff)\n                if has_rt:\n                    aff = _class.affected_service('route', svc.get('rt'), svc.get('rtdir'))\n                    for_routes.append(aff)\n\n            yield _class(_id, subject, text, priority, for_stops, for_routes)", "response": "Create a bulletin object from an API response."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _normalise_path(path: Union[str, pathlib.Path]) -> pathlib.Path:\n    if isinstance(path, str):\n        return pathlib.Path(path)\n    return path", "response": "Converts a path string or Path object to a pathlib. Path object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef root(path: Union[str, pathlib.Path]) -> _Root:\n    return _Root.from_path(_normalise_path(path))", "response": "Retrieve a root directory object from a path."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nretrieve an appropriate entity object from a path.", "response": "def entity(path: Union[str, pathlib.Path]) -> _Entity:\n    \"\"\"\n    Retrieve an appropriate entity object from a path.\n\n    :param path: The path of the entity to represent, either a string or Path\n                 object.\n    :return: An entity representing the input path.\n    \"\"\"\n    return _Entity.from_path(_normalise_path(path))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompare two paths. :param left: The left side or \"before\" entity. :param right: The right side or \"after\" entity. :return: A comparison details what has changed from the left side to the right side.", "response": "def compare(left: Union[str, pathlib.Path, _Entity],\n            right: Union[str, pathlib.Path, _Entity]) -> Comparison:\n    \"\"\"\n    Compare two paths.\n\n    :param left: The left side or \"before\" entity.\n    :param right: The right side or \"after\" entity.\n    :return: A comparison details what has changed from the left side to the\n             right side.\n    \"\"\"\n\n    def normalise(param: Union[str, pathlib.Path, _Entity]) -> _Entity:\n        \"\"\"\n        Turns any one of a number of types of input into an entity.\n\n        :param param: The input - either a path string, a path object, or a\n                      full blown entity.\n        :return: The input param as an entity.\n        \"\"\"\n        if isinstance(param, str):\n            param = pathlib.Path(param)\n        if isinstance(param, pathlib.Path):\n            param = _Entity.from_path(param)\n        return param\n\n    return Comparison.compare(normalise(left), normalise(right))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef r_get_numbers(matchgroup, num):\n    res = []\n    for i in range(num):\n        res.append(float(matchgroup.next().group()))\n    return np.array(res)", "response": "A helper function which can be used similarly to fscanf ( fid num ) to extract num arguments from the regex iterator"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads the instrumental geometry information from the XPARM. XDS or GXPARM. XDS files at the proposed location.", "response": "def read_XPARM(path_to_XPARM='.'):\n    \"\"\"Loads the instrumental geometry information from the XPARM.XDS or GXPARM.XDS files at the proposed location\"\"\"\n\n    if not os.path.exists(path_to_XPARM):\n        raise Exception(\"path \" + path_to_XPARM + \"does not exist\")\n\n    if os.path.isdir(path_to_XPARM):\n        candidate = os.path.join(path_to_XPARM, 'GXPARM.XDS')\n        if os.path.isfile(candidate):\n            path_to_XPARM = candidate\n        else:\n            candidate = os.path.join(path_to_XPARM, 'XPARM.XDS')\n            if os.path.isfile(candidate):\n                path_to_XPARM = candidate\n            else:\n                raise Exception(\"files GXPARM.XDS and XPARM.XDS are not found in the folder \" + path_to_XPARM)\n\n    with open(path_to_XPARM) as f:\n        f.readline()  # skip header\n        text = f.read()\n\n    # parse the rest to numbers\n    f = re.compile('-?\\d+\\.?\\d*').finditer(text)\n\n    try:\n        result = dict(starting_frame=r_get_numbers(f, 1),\n                      starting_angle=r_get_numbers(f, 1),\n                      oscillation_angle=r_get_numbers(f, 1),\n                      rotation_axis=r_get_numbers(f, 3),\n\n                      wavelength=r_get_numbers(f, 1),\n                      wavevector=r_get_numbers(f, 3),\n\n                      space_group_nr=r_get_numbers(f, 1),\n                      cell=r_get_numbers(f, 6),\n                      unit_cell_vectors=np.reshape(r_get_numbers(f, 9), (3, 3)),\n\n                      number_of_detector_segments=r_get_numbers(f, 1),\n                      NX=r_get_numbers(f, 1),\n                      NY=r_get_numbers(f, 1),\n                      pixelsize_x=r_get_numbers(f, 1),\n                      pixelsize_y=r_get_numbers(f, 1),\n\n                      x_center=r_get_numbers(f, 1),\n                      y_center=r_get_numbers(f, 1),\n                      distance_to_detector=r_get_numbers(f, 1),\n\n                      detector_x=r_get_numbers(f, 3),\n                      detector_y=r_get_numbers(f, 3),\n                      detector_normal=r_get_numbers(f, 3),\n                      detector_segment_crossection=r_get_numbers(f, 5),\n                      detector_segment_geometry=r_get_numbers(f, 9))\n\n    except StopIteration:\n        raise Exception('Wrong format of the XPARM.XDS file')\n\n    # check there is nothing left\n    try:\n        f.next()\n    except StopIteration:\n        pass\n    else:\n        raise Exception('Wrong format of the XPARM.XDS file')\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates an hdf5 file with large cache size", "response": "def create_h5py_with_large_cache(filename, cache_size_mb):\n    \"\"\"\nAllows to open the hdf5 file with specified cache size\n    \"\"\"\n    # h5py does not allow to control the cache size from the high level\n    # we employ the workaround\n    # sources:\n    #http://stackoverflow.com/questions/14653259/how-to-set-cache-settings-while-using-h5py-high-level-interface\n    #https://groups.google.com/forum/#!msg/h5py/RVx1ZB6LpE4/KH57vq5yw2AJ\n    propfaid = h5py.h5p.create(h5py.h5p.FILE_ACCESS)\n    settings = list(propfaid.get_cache())\n    settings[2] = 1024 * 1024 * cache_size_mb\n    propfaid.set_cache(*settings)\n    fid = h5py.h5f.create(filename, flags=h5py.h5f.ACC_EXCL, fapl=propfaid)\n    fin = h5py.File(fid)\n    return fin"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef find_features(seqs, locus_tag=\"all\", utr_len=200):\n    found_features = []\n\n    for seq_i in seqs:\n        for feature in seq_i.features:\n            if feature.type == \"CDS\" and (locus_tag == \"all\" or \\\n                    ('locus_tag' in feature.qualifiers and \\\n                    feature.qualifiers['locus_tag'][0] == locus_tag)):\n                start = max(0, feature.location.nofuzzy_start - utr_len)\n                stop  = max(0, feature.location.nofuzzy_end + utr_len)\n                feature_seq = seq_i.seq[start:stop]\n                f_match = FeatureMatch(feature, feature_seq, feature.strand,\n                                       utr_len)\n                found_features.append(f_match)\n\n    return found_features", "response": "Find features in sequences by locus tag"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting nest - level of this port.", "response": "def getLevel(self):\n        \"\"\"\n        Get nest-level of this port\n        \"\"\"\n        lvl = 0\n        p = self\n        while True:\n            p = p.parent\n            if not isinstance(p, LPort):\n                break\n            lvl += 1\n        return lvl"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef normalize_LCSH(subject):\n    # Strip then divide on -- which is a delimiter for LCSH;\n    # rejoin after stripping parts.\n    subject_parts = subject.strip().split('--')\n    joined_subject = ' -- '.join([part.strip() for part in subject_parts])\n\n    # Check if there is punctuation at the end of the string,\n    # and if not, add a trailing period.\n    if re.search(r'[^a-zA-Z0-9]$', joined_subject) is None:\n        joined_subject = joined_subject + '.'\n\n    return joined_subject", "response": "Normalize a LCSH subject heading prior to indexing."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef normalize_UNTL(subject):\n    subject = subject.strip()\n    subject = re.sub(r'[\\s]+', ' ', subject)\n    return subject", "response": "Normalize a UNTL subject heading for consistency."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nnormalizing a UNTL subject heading to be used in SOLR.", "response": "def UNTL_to_encodedUNTL(subject):\n    \"\"\"Normalize a UNTL subject heading to be used in SOLR.\"\"\"\n    subject = normalize_UNTL(subject)\n    subject = subject.replace(' ', '_')\n    subject = subject.replace('_-_', '/')\n    return subject"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nnormalize UNTL elements by their qualifier.", "response": "def untldict_normalizer(untl_dict, normalizations):\n    \"\"\"Normalize UNTL elements by their qualifier.\n\n    Takes a UNTL descriptive metadata dictionary and a dictionary of\n    the elements and the qualifiers for normalization:\n    {'element1': ['qualifier1', 'qualifier2'],\n     'element2': ['qualifier3']}\n    and normalizes the elements with that qualifier.\n    \"\"\"\n    # Loop through the element types in the UNTL metadata.\n    for element_type, element_list in untl_dict.items():\n        # A normalization is required for that element type.\n        if element_type in normalizations:\n            # Get the required normalizations for specific qualifiers list.\n            norm_qualifier_list = normalizations.get(element_type)\n            # Loop through the element lists within that element type.\n            for element in element_list:\n                # Determine if the qualifier requires normalization.\n                qualifier = element.get('qualifier', None)\n                if qualifier in norm_qualifier_list:\n                    content = element.get('content', None)\n                    # Determine if there is normalizing for the element.\n                    if element_type in ELEMENT_NORMALIZERS:\n                        elem_norms = ELEMENT_NORMALIZERS.get(element_type,\n                                                             None)\n                        # If the qualified element requires a\n                        # normalization and has content, replace the\n                        # content with the normalized.\n                        if qualifier in elem_norms:\n                            if content and content != '':\n                                element['content'] = \\\n                                    elem_norms[qualifier](content)\n    return untl_dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef start(config, bugnumber=\"\"):\n    repo = config.repo\n\n    if bugnumber:\n        summary, bugnumber, url = get_summary(config, bugnumber)\n    else:\n        url = None\n        summary = None\n\n    if summary:\n        summary = input('Summary [\"{}\"]: '.format(summary)).strip() or summary\n    else:\n        summary = input(\"Summary: \").strip()\n\n    branch_name = \"\"\n    if bugnumber:\n        if is_github({\"bugnumber\": bugnumber, \"url\": url}):\n            branch_name = \"{}-\".format(bugnumber)\n        else:\n            branch_name = \"{}-\".format(bugnumber)\n\n    def clean_branch_name(string):\n        string = re.sub(r\"\\s+\", \" \", string)\n        string = string.replace(\" \", \"-\")\n        string = string.replace(\"->\", \"-\").replace(\"=>\", \"-\")\n        for each in \"@%^&:'\\\"/(),[]{}!.?`$<>#*;=\":\n            string = string.replace(each, \"\")\n        string = re.sub(\"-+\", \"-\", string)\n        string = string.strip(\"-\")\n        return string.lower().strip()\n\n    branch_name += clean_branch_name(summary)\n\n    if not branch_name:\n        error_out(\"Must provide a branch name\")\n\n    # Check that the branch doesn't already exist\n    found = list(find(repo, branch_name, exact=True))\n    if found:\n        error_out(\"There is already a branch called {!r}\".format(found[0].name))\n\n    new_branch = repo.create_head(branch_name)\n    new_branch.checkout()\n    if config.verbose:\n        click.echo(\"Checkout out new branch: {}\".format(branch_name))\n\n    save(config.configfile, summary, branch_name, bugnumber=bugnumber, url=url)", "response": "Create a new topic branch."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a summary for this bug number or None", "response": "def get_summary(config, bugnumber):\n    \"\"\"return a summary for this bug/issue. If it can't be found,\n    return None.\"\"\"\n\n    bugzilla_url_regex = re.compile(\n        re.escape(\"https://bugzilla.mozilla.org/show_bug.cgi?id=\") + r\"(\\d+)$\"\n    )\n\n    # The user could have pasted in a bugzilla ID or a bugzilla URL\n    if bugzilla_url_regex.search(bugnumber.split(\"#\")[0]):\n        # that's easy then!\n        bugzilla_id, = bugzilla_url_regex.search(bugnumber.split(\"#\")[0]).groups()\n        bugzilla_id = int(bugzilla_id)\n        summary, url = bugzilla.get_summary(config, bugzilla_id)\n        return summary, bugzilla_id, url\n\n    # The user could have pasted in a GitHub issue URL\n    github_url_regex = re.compile(r\"https://github.com/([^/]+)/([^/]+)/issues/(\\d+)\")\n    if github_url_regex.search(bugnumber.split(\"#\")[0]):\n        # that's also easy\n        org, repo, id_, = github_url_regex.search(bugnumber.split(\"#\")[0]).groups()\n        id_ = int(id_)\n        title, url = github.get_title(config, org, repo, id_)\n        return title, id_, url\n\n    # If it's a number it can be either a github issue or a bugzilla bug\n    if bugnumber.isdigit():\n        # try both and see if one of them turns up something interesting\n\n        repo = config.repo\n        state = read(config.configfile)\n        fork_name = state.get(\"FORK_NAME\", getpass.getuser())\n        if config.verbose:\n            info_out(\"Using fork name: {}\".format(fork_name))\n        candidates = []\n        # Looping over the remotes, let's figure out which one\n        # is the one that has issues. Let's try every one that isn't\n        # your fork remote.\n        for origin in repo.remotes:\n            if origin.name == fork_name:\n                continue\n            url = origin.url\n            org, repo = parse_remote_url(origin.url)\n            github_title, github_url = github.get_title(\n                config, org, repo, int(bugnumber)\n            )\n            if github_title:\n                candidates.append((github_title, int(bugnumber), github_url))\n\n        bugzilla_summary, bugzilla_url = bugzilla.get_summary(config, bugnumber)\n        if bugzilla_summary:\n            candidates.append((bugzilla_summary, int(bugnumber), bugzilla_url))\n\n        if len(candidates) > 1:\n            info_out(\n                \"Input is ambiguous. Multiple possibilities found. \"\n                \"Please re-run with the full URL:\"\n            )\n            for title, _, url in candidates:\n                info_out(\"\\t{}\".format(url))\n                info_out(\"\\t{}\\n\".format(title))\n            error_out(\"Awaiting your choice\")\n        elif len(candidates) == 1:\n            return candidates[0]\n        else:\n            error_out(\"ID could not be found on GitHub or Bugzilla\")\n        raise Exception(bugnumber)\n\n    return bugnumber, None, None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a tuple of org repo from the remote git URL", "response": "def parse_remote_url(url):\n    \"\"\"return a tuple of (org, repo) from the remote git URL\"\"\"\n    # The URL will either be git@github.com:org/repo.git or\n    # https://github.com/org/repo.git and in both cases\n    # it's not guarantee that the domain is github.com.\n    # FIXME: Make it work non-github.com domains\n    if url.startswith(\"git@\"):\n        path = url.split(\":\", 1)[1]\n    else:\n        parsed = urllib.parse.urlparse(url)\n        path = parsed.path[1:]\n\n    assert path.endswith(\".git\"), path\n    path = path[:-4]\n    return path.split(\"/\")"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconcatenating conditioning vector on feature map axis.", "response": "def conv_cond_concat(x, y):\n    \"\"\"Concatenate conditioning vector on feature map axis.\"\"\"\n    x_shapes = x.get_shape()\n    y_shapes = y.get_shape()\n    return tf.concat(3, [x, y*tf.ones([x_shapes[0], x_shapes[1], x_shapes[2], y_shapes[3]])])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef lrelu_sq(x):\n    dim = len(x.get_shape()) - 1\n    return tf.concat(dim, [lrelu(x), tf.minimum(tf.abs(x), tf.square(x))])", "response": "Concatenates lrelu and square\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalculating the average gradient for each shared variable across all towers.", "response": "def avg_grads(tower_grads):\n  \"\"\"Calculate the average gradient for each shared variable across all towers.\n\n  Note that this function provides a synchronization point across all towers.\n\n  Args:\n    tower_grads: List of lists of (gradient, variable) tuples. The outer list\n      is over individual gradients. The inner list is over the gradient\n      calculation for each tower.\n  Returns:\n     List of pairs of (gradient, variable) where the gradient has been averaged\n     across all towers.\n  \"\"\"\n  average_grads = []\n  for grad_and_vars in zip(*tower_grads):\n    # Note that each grad_and_vars looks like the following:\n    #   ((grad0_gpu0, var0_gpu0), ... , (grad0_gpuN, var0_gpuN))\n    grads = []\n    for g, _ in grad_and_vars:\n      # Add 0 dimension to the gradients to represent the tower.\n      expanded_g = tf.expand_dims(g, 0)\n\n      # Append on a 'tower' dimension which we will average over below.\n      grads.append(expanded_g)\n\n    # Average over the 'tower' dimension.\n    grad = tf.concat(0, grads)\n    grad = tf.reduce_mean(grad, 0)\n\n    # Keep in mind that the Variables are redundant because they are shared\n    # across towers. So .. we will just return the first tower's pointer to\n    # the Variable.\n    v = grad_and_vars[0][1]\n    grad_and_var = (grad, v)\n    average_grads.append(grad_and_var)\n  return average_grads"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef stream_template(template_name, **context):\n    ''' allow streaming of jinja templates for reduced page load start latency (e.g. for large lists) '''\n    app.update_template_context(context)\n    t = app.jinja_env.get_template(template_name)\n    rv = t.stream(context)\n    rv.enable_buffering(5)\n    return rv", "response": "allow streaming of jinja templates for reduced page load start latency"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert escaped unicode web entities to unicode", "response": "def unescape_utf8(msg):\n    ''' convert escaped unicode web entities to unicode '''\n    def sub(m):\n        text = m.group(0)\n        if text[:3] == \"&#x\": return unichr(int(text[3:-1], 16))\n        else:                 return unichr(int(text[2:-1]))\n    return re.sub(\"&#?\\w+;\", sub, urllib.unquote(msg))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfasts iterator of playable file objects found on disk", "response": "def iterplayables():\n    ''' fast iterator of playable file object/dicts found on disk '''\n    ls = DirScanner(stripdot=True)\n    ## filter out just mp3 files (and dirs to support recursion)\n    filt = lambda x: ( os.path.isdir(x) or x[-4:].lower() in ALLOWED_TYPES )\n    ## take the last two segments of the path as the label\n    func = lambda x: '/'.join(x.split('/')[-2:])\n    ## iterate over all the files (excluding dirs), filtering for .mp3 and .m4a\n    for x,y in ls.iteritems(want_files=True, want_dirs=False, func=func, filt=filt):\n        yield {      'name': x.decode('utf-8'),\n                'file_name': escape_utf8(y)     }"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nextract split nodes from the root node", "response": "def extractSplits(root: LNode):\n    \"\"\"\n    convert group of indexed assignments witch are splitting signal to Split node\n\n    a = sig[0]\n    b = sig[1]\n    to\n    a, b = sig\n\n    :param toL: dictionary {hdl object: layout object}\n    \"\"\"\n    toL = root._node2lnode\n    signals = root.originObj._ctx.signals\n\n    # search from \"sig\" side (look at doc string)\n    for s in signals:\n        if len(s.drivers) == 1 and len(s.endpoints) > 1:\n            expectedItems = None\n            sliceParts = []\n            for ep in s.endpoints:\n                if isinstance(ep, Assignment) and not ep.indexes and ep.src.hidden:\n                    op = ep.src.origin\n                else:\n                    op = ep\n                if isinstance(op, Operator)\\\n                        and op.operator == AllOps.INDEX\\\n                        and op.operands[0] is s:\n                    index = op.operands[1]\n                    if isConst(index):\n                        i = index.staticEval().toPy()\n                        if isinstance(i, int):\n                            i = slice(i + 1, i)\n\n                        t = s._dtype\n                        if isinstance(t, Bits):\n                            w = t.bit_length()\n                        elif isinstance(t, HArray):\n                            w = int(t.size)\n                        else:\n                            # slice on unexpected data type\n                            raise NotImplementedError(t)\n                        sliceW = i.start - i.stop\n                        items = w // sliceW\n                        if expectedItems is None:\n                            expectedItems = items\n                        else:\n                            if expectedItems != items:\n                                continue\n\n                        if items * sliceW == w:\n                            sliceI = i.stop // sliceW\n                            if ep not in toL:\n                                continue\n                            sliceParts.append((sliceI, ep))\n                            continue\n\n            compatible = expectedItems is not None and expectedItems == len(\n                sliceParts)\n            if compatible:\n                # reduce to slice\n                sliceParts.sort(reverse=True)\n                n = toL[sliceParts[0][1]]\n                p = n.west[0]\n                if not p.incomingEdges:\n                    return\n                srcPorts = p.incomingEdges[0].srcs\n                assert len(srcPorts) == 1\n                srcPort = srcPorts[0]\n                dstPortsOnInputNet = list(p.incomingEdges[0].dsts)\n                sliceNode = root.addNode(\n                    \"SLICE\", originObj=InterfaceSplitInfo(sliceParts))\n                inputPort = sliceNode.addPort(\n                    \"\", PortType.INPUT, PortSide.WEST)\n\n                # create new sliceNode\n                for i, assig in sliceParts:\n                    name = \"[%d]\" % i\n                    outPort = sliceNode.addPort(\n                        name, PortType.OUTPUT, PortSide.EAST)\n                    oldAssigNode = toL[assig]\n                    dstPorts = []\n\n                    dstPortsOnInputNet.remove(oldAssigNode.west[0])\n                    for e in list(oldAssigNode.west[0].incomingEdges):\n                        e.remove()\n\n                    for e in list(oldAssigNode.east[0].outgoingEdges):\n                        for _dst in e.dsts:\n                            dstPorts.append((_dst, e.originObj))\n                        e.remove()\n\n                    root.children.remove(oldAssigNode)\n                    # remove index value node (we know that it is constant,\n                    # from original select)\n                    _e = oldAssigNode.west[1].incomingEdges[0]\n                    _e.removeTarget(oldAssigNode.west[1])\n                    assert len(_e.srcs) == 1\n                    indexValNodeP = _e.srcs[0]\n                    if not _e.dsts:\n                        _e.remove()\n\n                    if not indexValNodeP.outgoingEdges:\n                        root.children.remove(indexValNodeP.parentNode)\n\n                    root.addHyperEdge([outPort],\n                                      [dst[0] for dst in dstPorts],\n                                      originObj=dstPorts[0][1])\n\n                dstPortsOnInputNet.append(inputPort)\n                root.addHyperEdge([srcPort, ], dstPortsOnInputNet,\n                                  name=e.name, originObj=e.originObj)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nencodes a list of fields and files into a multipart form data.", "response": "def encode_multipart_formdata(fields):\n    \"\"\"\n    fields is a sequence of (name, value) elements for regular form fields.\n    files is a sequence of (name, filename, value) elements for data to be\n    uploaded as files.\n    Return (content_type, body) ready for httplib.HTTP instance\n    \"\"\"\n    BOUNDARY = '----------ThIs_Is_tHe_bouNdaRY_$'\n    CRLF = '\\r\\n'.encode('utf-8')\n    L = []\n    for (key, value) in fields:\n        if not isinstance(value, types.InputFile):\n            _append_bytes(L, '--' + BOUNDARY)\n            _append_bytes(L, 'Content-Disposition: form-data; name=\"%s\"' % key)\n            _append_bytes(L, '')\n            _append_bytes(L, value)\n        else:\n            _append_bytes(L, '--' + BOUNDARY)\n            _append_bytes(L, 'Content-Disposition: form-data; name=\"%s\"; filename=\"%s\"' % (key, value.name))\n            _append_bytes(L, 'Content-Type: %s' % value.content_type)\n            _append_bytes(L, '')\n            _append_bytes(L, value.content)\n    _append_bytes(L, '--' + BOUNDARY + '--')\n    _append_bytes(L, '')\n    body = CRLF.join(L)\n    content_type = 'multipart/form-data; boundary=%s' % BOUNDARY\n    return content_type, body"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncomputing the residual map between a masked observed data and a model data.", "response": "def residual_map_from_data_mask_and_model_data(data, mask, model_data):\n    \"\"\"Compute the residual map between a masked observed data and model data, where:\n\n    Residuals = (Data - Model_Data).\n\n    Parameters\n    -----------\n    data : np.ndarray\n        The observed data that is fitted.\n    mask : np.ndarray\n        The mask applied to the data, where *False* entries are included in the calculation.\n    model_data : np.ndarray\n        The model data used to fit the observed data.\n    \"\"\"\n    return np.subtract(data, model_data, out=np.zeros_like(data), where=np.asarray(mask) == 0)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef chi_squared_map_from_residual_map_noise_map_and_mask(residual_map, noise_map, mask):\n    return np.square(np.divide(residual_map, noise_map, out=np.zeros_like(residual_map),\n                               where=np.asarray(mask) == 0))", "response": "Computes the chi - squared map between a residual - map and a noise - map and a mask."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntesting if this address is allocated for private networks.", "response": "def is_private(self):\n        \"\"\"Test if this address is allocated for private networks.\n\n        Returns:\n            A boolean, True if the address is reserved per RFC 1918.\n\n        \"\"\"\n        private_10 = IPv4Network(u'10.0.0.0/8')\n        private_172 = IPv4Network(u'172.16.0.0/12')\n        private_192 = IPv4Network(u'192.168.0.0/16')\n        return (self in private_10 or\n                self in private_172 or\n                self in private_192)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntests if the address is otherwise IETF reserved.", "response": "def is_reserved(self):\n        \"\"\"Test if the address is otherwise IETF reserved.\n\n        Returns:\n            A boolean, True if the address is within one of the\n            reserved IPv6 Network ranges.\n\n        \"\"\"\n        reserved_nets = [IPv6Network(u'::/8'), IPv6Network(u'100::/8'),\n                         IPv6Network(u'200::/7'), IPv6Network(u'400::/6'),\n                         IPv6Network(u'800::/5'), IPv6Network(u'1000::/4'),\n                         IPv6Network(u'4000::/3'), IPv6Network(u'6000::/3'),\n                         IPv6Network(u'8000::/3'), IPv6Network(u'A000::/3'),\n                         IPv6Network(u'C000::/3'), IPv6Network(u'E000::/4'),\n                         IPv6Network(u'F000::/5'), IPv6Network(u'F800::/6'),\n                         IPv6Network(u'FE00::/9')]\n\n        return any(self in x for x in reserved_nets)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfunctions to ensure the given check value is in the given data type and return the default value if no value is given", "response": "def ensure(data_type, check_value, default_value=None):\n    \"\"\"\n    function to ensure the given check value is in the given data type, if yes,\n    return the check value directly, otherwise return the default value\n\n    :param data_type: different data type: can be int, str, list, tuple etc,\n      must be python supportable data type or new defined data type\n    :param check_value: different value: the value to check\n    :param default_value: None/ different value: provide the default value\n    :return: check value or default value\n    \"\"\"\n    if default_value is not None and not isinstance(default_value, data_type):\n        raise ValueError(\"default_value must be the value in the given data \"\n                         \"type.\")\n    elif isinstance(check_value, data_type):\n        return check_value\n    try:\n        new_value = data_type(check_value)\n    except:\n        return default_value\n    return new_value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nturning a normalized byte string into a long - int", "response": "def inflate_long(s, always_positive=False):\n    \"\"\"turns a normalized byte string into a long-int (adapted from Crypto.Util.number)\"\"\"\n    out = long(0)\n    negative = 0\n    if not always_positive and (len(s) > 0) and (byte_ord(s[0]) >= 0x80):\n        negative = 1\n    if len(s) % 4:\n        filler = zero_byte\n        if negative:\n            filler = max_byte\n        # never convert this to ``s +=`` because this is a string, not a number\n        # noinspection PyAugmentAssignment\n        s = filler * (4 - len(s) % 4) + s\n    for i in range(0, len(s), 4):\n        out = (out << 32) + struct.unpack('>I', s[i:i+4])[0]\n    if negative:\n        out -= (long(1) << (8 * len(s)))\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nturn a long - int into a normalized byte string", "response": "def deflate_long(n, add_sign_padding=True):\n    \"\"\"turns a long-int into a normalized byte string (adapted from Crypto.Util.number)\"\"\"\n    # after much testing, this algorithm was deemed to be the fastest\n    s = bytes()\n    n = long(n)\n    while (n != 0) and (n != -1):\n        s = struct.pack('>I', n & xffffffff) + s\n        n >>= 32\n    # strip off leading zeros, FFs\n    for i in enumerate(s):\n        if (n == 0) and (i[1] != deflate_zero):\n            break\n        if (n == -1) and (i[1] != deflate_ff):\n            break\n    else:\n        # degenerate case, n was either 0 or -1\n        i = (0,)\n        if n == 0:\n            s = zero_byte\n        else:\n            s = max_byte\n    s = s[i[0]:]\n    if add_sign_padding:\n        if (n == 0) and (byte_ord(s[0]) >= 0x80):\n            s = zero_byte + s\n        if (n == -1) and (byte_ord(s[0]) < 0x80):\n            s = max_byte + s\n    return s"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef log_to_file(filename, level=DEBUG):\n    l = logging.getLogger(\"paramiko\")\n    if len(l.handlers) > 0:\n        return\n    l.setLevel(level)\n    f = open(filename, 'w')\n    lh = logging.StreamHandler(f)\n    lh.setFormatter(logging.Formatter('%(levelname)-.3s [%(asctime)s.%(msecs)03d] thr=%(_threadid)-3d %(name)s: %(message)s',\n                                      '%Y%m%d-%H:%M:%S'))\n    l.addHandler(lh)", "response": "send paramiko logs to a logfile if they are not already going somewhere"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef mark_resolved(task_id):\n    from . import models\n    models.FailedTask.objects.filter(task_id=task_id, datetime_resolved=None).update(datetime_resolved=now())", "response": "Mark the specified task as resolved in the FailedTask table."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning all tables stored in this database", "response": "def tables(self):\n        \"\"\"\n        :return: all tables stored in this database\n        \"\"\"\n        cursor = self.connection.cursor()\n        cursor.execute(\"show tables in %s\" % self.db)\n        self._tables = [t.Table(r[0], con=self.connection, db=self.db) for r in cursor.fetchall()]\n        return self._tables"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef tcounts(self):\n        df = pd.DataFrame([[t.name(), t.size()] for t in self.tables()], columns=[\"name\", \"size\"])\n        df.index = df.name\n        return df", "response": "Returns a data frame containing the names and sizes for all tables in this database."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dcounts(self):\n        print(\"WARNING: Distinct value count for all tables can take a long time...\", file=sys.stderr)\n        sys.stderr.flush()\n\n        data = []\n        for t in self.tables():\n            for c in t.columns():\n                data.append([t.name(), c.name(), c.dcount(), t.size(), c.dcount() / float(t.size())])\n        df = pd.DataFrame(data, columns=[\"table\", \"column\", \"distinct\", \"size\", \"fraction\"])\n        return df", "response": "Returns a data frame with names distinct counts and fractions for all columns in the database."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nratio test to check if two floating point numbers are equal.", "response": "def is_equal(a, b, tol):\n    \"\"\"Ratio test to check if two floating point numbers are equal.\n\n    Parameters\n    ----------\n    a: float\n        The first floating point number.\n    b: float\n        The second floating point number.\n    tol: float\n        The tolerance used.\n\n    Returns\n    -------\n    bool\n        Whether or not the two numbers are deemed equal.\n    \"\"\"\n    if a == b or abs(a-b) <= tol * max(abs(a), abs(b)):\n        return True\n    else:\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalculating the hypergeometric p - value when p = f k ; N K n is already known.", "response": "def get_hgp(p, k, N, K, n):\n    \"\"\"Calculate the hypergeometric p-value when p = f(k; N,K,n) is already known.\n    \"\"\"\n    pval = p\n    while k < min(K, n):\n        p *= (float((n-k)*(K-k) / float((k+1)*(N-K-n+k+1))))\n        pval += p\n        k += 1\n    return pval"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_xlmhg_stat(v, X, L, tol=DEFAULT_TOL):\n    assert isinstance(v, np.ndarray) and v.ndim == 1 and \\\n           np.issubdtype(v.dtype, np.integer)\n    assert isinstance(X, int)\n    assert isinstance(L, int)\n    assert isinstance(tol, float)\n\n    N = v.size\n    if not N > 0:\n        raise ValueError('List is empty!')\n    if not (1 <= X <= N):\n        raise ValueError(\n            'Invalid value X=%d; should be >= 1 and <= %d.' % (X, N)\n        )\n    if not (1 <= L <= N):\n        raise ValueError(\n            'Invalid value L=%d; should be >= 1 and <= %d.' % (L, N)\n        )\n    if not (0.0 <= tol < 1.0):\n        raise ValueError('Invalid value tol=%.1e; should be in [0,1)' % (tol))\n    \n    K = int(np.sum(v != 0))\n    if K == 0:\n        return 1.0, 0\n \n    p = 1.0\n    stat = 1.1\n    n_star = 0\n    k = 0\n    for n in range(L):\n        if v[n] == 0:\n            # calculate f(k; N,K,n+1) from f(k; N,K,n)\n            p *= (float((n+1)*(N-K-n+k)) / float((N-n)*(n-k+1)))\n        else:\n            # we hit a 1\n            # calculate f(k+1; N,K,n+1) from f(k; N,K,n)\n            p *= (float((n+1)*(K-k)) / float((N-n)*(k+1)))\n            k += 1\n            # calculate hypergeometric p-value only if enough elements have\n            # been seen\n            if k >= X:\n                hgp = get_hgp(p, k, N, K, n+1)\n                if hgp < stat and not is_equal(hgp, stat, tol):\n                    stat = hgp\n                    n_star = n+1\n\n    stat = min(stat, 1.0)\n    return stat, n_star", "response": "Calculate the XL - mHG test statistic using recurrence relations."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalculates the XL - mHG p - value using Algorithm 2.", "response": "def get_xlmhg_pval2(N, K, X, L, stat, tol=DEFAULT_TOL):\n    \"\"\"Calculate the XL-mHG p-value using \"Algorithm 2\".\n\n    Parameters\n    ----------\n    N: int\n        The length of the list.\n    K: int\n        The number of 1's in the list.\n    X: int\n        The XL-mHG ``X`` parameter.\n    L: int\n        The XL-mHG ``L`` parameter.\n    stat: float\n        The XL-mHG test statistic.\n    tol: float, optional\n        The tolerance used for comparing floats. [1e-12]\n\n    Returns\n    -------\n    float\n        The XL-mHG p-value. NaN if floating point precision was insufficient\n        for calculating the p-value.\n    \"\"\"\n    # type checking\n    assert isinstance(N, int)\n    assert isinstance(X, int)\n    assert isinstance(L, int)\n    assert isinstance(stat, float)\n    assert isinstance(tol, float)\n\n    # raise exceptions for invalid parameters\n    if not (N >= 1):\n        raise ValueError('Invalid value N=%d; must be >= 1.' %(N))\n    if not (1 <= X <= N):\n        raise ValueError(\n            'Invalid value X=%d; must be >= 1 and <= %d.' %(X, N)\n        )\n    if not (1 <= L <= N):\n        raise ValueError(\n            'Invalid value L=%d; must be >= 1 and <= %d.' %(L, N)\n        )\n    if not (0 < stat <= 1.0):\n        raise ValueError(\n            'Invalid value s=%.1e; must be in (0,1].' %(stat)\n        )\n    if not (0.0 <= tol < 1.0):\n        raise ValueError('Invalid value tol=%.1e; must be in [0,1)' %(tol))\n\n    # special case: stat = 1.0 => pval = 1.0\n    if stat == 1.0:\n        return 1.0\n\n    W = N-K\n    table = np.empty((K+1, L+1), dtype=np.float64)\n    table[0,0] = 1.0 # initially, *all* paths have never entered R before\n    \n    pval = 0.0\n    p_start = 1.0\n    p = None\n    hgp = None\n    k = None\n    w = None\n\n    # fill dynamic programming table and calculate XL-mHG p-value\n    # note: we only need to go over the first L cutoffs, since lower cutoffs\n    #       cannot be in R (by definition)\n    for n in range(1, L+1):\n        \n        if K >= n:\n            k = n\n            p_start *= (float(K-n+1) / float(N-n+1))\n        else:\n            k = K\n            p_start *= (float(n) / float(n-K))\n\n        if p_start == 0.0:\n            # not enough floating point precision to calculate\n            # the hypergeometric p-value\n            return float('nan')\n\n        p = p_start\n        hgp = p\n        w = n - k\n        \n        if k == K and (hgp > stat and not is_equal(hgp, stat, tol)):\n            # We've exited R (or we were never in it).\n            # That means we're done here!\n            break\n            \n        # Check if we've reached R. If so, \"go down the diagonal\" until we exit R.\n        # Three conditions:\n        # 1. k >= X         // No configuration with k < X can be in R.\n        # 2. w < W          // No configuration with w = W can be in R.\n        # 3. pval <= s      // The basic criterion for being in R.\n        while k >= X and w < W and (hgp < stat or is_equal(hgp, stat, tol)):\n            # We're in R!\n            # Note:\n            #   For w = W, we always have hgp = 1.0. Since stat < 1.0,\n            #   we could just assume that w < W. But this assumption might fail\n            #   due to limited floating point accuracy.\n            \n            # First things first: set table[k, w] to 0 to indicate that this is\n            # R territory.\n            table[k, w] = 0\n            \n            # check if we've \"just entered\" R (this is only possible \"from below\")\n            if table[k-1, w] > 0:\n                # calculate the fraction of \"fresh\" paths (paths which have never entered R before)\n                # that enter here, and add that number to r\n                pval += (table[k-1, w] * (float(K-k+1)/float(N-n+1)))\n                \n            p *= (float(k*(N-K-n+k)) / float((n-k+1)*(K-k+1)))\n            hgp += p\n            w += 1\n            k -= 1\n            \n        # now we're no longer in R\n        while k >= 0 and w <= W:\n            if k == 0:\n                # paths only come in \"from the left\"\n                table[k, w] = table[k, w-1] * (float(W-w+1)/float(N-n+1))\n            elif w == 0:\n                # paths only come in \"from below\"\n                table[k, w] = table[k-1, w] * (float(K-k+1)/float(N-n+1))\n            else:\n                # paths come in \"from the left\" and \"from below\"\n                table[k, w] = table[k, w-1] * (float(W-w+1)/float(N-n+1)) + \\\n                        table[k-1, w] * (float(K-k+1)/float(N-n+1))\n            w += 1\n            k -= 1\n            \n    return pval"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getPortSideView(self, side) -> List[\"LPort\"]:\n        if side == PortSide.WEST:\n            return self.west\n        elif side == PortSide.EAST:\n            return self.east\n        elif side == PortSide.NORTH:\n            return self.north\n        elif side == PortSide.SOUTH:\n            return self.south\n        else:\n            raise ValueError(side)", "response": "Returns a list of all ports of given side."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef iterEdges(self, filterSelfLoops=False):\n        for p in self.iterPorts():\n            yield from p.iterEdges(filterSelfLoops=filterSelfLoops)", "response": "Iterate edges connected from outside of this unit."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef link(source_path):\n    if not os.path.isfile(source_path):\n        raise SourceNotFound(source_path)\n    with open(source_path, 'r') as f:\n        content = f.read()\n    block_map = BlockMap()  # The map will be populated with the following function call.\n    all_block = convert_lines_to_block(\n            content.splitlines(), block_map, LinkStack(source_path), source_path)\n    return all_block, block_map.get_variables()", "response": "Links the content found at source_path and represents a Block that represents the content."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_block_dict(top_level_block):\n    block_stack = [top_level_block]\n    block_dict = {}\n    while block_stack:\n        block = block_stack.pop()\n        block_dict[block.name] = str(block)\n        for segment in block.segments:\n            if isinstance(segment, Block):\n                block_stack.append(segment)\n    return block_dict", "response": "Returns a dictionary of block names to block contents for all child blocks as\n    well as the original block itself."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert the specified list of lines into a single block object.", "response": "def convert_lines_to_block(lines, block_map, link_stack, source_path, block_name=ALL_BLOCK_NAME):\n    \"\"\"Converts the specified block content lines (list of strings) into a Block object.\n\n    Nested blocks are recursively converted into strings and cached in the block_map. Include tags\n    are processed as well. The resulting block string is also added to the block_map, along with any\n    nested blocks.\n\n    PARAMETERS:\n    lines       -- str; content lines to be converted into a Block.\n    block_map   -- BlockMap\n    link_stack  -- LinkStack\n    source_path -- str; the path of the file from which this content came, relative to the current\n                   working directory.\n    block_name  -- str; the name of the block that contains this content. By default, the name is\n                  'all'\n\n    RETURNS:\n    Block; the result of converting the block content.\n    \"\"\"\n    found_closing_block = False\n    segments = []\n    while lines:\n        line = lines.pop(0)\n\n        # Check if the line is a closing tag. This should only occur if we encounter the closing\n        # block tag that matches the block_name parameter.\n        close_tag_match = BLOCK_CLOSE_REGEX.match(line)\n        if close_tag_match:\n            if close_tag_match.group(1) != block_name:\n                raise InvalidBlockName('Expected closing block ' + block_name + \\\n                    'but found block named \"' + block_tag_match.group(1) + '\" in ' + source_path)\n            # If the block name is valid, we are done processing this block.\n            found_closing_block = True\n            break\n\n        # Otherwise, check if the line is a nested block.\n        open_tag_match = BLOCK_OPEN_REGEX.match(line)\n        if open_tag_match:\n            # Make sure the block name is not the reserved ALL_BLOCK_NAME.\n            inner_block_name = open_tag_match.group(1)\n            if inner_block_name == ALL_BLOCK_NAME:\n                raise InvalidBlockName(\n                    '\"{0}\" is a reserved block name, but found block named \"{0}\" in {1}'.format(\n                        ALL_BLOCK_NAME, source_path))\n\n            # Recursively convert nested block contents to a Block.\n            inner_block = convert_lines_to_block(\n                lines,\n                block_map,\n                link_stack,\n                source_path,\n                inner_block_name)\n            segments.append(inner_block)\n            continue\n\n        # Otherwise, check if the line is a variable. The line should be omitted.\n        variable_match = VARIABLE_REGEX.match(line)\n        if variable_match:\n            process_variable(variable_match, block_map)\n            continue\n\n        # Otherwise, check if the line is an include tag.\n        include_match = INCLUDE_REGEX.match(line)\n        if include_match:\n            included_content = process_links(include_match, block_map, link_stack, source_path)\n            # Omit empty content.\n            if included_content != '':\n                append_text_to_segments(segments, included_content)\n        else:\n            append_text_to_segments(segments, line)\n\n    if block_name != ALL_BLOCK_NAME and not found_closing_block:\n        raise InvalidBlockName(\n                'Expected closing block called \"{0}\" in {1}'.format(block_name, source_path))\n\n    block = Block(source_path, block_name, segments)\n    block_map.add_block(block)\n    return block"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprocessing a string of content for include tags.", "response": "def process_links(include_match, block_map, link_stack, source_path):\n    \"\"\"Process a string of content for include tags.\n\n    This function assumes there are no blocks in the content. The content is split into segments,\n    with include tags being replaced by Block objects.\n\n    PARAMETERS:\n    content     -- str; content to be converted into a Block.\n    block_map   -- BlockMap\n    link_stack  -- LinkStack\n    source_path -- str; the filepath of the file from which this content came.\n\n    RETURNS:\n    list of str; segments that the comprise the content.\n    \"\"\"\n    leading_whitespace = include_match.group(1)\n    include_path = include_match.group(2)\n\n    # Optional block name. If match is None, block name was ommitted (default to 'all').\n    block_name = include_match.group(3)\n    if block_name is not None:\n        block_name = block_name.lstrip(':')\n    else:\n        block_name = ALL_BLOCK_NAME\n\n    return retrieve_block_from_map(\n            source_path,\n            include_path.strip(),\n            block_name.strip(),\n            leading_whitespace,\n            block_map,\n            link_stack)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef retrieve_block_from_map(\n        source_path,\n        include_path,\n        block_name,\n        leading_whitespace,\n        block_map,\n        link_stack):\n    \"\"\"Given a source directory, the path specified in an include tag, and the block name, retrieve\n    the corresponding Block from the block_map (adding it to the map if necessary).\n\n    The paths in include tags are interpreted as follows:\n\n    1. relative to the directory of source_path.\n    2. relative to the current working directory.\n\n    If the included block is not found in either location, an exception is raised. If a cycle is\n    detected, an exception is raised.\n    \"\"\"\n    # Check if the included file exists.\n    relative_to_source = os.path.join(os.path.dirname(source_path), include_path)\n    if os.path.isfile(relative_to_source):\n        filename = relative_to_source\n    elif os.path.isfile(include_path):\n        filename = include_path\n    else:\n        raise IncludeNonExistentBlock(\n            source_path + ' tried to include a non-existent file: ' + include_path)\n\n    # Add included file to stack, checking for cycles in the process.\n    link_stack.push(filename)\n\n    # Process the block's file if it hasn't been processed before.\n    if not block_map.has_block(filename, block_name):\n        with open(filename, 'r') as f:\n            content = f.read()\n        convert_lines_to_block(content.splitlines(), block_map, link_stack, filename)\n\n    # If the block is not in the map even after converting, then the block doesn't exist.\n    if not block_map.has_block(filename, block_name):\n        raise IncludeNonExistentBlock(\n            source_path + ' tried to include a non-existent block: ' + filename + ':' + block_name)\n\n    link_stack.pop()\n    # Convert the Block to a string and indent.\n    return indent(str(block_map.get_block(filename, block_name)), leading_whitespace)", "response": "Given a source directory and a path specified in an include tag and a block name retrieve the corresponding Block from the block_map."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef branches(self):\n\t\treq_message = 'https://api.bitbucket.org/1.0/repositories/' + self.reponame + '/branches'\n\t\tresponse_data = self._bitbucketAPIRequest(req_message)\n\t\treturn response_data.keys()", "response": "Return a list of branches for given repository"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _commitData(self, commit):\n\t\treturn {\n\t\t\t\"hexsha\": commit['hash'],\n\t\t\t\"adate\": time.mktime(time.strptime(commit['date'][:19], '%Y-%m-%dT%H:%M:%S')),\n\t\t\t\"cdate\": time.mktime(time.strptime(commit['date'][:19], '%Y-%m-%dT%H:%M:%S')),\n\t\t\t\"author\": commit['author']['raw'],\n\t\t\t\"message\": commit['message']\n\t\t}", "response": "Get data from a commit object\n\t"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef commit(self, commit):\n\t\treq_message = 'https://api.bitbucket.org/2.0/repositories/atlassian/aui/commit/' + commit\n\t\tresponse_data = self._bitbucketAPIRequest(req_message)\n\t\ttry:\n\t\t\treturn self._commitData(response_data)\n\t\texcept (ValueError, KeyError):\n\t\t\traise KeyError(\"Commit %s not found\" % commit)", "response": "Get data for a given commit"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrap the function in a `warnings.catch_warnings` context. It can be used to silence some particular specific warnings, or instead to treat them as errors within the function body. Example: >>> import warnings >>> from moclo.utils import catch_warnings >>> @catch_warnings('ignore') ... def are_you_scared(): ... warnings.warn(\"I'm warning you !\") ... return False >>> are_you_scared() False", "response": "def catch_warnings(action, category=Warning, lineno=0, append=False):\n    \"\"\"Wrap the function in a `warnings.catch_warnings` context.\n\n    It can be used to silence some particular specific warnings, or instead\n    to treat them as errors within the function body.\n\n    Example:\n        >>> import warnings\n        >>> from moclo.utils import catch_warnings\n        >>> @catch_warnings('ignore')\n        ... def are_you_scared():\n        ...     warnings.warn(\"I'm warning you !\")\n        ...     return False\n        >>> are_you_scared()\n        False\n\n    \"\"\"\n\n    def decorator(func):\n        @functools.wraps(func)\n        def newfunc(*args, **kwargs):\n            with warnings.catch_warnings():\n                warnings.simplefilter(action, category, lineno, append)\n                return func(*args, **kwargs)\n\n        return newfunc\n\n    return decorator"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _guess_caller():\n    import inspect\n    global _caller_path\n\n    caller = inspect.stack()[1]\n    caller_module = inspect.getmodule(caller[0])\n    if hasattr(caller_module, '__file__'):\n        _caller_path = os.path.abspath(caller_module.__file__)\n    return _caller_path", "response": "Try to guess which module is the caller"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the root path for the current project.", "response": "def set_root_path(self, root_path=None, settings_module=None):\n        \"\"\"\n        root_path will only be used for 3 situations:\n        1. fix ``static_path`` and ``template_path``\n        2. check project's directory name with the value in settings.PROJECT\n        3. append parent path to sys.path\n        \"\"\"\n        if root_path:\n            self.root_path = root_path\n            return\n\n        if settings_module:\n            self.root_path = os.path.dirname(os.path.abspath(settings_module.__file__))\n            return\n\n        # try to guess which module import app.py\n        import inspect\n\n        caller = inspect.stack()[1]\n        caller_module = inspect.getmodule(caller[0])\n        assert hasattr(caller_module, '__file__'), 'Caller module %s should have __file__ attr' % caller_module\n        self.root_path = os.path.dirname(os.path.abspath(caller_module.__file__))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfixing static_path and template_path to be absolute", "response": "def _fix_paths(self, options):\n        \"\"\"\n        fix `static_path` and `template_path` to be absolute\n        path according to self.root_path so that PWD can be ignoreed.\n        \"\"\"\n        for k in ('template_path', 'static_path'):\n            if k in options:\n                v = options.pop(k)\n                if v is None:\n                    continue\n                if not os.path.isabs(v):\n                    v = os.path.abspath(\n                        os.path.join(self.root_path, v))\n                    app_log.debug('Fix %s to be absolute: %s' % (k, v))\n                options[k] = v"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef route(self, url, host=None):\n        def fn(handler_cls):\n            handlers = self._get_handlers_on_host(host)\n            handlers.insert(0, (url, handler_cls))\n            return handler_cls\n        return fn", "response": "This is a decorator that adds a new handler to the list of handlers that match the given URL."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef route_many(self, *args, **kwargs):\n        if len(args) == 2:\n            prefix, rules = args\n        elif len(args) == 1:\n            prefix = None\n            rules = args[0]\n        else:\n            raise ValueError('The amount of args of route_many method can only be one or two')\n        router = Router(rules, prefix=prefix)\n        self.add_handlers(router.get_handlers(), host=kwargs.get('host'))", "response": "Route many to the specified routes."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconfigure the settings object based on the module settings object.", "response": "def module_config(self, settings_module):\n        \"\"\"\n        Optional function\n        \"\"\"\n        assert hasattr(settings_module, '__file__'), 'settings must be a module'\n        # set root_path according to module file\n        self.set_root_path(settings_module=settings_module)\n        app_log.debug('Set root_path: %s', self.root_path)\n\n        global settings\n\n        self.update_settings(dict(\n            [(i, getattr(settings_module, i)) for i in dir(settings_module)\n             if not i.startswith('_') and i == i.upper()]))\n\n        settings._module = settings_module\n\n        # keep a mapping to app on settings object\n        settings._app = self"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing command line arguments and apply them to settings. py", "response": "def command_line_config(self):\n        \"\"\"\n        settings.py is the basis\n\n        if wants to change them by command line arguments,\n        the existing option will be transformed to the value type in settings.py\n        the unexisting option will be treated as string by default,\n        and transform to certain type if `!<type>` was added after the value.\n\n        example:\n        $ python app.py --PORT=1000\n\n        NOTE This method is deprecated, use `torext.script` to parse command line arguments instead.\n        \"\"\"\n\n        args = sys.argv[1:]\n        args_dict = {}\n        existed_keys = []\n        new_keys = []\n\n        for t in args:\n            if not t.startswith('--'):\n                raise errors.ArgsParseError('Bad arg: %s' % t)\n            try:\n                key, value = tuple(t[2:].split('='))\n            except:\n                raise errors.ArgsParseError('Bad arg: %s' % t)\n\n            args_dict[key] = value\n\n            if key in settings:\n                existed_keys.append(key)\n            else:\n                new_keys.append(key)\n\n        if existed_keys:\n            app_log.debug('Changed settings:')\n            for i in existed_keys:\n                before = settings[i]\n                type_ = type(before)\n                if type_ is bool:\n                    if args_dict[i] == 'True':\n                        _value = True\n                    elif args_dict[i] == 'False':\n                        _value = False\n                    else:\n                        raise errors.ArgsParseError('%s should only be True or False' % i)\n                else:\n                    _value = type_(args_dict[i])\n                settings[i] = _value\n                app_log.debug('  %s  [%s]%s (%s)', i, type(settings[i]), settings[i], before)\n\n        if new_keys:\n            app_log.debug('New settings:')\n            for i in new_keys:\n                settings[i] = args_dict[i]\n                app_log.debug('  %s  %s', i, args_dict[i])\n\n        # NOTE if ``command_line_config`` is called, logging must be re-configed\n        self.update_settings({})"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _init_application(self, application=None):\n        if application:\n            self.application = application\n        else:\n            self.application = self.make_application()", "response": "Initialize application object for torext app"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _log_function(self, handler):\n        if handler.get_status() < 400:\n            log_method = request_log.info\n        elif handler.get_status() < 500:\n            log_method = request_log.warning\n        else:\n            log_method = request_log.error\n        for i in settings['LOGGING_IGNORE_URLS']:\n            if handler.request.uri.startswith(i):\n                log_method = request_log.debug\n                break\n\n        request_time = 1000.0 * handler.request.request_time()\n        log_method(\"%d %s %.2fms\", handler.get_status(),\n                   handler._request_summary(), request_time)", "response": "Override Application. log_function so that what to log can be controlled."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef xavier_init(fan_in, fan_out, constant=1): \n    # https://stackoverflow.com/questions/33640581/how-to-do-xavier-initialization-on-tensorflow\n    low = -constant*np.sqrt(6.0/(fan_in + fan_out)) \n    high = constant*np.sqrt(6.0/(fan_in + fan_out))\n    return tf.random_uniform((fan_in, fan_out), \n                             minval=low, maxval=high, \n                             dtype=tf.float32)", "response": "Initialize the Xavier network weights."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef partial_fit(self, X):\n        opt, cost = self.sess.run((self.optimizer, self.cost), \n                                  feed_dict={self.x: X})\n        return cost", "response": "Train model based on mini - batch of input data. Return cost of mini - batch."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef transform(self, X):\n        # Note: This maps to mean of distribution, we could alternatively\n        # sample from Gaussian distribution\n        return self.sess.run(self.z_mean, feed_dict={self.x: X})", "response": "Transform data by mapping it into the latent space."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef generate(self, z_mu=None):\n        if z_mu is None:\n            z_mu = np.random.normal(size=self.network_architecture[\"n_z\"])\n        # Note: This maps to mean of distribution, we could alternatively\n        # sample from Gaussian distribution\n        return self.sess.run(self.x_reconstr_mean, \n                             feed_dict={self.z: z_mu})", "response": "Generate data by sampling from latent space."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nusing VAE to reconstruct given data.", "response": "def reconstruct(self, X):\n        \"\"\" Use VAE to reconstruct given data. \"\"\"\n        return self.sess.run(self.x_reconstr_mean, \n                             feed_dict={self.x: X})"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_gmsh(filename, boundary_file):\n    mesh = {}\n\n    fid = open(filename, 'r')\n    line = fid.readline()\n    while(line):\n        if(line.startswith('$MeshFormat')):\n            pass\n        elif(line.startswith('$Nodes')):\n            nodes = []\n            line = fid.readline()\n            nr_nodes = np.fromstring(line, dtype=int, count=1, sep=r'\\n')\n            nr_nodes\n            while(line):\n                line = fid.readline()\n                if(line.startswith('$EndNodes')):\n                    break\n                node = np.fromstring(line, dtype=float, sep=' ')\n                nodes.append(node)\n            mesh['nodes'] = nodes\n        elif(line.startswith('$Elements')):\n            \"\"\"\n            Create a dictionary with the element types as keys. E.g.:\n            elements['15'] provides all elements of type 15 (Points)\n            \"\"\"\n            elements = {}\n            line = fid.readline()\n            nr_elements = np.fromstring(line, dtype=int, count=1, sep=r'\\n')\n            nr_elements\n            while(line):\n                line = fid.readline()\n                if(line.startswith('$EndElements')):\n                    break\n                element = np.fromstring(line, dtype=int, sep=' ')\n                # el_nr = element[0]\n                el_type = element[1]\n                el_nr_tags = element[2]\n                # el_tags = element[3:3 + el_nr_tags]\n                el_nodes = element[3 + el_nr_tags:]\n\n                # now decide where to put it\n                key = str(el_type)\n                if(key in elements.keys()):\n                    elements[key].append(el_nodes)\n                else:\n                    elements[key] = []\n                    elements[key].append(el_nodes)\n\n            mesh['elements'] = elements\n        line = fid.readline()\n\n    fid.close()\n\n    # if boundary_file is != None, then sort the lines (element type 1)\n    # according to the element types\n    boundaries = {}\n\n    if(boundary_file is not None):\n        # load the original boundary lines\n        # it is possible that GMSH added additional nodes on these lines, and\n        # that is why we need to find all mesh lines that lie on these original\n        # lines.\n        bids = np.loadtxt(boundary_file)\n\n        for btype in ('12', '11'):\n            # select all original boundaries with this type\n            a = np.where(bids[:, 4] == int(btype))[0]\n            boundaries[btype] = []\n            # for each of those lines, find all lines of the mesh that belong\n            # here\n            for orig_line in bids[a, :]:\n                # print('Find all lines lying on the line: ')\n                found_one_line = False\n                # print(orig_line)\n                # construct line equation\n\n                # x1 == x2 ?\n                # split into coordinates\n                ox1 = orig_line[0]\n                ox2 = orig_line[2]\n                oy1 = orig_line[1]\n                oy2 = orig_line[3]\n\n                if(orig_line[0] == orig_line[2]):\n                    # special case: we only need to find all lines with x1 ==\n                    # x2 == x1_orig and y_min >= y_orig_min and y_max <=\n                    # <_orig_max\n                    for line in elements['1']:\n                        if(btype == '11'):\n                            if(line[0] == 48 and line[1] == 150):\n                                pass\n                                # print('Find all lines lying on the line: ')\n                                # print('This is the line')\n\n                        # it doesn't matter any more to be able to assign x ->\n                        # y values. Thus we can sort the y values and just\n                        # check\n                        # if the new line lies in between the original one\n                        oy1, oy2 = np.sort([orig_line[1], orig_line[3]])\n                        x1, x2 = np.sort(\n                            [\n                                mesh['nodes'][line[0] - 1][1],\n                                mesh['nodes'][line[1] - 1][1]\n                            ]\n                        )\n                        y1, y2 = np.sort(\n                            [\n                                mesh['nodes'][line[0] - 1][2],\n                                mesh['nodes'][line[1] - 1][2]\n                            ]\n                        )\n\n                        if np.isclose(x1, x2) and np.isclose(x2, ox1):\n                            if(y1 >= oy1 and y2 <= oy2):\n                                found_one_line = True\n                                boundaries[btype].append(line)\n\n                else:\n                    # print('checking with full line equation')\n                    # no vertical line\n                    # we need the full check using the line equation\n                    slope = (orig_line[1] - orig_line[3]) / (\n                        orig_line[0] - orig_line[2])\n                    intersect = orig_line[1] - (slope * orig_line[0])\n                    # print('Slope', slope, ' Intercept ', intersect)\n                    for line in elements['1']:\n                        x1 = mesh['nodes'][line[0] - 1][1]\n                        y1 = mesh['nodes'][line[0] - 1][2]\n                        x2 = mesh['nodes'][line[1] - 1][1]\n                        y2 = mesh['nodes'][line[1] - 1][2]\n\n                        # print(x1, x2, y1, y1)\n                        check = False\n                        # check if x coordinates of the test line fit in the\n                        # original line\n                        if(ox1 < ox2):\n                            if(x1 < x2):\n                                if((np.isclose(x1, ox1) or x1 > ox1) and\n                                   (np.isclose(x2, ox2) or x2 < ox2)):\n                                    check = True\n                            else:\n                                if((np.isclose(x2, ox1) or x2 >= ox1) and\n                                   (np.isclose(x1, ox2) or x1 <= ox2)):\n                                    check = True\n                        else:\n                            if(x1 < x2):\n                                if((np.isclose(x1, ox2) or x1 >= ox2) and\n                                   (np.isclose(x2, ox1) or x2 <= ox1)):\n                                    check = True\n                            else:\n                                if((np.isclose(x2, ox2) or x2 >= ox2) and\n                                   (np.isclose(x1, ox1) or x1 <= ox1)):\n                                    check = True\n\n                        # print('boundary check:', check)\n                        if(check):\n                            # the line lies within the x-range of the orig line\n                            ytest1 = slope * x1 + intersect\n                            ytest2 = slope * x2 + intersect\n                            if(np.around(ytest1 - y1, 5) == 0 and\n                               np.around(ytest2 - y2, 5) == 0):\n                                boundaries[btype].append(line)\n                                # found = True\n                                found_one_line = True\n                                # print('found it new', line)\n                # add a weak check: we need to find at least one line in the\n                # mesh corresponding to this boundary line:\n                if not found_one_line:\n                    raise Exception('no mesh line found for this boundary')\n\n            print('Total number of boundaries of this type:',\n                  len(boundaries[btype]))\n    mesh['boundaries'] = boundaries\n    return mesh", "response": "Parse a GMSH file and return a dictionary containing the data and the CRTomo grids that are part of the GMSH file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_header(mesh):\n    nr_all_nodes = len(mesh['nodes'])\n    nr_types = 1  # triangles\n\n    # compute bandwidth\n    bandwidth = -1\n    for triangle in mesh['elements']['2']:\n        diff1 = abs(triangle[0] - triangle[1])\n        diff2 = abs(triangle[0] - triangle[2])\n        diff3 = abs(triangle[1] - triangle[2])\n        diffm = max(diff1, diff2, diff3)\n        if(diffm > bandwidth):\n            bandwidth = diffm\n\n    el_infos = []\n    # triangles\n    for element in ('2',):\n        el = mesh['elements'][element]\n        if(element == '2'):\n            el_type = 3\n        elif(element == '1'):\n            el_type = 12  # Neumann\n        nr = len(el)\n        nr_nodes = len(el[0])\n        el_infos.append((el_type, nr, nr_nodes))\n\n    # boundary elements\n    for btype in ('12', '11'):\n        if(btype in mesh['boundaries']):\n            el_type = int(btype)\n            nr = len(mesh['boundaries'][btype])\n            nr_nodes = 2\n            if(nr > 0):\n                nr_types += 1\n                el_infos.append((el_type, nr, nr_nodes))\n\n    # now convert to string\n    str_header = ''\n    for a, b, c in [(nr_all_nodes, nr_types, bandwidth), ] + el_infos:\n        str_header = str_header + '{0}  {1} {2}\\n'.format(a, b, c)\n    return str_header", "response": "This function returns the header of the current node list."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_ajd_bound(mesh):\n    print('Get elements adjacent to boundaries')\n    boundary_elements = []\n    str_adj_boundaries = ''\n    # for boundary in mesh['elements']['1']:\n    boundaries = mesh['boundaries']['12'] + mesh['boundaries']['11']\n    for boundary in boundaries:\n        # now find the triangle ('2') with two nodes equal to this boundary\n        indices = [nr if (boundary[0] in x and boundary[1] in x) else np.nan\n                   for (nr, x) in enumerate(mesh['elements']['2'])]\n        indices = np.array(indices)[~np.isnan(indices)]\n        if(len(indices) != 1):\n            print('More than one neighbour found!')\n        elif(len(indices) == 0):\n            print('No neighbour found!')\n        boundary_elements.append(indices[0])\n        str_adj_boundaries += '{0}\\n'.format(int(indices[0]) + 1)\n    return str_adj_boundaries, boundary_elements", "response": "Determine triangular elements adjacent to the boundary elements"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef write_elec_file(filename, mesh):\n    elecs = []\n    # print('Write electrodes')\n    electrodes = np.loadtxt(filename)\n    for i in electrodes:\n        # find\n        for nr, j in enumerate(mesh['nodes']):\n            if np.isclose(j[1], i[0]) and np.isclose(j[2], i[1]):\n                elecs.append(nr + 1)\n\n    fid = open('elec.dat', 'w')\n    fid.write('{0}\\n'.format(len(elecs)))\n    for i in elecs:\n        fid.write('{0}\\n'.format(i))\n    fid.close()", "response": "Write the electrode positions and indices of the electrodes in the file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_center(self):\n        dist = self.get_distance()\n        diff = self.get_diff()\n        direction = diff / dist\n\n        center_x = self.p2_x + (dist * 0.5) * direction[0]\n        center_y = self.p2_y + (dist * 0.5) * direction[1]\n\n        return np.array([center_x, center_y])", "response": "Return x y coordinate of central point of the current species"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the MDP state size.", "response": "def state_size(self) -> Sequence[Shape]:\n        '''Returns the MDP state size.'''\n        return self._sizes(self._compiler.rddl.state_size)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the MDP action size.", "response": "def action_size(self) -> Sequence[Shape]:\n        '''Returns the MDP action size.'''\n        return self._sizes(self._compiler.rddl.action_size)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef interm_size(self) -> Sequence[Shape]:\n        '''Returns the MDP intermediate state size.'''\n        return self._sizes(self._compiler.rddl.interm_size)", "response": "Returns the MDP intermediate state size."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the simulation cell output size.", "response": "def output_size(self) -> Tuple[Sequence[Shape], Sequence[Shape], Sequence[Shape], int]:\n        '''Returns the simulation cell output size.'''\n        return (self.state_size, self.action_size, self.interm_size, 1)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef initial_state(self) -> StateTensor:\n        '''Returns the initial state tensor.'''\n        s0 = []\n        for fluent in self._compiler.compile_initial_state(self._batch_size):\n            s0.append(self._output_size(fluent))\n        s0 = tuple(s0)\n        return s0", "response": "Returns the initial state tensor."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nyield the fluents tensors.", "response": "def _tensors(cls, fluents: Sequence[FluentPair]) -> Iterable[tf.Tensor]:\n        '''Yields the `fluents`' tensors.'''\n        for _, fluent in fluents:\n            tensor = cls._output_size(fluent.tensor)\n            yield tensor"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _dtype(cls, tensor: tf.Tensor) -> tf.Tensor:\n        '''Converts `tensor` to tf.float32 datatype if needed.'''\n        if tensor.dtype != tf.float32:\n            tensor = tf.cast(tensor, tf.float32)\n        return tensor", "response": "Converts tensor to tf. float32 datatype if needed."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns output tensors for fluents.", "response": "def _output(cls, fluents: Sequence[FluentPair]) -> Sequence[tf.Tensor]:\n        '''Returns output tensors for `fluents`.'''\n        return tuple(cls._dtype(t) for t in cls._tensors(fluents))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef output_size(self) -> Tuple[Sequence[Shape], Sequence[Shape], Sequence[Shape], int]:\n        '''Returns the simulation output size.'''\n        return self._cell.output_size", "response": "Returns the simulation output size."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the input tensor for the given horizon.", "response": "def timesteps(self, horizon: int) -> tf.Tensor:\n        '''Returns the input tensor for the given `horizon`.'''\n        start, limit, delta = horizon - 1, -1, -1\n        timesteps_range = tf.range(start, limit, delta, dtype=tf.float32)\n        timesteps_range = tf.expand_dims(timesteps_range, -1)\n        batch_timesteps = tf.stack([timesteps_range] * self.batch_size)\n        return batch_timesteps"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the ops for the trajectory generation with given horizon and initial_state.", "response": "def trajectory(self,\n            horizon: int,\n            initial_state: Optional[StateTensor] = None) -> TrajectoryOutput:\n        '''Returns the ops for the trajectory generation with given `horizon`\n        and `initial_state`.\n\n        The simulation returns states, actions and interms as a\n        sequence of tensors (i.e., all representations are factored).\n        The reward is a batch sized tensor.\n        The trajectoty output is a tuple: (initial_state, states, actions, interms, rewards).\n        If initial state is None, use default compiler's initial state.\n\n        Note:\n            All tensors have shape: (batch_size, horizon, fluent_shape).\n            Except initial state that has shape: (batch_size, fluent_shape).\n\n        Args:\n            horizon (int): The number of simulation timesteps.\n            initial_state (Optional[Sequence[tf.Tensor]]): The initial state tensors.\n\n        Returns:\n            Tuple[StateTensor, StatesTensor, ActionsTensor, IntermsTensor, tf.Tensor]: Trajectory output tuple.\n        '''\n        if initial_state is None:\n            initial_state = self._cell.initial_state()\n\n        with self.graph.as_default():\n            self.inputs = self.timesteps(horizon)\n            outputs, _ = tf.nn.dynamic_rnn(\n                                self._cell,\n                                self.inputs,\n                                initial_state=initial_state,\n                                dtype=tf.float32,\n                                scope=\"trajectory\")\n            states, actions, interms, rewards = outputs\n\n            # fluent types\n            state_dtype = map(rddl2tf.utils.range_type_to_dtype, self._cell._compiler.rddl.state_range_type)\n            states = self._output(states, state_dtype)\n            interm_dtype = map(rddl2tf.utils.range_type_to_dtype, self._cell._compiler.rddl.interm_range_type)\n            interms = self._output(interms, interm_dtype)\n            action_dtype = map(rddl2tf.utils.range_type_to_dtype, self._cell._compiler.rddl.action_range_type)\n            actions = self._output(actions, action_dtype)\n\n            outputs = (initial_state, states, actions, interms, rewards)\n\n        return outputs"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run(self,\n            horizon: int,\n            initial_state: Optional[StateTensor] = None) -> SimulationOutput:\n        '''Builds the MDP graph and simulates in batch the trajectories\n        with given `horizon`. Returns the non-fluents, states, actions, interms\n        and rewards. Fluents and non-fluents are returned in factored form.\n\n        Note:\n            All output arrays have shape: (batch_size, horizon, fluent_shape).\n            Except initial state that has shape: (batch_size, fluent_shape).\n\n        Args:\n            horizon (int): The number of timesteps in the simulation.\n            initial_state (Optional[Sequence[tf.Tensor]]): The initial state tensors.\n\n        Returns:\n            Tuple[NonFluentsArray, StatesArray, ActionsArray, IntermsArray, np.array]: Simulation ouput tuple.\n        '''\n        trajectory = self.trajectory(horizon, initial_state)\n\n        with tf.Session(graph=self.graph) as sess:\n            sess.run(tf.global_variables_initializer())\n            non_fluents = sess.run(self._non_fluents)\n            initial_state, states, actions, interms, rewards = sess.run(trajectory)\n\n        # non-fluents\n        non_fluent_ordering = self._cell._compiler.rddl.domain.non_fluent_ordering\n        non_fluents = tuple(zip(non_fluent_ordering, non_fluents))\n\n        # states\n        state_fluent_ordering = self._cell._compiler.rddl.domain.state_fluent_ordering\n        states = tuple(zip(state_fluent_ordering, states))\n\n        # interms\n        interm_fluent_ordering = self._cell._compiler.rddl.domain.interm_fluent_ordering\n        interms = tuple(zip(interm_fluent_ordering, interms))\n\n        # actions\n        action_fluent_ordering = self._cell._compiler.rddl.domain.action_fluent_ordering\n        actions = tuple(zip(action_fluent_ordering, actions))\n\n        # rewards\n        rewards = np.squeeze(rewards)\n\n        outputs = (non_fluents, initial_state, states, actions, interms, rewards)\n\n        return outputs", "response": "Builds the MDP graph and simulates in batch the trajectories\n        with given horizon."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts tensors to the corresponding dtypes.", "response": "def _output(cls,\n            tensors: Sequence[tf.Tensor],\n            dtypes: Sequence[tf.DType]) -> Sequence[tf.Tensor]:\n        '''Converts `tensors` to the corresponding `dtypes`.'''\n        outputs = []\n        for tensor, dtype in zip(tensors, dtypes):\n            tensor = tensor[0]\n            if tensor.dtype != dtype:\n                tensor = tf.cast(tensor, dtype)\n            outputs.append(tensor)\n        return tuple(outputs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of Genotypes instances containing a pointer to the variant as well as a vector of encoded genotypes.", "response": "def get_variant_genotypes(self, variant):\n        \"\"\"Get the genotypes from a well formed variant instance.\n\n        Args:\n            marker (Variant): A Variant instance.\n\n        Returns:\n            A list of Genotypes instance containing a pointer to the variant as\n            well as a vector of encoded genotypes.\n\n        \"\"\"\n        if not self.has_index:\n            raise NotImplementedError(\"Not implemented when IMPUTE2 file is \"\n                                      \"not indexed (see genipe)\")\n\n        # Find the variant in the index\n        try:\n            impute2_chrom = CHROM_STR_TO_INT[variant.chrom.name]\n        except KeyError:\n            raise ValueError(\n                \"Invalid chromosome ('{}') for IMPUTE2.\".format(variant.chrom)\n            )\n\n        variant_info = self._impute2_index[\n            (self._impute2_index.chrom == impute2_chrom) &\n            (self._impute2_index.pos == variant.pos)\n        ]\n\n        if variant_info.shape[0] == 0:\n            logging.variant_not_found(variant)\n            return []\n\n        elif variant_info.shape[0] == 1:\n            return self._get_biallelic_variant(variant, variant_info)\n\n        else:\n            return self._get_multialleic_variant(variant, variant_info)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_biallelic_variant(self, variant, info, _check_alleles=True):\n        info = info.iloc[0, :]\n        assert not info.multiallelic\n\n        # Seeking and parsing the file\n        self._impute2_file.seek(info.seek)\n        genotypes = self._parse_impute2_line(self._impute2_file.readline())\n\n        variant_alleles = variant._encode_alleles([\n            genotypes.reference, genotypes.coded,\n        ])\n        if (_check_alleles and variant_alleles != variant.alleles):\n            # Variant with requested alleles is unavailable.\n            logging.variant_not_found(variant)\n            return []\n\n        return [genotypes]", "response": "Creates a bi - alleles variant."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef iter_genotypes(self):\n        # Seeking at the beginning of the file\n        self._impute2_file.seek(0)\n\n        # Parsing each lines of the IMPUTE2 file\n        for i, line in enumerate(self._impute2_file):\n            genotypes = self._parse_impute2_line(line)\n\n            variant_info = None\n            if self.has_index:\n                variant_info = self._impute2_index.iloc[i, :]\n            self._fix_genotypes_object(genotypes, variant_info)\n\n            yield genotypes", "response": "Iterates on available markers."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\niterates over the variants in the IMPUTE2 file.", "response": "def iter_variants(self):\n        \"\"\"Iterate over marker information.\"\"\"\n        if not self.has_index:\n            raise NotImplementedError(\"Not implemented when IMPUTE2 file is \"\n                                      \"not indexed (see genipe)\")\n\n        for name, row in self._impute2_index.iterrows():\n            # Seeking to the right place in the file\n            f = self._impute2_file\n            f.seek(int(row.seek))\n            chrom, name, pos, a1, a2 = f.read(1024).split(\" \")[:5]\n            pos = int(pos)\n\n            yield Variant(name, CHROM_STR_ENCODE.get(chrom, chrom), pos,\n                          [a1, a2])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_variants_in_region(self, chrom, start, end):\n        if not self.has_index:\n            raise NotImplementedError(\"Not implemented when IMPUTE2 file is \"\n                                      \"not indexed (see genipe)\")\n\n        if not self._index_has_location:\n            raise NotImplementedError(\"Not implemented when index doesn't \"\n                                      \"have location information.\")\n\n        # Getting the required variants\n        required = self._impute2_index.loc[\n            (self._impute2_index.chrom == CHROM_STR_TO_INT[chrom]) &\n            (start <= self._impute2_index.pos) &\n            (self._impute2_index.pos <= end)\n        ]\n\n        for name, variant_info in required.iterrows():\n            for genotypes in self.get_variant_by_name(name, variant_info):\n                self._fix_genotypes_object(genotypes, variant_info)\n                yield genotypes", "response": "Iterate over the variants in a region."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_variant_by_name(self, name, variant_info=None):\n        # From 1.3.2 onwards, PyPlink sets unique names.\n        if not self.has_index:\n            raise NotImplementedError(\"Not implemented when IMPUTE2 file is \"\n                                      \"not indexed (see genipe)\")\n\n        # Getting the seek position\n        if variant_info is None:\n            try:\n                variant_info = self._impute2_index.loc[name, :]\n\n            except KeyError:\n                if name in self.get_duplicated_markers():\n                    # The variant is a duplicated one, so we go through all the\n                    # variants with the same name and the :dupx suffix\n                    return [\n                        self.get_variant_by_name(dup_name).pop()\n                        for dup_name in self.get_duplicated_markers()[name]\n                    ]\n\n                else:\n                    # The variant is not in the index\n                    logging.variant_name_not_found(name)\n                    return []\n\n        # Seeking to the right place in the file\n        self._impute2_file.seek(variant_info.seek)\n\n        # Parsing the file\n        genotypes = self._parse_impute2_line(self._impute2_file.readline())\n\n        # Fixing the object\n        self._fix_genotypes_object(genotypes, variant_info)\n\n        return [genotypes]", "response": "Get the genotype of a specific variant using it s name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfixing a genotypes object.", "response": "def _fix_genotypes_object(self, genotypes, variant_info):\n        \"\"\"Fixes a genotypes object (variant name, multi-allelic value.\"\"\"\n        # Checking the name (if there were duplications)\n        if self.has_index and variant_info.name != genotypes.variant.name:\n            if not variant_info.name.startswith(genotypes.variant.name):\n                raise ValueError(\"Index file not synced with IMPUTE2 file\")\n            genotypes.variant.name = variant_info.name\n\n        # Trying to set multi-allelic information\n        if self.has_index and self._index_has_location:\n            # Location was in the index, so we can automatically set the\n            # multi-allelic state of the genotypes\n            genotypes.multiallelic = variant_info.multiallelic\n\n        else:\n            # Location was not in the index, so we check one marker before and\n            # after the one we found\n            logging.warning(\"Multiallelic variants are not detected on \"\n                            \"unindexed files.\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing the current IMPUTE2 line and returns a Genotypes object.", "response": "def _parse_impute2_line(self, line):\n        \"\"\"Parses the current IMPUTE2 line (a single variant).\n\n        Args:\n            line (str): An IMPUTE2 line.\n\n        Returns:\n            Genotypes: The genotype in dosage format.\n\n        Warning\n        =======\n            By default, the genotypes object has multiallelic set to False.\n\n        \"\"\"\n        # Splitting\n        row = line.rstrip(\"\\r\\n\").split(\" \")\n\n        # Constructing the probabilities\n        prob = np.array(row[5:], dtype=float)\n        prob.shape = (prob.shape[0] // 3, 3)\n\n        # Constructing the dosage\n        dosage = 2 * prob[:, 2] + prob[:, 1]\n        if self.prob_t > 0:\n            dosage[~np.any(prob >= self.prob_t, axis=1)] = np.nan\n\n        return Genotypes(\n            Variant(row[1], CHROM_STR_ENCODE.get(row[0], row[0]), int(row[2]),\n                    [row[3], row[4]]),\n            dosage,\n            reference=row[3],\n            coded=row[4],\n            multiallelic=False,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nhooking the create method of the PCDM Collection resource.", "response": "def _post_create(self, auto_refresh=False):\n\n\t\t'''\n\t\tresource.create() hook\n\n\t\tFor PCDM Collections, post creation, also create\n\t\t'''\n\n\t\t# set PCDM triple as Collection\n\t\tself.add_triple(self.rdf.prefixes.rdf.type, self.rdf.prefixes.pcdm.Collection)\n\t\tself.update(auto_refresh=auto_refresh)\n\n\t\t# create /members child resource\n\t\tmembers_child = PCDMMembersContainer(\n\t\t\tself.repo,\n\t\t\t'%s/members' % self.uri_as_string(),\n\t\t\tmembershipResource=self.uri,\n\t\t\thasMemberRelation=self.rdf.prefixes.pcdm.hasMember,\n\t\t\tinsertedContentRelation=self.rdf.prefixes.ore.proxyFor)\n\t\tmembers_child.create(specify_uri=True)\n\n\t\t# create /related child resource\n\t\trelated_child = PCDMRelatedContainer(\n\t\t\tself.repo,\n\t\t\t'%s/related' % self.uri_as_string(),\n\t\t\tmembershipResource=self.uri,\n\t\t\thasMemberRelation=self.rdf.prefixes.ore.aggregates,\n\t\t\tinsertedContentRelation=self.rdf.prefixes.ore.proxyFor)\n\t\trelated_child.create(specify_uri=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_related(self):\n\n\t\t'''\n\t\tget ore:aggregates for this resource, optionally retrieving resource payload\n\n\t\tArgs:\n\t\t\tretrieve (bool): if True, issue .refresh() on resource thereby confirming existence and retrieving payload\n\t\t'''\n\n\t\tif self.exists and hasattr(self.rdf.triples, 'ore') and hasattr(self.rdf.triples.ore, 'aggregates'):\n\t\t\trelated = [ self.repo.parse_uri(uri) for uri in self.rdf.triples.ore.aggregates ]\n\n\t\t\t# return\n\t\t\treturn related\n\n\t\telse:\n\t\t\treturn []", "response": "Returns a list of related resources for this resource optionally retrieving resource payload"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _post_create(self, auto_refresh=False):\n\n\t\t'''\n\t\tresource.create() hook\n\t\t'''\n\n\t\t# set PCDM triple as Object\n\t\tself.add_triple(self.rdf.prefixes.rdf.type, self.rdf.prefixes.pcdm.Object)\n\t\tself.update(auto_refresh=auto_refresh)\n\n\t\t# create /files child resource\n\t\tfiles_child = PCDMFilesContainer(\n\t\t\tself.repo,\n\t\t\t'%s/files' % self.uri_as_string(),\n\t\t\tmembershipResource=self.uri,\n\t\t\thasMemberRelation=self.rdf.prefixes.pcdm.hasFile)\n\t\tfiles_child.create(specify_uri=True)\n\n\t\t# create /members child resource\n\t\tmembers_child = PCDMMembersContainer(\n\t\t\tself.repo,\n\t\t\t'%s/members' % self.uri_as_string(),\n\t\t\tmembershipResource=self.uri,\n\t\t\thasMemberRelation=self.rdf.prefixes.pcdm.hasMember,\n\t\t\tinsertedContentRelation=self.rdf.prefixes.ore.proxyFor)\n\t\tmembers_child.create(specify_uri=True)\n\n\t\t# create /related child resource\n\t\trelated_child = PCDMRelatedContainer(\n\t\t\tself.repo,\n\t\t\t'%s/related' % self.uri_as_string(),\n\t\t\tmembershipResource=self.uri,\n\t\t\thasMemberRelation=self.rdf.prefixes.ore.aggregates,\n\t\t\tinsertedContentRelation=self.rdf.prefixes.ore.proxyFor)\n\t\trelated_child.create(specify_uri=True)\n\n\t\t# create /associated child resource\n\t\tassociated_child = PCDMAssociatedContainer(\n\t\t\tself.repo,\n\t\t\t'%s/associated' % self.uri_as_string(),\n\t\t\tmembershipResource=self.uri,\n\t\t\thasMemberRelation=self.rdf.prefixes.pcdm.hasRelatedFile)\n\t\tassociated_child.create(specify_uri=True)", "response": "create the object in the repository"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_members(self, retrieve=False):\n\n\t\t'''\n\t\tget pcdm:hasMember for this resource\n\n\t\tArgs:\n\t\t\tretrieve (bool): if True, issue .refresh() on resource thereby confirming existence and retrieving payload\n\t\t'''\n\n\t\tif self.exists and hasattr(self.rdf.triples, 'pcdm') and hasattr(self.rdf.triples.pcdm, 'hasMember'):\n\t\t\tmembers = [ self.repo.parse_uri(uri) for uri in self.rdf.triples.pcdm.hasMember ]\n\n\t\t\t# return\n\t\t\treturn members\n\n\t\telse:\n\t\t\treturn []", "response": "get members of this resource"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_files(self, retrieve=False):\n\n\t\t'''\n\t\tget pcdm:hasFile for this resource\n\n\t\tArgs:\n\t\t\tretrieve (bool): if True, issue .refresh() on resource thereby confirming existence and retrieving payload\n\t\t'''\n\n\t\tif self.exists and hasattr(self.rdf.triples, 'pcdm') and hasattr(self.rdf.triples.pcdm, 'hasFile'):\n\t\t\tfiles = [ self.repo.parse_uri(uri) for uri in self.rdf.triples.pcdm.hasFile ]\n\n\t\t\t# return\n\t\t\treturn files\n\n\t\telse:\n\t\t\treturn []", "response": "get the list of files in the resource"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the list of files that are associated with this resource", "response": "def get_associated(self, retrieve=False):\n\n\t\t'''\n\t\tget pcdm:hasRelatedFile for this resource\n\n\t\tArgs:\n\t\t\tretrieve (bool): if True, issue .refresh() on resource thereby confirming existence and retrieving payload\n\t\t'''\n\n\t\tif self.exists and hasattr(self.rdf.triples, 'pcdm') and hasattr(self.rdf.triples.pcdm, 'hasRelatedFile'):\n\t\t\tfiles = [ self.repo.parse_uri(uri) for uri in self.rdf.triples.pcdm.hasRelatedFile ]\n\n\t\t\t# return\n\t\t\treturn files\n\n\t\telse:\n\t\t\treturn []"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nhooks to create the resource.", "response": "def _post_create(self, auto_refresh=False):\n\n\t\t'''\n\t\tresource.create() hook\n\n\t\tFor PCDM File\n\t\t'''\n\n\t\t# set PCDM triple as Collection\n\t\tself.add_triple(self.rdf.prefixes.rdf.type, self.rdf.prefixes.pcdm.File)\n\t\tself.update(auto_refresh=auto_refresh)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nhooks the resource creation and update the object", "response": "def _post_create(self, auto_refresh=False):\n\n\t\t'''\n\t\tresource.create() hook\n\t\t'''\n\n\t\t# set rdf type\n\t\tself.add_triple(self.rdf.prefixes.rdf.type, self.rdf.prefixes.ore.Proxy)\n\n\t\t# set triple for what this resource is a proxy for\n\t\tif self.proxyForURI:\n\t\t\tself.add_triple(self.rdf.prefixes.ore.proxyFor, self.proxyForURI)\n\n\t\t# if proxyIn set, add triple\n\t\tif self.proxyInURI:\n\t\t\tself.add_triple(self.rdf.prefixes.ore.proxyFor, self.proxyForURI)\n\n\t\t# update\n\t\tself.update(auto_refresh=auto_refresh)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_variant_genotypes(self, variant):\n        # Find the variant in the bim.\n        try:\n            plink_chrom = CHROM_STR_TO_INT[variant.chrom.name]\n        except KeyError:\n            raise ValueError(\n                \"Invalid chromosome ('{}') for Plink.\".format(variant.chrom)\n            )\n\n        info = self.bim.loc[\n            (self.bim.chrom == plink_chrom) &\n            (self.bim.pos == variant.pos), :\n        ]\n\n        if info.shape[0] == 0:\n            logging.variant_not_found(variant)\n            return []\n\n        elif info.shape[0] == 1:\n            return self._get_biallelic_variant(variant, info)\n\n        else:\n            return self._get_multialleic_variant(variant, info)", "response": "Get the genotypes from a well formed variant instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef iter_genotypes(self):\n        # Iterating over all markers\n        for i, (_, genotypes) in enumerate(self.bed.iter_geno()):\n            info = self.bim.iloc[i, :]\n\n            yield Genotypes(\n                Variant(info.name, CHROM_INT_TO_STR[info.chrom],\n                        info.pos, [info.a1, info.a2]),\n                self._normalize_missing(genotypes),\n                reference=info.a2,\n                coded=info.a1,\n                multiallelic=info.multiallelic\n            )", "response": "Iterates over all available genotypes."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef iter_variants(self):\n        for idx, row in self.bim.iterrows():\n            yield Variant(\n                row.name, CHROM_INT_TO_STR[row.chrom], row.pos,\n                [row.a1, row.a2]\n            )", "response": "Iterate over all the variants in the BIM file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\niterate over variants in a region.", "response": "def get_variants_in_region(self, chrom, start, end):\n        \"\"\"Iterate over variants in a region.\"\"\"\n        bim = self.bim.loc[\n            (self.bim[\"chrom\"] == CHROM_STR_TO_INT[chrom]) &\n            (start <= self.bim[\"pos\"]) &\n            (self.bim[\"pos\"] <= end)\n        ]\n        for i, g in enumerate(self.bed.iter_geno_marker(bim.index)):\n            info = bim.iloc[i, :]\n            name, geno = g\n            yield Genotypes(\n                Variant(info.name, CHROM_INT_TO_STR[info.chrom],\n                        info.pos, [info.a1, info.a2]),\n                self._normalize_missing(geno),\n                reference=info.a2,\n                coded=info.a1,\n                multiallelic=info.multiallelic\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_variant_by_name(self, name):\n        # From 1.3.2 onwards, PyPlink sets unique names.\n        # Getting the genotypes\n        try:\n            geno, i = self.bed.get_geno_marker(name, return_index=True)\n\n        except ValueError:\n            if name in self.bed.get_duplicated_markers():\n                # The variant is a duplicated one, so we go through all the\n                # variants with the same name and the :dupx suffix\n                return [\n                    self.get_variant_by_name(dup_name).pop()\n                    for dup_name in self.bed.get_duplicated_markers()[name]\n                ]\n\n            else:\n                # The variant is not in the BIM file, so we return an empty\n                # list\n                logging.variant_name_not_found(name)\n                return []\n\n        else:\n            info = self.bim.iloc[i, :]\n            return [Genotypes(\n                Variant(info.name, CHROM_INT_TO_STR[info.chrom], info.pos,\n                        [info.a1, info.a2]),\n                self._normalize_missing(geno),\n                reference=info.a2,\n                coded=info.a1,\n                multiallelic=info.multiallelic,\n            )]", "response": "Get the genotype of a specific variant using it s name."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nnormalize a plink genotype vector to have missing values.", "response": "def _normalize_missing(g):\n        \"\"\"Normalize a plink genotype vector.\"\"\"\n        g = g.astype(float)\n        g[g == -1.0] = np.nan\n        return g"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef configs(max_configs=1, offset=None, serial=False, create_uuid=True):\n    global default_selector\n    return default_selector.configs(max_configs, offset, serial, create_uuid)", "response": "Generate max_configs configs in a sequence"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef maybe_download_and_extract():\n  dest_directory = \"/tmp/cifar\"\n  if not os.path.exists(dest_directory):\n    os.makedirs(dest_directory)\n  filename = DATA_URL.split('/')[-1]\n  filepath = os.path.join(dest_directory, filename)\n  if not os.path.exists(filepath):\n    def _progress(count, block_size, total_size):\n      sys.stdout.write('\\r>> Downloading %s %.1f%%' % (filename,\n          float(count * block_size) / float(total_size) * 100.0))\n      sys.stdout.flush()\n    filepath, _ = urllib.request.urlretrieve(DATA_URL, filepath, _progress)\n    print()\n    statinfo = os.stat(filepath)\n    print('Successfully downloaded', filename, statinfo.st_size, 'bytes.')\n    tarfile.open(filepath, 'r:gz').extractall(dest_directory)", "response": "Download and extract the tarball from Alex s website."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nplot a single CIFAR image.", "response": "def plot(config, image, file):\n    \"\"\" Plot a single CIFAR image.\"\"\"\n    image = np.squeeze(image)\n    print(file, image.shape)\n    imsave(file, image)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_seqtype_from_ext(handle):\n    '''Predict the filetype from a handle's name'''\n    if isinstance(handle, basestring):\n        name = handle\n    elif hasattr(handle, 'filename'):\n        name = handle.filename\n    elif hasattr(handle, 'name'):\n        name = handle.name\n    else:\n        raise ValueError(\"Unknown datatype for handle!\")\n\n    modifier = ''\n    dummy, ext = path.splitext(name.lower())\n    if ext == \".gz\":\n        modifier = 'gz-'\n        dummy, ext = path.splitext(dummy)\n\n    if not ext:\n        ext = \".\" + dummy\n\n    if ext in (\".gbk\", \".gb\", \".genbank\", \".gbff\"):\n        return modifier + \"genbank\"\n    elif ext in (\".embl\", \".emb\"):\n        return modifier + \"embl\"\n    elif ext in (\".fa\", \".fasta\", \".fna\", \".faa\", \".fas\"):\n        return modifier + \"fasta\"\n    else:\n        raise ValueError(\"Unknown file format '%s'.\" % ext)", "response": "Predict the filetype from a handle s name"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _guess_seqtype_from_file(handle):\n    \"Guess the sequence type from the file's contents\"\n    if isinstance(handle, basestring):\n        handle = StringIO(handle)\n\n    for line in handle:\n        if not line.strip():\n            continue\n        if line.lstrip().split()[0] in ('LOCUS', 'FEATURES', 'source', 'CDS',\n                                        'gene'):\n            return 'genbank'\n        if len(line) > 2 and line[:3] in ('ID ', 'FT '):\n            return 'embl'\n        if line.startswith('>'):\n            return 'fasta'\n    handle.seek(0)\n    import string\n    from Bio.Data import IUPACData as iupac\n    all_input_letters = set(handle.read().lower())\n    all_valid = set(string.digits)\n    all_valid.update(set(iupac.protein_letters.lower()))\n    all_valid.update(set(iupac.unambiguous_dna_letters.lower()))\n    all_valid.update(set('- \\n'))\n    if all_valid.issuperset(all_input_letters):\n        return 'fasta'\n\n    raise ValueError(\"Failed to guess format for input\")", "response": "Guess the sequence type from the file s contents"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _unzip_handle(handle):\n    if isinstance(handle, basestring):\n        handle = _gzip_open_filename(handle)\n    else:\n        handle = _gzip_open_handle(handle)\n    return handle", "response": "Transparently unzip the file handle"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _gzip_open_filename(handle):\n    import gzip\n    if sys.version_info[0] > 2:\n        handle = gzip.open(handle, mode='rt', encoding=\"UTF-8\")\n    else:\n        handle = gzip.open(handle)\n    return handle", "response": "Hide Python 2 vs. 3 differences in gzip. open"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nhiding Python 2 vs. 3 differences in gzip. GzipFile", "response": "def _gzip_open_handle(handle):\n    \"\"\"\"Hide Python 2 vs. 3 differences in gzip.GzipFile()\"\"\"\n    import gzip\n    if sys.version_info[0] > 2:\n        import io\n        handle = io.TextIOWrapper(gzip.GzipFile(fileobj=handle), encoding=\"UTF-8\")\n    else:\n        handle = gzip.GzipFile(fileobj=handle)\n    return handle"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sanity_check_insdcio(handle, id_marker, fake_id_line):\n    found_id = False\n    found_end_marker = False\n    for line in handle:\n        line = line.strip()\n        if not line:\n            continue\n        if line.startswith(id_marker):\n            found_id = True\n            break\n        if line.startswith('//'):\n            found_end_marker = True\n            break\n\n    handle.seek(0)\n    # We found an ID, file looks good.\n    if found_id:\n        return handle\n\n    # If there's no ID and no end marker, just give up.\n    if not found_end_marker:\n        return handle\n\n    # If we found an end marker but no ID, fake one.\n    new_handle = StringIO()\n    new_handle.write(\"%s\\n\" % fake_id_line)\n    new_handle.write(handle.read())\n    new_handle.seek(0)\n    return new_handle", "response": "Sanity check for insdcio style files"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sanity_check_fasta(handle):\n    header_found = False\n    for line in handle:\n        if line.startswith('>'):\n            header_found = True\n            break\n\n    handle.seek(0)\n\n    if header_found:\n        return handle\n\n    fake_header_line = \">DUMMY\"\n    new_handle = StringIO()\n    new_handle.write(\"%s\\n\" % fake_header_line)\n    new_handle.write(handle.read())\n    new_handle.seek(0)\n    return new_handle", "response": "Sanity check FASTA files."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse(handle, seqtype=None, robust=False):\n    '''Wrap SeqIO.parse'''\n    if seqtype is None:\n        seqtype = _get_seqtype_from_ext(handle)\n\n    if seqtype.startswith('gz-'):\n        handle = _unzip_handle(handle)\n        seqtype = seqtype[3:]\n\n    # False positive from pylint, both handles are fileobj-like\n    # pylint: disable=redefined-variable-type\n    if robust:\n        if seqtype == \"embl\":\n            handle = sanity_check_embl(handle)\n        elif seqtype == \"genbank\":\n            handle = sanity_check_genbank(handle)\n        elif seqtype == \"fasta\":\n            handle = sanity_check_fasta(handle)\n    # pylint: enable=redefined-variable-type\n\n    return SeqIO.parse(handle, seqtype)", "response": "Wrap SeqIO. parse to handle and return a new object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn whether the order of ports is fixed.", "response": "def isOrderFixed(self):\n        \"\"\"\n        Returns whether the order of ports is fixed.\n\n        @return true if the order of ports is fixed\n        \"\"\"\n        return (self == PortConstraints.FIXED_ORDER\n                or self == PortConstraints.FIXED_RATIO\n                or self == PortConstraints.FIXED_POS)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngiving a list of dictionaries with uniform keys returns a single Dictionary with keys holding a List of values matching the key in the original List.", "response": "def _dicts_to_columns(dicts):\n    \"\"\"\n    Given a List of Dictionaries with uniform keys, returns a single Dictionary\n    with keys holding a List of values matching the key in the original List.\n\n    [{'name': 'Field Museum', 'location': 'Chicago'},\n     {'name': 'Epcot', 'location': 'Orlando'}]\n      =>\n    {'name': ['Field Museum', 'Epcot'],\n     'location': ['Chicago', 'Orlando']}\n    \"\"\"\n    keys = dicts[0].keys()\n    result = dict((k, []) for k in keys)\n\n    for d in dicts:\n        for k, v in d.items():\n            result[k] += [v]\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a new IGraph instance from a list of vertices and edges.", "response": "def from_vertices_and_edges(vertices, edges, vertex_name_key='name', vertex_id_key='id',\n                            edge_foreign_keys=('source', 'target'), directed=True):\n    \"\"\"\n    This representation assumes that vertices and edges are encoded in\n    two lists, each list containing a Python dict for each vertex and\n    each edge, respectively. A distinguished element of the vertex dicts\n    contain a vertex ID which is used in the edge dicts to refer to\n    source and target vertices. All the remaining elements of the dicts\n    are considered vertex and edge attributes.\n\n    @param vertices: a list of dicts for the vertices.\n    @param edges: a list of dicts for the edges.\n    @param vertex_name_key: the name of the distinguished key in the dicts\n      in the vertex data source that contains the vertex names. Will also be used\n      as vertex label.\n    @param vertex_id_key: the name of the distinguished key in the dicts\n      in the vertex data source that contains a unique identifier for the vertex.\n    @param edge_foreign_keys: the name of the attributes in the dicts in C{edges}\n      that contain the source and target vertex names.\n    @return: IGraph instance with integers for vertex ids, edge sources, and edge targets.\n    \"\"\"\n    vertex_data = _dicts_to_columns(vertices)\n    edge_data = _dicts_to_columns(edges)\n    n = len(vertices)\n    vertex_index = dict(zip(vertex_data[vertex_id_key], range(n)))\n\n    # Iterate over `edges` to create `edge_list`, where every list item is a pair of integers.\n    edge_list = list(map(lambda source, target: (vertex_index[source], vertex_index[target]),\n                         edge_data[edge_foreign_keys[0]],\n                         edge_data[edge_foreign_keys[1]]))\n\n    g = IGraph(n=n, edges=edge_list, directed=directed, vertex_attrs=vertex_data, edge_attrs=edge_data)\n    g.vs['name'] = g.vs[vertex_name_key]\n    g.vs['indegree'] = g.degree(mode=\"in\")\n    g.vs['outdegree'] = g.degree(mode=\"out\")\n    g.vs['label'] = g.vs[vertex_name_key]\n    if 'group' not in g.vs.attributes():\n        g.vs['group'] = labels_to_groups(g.vs['label'])\n    return g"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngiving a list of Dictionaries with source target and weight attributes return a weighted directed graph.", "response": "def from_edges(edges, source_key='source', target_key='target', weight_key='weight', directed=True):\n    \"\"\"\n    Given a List of Dictionaries with source, target, and weight attributes, return a weighted, directed graph.\n    \"\"\"\n    raw = list(map(lambda x: [x[source_key], x[target_key], int(x[weight_key])], edges))\n    g = IGraph.TupleList(raw, weights=True, directed=directed)\n    g.vs['indegree'] = g.degree(mode=\"in\")\n    g.vs['outdegree'] = g.degree(mode=\"out\")\n    g.vs['label'] = g.vs['name']\n    if 'group' not in g.vs.attributes():\n        g.vs['group'] = labels_to_groups(g.vs['label'])\n    return g"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nflip the alleles of an Genotypes instance.", "response": "def flip_alleles(genotypes):\n    \"\"\"Flip the alleles of an Genotypes instance.\"\"\"\n    warnings.warn(\"deprecated: use 'Genotypes.flip_coded'\", DeprecationWarning)\n    genotypes.reference, genotypes.coded = (genotypes.coded,\n                                            genotypes.reference)\n    genotypes.genotypes = 2 - genotypes.genotypes\n    return genotypes"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef code_minor(genotypes):\n    warnings.warn(\"deprecated: use 'Genotypes.code_minor'\", DeprecationWarning)\n    _, minor_coded = maf(genotypes)\n    if not minor_coded:\n        return flip_alleles(genotypes)\n\n    return genotypes", "response": "Encode the genotypes with respect to the minor allele."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef maf(genotypes):\n    warnings.warn(\"deprecated: use 'Genotypes.maf'\", DeprecationWarning)\n    g = genotypes.genotypes\n    maf = np.nansum(g) / (2 * np.sum(~np.isnan(g)))\n    if maf > 0.5:\n        maf = 1 - maf\n        return maf, False\n\n    return maf, True", "response": "Computes the MAF and returns a boolean indicating if the minor allele\n    is currently the coded allele."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef genotype_to_df(g, samples, as_string=False):\n    name = g.variant.name if g.variant.name else \"genotypes\"\n    df = pd.DataFrame(g.genotypes, index=samples, columns=[name])\n\n    if as_string:\n        df[\"alleles\"] = None\n\n        hard_calls = df[name].round()\n        df.loc[hard_calls == 0, \"alleles\"] = \"{0}/{0}\".format(g.reference)\n        df.loc[hard_calls == 1, \"alleles\"] = \"{0}/{1}\".format(g.reference,\n                                                              g.coded)\n        df.loc[hard_calls == 2, \"alleles\"] = \"{0}/{0}\".format(g.coded)\n\n        df = df[[\"alleles\"]]\n        df.columns = [name]\n\n    return df", "response": "Convert a genotype object to a pandas dataframe."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef compute_ld(cur_geno, other_genotypes, r2=False):\n    # Normalizing the current genotypes\n    norm_cur = normalize_genotypes(cur_geno)\n\n    # Normalizing and creating the matrix for the other genotypes\n    norm_others = np.stack(\n        tuple(normalize_genotypes(g) for g in other_genotypes),\n        axis=1,\n    )\n\n    # Making sure the size is the same\n    assert norm_cur.shape[0] == norm_others.shape[0]\n\n    # Getting the number of \"samples\" per marker (taking into account NaN)\n    n = (\n        ~np.isnan(norm_cur.reshape(norm_cur.shape[0], 1)) *\n        ~np.isnan(norm_others)\n    ).sum(axis=0)\n\n    # Computing r (replacing NaN by 0)\n    r = pd.Series(\n        np.dot(\n            np.nan_to_num(norm_cur), np.nan_to_num(norm_others) / n\n        ),\n        index=[g.variant.name for g in other_genotypes],\n        name=\"r2\" if r2 else \"r\",\n    )\n\n    # Checking no \"invalid\" values (i.e. < -1 or > 1)\n    r.loc[r > 1] = 1\n    r.loc[r < -1] = -1\n\n    if r2:\n        return r ** 2\n    else:\n        return r", "response": "Compute the LD between a marker and a list of genotypes."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef normalize_genotypes(genotypes):\n    genotypes = genotypes.genotypes\n    return (genotypes - np.nanmean(genotypes)) / np.nanstd(genotypes)", "response": "Normalize the genotypes.\n\n    Args:\n        genotypes (Genotypes): The genotypes to normalize.\n\n    Returns:\n        numpy.array: The normalized genotypes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_tdm(self, m):\n        m = np.atleast_2d(m)\n        assert len(m.shape) == 2\n        tdm = crtomo.tdMan(grid=self.grid, tempdir=self.tempdir)\n        tdm.configs.add_to_configs(self.configs)\n\n        pid_mag = tdm.parman.add_data(m[0, :])\n        tdm.register_magnitude_model(pid_mag)\n        if m.shape[0] == 2:\n            pid_pha = tdm.parman.add_data(m[1, :])\n        else:\n            pid_pha = tdm.parman.add_data(np.zeros(m.shape[1]))\n        tdm.register_phase_model(pid_pha)\n        return tdm", "response": "Returns a tdMan instance for a given model."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncomputes a model response i. e. complex impedances of the next set of cells.", "response": "def forward_complex(self, log_sigma):\n        \"\"\"Compute a model response, i.e. complex impedances\n\n        Parameters\n        ----------\n        log_sigma : 1xN or 2xN numpy.ndarray\n            Model parameters log sigma, N the number of cells. If first\n            dimension is of length one, assume phase values to be zero\n\n        Returns\n        -------\n        measurements : Nx2 numpy nd array\n            Return log_e sigma values of computed forward response\n        \"\"\"\n        m = 1.0 / np.exp(log_sigma)\n        tdm = self._get_tdm(m)\n        measurements = tdm.measurements()\n        # import IPython\n        # IPython.embed()\n        # convert R to log sigma\n        measurements[:, 0] = np.log(1.0 / measurements[:, 0])\n        return measurements"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the sensitivity matrix for the current set of resources.", "response": "def J(self, log_sigma):\n        \"\"\"Return the sensitivity matrix\n\n        Parameters\n        ----------\n        log_sigma : numpy.ndarray\n            log_e conductivities\n\n        \"\"\"\n        m = 1.0 / np.exp(log_sigma)\n        tdm = self._get_tdm(m)\n\n        tdm.model(\n            sensitivities=True,\n            # output_directory=stage_dir + 'modeling',\n        )\n\n        measurements = tdm.measurements()\n\n        # build up the sensitivity matrix\n        sens_list = []\n        for config_nr, cids in sorted(\n                tdm.assignments['sensitivities'].items()):\n            sens_list.append(tdm.parman.parsets[cids[0]])\n\n        sensitivities_lin = np.array(sens_list)\n        # now convert to the log-sensitivities relevant for CRTomo and the\n        # resolution matrix\n        sensitivities_log = sensitivities_lin\n        # multiply measurements on first dimension\n        measurements_rep = np.repeat(\n            measurements[:, 0, np.newaxis],\n            sensitivities_lin.shape[1],\n            axis=1)\n        # sensitivities_log = sensitivities_log * mfit\n\n        # multiply resistivities on second dimension\n        m_rep = np.repeat(\n            m[np.newaxis, :], sensitivities_lin.shape[0], axis=0\n        )\n\n        # eq. 3.41 in Kemna, 2000: notice that m_rep here is in rho, not sigma\n        factor = - 1 / (m_rep * measurements_rep)\n        sensitivities_log = factor * sensitivities_lin\n\n#         import IPython\n#         IPython.embed()\n\n        return sensitivities_log"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef generate(bits, progress_func=None):\n        rsa = RSA.generate(bits, os.urandom, progress_func)\n        key = RSAKey(vals=(rsa.e, rsa.n))\n        key.d = rsa.d\n        key.p = rsa.p\n        key.q = rsa.q\n        return key", "response": "This factory function can be used to generate a new private RSA key."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _pkcs1imify(self, data):\n        size = len(util.deflate_long(self.n, 0))\n        filler = max_byte * (size - len(SHA1_DIGESTINFO) - len(data) - 3)\n        return zero_byte + one_byte + filler + zero_byte + SHA1_DIGESTINFO + data", "response": "Convert a 20 - byte SHA1 hash into a blob of data as large as the key s N using PKCS1 s EMA - PKCS1 - v1_5 encoding."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmapping a list of Ironic UUID to BM nodes.", "response": "def set_ironic_uuid(self, uuid_list):\n        \"\"\"Map a list of Ironic UUID to BM nodes.\n        \"\"\"\n        # TODO(Gon\u00e9ri): ensure we adjust the correct node\n        i = iter(self.nodes)\n        for uuid in uuid_list:\n            node = next(i)\n            node.uuid = uuid"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef find_resistance(record):\n    for feature in record.features:\n        labels = set(feature.qualifiers.get(\"label\", []))\n        cassettes = labels.intersection(_ANTIBIOTICS)\n        if len(cassettes) > 1:\n            raise RuntimeError(\"multiple resistance cassettes detected\")\n        elif len(cassettes) == 1:\n            return _ANTIBIOTICS.get(cassettes.pop())\n    raise RuntimeError(\"could not find the resistance of '{}'\".format(record.id))", "response": "Infer the antibiotics resistance of the given record."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get(self, resource_endpoint, query_params={}):\n        url = self._create_request_url(resource_endpoint)\n        if query_params:\n            return req.get(url, headers=self.auth_header, params=query_params)\n        else:\n            return req.get(url, headers=self.auth_header)", "response": "Don t use it."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndonning t use it.", "response": "def post(self, resource_endpoint, data={}, files=None):\n        \"\"\"Don't use it.\"\"\"\n        url = self._create_request_url(resource_endpoint)\n        if files:\n            data = self._prepare_params_for_file_upload(data)\n            return req.post(url, headers=self.auth_header, files=files, data=data)\n        else:\n            return req.post(url, headers=self.auth_header, json=data)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndon t use it.", "response": "def patch(self, resource_endpoint, data={}):\n        \"\"\"Don't use it.\"\"\"\n        url = self._create_request_url(resource_endpoint)\n        return req.patch(url, headers=self.auth_header, json=data)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef reverse_complement(\n        self,\n        id=False,\n        name=False,\n        description=False,\n        features=True,\n        annotations=False,\n        letter_annotations=True,\n        dbxrefs=False,\n    ):\n        \"\"\"Return a new ``CircularRecord`` with reverse complement sequence.\n        \"\"\"\n        return type(self)(\n            super(CircularRecord, self).reverse_complement(\n                id=id,\n                name=name,\n                description=description,\n                features=features,\n                annotations=annotations,\n                letter_annotations=letter_annotations,\n                dbxrefs=dbxrefs,\n            )\n        )", "response": "Returns a new instance of the class with reverse complement sequence."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nregisters the SSH private key.", "response": "def load_private_key(self, priv_key):\n        \"\"\"Register the SSH private key.\"\"\"\n        with open(priv_key) as fd:\n            self._private_key = paramiko.RSAKey.from_private_key(fd)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef start(self):\n        if self.via_ip:\n            connect_to = self.via_ip\n            self.description = '[%s@%s via %s]' % (self._user,\n                                                   self._hostname,\n                                                   self.via_ip)\n        else:\n            connect_to = self._hostname\n            self.description = '[%s@%s]' % (self._user,\n                                            self._hostname)\n\n        exception = None\n        for i in range(60):\n            try:\n                self._client.connect(\n                    connect_to,\n                    username=self._user,\n                    allow_agent=True,\n                    key_filename=self._key_filename)\n            # NOTE(Gon\u00e9ri): TypeError is in the list because of\n            # https://github.com/paramiko/paramiko/issues/615\n                self._transport = self._get_transport()\n            except (OSError,\n                    TypeError,\n                    ssh_exception.SSHException,\n                    ssh_exception.NoValidConnectionsError) as e:\n                exception = e\n                LOG.info('%s waiting for %s: %s' %\n                         (self.description, connect_to, str(exception)))\n                time.sleep(1)\n            else:\n                LOG.debug('%s connected' % self.description)\n                self._started = True\n                return\n\n        _error = (\"unable to connect to ssh service on '%s': %s\" %\n                  (self._hostname, str(exception)))\n        LOG.error(_error)\n        raise exception", "response": "Start the ssh client and connect to the host."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nruns a command on the remote host.", "response": "def run(self, cmd, sudo=False, ignore_error=False, success_status=(0,),\n            error_callback=None, custom_log=None, retry=0):\n        \"\"\"Run a command on the remote host.\n\n        The command is run on the remote host, if there is a redirected host\n        then the command will be run on that redirected host. See __init__.\n\n        :param cmd: the command to run\n        :type cmd: str\n        :param sudo: True if the command should be run with sudo, this parameter\n        disable the use of environment files.\n        :type sudo: str\n        :param success_status: the list of the possible success status\n        :type success_status: list\n        :param error_callback: if provided, the callback to call in case of\n        a failure. it will be called with two args, the output of the command\n        and the returned error code.\n        :return: the tuple (output of the command, returned code)\n        :rtype: tuple\n        :param custom_log: a optional string to record in the log instead of the command.\n        This is useful for example if you want to hide a password.\n        :type custom_log: str\n        \"\"\"\n        self._check_started()\n        cmd_output = io.StringIO()\n        channel = self._get_channel()\n        cmd = self._prepare_cmd(cmd, sudo=sudo)\n\n        if not custom_log:\n            custom_log = cmd\n        LOG.info(\"%s run '%s'\" % (self.description, custom_log))\n        channel.exec_command(cmd)\n\n        while True:\n            received = None\n            rl, _, _ = select.select([channel], [], [], 30)\n            if rl:\n                received = channel.recv(1024).decode('UTF-8', 'ignore').strip()\n                if received:\n                    LOG.debug(received)\n                    cmd_output.write(received)\n            if channel.exit_status_ready() and not received:\n                break\n        cmd_output = cmd_output.getvalue()\n        exit_status = channel.exit_status\n        try:\n            return self._evaluate_run_result(\n                exit_status, cmd_output, ignore_error=ignore_error,\n                success_status=success_status, error_callback=error_callback,\n                custom_log=custom_log)\n        except (paramiko.ssh_exception.SSHException, socket.error) as e:\n            if not retry:\n                raise e\n            else:\n                return self.run(\n                    cmd, sudo=sudo, ignore_error=ignore_error,\n                    success_status=success_status,\n                    error_callback=error_callback, custom_log=custom_log,\n                    retry=(retry - 1))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_channel(self):\n        channel = self._transport.open_session()\n        channel.set_combine_stderr(True)\n        channel.get_pty()\n        return channel", "response": "Returns a channel according to if there is a redirection to do or\n        not."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef send_file(self, local_path, remote_path, unix_mode=None):\n        self._check_started()\n        sftp = paramiko.SFTPClient.from_transport(self._transport)\n        sftp.put(local_path, remote_path)\n        if unix_mode:\n            sftp.chmod(remote_path, unix_mode)", "response": "Send a file to the remote host."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsends a directory to the remote host.", "response": "def send_dir(self, local_path, remote_path):\n        \"\"\"Send a directory to the remote host.\n        :param local_path: the local path of the directory\n        :type local_path: str\n        :param remote_path: the remote path of the directory\n        :type remote_path: str\n        :return: the file attributes\n        :rtype: paramiko.sftp_attr.SFTPAttributes\n        \"\"\"\n        directory, parent = os.path.split(local_path)\n        os.chdir(directory)\n        self._check_started()\n        sftp = paramiko.SFTPClient.from_transport(self._transport)\n        for walker in os.walk(parent):\n            try:\n                sftp.mkdir(os.path.join(remote_path, walker[0]))\n            except Exception:\n                LOG.info('directory %s exists' % walker[0])\n            for file in walker[2]:\n                sftp.put(os.path.join(walker[0], file),\n                         os.path.join(remote_path, walker[0], file))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a file with a content.", "response": "def create_file(self, path, content, mode='w'):\n        \"\"\"Create a file with a content.\n        :param path: the path of the file.\n        :type path: str\n        :param content: the content of the file\n        :type content: str\n        :param mode: the mode of the file while opening it\n        :type mode: str\n        \"\"\"\n        self._check_started()\n        sftp = paramiko.SFTPClient.from_transport(self._transport)\n        with sftp.open(path, mode) as remote_file:\n            remote_file.write(content)\n            remote_file.flush()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_grid(key):\n    rbase = grid_files[key]\n    elem_file = pk.resource_filename('crtomo', rbase['elem'])\n    elec_file = pk.resource_filename('crtomo', rbase['elec'])\n\n    grid = CRGrid.crt_grid(elem_file=elem_file, elec_file=elec_file)\n    return grid", "response": "Return a crtomo. grid. crt_grid instance that contains the specified key."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef readline(self, timeout):\n        buf = self.__remainder\n        while not linefeed_byte in buf:\n            buf += self._read_timeout(timeout)\n        n = buf.index(linefeed_byte)\n        self.__remainder = buf[n + 1:]\n        buf = buf[:n]\n        if (len(buf) > 0) and (buf[-1] == cr_byte_value):\n            buf = buf[:-1]\n        return u(buf)", "response": "Read a line from the socket."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a new bitfield class from a list of fields and a type of the underlying register.", "response": "def make_bf(name, fields, basetype=c_uint32, doc=None):\n    \"\"\"\n    Create a new Bitfield class, correctly assigning the anonymous\n    fields from the Union in order to get the desired behavior.\n    \n    Parameters::\n    \n        name\n            The name of the class.  This is similar to the namedtuple\n            recipe, in that you'll generally pass the same name here as\n            a string that you do in defining the class itself.\n            \n        fields\n            A list of fields.  Fields are in order from the LSB of the\n            underlying register, and must be 3-tuples of the form::\n            \n                ('fieldname', fieldtype, bits),\n                ('such_as', c_uint, 5),\n                ('this', c_int, 3)\n                \n            fieldtypes should be either c_uint, c_int, or c_bool.  make_bf\n            takes care of any sizing requirements appropriately.\n                \n        basetype\n            The type of the underlying register.  This should usually be an\n            explicit size variant of c_uint, such as a c_uint32.\n            \n        doc\n            The optional docstring for the newly created class.\n    \n    \"\"\"\n    # We need to hack on the fields array to get our integer sizes correct.\n    unsigned_types = [c_uint8, c_uint16, c_uint32, c_uint64]\n    signed_types = [c_int8, c_int16, c_int32, c_int64]\n    \n    unsigned    = next(t for t in unsigned_types if sizeof(t) >= sizeof(basetype))\n    signed      = next(t for t in signed_types if sizeof(t) >= sizeof(basetype))\n    \n    def fixed_type(t):\n        if t in unsigned_types:\n            return unsigned\n        elif t in signed_types:\n            return signed\n        elif t is c_bool:\n            return unsigned\n        else:\n            try:\n                raise TypeError(\"Field of type {0} not allowed, only integer and boolean types.\".format(t.__name__))\n            except AttributeError:\n                raise TypeError(\"{0!r} not a class.\".format(t))\n    \n    fields = [ (name, fixed_type(cls), size) for (name, cls, size) in fields ]\n\n    # Define the underlying bitfield type\n    bitfield = type(name + '_bitfield', (LittleEndianStructure, ), {})\n    bitfield._fields_ = fields\n    bitfield._pack_ = 1\n    \n    # Set up the docstring\n    if doc is None:\n        doc = _docstring_template.format(\n            name = name,\n            base = basetype.__name__\n        )\n        namewidth = max(len(t[0]) for t in fields)\n        doc += ''.join(\n            _docstring_field_template.format(\n                name = t[0],\n                nw = namewidth,\n                base = t[1].__name__,\n                n = t[2]\n            ) for t in fields\n        )\n\n    # Set up the union\n    d = {\n        '_fields_' : [('base', basetype), ('_b', bitfield)],\n        '__doc__' : doc\n    }\n    return type(name, (Union, Bitfield), d)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprints all the fields of a Bitfield object to stdout.", "response": "def print_fields(bf, *args, **kwargs):\n    \"\"\"\n    Print all the fields of a Bitfield object to stdout.  This is\n    primarly a diagnostic aid during debugging.\n    \"\"\"\n    \n    vals = {k: hex(v) for k, v in bf.items()}\n    print(bf.base, vals, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a new bitfield with the same value.", "response": "def clone(self):\n        \"\"\"Return a new bitfield with the same value.\n        \n        The returned value is a copy, and so is no longer linked to the\n        original bitfield.  This is important when the original is located\n        at anything other than normal memory, with accesses to it either\n        slow or having side effects.  Creating a clone, and working\n        against that clone, means that only one read will occur.\n        \n        \"\"\"\n        temp = self.__class__()\n        temp.base = self.base\n        return temp"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef items(self):\n        temp = self.clone()\n        return [(f, getattr(temp, f)) for f in iter(self)]", "response": "Returns an iterator over the named bitfields in the structure as\n        2 - tuples of ( key value )."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update(self, E=None, **F):\n        '''\n        D.update([E, ]**F) -> None\n        Update the bitfield from dict/iterable E and F.\n        If E present and has a .keys() method, does:   for k in E: D.k = E[k]\n        If E present and lacks .keys() method, does:   for (k, v) in E: D.k = v\n        In either case, this is followed by:           for k in F: D.k = F[k]\n        \n        The entire update is applied in a single read and a single write, \n        in case the target is a memory-mapped register.  The read and write\n        are independent, rather than an atomic RMW cycle.\n        \n        '''\n        \n        temp = self.clone()\n        if E:\n            try:\n                for k in E.keys():\n                    setattr(temp, k, E[k])\n            except (AttributeError, ValueError):\n                for k, v in E:\n                    setattr(temp, k, v)\n                    \n        for k, v in F.items():\n            setattr(temp, k, v)\n            \n        self.base = temp.base", "response": "Update the bitfield from dict E and F."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _normalize_tabular_data(tabular_data, headers):\n\n    if hasattr(tabular_data, \"keys\") and hasattr(tabular_data, \"values\"):\n        # dict-like and pandas.DataFrame?\n        if hasattr(tabular_data.values, \"__call__\"):\n            # likely a conventional dict\n            keys = tabular_data.keys()\n            rows = list(izip_longest(*tabular_data.values()))  # columns have to be transposed\n        elif hasattr(tabular_data, \"index\"):\n            # values is a property, has .index => it's likely a pandas.DataFrame (pandas 0.11.0)\n            keys = tabular_data.keys()\n            vals = tabular_data.values  # values matrix doesn't need to be transposed\n            names = tabular_data.index\n            rows = [[v]+list(row) for v,row in zip(names, vals)]\n        else:\n            raise ValueError(\"tabular data doesn't appear to be a dict or a DataFrame\")\n\n        if headers == \"keys\":\n            headers = list(map(_text_type,keys))  # headers should be strings\n\n    else:  # it's a usual an iterable of iterables, or a NumPy array\n        rows = list(tabular_data)\n\n        if (headers == \"keys\" and\n            hasattr(tabular_data, \"dtype\") and\n            getattr(tabular_data.dtype, \"names\")):\n            # numpy record array\n            headers = tabular_data.dtype.names\n        elif (headers == \"keys\"\n              and len(rows) > 0\n              and isinstance(rows[0], tuple)\n              and hasattr(rows[0], \"_fields\")): # namedtuple\n            headers = list(map(_text_type, rows[0]._fields))\n        elif headers == \"keys\" and len(rows) > 0:  # keys are column indices\n            headers = list(map(_text_type, range(len(rows[0]))))\n\n    # take headers from the first row if necessary\n    if headers == \"firstrow\" and len(rows) > 0:\n        headers = list(map(_text_type, rows[0])) # headers should be strings\n        rows = rows[1:]\n\n    headers = list(headers)\n    rows = list(map(list,rows))\n\n    # pad with empty headers for initial columns if necessary\n    if headers and len(rows) > 0:\n       nhs = len(headers)\n       ncols = len(rows[0])\n       if nhs < ncols:\n           headers = [\"\"]*(ncols - nhs) + headers\n\n    return rows, headers", "response": "Transform a supported data type to a list of lists and a list of headers."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding the list of new paths in this comparison.", "response": "def new(self, base: pathlib.PurePath = pathlib.PurePath(),\n            include_intermediates: bool = True) -> Iterator[str]:\n        \"\"\"\n        Find the list of new paths in this comparison.\n\n        :param base: The base directory to prepend to the right entity's name.\n        :param include_intermediates: Whether to include new non-empty\n                                      directories in the returned iterable. If\n                                      you only care about files, or are using\n                                      flat key-based storage system like S3\n                                      where directories are a made-up concept,\n                                      this can be set to false.\n        :return: An iterator of the new paths.\n        \"\"\"\n        if self.is_new:\n            yield str(base / self.right.name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef modified(self, base: pathlib.PurePath = pathlib.PurePath()) \\\n            -> Iterator[str]:\n        \"\"\"\n        Find the paths of modified files. There is no option to include\n        intermediate directories, as all files and directories exist in both\n        the left and right trees.\n\n        :param base: The base directory to recursively append to the right\n                     entity.\n        :return: An iterable of paths of modified files.\n        \"\"\"\n        # N.B. this method will only ever return files, as directories cannot\n        # be \"modified\"\n        if self.is_modified:\n            yield str(base / self.right.name)", "response": "Find the paths of modified files in both the left and right trees."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfinds the paths of deleted entities between the left and right entities.", "response": "def deleted(self, base: pathlib.PurePath = pathlib.PurePath(),\n                include_children: bool = True,\n                include_directories: bool = True) -> Iterator[str]:\n        \"\"\"\n        Find the paths of entities deleted between the left and right entities\n        in this comparison.\n\n        :param base: The base directory to recursively append to entities.\n        :param include_children: Whether to recursively include children of\n                                 deleted directories. These are themselves\n                                 deleted by definition, however it may be\n                                 useful to the caller to list them explicitly.\n        :param include_directories: Whether to include directories in the\n                                    returned iterable.\n        :return: An iterable of deleted paths.\n        \"\"\"\n        if self.is_deleted:\n            yield str(base / self.left.name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate the comparison of two entities.", "response": "def compare(left: Optional[L], right: Optional[R]) -> 'Comparison[L, R]':\n        \"\"\"\n        Calculate the comparison of two entities.\n\n        | left      | right     | Return Type             |\n        |===========|===========|=========================|\n        | file      | file      | FileComparison          |\n        | file      | directory | FileDirectoryComparison |\n        | file      | None      | FileComparison          |\n        | directory | file      | DirectoryFileComparison |\n        | directory | directory | DirectoryComparison     |\n        | directory | None      | DirectoryComparison     |\n        | None      | file      | FileComparison          |\n        | None      | directory | DirectoryComparison     |\n        | None      | None      | TypeError               |\n\n        :param left: The left side or \"before\" entity.\n        :param right: The right side or \"after\" entity.\n        :return: See table above.\n        \"\"\"\n        if isinstance(left, File) and isinstance(right, Directory):\n            return FileDirectoryComparison(left, right)\n\n        if isinstance(left, Directory) and isinstance(right, File):\n            return DirectoryFileComparison(left, right)\n\n        if isinstance(left, File) or isinstance(right, File):\n            return FileComparison(left, right)\n\n        if isinstance(left, Directory) or isinstance(right, Directory):\n            return DirectoryComparison(left, right)\n\n        raise TypeError(f'Cannot compare entities: {left}, {right}')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef print_hierarchy(self, level: int = 0, file: IO[str] = sys.stdout) \\\n            -> None:\n        \"\"\"\n        Print this comparison and its children with indentation to represent\n        nesting.\n\n        :param level: The level of indentation to use. This is mostly for\n                      internal use, but you can use it to inset the root\n                      comparison.\n        :param file: The stream to print to. Defaults to stdout.\n        \"\"\"\n        print(' ' * self._INDENT_SIZE * level + str(self), file=file)", "response": "Print this comparison and its children with indentation to represent the root\n                     ."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn whether the file on the left and right are different.", "response": "def is_modified(self) -> bool:\n        \"\"\"\n        Find whether the files on the left and right are different. Note,\n        modified implies the contents of the file have changed, which is\n        predicated on the file existing on both the left and right. Therefore\n        this will be false if the file on the left has been deleted, or the\n        file on the right is new.\n\n        :return: Whether the file has been modified.\n        \"\"\"\n        if self.is_new or self.is_deleted:\n            return False\n        return self.left.md5 != self.right.md5"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef generate_index(fn, cols=None, names=None, sep=\" \"):\n    # Some assertions\n    assert cols is not None, \"'cols' was not set\"\n    assert names is not None, \"'names' was not set\"\n    assert len(cols) == len(names)\n\n    # Getting the open function\n    bgzip, open_func = get_open_func(fn, return_fmt=True)\n\n    # Reading the required columns\n    data = pd.read_csv(fn, sep=sep, engine=\"c\", usecols=cols, names=names,\n                       compression=\"gzip\" if bgzip else None)\n\n    # Getting the seek information\n    f = open_func(fn, \"rb\")\n    data[\"seek\"] = np.fromiter(_seek_generator(f), dtype=np.uint)[:-1]\n    f.close()\n\n    # Saving the index to file\n    write_index(get_index_fn(fn), data)\n\n    return data", "response": "Builds a index for the given file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the opening function.", "response": "def get_open_func(fn, return_fmt=False):\n    \"\"\"Get the opening function.\n\n    Args:\n        fn (str): the name of the file.\n        return_fmt (bool): if the file format needs to be returned.\n\n    Returns:\n        tuple: either a tuple containing two elements: a boolean telling if the\n        format is bgzip, and the opening function.\n\n    \"\"\"\n    # The file might be compressed using bgzip\n    bgzip = None\n    with open(fn, \"rb\") as i_file:\n        bgzip = i_file.read(3) == b\"\\x1f\\x8b\\x08\"\n\n    if bgzip and not HAS_BIOPYTHON:\n        raise ValueError(\"needs BioPython to index a bgzip file\")\n\n    open_func = open\n    if bgzip:\n        open_func = BgzfReader\n\n    # Trying to read\n    try:\n        with open_func(fn, \"r\") as i_file:\n            if bgzip:\n                if not i_file.seekable():\n                    raise ValueError\n            pass\n\n    except ValueError:\n        raise ValueError(\"{}: use bgzip for compression...\".format(fn))\n\n    if return_fmt:\n        return bgzip, open_func\n\n    return open_func"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_index(fn, cols, names, sep):\n    if not has_index(fn):\n        # The index doesn't exists, generate it\n        return generate_index(fn, cols, names, sep)\n\n    # Retrieving the index\n    file_index = read_index(get_index_fn(fn))\n\n    # Checking the names are there\n    if len(set(names) - (set(file_index.columns) - {'seek'})) != 0:\n        raise ValueError(\"{}: missing index columns: reindex\".format(fn))\n\n    if \"seek\" not in file_index.columns:\n        raise ValueError(\"{}: invalid index: reindex\".format(fn))\n\n    return file_index", "response": "Restores the index for a given file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef write_index(fn, index):\n    with open(fn, \"wb\") as o_file:\n        o_file.write(_CHECK_STRING)\n        o_file.write(zlib.compress(bytes(\n            index.to_csv(None, index=False, encoding=\"utf-8\"),\n            encoding=\"utf-8\",\n        )))", "response": "Writes the index to file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read_index(fn):\n    index = None\n    with open(fn, \"rb\") as i_file:\n        if i_file.read(len(_CHECK_STRING)) != _CHECK_STRING:\n            raise ValueError(\"{}: not a valid index file\".format(fn))\n\n        index = pd.read_csv(io.StringIO(\n            zlib.decompress(i_file.read()).decode(encoding=\"utf-8\"),\n        ))\n\n    return index", "response": "Reads index from file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef make_path(phase) -> str:\n    return \"{}/{}{}{}\".format(conf.instance.output_path, phase.phase_path, phase.phase_name, phase.phase_tag)", "response": "Create the path to the folder where the metadata and optimizer pickle should be saved"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef save_optimizer_for_phase(phase):\n    with open(make_optimizer_pickle_path(phase), \"w+b\") as f:\n        f.write(pickle.dumps(phase.optimizer))", "response": "Save the optimizer associated with the phase as a pickle\n       "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef assert_optimizer_pickle_matches_for_phase(phase):\n    path = make_optimizer_pickle_path(phase)\n    if os.path.exists(path):\n        with open(path, \"r+b\") as f:\n            loaded_optimizer = pickle.loads(f.read())\n            if phase.optimizer != loaded_optimizer:\n                raise exc.PipelineException(\n                    f\"Can't restart phase at path {path} because settings don't match. \"\n                    f\"Did you change the optimizer settings or model?\")", "response": "Assert that the previously saved optimizer is equal to the phase s optimizer."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add(self, phase_name, result):\n        if phase_name in self.__result_dict:\n            raise exc.PipelineException(\n                \"Results from a phase called {} already exist in the pipeline\".format(phase_name))\n        self.__result_list.append(result)\n        self.__result_dict[phase_name] = result", "response": "Adds the result of a phase."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the result of a previous phase by its name.", "response": "def from_phase(self, phase_name):\n        \"\"\"\n        Returns the result of a previous phase by its name\n\n        Parameters\n        ----------\n        phase_name: str\n            The name of a previous phase\n\n        Returns\n        -------\n        result: Result\n            The result of that phase\n\n        Raises\n        ------\n        exc.PipelineException\n            If no phase with the expected result is found\n        \"\"\"\n        try:\n            return self.__result_dict[phase_name]\n        except KeyError:\n            raise exc.PipelineException(\"No previous phase named {} found in results ({})\".format(phase_name, \", \".join(\n                self.__result_dict.keys())))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef save_metadata(self, phase, data_name):\n        with open(\"{}/.metadata\".format(make_path(phase)), \"w+\") as f:\n            f.write(\"pipeline={}\\nphase={}\\ndata={}\".format(self.pipeline_name, phase.phase_name,\n                                                            data_name))", "response": "Save the metadata associated with the given phase."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrunning the function for each phase in the pipeline and returns the results for that phase.", "response": "def run_function(self, func, data_name=None, assert_optimizer_pickle_matches=True):\n        \"\"\"\n        Run the function for each phase in the pipeline.\n\n        Parameters\n        ----------\n        assert_optimizer_pickle_matches\n        data_name\n        func\n            A function that takes a phase and prior results, returning results for that phase\n\n        Returns\n        -------\n        results: ResultsCollection\n            A collection of results\n        \"\"\"\n        results = ResultsCollection()\n        for i, phase in enumerate(self.phases):\n            logger.info(\"Running Phase {} (Number {})\".format(phase.optimizer.phase_name, i))\n            if assert_optimizer_pickle_matches:\n                assert_optimizer_pickle_matches_for_phase(phase)\n            save_optimizer_for_phase(phase)\n            self.save_metadata(phase, data_name)\n            results.add(phase.phase_name, func(phase, results))\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef strtobytes(input, encoding):\n    py_version = sys.version_info[0]\n    if py_version >= 3:\n        return _strtobytes_py3(input, encoding)\n    return _strtobytes_py2(input, encoding)", "response": "Take a str and transform it into a byte array."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef index_impute2(fn):\n    logger.info(\"Indexing {} (IMPUTE2)\".format(fn))\n    impute2_index(fn, cols=[0, 1, 2], names=[\"chrom\", \"name\", \"pos\"], sep=\" \")\n    logger.info(\"Index generated\")", "response": "Indexes an IMPUTE2 file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nindexing a BGEN file.", "response": "def index_bgen(fn, legacy=False):\n    \"\"\"Indexes a BGEN file.\n\n    Args:\n        fn (str): The name of the BGEN file.\n\n    \"\"\"\n    logger.info(\"Indexing {} (BGEN) using 'bgenix'{}\".format(\n        fn, \" (legacy mode)\" if legacy else \"\",\n    ))\n    command = [\"bgenix\", \"-g\", fn, \"-index\"]\n    if legacy:\n        command.append(\"-with-rowid\")\n    try:\n        logger.info(\"Executing '{}'\".format(\" \".join(command)))\n        subprocess.Popen(command).communicate()\n    except FileNotFoundError:\n        logger.error(\"Cannot find 'bgenix', impossible to index {}\".format(fn))\n        sys.exit(1)\n    logger.info(\"Index generated\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_args():\n    parser = argparse.ArgumentParser(\n        prog=\"geneparse-indexer\",\n        description=\"Genotype file indexer.\"\n    )\n\n    # IMPUTE2 files\n    group = parser.add_argument_group(\"IMPUTE2 index\")\n    group.add_argument(\n        \"--impute2\", metavar=\"IMPUTE2\", type=str, nargs=\"+\",\n        help=\"Index an IMPUTE2 genotype file format. The file can be plain \"\n             \"text or bgzipped.\",\n    )\n\n    # BGEN files\n    group = parser.add_argument_group(\"BGEN index\")\n    group.add_argument(\n        \"--bgen\", metavar=\"BGEN\", type=str, nargs=\"+\",\n        help=\"Index a BGEN genotype file. This requires 'bgenix' to be in the \"\n             \"PATH.\",\n    )\n    group.add_argument(\n        \"--legacy\", action=\"store_true\",\n        help=\"Index the file using the '-with-rowid' option. This flag \"\n             \"enables compatibility with SQLITE prior to version 3.8.2. See \"\n             \"https://bitbucket.org/gavinband/bgen/wiki/bgenix for more \"\n             \"information.\",\n    )\n\n    return parser.parse_args()", "response": "Parses the arguments and options."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_untl_xml_subelement(parent, element, prefix=''):\n    subelement = SubElement(parent, prefix + element.tag)\n    if element.content is not None:\n        subelement.text = element.content\n    if element.qualifier is not None:\n        subelement.attrib[\"qualifier\"] = element.qualifier\n    if element.children > 0:\n        for child in element.children:\n            SubElement(subelement, prefix + child.tag).text = child.content\n    else:\n        subelement.text = element.content\n\n    return subelement", "response": "Create a UNTL XML subelement."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_missing_children(required_children, element_children):\n    element_tags = [element.tag for element in element_children]\n    # Loop through the elements that should be in the form.\n    for contained_element in required_children:\n        # If the element doesn't exist in the form,\n        # add the element to the children.\n        if contained_element not in element_tags:\n            try:\n                added_child = PYUNTL_DISPATCH[contained_element](content='')\n            except:\n                added_child = PYUNTL_DISPATCH[contained_element]()\n            element_children.append(added_child)\n    return element_children", "response": "Determine if there are elements not in the children\n    that need to be included as blank elements in the form."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_qualifier(self, value):\n        if self.allows_qualifier:\n            self.qualifier = value.strip()\n        else:\n            raise UNTLStructureException(\n                'Element \"%s\" does not allow a qualifier' % (self.tag,)\n            )", "response": "Sets the qualifier for the element."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a child object to the current one.", "response": "def add_child(self, child):\n        \"\"\"Add a child object to the current one.\n\n        Checks the contained_children list to make sure that the object\n        is allowable, and throws an exception if not.\n        \"\"\"\n        if child.tag in self.contained_children:\n            self.children.append(child)\n        else:\n            raise UNTLStructureException(\n                'Invalid child \"%s\" for parent \"%s\"' % (\n                    child.tag,\n                    self.tag\n                )\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the textual content for the object.", "response": "def set_content(self, content):\n        \"\"\"Set textual content for the object/node.\n\n        Verifies the node is allowed to contain content, and throws an\n        exception if not.\n        \"\"\"\n        if self.allows_content:\n            self.content = content.strip()\n        else:\n            raise UNTLStructureException(\n                'Element \"%s\" does not allow textual content' % (self.tag,)\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd the form attribute to the UNTL Python object.", "response": "def add_form(self, **kwargs):\n        \"\"\"Add the form attribute to the UNTL Python object.\"\"\"\n        vocabularies = kwargs.get('vocabularies', None)\n        qualifier = kwargs.get('qualifier', None)\n        content = kwargs.get('content', None)\n        parent_tag = kwargs.get('parent_tag', None)\n        superuser = kwargs.get('superuser', False)\n        # Element has both the qualifier and content.\n        if qualifier is not None and content is not None:\n            # Create the form attribute.\n            self.form = UNTL_FORM_DISPATCH[self.tag](\n                vocabularies=vocabularies,\n                qualifier_value=qualifier,\n                input_value=content,\n                untl_object=self,\n                superuser=superuser,\n            )\n        # Element just has a qualifier.\n        elif qualifier is not None:\n            # Create the form attribute.\n            self.form = UNTL_FORM_DISPATCH[self.tag](\n                vocabularies=vocabularies,\n                qualifier_value=qualifier,\n                untl_object=self,\n                superuser=superuser,\n            )\n        # Element just has content.\n        elif content is not None:\n            # If the element is a child element,\n            # create the form attribute.\n            if parent_tag is None:\n                self.form = UNTL_FORM_DISPATCH[self.tag](\n                    vocabularies=vocabularies,\n                    input_value=content,\n                    untl_object=self,\n                    superuser=superuser,\n                )\n            else:\n                # Create the form attribute.\n                self.form = UNTL_FORM_DISPATCH[self.tag](\n                    vocabularies=vocabularies,\n                    input_value=content,\n                    untl_object=self,\n                    parent_tag=parent_tag,\n                    superuser=superuser,\n                )\n        # Element has children and no qualifiers or content\n        # or is blank (not originally in the UNTL record).\n        else:\n            # Element is a child element.\n            if parent_tag is None:\n                # Create the form attribute.\n                self.form = UNTL_FORM_DISPATCH[self.tag](\n                    vocabularies=vocabularies,\n                    untl_object=self,\n                    superuser=superuser,\n                )\n            else:\n                # Create the form attribute.\n                self.form = UNTL_FORM_DISPATCH[self.tag](\n                    vocabularies=vocabularies,\n                    untl_object=self,\n                    parent_tag=parent_tag,\n                    superuser=superuser,\n                )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate length of record excluding metadata.", "response": "def record_content_length(self):\n        \"\"\"Calculate length of record, excluding metadata.\"\"\"\n        untldict = py2dict(self)\n        untldict.pop('meta', None)\n        return len(str(untldict))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates the form data for the UNTL elements.", "response": "def create_form_data(self, **kwargs):\n        \"\"\"Create groupings of form elements.\"\"\"\n        # Get the specified keyword arguments.\n        children = kwargs.get('children', [])\n        sort_order = kwargs.get('sort_order', None)\n        solr_response = kwargs.get('solr_response', None)\n        superuser = kwargs.get('superuser', False)\n        # Get the vocabularies to pull the qualifiers from.\n        vocabularies = self.get_vocabularies()\n        # Loop through all UNTL elements in the Python object.\n        for element in children:\n            # Add children that are missing from the form.\n            element.children = add_missing_children(\n                element.contained_children,\n                element.children,\n            )\n            # Add the form attribute to the element.\n            element.add_form(\n                vocabularies=vocabularies,\n                qualifier=element.qualifier,\n                content=element.content,\n                superuser=superuser,\n            )\n            # Element can contain children.\n            if element.form.has_children:\n                # If the parent has a qualifier,\n                # create a representative form element for the parent.\n                if getattr(element.form, 'qualifier_name', False):\n                    add_parent = PARENT_FORM[element.form.qualifier_name](\n                        content=element.qualifier,\n                    )\n                    # Add the parent to the list of child elements.\n                    element.children.append(add_parent)\n                # Sort the elements by the index of child sort.\n                element.children.sort(\n                    key=lambda obj: element.form.child_sort.index(obj.tag)\n                )\n                # Loop through the element's children (if it has any).\n                for child in element.children:\n                    # Add the form attribute to the element.\n                    child.add_form(\n                        vocabularies=vocabularies,\n                        qualifier=child.qualifier,\n                        content=child.content,\n                        parent_tag=element.tag,\n                        superuser=superuser,\n                    )\n        element_group_dict = {}\n        # Group related objects together.\n        for element in children:\n            # Make meta-hidden its own group.\n            if element.form.name == 'meta' and element.qualifier == 'hidden':\n                element_group_dict['hidden'] = [element]\n            # Element is not meta-hidden.\n            else:\n                # Make sure the dictionary key exists.\n                if element.form.name not in element_group_dict:\n                    element_group_dict[element.form.name] = []\n                element_group_dict[element.form.name].append(element)\n        # If the hidden meta element doesn't exist, add it to its own group.\n        if 'hidden' not in element_group_dict:\n            hidden_element = PYUNTL_DISPATCH['meta'](\n                qualifier='hidden',\n                content='False')\n            hidden_element.add_form(\n                vocabularies=vocabularies,\n                qualifier=hidden_element.qualifier,\n                content=hidden_element.content,\n                superuser=superuser,\n            )\n            element_group_dict['hidden'] = [hidden_element]\n        # Create a list of group object elements.\n        element_list = self.create_form_groupings(\n            vocabularies,\n            solr_response,\n            element_group_dict,\n            sort_order,\n        )\n        # Return the list of UNTL elements with form data added.\n        return element_list"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a list of group objects from groupings of element objects.", "response": "def create_form_groupings(self,\n                              vocabularies,\n                              solr_response,\n                              element_group_dict,\n                              sort_order):\n        \"\"\"Create a group object from groupings of element objects.\"\"\"\n        element_list = []\n        # Loop through the group dictionary.\n        for group_name, group_list in element_group_dict.items():\n            # Create the element group.\n            element_group = UNTL_GROUP_DISPATCH[group_name](\n                vocabularies=vocabularies,\n                solr_response=solr_response,\n                group_name=group_name,\n                group_list=group_list,\n            )\n            # Loop through the adjustable forms of the group if they exist.\n            if element_group.adjustable_form is not None:\n                for adj_name, form_dict in element_group.adjustable_form.items():\n                    # If an item has an adjustable form,\n                    # append it to the adjustable list.\n                    if form_dict['value_py'] is not None:\n                        self.adjustable_items.append(adj_name)\n            # Append the group to the element group list.\n            element_list.append(element_group)\n        # Sort the elements by the index of sort_order pre-ordered list.\n        element_list.sort(key=lambda obj: sort_order.index(obj.group_name))\n        return element_list"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the vocabularies to pull the qualifiers from.", "response": "def get_vocabularies(self):\n        \"\"\"Get the vocabularies to pull the qualifiers from.\"\"\"\n        # Timeout in seconds.\n        timeout = 15\n        socket.setdefaulttimeout(timeout)\n        # Create the ordered vocabulary URL.\n        vocab_url = VOCABULARIES_URL.replace('all', 'all-verbose')\n        # Request the vocabularies dictionary.\n        try:\n            vocab_dict = eval(urllib2.urlopen(vocab_url).read())\n        except:\n            raise UNTLStructureException('Could not retrieve the vocabularies')\n        return vocab_dict"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a UNTL document in a string from a UNTL metadata root object.", "response": "def create_xml_string(self):\n        \"\"\"Create a UNTL document in a string from a UNTL metadata\n        root object.\n\n        untl_xml_string = metadata_root_object.create_xml_string()\n        \"\"\"\n        root = self.create_xml()\n\n        xml = '<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n' + tostring(\n            root, pretty_print=True\n        )\n        return xml"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate an ElementTree representation of the object.", "response": "def create_xml(self, useNamespace=False):\n        \"\"\"Create an ElementTree representation of the object.\"\"\"\n        UNTL_NAMESPACE = 'http://digital2.library.unt.edu/untl/'\n        UNTL = '{%s}' % UNTL_NAMESPACE\n\n        NSMAP = {'untl': UNTL_NAMESPACE}\n\n        if useNamespace:\n            root = Element(UNTL + self.tag, nsmap=NSMAP)\n        else:\n            root = Element(self.tag)\n\n        # Sort the elements by the index of\n        # UNTL_XML_ORDER pre-ordered list.\n        self.sort_untl(UNTL_XML_ORDER)\n        # Create an XML structure from field list.\n        for element in self.children:\n            if useNamespace:\n                create_untl_xml_subelement(root, element, UNTL)\n            else:\n                create_untl_xml_subelement(root, element)\n        return root"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_element_dict(self):\n        untl_dict = {}\n        # Loop through all UNTL elements in the Python object.\n        for element in self.children:\n            # If an entry for the element list hasn't been made in the\n            # dictionary, start an empty element list.\n            if element.tag not in untl_dict:\n                untl_dict[element.tag] = []\n            # Create a dictionary to put the element into.\n            # Add any qualifier.\n            element_dict = {}\n            if element.qualifier is not None:\n                element_dict['qualifier'] = element.qualifier\n            # Add any children that have content.\n            if len(element.contained_children) > 0:\n                child_dict = {}\n                for child in element.children:\n                    if child.content is not None:\n                        child_dict[child.tag] = child.content\n                # Set the element's content as the dictionary\n                # of children elements.\n                element_dict['content'] = child_dict\n            # The element has content, but no children.\n            elif element.content is not None:\n                element_dict['content'] = element.content\n            # Append the dictionary element to the element list.\n            untl_dict[element.tag].append(element_dict)\n\n        return untl_dict", "response": "Convert a UNTL Python object into a UNTL Python dictionary."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a UNTL XML file.", "response": "def create_xml_file(self, untl_filename):\n        \"\"\"Create a UNTL file.\n\n        Writes file to supplied file path.\n        \"\"\"\n        try:\n            f = open(untl_filename, 'w')\n            f.write(self.create_xml_string().encode('utf-8'))\n            f.close()\n        except:\n            raise UNTLStructureException(\n                'Failed to create UNTL XML file. File: %s' % (untl_filename)\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsorting the UNTL Python object by the index of a sort structure pre - ordered list.", "response": "def sort_untl(self, sort_structure):\n        \"\"\"Sort the UNTL Python object by the index\n        of a sort structure pre-ordered list.\n        \"\"\"\n        self.children.sort(key=lambda obj: sort_structure.index(obj.tag))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a form dictionary with the key being the element name and the value being a list of form element objects.", "response": "def generate_form_data(self, **kwargs):\n        \"\"\"Create a form dictionary with the key being the element name\n        and the value being a list of form element objects.\n        \"\"\"\n        # Add elements that are missing from the form.\n        self.children = add_missing_children(\n            self.contained_children,\n            self.children\n        )\n        # Add children to the keyword arguments.\n        kwargs['children'] = self.children\n        # Create the form object.\n        return FormGenerator(**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nstores state of an event in memory", "response": "async def track_event(event, state, service_name):\n    \"\"\"\n    Store state of events in memory\n    :param event: Event object\n    :param state: EventState object\n    :param service_name: Name of service name\n    \"\"\"\n    redis = await aioredis.create_redis(\n        (EVENT_TRACKING_HOST, 6379), loop=loop)\n\n    now = datetime.utcnow()\n    event_id = event.event_id\n\n    tracking_data = json.dumps({\n        \"event_id\": event_id,\n        \"timestamp\": str(now),\n        \"state\": state\n    })\n    await redis.rpush(service_name, tracking_data)\n    redis.close()\n    await redis.wait_closed()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef contributor_director(**kwargs):\n    if kwargs.get('qualifier') in ETD_MS_CONTRIBUTOR_EXPANSION:\n        # Return the element object.\n        return ETD_MSContributor(\n            role=ETD_MS_CONTRIBUTOR_EXPANSION[kwargs.get('qualifier')],\n            **kwargs\n        )\n    else:\n        return None", "response": "Define the expanded qualifier name."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndirect which class should be used based on the date qualifier", "response": "def date_director(**kwargs):\n    \"\"\"Direct which class should be used based on the date qualifier\n    or if the date should be converted at all.\n    \"\"\"\n    # If the date is a creation date, return the element object.\n    if kwargs.get('qualifier') == 'creation':\n        return ETD_MSDate(content=kwargs.get('content').strip())\n    elif kwargs.get('qualifier') != 'digitized':\n        # Return the element object.\n        return ETD_MSDate(content=kwargs.get('content').strip())\n    else:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef identifier_director(**kwargs):\n    ark = kwargs.get('ark', None)\n    qualifier = kwargs.get('qualifier', None)\n    content = kwargs.get('content', '')\n\n    # See if the ark and domain name were given.\n    if ark:\n        content = 'http://digital.library.unt.edu/%s' % ark\n    elif qualifier:\n        content = '%s: %s' % (qualifier, content)\n    return ETD_MSIdentifier(content=content)", "response": "Direct how to handle the identifier element."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndirecting how to handle a subject element.", "response": "def subject_director(**kwargs):\n    \"\"\"Direct how to handle a subject element.\"\"\"\n    if kwargs.get('qualifier') not in ['KWD', '']:\n        return ETD_MSSubject(scheme=kwargs.get('qualifier'), **kwargs)\n    else:\n        return ETD_MSSubject(content=kwargs.get('content'))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a child object to the current one.", "response": "def add_child(self, child):\n        \"\"\"Add a child object to the current one.\n\n        Checks the contained_children list to make sure that the object\n        is allowable, and throws an exception if not.\n        \"\"\"\n        # Make sure the child exists before adding it.\n        if child:\n            # Add the child if it is allowed to exist under the parent.\n            if child.tag in self.contained_children:\n                self.children.append(child)\n            else:\n                raise ETD_MS_StructureException(\n                    'Invalid child \"%s\" for parent \"%s\"' %\n                    (child.tag, self.tag)\n                )"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the requested element content from a list of children.", "response": "def get_child_content(self, children, element_name):\n        \"\"\"Get the requested element content from a list of children.\"\"\"\n        # Loop through the children and get the specified element.\n        for child in children:\n            # If the child is the requested element, return its content.\n            if child.tag == element_name:\n                return child.content\n        return ''"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfunctioning to compute the shifted color map for a given colormap.", "response": "def shiftedColorMap(cmap, start=0, midpoint=0.5, stop=1.0, name='shiftedcmap'):\n    '''\n    Function to offset the \"center\" of a colormap. Useful for\n    data with a negative min and positive max and you want the\n    middle of the colormap's dynamic range to be at zero\n\n    Parameters\n    ----------\n    cmap:\n        The matplotlib colormap to be altered\n    start:\n        Offset from lowest point in the colormap's range.  Defaults to 0.0 (no\n        lower ofset). Should be between 0.0 and `midpoint`.\n    midpoint:\n        The new center of the colormap. Defaults to 0.5 (no shift). Should be\n        between 0.0 and 1.0. In general, this should be  1 - vmax/(vmax +\n        abs(vmin)) For example if your data range from -15.0 to +5.0 and you\n        want the center of the colormap at 0.0, `midpoint` should be set to  1\n        - 5/(5 + 15)) or 0.75\n    stop:\n        Offset from highets point in the colormap's range.  Defaults to 1.0 (no\n        upper ofset). Should be between `midpoint` and 1.0.\n    '''\n    cdict = {\n        'red': [],\n        'green': [],\n        'blue': [],\n        'alpha': []\n    }\n\n    # regular index to compute the colors\n    reg_index = np.linspace(start, stop, 257)\n\n    # shifted index to match the data\n    shift_index = np.hstack([\n        np.linspace(0.0, midpoint, 128, endpoint=False),\n        np.linspace(midpoint, 1.0, 129, endpoint=True)\n    ])\n\n    for ri, si in zip(reg_index, shift_index):\n        r, g, b, a = cmap(ri)\n\n        cdict['red'].append((si, r, r))\n        cdict['green'].append((si, g, g))\n        cdict['blue'].append((si, b, b))\n        cdict['alpha'].append((si, a, a))\n\n    newcmap = mpl.colors.LinearSegmentedColormap(name, cdict)\n    plt.register_cmap(cmap=newcmap)\n\n    return newcmap"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef read_lastmodfile(directory):\n    filename = '{0}/exe/inv.lastmod'.format(directory)\n    # filename HAS to exist. Otherwise the inversion was not finished\n    if(not os.path.isfile(filename)):\n        return None\n\n    linestring = open(filename, 'r').readline().strip()\n    linestring = linestring.replace(\"\\n\", '')\n    linestring = linestring.replace(\".mag\", '')\n    linestring = linestring.replace(\"../inv/rho\", '')\n    return linestring", "response": "Read the last mod file in the specified directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets an event handler for given event.", "response": "def setHandler(self, event_name, callback):\n        \"\"\"Set an handler for given event.\"\"\"\n        if event_name not in self.handlers:\n            raise ValueError('{} is not a valid event'.format(event_name))\n        if callable(event_name):\n            raise TypeError('{} is not callable'.format(callback))\n        self.handlers[event_name] = callback"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck if an event has a handler.", "response": "def isHandlerPresent(self, event_name):\n        \"\"\"Check if an event has an handler.\"\"\"\n        if event_name not in self.handlers:\n            raise ValueError('{} is not a valid event'.format(event_name))\n        return self.handlers[event_name] is not None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving handler for given event.", "response": "def removeHandler(self, event_name):\n        \"\"\"Remove handler for given event.\"\"\"\n        if event_name not in self.handlers:\n            raise ValueError('{} is not a valid event'.format(event_name))\n        self.handlers[event_name] = None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_fct_number_of_arg(self, fct):\n        py_version = sys.version_info[0]\n        if py_version >= 3:\n            return len(inspect.signature(fct).parameters)\n        return len(inspect.getargspec(fct)[0])", "response": "Get the number of argument of a fuction."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngiving a config, performs an end-to-end publishing pipeline and returns the result: linking -> compiling -> templating -> writing NOTE: at most one of source and template can be None. If both are None, the publisher effectively has nothing to do; an exception is raised. PARAMETERS: config -- Config; a context that includes variables, compiler options, and templater information. source -- str; path to a source file, relative to the current working directory. If None, the publisher effectively becomes a templating engine. template -- str; path to a Jinja template file. Templar treats the path as relative to the list of template directories in config. If the template cannot be found relative to those directories, Templar finally tries the path relative to the current directory. If template is None, the publisher effectively becomes a linker and compiler. destination -- str; path for the destination file. jinja_env -- jinja2.Environment; if None, a Jinja2 Environment is created with a FileSystemLoader that is configured with config.template_dirs. Otherwise, the given Jinja2 Environment is used to retrieve and render the template. no_write -- bool; if True, the result is not written to a file or printed. If False and destination is provided, the result is written to the provided destination file. RETURNS: str; the result of the publishing pipeline.", "response": "def publish(config, source=None, template=None, destination=None, jinja_env=None, no_write=False):\n    \"\"\"Given a config, performs an end-to-end publishing pipeline and returns the result:\n\n        linking -> compiling -> templating -> writing\n\n    NOTE: at most one of source and template can be None. If both are None, the publisher\n    effectively has nothing to do; an exception is raised.\n\n    PARAMETERS:\n    config      -- Config; a context that includes variables, compiler options, and templater\n                   information.\n    source      -- str; path to a source file, relative to the current working directory. If None,\n                   the publisher effectively becomes a templating engine.\n    template    -- str; path to a Jinja template file. Templar treats the path as relative to the\n                   list of template directories in config. If the template cannot be found relative\n                   to those directories, Templar finally tries the path relative to the current\n                   directory.\n\n                   If template is None, the publisher effectively becomes a linker and compiler.\n    destination -- str; path for the destination file.\n    jinja_env   -- jinja2.Environment; if None, a Jinja2 Environment is created with a\n                   FileSystemLoader that is configured with config.template_dirs. Otherwise, the\n                   given Jinja2 Environment is used to retrieve and render the template.\n    no_write    -- bool; if True, the result is not written to a file or printed. If False and\n                   destination is provided, the result is written to the provided destination file.\n\n    RETURNS:\n    str; the result of the publishing pipeline.\n    \"\"\"\n    if not isinstance(config, Config):\n        raise PublishError(\n                \"config must be a Config object, \"\n                \"but instead was type '{}'\".format(type(config).__name__))\n\n    if source is None and template is None:\n        raise PublishError('When publishing, source and template cannot both be omitted.')\n\n    variables = config.variables\n    if source:\n        # Linking stage.\n        all_block, extracted_variables = linker.link(source)\n        variables.update(extracted_variables)\n\n        # Compiling stage.\n        block_variables = {}\n        for rule in config.rules:\n            if rule.applies(source, destination):\n                if isinstance(rule, VariableRule):\n                    variables.update(rule.apply(str(all_block)))\n                else:\n                    all_block.apply_rule(rule)\n        block_variables.update(linker.get_block_dict(all_block))\n        variables['blocks'] = block_variables   # Blocks are namespaced with 'blocks'.\n\n    # Templating stage.\n    if template:\n        if not jinja_env:\n            jinja_env = jinja2.Environment(loader=jinja2.FileSystemLoader(config.template_dirs))\n        jinja_template = jinja_env.get_template(template)\n        result = jinja_template.render(variables)\n\n        # Handle recursive evaluation of Jinja expressions.\n        iterations = 0\n        while config.recursively_evaluate_jinja_expressions \\\n                and iterations < _MAX_JINJA_RECURSIVE_DEPTH + 1 \\\n                and  _jinja_expression_re.search(result):\n            if iterations == _MAX_JINJA_RECURSIVE_DEPTH:\n                raise PublishError('\\n'.join([\n                    'Recursive Jinja expression evaluation exceeded the allowed '\n                        'number of iterations. Last state of template:',\n                    result]))\n            jinja_env = jinja2.Environment(loader=jinja2.DictLoader({'intermediate': result}))\n            jinja_template = jinja_env.get_template('intermediate')\n            result = jinja_template.render(variables)\n            iterations += 1\n    else:\n        # template is None implies source is not None, so variables['blocks'] must exist.\n        result = variables['blocks']['all']\n\n    # Writing stage.\n    if not no_write and destination:\n        destination_dir = os.path.dirname(destination)\n        if destination_dir != '' and not os.path.isdir(destination_dir):\n            os.makedirs(destination_dir)\n        with open(destination, 'w') as f:\n            f.write(result)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ensure_ajax(valid_request_methods, error_response_context=None):\n    def real_decorator(view_func):\n        def wrap_func(request, *args, **kwargs):\n            if not isinstance(request, HttpRequest):\n                # make sure the request is a django httprequest\n                return generate_error_json_response(\"Invalid request!\",\n                                                    error_response_context)\n            elif not request.is_ajax():\n                # ensure the request is an ajax request\n                return generate_error_json_response(\"Invalid request type!\",\n                                                    error_response_context)\n            elif request.method not in valid_request_methods:\n                # check if the request method is in allowed request methods\n                return generate_error_json_response(\"Invalid request method!\",\n                                                    error_response_context)\n            else:\n                return view_func(request, *args, **kwargs)\n        wrap_func.__doc__ = view_func.__doc__\n        wrap_func.__name__ = view_func.__name__\n        return wrap_func\n    return real_decorator", "response": "This is a decorator that ensures the received request is ajax request and it is included in the list of allowed request methods."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef generate_error_json_response(error_dict, error_response_context=None):\n    response = error_dict\n    if isinstance(error_dict, str):\n        response = {\"error\": response}\n    if error_response_context is None:\n        error_response_context = {\n            'draw': 0, 'recordsTotal': 0, 'recordsFiltered': 0, 'data': []\n        }\n    response.update(error_response_context)\n    return JsonResponse(response)", "response": "Generates a json response for an error"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _mergeGoSymbols(self, jsons = []):\n\t\t# <siXy> imports are per file, exports are per package\n\t\t# on the highest level we have: pkgname, types, funcs, vars, imports.\n\n\t\tsymbols = {}\n\t\tsymbols[\"types\"] = []\n\t\tsymbols[\"funcs\"] = []\n\t\tsymbols[\"vars\"]  = []\n\t\tfor file_json in jsons:\n\t\t\tsymbols[\"types\"] += file_json[\"types\"]\n\t\t\tsymbols[\"funcs\"] += file_json[\"funcs\"]\n\t\t\tsymbols[\"vars\"]  += file_json[\"vars\"]\n\n\t\treturn symbols", "response": "Merge all exported symbols for a given package."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget a descriptive error message from a system error number.", "response": "def format_system_message(errno):\n    \"\"\"\n    Call FormatMessage with a system error number to retrieve\n    the descriptive error message.\n    \"\"\"\n    # first some flags used by FormatMessageW\n    ALLOCATE_BUFFER = 0x100\n    ARGUMENT_ARRAY = 0x2000\n    FROM_HMODULE = 0x800\n    FROM_STRING = 0x400\n    FROM_SYSTEM = 0x1000\n    IGNORE_INSERTS = 0x200\n\n    # Let FormatMessageW allocate the buffer (we'll free it below)\n    # Also, let it know we want a system error message.\n    flags = ALLOCATE_BUFFER | FROM_SYSTEM\n    source = None\n    message_id = errno\n    language_id = 0\n    result_buffer = ctypes.wintypes.LPWSTR()\n    buffer_size = 0\n    arguments = None\n    format_bytes = ctypes.windll.kernel32.FormatMessageW(\n        flags,\n        source,\n        message_id,\n        language_id,\n        ctypes.byref(result_buffer),\n        buffer_size,\n        arguments,\n    )\n    # note the following will cause an infinite loop if GetLastError\n    #  repeatedly returns an error that cannot be formatted, although\n    #  this should not happen.\n    handle_nonzero_success(format_bytes)\n    message = result_buffer.value\n    ctypes.windll.kernel32.LocalFree(result_buffer)\n    return message"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef read(self, n):\n        out = ctypes.create_string_buffer(n)\n        ctypes.windll.kernel32.RtlMoveMemory(out, self.view + self.pos, n)\n        self.pos += n\n        return out.raw", "response": "Read n bytes from mapped view."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert fluents to tensors with datatype tf. float32.", "response": "def _output(cls, fluents: Sequence[FluentPair]) -> Sequence[tf.Tensor]:\n        '''Converts `fluents` to tensors with datatype tf.float32.'''\n        output = []\n        for _, fluent in fluents:\n            tensor = fluent.tensor\n            if tensor.dtype != tf.float32:\n                tensor = tf.cast(tensor, tf.float32)\n            output.append(tensor)\n        return tuple(output)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting a hyperparameter. Can be used to set an array of hyperparameters.", "response": "def set(self, key, value):\n        \"\"\"Sets a hyperparameter.  Can be used to set an array of hyperparameters.\"\"\"\n        self.store[key]=value\n        return self.store"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_config_value(self, k, i):\n        if(not isinstance(self.store[k], list)):\n            return self.store[k]\n        else:\n            return self.store[k][i]", "response": "Gets the ith config value for k. e. g. get_config_value ( x 1 )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef configs(self, max_configs=1, offset=None, serial=False, create_uuid=True):\n        if len(self.store)==0:\n            return []\n\n        configs = []\n\n        if(offset is None):\n            offset = max(0, random.randint(0, self.count_configs()))\n        for i in range(max_configs):\n            # get an element to index over\n\n            config = self.config_at(offset)\n            if(create_uuid):\n              config[\"uuid\"]=uuid.uuid4().hex\n            configs.append(config)\n            if(serial):\n                offset+=1\n            else:\n                offset = max(0, random.randint(0, self.count_configs()))\n        return configs", "response": "Generate max_configs each one a dictionary. e. g. [ x 1 ]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the ith config", "response": "def config_at(self, i):\n      \"\"\"Gets the ith config\"\"\"\n      selections = {}\n      for key in self.store:\n        value = self.store[key]\n        if isinstance(value, list):\n            selected = i % len(value)\n            i = i // len(value)\n            selections[key]= value[selected]\n        else:\n            selections[key]= value\n\n      return Config(selections)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the best results according to your custom sort method.", "response": "def top(self, sort_by):\n        \"\"\"Get the best results according to your custom sort method.\"\"\"\n        sort = sorted(self.results, key=sort_by)\n        return sort"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload a config from disk", "response": "def load(self, filename):\n        \"\"\"Loads a config from disk\"\"\"\n        content = open(filename)\n        return Config(json.load(content))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads a config from disk. Defaults to a random config if none is specified.", "response": "def load_or_create_config(self, filename, config=None):\n        \"\"\"Loads a config from disk.  Defaults to a random config if none is specified\"\"\"\n        os.makedirs(os.path.dirname(os.path.expanduser(filename)), exist_ok=True)\n        if os.path.exists(filename):\n            return self.load(filename)\n\n        if(config == None):\n            config = self.random_config()\n\n        self.save(filename, config)\n        return config"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef save(self, filename, config):\n        return open(os.path.expanduser(filename), 'w').write(json.dumps(config, cls=HCEncoder, sort_keys=True, indent=2, separators=(',', ': ')))", "response": "Loads a config from disk"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef configure(self, repositories):\n        self.enable_repositories(repositories)\n        self.create_stack_user()\n        self.install_base_packages()\n        self.clean_system()\n        self.yum_update(allow_reboot=True)\n        self.install_osp()\n        self.set_selinux('permissive')\n        self.fix_hostname()", "response": "Configure the system to be ready for an undercloud installation."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndeploy an undercloud on the host.", "response": "def openstack_undercloud_install(self):\n        \"\"\"Deploy an undercloud on the host.\n        \"\"\"\n        instack_undercloud_ver, _ = self.run('repoquery --whatprovides /usr/share/instack-undercloud/puppet-stack-config/puppet-stack-config.pp')\n        if instack_undercloud_ver.rstrip('\\n') == 'instack-undercloud-0:2.2.0-1.el7ost.noarch':\n            LOG.warn('Workaround for BZ1298189')\n            self.run(\"sed -i \\\"s/.*Keystone_domain\\['heat_domain'\\].*/Service\\['keystone'\\] -> Class\\['::keystone::roles::admin'\\] -> Class\\['::heat::keystone::domain'\\]/\\\" /usr/share/instack-undercloud/puppet-stack-config/puppet-stack-config.pp\")\n\n        self.run('OS_PASSWORD=bob openstack undercloud install', user='stack')\n        # NOTE(Gon\u00e9ri): we also need this after the overcloud deployment\n        if self.run('rpm -qa openstack-ironic-api')[0].rstrip('\\n') == 'openstack-ironic-api-4.2.2-3.el7ost.noarch':\n            LOG.warn('Workaround for BZ1297796')\n            self.run('systemctl start openstack-ironic-api.service')\n        self.add_environment_file(user='stack', filename='stackrc')\n        self.run('heat stack-list', user='stack')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_instackenv(self):\n        self.add_environment_file(user='stack', filename='stackrc')\n        self.run('openstack baremetal import --json instackenv.json', user='stack')\n        ironic_node_nbr = 0\n        count_cmd = 'jq -M \"{filter}|length\" /home/stack/instackenv.json'\n        # Nodes are either in the .nodes list or at the root of the document\n        for f in ['.nodes', '.']:\n            try:\n                ironic_node_nbr = int(\n                    self.run(count_cmd.format(filter=f), user='stack')[0])\n            except ValueError:\n                pass\n            if ironic_node_nbr > 0:\n                break\n        self._wait_for_ironic_nodes(ironic_node_nbr)\n        # register association with the newly created ironic nodes and the\n        # existing barematal nodes in the factory\n        self.baremetal_factory.set_ironic_uuid(self.list_nodes())\n        self.run('openstack baremetal configure boot', user='stack')", "response": "Load the instackenv. json file and wait till the ironic nodes are ready."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_flavor(self, name):\n        self.add_environment_file(user='stack', filename='stackrc')\n        self.run('openstack flavor create --id auto --ram 4096 --disk 40 --vcpus 1 baremetal', user='stack', success_status=(0, 1))\n        self.run('openstack flavor set --property \"cpu_arch\"=\"x86_64\" --property \"capabilities:boot_option\"=\"local\" baremetal', user='stack')\n        self.run('openstack flavor set --property \"capabilities:profile\"=\"baremetal\" baremetal', user='stack')", "response": "Create a new baremetal flavor."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef list_nodes(self):\n        self.add_environment_file(user='stack', filename='stackrc')\n        ret, _ = self.run(\"ironic node-list --fields uuid|awk '/-.*-/ {print $2}'\", user='stack')\n        # NOTE(Gon\u00e9ri): the good new is, the order of the nodes is preserved and follow the one from\n        # the instackenv.json, BUT it may be interesting to add a check.\n        return ret.split()", "response": "List the Ironic nodes UUID."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_flavor(self, node, flavor):\n        command = (\n            'ironic node-update {uuid} add '\n            'properties/capabilities=profile:{flavor},boot_option:local').format(\n                uuid=node.uuid, flavor=flavor)\n\n        node.flavor = flavor\n        self.add_environment_file(user='stack', filename='stackrc')\n        self.run(command, user='stack')", "response": "Set a flavor to a given ironic node"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfilter query helper that handles soft - deleted logic.", "response": "def read(cls, *criteria, **kwargs):\n        \"\"\"\n        filter query helper that handles soft delete logic. If your query conditions do not require expressions,\n        consider using read_by.\n\n        :param criteria: where clause conditions\n        :param kwargs: set removed=True if you want soft-deleted rows\n        :return: row object generator\n        \"\"\"\n        if not kwargs.get('removed', False):\n            return cls.query.filter(cls.time_removed == 0, *criteria)\n        return cls.query.filter(*criteria)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndeleting a row from the DB.", "response": "def delete(self, session, commit=True, soft=True):\n        \"\"\"\n        Delete a row from the DB.\n\n        :param session: flask_sqlalchemy session object\n        :param commit: whether to issue the commit\n        :param soft: whether this is a soft delete (i.e., update time_removed)\n        \"\"\"\n        if soft:\n            self.time_removed = sqlalchemy.func.unix_timestamp()\n        else:\n            session.delete(self)\n\n        if commit:\n            session.commit()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef walk_paths(self,\n                   base: Optional[pathlib.PurePath] = pathlib.PurePath()) \\\n            -> Iterator[pathlib.PurePath]:\n        \"\"\"\n        Recursively traverse all paths inside this entity, including the entity\n        itself.\n\n        :param base: The base path to prepend to the entity name.\n        :return: An iterator of paths.\n        \"\"\"\n        raise NotImplementedError()", "response": "Recursively walks all paths inside this entity including the entity s base path."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates an entity from a local path.", "response": "def from_path(cls, path: pathlib.Path) -> 'Entity':\n        \"\"\"\n        Create an entity from a local path.\n\n        :param path: The path to the entity, either a file or directory.\n        :return: An entity instance representing the path.\n        \"\"\"\n        if path.is_file():\n            return File.from_path(path)\n        return Directory.from_path(path)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate the MD5 checksum of a file.", "response": "def _md5(path: pathlib.PurePath):\n        \"\"\"\n        Calculate the MD5 checksum of a file.\n\n        :param path: The path of the file whose checksum to calculate.\n        :return: The lowercase hex representation of the file's MD5\n                    checksum, exactly 32 chars long.\n        \"\"\"\n        hash_ = hashlib.md5()\n        with open(path, 'rb') as f:\n            for chunk in iter(lambda: f.read(4096), b''):\n                hash_.update(chunk)\n        return hash_.hexdigest()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef from_path(cls, path: pathlib.Path) -> 'File':\n        if not path.is_file():\n            raise ValueError('Path does not point to a file')\n        return File(path.name, path.stat().st_size, cls._md5(path))", "response": "Create a file entity from a file path."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a directory entity from a directory path.", "response": "def from_path(cls, path: pathlib.Path) -> 'Directory':\n        \"\"\"\n        Create a directory entity from a directory path.\n\n        :param path: The path of the directory.\n        :return: A directory entity instance representing the directory.\n        :raises ValueError: If the path does not point to a directory.\n        \"\"\"\n        if not path.is_dir():\n            raise ValueError('Path does not point to a directory')\n        return Directory(path.name, {entity.name: Entity.from_path(entity)\n                                     for entity in path.iterdir()})"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef iter_genotypes(self):\n        for v in self.get_vcf():\n            alleles = {v.REF} | set(v.ALT)\n\n            if self.quality_field:\n                variant = ImputedVariant(v.ID, v.CHROM, v.POS, alleles,\n                                         getattr(v, self.quality_field))\n            else:\n                variant = Variant(v.ID, v.CHROM, v.POS, alleles)\n\n            for coded_allele, g in self._make_genotypes(v.ALT, v.genotypes):\n                yield Genotypes(variant, g, v.REF, coded_allele,\n                                multiallelic=len(v.ALT) > 1)", "response": "Iterates on available markers."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\niterates over the variants in the marker information.", "response": "def iter_variants(self):\n        \"\"\"Iterate over marker information.\"\"\"\n        for v in self.get_vcf():\n            yield Variant(v.ID, v.CHROM, v.POS, {v.REF} | set(v.ALT))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\niterates over variants in a region.", "response": "def get_variants_in_region(self, chrom, start, end):\n        \"\"\"Iterate over variants in a region.\"\"\"\n        region = self.get_vcf()(\n            \"{}:{}-{}\".format(chrom, start, end)\n        )\n        for v in region:\n            for coded_allele, g in self._make_genotypes(v.ALT, v.genotypes):\n                variant = Variant(\n                    v.ID, v.CHROM, v.POS, [v.REF, coded_allele]\n                )\n                yield Genotypes(variant, g, v.REF, coded_allele,\n                                multiallelic=len(v.ALT) > 1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef best_result(self):\n        best_result = None\n        for result in self.results:\n            if best_result is None or result.figure_of_merit > best_result.figure_of_merit:\n                best_result = result\n        return best_result", "response": "Returns the result that has the highest figure of merit."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the figure of merit array.", "response": "def figure_of_merit_array(self):\n        \"\"\"\n        Returns\n        -------\n        figure_of_merit_array: np.ndarray\n            An array of figures of merit. This array has the same dimensionality as the grid search, with the value in\n            each entry being the figure of merit taken from the optimization performed at that point.\n        \"\"\"\n        return np.reshape(np.array([result.figure_of_merit for result in self.results]),\n                          tuple(self.side_length for _ in range(self.no_dimensions)))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef make_lists(self, grid_priors):\n        return optimizer.make_lists(len(grid_priors), step_size=self.hyper_step_size, centre_steps=False)", "response": "Generates a list of lists of floats where each list of floats represents the values in each dimension for one\n        step of the grid search."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfits an analysis with a set of priors.", "response": "def fit(self, analysis, grid_priors):\n        \"\"\"\n        Fit an analysis with a set of grid priors. The grid priors are priors associated with the model mapper\n        of this instance that are replaced by uniform priors for each step of the grid search.\n\n        Parameters\n        ----------\n        analysis: non_linear.Analysis\n            An analysis used to determine the fitness of a given model instance\n        grid_priors: [p.Prior]\n            A list of priors to be substituted for uniform priors across the grid.\n\n        Returns\n        -------\n        result: GridSearchResult\n            An object that comprises the results from each individual fit\n        \"\"\"\n        grid_priors = list(set(grid_priors))\n        results = []\n        lists = self.make_lists(grid_priors)\n\n        results_list = [list(map(self.variable.name_for_prior, grid_priors)) + [\"figure_of_merit\"]]\n\n        def write_results():\n            with open(\"{}/results\".format(self.phase_output_path), \"w+\") as f:\n                f.write(\"\\n\".join(map(lambda ls: \", \".join(\n                    map(lambda value: \"{:.2f}\".format(value) if isinstance(value, float) else str(value), ls)),\n                                      results_list)))\n\n        for values in lists:\n            arguments = self.make_arguments(values, grid_priors)\n            model_mapper = self.variable.mapper_from_partial_prior_arguments(arguments)\n\n            labels = []\n            for prior in arguments.values():\n                labels.append(\n                    \"{}_{:.2f}_{:.2f}\".format(model_mapper.name_for_prior(prior), prior.lower_limit, prior.upper_limit))\n\n            name_path = \"{}{}/{}\".format(self.phase_name, self.phase_tag, \"_\".join(labels))\n            optimizer_instance = self.optimizer_instance(model_mapper, name_path)\n            optimizer_instance.constant = self.constant\n            result = optimizer_instance.fit(analysis)\n            results.append(result)\n\n            results_list.append([*[prior.lower_limit for prior in arguments.values()], result.figure_of_merit])\n\n            write_results()\n\n        return GridSearchResult(results, lists)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef portTryReduce(root: LNode, port: LPort):\n    if not port.children:\n        return\n\n    for p in port.children:\n        portTryReduce(root, p)\n\n    target_nodes = {}\n    ch_cnt = countDirectlyConnected(port, target_nodes)\n    if not target_nodes:\n        # disconnected port\n        return\n\n    new_target, children_edge_to_destroy = max(target_nodes.items(),\n                                               key=lambda x: len(x[1]))\n    cnt = len(children_edge_to_destroy)\n    if cnt < ch_cnt / 2 or cnt == 1 and ch_cnt == 2:\n        # too small to few shared connection to reduce\n        return\n\n    children_to_destroy = set()\n    on_target_children_to_destroy = set()\n    for child, edge in children_edge_to_destroy:\n        if child.direction == PortType.OUTPUT:\n            target_ch = edge.dsts\n        elif child.direction == PortType.INPUT:\n            target_ch = edge.srcs\n        else:\n            raise ValueError(child.direction)\n        if len(target_ch) != 1:\n            raise NotImplementedError(\"multiple connected nodes\", target_ch)\n        target_ch = target_ch[0]\n\n        try:\n            assert target_ch.parent is new_target, (\n                target_ch,\n                target_ch.parent,\n                new_target)\n        except AssertionError:\n            print('Wrong target:\\n', edge.src, \"\\n\", edge.dst,\n                  \"\\n\", target_ch.parent, \"\\n\", new_target)\n            raise\n\n        if child.direction == PortType.OUTPUT:\n            edge.removeTarget(target_ch)\n        elif child.direction == PortType.INPUT:\n            edge.removeTarget(child)\n\n        if not edge.srcs or not edge.dsts:\n            edge.remove()\n\n        if not target_ch.incomingEdges and not target_ch.outgoingEdges:\n            # disconnect selected children from this port and target\n            on_target_children_to_destroy.add(target_ch)\n\n        if not child.incomingEdges and not child.outgoingEdges:\n            children_to_destroy.add(child)\n\n    # destroy children of new target and this port if possible\n    port.children = [\n        ch for ch in port.children if ch not in children_to_destroy]\n    new_target.children = [\n        ch for ch in new_target.children if ch not in on_target_children_to_destroy]\n\n    # connect this port to new target as it was connected by children before\n    # [TODO] names for new edges\n    if port.direction == PortType.OUTPUT:\n        root.addEdge(port, new_target)\n    elif port.direction == PortType.INPUT:\n        root.addEdge(new_target, port)\n    else:\n        raise NotImplementedError(port.direction)", "response": "This function tries to reduce the children of a port and returns a new tree that is reduced to the same tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef resolveSharedConnections(root: LNode):\n    for ch in root.children:\n        resolveSharedConnections(ch)\n\n    for ch in root.children:\n        for p in ch.iterPorts():\n            portTryReduce(root, p)", "response": "Walk all ports on all nodes and group subinterfaces to only parent interface connection"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef countDirectlyConnected(port: LPort, result: dict) -> int:\n    inEdges = port.incomingEdges\n    outEdges = port.outgoingEdges\n\n    if port.children:\n        ch_cnt = 0\n        # try:\n        #    assert not inEdges, (port, port.children, inEdges)\n        #    assert not outEdges, (port, port.children, outEdges)\n        # except AssertionError:\n        #    raise\n        for ch in port.children:\n            ch_cnt += countDirectlyConnected(ch, result)\n\n        return ch_cnt\n\n    elif not inEdges and not outEdges:\n        # this port is not connected, just check if it expected state\n        if port.direction == PortType.INPUT:\n            if port.originObj is not None:\n                assert not port.originObj.src.drivers, port.originObj\n            else:\n                print(\"Warning\", port, \"not connected\")\n        return 0\n    else:\n        connectedElemCnt = 0\n        for e in inEdges:\n            connectedElemCnt += len(e.srcs)\n            if connectedElemCnt > 1:\n                return 0\n\n        for e in outEdges:\n            connectedElemCnt += len(e.dsts)\n            if connectedElemCnt > 1:\n                return 0\n\n        if connectedElemCnt != 1:\n            return 0\n\n        if inEdges:\n            e = inEdges[0]\n        else:\n            e = outEdges[0]\n\n        # if is connected to different port\n        if e.srcs[0].name != e.dsts[0].name:\n            return 0\n\n        if e.srcs[0] is port:\n            p = e.dsts[0].parent\n        else:\n            # (can be hyperedge and then this does not have to be)\n            # assert e.dsts[0] is port, (e, port)\n            p = e.srcs[0].parent\n\n        # if is part of interface which can be reduced\n        if not isinstance(p, LNode):\n            connections = result.get(p, [])\n            connections.append((port, e))\n            result[p] = connections\n\n        return 1", "response": "Count how many ports are directly connected to other nodes."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates the node. This method should only be called by the BaremetalFactory.", "response": "def deploy(self, image_name, ip, flavor='m1.small'):\n        \"\"\"Create the node.\n\n        This method should only be called by the BaremetalFactory.\n        \"\"\"\n        body_value = {\n            \"port\": {\n                \"admin_state_up\": True,\n                \"name\": self.name + '_provision',\n                \"network_id\": os_utils.get_network_id(self.nova_api, 'provision_bob'),\n                'fixed_ips': [{'ip_address': ip}]}}\n        response = self.neutron.create_port(body=body_value)\n        self._provision_port_id = response['port']['id']\n        self.mac = response['port']['mac_address']\n\n        image_id_to_boot_from = os_utils.get_image_id(self.nova_api, image_name)\n        flavor_id = os_utils.get_flavor_id(self.nova_api, flavor)\n        # TODO(Gon\u00e9ri): We don't need keypair for the BM nodes\n        keypair_id = os_utils.get_keypair_id(self.nova_api, self._keypair)\n        # Ensure with get DHCP lease on the provision network first\n        nics = [{'port-id': self._provision_port_id}]\n\n        self._os_instance = os_provisioner.build_openstack_instance(\n            self.nova_api,\n            self.name,\n            image_id_to_boot_from,\n            flavor_id,\n            keypair_id,\n            nics)\n\n        if not self._os_instance:\n            LOG.error(\"deployment has failed\")\n            raise Exception()\n\n        os_provisioner.add_provision_security_group(self.nova_api)\n        os_utils.add_security_groups(self._os_instance, ['provision'])\n        os_utils.add_security_groups(self._os_instance, self._security_groups)\n        LOG.info(\"add security groups '%s'\" % self._security_groups)\n        LOG.info(\"instance '%s' ready to use\" % self.name)\n\n        # the instance should be off for Ironic\n        self._os_instance.stop()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nspecify which file ipxe should load during the netboot.", "response": "def pxe_netboot(self, filename):\n        \"\"\"Specify which file ipxe should load during the netboot.\"\"\"\n        new_port = {\n            'extra_dhcp_opts': [\n                {'opt_name': 'bootfile-name', 'opt_value': 'http://192.0.2.240:8088/' + filename, 'ip_version': 4, },\n                {'opt_name': 'tftp-server', 'opt_value': '192.0.2.240', 'ip_version': '4'},\n                {'opt_name': 'server-ip-address', 'opt_value': '192.0.2.240', 'ip_version': '4'}\n            ]\n        }\n        self.neutron.update_port(self._provision_port_id, {'port': new_port})"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef initialize(self, size=2):\n        # The IP should be in this range, this is the default DHCP range used by the introspection.\n        # inspection_iprange = 192.0.2.100,192.0.2.120\n        for i in range(0, size):\n            self.nodes.append(\n                Baremetal(\n                    self.nova_api,\n                    self.neutron,\n                    self._keypair,\n                    self._key_filename,\n                    self._security_groups,\n                    name='baremetal_%d' % i))\n        with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n            for bm_node in self.nodes:\n                future = executor.submit(\n                    bm_node.deploy,\n                    'ipxe.usb',\n                    '192.0.2.%d' % self._idx,\n                    flavor='m1.large')\n                self._idx += 1\n                bm_node._future = future\n            for bm_node in self.nodes:\n                bm_node._future.result()\n                pm_addr = self.bmc.register_host(bm_node.name)\n                self.instackenv.append({\n                    \"pm_type\": \"pxe_ipmitool\",\n                    \"mac\": [bm_node.mac],\n                    # TODO(Gon\u00e9ri): We should get these informations from the baremetal node's flavor\n                    \"cpu\": \"4\",\n                    \"memory\": \"8196\",\n                    \"disk\": \"80\",\n                    \"arch\": \"x86_64\",\n                    \"pm_user\": \"admin\",\n                    \"pm_password\": \"password\",\n                    \"pm_addr\": pm_addr\n                })\n        self.bmc.ssh_pool.stop_all()", "response": "Populate the baremetal poll."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_bmc(self, os_username, os_password, os_project_id, os_auth_url):\n        bmc = ovb_bmc.OvbBmc(\n            nova_api=self.nova_api,\n            neutron=self.neutron,\n            keypair=self._keypair,\n            key_filename=self._key_filename,\n            security_groups=self._security_groups,\n            image_name='Fedora 23 x86_64',\n            ip='192.0.2.254',\n            os_username=os_username,\n            os_password=os_password,\n            os_project_id=os_project_id,\n            os_auth_url=os_auth_url)\n        return bmc", "response": "Create the BMC machine."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef untlxml2py(untl_filename):\n    # Create a stack to hold parents.\n    parent_stack = []\n    # Use iterparse to open the file and loop through elements.\n    for event, element in iterparse(untl_filename, events=('start', 'end')):\n        if NAMESPACE_REGEX.search(element.tag, 0):\n            element_tag = NAMESPACE_REGEX.search(element.tag, 0).group(1)\n        else:\n            element_tag = element.tag\n        # Process the element if it exists in UNTL.\n        if element_tag in PYUNTL_DISPATCH:\n            # If it is the element's opening tag,\n            # add it to the parent stack.\n            if event == 'start':\n                parent_stack.append(PYUNTL_DISPATCH[element_tag]())\n            # If it is the element's closing tag,\n            # remove element from stack. Add qualifier and content.\n            elif event == 'end':\n                child = parent_stack.pop()\n                if element.text is not None:\n                    content = element.text.strip()\n                    if content != '':\n                        child.set_content(element.text)\n                if element.get('qualifier', False):\n                    child.set_qualifier(element.get('qualifier'))\n\n                # Add the element to its parent.\n                if len(parent_stack) > 0:\n                    parent_stack[-1].add_child(child)\n                # If it doesn't have a parent, it is the root element,\n                # so return it.\n                else:\n                    return child\n        else:\n            raise PyuntlException(\n                'Element \"%s\" not in UNTL dispatch.' % (element_tag)\n            )", "response": "Parse a UNTL XML file into a pyuntl element tree."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef untldict2py(untl_dict):\n    # Create the root element.\n    untl_root = PYUNTL_DISPATCH['metadata']()\n    untl_py_list = []\n    for element_name, element_list in untl_dict.items():\n        # Loop through the element dictionaries in the element list.\n        for element_dict in element_list:\n            qualifier = element_dict.get('qualifier', None)\n            content = element_dict.get('content', None)\n            child_list = []\n            # Handle content that is children elements.\n            if isinstance(content, dict):\n                for key, value in content.items():\n                    child_list.append(\n                        PYUNTL_DISPATCH[key](content=value),\n                    )\n                # Create the UNTL element that will have children elements\n                # added to it.\n                if qualifier is not None:\n                    untl_element = PYUNTL_DISPATCH[element_name](\n                        qualifier=qualifier\n                    )\n                else:\n                    untl_element = PYUNTL_DISPATCH[element_name]()\n                # Add the element's children to the element.\n                for child in child_list:\n                    untl_element.add_child(child)\n            # If not child element, create the element and\n            # add qualifier and content as available.\n            elif content is not None and qualifier is not None:\n                untl_element = PYUNTL_DISPATCH[element_name](\n                    qualifier=qualifier,\n                    content=content,\n                )\n            elif qualifier is not None:\n                untl_element = PYUNTL_DISPATCH[element_name](\n                    qualifier=qualifier,\n                )\n            elif content is not None:\n                untl_element = PYUNTL_DISPATCH[element_name](\n                    content=content,\n                )\n            # Create element that only has children.\n            elif len(child_list) > 0:\n                untl_element = PYUNTL_DISPATCH[element_name]()\n            # Add the UNTL element to the Python element list.\n            untl_py_list.append(untl_element)\n    # Add the UNTL elements to the root element.\n    for untl_element in untl_py_list:\n        untl_root.add_child(untl_element)\n    return untl_root", "response": "Convert a UNTL dictionary into a Python object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef post2pydict(post, ignore_list):\n    root_element = PYUNTL_DISPATCH['metadata']()\n    untl_form_dict = {}\n    # Turn the posted data into usable data\n    # (otherwise the value lists get messed up).\n    form_post = dict(post.copy())\n    # Loop through all the field lists.\n    for key, value_list in form_post.items():\n        if key not in ignore_list:\n            # Split the key into the element_tag (ex. title)\n            # and element attribute (ex. qualifier, content).\n            (element_tag, element_attribute) = key.split('-', 1)\n            if element_tag not in untl_form_dict:\n                untl_form_dict[element_tag] = ()\n            # Add the value list to the dictionary.\n            untl_form_dict[element_tag] += (element_attribute, value_list),\n\n    for element_tag, attribute_tuple in untl_form_dict.items():\n        # Get the count of attributes/content in the element tuple.\n        attribute_count = len(attribute_tuple)\n        # Get the count of the first attribute's values.\n        value_count = len(attribute_tuple[0][1])\n        # Check to see that all attribute/content values align numerically.\n        for i in range(0, attribute_count):\n            if not len(attribute_tuple[i][1]) == value_count:\n                raise PyuntlException('Field values did not match up '\n                                      'numerically for %s' % (element_tag))\n        # Create a value loop to get all values from the tuple.\n        for i in range(0, value_count):\n            untl_element = None\n            content = ''\n            qualifier = ''\n            child_list = []\n            # Loop through the attributes.\n            # attribute_tuple[j][0] represents the attribute/content name.\n            # attribute_tuple[j][1][i] represents the\n            # current attribute/content value.\n            for j in range(0, attribute_count):\n                if attribute_tuple[j][0] == 'content':\n                    content = unicode(attribute_tuple[j][1][i])\n                elif attribute_tuple[j][0] == 'qualifier':\n                    qualifier = attribute_tuple[j][1][i]\n                # Create a child UNTL element from the data.\n                else:\n                    # If the child has content, append it to the child list.\n                    if attribute_tuple[j][1][i] != '':\n                        child_tag = attribute_tuple[j][0]\n                        # Check if the child is the attribute of the element.\n                        if child_tag in PARENT_FORM:\n                            qualifier = attribute_tuple[j][1][i]\n                        # Else, the child is a normal child of the element.\n                        else:\n                            child_list.append(\n                                PYUNTL_DISPATCH[attribute_tuple[j][0]](\n                                    content=attribute_tuple[j][1][i]\n                                )\n                            )\n            # Create the UNTL element.\n            if content != '' and qualifier != '':\n                untl_element = PYUNTL_DISPATCH[element_tag](content=content,\n                                                            qualifier=qualifier)\n            elif content != '':\n                untl_element = PYUNTL_DISPATCH[element_tag](content=content)\n            elif qualifier != '':\n                untl_element = PYUNTL_DISPATCH[element_tag](qualifier=qualifier)\n            # This element only has children elements.\n            elif len(child_list) > 0:\n                untl_element = PYUNTL_DISPATCH[element_tag]()\n            # If the element has children, add them.\n            if len(child_list) > 0 and untl_element is not None:\n                for child in child_list:\n                    untl_element.add_child(child)\n            # Add the UNTL element to the root element.\n            if untl_element is not None:\n                root_element.add_child(untl_element)\n    return root_element.create_element_dict()", "response": "Convert the UNTL posted data to a Python dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef untlpy2dcpy(untl_elements, **kwargs):\n    sDate = None\n    eDate = None\n    ark = kwargs.get('ark', None)\n    domain_name = kwargs.get('domain_name', None)\n    scheme = kwargs.get('scheme', 'http')\n    resolve_values = kwargs.get('resolve_values', None)\n    resolve_urls = kwargs.get('resolve_urls', None)\n    verbose_vocabularies = kwargs.get('verbose_vocabularies', None)\n    # If either resolvers were requested, get the vocabulary data.\n    if resolve_values or resolve_urls:\n        if verbose_vocabularies:\n            # If the vocabularies were passed to the function, use them.\n            vocab_data = verbose_vocabularies\n        else:\n            # Otherwise, retrieve them using the pyuntl method.\n            vocab_data = retrieve_vocab()\n    else:\n        vocab_data = None\n    # Create the DC parent element.\n    dc_root = DC_CONVERSION_DISPATCH['dc']()\n    for element in untl_elements.children:\n        # Check if the UNTL element should be converted to DC.\n        if element.tag in DC_CONVERSION_DISPATCH:\n            # Check if the element has its content stored in children nodes.\n            if element.children:\n                dc_element = DC_CONVERSION_DISPATCH[element.tag](\n                    qualifier=element.qualifier,\n                    children=element.children,\n                    resolve_values=resolve_values,\n                    resolve_urls=resolve_urls,\n                    vocab_data=vocab_data,\n                )\n            # It is a normal element.\n            else:\n                dc_element = DC_CONVERSION_DISPATCH[element.tag](\n                    qualifier=element.qualifier,\n                    content=element.content,\n                    resolve_values=resolve_values,\n                    resolve_urls=resolve_urls,\n                    vocab_data=vocab_data,\n                )\n            if element.tag == 'coverage':\n                # Handle start and end dates.\n                if element.qualifier == 'sDate':\n                    sDate = dc_element\n                elif element.qualifier == 'eDate':\n                    eDate = dc_element\n                # Otherwise, add the coverage element to the structure.\n                else:\n                    dc_root.add_child(dc_element)\n            # Add non coverage DC element to the structure.\n            elif dc_element:\n                dc_root.add_child(dc_element)\n    # If the domain and ark were specified\n    # try to turn them into indentifier elements.\n    if ark and domain_name:\n        # Create and add the permalink identifier.\n        permalink_identifier = DC_CONVERSION_DISPATCH['identifier'](\n            qualifier='permalink',\n            domain_name=domain_name,\n            ark=ark,\n            scheme=scheme\n        )\n        dc_root.add_child(permalink_identifier)\n        # Create and add the ark identifier.\n        ark_identifier = DC_CONVERSION_DISPATCH['identifier'](\n            qualifier='ark',\n            content=ark,\n        )\n        dc_root.add_child(ark_identifier)\n    if sDate and eDate:\n        # If a start and end date exist, combine them into one element.\n        dc_element = DC_CONVERSION_DISPATCH['coverage'](\n            content='%s-%s' % (sDate.content, eDate.content),\n        )\n        dc_root.add_child(dc_element)\n    elif sDate:\n        dc_root.add_child(sDate)\n    elif eDate:\n        dc_root.add_child(eDate)\n    return dc_root", "response": "Convert the UNTL elements structure into a DC structure."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef untlpy2highwirepy(untl_elements, **kwargs):\n    highwire_list = []\n    title = None\n    publisher = None\n    creation = None\n    escape = kwargs.get('escape', False)\n    for element in untl_elements.children:\n        # If the UNTL element should be converted to highwire,\n        # create highwire element.\n        if element.tag in HIGHWIRE_CONVERSION_DISPATCH:\n            highwire_element = HIGHWIRE_CONVERSION_DISPATCH[element.tag](\n                qualifier=element.qualifier,\n                content=element.content,\n                children=element.children,\n                escape=escape,\n            )\n            if highwire_element:\n                if element.tag == 'title':\n                    if element.qualifier != 'officialtitle' and not title:\n                        title = highwire_element\n                    elif element.qualifier == 'officialtitle':\n                        title = highwire_element\n                elif element.tag == 'publisher':\n                    if not publisher:\n                        # This is the first publisher element.\n                        publisher = highwire_element\n                        highwire_list.append(publisher)\n                elif element.tag == 'date':\n                    # If a creation date hasn't been found yet,\n                    # verify this date is acceptable.\n                    if not creation and element.qualifier == 'creation':\n                        if highwire_element.content:\n                            creation = highwire_element\n                            if creation:\n                                highwire_list.append(creation)\n                # Otherwise, add the element to the list if it has content.\n                elif highwire_element.content:\n                    highwire_list.append(highwire_element)\n        # If the title was found, add it to the list.\n    if title:\n        highwire_list.append(title)\n    return highwire_list", "response": "Convert a UNTL Python object to a highwire Python object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef untlpydict2dcformatteddict(untl_dict, **kwargs):\n    ark = kwargs.get('ark', None)\n    domain_name = kwargs.get('domain_name', None)\n    scheme = kwargs.get('scheme', 'http')\n    resolve_values = kwargs.get('resolve_values', None)\n    resolve_urls = kwargs.get('resolve_urls', None)\n    verbose_vocabularies = kwargs.get('verbose_vocabularies', None)\n    # Get the UNTL object.\n    untl_py = untldict2py(untl_dict)\n    # Convert it to a DC object.\n    dc_py = untlpy2dcpy(\n        untl_py,\n        ark=ark,\n        domain_name=domain_name,\n        resolve_values=resolve_values,\n        resolve_urls=resolve_urls,\n        verbose_vocabularies=verbose_vocabularies,\n        scheme=scheme\n    )\n    # Return a formatted DC dictionary.\n    return dcpy2formatteddcdict(dc_py)", "response": "Convert a UNTL data dictionary to a formatted DC data dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef formatted_dc_dict(dc_dict):\n    for key, element_list in dc_dict.items():\n        new_element_list = []\n        # Add the content for each element to the new element list.\n        for element in element_list:\n            new_element_list.append(element['content'])\n        dc_dict[key] = new_element_list\n    return dc_dict", "response": "Change the formatting of the DC data dictionary into a dictionary that contains a list of values for each element."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates a DC XML string from a dictionary.", "response": "def generate_dc_xml(dc_dict):\n    \"\"\"Generate a DC XML string.\"\"\"\n    # Define the root namespace.\n    root_namespace = '{%s}' % DC_NAMESPACES['oai_dc']\n    # Set the elements namespace URL.\n    elements_namespace = '{%s}' % DC_NAMESPACES['dc']\n    schema_location = ('http://www.openarchives.org/OAI/2.0/oai_dc/ '\n                       'http://www.openarchives.org/OAI/2.0/oai_dc.xsd')\n    root_attributes = {\n        '{%s}schemaLocation' % XSI: schema_location,\n    }\n    # Return the DC XML string.\n    return pydict2xmlstring(\n        dc_dict,\n        ordering=DC_ORDER,\n        root_label='dc',\n        root_namespace=root_namespace,\n        elements_namespace=elements_namespace,\n        namespace_map=DC_NAMESPACES,\n        root_attributes=root_attributes,\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates DC JSON data.", "response": "def generate_dc_json(dc_dict):\n    \"\"\"Generate DC JSON data.\n\n    Returns data as a JSON formatted string.\n    \"\"\"\n    formatted_dict = formatted_dc_dict(dc_dict)\n    return json.dumps(formatted_dict, sort_keys=True, indent=4)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef highwirepy2dict(highwire_elements):\n    highwire_dict = {}\n    # Make a list of content dictionaries for each element name.\n    for element in highwire_elements:\n        if element.name not in highwire_dict:\n            highwire_dict[element.name] = []\n        highwire_dict[element.name].append({'content': element.content})\n    return highwire_dict", "response": "Convert a list of highwire elements into a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts highwire elements into a JSON formatted string.", "response": "def generate_highwire_json(highwire_elements):\n    \"\"\"Convert highwire elements into a JSON structure.\n\n    Returns data as a JSON formatted string.\n    \"\"\"\n    highwire_dict = highwirepy2dict(highwire_elements)\n    return json.dumps(highwire_dict, sort_keys=True, indent=4)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dcdict2rdfpy(dc_dict):\n    ark_prefix = 'ark: ark:'\n    uri = URIRef('')\n    # Create the RDF Python object.\n    rdf_py = ConjunctiveGraph()\n    # Set DC namespace definition.\n    DC = Namespace('http://purl.org/dc/elements/1.1/')\n    # Get the ark for the subject URI from the ark identifier.\n    for element_value in dc_dict['identifier']:\n        if element_value['content'].startswith(ark_prefix):\n            uri = URIRef(\n                element_value['content'].replace(\n                    ark_prefix, 'info:ark'\n                )\n            )\n    # Bind the prefix/namespace pair.\n    rdf_py.bind('dc', DC)\n    # Get the values for each element in the ordered DC elements.\n    for element_name in DC_ORDER:\n        element_value_list = dc_dict.get(element_name, [])\n        # Add the values to the RDF object.\n        for element_value in element_value_list:\n            # Handle URL values differently.\n            if ('http' in element_value['content'] and ' ' not in element_value['content']):\n                rdf_py.add((\n                    uri,\n                    DC[element_name],\n                    URIRef(element_value['content'])\n                ))\n            else:\n                rdf_py.add((\n                    uri,\n                    DC[element_name],\n                    Literal(element_value['content'])\n                ))\n    return rdf_py", "response": "Convert a DC dictionary into an RDF Python object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_empty_fields(untl_dict):\n    # Iterate the ordered UNTL XML element list to determine\n    # which elements are missing from the untl_dict.\n    for element in UNTL_XML_ORDER:\n        if element not in untl_dict:\n            # Try to create an element with content and qualifier.\n            try:\n                py_object = PYUNTL_DISPATCH[element](\n                    content='',\n                    qualifier='',\n                )\n            except:\n                # Try to create an element with content.\n                try:\n                    py_object = PYUNTL_DISPATCH[element](content='')\n                except:\n                    # Try to create an element without content.\n                    try:\n                        py_object = PYUNTL_DISPATCH[element]()\n                    except:\n                        raise PyuntlException(\n                            'Could not add empty element field.'\n                        )\n                    else:\n                        untl_dict[element] = [{'content': {}}]\n                else:\n                    # Handle element without children.\n                    if not py_object.contained_children:\n                        untl_dict[element] = [{'content': ''}]\n                    else:\n                        untl_dict[element] = [{'content': {}}]\n            else:\n                # Handle element without children.\n                if not py_object.contained_children:\n                    untl_dict[element] = [{'content': '', 'qualifier': ''}]\n                else:\n                    untl_dict[element] = [{'content': {}, 'qualifier': ''}]\n            # Add empty contained children.\n            for child in py_object.contained_children:\n                untl_dict[element][0].setdefault('content', {})\n                untl_dict[element][0]['content'][child] = ''\n    return untl_dict", "response": "Add empty values if UNTL fields don t have values."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds empty values for ETD_MS fields that don t have values.", "response": "def add_empty_etd_ms_fields(etd_ms_dict):\n    \"\"\"Add empty values for ETD_MS fields that don't have values.\"\"\"\n    # Determine which ETD MS elements are missing from the etd_ms_dict.\n    for element in ETD_MS_ORDER:\n        if element not in etd_ms_dict:\n            # Try to create an element with content and qualifier.\n            try:\n                py_object = ETD_MS_CONVERSION_DISPATCH[element](\n                    content='',\n                    qualifier='',\n                )\n            except:\n                # Try to create an element with content.\n                try:\n                    py_object = ETD_MS_CONVERSION_DISPATCH[element](content='')\n                except:\n                    # Try to create an element without content.\n                    try:\n                        py_object = ETD_MS_CONVERSION_DISPATCH[element]()\n                    except:\n                        raise PyuntlException(\n                            'Could not add empty element field.'\n                        )\n                    else:\n                        etd_ms_dict[element] = [{'content': {}}]\n                else:\n                    # Handle element without children.\n                    if not py_object.contained_children:\n                        etd_ms_dict[element] = [{'content': ''}]\n                    else:\n                        etd_ms_dict[element] = [{'content': {}}]\n            else:\n                # Handle element without children.\n                if py_object:\n                    if not py_object.contained_children:\n                        etd_ms_dict[element] = [{'content': '',\n                                                 'qualifier': ''}]\n                else:\n                    etd_ms_dict[element] = [{'content': {},\n                                             'qualifier': ''}]\n            # Add empty contained children.\n            if py_object:\n                for child in py_object.contained_children:\n                    etd_ms_dict[element][0].setdefault('content', {})\n                    etd_ms_dict[element][0]['content'][child] = ''\n    return etd_ms_dict"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfinds the errors in the UNTL dict.", "response": "def find_untl_errors(untl_dict, **kwargs):\n    \"\"\"Add empty required qualifiers to create valid UNTL.\"\"\"\n    fix_errors = kwargs.get('fix_errors', False)\n    error_dict = {}\n    # Loop through all elements that require qualifiers.\n    for element_name in REQUIRES_QUALIFIER:\n        # Loop through the existing elements that require qualifers.\n        for element in untl_dict.get(element_name, []):\n            error_dict[element_name] = 'no_qualifier'\n            # If it should be fixed, set an empty qualifier\n            # if it doesn't have one.\n            if fix_errors:\n                element.setdefault('qualifier', '')\n    # Combine the error dict and UNTL dict into a dict.\n    found_data = {\n        'untl_dict': untl_dict,\n        'error_dict': error_dict,\n    }\n    return found_data"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef untlpy2etd_ms(untl_elements, **kwargs):\n    degree_children = {}\n    date_exists = False\n    seen_creation = False\n    # Make the root element.\n    etd_ms_root = ETD_MS_CONVERSION_DISPATCH['thesis']()\n    for element in untl_elements.children:\n        etd_ms_element = None\n        # Convert the UNTL element to etd_ms where applicable.\n        if element.tag in ETD_MS_CONVERSION_DISPATCH:\n            # Create the etd_ms_element if the element's content\n            # is stored in children nodes.\n            if element.children:\n                etd_ms_element = ETD_MS_CONVERSION_DISPATCH[element.tag](\n                    qualifier=element.qualifier,\n                    children=element.children,\n                )\n            # If we hit a degree element, make just that one.\n            elif element.tag == 'degree':\n                # Make a dict of the degree children information.\n                if element.qualifier in ['name',\n                                         'level',\n                                         'discipline',\n                                         'grantor']:\n                    degree_children[element.qualifier] = element.content\n            # For date elements, limit to first instance of creation date.\n            elif element.tag == 'date':\n                if element.qualifier == 'creation':\n                    # If the root already has a date, delete the child.\n                    for child in etd_ms_root.children:\n                        if child.tag == 'date':\n                            del child\n                            if not seen_creation:\n                                date_exists = False\n                    seen_creation = True\n                    if not date_exists:\n                        # Create the etd_ms element.\n                        etd_ms_element = ETD_MS_CONVERSION_DISPATCH[element.tag](\n                            qualifier=element.qualifier,\n                            content=element.content,\n                        )\n                        date_exists = True\n            # It is a normal element.\n            elif element.tag not in ['date', 'degree']:\n                # Create the etd_ms_element.\n                etd_ms_element = ETD_MS_CONVERSION_DISPATCH[element.tag](\n                    qualifier=element.qualifier,\n                    content=element.content,\n                )\n            # Add the element to the structure if the element exists.\n            if etd_ms_element:\n                etd_ms_root.add_child(etd_ms_element)\n        if element.tag == 'meta':\n            # Initialize ark to False because it may not exist yet.\n            ark = False\n            # Iterate through children and look for ark.\n            for i in etd_ms_root.children:\n                if i.tag == 'identifier' and i.content.startswith(\n                    'http://digital.library.unt.edu/'\n                ):\n                    ark = True\n            # If the ark doesn't yet exist, try and create it.\n            if not ark:\n                # Reset for future tests.\n                ark = False\n                if element.qualifier == 'ark':\n                    ark = element.content\n                if ark is not None:\n                    # Create the ark identifier element and add it.\n                    ark_identifier = ETD_MS_CONVERSION_DISPATCH['identifier'](\n                        ark=ark,\n                    )\n                    etd_ms_root.add_child(ark_identifier)\n    # If children exist for the degree, make a degree element.\n    if degree_children:\n        degree_element = ETD_MS_CONVERSION_DISPATCH['degree']()\n        # When we have all the elements stored, add the children to the\n        # degree node.\n        degree_child_element = None\n        for k, v in degree_children.iteritems():\n            # Create the individual classes for degrees.\n            degree_child_element = ETD_MS_DEGREE_DISPATCH[k](\n                content=v,\n            )\n            # If the keys in degree_children are valid,\n            # add it to the child.\n            if degree_child_element:\n                degree_element.add_child(degree_child_element)\n        etd_ms_root.add_child(degree_element)\n    return etd_ms_root", "response": "Convert the UNTL elements structure into an ETD_MS structure."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates an ETD MS XML file.", "response": "def etd_ms_dict2xmlfile(filename, metadata_dict):\n    \"\"\"Create an ETD MS XML file.\"\"\"\n    try:\n        f = open(filename, 'w')\n        f.write(generate_etd_ms_xml(metadata_dict).encode(\"utf-8\"))\n        f.close()\n    except:\n        raise MetadataGeneratorException(\n            'Failed to create an XML file. Filename: %s' % (filename)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef signal_to_noise_map(self):\n        signal_to_noise_map = np.divide(self.data, self.noise_map)\n        signal_to_noise_map[signal_to_noise_map < 0] = 0\n        return signal_to_noise_map", "response": "The signal - to - noise - map of the data and noise - map which are fitted."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the structure of the most parts of the class cls.", "response": "def structure(cls):\n        # type: () -> Text\n        \"\"\"Get the part structure, as a DNA regex pattern.\n\n        The structure of most parts can be obtained automatically from the\n        part signature and the restriction enzyme used in the Golden Gate\n        assembly.\n\n        Warning:\n            If overloading this method, the returned pattern must include 3\n            capture groups to capture the following features:\n\n            1. The upstream (5') overhang sequence\n            2. The vector placeholder sequence\n            3. The downstream (3') overhang sequence\n\n        \"\"\"\n\n        if cls.signature is NotImplemented:\n            raise NotImplementedError(\"no signature defined\")\n\n        up = cls.cutter.elucidate()\n        down = str(Seq(up).reverse_complement())\n        ovhg = cls.cutter.ovhgseq\n        upsig, downsig = cls.signature\n\n        if cls.cutter.is_5overhang():\n            upsite = \"^{}_\".format(ovhg)\n            downsite = \"_{}^\".format(Seq(ovhg).reverse_complement())\n        else:\n            upsite = \"_{}^\".format(ovhg)\n            downsite = \"^{}_\".format(Seq(ovhg).reverse_complement())\n\n        if issubclass(cls, AbstractModule):\n            return \"\".join(\n                [\n                    up.replace(upsite, \"({})(\".format(upsig)),\n                    \"N*\",\n                    down.replace(downsite, \")({})\".format(downsig)),\n                ]\n            )\n        elif issubclass(cls, AbstractVector):\n            return \"\".join(\n                [\n                    down.replace(downsite, \"({})(\".format(downsig)),\n                    \"N*\",\n                    up.replace(upsite, \")({})\".format(upsig)),\n                ]\n            )\n        else:\n            raise RuntimeError(\"Part must be either a module or a vector!\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload the record in a concrete subclass of this type.", "response": "def characterize(cls, record):\n        \"\"\"Load the record in a concrete subclass of this type.\n        \"\"\"\n        classes = list(cls.__subclasses__())\n        if not isabstract(cls):\n            classes.append(cls)\n        for subclass in classes:\n            entity = subclass(record)\n            if entity.is_valid():\n                return entity\n        raise RuntimeError(\"could not find the type for '{}'\".format(record.id))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrequest a pseudo - terminal from the server.", "response": "def get_pty(self, term='vt100', width=80, height=24, width_pixels=0,\n                height_pixels=0):\n        \"\"\"\n        Request a pseudo-terminal from the server.  This is usually used right\n        after creating a client channel, to ask the server to provide some\n        basic terminal semantics for a shell invoked with `invoke_shell`.\n        It isn't necessary (or desirable) to call this method if you're going\n        to exectue a single command with `exec_command`.\n\n        :param str term: the terminal type to emulate (for example, ``'vt100'``)\n        :param int width: width (in characters) of the terminal screen\n        :param int height: height (in characters) of the terminal screen\n        :param int width_pixels: width (in pixels) of the terminal screen\n        :param int height_pixels: height (in pixels) of the terminal screen\n        \n        :raises SSHException:\n            if the request was rejected or the channel was closed\n        \"\"\"\n        if self.closed or self.eof_received or self.eof_sent or not self.active:\n            raise SSHException('Channel is not open')\n        m = Message()\n        m.add_byte(cMSG_CHANNEL_REQUEST)\n        m.add_int(self.remote_chanid)\n        m.add_string('pty-req')\n        m.add_boolean(True)\n        m.add_string(term)\n        m.add_int(width)\n        m.add_int(height)\n        m.add_int(width_pixels)\n        m.add_int(height_pixels)\n        m.add_string(bytes())\n        self._event_pending()\n        self.transport._send_user_message(m)\n        self._wait_for_event()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninvokes an interactive shell session on this channel.", "response": "def invoke_shell(self):\n        \"\"\"\n        Request an interactive shell session on this channel.  If the server\n        allows it, the channel will then be directly connected to the stdin,\n        stdout, and stderr of the shell.\n        \n        Normally you would call `get_pty` before this, in which case the\n        shell will operate through the pty, and the channel will be connected\n        to the stdin and stdout of the pty.\n        \n        When the shell exits, the channel will be closed and can't be reused.\n        You must open a new channel if you wish to open another shell.\n        \n        :raises SSHException: if the request was rejected or the channel was\n            closed\n        \"\"\"\n        if self.closed or self.eof_received or self.eof_sent or not self.active:\n            raise SSHException('Channel is not open')\n        m = Message()\n        m.add_byte(cMSG_CHANNEL_REQUEST)\n        m.add_int(self.remote_chanid)\n        m.add_string('shell')\n        m.add_boolean(True)\n        self._event_pending()\n        self.transport._send_user_message(m)\n        self._wait_for_event()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef resize_pty(self, width=80, height=24, width_pixels=0, height_pixels=0):\n        if self.closed or self.eof_received or self.eof_sent or not self.active:\n            raise SSHException('Channel is not open')\n        m = Message()\n        m.add_byte(cMSG_CHANNEL_REQUEST)\n        m.add_int(self.remote_chanid)\n        m.add_string('window-change')\n        m.add_boolean(False)\n        m.add_int(width)\n        m.add_int(height)\n        m.add_int(width_pixels)\n        m.add_int(height_pixels)\n        self.transport._send_user_message(m)", "response": "This method is used to resize the pseudo - terminal."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrequest a forward SSH Agent on this channel.", "response": "def request_forward_agent(self, handler):\n        \"\"\"\n        Request for a forward SSH Agent on this channel.\n        This is only valid for an ssh-agent from OpenSSH !!!\n\n        :param function handler:\n            a required handler to use for incoming SSH Agent connections\n\n        :return: True if we are ok, else False (at that time we always return ok)\n\n        :raises: SSHException in case of channel problem.\n        \"\"\"\n        if self.closed or self.eof_received or self.eof_sent or not self.active:\n            raise SSHException('Channel is not open')\n\n        m = Message()\n        m.add_byte(cMSG_CHANNEL_REQUEST)\n        m.add_int(self.remote_chanid)\n        m.add_string('auth-agent-req@openssh.com')\n        m.add_boolean(False)\n        self.transport._send_user_message(m)\n        self.transport._set_forward_agent_handler(handler)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef send_stderr(self, s):\n        size = len(s)\n        self.lock.acquire()\n        try:\n            size = self._wait_for_send_window(size)\n            if size == 0:\n                # eof or similar\n                return 0\n            m = Message()\n            m.add_byte(cMSG_CHANNEL_EXTENDED_DATA)\n            m.add_int(self.remote_chanid)\n            m.add_int(1)\n            m.add_string(s[:size])\n        finally:\n            self.lock.release()\n        # Note: We release self.lock before calling _send_user_message.\n        # Otherwise, we can deadlock during re-keying.\n        self.transport._send_user_message(m)\n        return size", "response": "Send data to the channel on the stderr stream."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef global_request(self, kind, data=None, wait=True):\n        if wait:\n            self.completion_event = threading.Event()\n        m = Message()\n        m.add_byte(cMSG_GLOBAL_REQUEST)\n        m.add_string(kind)\n        m.add_boolean(wait)\n        if data is not None:\n            m.add(*data)\n        self._log(DEBUG, 'Sending global request \"%s\"' % kind)\n        self._send_user_message(m)\n        if not wait:\n            return None\n        while True:\n            self.completion_event.wait(0.1)\n            if not self.active:\n                return None\n            if self.completion_event.isSet():\n                break\n        return self.global_response", "response": "Makes a global request to the remote host."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncomputing the key for the given id and nbytes.", "response": "def _compute_key(self, id, nbytes):\n        \"\"\"id is 'A' - 'F' for the various keys used by ssh\"\"\"\n        m = Message()\n        m.add_mpint(self.K)\n        m.add_bytes(self.H)\n        m.add_byte(b(id))\n        m.add_bytes(self.session_id)\n        out = sofar = sha1(m.asbytes()).digest()\n        while len(out) < nbytes:\n            m = Message()\n            m.add_mpint(self.K)\n            m.add_bytes(self.H)\n            m.add_bytes(sofar)\n            digest = sha1(m.asbytes()).digest()\n            out += digest\n            sofar += digest\n        return out[:nbytes]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsend a KEXINIT message to the other side that we don t know about.", "response": "def _send_kex_init(self):\n        \"\"\"\n        announce to the other side that we'd like to negotiate keys, and what\n        kind of key negotiation we support.\n        \"\"\"\n        self.clear_to_send_lock.acquire()\n        try:\n            self.clear_to_send.clear()\n        finally:\n            self.clear_to_send_lock.release()\n        self.in_kex = True\n        if self.server_mode:\n            if (self._modulus_pack is None) and ('diffie-hellman-group-exchange-sha1' in self._preferred_kex):\n                # can't do group-exchange if we don't have a pack of potential primes\n                pkex = list(self.get_security_options().kex)\n                pkex.remove('diffie-hellman-group-exchange-sha1')\n                self.get_security_options().kex = pkex\n            available_server_keys = list(filter(list(self.server_key_dict.keys()).__contains__,\n                                                self._preferred_keys))\n        else:\n            available_server_keys = self._preferred_keys\n\n        m = Message()\n        m.add_byte(cMSG_KEXINIT)\n        m.add_bytes(os.urandom(16))\n        m.add_list(self._preferred_kex)\n        m.add_list(available_server_keys)\n        m.add_list(self._preferred_ciphers)\n        m.add_list(self._preferred_ciphers)\n        m.add_list(self._preferred_macs)\n        m.add_list(self._preferred_macs)\n        m.add_list(self._preferred_compression)\n        m.add_list(self._preferred_compression)\n        m.add_string(bytes())\n        m.add_string(bytes())\n        m.add_boolean(False)\n        m.add_int(0)\n        # save a copy for later (needed to compute a hash)\n        self.local_kex_init = m.asbytes()\n        self._send_message(m)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nswitches on newly negotiated encryption parameters for inbound traffic", "response": "def _activate_inbound(self):\n        \"\"\"switch on newly negotiated encryption parameters for inbound traffic\"\"\"\n        block_size = self._cipher_info[self.remote_cipher]['block-size']\n        if self.server_mode:\n            IV_in = self._compute_key('A', block_size)\n            key_in = self._compute_key('C', self._cipher_info[self.remote_cipher]['key-size'])\n        else:\n            IV_in = self._compute_key('B', block_size)\n            key_in = self._compute_key('D', self._cipher_info[self.remote_cipher]['key-size'])\n        engine = self._get_cipher(self.remote_cipher, key_in, IV_in)\n        mac_size = self._mac_info[self.remote_mac]['size']\n        mac_engine = self._mac_info[self.remote_mac]['class']\n        # initial mac keys are done in the hash's natural size (not the potentially truncated\n        # transmission size)\n        if self.server_mode:\n            mac_key = self._compute_key('E', mac_engine().digest_size)\n        else:\n            mac_key = self._compute_key('F', mac_engine().digest_size)\n        self.packetizer.set_inbound_cipher(engine, block_size, mac_engine, mac_size, mac_key)\n        compress_in = self._compression_info[self.remote_compression][1]\n        if (compress_in is not None) and ((self.remote_compression != 'zlib@openssh.com') or self.authenticated):\n            self._log(DEBUG, 'Switching on inbound compression ...')\n            self.packetizer.set_inbound_compressor(compress_in())"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef enable_user(self, user):\n        if user in self.ssh_pool._ssh_clients:\n            return\n\n        if user == 'root':\n            _root_ssh_client = ssh.SshClient(\n                hostname=self.hostname,\n                user='root',\n                key_filename=self._key_filename,\n                via_ip=self.via_ip)\n\n            # connect as a root user\n            _root_ssh_client.start()\n            result, _ = _root_ssh_client.run('uname -a')\n\n            image_user = None\n            # check if root is not allowed\n            if 'Please login as the user \"cloud-user\"' in result:\n                image_user = 'cloud-user'\n                _root_ssh_client.stop()\n            elif 'Please login as the user \"fedora\" rather than the user \"root\"' in result:\n                image_user = 'fedora'\n                _root_ssh_client.stop()\n            elif 'Please login as the user \"centos\" rather than the user \"root\"' in result:\n                image_user = 'centos'\n                _root_ssh_client.stop()\n\n            if image_user:\n                self.enable_user(image_user)\n                LOG.info('enabling the root user')\n                _cmd = \"sudo sed -i 's,.*ssh-rsa,ssh-rsa,' /root/.ssh/authorized_keys\"\n                self.ssh_pool.run(image_user, _cmd)\n                _root_ssh_client.start()\n            self.ssh_pool.add_ssh_client('root', _root_ssh_client)\n            return\n\n        # add the cloud user to the ssh pool\n        self.ssh_pool.build_ssh_client(\n            hostname=self.hostname,\n            user=user,\n            key_filename=self._key_filename,\n            via_ip=self.via_ip)", "response": "Enable the root account on the remote host."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupload a local file on the remote host.", "response": "def send_file(self, local_path, remote_path, user='root', unix_mode=None):\n        \"\"\"Upload a local file on the remote host.\n        \"\"\"\n        self.enable_user(user)\n        return self.ssh_pool.send_file(user, local_path, remote_path, unix_mode=unix_mode)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupload a directory on the remote host.", "response": "def send_dir(self, local_path, remote_path, user='root'):\n        \"\"\"Upload a directory on the remote host.\n        \"\"\"\n        self.enable_user(user)\n        return self.ssh_pool.send_dir(user, local_path, remote_path)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a file on the remote host.", "response": "def create_file(self, path, content, mode='w', user='root'):\n        \"\"\"Create a file on the remote host.\n        \"\"\"\n        self.enable_user(user)\n        return self.ssh_pool.create_file(user, path, content, mode)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run(self, cmd, user='root', sudo=False, ignore_error=False,\n            success_status=(0,), error_callback=None, custom_log=None, retry=0):\n        \"\"\"Run a command on the remote host.\n        \"\"\"\n        self.enable_user(user)\n        return self.ssh_pool.run(\n            user, cmd, sudo=sudo, ignore_error=ignore_error,\n            success_status=success_status, error_callback=error_callback,\n            custom_log=custom_log, retry=retry)", "response": "Run a command on the remote host."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef yum_install(self, packages, ignore_error=False):\n        return self.run('yum install -y --quiet ' + ' '.join(packages), ignore_error=ignore_error, retry=5)", "response": "Install some packages on the remote host."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nregister the host on the RHSM.", "response": "def rhsm_register(self, rhsm):\n        \"\"\"Register the host on the RHSM.\n\n        :param rhsm: a dict of parameters (login, password, pool_id)\n        \"\"\"\n        # Get rhsm credentials\n        login = rhsm.get('login')\n        password = rhsm.get('password', os.environ.get('RHN_PW'))\n        pool_id = rhsm.get('pool_id')\n        # Ensure the RHEL beta channel are disabled\n        self.run('rm /etc/pki/product/69.pem', ignore_error=True)\n        custom_log = 'subscription-manager register --username %s --password *******' % login\n        self.run(\n            'subscription-manager register --username %s --password \"%s\"' % (\n                login, password),\n            success_status=(0, 64),\n            custom_log=custom_log,\n            retry=3)\n        if pool_id:\n            self.run('subscription-manager attach --pool %s' % pool_id)\n        else:\n            self.run('subscription-manager attach --auto')\n        self.rhsm_active = True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nenable a list of RHSM repositories.", "response": "def enable_repositories(self, repositories):\n        \"\"\"Enable a list of RHSM repositories.\n\n        :param repositories: a dict in this format:\n            [{'type': 'rhsm_channel', 'name': 'rhel-7-server-rpms'}]\n        \"\"\"\n        for r in repositories:\n            if r['type'] != 'rhsm_channel':\n                continue\n            if r['name'] not in self.rhsm_channels:\n                self.rhsm_channels.append(r['name'])\n\n        if self.rhsm_active:\n            subscription_cmd = \"subscription-manager repos '--disable=*' --enable=\" + ' --enable='.join(\n                self.rhsm_channels)\n            self.run(subscription_cmd)\n\n        repo_files = [r for r in repositories if r['type'] == 'yum_repo']\n        for repo_file in repo_files:\n            self.create_file(repo_file['dest'], repo_file['content'])\n\n        packages = [r['name'] for r in repositories if r['type'] == 'package']\n        if packages:\n            self.yum_install(packages)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_stack_user(self):\n        self.run('adduser -m stack', success_status=(0, 9))\n        self.create_file('/etc/sudoers.d/stack', 'stack ALL=(root) NOPASSWD:ALL\\n')\n        self.run('mkdir -p /home/stack/.ssh')\n        self.run('cp /root/.ssh/authorized_keys /home/stack/.ssh/authorized_keys')\n        self.run('chown -R stack:stack /home/stack/.ssh')\n        self.run('chmod 700 /home/stack/.ssh')\n        self.run('chmod 600 /home/stack/.ssh/authorized_keys')\n        self.ssh_pool.build_ssh_client(self.hostname, 'stack',\n                                       self._key_filename,\n                                       self.via_ip)", "response": "Create the stack user on the machine."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fetch_image(self, path, dest, user='root'):\n        self.run('test -f %s || curl -L -s -o %s %s' % (dest, dest, path),\n                 user=user, ignore_error=True)", "response": "Fetch an image from a remote location."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncleaning up unnecessary packages from the system.", "response": "def clean_system(self):\n        \"\"\"Clean up unnecessary packages from the system.\n        \"\"\"\n        self.run('systemctl disable NetworkManager', success_status=(0, 1))\n        self.run('systemctl stop NetworkManager', success_status=(0, 5))\n        self.run('pkill -9 dhclient', success_status=(0, 1))\n        self.yum_remove(['cloud-init', 'NetworkManager'])\n        self.run('systemctl enable network')\n        self.run('systemctl restart network')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndoing a yum update on the system.", "response": "def yum_update(self, allow_reboot=False):\n        \"\"\"Do a yum update on the system.\n\n        :param allow_reboot: If True and if a new kernel has been installed,\n        the system will be rebooted\n        \"\"\"\n        self.run('yum clean all')\n        self.run('test -f /usr/bin/subscription-manager && subscription-manager repos --list-enabled',\n                 ignore_error=True)\n        self.run('yum repolist')\n        self.run('yum update -y --quiet', retry=3)\n        # reboot if a new initrd has been generated since the boot\n        if allow_reboot:\n            self.run('grubby --set-default $(ls /boot/vmlinuz-*.x86_64|tail -1)')\n            default_kernel = self.run('grubby --default-kernel')[0].rstrip()\n            cur_kernel = self.run('uname -r')[0].rstrip()\n            if cur_kernel not in default_kernel:\n                self.run('reboot', ignore_error=True)\n            self.ssh_pool.stop_all()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nhelp to enable SELinux on the host.", "response": "def set_selinux(self, state):\n        \"\"\"Help to enable/disable SELinux on the host.\n        \"\"\"\n        allowed_states = ('enforcing', 'permissive', 'disabled')\n        if state not in allowed_states:\n            raise Exception\n        self.run('setenforce %s' % state)\n        self.create_file('/etc/sysconfig/selinux',\n                         'SELINUX=%s\\nSELINUXTYPE=targeted\\n' % state)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef queryjoin(argdict=dict(), **kwargs):\n    if kwargs: argdict.update(kwargs)\n    \n    if issubclass(type(argdict), dict):                    \n        args = [\"{}={}\".format(k, v) for k, v in argdict.items() if v != None]\n    return \"&\".join(args)", "response": "Turn a dictionary into a querystring for a URL."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nbeing an object iterable like a list?", "response": "def listlike(obj):\n    \"\"\"Is an object iterable like a list (and not a string)?\"\"\"\n    \n    return hasattr(obj, \"__iter__\") \\\n    and not issubclass(type(obj), str)\\\n    and not issubclass(type(obj), unicode)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert a dict that contains at least pid ln rtdir and pt into a GeoJSON FeatureCollection.", "response": "def patterntogeojson(pattern, color=False):\n    import geojson\n    \n    \"\"\"\n    Turns an an API response of a pattern into a GeoJSON FeatureCollection.\n    Takes a dict that contains at least `pid`, `ln`, `rtdir`, and `pt`.\n    \n    >>> api_response = {'ln': '123.45', 'pid': '1', 'pt': [], 'rtdir': 'OUTBOUND'}\n    >>> pt1 = {'lat': '40.449', 'lon': '-79.983', 'seq': '1', 'typ': 'W'}\n    >>> pt2 = {'stpid': '1', 'seq': '2', 'stpnm': '3142 Test Ave FS', 'lon': '-79.984', 'pdist': '42.4', 'lat': '40.450', 'typ': 'S'}\n    >>> api_response['pt'] = [pt1, pt2]\n    >>> patterntogeojson(api_response) # doctest: +ELLIPSIS\n    {\"features\": [{\"geometry\": {\"coordinates\": ... \"name\": \"3142 Test Ave FS\", \"type\": \"stop\"}, \"type\": \"Feature\"}], \"type\": \"FeatureCollection\"}\n    \"\"\" \n    # Base properties for the pattern\n    properties = dict(\n        pid = pattern['pid'],\n        length = pattern['ln'],\n        direction = pattern['rtdir'],\n        color = color or \"\"\n    )        \n        \n    points = [(float(point.get('lon')), float(point.get('lat'))) for point in pattern['pt']]\n    \n    return geojson.LineString(coordinates=points, properties=properties)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_by_range(model_cls, *args, **kwargs):\n    start_timestamp = kwargs.get('start_timestamp')\n    end_timestamp = kwargs.get('end_timestamp')\n    if (start_timestamp is not None) and (end_timestamp is not None) and (start_timestamp > end_timestamp):\n        raise InvalidTimestampRange\n\n    models = model_cls.read_time_range(*args, end_timestamp=end_timestamp).order_by(model_cls.time_order)\n\n    #\n    # start time -> Loop through until you find one set before or on start\n    #\n    if start_timestamp is not None:\n        index = 0\n        for index, model in enumerate(models, start=1):\n            if model.timestamp <= start_timestamp:\n                break\n        models = models[:index]\n\n    return models", "response": "Get ordered list of models for the specified time range."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef read_time_range(cls, *args, **kwargs):\n        criteria = list(args)\n        start = kwargs.get('start_timestamp')\n        end = kwargs.get('end_timestamp')\n        if start is not None:\n            criteria.append(cls.time_order <= -start)\n        if end is not None:\n            criteria.append(cls.time_order >= -end)\n        return cls.read(*criteria)", "response": "Reads all timezones set within a given time. Uses time_dsc_index\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds data to the parameter set and return the ID of the new object.", "response": "def add_data(self, data, metadata=None):\n        \"\"\"Add data to the parameter set\n\n        Parameters\n        ----------\n        data: numpy.ndarray\n            one or more parameter sets. It must either be 1D or 2D, with the\n            first dimension the number of parameter sets (K), and the second\n            the number of elements (N): K x N\n        metadata: object, optional\n            the provided object will be stored in in the metadata dict and can\n            be received with the ID that is returned. If multiple (K) datasets\n            are added at ones, provide a list of objects with len K.\n\n        Returns\n        -------\n        int, ID\n            ID which can be used to access the parameter set\n\n        Examples\n        --------\n\n        >>> # suppose that grid is a fully initialized grid oject with 100\n            # elements\n            parman = ParMan(grid)\n            #\n            one_data_set = np.ones(100)\n            cid = parman.add_data(one_data_set)\n            print(parman.parsets[cid])\n            two_data_sets = np.ones((2, 100))\n            cids = parman.add_data(two_data_sets)\n            print(cids)\n        [0, ]\n        [1, 2]\n\n        \"\"\"\n        subdata = np.atleast_2d(data)\n\n        # we try to accommodate transposed input\n        if subdata.shape[1] != self.grid.nr_of_elements:\n            if subdata.shape[0] == self.grid.nr_of_elements:\n                subdata = subdata.T\n            else:\n                raise Exception(\n                    'Number of values does not match the number of ' +\n                    'elements in the grid'\n                )\n\n        # now make sure that metadata can be zipped with the subdata\n        K = subdata.shape[0]\n        if metadata is not None:\n            if K > 1:\n                if(not isinstance(metadata, (list, tuple)) or\n                   len(metadata) != K):\n                    raise Exception('metadata does not fit the provided data')\n            else:\n                # K == 1\n                metadata = [metadata, ]\n\n        if metadata is None:\n            metadata = [None for i in range(0, K)]\n\n        return_ids = []\n        for dataset, meta in zip(subdata, metadata):\n            cid = self._get_next_index()\n            self.parsets[cid] = dataset\n            self.metadata[cid] = meta\n            return_ids.append(cid)\n\n        if len(return_ids) == 1:\n            return return_ids[0]\n        else:\n            return return_ids"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load_inv_result(self, filename, columns=2):\n        assert os.path.isfile(filename)\n        try:\n            iterator = iter(columns)\n        except TypeError:\n            # not iterable\n            iterator = [columns, ]\n\n        pid_list = []\n        for column in iterator:\n            data = np.loadtxt(filename, skiprows=1)\n            pid = self.add_data(data[:, column])\n            pid_list.append(pid)\n\n        if len(pid_list) == 1:\n            return pid_list[0]\n        else:\n            return pid_list", "response": "Load one parameter set from a rho*.mag or rho*.pha file produced by\n            CRTomo."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading one parameter set from a file which contains one value per line per line.", "response": "def load_model_from_file(self, filename):\n        \"\"\"Load one parameter set from a file which contains one value per line\n\n        No row is skipped.\n\n        Parameters\n        ----------\n        filename : string, file path\n            Filename to loaded data from\n\n        Returns\n        -------\n        pid : int\n            ID of parameter set\n        \"\"\"\n        assert os.path.isfile(filename)\n        data = np.loadtxt(filename).squeeze()\n        assert len(data.shape) == 1\n        pid = self.add_data(data)\n        return pid"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload real and imaginary parts from a sens. dat file generated by CRMod", "response": "def load_from_sens_file(self, filename):\n        \"\"\"Load real and imaginary parts from a sens.dat file generated by\n        CRMod\n\n        Parameters\n        ----------\n        filename: string\n            filename of sensitivity file\n\n        Returns\n        -------\n        nid_re: int\n            ID of real part of sensitivities\n        nid_im: int\n            ID of imaginary part of sensitivities\n        \"\"\"\n        sens_data = np.loadtxt(filename, skiprows=1)\n        nid_re = self.add_data(sens_data[:, 2])\n        nid_im = self.add_data(sens_data[:, 3])\n        return nid_re, nid_im"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef save_to_rho_file(self, filename, cid_mag, cid_pha=None):\n        mag_data = self.parsets[cid_mag]\n        if cid_pha is None:\n            pha_data = np.zeros(mag_data.shape)\n        else:\n            pha_data = self.parsets[cid_pha]\n\n        with open(filename, 'wb') as fid:\n            fid.write(\n                bytes(\n                    '{0}\\n'.format(self.grid.nr_of_elements),\n                    'utf-8',\n                )\n            )\n            np.savetxt(\n                fid,\n                np.vstack((\n                    mag_data,\n                    pha_data,\n                )).T,\n                fmt='%f %f'\n            )", "response": "Save one or two parameter sets in the rho. dat forward model format."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_empty_dataset(self, value=1):\n        subdata = np.ones(self.grid.nr_of_elements) * value\n        pid = self.add_data(subdata)\n        return pid", "response": "Create an empty data set. Empty means all elements have the same value."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncleans the pid to be used in the log file.", "response": "def _clean_pid(self, pid):\n        \"\"\"if pid is a number, don't do anything. If pid is a list with one\n        entry, strip the list and return the number. If pid contains more than\n        one entries, do nothing.\n        \"\"\"\n        if isinstance(pid, (list, tuple)):\n            if len(pid) == 1:\n                return pid[0]\n            else:\n                return pid\n        return pid"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef modify_area(self, pid, xmin, xmax, zmin, zmax, value):\n        area_polygon = shapgeo.Polygon(\n            ((xmin, zmax), (xmax, zmax), (xmax, zmin), (xmin, zmin))\n        )\n        self.modify_polygon(pid, area_polygon, value)", "response": "Modify the given dataset in the rectangular area given by the\n        parameters and assign all parameters inside this area the given value."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmodify parts of a parameter set by setting all parameters located in or touching the provided shapely. geometry. Polygon instance.", "response": "def modify_polygon(self, pid, polygon, value):\n        \"\"\"Modify parts of a parameter set by setting all parameters located\n        in, or touching, the provided :class:`shapely.geometry.Polygon`\n        instance.\n\n        Parameters\n        ----------\n        pid: int\n            id of parameter set to vary\n        polygon: :class:`shapely.geometry.Polygon` instance\n            polygon that determines the area to modify\n        value: float\n            value that is assigned to all elements in the polygon\n\n        Examples\n        --------\n        >>> import shapely.geometry\n            polygon = shapely.geometry.Polygon((\n                (2, 0), (4, -1), (2, -1)\n            ))\n            tdman.parman.modify_polygon(pid, polygon, 3)\n\n        \"\"\"\n        # create grid polygons\n        grid_polygons = []\n        for x, z in zip(self.grid.grid['x'], self.grid.grid['z']):\n            coords = [(a, b) for a, b in zip(x, z)]\n            grid_polygons.append(\n                shapgeo.Polygon(coords)\n            )\n\n        # now determine elements in area\n        elements_in_area = []\n        for nr, element in enumerate(grid_polygons):\n            if polygon.contains(element):\n                elements_in_area.append(nr)\n            elif polygon.equals(element):\n                elements_in_area.append(nr)\n            elif polygon.crosses(element):\n                elements_in_area.append(nr)\n                # only take crossed elements with at least A % overlap\n                # int_area = polygon.intersect(element).area\n                # print('overlap: ',\n                #       int_area,\n                #       element.area,\n                #       element.area / int_area\n                #       )\n\n        # change the values\n        pid_clean = self._clean_pid(pid)\n        self.parsets[pid_clean][elements_in_area] = value"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nextracts values at certain points in a given parameter set.", "response": "def extract_points(self, pid, points):\n        \"\"\"Extract values at certain points in the grid from a given parameter\n        set. Cells are selected by interpolating the centroids of the cells\n        towards the line using a \"nearest\" scheme.\n\n        Note that data is only returned for the points provided. If you want to\n        extract multiple data points along a line, defined by start and end\n        point, use the **extract_along_line** function.\n\n        Parameters\n        ----------\n        pid: int\n            The parameter id to extract values from\n        points: Nx2 numpy.ndarray\n            (x, y) pairs\n\n        Returns\n        -------\n        values: numpy.ndarray (n x 1)\n            data values for extracted data points\n        \"\"\"\n        xy = self.grid.get_element_centroids()\n        data = self.parsets[pid]\n\n        iobj = spi.NearestNDInterpolator(xy, data)\n        values = iobj(points)\n        return values"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef extract_along_line(self, pid, xy0, xy1, N=10):\n        assert N >= 2\n        xy0 = np.array(xy0).squeeze()\n        xy1 = np.array(xy1).squeeze()\n        assert xy0.size == 2\n        assert xy1.size == 2\n\n        # compute points\n        points = [(x, y) for x, y in zip(\n            np.linspace(xy0[0], xy1[0], N), np.linspace(xy0[1], xy1[1], N)\n        )]\n        result = self.extract_points(pid, points)\n\n        results_xyv = np.hstack((\n            points,\n            result[:, np.newaxis]\n        ))\n        return results_xyv", "response": "Extract parameter values along a given line."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nextracting all data points whose element centroid lies within the given polygon.", "response": "def extract_polygon_area(self, pid, polygon_points):\n        \"\"\"Extract all data points whose element centroid lies within the given\n        polygon.\n\n        Parameters\n        ----------\n\n        Returns\n        -------\n        \"\"\"\n        polygon = shapgeo.Polygon(polygon_points)\n        xy = self.grid.get_element_centroids()\n        in_poly = []\n        for nr, point in enumerate(xy):\n            if shapgeo.Point(point).within(polygon):\n                in_poly.append(nr)\n\n        values = self.parsets[pid][in_poly]\n        return np.array(in_poly), values"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef rotate_point(xorigin, yorigin, x, y, angle):\n    rotx = (x - xorigin) * np.cos(angle) - (y - yorigin) * np.sin(angle)\n    roty = (x - yorigin) * np.sin(angle) + (y - yorigin) * np.cos(angle)\n    return rotx, roty", "response": "Rotate the given point by angle"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nhomogenizing the grid by homogenizing the electrodes", "response": "def homogenize_grid(grid_old, dx, dy):\n    \"\"\"\n    1) fit line through electrodes\n    2) rotate electrodes so that line lies in the horizontal plane\n    3) translate z-coordinates so that all z-coordinates are negative\n    \"\"\"\n\n    # 1 line fit\n    x = grid_old.electrodes[:, 0]\n    y = grid_old.electrodes[:, 1]\n    sort_indices = np.argsort(x)\n    x_sort = x[sort_indices]\n    y_sort = y[sort_indices]\n    p = np.polyfit(x_sort, y_sort, 1)\n\n    # 2. rotate around first electrode\n    offsetx = x_sort[0]\n    offsety = y_sort[0]\n\n    alpha = -np.arctan2(p[0], 1.0)  # * 180 / np.pi\n\n    xn = []\n    yn = []\n    for xc, yc in zip(x, y):\n        rotx, roty = rotate_point(offsetx, offsety, xc, yc, alpha)\n        xn.append(rotx + offsetx)\n        yn.append(roty + offsety)\n\n    new_coordinates = np.vstack((xn, yn)).T\n\n    # move vertically\n\n    # this line is a horizontal line\n    p_rot = np.polyfit(\n        new_coordinates[:, 0],\n        new_coordinates[:, 1],\n        1\n    )\n    y_rot = np.polyval(\n        p_rot,\n        new_coordinates[:, 0],\n    )\n    ymax = y_rot[0]\n\n    new_coordinates_trans = np.copy(new_coordinates)\n    new_coordinates_trans[:, 1] -= ymax\n\n    #\n    fig, ax = plt.subplots(1, 1)\n    ax.scatter(x, y, color='r', label='original')\n\n    ax.plot(\n        x,\n        np.polyval(p, x),\n        '-',\n        label='fit',\n        color='r',\n    )\n\n    ax.scatter(\n        xn, yn,\n        color='c',\n        label='rotated',\n    )\n\n    ax.plot(\n        xn,\n        y_rot,\n        '-',\n        label='fit',\n        color='c',\n    )\n\n    ax.scatter(\n        new_coordinates_trans[:, 0],\n        new_coordinates_trans[:, 1],\n        label='homog',\n    )\n\n    # plot the line through the new coordintes\n    pnew = np.polyfit(\n        new_coordinates_trans[:, 0],\n        new_coordinates_trans[:, 1],\n        1\n    )\n    ax.plot(\n        new_coordinates_trans[:, 0],\n        np.polyval(pnew, new_coordinates_trans[:, 0]),\n        '-',\n        label='fit homogenized',\n    )\n\n    ax.legend(loc='best')\n\n    ax.set_xlabel('x [m]')\n    ax.set_ylabel('y [m]')\n\n    fig.tight_layout()\n    fig.savefig('output_electrodes.png', dpi=300)\n\n    # electrodes = np.hstack((\n    # boundaries\n    bx = new_coordinates_trans[sort_indices, 0]\n    by = new_coordinates_trans[sort_indices, 1]\n    btype = [12 for i in bx]\n\n    # add boundary\n    # get deepest boundary coordinate\n    y1 = by[-1] - dy\n    y2 = by[0] - dy\n\n    ymin = min(y1, y2)\n\n    bx = np.hstack(\n        (bx[0] - dx,\n         bx,\n         [bx[-1] + dx, bx[-1] + dx, bx[0] - dx])\n    )\n\n    by = np.hstack(\n        (by[0],\n         by,\n         [by[-1], ymin, ymin]\n         )\n    )\n\n    btype = np.hstack((12,\n                       btype,\n                       [11, 11, 11]))\n\n    boundaries = np.vstack((bx, by, btype)).T\n\n    # fig, ax = plt.subplots(1, 1)\n    # ax.scatter(bx, by)\n    # ax.set_aspect('equal')\n    # fig.tight_layout()\n    # fig.savefig('boundaries.png', dpi=300)\n\n    grid_new = grid_container(None, None, grid_old.char_length_file)\n    grid_new.boundaries = np.copy(boundaries)\n    grid_new.electrodes = np.copy(new_coordinates_trans)\n\n    fig, ax = plt.subplots(1, 1)\n    ax.scatter(bx, by, color='g', label='boundaries')\n    ax.scatter(new_coordinates[:, 0], new_coordinates[:, 1], color='g',\n               label='electrodes')\n    ax.set_aspect('equal')\n    ax.legend()\n    fig.tight_layout()\n    fig.savefig('output_boundaries.png', dpi=300)\n\n    def transform_back(data):\n        new_data = np.copy(data)\n        new_data[:, 1] += ymax\n        new_data[:, 0] -= offsetx\n        new_data[:, 1] -= offsety\n\n        tmpx = (new_data[:, 0]) * np.cos(-alpha) - (new_data[:, 1]) * np.sin(\n            -alpha)\n        tmpy = (new_data[:, 0]) * np.sin(-alpha) + (new_data[:, 1]) * np.cos(\n            -alpha)\n        tmpx += offsetx\n        tmpy += offsety\n        return tmpx, tmpy\n\n    shell_script = ''\n    shell_script += '#!/bin/bash\\n'\n    shell_script += 'cr_trig_create grid\\n'\n\n    cmd1 = ''.join((\n        'grid_translate -e grid/elem.dat ',\n        '--dx {0} --dz {1} -o elem_trans1.dat'.format(\n            offsetx, ymax - offsety)\n    ))\n    cmd2 = ''.join((\n        'grid_rotate -e elem_trans1.dat ',\n        '-a {0} -o elem_trans1_rot1.dat'.format(-alpha * 180 / np.pi)\n    ))\n    cmd3 = ''.join((\n        'grid_translate -e elem_trans1_rot1.dat ',\n        '--dx {0} --dz {1} -o elem_trans1_rot1_trans2.dat'.format(\n            offsetx, offsety)\n    ))\n    shell_script += cmd1 + '\\n'\n    shell_script += cmd2 + '\\n'\n    shell_script += cmd3 + '\\n'\n\n    shell_script += ''.join((\n        'grid_plot_wireframe --fancy -t grid/elec.dat ',\n        '-e elem_trans1_rot1_trans2.dat -o trans1_rot1_trans2.png'\n    ))\n\n    grid_new.script = shell_script\n\n    tmpx, tmpy = transform_back(grid_new.electrodes)\n    bx, by = transform_back(grid_new.boundaries[:, 0:2])\n\n    grid_map = grid_container(char_length_file=grid_old.char_length_file)\n    grid_map.electrodes = np.vstack((tmpx, tmpy)).T\n    grid_map.boundaries = np.vstack((bx, by, grid_new.boundaries[:, 2])).T\n\n    fig, ax = plt.subplots(1, 1)\n    ax.scatter(tmpx, tmpy, color='r', label='new')\n    ax.scatter(x, y, color='b', label='old')\n    ax.scatter(bx, by, color='g', label='boundaries')\n    ax.set_aspect('equal')\n    ax.legend()\n    fig.tight_layout()\n    fig.savefig('output_map.png', dpi=300)\n\n    return grid_new, grid_map"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_R_mod(options, rho0):\n    tomodir = tdManager.tdMan(\n        elem_file=options.elem_file,\n        elec_file=options.elec_file,\n        config_file=options.config_file,\n    )\n\n    # set model\n    tomodir.add_homogeneous_model(magnitude=rho0)\n\n    # only interested in magnitudes\n    Z = tomodir.measurements()[:, 0]\n\n    return Z", "response": "Compute synthetic measurements over a homogeneous half - space\n   "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef converter_pm_log10(data):\n    # indices_zero = np.where(data == 0)\n    indices_gt_zero = np.where(data > 0)\n    indices_lt_zero = np.where(data < 0)\n\n    data_converted = np.zeros(data.shape)\n    data_converted[indices_gt_zero] = np.log10(data[indices_gt_zero])\n    data_converted[indices_lt_zero] = -np.log10(-data[indices_lt_zero])\n    return indices_gt_zero, indices_lt_zero, data_converted", "response": "Convert the given data to array\n        log10"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef plot_nodes_pcolor_to_ax(self, ax, nid, **kwargs):\n        fig = ax.get_figure()\n        x = self.grid.nodes['presort'][:, 1]\n        z = self.grid.nodes['presort'][:, 2]\n        ax.scatter(x, z)\n        xz = np.vstack((x, z)).T\n\n        # generate grid\n        X, Z = np.meshgrid(\n            np.linspace(x.min(), x.max(), 100),\n            np.linspace(z.min(), z.max(), 100),\n        )\n\n        values = np.array(self.nodeman.nodevals[nid])\n        # linear\n        # cubic\n        cint = scipy.interpolate.griddata(\n            xz,\n            values,\n            (X, Z),\n            method='linear',\n            # method='linear',\n            # method='nearest',\n            fill_value=np.nan,\n        )\n        cint_ma = np.ma.masked_invalid(cint)\n\n        pc = ax.pcolormesh(\n            X, Z,\n            cint_ma,\n            cmap=kwargs.get('cmap', 'jet'),\n            vmin=kwargs.get('vmin', None),\n            vmax=kwargs.get('vmax', None),\n        )\n        if kwargs.get('plot_colorbar', False):\n            divider = make_axes_locatable(ax)\n            cbposition = kwargs.get('cbposition', 'vertical')\n            if cbposition == 'horizontal':\n                ax_cb = divider.new_vertical(\n                    size=0.1, pad=0.4, pack_start=True\n                )\n            elif cbposition == 'vertical':\n                ax_cb = divider.new_horizontal(\n                    size=0.1, pad=0.4,\n                )\n            else:\n                raise Exception('cbposition not recognized')\n\n            ax.get_figure().add_axes(ax_cb)\n\n            cb = fig.colorbar(\n                pc,\n                cax=ax_cb,\n                orientation=cbposition,\n                label=kwargs.get('cblabel', ''),\n                ticks=mpl.ticker.MaxNLocator(kwargs.get('cbnrticks', 3)),\n                format=kwargs.get('cbformat', None),\n                extend='both',\n            )\n\n        no_elecs = kwargs.get('no_elecs', False)\n        if self.grid.electrodes is not None and no_elecs is not True:\n            ax.scatter(\n                self.grid.electrodes[:, 1],\n                self.grid.electrodes[:, 2],\n                color=self.grid.props['electrode_color'],\n                # clip_on=False,\n            )\n\n            return fig, ax, pc, cb\n        return fig, ax, pc", "response": "Plot node data to an axes object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef plot_nodes_contour_to_ax(self, ax, nid, **kwargs):\n        x = self.grid.nodes['presort'][:, 1]\n        z = self.grid.nodes['presort'][:, 2]\n        ax.scatter(x, z)\n        xz = np.vstack((x, z)).T\n\n        # generate grid\n        X, Z = np.meshgrid(\n            np.linspace(x.min(), x.max(), 100),\n            np.linspace(z.min(), z.max(), 100),\n        )\n\n        values = np.array(self.nodeman.nodevals[nid])\n        # linear\n        # cubic\n        cint = scipy.interpolate.griddata(\n            xz,\n            values,\n            (X, Z),\n            method='linear',\n            # method='linear',\n            # method='nearest',\n            fill_value=np.nan,\n        )\n        cint_ma = np.ma.masked_invalid(cint)\n\n        pc = ax.contourf(\n            X, Z, cint_ma,\n            cmap=kwargs.get('cmap', 'jet'),\n            vmin=kwargs.get('vmin', None),\n            vmax=kwargs.get('vmax', None),\n        )\n        # pc = ax.pcolormesh(\n        #     X, Z, cint_ma,\n        #     vmin=-40,\n        #     vmax=40,\n        # )\n        # cb = fig.colorbar(pc)\n        return pc", "response": "Plot node data to an axes object."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nplots the elements of the given set of elements.", "response": "def plot_elements_to_ax(self, cid, ax=None, **kwargs):\n        \"\"\"Plot element data (parameter sets).\n\n        If the parameter *ax* is not set, then a new figure will be created\n        with a corresponding axes.\n\n\n        Parameters\n        ----------\n        cid : int or :py:class:`numpy.ndarray`\n            if *cid* is an int, then treat it as the id of the parameter set\n            stored in self.parman. Otherwise, expect it to be the data to plot.\n            At the moment no checks are made that the data fits the grid.\n        ax : matplotlib.Axes, optional\n            plot to this axes object, if provided\n        alpha_cid : int, optional\n            if given, use the corresponding dataset in self.parman as the alpha\n            channel. No checks are made if all values of this data set lie\n            between 0 and 1 (0 being fully transparent, and 1 being opaque).\n        xmin : float, optional\n            minimal x limit to plot\n        xmax : float, optional\n            maximal x limit to plot\n        zmin : float, optional\n            minimal z limit to plot\n        zmax : float, optional\n            maximial z limit to plot\n        converter : function, optional\n            if given, then use this function to convert the data into another\n            representation. The given function must work with a numpy array.\n            Default: None\n        norm : norm object, optional\n            the norm object for matplotlib plotting can be provided here\n        cmap_name : string, optional\n            name of the colorbar to use. Default is \"viridis\". To reverse\n            colors, use the _r version \"viridis_r\"\n        cbposition : ?\n            ?\n        cblabel : string, optional\n            colorbar label\n        cbsegments : int, optional\n            ?\n        cbnrticks : int, optional\n            ?\n        over : color, optional\n            color to use for values above the current cb-limit. Default: ?\n        under :\n            color to use for values below the current cb-limit. Default: ?\n        bad :\n            color to use for nan-values. Default: ?\n        plot_colorbar : bool, optional\n            if true, plot a colorbar next to the plot\n        title : string, optional\n            plot title string\n        xlabel : string, optional\n            Set xlabel of the resulting plot\n        ylabel : string, optional\n            Set ylabel of the resulting plot\n        no_elecs : bool, optional\n            If True, plot no electrodes\n        rasterize: bool, optional\n            if True, rasterize the plot. Default: False\n\n        Returns\n        -------\n        fig:\n\n        ax:\n\n        cnorm:\n\n        cmap:\n\n        cb: colorbar instance, optional\n            only of plot_colorbar is True\n        scalarMap:\n            use to create custom colorbars\n\n        \"\"\"\n\n        rasterize = kwargs.get('rasterize', False)\n        xmin = kwargs.get('xmin', self.grid.grid['x'].min())\n        xmax = kwargs.get('xmax', self.grid.grid['x'].max())\n        zmin = kwargs.get('zmin', self.grid.grid['z'].min())\n        zmax = kwargs.get('zmax', self.grid.grid['z'].max())\n\n        # try to create a suitable default figure size\n        if ax is None:\n            # 15 cm\n            sizex = 15 / 2.54\n            sizez = sizex * (np.abs(zmax - zmin) / np.abs(xmax - xmin) * 1.1)\n            # add 1 inch to accommodate colorbar\n            sizez += 1.3\n            fig, ax = plt.subplots(figsize=(sizex, sizez))\n        else:\n            fig = ax.get_figure()\n            sizex, sizez = fig.get_size_inches()\n\n        # get data\n        if isinstance(cid, int):\n            subdata = self.parman.parsets[cid]\n        else:\n            subdata = cid\n\n        if 'converter' in kwargs:\n            subdata = kwargs['converter'](subdata)\n\n        # color map\n        cmap_name = kwargs.get('cmap_name', 'viridis')\n        cmap = mpl.cm.get_cmap(\n            cmap_name,\n            kwargs.get('cbsegments', None)\n        )\n        over = kwargs.get('over', 'orange')\n        under = kwargs.get('under', 'mediumblue')\n        bad = kwargs.get('bad', 'white')\n        cmap.set_over(over)\n        cmap.set_under(under)\n        cmap.set_bad(bad)\n\n        # normalize data\n        data_min = kwargs.get('cbmin', subdata.min())\n        data_max = kwargs.get('cbmax', subdata.max())\n        if(data_min is not None and data_max is not None and\n           data_min == data_max):\n            data_min -= 1\n            data_max += 1\n        cnorm = mpl.colors.Normalize(vmin=data_min, vmax=data_max)\n        scalarMap = mpl.cm.ScalarMappable(norm=cnorm, cmap=cmap)\n        fcolors = scalarMap.to_rgba(subdata)\n        scalarMap.set_array(subdata)\n\n        # if applicable, apply alpha values\n        alpha_cid = kwargs.get('cid_alpha', None)\n        if isinstance(alpha_cid, int):\n            print('applying alpha')\n            alpha = self.parman.parsets[alpha_cid]\n            # make sure this data set is normalized between 0 and 1\n            if np.nanmin(alpha) < 0 or np.nanmax(alpha) > 1:\n                raise Exception(\n                    'alpha data set must be normalized between 0 and 1'\n                )\n            fcolors[:, 3] = alpha\n\n        all_xz = []\n        for x, z in zip(self.grid.grid['x'], self.grid.grid['z']):\n            tmp = np.vstack((x, z)).T\n            all_xz.append(tmp)\n\n        norm = kwargs.get('norm', None)\n\n        collection = mpl.collections.PolyCollection(\n            all_xz,\n            edgecolor=fcolors,\n            facecolor=fcolors,\n            linewidth=0.0,\n            cmap=cmap,\n            norm=norm,\n            rasterized=rasterize,\n        )\n        collection.set_cmap(cmap)\n        ax.add_collection(collection)\n        no_elecs = kwargs.get('no_elecs', False)\n        if self.grid.electrodes is not None and no_elecs is not True:\n            ax.scatter(\n                self.grid.electrodes[:, 1],\n                self.grid.electrodes[:, 2],\n                color=self.grid.props['electrode_color'],\n                # clip_on=False,\n            )\n\n        ax.set_xlim(xmin, xmax)\n        ax.set_ylim(zmin, zmax)\n        ax.set_xlabel(kwargs.get('xlabel', 'x'))\n        ax.set_ylabel(kwargs.get('zlabel', 'z'))\n        ax.set_aspect('equal')\n        ax.set_title(\n            kwargs.get('title', '')\n        )\n\n        if kwargs.get('plot_colorbar', False):\n            divider = make_axes_locatable(ax)\n            cbposition = kwargs.get('cbposition', 'vertical')\n            if cbposition == 'horizontal':\n                ax_cb = divider.new_vertical(\n                    size=0.1, pad=0.4, pack_start=True\n                )\n            elif cbposition == 'vertical':\n                ax_cb = divider.new_horizontal(\n                    size=0.1, pad=0.4,\n                )\n            else:\n                raise Exception('cbposition not recognized')\n\n            ax.get_figure().add_axes(ax_cb)\n\n            cb = fig.colorbar(\n                scalarMap,\n                cax=ax_cb,\n                orientation=cbposition,\n                label=kwargs.get('cblabel', ''),\n                ticks=mpl.ticker.MaxNLocator(kwargs.get('cbnrticks', 3)),\n                format=kwargs.get('cbformat', None),\n                extend='both',\n            )\n\n            return fig, ax, cnorm, cmap, cb, scalarMap\n\n        return fig, ax, cnorm, cmap, scalarMap"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef make_and_return_path_from_path_and_folder_names(path, folder_names):\n    for folder_name in folder_names:\n\n        path += folder_name + '/'\n\n        try:\n            os.makedirs(path)\n        except FileExistsError:\n            pass\n\n    return path", "response": "This function creates a directory structure from a set of folder names and returns the path to the inner - most folder."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nregister an existing nova VM with the BMC host.", "response": "def register_host(self, bm_instance):\n        \"\"\"Register an existing nova VM.\n\n        A new interface will be attached to the BMC host with a new IP. An openstackbmc\n        service will be binded to this IP.\n\n        Once the VM has been registered, it is possible to use IPMI on this IP\n        to start or stop the virtual machine.\n        \"\"\"\n        bmc_ip = '10.130.%d.100' % (self._bmc_range_start + self._nic_cpt)\n        bmc_net = '10.130.%d.0' % (self._bmc_range_start + self._nic_cpt)\n        bmc_gw = '10.130.%d.1' % (self._bmc_range_start + self._nic_cpt)\n        device = 'eth%d' % (2 + self._nic_cpt)\n        body_create_subnet = {\n            'subnets': [{\n                'name': 'bmc_' + device,\n                'cidr': bmc_net + '/24',\n                'ip_version': 4,\n                'network_id': self._bmc_net['id']}]}\n        subnet_id = self.neutron.create_subnet(body=body_create_subnet)['subnets'][0]['id']\n        self.attach_subnet_to_router(subnet_id)\n        self.os_instance.interface_attach(None, self._bmc_net['id'], bmc_ip)\n        content = \"\"\"\nDEVICE=\"{device}\"\nBOOTPROTO=static\nIPADDR={bmc_ip}\nNETMASK=255.255.255.0\nONBOOT=yes\n\"\"\"\n        self.create_file(\n            '/etc/sysconfig/network-scripts/ifcfg-%s' % device,\n            content=content.format(device=device, bmc_ip=bmc_ip, bmc_gw=bmc_gw))\n\n        content = \"\"\"\n192.0.2.0/24 via {bmc_gw}\n\"\"\"\n        self.create_file(\n            '/etc/sysconfig/network-scripts/route-%s' % device,\n            content=content.format(bmc_gw=bmc_gw))\n        self.run('ifup %s' % device)\n\n        # Ensure the outgoing traffic go through the correct NIC to avoid spoofing\n        # protection\n        # TODO(Gon\u00e9ri): This should be persistant.\n        self.run('ip rule add from %s table %d' % (bmc_ip, self._nic_cpt + 2))\n        self.run('ip route add default via %s dev %s table %d' % (bmc_gw, device, self._nic_cpt + 2))\n\n        content = \"\"\"\n[Unit]\nDescription=openstack-bmc {bm_instance} Service\n[Service]\nExecStart=/usr/local/bin/openstackbmc  --os-user {os_username} --os-password {os_password} --os-project-id {os_project_id} --os-auth-url {os_auth_url} --instance {bm_instance} --address {bmc_ip}\nUser=root\nStandardOutput=kmsg+console\nStandardError=inherit\nRestart=always\n[Install]\nWantedBy=multi-user.target\n\"\"\"\n        unit = 'openstack-bmc-%d.service' % self._nic_cpt\n        self.create_file(\n            '/usr/lib/systemd/system/%s' % unit,\n            content.format(\n                os_username=self.os_username,\n                os_password=protect_password(self.os_password),\n                os_project_id=self.os_project_id,\n                os_auth_url=self.os_auth_url,\n                bm_instance=bm_instance,\n                bmc_ip=bmc_ip))\n        self.run('systemctl enable %s' % unit)\n        self.run('systemctl start %s' % unit)\n        self._nic_cpt += 1\n\n        return bmc_ip"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef Godeps(self):\n        dict = []\n        for package in sorted(self._packages.keys()):\n            dict.append({\n                \"ImportPath\": str(package),\n                \"Rev\": str(self._packages[package])\n            })\n\n        return dict", "response": "Return the snapshot in Godeps. json form\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef GLOGFILE(self):\n        lines = []\n        for package in sorted(self._packages.keys()):\n            lines.append(\"%s %s\" % (str(package), str(self._packages[package])))\n\n        return \"\\n\".join(lines)", "response": "Return the snapshot in GLOGFILE form\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef Glide(self):\n        dict = {\n            \"hash\": \"???\",\n            \"updated\": str(datetime.datetime.now(tz=pytz.utc).isoformat()),\n            \"imports\": [],\n        }\n\n        decomposer = ImportPathsDecomposerBuilder().buildLocalDecomposer()\n        decomposer.decompose(self._packages.keys())\n        classes = decomposer.classes()\n\n        for ipp in classes:\n            dep = {\n                \"name\": ipp,\n                \"version\": str(self._packages[classes[ipp][0]])\n            }\n            if len(classes[ipp]) > 1 or classes[ipp][0] != ipp:\n                dep[\"subpackages\"] = map(lambda l: l[len(ipp)+1:], classes[ipp])\n\n            dict[\"imports\"].append(dep)\n\n        return yaml.dump(dict, default_flow_style=False)", "response": "Return the snapshot in glide. lock form\n       "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef render(self,\n            trajectories: Tuple[NonFluents, Fluents, Fluents, Fluents, np.array],\n            batch: Optional[int] = None) -> None:\n        '''Render the simulated state-action `trajectories` for Navigation domain.\n\n        Args:\n            stats: Performance statistics.\n            trajectories: NonFluents, states, actions, interms and rewards.\n            batch: Number of batches to render.\n        '''\n\n        non_fluents, initial_state, states, actions, interms, rewards = trajectories\n\n        non_fluents = dict(non_fluents)\n        states  = dict((name, fluent[0]) for name, fluent in states)\n        actions = dict((name, fluent[0]) for name, fluent in actions)\n        rewards = rewards[0]\n\n        idx = self._compiler.rddl.domain.state_fluent_ordering.index('location/1')\n\n        start = initial_state[idx][0]\n        g = non_fluents['GOAL/1']\n        path = states['location/1']\n        deltas = actions['move/1']\n\n        centers = non_fluents['DECELERATION_ZONE_CENTER/2']\n        decays = non_fluents['DECELERATION_ZONE_DECAY/1']\n        zones = [(x, y, d) for (x, y), d in zip(centers, decays)]\n\n        self._ax1 = plt.gca()\n\n        self._render_state_space()\n        self._render_start_and_goal_positions(start, g)\n        self._render_deceleration_zones(zones)\n        self._render_state_action_trajectory(start, path, deltas)\n\n        plt.title('Navigation', fontweight='bold')\n        plt.legend(loc='lower right')\n        plt.show()", "response": "Render the simulated state - action trajectories for Navigation domain."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntiming the execution of a function. If the process is stopped and restarted then timing is continued using saved files. Parameters ---------- func Some function to be timed Returns ------- timed_function The same function with a timer attached.", "response": "def persistent_timer(func):\n    \"\"\"\n    Times the execution of a function. If the process is stopped and restarted then timing is continued using saved\n    files.\n\n    Parameters\n    ----------\n    func\n        Some function to be timed\n\n    Returns\n    -------\n    timed_function\n        The same function with a timer attached.\n    \"\"\"\n\n    @functools.wraps(func)\n    def timed_function(optimizer_instance, *args, **kwargs):\n        start_time_path = \"{}/.start_time\".format(optimizer_instance.phase_output_path)\n        try:\n            with open(start_time_path) as f:\n                start = float(f.read())\n        except FileNotFoundError:\n            start = time.time()\n            with open(start_time_path, \"w+\") as f:\n                f.write(str(start))\n\n        result = func(optimizer_instance, *args, **kwargs)\n\n        execution_time = str(dt.timedelta(seconds=time.time() - start))\n\n        logger.info(\"{} took {} to run\".format(\n            optimizer_instance.phase_name,\n            execution_time\n        ))\n        with open(\"{}/execution_time\".format(optimizer_instance.phase_output_path), \"w+\") as f:\n            f.write(execution_time)\n        return result\n\n    return timed_function"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a model mapper created by taking results from this phase and creating priors with the defined absolute width.", "response": "def variable_absolute(self, a: float) -> mm.ModelMapper:\n        \"\"\"\n        Parameters\n        ----------\n        a\n            The absolute width of gaussian priors\n\n        Returns\n        -------\n        A model mapper created by taking results from this phase and creating priors with the defined absolute width.\n        \"\"\"\n        return self.previous_variable.mapper_from_gaussian_tuples(self.gaussian_tuples, a=a)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a model mapper created by taking results from this phase and creating priors with the defined relative width.", "response": "def variable_relative(self, r: float) -> mm.ModelMapper:\n        \"\"\"\n        Parameters\n        ----------\n        r\n            The relative width of gaussian priors\n\n        Returns\n        -------\n        A model mapper created by taking results from this phase and creating priors with the defined relative width.\n        \"\"\"\n        return self.previous_variable.mapper_from_gaussian_tuples(self.gaussian_tuples, r=r)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef backup(self):\n        try:\n            shutil.rmtree(self.backup_path)\n        except FileNotFoundError:\n            pass\n        try:\n            shutil.copytree(self.opt_path, self.backup_path)\n        except shutil.Error as e:\n            logger.exception(e)", "response": "Copy the files from the sym - linked optimizer folder to the backup folder in the workspace."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef restore(self):\n        if os.path.exists(self.backup_path):\n            for file in glob.glob(self.backup_path + \"/*\"):\n                shutil.copy(file, self.path)", "response": "Copy files from the backup folder to the sym - linked optimizer folder."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a config field from this optimizer s section in non_linear. ini by a key and value type.", "response": "def config(self, attribute_name, attribute_type=str):\n        \"\"\"\n        Get a config field from this optimizer's section in non_linear.ini by a key and value type.\n\n        Parameters\n        ----------\n        attribute_name: str\n            The analysis_path of the field\n        attribute_type: type\n            The type of the value\n\n        Returns\n        -------\n        attribute\n            An attribute for the key with the specified type.\n        \"\"\"\n        return self.named_config.get(self.__class__.__name__, attribute_name, attribute_type)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_paramnames_file(self):\n        paramnames_names = self.variable.param_names\n        paramnames_labels = self.param_labels\n        with open(self.file_param_names, 'w') as paramnames:\n            for i in range(self.variable.prior_count):\n                line = paramnames_names[i]\n                line += ' ' * (70 - len(line)) + paramnames_labels[i]\n                paramnames.write(line + '\\n')", "response": "The param_names file lists every parameter s analysis_path and Latex tag and is used for GetDist*\n        visualization."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompute the Gaussian Priors of the current set of resources at a given sigma limit.", "response": "def gaussian_priors_at_sigma_limit(self, sigma_limit):\n        \"\"\"Compute the Gaussian Priors these results should be initialzed with in the next phase, by taking their \\\n        most probable values (e.g the means of their PDF) and computing the error at an input sigma_limit.\n\n        Parameters\n        -----------\n        sigma_limit : float\n            The sigma limit within which the PDF is used to estimate errors (e.g. sigma_limit = 1.0 uses 0.6826 of the \\\n            PDF).\n        \"\"\"\n\n        means = self.most_probable_from_summary()\n        uppers = self.model_at_upper_sigma_limit(sigma_limit)\n        lowers = self.model_at_lower_sigma_limit(sigma_limit)\n\n        # noinspection PyArgumentList\n        sigmas = list(map(lambda mean, upper, lower: max([upper - mean, mean - lower]), means, uppers, lowers))\n\n        return list(map(lambda mean, sigma: (mean, sigma), means, sigmas))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef model_at_upper_sigma_limit(self, sigma_limit):\n        return list(map(lambda param: param[1], self.model_at_sigma_limit(sigma_limit)))", "response": "Setup 1D vectors of the upper and lower limits of the multinest nlo."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef weighted_sample_instance_from_weighted_samples(self, index):\n        model, weight, likelihood = self.weighted_sample_model_from_weighted_samples(index)\n\n        self._weighted_sample_model = model\n\n        return self.variable.instance_from_physical_vector(model), weight, likelihood", "response": "Setup a model instance of a weighted sample including its weight and likelihood."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef weighted_sample_model_from_weighted_samples(self, index):\n        return list(self.pdf.samples[index]), self.pdf.weights[index], -0.5 * self.pdf.loglikes[index]", "response": "This routine returns the model weight and likelihood hood from a weighted sample."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef compare_digest(a, b):\n    py_version = sys.version_info[0]\n    if py_version >= 3:\n        return _compare_digest_py3(a, b)\n    return _compare_digest_py2(a, b)", "response": "Compare 2 hash digest."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _render_trajectories(self,\n            trajectories: Tuple[NonFluents, Fluents, Fluents, Fluents, np.array]) -> None:\n        '''Prints the first batch of simulated `trajectories`.\n\n        Args:\n            trajectories: NonFluents, states, actions, interms and rewards.\n        '''\n        if self._verbose:\n            non_fluents, initial_state, states, actions, interms, rewards = trajectories\n            shape = states[0][1].shape\n            batch_size, horizon, = shape[0], shape[1]\n            states = [(s[0], s[1][0]) for s in states]\n            interms = [(f[0], f[1][0]) for f in interms]\n            actions = [(a[0], a[1][0]) for a in actions]\n            rewards = np.reshape(rewards, [batch_size, horizon])[0]\n            self._render_batch(non_fluents, states, actions, interms, rewards)", "response": "Prints the first batch of simulated trajectories."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprinting a batch of state actions interms and rewards for given horizon.", "response": "def _render_batch(self,\n            non_fluents: NonFluents,\n            states: Fluents, actions: Fluents, interms: Fluents,\n            rewards: np.array,\n            horizon: Optional[int] = None) -> None:\n        '''Prints `non_fluents`, `states`, `actions`, `interms` and `rewards`\n        for given `horizon`.\n\n        Args:\n            states (Sequence[Tuple[str, np.array]]): A state trajectory.\n            actions (Sequence[Tuple[str, np.array]]): An action trajectory.\n            interms (Sequence[Tuple[str, np.array]]): An interm state trajectory.\n            rewards (np.array): Sequence of rewards (1-dimensional array).\n            horizon (Optional[int]): Number of timesteps.\n        '''\n        if horizon is None:\n            horizon = len(states[0][1])\n            self._render_round_init(horizon, non_fluents)\n            for t in range(horizon):\n                s = [(s[0], s[1][t]) for s in states]\n                f = [(f[0], f[1][t]) for f in interms]\n                a = [(a[0], a[1][t]) for a in actions]\n                r = rewards[t]\n                self._render_timestep(t, s, a, f, r)\n            self._render_round_end(rewards)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprinting fluents and rewards for the given timestep t.", "response": "def _render_timestep(self,\n            t: int,\n            s: Fluents, a: Fluents, f: Fluents,\n            r: np.float32) -> None:\n        '''Prints fluents and rewards for the given timestep `t`.\n\n        Args:\n            t (int): timestep\n            s (Sequence[Tuple[str], np.array]: State fluents.\n            a (Sequence[Tuple[str], np.array]: Action fluents.\n            f (Sequence[Tuple[str], np.array]: Interm state fluents.\n            r (np.float32): Reward.\n        '''\n        print(\"============================\")\n        print(\"TIME = {}\".format(t))\n        print(\"============================\")\n        fluent_variables = self._compiler.rddl.action_fluent_variables\n        self._render_fluent_timestep('action', a, fluent_variables)\n        fluent_variables = self._compiler.rddl.interm_fluent_variables\n        self._render_fluent_timestep('interms', f, fluent_variables)\n        fluent_variables = self._compiler.rddl.state_fluent_variables\n        self._render_fluent_timestep('states', s, fluent_variables)\n        self._render_reward(r)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprinting fluents of given fluent_type as list of instantiated variables with corresponding values.", "response": "def _render_fluent_timestep(self,\n            fluent_type: str,\n            fluents: Sequence[Tuple[str, np.array]],\n            fluent_variables: Sequence[Tuple[str, List[str]]]) -> None:\n        '''Prints `fluents` of given `fluent_type` as list of instantiated variables\n        with corresponding values.\n\n        Args:\n            fluent_type (str): Fluent type.\n            fluents (Sequence[Tuple[str, np.array]]): List of pairs (fluent_name, fluent_values).\n            fluent_variables (Sequence[Tuple[str, List[str]]]): List of pairs (fluent_name, args).\n        '''\n        for fluent_pair, variable_list in zip(fluents, fluent_variables):\n            name, fluent = fluent_pair\n            _, variables = variable_list\n            print(name)\n            fluent = fluent.flatten()\n            for variable, value in zip(variables, fluent):\n                print('- {}: {} = {}'.format(fluent_type, variable, value))\n        print()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _render_round_init(self, horizon: int, non_fluents: NonFluents) -> None:\n        '''Prints round init information about `horizon` and `non_fluents`.'''\n        print('*********************************************************')\n        print('>>> ROUND INIT, horizon = {}'.format(horizon))\n        print('*********************************************************')\n        fluent_variables = self._compiler.rddl.non_fluent_variables\n        self._render_fluent_timestep('non-fluents', non_fluents, fluent_variables)", "response": "Prints round init information about horizon and non_fluents."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprint round end information about rewards.", "response": "def _render_round_end(self, rewards: np.array) -> None:\n        '''Prints round end information about `rewards`.'''\n        print(\"*********************************************************\")\n        print(\">>> ROUND END\")\n        print(\"*********************************************************\")\n        total_reward = np.sum(rewards)\n        print(\"==> Objective value = {}\".format(total_reward))\n        print(\"==> rewards = {}\".format(list(rewards)))\n        print()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _truncate_to_field(model, field_name, value):\n    field = model._meta.get_field(field_name)  # pylint: disable=protected-access\n    if len(value) > field.max_length:\n        midpoint = field.max_length // 2\n        len_after_midpoint = field.max_length - midpoint\n        first = value[:midpoint]\n        sep = '...'\n        last = value[len(value) - len_after_midpoint + len(sep):]\n        value = sep.join([first, last])\n    return value", "response": "Shorten data to fit in the specified model field."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\npersists a record of the task.", "response": "def on_failure(self, exc, task_id, args, kwargs, einfo):\n        \"\"\"\n        If the task fails, persist a record of the task.\n        \"\"\"\n        if not FailedTask.objects.filter(task_id=task_id, datetime_resolved=None).exists():\n            FailedTask.objects.create(\n                task_name=_truncate_to_field(FailedTask, 'task_name', self.name),\n                task_id=task_id,  # Fixed length UUID: No need to truncate\n                args=args,\n                kwargs=kwargs,\n                exc=_truncate_to_field(FailedTask, 'exc', repr(exc)),\n            )\n        super(PersistOnFailureTask, self).on_failure(exc, task_id, args, kwargs, einfo)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrender the simulated trajectories for the given batch.", "response": "def render(self,\n            trajectories: Tuple[NonFluents, Fluents, Fluents, Fluents, np.array],\n            batch: Optional[int] = None) -> None:\n        '''Renders the simulated `trajectories` for the given `batch`.\n\n        Args:\n            trajectories: NonFluents, states, actions, interms and rewards.\n            batch: Number of batches to render.\n        '''\n        raise NotImplementedError"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef min(self):\n        res = self._qexec(\"min(%s)\" % self._name)\n        if len(res) > 0:\n            self._min = res[0][0]\n        return self._min", "response": "returns the minimum of the column\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the maximum value of the column", "response": "def max(self):\n        \"\"\"\n        :returns the maximum of the column\n        \"\"\"\n        res = self._qexec(\"max(%s)\" % self._name)\n        if len(res) > 0:\n            self._max = res[0][0]\n        return self._max"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nbuild the distribution of distinct values for this object", "response": "def distribution(self, limit=1024):\n        \"\"\"\n        Build the distribution of distinct values\n        \"\"\"\n        res = self._qexec(\"%s, count(*) as __cnt\" % self.name(), group=\"%s\" % self.name(),\n                          order=\"__cnt DESC LIMIT %d\" % limit)\n        dist = []\n        cnt = self._table.size()\n        for i, r in enumerate(res):\n            dist.append(list(r) + [i, r[1] / float(cnt)])\n\n        self._distribution = pd.DataFrame(dist, columns=[\"value\", \"cnt\", \"r\", \"fraction\"])\n        self._distribution.index = self._distribution.r\n\n        return self._distribution"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngives either a column index or name return the column structure", "response": "def column(self, col):\n        \"\"\"\n        Given either a column index or name return the column structure\n        :param col: either index or name\n        :return: column data structure\n        \"\"\"\n        if type(col) is str:\n            for c in self._cols:\n                if c.name == col:\n                    return c\n        else:\n            return self._cols[col]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the list of columns in this table", "response": "def columns(self):\n        \"\"\"\n        :return: the list of column in this table\n        \"\"\"\n        c = self._connection.cursor()\n        c.execute(\"describe `%s`.`%s`\" % (self._db, self._name))\n        self._cols = []\n        for col in c.fetchall():\n            self._cols.append(Column.build(col, table=self, con=self._connection))\n        return self._cols"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a data frame of name distinct value fractions", "response": "def distinct_value_fractions(self):\n        \"\"\"\n        :return: returns a data frame of name distinct value fractions\n        \"\"\"\n        return pd.DataFrame([c.dcount() / float(self.size()) for c in self.columns()],\n                            index=[c.name() for c in self.columns()], columns=[\"fraction\"])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse(self, name):\n\t\tname = name.strip()\n\t\tgroups = self._parseFedora(name)\n\t\tif groups:\n\t\t\tself._signature = DistributionNameSignature(\"Fedora\", groups.group(1))\n\t\t\treturn self\n\n\t\traise ValueError(\"Distribution name '%s' not recognized\" % name)", "response": "Parse a distribution string and return a Distribution object"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef branches(self):\n\t\tif self.github.get_rate_limit().rate.limit == 0:\n\t\t\traise GithubException\n\n\t\tbranches = self.repo.get_branches()\n\t\treturn [x.name for x in branches]", "response": "Return a list of branches for given repository\n\tRaises GithubException if rate limit is exceeded\n\t"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _commitData(self, commit):\n\t\treturn {\n\t\t\t\"hexsha\": commit.sha,\n\t\t\t\"adate\": time.mktime(commit.commit.author.date.timetuple()),\n\t\t\t\"cdate\": time.mktime(commit.commit.committer.date.timetuple()),\n\t\t\t\"author\": \"%s <%s>\" % (commit.commit.author.name, commit.commit.author.email),\n\t\t\t\"message\": commit.commit.message\n\t\t}", "response": "Get data from a commit object\n\t"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef commits(self, branch, since=0, to=int(time.time()) + 86400):\n\t\tif self.github.get_rate_limit().rate.limit == 0:\n\t\t\traise GithubException\n\n\t\tcommits = {}\n\t\tsince_dt = datetime.datetime.fromtimestamp(since)\n\t\tto_dt = datetime.datetime.fromtimestamp(to)\n\t\tfor commit in self.repo.get_commits(sha=branch, since=since_dt, until=to_dt):\n\t\t\tcommits[commit.sha] = self._commitData(commit)\n\t\treturn commits", "response": "For given branch return a list of commits."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting data for a given commit.", "response": "def commit(self, commit):\n\t\t\"\"\"Get data for a given commit\n\n\t\tRaises KeyError if a commit is not found or not parsed.\n\n\t\t:param commit: repository commit\n\t\t:type  commit: string\n\t\t\"\"\"\n\t\ttry:\n\t\t\treturn self._commitData(self.repo.get_commit(commit))\n\t\texcept (ValueError, KeyError, GithubException):\n\t\t\traise KeyError(\"Commit %s not found\" % commit)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget access token info.", "response": "def get_token(url: str, scopes: str, credentials_dir: str) -> dict:\n    \"\"\"\n    Get access token info.\n    \"\"\"\n\n    tokens.configure(url=url, dir=credentials_dir)\n    tokens.manage('lizzy', [scopes])\n    tokens.start()\n\n    return tokens.get('lizzy')"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset various configuration options", "response": "def config(config, fork_name=\"\", origin_name=\"\"):\n    \"\"\"Setting various configuration options\"\"\"\n    state = read(config.configfile)\n    any_set = False\n    if fork_name:\n        update(config.configfile, {\"FORK_NAME\": fork_name})\n        success_out(\"fork-name set to: {}\".format(fork_name))\n        any_set = True\n    if origin_name:\n        update(config.configfile, {\"ORIGIN_NAME\": origin_name})\n        success_out(\"origin-name set to: {}\".format(origin_name))\n        any_set = True\n    if not any_set:\n        info_out(\"Fork-name: {}\".format(state[\"FORK_NAME\"]))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def persist_event(topic, event, pool):\n    # Event to json\n    json_event = json.dumps(event.__dict__)\n\n    # Connect to database or create and connect if non existent\n    conn = await pool.acquire()\n\n    # Insert event if not processed\n    try:\n        query = \"\"\"\n            CREATE TABLE IF NOT EXISTS public.\"topic_placeholder\"\n            (\n              id SERIAL PRIMARY KEY,\n              event json NOT NULL,\n              issued_at timestamp without time zone NOT NULL\n            )\n            WITH (\n              OIDS=FALSE\n            );\n            ALTER TABLE public.\"topic_placeholder\"\n              OWNER TO root;\n        \"\"\"\n        query = query.replace('topic_placeholder', topic)\n        await conn.execute(query)\n        issued_at = datetime.utcnow()\n        query = 'INSERT INTO \"%s\" (event, issued_at) VALUES ($1, $2)' % topic\n        await conn.execute(query, json_event, issued_at)\n    finally:\n        await pool.release(conn)", "response": "Persist an event into the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_homogeneous_model(self, magnitude, phase=0, frequency=None):\n        if frequency is None:\n            frequencies = self.frequencies\n        else:\n            assert isinstance(frequency, Number)\n            frequencies = [frequency, ]\n\n        for freq in frequencies:\n            pidm, pidp = self.tds[freq].add_homogeneous_model(magnitude, phase)\n            self.a['forward_rmag'][freq] = pidm\n            self.a['forward_rpha'][freq] = pidp", "response": "Add homogeneous models to one or all tomodirs."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading sEIT data from. ctr files.", "response": "def load_data_crt_files(self, data_dict):\n        \"\"\"Load sEIT data from .ctr files (volt.dat files readable by CRTomo,\n        produced by CRMod)\n\n        Parameters\n        ----------\n        data_dict : dict\n            Data files that are imported. See example down below\n\n        Examples\n        --------\n\n        >>> import glob\n            data_files = {}\n            data_files['frequencies'] = 'data/frequencies.dat'\n            files = sorted(glob.glob('data/volt_*.crt'))\n            data_files['crt'] = files\n\n        \"\"\"\n        if isinstance(data_dict, str):\n            raise Exception('Parameter must be a dict!')\n\n        frequency_data = data_dict['frequencies']\n        if isinstance(frequency_data, str):\n            frequencies = np.loadtxt(data_dict['frequencies'])\n        else:\n            # if this is not a string, assume it to be the data\n            frequencies = frequency_data\n\n        if frequencies.size != len(data_dict['crt']):\n            raise Exception(\n                'number of frequencies does not match the number of data files'\n            )\n        self._init_frequencies(frequencies)\n\n        for frequency, filename in zip(frequencies, data_dict['crt']):\n            subdata = np.atleast_2d(np.loadtxt(filename, skiprows=1))\n            if subdata.size == 0:\n                continue\n            # extract configurations\n            A = (subdata[:, 0] / 1e4).astype(int)\n            B = (subdata[:, 0] % 1e4).astype(int)\n            M = (subdata[:, 1] / 1e4).astype(int)\n            N = (subdata[:, 1] % 1e4).astype(int)\n\n            ABMN = np.vstack((A, B, M, N)).T\n\n            magnitudes = subdata[:, 2]\n            phases = subdata[:, 3]\n\n            self.tds[frequency].configs.add_to_configs(ABMN)\n            self.tds[frequency].register_measurements(magnitudes, phases)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef apply_crtomo_cfg(self):\n        for key in sorted(self.tds.keys()):\n            self.tds[key].crtomo_cfg = self.crtomo_cfg.copy()", "response": "Set the global crtomo_cfg for all frequencies\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the global noise_model for all frequencies", "response": "def apply_noise_models(self):\n        \"\"\"Set the global noise_model for all frequencies\n        \"\"\"\n        for key in sorted(self.tds.keys()):\n            self.tds[key].noise_model = self.noise_model"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef save_to_eitdir(self, directory):\n        if os.path.isdir(directory):\n            raise Exception('output directory already exists')\n\n        os.makedirs(directory)\n        np.savetxt(directory + os.sep + 'frequencies.dat', self.frequencies)\n\n        invmod_dir = directory + os.sep + 'invmod'\n        os.makedirs(invmod_dir)\n        for nr, key in enumerate(sorted(self.tds.keys())):\n            outdir = invmod_dir + os.sep + '{0:02}_{1:.6f}'.format(nr, key)\n            self.tds[key].save_to_tomodir(outdir)", "response": "Save the eit data into a eit directory structure"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload the inversion results and store them in self. a", "response": "def load_inversion_results(self, sipdir):\n        \"\"\"Given an sEIT inversion directory, load inversion results and store\n        the corresponding parameter ids in self.assignments\n\n        Note that all previous data stored in this instance of the eitManager\n        will be overwritten, if required!\n        \"\"\"\n        # load frequencies and initialize tomodir objects for all frequencies\n        frequency_file = sipdir + os.sep + 'frequencies.dat'\n        frequencies = np.loadtxt(frequency_file)\n        self._init_frequencies(frequencies)\n\n        # cycle through all tomodirs on disc and load the data\n        for nr, (frequency_key, item) in enumerate(sorted(self.tds.items())):\n            for label in ('rmag', 'rpha', 'cre', 'cim'):\n                if label not in self.assigments:\n                    self.a[label] = {}\n\n            tdir = sipdir + os.sep + 'invmod' + os.sep + '{:02}_{:.6f}'.format(\n                nr, frequency_key) + os.sep\n\n            rmag_file = sorted(glob(tdir + 'inv/*.mag'))[-1]\n            rmag_data = np.loadtxt(rmag_file, skiprows=1)[:, 2]\n            pid_rmag = item.parman.add_data(rmag_data)\n            self.a['rmag'][frequency_key] = pid_rmag\n\n            rpha_file = sorted(glob(tdir + 'inv/*.pha'))[-1]\n            rpha_data = np.loadtxt(rpha_file, skiprows=1)[:, 2]\n            pid_rpha = item.parman.add_data(rpha_data)\n            self.a['rpha'][frequency_key] = pid_rpha\n\n            sigma_file = sorted(glob(tdir + 'inv/*.sig'))[-1]\n            sigma_data = np.loadtxt(sigma_file, skiprows=1)\n            pid_cre = item.parman.add_data(sigma_data[:, 0])\n            pid_cim = item.parman.add_data(sigma_data[:, 1])\n            self.a['cre'][frequency_key] = pid_cre\n            self.a['cim'][frequency_key] = pid_cim"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate plots of the forward models of the magnitude and phalim.", "response": "def plot_forward_models(self, maglim=None, phalim=None, **kwargs):\n        \"\"\"Create plots of the forward models\n\n        Returns\n        -------\n        mag_fig: dict\n            Dictionary containing the figure and axes objects of the magnitude\n            plots\n\n        \"\"\"\n        return_dict = {}\n\n        N = len(self.frequencies)\n        nrx = min(N, 4)\n        nrz = int(np.ceil(N / nrx))\n\n        for index, key, limits in zip(\n                (0, 1), ('rmag', 'rpha'), (maglim, phalim)):\n            if limits is None:\n                cbmin = None\n                cbmax = None\n            else:\n                cbmin = limits[0]\n                cbmax = limits[1]\n\n            fig, axes = plt.subplots(\n                nrz, nrx,\n                figsize=(16 / 2.54, nrz * 3 / 2.54),\n                sharex=True, sharey=True,\n            )\n            for ax in axes.flat:\n                ax.set_visible(False)\n\n            for ax, frequency in zip(axes.flat, self.frequencies):\n                ax.set_visible(True)\n                td = self.tds[frequency]\n                pids = td.a['forward_model']\n                td.plot.plot_elements_to_ax(\n                    pids[index],\n                    ax=ax,\n                    plot_colorbar=True,\n                    cbposition='horizontal',\n                    cbmin=cbmin,\n                    cbmax=cbmax,\n                    **kwargs\n                )\n            for ax in axes[0:-1, :].flat:\n                ax.set_xlabel('')\n\n            for ax in axes[:, 1:].flat:\n                ax.set_ylabel('')\n\n            fig.tight_layout()\n            return_dict[key] = {\n                'fig': fig,\n                'axes': axes,\n            }\n\n        return return_dict"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding configurations to all tomodirs with abmn configurations.", "response": "def add_to_configs(self, configs):\n        \"\"\"Add configurations to all tomodirs\n\n        Parameters\n        ----------\n        configs : :class:`numpy.ndarray`\n            Nx4 numpy array with abmn configurations\n\n        \"\"\"\n        for f, td in self.tds.items():\n            td.configs.add_to_configs(configs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrunning the forward modeling for all frequencies.", "response": "def model(self, **kwargs):\n        \"\"\"Run the forward modeling for all frequencies.\n\n        Use :py:func:`crtomo.eitManager.eitMan.measurements` to retrieve the\n        resulting synthetic measurement spectra.\n\n        Parameters\n        ----------\n        **kwargs : dict, optional\n            All kwargs are directly provide to the underlying\n            :py:func:`crtomo.tdManager.tdMan.model` function calls.\n\n        \"\"\"\n        for key, td in self.tds.items():\n            td.model(**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef measurements(self):\n        m_all = np.array([self.tds[key].measurements() for key in\n                          sorted(self.tds.keys())])\n        return m_all", "response": "Return a list of all measurements in the current TDS"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a dictionary of SIP spectra with the modeled SIP spectra as keys", "response": "def get_measurement_responses(self):\n        \"\"\"Return a dictionary of sip_responses for the modeled SIP spectra\n\n        Note that this function does NOT check that each frequency contains the\n        same configurations!\n\n        Returns\n        -------\n        responses : dict\n            Dictionary with configurations as keys\n\n        \"\"\"\n        # take configurations from first tomodir\n        configs = self.tds[sorted(self.tds.keys())[0]].configs.configs\n\n        measurements = self.measurements()\n        responses = {}\n        for config, sip_measurement in zip(configs,\n                                           np.rollaxis(measurements, 1)):\n            sip = sip_response(\n                frequencies=self.frequencies,\n                rmag=sip_measurement[:, 0],\n                rpha=sip_measurement[:, 1]\n            )\n            responses[tuple(config)] = sip\n        return responses"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_google_token(account_email,\n                     oauth_client_id,\n                     oauth_redirect_uri,\n                     oauth_scope,\n                     account_password=None,\n                     account_otp_secret=None,\n                     **kwargs):\n    \"\"\"\n    :param account_email: (REQUIRED)\n    :param oauth_client_id: (REQUIRED)\n    :param oauth_redirect_uri: (REQUIRED)\n    :param oauth_scope: (REQUIRED)\n    :param account_password: Necessary for first use.\n    :param account_otp_secret: Necessary for first use if enabled on account\n    :return: generated token\n    \"\"\"\n\n    items = {\"account_email\": account_email,\n             \"oauth_client_id\": oauth_client_id,\n             \"oauth_redirect_uri\": oauth_redirect_uri,\n             \"oauth_scope\": oauth_scope,\n             \"account_password\": account_password,\n             \"account_otp_secret\": account_otp_secret}\n    for key, value in kwargs.items():\n        if key not in items:\n            items[key] = value\n\n    generator = GoogleTokenGenerator(**items)\n    return generator.generate()", "response": "Returns a Google token for the given account."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncommand to create a database", "response": "def create_database(name, number=1, force_clear=False):\n    \"\"\"Command to create a database\n    \"\"\"\n    print 'Got:'\n    print 'name', name, type(name)\n    print 'number', number, type(number)\n    print 'force_clear', force_clear, type(force_clear)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncommand to run server", "response": "def run(**kwargs):\n    \"\"\"Command to run server, pass `--PORT 9000`, `--TEMPLATE_PATH templates`\n    as arguments to affect on global settings object.\n    \"\"\"\n    from sampleproject.app import app\n\n    app.update_settings(**kwargs)\n    app.run()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\niterates on available markers.", "response": "def iter_genotypes(self):\n        \"\"\"Iterates on available markers.\n\n        Returns:\n            Genotypes instances.\n\n        \"\"\"\n        # Parsing each column of the dataframe\n        for variant in self.df.columns:\n            genotypes = self.df.loc[:, variant].values\n            info = self.map_info.loc[variant, :]\n\n            yield Genotypes(\n                Variant(info.name, info.chrom, info.pos, [info.a1, info.a2]),\n                genotypes,\n                reference=info.a2,\n                coded=info.a1,\n                multiallelic=False,\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_variant_by_name(self, name):\n        try:\n            geno = self.df.loc[:, name].values\n            info = self.map_info.loc[name, :]\n\n        except KeyError:\n            # The variant is not in the data, so we return an empty\n            # list\n            logging.variant_name_not_found(name)\n            return []\n\n        else:\n            return [Genotypes(\n                Variant(info.name, info.chrom, info.pos, [info.a1, info.a2]),\n                geno,\n                reference=info.a2,\n                coded=info.a1,\n                multiallelic=False,\n            )]", "response": "Get the genotypes for a given variant name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the long path name for a Windows path.", "response": "def _get_long_path_name(path):\n  \"\"\"\n  Returns the long path name for a Windows path, i.e. the properly cased\n  path of an existing file or directory.\n  \"\"\"\n\n  # Thanks to http://stackoverflow.com/a/3694799/791713\n  buf = ctypes.create_unicode_buffer(len(path) + 1)\n  GetLongPathNameW = ctypes.windll.kernel32.GetLongPathNameW\n  res = GetLongPathNameW(path, buf, len(path) + 1)\n  if res == 0 or res > 260:\n    return path\n  else:\n    return buf.value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_dependency_walker():\n\n  for dirname in os.getenv('PATH', '').split(os.pathsep):\n    filename = os.path.join(dirname, 'depends.exe')\n    if os.path.isfile(filename):\n      logger.info('Dependency Walker found at \"{}\"'.format(filename))\n      return filename\n\n  temp_exe = os.path.join(tempfile.gettempdir(), 'depends.exe')\n  temp_dll = os.path.join(tempfile.gettempdir(), 'depends.dll')\n  if os.path.isfile(temp_exe):\n    logger.info('Dependency Walker found at \"{}\"'.format(temp_exe))\n    return temp_exe\n\n  logger.info('Dependency Walker not found. Downloading ...')\n  with urlopen('http://dependencywalker.com/depends22_x64.zip') as fp:\n    data = fp.read()\n\n  logger.info('Extracting Dependency Walker to \"{}\"'.format(temp_exe))\n  with zipfile.ZipFile(io.BytesIO(data)) as fp:\n    with fp.open('depends.exe') as src:\n      with open(temp_exe, 'wb') as dst:\n        shutil.copyfileobj(src, dst)\n    with fp.open('depends.dll') as src:\n      with open(temp_dll, 'wb') as dst:\n        shutil.copyfileobj(src, dst)\n\n  return temp_exe", "response": "Checks if the Dependency Walker is in the system PATH and if not it will be downloaded and extracted to a temporary directory."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of Dependency objects for the specified PE file.", "response": "def get_dependencies(pefile):\n  \"\"\"\n  Uses Dependency Walker to get a list of dependencies for the specified\n  PE file (a Windows executable or dynamic link library).\n  \"\"\"\n\n  # Check if we already analyzed this file before.\n  hasher = hashlib.sha1(os.path.normpath(pefile).encode('utf8'))\n  cachefile = hasher.hexdigest() + '_' + os.path.basename(pefile) + '-deps.csv'\n  cachefile = os.path.join(CACHE_DIR, cachefile)\n\n  if nr.path.compare_timestamp(pefile, cachefile):\n    # Cachefile doesn't exist or is older than changes to pefile.\n    logger.info('Analyzing \"{}\" ...'.format(pefile))\n    nr.path.makedirs(os.path.dirname(cachefile))\n\n    command = [get_dependency_walker(), '/c', '/oc:' + cachefile, pefile]\n    logger.debug('Running command: {}'.format(command))\n    code = subprocess.call(command)\n\n    if code > 0x00010000:  # Processing error and no work was done\n      raise RuntimeError('Dependency Walker exited with non-zero returncode {}.'.format(code))\n\n  else:\n    logger.info('Using cached dependency information for \"{}\"'.format(pefile))\n\n  result = []\n  with io.open(cachefile) as src:\n    src.readline()  # header\n    for line in csv.reader(src):\n      dep = Dependency(line[1])\n      if dep.name.lower()[:6] in ('api-ms', 'ext-ms'):\n        continue\n      result.append(dep)\n\n  return result"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nresolve the dependency on the system.", "response": "def resolve_dependency(dep):\n  \"\"\"\n  Attempts to find the #Dependency on the system. Returns the filename of the\n  native library or None if it can not be found.\n  \"\"\"\n\n  for dirname in os.getenv('PATH', '').split(os.pathsep):\n    filename = os.path.join(dirname, dep.name)\n    if os.path.isfile(filename):\n      return _get_long_path_name(filename)\n  return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nprinting the usage of the command line.", "response": "def print_usage(self, hint=None):\n        \"\"\"Usage format should be like:\n        Lineno | Content\n             1 | Script description (__doc__)\n             2 | Usage: {script name} [COMMAND] [ARGUMENTS]\n             3 | \\n\n             4 | Commands:\n             5 |   cmd1               cmd1 description.\n             6 |   cmd2isverylong     cmd2 description, and it is also\n             7 |                      long as shit.\n             7 |   cmd3               cmd3 description.\n        \"\"\"\n        buf = []\n\n        # Description\n        if __doc__:\n            buf.append(__doc__)\n\n        # Usage\n        script_name = sys.argv[0]\n        buf.append('Usage: %s [COMMAND] [ARGUMENTS]' % script_name)\n\n        buf.append('')\n        buf.append('Commands:')\n\n        # Commands\n        indent_size = 2\n        tab_size = 4\n        doc_width = 50\n        grid_len = max(len(i) for i in list(self._commands.keys())) + tab_size\n\n        for name in self._commands_list:\n            command = self._commands[name]\n            line = ' ' * indent_size + name + ' ' * (grid_len - len(name))\n            doc = command.doc\n            pieces = [doc[i:i + doc_width] for i in range(0, len(doc), doc_width)]\n            line += pieces[0]\n            if len(pieces) > 1:\n                line += '\\n'\n                line += '\\n'.join(' ' * (grid_len + 2) + i for i in pieces[1:])\n\n            buf.append(line)\n\n        print('\\n'.join(buf))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding port to LNode", "response": "def _addPort(n: LNode, lp: LPort, intf: Interface,\n             reverseDirection=False):\n    \"\"\"\n    add port to LPort for interface\n    \"\"\"\n    origin = originObjOfPort(intf)\n    d = intf._direction\n    d = PortTypeFromDir(d)\n\n    if reverseDirection:\n        d = PortType.opposite(d)\n\n    new_lp = LPort(lp, d, lp.side, name=intf._name)\n    new_lp.originObj = origin\n    if intf._interfaces:\n        for child_intf in intf._interfaces:\n            _addPort(n, new_lp, child_intf,\n                     reverseDirection=reverseDirection)\n\n    lp.children.append(new_lp)\n    new_lp.parent = lp\n    if n._node2lnode is not None:\n        n._node2lnode[origin] = new_lp\n\n    return new_lp"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding a LayoutExternalPort for interface", "response": "def addPort(n: LNode, intf: Interface):\n    \"\"\"\n    Add LayoutExternalPort for interface\n    \"\"\"\n    d = PortTypeFromDir(intf._direction)\n    ext_p = LayoutExternalPort(\n        n, name=intf._name, direction=d, node2lnode=n._node2lnode)\n    ext_p.originObj = originObjOfPort(intf)\n    n.children.append(ext_p)\n    addPortToLNode(ext_p, intf, reverseDirection=True)\n    return ext_p"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getDefault(self, k):\n        try:\n            return self[k], True\n        except KeyError:\n            v = self[k] = NetCtx(self, k)\n            return v, False", "response": "get default value for key k"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the list as a numpy. ndarray.", "response": "def v(self):\n        \"\"\"(property) Returns the list as a `numpy.ndarray`\n                      (with dtype ``np.uint8``).\n        \"\"\"\n        v = np.zeros(self.N, dtype=np.uint8)\n        v[self.indices] = 1\n        return v"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef hash(self):\n        data_str = ';'.join(\n            [str(repr(var)) for var in\n             [self.N, self.K, self.X, self.L,\n              self.stat, self.cutoff, self.pval,\n              self.pval_thresh, self.escore_pval_thresh]])\n        data_str += ';'\n        data = data_str.encode('UTF-8') + self.indices.tobytes()\n        return str(hashlib.md5(data).hexdigest())", "response": "( property ) Returns a unique hash value for the result."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the fold enrichment at the XL - mHG cutoff.", "response": "def fold_enrichment(self):\n        \"\"\"(property) Returns the fold enrichment at the XL-mHG cutoff.\"\"\"\n        return self.k / (self.K*(self.cutoff/float(self.N)))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef escore(self):\n        hg_pval_thresh = self.escore_pval_thresh or self.pval\n        escore_tol = self.escore_tol or mhg_cython.get_default_tol()\n        es = mhg_cython.get_xlmhg_escore(\n            self.indices, self.N, self.K, self.X, self.L,\n            hg_pval_thresh, escore_tol)\n        return es", "response": "( property ) Returns the E - score associated with the result."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nlooping over the object, process path attribute sets, and drawlines based on their current contents.", "response": "def drawtree(self):\n        '''\n        Loop over the object, process path attribute sets, and drawlines based\n        on their current contents.\n        '''\n        self.win.erase()\n        self.line = 0\n        for child, depth in self.traverse():\n            child.curline = self.curline\n            child.picked = self.picked\n            child.expanded = self.expanded\n            child.sized = self.sized\n            if depth == 0:\n                continue\n            if self.line == self.curline:\n                self.color.curline(child.name, child.picked)\n                children = child.children\n                name = child.name\n            else:\n                self.color.default(child.name, child.picked)\n            if child.name in self.sized and not self.sized[child.name]:\n                self.sized[child.name] = \" [\" + du(child.name) + \"]\"\n            child.drawline(depth, self.line, self.win)\n            self.line += 1\n        self.win.refresh()\n        self.mkheader(name)\n        self.mkfooter(name, children)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nimport a Config from a given path relative to the current directory.", "response": "def import_config(config_path):\n    \"\"\"Import a Config from a given path, relative to the current directory.\n\n    The module specified by the config file must contain a variable called `configuration` that is\n    assigned to a Config object.\n    \"\"\"\n    if not os.path.isfile(config_path):\n        raise ConfigBuilderError(\n                'Could not find config file: ' + config_path)\n    loader = importlib.machinery.SourceFileLoader(config_path, config_path)\n    module = loader.load_module()\n\n    if not hasattr(module, 'config') or not isinstance(module.config, Config):\n        raise ConfigBuilderError(\n            'Could not load config file \"{}\": config files must contain '\n            'a variable called \"config\" that is '\n            'assigned to a Config object.'.format(config_path))\n    return module.config"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a list of lists of floats covering every combination across no_dimensions of points of integer step size.", "response": "def make_lists(no_dimensions, step_size, centre_steps=True):\n    \"\"\"\n    Create a list of lists of floats covering every combination across no_dimensions of points of integer step size\n    between 0 and 1 inclusive.\n\n    Parameters\n    ----------\n    no_dimensions: int\n        The number of dimensions, that is the length of the lists\n    step_size: float\n        The step size\n    centre_steps: bool\n\n    Returns\n    -------\n    lists: [[float]]\n        A list of lists\n    \"\"\"\n    if no_dimensions == 0:\n        return [[]]\n\n    sub_lists = make_lists(no_dimensions - 1, step_size, centre_steps=centre_steps)\n    return [[step_size * value + (0.5 * step_size if centre_steps else 0)] + sub_list for value in\n            range(0, int((1 / step_size))) for sub_list in sub_lists]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getRootIntfPort(port: LPort):\n    while True:\n        if isinstance(port.parent, LNode):\n            return port\n        else:\n            port = port.parent", "response": "Returns the root edge of the given port"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef portCnt(port):\n    if port.children:\n        return sum(map(lambda p: portCnt(p), port.children))\n    else:\n        return 1", "response": "Count the number of ports without children"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncopy a port to another LPort", "response": "def _copyPort(port: LPort, targetParent: Union[LPort], reverseDirection):\n    \"\"\"\n    add port to LPort for interface\n    \"\"\"\n    d = port.direction\n    side = port.side\n    if reverseDirection:\n        d = PortType.opposite(d)\n        side = PortSide.opposite(side)\n\n    newP = LPort(targetParent.parentNode, d, side, name=port.name)\n    if isinstance(targetParent, LPort):\n        targetParent.children.append(newP)\n        newP.parent = targetParent\n    else:\n        targetParent.getPortSideView(side).append(newP)\n\n    for ch in port.children:\n        _copyPort(ch, newP, reverseDirection)\n\n    return newP"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncopy a port on targetNode", "response": "def copyPort(port, targetLNode, reverseDir, topPortName=None):\n    \"\"\"\n    Create identical port on targetNode\n    \"\"\"\n    newP = _copyPort(port, targetLNode, reverseDir)\n\n    if topPortName is not None:\n        newP.name = topPortName\n\n    return newP"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwalk the ports recursively and yields all the ports with any children.", "response": "def walkSignalPorts(rootPort: LPort):\n    \"\"\"\n    recursively walk ports without any children\n    \"\"\"\n    if rootPort.children:\n        for ch in rootPort.children:\n            yield from walkSignalPorts(ch)\n    else:\n        yield rootPort"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef reconnectPorts(root: LNode, srcPort: LPort,\n                   oldSplits: List[Tuple[LNode, LEdge]],\n                   newSplitNode: LNode):\n    \"\"\"\n    :ivar root: top LNode instance in which are nodes and links stored\n    :ivar srcPort: for SLICE it is port which is connected to input of SLICE node\n        for CONCAT it is port which is connected to output of CONCAT\n    :ivar oldSplits: list of tuples (node, edge) which should be disconnected from graph\n    :ivar newSplitNode: new node which should be connected to graph\n    \"\"\"\n    # sort oldSplit nodes because they are not in same order as signals on\n    # ports\n    mainPortSignals = list(walkSignalPorts(srcPort))\n    portOrder = {p: i for i, p in enumerate(mainPortSignals)}\n    isOneToN = len(newSplitNode.west) == 1\n\n    def portSortKey(x):\n        n, e = x\n        if e.dstNode is n:\n            return portOrder[e.src]\n        elif e.srcNode is n:\n            return portOrder[e.dst]\n        else:\n            raise ValueError(\"Edge not connected to split node\", e, n)\n\n    oldSplits.sort(key=portSortKey)\n    newSplitPorts = [walkSignalPorts(p) for p in\n                     (newSplitNode.east if isOneToN else newSplitNode.west)]\n\n    if isOneToN:\n        newMainPort = newSplitNode.west[0]\n    else:\n        newMainPort = newSplitNode.east[0]\n\n    for mainPort, splitInp, (oldSplitNode, e) in zip(\n            mainPortSignals,\n            walkSignalPorts(newMainPort),\n            oldSplits):\n        assert mainPort.direction != splitInp.direction, (\n            mainPort, splitInp)\n\n        # reconnect edge from src port to split node\n        assert (e.src is mainPort and e.dstNode is oldSplitNode)\\\n            or (e.dst is mainPort and e.srcNode is oldSplitNode), e\n        e.remove()\n\n        _newSplitPorts = [next(p) for p in newSplitPorts]\n        # reconnect part from split node to other target nodes\n        if oldSplitNode.name == \"CONCAT\":\n            root.addEdge(splitInp, mainPort,\n                         originObj=e.originObj)\n\n            for oldP, newP in zip(oldSplitNode.west, _newSplitPorts):\n                for e in list(oldP.incomingEdges):\n                    root.addEdge(e.src, newP, originObj=e.originObj)\n                    e.remove()\n\n        elif oldSplitNode.name == \"SLICE\":\n            root.addEdge(mainPort, splitInp,\n                         originObj=e.originObj)\n\n            for oldP, newP in zip(oldSplitNode.east, reversed(_newSplitPorts)):\n                for e in list(oldP.outgoingEdges):\n                    root.addEdge(newP, e.dst, originObj=e.originObj)\n                    e.remove()\n        else:\n            raise ValueError(oldSplitNode)\n\n        root.children.remove(oldSplitNode)", "response": "re - connects ports from one node to another."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmerge all split and concatenation nodes and group them by target interface.", "response": "def mergeSplitsOnInterfaces(root: LNode):\n    \"\"\"\n    collect all split/concatenation nodes and group them by target interface\n    \"\"\"\n    for ch in root.children:\n        if ch.children:\n            mergeSplitsOnInterfaces(ch)\n\n    ctx = MergeSplitsOnInterfacesCtx()\n    for ch in root.children:\n        srcPorts = None\n        try:\n            if ch.name == \"CONCAT\":\n                p = single(ch.east, lambda x: True)\n                e = single(p.outgoingEdges, lambda x: True)\n                srcPorts = e.dsts\n            elif ch.name == \"SLICE\":\n                p = single(ch.west, lambda x: True)\n                e = single(p.incomingEdges, lambda x: True)\n                srcPorts = e.srcs\n        except (DuplicitValueExc, NoValueExc):\n            continue\n\n        if srcPorts is not None:\n            for srcPort in srcPorts:\n                if isinstance(srcPort.parent, LPort):\n                    # only for non primitive ports\n                    rootPort = getRootIntfPort(srcPort)\n                    ctx.register(rootPort, ch, e)\n\n    # join them if it is possible\n    for srcPort, splitsAndConcats in ctx.iterPortSplits():\n        if len(splitsAndConcats) <= 1:\n            continue\n\n        name = \"SPLIT\" if srcPort.direction == PortType.OUTPUT else \"CONCAT\"\n        newSplitNode = root.addNode(name)\n        copyPort(srcPort, newSplitNode, True, \"\")\n        n = splitsAndConcats[0][0]\n        for i in range(max(len(n.west),\n                           len(n.east))):\n            copyPort(\n                srcPort, newSplitNode,\n                False, \"[%d]\" % i)\n\n        reconnectPorts(root, srcPort, splitsAndConcats,\n                       newSplitNode)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget metadata about the package and module.", "response": "def get_metadata(main_file):\n    \"\"\"Get metadata about the package/module.\n\n    Positional arguments:\n    main_file -- python file path within `HERE` which has __author__ and the others defined as global variables.\n\n    Returns:\n    Dictionary to be passed into setuptools.setup().\n    \"\"\"\n    with open(os.path.join(HERE, 'README.md'), encoding='utf-8') as f:\n        long_description = f.read()\n\n    with open(os.path.join(HERE, main_file), encoding='utf-8') as f:\n        lines = [l.strip() for l in f if l.startswith('__')]\n    metadata = ast.literal_eval(\"{'\" + \", '\".join([l.replace(' = ', \"': \") for l in lines]) + '}')\n    __author__, __license__, __version__ = [metadata[k] for k in ('__author__', '__license__', '__version__')]\n\n    everything = dict(version=__version__, long_description=long_description, author=__author__, license=__license__)\n    if not all(everything.values()):\n        raise ValueError('Failed to obtain metadata from package/module.')\n\n    return everything"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef main_with_metrics():\n    try:\n        main()\n    except Exception:\n        report_metric(\"bus.lizzy-client.failed\", 1)\n        raise\n    except SystemExit as sys_exit:\n        if sys_exit.code == 0:\n            report_metric(\"bus.lizzy-client.success\", 1)\n        else:\n            report_metric(\"bus.lizzy-client.failed\", 1)\n        raise\n    else:\n        report_metric(\"bus.lizzy-client.success\", 1)", "response": "Runs main and reports success and failure metrics"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprints an agent error and exits", "response": "def agent_error(e: requests.HTTPError, fatal=True):\n    \"\"\"\n    Prints an agent error and exits\n    \"\"\"\n    try:\n        data = e.response.json()\n        details = data['detail']  # type: str\n    except JSONDecodeError:\n        details = e.response.text or str(e.response)\n\n    lines = ('[AGENT] {}'.format(line) for line in details.splitlines())\n    msg = '\\n' + '\\n'.join(lines)\n\n    if fatal:\n        fatal_error(msg)\n    else:\n        error(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if items included in `stack_references` are Senza definition file paths or stack name reference. If Senza definition file path, substitute the definition file path by the stack name in the same position on the list.", "response": "def parse_stack_refs(stack_references: List[str]) -> List[str]:\n    '''\n    Check if items included in `stack_references` are Senza definition\n    file paths or stack name reference. If Senza definition file path,\n    substitute the definition file path by the stack name in the same\n    position on the list.\n    '''\n    stack_names = []\n    references = list(stack_references)\n    references.reverse()\n    while references:\n        current = references.pop()\n        # current that might be a file\n        file_path = os.path.abspath(current)\n        if os.path.exists(file_path) and os.path.isfile(file_path):\n            try:\n                with open(file_path) as fd:\n                    data = yaml.safe_load(fd)\n                current = data['SenzaInfo']['StackName']\n            except (KeyError, TypeError, YAMLError):\n                raise click.UsageError(\n                    'Invalid senza definition {}'.format(current)\n                )\n        stack_names.append(current)\n    return stack_names"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create(definition: dict, version: str, parameter: tuple,\n           region: str,\n           disable_rollback: bool,\n           dry_run: bool,\n           force: bool,\n           tag: List[str],\n           timeout: int,\n           keep_stacks: Optional[int],\n           traffic: int,\n           verbose: bool,\n           remote: str,\n           parameter_file: Optional[str]\n           ):\n    \"\"\"\n    Create a new Cloud Formation stack from the given Senza definition file\n    \"\"\"\n    lizzy = setup_lizzy_client(remote)\n    parameter = list(parameter) or []\n    if parameter_file:\n        parameter.extend(read_parameter_file(parameter_file))\n\n    if not force:  # pragma: no cover\n        # supporting artifact checking would imply copying a large amount of code\n        # from senza, so it should be considered out of scope until senza\n        # and lizzy client are merged\n        warning(\"WARNING: \"\n                \"Artifact checking is still not supported by lizzy-client.\")\n\n    with Action('Requesting new stack..') as action:\n        new_stack, output = lizzy.new_stack(keep_stacks, traffic,\n                                            definition, version,\n                                            disable_rollback, parameter,\n                                            region=region,\n                                            dry_run=dry_run,\n                                            tags=tag)\n\n    stack_id = '{stack_name}-{version}'.format_map(new_stack)\n    print(output)\n\n    info('Stack ID: {}'.format(stack_id))\n\n    if dry_run:\n        info(\"Post deployment steps skipped\")\n        exit(0)\n\n    with Action('Waiting for new stack...') as action:\n        if verbose:\n            print()  # ensure that new states will not be printed on the same line as the action\n\n        last_state = None\n        for state in lizzy.wait_for_deployment(stack_id, region=region):\n            if state != last_state and verbose:\n                click.echo(' {}'.format(state))\n            else:\n                action.progress()\n            last_state = state\n\n        # TODO be prepared to handle all final AWS CF states\n        if last_state == 'ROLLBACK_COMPLETE':\n            fatal_error(\n                'Stack was rollback after deployment. Check your application log for possible reasons.')\n        elif last_state != 'CREATE_COMPLETE':\n            fatal_error('Deployment failed: {}'.format(last_state))\n\n    info('Deployment Successful')\n\n    if traffic is not None:\n        with Action('Requesting traffic change..'):\n            try:\n                lizzy.traffic(stack_id, traffic, region=region)\n            except requests.ConnectionError as e:\n                connection_error(e, fatal=False)\n            except requests.HTTPError as e:\n                agent_error(e, fatal=False)\n\n    # TODO unit test this\n    if keep_stacks is not None:\n        versions_to_keep = keep_stacks + 1\n        stacks_to_remove_counter = 1\n        end_time = datetime.datetime.utcnow() + datetime.timedelta(seconds=timeout)\n        while stacks_to_remove_counter > 0 and datetime.datetime.utcnow() <= end_time:\n            try:\n                all_stacks = lizzy.get_stacks([new_stack['stack_name']],\n                                              region=region)\n            except requests.ConnectionError as e:\n                connection_error(e, fatal=False)\n                error(\"Failed to fetch old stacks. \"\n                      \"Old stacks WILL NOT BE DELETED\")\n                exit(1)\n            except requests.HTTPError as e:\n                agent_error(e, fatal=False)\n                error(\"Failed to fetch old stacks. \"\n                      \"Old stacks WILL NOT BE DELETED\")\n                exit(1)\n            else:\n                sorted_stacks = sorted(all_stacks,\n                                       key=lambda stack: stack['creation_time'])\n                stacks_to_remove = sorted_stacks[:-versions_to_keep]\n                stacks_to_remove_counter = len(stacks_to_remove)\n                with Action('Deleting old stacks..'):\n                    print()\n                    for old_stack in stacks_to_remove:\n                        old_stack_id = '{stack_name}-{version}'.format_map(\n                            old_stack)\n                        if old_stack['status'] in COMPLETE_STATES:\n                            click.echo(' {}'.format(old_stack_id))\n                            try:\n                                lizzy.delete(old_stack_id, region=region)\n                                stacks_to_remove_counter -= 1\n                            except requests.ConnectionError as e:\n                                connection_error(e, fatal=False)\n                            except requests.HTTPError as e:\n                                agent_error(e, fatal=False)\n                        else:\n                            click.echo(' > {} current status is {} trying '\n                                       'again later'.format(old_stack_id,\n                                                            old_stack['status']))\n                if stacks_to_remove_counter > 0:\n                    time.sleep(5)\n\n        if datetime.datetime.utcnow() > end_time:\n            click.echo('Timeout waiting for related stacks to be ready.')", "response": "Create a new Cloud Formation stack from a Senza definition file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delete(stack_ref: List[str],\n           region: str, dry_run: bool, force: bool, remote: str):\n    \"\"\"Delete Cloud Formation stacks\"\"\"\n    lizzy = setup_lizzy_client(remote)\n    stack_refs = get_stack_refs(stack_ref)\n    all_with_version = all(stack.version is not None\n                           for stack in stack_refs)\n\n    # this is misleading but it's the current behaviour of senza\n    # TODO Lizzy list (stack_refs) to see if it actually matches more than one stack\n    # to match senza behaviour\n    if (not all_with_version and not dry_run and not force):\n        fatal_error(\n            'Error: {} matching stacks found. '.format(len(stack_refs)) +\n            'Please use the \"--force\" flag if you really want to delete multiple stacks.')\n\n    # TODO pass force option to agent\n\n    output = ''\n    for stack in stack_refs:\n        if stack.version is not None:\n            stack_id = '{stack.name}-{stack.version}'.format(stack=stack)\n        else:\n            stack_id = stack.name\n\n        with Action(\"Requesting stack '{stack_id}' deletion..\",\n                    stack_id=stack_id):\n            output = lizzy.delete(stack_id, region=region, dry_run=dry_run)\n\n    print(output)", "response": "Delete a single stack in a given region."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef py2dict(elements):\n    metadata_dict = {}\n    # Loop through all elements in the Python object.\n    for element in elements.children:\n        # Start an empty element list if an entry for the element\n        # list hasn't been made in the dictionary.\n        if element.tag not in metadata_dict:\n            metadata_dict[element.tag] = []\n        element_dict = {}\n        if hasattr(element, 'qualifier') and element.qualifier is not None:\n            element_dict['qualifier'] = element.qualifier\n        # Set the element's content as a dictionary\n        # of children elements.\n        if len(element.children) > 0:\n            child_dict = {}\n            for child in element.children:\n                if child.content is not None:\n                    child_dict[child.tag] = child.content\n            element_dict['content'] = child_dict\n        # Set element content that is not children.\n        elif element.content is not None:\n            if element.content.strip() != '':\n                element_dict['content'] = element.content\n        # Append the dictionary to the element list\n        # if the element has content or children.\n        if element_dict.get('content', False):\n            metadata_dict[element.tag].append(element_dict)\n\n    return metadata_dict", "response": "Convert a Python object into a Python dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert a Python object into a Python dictionary.", "response": "def etd_ms_py2dict(elements):\n    \"\"\"Convert a Python object into a Python dictionary.\"\"\"\n    metadata_dict = {}\n    # Loop through all elements in the Python object.\n    for element in elements.children:\n        # Start an empty element list if an entry for the element\n        # list hasn't been made in the dictionary.\n        if element.tag not in metadata_dict:\n            metadata_dict[element.tag] = []\n        element_dict = {}\n        if hasattr(element, 'role'):\n            element_dict['role'] = element.role\n        elif hasattr(element, 'scheme'):\n            element_dict['scheme'] = element.scheme\n        elif hasattr(element, 'qualifier') and element.qualifier is not None \\\n                and element.tag == 'title':\n            element_dict['qualifier'] = element.qualifier\n        # Set the element's content as a dictionary\n        # of children elements.\n        if element.children:\n            child_dict = {}\n            for child in element.children:\n                if child.content is not None:\n                    child_dict[child.tag] = child.content\n            element_dict['content'] = child_dict\n        # Set element content that is not children.\n        elif element.content is not None:\n            if element.content.strip() != '':\n                element_dict['content'] = element.content\n        # Append the dictionary to the element list\n        # if the element has content or children.\n        if element_dict.get('content', False):\n            metadata_dict[element.tag].append(element_dict)\n\n    return metadata_dict"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pydict2xml(filename, metadata_dict, **kwargs):\n    try:\n        f = open(filename, 'w')\n        f.write(pydict2xmlstring(metadata_dict, **kwargs).encode('utf-8'))\n        f.close()\n    except:\n        raise MetadataGeneratorException(\n            'Failed to create an XML file. Filename: %s' % (filename)\n        )", "response": "Create an XML file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pydict2xmlstring(metadata_dict, **kwargs):\n    ordering = kwargs.get('ordering', UNTL_XML_ORDER)\n    root_label = kwargs.get('root_label', 'metadata')\n    root_namespace = kwargs.get('root_namespace', None)\n    elements_namespace = kwargs.get('elements_namespace', None)\n    namespace_map = kwargs.get('namespace_map', None)\n    root_attributes = kwargs.get('root_attributes', None)\n    # Set any root namespace and namespace map.\n    if root_namespace and namespace_map:\n        root = Element(root_namespace + root_label, nsmap=namespace_map)\n    elif namespace_map:\n        root = Element(root_label, nsmap=namespace_map)\n    else:\n        root = Element(root_label)\n    # Set any root element attributes.\n    if root_attributes:\n        for key, value in root_attributes.items():\n            root.attrib[key] = value\n    # Create an XML structure from field list.\n    for metadata_key in ordering:\n        if metadata_key in metadata_dict:\n            for element in metadata_dict[metadata_key]:\n                if 'content' in element and 'qualifier' in element:\n                    create_dict_subelement(\n                        root,\n                        metadata_key,\n                        element['content'],\n                        attribs={'qualifier': element['qualifier']},\n                        namespace=elements_namespace,\n                    )\n                elif 'content' in element and 'role' in element:\n                    create_dict_subelement(\n                        root,\n                        metadata_key,\n                        element['content'],\n                        attribs={'role': element['role']},\n                        namespace=elements_namespace,\n                    )\n                elif 'content' in element and 'scheme' in element:\n                    create_dict_subelement(\n                        root,\n                        metadata_key,\n                        element['content'],\n                        attribs={'scheme': element['scheme']},\n                        namespace=elements_namespace,\n                    )\n                elif 'content' in element:\n                    create_dict_subelement(\n                        root,\n                        metadata_key,\n                        element['content'],\n                        namespace=elements_namespace,\n                    )\n    # Create the XML tree.\n    return '<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n' + tostring(\n        root,\n        pretty_print=True\n    )", "response": "Create an XML string from a metadata dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_dict_subelement(root, subelement, content, **kwargs):\n    attribs = kwargs.get('attribs', None)\n    namespace = kwargs.get('namespace', None)\n    key = subelement\n\n    # Add subelement's namespace and attributes.\n    if namespace and attribs:\n        subelement = SubElement(root, namespace + subelement, attribs)\n    elif namespace:\n        subelement = SubElement(root, namespace + subelement)\n    elif attribs:\n        subelement = SubElement(root, subelement, attribs)\n    # Otherwise, create SubElement without any extra data.\n    else:\n        subelement = SubElement(root, subelement)\n    if not isinstance(content, dict):\n        subelement.text = content\n    # Do special case ordering for degree children on etd_ms.\n    elif key == 'degree':\n        for degree_order_key in DEGREE_ORDER:\n            for descriptor, value in content.items():\n                if descriptor == degree_order_key:\n                    sub_descriptors = SubElement(subelement, descriptor)\n                    sub_descriptors.text = value\n    else:\n        for descriptor, value in content.items():\n            sub_descriptors = SubElement(subelement, descriptor)\n            sub_descriptors.text = value", "response": "Create a XML subelement from a Python dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating an XML string from the highwire data dictionary.", "response": "def highwiredict2xmlstring(highwire_elements, ordering=HIGHWIRE_ORDER):\n    \"\"\"Create an XML string from the highwire data dictionary.\"\"\"\n    # Sort the elements by the ordering list.\n    highwire_elements.sort(key=lambda obj: ordering.index(obj.name))\n    root = Element('metadata')\n    for element in highwire_elements:\n        attribs = {'name': element.name, 'content': element.content}\n        SubElement(root, 'meta', attribs)\n    # Create the XML tree.\n    return '<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n' + tostring(\n        root,\n        pretty_print=True\n    )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef writeANVLString(ANVLDict, ordering=UNTL_XML_ORDER):\n    lines = []\n    # Loop through the ordering for the data.\n    for key in ordering:\n        # Make sure the element exists in the data set.\n        if key in ANVLDict:\n            # Get the list of elements.\n            element_list = ANVLDict[key]\n            # Loop through the element contents.\n            for element in element_list:\n                value = element.get('content', '')\n                offset = len(key) + 1\n                line = '%s: %s' % (key, breakString(value, 79, offset))\n                lines.append(line)\n    return '\\n'.join(lines)", "response": "Take a dictionary and write out the key value pairs\n    in ANVL format."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get(binary_name):\n    if binary_name not in binaries:\n        raise Exception('binary_name: {0} not found'.format(binary_name))\n\n    system = platform.system()\n    binary_list = binaries[binary_name][system]\n\n    # check list for a valid entry\n    for filename in binary_list:\n        valid_file = shutil.which(filename)\n        if valid_file:\n            return os.path.abspath(valid_file)", "response": "return a valid path to the given binary"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the upgrade lock.", "response": "def get_upgrade_lock(dbname, connect_str, timeout=LOCK_TIMEOUT):\n    \"\"\"\n    Wait until you can get the lock, then yield it, and eventually release it.\n\n    Inspired by: http://arr.gr/blog/2016/05/mysql-named-locks-in-python-context-managers/\n\n    :param dbname: database to upgrade\n    :param connect_str: connection string to the database\n    :param timeout: how long to wait between tries for the lock, default 5 seconds\n    \"\"\"\n    #\n    # Open connection and try to get the lock\n    #\n    engine = sqlalchemy.create_engine(connect_str)\n    cursor = engine.execute(\"SELECT GET_LOCK('upgrade_{}', {})\".format(dbname, timeout))\n    lock = cursor.scalar()\n    cursor.close()\n\n    #\n    # Keep trying until you get it.\n    #\n    while not lock:\n        logger.info('Cannot acquire {} upgrade lock. Sleeping {} seconds.'.format(dbname, timeout))\n        time.sleep(timeout)\n        cursor = engine.execute(\"SELECT GET_LOCK('upgrade_{}', {})\".format(dbname, timeout))\n        lock = cursor.scalar()\n        cursor.close()\n    logger.info('Acquired {} upgrade lock'.format(dbname))\n    yield lock\n\n    #\n    # Release the lock and close the connection.\n    #\n    cursor = engine.execute(\"SELECT RELEASE_LOCK('upgrade_{}')\".format(dbname))\n    cursor.close()\n    engine.dispose()\n    logger.info('Released {} upgrade lock'.format(dbname))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the database s upgrade lock and run alembic.", "response": "def upgrade(dbname, connect_str, alembic_conf):\n    \"\"\"\n    Get the database's upgrade lock and run alembic.\n\n    :param dbname: Name of the database to upgrade/create\n    :param connect_str: Connection string to the database (usually Flask's SQLALCHEMY_DATABASE_URI)\n    :param alembic_conf: location of alembic.ini\n    \"\"\"\n    #\n    # The db has to exist before we can get the lock. On the off-chance that another process creates the db between\n    # checking if it exists and running the create, ignore the exception.\n    #\n    if not sqlalchemy_utils.database_exists(connect_str):\n        logger.info('Creating {}'.format(dbname))\n        try:\n            sqlalchemy_utils.create_database(connect_str)\n        except sqlalchemy.exc.ProgrammingError as exc:\n            if not sqlalchemy_utils.database_exists(connect_str):\n                logger.error('Could not create {}'.format(dbname))\n                raise exc\n\n    with get_upgrade_lock(dbname, connect_str):\n        alembic_config = alembic.config.Config(\n            alembic_conf,\n            attributes={'configure_logger': False})\n        logger.info('Upgrading {} to head'.format(dbname))\n        alembic.command.upgrade(alembic_config, 'head')"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns list of packages in distribution", "response": "def getPackages(self, distribution = \"rawhide\"):\n\t\t\"\"\"\n\t\t:param distribution: package distribution\n\t\t:type  distribution: string\n\t\t:returns: [string]\n\t\t:raises KeyError: if distribution not found\n\t\t\"\"\"\n\t\tif self._packages == {}:\n\t\t\tfile_location = \"%s/data/distribution_packages.json\" % getScriptDir(__file__)\n\t\t\twith open(file_location, \"r\") as f:\n\t\t\t\tpackages = json.load(f)\n\t\t\tfor pkg in packages:\n\t\t\t\tfor distro in pkg[\"distributions\"]:\n\t\t\t\t\ttry:\n\t\t\t\t\t\tself._packages[distro].append(pkg[\"package\"])\n\t\t\t\t\texcept KeyError:\n\t\t\t\t\t\tself._packages[distro] = [pkg[\"package\"]]\n\n\t\treturn self._packages[distribution]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreplace boolean variables by the characters F / T", "response": "def _check_and_convert_bools(self):\n        \"\"\"Replace boolean variables by the characters 'F'/'T'\n        \"\"\"\n        replacements = {\n            True: 'T',\n            False: 'F',\n        }\n\n        for key in self.bools:\n            if isinstance(self[key], bool):\n                self[key] = replacements[self[key]]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfills the dictionary with all default values", "response": "def set_defaults(self):\n        \"\"\"\n        Fill the dictionary with all defaults\n        \"\"\"\n        self['mswitch'] = '***FILES***'\n        self['elem'] = '../grid/elem.dat'\n        self['elec'] = '../grid/elec.dat'\n        self['rho'] = '../rho/rho.dat'\n        self['config'] = '../config/config.dat'\n        self['write_pots'] = 'F'  # ! potentials ?\n        self['pot_file'] = '../mod/pot/pot.dat'\n        self['write_volts'] = 'T'  # ! measurements ?\n        self['volt_file'] = '../mod/volt.dat'\n        self['write_sens'] = 'F'  # ! sensitivities ?\n        self['sens_file'] = '../mod/sens/sens.dat'\n        self['another_dataset'] = 'F'  # ! another dataset ?\n        self['2D'] = '1'  # ! 2D (=0) or 2.5D (=1)\n        self['fictitious_sink'] = 'F'  # ! fictitious sink ?\n        self['sink_node'] = '1660'  # ! fictitious sink node number\n        self['boundary_values'] = 'F'  # ! boundary values ?\n        self['boundary_file'] = 'boundary.dat'"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfill the dictionary with all default values", "response": "def set_defaults(self):\n        \"\"\"Fill the dictionary with all defaults\n        \"\"\"\n        self['mswitch'] = 1\n        self['elem'] = '../grid/elem.dat'\n        self['elec'] = '../grid/elec.dat'\n        self['volt'] = '../mod/volt.dat'\n        self['inv_dir'] = '../inv'\n        self['diff_inv'] = 'F ! difference inversion?'\n        self['iseed_var'] = 'iseed variance'\n        self['cells_x'] = '0    ! # cells in x-direction'\n        self['cells_z'] = '-1    ! # cells in z-direction'\n        self['ani_x'] = '1.000  ! smoothing parameter in x-direction'\n        self['ani_z'] = '1.000  ! smoothing parameter in z-direction'\n        self['max_it'] = '20    ! max. nr of iterations'\n        self['dc_inv'] = 'F     ! DC inversion?'\n        self['robust_inv'] = 'T     ! robust inversion?'\n        self['fpi_inv'] = 'F     ! final phase improvement?'\n        self['mag_rel'] = '5'\n        self['mag_abs'] = '1e-3'\n        self['pha_a1'] = 0\n        self['pha_b'] = 0\n        self['pha_rel'] = 0\n        self['pha_abs'] = 0\n        self['hom_bg'] = 'F'\n        self['hom_mag'] = '10.00'\n        self['hom_pha'] = '0.00'\n        self['another_ds'] = 'F'\n        self['d2_5'] = '1'\n        self['fic_sink'] = 'F'\n        self['fic_sink_node'] = '10000'\n        self['boundaries'] = 'F'\n        self['boundaries_file'] = 'boundary.dat'\n        self['mswitch2'] = '1'\n        self['lambda'] = 'lambda'"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef write_to_file(self, filename):\n        fid = open(filename, 'w')\n\n        for key in self.key_order:\n            if(key == -1):\n                fid.write('\\n')\n            else:\n                fid.write('{0}\\n'.format(self[key]))\n\n        fid.close()", "response": "Write the configuration to a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse(self, importpath):\n\t\t# reset default values\n\t\tself.native = False\n\t\tself._prefix = \"\"\n\t\tself._package = \"\"\n\n\t\turl = re.sub(r'http://', '', importpath)\n\t\turl = re.sub(r'https://', '', url)\n\n\t\t# is import path native package?\n\t\tif url.split('/')[0] in self.native_packages[\"packages\"]:\n\t\t\tself.native = True\n\t\t\treturn self\n\n\t\tfor regex in self.known_ipprefixes:\n\t\t\tmatch = re.search(regex, url)\n\t\t\tif match:\n\t\t\t\tself._prefix = match.group(1)\n\t\t\t\tif match.group(3):\n\t\t\t\t\tself._package = match.group(3)\n\t\t\t\treturn self\n\n\t\traise ValueError(\"Import path prefix for '%s' not recognized\" % importpath)", "response": "Parse the import path and return a boolean indicating if it is native or not."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sub_retab(match):\n    before = match.group(1)\n    tabs = len(match.group(2))\n    return before + (' ' * (TAB_SIZE * tabs - len(before) % TAB_SIZE))", "response": "r Removes all tabs and convert them into spaces."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef handle_whitespace(text):\n    text = re_retab.sub(sub_retab, text)\n    text = re_whitespace.sub('', text).strip()\n    return text", "response": "r Handles whitespace cleanup."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_variables(text):\n    variables = {var: value for var, value in re_vars.findall(text)}\n    text = re_vars.sub('', text)\n    return text, variables", "response": "Extracts variables that can be used in templating engines."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nretrieve all link references within the text.", "response": "def get_references(text):\n    \"\"\"Retrieves all link references within the text.\n\n    Link references can be defined anywhere in the text, and look like\n    this:\n\n        [id]: www.example.com \"optional title\"\n\n    A link (either <a> or <img>) can then refer to the link reference:\n\n        [this is a link][id]\n\n    Link IDs are case insensitive. Link references are also removed\n    from the text after they have been retrieved.\n\n    RETURNS:\n    text       -- str; text with all link labels removed\n    references -- dict; link ids to (URL, title), where title is the\n                  empty string if it is omitted.\n    \"\"\"\n    references = {}\n    for ref_id, link, _, title in re_references.findall(text):\n        ref_id = re.sub(r'<(.*?)>', r'\\1', ref_id).lower().strip()\n        references[ref_id] = (link, title)\n    text = re_references.sub('', text)\n    return text, references"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_footnote_backreferences(text, markdown_obj):\n    footnotes = OrderedDict()\n    for footnote_id, footnote in re_footnote_backreferences.findall(text):\n        footnote_id = re.sub(r'<(.*?)>', r'\\1', footnote_id).lower().strip()\n        footnote = re.sub(r'^[ ]{0,4}', '', footnote, flags=re.M)\n        footnotes[footnote_id] = footnote\n    text = re_footnote_backreferences.sub('', text)\n    return text, footnotes", "response": "Retrieves all footnote backreferences within the text."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef hash_blocks(text, hashes):\n    def sub(match):\n        block = match.group(1)\n        hashed = hash_text(block, 'block')\n        hashes[hashed] = block\n        return '\\n\\n' + hashed + '\\n\\n'\n    return re_block.sub(sub, text)", "response": "Hashes HTML block tags."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nhashing ordered and unordered lists.", "response": "def hash_lists(text, hashes, markdown_obj):\n    \"\"\"Hashes ordered and unordered lists.\n\n    re_list captures as many consecutive list items as possible and\n    groups them into one list. Before hashing the lists, the items\n    are recursively converted from Markdown to HTML. Upon unhashing,\n    the lists will be ready in their final form.\n\n    An attempt at list formatting is done by adding two spaces to\n    each list item. Since list conversion is a recursive process,\n    each nested list will add an additional two spaces to list items.\n    The only exception is for pre blocks -- these are \"pulled out\" of\n    indentation when the list is unhashed.\n\n    A note on implementation: Markdown syntax for list items is\n    essentially the same, except everything is shifted to the right by\n    four spaces. This assumption is made when recursively converting\n    list items.\n\n    List items that consist of only a single paragraph of text are\n    \"pulled out\" of the paragraph (that is, the <p> tag is removed).\n    This differs slightly from original Markdown syntax, which encloses\n    list items in <p> tags if list items are separated by one or more\n    blank lines.\n    \"\"\"\n    for style, marker in (('u', '[+*-]'), ('o', r'\\d+\\.')):\n        list_re = re.compile(re_list % (marker, marker), re.S | re.X)\n        # import pdb\n        # pdb.set_trace()\n        for match in list_re.finditer(text):\n            if not match:\n                continue\n            lst = match.group(1)\n            items = re.split(r'(?:\\n|\\A) {0,3}%s ' % marker, lst)[1:]\n            whole_list = ''\n            for item in items:\n                item = re.sub(r'^ {1,4}', '', item, flags=re.M)\n                item = markdown_obj.convert(item)\n                par_match = re.match('<p>(.*?)</p>', item, flags=re.S)\n                if par_match and par_match.group(0) == item.strip():\n                    item = par_match.group(1)\n                whole_list += '<li>{}</li>\\n'.format(item)\n            whole_list = '<{0}l>\\n{1}\\n</{0}l>'.format(\n                    style,\n                    re.sub('^', '  ', whole_list.strip(), flags=re.M))\n            hashed = hash_text(whole_list, 'list')\n            hashes[hashed] = whole_list\n            start = text.index(match.group(0))\n            end = start + len(match.group(0))\n            text = text[:start] + '\\n\\n' + hashed + '\\n\\n' + text[end:]\n    return text"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef hash_codeblocks(text, hashes):\n    def sub(match):\n        block = match.group(1).rstrip('\\n')\n        block = re.sub(r'(?:(?<=\\n)|(?<=\\A)) {4}', '', block)\n        block = escape(block)\n        block = '<pre><code>{}</code></pre>'.format(block)\n        hashed = hash_text(block, 'pre')\n        hashes[hashed] = block\n        return '\\n\\n' + hashed + '\\n\\n'\n    return re_codeblock.sub(sub, text)", "response": "Hashes codeblocks in text."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nhash block quotes. Block quotes are defined to be lines that start with \"> \" (the space is not optional). All Markdown syntax in a blockquote is recursively converted, which allows (among other things) headers, codeblocks, and blockquotes to be used inside of blockquotes. The \"> \" is simply stripped from the front of any blockquote lines and the result is recursively converted.", "response": "def hash_blockquotes(text, hashes, markdown_obj):\n    \"\"\"Hashes block quotes.\n\n    Block quotes are defined to be lines that start with \"> \" (the\n    space is not optional).\n\n    All Markdown syntax in a blockquote is recursively converted,\n    which allows (among other things) headers, codeblocks, and\n    blockquotes to be used inside of blockquotes. The \"> \" is simply\n    stripped from the front of any blockquote lines and the result is\n    recursively converted.\n    \"\"\"\n    def sub(match):\n        block = match.group(1).strip()\n        block = re.sub(r'(?:(?<=\\n)|(?<=\\A))> ?', '', block)\n        block = markdown_obj.convert(block)\n        block = '<blockquote>{}</blockquote>'.format(block)\n        hashed = hash_text(block, 'blockquote')\n        hashes[hashed] = block\n        return '\\n\\n' + hashed + '\\n\\n'\n    return re_blockquote.sub(sub, text)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nhash inline code tags.", "response": "def hash_codes(text, hashes):\n    \"\"\"Hashes inline code tags.\n\n    Code tags can begin with an arbitrary number of back-ticks, as long\n    as the close contains the same number of back-ticks. This allows\n    back-ticks to be used within the code tag.\n\n    HTML entities (&, <, >, \", ') are automatically escaped inside the\n    code tag.\n    \"\"\"\n    def sub(match):\n        code = '<code>{}</code>'.format(escape(match.group(2)))\n        hashed = hash_text(code, 'code')\n        hashes[hashed] = code\n        return hashed\n    return re_code.sub(sub, text)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nhashing an <a> link or an <img> link. This function only converts inline link styles: [text here](path/to/resource \"optional title\") ![alt text here](path/to/resource \"optional title\") For reference style links, see hash_reference_links", "response": "def hash_inline_links(text, hashes, markdown_obj):\n    \"\"\"Hashes an <a> link or an <img> link.\n\n    This function only converts inline link styles:\n\n        [text here](path/to/resource \"optional title\")\n        ![alt text here](path/to/resource \"optional title\")\n\n    For reference style links, see hash_reference_links\n    \"\"\"\n    def sub(match):\n        is_img = match.group(1) != ''\n        content = match.group(2)\n        link = match.group(3)\n        title = match.group(5)\n        if title:\n            title = ' title=\"{0}\"'.format(title.strip())\n        else:\n            title = ''\n        if is_img:\n            result = '<img src=\"{0}\" alt=\"{1}\"{2}>'.format(\n                    link, content, title)\n        else:\n            result = '<a href=\"{0}\"{2}>{1}</a>'.format(link,\n                    markdown_obj.convert(content).replace('<p>', '').replace('</p>', ''),\n                    title)\n        hashed = hash_text(result, 'link')\n        hashes[hashed] = result\n        return hashed\n    return re_inline_link.sub(sub, text)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef hash_reference_links(text, hashes, markdown_obj):\n    def sub(match):\n        is_img = match.group(1) != ''\n        content = match.group(2)\n        ref = match.group(3).strip().lower()\n        if not ref:\n            ref = content.strip().lower()\n        ref = ref.replace('\\n', ' ')\n        if ref not in markdown_obj.references:\n            link, title = '', ''\n        else:\n            link, title = markdown_obj.references[ref]\n        if title:\n            title = ' title=\"{0}\"'.format(title)\n        if is_img:\n            result = '<img src=\"{0}\" alt=\"{1}\"{2}>'.format(\n                    link, content, title)\n        else:\n            result = '<a href=\"{0}\"{2}>{1}</a>'.format(link,\n                    markdown_obj.convert(content).replace('<p>', '').replace('</p>', '').strip(),\n                    title)\n        hashed = hash_text(result, 'link')\n        hashes[hashed] = result\n        return hashed\n    return re_reference_link.sub(sub, text)", "response": "Hashes an implicit link or inline style link."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nhash a footnote reference text here.", "response": "def hash_footnote_reference(text, hashes, markdown_obj):\n    \"\"\"Hashes a footnote [^id] reference\n\n    This function converts footnote styles:\n\n        text here[^id]\n\n    Footnotes can be defined anywhere in the Markdown text.\n    \"\"\"\n    footnotes = markdown_obj.footnotes\n    numbers = {f: i+1 for i, f in enumerate(footnotes)}\n    def sub(match):\n        footnote_id = match.group(1)\n        if footnote_id not in footnotes:\n            return ''\n        number = numbers[footnote_id]\n        result = '<sup><a href=\"#fnref-{0}\">{0}</a></sup>'.format(number)\n        hashed = hash_text(result, 'footnote')\n        hashes[hashed] = result\n        return hashed\n    return re_footnote.sub(sub, text)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef hash_tags(text, hashes):\n    def sub(match):\n        hashed = hash_text(match.group(0), 'tag')\n        hashes[hashed] = match.group(0)\n        return hashed\n    return re_tag.sub(sub, text)", "response": "Hashes any non - block tags."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef emphasis_sub(match):\n    level = len(match.group(1))\n    content = match.group(2)\n    if level == 3:\n        return '<strong><em>{0}</em></strong>'.format(content)\n    elif level == 2:\n        return '<strong>{0}</strong>'.format(content)\n    elif level == 1:\n        return '<em>{0}</em>'.format(content)", "response": "Substitutes <strong > and <em > tags."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsubstitutes atx headers ( headers defined using. s ).", "response": "def atx_header_sub(match):\n    \"\"\"Substitutes atx headers (headers defined using #'s).\"\"\"\n    level = len(match.group(1))\n    title = match.group(2)\n\n    id_class = ''\n    ids = match.group(3) if match.group(3) else ''\n    id_match = re.search('#([\\w-]+)', ids)\n    if id_match:\n        id_class += ' id=\"' + id_match.group(1) + '\"'\n    classes = ' '.join(re.findall('\\.([\\w-]+)', ids))\n    if classes:\n        id_class += ' class=\"' + classes + '\"'\n    return '\\n<h{0}{2}>{1}</h{0}>\\n'.format(level, title, id_class)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef slug_sub(match):\n    level = match.group(1)\n    title = match.group(2)\n    slug = title.lower()\n    slug = re.sub(r'<.+?>|[^\\w-]', ' ', slug)\n    slug = re.sub(r'[ \\t]+', ' ', slug).strip()\n    slug = slug.replace(' ', '-')\n    if slug:\n        return '<{0} id=\"{1}\">{2}</{0}>'.format(level, slug, title)\n    return match.group(0)", "response": "Assigns id - less headers a slug that is derived from their\n    titles."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a set of all nodes containg the root_nodes and all nodes reacheable from them and return the resulting subgraph", "response": "def truncateGraph(graph, root_nodes):\n\t\t\"\"\"Create a set of all nodes containg the root_nodes and\n\t\t   all nodes reacheable from them\n\t\t\"\"\"\n\t\tsubgraph = Graph()\n\t\tfor node in root_nodes:\n\t\t\tsubgraph = GraphUtils.joinGraphs(subgraph, GraphUtils.getReacheableSubgraph(graph, node))\n\n\t\treturn subgraph"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving all nodes for with node_fnc does not hold", "response": "def filterGraph(graph, node_fnc):\n\t\t\"\"\"Remove all nodes for with node_fnc does not hold\n\t\t\"\"\"\n\t\tnodes = filter(lambda l: node_fnc(l), graph.nodes())\n\t\tedges = {}\n\n\t\tgedges = graph.edges()\n\t\tfor u in gedges:\n\t\t\tif u not in nodes:\n\t\t\t\tcontinue\n\t\t\tfor v in gedges[u]:\n\t\t\t\tif v not in nodes:\n\t\t\t\t\tcontinue\n\t\t\t\ttry:\n\t\t\t\t\tedges[u].append(v)\n\t\t\t\texcept KeyError:\n\t\t\t\t\tedges[u] = [v]\n\n\t\treturn Graph(nodes, edges)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncommit the current branch with all files.", "response": "def commit(config, no_verify):\n    \"\"\"Commit the current branch with all files.\"\"\"\n    repo = config.repo\n\n    active_branch = repo.active_branch\n    if active_branch.name == \"master\":\n        error_out(\n            \"Can't commit when on the master branch. \"\n            \"You really ought to do work in branches.\"\n        )\n\n    now = time.time()\n\n    def count_files_in_directory(directory):\n        count = 0\n        for root, _, files in os.walk(directory):\n            # We COULD crosscheck these files against the .gitignore\n            # if we ever felt overachievious.\n            count += len(files)\n        return count\n\n    # First group all untracked files by root folder\n    all_untracked_files = {}\n    for path in repo.untracked_files:\n        root = path.split(os.path.sep)[0]\n        if root not in all_untracked_files:\n            all_untracked_files[root] = {\n                \"files\": [],\n                \"total_count\": count_files_in_directory(root),\n            }\n        all_untracked_files[root][\"files\"].append(path)\n\n    # Now filter this based on it being single files or a bunch\n    untracked_files = {}\n    for root, info in all_untracked_files.items():\n        for path in info[\"files\"]:\n            age = now - os.stat(path).st_mtime\n            # If there's fewer untracked files in its directory, suggest\n            # the directory instead.\n            if info[\"total_count\"] == 1:\n                path = root\n            if path in untracked_files:\n                if age < untracked_files[path]:\n                    # youngest file in that directory\n                    untracked_files[path] = age\n            else:\n                untracked_files[path] = age\n\n    if untracked_files:\n        ordered = sorted(untracked_files.items(), key=lambda x: x[1], reverse=True)\n        info_out(\"NOTE! There are untracked files:\")\n        for path, age in ordered:\n            if os.path.isdir(path):\n                path = path + \"/\"\n            print(\"\\t\", path.ljust(60), humanize_seconds(age), \"old\")\n\n        # But only put up this input question if one the files is\n        # younger than 12 hours.\n        young_ones = [x for x in untracked_files.values() if x < 60 * 60 * 12]\n        if young_ones:\n            ignore = input(\"Ignore untracked files? [Y/n] \").lower().strip()\n            if ignore.lower().strip() == \"n\":\n                error_out(\n                    \"\\n\\tLeaving it up to you to figure out what to do \"\n                    \"with those untracked files.\"\n                )\n                return 1\n            print(\"\")\n\n    state = read(config.configfile)\n\n    try:\n        data = load(config.configfile, active_branch.name)\n    except KeyError:\n        error_out(\n            \"You're in a branch that was not created with gg.\\n\"\n            \"No branch information available.\"\n        )\n\n    print(\"Commit message: (type a new one if you want to override)\")\n    msg = data[\"description\"]\n    if data.get(\"bugnumber\"):\n        if is_bugzilla(data):\n            msg = \"bug {} - {}\".format(data[\"bugnumber\"], data[\"description\"])\n            msg = input('\"{}\" '.format(msg)).strip() or msg\n        elif is_github(data):\n            msg = input('\"{}\" '.format(msg)).strip() or msg\n            msg += \"\\n\\nPart of #{}\".format(data[\"bugnumber\"])\n\n    if data[\"bugnumber\"]:\n        question = 'Add the \"fixes\" mention? [N/y] '\n        fixes = input(question).lower().strip()\n        if fixes in (\"y\", \"yes\"):\n            if is_bugzilla(data):\n                msg = \"fixes \" + msg\n            elif is_github(data):\n                msg = msg.replace(\"Part of \", \"Fixes \")\n            else:\n                raise NotImplementedError\n\n    # Now we're going to do the equivalent of `git commit -a -m \"...\"`\n    index = repo.index\n    files_added = []\n    files_removed = []\n    for x in repo.index.diff(None):\n        if x.deleted_file:\n            files_removed.append(x.b_path)\n        else:\n            files_added.append(x.b_path)\n    files_new = []\n    for x in repo.index.diff(repo.head.commit):\n        files_new.append(x.b_path)\n\n    proceed = True\n    if not (files_added or files_removed or files_new):\n        info_out(\"No files to add or remove.\")\n        proceed = False\n        if input(\"Proceed anyway? [Y/n] \").lower().strip() == \"n\":\n            proceed = True\n\n    if proceed:\n        if not repo.is_dirty():\n            error_out(\"Branch is not dirty. There is nothing to commit.\")\n        if files_added:\n            index.add(files_added)\n        if files_removed:\n            index.remove(files_removed)\n        try:\n            commit = index.commit(msg)\n        except git.exc.HookExecutionError as exception:\n            if not no_verify:\n                info_out(\n                    \"Commit hook failed ({}, exit code {})\".format(\n                        exception.command, exception.status\n                    )\n                )\n                if exception.stdout:\n                    error_out(exception.stdout)\n                elif exception.stderr:\n                    error_out(exception.stderr)\n                else:\n                    error_out(\"Commit hook failed.\")\n            else:\n                commit = index.commit(msg, skip_hooks=True)\n\n        success_out(\"Commit created {}\".format(commit.hexsha))\n\n    if not state.get(\"FORK_NAME\"):\n        info_out(\"Can't help you push the commit. Please run: gg config --help\")\n        return 0\n\n    try:\n        repo.remotes[state[\"FORK_NAME\"]]\n    except IndexError:\n        error_out(\"There is no remote called '{}'\".format(state[\"FORK_NAME\"]))\n\n    push_for_you = (\n        input(\"Push branch to {}? [Y/n] \".format(state[\"FORK_NAME\"])).lower().strip()\n    )\n    if push_for_you not in (\"n\", \"no\"):\n        destination = repo.remotes[state[\"FORK_NAME\"]]\n        pushed, = destination.push()\n        # Was it rejected?\n        if (\n            pushed.flags & git.remote.PushInfo.REJECTED\n            or pushed.flags & git.remote.PushInfo.REMOTE_REJECTED\n        ):\n            error_out('The push was rejected (\"{}\")'.format(pushed.summary), False)\n\n            try_force_push = input(\"Try to force push? [Y/n] \").lower().strip()\n            if try_force_push not in (\"no\", \"n\"):\n                pushed, = destination.push(force=True)\n                info_out(pushed.summary)\n            else:\n                return 0\n\n    else:\n        # If you don't want to push, then don't bother with GitHub\n        # Pull Request stuff.\n        return 0\n\n    if not state.get(\"GITHUB\"):\n        if config.verbose:\n            info_out(\n                \"Can't help create a GitHub Pull Request.\\n\"\n                \"Consider running: gg github --help\"\n            )\n        return 0\n\n    origin = repo.remotes[state.get(\"ORIGIN_NAME\", \"origin\")]\n    rest = re.split(r\"github\\.com[:/]\", origin.url)[1]\n    org, repo = rest.split(\".git\")[0].split(\"/\", 1)\n\n    # Search for an existing open pull request, and remind us of the link\n    # to it.\n    search = {\n        \"head\": \"{}:{}\".format(state[\"FORK_NAME\"], active_branch.name),\n        \"state\": \"open\",\n    }\n    for pull_request in github.find_pull_requests(config, org, repo, **search):\n        print(\"Pull Request already created:\")\n        print(\"\")\n        print(\"\\t\", pull_request[\"html_url\"])\n        break\n    else:\n        # If no known Pull Request exists, make a link to create a new one.\n        github_url = \"https://github.com/{}/{}/compare/{}:{}...{}:{}?expand=1\"\n        github_url = github_url.format(\n            org, repo, org, \"master\", state[\"FORK_NAME\"], active_branch.name\n        )\n        print(\"Now, to make a Pull Request, go to:\")\n        print(\"\")\n        success_out(github_url)\n    print(\"(\u2318-click to open URLs)\")\n\n    return 0"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting amount to human readable format", "response": "def _humanize_time(amount, units):\n    \"\"\"Chopped and changed from http://stackoverflow.com/a/6574789/205832\"\"\"\n    intervals = (1, 60, 60 * 60, 60 * 60 * 24, 604800, 2419200, 29030400)\n    names = (\n        (\"second\", \"seconds\"),\n        (\"minute\", \"minutes\"),\n        (\"hour\", \"hours\"),\n        (\"day\", \"days\"),\n        (\"week\", \"weeks\"),\n        (\"month\", \"months\"),\n        (\"year\", \"years\"),\n    )\n\n    result = []\n    unit = [x[1] for x in names].index(units)\n    # Convert to seconds\n    amount = amount * intervals[unit]\n    for i in range(len(names) - 1, -1, -1):\n        a = int(amount) // intervals[i]\n        if a > 0:\n            result.append((a, names[i][1 % a]))\n            amount -= a * intervals[i]\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of all non dotfiles in a given directory.", "response": "def listdir(self, path):\n        '''\n        Return a list of all non dotfiles in a given directory.\n        '''\n        for f in os.listdir(path):\n            if not f.startswith('.'):\n                yield f"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of absolute paths to be used to instantiate path objects for traversal based on whether hidden attribute is set.", "response": "def getchildren(self):\n        '''\n        Create list of absolute paths to be used to instantiate path objects\n        for traversal, based on whether or not hidden attribute is set.\n        '''\n        try:\n            if self.hidden:\n                return [os.path.join(self.name, child)\n                        for child in sorted(self.listdir(self.name))]\n            else:\n                return [os.path.join(self.name, child)\n                        for child in sorted(os.listdir(self.name))]\n        except OSError:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget paths of all children of this class", "response": "def getpaths(self):\n        '''\n        If we have children, use a list comprehension to instantiate new paths\n        objects to traverse.\n        '''\n        self.children = self.getchildren()\n        if self.children is None:\n            return\n        if self.paths is None:\n            self.paths = [Paths(self.screen,\n                                os.path.join(self.name, child),\n                                self.hidden,\n                                self.picked,\n                                self.expanded,\n                                self.sized)\n                          for child in self.children]\n        return self.paths"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef traverse(self):\n        '''\n        Recursive generator that lazily unfolds the filesystem.\n        '''\n        yield self, 0\n        if self.name in self.expanded:\n            for path in self.getpaths():\n                for child, depth in path.traverse():\n                    yield child, depth + 1", "response": "Recursive generator that lazily unfolds the filesystem."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomputing the intersection point of two lines in a .", "response": "def line_line_intersect(x, y):\n    \"\"\"Compute the intersection point of two lines\n\n    Parameters\n    ----------\n    x = x4 array: x1, x2, x3, x4\n    y = x4 array: y1, y2, y3, y4\n    line 1 is defined by p1,p2\n    line 2 is defined by p3,p4\n\n    Returns\n    -------\n    Ix: x-coordinate of intersection\n    Iy: y-coordinate of intersection\n    \"\"\"\n    A = x[0] * y[1] - y[0] * x[1]\n    B = x[2] * y[3] - y[2] * x[4]\n    C = (x[0] - x[1]) * (y[2] - y[3]) - (y[0] - y[1]) * (x[2] - x[3])\n\n    Ix = (A * (x[2] - x[3]) - (x[0] - x[1]) * B) / C\n    Iy = (A * (y[2] - y[3]) - (y[0] - y[1]) * B) / C\n    return Ix, Iy"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncomputing shortest distance of points in x y to the line described by the end points in x y.", "response": "def distances(x, y, px, py, plot=False):\n    \"\"\"\n    Compute shortest distance of points (px, py) to the line described by the\n    end points in (x, y).\n\n    Parameters\n    ----------\n    x,y: x and y coordinates of line\n    px: x coordinates of data points\n    py: y coordiante of data points\n\n    Returns\n    -------\n    distances: list of distances\n    \"\"\"\n\n    length_line = np.sqrt((x[1] - x[0]) ** 2 + (y[1] - y[0]) ** 2)\n\n    horizontal = (np.diff(y) == 0)\n    vertical = (np.diff(x) == 0)\n\n    dist = []\n    dpl = []\n    counter = 0\n    for xp, yp in zip(px, py):\n        # compute distances to the end points\n        dp = np.sqrt((xp - x) ** 2 + (yp - y) ** 2)\n\n        dpl.append(dp)\n        if np.any(dp > length_line):\n            point_dist = np.min(dp)\n        elif horizontal:\n            point_dist = np.abs(yp - y[0])\n        elif vertical:\n            point_dist = np.abs(xp - x[0])\n        else:\n            nominator = np.abs(\n                (y[1] - y[0]) * xp -\n                (x[1] - x[0]) * yp +\n                x[1] * y[0] -\n                y[1] * x[0])\n            denominator = np.sqrt((y[1] - y[0]) ** 2 + (x[1] - x[0]) ** 2)\n            point_dist = nominator / denominator\n\n        dist.append(point_dist)\n        counter += 1\n\n    # debug plot\n    if plot:\n        fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n        ax.scatter(x, y)\n        ax.scatter(px, py, color='r')\n\n        index = 0\n        for xp, yp in zip(px, py):\n            ax.annotate('{0:.5}, {1:.5}, {2:.5}'.format(\n                dist[index], dpl[index][0], dpl[index][1]),\n                xy=(xp, yp))\n            index += 1\n        ax.plot(x, y)\n        ax.set_aspect('equal')\n    return dist"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncomputing the element pairs for regulazisation decoupling for a given line in a given grid.", "response": "def get_decouplings_for_line(grid, line, settings, fids=None):\n    \"\"\"Compute the element pairs for regulazisation decoupling, given a grid\n    object and a line, denoted by start and end coordinates, in the grid.\n\n    Parameters\n    ----------\n    grid: a crtomo.grid.crt_grid object\n    line: np.array/list with 4 entries: x1, y1, x2, x2, denoting start and end\n          point\n    fids: None, or: list with file ids for\n        debug_nodes\n\n\n\n    Returns\n    -------\n    neighbors: Mx2 array with the numbers of adjoining elements along the given\n               line\n    \"\"\"\n    key = 'presort'\n    # x/z coordinates of 'macro'-line\n    x = [line[0], line[2]]\n    y = [line[1], line[3]]\n\n    # x/z coordinates of all nodes in the grid\n    nx = grid.nodes[key][:, 1]\n    ny = grid.nodes[key][:, 2]\n    nxy = np.vstack((nx, ny)).T\n\n    # shortest distance of all nodes to this line\n    dist = np.array(distances(x, y, nx, ny))\n\n    # set the epsilon environment\n    if settings.get('eps', None) is not None:\n        eps = settings['eps']\n        print('Taking user supplied eps value: {0}'.format(eps))\n    else:\n        import scipy.spatial.distance as spdist\n        pair_distances = spdist.pdist(nxy)\n        print('automatic eps determination')\n        print('minimal distance: {0}'.format(pair_distances.min()))\n        eps = np.sqrt(\n            pair_distances.min() ** 2 - (pair_distances.min() ** 2) / 4\n        )\n        print('estimated smallest distance to next node: {0}'.format(eps))\n        eps *= 0.5\n        print('final eps (0.5 * estimate): {0}'.format(eps))\n        if eps == 0:\n            raise Exception('eps == 0')\n\n    # only consider nodes that lie in the eps environment\n    indices = np.where(dist < eps)[0]\n\n    # extract these nodes\n    nodes = grid.nodes[key][indices, 0]\n    nodes = indices\n\n    nodes_full = np.hstack((\n        grid.nodes[key][indices, :].squeeze(),\n        np.atleast_2d(dist[indices]).T,\n    ))\n    if fids is not None:\n        np.savetxt(\n            fids[0],\n            nodes_full.squeeze()\n        )\n        np.savetxt(\n            fids[1],\n            np.atleast_2d(dist).T,\n        )\n\n    elm_indices = []\n    elm_nodes = []\n    # find elements with two nodes in it\n    for elmnr, element in enumerate(grid.elements):\n        if len(np.intersect1d(element, nodes)) == 2:\n            elm_indices.append(elmnr)\n            elm_nodes.append(element)\n\n    elms = np.array(elm_nodes)\n\n    # find neighboring elements\n    neighbors = []\n    eta = settings['eta']\n    # for each element on the line\n    for index, elm in enumerate(elms):\n        found_it = False\n        for index1, elm1 in enumerate(elms):\n            ints = np.intersect1d(elm, elm1)\n            # only two nodes can be on a line\n            if len(ints) == 2:\n                # this check ensures that we do not identify the\n                # boundary between two adjacent cells on the line\n                # as a decoupling line.\n                if np.all(dist[ints] < eps):\n                    found_it = True\n                    break\n                else:\n                    pass\n                    # print(\n                    #     'distances of neighbor not correct:', dist[ints], eps\n                    # )\n            # probably the element itself\n            elif len(ints) > 2:\n                # print('found more than two common nodes!')\n                # print('element nodes:', elm)\n                # print('element1 nodes:', elm1)\n                pass\n        if found_it:\n            nb = (elm_indices[index] + 1, elm_indices[index1] + 1, eta)\n            # reversed neighbor\n            # nb_rev = (nb[1], nb[0], nb[2])\n            # if nb_rev not in neighbors:\n            if True:\n                neighbors.append(\n                    nb\n                )\n        else:\n            pass\n            print('No neighbors found. Strange...')\n\n    return np.array(neighbors)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the path of a file installed along the package", "response": "def pkg_data_filename(resource_name, filename=None):\n    \"\"\"Returns the path of a file installed along the package\n    \"\"\"\n    resource_filename = pkg_resources.resource_filename(\n        tripleohelper.__name__,\n        resource_name\n    )\n    if filename is not None:\n        resource_filename = os.path.join(resource_filename, filename)\n    return resource_filename"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef write_extra_data(self, stream: WriteStream) -> None:\n        if self.params:\n            stream.align(8)\n            if self._params_offset_writer:\n                self._params_offset_writer.write_current_offset(stream)\n            else:\n                self._params_offset = stream.tell()\n            self.params.write(stream)\n\n        if self.actions:\n            stream.align(8)\n            if self._actions_offset_writer:\n                self._actions_offset_writer.write_current_offset(stream)\n            else:\n                self._actions_offset = stream.tell()\n            for s in self.actions:\n                stream.write_string_ref(s.v)\n\n        if self.queries:\n            stream.align(8)\n            if self._queries_offset_writer:\n                self._queries_offset_writer.write_current_offset(stream)\n            else:\n                self._queries_offset = stream.tell()\n            for s in self.queries:\n                stream.write_string_ref(s.v)", "response": "Writes the param container and string pointer arrays."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmerge the current branch into master.", "response": "def merge(config):\n    \"\"\"Merge the current branch into master.\"\"\"\n    repo = config.repo\n\n    active_branch = repo.active_branch\n    if active_branch.name == \"master\":\n        error_out(\"You're already on the master branch.\")\n\n    if repo.is_dirty():\n        error_out(\n            'Repo is \"dirty\". ({})'.format(\n                \", \".join([repr(x.b_path) for x in repo.index.diff(None)])\n            )\n        )\n\n    branch_name = active_branch.name\n\n    state = read(config.configfile)\n    origin_name = state.get(\"ORIGIN_NAME\", \"origin\")\n    upstream_remote = None\n    for remote in repo.remotes:\n        if remote.name == origin_name:\n            upstream_remote = remote\n            break\n    if not upstream_remote:\n        error_out(\"No remote called {!r} found\".format(origin_name))\n\n    repo.heads.master.checkout()\n    upstream_remote.pull(repo.heads.master)\n\n    repo.git.merge(branch_name)\n    repo.git.branch(\"-d\", branch_name)\n    success_out(\"Branch {!r} deleted.\".format(branch_name))\n\n    info_out(\"NOW, you might want to run:\\n\")\n    info_out(\"git push origin master\\n\\n\")\n\n    push_for_you = input(\"Run that push? [Y/n] \").lower().strip() != \"n\"\n    if push_for_you:\n        upstream_remote.push(\"master\")\n        success_out(\"Current master pushed to {}\".format(upstream_remote.name))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef chord_task(*args, **kwargs):\n    given_backend = kwargs.get(u'backend', None)\n    if not isinstance(given_backend, ChordableDjangoBackend):\n        kwargs[u'backend'] = ChordableDjangoBackend(kwargs.get('app', current_app))\n    return task(*args, **kwargs)", "response": "u Override of the default task decorator to specify use of this backend."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef on_chord_part_return(self, task, state, result, propagate=False):  # pylint: disable=redefined-outer-name\n        with transaction.atomic():\n            chord_data = ChordData.objects.select_for_update().get(  # select_for_update will prevent race conditions\n                callback_result__task_id=task.request.chord[u'options'][u'task_id']\n            )\n            _ = TaskMeta.objects.update_or_create(\n                task_id=task.request.id,\n                defaults={\n                    u'status': state,\n                    u'result': result\n                }\n            )\n            if chord_data.is_ready():\n                # we don't use celery beat, so this is as good a place as any to fire off periodic cleanup tasks\n                self.get_suitable_app(current_app).tasks[u'celery.backend_cleanup'].apply_async()\n                chord_data.execute_callback()", "response": "Update the ChordData object and execute callback if needed."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_suitable_app(cls, given_app):\n        if not isinstance(getattr(given_app, 'backend', None), ChordableDjangoBackend):\n            return_app = deepcopy(given_app)\n            return_app.backend = ChordableDjangoBackend(return_app)\n            return return_app\n        else:\n            return given_app", "response": "u Return a clone of given_app with ChordableDjangoBackend if needed."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef invalidate(self, comparison: Comparison[Entity, Entity]) -> None:\n\n        @backoff.on_exception(backoff.expo,\n                              requests.exceptions.RequestException,\n                              max_tries=5,\n                              giveup=lambda e:\n                              400 <= e.response.status_code < 500)\n        def _request(chunk: List[str]) -> requests.Response:\n            \"\"\"\n            Send a purge cache request to Cloudflare. This method will\n            automatically retry with a back-off in case of server-side error.\n\n            :param chunk: The list of paths to purge. These should not have a\n                          leading slash, and will be combined with the prefix\n                          to form a URL.\n            :return: Cloudflare's response to our successful request.\n            :raises requests.exceptions.RequestException: If the request fails\n                                                          on the 5th attempt.\n            \"\"\"\n            response = self._session.delete(\n                f'{self._API_BASE}/client/v4/zones/{self._zone}/purge_cache',\n                headers={\n                    'X-Auth-Email': self._email,\n                    'X-Auth-Key': self._key\n                },\n                json={\n                    'files': [self._prefix + path for path in chunk]\n                })\n            response.raise_for_status()\n            return response\n\n        paths = itertools.chain(comparison.deleted(), comparison.modified())\n        for chunk_ in util.chunk(paths, self._MAX_INVALIDATIONS_PER_REQUEST):\n            chunk_ = list(chunk_)\n            if not chunk_:\n                # nothing to do\n                return\n            logger.info('Invalidating %d paths (%s)', len(chunk_),\n                        ', '.join(chunk_))\n            response_ = _request(chunk_)\n            logger.debug('Cloudflare invalidation response [%d]: %s',\n                         response_.status_code,\n                         response_.text)\n            json_ = response_.json()\n            if not json_['success']:\n                # this would be strange - the API returned a success response\n                # code, but success was not \"true\"\n                # TODO more appropriate exception, with handling upstream\n                raise RuntimeError('Cloudflare reported failure')\n            logger.info('Created invalidation %s', json_['result']['id'])", "response": "Invalidate the cache for the specified paths in a specific zone."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef linked_model_for_class(self, cls, make_constants_variable=False, **kwargs):\n        constructor_args = inspect.getfullargspec(cls).args\n        attribute_tuples = self.attribute_tuples\n        new_model = PriorModel(cls)\n        for attribute_tuple in attribute_tuples:\n            name = attribute_tuple.name\n            if name in constructor_args or (\n                    is_tuple_like_attribute_name(name) and tuple_name(name) in constructor_args):\n                attribute = kwargs[name] if name in kwargs else attribute_tuple.value\n                if make_constants_variable and isinstance(attribute, Constant):\n                    new_attribute = getattr(new_model, name)\n                    if isinstance(new_attribute, Prior):\n                        new_attribute.mean = attribute.value\n                        continue\n                setattr(new_model, name, attribute)\n        return new_model", "response": "Creates a new PriorModel wrapping the specified class with attributes from this instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of priors for all prior tuples in the current object.", "response": "def prior_tuples(self):\n        \"\"\"\n        Returns\n        -------\n        priors: [(String, Prior))]\n        \"\"\"\n        return [prior for tuple_prior in self.tuple_prior_tuples for prior in\n                tuple_prior[1].prior_tuples] + self.direct_prior_tuples + [prior for prior_model in\n                                                                           self.prior_model_tuples\n                                                                           for prior in\n                                                                           prior_model[1].prior_tuples]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef constant_tuples(self):\n        return [constant_tuple for tuple_prior in self.tuple_prior_tuples for constant_tuple in\n                tuple_prior[1].constant_tuples] + self.direct_constant_tuples", "response": "Returns a list of constant tuples for all of the tuples in the cluster."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate an instance of the associated class for a set of arguments.", "response": "def instance_for_arguments(self, arguments: {Prior: float}):\n        \"\"\"\n        Create an instance of the associated class for a set of arguments\n\n        Parameters\n        ----------\n        arguments: {Prior: float}\n            Dictionary mapping_matrix priors to attribute analysis_path and value pairs\n\n        Returns\n        -------\n            An instance of the class\n        \"\"\"\n        for prior, value in arguments.items():\n            prior.assert_within_limits(value)\n        model_arguments = {t.name: arguments[t.prior] for t in self.direct_prior_tuples}\n        constant_arguments = {t.name: t.constant.value for t in self.direct_constant_tuples}\n        for tuple_prior in self.tuple_prior_tuples:\n            model_arguments[tuple_prior.name] = tuple_prior.prior.value_for_arguments(arguments)\n        for prior_model_tuple in self.direct_prior_model_tuples:\n            model_arguments[prior_model_tuple.name] = prior_model_tuple.prior_model.instance_for_arguments(arguments)\n\n        return self.cls(**{**model_arguments, **constant_arguments})"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef gaussian_prior_model_for_arguments(self, arguments):\n        new_model = copy.deepcopy(self)\n\n        model_arguments = {t.name: arguments[t.prior] for t in self.direct_prior_tuples}\n\n        for tuple_prior_tuple in self.tuple_prior_tuples:\n            setattr(new_model, tuple_prior_tuple.name,\n                    tuple_prior_tuple.prior.gaussian_tuple_prior_for_arguments(arguments))\n        for prior_tuple in self.direct_prior_tuples:\n            setattr(new_model, prior_tuple.name, model_arguments[prior_tuple.name])\n        for constant_tuple in self.constant_tuples:\n            setattr(new_model, constant_tuple.name, constant_tuple.constant)\n\n        for name, prior_model in self.direct_prior_model_tuples:\n            setattr(new_model, name, prior_model.gaussian_prior_model_for_arguments(arguments))\n\n        return new_model", "response": "Create a new model mapper with a set of Gaussian priors based on tuples provided by a previous nonlinear search."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef instance_for_arguments(self, arguments):\n        result = ModelInstance()\n        for key, value in self.__dict__.items():\n            if isinstance(value, AbstractPriorModel):\n                value = value.instance_for_arguments(arguments)\n            setattr(result, key, value)\n        return result", "response": "Returns a ModelInstance object for the given dictionary of arguments."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef gaussian_prior_model_for_arguments(self, arguments):\n        return CollectionPriorModel(\n            {\n                key: value.gaussian_prior_model_for_arguments(arguments)\n                if isinstance(value, AbstractPriorModel)\n                else value\n                for key, value in self.__dict__.items() if key not in ('component_number', 'item_number', 'id')\n            }\n        )", "response": "Returns a new prior model for the given arguments."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a set of priors that are used to store the current set of priors.", "response": "def prior_tuples(self):\n        \"\"\"\n        Returns\n        -------\n        priors: [(String, Union(Prior, TuplePrior))]\n        \"\"\"\n        return set([prior for prior_model in self.prior_models for prior in prior_model.prior_tuples])"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsends a GET request to the Wordpress REST API v1. 1 and return the response", "response": "def get(self, path, params=None):\n        \"\"\"\n        Send a GET request to the Wordpress REST API v1.1 and return the response\n        :param path: aka resource\n        :param params: querystring args\n        :return: requests.reponse object\n        \"\"\"\n        api_url = self.api_base_url + path\n\n        headers = None\n        try:\n            headers = {\n                \"Authorization\": 'Bearer {}'.format(settings.WP_API_AUTH_TOKEN)\n            }\n        except AttributeError:\n            if self.first_get:\n                logger.warning(\"WP_API_AUTH_TOKEN not found in settings. Only public APIs are available.\")\n\n        self.first_get = False\n\n        return requests.get(api_url, headers=headers, params=params)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading a single post from the WordPress REST API.", "response": "def load_post(self, wp_post_id):\n        \"\"\"\n        Refresh local content for a single post from the the WordPress REST API.\n        This can be called from a webhook on the WordPress side when a post is updated.\n\n        :param wp_post_id: the wordpress post ID\n        :return: the fully loaded local post object\n        \"\"\"\n        path = \"sites/{}/posts/{}\".format(self.site_id, wp_post_id)\n        response = self.get(path)\n\n        if response.ok and response.text:\n\n            api_post = response.json()\n\n            self.get_ref_data_map(bulk_mode=False)\n            self.load_wp_post(api_post, bulk_mode=False)\n\n            # the post should exist in the db now, so return it so that callers can work with it\n            try:\n                post = Post.objects.get(site_id=self.site_id, wp_id=wp_post_id)\n            except Exception as ex:\n                logger.exception(\"Unable to load post with wp_post_id={}:\\n{}\".format(wp_post_id, ex.message))\n            else:\n                return post\n        else:\n            logger.warning(\"Unable to load post with wp_post_id={}:\\n{}\".format(wp_post_id, response.text))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload the content of a WordPress. com site.", "response": "def load_site(self, purge_first=False, full=False, modified_after=None, type=None, status=None, batch_size=None):\n        \"\"\"\n        Sync content from a WordPress.com site via the REST API.\n\n        :param purge_first: Should we remove all local content first? Careful, destructive!\n        :param full: If True, crawl backwards chronologically through all content, not just recently modified\n                     Default is False, only load recently modified content.\n        :param modified_after: If None, pick up where we left off last time; otherwise go back to this point in time\n                               Default is None, pick up where we left off last time.\n        :param type: the type(s) of processing:\n            - all: loads all content\n            - ref_data: just loads categories, tags, authors, and media\n            - post: just loads posts with post_type=post, and related ref data\n            - page: just loads posts with post_type=page, and related ref data\n            - attachment: just loads posts with post_type=attachment, and related ref data\n        :param status: the post statuses to load:\n            - publish: loads published posts (default)\n            - private: loads private posts\n            - draft: loads draft posts\n            - pending: loads pending posts\n            - future: loads future posts\n            - trash: loads posts in the trash\n            - any: loads posts with any status\n        :param batch_size: The number of posts to request from the WP API for each page\n                           Note this doesn't apply to smaller requests such as tags, categories, etc.\n        :return: None\n        \"\"\"\n        # capture loading vars\n        self.purge_first = purge_first\n        self.full = full\n        self.modified_after = modified_after\n        self.batch_size = batch_size or 100\n\n        if type is None:\n            type = \"all\"\n\n        if status is None:\n            status = \"publish\"\n\n        if type in [\"all\", \"ref_data\"]:\n            self.load_categories()\n            self.load_tags()\n            self.load_authors()\n            self.load_media()\n\n        # get ref data into memory for faster lookups\n        if type in [\"all\", \"attachment\", \"post\", \"page\"]:\n            self.get_ref_data_map()\n\n        # load posts of each type that we need\n        if type == \"all\":\n            for post_type in [\"attachment\", \"post\", \"page\"]:\n                self.load_posts(post_type=post_type, status=status)\n        elif type in [\"attachment\", \"post\", \"page\"]:\n            self.load_posts(post_type=type, status=status)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load_categories(self, max_pages=30):\n        logger.info(\"loading categories\")\n\n        # clear them all out so we don't get dupes if requested\n        if self.purge_first:\n            Category.objects.filter(site_id=self.site_id).delete()\n\n        path = \"sites/{}/categories\".format(self.site_id)\n        params = {\"number\": 100}\n        page = 1\n\n        response = self.get(path, params)\n\n        if not response.ok:\n            logger.warning(\"Response NOT OK! status_code=%s\\n%s\", response.status_code, response.text)\n\n        while response.ok and response.text and page < max_pages:\n            logger.info(\" - page: %d\", page)\n\n            api_categories = response.json().get(\"categories\")\n            if not api_categories:\n                # we're done here\n                break\n\n            categories = []\n            for api_category in api_categories:\n\n                # if it exists locally, update local version if anything has changed\n                existing_category = Category.objects.filter(site_id=self.site_id, wp_id=api_category[\"ID\"]).first()\n                if existing_category:\n                    self.update_existing_category(existing_category, api_category)\n                else:\n                    categories.append(self.get_new_category(api_category))\n\n            if categories:\n                Category.objects.bulk_create(categories)\n            elif not self.full:\n                # we're done here\n                break\n\n            # get next page\n            page += 1\n            params[\"page\"] = page\n            response = self.get(path, params)\n\n            if not response.ok:\n                logger.warning(\"Response NOT OK! status_code=%s\\n%s\", response.status_code, response.text)\n                return", "response": "Load all WordPress categories from the given site."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_new_category(self, api_category):\n        return Category(site_id=self.site_id,\n                        wp_id=api_category[\"ID\"],\n                        **self.api_object_data(\"category\", api_category))", "response": "Instantiate a new Category from api data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading all WordPress tags from the given site.", "response": "def load_tags(self, max_pages=30):\n        \"\"\"\n        Load all WordPress tags from the given site.\n\n        :param max_pages: kill counter to avoid infinite looping\n        :return: None\n        \"\"\"\n        logger.info(\"loading tags\")\n\n        # clear them all out so we don't get dupes if requested\n        if self.purge_first:\n            Tag.objects.filter(site_id=self.site_id).delete()\n\n        path = \"sites/{}/tags\".format(self.site_id)\n        params = {\"number\": 1000}\n        page = 1\n\n        response = self.get(path, params)\n\n        if not response.ok:\n            logger.warning(\"Response NOT OK! status_code=%s\\n%s\", response.status_code, response.text)\n\n        while response.ok and response.text and page < max_pages:\n            logger.info(\" - page: %d\", page)\n\n            api_tags = response.json().get(\"tags\")\n            if not api_tags:\n                # we're done here\n                break\n\n            tags = []\n            for api_tag in api_tags:\n\n                # if it exists locally, update local version if anything has changed\n                existing_tag = Tag.objects.filter(site_id=self.site_id, wp_id=api_tag[\"ID\"]).first()\n                if existing_tag:\n                    self.update_existing_tag(existing_tag, api_tag)\n                else:\n                    tags.append(self.get_new_tag(api_tag))\n\n            if tags:\n                Tag.objects.bulk_create(tags)\n            elif not self.full:\n                # we're done here\n                break\n\n            # get next page\n            page += 1\n            params[\"page\"] = page\n            response = self.get(path, params)\n\n            if not response.ok:\n                logger.warning(\"Response NOT OK! status_code=%s\\n%s\", response.status_code, response.text)\n                return"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_new_tag(self, api_tag):\n        return Tag(site_id=self.site_id,\n                   wp_id=api_tag[\"ID\"],\n                   **self.api_object_data(\"tag\", api_tag))", "response": "Instantiate a new Tag from api data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading all WordPress authors from the given site.", "response": "def load_authors(self, max_pages=10):\n        \"\"\"\n        Load all WordPress authors from the given site.\n\n        :param max_pages: kill counter to avoid infinite looping\n        :return: None\n        \"\"\"\n        logger.info(\"loading authors\")\n\n        # clear them all out so we don't get dupes if requested\n        if self.purge_first:\n            Author.objects.filter(site_id=self.site_id).delete()\n\n        path = \"sites/{}/users\".format(self.site_id)\n        params = {\"number\": 100}\n        page = 1\n\n        response = self.get(path, params)\n\n        if not response.ok:\n            logger.warning(\"Response NOT OK! status_code=%s\\n%s\", response.status_code, response.text)\n\n        while response.ok and response.text and page < max_pages:\n            logger.info(\" - page: %d\", page)\n\n            api_users = response.json().get(\"users\")\n            if not api_users:\n                # we're done here\n                break\n\n            authors = []\n            for api_author in api_users:\n\n                # if it exists locally, update local version if anything has changed\n                existing_author = Author.objects.filter(site_id=self.site_id, wp_id=api_author[\"ID\"]).first()\n                if existing_author:\n                    self.update_existing_author(existing_author, api_author)\n                else:\n                    authors.append(self.get_new_author(api_author))\n\n            if authors:\n                Author.objects.bulk_create(authors)\n            elif not self.full:\n                # we're done here\n                break\n\n            # get next page\n            # this endpoint doesn't have a page param, so use offset\n            params[\"offset\"] = page * 100\n            page += 1\n            response = self.get(path, params)\n\n            if not response.ok:\n                logger.warning(\"Response NOT OK! status_code=%s\\n%s\", response.status_code, response.text)\n                return"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_new_author(self, api_author):\n        return Author(site_id=self.site_id,\n                      wp_id=api_author[\"ID\"],\n                      **self.api_object_data(\"author\", api_author))", "response": "Instantiate a new Author from api data."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload all WordPress media from the given site.", "response": "def load_media(self, max_pages=150):\n        \"\"\"\n        Load all WordPress media from the given site.\n\n        :param max_pages: kill counter to avoid infinite looping\n        :return: None\n        \"\"\"\n        logger.info(\"loading media\")\n\n        # clear them all out so we don't get dupes\n        if self.purge_first:\n            logger.warning(\"purging ALL media from site %s\", self.site_id)\n            Media.objects.filter(site_id=self.site_id).delete()\n\n        path = \"sites/{}/media\".format(self.site_id)\n        params = {\"number\": 100}\n        self.set_media_params_after(params)\n        page = 1\n\n        response = self.get(path, params)\n\n        if not response.ok:\n            logger.warning(\"Response NOT OK! status_code=%s\\n%s\", response.status_code, response.text)\n\n        while response.ok and response.text and page < max_pages:\n            logger.info(\" - page: %d\", page)\n\n            api_medias = response.json().get(\"media\")\n            if not api_medias:\n                # we're done here\n                break\n\n            medias = []\n            for api_media in api_medias:\n\n                # exclude media items that are not attached to posts (for now)\n                if api_media[\"post_ID\"] != 0:\n\n                    # if it exists locally, update local version if anything has changed\n                    existing_media = Media.objects.filter(site_id=self.site_id, wp_id=api_media[\"ID\"]).first()\n                    if existing_media:\n                        self.update_existing_media(existing_media, api_media)\n                    else:\n                        medias.append(self.get_new_media(api_media))\n\n            if medias:\n                Media.objects.bulk_create(medias)\n\n            # get next page\n            page += 1\n            params[\"page\"] = page\n            response = self.get(path, params)\n\n            if not response.ok:\n                logger.warning(\"Response NOT OK! status_code=%s\\n%s\", response.status_code, response.text)\n                return"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_media_params_after(self, params):\n        if not self.full:\n            if self.modified_after:\n                ninety_days_ago = self.modified_after - timedelta(days=90)\n            else:\n                ninety_days_ago = datetime.utcnow() - timedelta(days=90)\n            params[\"after\"] = ninety_days_ago.isoformat()", "response": "Set the GET params dict to include the after key."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget referential data from the local db into the self. ref_data_map dictionary.", "response": "def get_ref_data_map(self, bulk_mode=True):\n        \"\"\"\n        Get referential data from the local db into the self.ref_data_map dictionary.\n        This allows for fast FK lookups when looping through posts.\n\n        :param bulk_mode: if True, actually get all of the existing ref data\n                          else this would be too much memory, so just build empty dicts\n        :return: None\n        \"\"\"\n        if bulk_mode:\n            self.ref_data_map = {\n                \"authors\": {a.wp_id: a for a in Author.objects.filter(site_id=self.site_id)},\n                \"categories\": {c.wp_id: c for c in Category.objects.filter(site_id=self.site_id)},\n                \"tags\": {t.wp_id: t for t in Tag.objects.filter(site_id=self.site_id)},\n                \"media\": {m.wp_id: m for m in Media.objects.filter(site_id=self.site_id)}\n            }\n        else:\n            # in single post mode, WP ref data is handled dynamically for the post\n            self.ref_data_map = {\n                \"authors\": {},\n                \"categories\": {},\n                \"tags\": {},\n                \"media\": {}\n            }"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_posts(self, post_type=None, max_pages=200, status=None):\n        logger.info(\"loading posts with post_type=%s\", post_type)\n\n        # clear them all out so we don't get dupes\n        if self.purge_first:\n            Post.objects.filter(site_id=self.site_id, post_type=post_type).delete()\n\n        path = \"sites/{}/posts\".format(self.site_id)\n\n        # type allows us to pull information about pages, attachments, guest-authors, etc.\n        # you know, posts that aren't posts... thank you WordPress!\n        if not post_type:\n            post_type = \"post\"\n        if not status:\n            status = \"publish\"\n        params = {\"number\": self.batch_size, \"type\": post_type, \"status\": status}\n        self.set_posts_param_modified_after(params, post_type, status)\n\n        # get first page\n        response = self.get(path, params)\n\n        if not response.ok:\n            logger.warning(\"Response NOT OK! status_code=%s\\n%s\", response.status_code, response.text)\n\n        # process all posts in the response\n        self.process_posts_response(response, path, params, max_pages)", "response": "Load all WordPress posts of a given post_type from a site."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_posts_param_modified_after(self, params, post_type, status):\n        if not self.purge_first and not self.full and not self.modified_after:\n            if status == \"any\":\n                latest = Post.objects.filter(post_type=post_type).order_by(\"-modified\").first()\n            else:\n                latest = Post.objects.filter(post_type=post_type, status=status).order_by(\"-modified\").first()\n            if latest:\n                self.modified_after = latest.modified\n\n        if self.modified_after:\n            params[\"modified_after\"] = self.modified_after.isoformat()\n            logger.info(\"getting posts after: %s\", params[\"modified_after\"])", "response": "Set modified_after date to continue where we left off if appropriate"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprocesses posts from a WP API.", "response": "def process_posts_response(self, response, path, params, max_pages):\n        \"\"\"\n        Insert / update all posts in a posts list response, in batches.\n\n        :param response: a response that contains a list of posts from the WP API\n        :param path: the path we're using to get the list of posts (for subsquent pages)\n        :param params: the path we're using to get the list of posts (for subsquent pages)\n        :param max_pages: kill counter to avoid infinite looping\n        :return: None\n        \"\"\"\n        page = 1\n        num_processed_posts = 0\n        api_posts_found = None\n        while response.ok and response.text and page < max_pages:\n\n            logger.info(\" - page: %d\", page)\n\n            posts = []\n            post_categories = {}\n            post_tags = {}\n            post_media_attachments = {}\n\n            api_json = response.json()\n            api_posts = api_json.get(\"posts\")\n            if not api_posts_found:\n                api_posts_found = api_json.get(\"found\", max_pages * self.batch_size)\n                logger.info(\"Found %s posts\", api_posts_found)\n\n            # we're done if no posts left to process\n            if not api_posts:\n                break\n\n            logger.info(\"Processing post modified date: %s\", api_posts[0][\"modified\"])\n\n            for api_post in api_posts:\n                self.load_wp_post(api_post,\n                                  bulk_mode=True,\n                                  post_categories=post_categories,\n                                  post_tags=post_tags,\n                                  post_media_attachments=post_media_attachments,\n                                  posts=posts)\n                num_processed_posts += 1\n                logger.debug(\"Processed %s of %s posts, modified date: %s\", num_processed_posts, api_posts_found, api_post[\"modified\"])\n\n            if posts:\n                self.bulk_create_posts(posts, post_categories, post_tags, post_media_attachments)\n\n            # we're done if we've processed all posts\n            if num_processed_posts >= api_posts_found:\n                break\n\n            # get next page\n            page += 1\n            next_page_handle = api_json.get(\"meta\", {}).get(\"next_page\")\n            if next_page_handle:\n                params[\"page_handle\"] = next_page_handle\n            else:\n                # no more pages left\n                break\n\n            response = self.get(path, params)\n\n            if not response.ok:\n                logger.warning(\"Response NOT OK! status_code=%s\\n%s\", response.status_code, response.text)\n                break"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_wp_post(self, api_post, bulk_mode=True, post_categories=None, post_tags=None, post_media_attachments=None, posts=None):\n        # initialize reference vars if none supplied\n        if post_categories is None:\n            post_categories = {}\n\n        if post_tags is None:\n            post_tags = {}\n\n        if post_media_attachments is None:\n            post_media_attachments = {}\n\n        if posts is None:\n            posts = []\n\n        # process objects related to this post\n        author = None\n        if api_post[\"author\"].get(\"ID\"):\n            author = self.process_post_author(bulk_mode, api_post[\"author\"])\n\n        # process many-to-many fields\n        self.process_post_categories(bulk_mode, api_post, post_categories)\n        self.process_post_tags(bulk_mode, api_post, post_tags)\n        self.process_post_media_attachments(bulk_mode, api_post, post_media_attachments)\n\n        # if this post exists, update it; else create it\n        existing_post = Post.objects.filter(site_id=self.site_id, wp_id=api_post[\"ID\"]).first()\n        if existing_post:\n            self.process_existing_post(existing_post, api_post, author, post_categories, post_tags, post_media_attachments)\n        else:\n            self.process_new_post(bulk_mode, api_post, posts, author, post_categories, post_tags, post_media_attachments)\n\n        # if this is a real post (not an attachment, page, etc.), sync child attachments that haven been deleted\n        # these are generally other posts with post_type=attachment representing media that has been \"uploaded to the post\"\n        # they can be deleted on the WP side, creating an orphan here without this step.\n        if api_post[\"type\"] == \"post\":\n            self.sync_deleted_attachments(api_post)", "response": "Load a single post from API data."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprocessing an author related to a post.", "response": "def process_post_author(self, bulk_mode, api_author):\n        \"\"\"\n        Create or update an Author related to a post.\n\n        :param bulk_mode: If True, minimize db operations by bulk creating post objects\n        :param api_author: the data in the api for the Author\n        :return: the up-to-date Author object\n        \"\"\"\n        # get from the ref data map if in bulk mode, else look it up from the db\n        if bulk_mode:\n            author = self.ref_data_map[\"authors\"].get(api_author[\"ID\"])\n            if author:\n                self.update_existing_author(author, api_author)\n            else:\n                # if the author wasn't found (likely because it's a Byline or guest author, not a user),\n                # go ahead and create the author now\n                author = Author.objects.create(site_id=self.site_id,\n                                               wp_id=api_author[\"ID\"],\n                                               **self.api_object_data(\"author\", api_author))\n        else:\n            # do a direct db lookup if we're not in bulk mode\n            author, created = self.get_or_create_author(api_author)\n            if author and not created:\n                self.update_existing_author(author, api_author)\n\n        # add to the ref data map so we don't try to create it again\n        if author:\n            self.ref_data_map[\"authors\"][api_author[\"ID\"]] = author\n\n        return author"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfinds or create an Author object given API data.", "response": "def get_or_create_author(self, api_author):\n        \"\"\"\n        Find or create an Author object given API data.\n\n        :param api_author: the API data for the Author\n        :return: a tuple of an Author instance and a boolean indicating whether the author was created or not\n        \"\"\"\n        return Author.objects.get_or_create(site_id=self.site_id,\n                                            wp_id=api_author[\"ID\"],\n                                            defaults=self.api_object_data(\"author\", api_author))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef process_post_categories(self, bulk_mode, api_post, post_categories):\n        post_categories[api_post[\"ID\"]] = []\n        for api_category in six.itervalues(api_post[\"categories\"]):\n            category = self.process_post_category(bulk_mode, api_category)\n            if category:\n                post_categories[api_post[\"ID\"]].append(category)", "response": "Process the API post data and add the corresponding Categories to the post_categories dict."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprocesses a post category and return the Category object.", "response": "def process_post_category(self, bulk_mode, api_category):\n        \"\"\"\n        Create or update a Category related to a post.\n\n        :param bulk_mode: If True, minimize db operations by bulk creating post objects\n        :param api_category: the API data for the Category\n        :return: the Category object\n        \"\"\"\n        category = None\n\n        # try to get from the ref data map if in bulk mode\n        if bulk_mode:\n            category = self.ref_data_map[\"categories\"].get(api_category[\"ID\"])\n\n        # double check the db before giving up, we may have sync'd it in a previous run\n        if not category:\n            category, created = Category.objects.get_or_create(site_id=self.site_id,\n                                                               wp_id=api_category[\"ID\"],\n                                                               defaults=self.api_object_data(\"category\", api_category))\n\n            if category and not created:\n                self.update_existing_category(category, api_category)\n\n            # add to ref data map so later lookups work\n            if category:\n                self.ref_data_map[\"categories\"][api_category[\"ID\"]] = category\n\n        return category"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprocessing the API data for a post.", "response": "def process_post_tags(self, bulk_mode, api_post, post_tags):\n        \"\"\"\n        Create or update Tags related to a post.\n\n        :param bulk_mode: If True, minimize db operations by bulk creating post objects\n        :param api_post: the API data for the post\n        :param post_tags: a mapping of Tags keyed by post ID\n        :return: None\n        \"\"\"\n        post_tags[api_post[\"ID\"]] = []\n        for api_tag in six.itervalues(api_post[\"tags\"]):\n            tag = self.process_post_tag(bulk_mode, api_tag)\n            if tag:\n                post_tags[api_post[\"ID\"]].append(tag)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nprocessing a post tag and return the Tag object", "response": "def process_post_tag(self, bulk_mode, api_tag):\n        \"\"\"\n        Create or update a Tag related to a post.\n\n        :param bulk_mode: If True, minimize db operations by bulk creating post objects\n        :param api_tag: the API data for the Tag\n        :return: the Tag object\n        \"\"\"\n        tag = None\n\n        # try to get from the ref data map if in bulk mode\n        if bulk_mode:\n            tag = self.ref_data_map[\"tags\"].get(api_tag[\"ID\"])\n\n        # double check the db before giving up, we may have sync'd it in a previous run\n        if not tag:\n            tag, created = Tag.objects.get_or_create(site_id=self.site_id,\n                                                     wp_id=api_tag[\"ID\"],\n                                                     defaults=self.api_object_data(\"tag\", api_tag))\n            if tag and not created:\n                self.update_existing_tag(tag, api_tag)\n\n            # add to ref data map so later lookups work\n            if tag:\n                self.ref_data_map[\"tags\"][api_tag[\"ID\"]] = tag\n\n        return tag"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef process_post_media_attachments(self, bulk_mode, api_post, post_media_attachments):\n        post_media_attachments[api_post[\"ID\"]] = []\n\n        for api_attachment in six.itervalues(api_post[\"attachments\"]):\n            attachment = self.process_post_media_attachment(bulk_mode, api_attachment)\n            if attachment:\n                post_media_attachments[api_post[\"ID\"]].append(attachment)", "response": "Processes the API data for a post and adds or updates the Media objects related to that post."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef process_post_media_attachment(self, bulk_mode, api_media_attachment):\n        attachment = None\n\n        # try to get from the ref data map if in bulk mode\n        if bulk_mode:\n            attachment = self.ref_data_map[\"media\"].get(api_media_attachment[\"ID\"])\n\n        # double check the db before giving up, we may have sync'd it in a previous run\n        if not attachment:\n            # do a direct db lookup if we're not in bulk mode\n            attachment, created = self.get_or_create_media(api_media_attachment)\n            if attachment and not created:\n                self.update_existing_media(attachment, api_media_attachment)\n\n            # add to ref data map so later lookups work\n            if attachment:\n                self.ref_data_map[\"media\"][api_media_attachment[\"ID\"]] = attachment\n\n        return attachment", "response": "Process a Media Attachment in bulk mode."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_or_create_media(self, api_media):\n        return Media.objects.get_or_create(site_id=self.site_id,\n                                           wp_id=api_media[\"ID\"],\n                                           defaults=self.api_object_data(\"media\", api_media))", "response": "Find or create a Media object given API data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprocess an existing post from WP API data.", "response": "def process_existing_post(existing_post, api_post, author, post_categories, post_tags, post_media_attachments):\n        \"\"\"\n        Sync attributes for a single post from WP API data.\n\n        :param existing_post: Post object that needs to be sync'd\n        :param api_post: the API data for the Post\n        :param author: the Author object of the post (should already exist in the db)\n        :param post_categories: the Categories to attach to the post (should already exist in the db)\n        :param post_tags: the Tags to attach to the post (should already exist in the db)\n        :param post_media_attachments: the Medias to attach to the post (should already exist in the db)\n        :return: None\n        \"\"\"\n        # don't bother checking what's different, just update all fields\n        existing_post.author = author\n        existing_post.post_date = api_post[\"date\"]\n        existing_post.modified = api_post[\"modified\"]\n        existing_post.title = api_post[\"title\"]\n        existing_post.url = api_post[\"URL\"]\n        existing_post.short_url = api_post[\"short_URL\"]\n        existing_post.content = api_post[\"content\"]\n        existing_post.excerpt = api_post[\"excerpt\"]\n        existing_post.slug = api_post[\"slug\"]\n        existing_post.guid = api_post[\"guid\"]\n        existing_post.status = api_post[\"status\"]\n        existing_post.sticky = api_post[\"sticky\"]\n        existing_post.password = api_post[\"password\"]\n        existing_post.parent = api_post[\"parent\"]\n        existing_post.post_type = api_post[\"type\"]\n        existing_post.likes_enabled = api_post[\"likes_enabled\"]\n        existing_post.sharing_enabled = api_post[\"sharing_enabled\"]\n        existing_post.like_count = api_post[\"like_count\"]\n        existing_post.global_ID = api_post[\"global_ID\"]\n        existing_post.featured_image = api_post[\"featured_image\"]\n        existing_post.format = api_post[\"format\"]\n        existing_post.menu_order = api_post[\"menu_order\"]\n        existing_post.metadata = api_post[\"metadata\"]\n        existing_post.post_thumbnail = api_post[\"post_thumbnail\"]\n\n        WPAPILoader.process_post_many_to_many_field(existing_post, \"categories\", post_categories)\n        WPAPILoader.process_post_many_to_many_field(existing_post, \"tags\", post_tags)\n        WPAPILoader.process_post_many_to_many_field(existing_post, \"attachments\", post_media_attachments)\n\n        existing_post.save()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef process_post_many_to_many_field(existing_post, field, related_objects):\n        to_add = set(related_objects.get(existing_post.wp_id, set())) - set(getattr(existing_post, field).all())\n        to_remove = set(getattr(existing_post, field).all()) - set(related_objects.get(existing_post.wp_id, set()))\n\n        if to_add:\n            getattr(existing_post, field).add(*to_add)\n        if to_remove:\n            getattr(existing_post, field).remove(*to_remove)", "response": "Sync data for a many - to - many field related to a post."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef process_new_post(self, bulk_mode, api_post, posts, author, post_categories, post_tags, post_media_attachments):\n        post = Post(site_id=self.site_id,\n                    wp_id=api_post[\"ID\"],\n                    author=author,\n                    post_date=api_post[\"date\"],\n                    modified=api_post[\"modified\"],\n                    title=api_post[\"title\"],\n                    url=api_post[\"URL\"],\n                    short_url=api_post[\"short_URL\"],\n                    content=api_post[\"content\"],\n                    excerpt=api_post[\"excerpt\"],\n                    slug=api_post[\"slug\"],\n                    guid=api_post[\"guid\"],\n                    status=api_post[\"status\"],\n                    sticky=api_post[\"sticky\"],\n                    password=api_post[\"password\"],\n                    parent=api_post[\"parent\"],\n                    post_type=api_post[\"type\"],\n                    likes_enabled=api_post[\"likes_enabled\"],\n                    sharing_enabled=api_post[\"sharing_enabled\"],\n                    like_count=api_post[\"like_count\"],\n                    global_ID=api_post[\"global_ID\"],\n                    featured_image=api_post[\"featured_image\"],\n                    format=api_post[\"format\"],\n                    menu_order=api_post[\"menu_order\"],\n                    metadata=api_post[\"metadata\"],\n                    post_thumbnail=api_post[\"post_thumbnail\"])\n        posts.append(post)\n\n        # if we're not in bulk mode, go ahead and create the post in the db now\n        # otherwise this happens after all API posts are processed\n        if not bulk_mode:\n            self.bulk_create_posts(posts, post_categories, post_tags, post_media_attachments)", "response": "Create a new post object from the API data."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sync_deleted_attachments(self, api_post):\n        existing_IDs = set(Post.objects.filter(site_id=self.site_id,\n                                               post_type=\"attachment\",\n                                               parent__icontains='\"ID\":{}'.format(api_post[\"ID\"]))\n                                       .values_list(\"wp_id\", flat=True))\n\n        # can't delete what we don't have\n        if existing_IDs:\n\n            api_IDs = set()\n\n            # call the API again to the get the full list of attachment posts whose parent is this post's wp_id\n            path = \"sites/{}/posts/\".format(self.site_id)\n            params = {\n                \"type\": \"attachment\",\n                \"parent_id\": api_post[\"ID\"],\n                \"fields\": \"ID\",\n                \"number\": 100\n            }\n            page = 1\n\n            response = self.get(path, params)\n\n            if not response.ok:\n                logger.warning(\"Response NOT OK! status_code=%s\\n%s\", response.status_code, response.text)\n\n            # loop around since there may be more than 100 attachments (example: really large slideshows)\n            while response.ok and response.text and page < 10:\n\n                api_json = response.json()\n                api_attachments = api_json.get(\"posts\", [])\n\n                # iteratively extend the set to include this page's IDs\n                api_IDs |= set(a[\"ID\"] for a in api_attachments)\n\n                # get next page\n                page += 1\n                next_page_handle = api_json.get(\"meta\", {}).get(\"next_page\")\n                if next_page_handle:\n                    params[\"page_handle\"] = next_page_handle\n                else:\n                    # no more pages left\n                    break\n\n                response = self.get(path, params)\n\n                if not response.ok:\n                    logger.warning(\"Response NOT OK! status_code=%s\\n%s\", response.status_code, response.text)\n                    return\n\n            # perform set difference\n            to_remove = existing_IDs - api_IDs\n\n            # purge the extras\n            if to_remove:\n                Post.objects.filter(site_id=self.site_id,\n                                    post_type=\"attachment\",\n                                    parent__icontains='\"ID\":{}'.format(api_post[\"ID\"]),\n                                    wp_id__in=list(to_remove)).delete()", "response": "This method is used to delete extra local attachments from a given post on the WordPress side."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef prevparent(self, parent, depth):\n        '''\n        Subtract lines from our curline if the name of a node is prefixed with\n        the parent directory when traversing the grandparent object.\n        '''\n        pdir = os.path.dirname(self.name)\n        if depth > 1:  # can't jump to parent of root node!\n            for c, d in parent.traverse():\n                if c.name == self.name:\n                    break\n                if c.name.startswith(pdir):\n                    parent.curline -= 1\n        else:  # otherwise jus skip to previous directory\n            pdir = self.name\n            # - 1 otherwise hidden parent node throws count off & our\n            # self.curline doesn't change!\n            line = -1\n            for c, d in parent.traverse():\n                if c.name == self.name:\n                    break\n                if os.path.isdir(c.name) and c.name in parent.children[0:]:\n                    parent.curline = line\n                line += 1\n        return pdir", "response": "Return the name of the previous parent directory."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef token(config, token):\n    if not token:\n        info_out(\n            \"To generate a personal API token, go to:\\n\\n\\t\"\n            \"https://github.com/settings/tokens\\n\\n\"\n            \"To read more about it, go to:\\n\\n\\t\"\n            \"https://help.github.com/articles/creating-an-access\"\n            \"-token-for-command-line-use/\\n\\n\"\n            'Remember to enable \"repo\" in the scopes.'\n        )\n        token = getpass.getpass(\"GitHub API Token: \").strip()\n    url = urllib.parse.urljoin(config.github_url, \"/user\")\n    assert url.startswith(\"https://\"), url\n    response = requests.get(url, headers={\"Authorization\": \"token {}\".format(token)})\n    if response.status_code == 200:\n        update(\n            config.configfile,\n            {\n                \"GITHUB\": {\n                    \"github_url\": config.github_url,\n                    \"token\": token,\n                    \"login\": response.json()[\"login\"],\n                }\n            },\n        )\n        name = response.json()[\"name\"] or response.json()[\"login\"]\n        success_out(\"Hi! {}\".format(name))\n    else:\n        error_out(\"Failed - {} ({})\".format(response.status_code, response.content))", "response": "Store and fetch a GitHub access token"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlog the response to the log file.", "response": "def log_response(handler):\n    \"\"\"\n    Acturally, logging response is not a server's responsibility,\n    you should use http tools like Chrome Developer Tools to analyse the response.\n\n    Although this function and its setting(LOG_RESPONSE) is not recommended to use,\n    if you are laze as I was and working in development, nothing could stop you.\n    \"\"\"\n    content_type = handler._headers.get('Content-Type', None)\n    headers_str = handler._generate_headers()\n    block = 'Response Infomations:\\n' + headers_str.strip()\n\n    if content_type and ('text' in content_type or 'json' in content_type):\n        limit = 0\n        if 'LOG_RESPONSE_LINE_LIMIT' in settings:\n            limit = settings['LOG_RESPONSE_LINE_LIMIT']\n\n        def cut(s):\n            if limit and len(s) > limit:\n                return [s[:limit]] + cut(s[limit:])\n            else:\n                return [s]\n\n        body = ''.join(handler._write_buffer)\n        lines = []\n        for i in body.split('\\n'):\n            lines += ['| ' + j for j in cut(i)]\n        block += '\\nBody:\\n' + '\\n'.join(lines)\n    app_log.info(block)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef log_request(handler):\n    block = 'Request Infomations:\\n' + _format_headers_log(handler.request.headers)\n\n    if handler.request.arguments:\n        block += '+----Arguments----+\\n'\n        for k, v in handler.request.arguments.items():\n            block += '| {0:<15} | {1:<15} \\n'.format(repr(k), repr(v))\n\n    app_log.info(block)", "response": "Log the request to the log."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef write_json(self, chunk, code=None, headers=None):\n        assert chunk is not None, 'None cound not be written in write_json'\n        self.set_header(\"Content-Type\", \"application/json; charset=UTF-8\")\n        if isinstance(chunk, dict) or isinstance(chunk, list):\n            chunk = self.json_encode(chunk)\n\n        # convert chunk to utf8 before `RequestHandler.write()`\n        # so that if any error occurs, we can catch and log it\n        try:\n            chunk = utf8(chunk)\n        except Exception:\n            app_log.error('chunk encoding error, repr: %s' % repr(chunk))\n            raise_exc_info(sys.exc_info())\n\n        self.write(chunk)\n\n        if code:\n            self.set_status(code)\n\n        if headers:\n            for k, v in headers.items():\n                self.set_header(k, v)", "response": "A convenient method that binds chunk code and headers together"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef write_file(self, file_path, mime_type=None):\n        if not os.path.exists(file_path):\n            raise HTTPError(404)\n        if not os.path.isfile(file_path):\n            raise HTTPError(403, \"%s is not a file\", file_path)\n\n        stat_result = os.stat(file_path)\n        modified = datetime.datetime.fromtimestamp(stat_result[stat.ST_MTIME])\n\n        self.set_header(\"Last-Modified\", modified)\n\n        if not mime_type:\n            mime_type, _encoding = mimetypes.guess_type(file_path)\n        if mime_type:\n            self.set_header(\"Content-Type\", mime_type)\n\n        # Check the If-Modified-Since, and don't send the result if the\n        # content has not been modified\n        ims_value = self.request.headers.get(\"If-Modified-Since\")\n        if ims_value is not None:\n            date_tuple = email.utils.parsedate(ims_value)\n            if_since = datetime.datetime.fromtimestamp(time.mktime(date_tuple))\n            if if_since >= modified:\n                self.set_status(304)\n                return\n\n        with open(file_path, \"rb\") as file:\n            data = file.read()\n            hasher = hashlib.sha1()\n            hasher.update(data)\n            self.set_header(\"Etag\", '\"%s\"' % hasher.hexdigest())\n            self.write(data)", "response": "Write the file to the response."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndecoding a signed value from a cookie.", "response": "def decode_signed_value(self, name, value, max_age_days=None):\n        \"\"\"Do what `RequestHandler.get_secure_cookie` does(when `value` is not None),\n        but with a more friendly name\n\n        What opposite to it is `RequestHandler.create_signed_value`\n        \"\"\"\n        kwgs = {}\n        if max_age_days is not None:\n            kwgs['max_age_days'] = max_age_days\n        return tornado.web.decode_signed_value(settings['COOKIE_SECRET'], name, value, **kwgs)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef prepare(self):\n        if settings['LOG_REQUEST']:\n            log_request(self)\n\n        for i in self.PREPARES:\n            getattr(self, 'prepare_' + i)()\n            if self._finished:\n                return", "response": "This method is used to prepare the raw request and handling process."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef render_string(self, template_name, **kwargs):\n        if 'tornado' == settings['TEMPLATE_ENGINE']:\n            return super(BaseHandler, self).render_string(template_name, **kwargs)\n        elif 'jinja2' == settings['TEMPLATE_ENGINE']:\n            return jinja2_render(template_name, **kwargs)\n        else:\n            raise errors.SettingsError(\n                '%s is not a supported TEMPLATE_ENGINE, should be `tornado` or `jinja2`'\n                % settings['TEMPLATE_ENGINE'])", "response": "This method is rewritten to support multiple template engine\n            and jinja2 templates."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfinishes this response ending the HTTP request.", "response": "def finish(self):\n        \"\"\"Finishes this response, ending the HTTP request.\"\"\"\n        if self._finished:\n            raise RuntimeError(\"finish() called twice.  May be caused \"\n                               \"by using async operations without the \"\n                               \"@asynchronous decorator.\")\n        if not hasattr(self, '_stream_queue') or not self._stream_queue:\n            raise RuntimeError(\"`_stream_queue` was not assigned, you should\"\n                               \"call `write_stream_queue` to set.\")\n\n        # === Replace `if not self._headers_written` === #\n        self.set_status(200)\n        self.set_header(\"Content-Type\", \"text/event-stream\")\n        self.set_header(\"Cache-Control\", \"no-cache\")\n        self.set_header(\"Access-Control-Allow-Origin\", \"*\")\n        # ============================================== #\n\n        self.request.connection.set_close_callback(None)\n\n        # === Add before self.flush === #\n        # Reset buffer\n        self._write_buffer = []\n        self._headers_written = False\n        # ============================= #\n\n        self.flush(include_footers=True)\n\n        # === Add after self.flush === #\n        self._write_buffer = self._stream_queue\n        self.request.connection._write_buffer = self._stream_queue\n        # ============================ #\n\n        self.request.finish()\n        self._log()\n        self._finished = True\n        self.on_finish()\n        # Break up a reference cycle between this handler and the\n        # _ui_module closures to allow for faster GC on CPython.\n        self.ui = None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nread a csv and returns a List of Dicts with keys given by header row.", "response": "def csv_to_dicts(file, header=None):\n    \"\"\"Reads a csv and returns a List of Dicts with keys given by header row.\"\"\"\n    with open(file) as csvfile:\n        return [row for row in csv.DictReader(csvfile, fieldnames=header)]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_uri(self, uri=None):\n\n\t\t'''\n\t\tparses and cleans up possible uri inputs, return instance of rdflib.term.URIRef\n\n\t\tArgs:\n\t\t\turi (rdflib.term.URIRef,str): input URI\n\n\t\tReturns:\n\t\t\trdflib.term.URIRef\n\t\t'''\n\n\t\t# no uri provided, assume root\n\t\tif not uri:\n\t\t\treturn rdflib.term.URIRef(self.root)\n\n\t\t# string uri provided\n\t\telif type(uri) == str:\n\n\t\t\t# assume \"short\" uri, expand with repo root\n\t\t\tif type(uri) == str and not uri.startswith('http'):\n\t\t\t\treturn rdflib.term.URIRef(\"%s%s\" % (self.root, uri))\n\n\t\t\t# else, assume full uri\n\t\t\telse:\n\t\t\t\treturn rdflib.term.URIRef(uri)\n\n\t\t# already rdflib.term.URIRef\n\t\telif type(uri) == rdflib.term.URIRef:\n\t\t\treturn uri\n\n\t\t# unknown input\n\t\telse:\n\t\t\traise TypeError('invalid URI input')", "response": "parse_uri parses and cleans up possible uri inputs"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_resource(self, resource_type=None, uri=None):\n\n\t\t'''\n\t\tConvenience method for creating a new resource\n\n\t\tNote: A Resource is instantiated, but is not yet created.  Still requires resource.create().\n\n\t\tArgs:\n\t\t\turi (rdflib.term.URIRef, str): uri of resource to create\n\t\t\tresource_type (NonRDFSource (Binary), BasicContainer, DirectContainer, IndirectContainer):  resource type to create\n\n\t\tReturns:\n\t\t\t(NonRDFSource (Binary), BasicContainer, DirectContainer, IndirectContainer): instance of appropriate type\n\t\t'''\n\n\t\tif resource_type in [NonRDFSource, Binary, BasicContainer, DirectContainer, IndirectContainer]:\n\t\t\treturn resource_type(self, uri)\n\t\telse:\n\t\t\traise TypeError(\"expecting Resource type, such as BasicContainer or NonRDFSource\")", "response": "Create a new resource in the RDF database."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_resource(self, uri, resource_type=None, response_format=None):\n\n\t\t'''\n\t\tRetrieve resource:\n\t\t\t- Issues an initial GET request\n\t\t\t- If 200, continues, 404, returns False, otherwise raises Exception\n\t\t\t- Parse resource type\n\t\t\t\t- If custom resource type parser provided, this fires\n\t\t\t\t- Else, or if custom parser misses, fire HEAD request and parse LDP resource type from Link header\n\t\t\t- Return instantiated pyfc4 resource\n\n\t\tArgs:\n\t\t\turi (rdflib.term.URIRef,str): input URI\n\t\t\tresource_type (): resource class e.g. BasicContainer, NonRDFSource, or extensions thereof\n\t\t\tresponse_format (str): expects mimetype / Content-Type header such as 'application/rdf+xml', 'text/turtle', etc.\n\n\t\tReturns:\n\t\t\tResource\n\t\t'''\n\n\t\t# handle uri\n\t\turi = self.parse_uri(uri)\n\n\t\t# remove fcr:metadata if included, as handled below\n\t\tif uri.toPython().endswith('/fcr:metadata'):\n\t\t\turi = rdflib.term.URIRef(uri.toPython().rstrip('/fcr:metadata'))\n\n\t\t# fire GET request\n\t\tget_response = self.api.http_request(\n\t\t\t'GET',\n\t\t\t\"%s/fcr:metadata\" % uri,\n\t\t\tresponse_format=response_format)\n\n\t\t# 404, item does not exist, return False\n\t\tif get_response.status_code == 404:\n\t\t\tlogger.debug('resource uri %s not found, returning False' % uri)\n\t\t\treturn False\n\n\t\t# assume exists, parse headers for resource type and return instance\n\t\telif get_response.status_code == 200:\n\n\t\t\t# if resource_type not provided\n\t\t\tif not resource_type:\n\n\t\t\t\t# if custom resource type parser affixed to repo instance, fire\n\t\t\t\tif self.custom_resource_type_parser:\n\t\t\t\t\tlogger.debug(\"custom resource type parser provided, attempting\")\n\t\t\t\t\tresource_type = self.custom_resource_type_parser(self, uri, get_response)\n\n\t\t\t\t# parse LDP resource type from headers if custom resource parser misses,\n\t\t\t\t# or not provided\n\t\t\t\tif not resource_type:\n\t\t\t\t\t# Issue HEAD request to get LDP resource type from URI proper, not /fcr:metadata\n\t\t\t\t\thead_response = self.api.http_request('HEAD', uri)\n\t\t\t\t\tresource_type = self.api.parse_resource_type(head_response)\n\n\t\t\tlogger.debug('using resource type: %s' % resource_type)\n\n\t\t\t# return resource\n\t\t\treturn resource_type(self,\n\t\t\t\turi,\n\t\t\t\tresponse=get_response)\n\n\t\telse:\n\t\t\traise Exception('HTTP %s, error retrieving resource uri %s' % (get_response.status_code, uri))", "response": "Get a resource from the repository"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstarting a new transaction from repository", "response": "def start_txn(self, txn_name=None):\n\n\t\t'''\n\t\tRequest new transaction from repository, init new Transaction,\n\t\tstore in self.txns\n\n\t\tArgs:\n\t\t\ttxn_name (str): human name for transaction\n\n\t\tReturn:\n\t\t\t(Transaction): returns intance of newly created transaction\n\t\t'''\n\n\t\t# if no name provided, create one\n\t\tif not txn_name:\n\t\t\ttxn_name = uuid.uuid4().hex\n\n\t\t# request new transaction\n\t\ttxn_response = self.api.http_request('POST','%s/fcr:tx' % self.root, data=None, headers=None)\n\n\t\t# if 201, transaction was created\n\t\tif txn_response.status_code == 201:\n\n\t\t\ttxn_uri = txn_response.headers['Location']\n\t\t\tlogger.debug(\"spawning transaction: %s\" % txn_uri)\n\n\t\t\t# init new Transaction, and pass Expires header\n\t\t\ttxn = Transaction(\n\t\t\t\tself, # pass the repository\n\t\t\t\ttxn_name,\n\t\t\t\ttxn_uri,\n\t\t\t\texpires = txn_response.headers['Expires'])\n\n\t\t\t# append to self\n\t\t\tself.txns[txn_name] = txn\n\n\t\t\t# return\n\t\t\treturn txn"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_txn(self, txn_name, txn_uri):\n\n\t\t'''\n\t\tRetrieves known transaction and adds to self.txns.\n\n\t\tTODO:\n\t\t\tPerhaps this should send a keep-alive request as well?  Obviously still needed, and would reset timer.\n\n\t\tArgs:\n\t\t\ttxn_prefix (str, rdflib.term.URIRef): uri of the transaction. e.g. http://localhost:8080/rest/txn:123456789\n\t\t\ttxn_name (str): local, human name for transaction\n\n\t\tReturn:\n\t\t\t(Transaction) local instance of transactions from self.txns[txn_uri]\n\t\t'''\n\n\t\t# parse uri\n\t\ttxn_uri = self.parse_uri(txn_uri)\n\n\t\t# request new transaction\n\t\ttxn_response = self.api.http_request('GET',txn_uri, data=None, headers=None)\n\n\t\t# if 200, transaction exists\n\t\tif txn_response.status_code == 200:\n\t\t\tlogger.debug(\"transactoin found: %s\" % txn_uri)\n\n\t\t\t# init new Transaction, and pass Expires header\n\t\t\ttxn = Transaction(\n\t\t\t\tself, # pass the repository\n\t\t\t\ttxn_name,\n\t\t\t\ttxn_uri,\n\t\t\t\texpires = None)\n\n\t\t\t# append to self\n\t\t\tself.txns[txn_name] = txn\n\n\t\t\t# return\n\t\t\treturn txn\n\n\t\t# if 404, transaction does not exist\n\t\telif txn_response.status_code in [404, 410]:\n\t\t\tlogger.debug(\"transaction does not exist: %s\" % txn_uri)\n\t\t\treturn False\n\n\t\telse:\n\t\t\traise Exception('HTTP %s, could not retrieve transaction' % txn_response.status_code)", "response": "Retrieves a known transaction and adds it to self. txns."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef keep_alive(self):\n\n\t\t'''\n\t\tKeep current transaction alive, updates self.expires\n\n\t\tArgs:\n\t\t\tNone\n\n\t\tReturn:\n\t\t\tNone: sets new self.expires\n\t\t'''\n\n\t\t# keep transaction alive\n\t\ttxn_response = self.api.http_request('POST','%sfcr:tx' % self.root, data=None, headers=None)\n\n\t\t# if 204, transaction kept alive\n\t\tif txn_response.status_code == 204:\n\t\t\tlogger.debug(\"continuing transaction: %s\" % self.root)\n\t\t\t# update status and timer\n\t\t\tself.active = True\n\t\t\tself.expires = txn_response.headers['Expires']\n\t\t\treturn  True\n\n\t\t# if 410, transaction does not exist\n\t\telif txn_response.status_code == 410:\n\t\t\tlogger.debug(\"transaction does not exist: %s\" % self.root)\n\t\t\tself.active = False\n\t\t\treturn False\n\n\t\telse:\n\t\t\traise Exception('HTTP %s, could not continue transaction' % txn_response.status_code)", "response": "Keep current transaction alive, updates self.expires\n\n\t\tArgs:\n\t\t\tNone\n\n\t\tReturn:\n\t\t\tNone: sets new self.expires"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _close(self, close_type):\n\n\t\t'''\n\t\tEnds transaction by committing, or rolling back, all changes during transaction.\n\n\t\tArgs:\n\t\t\tclose_type (str): expects \"commit\" or \"rollback\"\n\n\t\tReturn:\n\t\t\t(bool)\n\t\t'''\n\n\t\t# commit transaction\n\t\ttxn_response = self.api.http_request('POST','%sfcr:tx/fcr:%s' % (self.root, close_type), data=None, headers=None)\n\n\t\t# if 204, transaction was closed\n\t\tif txn_response.status_code == 204:\n\t\t\tlogger.debug(\"%s for transaction: %s, successful\" % (close_type, self.root))\n\t\t\t# update self.active\n\t\t\tself.active = False\n\t\t\t# return\n\t\t\treturn True\n\n\t\t# if 410 or 404, transaction does not exist\n\t\telif txn_response.status_code in [404, 410]:\n\t\t\tlogger.debug(\"transaction does not exist: %s\" % self.root)\n\t\t\t# update self.active\n\t\t\tself.active = False\n\t\t\treturn False\n\n\t\telse:\n\t\t\traise Exception('HTTP %s, could not commit transaction' % txn_response.status_code)", "response": "Ends transaction by committing, or rolling back, all changes during transaction.\n\n\t\tArgs:\n\t\t\tclose_type (str): expects \"commit\" or \"rollback\"\n\n\t\tReturn:\n\t\t\t(bool)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef http_request(self,\n\t\t\tverb,\n\t\t\turi,\n\t\t\tdata=None,\n\t\t\theaders=None,\n\t\t\tfiles=None,\n\t\t\tresponse_format=None,\n\t\t\tis_rdf = True,\n\t\t\tstream = False\n\t\t):\n\n\t\t'''\n\t\tPrimary route for all HTTP requests to repository.  Ability to set most parameters for requests library,\n\t\twith some additional convenience parameters as well.\n\n\t\tArgs:\n\t\t\tverb (str): HTTP verb to use for request, e.g. PUT, POST, GET, HEAD, PATCH, etc.\n\t\t\turi (rdflib.term.URIRef,str): input URI\n\t\t\tdata (str,file): payload of data to send for request, may be overridden in preperation of request\n\t\t\theaders (dict): optional dictionary of headers passed directly to requests.request\n\t\t\tfiles (dict): optional dictionary of files passed directly to requests.request\n\t\t\tresponse_format (str): desired response format for resource's payload, e.g. 'application/rdf+xml', 'text/turtle', etc.\n\t\t\tis_rdf (bool): if True, set Accept header based on combination of response_format and headers\n\t\t\tstream (bool): passed directly to requests.request for stream parameter\n\n\t\tReturns:\n\t\t\trequests.models.Response\n\t\t'''\n\n\t\t# set content negotiated response format for RDFSources\n\t\tif is_rdf:\n\t\t\t'''\n\t\t\tAcceptable content negotiated response formats include:\n\t\t\t\tapplication/ld+json (discouraged, if not prohibited, as it drops prefixes used in repository)\n\t\t\t\tapplication/n-triples\n\t\t\t\tapplication/rdf+xml\n\t\t\t\ttext/n3 (or text/rdf+n3)\n\t\t\t\ttext/plain\n\t\t\t\ttext/turtle (or application/x-turtle)\n\t\t\t'''\n\t\t\t# set for GET requests only\n\t\t\tif verb == 'GET':\n\t\t\t\t# if no response_format has been requested to this point, use repository instance default\n\t\t\t\tif not response_format:\n\t\t\t\t\tresponse_format = self.repo.default_serialization\n\t\t\t\t# if headers present, append\n\t\t\t\tif headers and 'Accept' not in headers.keys():\n\t\t\t\t\theaders['Accept'] = response_format\n\t\t\t\t# if headers are blank, init dictionary\n\t\t\t\telse:\n\t\t\t\t\theaders = {'Accept':response_format}\n\n\t\t# prepare uri for HTTP request\n\t\tif type(uri) == rdflib.term.URIRef:\n\t\t\turi = uri.toPython()\n\n\t\tlogger.debug(\"%s request for %s, format %s, headers %s\" %\n\t\t\t(verb, uri, response_format, headers))\n\n\t\t# manually prepare request\n\t\tsession = requests.Session()\n\t\trequest = requests.Request(verb, uri, auth=(self.repo.username, self.repo.password), data=data, headers=headers, files=files)\n\t\tprepped_request = session.prepare_request(request)\n\t\tresponse = session.send(prepped_request,\n\t\t\tstream=stream,\n\t\t)\n\t\treturn response", "response": "This function is used to make HTTP requests to the repository."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_resource_type(self, response):\n\n\t\t'''\n\t\tparse resource type from self.http_request()\n\n\t\tNote: uses isinstance() as plugins may extend these base LDP resource type.\n\n\t\tArgs:\n\t\t\tresponse (requests.models.Response): response object\n\n\t\tReturns:\n\t\t\t[NonRDFSource, BasicContainer, DirectContainer, IndirectContainer]\n\t\t'''\n\n\t\t# parse 'Link' header\n\t\tlinks = [\n\t\t\tlink.split(\";\")[0].lstrip('<').rstrip('>')\n\t\t\tfor link in response.headers['Link'].split(', ')\n\t\t\tif link.startswith('<http://www.w3.org/ns/ldp#')]\n\n\t\t# parse resource type string with self.repo.namespace_manager.compute_qname()\n\t\tldp_resource_types = [\n\t\t\tself.repo.namespace_manager.compute_qname(resource_type)[2]\n\t\t\tfor resource_type in links]\n\n\t\tlogger.debug('Parsed LDP resource types from LINK header: %s' % ldp_resource_types)\n\n\t\t# with LDP types in hand, select appropriate resource type\n\t\t# NonRDF Source\n\t\tif 'NonRDFSource' in ldp_resource_types:\n\t\t\treturn NonRDFSource\n\t\t# Basic Container\n\t\telif 'BasicContainer' in ldp_resource_types:\n\t\t\treturn BasicContainer\n\t\t# Direct Container\n\t\telif 'DirectContainer' in ldp_resource_types:\n\t\t\treturn DirectContainer\n\t\t# Indirect Container\n\t\telif 'IndirectContainer' in ldp_resource_types:\n\t\t\treturn IndirectContainer\n\t\telse:\n\t\t\tlogger.debug('could not determine resource type from Link header, returning False')\n\t\t\treturn False", "response": "parse resource type from response object"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_rdf_payload(self, data, headers):\n\n\t\t'''\n\t\tsmall function to parse RDF payloads from various repository endpoints\n\n\t\tArgs:\n\t\t\tdata (response.data): data from requests response\n\t\t\theaders (response.headers): headers from requests response\n\n\t\tReturns:\n\t\t\t(rdflib.Graph): parsed graph\n\t\t'''\n\n\t\t# handle edge case for content-types not recognized by rdflib parser\n\t\tif headers['Content-Type'].startswith('text/plain'):\n\t\t\tlogger.debug('text/plain Content-Type detected, using application/n-triples for parser')\n\t\t\tparse_format = 'application/n-triples'\n\t\telse:\n\t\t\tparse_format = headers['Content-Type']\n\n\t\t# clean parse format for rdf parser (see: https://www.w3.org/2008/01/rdf-media-types)\n\t\tif ';charset' in parse_format:\n\t\t\tparse_format = parse_format.split(';')[0]\n\n\t\t# parse graph\n\t\tgraph = rdflib.Graph().parse(\n\t\t\tdata=data.decode('utf-8'),\n\t\t\tformat=parse_format)\n\n\t\t# return graph\n\t\treturn graph", "response": "parse RDF payloads from various repository endpoints"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef build_query(self):\n\n\t\t'''\n\t\tUsing the three graphs derived from self._diff_graph(), build a sparql update query in the format:\n\n\t\tPREFIX foo: <http://foo.com>\n\t\tPREFIX bar: <http://bar.com>\n\n\t\tDELETE {...}\n\t\tINSERT {...}\n\t\tWHERE {...}\n\n\t\tArgs:\n\t\t\tNone: uses variables from self\n\n\t\tReturns:\n\t\t\t(str) sparql update query as string\n\n\t\t'''\n\n\t\t# derive namespaces to include prefixes in Sparql update query\n\t\tself._derive_namespaces()\n\n\t\tsparql_query = ''\n\n\t\t# add prefixes\n\t\tfor ns_prefix, ns_uri in self.update_prefixes.items():\n\t\t\tsparql_query += \"PREFIX %s: <%s>\\n\" % (ns_prefix, str(ns_uri))\n\n\t\t# deletes\n\t\tremoved_serialized = self.diffs.removed.serialize(format='nt').decode('utf-8')\n\t\tsparql_query += '\\nDELETE {\\n%s}\\n\\n' % removed_serialized\n\n\t\t# inserts\n\t\tadded_serialized = self.diffs.added.serialize(format='nt').decode('utf-8')\n\t\tsparql_query += '\\nINSERT {\\n%s}\\n\\n' % added_serialized\n\n\t\t# where (not yet implemented)\n\t\tsparql_query += 'WHERE {}'\n\n\t\t# debug\n\t\t# logger.debug(sparql_query)\n\n\t\t# return query\n\t\treturn sparql_query", "response": "Build a SPARQL query string from the diff graph"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if resource exists update self. exists", "response": "def check_exists(self):\n\n\t\t'''\n\t\tCheck if resource exists, update self.exists, returns\n\n\t\tReturns:\n\t\t\tNone: sets self.exists\n\t\t'''\n\n\t\tresponse = self.repo.api.http_request('HEAD', self.uri)\n\t\tself.status_code = response.status_code\n\t\t# resource exists\n\t\tif self.status_code == 200:\n\t\t\tself.exists = True\n\t\t# resource no longer here\n\t\telif self.status_code == 410:\n\t\t\tself.exists = False\n\t\t# resource not found\n\t\telif self.status_code == 404:\n\t\t\tself.exists = False\n\t\treturn self.exists"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create(self, specify_uri=False, ignore_tombstone=False, serialization_format=None, stream=False, auto_refresh=None):\n\n\t\t'''\n\t\tPrimary method to create resources.\n\n\t\tArgs:\n\t\t\tspecify_uri (bool): If True, uses PUT verb and sets the URI during creation.  If False, uses POST and gets repository minted URI\n\t\t\tignore_tombstone (bool): If True, will attempt creation, if tombstone exists (409), will delete tombstone and retry\n\t\t\tserialization_format(str): Content-Type header / mimetype that will be used to serialize self.rdf.graph, and set headers for PUT/POST requests\n\t\t\tauto_refresh (bool): If True, refreshes resource after update. If left None, defaults to repo.default_auto_refresh\n\t\t'''\n\n\t\t# if resource claims existence, raise exception\n\t\tif self.exists:\n\t\t\traise Exception('resource exists attribute True, aborting')\n\n\t\t# else, continue\n\t\telse:\n\n\t\t\t# determine verb based on specify_uri parameter\n\t\t\tif specify_uri:\n\t\t\t\tverb = 'PUT'\n\t\t\telse:\n\t\t\t\tverb = 'POST'\n\n\t\t\tlogger.debug('creating resource %s with verb %s' % (self.uri, verb))\n\n\t\t\t# check if NonRDFSource, or extension thereof\n\t\t\t#if so, run self.binary._prep_binary()\n\t\t\tif issubclass(type(self),NonRDFSource):\n\t\t\t\tself.binary._prep_binary()\n\t\t\t\tdata = self.binary.data\n\n\t\t\t# otherwise, prep for RDF\n\t\t\telse:\n\t\t\t\t# determine serialization\n\t\t\t\tif not serialization_format:\n\t\t\t\t\tserialization_format = self.repo.default_serialization\n\t\t\t\tdata = self.rdf.graph.serialize(format=serialization_format)\n\t\t\t\tlogger.debug('Serialized graph used for resource creation:')\n\t\t\t\tlogger.debug(data.decode('utf-8'))\n\t\t\t\tself.headers['Content-Type'] = serialization_format\n\n\t\t\t# fire creation request\n\t\t\tresponse = self.repo.api.http_request(verb, self.uri, data=data, headers=self.headers, stream=stream)\n\t\t\treturn self._handle_create(response, ignore_tombstone, auto_refresh)", "response": "This method creates a new resource in the repository."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _handle_create(self, response, ignore_tombstone, auto_refresh):\n\n\t\t'''\n\t\tHandles response from self.create()\n\n\t\tArgs:\n\t\t\tresponse (requests.models.Response): response object from self.create()\n\t\t\tignore_tombstone (bool): If True, will attempt creation, if tombstone exists (409), will delete tombstone and retry\n\t\t'''\n\n\t\t# 201, success, refresh\n\t\tif response.status_code == 201:\n\t\t\t# if not specifying uri, capture from response and append to object\n\t\t\tself.uri = self.repo.parse_uri(response.text)\n\t\t\t# creation successful\n\t\t\tif auto_refresh:\n\t\t\t\tself.refresh()\n\t\t\telif auto_refresh == None:\n\t\t\t\tif self.repo.default_auto_refresh:\n\t\t\t\t\tself.refresh()\n\t\t\t# fire resource._post_create hook if exists\n\t\t\tif hasattr(self,'_post_create'):\n\t\t\t\tself._post_create(auto_refresh=auto_refresh)\n\n\t\t# 404, assumed POST, target location does not exist\n\t\telif response.status_code == 404:\n\t\t\traise Exception('HTTP 404, for this POST request target location does not exist')\n\n\t\t# 409, conflict, resource likely exists\n\t\telif response.status_code == 409:\n\t\t\traise Exception('HTTP 409, resource already exists')\n\n\t\t# 410, tombstone present\n\t\telif response.status_code == 410:\n\t\t\tif ignore_tombstone:\n\t\t\t\tresponse = self.repo.api.http_request('DELETE', '%s/fcr:tombstone' % self.uri)\n\t\t\t\tif response.status_code == 204:\n\t\t\t\t\tlogger.debug('tombstone removed, retrying create')\n\t\t\t\t\tself.create()\n\t\t\t\telse:\n\t\t\t\t\traise Exception('HTTP %s, Could not remove tombstone for %s' % (response.status_code, self.uri))\n\t\t\telse:\n\t\t\t\traise Exception('tombstone for %s detected, aborting' % self.uri)\n\n\t\t# 415, unsupported media type\n\t\telif response.status_code == 415:\n\t\t\traise Exception('HTTP 415, unsupported media type')\n\n\t\t# unknown status code\n\t\telse:\n\t\t\traise Exception('HTTP %s, unknown error creating resource' % response.status_code)\n\n\t\t# if all goes well, return self\n\t\treturn self", "response": "Handles response from self.create()\n\n\t\tArgs:\n\t\t\tresponse (requests.models.Response): response object from self.create()\n\t\t\tignore_tombstone (bool): If True, will attempt creation, if tombstone exists (409), will delete tombstone and retry"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef options(self):\n\n\t\t'''\n\t\tSmall method to return headers of an OPTIONS request to self.uri\n\n\t\tArgs:\n\t\t\tNone\n\n\t\tReturn:\n\t\t\t(dict) response headers from OPTIONS request\n\t\t'''\n\n\t\t# http request\n\t\tresponse = self.repo.api.http_request('OPTIONS', self.uri)\n\t\treturn response.headers", "response": "get\n\tSmall method to return headers of an OPTIONS request to self. uri\n\tNone\n\tReturn"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncopying resource to another location", "response": "def copy(self, destination):\n\n\t\t'''\n\t\tMethod to copy resource to another location\n\n\t\tArgs:\n\t\t\tdestination (rdflib.term.URIRef, str): URI location to move resource\n\n\t\tReturns:\n\t\t\t(Resource) new, moved instance of resource\n\t\t'''\n\n\t\t# set move headers\n\t\tdestination_uri = self.repo.parse_uri(destination)\n\n\t\t# http request\n\t\tresponse = self.repo.api.http_request('COPY', self.uri, data=None, headers={'Destination':destination_uri.toPython()})\n\n\t\t# handle response\n\t\tif response.status_code == 201:\n\t\t\treturn destination_uri\n\t\telse:\n\t\t\traise Exception('HTTP %s, could not move resource %s to %s' % (response.status_code, self.uri, destination_uri))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef delete(self, remove_tombstone=True):\n\n\t\t'''\n\t\tMethod to delete resources.\n\n\t\tArgs:\n\t\t\tremove_tombstone (bool): If True, will remove tombstone at uri/fcr:tombstone when removing resource.\n\n\t\tReturns:\n\t\t\t(bool)\n\t\t'''\n\n\t\tresponse = self.repo.api.http_request('DELETE', self.uri)\n\n\t\t# update exists\n\t\tif response.status_code == 204:\n\t\t\t# removal successful, updating self\n\t\t\tself._empty_resource_attributes()\n\n\t\tif remove_tombstone:\n\t\t\tself.repo.api.http_request('DELETE', '%s/fcr:tombstone' % self.uri)\n\n\t\treturn True", "response": "Method to delete resources.\n\n\t\tArgs:\n\t\t\tremove_tombstone (bool): If True, will remove tombstone at uri/fcr:tombstone when removing resource.\n\n\t\tReturns:\n\t\t\t(bool)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nrefreshes the RDF information for this resource.", "response": "def refresh(self, refresh_binary=True):\n\n\t\t'''\n\t\tPerforms GET request and refreshes RDF information for resource.\n\n\t\tArgs:\n\t\t\tNone\n\n\t\tReturns:\n\t\t\tNone\n\t\t'''\n\n\t\tupdated_self = self.repo.get_resource(self.uri)\n\n\t\t# if resource type of updated_self != self, raise exception\n\t\tif not isinstance(self, type(updated_self)):\n\t\t\traise Exception('Instantiated %s, but repository reports this resource is %s' % (type(updated_self), type(self)) )\n\n\t\tif updated_self:\n\n\t\t\t# update attributes\n\t\t\tself.status_code = updated_self.status_code\n\t\t\tself.rdf.data = updated_self.rdf.data\n\t\t\tself.headers = updated_self.headers\n\t\t\tself.exists = updated_self.exists\n\n\t\t\t# update graph if RDFSource\n\t\t\tif type(self) != NonRDFSource:\n\t\t\t\tself._parse_graph()\n\n\t\t\t# empty versions\n\t\t\tself.versions = SimpleNamespace()\n\n\t\t\t# if NonRDF, set binary attributes\n\t\t\tif type(updated_self) == NonRDFSource and refresh_binary:\n\t\t\t\tself.binary.refresh(updated_self)\n\n\t\t\t# fire resource._post_create hook if exists\n\t\t\tif hasattr(self,'_post_refresh'):\n\t\t\t\tself._post_refresh()\n\n\t\t\t# cleanup\n\t\t\tdel(updated_self)\n\n\t\telse:\n\t\t\tlogger.debug('resource %s not found, dumping values')\n\t\t\tself._empty_resource_attributes()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbuilding RDF graph from incoming RDF content.", "response": "def _build_rdf(self, data=None):\n\n\t\t'''\n\t\tParse incoming rdf as self.rdf.orig_graph, create copy at self.rdf.graph\n\n\t\tArgs:\n\t\t\tdata (): payload from GET request, expected RDF content in various serialization formats\n\n\t\tReturns:\n\t\t\tNone\n\t\t'''\n\n\t\t# recreate rdf data\n\t\tself.rdf = SimpleNamespace()\n\t\tself.rdf.data = data\n\t\tself.rdf.prefixes = SimpleNamespace()\n\t\tself.rdf.uris = SimpleNamespace()\n\t\t# populate prefixes\n\t\tfor prefix,uri in self.repo.context.items():\n\t\t\tsetattr(self.rdf.prefixes, prefix, rdflib.Namespace(uri))\n\t\t# graph\n\t\tself._parse_graph()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse the RDF graph of the resource", "response": "def _parse_graph(self):\n\n\t\t'''\n\t\tuse Content-Type from headers to determine parsing method\n\n\t\tArgs:\n\t\t\tNone\n\n\t\tReturn:\n\t\t\tNone: sets self.rdf by parsing data from GET request, or setting blank graph of resource does not yet exist\n\t\t'''\n\n\t\t# if resource exists, parse self.rdf.data\n\t\tif self.exists:\n\t\t\tself.rdf.graph = self.repo.api.parse_rdf_payload(self.rdf.data, self.headers)\n\n\t\t# else, create empty graph\n\t\telse:\n\t\t\tself.rdf.graph = rdflib.Graph()\n\n\t\t# bind any additional namespaces from repo instance, but do not override\n\t\tself.rdf.namespace_manager = rdflib.namespace.NamespaceManager(self.rdf.graph)\n\t\tfor ns_prefix, ns_uri in self.rdf.prefixes.__dict__.items():\n\t\t\tself.rdf.namespace_manager.bind(ns_prefix, ns_uri, override=False)\n\n\t\t# conversely, add namespaces from parsed graph to self.rdf.prefixes\n\t\tfor ns_prefix, ns_uri in self.rdf.graph.namespaces():\n\t\t\tsetattr(self.rdf.prefixes, ns_prefix, rdflib.Namespace(ns_uri))\n\t\t\tsetattr(self.rdf.uris, rdflib.Namespace(ns_uri), ns_prefix)\n\n\t\t# pin old graph to resource, create copy graph for modifications\n\t\tself.rdf._orig_graph = copy.deepcopy(self.rdf.graph)\n\n\t\t# parse triples for object-like access\n\t\tself.parse_object_like_triples()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _diff_graph(self):\n\n\t\t'''\n\t\tUses rdflib.compare diff, https://github.com/RDFLib/rdflib/blob/master/rdflib/compare.py\n\t\tWhen a resource is retrieved, the graph retrieved and parsed at that time is saved to self.rdf._orig_graph,\n\t\tand all local modifications are made to self.rdf.graph.  This method compares the two graphs and returns the diff\n\t\tin the format of three graphs:\n\n\t\t\toverlap - triples SHARED by both\n\t\t\tremoved - triples that exist ONLY in the original graph, self.rdf._orig_graph\n\t\t\tadded - triples that exist ONLY in the modified graph, self.rdf.graph\n\n\t\tThese are used for building a sparql update query for self.update.\n\n\t\tArgs:\n\t\t\tNone\n\n\t\tReturns:\n\t\t\tNone: sets self.rdf.diffs and adds the three graphs mentioned, 'overlap', 'removed', and 'added'\n\t\t'''\n\n\t\toverlap, removed, added = graph_diff(\n\t\t\tto_isomorphic(self.rdf._orig_graph),\n\t\t\tto_isomorphic(self.rdf.graph))\n\t\tdiffs = SimpleNamespace()\n\t\tdiffs.overlap = overlap\n\t\tdiffs.removed = removed\n\t\tdiffs.added = added\n\t\tself.rdf.diffs = diffs", "response": "This method compares the graph and returns the diff in a simple format that can be used to build a sparql update query."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a new namespace to the current context", "response": "def add_namespace(self, ns_prefix, ns_uri):\n\n\t\t'''\n\t\tpreferred method is to instantiate with repository under 'context',\n\t\tbut prefixes / namespaces can be added for a Resource instance\n\n\t\tadds to self.rdf.prefixes which will endure through create/update/refresh,\n\t\tand get added back to parsed graph namespaces\n\n\t\tArgs:\n\t\t\tns_prefix (str): prefix for namespace, e.g. 'dc', 'foaf'\n\t\t\tns_uri (str): string of namespace / ontology. e.g. 'http://purl.org/dc/elements/1.1/', 'http://xmlns.com/foaf/0.1/'\n\n\t\tReturns:\n\t\t\tNone: binds this new prefix:namespace combination to self.rdf.prefixes for use, and self.rdf.graph for serialization\n\t\t'''\n\n\t\t# add to prefixes\n\t\tsetattr(self.rdf.prefixes, ns_prefix, rdflib.Namespace(ns_uri))\n\n\t\t# bind to graph\n\t\tself.rdf.namespace_manager.bind(ns_prefix, ns_uri, override=False)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_triple(self, p, o, auto_refresh=True):\n\n\t\t'''\n\t\tadd triple by providing p,o, assumes s = subject\n\n\t\tArgs:\n\t\t\tp (rdflib.term.URIRef): predicate\n\t\t\to (): object\n\t\t\tauto_refresh (bool): whether or not to update object-like self.rdf.triples\n\n\t\tReturns:\n\t\t\tNone: adds triple to self.rdf.graph\n\t\t'''\n\n\t\tself.rdf.graph.add((self.uri, p, self._handle_object(o)))\n\n\t\t# determine if triples refreshed\n\t\tself._handle_triple_refresh(auto_refresh)", "response": "Adds a triple to the graph"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_triple(self, p, o, auto_refresh=True):\n\n\t\t'''\n\t\tAssuming the predicate or object matches a single triple, sets the other for that triple.\n\n\t\tArgs:\n\t\t\tp (rdflib.term.URIRef): predicate\n\t\t\to (): object\n\t\t\tauto_refresh (bool): whether or not to update object-like self.rdf.triples\n\n\t\tReturns:\n\t\t\tNone: modifies pre-existing triple in self.rdf.graph\n\t\t'''\n\n\t\tself.rdf.graph.set((self.uri, p, self._handle_object(o)))\n\n\t\t# determine if triples refreshed\n\t\tself._handle_triple_refresh(auto_refresh)", "response": "Sets the triple p to o in the graph."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef remove_triple(self, p, o, auto_refresh=True):\n\n\t\t'''\n\t\tremove triple by supplying p,o\n\n\t\tArgs:\n\t\t\tp (rdflib.term.URIRef): predicate\n\t\t\to (): object\n\t\t\tauto_refresh (bool): whether or not to update object-like self.rdf.triples\n\n\t\tReturns:\n\t\t\tNone: removes triple from self.rdf.graph\n\t\t'''\n\n\t\tself.rdf.graph.remove((self.uri, p, self._handle_object(o)))\n\n\t\t# determine if triples refreshed\n\t\tself._handle_triple_refresh(auto_refresh)", "response": "Removes a triple from the graph at the given predicate and object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update(self, sparql_query_only=False, auto_refresh=None, update_binary=True):\n\n\t\t'''\n\t\tMethod to update resources in repository.  Firing this method computes the difference in the local modified graph and the original one,\n\t\tcreates an instance of SparqlUpdate and builds a sparql query that represents these differences, and sends this as a PATCH request.\n\n\t\tNote: send PATCH request, regardless of RDF or NonRDF, to [uri]/fcr:metadata\n\n\t\tIf the resource is NonRDF (Binary), this also method also updates the binary data.\n\n\t\tArgs:\n\t\t\tsparql_query_only (bool): If True, returns only the sparql query string and does not perform any actual updates\n\t\t\tauto_refresh (bool): If True, refreshes resource after update. If left None, defaults to repo.default_auto_refresh\n\t\t\tupdate_binary (bool): If True, and resource is NonRDF, updates binary data as well\n\n\t\tReturns:\n\t\t\t(bool)\n\t\t'''\n\n\t\t# run diff on graphs, send as PATCH request\n\t\tself._diff_graph()\n\t\tsq = SparqlUpdate(self.rdf.prefixes, self.rdf.diffs)\n\t\tif sparql_query_only:\n\t\t\treturn sq.build_query()\n\t\tresponse = self.repo.api.http_request(\n\t\t\t'PATCH',\n\t\t\t'%s/fcr:metadata' % self.uri, # send RDF updates to URI/fcr:metadata\n\t\t\tdata=sq.build_query(),\n\t\t\theaders={'Content-Type':'application/sparql-update'})\n\n\t\t# if RDF update not 204, raise Exception\n\t\tif response.status_code != 204:\n\t\t\tlogger.debug(response.content)\n\t\t\traise Exception('HTTP %s, expecting 204' % response.status_code)\n\n\t\t# if NonRDFSource, and self.binary.data is not a Response object, update binary as well\n\t\tif type(self) == NonRDFSource and update_binary and type(self.binary.data) != requests.models.Response:\n\t\t\tself.binary._prep_binary()\n\t\t\tbinary_data = self.binary.data\n\t\t\tbinary_response = self.repo.api.http_request(\n\t\t\t\t'PUT',\n\t\t\t\tself.uri,\n\t\t\t\tdata=binary_data,\n\t\t\t\theaders={'Content-Type':self.binary.mimetype})\n\n\t\t\t# if not refreshing RDF, still update binary here\n\t\t\tif not auto_refresh and not self.repo.default_auto_refresh:\n\t\t\t\tlogger.debug(\"not refreshing resource RDF, but updated binary, so must refresh binary data\")\n\t\t\t\tupdated_self = self.repo.get_resource(self.uri)\n\t\t\t\tself.binary.refresh(updated_self)\n\n\t\t# fire optional post-update hook\n\t\tif hasattr(self,'_post_update'):\n\t\t\tself._post_update()\n\n\t\t# determine refreshing\n\t\t'''\n\t\tIf not updating binary, pass that bool to refresh as refresh_binary flag to avoid touching binary data\n\t\t'''\n\t\tif auto_refresh:\n\t\t\tself.refresh(refresh_binary=update_binary)\n\t\telif auto_refresh == None:\n\t\t\tif self.repo.default_auto_refresh:\n\t\t\t\tself.refresh(refresh_binary=update_binary)\n\t\treturn True", "response": "This method updates the resource in repository."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parents(self, as_resources=False):\n\n\t\t'''\n\t\tmethod to return hierarchical parents of this resource\n\n\t\tArgs:\n\t\t\tas_resources (bool): if True, opens each as appropriate resource type instead of return URI only\n\n\t\tReturns:\n\t\t\t(list): list of resources\n\t\t'''\n\n\t\tparents = [o for s,p,o in self.rdf.graph.triples((None, self.rdf.prefixes.fedora.hasParent, None))]\n\n\t\t# if as_resources, issue GET requests for children and return\n\t\tif as_resources:\n\t\t\tlogger.debug('retrieving parent as resource')\n\t\t\tparents = [ self.repo.get_resource(parent) for parent in parents ]\n\n\t\treturn parents", "response": "method to return hierarchical parents of this resource"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef siblings(self, as_resources=False):\n\n\t\t'''\n\t\tmethod to return hierarchical siblings of this resource.\n\n\t\tArgs:\n\t\t\tas_resources (bool): if True, opens each as appropriate resource type instead of return URI only\n\n\t\tReturns:\n\t\t\t(list): list of resources\n\t\t'''\n\n\t\tsiblings = set()\n\n\t\t# loop through parents and get children\n\t\tfor parent in self.parents(as_resources=True):\n\t\t\tfor sibling in parent.children(as_resources=as_resources):\n\t\t\t\tsiblings.add(sibling)\n\n\t\t# remove self\n\t\tif as_resources:\n\t\t\tsiblings.remove(self)\n\t\tif not as_resources:\n\t\t\tsiblings.remove(self.uri)\n\n\t\treturn list(siblings)", "response": "get the siblings of this resource"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_versions(self):\n\n\t\t'''\n\t\tretrieves all versions of an object, and stores them at self.versions\n\n\t\tArgs:\n\t\t\tNone\n\n\t\tReturns:\n\t\t\tNone: appends instances\n\t\t'''\n\n\t\t# get all versions\n\t\tversions_response = self.repo.api.http_request('GET', '%s/fcr:versions' % self.uri)\n\n\t\t# parse response\n\t\tversions_graph = self.repo.api.parse_rdf_payload(versions_response.content, versions_response.headers)\n\n\t\t# loop through fedora.hasVersion\n\t\tfor version_uri in versions_graph.objects(self.uri, self.rdf.prefixes.fedora.hasVersion):\n\n\t\t\t# get label\n\t\t\tversion_label = versions_graph.value(version_uri, self.rdf.prefixes.fedora.hasVersionLabel, None).toPython()\n\n\t\t\t# affix version\n\t\t\tself._affix_version(version_uri, version_label)", "response": "get all versions of an object and store them at self. versions\n\t"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndumping the current resource to RDF data.", "response": "def dump(self,format='ttl'):\n\n\t\t'''\n\t\tConvenience method to return RDF data for resource,\n\t\toptionally selecting serialization format.\n\t\tInspired by .dump from Samvera.\n\n\t\tArgs:\n\t\t\tformat (str): expecting serialization formats accepted by rdflib.serialization(format=)\n\t\t'''\n\n\t\treturn self.rdf.graph.serialize(format=format).decode('utf-8')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete(self):\n\n\t\t'''\n\t\tmethod to remove version from resource's history\n\t\t'''\n\n\t\t# send patch\n\t\tresponse = self.resource.repo.api.http_request('DELETE', self.uri)\n\n\t\t# if response 204\n\t\tif response.status_code == 204:\n\t\t\tlogger.debug('deleting previous version of resource, %s' % self.uri)\n\n\t\t\t# remove from resource versions\n\t\t\tdelattr(self._current_resource.versions, self.label)\n\n\t\t# if 400, likely most recent version and cannot remove\n\t\telif response.status_code == 400:\n\t\t\traise Exception('HTTP 400, likely most recent resource version which cannot be removed')\n\n\t\telse:\n\t\t\traise Exception('HTTP %s, could not delete resource version: %s' % (response.status_code, self.uri))", "response": "method to delete resource version from history\n\t"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef empty(self):\n\n\t\t'''\n\t\tMethod to empty attributes, particularly for use when\n\t\tobject is deleted but remains as variable\n\t\t'''\n\n\t\tself.resource = None\n\t\tself.delivery = None\n\t\tself.data = None\n\t\tself.stream = False\n\t\tself.mimetype = None\n\t\tself.location = None", "response": "Empty the object attributes."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef refresh(self, updated_self):\n\n\t\t'''\n\t\tmethod to refresh binary attributes and data\n\n\t\tArgs:\n\t\t\tupdated_self (Resource): resource this binary data attaches to\n\n\t\tReturns:\n\t\t\tNone: updates attributes\n\t\t'''\n\n\t\tlogger.debug('refreshing binary attributes')\n\t\tself.mimetype = updated_self.binary.mimetype\n\t\tself.data = updated_self.binary.data", "response": "This method is used to refresh the binary attributes and data of the resource."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses binary data and make available via generators self", "response": "def parse_binary(self):\n\n\t\t'''\n\t\twhen retrieving a NonRDF resource, parse binary data and make available\n\t\tvia generators\n\t\t'''\n\n\t\t# derive mimetype\n\t\tself.mimetype = self.resource.rdf.graph.value(\n\t\t\tself.resource.uri,\n\t\t\tself.resource.rdf.prefixes.ebucore.hasMimeType).toPython()\n\n\t\t# get binary content as stremable response\n\t\tself.data = self.resource.repo.api.http_request(\n\t\t\t'GET',\n\t\t\tself.resource.uri,\n\t\t\tdata=None,\n\t\t\theaders={'Content-Type':self.resource.mimetype},\n\t\t\tis_rdf=False,\n\t\t\tstream=True)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _prep_binary_mimetype(self):\n\n\t\t'''\n\t\tSets Content-Type header based on headers and/or self.binary.mimetype values\n\t\tImplicitly favors Content-Type header if set\n\n\t\tArgs:\n\t\t\tNone\n\n\t\tReturns:\n\t\t\tNone: sets attributes in self.binary and headers\n\t\t'''\n\n\t\t# neither present\n\t\tif not self.mimetype and 'Content-Type' not in self.resource.headers.keys():\n\t\t\traise Exception('to create/update NonRDFSource, mimetype or Content-Type header is required')\n\n\t\t# mimetype, no Content-Type\n\t\telif self.mimetype and 'Content-Type' not in self.resource.headers.keys():\n\t\t\tlogger.debug('setting Content-Type header with provided mimetype: %s'\n\t\t\t\t% self.mimetype)\n\t\t\tself.resource.headers['Content-Type'] = self.mimetype", "response": "Sets the Content - Type header based on the mimetype of the binary resource."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _prep_binary_content(self):\n\n\t\t'''\n\t\tSets delivery method of either payload or header\n\t\tFavors Content-Location header if set\n\n\t\tArgs:\n\t\t\tNone\n\n\t\tReturns:\n\t\t\tNone: sets attributes in self.binary and headers\n\t\t'''\n\n\t\t# nothing present\n\t\tif not self.data and not self.location and 'Content-Location' not in self.resource.headers.keys():\n\t\t\traise Exception('creating/updating NonRDFSource requires content from self.binary.data, self.binary.location, or the Content-Location header')\n\n\t\telif 'Content-Location' in self.resource.headers.keys():\n\t\t\tlogger.debug('Content-Location header found, using')\n\t\t\tself.delivery = 'header'\n\n\t\t# if Content-Location is not set, look for self.data_location then self.data\n\t\telif 'Content-Location' not in self.resource.headers.keys():\n\n\t\t\t# data_location set, trumps Content self.data\n\t\t\tif self.location:\n\t\t\t\t# set appropriate header\n\t\t\t\tself.resource.headers['Content-Location'] = self.location\n\t\t\t\tself.delivery = 'header'\n\n\t\t\t# data attribute is plain text, binary, or file-like object\n\t\t\telif self.data:\n\n\t\t\t\t# if file-like object, set flag for api.http_request\n\t\t\t\tif isinstance(self.data, io.BufferedIOBase):\n\t\t\t\t\tlogger.debug('detected file-like object')\n\t\t\t\t\tself.delivery = 'payload'\n\n\t\t\t\t# else, just bytes\n\t\t\t\telse:\n\t\t\t\t\tlogger.debug('detected bytes')\n\t\t\t\t\tself.delivery = 'payload'", "response": "Sets delivery method of either payload or header depending on the type of data and location."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef range(self, byte_start, byte_end, stream=True):\n\n\t\t'''\n\t\tmethod to return a particular byte range from NonRDF resource's binary data\n\t\thttps://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html\n\n\t\tArgs:\n\t\t\tbyte_start(int): position of range start\n\t\t\tbyte_end(int): position of range end\n\n\t\tReturns:\n\t\t\t(requests.Response): streamable response\n\t\t'''\n\n\t\tresponse = self.resource.repo.api.http_request(\n\t\t\t'GET',\n\t\t\tself.resource.uri,\n\t\t\tdata=None,\n\t\t\theaders={\n\t\t\t\t'Content-Type':self.mimetype,\n\t\t\t\t'Range':'bytes=%s-%s' % (byte_start, byte_end)\n\t\t\t},\n\t\t\tis_rdf=False,\n\t\t\tstream=stream)\n\n\t\t# expects 206\n\t\tif response.status_code == 206:\n\t\t\treturn response\n\n\t\telse:\n\t\t\traise Exception('HTTP %s, but was expecting 206' % response.status_code)", "response": "This method returns a particular byte range from the NonRDF resource s binary data."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fixity(self, response_format=None):\n\n\t\t'''\n\t\tIssues fixity check, return parsed graph\n\n\t\tArgs:\n\t\t\tNone\n\n\t\tReturns:\n\t\t\t(dict): ('verdict':(bool): verdict of fixity check, 'premis_graph':(rdflib.Graph): parsed PREMIS graph from check)\n\t\t'''\n\n\t\t# if no response_format, use default\n\t\tif not response_format:\n\t\t\tresponse_format = self.repo.default_serialization\n\n\t\t# issue GET request for fixity check\n\t\tresponse = self.repo.api.http_request('GET', '%s/fcr:fixity' % self.uri)\n\n\t\t# parse\n\t\tfixity_graph = self.repo.api.parse_rdf_payload(response.content, response.headers)\n\n\t\t# determine verdict\n\t\tfor outcome in fixity_graph.objects(None, self.rdf.prefixes.premis.hasEventOutcome):\n\t\t\tif outcome.toPython() == 'SUCCESS':\n\t\t\t\tverdict = True\n\t\t\telse:\n\t\t\t\tverdict = False\n\n\t\treturn {\n\t\t\t'verdict':verdict,\n\t\t\t'premis_graph':fixity_graph\n\t\t}", "response": "This method returns parsed graph from a fixity check"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngives an execution trace returns a python set containing the names of each block for which the user code was executed.", "response": "def executed_block_set(trace):\n    \"\"\"\n    Given an execution trace, returns a python set object containing the names of each block for which the user code\n    was executed. Block names can be set via set_debug_name().\n    \"\"\"\n    executed_set = set()\n    for entry in trace:\n        if entry[0] == 'execute':\n            executed_set.add(entry[get_trace_index('execute', 'BLOCK_NAME')])\n    return executed_set"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_value(self, consumer=None):\n        if consumer:\n            self.consumers[consumer] = True\n        return self.value", "response": "Returns the value of the attribute."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns True if we are in a valid time range False otherwise.", "response": "def _before_valid_time_range(self):\n        \"\"\"\n        In case of uncertainty (times not specified), we assume that we are in a valid range.\n        \"\"\"\n        if self.start_time is not None:\n            try:\n                if self.time < self.start_time:\n                    return True\n            except TypeError:\n                return False\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns True if the time is after the end time of the uncertainty.", "response": "def _after_valid_time_range(self):\n        \"\"\"\n        In case of uncertainty (times not specified), we assume that we are in a valid range.\n        \"\"\"\n        if self.end_time is not None:\n            try:\n                if self.time > self.end_time:\n                    return True\n            except TypeError:\n                return False\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the input data for the given key.", "response": "def set_input_data(self, key, value):\n        \"\"\"\n        set_input_data will automatically create an input channel if necessary.\n        Automatic channel creation is intended for the case where users are trying to set initial values on a block\n        whose input channels aren't subscribed to anything in the graph.\n        \"\"\"\n        if not key in self.input_channels.keys():\n            self.set_input_channel(key, Channel())\n        self.input_channels[key].set_value(Data(self.time, value))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the output channel object for the given output channel name.", "response": "def get_output_channel(self, output_channel_name):\n        \"\"\"\n        get_output_channel will create a new channel object if necessary.\n        \"\"\"\n        if not output_channel_name in self.output_channels.keys():\n            self.output_channels[output_channel_name] = Channel()\n        self.output_channels[output_channel_name].add_producer(self)\n        return self.output_channels[output_channel_name]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a set of DataBlocks whose inputs were updated. This will be used by the Graph run() method to invoke the step() method of the next blocks in the chain (we don't invoke those call the step() method of those blocks directly from here, because then the stack could get quite large).", "response": "def step(self, trace):\n        \"\"\"\n        Returns a set of DataBlocks whose inputs were updated. This will be used by the Graph run() method to invoke\n        the step() method of the next blocks in the chain (we don't invoke those call the step() method of those\n        blocks directly from here, because then the stack could get quite large).\n        \"\"\"\n        downstream_blocks = []\n\n        # Restrict the set of input channels we consider to those that are active (a channel is typically deactivated\n        # before it starts producing useful data, and after it has reached the end of useful data)\n        active_input_channels_names = [channel_name for channel_name in self.input_channels.keys()\n                                       if self.input_channels[channel_name].active]\n        active_input_channels = {name: self.input_channels[name] for name in active_input_channels_names}\n\n        # If this is a block that has one or more input channels but none of them are active, bail out:\n        if self.input_channels and not active_input_channels:\n            return downstream_blocks\n\n        # 2. Pull data for earliest time. If there are no input channels, we just proceed:\n        unprocessed_input_channels = {}\n        if active_input_channels:\n            self.update_output_channel_timestamps()\n            # Get the collection of channels from which I have not already consumed data:\n            unprocessed_input_channel_names = [channel_name for channel_name in active_input_channels.keys()\n                                          if not active_input_channels[channel_name].consumers[self]]\n            unprocessed_input_channels = {name:active_input_channels[name] for name in unprocessed_input_channel_names}\n            channel_with_earliest_data = min(active_input_channels.values())\n\n            if not unprocessed_input_channels:\n                # If I have some input channels but none of them are unprocessed, then there is no data to be pulled.\n                # In this case, we need to pass along the current time, and be done.\n                self.advance_self_to_latest_time_of_data_in_channels()\n                self.update_output_channel_timestamps()\n                return downstream_blocks\n\n        if self.terminated():\n            return downstream_blocks\n\n        if unprocessed_input_channels:\n            state_change = False\n            for input_channel_name in unprocessed_input_channels.keys():\n                # We compare against the timestamps for all channels because even if a given channel has provided us\n                # valid data, if its timestamp is still earlier than what we believe to be the current timestamp, then\n                # we need to provide it the opportunity to potentially give even more recent data.\n                if unprocessed_input_channels[input_channel_name] <= channel_with_earliest_data:\n                    new_data = unprocessed_input_channels[input_channel_name].get_value(self)  # gets value AND marks as consumed.\n                    logging.debug(\"==> Pulling data (\" + str(new_data.data) + \") from channel '\" +\n                                  input_channel_name + \"' -- \" + str(self))\n                    if (not self.input_data) or \\\n                            (not input_channel_name in self.input_data) or \\\n                                    self.input_data[input_channel_name] != new_data:\n                        state_change = True\n                        self.input_data[input_channel_name] = new_data\n            if not state_change:\n                return downstream_blocks\n            self.advance_self_to_latest_time_of_pulled_data()\n\n        for input_name in self.input_data.keys():\n            logging.debug(\"# BLOCK \" + str(self) + \": time=\" + str(self.time) + \", \" + str(input_name) + \" = \" +\n                          str(self.input_data[input_name]))\n\n        # 3. Ensure inputs satisfied (note that we want input data for all channels, not just those currently active):\n        if self.input_channels:\n            for input_channel_name in self.input_channels.keys():\n                if input_channel_name not in self.input_data.keys():\n                    logging.debug(\"     Channel \" + input_channel_name + \" not satisfied. Bailing out.\")\n                    return downstream_blocks\n\n        # Ensure that -- if there are any downstream channels -- they are all open.\n        # Note that this has to happen after pulling data from the input channels in order to properly accommodate the\n        # case in which a block consumes its own outputs.\n        if self.output_channels:\n            for output_channel in self.output_channels.values():\n                if not output_channel.is_open():\n                    return downstream_blocks\n\n        # 4. Execute user code:\n        logging.debug(\"Executing block code for: \" + str(self))\n        trace.append(['execute', self.time, str(self)])\n        self.block_code()  # the block_code() method is responsible for setting new values in the output channels\n        # logging.debug(\"After executing user code, block time is: \" + str(self.time))\n\n        self.update_output_channel_timestamps()\n        if self._after_valid_time_range():\n            self.terminate()\n\n        for output_channel in self.output_channels.values():\n            if self._in_valid_time_range():\n                for consumer in output_channel.get_consumers():\n                    # logging.debug(str(self) + \" is nominating block to append to run list: \" + str(consumer))\n                    downstream_blocks.append(consumer)\n            else:\n                output_channel.mark_consumers_hungry_for_more()\n                #if self._after_valid_time_range():\n                #    self.terminate()\n\n        # Return collection of downstream neighbors:\n        return downstream_blocks"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef block_code(self):\n        inputs = self._get_all_input_values()\n        outputs = {}\n        \"\"\"\n        self.f = self.user_function(**inputs)\n        try:\n            outputs = self.f.send(inputs)\n        except StopIteration:\n            self.terminate()\n        \"\"\"\n        if self.first_time:\n            self.f = self.user_function(**inputs)\n            outputs = self.f.next()\n            self.first_time = False\n        else:\n            try:\n                outputs = self.f.send(inputs)\n            except StopIteration:\n                self.terminate()\n\n        if outputs:\n            for key in outputs.keys():\n                self.set_output_data(key, outputs[key])\n        if 'previous_outputs' in self.output_channels.keys():\n            self.output_channels['previous_outputs'].set_value(Data(self.time, copy.deepcopy(outputs)))", "response": "Block code for the user."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nperforming an HTTP request using base_url and parameters", "response": "def _http_request(self, base_url, **kwargs):\n        \"\"\"\n        Perform an HTTP Request using base_url and parameters\n        given by kwargs. \n        Results are expected to be given in JSON format\n        and are parsed to python data structures.\n        \"\"\"\n\n        # Build our URI\n        request_params = urlencode(kwargs)\n        uri = u'%s?%s&ywsid=%s&output=%s' % \\\n            (base_url, request_params, self._client_key, self._output)\n\n        self.LOG.debug(\"_http_request() - URI: %s\", uri)\n\n        header, response = self._conn.request(uri, method='GET')\n\n        return header, response"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nperforms a Review Search based on a bounding box.", "response": "def by_bounding_box(self, tl_lat, tl_long, br_lat, br_long, term=None, num_biz_requested=None, category=None):\n        \"\"\"\n        Perform a Yelp Review Search based on a map bounding box.\n\n        Args:\n          tl_lat   - bounding box top left latitude \n          tl_long  - bounding box top left longitude  \n          br_lat   - bounding box bottom right latitude\n          br_long  - bounding box bottom right longitude\n          term     - Search term to filter by (Optional)\n          num_biz_requested - Maximum number of matching results to return (Optional)\n          category - '+'-seperated list of categories to filter by. See\n        http://www.yelp.com/developers/documentation/category_list\n        \t\t\t  for list of valid categories. (Optional)\n\n        \"\"\"\n\n        header, content = self._http_request(\n            self.BASE_URL, \n            tl_lat  = tl_lat, \n            tl_long = tl_long,\n            br_lat  = br_lat, \n            br_long = br_long,\n            term    = term,\n            category = category,\n            num_biz_requested = num_biz_requested\n        )\t\t\n        return json.loads(content)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef by_geopoint(self, lat, long, radius, term=None, num_biz_requested=None, category=None):\n        \n        header, content = self._http_request(\n            self.BASE_URL,\n            lat    = lat, \n            long   = long, \n            radius = radius, \n            term   = None, \n            num_biz_requested = None\n        )\t\t\n        return json.loads(content)", "response": "Perform a Review Search based on a geopoint and radius tuple."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef by_location(self, location, cc=None, radius=None, term=None, num_biz_requested=None, category=None):\n\n        header, content = self._http_request(\n            self.BASE_URL, \n            location = location, \n            cc = cc,\n            radius = radius,\n            term = term,\n            num_biz_requested = num_biz_requested\n        )\t\t\n        return json.loads(content)", "response": "Perform a Yelp Review Search based on a location specifier."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef by_phone(self, phone, cc=None):\n\n        header, content = self._http_request(self.BASE_URL, phone=phone, cc=cc)\n        return json.loads(content)", "response": "Perform a Yelp Phone API Search based on phone number given."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nperforming a Yelp Neighborhood API Search based on a geopoint.", "response": "def by_geopoint(self, lat, long):\n        \"\"\"\n        Perform a Yelp Neighborhood API Search based on a geopoint.\n\n        Args:\n          lat      - geopoint latitude \n          long     - geopoint longitude  \n        \"\"\"\n\n        header, content = self._http_request(self.BASE_URL, lat=lat, long=long)\t\t\n        return json.loads(content)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef by_location(self, location, cc=None):\n\n        header, content = self._http_request(self.BASE_URL, location=location, cc=cc)\t\t\n        return json.loads(content)", "response": "Perform a Yelp Neighborhood API Search based on a location specifier."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\npublishes an event to the broker.", "response": "async def emit_event(self, event):\n        \"\"\"\n        Publish an event\n        :param event: Event object\n        \"\"\"\n        self.log.info(\"publishing event on %s\", self.publish_topic)\n        if self.config.extra['config']['pub_options']['retain']:\n            try:\n                await persist_event(\n                    self.publish_topic,\n                    event,\n                    self.pool\n                )\n            except SystemError as error:\n                self.log.error(error)\n                return\n\n        await asyncio.sleep(1)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check_transport_host(self):\n        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        result = sock.connect_ex(('events-server', 8080))\n        if result == 0:\n            logging.info('port 8080 on zmq is open!')\n            return True\n        return False", "response": "Check if zeromq socket is available on transport host"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nstart a producer or consumer service", "response": "def start(self):\n        \"\"\"\n        Start a producer/consumer service\n        \"\"\"\n        component = Component(self.config, self.handlers)\n        component.run()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sample(config, samples):\n  url = get_api_path('sample.json')\n  multiple_files = []\n  images = [s['image'] for s in samples]\n  labels = [s['label'] for s in samples]\n  for image in images:\n    multiple_files.append(('images', (image, open(image, 'rb'), 'image/png')))\n  headers=get_headers(no_content_type=True)\n  headers[\"config\"]= json.dumps(config, cls=HCEncoder)\n  headers[\"labels\"]= json.dumps(labels)\n  print(\"With headers\", headers)\n\n  try:\n      r = requests.post(url, files=multiple_files, headers=headers, timeout=30)\n      return r.text\n  except requests.exceptions.RequestException:\n      e = sys.exc_info()[0]\n      print(\"Error while calling hyperchamber - \", e)\n      return None", "response": "Upload a series of samples."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef measure(config, result, max_retries=10):\n  url = get_api_path('measurement.json')\n  data = {'config': config, 'result': result}\n  retries = 0\n  while(retries < max_retries):\n      try:\n          r = requests.post(url, data=json.dumps(data, cls=HCEncoder), headers=get_headers(), timeout=30)\n          return r.text\n      except requests.exceptions.RequestException:\n          e = sys.exc_info()[0]\n          print(\"Error while calling hyperchamber - retrying \", e)\n          retries += 1", "response": "Records results on hyperchamber. io. Used when you are done testing a config."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef move_selection(reverse=False):\n    global selected_pid\n    if selected_pid not in gunicorns:\n        selected_pid = None\n    found = False\n    pids = sorted(gunicorns.keys(), reverse=reverse)\n    # Iterate items twice to enable wrapping.\n    for pid in pids + pids:\n        if selected_pid is None or found:\n            selected_pid = pid\n            return\n        found = pid == selected_pid", "response": "Moves the selection of gunicorns to the next one."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update_gunicorns():\n    global tick\n    tick += 1\n    if (tick * screen_delay) % ps_delay != 0:\n        return\n    tick = 0\n    for pid in gunicorns:\n        gunicorns[pid].update({\"workers\": 0, \"mem\": 0})\n    ps = Popen(PS_ARGS, stdout=PIPE).communicate()[0].split(\"\\n\")\n    headings = ps.pop(0).split()\n    name_col = headings.index(cmd_heading)\n    num_cols = len(headings) - 1\n    for row in ps:\n        cols = row.split(None, num_cols)\n        if cols and \"gunicorn: \" in cols[name_col]:\n            if \"gunicorn: worker\" in cols[name_col]:\n                is_worker = True\n            else:\n                is_worker = False\n\n            if is_worker:\n                pid = cols[headings.index(\"PPID\")]\n            else:\n                pid = cols[headings.index(\"PID\")]\n            if pid not in gunicorns:\n                gunicorns[pid] = {\"workers\": 0, \"mem\": 0, \"port\": None, \"name\":\n                    cols[name_col].strip().split(\"[\",1)[1].split(\"]\",1)[:-1]}\n            gunicorns[pid][\"mem\"] += int(cols[headings.index(\"RSS\")])\n            if is_worker:\n                gunicorns[pid][\"workers\"] += 1\n    # Remove gunicorns that were not found in the process list.\n    for pid in gunicorns.keys()[:]:\n        if gunicorns[pid][\"workers\"] == 0:\n            del gunicorns[pid]\n    # Determine ports if any are missing.\n    if not [g for g in gunicorns.values() if g[\"port\"] is None]:\n        return\n    for (pid, port) in ports_for_pids(gunicorns.keys()):\n        if pid in gunicorns:\n            gunicorns[pid][\"port\"] = port", "response": "Update the dictionary of gunicorns."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef handle_keypress(screen):\n    global selected_pid\n    try:\n        key = screen.getkey().upper()\n    except:\n        return\n    if key in (\"KEY_DOWN\", \"J\"):\n        move_selection()\n    elif key in (\"KEY_UP\", \"K\"):\n        move_selection(reverse=True)\n    elif key in (\"A\", \"+\"):\n        send_signal(\"TTIN\")\n        if selected_pid in gunicorns:\n            gunicorns[selected_pid][\"workers\"] = 0\n    elif key in (\"W\", \"-\"):\n        if selected_pid in gunicorns:\n            if gunicorns[selected_pid][\"workers\"] != 1:\n                send_signal(\"TTOU\")\n                gunicorns[selected_pid][\"workers\"] = 0\n    elif key in (\"R\",):\n        if selected_pid in gunicorns:\n            send_signal(\"HUP\")\n            del gunicorns[selected_pid]\n            selected_pid = None\n    elif key in (\"T\",):\n        for pid in gunicorns.copy().iterkeys():\n            selected_pid = pid\n            send_signal(\"HUP\")\n            del gunicorns[selected_pid]\n            selected_pid = None\n    elif key in (\"M\", \"-\"):\n        if selected_pid in gunicorns:\n            send_signal(\"QUIT\")\n            del gunicorns[selected_pid]\n            selected_pid = None\n    elif key in (\"Q\",):\n        raise KeyboardInterrupt", "response": "Handle a keypress event."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nformats a single row of text.", "response": "def format_row(pid=\"\", port=\"\", name=\"\", mem=\"\", workers=\"\", prefix_char=\"  \"):\n    \"\"\"\n    Applies consistant padding to each of the columns in a row and serves as\n    the source of the overall screen width.\n    \"\"\"\n    row = \"%s%-5s %-6s %-25s %8s %7s \" \\\n          % (prefix_char, pid, port, name, mem, workers)\n\n    global screen_width\n    if screen_width is None:\n        screen_width = len(row)\n    return row"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndisplay the gunicorn menu list.", "response": "def display_output(screen):\n    \"\"\"\n    Display the menu list of gunicorns.\n    \"\"\"\n    format_row() # Sets up the screen width.\n    screen_height = len(gunicorns) + len(instructions.split(\"\\n\")) + 9\n    if not gunicorns:\n        screen_height += 2 # A couple of blank lines are added when empty.\n    screen.erase()\n    win = curses.newwin(screen_height, screen_width + 6, 1, 3)\n    win.bkgd(\" \", curses.color_pair(1))\n    win.border()\n    x = 3\n    blank_line = y = count(2).next\n    win.addstr(y(), x, title.center(screen_width), curses.A_NORMAL)\n    blank_line()\n    win.addstr(y(), x, format_row(\" PID\", \"PORT\", \"NAME\", \"MEM (MB)\", \"WORKERS\"),\n        curses.A_STANDOUT)\n    if not gunicorns:\n        blank_line()\n        win.addstr(y(), x, no_gunicorns.center(screen_width),\n            curses.A_NORMAL)\n        blank_line()\n    else:\n        win.hline(y(), x, curses.ACS_HLINE, screen_width)\n        for (i, pid) in enumerate(sorted(gunicorns.keys())):\n            port = gunicorns[pid][\"port\"]\n            name = gunicorns[pid][\"name\"]\n            mem = \"%#.3f\" % (gunicorns[pid][\"mem\"] / 1000.)\n            workers = gunicorns[pid][\"workers\"]\n            # When a signal is sent to update the number of workers, the number\n            # of workers is set to zero as a marker to signify an update has\n            # occurred. We then piggyback this variable and use it as a counter\n            # to animate the display until the gunicorn is next updated.\n            if workers < 1:\n                gunicorns[pid][\"workers\"] -= 1\n                chars = \"|/-\\\\\"\n                workers *= -1\n                if workers == len(chars):\n                   gunicorns[pid][\"workers\"] = workers = 0\n                workers = chars[workers]\n            if pid == selected_pid:\n                attr = curses.A_STANDOUT\n                prefix_char = '> '\n            else:\n                attr = curses.A_NORMAL\n                prefix_char = '  '\n            win.addstr(y(), x, format_row(pid, port, name, mem, workers,\n                                          prefix_char), attr)\n    win.hline(y(), x, curses.ACS_HLINE, screen_width)\n    blank_line()\n    for line in instructions.split(\"\\n\"):\n        win.addstr(y(), x, line.center(screen_width), curses.A_NORMAL)\n    win.refresh()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a variant from the parser while disabling logging.", "response": "def _get_variant_silent(parser, variant):\n    \"\"\"Gets a variant from the parser while disabling logging.\"\"\"\n    prev_log = config.LOG_NOT_FOUND\n    config.LOG_NOT_FOUND = False\n    results = parser.get_variant_genotypes(variant)\n    config.LOG_NOT_FOUND = prev_log\n    return results"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _attrs_(mcs, cls, attr_name: str) -> Tuple[Any, ...]:\n        return tuple(map(lambda x: getattr(x, attr_name), list(cls)))", "response": "Returns a tuple containing just the value of the given attr_name of all\n        the elements from the cls."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the enumeration item regarding to the attribute name and value attr_value.", "response": "def _from_attr_(mcs, cls, attr_name: str, attr_value: Any) -> TypeVar:\n        \"\"\"\n        Returns the enumeration item regarding to the attribute name and value,\n        or None if not found for the given cls\n\n        :param attr_name: str: attribute's name\n        :param attr_value: different values: key to search for\n        :return: Enumeration Item\n        \"\"\"\n        return next(iter(filter(lambda x: getattr(x, attr_name) == attr_value,\n                                list(cls))), None)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprint in the console a table showing all the attributes for all the class holding the class.", "response": "def describe(cls) -> None:\n        \"\"\"\n        Prints in the console a table showing all the attributes for all the\n        definitions inside the class\n\n        :return: None\n        \"\"\"\n        max_lengths = []\n        for attr_name in cls.attr_names():\n            attr_func = \"%ss\" % attr_name\n            attr_list = list(map(str, getattr(cls, attr_func)())) + [attr_name]\n            max_lengths.append(max(list(map(len, attr_list))))\n        row_format = \"{:>%d} | {:>%d} | {:>%d}\" % tuple(max_lengths)\n        headers = [attr_name.capitalize() for attr_name in cls.attr_names()]\n        header_line = row_format.format(*headers)\n        output = \"Class: %s\\n\" % cls.__name__\n        output += header_line + \"\\n\"\n        output += \"-\"*(len(header_line)) + \"\\n\"\n        for item in cls:\n            format_list = [str(getattr(item, attr_name))\n                           for attr_name in cls.attr_names()]\n            output += row_format.format(*format_list) + \"\\n\"\n        print(output)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read_iter(use_fpi):\n    '''Return the path to the final .mag file either for the complex or the fpi\n    inversion.\n    '''\n    filename_rhosuffix = 'exe/inv.lastmod_rho'\n    filename = 'exe/inv.lastmod'\n    # filename HAS to exist. Otherwise the inversion was not finished\n    if(not os.path.isfile(filename)):\n        print('Inversion was not finished! No last iteration found.')\n\n    if(use_fpi is True):\n        if(os.path.isfile(filename_rhosuffix)):\n            filename = filename_rhosuffix\n\n    linestring = open(filename, 'r').readline().strip()\n    linestring = linestring.replace('\\n', '')\n    linestring = linestring.replace('../', '')\n    return linestring", "response": "Return the path to the final. mag file either for the complex or the fpi\n    inversion."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef td_type():\n    '''get type of the tomodir (complex or dc and whether fpi)\n    '''\n    cfg = np.genfromtxt('exe/crtomo.cfg',\n                        skip_header=15,\n                        dtype='str',\n                        usecols=([0]))\n    is_complex = False\n    if cfg[0] == 'F':\n        is_complex = True\n    is_fpi = False\n    if cfg[2] == 'T':\n        is_fpi = True\n\n    return is_complex, is_fpi", "response": "get type of the tomodir"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the type of the tomodir and the highest iteration to list all files and the dtype of the tomodir which will be plotted.", "response": "def list_datafiles():\n    '''Get the type of the tomodir and the highest iteration to list all files,\n    which will be plotted.\n    '''\n    is_cplx, is_fpi = td_type()\n    # get the highest iteration\n    it_rho = read_iter(is_fpi)\n    it_phase = read_iter(False)\n    # list the files\n    files = ['inv/coverage.mag']\n    dtype = ['cov']\n    files.append(it_rho)\n    dtype.append('mag')\n    if is_cplx:\n        files.append(it_rho.replace('mag', 'pha'))\n        dtype.append('pha')\n    if is_fpi:\n        files.append(it_phase.replace('mag', 'pha'))\n        dtype.append('pha_fpi')\n\n    return files, dtype"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads the datafiles and return cov mag phase and fpi phase values.", "response": "def read_datafiles(files, dtype, column):\n    '''Load the datafiles and return cov, mag, phase and fpi phase values.\n    '''\n    pha = []\n    pha_fpi = []\n    for filename, filetype in zip(files, dtype):\n        if filetype == 'cov':\n            cov = load_cov(filename)\n        elif filetype == 'mag':\n            mag = load_rho(filename, column)\n        elif filetype == 'pha':\n            pha = load_rho(filename, 2)\n        elif filetype == 'pha_fpi':\n            pha_fpi = load_rho(filename, 2)\n\n    return cov, mag, pha, pha_fpi"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load_cov(name):\n    '''Load a datafile with coverage file structure.\n    '''\n    content = np.genfromtxt(name, skip_header=1, skip_footer=1, usecols=([2]))\n\n    return content", "response": "Load a datafile with coverage file structure."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_rho(name, column):\n    '''Load a datafile with rho structure like mag and phase\n    '''\n    try:\n        content = np.loadtxt(name, skiprows=1, usecols=([column]))\n    except:\n        raise ValueError('Given column to open does not exist.')\n\n    return content", "response": "Load a datafile with rho structure like mag and phase"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef calc_complex(mag, pha):\n    ''' Calculate real and imaginary part of the complex conductivity from\n    magnitude and phase in log10.\n    '''\n    complx = [10 ** m * math.e ** (1j * p / 1e3) for m, p in zip(mag, pha)]\n    real = [math.log10((1 / c).real) for c in complx]\n    imag = []\n    for c in complx:\n        if ((1 / c).imag) == 0:\n            imag.append(math.nan)\n        else:\n            i = math.log10(abs((1 / c).imag))\n            imag.append(i)\n    return real, imag", "response": "Calculate real and imaginary part of the complex conductivity from magnitude and phase in log10."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef plot_ratio(cid, ax, plotman, title, alpha, vmin, vmax,\n               xmin, xmax, zmin, zmax, xunit, cbtiks, elecs):\n    '''Plot ratio of two conductivity directions.\n    '''\n    # handle options\n    cblabel = 'anisotropy ratio'\n    zlabel = 'z [' + xunit + ']'\n    xlabel = 'x [' + xunit + ']'\n    # cm = 'brg'\n    cm = 'RdYlGn'\n    xmin, xmax, zmin, zmax, vmin, vmax = check_minmax(\n            plotman,\n            cid,\n            xmin, xmax,\n            zmin, zmax,\n            vmin, vmax,\n            )\n    # plot\n    fig, ax, cnorm, cmap, cb, scalarMap = plotman.plot_elements_to_ax(\n            cid=cid,\n            ax=ax,\n            xmin=xmin,\n            xmax=xmax,\n            zmin=zmin,\n            zmax=zmax,\n            cblabel=cblabel,\n            cbnrticks=cbtiks,\n            title=title,\n            zlabel=zlabel,\n            xlabel=xlabel,\n            plot_colorbar=True,\n            cmap_name=cm,\n            no_elecs=elecs,\n            cbmin=vmin,\n            cbmax=vmax,\n            )\n    return fig, ax, cnorm, cmap, cb", "response": "Plot ratio of two conductivity directions."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncalculate alpha values from the coverage.", "response": "def alpha_from_cov(plotman, alpha_cov):\n    '''Calculate alpha values from the coverage/2.5.\n    '''\n    abscov = np.abs(load_cov('inv/coverage.mag'))\n    if alpha_cov:\n        normcov = np.divide(abscov, 2.5)\n        normcov[np.where(normcov > 1)] = 1\n        mask = np.subtract(1, normcov)\n        alpha = plotman.parman.add_data(mask)\n    else:\n        alpha = plotman.parman.add_data(np.ones(len(abscov)))\n    return alpha, plotman"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef check_minmax(plotman, cid, xmin, xmax, zmin, zmax, vmin, vmax):\n    '''Get min and max values for axes and colorbar if not given\n    '''\n    if xmin is None:\n        xmin = plotman.grid.grid['x'].min()\n    if xmax is None:\n        xmax = plotman.grid.grid['x'].max()\n    if zmin is None:\n        zmin = plotman.grid.grid['z'].min()\n    if zmax is None:\n        zmax = plotman.grid.grid['z'].max()\n    if isinstance(cid, int):\n            subdata = plotman.parman.parsets[cid]\n    else:\n            subdata = cid\n    if vmin is None:\n        vmin = subdata.min()\n    if vmax is None:\n        vmax = subdata.max()\n\n    return xmin, xmax, zmin, zmax, vmin, vmax", "response": "Get min and max values for axes and colorbar if not given\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncalculate appropriate sizes for the subfigures", "response": "def getfigsize(plotman):\n    '''calculate appropriate sizes for the subfigures\n    '''\n    xmin = plotman.grid.grid['x'].min()\n    xmax = plotman.grid.grid['x'].max()\n    zmin = plotman.grid.grid['z'].min()\n    zmax = plotman.grid.grid['z'].max()\n    if np.abs(zmax - zmin) < np.abs(xmax - xmin):\n        sizex = 10 / 2.54\n        sizez = 1.2 * sizex * (np.abs(zmax - zmin) / np.abs(xmax - xmin))\n    else:\n        sizez = 10 / 2.54\n        sizex = sizez * (np.abs(xmax - xmin) / np.abs(zmax - zmin))\n    # add 1 inch to accommodate colorbar\n    sizex += 1.3\n    sizez += 1\n    return sizex, sizez"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_tdplot(plotman, cov, mag, pha, pha_fpi, alpha, options):\n    '''Plot the data of the tomodir in one overview plot.\n    '''\n    sizex, sizez = getfigsize(plotman)\n    # create figure\n    f, ax = plt.subplots(2, 4, figsize=(4 * sizex, 2 * sizez))\n    if options.title is not None:\n        plt.suptitle(options.title, fontsize=18)\n    # plot magnitue\n    if options.cmaglin:\n        cid = plotman.parman.add_data(np.power(10, mag))\n        loglin = 'rho'\n    else:\n        cid = plotman.parman.add_data(mag)\n        loglin = 'log_rho'\n    plot_mag(cid, ax[0, 0], plotman, 'Magnitude', loglin, alpha,\n             options.mag_vmin, options.mag_vmax,\n             options.xmin, options.xmax, options.zmin, options.zmax,\n             options.unit, options.mag_cbtiks, options.no_elecs,\n             )\n    # plot coverage\n    cid = plotman.parman.add_data(cov)\n    plot_cov(cid, ax[1, 0], plotman, 'Coverage',\n             options.cov_vmin, options.cov_vmax,\n             options.xmin, options.xmax, options.zmin, options.zmax,\n             options.unit, options.cov_cbtiks, options.no_elecs,\n             )\n    # plot phase, real, imag\n    create_non_dcplots(plotman, ax, mag, pha, options, alpha)\n    # plot fpi phase, real, imag\n    create_fpiplots(plotman, ax, mag, pha_fpi, options, alpha)\n    f.tight_layout()\n    f.savefig('td_overview.png', dpi=300)\n    return f, ax", "response": "Create the data of the tomodir in one overview plot."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a single plot for the tomodir.", "response": "def create_singleplots(plotman, cov, mag, pha, pha_fpi, alpha, options):\n    '''Plot the data of the tomodir in individual plots.\n    '''\n    magunit = 'log_rho'\n    if not pha == []:\n        [real, imag] = calc_complex(mag, pha)\n        if not pha_fpi == []:\n            [real_fpi, imag_fpi] = calc_complex(mag, pha_fpi)\n            if options.cmaglin:\n                mag = np.power(10, mag)\n                magunit = 'rho'\n            data = np.column_stack((mag, cov, pha, real, imag,\n                                    pha_fpi, real_fpi, imag_fpi))\n            titles = ['Magnitude', 'Coverage',\n                      'Phase', 'Real Part', 'Imaginary Part',\n                      'FPI Phase', 'FPI Real Part', 'FPI Imaginary Part']\n            unites = [\n                magunit, 'cov',\n                'phi', 'log_real', 'log_imag',\n                'phi', 'log_real', 'log_imag'\n            ]\n            vmins = [options.mag_vmin, options.cov_vmin,\n                     options.pha_vmin, options.real_vmin, options.imag_vmin,\n                     options.pha_vmin, options.real_vmin, options.imag_vmin]\n            vmaxs = [options.mag_vmax, options.cov_vmax,\n                     options.pha_vmax, options.real_vmax, options.imag_vmax,\n                     options.pha_vmax, options.real_vmax, options.imag_vmax]\n            cmaps = ['jet', 'GnBu',\n                     'jet_r', 'jet_r', 'plasma_r',\n                     'plasma', 'jet_r', 'plasma_r']\n            saves = ['rho', 'cov',\n                     'phi', 'real', 'imag',\n                     'fpi_phi', 'fpi_real', 'fpi_imag']\n        else:\n            if options.cmaglin:\n                mag = np.power(10, mag)\n                magunit = 'rho'\n            data = np.column_stack((mag, cov, pha, real, imag))\n            titles = ['Magnitude', 'Coverage',\n                      'Phase', 'Real Part', 'Imaginary Part']\n            unites = [magunit, 'cov',\n                      'phi', 'log_real', 'log_imag']\n            vmins = [options.mag_vmin, options.cov_vmin,\n                     options.pha_vmin, options.real_vmin, options.imag_vmin]\n            vmaxs = [options.mag_vmax, options.cov_vmax,\n                     options.pha_vmax, options.real_vmax, options.imag_vmax]\n            cmaps = ['jet', 'GnBu',\n                     'jet_r', 'jet_r', 'plasma_r']\n            saves = ['rho', 'cov',\n                     'phi', 'real', 'imag']\n    else:\n        data = np.column_stack((mag, cov))\n        titles = ['Magnitude', 'Coverage']\n        unites = [magunit, 'cov']\n        vmins = [options.mag_vmin, options.cov_vmin]\n        vmaxs = [options.mag_vmax, options.cov_vmax]\n        cmaps = ['jet', 'GnBu']\n        saves = ['rho', 'cov']\n    try:\n        mod_rho = np.genfromtxt('rho/rho.dat', skip_header=1, usecols=([0]))\n        mod_pha = np.genfromtxt('rho/rho.dat', skip_header=1, usecols=([1]))\n        data = np.column_stack((data, mod_rho, mod_pha))\n        titles.append('Model')\n        titles.append('Model')\n        unites.append('rho')\n        unites.append('phi')\n        vmins.append(options.mag_vmin)\n        vmins.append(options.pha_vmin)\n        vmaxs.append(options.mag_vmax)\n        vmaxs.append(options.pha_vmax)\n        cmaps.append('jet')\n        cmaps.append('plasma')\n        saves.append('rhomod')\n        saves.append('phamod')\n    except:\n        pass\n    for datum, title, unit, vmin, vmax, cm, save in zip(\n            np.transpose(data), titles, unites, vmins, vmaxs, cmaps, saves):\n        sizex, sizez = getfigsize(plotman)\n        f, ax = plt.subplots(1, figsize=(sizex, sizez))\n        cid = plotman.parman.add_data(datum)\n        # handle options\n        cblabel = units.get_label(unit)\n        if options.title is not None:\n            title = options.title\n        zlabel = 'z [' + options.unit + ']'\n        xlabel = 'x [' + options.unit + ']'\n        xmin, xmax, zmin, zmax, vmin, vmax = check_minmax(\n                plotman,\n                cid,\n                options.xmin, options.xmax,\n                options.zmin, options.zmax,\n                vmin, vmax\n                )\n        # plot\n        cmap = mpl_cm.get_cmap(cm)\n        fig, ax, cnorm, cmap, cb, scalarMap = plotman.plot_elements_to_ax(\n                cid=cid,\n                cid_alpha=alpha,\n                ax=ax,\n                xmin=xmin,\n                xmax=xmax,\n                zmin=zmin,\n                zmax=zmax,\n                cblabel=cblabel,\n                title=title,\n                zlabel=zlabel,\n                xlabel=xlabel,\n                plot_colorbar=True,\n                cmap_name=cm,\n                over=cmap(1.0),\n            under=cmap(0.0),\n                no_elecs=options.no_elecs,\n                cbmin=vmin,\n                cbmax=vmax,\n                )\n        f.tight_layout()\n        f.savefig(save + '.png', dpi=300)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates an overview plot for the tomodir in one overview plot.", "response": "def create_anisomagplot(plotman, x, y, z, alpha, options):\n    '''Plot the data of the tomodir in one overview plot.\n    '''\n    sizex, sizez = getfigsize(plotman)\n    # create figure\n    f, ax = plt.subplots(2, 3, figsize=(3 * sizex, 2 * sizez))\n    if options.title is not None:\n        plt.suptitle(options.title, fontsize=18)\n        plt.subplots_adjust(wspace=1.5, top=2)\n    # plot magnitue\n    if options.cmaglin:\n        cidx = plotman.parman.add_data(np.power(10, x))\n        cidy = plotman.parman.add_data(np.power(10, y))\n        cidz = plotman.parman.add_data(np.power(10, z))\n        loglin = 'rho'\n    else:\n        cidx = plotman.parman.add_data(x)\n        cidy = plotman.parman.add_data(y)\n        cidz = plotman.parman.add_data(z)\n        loglin = 'log_rho'\n    cidxy = plotman.parman.add_data(np.divide(x, y))\n    cidyz = plotman.parman.add_data(np.divide(y, z))\n    cidzx = plotman.parman.add_data(np.divide(z, x))\n    plot_mag(cidx, ax[0, 0], plotman, 'x', loglin, alpha,\n             options.mag_vmin, options.mag_vmax,\n             options.xmin, options.xmax, options.zmin, options.zmax,\n             options.unit, options.mag_cbtiks, options.no_elecs,\n             )\n    plot_mag(cidy, ax[0, 1], plotman, 'y', loglin, alpha,\n             options.mag_vmin, options.mag_vmax,\n             options.xmin, options.xmax, options.zmin, options.zmax,\n             options.unit, options.mag_cbtiks, options.no_elecs,\n             )\n    plot_mag(cidz, ax[0, 2], plotman, 'z', loglin, alpha,\n             options.mag_vmin, options.mag_vmax,\n             options.xmin, options.xmax, options.zmin, options.zmax,\n             options.unit, options.mag_cbtiks, options.no_elecs,\n             )\n    plot_ratio(cidxy, ax[1, 0], plotman, 'x/y', alpha,\n               options.rat_vmin, options.rat_vmax,\n               options.xmin, options.xmax, options.zmin, options.zmax,\n               options.unit, options.mag_cbtiks, options.no_elecs,\n               )\n    plot_ratio(cidyz, ax[1, 1], plotman, 'y/z', alpha,\n               options.rat_vmin, options.rat_vmax,\n               options.xmin, options.xmax, options.zmin, options.zmax,\n               options.unit, options.mag_cbtiks, options.no_elecs,\n               )\n    plot_ratio(cidzx, ax[1, 2], plotman, 'z/x', alpha,\n               options.rat_vmin, options.rat_vmax,\n               options.xmin, options.xmax, options.zmin, options.zmax,\n               options.unit, options.mag_cbtiks, options.no_elecs,\n               )\n    f.tight_layout()\n    f.savefig('mag_aniso.png', dpi=300)\n    return f, ax"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating an overview plot of the data of the tomodir in one overview plot.", "response": "def create_anisophaplot(plotman, x, y, z, alpha, options):\n    '''Plot the data of the tomodir in one overview plot.\n    '''\n    sizex, sizez = getfigsize(plotman)\n    # create figure\n    f, ax = plt.subplots(2, 3, figsize=(3 * sizex, 2 * sizez))\n    if options.title is not None:\n        plt.suptitle(options.title, fontsize=18)\n        plt.subplots_adjust(wspace=1, top=0.8)\n    # plot phase\n    cidx = plotman.parman.add_data(x)\n    cidy = plotman.parman.add_data(y)\n    cidz = plotman.parman.add_data(z)\n    cidxy = plotman.parman.add_data(np.subtract(x, y))\n    cidyz = plotman.parman.add_data(np.subtract(y, z))\n    cidzx = plotman.parman.add_data(np.subtract(z, x))\n    plot_pha(cidx, ax[0, 0], plotman, 'x', alpha,\n             options.pha_vmin, options.pha_vmax,\n             options.xmin, options.xmax, options.zmin, options.zmax,\n             options.unit, options.pha_cbtiks, options.no_elecs,\n             )\n    plot_pha(cidy, ax[0, 1], plotman, 'y', alpha,\n             options.pha_vmin, options.pha_vmax,\n             options.xmin, options.xmax, options.zmin, options.zmax,\n             options.unit, options.pha_cbtiks, options.no_elecs,\n             )\n    plot_pha(cidz, ax[0, 2], plotman, 'z', alpha,\n             options.pha_vmin, options.pha_vmax,\n             options.xmin, options.xmax, options.zmin, options.zmax,\n             options.unit, options.pha_cbtiks, options.no_elecs,\n             )\n    plot_ratio(cidxy, ax[1, 0], plotman, 'x-y', alpha,\n               options.rat_vmin, options.rat_vmax,\n               options.xmin, options.xmax, options.zmin, options.zmax,\n               options.unit, options.mag_cbtiks, options.no_elecs,\n               )\n    plot_ratio(cidyz, ax[1, 1], plotman, 'y-z', alpha,\n               options.rat_vmin, options.rat_vmax,\n               options.xmin, options.xmax, options.zmin, options.zmax,\n               options.unit, options.mag_cbtiks, options.no_elecs,\n               )\n    plot_ratio(cidzx, ax[1, 2], plotman, 'z-x', alpha,\n               options.rat_vmin, options.rat_vmax,\n               options.xmin, options.xmax, options.zmin, options.zmax,\n               options.unit, options.mag_cbtiks, options.no_elecs,\n               )\n    f.tight_layout()\n    f.savefig('pha_aniso.png', dpi=300)\n    return f, ax"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_hlammagplot(plotman, h, ratio, alpha, options):\n    '''Plot the data of the tomodir in one overview plot.\n    '''\n    sizex, sizez = getfigsize(plotman)\n    # create figure\n    f, ax = plt.subplots(1, 3, figsize=(3 * sizex, sizez))\n    if options.title is not None:\n        plt.suptitle(options.title, fontsize=18)\n        plt.subplots_adjust(wspace=1, top=0.8)\n    # plot magnitue\n    if options.cmaglin:\n        cidh = plotman.parman.add_data(np.power(10, h))\n        cidv = plotman.parman.add_data(\n                np.divide(np.power(10, h), np.power(10, ratio)))\n        loglin = 'rho'\n    else:\n        cidh = plotman.parman.add_data(h)\n        cidv = plotman.parman.add_data(\n                np.log10(np.divide(np.power(10, h), np.power(10, ratio))))\n        loglin = 'log_rho'\n\n    cidr = plotman.parman.add_data(np.power(10, ratio))\n    plot_mag(cidh, ax[0], plotman, 'horizontal', loglin, alpha,\n             options.mag_vmin, options.mag_vmax,\n             options.xmin, options.xmax, options.zmin, options.zmax,\n             options.unit, options.mag_cbtiks, options.no_elecs,\n             )\n    plot_mag(cidv, ax[1], plotman, 'vertical', loglin, alpha,\n             options.mag_vmin, options.mag_vmax,\n             options.xmin, options.xmax, options.zmin, options.zmax,\n             options.unit, options.mag_cbtiks, options.no_elecs,\n             )\n    plot_ratio(cidr, ax[2], plotman, 'hor/ver', alpha,\n               options.rat_vmin, options.rat_vmax,\n               options.xmin, options.xmax, options.zmin, options.zmax,\n               options.unit, options.mag_cbtiks, options.no_elecs,\n               )\n    f.tight_layout()\n    f.savefig('mag_hlam.png', dpi=300)\n    return f, ax", "response": "Create the hlammag plot."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_hlamphaplot(plotman, h, v, alpha, options):\n    '''Plot the data of the tomodir in one overview plot.\n    '''\n    sizex, sizez = getfigsize(plotman)\n    # create figure\n    f, ax = plt.subplots(1, 3, figsize=(3 * sizex, sizez))\n    if options.title is not None:\n        plt.suptitle(options.title, fontsize=18)\n        plt.subplots_adjust(wspace=1, top=0.8)\n    cidh = plotman.parman.add_data(h)\n    cidv = plotman.parman.add_data(v)\n\n    cidr = plotman.parman.add_data(np.subtract(h, v))\n    plot_pha(cidh, ax[0], plotman, 'horizontal', alpha,\n             options.pha_vmin, options.pha_vmax,\n             options.xmin, options.xmax, options.zmin, options.zmax,\n             options.unit, options.pha_cbtiks, options.no_elecs,\n             )\n    plot_pha(cidv, ax[1], plotman, 'vertical', alpha,\n             options.pha_vmin, options.pha_vmax,\n             options.xmin, options.xmax, options.zmin, options.zmax,\n             options.unit, options.pha_cbtiks, options.no_elecs,\n             )\n    plot_ratio(cidr, ax[2], plotman, 'hor - ver', alpha,\n               options.rat_vmin, options.rat_vmax,\n               options.xmin, options.xmax, options.zmin, options.zmax,\n               options.unit, options.pha_cbtiks, options.no_elecs,\n               )\n    f.tight_layout()\n    f.savefig('pha_hlam.png', dpi=300)\n    return f, ax", "response": "Create the data of the tomodir in one overview plot."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef citation_director(**kwargs):\n    qualifier = kwargs.get('qualifier', '')\n    content = kwargs.get('content', '')\n    if qualifier == 'publicationTitle':\n        return CitationJournalTitle(content=content)\n    elif qualifier == 'volume':\n        return CitationVolume(content=content)\n    elif qualifier == 'issue':\n        return CitationIssue(content=content)\n    elif qualifier == 'pageStart':\n        return CitationFirstpage(content=content)\n    elif qualifier == 'pageEnd':\n        return CitationLastpage(content=content)\n    else:\n        return None", "response": "Direct the citation elements based on their qualifier."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndirect the identifier elements based on their qualifier.", "response": "def identifier_director(**kwargs):\n    \"\"\"Direct the identifier elements based on their qualifier.\"\"\"\n    qualifier = kwargs.get('qualifier', '')\n    content = kwargs.get('content', '')\n    if qualifier == 'ISBN':\n        return CitationISBN(content=content)\n    elif qualifier == 'ISSN':\n        return CitationISSN(content=content)\n    elif qualifier == 'DOI':\n        return CitationDOI(content=content)\n    elif qualifier == 'REP-NO':\n        return CitationTechnicalReportNumber(content=content)\n    else:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_author(self, **kwargs):\n        qualifier = kwargs.get('qualifier', '')\n        children = kwargs.get('children', [])\n        creator_type_per = False\n        author_name = None\n        # Find the creator type in children.\n        for child in children:\n            if child.tag == 'type' and child.content == 'per':\n                creator_type_per = True\n            # Get the author name.\n            elif child.tag == 'name':\n                author_name = child.content\n        if qualifier == 'aut' and creator_type_per and author_name:\n            return author_name\n\n        return None", "response": "Determine the authors from the creator field."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_publisher_name(self, **kwargs):\n        children = kwargs.get('children', [])\n        # Find the creator type in children.\n        for child in children:\n            if child.tag == 'name':\n                return child.content\n        return None", "response": "Get the publisher name."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_publication_date(self, **kwargs):\n        date_string = kwargs.get('content', '')\n        date_match = CREATION_DATE_REGEX.match(date_string)\n        month_match = CREATION_MONTH_REGEX.match(date_string)\n        year_match = CREATION_YEAR_REGEX.match(date_string)\n        # Check if a date match exists.\n        if date_match:\n            (year, month, day) = date_match.groups('')\n            # Create the date.\n            try:\n                creation_date = datetime.date(int(year), int(month), int(day))\n            except ValueError:\n                return None\n            else:\n                return '%s/%s/%s' % (\n                    format_date_string(creation_date.month),\n                    format_date_string(creation_date.day),\n                    creation_date.year,\n                )\n        elif month_match:\n            (year, month) = month_match.groups('')\n            # Create the date.\n            try:\n                creation_date = datetime.date(int(year), int(month), 1)\n            except ValueError:\n                return None\n            else:\n                return '%s/%s' % (\n                    format_date_string(creation_date.month),\n                    creation_date.year,\n                )\n        elif year_match:\n            year = year_match.groups('')[0]\n            return year\n        else:\n            return None", "response": "Determine the creation date for the publication date."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_online_date(self, **kwargs):\n        qualifier = kwargs.get('qualifier', '')\n        content = kwargs.get('content', '')\n        # Handle meta-creation-date element.\n        if qualifier == 'metadataCreationDate':\n            date_match = META_CREATION_DATE_REGEX.match(content)\n            (year, month, day) = date_match.groups('')\n            # Create the date.\n            creation_date = datetime.date(int(year), int(month), int(day))\n            return '%s/%s/%s' % (\n                format_date_string(creation_date.month),\n                format_date_string(creation_date.day),\n                creation_date.year,\n            )\n        return None", "response": "Get the online date from the meta creation date."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the dissertation institution.", "response": "def get_institution(self, **kwargs):\n        \"\"\"Get the dissertation institution.\"\"\"\n        qualifier = kwargs.get('qualifier', '')\n        content = kwargs.get('content', '')\n        if qualifier == 'grantor':\n            return content\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalls the similarity service to get the similar docs for a given query.", "response": "def call_doc_similarity(self, keywords, rerank_by_doc, start_date, end_date):\n        \"\"\"\n        :param keywords: a string, a query, A dark knight\n        :return: similar docs as returned by the vector similarity service\n        \"\"\"\n        payload = {'query': keywords, 'k': self.constraint_remap_config['k'], 'rerank_by_doc': rerank_by_doc}\n        if start_date is not None:\n            payload['start_date'] = start_date\n        if end_date is not None:\n            payload['end_date'] = end_date\n\n        \"\"\"\n        if rerank_by_doc is true then the results are returned as:\n        [ {\n            'doc_id': str(doc_id),\n            'id_score_tups': [(str(faiss_id), diff_score <float32>) ],\n            'score': doc_relevance <float32>\n          } \n        ]\n        \n        otherwise the results are:\n        [ {\n            'score': diff_score <float32>, \n            'sentence_id': str(<int64>)\n          } \n        ]\n        \"\"\"\n        similar_docs = list()\n        try:\n            response = requests.get(self.constraint_remap_config['similarity_url'], params=payload)\n            if response.status_code == 200:\n                similar_docs.extend(response.json())\n        except Exception as e:\n            print('Error: {}, while calling document similarity for query: {}'.format(e, keywords))\n\n        if rerank_by_doc:\n            for similar_doc in similar_docs:\n                similar_doc['sentence_id'] = [divmod(int(x[0]), 10000)[1] for x in similar_doc['id_score_tups']]\n\n        else:\n            for similar_doc in similar_docs:\n                doc_id, real_sentence_id = divmod(int(similar_doc['sentence_id']), 10000)\n                similar_doc['sentence_id'] = real_sentence_id\n                similar_doc['doc_id'] = str(doc_id)\n        return similar_docs"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading the model. results file", "response": "def model_results(self) -> str:\n        \"\"\"\n        Reads the model.results file\n        \"\"\"\n        with open(os.path.join(self.directory, \"model.results\")) as f:\n            return f.read()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef optimizer(self) -> non_linear.NonLinearOptimizer:\n        if self.__optimizer is None:\n            with open(os.path.join(self.directory, \".optimizer.pickle\"), \"r+b\") as f:\n                self.__optimizer = pickle.loads(f.read())\n        return self.__optimizer", "response": "Returns the optimizer object that was used in this phase."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of all phases that match the passed arguments.", "response": "def phases_with(self, **kwargs) -> [PhaseOutput]:\n        \"\"\"\n        Filters phases. If no arguments are passed all phases are returned. Arguments must be key value pairs, with\n        phase, data or pipeline as the key.\n\n        Parameters\n        ----------\n        kwargs\n            Filters, e.g. pipeline=pipeline1\n        \"\"\"\n        return [phase for phase in self.phases if\n                all([getattr(phase, key) == value for key, value in kwargs.items()])]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload a list of optimizers for phases in the directory that match the given filters.", "response": "def optimizers_with(self, **kwargs) -> [non_linear.NonLinearOptimizer]:\n        \"\"\"\n        Load a list of optimizers for phases in the directory with zero or more filters applied.\n\n        Parameters\n        ----------\n        kwargs\n            Filters, e.g. pipeline=pipeline1\n\n        Returns\n        -------\n        optimizers\n            A list of optimizers, one for each phase in the directory that matches the filters.\n        \"\"\"\n        return [phase.optimizer for phase in self.phases_with(**kwargs)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a string containing the model results for all phases in the directory.", "response": "def model_results(self, **kwargs) -> str:\n        \"\"\"\n        Collates model results from all phases in the directory or some subset if filters are applied.\n\n        Parameters\n        ----------\n        kwargs\n            Filters, e.g. pipeline=pipeline1\n\n        Returns\n        -------\n        model_results\n            A string joining headers and results for all included phases.\n        \"\"\"\n        return \"\\n\\n\".join(\"{}\\n\\n{}\".format(phase.header, phase.model_results) for phase in\n                           self.phases_with(**kwargs))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef branches(config, searchstring=\"\"):\n    repo = config.repo\n\n    branches_ = list(find(repo, searchstring))\n    if branches_:\n        merged = get_merged_branches(repo)\n        info_out(\"Found existing branches...\")\n        print_list(branches_, merged)\n        if len(branches_) == 1 and searchstring:\n            # If the found branch is the current one, error\n            active_branch = repo.active_branch\n            if active_branch == branches_[0]:\n                error_out(\"You're already on '{}'\".format(branches_[0].name))\n            branch_name = branches_[0].name\n            if len(branch_name) > 50:\n                branch_name = branch_name[:47] + \"\u2026\"\n            check_it_out = (\n                input(\"Check out '{}'? [Y/n] \".format(branch_name)).lower().strip()\n                != \"n\"\n            )\n            if check_it_out:\n                branches_[0].checkout()\n    elif searchstring:\n        error_out(\"Found no branches matching '{}'.\".format(searchstring))\n    else:\n        error_out(\"Found no branches.\")", "response": "List all branches. And if exactly 1 found offer to check it out."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndecode base64 string to byte array.", "response": "def decodebytes(input):\n    \"\"\"Decode base64 string to byte array.\"\"\"\n    py_version = sys.version_info[0]\n    if py_version >= 3:\n        return _decodebytes_py3(input)\n    return _decodebytes_py2(input)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncapturing the current state of a project based on its provider and the given commit.", "response": "def capture(self, commit = \"\"):\n\t\t\"\"\"Capture the current state of a project based on its provider\n\n\t\tCommit is relevant only for upstream providers.\n\t\tIf empty, the latest commit from provider repository is taken.\n\t\tIt is ignored for distribution providers.\n\n\t\t:param provider: project provider, e.g. upstream repository, distribution builder\n\t\t:type  provider: json/dict\n\t\t:param commit: project's original commit\n\t\t:type  commit: string\n\t\t\"\"\"\n\t\tself._validateProvider(self._provider)\n\n\t\t# get client for repository\n\t\t# TODO(jchaloup): read config file to switch between local and remove clients\n\t\t# TODO(jchaloup): remote client can cover gofed infratructure or any remove source for repository info\n\t\tclient = RepositoryClientBuilder().buildWithRemoteClient(self._provider)\n\n\t\tif self._provider[\"provider\"] == \"github\":\n\t\t\tself._signature = ProjectGithubRepositoryCapturer(self._provider, client).capture(commit).signature()\n\t\telif self._provider[\"provider\"] == \"bitbucket\":\n\t\t\tself._signature = ProjectBitbucketRepositoryCapturer(self._provider, client).capture(commit).signature()\n\t\telse:\n\t\t\traise KeyError(\"Provider '%s' not recognized\" % self._provider[\"provider\"])\n\n\t\treturn self"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlogs that duplicates were found.", "response": "def found_duplicates(counts):\n    \"\"\"Log that duplicates were found.\n\n    :param counts: A list of duplicate marker names along with their number\n                   of occurences.\n    :type counts: list\n\n    \"\"\"\n    _logger.warning(\"Duplicated markers found\")\n    for marker, count in counts:\n        _logger.warning(\" - {}: {:,d} times\".format(marker, count))\n    _logger.warning(\"Appending ':dupX' to the duplicated markers according \"\n                    \"to their location in the file.\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds command line arguments to the parser.", "response": "def add_arguments(self, parser):\n        \"\"\"\n        Add arguments to the command parser.\n\n        Uses argparse syntax.  See documentation at\n        https://docs.python.org/3/library/argparse.html.\n        \"\"\"\n        parser.add_argument(\n            '--dry-run',\n            action='store_true',\n            default=False,\n            help=\"Output what we're going to do, but don't actually do it.\"\n        )\n        parser.add_argument(\n            '--task-name', '-t',\n            default=None,\n            help=u\"Restrict cleanup to tasks matching the named task.\",\n        )\n        parser.add_argument(\n            '--age', '-a',\n            type=int,\n            default=30,\n            help=u\"Only delete tasks that have been resolved for at least the specified number of days (default: 30)\",\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef patch_model_schemas(mapping):\n    from mbdata.models import Base\n\n    for table in Base.metadata.sorted_tables:\n        if table.schema is None:\n            continue\n        table.schema = mapping.get(table.schema, table.schema)", "response": "Update mbdata. models to use different schema names"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef detectRamPorts(stm: IfContainer, current_en: RtlSignalBase):\n    if stm.ifFalse or stm.elIfs:\n        return\n    for _stm in stm.ifTrue:\n        if isinstance(_stm, IfContainer):\n            yield from detectRamPorts(_stm, _stm.cond & current_en)\n        elif isinstance(_stm, Assignment):\n            if isinstance(_stm.dst._dtype, HArray):\n                assert len(_stm.indexes) == 1, \"one address per RAM port\"\n                w_addr = _stm.indexes[0]\n                mem = _stm.dst\n                yield (RAM_WRITE, mem, w_addr, current_en, _stm.src)\n            elif _stm.src.hidden and len(_stm.src.drivers) == 1:\n                op = _stm.src.drivers[0]\n                mem = op.operands[0]\n                if isinstance(mem._dtype, HArray) and op.operator == AllOps.INDEX:\n                    r_addr = op.operands[1]\n                    if _stm.indexes:\n                        raise NotImplementedError()\n                    yield (RAM_READ, mem, r_addr, current_en, _stm.dst)", "response": "Detect the RAM ports in a IfContainer."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd and connects input port on a node.", "response": "def addInputPort(self, node, name,\n                     i: Union[Value, RtlSignalBase],\n                     side=PortSide.WEST):\n        \"\"\"\n        Add and connect input port on subnode\n\n        :param node: node where to add input port\n        :param name: name of newly added port\n        :param i: input value\n        :param side: side where input port should be added \n        \"\"\"\n        root = self.node\n        port = node.addPort(name, PortType.INPUT, side)\n        netCtxs = self.netCtxs\n\n        if isinstance(i, LPort):\n            root.addEdge(i, port)\n        elif isConst(i):\n            i = i.staticEval()\n            c, wasThereBefore = self.netCtxs.getDefault(i)\n            if not wasThereBefore:\n                v = ValueAsLNode(root, i).east[0]\n                c.addDriver(v)\n            c.addEndpoint(port)\n        elif i.hidden:\n            # later connect driver of this signal to output port\n            ctx, wasThereBefore = netCtxs.getDefault(i)\n            if not wasThereBefore:\n                self.lazyLoadNet(i)\n            ctx.addEndpoint(port)\n        else:\n            portCtx = self.portCtx\n            rootCtx, _ = self.rootNetCtxs.getDefault(i)\n\n            if self.isVirtual:\n                # later connect signal in root to input port or input port of\n                # wrap node\n                rootCtx.addEndpoint(port)\n            else:\n                # spot input port on this wrap node if required\n                isNewlySpotted = (i, PortType.INPUT) not in portCtx.data\n                src = portCtx.register(i, PortType.INPUT)\n                # connect input port on wrap node with specified output port\n                ctx, _ = netCtxs.getDefault(i)\n                ctx.addDriver(src)\n                ctx.addEndpoint(port)\n\n                if isNewlySpotted:\n                    # get input port from parent view\n                    _port = portCtx.getOutside(i, PortType.INPUT)\n                    rootCtx.addEndpoint(_port)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef addOutputPort(self, node: LNode, name: str,\n                      out: Optional[Union[RtlSignalBase, LPort]],\n                      side=PortSide.EAST):\n        \"\"\"\n        Add and connect output port on subnode\n        \"\"\"\n        oPort = node.addPort(name, PortType.OUTPUT, side)\n        if out is not None:\n            if isinstance(out, LPort):\n                self.node.addEdge(oPort, out)\n            elif out.hidden:\n                raise ValueError(\"Hidden signals should not be connected to outside\", name)\n            elif self.isVirtual:\n                # This node is inlined inside of parent.\n                # Mark that this output of subnode should be connected\n                # to output of parent node.\n                ctx, _ = self.netCtxs.getDefault(out)\n                ctx.addDriver(oPort)\n            else:\n                # connect my signal to my output port\n                _out = self.portCtx.getInside(out, PortType.OUTPUT)\n                self.node.addEdge(oPort, _out, originObj=out)\n                # mark connection of output port to parent net\n                ooPort = self.portCtx.getOutside(out, PortType.OUTPUT)\n                ctx, _ = self.rootNetCtxs.getDefault(out)\n                ctx.addDriver(ooPort)\n\n        return oPort", "response": "Add and connect an output port on a node."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef lazyLoadNet(self, signal: RtlSignalBase):\n        d_cnt = len(signal.drivers)\n        if d_cnt == 1:\n            driver = signal.drivers[0]\n            if isinstance(driver, Operator):\n                d = self.addOperatorAsLNode(driver)\n                if isinstance(d, LNode):\n                    c, _ = self.netCtxs.getDefault(signal)\n                    c.addDriver(d.east[0])\n                else:\n                    self.netCtxs.joinNetsByKeyVal(signal, d)\n        elif d_cnt == 0 and signal.defVal._isFullVld():\n            raise AssertionError(\"Value of this net should have been already rendered\")\n        else:\n            raise AssertionError(signal, signal.drivers)", "response": "lazyLoadNet - lazy loads the network for the given signal"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef renderContent(self):\n        stm = self.stm\n        portCtx = self.portCtx\n        # for each inputs and outputs render expression trees\n\n        # walk statements and render muxs and memories\n        for o in stm._outputs:\n            if not self.isVirtual:\n                portCtx.register(o, PortType.OUTPUT)\n\n        canHaveRamPorts = isinstance(stm, IfContainer) and arr_any(\n            chain(stm._inputs, stm._outputs),\n            lambda s: isinstance(s._dtype, HArray))\n        # render RAM ports\n        consumedOutputs = set()\n        if canHaveRamPorts:\n            for pType, memSig, addrSig, enSig, io in detectRamPorts(stm, stm.cond):\n                if pType == RAM_READ:\n                    self.createRamReadNode(memSig, enSig, addrSig,\n                                           io, True)\n                    consumedOutputs.add(io)\n\n                elif pType == RAM_WRITE:\n                    self.createRamWriteNode(memSig, enSig, addrSig,\n                                            io, True)\n                    consumedOutputs.add(memSig)\n\n                else:\n                    raise TypeError()\n\n        for o in stm._outputs:\n            if o not in consumedOutputs:\n                self.renderForSignal(stm, o, True)\n\n        if not self.isVirtual:\n            self.netCtxs.applyConnections(self.node)", "response": "Walk from outputs to inputs and render all operator and statement nodes for each public signal and signal that are not already in the tree"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef renderForSignal(self, stm: Union[HdlStatement, List[HdlStatement]],\n                        s: RtlSignalBase,\n                        connectOut) -> Optional[Tuple[LNode, Union[RtlSignalBase, LPort]]]:\n        \"\"\"\n        Walk statement and render nodes which are representing\n        hardware components (MUX, LATCH, FF, ...) for specified signal\n        \"\"\"\n        # filter statements for this signal only if required\n        if not isinstance(stm, HdlStatement):\n            stm = list(walkStatementsForSig(stm, s))\n            if not stm:\n                return None\n            elif len(stm) != 1:\n                raise NotImplementedError(\"deduced MUX\")\n            else:\n                stm = stm[0]\n\n        # render assignment instances\n        if isinstance(stm, Assignment):\n            return self.createAssignment(stm, connectOut)\n\n        encl = stm._enclosed_for\n        full_ev_dep = stm._is_completly_event_dependent\n        par = stm.parentStm\n        parent_ev_dep = par is not None and par._now_is_event_dependent\n\n        # render IfContainer instances\n        if isinstance(stm, IfContainer):\n            if full_ev_dep and not parent_ev_dep:\n                # FF with optional MUX\n                return self.renderEventDepIfContainer(stm, s, connectOut)\n\n            else:\n                latched = par is None and not parent_ev_dep and s not in encl\n                # MUX/LATCH/MUX+LATCH\n                controls = [stm.cond]\n                ren = self.renderForSignal(stm.ifTrue, s, False)\n                if ren is not None:\n                    inputs = [ren[1]]\n                else:\n                    inputs = []\n\n                for c, stms in stm.elIfs:\n                    controls.append(c)\n                    ren = self.renderForSignal(stms, s, False)\n                    if ren is not None:\n                        inputs.append(ren[1])\n                if stm.ifFalse:\n                    ren = self.renderForSignal(stm.ifFalse, s, False)\n                    if ren is not None:\n                        inputs.append(ren[1])\n\n                return self.createMux(s, inputs, controls, connectOut,\n                                      latched=latched)\n\n        # render SwitchContainer instances\n        elif isinstance(stm, SwitchContainer):\n            latched = s not in encl\n            inputs = []\n            for _, stms in stm.cases:\n                d = self.renderForSignal(stms, s, False)\n                if d is not None:\n                    _, port = d\n                    inputs.append(port)\n                else:\n                    assert latched, (s, stm)\n\n            if stm.default:\n                d = self.renderForSignal(stm.default, s, False)\n                if d is not None:\n                    _, port = d\n                    inputs.append(port)\n                else:\n                    assert latched, (s, stm)\n\n            return self.createMux(s, inputs, stm.switchOn, connectOut,\n                                  latched=latched)\n        else:\n            raise TypeError(stm)", "response": "Render the given signal and return the corresponding LNode and LPort."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating a new name based on the project and the name of the project.", "response": "def generate(self, project):\n\t\t\"\"\"\n\t\tPackage name construction is based on provider, not on prefix.\n\t\tPrefix does not have to equal provider_prefix.\n\t\t\"\"\"\n\t\tfor assignment in self.s2n_mapping:\n\t\t\tif assignment[\"ipprefix\"] == project:\n\t\t\t\tself._name = assignment[\"package\"]\n\t\t\t\treturn self\n\n\t\t#\n\t\t# github.com -> github\n\t\t# code.google.com/p/ -> googlecode\n\t\t# golang.org/x/ -> golangorg\n\t\t# gopkg.in/check.v1 -> gopkg-check\n\t\t# camlistore.org\n\t\t#\n\n\t\tname = project\n\t\tif name.startswith(\"github.com\"):\n\t\t\tname = re.sub(r\"^github\\.com\", \"github\", name)\n\n\t\tif name.startswith(\"gopkg.in\"):\n\t\t\tname = re.sub(r\"gopkg\\.in\", \"gopkg\", name)\n\t\t\t# any version marks?\n\t\t\tname = re.sub(r\"\\.v\\d\", \"\", name)\n\t\t\tname = re.sub(r\"/v\\d/\", \"/\", name)\n\n\t\tif name.startswith(\"code.google.com/p\"):\n\t\t\tname = re.sub(r\"^code\\.google\\.com/p\", \"googlecode\", name)\n\n\t\tif name.startswith(\"golang.org/x\"):\n\t\t\tname = re.sub(r\"^golang\\.org/x\", \"golangorg\", name)\n\n\t\tif name.startswith(\"google.golang.org\"):\n\t\t\tname = re.sub(r\"^google\\.golang\\.org\", \"googlegolangorg\", name)\n\n\t\tif name.startswith(\"bitbucket.org\"):\n\t\t\tname = re.sub(r\"^bitbucket\\.org\", \"bitbucket\", name)\n\n\t\tif name.startswith(\"k8s.io\"):\n\t\t\tname = re.sub(r\"^k8s\\.io\", \"k8s\", name)\n\n\t\tif name.endswith(\".org\"):\n\t\t\tname = re.sub(r\"\\.org$\", \"\", name)\n\n\t\tname = name.replace(\"/\", \"-\")\n\n\t\tself._name = \"golang-%s\" % name\n\n\t\treturn self"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef hash_host(hostname, salt=None):\n        if salt is None:\n            salt = os.urandom(sha1().digest_size)\n        else:\n            if salt.startswith('|1|'):\n                salt = salt.split('|')[2]\n            salt = decodebytes(b(salt))\n        assert len(salt) == sha1().digest_size\n        hmac = HMAC(salt, b(hostname), sha1).digest()\n        hostkey = '|1|%s|%s' % (u(encodebytes(salt)), u(encodebytes(hmac)))\n        return hostkey.replace('\\n', '')", "response": "Return a hashed form of the hostname as used by OpenSSH when storing\n        hashed hostnames in the known_hosts file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef from_line(cls, line, lineno=None):\n        log = get_logger('paramiko.hostkeys')\n        fields = line.split(' ')\n        if len(fields) < 3:\n            # Bad number of fields\n            log.info(\"Not enough fields found in known_hosts in line %s (%r)\" %\n                     (lineno, line))\n            return None\n        fields = fields[:3]\n\n        names, keytype, key = fields\n        names = names.split(',')\n\n        # Decide what kind of key we're looking at and create an object\n        # to hold it accordingly.\n        try:\n            key = b(key)\n            if keytype == 'ssh-rsa':\n                key = RSAKey(data=decodebytes(key))\n            elif keytype == 'ssh-dss':\n                key = DSSKey(data=decodebytes(key))\n            elif keytype == 'ecdsa-sha2-nistp256':\n                key = ECDSAKey(data=decodebytes(key))\n            else:\n                log.info(\"Unable to handle key of type %s\" % (keytype,))\n                return None\n\n        except binascii.Error as e:\n            raise InvalidHostKey(line, e)\n\n        return cls(names, key)", "response": "Parses a line of text to find the names for the host the type of key and the key data."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_grid_data(self, data):\n        self.grid_data.append(data)\n        return len(self.grid_data) - 1", "response": "Adds data to the grid data list"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _read_elem_nodes(self, fid):\n        nodes = {}\n\n        #   # prepare nodes\n        #   nodes_sorted = np.zeros((number_of_nodes, 3), dtype=float)\n        #   nodes = np.zeros((number_of_nodes, 3), dtype=float)\n\n        # read in nodes\n        nodes_raw = np.empty((self.header['nr_nodes'], 3), dtype=float)\n        for nr in range(0, self.header['nr_nodes']):\n            node_line = fid.readline().lstrip()\n            nodes_raw[nr, :] = np.fromstring(\n                node_line, dtype=float, sep='    ')\n\n        # round node coordinates to 5th decimal point. Sometimes this is\n        # important when we deal with mal-formatted node data\n        nodes_raw[:, 1:3] = np.round(nodes_raw[:, 1:3], 5)\n\n        # check for CutMcK\n        # The check is based on the first node, but if one node was renumbered,\n        # so were all the others.\n        if(nodes_raw[:, 0] != list(range(1, nodes_raw.shape[0]))):\n            self.header['cutmck'] = True\n            print(\n                'This grid was sorted using CutMcK. The nodes were resorted!')\n        else:\n            self.header['cutmck'] = False\n\n        # Rearrange nodes when CutMcK was used.\n        if(self.header['cutmck']):\n            nodes_cutmck = np.empty_like(nodes_raw)\n            nodes_cutmck_index = np.zeros(nodes_raw.shape[0], dtype=int)\n            for node in range(0, self.header['nr_nodes']):\n                new_index = np.where(nodes_raw[:, 0].astype(int) == (node + 1))\n                nodes_cutmck[new_index[0], 1:3] = nodes_raw[node, 1:3]\n                nodes_cutmck[new_index[0], 0] = new_index[0]\n                nodes_cutmck_index[node] = new_index[0]\n            # sort them\n            nodes_sorted = nodes_cutmck[nodes_cutmck_index, :]\n            nodes['presort'] = nodes_cutmck\n            nodes['cutmck_index'] = nodes_cutmck_index\n            nodes['rev_cutmck_index'] = np.argsort(nodes_cutmck_index)\n        else:\n            nodes_sorted = nodes_raw\n            nodes['presort'] = nodes_raw\n\n        # prepare node dict\n        nodes['raw'] = nodes_raw\n        nodes['sorted'] = nodes_sorted\n\n        self.nodes = nodes\n        self.nr_of_nodes = nodes['raw'].shape[0]", "response": "Read the nodes from an elem. dat file and store them in the self. nodes dict."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _read_elem_elements(self, fid):\n        elements = {}\n\n        # read elements\n        for element_type in range(0, self.header['nr_element_types']):\n            element_list = []\n            for element_coordinates in range(\n                    0, self.header['element_infos'][element_type, 1]):\n                element_coordinates_line = fid.readline().lstrip()\n                tmp_element = self.element()\n                tmp_element.nodes = np.fromstring(element_coordinates_line,\n                                                  dtype=int, sep=' ')\n                tmp_element.xcoords = self.nodes['presort'][tmp_element.nodes -\n                                                            1, 1]\n                tmp_element.zcoords = self.nodes['presort'][tmp_element.nodes -\n                                                            1, 2]\n                element_list.append(tmp_element)\n            element_type_number = self.header['element_infos'][element_type, 0]\n            elements[element_type_number] = element_list\n        self.element_data = elements", "response": "Read all FE elements from the file stream."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\npreparing the grids for the we .", "response": "def _prepare_grids(self):\n        \"\"\"\n        depending on the type of grid (rectangular or triangle), prepare grids\n        or triangle lists\n\n        TODO: We want some nice way of not needing to know in the future if we\n              loaded triangles or quadratic elements.\n        \"\"\"\n        if(self.header['element_infos'][0, 2] == 3):\n            print('Triangular grid found')\n            self.grid_is_rectangular = False\n\n            triangles = self.element_data[3]\n            triangles = [x.nodes for x in triangles]\n            # python starts arrays with 0, but elem.dat with 1\n            triangles = np.array(triangles) - 1\n            self.elements = triangles\n            tri_x = self.nodes['presort'][triangles, 1]\n            tri_z = self.nodes['presort'][triangles, 2]\n            self.grid = {}\n            self.grid['x'] = tri_x\n            self.grid['z'] = tri_z\n\n        else:\n            print('Rectangular grid found')\n            self.grid_is_rectangular = True\n            quads_raw = [x.nodes for x in self.element_data[8]]\n            quads = np.array(quads_raw) - 1\n            self.elements = quads\n            quads_x = self.nodes['presort'][quads, 1]\n            quads_z = self.nodes['presort'][quads, 2]\n            self.grid = {}\n            self.grid['x'] = quads_x\n            self.grid['z'] = quads_z\n\n            # calculate the dimensions of the grid\n            try:\n                self.calculate_dimensions()\n            except Exception as e:\n                self.nr_nodes_x = None\n                self.nr_nodes_z = None\n                self.nr_elements_x = None\n                self.nr_elements_z = None\n        self.nr_of_elements = self.grid['x'].shape[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef calculate_dimensions(self):\n        x_coordinates = np.sort(self.grid['x'][:, 0])  # first x node\n        self.nr_nodes_z = np.where(x_coordinates == x_coordinates[0])[0].size\n        self.nr_elements_x = self.elements.shape[0] / (self.nr_nodes_z - 1)\n        self.nr_nodes_x = self.nr_elements_x + 1\n        self.nr_elements_z = self.nr_nodes_z - 1", "response": "For a regular grid calculate the element and node dimensions"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn min max x and z coordinates of grid", "response": "def get_minmax(self):\n        \"\"\"Return min/max x/z coordinates of grid\n\n        Returns\n        -------\n        x: [float, float]\n            min, max values of grid dimensions in x direction (sideways)\n        z: [float, float]\n            min, max values of grid dimensions in z direction (downwards)\n\n        \"\"\"\n        x_minmax = [np.min(self.grid['x']), np.max(self.grid['x'].max())]\n        z_minmax = [np.min(self.grid['z']), np.max(self.grid['z'].max())]\n        return x_minmax, z_minmax"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _read_elem_neighbors(self, fid):\n        # get number of boundary elements\n        # types 11 and 12 are boundary elements\n        sizes = sum([len(self.element_data[key]) for key in (11, 12) if\n                     self.element_data.get(key, None) is not None])\n        self.neighbors = []\n\n        try:\n            for i in range(0, sizes):\n                self.neighbors.append(int(fid.readline().strip()))\n        except Exception as e:\n            raise Exception('Not enough neighbors in file')", "response": "Read the boundary - element - neighbors from the end of the file"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef save_elem_file(self, output):\n        with open(output, 'wb') as fid:\n            self._write_elem_header(fid)\n            self._write_nodes(fid)\n            self._write_elements(fid)\n            self._write_neighbors(fid)", "response": "Save elem. dat to file."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads elem. dat and elec. dat", "response": "def load_grid(self, elem_file, elec_file):\n        \"\"\"Load elem.dat and elec.dat\n        \"\"\"\n        self.load_elem_file(elem_file)\n        self.load_elec_file(elec_file)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the node number for a given electrode.", "response": "def get_electrode_node(self, electrode):\n        \"\"\"\n        For a given electrode (e.g. from a config.dat file), return the true\n        node number as in self.nodes['sorted']\n        \"\"\"\n        elec_node_raw = int(self.electrodes[electrode - 1][0])\n        if(self.header['cutmck']):\n            elec_node = self.nodes['rev_cutmck_index'][elec_node_raw]\n        else:\n            elec_node = elec_node_raw - 1\n        return int(elec_node)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef plot_grid_to_ax(self, ax, **kwargs):\n        all_xz = []\n        for x, z in zip(self.grid['x'], self.grid['z']):\n            tmp = np.vstack((x, z)).T\n            all_xz.append(tmp)\n        collection = mpl.collections.PolyCollection(\n            all_xz,\n            edgecolor='k',\n            facecolor='none',\n            linewidth=0.4,\n        )\n        ax.add_collection(collection)\n        if self.electrodes is not None:\n            ax.scatter(\n                self.electrodes[:, 1],\n                self.electrodes[:, 2],\n                color=self.props['electrode_color'],\n                clip_on=False,\n            )\n        ax.set_xlim(self.grid['x'].min(), self.grid['x'].max())\n        ax.set_ylim(self.grid['z'].min(), self.grid['z'].max())\n        # ax.autoscale_view()\n        ax.set_aspect('equal')\n\n        if kwargs.get('plot_electrode_numbers', False):\n            for nr, xy in enumerate(self.electrodes[:, 1:3]):\n                ax.text(\n                    xy[0], xy[1],\n                    format(nr + 1),\n                    bbox=dict(boxstyle='circle', facecolor='red', alpha=0.8)\n                )", "response": "Plots the electrodes in the grid."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nplots the electrode numbers in the grid.", "response": "def plot_grid(self, **kwargs):\n        \"\"\"\n        Other Parameters\n        ----------------\n        plot_electrode_numbers: bool, optional\n            Plot electrode numbers in the grid, default: False\n        \"\"\"\n        fig, ax = plt.subplots(1, 1)\n        self.plot_grid_to_ax(ax, **kwargs)\n        return fig, ax"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_element_centroids(self):\n        centroids = np.vstack((\n            np.mean(self.grid['x'], axis=1), np.mean(self.grid['z'], axis=1)\n        )).T\n\n        return centroids", "response": "return the central points of all elements"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_internal_angles(self):\n\n        angles = []\n\n        for elx, elz in zip(self.grid['x'], self.grid['z']):\n            el_angles = []\n            xy = np.vstack((elx, elz))\n            for i in range(0, elx.size):\n                i1 = (i - 1) % elx.size\n                i2 = (i + 1) % elx.size\n\n                a = (xy[:, i] - xy[:, i1])\n                b = (xy[:, i2] - xy[:, i])\n                # note that nodes are ordered counter-clockwise!\n                angle = np.pi - np.arctan2(\n                    a[0] * b[1] - a[1] * b[0],\n                    a[0] * b[0] + a[1] * b[1]\n                )\n                el_angles.append(angle * 180 / np.pi)\n            angles.append(el_angles)\n        return np.array(angles)", "response": "Compute all internal angles of the grid. Returns numpy. ndarray with N the number of elements and K the internal angles in degrees\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nanalyze the internal angles of the grid and produce a histogram of the internal angles.", "response": "def analyze_internal_angles(self, return_plot=False):\n        \"\"\"Analyze the internal angles of the grid. Angles shouldn't be too\n        small because this can cause problems/uncertainties in the\n        Finite-Element solution of the forward problem. This function prints\n        the min/max values, as well as quantiles, to the command line, and can\n        also produce a histogram plot of the angles.\n\n        Parameters\n        ----------\n        return_plot: bool\n            if true, return (fig, ax) objects of the histogram plot\n\n        Returns\n        -------\n        fig: matplotlib.figure\n            figure object\n        ax: matplotlib.axes\n            axes object\n\n        Examples\n        --------\n\n            >>> import crtomo.grid as CRGrid\n                grid = CRGrid.crt_grid()\n                grid.load_elem_file('elem.dat')\n                fig, ax = grid.analyze_internal_angles(Angles)\n            This grid was sorted using CutMcK. The nodes were resorted!\n            Triangular grid found\n            Minimal angle: 22.156368696965796 degrees\n            Maximal angle: 134.99337326279496 degrees\n            Angle percentile 10%: 51.22 degrees\n            Angle percentile 20%: 55.59 degrees\n            Angle percentile 30%: 58.26 degrees\n            Angle percentile 40%: 59.49 degrees\n            Angle percentile 50%: 59.95 degrees\n            Angle percentile 60%: 60.25 degrees\n            Angle percentile 70%: 61.16 degrees\n            Angle percentile 80%: 63.44 degrees\n            Angle percentile 90%: 68.72 degrees\n            generating plot...\n            >>> # save to file with\n                fig.savefig('element_angles.png', dpi=300)\n\n        \"\"\"\n        angles = self.get_internal_angles().flatten()\n\n        print('Minimal angle: {0} degrees'.format(np.min(angles)))\n        print('Maximal angle: {0} degrees'.format(np.max(angles)))\n        # print out quantiles\n        for i in range(10, 100, 10):\n            print('Angle percentile {0}%: {1:0.2f} degrees'.format(\n                i,\n                np.percentile(angles, i),\n            ))\n\n        if return_plot:\n            print('generating plot...')\n            fig, ax = plt.subplots(1, 1, figsize=(12 / 2.54, 8 / 2.54))\n            ax.hist(angles, int(angles.size / 10))\n            ax.set_xlabel('angle [deg]')\n            ax.set_ylabel('count')\n            fig.tight_layout()\n            # fig.savefig('plot_element_angles.jpg', dpi=300)\n            return fig, ax"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of element numbers that are adjacent to each other.", "response": "def element_neighbors(self):\n        \"\"\"Return a list with element numbers (zero indexed) of neighboring\n        elements. Note that the elements are not sorted. No spacial orientation\n        can be inferred from the order of neighbors.\n\n        WARNING: This function is slow due to a nested loop. This would be a\n        good starting point for further optimizations.\n\n        In order to speed things up, we could search using the raw data, i.e.,\n        with CutMcK enabled sorting, and then restrict the loops to 2x the\n        bandwidth (before - after).\n\n        While not being returned, this function also sets the variable\n        self.element_neighbors_edges, in which the common nodes with each\n        neighbor are stored.\n\n        Returns\n        -------\n        neighbors : list\n            a list (length equal to nr of elements) with neighboring elements\n\n        Examples\n        --------\n\n\n        \"\"\"\n        if self.element_neighbors_data is not None:\n            return self.element_neighbors_data\n\n        max_nr_edges = self.header['element_infos'][0, 2]\n\n        # initialize the neighbor array\n        self.element_neighbors_data = []\n        self.element_neighbors_edges = []\n\n        # determine neighbors\n        print('Looking for neighbors')\n        for nr, element_nodes in enumerate(self.elements):\n            # print('element {0}/{1}'.format(nr + 1, self.nr_of_elements))\n            # print(element_nodes)\n            neighbors = []\n            neighbors_edges = []  # store the edges to this neighbor\n            for nr1, el in enumerate(self.elements):\n                # we look for elements that have two nodes in common with this\n                # element\n                intersection = np.intersect1d(element_nodes, el)\n                if intersection.size == 2:\n                    neighbors.append(nr1)\n                    neighbors_edges.append(intersection)\n                    # stop if we reached the maximum number of possible edges\n                    # this saves us quite some loop iterations\n                    if len(neighbors) == max_nr_edges:\n                        break\n            self.element_neighbors_data.append(neighbors)\n            self.element_neighbors_edges.append(neighbors_edges)\n        return self.element_neighbors_data"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the smoothing regularization matrix Wm of the grid", "response": "def Wm(self):\n        \"\"\"Return the smoothing regularization matrix Wm of the grid\n\n        \"\"\"\n        centroids = self.get_element_centroids()\n\n        Wm = scipy.sparse.csr_matrix(\n            (self.nr_of_elements, self.nr_of_elements))\n        # Wm = np.zeros((self.nr_of_elements, self.nr_of_elements))\n        for i, nb in enumerate(self.element_neighbors):\n            for j, edges in zip(nb, self.element_neighbors_edges[i]):\n                # side length\n                edge_coords = self.nodes['presort'][edges][:, 1:]\n                edge_length = np.linalg.norm(\n                    edge_coords[1, :] - edge_coords[0, :]\n                )\n                distance = np.linalg.norm(centroids[i] - centroids[j])\n\n                # main diagonal\n                Wm[i, i] += edge_length / distance\n                # side diagonals\n                Wm[i, j] -= edge_length / distance\n        return Wm"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_surface_grid(nr_electrodes=None, spacing=None,\n                            electrodes_x=None,\n                            depth=None,\n                            left=None,\n                            right=None,\n                            char_lengths=None,\n                            lines=None,\n                            debug=False,\n                            workdir=None):\n        \"\"\"This is a simple wrapper for cr_trig_create to create simple surface\n        grids.\n\n        Automatically generated electrode positions are rounded to the third\n        digit.\n\n        Parameters\n        ----------\n        nr_electrodes: int, optional\n            the number of surface electrodes\n        spacing: float, optional\n            the spacing between electrodes, usually in [m], required if nr of\n            electrodes is given\n        electrodes_x: array, optional\n            x-electrode positions can be provided here, e.g., for\n            non-equidistant electrode distances\n        depth: float, optional\n            the depth of the grid. If not given, this is computed as half the\n            maximum distance between electrodes\n        left: float, optional\n            the space allocated left of the first electrode. If not given,\n            compute as a fourth of the maximum inter-electrode distance\n        right: float, optional\n            the space allocated right of the first electrode. If not given,\n            compute as a fourth of the maximum inter-electrode distance\n        char_lengths: float|list of 4 floats, optional\n            characteristic lengths, as used by cr_trig_create\n        lines: list of floats, optional\n            at the given depths, add horizontal lines in the grid. Note that\n            all positive values will be multiplied by -1!\n        debug: bool, optional\n            default: False. If true, don't hide the output of cr_trig_create\n        workdir: string, optional\n            if set, use this directory to create the grid. Don't delete files\n            afterwards.\n\n        Returns\n        -------\n        grid: :class:`crtomo.grid.crt_grid` instance\n            the generated grid\n\n        Examples\n        --------\n        >>> from crtomo.grid import crt_grid\n        >>> grid = crt_grid.create_surface_grid(40, spacing=0.25, depth=5,\n        ...     left=2, right=2, char_lengths=[0.1, 0.5, 0.1, 0.5],\n        ...     lines=[0.4, 0.8], debug=False, workdir=None)\n        >>> import pylab as plt\n        >>> fig, ax = plt.subplots()\n        >>> grid.plot_grid_to_ax(ax)\n\n        \"\"\"\n        # check if all required information are present\n        if(electrodes_x is None and\n           (nr_electrodes is None or spacing is None)):\n            raise Exception(\n                'You must provide either the parameter \"electrodes_\" or ' +\n                'the parameters \"nr_electrodes\" AND \"spacing\"'\n            )\n\n        if electrodes_x is None:\n            electrodes = np.array(\n                [(x, 0.0) for x in np.arange(0.0, nr_electrodes)]\n            )\n            electrodes[:, 0] = electrodes[:, 0] * spacing\n            electrodes = np.round(electrodes, 3)\n        else:\n            nr_electrodes = len(electrodes_x)\n            electrodes = np.hstack((electrodes_x, np.zeros_like(electrodes_x)))\n\n        max_distance = np.abs(\n            np.max(electrodes[:, 0]) - np.min(electrodes[:, 0])\n        )\n        minx = electrodes[:, 0].min()\n        maxx = electrodes[:, 0].max()\n\n        if left is None:\n            left = max_distance / 4\n        if right is None:\n            right = max_distance / 4\n        if depth is None:\n            depth = max_distance / 2\n\n        # min/max coordinates of final grid\n        minimum_x = minx - left\n        maximum_x = maxx + left\n        minimum_z = -depth\n        maximum_z = 0\n\n        boundary_noflow = 11\n        boundary_mixed = 12\n        # prepare extra lines\n        extra_lines = []\n        add_boundary_nodes_left = []\n        add_boundary_nodes_right = []\n\n        if lines is not None:\n            lines = np.array(lines)\n            lines[np.where(np.array(lines) < 0)] *= -1\n            lines = sorted(lines)\n            for line_depth in lines:\n                extra_lines.append(\n                    (minimum_x, -line_depth, maximum_x, -line_depth)\n                )\n                add_boundary_nodes_left.append(\n                    (minimum_x, -line_depth, boundary_mixed)\n                )\n                add_boundary_nodes_right.append(\n                    (maximum_x, -line_depth, boundary_mixed)\n                )\n            # reverse direction of right nodes\n            add_boundary_nodes_left = np.array(add_boundary_nodes_left)[::-1]\n            add_boundary_nodes_right = np.array(add_boundary_nodes_right)\n\n        surface_electrodes = np.hstack((\n            electrodes, boundary_noflow * np.ones((electrodes.shape[0], 1))\n        ))\n        # import IPython\n        # IPython.embed()\n        boundaries = np.vstack((\n            (minimum_x, 0, boundary_noflow),\n            surface_electrodes,\n            (maximum_x, maximum_z, boundary_mixed),\n        ))\n        if len(add_boundary_nodes_right) != 0:\n            boundaries = np.vstack((\n                boundaries,\n                add_boundary_nodes_right,\n            ))\n\n        boundaries = np.vstack((\n            boundaries,\n            (maximum_x, minimum_z, boundary_mixed),\n            (minimum_x, minimum_z, boundary_mixed),\n        ))\n        if len(add_boundary_nodes_left) != 0:\n            boundaries = np.vstack(\n                (\n                    add_boundary_nodes_left,\n                )\n            )\n\n        if char_lengths is None:\n            char_lengths = [spacing / 3.0, ]\n\n        if workdir is None:\n            tempdir_obj = tempfile.TemporaryDirectory()\n            tempdir = tempdir_obj.name\n        else:\n            if not os.path.isdir(workdir):\n                os.makedirs(workdir)\n            tempdir = workdir\n\n        np.savetxt(\n            tempdir + os.sep + 'electrodes.dat', electrodes,\n            fmt='%.3f %.3f'\n        )\n        np.savetxt(tempdir + os.sep + 'boundaries.dat', boundaries,\n                   fmt='%.4f %.4f %i')\n        np.savetxt(\n            tempdir + os.sep + 'char_length.dat',\n            np.atleast_1d(char_lengths)\n        )\n        if extra_lines:\n            np.savetxt(\n                tempdir + os.sep + 'extra_lines.dat',\n                np.atleast_2d(extra_lines),\n                fmt='%.4f %.4f %.4f %.4f'\n            )\n        pwd = os.getcwd()\n        os.chdir(tempdir)\n        try:\n            if debug:\n                subprocess.call(\n                    'cr_trig_create grid',\n                    shell=True,\n                )\n            else:\n                subprocess.check_output(\n                    'cr_trig_create grid',\n                    shell=True,\n                    # stdout=subprocess.STDOUT,\n                    # stderr=subprocess.STDOUT,\n                )\n        except subprocess.CalledProcessError as e:\n            print('there was an error generating the grid')\n            print(e.returncode)\n            print(e.output)\n            import shutil\n            shutil.copytree(tempdir, pwd + os.sep + 'GRID_FAIL')\n            exit()\n        finally:\n            os.chdir(pwd)\n        grid = crt_grid(\n            elem_file=tempdir + os.sep + 'grid' + os.sep + 'elem.dat',\n            elec_file=tempdir + os.sep + 'grid' + os.sep + 'elec.dat',\n        )\n        if workdir is None:\n            tempdir_obj.cleanup()\n\n        return grid", "response": "This is a simple wrapper for cr_trig_create to create simple surface grids."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _initialize_components(self, kwargs):\n        tomodir = None\n\n        # load/assign grid\n        if 'tomodir' in kwargs:\n            # load grid\n            tomodir = kwargs.get('tomodir')\n            print('importing tomodir {}'.format(tomodir))\n            assert os.path.isdir(tomodir)\n            grid = CRGrid.crt_grid(\n                tomodir + os.sep + 'grid' + os.sep + 'elem.dat',\n                tomodir + os.sep + 'grid' + os.sep + 'elec.dat',\n            )\n            self.grid = grid\n        elif 'grid' in kwargs:\n            self.grid = kwargs.get('grid')\n        elif 'elem_file' in kwargs and 'elec_file' in kwargs:\n            grid = CRGrid.crt_grid()\n            grid.load_grid(\n                kwargs['elem_file'],\n                kwargs['elec_file'],\n            )\n            self.grid = grid\n        else:\n            raise Exception(\n                'You must provide either a grid instance or ' +\n                'elem_file/elec_file file paths'\n            )\n\n        crmod_cfg = kwargs.get('crmod_cfg', CRcfg.crmod_config())\n        self.crmod_cfg = crmod_cfg\n\n        crtomo_cfg = kwargs.get('crtomo_cfg', CRcfg.crtomo_config())\n        self.crtomo_cfg = crtomo_cfg\n\n        parman = kwargs.get('parman', pM.ParMan(self.grid))\n        self.parman = parman\n\n        nodeman = kwargs.get('nodeman', nM.NodeMan(self.grid))\n        self.nodeman = nodeman\n\n        configs_abmn = kwargs.get('configs_abmn', None)\n        config = cConf.ConfigManager(\n            nr_of_electrodes=self.grid.nr_of_electrodes\n        )\n        if configs_abmn is not None:\n            config.add_to_configs(configs_abmn)\n        self.configs = config\n\n        config_file = kwargs.get('config_file', None)\n        if config_file is not None:\n            self.configs.load_crmod_config(config_file)\n\n        voltage_file = kwargs.get('volt_file', None)\n        if voltage_file is not None:\n            cids = self.configs.load_crmod_volt(voltage_file)\n            self.assignments['measurements'] = cids\n\n        self.plot = PlotManager.plotManager(\n            grid=self.grid,\n            nm=self.nodeman,\n            pm=self.parman,\n        )\n\n        # if we load from a tomodir, also load configs and inversion results\n        if tomodir is not None:\n            print('importing tomodir results')\n            # forward configurations\n            config_file = tomodir + os.sep + 'config' + os.sep + 'config.dat'\n            if os.path.isfile(config_file):\n                self.configs.load_crmod_config(config_file)\n            # load inversion results\n            self.read_inversion_results(tomodir)", "response": "initialize the various components using the supplied kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_tomodir(self, directory):\n        pwd = os.getcwd()\n        if not os.path.isdir(directory):\n            os.makedirs(directory)\n        os.chdir(directory)\n\n        directories = (\n            'config',\n            'exe',\n            'grid',\n            'mod',\n            'mod/pot',\n            'mod/sens',\n            'rho',\n        )\n        for directory in directories:\n            if not os.path.isdir(directory):\n                os.makedirs(directory)\n\n        os.chdir(pwd)", "response": "Create a tomodir subdirectory structure in the given directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks if this instance can model and or invert the related resources.", "response": "def _check_state(self):\n        \"\"\"Check if this instance can model and/or can invert\n        \"\"\"\n        if(self.grid is not None and\n           self.configs.configs is not None and\n           self.assignments['forward_model'] is not None):\n            self.can_model = True\n\n        if(self.grid is not None and\n           self.assignments['measurements'] is not None):\n            self.can_invert = True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_rho_file(self, filename):\n        pids = self.parman.load_from_rho_file(filename)\n        self.register_magnitude_model(pids[0])\n        self.register_phase_model(pids[1])\n        return pids", "response": "Load a forward model from a rho. dat file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef save_to_tomodir(self, directory):\n        self.create_tomodir(directory)\n\n        self.grid.save_elem_file(\n            directory + os.sep + 'grid/elem.dat'\n        )\n\n        self.grid.save_elec_file(\n            directory + os.sep + 'grid/elec.dat'\n        )\n\n        # modeling\n        if self.configs.configs is not None:\n            self.configs.write_crmod_config(\n                directory + os.sep + 'config/config.dat'\n            )\n\n        if self.assignments['forward_model'] is not None:\n            self.parman.save_to_rho_file(\n                directory + os.sep + 'rho/rho.dat',\n                self.assignments['forward_model'][0],\n                self.assignments['forward_model'][1],\n            )\n\n        self.crmod_cfg.write_to_file(\n            directory + os.sep + 'exe/crmod.cfg'\n        )\n\n        if self.assignments['measurements'] is not None:\n            self.configs.write_crmod_volt(\n                directory + os.sep + 'mod/volt.dat',\n                self.assignments['measurements']\n            )\n\n        if self.assignments['sensitivities'] is not None:\n            self._save_sensitivities(\n                directory + os.sep + 'mod/sens',\n            )\n\n        if self.assignments['potentials'] is not None:\n            self._save_potentials(\n                directory + os.sep + 'mod/pot',\n            )\n\n        # inversion\n        self.crtomo_cfg.write_to_file(\n            directory + os.sep + 'exe/crtomo.cfg'\n        )\n\n        if self.noise_model is not None:\n            self.noise_model.write_crt_noisemod(\n                directory + os.sep + 'exe/crt.noisemod'\n            )\n\n        if not os.path.isdir(directory + os.sep + 'inv'):\n            os.makedirs(directory + os.sep + 'inv')", "response": "Save the tomodir instance to a directory structure."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _save_sensitivities(self, directory):\n        print('saving sensitivities')\n        digits = int(np.ceil(np.log10(self.configs.configs.shape[0])))\n        for i in range(0, self.configs.configs.shape[0]):\n            sens_data, meta_data = self.get_sensitivity(i)\n            filename_raw = 'sens{0:0' + '{0}'.format(digits) + '}.dat'\n            filename = directory + os.sep + filename_raw.format(i + 1)\n\n            grid_xz = self.grid.get_element_centroids()\n            all_data = np.vstack((\n                grid_xz[:, 0],\n                grid_xz[:, 0],\n                sens_data[0],\n                sens_data[1],\n            )).T\n            with open(filename, 'wb') as fid:\n                fid.write(bytes(\n                    '{0} {1}\\n'.format(meta_data[0], meta_data[1]),\n                    'utf-8'\n                ))\n                np.savetxt(fid, all_data)", "response": "save sensitivities to a directory"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _save_potentials(self, directory):\n        print('saving potentials')\n        digits = int(np.ceil(np.log10(self.configs.configs.shape[0])))\n        for i in range(0, self.configs.configs.shape[0]):\n            pot_data = self.get_potential(i)\n            filename_raw = 'pot{0:0' + '{0}'.format(digits) + '}.dat'\n            filename = directory + os.sep + filename_raw.format(i + 1)\n\n            nodes = self.grid.nodes['sorted'][:, 1:3]\n            all_data = np.hstack((\n                nodes,\n                pot_data[0][:, np.newaxis],\n                pot_data[1][:, np.newaxis],\n            ))\n            with open(filename, 'wb') as fid:\n                np.savetxt(fid, all_data)", "response": "save potentials to a directory"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef clear_measurements(self):\n        mid_list = self.assignments.get('measurements', None)\n        if mid_list is not None:\n            for mid in mid_list:\n                self.configs.delete_measurements(mid=mid)\n            self.assignments['measurements'] = None", "response": "Forget any previous measurements"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef measurements(self):\n        # check if we have measurements\n        mid = self.assignments.get('measurements', None)\n        if mid is None:\n            return_value = self.model(\n                voltages=True,\n                sensitivities=False,\n                potentials=False,\n            )\n            if return_value is None:\n                print('cannot model')\n                return\n\n        # retrieve measurements\n        cids = self.assignments['measurements']\n        measurements = np.vstack((\n            self.configs.measurements[cids[0]],\n            self.configs.measurements[cids[1]],\n        )).T\n        return measurements", "response": "Return the measurements associated with this instance."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _read_modeling_results(self, directory, silent=False):\n\n        voltage_file = directory + os.sep + 'volt.dat'\n        if os.path.isfile(voltage_file):\n            if not silent:\n                print('reading voltages')\n            self.read_voltages(voltage_file)\n\n        sens_files = sorted(glob(\n            directory + os.sep + 'sens' + os.sep + 'sens*.dat')\n        )\n        # check if there are sensitivity files, and that the nr corresponds to\n        # the nr of configs\n        if(len(sens_files) > 0 and\n           len(sens_files) == self.configs.nr_of_configs):\n            print('reading sensitivities')\n            self._read_sensitivities(directory + os.sep + 'sens')\n\n        # same for potentials\n        pot_files = sorted(glob(\n            directory + os.sep + 'pot' + os.sep + 'pot*.dat')\n        )\n        # check if there are sensitivity files, and that the nr corresponds to\n        # the nr of configs\n        if(len(pot_files) > 0 and\n           len(pot_files) == self.configs.nr_of_configs):\n            print('reading potentials')\n            self._read_potentials(directory + os.sep + 'pot')", "response": "Read modeling results from a given mod / directory."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _read_sensitivities(self, sens_dir):\n        if self.assignments['sensitivities'] is not None:\n            print('Sensitivities already imported. Will not overwrite!')\n            return\n        else:\n            self.assignments['sensitivities'] = {}\n\n        sens_files = sorted(glob(sens_dir + os.sep + 'sens*.dat'))\n        for nr, filename in enumerate(sens_files):\n            with open(filename, 'r') as fid:\n                metadata = np.fromstring(\n                    fid.readline().strip(), sep=' ', count=2\n                )\n                meta_re = metadata[0]\n                meta_im = metadata[1]\n\n                sens_data = np.loadtxt(fid)\n\n                cids = self.parman.add_data(\n                    sens_data[:, 2:4],\n                    [meta_re, meta_im],\n                )\n                # store cids for later retrieval\n                self.assignments['sensitivities'][nr] = cids", "response": "import sensitivities from a directory and store them in self. assignments"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nimports potentials from a directory", "response": "def _read_potentials(self, pot_dir):\n        \"\"\"import potentials from a directory\n        \"\"\"\n        if self.assignments['potentials'] is not None:\n            print('Potentials already imported. Will not overwrite!')\n            return\n        else:\n            self.assignments['potentials'] = {}\n\n        pot_files = sorted(glob(pot_dir + os.sep + 'pot*.dat'))\n        for nr, filename in enumerate(pot_files):\n            with open(filename, 'r') as fid:\n                pot_data = np.loadtxt(fid)\n\n                nids = self.nodeman.add_data(\n                    pot_data[:, 2:4],\n                )\n                # store cids for later retrieval\n                self.assignments['potentials'][nr] = nids"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the potential data for a given measurement configuration.", "response": "def get_potential(self, config_nr):\n        \"\"\"Return potential data for a given measurement configuration.\n\n        Parameters\n        ----------\n        config_nr: int\n            Number of the configurations. Starts at 0\n\n        Returns\n        -------\n        pot_data: list with two numpy.ndarrays\n            First array: magnitude potentials, second array: phase potentials\n\n        \"\"\"\n        if self.assignments['potentials'] is None:\n            self._check_state()\n            if self.can_model:\n                self.model(potentials=True)\n\n        nids = self.assignments['potentials'][config_nr]\n        pot_data = [self.nodeman.nodevals[nid] for nid in nids]\n        return pot_data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_sensitivity(self, config_nr):\n        if self.assignments['sensitivities'] is None:\n            self._check_state()\n            if self.can_model:\n                self.model(sensitivities=True)\n        cids = self.assignments['sensitivities'][config_nr]\n        sens_data = [self.parman.parsets[cid] for cid in cids]\n        meta_data = [self.parman.metadata[cid] for cid in cids]\n\n        return sens_data, meta_data", "response": "return a sensitivity as well as corresponding metadata for a given taxonomy configuration. Indices start at zero."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a nice looking plot of the sensitivity distribution for the current locale.", "response": "def plot_sensitivity(self, config_nr=None, sens_data=None,\n                         mag_only=False, absv=False,\n                         **kwargs):\n        \"\"\"Create a nice looking plot of the sensitivity distribution for the\n        given configuration nr. Configs start at 1!\n\n        Parameters\n        ----------\n        config_nr : int, optional\n            The configuration number (starting with 0) to compute the\n            sensitivity for.\n        sens_data : Nx2 numpy.ndarray, optional\n            If provided, use this data as sensitivity data (do not compute\n            anything)\n        mag_only : bool, optional\n            Plot only the magnitude sensitivities\n        absv : bool, optional\n            If true, plot absolute values of sensitivity\n\n        Returns\n        -------\n        fig\n        ax\n\n        Examples\n        --------\n\n        .. plot::\n\n            import crtomo.debug\n            import crtomo\n            grid = crtomo.debug.get_grid(key=20)\n            td = crtomo.tdMan(grid=grid)\n            td.configs.add_to_configs([1, 5, 9, 13])\n            cid_mag, cid_pha = td.add_homogeneous_model(25, 0)\n            td.register_forward_model(cid_mag, cid_pha)\n            td.model(sensitivities=True)\n            fig, axes = td.plot_sensitivity(0)\n            fig.tight_layout()\n            fig.savefig('sens_plot.pdf', bboch_inches='tight')\n\n        \"\"\"\n\n        def _rescale_sensitivity(sens_data):\n            norm_value = np.abs(sens_data).max()\n            sens_normed = sens_data / norm_value\n\n            indices_gt_zero = sens_data > 1e-5\n            indices_lt_zero = sens_data < -1e-5\n\n            # map all values greater than zero to the range [0.5, 1]\n            x = np.log10(sens_normed[indices_gt_zero])\n            # log_norm_factor = np.abs(x).max()\n            log_norm_factor = -5\n            y1 = 1 - x / (2 * log_norm_factor)\n\n            # map all values smaller than zero to the range [0, 0.5]\n            x = np.log10(np.abs(sens_normed[indices_lt_zero]))\n            y = x / (2 * log_norm_factor)\n\n            y2 = np.abs(y)\n\n            # reassign values\n            sens_data[:] = 0.5\n            sens_data[indices_gt_zero] = y1\n            sens_data[indices_lt_zero] = y2\n            return sens_data\n\n        assert config_nr is not None or sens_data is not None\n        assert not (config_nr is not None and sens_data is not None)\n\n        if config_nr is not None:\n            cids = self.assignments['sensitivities'][config_nr]\n\n            sens_mag = self.parman.parsets[cids[0]]\n            sens_pha = self.parman.parsets[cids[1]]\n        else:\n            sens_mag = sens_data[:, 0]\n            sens_pha = sens_data[:, 1]\n\n        if absv:\n            sens_mag = np.log10(np.abs(sens_mag) / np.abs(sens_mag).max())\n            sens_pha = np.log10(np.abs(sens_pha) / np.abs(sens_pha).max())\n            cbmin = sens_mag.min()\n            cbmax = sens_mag.max()\n        else:\n            _rescale_sensitivity(sens_mag)\n            _rescale_sensitivity(sens_pha)\n            cbmin = 0\n            cbmax = 1\n\n        cmap_jet = matplotlib.cm.get_cmap('jet')\n        colors = [cmap_jet(i) for i in np.arange(0, 1.1, 0.1)]\n        cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\n            'jetn9', colors, N=9)\n        over = kwargs.get('over', 'orange')\n        under = kwargs.get('under', 'cyan')\n        bad = kwargs.get('bad', 'white')\n        cmap.set_over(over)\n        cmap.set_under(under)\n        cmap.set_bad(bad)\n        if mag_only:\n            Nx = 1\n        else:\n            Nx = 2\n\n        fig, axes = plt.subplots(1, Nx, figsize=(15 / 2.54, 12 / 2.54))\n        axes = np.atleast_1d(axes)\n        # magnitude\n        ax = axes[0]\n        cid = self.parman.add_data(sens_mag)\n        fig, ax, cnorm, cmap, cb, sM = self.plot.plot_elements_to_ax(\n            cid=cid,\n            ax=ax,\n            plot_colorbar=True,\n            # cmap_name='seismic',\n            cmap_name='jet_r',\n            cbsegments=18,\n            cbmin=cbmin,\n            cbmax=cbmax,\n            bad='white',\n            # cbmin=-cblim,\n            # cbmax=cblim,\n            # converter=converter_pm_log10,\n            # norm = colors.SymLogNorm(\n            #     linthresh=0.03,\n            #     linscale=0.03,\n            #     vmin=-1.0,\n            #     vmax=1.0\n            # ),\n            # xmin=-0.25,\n            # xmax=10,\n            # zmin=-2,\n        )\n        if not absv:\n            cb.set_ticks([0, 0.25, 0.5, 0.75, 1])\n            cb.set_ticklabels([\n                '-1',\n                r'$-10^{-2.5}$',\n                '0',\n                r'$10^{-2.5}$',\n                '1',\n            ])\n\n        # self.plot.plot_elements_to_ax(\n        #     cid=cids[0],\n        #     ax=ax,\n        # )\n\n        if not mag_only:\n            cid = self.parman.add_data(sens_pha)\n            # plot phase\n            ax = axes[1]\n            fig, ax, cnorm, cmap, cb, sM = self.plot.plot_elements_to_ax(\n                cid=cid,\n                ax=ax,\n                plot_colorbar=True,\n                # cmap_name='seismic',\n                cmap_name='jet_r',\n                cbsegments=18,\n                cbmin=cbmin,\n                cbmax=cbmax,\n                bad='white',\n            )\n            if not absv:\n                cb.set_ticks([0, 0.25, 0.5, 0.75, 1])\n                cb.set_ticklabels([\n                    '-1',\n                    r'$-10^{-2.5}$',\n                    '0',\n                    r'$10^{-2.5}$',\n                    '1',\n                ])\n\n        fig.tight_layout()\n\n        return fig, axes"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef read_voltages(self, voltage_file):\n\n        measurements_raw = np.loadtxt(\n            voltage_file,\n            skiprows=1,\n        )\n        measurements = np.atleast_2d(measurements_raw)\n\n        # extract measurement configurations\n        A = (measurements[:, 0] / 1e4).astype(int)\n        B = (measurements[:, 0] % 1e4).astype(int)\n        M = (measurements[:, 1] / 1e4).astype(int)\n        N = (measurements[:, 1] % 1e4).astype(int)\n        ABMN = np.vstack((A, B, M, N)).T\n\n        if self.configs.configs is None:\n            self.configs.configs = ABMN\n        else:\n            # configurations don't match\n            if not np.all(ABMN == self.configs.configs):\n                for nr, (old_config, new_config) in enumerate(zip(\n                        self.configs.configs, ABMN)):\n\n                    if np.all(old_config == new_config):\n                        continue\n                    # check polarity\n                    current_electrodes_are_equal = np.all(\n                        old_config[0:2] == new_config[0:2]\n                    )\n                    voltage_electrodes_are_switched = np.all(\n                        old_config[2:4] == new_config[4:1:-1]\n                    )\n\n                    if(current_electrodes_are_equal and\n                       voltage_electrodes_are_switched):\n\n                        if len(self.configs.measurements.keys()) > 0:\n                            raise Exception(\n                                'need to switch electrode polarity, but ' +\n                                'there are already measurements stored for ' +\n                                'the old configuration!')\n                        else:\n                            # switch M/N in configurations\n                            self.configs.configs[nr, :] = new_config\n                    else:\n                        raise Exception(\n                            'There was an error matching configurations of ' +\n                            'voltages with configurations already imported'\n                        )\n\n        # add measurements to the config instance\n        mid_mag = self.configs.add_measurements(\n            measurements[:, 2]\n        )\n        mid_pha = self.configs.add_measurements(\n            measurements[:, 3]\n        )\n\n        self.assignments['measurements'] = [mid_mag, mid_pha]", "response": "import voltages from a volt. dat file"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef model(self,\n              voltages=True,\n              sensitivities=False,\n              potentials=False,\n              output_directory=None,\n              silent=False,\n              ):\n        \"\"\"Forward model the tomodir and read in the results\n        \"\"\"\n        self._check_state()\n        if self.can_model:\n            if output_directory is not None:\n                if not os.path.isdir(output_directory):\n                    os.makedirs(output_directory)\n                    tempdir = output_directory\n                    self._model(voltages, sensitivities, potentials, tempdir)\n                else:\n                    raise IOError(\n                        'output directory already exists: {0}'.format(\n                            output_directory\n                        )\n                    )\n            else:\n                with tempfile.TemporaryDirectory(dir=self.tempdir) as tempdir:\n                    self._model(\n                        voltages, sensitivities, potentials, tempdir,\n                        silent=silent\n                    )\n\n            return 1\n        else:\n            print('Sorry, not all required information to model are present')\n            print('Check:')\n            print('1) configurations present: self.configs.configs')\n            print('2) is a model present')\n            return None", "response": "Forward model the tomodir and read in the results"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _invert(self, tempdir, catch_output=True, **kwargs):\n        nr_cores = kwargs.get('cores', 2)\n        print('attempting inversion in directory: {0}'.format(tempdir))\n        pwd = os.getcwd()\n        os.chdir(tempdir)\n\n        self.save_to_tomodir('.')\n        os.chdir('exe')\n        binary = CRBin.get('CRTomo')\n        print('Using binary: {0}'.format(binary))\n        print('calling CRTomo')\n        # store env variable\n        env_omp = os.environ.get('OMP_NUM_THREADS', '')\n        os.environ['OMP_NUM_THREADS'] = '{0}'.format(nr_cores)\n        if catch_output:\n            subprocess.check_output(\n                binary,\n                shell=True,\n                stderr=subprocess.STDOUT,\n            )\n        else:\n            subprocess.call(\n                binary,\n                shell=True,\n            )\n        # reset environment variable\n        os.environ['OMP_NUM_THREADS'] = env_omp\n\n        print('finished')\n\n        os.chdir(pwd)\n        self.read_inversion_results(tempdir)", "response": "Internal function than runs an inversion using the CRTomo binary."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef invert(self, output_directory=None, catch_output=True, **kwargs):\n        self._check_state()\n        if self.can_invert:\n            if output_directory is not None:\n                if not os.path.isdir(output_directory):\n                    os.makedirs(output_directory)\n                    tempdir = output_directory\n                    self._invert(tempdir, catch_output, **kwargs)\n                else:\n                    raise IOError(\n                        'output directory already exists: {0}'.format(\n                            output_directory\n                        )\n                    )\n            else:\n                with tempfile.TemporaryDirectory(dir=self.tempdir) as tempdir:\n                    self._invert(tempdir, catch_output, **kwargs)\n\n            return 0\n        else:\n            print(\n                'Sorry, no measurements present, cannot model yet'\n            )\n            return 1", "response": "Invert this instance and import the result files."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nimporting inversion results from a tomodir into this instance", "response": "def read_inversion_results(self, tomodir):\n        \"\"\"Import inversion results from a tomodir into this instance\n\n        WARNING: Not finished!\n        \"\"\"\n        self._read_inversion_results(tomodir)\n        self._read_inv_ctr(tomodir)\n        self._read_resm_m(tomodir)\n        self._read_eps_ctr(tomodir)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _read_inversion_results(self, tomodir):\n        basedir = tomodir + os.sep + 'inv' + os.sep\n        print(basedir)\n        inv_mag = sorted(glob(basedir + 'rho*.mag'))\n        inv_pha = sorted(glob(basedir + 'rho*.pha'))\n        inv_sig = sorted(glob(basedir + 'rho*.sig'))\n\n        assert len(inv_mag) == len(inv_pha)\n        assert len(inv_mag) == len(inv_sig)\n\n        pids_mag = [self.parman.load_inv_result(filename) for filename in\n                    inv_mag]\n        pids_pha = [self.parman.load_inv_result(filename) for filename in\n                    inv_pha]\n        pids_sig = [self.parman.load_inv_result(filename, columns=[0, 1]) for\n                    filename in inv_sig]\n        self.assignments['inversion'] = {\n            'rmag': pids_mag,\n            'rpha': pids_pha,\n            'cre_cim': pids_sig,\n        }", "response": "Read inversion results from the tomodir and store them in self. assignments."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef plot_eps_data_hist(self, dfs):\n        # check if this is a DC inversion\n        if 'datum' in dfs[0]:\n            dc_inv = True\n        else:\n            dc_inv = False\n\n        nr_y = len(dfs)\n        size_y = 5 / 2.54 * nr_y\n        if dc_inv:\n            nr_x = 1\n        else:\n            nr_x = 3\n        size_x = 15 / 2.54\n\n        fig, axes = plt.subplots(nr_y, nr_x, figsize=(size_x, size_y))\n        axes = np.atleast_2d(axes)\n\n        # plot initial data errors\n        df = dfs[0]\n        if dc_inv:\n            ax = axes[0, 0]\n            ax.hist(\n                df['datum'] / df['eps_r'],\n                100,\n            )\n            ax.set_xlabel(r'$-log(|R|) / \\epsilon_r$')\n            ax.set_ylabel(r'count')\n        else:\n            # complex inversion\n            ax = axes[0, 0]\n            ax.hist(\n                df['-log(|R|)'] / df['eps'],\n                100,\n            )\n            ax.set_xlabel(r'$-log(|R|)$')\n            ax.set_ylabel(r'count')\n\n            ax = axes[0, 1]\n            ax.hist(\n                df['-log(|R|)'] / df['eps_r'],\n                100,\n            )\n            ax.set_xlabel(r'$-log(|R|) / \\epsilon_r$')\n            ax.set_ylabel(r'count')\n\n            ax = axes[0, 2]\n            phase_data = df['-Phase(rad)'] / df['eps_p']\n            if not np.all(np.isinf(phase_data) | np.isnan(phase_data)):\n                ax.hist(\n                    phase_data,\n                    100,\n                )\n            ax.set_xlabel(r'$-\\phi[rad] / \\epsilon_p$')\n            ax.set_ylabel(r'count')\n\n        # iterations\n        for it, df in enumerate(dfs[1:]):\n            ax = axes[1 + it, 0]\n            ax.hist(\n                df['psi'],\n                100\n            )\n            rms = np.sqrt(\n                1 / df['psi'].shape[0] *\n                np.sum(\n                    df['psi'] ** 2\n                )\n            )\n            ax.axvline(rms, color='k', linestyle='dashed')\n            ax.set_title('iteration: {0}'.format(it))\n            ax.set_xlabel('psi')\n            ax.set_ylabel(r'count')\n\n            ax = axes[1 + it, 1]\n            Rdat = df['Re(d)']\n            Rmod = df['Re(f(m))']\n\n            ax.scatter(\n                Rdat,\n                Rmod,\n            )\n            ax.set_xlabel(r'$log(R_{data}~[\\Omega])$')\n            ax.set_ylabel(r'$log(R_{mod}~[\\Omega])$')\n\n            ax = axes[1 + it, 2]\n            phidat = df['Im(d)']\n            phimod = df['Im(f(m))']\n\n            ax.scatter(\n                phidat,\n                phimod,\n            )\n            ax.set_xlabel(r'$\\phi_{data}~[mrad]$')\n            ax.set_ylabel(r'$\\phi_{mod}~[mrad]$')\n\n        fig.tight_layout()\n        fig.savefig('eps_plot_hist.png', dpi=300)", "response": "Plot histograms of data residuals and data error weighting and weighting of the data."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _read_eps_ctr(tomodir):\n        epsctr_file = tomodir + os.sep + 'inv' + os.sep + 'eps.ctr'\n        if not os.path.isfile(epsctr_file):\n            print('eps.ctr not found: {0}'.format(epsctr_file))\n            print(os.getcwd())\n            return 1\n\n        with open(epsctr_file, 'r') as fid:\n            lines = fid.readlines()\n        group = itertools.groupby(lines, lambda x: x == '\\n')\n        dfs = []\n        # group\n        for x in group:\n            # print(x)\n            if not x[0]:\n                data = [y for y in x[1]]\n                if data[0].startswith('IT') or data[0].startswith('PIT'):\n                    del(data[0])\n                data[0] = data[0].replace('-Phase (rad)', '-Phase(rad)')\n                tfile = StringIO(''.join(data))\n                df = pd.read_csv(\n                    tfile,\n                    delim_whitespace=True,\n                    na_values=['Infinity'],\n                )\n                dfs.append(df)\n        return dfs", "response": "Parse a CRTomo eps. ctr file and return a pandas DataFrame"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread in selected results of the inv. ctr file and return a dictionary containing the result.", "response": "def _read_inv_ctr(self, tomodir):\n        \"\"\"Read in selected results of the inv.ctr file\n\n        Parameters\n        ----------\n        tomodir: string\n            directory path to a tomodir\n\n        Returns\n        -------\n        inv_ctr:    ?\n            structure containing inv.ctr data\n\n        \"\"\"\n        invctr_file = tomodir + os.sep + 'inv' + os.sep + 'inv.ctr'\n        if not os.path.isfile(invctr_file):\n            print('inv.ctr not found: {0}'.format(invctr_file))\n            print(os.getcwd())\n            return 1\n\n        # read header\n        with open(invctr_file, 'r') as fid:\n            lines = fid.readlines()\n\n        # check for robust inversion\n        is_robust_inversion = False\n        nr_of_data_points = None\n        for i, line in enumerate(lines):\n            if line.startswith('***PARAMETERS***'):\n                raw_value = lines[i + 7].strip()[0]\n                if raw_value == 'T':\n                    is_robust_inversion = True\n            if line.startswith('# Data points'):\n                nr_of_data_points = int(line[15:].strip())\n\n        print('is robust', is_robust_inversion)\n\n        # find section that contains the iteration data\n        for i, line in enumerate(lines):\n            if line.strip().startswith('ID it.'):\n                break\n\n        # TODO: check for robust iteration\n\n        # we have three types of lines:\n        # 1. first iteration line\n        # 2. other main iteration lines\n        # 3. update lines\n\n        # prepare regular expressions for these three types, each in two\n        # flavors: robust and non-robust\n\n        \"\"\"\n! first iteration, robust\n100 FORMAT (t1,a3,t5,i3,t11,g10.4,t69,g10.4,t81,g10.4,t93,i4,t105,g9.3)\n! first iteration, non-robust\n101 FORMAT (t1,a3,t5,i3,t11,g10.4,t69,g10.4,t81,g10.4,t93,i4)\n\n! other iterations, robust\n110 FORMAT (t1,a3,t5,i3,t11,g10.4,t23,g10.4,t34,g10.4,t46,g10.4,t58,&\ni6,t69,g10.4,t81,g10.4,t93,i4,t105,g9.3,t117,f5.3)\n! other iterations, non-robust\n111 FORMAT (t1,a3,t5,i3,t11,g10.4,t23,g10.4,t34,g10.4,t46,g10.4,t58,&\ni6,t69,g10.4,t81,g10.4,t93,i4,t105,f5.3)\n\n! update iterations, non-robust\n105 FORMAT (t1,a3,t5,i3,t11,g10.4,t23,g9.3,t34,g10.4,t46,g10.4,t58,&\ni6,t105,f5.3)\n! update iterations, robust\n106 FORMAT (t1,a3,t5,i3,t11,g10.4,t23,g9.3,t34,g10.4,t46,g10.4,t58,&\ni6,t105,g9.3,t117,f5.3)\n\n        \"\"\"\n\n        # this identifies a float number, or a NaN value\n        reg_float = ''.join((\n            '((?:[-+]?(?:\\d+(?:\\.\\d*)?|\\.\\d+)(?:[eE][-+]?\\d+)?)',\n            '|',\n            '(?:NaN))'\n        ))\n\n        reg_int = '(\\d{1,3})'\n\n        # (t1,a3,t5,i3,t11,g10.4,t69,g10.4,t81,g10.4,t93,i4)\n        # first iteration line of non-robust inversion\n        reg_it1_norob = ''.join((\n            '([a-zA-Z]{1,3})',\n            ' *' + reg_int,\n            ' *' + reg_float,\n            ' *' + reg_float,\n            ' *' + reg_float,\n            ' *' + reg_int,\n        ))\n        # first iteration line of robust inversion\n        reg_it1_robust = ''.join((\n            '([a-zA-Z]{1,3})',\n            ' *(\\d{1,3})',\n            ' *' + reg_float,   # data RMS\n            ' *' + reg_float,   # mag RMS\n            ' *' + reg_float,   # pha RMS\n            ' *' + reg_int,     # nr excluded data\n            ' *' + reg_float,   # L1-ratio\n        ))\n\n        # second-to-last iterations, robust\n        reg_it2plus_rob = ''.join((\n            '([a-zA-Z]{1,3})',\n            ' *(\\d{1,3})',\n            ' *' + reg_float,   # data RMS\n            ' *' + reg_float,   # stepsize\n            ' *' + reg_float,   # lambda\n            ' *' + reg_float,   # roughness\n            ' *' + reg_int,     # CG-steps\n            ' *' + reg_float,   # mag RMS\n            ' *' + reg_float,   # pha RMS\n            ' *' + reg_int,     # nr excluded data\n            ' *' + reg_float,   # l1-ratio\n            ' *' + reg_float,   # steplength\n        ))\n\n        # second-to-last iterations, non-robustk\n        # (t1,a3,t5,i3,t11,g10.4,t23,g10.4,t34,g10.4,t46,g10.4,t58,&\n        # i6,t69,g10.4,t81,g10.4,t93,i4,t105,f5.3)\n        reg_it2plus_norob = ''.join((\n            '([a-zA-Z]{1,3})',\n            ' *(\\d{1,3})',\n            ' *' + reg_float,   # data RMS\n            ' *' + reg_float,   # stepsize\n            ' *' + reg_float,   # lambda\n            ' *' + reg_float,   # roughness\n            ' *' + reg_int,     # CG-steps\n            ' *' + reg_float,   # mag RMS\n            ' *' + reg_float,   # pha RMS\n            ' *' + reg_int,     # nr excluded data\n            ' *' + reg_float,   # steplength\n        ))\n\n        # update robust\n        reg_update_rob = ''.join((\n            '([a-zA-Z]{1,3})',\n            ' *(\\d{1,3})',\n            ' *' + reg_float,  # data RMS\n            ' *' + reg_float,  # stepsize\n            ' *' + reg_float,  # lambda\n            ' *' + reg_float,  # roughness\n            ' *' + reg_int,  # CG-steps\n            ' *' + reg_float,  # l1ratio\n        ))\n        # update non-robust\n        reg_update_norob = ''.join((\n            '([a-zA-Z]{1,3})',\n            ' *(\\d{1,3})',\n            ' *' + reg_float,  # data RMS\n            ' *' + reg_float,  # stepsize\n            ' *' + reg_float,  # lambda\n            ' *' + reg_float,  # roughness\n            ' *' + reg_int,  # CG-steps\n            ' *' + reg_float,  # steplength\n        ))\n\n        # iteration counter\n        current_iteration = 0\n        iterations = []\n\n        for line in lines[i:]:\n            linec = line.strip()\n            if linec.startswith('IT') or linec.startswith('PIT'):\n                if linec[0:3].strip() == 'IT':\n                    it_type = 'DC/IP'\n                else:\n                    it_type = 'FPI'\n\n                values = None\n\n                # main iterations\n                if is_robust_inversion:\n                    if current_iteration == 0:\n                        # first iteration, robust\n                        g = re.compile(reg_it1_robust).search(linec).groups()\n                        keyfuncs = [\n                            (None, None),\n                            ('iteration', int),\n                            ('dataRMS', float),\n                            ('magRMS', float),\n                            ('phaRMS', float),\n                            ('nrdata', int),\n                            ('l1ratio', float),\n                        ]\n                        values = {}\n                        for value, (key, func) in zip(g, keyfuncs):\n                            if key is not None:\n                                values[key] = func(value)\n                    else:\n                        # second-to-last iterations, robust\n                        g = re.compile(\n                            reg_it2plus_rob\n                        ).search(linec).groups()\n                        keyfuncs = [\n                            (None, None),\n                            ('iteration', int),\n                            ('dataRMS', float),\n                            ('stepsize', float),\n                            ('lambda', float),\n                            ('roughness', float),\n                            ('cgsteps', int),\n                            ('magRMS', float),\n                            ('phaRMS', float),\n                            ('nrdata', int),\n                            ('l1ratio', float),\n                            ('steplength', float),\n                        ]\n                        values = {}\n                        for value, (key, func) in zip(g, keyfuncs):\n                            if key is not None:\n                                values[key] = func(value)\n                    values['type'] = 'main'\n                    values['main_iteration'] = current_iteration\n                    values['it_type'] = it_type\n                    iterations.append(values)\n                    current_iteration += 1\n                else:\n                    if current_iteration == 0:\n                        # non-robust, first iteration\n                        g = re.compile(reg_it1_norob).search(linec).groups()\n\n                        keyfuncs = [\n                            (None, None),\n                            ('iteration', int),\n                            ('dataRMS', float),\n                            ('magRMS', float),\n                            ('phaRMS', float),\n                            ('nrdata', int)\n                        ]\n                        values = {}\n                        for value, (key, func) in zip(g, keyfuncs):\n                            if key is not None:\n                                values[key] = func(value)\n                    else:\n                        g = re.compile(\n                            reg_it2plus_norob\n                        ).search(linec).groups()\n                        keyfuncs = [\n                            (None, None),\n                            ('iteration', int),\n                            ('dataRMS', float),\n                            ('stepsize', float),\n                            ('lambda', float),\n                            ('roughness', float),\n                            ('cgsteps', int),\n                            ('magRMS', float),\n                            ('phaRMS', float),\n                            ('nrdata', int),\n                            ('steplength', float),\n                        ]\n                        values = {}\n                        for value, (key, func) in zip(g, keyfuncs):\n                            if key is not None:\n                                values[key] = func(value)\n                    values['type'] = 'main'\n                    values['it_type'] = it_type\n                    values['main_iteration'] = current_iteration\n                    iterations.append(values)\n                    current_iteration += 1\n            elif linec.startswith('UP'):\n                # update iterations\n                if is_robust_inversion:\n                    # robust\n                    g = re.compile(\n                        reg_update_rob\n                    ).search(linec).groups()\n                    keyfuncs = [\n                        (None, None),\n                        ('iteration', int),\n                        ('dataRMS', float),\n                        ('stepsize', float),\n                        ('lambda', float),\n                        ('roughness', float),\n                        ('cgsteps', int),\n                        ('l1-ratio', float),\n                    ]\n                    values = {}\n                    for value, (key, func) in zip(g, keyfuncs):\n                        if key is not None:\n                            values[key] = func(value)\n                else:\n                    g = re.compile(\n                        reg_update_norob\n                    ).search(linec).groups()\n                    keyfuncs = [\n                        (None, None),\n                        ('iteration', int),\n                        ('dataRMS', float),\n                        ('stepsize', float),\n                        ('lambda', float),\n                        ('roughness', float),\n                        ('cgsteps', int),\n                        ('steplength', float),\n                    ]\n                    values = {}\n                    for value, (key, func) in zip(g, keyfuncs):\n                        if key is not None:\n                            values[key] = func(value)\n                values['type'] = 'update'\n                values['it_type'] = it_type\n                values['main_iteration'] = current_iteration\n                iterations.append(values)\n\n        df = pd.DataFrame(iterations)\n        df = df.reindex_axis([\n            'iteration',\n            'main_iteration',\n            'it_type',\n            'type',\n            'dataRMS',\n            'magRMS',\n            'phaRMS',\n            'lambda',\n            'roughness',\n            'cgsteps',\n            'nrdata',\n            'steplength',\n            'stepsize',\n            'l1ratio',\n        ], axis=1)\n\n        df['nrdata'] = nr_of_data_points - df['nrdata']\n        return df"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading in the resolution matrix of an inversion of a tomodir.", "response": "def _read_resm_m(self, tomodir):\n        \"\"\"Read in the resolution matrix of an inversion\n\n        Parameters\n        ----------\n        tomodir: string\n            directory path to a tomodir\n\n        \"\"\"\n        resm_file = tomodir + os.sep + 'inv' + os.sep + 'res_m.diag'\n        if not os.path.isfile(resm_file):\n            print('res_m.diag not found: {0}'.format(resm_file))\n            print(os.getcwd())\n            return 1\n\n        # read header\n        with open(resm_file, 'rb') as fid:\n            first_line = fid.readline().strip()\n            header_raw = np.fromstring(first_line, count=4, sep=' ')\n            header_raw\n            # nr_cells = int(header_raw[0])\n            # lam = float(header_raw[1])\n\n            subdata = np.genfromtxt(fid)\n            print(subdata.shape)\n            pid = self.parman.add_data(subdata[:, 0])\n            self.assignments['resm'] = pid"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nregisters measurements as magnitude and phase measurements used for the inversion of the current object.", "response": "def register_measurements(self, mag, pha=None):\n        \"\"\"Register measurements as magnitude/phase measurements used for the\n        inversion\n\n        Parameters\n        ----------\n        mag: int|numpy.ndarray\n            magnitude measurement id for the corresponding measurement data in\n            self.configs.measurements. If mag is a numpy.ndarray, assume\n            mag to be the data itself an register it\n        pha: int, optional\n            phase measurement id for the corresponding measurement data in\n            self.configs.measurements. If not present, a new measurement set\n            will be added with zeros only.\n        \"\"\"\n        if isinstance(mag, np.ndarray):\n            # make sure that this array is 1D at the most\n            # the 0 indicates only one measurement\n            assert len(mag.squeeze().shape) in (0, 1)\n            mid_mag = self.configs.add_measurements(mag)\n        else:\n            mid_mag = mag\n\n        if pha is not None:\n            if isinstance(pha, np.ndarray):\n                mid_pha = self.configs.add_measurements(pha)\n            else:\n                mid_pha = pha\n        else:\n            mid_pha = self.configs.add_measurements(\n                np.zeros_like(\n                    self.configs.measurements[mid_mag]\n                )\n            )\n        self.assignments['measurements'] = [mid_mag, mid_pha]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef register_forward_model(self, pid_mag, pid_pha):\n        self.register_magnitude_model(pid_mag)\n        self.register_phase_model(pid_pha)", "response": "Register parameter sets as the forward models for magnitude and phase"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef register_magnitude_model(self, pid):\n        if self.assignments['forward_model'] is None:\n            self.assignments['forward_model'] = [None, None]\n\n        self.assignments['forward_model'][0] = pid", "response": "Register a given parameter model as the forward magnitude model."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nregister a given parameter model as the forward phase model.", "response": "def register_phase_model(self, pid):\n        \"\"\"Set a given parameter model to the forward phase model\n        \"\"\"\n        if self.assignments['forward_model'] is None:\n            self.assignments['forward_model'] = [None, None]\n\n        self.assignments['forward_model'][1] = pid"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding a homogeneous resistivity model to the tomodir. This is useful for synthetic measurements.", "response": "def add_homogeneous_model(self, magnitude, phase=0):\n        \"\"\"Add a homogeneous resistivity model to the tomodir. This is useful\n        for synthetic measurements.\n\n        Parameters\n        ----------\n        magnitude : float\n            magnitude [Ohm m] value of the homogeneous model\n        phase : float, optional\n            phase [mrad] value of the homogeneous model\n\n\n        Returns\n        -------\n        pid_mag : int\n            ID value of the parameter set of the magnitude model\n        pid_pha : int\n            ID value of the parameter set of the phase model\n\n        Note that the parameter sets are automatically registered as the\n        forward models for magnitude and phase values.\n        \"\"\"\n        if self.assignments['forward_model'] is not None:\n            print('model already set, will overwrite')\n\n        # generate distributions\n        magnitude_model = np.ones(self.grid.nr_of_elements) * magnitude\n        phase_model = np.ones(self.grid.nr_of_elements) * phase\n        pid_mag = self.parman.add_data(magnitude_model)\n        pid_pha = self.parman.add_data(phase_model)\n\n        self.assignments['forward_model'] = [pid_mag, pid_pha]\n        return pid_mag, pid_pha"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef check_measurements_against_sensitivities(\n            self, magnitude, phase=0, return_plot=False):\n        \"\"\"Check for all configurations if the sensitivities add up to a given\n        homogeneous model\n\n        Parameters\n        ----------\n        magnitude : float\n            magnitude used for the homogeneous model\n        phase : float, optional, default=0\n            phase value used for the homogeneous model\n        return_plot : bool, optional, default=False\n            create a plot analyzing the differences\n\n        Returns\n        -------\n        results : Nx6 numpy.ndarray\n            Results of the analysis.\n\n            * magnitude measurement [Ohm]\n            * sum of sensitivities [Volt]\n            * relative deviation of sensitivity-sum from measurement [in\n              percent]\n\n        fig : matplotlib.figure, optional\n            figure object. Only returned of return_plot=True\n        axes : list\n            list of axes corresponding to the figure\n\n        Examples\n        --------\n\n        >>> #!/usr/bin/python\n            import crtomo.tdManager as CRtdMan\n            tdm = CRtdMan.tdMan(\n                    elem_file='grid/elem.dat',\n                    elec_file='grid/elec.dat',\n                    config_file='config/config.dat',\n            )\n            results, fig, axes = tdm.check_measurements_against_sensitivities(\n                    magnitude=100,\n                    phase=-10,\n                    return_plot=True\n            )\n            fig.savefig('sensitivity_comparison.png', dpi=300)\n\n        \"\"\"\n        # generate a temporary tdMan instance\n        tdm = tdMan(\n            grid=self.grid,\n            configs=self.configs,\n        )\n        tdm.add_homogeneous_model(magnitude, phase)\n        measurements = tdm.measurements()\n\n        Z = measurements[:, 0] * np.exp(1j * measurements[:, 1] / 1000)\n\n        results = []\n        for nr in range(0, tdm.configs.nr_of_configs):\n            sensitivities = tdm.get_sensitivity(nr)\n            sens_re = sensitivities[0][0]\n            sens_im = sensitivities[0][1]\n\n            sens_mag = 1.0 / measurements[nr, 0] * (\n                np.real(Z[nr]) * sens_re + np.imag(Z[nr]) * sens_im\n            )\n\n            V_mag_from_sens = sens_mag.sum() / magnitude\n            if phase != 0:\n                outer = 1 / (1 + (np.imag(Z[nr]) / np.real(Z[nr])) ** 2)\n                inner1 = - sens_re / np.real(Z[nr]) ** 2 * np.imag(Z[nr])\n                inner2 = sens_im * np.real(Z[nr])\n                sens_pha = outer * (inner1 + inner2)\n\n                V_pha_from_sens = sens_pha.sum() / phase\n            else:\n                V_pha_from_sens = None\n\n            print(\n                'WARNING: We still do not know where the minus sign comes ' +\n                'from!'\n            )\n            V_mag_from_sens *= -1\n\n            results.append((\n                measurements[nr][0],\n                V_mag_from_sens,\n                (measurements[nr][0] - V_mag_from_sens) / measurements[nr][0] *\n                100,\n                measurements[nr][1],\n                V_pha_from_sens,\n                (measurements[nr][1] - V_mag_from_sens) / measurements[nr][1] *\n                100,\n            ))\n        results = np.array(results)\n\n        if return_plot:\n            nr_x = 2\n            if phase == 0:\n                nr_x = 1\n            fig, axes = plt.subplots(1, nr_x, figsize=(15 / 2.54, 7 / 2.54))\n            fig.suptitle('Comparison sum of sensitivities to measurements')\n            # plot phase first\n            if phase != 0:\n                ax = axes[1]\n                ax.plot(results[:, 5], '.')\n                ax.set_xlabel('configuration number')\n                ax.set_ylabel(\n                    r'$\\frac{V_i^{\\mathrm{pha}} - ' +\n                    r' \\sum s_{ij}^{\\mathrm{pha}} \\cdot ' +\n                    r'\\phi_0}{V_i}~[\\%]$'\n                )\n\n                # set ax for magnitude plot\n                ax = axes[0]\n            else:\n                ax = axes\n\n            ax.plot(results[:, 2], '.')\n            ax.set_xlabel('configuration number')\n            # ax.set_ylabel('deviation from magnitude measurement [\\%]')\n            ax.set_ylabel(\n                r'$\\frac{V_i^{\\mathrm{mag}} - ' +\n                r'\\sum s_{ij}^{\\mathrm{mag}} \\cdot ' +\n                r'\\sigma_0}{V_i}~[\\%]$'\n            )\n\n            fig.tight_layout()\n            return results, fig, axes\n        else:\n            return results", "response": "Check for all configurations and return a list of results."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nplotting a given parameter set", "response": "def show_parset(self, pid):\n        \"\"\"Plot a given parameter set\n        \"\"\"\n        fig, ax = plt.subplots()\n        self.plot.plot_elements_to_ax(pid, ax=ax)\n        return fig, ax"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef plot_forward_models(self):\n        pids_rho = self.assignments.get('forward_model', None)\n        if pids_rho is None:\n            raise Exception('you need to load the forward model first')\n        fig, axes = plt.subplots(1, 2, figsize=(16 / 2.54, 8 / 2.54))\n        ax = axes[0]\n        self.plot.plot_elements_to_ax(\n            pids_rho[0],\n            ax=ax,\n            plot_colorbar=True,\n            cblabel=r'$|\\rho| [\\Omega m]$',\n        )\n\n        ax = axes[1]\n        self.plot.plot_elements_to_ax(\n            pids_rho[1],\n            ax=ax,\n            plot_colorbar=True,\n            cblabel=r'$\\phi [mrad]$',\n        )\n        fig.tight_layout()\n        return fig, axes", "response": "Plot the forward models"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cythonize(*args, **kwargs):\n    '''\n    dirty hack, only import cythonize at the time you use it.\n\n    if you don't write Cython extension,\n    you won't fail even if you don't install Cython.\n    '''\n    global cythonize\n    from Cython.Build import cythonize\n    return cythonize(*args, **kwargs)", "response": "dirty hack to import Cython. Build and cythonize"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef mbcs_work_around():\n    '''\n    work around for mbcs codec to make \"bdist_wininst\" work\n    https://mail.python.org/pipermail/python-list/2012-February/620326.html\n    '''\n    import codecs\n    try:\n        codecs.lookup('mbcs')\n    except LookupError:\n        ascii = codecs.lookup('ascii')\n        codecs.register(lambda name: {True: ascii}.get(name == 'mbcs'))", "response": "work around for mbcs codec to make bdist_wininst work\n    https://mail. python. org / pipermail - list / 2015 - February - 620326"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconstruct API endpoint URLs using instance options in self. args and local arguments passed to the function as a dictionary argdict.", "response": "def endpoint(self, endpt, argdict=None):\n        \"\"\"\n        Construct API endpoint URLs using instance options in `self.args` \n        and local arguments passed to the function as a dictionary `argdict`.\n        \n        >>> api = BustimeAPI(\"BOGUSAPIKEY\")\n        >>> api.endpoint('VEHICLES') \n        'http://realtime.portauthority.org/bustime/api/v1/getvehicles?key=BOGUSAPIKEY&tmres=s&localestring=en_US'\n        >>> api.endpoint('PREDICTION', dict(stpid=4123, rt=\"61C\"))\n        'http://realtime.portauthority.org/bustime/api/v1/getpredictions?key=BOGUSAPIKEY&tmres=s&localestring=en_US&format=json&rt=61C&stpid=4123'\n        \"\"\"\n        \n        instanceargs = \"{}&{}\".format(queryjoin(key=self.key), queryjoin(self.args))\n        if argdict:\n            localargs = queryjoin(argdict)\n            querystring = \"{}&{}\".format(instanceargs, localargs)\n        else:    \n            querystring = instanceargs\n        return \"{}?{}\".format(self.ENDPOINTS[endpt], querystring)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngrab an API response.", "response": "def response(self, url):\n        \"\"\"Grab an API response.\"\"\"\n        \n        resp = requests.get(url).content\n        return self.parseresponse(resp)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef errorhandle(self, resp):            \n        if self.format == 'json':\n            parsed = xmltodict.parse(resp)\n            errors = parsed[self.RESPONSE_TOKEN][self.ERROR_TOKEN]\n            # Create list of errors if more than one error response is given\n            if type(errors) is list and len(errors) > 1:\n                messages = \", \".join([\" \".join([\"{}: {}\".format(k,v) for k, v in e.items()]) for e in errors])\n            else:\n                overlimit = any('transaction limit' in msg.lower() for msg in errors.values())\n                if overlimit:\n                    raise APILimitExceeded(\"This API key has used up its daily quota of calls.\")\n                else:    \n                    messages = \" \".join([\"{}: {}\".format(k,v) for k, v in errors.items()])    \n        elif self.format == 'xml':\n            import xml.etree.ElementTree as ET\n            errors = ET.fromstring(resp).findall(self.ERROR_TOKEN)\n            messages = \", \".join(err.find('msg').text for err in errors)\n        else:\n            raise ValueError(\"Invalid API response format specified: {}.\" % self.format)        \n        \n        raise BustimeError(\"API returned: {}\".format(messages))", "response": "Parse API error responses and raise appropriate exceptions."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parseresponse(self, resp):\n        # Support Python 3's bytes type from socket repsonses\n        if sys.version_info.major > 2:\n            resp = resp.decode('utf-8')\n\t\n        if self.RESPONSE_TOKEN not in resp:\n            raise BustimeError(\"The Bustime API returned an invalid response: {}\".format(resp))\n        elif self.ERROR_TOKEN in resp:\n            return self.errorhandle(resp)\n        else:\n            if self.format == 'json':\n                return xmltodict.parse(resp)[self.RESPONSE_TOKEN]\n            elif self.format == 'xml':\n                return resp", "response": "Parse an API response."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of all vehicles in a given route or by vehicle ID.", "response": "def vehicles(self, vid=None, rt=None):\n        \"\"\"\n        Get busses by route or by vehicle ID.\n        \n        Arguments: either\n            `vid`: \"Set of one or more vehicle IDs whose location should be returned.\" \n                   Maximum of 10 `vid`s, either in a comma-separated list or an iterable.\n\n            `rt`: \"Set of one or more route designators for which matching vehicles should be returned.\"\n                  Maximum of 10 routes, either in a comma-separated list or an iterable.\n                  \n        Response:\n            `vehicle`: (vehicle container) contains list of\n                `vid`: bus #\n                `tmstmp`: local date/time of vehicle update\n                `lat`, `lon`: position\n                `hdg`: vehicle heading (e.g., 0: north, 180: south)\n                `pid`: pattern ID of current trip (see `self.geopatterns`)\n                `pdist`: distance into trip\n                `rt`: route (e.g, 88)\n                `des`: bus destinations (e.g., \"Penn to Bakery Square\")\n                `dly` (optional): True if bus is delayed\n                `spd`: speed in mph\n                `zone`: current zone (usually `None` here)\n                `tablockid`, `tatripid`: unsure, seems internal?\n                \n        http://realtime.portauthority.org/bustime/apidoc/v1/main.jsp?section=vehicles.jsp\n        \"\"\"\n        \n        if vid and rt:\n            raise ValueError(\"The `vid` and `route` parameters cannot be specified simultaneously.\")\n        if not (vid or rt):\n            raise ValueError(\"You must specify either the `vid` or `rt` parameter.\")\n\n        # Turn list into comma separated string\n        if listlike(rt): rt = \",\".join( map(str, rt) )\n        if listlike(vid): vid = \",\".join( map(str, vid) )\n\n        url = self.endpoint('VEHICLES', dict(vid=vid, rt=rt))        \n        return self.response(url)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef route_directions(self, rt):\n        url = self.endpoint('R_DIRECTIONS', dict(rt=rt))\n        return self.response(url)", "response": "Returns a list of directions for a route."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of stops for a particular route.", "response": "def stops(self, rt, direction):\n        \"\"\"\n        Return a list of stops for a particular route.\n        \n        Arguments:\n            `rt`: route designator\n            `dir`: route direction (INBOUND, OUTBOUND)\n        \n        Response:\n            `stop`: (stop container) contains list of \n                `stpid`: unique ID number for bus stop\n                `stpnm`: stop name (what shows up on the display in the bus,\n                         e.g., \"Forbes and Murray\")\n                `lat`, `lng`: location of stop\n                \n        http://realtime.portauthority.org/bustime/apidoc/v1/main.jsp?section=stops.jsp        \n        \"\"\"\n        url = self.endpoint('STOPS', dict(rt=rt, dir=direction))\n        return self.response(url)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef geopatterns(self, rt=None, pid=None):\n        if rt and pid:\n            raise ValueError(\"The `rt` and `pid` parameters cannot be specified simultaneously.\")\n        if not (rt or pid):\n            ValueError(\"You must specify either the `rt` or `pid` parameter.\")\n\n        if listlike(pid): pid = \",\".join(pid)\n        \n        url = self.endpoint(\"R_GEO\", dict(rt=rt, pid=pid))            \n        \n        return self._lru_geopatterns(url)", "response": "Returns a list of geographic points that make up a particular routing."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nretrieve predictions for 1 + stops or 1 + vehicles.", "response": "def predictions(self, stpid=\"\", rt=\"\", vid=\"\", maxpredictions=\"\"):\n        \"\"\"\n        Retrieve predictions for 1+ stops or 1+ vehicles.\n        \n        Arguments:\n            `stpid`: unique ID number for bus stop (single or comma-seperated list or iterable)\n            or\n            `vid`: vehicle ID number (single or comma-seperated list or iterable)\n            or\n            `stpid` and `rt`\n            \n            `maxpredictions` (optional): limit number of predictions returned\n\n        Response:\n            `prd`: (prediction container) contains list of\n                `tmstp`: when prediction was generated\n                `typ`: prediction type ('A' = arrival, 'D' = departure)\n                `stpid`: stop ID for prediction\n                `stpnm`: stop name for prediction\n                `vid`: vehicle ID for prediction\n                `dstp`: vehicle distance to stop (feet)\n                `rt`: bus route\n                `des`: bus destination\n                `prdtm`: ETA/ETD\n                `dly`: True if bus delayed\n                `tablockid`, `tatripid`, `zone`: internal, see `self.vehicles`\n                \n        http://realtime.portauthority.org/bustime/apidoc/v1/main.jsp?section=predictions.jsp    \n        \"\"\"\n        \n        if (stpid and vid) or (rt and vid):\n            raise ValueError(\"These parameters cannot be specified simultaneously.\")\n        elif not (stpid or rt or vid):\n            raise ValueError(\"You must specify a parameter.\")   \n        \n        if listlike(stpid): stpid = \",\".join(stpid)\n        if listlike(rt): rt = \",\".join(rt)\n        if listlike(vid): vid = \",\".join(vid)\n                 \n        if stpid or (rt and stpid) or vid:\n            url = self.endpoint('PREDICTION', dict(rt=rt, stpid=stpid, vid=vid, top=maxpredictions))\n            return self.response(url)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a list of service alerts for a given route or stop.", "response": "def bulletins(self, rt=\"\", rtdir=\"\", stpid=\"\"):\n        \"\"\"\n        Return list of service alerts ('bulletins') for a route or stop.\n        \n        Arguments:\n            `rt`: route designator\n            or\n            `stpid`: bus stop number\n            or (`rt` and `rtdir`) or (`rt` and `rtdir` and `stpid`)\n        \n        Response:\n             `sb`: (bulletin container) contains list of\n                 `nm`: bulletin name/ID\n                 `sbj`: bulletin subject\n                 `dtl`: full text and/or\n                 `brf`: short text\n                 `prty`: priority (high, medium, low) \n                 `srvc`: (routes bulletin applies to) contains list of \n                     `rt`: route designator\n                     `rtdir`: route direction\n                     `stpid`: bus stop ID number\n                     `stpnm`: bus stop name\n        \n        http://realtime.portauthority.org/bustime/apidoc/v1/main.jsp?section=serviceBulletins.jsp\n        \"\"\"\n        \n        if not (rt or stpid) or (rtdir and not (rt or stpid)):\n            raise ValueError(\"You must specify a parameter.\")   \n\n        if listlike(stpid): stpid = \",\".join(stpid)\n        if listlike(rt): rt = \",\".join(rt)\n        \n        url = self.endpoint('BULLETINS', dict(rt=rt, rtdir=rtdir, stpid=stpid))    \n        return self.response(url)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_stack_refs(refs: list):  # copy pasted from Senza\n    refs = list(refs)\n    refs.reverse()\n    stack_refs = []\n    last_stack = None\n    while refs:\n        ref = refs.pop()\n        if last_stack is not None and re.compile(r'v[0-9][a-zA-Z0-9-]*$').match(ref):\n            stack_refs.append(StackReference(last_stack, ref))\n        else:\n            try:\n                with open(ref) as fd:\n                    data = yaml.safe_load(fd)\n                ref = data['SenzaInfo']['StackName']\n            except (OSError, IOError):\n                # It's still possible that the ref is a regex\n                pass\n\n            if refs:\n                version = refs.pop()\n            else:\n                version = None\n            stack_refs.append(StackReference(ref, version))\n            last_stack = ref\n    return stack_refs", "response": "Returns a list of stack references with name and version."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef prior_model_tuples(self):\n        return list(filter(lambda t: isinstance(t[1], AbstractPriorModel), self.__dict__.items()))", "response": "Returns a list of tuples containing the prior model names and their corresponding PriorModel instances."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef list_prior_model_tuples(self):\n        return list(filter(lambda t: isinstance(t[1], CollectionPriorModel), self.__dict__.items()))", "response": "Returns a list of tuples containing the names of the prior models for this object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of tuples with the names of prior models and associated prior models.", "response": "def flat_prior_model_tuples(self):\n        \"\"\"\n        Returns\n        -------\n        prior_model_tuples: [(String, PriorModel)]\n            A list of tuples with the names of prior models and associated prior models. Names are fully qualified by\n            all objects in which they are embedded.\n        \"\"\"\n        return [(\"{}\".format(prior_model_name), flat_prior_model) for\n                prior_model_name, prior_model in\n                self.prior_model_tuples for\n                flat_prior_model_name, flat_prior_model in\n                prior_model.flat_prior_model_tuples]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef prior_tuples(self):\n        return {prior_tuple.prior: prior_tuple\n                for name, prior_model in self.prior_model_tuples\n                for prior_tuple in prior_model.prior_tuples}.values()", "response": "Returns a dictionary of priors associated with this mapper."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef constant_tuple_dict(self):\n        return {constant_tuple.constant: constant_tuple\n                for name, prior_model in self.prior_model_tuples\n                for constant_tuple in prior_model.constant_tuples}.values()", "response": "Returns a dictionary of all constants associated with this mapper."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef prior_tuples_ordered_by_id(self):\n        return sorted(list(self.prior_tuples), key=lambda prior_tuple: prior_tuple.prior.id)", "response": "Returns an ordered list of priors associated with this mapper\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef constant_tuples_ordered_by_id(self):\n        return sorted(list(self.constant_tuple_dict), key=lambda constant_tuple: constant_tuple.constant.id)", "response": "Returns a list of tuples mapping strings to Constant objects ordered by id"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef prior_prior_model_dict(self):\n        return {prior: prior_model[1] for prior_model in self.prior_model_tuples for _, prior in\n                prior_model[1].prior_tuples}", "response": "Returns a dictionary mapping priors to associated prior models."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef prior_model_name_prior_tuples_dict(self):\n        return {name: list(prior_model.prior_tuples) for name, prior_model in self.prior_model_tuples}", "response": "Returns a dictionary mapping the names of priors to lists of associated priors."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef prior_model_name_constant_tuples_dict(self):\n        return {name: list(prior_model.constant_tuples) for name, prior_model in self.prior_model_tuples}", "response": "Returns a dictionary mapping the names of priors to lists of associated constants."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef physical_vector_from_hypercube_vector(self, hypercube_vector):\n        return list(\n            map(lambda prior_tuple, unit: prior_tuple.prior.value_for(unit), self.prior_tuples_ordered_by_id,\n                hypercube_vector))", "response": "Returns a list of physical vector values for the given hypercube vector."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef physical_values_ordered_by_class(self, hypercube_vector):\n        model_instance = self.instance_from_unit_vector(hypercube_vector)\n        result = []\n        for instance_key in sorted(model_instance.__dict__.keys()):\n            instance = model_instance.__dict__[instance_key]\n            for attribute_key in sorted(instance.__dict__.keys()):\n\n                value = instance.__dict__[attribute_key]\n\n                if isinstance(value, tuple):\n                    result.extend(list(value))\n                else:\n                    result.append(value)\n        return result", "response": "Returns a list of all the values in the associated object that are in the same class as the given hypercube vector."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef instance_from_unit_vector(self, unit_vector):\n        arguments = dict(\n            map(lambda prior_tuple, unit: (prior_tuple.prior, prior_tuple.prior.value_for(unit)),\n                self.prior_tuples_ordered_by_id, unit_vector))\n\n        return self.instance_for_arguments(arguments)", "response": "This method creates a ModelInstance from a unit vector of parameter values."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a ModelInstance from a vector of parameter values.", "response": "def instance_from_physical_vector(self, physical_vector):\n        \"\"\"\n        Creates a ModelInstance, which has an attribute and class instance corresponding to every PriorModel \\\n        attributed to this instance.\n\n        This method takes as input a physical vector of parameter values, thus omitting the use of priors.\n\n        Parameters\n        ----------\n        physical_vector: [float]\n            A unit hypercube vector\n\n        Returns\n        -------\n        model_instance : autofit.mapper.model.ModelInstance\n            An object containing reconstructed model_mapper instances\n\n        \"\"\"\n        arguments = dict(\n            map(lambda prior_tuple, physical_unit: (prior_tuple.prior, physical_unit), self.prior_tuples_ordered_by_id,\n                physical_vector))\n\n        return self.instance_for_arguments(arguments)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef instance_for_arguments(self, arguments):\n\n        model_instance = ModelInstance()\n\n        for prior_model_tuple in self.prior_model_tuples:\n            setattr(model_instance, prior_model_tuple.name,\n                    prior_model_tuple.prior_model.instance_for_arguments(arguments))\n\n        return model_instance", "response": "Creates a ModelInstance which is created for every PriorModel\n            corresponding to every PriorModel\n            whose attribute and class instance corresponding to every PriorModel\n            whose attribute and class instance corresponding to every PriorModel\n            whose parameter values are arguments."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef mapper_from_partial_prior_arguments(self, arguments):\n        original_prior_dict = {prior: prior for prior in self.priors}\n        return self.mapper_from_prior_arguments({**original_prior_dict, **arguments})", "response": "Creates a new model mapper from a dictionary mapping existing priors to new priors keeping existing priors where no mapping is provided."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a new model mapper from a dictionary mapping priors to new priors.", "response": "def mapper_from_prior_arguments(self, arguments):\n        \"\"\"\n        Creates a new model mapper from a dictionary mapping_matrix existing priors to new priors.\n\n        Parameters\n        ----------\n        arguments: {Prior: Prior}\n            A dictionary mapping_matrix priors to priors\n\n        Returns\n        -------\n        model_mapper: ModelMapper\n            A new model mapper with updated priors.\n        \"\"\"\n        mapper = copy.deepcopy(self)\n\n        for prior_model_tuple in self.prior_model_tuples:\n            setattr(mapper, prior_model_tuple.name,\n                    prior_model_tuple.prior_model.gaussian_prior_model_for_arguments(arguments))\n\n        return mapper"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef mapper_from_gaussian_tuples(self, tuples, a=None, r=None):\n\n        prior_tuples = self.prior_tuples_ordered_by_id\n        prior_class_dict = self.prior_class_dict\n        arguments = {}\n\n        for i, prior_tuple in enumerate(prior_tuples):\n            prior = prior_tuple.prior\n            cls = prior_class_dict[prior]\n            mean = tuples[i][0]\n            if a is not None and r is not None:\n                raise exc.PriorException(\"Width of new priors cannot be both relative and absolute.\")\n            if a is not None:\n                width_type = \"a\"\n                value = a\n            elif r is not None:\n                width_type = \"r\"\n                value = r\n            else:\n                width_type, value = conf.instance.prior_width.get_for_nearest_ancestor(cls, prior_tuple.name)\n            if width_type == \"r\":\n                width = value * mean\n            elif width_type == \"a\":\n                width = value\n            else:\n                raise exc.PriorException(\"Prior widths must be relative 'r' or absolute 'a' e.g. a, 1.0\")\n            if isinstance(prior, GaussianPrior):\n                limits = (prior.lower_limit, prior.upper_limit)\n            else:\n                limits = conf.instance.prior_limit.get_for_nearest_ancestor(cls, prior_tuple.name)\n            arguments[prior] = GaussianPrior(mean, max(tuples[i][1], width), *limits)\n\n        return self.mapper_from_prior_arguments(arguments)", "response": "Creates a new model mapper from a list of floats describing the mean values of gaussian priors."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef info(self):\n        info = []\n\n        for prior_model_name, prior_model in self.prior_model_tuples:\n            info.append(prior_model.name + '\\n')\n            info.extend([f\"{prior_model_name}_{item}\" for item in prior_model.info])\n\n        return '\\n'.join(info)", "response": "Return the information for each resource in the overall model."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate project (snapshot) signature :param resource_provider: project provider :type resource_provider: dict :param resource: project resource :type resource: ProjectResource", "response": "def generate(self, resource_provider, resource):\n\t\t\"\"\"Generate project (snapshot) signature\n\n\t\t:param resource_provider: project provider\n\t\t:type  resource_provider: dict\n\t\t:param resource: project resource\n\t\t:type  resource: ProjectResource\n\t\t\"\"\"\n\t\tprovider = resource_provider[\"provider\"]\n\t\tif provider == \"github\":\n\t\t\treturn self.generateGithubRepositorySignature(resource_provider, resource)\n\t\tif provider == \"bitbucket\":\n\t\t\treturn self.generateBitbucketRepositorySignature(resource_provider, resource)\n\t\tif provider == \"googlecode\":\n\t\t\treturn self.generateGooglecodeRepositorySignature(resource_provider, resource)\n\t\tif provider == \"fedora\":\n\t\t\treturn self.generateFedoraDistributionPackageSignature(resource_provider, resource)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef push(config, force=False):\n    repo = config.repo\n\n    active_branch = repo.active_branch\n    if active_branch.name == \"master\":\n        error_out(\n            \"Can't commit when on the master branch. \"\n            \"You really ought to do work in branches.\"\n        )\n\n    state = read(config.configfile)\n\n    if not state.get(\"FORK_NAME\"):\n        info_out(\"Can't help you push the commit. Please run: gg config --help\")\n        return 0\n\n    try:\n        repo.remotes[state[\"FORK_NAME\"]]\n    except IndexError:\n        error_out(\"There is no remote called '{}'\".format(state[\"FORK_NAME\"]))\n\n    destination = repo.remotes[state[\"FORK_NAME\"]]\n    if force:\n        pushed, = destination.push(force=True)\n        info_out(pushed.summary)\n    else:\n        pushed, = destination.push()\n        # Was it rejected?\n        if (\n            pushed.flags & git.remote.PushInfo.REJECTED\n            or pushed.flags & git.remote.PushInfo.REMOTE_REJECTED\n        ):\n            error_out('The push was rejected (\"{}\")'.format(pushed.summary), False)\n\n            try_force_push = input(\"Try to force push? [Y/n] \").lower().strip()\n            if try_force_push not in (\"no\", \"n\"):\n                pushed, = destination.push(force=True)\n                info_out(pushed.summary)\n            else:\n                return 0", "response": "Create push the current branch."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the matplotlib modules and the style of the Seaborn Seaborn", "response": "def setup():\n    \"\"\"import the matplotlib modules and set the style\n    \"\"\"\n    import sys\n    already_loaded = 'matplotlib' in sys.modules\n\n    # just make sure we can access matplotlib as mpl\n    import matplotlib as mpl\n\n    if not already_loaded:\n        mpl.use('Agg')\n\n    import matplotlib.pyplot as plt\n\n    plt.style.use('seaborn')\n\n    general_settings()\n\n    import mpl_toolkits.axes_grid1 as axes_grid1\n    axes_grid1\n    return plt, mpl"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if a path exists.", "response": "def chkpath(path):\n    \"\"\"\n    Checks if a path exists.\n    \"\"\"\n    if os.path.exists(path):\n        return path\n    else:\n        msg = \"{0} does not exist.\".format(path)\n        raise argparse.ArgumentTypeError(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of valid arguments.", "response": "def getargs():\n    \"\"\"\n    Return a list of valid arguments.\n    \"\"\"\n    parser = argparse.ArgumentParser(description='\\\n    Select paths from a directory tree.')\n    parser.add_argument(\"-a\", \"--hidden\", action=\"store_false\",\n                        help=\"Show all hidden paths too.\")\n    parser.add_argument(\"-r\", \"--relative\", action=\"store_true\",\n                        help=\"Output relative paths.\")\n    parser.add_argument(\"path\", type=chkpath, nargs='?',\n                        default=\".\", help=\"A valid path.\")\n    return parser.parse_args()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef readin_volt(filename):\n    with open(filename, 'r') as fid:\n        content = np.loadtxt(fid, skiprows=1, usecols=[0, 1, 2])\n        volt = content[:, 2]\n        elecs = content[:, 0:2]\n    return elecs, volt", "response": "Read in measurement data from a volt. dat file and return electrodes and measured resistance."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncalculate the temperature effect correction of the current time series using inversion results of the current time series.", "response": "def calc_correction(volt1, volt2, volt3):\n    \"\"\"Remove the temperature effect from field data using inversion results of\n    that data:\n\n        print(volt[0])\n        d_obs^TC = d_obs + (d_est^TC - d_est)\n\n    Parameters\n    ----------\n    d_obs:\n        measured field data to correct (volt1)\n    d_est:\n        synthetic data of inversion result from d_obs (volt2)\n    d_estTC:\n        synthetic data of temperature corrected inversion result of d_obs\n        (volt3)\n    \"\"\"\n    volt = np.array([a - b + c for a, b, c in zip(volt1, volt2, volt3)])\n    volt[np.where(volt < 0)] = 0.000001\n\n    return volt"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsave the values in volt - format.", "response": "def save_volt(elecs, volt, filename):\n    \"\"\"Save the values in volt-format.\n    \"\"\"\n    # bring data in shape\n    content = np.column_stack((elecs, volt, np.zeros(len(volt))))\n\n    # save datapoints\n    with open(filename, 'w') as fid:\n        fid.write('{0}\\n'.format(content.shape[0]))\n    with open(filename, 'ab') as fid:\n        np.savetxt(fid, np.array(content), fmt='%i %i %f %f')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef main():\n    options = handle_options()\n\n    # read in observed and synthetic data\n    elecs, d_obs = readin_volt(options.d_obs)\n    elecs, d_est = readin_volt(options.d_est)\n    elecs, d_estTC = readin_volt(options.d_estTC)\n    # calculate corrected data\n    volt_corr = calc_correction(d_obs,\n                                d_est,\n                                d_estTC,\n                                )\n    # save data\n    save_volt(elecs,\n              volt_corr,\n              options.output,\n              )", "response": "Function to remove temperature effect from field data\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a list of priors contained in this tuple", "response": "def prior_tuples(self):\n        \"\"\"\n        Returns\n        -------\n        priors: [(String, Prior)]\n            A list of priors contained in this tuple\n        \"\"\"\n        return list(filter(lambda t: isinstance(t[1], Prior), self.__dict__.items()))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef constant_tuples(self):\n        return list(sorted(filter(lambda t: isinstance(t[1], Constant), self.__dict__.items()), key=lambda tup: tup[0]))", "response": "Returns a list of tuples of all Constant objects in the current object"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the value of the passed in arguments.", "response": "def value_for_arguments(self, arguments):\n        \"\"\"\n        Parameters\n        ----------\n        arguments: {Prior: float}\n            A dictionary of arguments\n\n        Returns\n        -------\n        tuple: (float,...)\n            A tuple of float values\n        \"\"\"\n\n        def convert(tup):\n            if hasattr(tup, \"prior\"):\n                return arguments[tup.prior]\n            return tup.constant.value\n\n        return tuple(map(convert, sorted(self.prior_tuples + self.constant_tuples, key=lambda tup: tup.name)))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef gaussian_tuple_prior_for_arguments(self, arguments):\n        tuple_prior = TuplePrior()\n        for prior_tuple in self.prior_tuples:\n            setattr(tuple_prior, prior_tuple.name, arguments[prior_tuple.prior])\n        return tuple_prior", "response": "Returns a new tuple prior with gaussian priors for the given arguments."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef recursive_update(default, custom):\n    '''Return a dict merged from default and custom\n\n    >>> recursive_update('a', 'b')\n    Traceback (most recent call last):\n        ...\n    TypeError: Params of recursive_update should be dicts\n\n    >>> recursive_update({'a': [1]}, {'a': [2], 'c': {'d': {'c': 3}}})\n    {'a': [2], 'c': {'d': {'c': 3}}}\n\n    >>> recursive_update({'a': {'c': 1, 'd': {}}, 'b': 4}, {'b': 5})\n    {'a': {'c': 1, 'd': {}}, 'b': 5}\n\n    >>> recursive_update({'a': {'c': 1, 'd': {}}, 'b': 4}, {'a': 2})\n    {'a': 2, 'b': 4}\n    '''\n    if not isinstance(default, dict) or not isinstance(custom, dict):\n        raise TypeError('Params of recursive_update should be dicts')\n\n    for key in custom:\n        if isinstance(custom[key], dict) and isinstance(\n                default.get(key), dict):\n            default[key] = recursive_update(default[key], custom[key])\n        else:\n            default[key] = custom[key]\n\n    return default", "response": "Recursive update of a dict with a dict merged from default and custom"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndeletes a found branch locally and remotely.", "response": "def cleanup(config, searchstring, force=False):\n    \"\"\"Deletes a found branch locally and remotely.\"\"\"\n    repo = config.repo\n\n    branches_ = list(find(repo, searchstring))\n    if not branches_:\n        error_out(\"No branches found\")\n    elif len(branches_) > 1:\n        error_out(\n            \"More than one branch found.{}\".format(\n                \"\\n\\t\".join([\"\"] + [x.name for x in branches_])\n            )\n        )\n\n    assert len(branches_) == 1\n    branch_name = branches_[0].name\n    active_branch = repo.active_branch\n    if branch_name == active_branch.name:\n        error_out(\"Can't clean up the current active branch.\")\n    # branch_name = active_branch.name\n    upstream_remote = None\n    fork_remote = None\n    state = read(config.configfile)\n    origin_name = state.get(\"ORIGIN_NAME\", \"origin\")\n    for remote in repo.remotes:\n        if remote.name == origin_name:\n            # remote.pull()\n            upstream_remote = remote\n            break\n    if not upstream_remote:\n        error_out(\"No remote called {!r} found\".format(origin_name))\n\n    # Check out master\n    repo.heads.master.checkout()\n    upstream_remote.pull(repo.heads.master)\n\n    # Is this one of the merged branches?!\n    # XXX I don't know how to do this \"nativly\" with GitPython.\n    merged_branches = [\n        x.strip()\n        for x in repo.git.branch(\"--merged\").splitlines()\n        if x.strip() and not x.strip().startswith(\"*\")\n    ]\n    was_merged = branch_name in merged_branches\n    certain = was_merged or force\n    if not certain:\n        # Need to ask the user.\n        # XXX This is where we could get smart and compare this branch\n        # with the master.\n        certain = (\n            input(\"Are you certain {} is actually merged? [Y/n] \".format(branch_name))\n            .lower()\n            .strip()\n            != \"n\"\n        )\n    if not certain:\n        return 1\n\n    if was_merged:\n        repo.git.branch(\"-d\", branch_name)\n    else:\n        repo.git.branch(\"-D\", branch_name)\n\n    fork_remote = None\n    state = read(config.configfile)\n    for remote in repo.remotes:\n        if remote.name == state.get(\"FORK_NAME\"):\n            fork_remote = remote\n            break\n    if fork_remote:\n        fork_remote.push(\":\" + branch_name)\n        info_out(\"Remote branch on fork deleted too.\")"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef readin_temp(temp_file):\n    with open(temp_file, 'r') as fid:\n        temp = np.loadtxt(fid, skiprows=1, usecols=[2])\n\n    return temp", "response": "Reads in the temperature file and returns a numpy array of the temperature"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the path to the final rho. mag file from the tomodir.", "response": "def read_iter():\n    '''Return the path to the final rho*.mag file from the tomodir.\n    '''\n    filename = 'exe/inv.lastmod'\n    linestring = open(filename, 'r').readline().strip()\n    linestring = linestring.replace('\\n', '')\n    linestring = linestring.replace('../', '')\n    return linestring"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef readin_rho(filename, rhofile=True, aniso=False):\n    if aniso:\n        a = [[0, 1, 2], [2, 3, 4]]\n    else:\n        a = [0, 2]\n    if rhofile:\n        if filename is None:\n            filename = 'rho/rho.dat'\n        with open(filename, 'r') as fid:\n            mag = np.loadtxt(fid, skiprows=1, usecols=(a[0]))\n\n    else:\n        if filename is None:\n            filename = read_iter()\n        with open(filename, 'r') as fid:\n            mag = np.power(10, np.loadtxt(fid, skiprows=1, usecols=(a[1])))\n\n    return mag", "response": "Read in the values of the resistivity in Ohmm."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfunctioning to calculate the correction of the individual resistivity of the system.", "response": "def calc_correction(temp, mag, add=False, T_std=10, m=0.021):\n    \"\"\"Function to add or substract the temperature effect to given data. The\n    function can be called in python scripts. For application via command line\n    in a file system use the script td_correct_temperature.py. The data is\n    taken and given in Ohmm.\n\n    rho_std_i = (m * (T_i - 25\u00b0) + 1) / (m * (T_std - 25\u00b0) + 1) * rho_i\n    rho_i = (m * (T_std - 25\u00b0) + 1) / (m * (T_i - 25\u00b0) + 1) * rho_std_i\n\n    Hayley (2007)\n\n    Parameters:\n        temp: temperature values corresponding to the individual resistivity\n              values\n        mag: resistivity values to be corrected\n        add: switch for adding instead of substracting the effect\n        T_std: standard temperature t or from which to correct (default=10\u00b0)\n        m:coeffcient (default=0.021)\n    \"\"\"\n    if mag.shape[1] == 3:\n        if add:\n            data_x = (m * (T_std - 25) + 1) / (m * (temp - 25) + 1) * mag[:, 0]\n            data_y = (m * (T_std - 25) + 1) / (m * (temp - 25) + 1) * mag[:, 1]\n            data_z = (m * (T_std - 25) + 1) / (m * (temp - 25) + 1) * mag[:, 2]\n            return np.column_stack((data_x, data_y, data_z))\n        else:\n            data_x = (m * (temp - 25) + 1) / (m * (T_std - 25) + 1) * mag[:, 0]\n            data_y = (m * (temp - 25) + 1) / (m * (T_std - 25) + 1) * mag[:, 1]\n            data_z = (m * (temp - 25) + 1) / (m * (T_std - 25) + 1) * mag[:, 2]\n            return np.column_stack((data_x, data_y, data_z))\n    else:\n        if add:\n            data_i = (m * (T_std - 25) + 1) / (m * (temp - 25) + 1) * mag\n            return data_i\n        else:\n            data_std = (m * (temp - 25) + 1) / (m * (T_std - 25) + 1) * mag\n            return data_std"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef save_mag_to_file(mag, filename, rhofile):\n    if rhofile:\n        # bring data in shape\n        null = np.zeros(len(mag))\n        if mag.shape[1] == 3:\n            null = np.column_stack((null, null, null, null))\n        result = np.column_stack((mag, null))\n\n        # save datapoints\n        with open(filename, 'w') as fid:\n            fid.write('{0}\\n'.format(mag.shape[0]))\n        with open(filename, 'ab') as fid:\n            np.savetxt(fid, np.array(result), fmt='%f')\n\n    else:\n        # bring data in shape\n        with open('inv/rho00.mag', 'r') as fid:\n            coor = np.loadtxt(fid, skiprows=1, usecols=[0, 1])\n        # calculated back to log\n        if mag.shape[1] == 3:\n            logx = [math.log(d, 10) for d in mag[:, 0]]\n            logy = [math.log(d, 10) for d in mag[:, 1]]\n            logz = [math.log(d, 10) for d in mag[:, 2]]\n            mag_log = np.column_stack((logx, logy, logz))\n        else:\n            mag_log = [math.log(d, 10) for d in mag]\n        content = np.column_stack((coor[:, 0], coor[:, 1], mag_log))\n\n        # save datapoints\n        with open(filename, 'w') as fid:\n            fid.write('{0}\\n'.format(content.shape[0]))\n        with open(filename, 'ab') as fid:\n            np.savetxt(fid, np.array(content), fmt='%f')", "response": "Save the values in rho - or mag - format."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef main():\n    options = handle_options()\n\n    # read in temperature and resistivity data\n    tempdata = readin_temp(options.temp_file)\n    magdata = readin_rho(options.filename,\n                         options.rhofile,\n                         aniso=options.aniso)\n    # calculate corrected data\n    mag_corr = calc_correction(temp=tempdata,\n                               mag=magdata,\n                               add=options.add,\n                               T_std=options.T_std,\n                               m=options.m,)\n    # save data\n    save_mag_to_file(mag_corr,\n                     options.output,\n                     options.rhofile)", "response": "Function to add or substract the temperature effect to data in a tomodir\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntakes a plural English word and turn it into singular", "response": "def singular(plural):\n    \"\"\"\n    Take a plural English word and turn it into singular\n\n    Obviously, this doesn't work in general. It know just enough words to\n    generate XML tag names for list items. For example, if we have an element\n    called 'tracks' in the response, it will be serialized as a list without\n    named items in JSON, but we need names for items in XML, so those will be\n    called 'track'.\n    \"\"\"\n    if plural.endswith('ies'):\n        return plural[:-3] + 'y'\n    if plural.endswith('s'):\n        return plural[:-1]\n    raise ValueError('unknown plural form %r' % (plural,))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef plot_single_configuration(self, config_nr, sens_file):\n        indices = elem.load_column_file_to_elements_advanced(\n            sens_file, [2, 3],\n            False,\n            False\n        )\n\n        elem.plt_opt.title = ''\n        elem.plt_opt.reverse = True\n        elem.plt_opt.cbmin = -1\n        elem.plt_opt.cbmax = 1\n        elem.plt_opt.cblabel = r'fill'\n        elem.plt_opt.xlabel = 'x (m)'\n        elem.plt_opt.ylabel = 'z (m)'\n\n        fig = plt.figure(figsize=(5, 7))\n        ax = fig.add_subplot(111)\n        ax, pm, cb = elem.plot_element_data_to_ax(\n            indices[0],\n            ax,\n            scale='asinh',\n            no_cb=False,\n        )\n        ax.scatter(\n            self.sens_centers[config_nr, 0],\n            self.sens_centers[config_nr, 1],\n            marker='*',\n            s=50,\n            color='w',\n            edgecolors='w',\n        )\n\n        self.color_electrodes(config_nr, ax)\n\n        # Output\n        sensf = sens_file.split('sens')[-1]\n        sensf = sensf.split('.')[0]\n        out = 'sens_center_' + sensf + '.png'\n        fig.savefig(out, bbox_inches='tight', dpi=300)\n        fig.clf()\n        plt.close(fig)", "response": "Plot sensitivity distribution with center of mass for a single configuration."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef plot_sens_center(self, frequency=2):\n        try:\n            colors = np.loadtxt(self.volt_file, skiprows=1)\n        except IOError:\n            print('IOError opening {0}'.format(volt_file))\n            exit()\n\n        # check for 1-dimensionality\n        if(len(colors.shape) > 1):\n            print('Artificial or Multi frequency data')\n            colors = colors[:, frequency].flatten()\n\n        colors = colors[~np.isnan(colors)]\n\n        elem.load_elem_file(self.elem_file)\n        elem.load_elec_file(self.elec_file)\n        nr_elements = len(elem.element_type_list[0])\n        elem.element_data = np.zeros((nr_elements, 1)) * np.nan\n\n        elem.plt_opt.title = ' '\n        elem.plt_opt.reverse = True\n        elem.plt_opt.cbmin = -1\n        elem.plt_opt.cbmax = 1\n        elem.plt_opt.cblabel = self.cblabel\n        elem.plt_opt.xlabel = 'x (m)'\n        elem.plt_opt.ylabel = 'z (m)'\n\n        fig = plt.figure(figsize=(5, 7))\n        ax = fig.add_subplot(111)\n        ax, pm, cb = elem.plot_element_data_to_ax(0, ax, scale='linear',\n                                                  no_cb=True)\n        ax.scatter(self.sens_centers[:, 0], self.sens_centers[:, 1], c=colors,\n                   s=100, edgecolors='none')\n\n        cb_pos = mpl_get_cb_bound_next_to_plot(ax)\n        ax1 = fig.add_axes(cb_pos, frame_on=True)\n        cmap = mpl.cm.jet_r\n        norm = mpl.colors.Normalize(vmin=np.nanmin(colors),\n                                    vmax=np.nanmax(colors))\n        mpl.colorbar.ColorbarBase(ax1, cmap=cmap, norm=norm,\n                                  orientation='vertical')\n\n        fig.savefig(self.output_file, bbox_inches='tight', dpi=300)", "response": "Plot sensitivity center distribution for all configurations in\n        config. dat."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef color_electrodes(self, config_nr, ax):\n        electrodes = np.loadtxt(options.config_file, skiprows=1)\n        electrodes = self.configs[~np.isnan(self.configs).any(1)]\n        electrodes = electrodes.astype(int)\n\n        conf = []\n        for dim in range(0, electrodes.shape[1]):\n            c = electrodes[config_nr, dim]\n            # c = c.partition('0')\n            a = np.round(c / 10000) - 1\n            b = np.mod(c, 10000) - 1\n            conf.append(a)\n            conf.append(b)\n        Ex, Ez = elem.get_electrodes()\n        color = ['#ffed00', '#ffed00', '#ff0000', '#ff0000']\n        ax.scatter(Ex[conf], Ez[conf], c=color, marker='s', s=60,\n                   clip_on=False, edgecolors='k')", "response": "Color the electrodes used in specific configuration."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompute the sensitivities for the given input data.", "response": "def compute_sens(self, elem_file, elec_file, configs):\n        \"\"\"\n        Compute the sensitivities for the given input data.\n        A CRMod instance is called to create the sensitivity files.\n        \"\"\"\n        CRMod_config = CRMod.config()\n        # activate 2D mode and set sink nr\n        if self.options.sink is not None:\n            print('2D mode with sink {0}'.format(self.options.sink))\n            CRMod_config['2D'] = 0\n            CRMod_config['fictitious_sink'] = 'T'\n            CRMod_config['sink_node'] = self.options.sink\n\n        CRMod_config['write_sens'] = 'T'\n        CRMod_instance = CRMod.CRMod(CRMod_config)\n        CRMod_instance.elemfile = elem_file\n        CRMod_instance.elecfile = elec_file\n        CRMod_instance.configdata = configs\n\n        resistivity = 100\n        # get number of elements\n        fid = open(elem_file, 'r')\n        fid.readline()\n        elements = int(fid.readline().strip().split()[1])\n        fid.close()\n\n        # create rho.dat file\n        rhodata = '{0}\\n'.format(elements)\n        for i in range(0, elements):\n            rhodata += '{0}   0\\n'.format(resistivity)\n        CRMod_instance.rhodata = rhodata\n\n        CRMod_instance.run_in_tempdir()\n        volt_file = CRMod_instance.volt_file\n        sens_files = CRMod_instance.sens_files\n        return sens_files, volt_file, CRMod_instance.temp_dir"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncomputes the center of mass of the modular entry.", "response": "def compute_center_of_mass(self, filename):\n        \"\"\"\n        Center of mass is computed using the sensitivity data output from CRMod\n        Data weights can be applied using command line options\n        \"\"\"\n        sens = np.loadtxt(filename, skiprows=1)\n\n        X = sens[:, 0]\n        Z = sens[:, 1]\n        # C = (np.abs(sens[:,2]))# ./ np.max(np.abs(sens[:,2]))\n        C = sens[:, 2]\n\n        x_center = 0\n        z_center = 0\n        sens_sum = 0\n\n        for i in range(0, C.shape[0]):\n            # unweighted\n            if(self.weight == 0):\n                weight = (C[i])\n            # abs\n            if(self.weight == 1):\n                weight = np.abs(C[i])\n            # log10\n            if(self.weight == 2):\n                weight = np.log10(np.abs(C[i]))\n            # sqrt\n            if(self.weight == 3):\n                weight = np.sqrt(np.abs(C[i]))\n\n            x_center += (X[i] * weight)\n            z_center += (Z[i] * weight)\n            sens_sum += weight\n        x_center /= sens_sum\n        z_center /= sens_sum\n\n        return (x_center, z_center)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef remove_tmp_dir(self, directory):\n        if(not directory.startswith('/tmp/')):\n            print('Directory not in /tmp')\n            exit()\n\n        print('Deleting directory: ' + directory)\n\n        shutil.rmtree(directory)", "response": "Remove the directory if it is located in tmp"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the options from the command line.", "response": "def handle_cmd_options():\n    '''\n    Get  the options from the command line.\n    '''\n    parser = OptionParser()\n    parser.add_option(\"-s\", \"--silent\", action=\"store_true\", dest=\"silent\",\n                      help=\"print any warnings\", default=False)\n    (options, args) = parser.parse_args()\n    return options, args"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmove file to folder if existing", "response": "def move(fname, folder, options):\n    \"\"\"Move file to dir if existing\n    \"\"\"\n    if os.path.isfile(fname):\n        shutil.move(fname, folder)\n    else:\n        if options.silent is False:\n            print('{0} missing'.format(fname))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating a path in the ~. automolens directory by taking the provided path base64 encoding it and extracting the first and last five characters.", "response": "def path_for(path):\n    \"\"\"\n    Generate a path in the ~/.autolens directory by taking the provided path, base64 encoding it and extracting the\n    first and last five characters.\n\n    Parameters\n    ----------\n    path: str\n        The path where multinest output is apparently saved\n\n    Returns\n    -------\n    actual_path: str\n        The path where multinest output is actually saved\n    \"\"\"\n    start = int(SUB_PATH_LENGTH / 2)\n    end = SUB_PATH_LENGTH - start\n    encoded_string = str(hashlib.sha224(path.encode(\"utf-8\")).hexdigest())\n    return \"{}/al_{}\".format(autolens_dir, (encoded_string[:start] + encoded_string[-end:]).replace(\"-\", \"\"))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a folder in the ~. autocolens directory and create a symlink to it at the provided path.", "response": "def make_linked_folder(sym_path):\n    \"\"\"\n    Create a folder in the ~/.autolens directory and create a sym link to it at the provided path.\n\n    If both folders already exist then nothing is changed. If the source folder exists but the destination folder does\n    not then the source folder is removed and replaced so as to conform to the behaviour that the user would expect\n    should they delete the sym linked folder.\n\n    Parameters\n    ----------\n    sym_path: str\n        The path where multinest output is apparently saved\n\n    Returns\n    -------\n    actual_path: str\n        The path where multinest output is actually saved\n    \"\"\"\n    source_path = path_for(sym_path)\n    if os.path.exists(source_path) and not os.path.exists(sym_path):\n        logger.debug(\"Source {} exists but target {} does not. Removing source.\".format(source_path, sym_path))\n        shutil.rmtree(source_path)\n    try:\n        logger.debug(\"Making source {}\".format(source_path))\n        os.mkdir(source_path)\n        logger.debug(\"Success\")\n    except FileExistsError as e:\n        logger.info(\"Source already existed\")\n        logger.debug(e)\n    try:\n        logger.debug(\"Making linking from source {} to sym {}\".format(source_path, sym_path))\n        os.symlink(source_path, sym_path)\n        logger.debug(\"Success\")\n    except FileExistsError as e:\n        logger.debug(\"Sym already existed\")\n        logger.debug(e)\n    return source_path"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprinting up to limit stack trace entries from the traceback tb.", "response": "def print_tb(tb, limit=None, file=None):\n    \"\"\"Print up to 'limit' stack trace entries from the traceback 'tb'.\n\n    If 'limit' is omitted or None, all entries are printed.  If 'file'\n    is omitted or None, the output goes to sys.stderr; otherwise\n    'file' should be an open file or file-like object with a write()\n    method.\n    \"\"\"\n    if file is None:\n        file = sys.stderr\n    if limit is None:\n        if hasattr(sys, 'tracebacklimit'):\n            limit = sys.tracebacklimit\n    file.write('\\n'.join(format_tb(tb, limit)) + '\\n')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef print_exception(etype, value, tb, limit=None, file=None, chain=True):\n    import traceback\n    if file is None:\n        file = sys.stderr\n    if tb:\n        file.write('Traceback (most recent call last):\\n')\n        print_tb(tb, limit, file)\n    lines = traceback.format_exception_only(etype, value)\n    for line in lines:\n        file.write(line)", "response": "Print an exception to file."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconstructs info about a project from artefact - project - packages data.", "response": "def construct(self, data):\n\t\t\"\"\"Construct info about a project from artefact\n\n\t\t:param data:\tgolang-project-packages artefact\n\t\t:type  data:\tjson/dict\n\t\t\"\"\"\n\t\toccurrences = {}\n\t\tmain_occurrences = {}\n\n\t\t# occurrences of devel packages\n\t\tfor pkg in data[\"data\"][\"dependencies\"]:\n\t\t\tpackage = pkg[\"package\"]\n\t\t\tfor item in pkg[\"dependencies\"]:\n\t\t\t\tdep = item[\"name\"]\n\t\t\t\tif package != \".\":\n\t\t\t\t\tdeps = map(lambda l: \"%s/%s\" % (package, l), item[\"location\"])\n\t\t\t\telse:\n\t\t\t\t\tdeps = item[\"location\"]\n\t\t\t\tif dep not in occurrences:\n\t\t\t\t\toccurrences[dep] = deps\n\t\t\t\telse:\n\t\t\t\t\toccurrences[dep] = occurrences[dep] + deps\n\n\t\tself.occurrences = occurrences\n\n\t\t# occurrences of main packages\n\t\tfor main in data[\"data\"][\"main\"]:\n\t\t\tfilename = main[\"filename\"]\n\t\t\tfor dep in main[\"dependencies\"]:\n\t\t\t\tif dep not in main_occurrences:\n\t\t\t\t\tmain_occurrences[dep] = [filename]\n\t\t\t\telse:\n\t\t\t\t\tmain_occurrences[dep].append(filename)\n\n\t\tself.main_occurrences = main_occurrences\n\t\n\t\t# test directories\n\t\tself.test_directories = sorted(map(lambda l: l[\"test\"], data[\"data\"][\"tests\"]))\n\n\t\t# provided devel packages\n\t\tself.provided_packages = sorted(data[\"data\"][\"packages\"])\n\n\t\t# imported paths in devel packages\n\t\timported_packages = []\n\t\timported_native_packages = []\n\t\tfor path in occurrences:\n\t\t\ttry:\n\t\t\t\tself.ipparser.parse(path)\n\t\t\texcept ValueError:\n\t\t\t\tcontinue\n\n\t\t\tif self.ipparser.isNative():\n\t\t\t\timported_native_packages.append(path)\n\t\t\telse:\n\t\t\t\timported_packages.append(path)\n\n\t\tself.imported_packages = sorted(imported_packages)\n\t\tself.imported_native_packages = sorted(imported_native_packages)\n\n\t\t# main packages\n\t\tself.main_packages = map(lambda l: l[\"filename\"], data[\"data\"][\"main\"])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of ImportInfo tuples for all module imports in the specified Python source file or the source string.", "response": "def get_imports(filename, source=None):\n  \"\"\"\n  Returns a list of #ImportInfo tuples for all module imports in the specified\n  Python source file or the *source* string.\n  \"\"\"\n\n  if source is None:\n    with open(filename, 'rb') as fp:\n      source = fp.read()\n\n  module = ast.parse(source, filename)\n  result = []\n\n  for node in _find_nodes(module, lambda x: isinstance(x, ast.Import)):\n    for alias in node.names:\n      result.append(ImportInfo(alias.name, filename, node.lineno))\n  for node in _find_nodes(module, lambda x: isinstance(x, ast.ImportFrom)):\n    import_name = '.' * node.level + (node.module or '')\n    result.append(ImportInfo(import_name, filename, node.lineno))\n\n  result.sort(key=lambda x: x.lineno)\n  return result"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef join_import_from(self, import_spec):\n\n    if not self.isroot and not self.ispkg:\n      parent = self.name.rpartition('.')[0]\n    else:\n      parent = self.name\n    return join_import_from(import_spec, parent)", "response": "Joins a relative import like from. foo import bar with this module as\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfinds the module specified by module_name in the module finder s search path and returns a ModuleInfo object.", "response": "def find_module(self, module_name):\n    \"\"\"\n    Attempts to find the module specified by *module_name* in the\n    ModuleFinder's search path and returns a #ModuleInfo object.\n\n    For builtin modules, the #ModuleInfo.filename will be None. Note that\n    the #ModuleInfo.imported_from is not filled by this method. It is used\n    with #ModuleFinder.iter_modules().\n    \"\"\"\n\n    if not module_name:\n      raise ValueError('empty module name')\n    if module_name in sys.builtin_module_names:\n      return ModuleInfo(module_name, None, 'builtin', [])\n    if module_name in self.modules:\n      return self.modules[module_name]\n\n    parts = module_name.split('.')\n    result = None\n    for dirname in self.path:\n      # TODO: Configurable behaviour for Python 2 where __init__.py is\n      #       required and namespace packages are not automatically\n      #       supported.\n      script_file = os.path.join(dirname, os.sep.join(parts)) + '.py'\n      if os.path.isfile(script_file):\n        result = ModuleInfo(module_name, script_file, ModuleInfo.SRC)\n        break\n      package_file = os.path.join(dirname, os.sep.join(parts), '__init__.py')\n      if os.path.isfile(package_file):\n        result = ModuleInfo(module_name, package_file, ModuleInfo.SRC)\n        break\n\n      for suffix in self.native_suffixes:\n        native_file = os.path.join(dirname, os.sep.join(parts)) + suffix\n        if os.path.isfile(native_file):\n          result = ModuleInfo(module_name, native_file, ModuleInfo.NATIVE)\n          break\n      if result:\n        break\n    else:\n      return ModuleInfo(module_name, None, ModuleInfo.NOTFOUND)\n\n    self.modules[module_name] = result\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\niterate over the modules that are imported by the specified module or Python source file.", "response": "def iter_modules(self, module=None, filename=None, source=None, excludes=None):\n    \"\"\"\n    An iterator for the modules that are imported by the specified *module*\n    or Python source file. The returned #ModuleInfo objects have their\n    *imported_from* member filled in order to be able to track how a module\n    was imported.\n    \"\"\"\n\n    if excludes is None:\n      excludes = self.excludes\n\n    if not filename:\n      if not module:\n        raise ValueError('need either module or filename parameter')\n      module = self.find_module(module)\n      if not module.filename or module.type == 'native':\n        return\n    else:\n      module = ModuleInfo('__main__', filename, ModuleInfo.SRC)\n\n    seen = set()\n    stack = collections.deque()\n\n    for imp in get_imports(module.filename, source):\n      stack.appendleft((module.join_import_from(imp.name), [module.name]))\n\n    yield module\n    while stack:\n      import_name, imported_from = stack.pop()\n      if import_name in seen:\n        continue\n      seen.add(import_name)\n      if check_module_exclude(import_name, excludes):\n        continue\n\n      module = self.find_module(import_name)\n      module.imported_from[:] = imported_from\n      yield module\n\n      if module.type == ModuleInfo.SRC:\n        imported_from = [module.name] + imported_from\n        for imp in get_imports(module.filename):\n          stack.append((module.join_import_from(imp.name), imported_from))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_tomodir(directory):\n    if os.path.isdir(directory):\n        if(os.path.isdir(directory + \"/exe\") and\n           os.path.isdir(directory + \"/config\") and\n           os.path.isdir(directory + \"/rho\") and\n           os.path.isdir(directory + \"/inv\") and\n           os.path.isdir(directory + \"/mod\")):\n                return True\n        else:\n                return False\n    else:\n        return False", "response": "Checks if the supplied directory is a tomodir directory and returns a boolean indicating if the directory is a tomodir."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the state of modeling and inversion for a given tomodir.", "response": "def td_is_finished(tomodir):\n    \"\"\"Return the state of modeling and inversion for a given tomodir. The\n    result does not take into account sensitivities or potentials, as\n    optionally generated by CRMod.\n\n    Parameters\n    ----------\n    tomodir: string\n        Directory to check\n\n    Returns\n    -------\n    crmod_is_finished: bool\n        True if a successful CRMod result is contained in the tomodir\n        directory.\n    crtomo_is_finished: bool\n        True if a successful CRTomo inversion results is contained in the\n        tomodir directory.\n    \"\"\"\n    if not is_tomodir(tomodir):\n        raise Exception('Supplied directory is not a tomodir!')\n\n    # crmod finished is determined by:\n    # config.dat/rho.dat/crmod.cfg are present\n    # volt.dat is present\n    if(os.path.isfile(tomodir + os.sep + 'config/config.dat') and\n       os.path.isfile(tomodir + os.sep + 'rho/rho.dat') and\n       os.path.isfile(tomodir + os.sep + 'grid/elem.dat') and\n       os.path.isfile(tomodir + os.sep + 'grid/elec.dat') and\n       os.path.isfile(tomodir + os.sep + 'exe/crmod.cfg') and\n       os.path.isfile(tomodir + os.sep + 'mod/volt.dat')):\n        crmod_is_finished = True\n    else:\n        crmod_is_finished = False\n\n    # crtomo is finished if\n    # crtomo.cfg/volt.dat/elem.dat/elec.dat are present\n    # inv/run.ctr contains the word \"CPU\" in the last line\n    if(os.path.isfile(tomodir + os.sep + 'grid/elem.dat') and\n       os.path.isfile(tomodir + os.sep + 'grid/elec.dat') and\n       os.path.isfile(tomodir + os.sep + 'exe/crtomo.cfg') and\n       os.path.isfile(tomodir + os.sep + 'inv/inv.ctr') and\n       os.path.isfile(tomodir + os.sep + 'inv/run.ctr') and\n       os.path.isfile(tomodir + os.sep + 'mod/volt.dat')):\n        with open(tomodir + os.sep + 'inv/run.ctr', 'r') as fid:\n            lines = fid.readlines()\n            crtomo_is_finished = False\n            # check the last 5 lines\n            for line in lines[-5:]:\n                test_line = line.strip()\n                regex = re.compile('CPU')\n                result = regex.match(test_line)\n                if result is not None:\n                    crtomo_is_finished = True\n    else:\n        crtomo_is_finished = False\n    return crmod_is_finished, crtomo_is_finished"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_sipdir(directory):\n    is_sipdir = True\n\n    if(not os.path.isfile(directory + os.sep + 'frequencies.dat')):\n        is_sipdir = False\n\n    if(not os.path.isdir(directory + os.sep + 'invmod')):\n        is_sipdir = False\n\n    return is_sipdir", "response": "Simple check if the supplied directory is a SIP directory."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sipdir_is_finished(sipdir):\n    if not is_sipdir(sipdir):\n        raise Exception('Directory is not a valid SIP directory!')\n\n    subdirs_raw = sorted(glob.glob(sipdir + os.sep + 'invmod' + os.sep + '*'))\n    subdirs = [x for x in subdirs_raw if os.path.isdir(x)]\n\n    crmod_finished = True\n    crtomo_finished = True\n    for subdir in subdirs:\n        subcrmod, subcrtomo = td_is_finished(subdir)\n        if not subcrmod:\n            crmod_finished = False\n        if not subcrtomo:\n            crtomo_finished = False\n\n    return crmod_finished, crtomo_finished", "response": "Returns the state of modeling and inversion for a given SIP directory."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of branches for given repository", "response": "def branches(self):\n\t\t\"\"\"Return a list of branches for given repository\n\n\t\t:return: [str]\n\t\t\"\"\"\n\t\t# TODO(jchaloup): find out of all branches are listed (even remote)\n\t\t# if there is a concept of remote branch\n\t\treturn map(lambda (b, r, n): b, self.repo.branches())"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets data from a commit object", "response": "def _commitData(self, changeset):\n\t\t\"\"\"Get data from a commit object\n\n\t\t:param changeset: tuple with changeset data\n\t\t:type  changeset: tuple\n\t\t\"\"\"\n\t\t(rev, node, tags, branch, author, desc, date) = changeset\n\t\tts = int(time.mktime(date.timetuple()))\n\t\treturn {\n\t\t\t\"hexsha\": node,\n\t\t\t\"adate\": ts,\n\t\t\t\"cdate\": ts,\n\t\t\t\"author\": author,\n\t\t\t\"message\": desc\n\t\t}"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets data for a given commit.", "response": "def commit(self, commit):\n\t\t\"\"\"Get data for a given commit\n\n\t\tRaises KeyError if a commit is not found or not parsed.\n\n\t\t:param commit: repository commit\n\t\t:type  commit: string\n\t\t\"\"\"\n\t\ttry:\n\t\t\tchangesets = self.repo.log(revrange=commit)\n\t\texcept error.CommandError:\n\t\t\traise KeyError(\"Commit %s not found\" % commit)\n\n\t\treturn self._commitData(changesets[0])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read(self, size=None):\n        if self._closed:\n            raise IOError('File is closed')\n        if not (self._flags & self.FLAG_READ):\n            raise IOError('File is not open for reading')\n        if (size is None) or (size < 0):\n            # go for broke\n            result = self._rbuffer\n            self._rbuffer = bytes()\n            self._pos += len(result)\n            while True:\n                try:\n                    new_data = self._read(self._DEFAULT_BUFSIZE)\n                except EOFError:\n                    new_data = None\n                if (new_data is None) or (len(new_data) == 0):\n                    break\n                result += new_data\n                self._realpos += len(new_data)\n                self._pos += len(new_data)\n            return result \n        if size <= len(self._rbuffer):\n            result = self._rbuffer[:size]\n            self._rbuffer = self._rbuffer[size:]\n            self._pos += len(result)\n            return result \n        while len(self._rbuffer) < size:\n            read_size = size - len(self._rbuffer)\n            if self._flags & self.FLAG_BUFFERED:\n                read_size = max(self._bufsize, read_size)\n            try:\n                new_data = self._read(read_size)\n            except EOFError:\n                new_data = None\n            if (new_data is None) or (len(new_data) == 0):\n                break\n            self._rbuffer += new_data\n            self._realpos += len(new_data)\n        result = self._rbuffer[:size]\n        self._rbuffer = self._rbuffer[size:]\n        self._pos += len(result)\n        return result", "response": "Reads at most size bytes from the file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef readline(self, size=None):\n        # it's almost silly how complex this function is.\n        if self._closed:\n            raise IOError('File is closed')\n        if not (self._flags & self.FLAG_READ):\n            raise IOError('File not open for reading')\n        line = self._rbuffer\n        while True:\n            if self._at_trailing_cr and (self._flags & self.FLAG_UNIVERSAL_NEWLINE) and (len(line) > 0):\n                # edge case: the newline may be '\\r\\n' and we may have read\n                # only the first '\\r' last time.\n                if line[0] == linefeed_byte_value:\n                    line = line[1:]\n                    self._record_newline(crlf)\n                else:\n                    self._record_newline(cr_byte)\n                self._at_trailing_cr = False\n            # check size before looking for a linefeed, in case we already have\n            # enough.\n            if (size is not None) and (size >= 0):\n                if len(line) >= size:\n                    # truncate line and return\n                    self._rbuffer = line[size:]\n                    line = line[:size]\n                    self._pos += len(line)\n                    return line if self._flags & self.FLAG_BINARY else u(line)\n                n = size - len(line)\n            else:\n                n = self._bufsize\n            if (linefeed_byte in line) or ((self._flags & self.FLAG_UNIVERSAL_NEWLINE) and (cr_byte in line)):\n                break\n            try:\n                new_data = self._read(n)\n            except EOFError:\n                new_data = None\n            if (new_data is None) or (len(new_data) == 0):\n                self._rbuffer = bytes()\n                self._pos += len(line)\n                return line if self._flags & self.FLAG_BINARY else u(line)\n            line += new_data\n            self._realpos += len(new_data)\n        # find the newline\n        pos = line.find(linefeed_byte)\n        if self._flags & self.FLAG_UNIVERSAL_NEWLINE:\n            rpos = line.find(cr_byte)\n            if (rpos >= 0) and (rpos < pos or pos < 0):\n                pos = rpos\n        xpos = pos + 1\n        if (line[pos] == cr_byte_value) and (xpos < len(line)) and (line[xpos] == linefeed_byte_value):\n            xpos += 1\n        self._rbuffer = line[xpos:]\n        lf = line[pos:xpos]\n        line = line[:pos] + linefeed_byte\n        if (len(self._rbuffer) == 0) and (lf == cr_byte):\n            # we could read the line up to a '\\r' and there could still be a\n            # '\\n' following that we read next time.  note that and eat it.\n            self._at_trailing_cr = True\n        else:\n            self._record_newline(lf)\n        self._pos += len(line)\n        return line if self._flags & self.FLAG_BINARY else u(line)", "response": "Read one entire line from the file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef enable_neutron_hack(self, os_username, os_password, os_project_id, os_auth_url):\n        self.yum_install(['python-neutronclient'])\n        self.send_file(pkg_data_filename('static', 'ovb_fix_neutron_addr'), '/usr/local/bin/ovb_fix_neutron_addr', unix_mode=0o755)\n        content = \"\"\"\n[Unit]\nDescription=OVB neutron hack Service\n[Service]\nExecStart=/usr/local/bin/ovb_fix_neutron_addr  --os-user {os_username} --os-password {os_password} --os-project-id {os_project_id} --os-auth-url {os_auth_url}\nUser=root\nStandardOutput=kmsg+console\nStandardError=inherit\nRestart=always\n[Install]\nWantedBy=multi-user.target\n\"\"\"\n        unit = 'ovb_fix_neutron_addr.service'\n        self.create_file(\n            '/usr/lib/systemd/system/%s' % unit,\n            content.format(\n                os_username=os_username,\n                os_password=protect_password(os_password),\n                os_project_id=os_project_id,\n                os_auth_url=os_auth_url))\n        self.run('systemctl enable %s' % unit)\n        self.run('systemctl start %s' % unit)", "response": "Enable the neutron hack on the undercloud."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\npatch the ironic - ramdisk to allow the new image to be written.", "response": "def patch_ironic_ramdisk(self):\n        \"\"\"Clean the disk before flushing the new image.\n\n        See: https://bugs.launchpad.net/ironic-lib/+bug/1550604\n        \"\"\"\n        tmpdir = self.run('mktemp -d')[0].rstrip('\\n')\n        self.run('cd {tmpdir}; zcat /home/stack/ironic-python-agent.initramfs| cpio -id'.format(tmpdir=tmpdir))\n        self.send_file(pkg_data_filename('static', 'ironic-wipefs.patch'), '/tmp/ironic-wipefs.patch')\n        self.run('cd {tmpdir}; patch -p0 < /tmp/ironic-wipefs.patch'.format(tmpdir=tmpdir))\n        self.run('cd {tmpdir}; find . | cpio --create --format=newc > /home/stack/ironic-python-agent.initramfs'.format(tmpdir=tmpdir))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nshows an interactive menu in the terminal.", "response": "def show_menu(title, options, default=None, height=None, width=None, multiselect=False, precolored=False):\n    \"\"\"\n    Shows an interactive menu in the terminal.\n\n    Arguments:\n        options: list of menu options\n        default: initial option to highlight\n        height: maximum height of the menu\n        width: maximum width of the menu\n        multiselect: allow multiple items to be selected?\n        precolored: allow strings with embedded ANSI commands\n\n    Returns:\n        * If multiselect is True, returns a list of selected options.\n        * If mutliselect is False, returns the selected option.\n        * If an option is a 2-tuple, the first item will be displayed and the\n          second item will be returned.\n        * If menu is cancelled (Esc pressed), returns None.\n        *\n    Notes:\n        * You can pass OptionGroup objects to `options` to create sub-headers\n          in the menu.\n    \"\"\"\n\n    plugins = [FilterPlugin()]\n    if any(isinstance(opt, OptionGroup) for opt in options):\n        plugins.append(OptionGroupPlugin())\n    if title:\n        plugins.append(TitlePlugin(title))\n    if precolored:\n        plugins.append(PrecoloredPlugin())\n    menu = Termenu(options, default=default, height=height,\n                   width=width, multiselect=multiselect, plugins=plugins)\n    return menu.show()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmarks a class method as extendable with plugins.", "response": "def pluggable(method):\n    \"\"\"\n    Mark a class method as extendable with plugins.\n    \"\"\"\n    def wrapped(self, *args, **kwargs):\n        if hasattr(self, \"_plugins\"):\n            # call the last plugin, it may call the previous via self.parent.method\n            # creating a call call chain\n            return getattr(self._plugins[-1], method.__name__)(*args, **kwargs)\n        else:\n            return method(self, *args, **kwargs)\n    wrapped.original = method\n    return wrapped"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nregister a plugin with a host object.", "response": "def register_plugin(host, plugin):\n    \"\"\"\n    Register a plugin with a host object. Some @pluggable methods in the host\n    will have their behaviour altered by the plugin.\n    \"\"\"\n    class OriginalMethods(object):\n        def __getattr__(self, name):\n            return lambda *args, **kwargs: getattr(host, name).original(host, *args, **kwargs)\n    if not hasattr(host, \"_plugins\"):\n        host._plugins = [OriginalMethods()]\n    plugin.parent = host._plugins[-1]\n    plugin.host = host\n    host._plugins.append(plugin)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nredirecting standard input to controlling terminal.", "response": "def redirect_std():\n    \"\"\"\n    Connect stdin/stdout to controlling terminal even if the scripts input and output\n    were redirected. This is useful in utilities based on termenu.\n    \"\"\"\n    stdin = sys.stdin\n    stdout = sys.stdout\n    if not sys.stdin.isatty():\n        sys.stdin = open_raw(\"/dev/tty\", \"r\", 0)\n    if not sys.stdout.isatty():\n        sys.stdout = open_raw(\"/dev/tty\", \"w\", 0)\n\n    return stdin, stdout"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _to_unicode(s):\n    try:\n        return s.encode('ascii')\n    except (UnicodeError, AttributeError):\n        try:\n            return s.decode('utf-8')\n        except UnicodeError:\n            return s", "response": "Decode a string as ascii or utf8 if possible."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nopen a file on the remote server.", "response": "def open(self, filename, mode='r', bufsize=-1):\n        \"\"\"\n        Open a file on the remote server.  The arguments are the same as for\n        Python's built-in `python:file` (aka `python:open`).  A file-like\n        object is returned, which closely mimics the behavior of a normal\n        Python file object, including the ability to be used as a context\n        manager.\n\n        The mode indicates how the file is to be opened: ``'r'`` for reading,\n        ``'w'`` for writing (truncating an existing file), ``'a'`` for\n        appending, ``'r+'`` for reading/writing, ``'w+'`` for reading/writing\n        (truncating an existing file), ``'a+'`` for reading/appending.  The\n        Python ``'b'`` flag is ignored, since SSH treats all files as binary.\n        The ``'U'`` flag is supported in a compatible way.\n\n        Since 1.5.2, an ``'x'`` flag indicates that the operation should only\n        succeed if the file was created and did not previously exist.  This has\n        no direct mapping to Python's file flags, but is commonly known as the\n        ``O_EXCL`` flag in posix.\n\n        The file will be buffered in standard Python style by default, but\n        can be altered with the ``bufsize`` parameter.  ``0`` turns off\n        buffering, ``1`` uses line buffering, and any number greater than 1\n        (``>1``) uses that specific buffer size.\n\n        :param str filename: name of the file to open\n        :param str mode: mode (Python-style) to open in\n        :param int bufsize: desired buffering (-1 = default buffer size)\n        :return: an `.SFTPFile` object representing the open file\n\n        :raises IOError: if the file could not be opened.\n        \"\"\"\n        filename = self._adjust_cwd(filename)\n        self._log(DEBUG, 'open(%r, %r)' % (filename, mode))\n        imode = 0\n        if ('r' in mode) or ('+' in mode):\n            imode |= SFTP_FLAG_READ\n        if ('w' in mode) or ('+' in mode) or ('a' in mode):\n            imode |= SFTP_FLAG_WRITE\n        if 'w' in mode:\n            imode |= SFTP_FLAG_CREATE | SFTP_FLAG_TRUNC\n        if 'a' in mode:\n            imode |= SFTP_FLAG_CREATE | SFTP_FLAG_APPEND\n        if 'x' in mode:\n            imode |= SFTP_FLAG_CREATE | SFTP_FLAG_EXCL\n        attrblock = SFTPAttributes()\n        t, msg = self._request(CMD_OPEN, filename, imode, attrblock)\n        if t != CMD_HANDLE:\n            raise SFTPError('Expected handle')\n        handle = msg.get_binary()\n        self._log(DEBUG, 'open(%r, %r) -> %s' % (filename, mode, hexlify(handle)))\n        return SFTPFile(self, handle, mode, bufsize)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a symbolic link of the source path at dest.", "response": "def symlink(self, source, dest):\n        \"\"\"\n        Create a symbolic link (shortcut) of the ``source`` path at\n        ``destination``.\n\n        :param str source: path of the original file\n        :param str dest: path of the newly created symlink\n        \"\"\"\n        dest = self._adjust_cwd(dest)\n        self._log(DEBUG, 'symlink(%r, %r)' % (source, dest))\n        source = bytestring(source)\n        self._request(CMD_SYMLINK, source, dest)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchanges the current directory of this SFTP session.", "response": "def chdir(self, path=None):\n        \"\"\"\n        Change the \"current directory\" of this SFTP session.  Since SFTP\n        doesn't really have the concept of a current working directory, this is\n        emulated by Paramiko.  Once you use this method to set a working\n        directory, all operations on this `.SFTPClient` object will be relative\n        to that path. You can pass in ``None`` to stop using a current working\n        directory.\n\n        :param str path: new current working directory\n\n        :raises IOError: if the requested path doesn't exist on the server\n\n        .. versionadded:: 1.4\n        \"\"\"\n        if path is None:\n            self._cwd = None\n            return\n        if not stat.S_ISDIR(self.stat(path).st_mode):\n            raise SFTPError(errno.ENOTDIR, \"%s: %s\" % (os.strerror(errno.ENOTDIR), path))\n        self._cwd = b(self.normalize(path))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncopying the contents of a file object to the server and return a new SFTPAttributes object containing the attributes about the file.", "response": "def putfo(self, fl, remotepath, file_size=0, callback=None, confirm=True):\n        \"\"\"\n        Copy the contents of an open file object (``fl``) to the SFTP server as\n        ``remotepath``. Any exception raised by operations will be passed\n        through.\n\n        The SFTP operations use pipelining for speed.\n\n        :param file fl: opened file or file-like object to copy\n        :param str remotepath: the destination path on the SFTP server\n        :param int file_size:\n            optional size parameter passed to callback. If none is specified,\n            size defaults to 0\n        :param callable callback:\n            optional callback function (form: ``func(int, int)``) that accepts\n            the bytes transferred so far and the total bytes to be transferred\n            (since 1.7.4)\n        :param bool confirm:\n            whether to do a stat() on the file afterwards to confirm the file\n            size (since 1.7.7)\n\n        :return:\n            an `.SFTPAttributes` object containing attributes about the given\n            file.\n\n        .. versionadded:: 1.10\n        \"\"\"\n        with self.file(remotepath, 'wb') as fr:\n            fr.set_pipelined(True)\n            size = 0\n            while True:\n                data = fl.read(32768)\n                fr.write(data)\n                size += len(data)\n                if callback is not None:\n                    callback(size, file_size)\n                if len(data) == 0:\n                    break\n        if confirm:\n            s = self.stat(remotepath)\n            if s.st_size != size:\n                raise IOError('size mismatch in put!  %d != %d' % (s.st_size, size))\n        else:\n            s = SFTPAttributes()\n        return s"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncopy a remote file from the SFTP server and write it to the specified file - like object fl.", "response": "def getfo(self, remotepath, fl, callback=None):\n        \"\"\"\n        Copy a remote file (``remotepath``) from the SFTP server and write to\n        an open file or file-like object, ``fl``.  Any exception raised by\n        operations will be passed through.  This method is primarily provided\n        as a convenience.\n\n        :param object remotepath: opened file or file-like object to copy to\n        :param str fl:\n            the destination path on the local host or open file object\n        :param callable callback:\n            optional callback function (form: ``func(int, int)``) that accepts\n            the bytes transferred so far and the total bytes to be transferred\n        :return: the `number <int>` of bytes written to the opened file object\n\n        .. versionadded:: 1.10\n        \"\"\"\n        with self.open(remotepath, 'rb') as fr:\n            file_size = self.stat(remotepath).st_size\n            fr.prefetch()\n            size = 0\n            while True:\n                data = fr.read(32768)\n                fl.write(data)\n                size += len(data)\n                if callback is not None:\n                    callback(size, file_size)\n                if len(data) == 0:\n                    break\n        return size"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_int(self):\n        byte = self.get_bytes(1)\n        if byte == max_byte:\n            return util.inflate_long(self.get_binary())\n        byte += self.get_bytes(3)\n        return struct.unpack('>I', byte)[0]", "response": "Fetch an int from the stream."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd an integer to the stream.", "response": "def add_size(self, n):\n        \"\"\"\n        Add an integer to the stream.\n        \n        :param int n: integer to add\n        \"\"\"\n        self.packet.write(struct.pack('>I', n))\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a string to the stream.", "response": "def add_string(self, s):\n        \"\"\"\n        Add a string to the stream.\n        \n        :param str s: string to add\n        \"\"\"\n        s = asbytes(s)\n        self.add_size(len(s))\n        self.packet.write(s)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nformat a log entry into unicode.", "response": "def format(self, record):\n        \"\"\"\n        return log in unicode\n        \"\"\"\n        self._format_record(record)\n\n        record_dict = {}\n        for k, v in record.__dict__.items():\n            if isinstance(k, str):\n                k = decode_(k, 'utf8')\n            if isinstance(v, str):\n                v = decode_(v, 'utf8', 'replace')\n            record_dict[k] = v\n\n        if 'color' in self.fmt or 'end_color' in self.fmt:\n            record_dict['color'], record_dict['end_color'] = _color(record.levelno)\n\n        log = self.ufmt % record_dict\n\n        if record.exc_text:\n            if log[-1:] != '\\n':\n                log += '\\n'\n            log += decode_(record.exc_text, 'utf8', 'replace')\n\n        log = log.replace('\\n', '\\n' + self.tab)\n\n        return log"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list(self, source_ids=None, seniority=\"all\", stage=None,\n            date_start=\"1494539999\", date_end=TIMESTAMP_NOW, filter_id=None,\n            page=1, limit=30, sort_by='ranking', filter_reference=None, order_by=None):\n        \"\"\"\n        Retreive all profiles that match the query param.\n\n        Args:\n            date_end:   <string> REQUIRED (default to timestamp of now)\n                        profiles' last date of reception\n            date_start: <string> REQUIRED (default to \"1494539999\")\n                        profiles' first date of reception\n            filter_id:     <string>\n            limit:      <int> (default to 30)\n                        number of fetched profiles/page\n            page:       <int> REQUIRED default to 1\n                        number of the page associated to the pagination\n            seniority:  <string> defaut to \"all\"\n                        profiles' seniority (\"all\", \"senior\", \"junior\")\n            sort_by:    <string>\n            source_ids: <array of strings> REQUIRED\n            stage:      <string>\n\n        Returns\n            Retrieve the profiles data as <dict>\n\n        \"\"\"\n        query_params = {}\n        query_params[\"date_end\"] = _validate_timestamp(date_end, \"date_end\")\n        query_params[\"date_start\"] = _validate_timestamp(date_start, \"date_start\")\n        if filter_id:\n            query_params[\"filter_id\"] = _validate_filter_id(filter_id)\n        if filter_reference:\n            query_params[\"filter_reference\"] = _validate_filter_reference(filter_reference)\n        query_params[\"limit\"] = _validate_limit(limit)\n        query_params[\"page\"] = _validate_page(page)\n        query_params[\"seniority\"] = _validate_seniority(seniority)\n        query_params[\"sort_by\"] = _validate_sort_by(sort_by)\n        query_params[\"source_ids\"] = json.dumps(_validate_source_ids(source_ids))\n        query_params[\"stage\"] = _validate_stage(stage)\n        query_params[\"order_by\"] = order_by\n\n        response = self.client.get(\"profiles\", query_params)\n        return response.json()", "response": "Returns a list of all the profiles in the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a profile resume to a sourced id.", "response": "def add(self, source_id=None, file_path=None, profile_reference=\"\",\n            timestamp_reception=None, training_metadata=[]):\n        \"\"\"\n        Add a profile resume to a sourced id.\n\n        Args:\n            source_id:              <string>\n                                    source id\n            file_path:              <string>\n                                    local path to resume file\n            profile_reference:      <string> (default to \"\")\n                                    reference to assign to the profile\n            timestamp_reception:    <string>\n                                    original date of the application of the profile\n\n        Returns\n            Response that contains code 201 if successful\n            Other status codes otherwise.\n\n        \"\"\"\n        data = {}\n        data[\"source_id\"] = _validate_source_id(source_id)\n        data[\"profile_reference\"] = _validate_profile_reference(profile_reference)\n        data[\"timestamp_reception\"] = _validate_timestamp(timestamp_reception, \"timestamp_reception\")\n        data[\"training_metadata\"] = _validate_training_metadata(training_metadata)\n        files = _get_file_metadata(file_path, profile_reference)\n        response = None\n        with open(file_path, 'rb') as in_file:\n            files = (files[0], in_file, files[2])\n            response = self.client.post(\"profile\", data=data, files={\"file\": files})\n        return response.json()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd all profiles from a given directory.", "response": "def addList(self, source_id, dir_path, is_recurcive=False, timestamp_reception=None, training_metadata=[]):\n        \"\"\"Add all profile from a given directory.\"\"\"\n        if not path.isdir(dir_path):\n            raise ValueError(dir_path + ' is not a directory')\n        files_to_send = _get_files_from_dir(dir_path, is_recurcive)\n        succeed_upload = {}\n        failed_upload = {}\n        for file_path in files_to_send:\n            try:\n                resp = self.add(source_id=source_id,\n                    file_path=file_path, profile_reference=\"\",\n                    timestamp_reception=timestamp_reception, training_metadata=training_metadata)\n                if resp['code'] != 200 and resp['code'] != 201:\n                    failed_upload[file_path] = ValueError('Invalid response: ' + str(resp))\n                else:\n                    succeed_upload[file_path] = resp\n            except BaseException as e:\n                failed_upload[file_path] = e\n        result = {\n            'success': succeed_upload,\n            'fail': failed_upload\n        }\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nretrieves the profile information associated with source id.", "response": "def get(self, source_id=None, profile_id=None, profile_reference=None):\n        \"\"\"\n        Retrieve the profile information associated with profile id.\n\n        Args:\n            source_id:              <string>\n                                    source id\n            profile_id:             <string>\n                                    profile id\n\n        Returns\n            profile information\n\n        \"\"\"\n        query_params = {}\n        query_params[\"source_id\"] = _validate_source_id(source_id)\n        if profile_id:\n            query_params[\"profile_id\"] = _validate_profile_id(profile_id)\n        if profile_reference:\n            query_params[\"profile_reference\"] = _validate_profile_reference(profile_reference)\n        response = self.client.get('profile', query_params)\n        return response.json()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nedits the profile stage given a filter.", "response": "def set(self, source_id=None, profile_id=None, filter_id=None, stage=None, profile_reference=None, filter_reference=None):\n        \"\"\"\n        Edit the profile stage given a filter.\n\n        Args:\n            profile_id:             <string>\n                                    profile id\n        body params:\n            source_id:              <string>\n                                    source id associated to the profile\n\n            filter_id:                 <string>\n                                    filter id\n            stage:                 <string>\n                                    profiles' stage associated to the filter ( null for all, NEW, YES, LATER or NO).\n\n        Returns\n            Response that contains code 201 if successful\n            Other status codes otherwise.\n\n        \"\"\"\n        data = {}\n        data[\"source_id\"] = _validate_source_id(source_id)\n        if profile_id:\n            data[\"profile_id\"] = _validate_profile_id(profile_id)\n        if filter_id:\n            data[\"filter_id\"] = _validate_filter_id(filter_id)\n        if profile_reference:\n            data[\"profile_reference\"] = _validate_profile_reference(profile_reference)\n        if filter_reference:\n            data[\"filter_reference\"] = _validate_filter_reference(filter_reference)\n        data[\"stage\"] = _validate_stage(stage)\n\n        response = self.client.patch('profile/stage', data=data)\n        return response.json()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get(self, source_id=None, profile_id=None, profile_reference=None, filter_id=None, filter_reference=None):\n        query_params = {}\n        query_params[\"source_id\"] = _validate_source_id(source_id)\n        if profile_id:\n            query_params[\"profile_id\"] = _validate_profile_id(profile_id)\n        if profile_reference:\n            query_params[\"profile_reference\"] = _validate_profile_reference(profile_reference)\n        if filter_id:\n            query_params[\"filter_id\"] = _validate_filter_id(filter_id)\n        if filter_reference:\n            query_params[\"filter_reference\"] = _validate_filter_reference(filter_reference)\n        response = self.client.get('profile/revealing', query_params)\n        return response", "response": "Retrieve the interpretability information."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check(self, profile_data, training_metadata=[]):\n        data = {\n            \"profile_json\": _validate_dict(profile_data, \"profile_data\"),\n            \"training_metadata\": _validate_training_metadata(training_metadata),\n        }\n        response = self.client.post(\"profile/json/check\", data=data)\n        return response.json()", "response": "Use the api to check weither the profile_data are valid."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add(self, source_id, profile_data, training_metadata=[], profile_reference=None, timestamp_reception=None):\n        data = {\n            \"source_id\": _validate_source_id(source_id),\n            \"profile_json\": _validate_dict(profile_data, \"profile_data\"),\n            \"training_metadata\": _validate_training_metadata(training_metadata),\n            \"profile_reference\": profile_reference\n        }\n\n        # some enrichement for profile_json\n        if timestamp_reception is not None:\n            data['timestamp_reception'] = _validate_timestamp(timestamp_reception, 'timestamp_reception')\n\n        response = self.client.post(\"profile/json\", data=data)\n        return response.json()", "response": "Use the api to add a new profile using profile_data."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert json ld output of etk to cdr object", "response": "def convert_jsonld_cdr(doc):\n    \"\"\"\n    converts json ld output of etk to cdr object\n    :param doc: the input Knowledge graph in json ld format\n    :return: a cdr object with embedded knowledge graph and doc_id.\n    # TODO DIG UI needs a @timestamp_crawl(?) add this too\n    \"\"\"\n    new_docs = list()\n    new_doc = dict()\n    kg = dict()\n    for key in list(doc):\n        if key == '@id':\n            new_doc['doc_id'] = doc['@id']\n        elif key == '@context':\n            new_doc[key] = doc[key]\n        elif key == '@type':\n            kg['type'] = list()\n            types = doc['@type']\n            if not isinstance(types, list):\n                types = [types]\n            for type in types:\n                kg['type'].append({'value': type, 'key': create_key_from_value(type, 'type')})\n        else:\n            kg[key] = list()\n            objs = doc[key]\n            if not isinstance(objs, list):\n                objs = [objs]\n            for obj in objs:\n                if '@id' in obj and '@context' in obj:\n                    new_docs.extend(convert_jsonld_cdr(obj))\n                if '@id' in obj:\n                    kg[key].append({'value': obj['@id'], 'key': obj['@id']})\n                elif '@value' in obj:\n                    val = obj['@value']\n                    k_val = create_key_from_value(val, key)\n                    kg[key].append({'value': val, 'key': k_val})\n\n    new_doc['knowledge_graph'] = kg\n    new_docs.append(new_doc)\n    return new_docs"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef md5sum(self, f):\n        ''' md5sums a file, returning the hex digest\n\n            Parameters:\n                - f     filename string\n        '''\n        m = hashlib.md5()\n        fh = open(f, 'r')\n        while 1:\n            chunk = fh.read(BUF_SIZE)\n            if not chunk: break\n            m.update(chunk)\n        fh.close()\n        return m.hexdigest()", "response": "md5sums a file returning the hex digest"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef iteritems(self, path=None, want_files=True, want_dirs=True, func=None, filt=None):\n        ''' streaming item iterator that can optionally run a function / filter function on each item (files/dirs)\n\n            Parameters:\n                - path          path to iterate on (note: this is called recursively)\n                - want_files    True if you want file results in the iteration, False if you don't\n                - want_dirs     True if you want directory results in the iteration, False if you don't\n                - func          function to run on each (this will cause the return output to expand to a list of tuples)\n                - filt          filter function - only iterates on files when filt(absolute_filename) == True\n        '''\n        if path is None: iter_path = self.path\n        else:            iter_path = path\n\n        for f in os.listdir(iter_path):\n            if f[0] == '.': continue\n\n            ## f (filename) -> af (absolute filename)\n            if self.absolute: af = os.path.abspath( os.path.join(iter_path, f) )\n            else:             af = os.path.join(iter_path, f)\n\n            ## filter out stuff we don't want\n            if filt and not filt(af): continue\n\n            ## detect broken path strings\n            if not os.path.exists(af): raise IOError('bad path: %s' % af)\n\n            ## return our main response\n            if ( os.path.isfile(af) and want_files ) or ( os.path.isdir(af) and want_dirs ):\n                if self.stripdot and af[:2] == './': af = af[2:]\n                if func: yield ( func(af), af )\n                else:    yield af\n\n            ## recurse & return for sub-dirs\n            if os.path.isdir(af):\n                for x in self.iteritems(path       = af,\n                                        want_files = want_files,\n                                        want_dirs  = want_dirs,\n                                        func       = func,\n                                        filt       = filt): yield x", "response": "streaming item iterator that can optionally run a function and filter function on each item"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef iterdupes(self, compare=None, filt=None):\n        ''' streaming item iterator with low overhead duplicate file detection\n\n            Parameters:\n                - compare       compare function between files (defaults to md5sum)\n        '''\n        if not compare: compare = self.md5sum\n        seen_siz = {}       ## store size   -> first seen filename\n        seen_sum = {}       ## store chksum -> first seen filename\n        size_func = lambda x: os.stat(x).st_size\n        for (fsize, f) in self.iteritems(want_dirs=False, func=size_func, filt=filt):\n            if fsize not in seen_siz:    ## state 1: no previous size collisions\n                seen_siz[fsize] = f\n                continue\n            else:\n                if seen_siz[fsize]:      ## state 2: defined key => str (initial, unscanned path)\n                    chksum = compare(seen_siz[fsize])\n                    if chksum in seen_sum:  yield (chksum, seen_siz[fsize])\n                    else:                   seen_sum[chksum] = seen_siz[fsize]\n                    seen_siz[fsize] = None\n\n                ## state 3: defined key => None (already scanned path, no-op)\n                chksum = compare(f)\n                if chksum in seen_sum:\n                    ## if it's a dupe, check if the first one was ever yielded then yield\n                    if seen_sum[chksum]:\n                        yield (chksum, seen_sum[chksum])\n                        seen_sum[chksum] = None\n                    yield (chksum, f)\n                else:\n                    ## if not, set the initial filename\n                    seen_sum[chksum] = f", "response": "streaming item iterator with low overhead duplicate file detection\n           "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef objects_to_root(objects: List) -> Root:\n\n    def _to_tree(objs: Iterable) -> Dict:\n        \"\"\"\n        Build a tree structure from a flat list of objects.\n\n        :param objs: The raw iterable of S3 `ObjectSummary`s, as returned by a\n                     bucket listing.\n        :return: The listing as a nested dictionary where keys are directory\n                 and file names. The values of directories will in turn be a\n                 dict. The values of keys representing files will be the\n                 `ObjectSummary` instance.\n        \"\"\"\n        path_tree = {}\n        for obj in objs:\n            is_dir = obj.key.endswith('/')\n            chunks = [chunk for chunk in obj.key.split('/') if chunk]\n            chunk_count = len(chunks)\n            tmp = path_tree\n            for i, chunk in enumerate(chunks):\n                is_last_chunk = i == chunk_count - 1\n\n                if is_last_chunk and not is_dir:\n                    tmp[chunk] = obj\n                else:\n                    # must be a directory\n                    if chunk not in tmp:\n                        # it doesn't exist - create it\n                        tmp[chunk] = {}\n                    tmp = tmp[chunk]\n        return path_tree\n\n    def _to_entity(key: str, value: Union[Dict, Any]) -> Entity:\n        \"\"\"\n        Turn a nested dictionary representing an S3 bucket into the correct\n        `Entity` object.\n\n        :param key: The name of the entity.\n        :param value: If the entity is a directory, the nested dict\n                      representing its contents. Otherwise, the `ObjectSummary`\n                      instance representing the file.\n        :return: The entity representing the entity name and value pair.\n        \"\"\"\n        if isinstance(value, dict):\n            return Directory(\n                key,\n                {key_: _to_entity(key_, value_)\n                 for key_, value_ in value.items()})\n\n        return File(pathlib.PurePath(value.key).name, value.size,\n                    value.e_tag.strip('\"'))\n\n    tree = _to_tree(objects)\n    return Root({pathlib.PurePath(key).name: _to_entity(key, value)\n                 for key, value in tree.items()})", "response": "Converts a list of s3 ObjectSummaries into a directory tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _delete(self, paths: Iterable[str]) -> None:\n        for chunk in util.chunk(paths, self._MAX_DELETES_PER_REQUEST):\n            keys = list([self._prefix + key for key in chunk])\n            logger.info('Deleting %d objects (%s)', len(keys), ', '.join(keys))\n            response = self._bucket.delete_objects(Delete={\n                'Objects': [{'Key': key} for key in keys],\n                'Quiet': True\n            })\n            logger.debug('Delete objects response: %s', response)", "response": "Delete a collection of paths from S3."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nuploading a collection of paths to S3.", "response": "def _upload(self, items: Iterable[Tuple[str, str]]) -> None:\n        \"\"\"\n        Upload a collection of paths to S3.\n\n        :param items: An iterable of pairs containing the local path of the\n                      file to upload, and the remote path to upload it to. The\n                      prefix will be appended to each remote path.\n        \"\"\"\n        for src, key in items:\n            logger.info(f'Uploading {src} to {key}')\n            mimetype, _ = mimetypes.guess_type(src)\n            if mimetype is None:\n                logger.warning(f'Could not guess MIME type for {src}')\n                mimetype = 'application/octet-stream'\n\n            logger.debug(f'Deduced MIME type: {mimetype}')\n            self._bucket.upload_file(src, key, ExtraArgs={\n                    'ContentType': mimetype\n                })"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef rotmat(alpha):\n    R = np.array(((np.cos(alpha), -np.sin(alpha)),\n                 (np.sin(alpha), np.cos(alpha))))\n\n    return R", "response": "Rotate around z - axis\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nemits a log statement when the task is submitted.", "response": "def apply_async(self, args=None, kwargs=None, **options):  # pylint: disable=arguments-differ\n        \"\"\"\n        Emit a log statement when the task is submitted.\n        \"\"\"\n        result = super(LoggedTask, self).apply_async(args=args, kwargs=kwargs, **options)\n        log.info('Task {}[{}] submitted with arguments {}, {}'.format(\n            self.name,\n            result.id,\n            args,\n            kwargs\n        ))\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef on_retry(self, exc, task_id, args, kwargs, einfo):\n        super(LoggedTask, self).on_retry(exc, task_id, args, kwargs, einfo)\n        log.warning('[{}] retried due to {}'.format(task_id, getattr(einfo, 'traceback', None)))", "response": "Called when a task is retried."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef on_failure(self, exc, task_id, args, kwargs, einfo):\n        log.error('[{}] failed due to {}'.format(task_id, getattr(einfo, 'traceback', None)))\n        super(LoggedTask, self).on_failure(exc, task_id, args, kwargs, einfo)", "response": "Log the exception that caused the task to fail."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef nodes_to_object(self, node, object):\n        \"Map all child nodes to one object's attributes\"\n\n        for n in list(node):\n            self.node_to_object(n, object)", "response": "Map all child nodes to one object s attributes"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmap a single node to one object s attributes", "response": "def node_to_object(self, node, object):\n        \"Map a single node to one object's attributes\"\n\n        attribute = self.to_lower(node.tag)\n\n        # Yield is a protected keyword in Python, so let's rename it\n        attribute = \"_yield\" if attribute == \"yield\" else attribute\n\n        try:\n            valueString = node.text or \"\"\n            value = float(valueString)\n        except ValueError:\n            value = node.text\n\n        try:\n            setattr(object, attribute, value)\n        except AttributeError():\n            sys.stderr.write(\"Attribute <%s> not supported.\" % attribute)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse(self, xml_file):\n        \"Get a list of parsed recipes from BeerXML input\"\n\n        recipes = []\n\n        with open(xml_file, \"rt\") as f:\n            tree = ElementTree.parse(f)\n\n        for recipeNode in tree.iter():\n            if self.to_lower(recipeNode.tag) != \"recipe\":\n                continue\n\n            recipe = Recipe()\n            recipes.append(recipe)\n\n            for recipeProperty in list(recipeNode):\n                tag_name = self.to_lower(recipeProperty.tag)\n\n                if tag_name == \"fermentables\":\n                    for fermentable_node in list(recipeProperty):\n                        fermentable = Fermentable()\n                        self.nodes_to_object(fermentable_node, fermentable)\n                        recipe.fermentables.append(fermentable)\n\n                elif tag_name == \"yeasts\":\n                    for yeast_node in list(recipeProperty):\n                        yeast = Yeast()\n                        self.nodes_to_object(yeast_node, yeast)\n                        recipe.yeasts.append(yeast)\n\n                elif tag_name == \"hops\":\n                    for hop_node in list(recipeProperty):\n                        hop = Hop()\n                        self.nodes_to_object(hop_node, hop)\n                        recipe.hops.append(hop)\n\n                elif tag_name == \"miscs\":\n                    for misc_node in list(recipeProperty):\n                        misc = Misc()\n                        self.nodes_to_object(misc_node, misc)\n                        recipe.miscs.append(misc)\n\n                elif tag_name == \"style\":\n                    style = Style()\n                    recipe.style = style\n                    self.nodes_to_object(recipeProperty, style)\n\n                elif tag_name == \"mash\":\n\n                    for mash_node in list(recipeProperty):\n                        mash = Mash()\n                        recipe.mash = mash\n\n                        if self.to_lower(mash_node.tag) == \"mash_steps\":\n                            for mash_step_node in list(mash_node):\n                                mash_step = MashStep()\n                                self.nodes_to_object(mash_step_node, mash_step)\n                                mash.steps.append(mash_step)\n                        else:\n                            self.nodes_to_object(mash_node, mash)\n\n                else:\n                    self.node_to_object(recipeProperty, recipe)\n\n        return recipes", "response": "Get a list of parsed recipes from BeerXML input"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_lower(self, string):\n        \"Helper function to transform strings to lower case\"\n        value = None\n        try:\n            value = string.lower()\n        except AttributeError:\n            value = \"\"\n        finally:\n            return value", "response": "Helper function to transform strings to lower case"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the section and key in dot notation format.", "response": "def _to_dot_key(cls, section, key=None):\n        \"\"\" Return the section and key in dot notation format. \"\"\"\n        if key:\n            return (NON_ALPHA_NUM.sub('_', section.lower()), NON_ALPHA_NUM.sub('_', key.lower()))\n        else:\n            return NON_ALPHA_NUM.sub('_', section.lower())"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a dot key to the internal dict.", "response": "def _add_dot_key(self, section, key=None):\n        \"\"\"\n        :param str section: Config section\n        :param str key: Config key\n        \"\"\"\n        if key:\n            self._dot_keys[self._to_dot_key(section, key)] = (section, key)\n        else:\n            self._dot_keys[self._to_dot_key(section)] = section"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread the config sources.", "response": "def read(self, sources):\n        \"\"\"\n        Queues the config sources to be read later (when config is accessed), or reads immediately if config has already\n        been accessed.\n\n        :param file/str/list sources: Config source string, file name, or file pointer, or list of the other sources.\n                                      If file source does not exist, it is ignored.\n        :return: True if all sources were successfully read or will be read, otherwise False\n        \"\"\"\n\n        all_read = True\n\n        if not isinstance(sources, list):\n            sources = [sources]\n\n        if self._sources_read:\n            for source in sources:\n                all_read &= self._read(source)\n        else:\n            for i, source in enumerate(sources):\n                if isinstance(source, IOBase):\n                    sources[i] = source.read()\n            self._sources.extend(sources)\n\n        return all_read"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nread and parses the config file", "response": "def _read(self, source):\n        \"\"\"\n        Reads and parses the config source\n\n        :param file/str source: Config source string, file name, or file pointer. If file name does not exist, it is\n                                ignored.\n        :return: True if source was successfully read, otherwise False\n        \"\"\"\n\n        if isinstance(source, str) and is_config(source):\n            source_fp = StringIO(source)\n        elif isinstance(source, IOBase) or isinstance(source, StringIO):\n            source_fp = source\n        elif os.path.exists(source):\n            source_fp = open(source)\n        else:\n            return False\n\n        self._parser.read_file(source_fp)\n        self._parse_extra(source_fp)\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsave the current config to a file.", "response": "def save(self, target_file=None, as_template=False):\n        \"\"\"\n        Save the config\n\n        :param str target_file: File to save to. Defaults to `self._last_source` if set\n        :param bool as_template: Save the config with all keys and sections commented out for user to modify\n        :raise AttributeError: if target file is not provided and `self._last_source` is not set\n        \"\"\"\n        self._read_sources()\n\n        if not target_file:\n            if not self._last_source:\n                raise AttributeError('Target file is required when last source is not set during instantiation')\n            target_file = self._last_source\n\n        output = str(self)\n\n        if as_template:\n            output_tmpl = []\n            for line in output.split('\\n'):\n                if line and not line.startswith('#'):\n                    line = '# %s' % line\n                output_tmpl.append(line)\n            output = '\\n'.join(output_tmpl)\n\n        with open(target_file, 'w') as fp:\n            fp.write(output)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _parse_extra(self, fp):\n\n        comment = ''\n        section = ''\n\n        fp.seek(0)\n        for line in fp:\n            line = line.rstrip()\n\n            if not line:\n                if comment:\n                    comment += '\\n'\n                continue\n\n            if line.startswith('#'):  # Comment\n                comment += line + '\\n'\n                continue\n\n            if line.startswith('['):  # Section\n                section = line.strip('[]')\n                self._add_dot_key(section)\n                if comment:\n                    self._comments[section] = comment.rstrip()\n\n            elif CONFIG_KEY_RE.match(line):  # Config\n                key = line.split('=', 1)[0].strip()\n                self._add_dot_key(section, key)\n                if comment:\n                    self._comments[(section, key)] = comment.rstrip()\n\n            comment = ''\n\n        if comment:\n            self._comments[self.LAST_COMMENT_KEY] = comment", "response": "Parse and store the comments and create maps for dot notion lookup"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(self, section, key, default=NO_DEFAULT_VALUE):\n        self._read_sources()\n\n        if (section, key) in self._dot_keys:\n            section, key = self._dot_keys[(section, key)]\n\n        try:\n            value = self._parser.get(section, key)\n        except Exception:\n            if default == NO_DEFAULT_VALUE:\n                return None\n            else:\n                return default\n\n        return self._typed_value(value)", "response": "Get the config value with data type transformation"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set(self, section, key, value, comment=None):\n\n        self._read_sources()\n\n        if (section, key) in self._dot_keys:\n            section, key = self._dot_keys[(section, key)]\n        elif section in self._dot_keys:\n            section = self._dot_keys[section]\n\n        if not isinstance(value, str):\n            value = str(value)\n\n        self._parser.set(section, key, value)\n\n        self._add_dot_key(section, key)\n        if comment:\n            self._set_comment(section, comment, key)", "response": "Set the value of the key in section to value."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntransforming string value to an actual data type of the same value.", "response": "def _typed_value(self, value):\n        \"\"\" Transform string value to an actual data type of the same value. \"\"\"\n\n        if value not in self._value_cache:\n            new_value = value\n            if is_int(value):\n                new_value = int(value)\n            elif is_float(value):\n                new_value = float(value)\n            elif is_bool(value):\n                new_value = to_bool(value)\n            elif is_none(value):\n                new_value = None\n            self._value_cache[value] = new_value\n\n        return self._value_cache[value]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_section(self, section, comment=None):\n        self._read_sources()\n\n        if self._to_dot_key(section) in self._dot_keys:\n            raise DuplicateSectionError(section)\n\n        self._parser.add_section(section)\n        self._add_dot_key(section)\n        if comment:\n            self._set_comment(section, comment)", "response": "Add a section to the log."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting a comment for the key or the section", "response": "def _set_comment(self, section, comment, key=None):\n        \"\"\"\n        Set a comment for section or key\n\n        :param str section: Section to add comment to\n        :param str comment: Comment to add\n        :param str key: Key to add comment to\n        \"\"\"\n\n        if '\\n' in comment:\n            comment = '\\n# '.join(comment.split('\\n'))\n        comment = '# ' + comment\n\n        if key:\n            self._comments[(section, key)] = comment\n        else:\n            self._comments[section] = comment"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting items for a given section", "response": "def items(self, section):\n        \"\"\"\n        Items for section with data type transformation (from str)\n\n        :param str section: Section to get items for.\n        :return: Generator of (key, value) for the section\n        \"\"\"\n        self._read_sources()\n\n        if section in self._dot_keys:\n            section = self._dot_keys[section]\n\n        for item in self._parser.items(section):\n            key, value = item\n            value = self._typed_value(value)\n            yield (key, value)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalculates appropriate sizes for the subfigures", "response": "def getfigsize(self, opt):\n        '''calculate appropriate sizes for the subfigures\n        '''\n        if opt.xmin is None:\n            opt.xmin = self.plotman.grid.grid['x'].min()\n        if opt.xmax is None:\n            opt.xmax = self.plotman.grid.grid['x'].max()\n        if opt.zmin is None:\n            opt.zmin = self.plotman.grid.grid['z'].min()\n        if opt.zmax is None:\n            opt.zmax = self.plotman.grid.grid['z'].max()\n        if np.abs(opt.zmax - opt.zmin) < np.abs(opt.xmax - opt.xmin):\n            self.sizex = 2 / 2.54\n            self.sizez = self.sizex * (\n                    np.abs(opt.zmax - opt.zmin) / np.abs(opt.xmax - opt.xmin))\n        else:\n            self.sizez = 2 / 2.54\n            self.sizex = 0.5 * self.sizez * (\n                    np.abs(opt.xmax - opt.xmin) / np.abs(opt.zmax - opt.zmin))\n            print('schmal')\n        # add 1 inch to accommodate colorbar\n        self.sizex += 4 * .5\n        self.sizex *= 4\n        self.sizez *= self.rows\n        self.sizez += 5"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading grid and calculate alpha values from the coverage / 2. 5.", "response": "def load_grid(self, alpha):\n        '''Load grid and calculate alpha values from the coverage/2.5.\n        '''\n        grid = CRGrid.crt_grid(self.dirs[0] + '/grid/elem.dat',\n                               self.dirs[0] + '/grid/elec.dat')\n        self.plotman = CRPlot.plotManager(grid=grid)\n\n        name = self.dirs[0] + '/inv/coverage.mag'\n        content = np.genfromtxt(name, skip_header=1,\n                                skip_footer=1, usecols=([2]))\n        abscov = np.abs(content)\n        if alpha:\n            normcov = np.divide(abscov, 2.5)\n            normcov[np.where(normcov > 1)] = 1\n            mask = np.subtract(1, normcov)\n            self.alpha = self.plotman.parman.add_data(mask)\n        else:\n            self.alpha = self.plotman.parman.add_data(np.ones(len(abscov)))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _sample_actions(self,\n            state: Sequence[tf.Tensor]) -> Tuple[Sequence[tf.Tensor], tf.Tensor, tf.Tensor]:\n        '''Returns sampled action fluents and tensors related to the sampling.\n\n        Args:\n            state (Sequence[tf.Tensor]): A list of state fluents.\n\n        Returns:\n            Tuple[Sequence[tf.Tensor], tf.Tensor, tf.Tensor]: A tuple with\n            action fluents, an integer tensor for the number of samples, and\n            a boolean tensor for checking all action preconditions.\n        '''\n        default = self.compiler.compile_default_action(self.batch_size)\n        bound_constraints = self.compiler.compile_action_bound_constraints(state)\n        action = self._sample_action(bound_constraints, default)\n        n, action, checking = self._check_preconditions(state, action, bound_constraints, default)\n        return action, n, checking", "response": "Returns sampled action fluents and tensors related to the sampling."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _check_preconditions(self,\n            state: Sequence[tf.Tensor],\n            action: Sequence[tf.Tensor],\n            bound_constraints: Dict[str, Constraints],\n            default: Sequence[tf.Tensor]) -> Tuple[tf.Tensor, Sequence[tf.Tensor], tf.Tensor]:\n        '''Samples action fluents until all preconditions are satisfied.\n\n        Checks action preconditions for the sampled `action` and current `state`,\n        and iff all preconditions are satisfied it returns the sampled action fluents.\n\n        Args:\n            state (Sequence[tf.Tensor]): A list of state fluents.\n            action (Sequence[tf.Tensor]): A list of action fluents.\n            bound_constraints (Dict[str, Tuple[Optional[TensorFluent], Optional[TensorFluent]]]): The bounds for each action fluent.\n            default (Sequence[tf.Tensor]): The default action fluents.\n\n        Returns:\n            Tuple[tf.Tensor, Sequence[tf.Tensor], tf.Tensor]: A tuple with\n            an integer tensor corresponding to the number of samples,\n            action fluents and a boolean tensor for checking all action preconditions.\n        '''\n\n        def condition(i, a, checking):\n            not_checking = tf.reduce_any(tf.logical_not(checking))\n            return not_checking\n\n        def body(i, a, checking):\n            new_action = []\n            new_sampled_action = self._sample_action(bound_constraints, default)\n            new_preconds_checking = self.compiler.compile_action_preconditions_checking(state, new_sampled_action)\n            for action_fluent, new_sampled_action_fluent in zip(a, new_sampled_action):\n                new_action_fluent = tf.where(checking, action_fluent, new_sampled_action_fluent)\n                new_action.append(new_action_fluent)\n            new_action = tuple(new_action)\n            new_checking = tf.logical_or(checking, new_preconds_checking)\n            return (i + 1, new_action, new_checking)\n\n        i0 = tf.constant(0)\n        preconds_checking = self.compiler.compile_action_preconditions_checking(state, action)\n        return tf.while_loop(condition, body, loop_vars=[i0, action, preconds_checking])", "response": "Returns a tuple of the fluents and the actions that are in the state and the default action fluents."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _sample_action(self,\n            constraints: Dict[str, Constraints],\n            default: Sequence[tf.Tensor],\n            prob: float = 0.3) -> Sequence[tf.Tensor]:\n        '''Samples action fluents respecting the given bound `constraints`.\n\n        With probability `prob` it chooses the action fluent default value,\n        with probability 1-`prob` it samples the fluent w.r.t. its bounds.\n\n        Args:\n            constraints (Dict[str, Tuple[Optional[TensorFluent], Optional[TensorFluent]]]): The bounds for each action fluent.\n            default (Sequence[tf.Tensor]): The default action fluents.\n            prob (float): A probability measure.\n\n        Returns:\n            Sequence[tf.Tensor]: A tuple of action fluents.\n        '''\n        ordering = self.compiler.rddl.domain.action_fluent_ordering\n        dtypes = map(rddl2tf.utils.range_type_to_dtype, self.compiler.rddl.action_range_type)\n        size = self.compiler.rddl.action_size\n\n        action = []\n        for name, dtype, size, default_value in zip(ordering, dtypes, size, default):\n            action_fluent = self._sample_action_fluent(name, dtype, size, constraints, default_value, prob)\n            action.append(action_fluent)\n\n        return tuple(action)", "response": "Samples action fluents respecting the given constraints."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _sample_action_fluent(self,\n            name: str,\n            dtype: tf.DType,\n            size: Sequence[int],\n            constraints: Dict[str, Constraints],\n            default_value: tf.Tensor,\n            prob: float) -> tf.Tensor:\n        '''Samples the action fluent with given `name`, `dtype`, and `size`.\n\n        With probability `prob` it chooses the action fluent `default_value`,\n        with probability 1-`prob` it samples the fluent w.r.t. its `constraints`.\n\n        Args:\n            name (str): The name of the action fluent.\n            dtype (tf.DType): The data type of the action fluent.\n            size (Sequence[int]): The size and shape of the action fluent.\n            constraints (Dict[str, Tuple[Optional[TensorFluent], Optional[TensorFluent]]]): The bounds for each action fluent.\n            default_value (tf.Tensor): The default value for the action fluent.\n            prob (float): A probability measure.\n\n        Returns:\n            tf.Tensor: A tensor for sampling the action fluent.\n        '''\n        shape = [self.batch_size] + list(size)\n\n        if dtype == tf.float32:\n            bounds = constraints.get(name)\n            if bounds is None:\n                low, high = -self.MAX_REAL_VALUE, self.MAX_REAL_VALUE\n                dist = tf.distributions.Uniform(low=low, high=high)\n                sampled_fluent = dist.sample(shape)\n            else:\n                low, high = bounds\n                batch = (low is not None and low.batch) or (high is not None and high.batch)\n                low = tf.cast(low.tensor, tf.float32) if low is not None else -self.MAX_REAL_VALUE\n                high = tf.cast(high.tensor, tf.float32) if high is not None else self.MAX_REAL_VALUE\n                dist = tf.distributions.Uniform(low=low, high=high)\n                if batch:\n                    sampled_fluent = dist.sample()\n                elif isinstance(low, tf.Tensor) or isinstance(high, tf.Tensor):\n                    if (low+high).shape.as_list() == list(size):\n                        sampled_fluent = dist.sample([self.batch_size])\n                    else:\n                        raise ValueError('bounds are not compatible with action fluent.')\n                else:\n                    sampled_fluent = dist.sample(shape)\n        elif dtype == tf.int32:\n            logits = [1.0] * self.MAX_INT_VALUE\n            dist = tf.distributions.Categorical(logits=logits, dtype=tf.int32)\n            sampled_fluent = dist.sample(shape)\n        elif dtype == tf.bool:\n            probs = 0.5\n            dist = tf.distributions.Bernoulli(probs=probs, dtype=tf.bool)\n            sampled_fluent = dist.sample(shape)\n\n        select_default = tf.distributions.Bernoulli(prob, dtype=tf.bool).sample(self.batch_size)\n        action_fluent = tf.where(select_default, default_value, sampled_fluent)\n\n        return action_fluent", "response": "Samples the action fluent with given name dtype and size and returns the tensor of the action fluent."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\npublishing an event to the broker.", "response": "async def emit_event(self, event):\n        \"\"\"\n        Publish an event\n        :param event: Event object\n        \"\"\"\n        self.log.info(\"publishing event on %s\", self.publish_topic)\n        if self.config.extra['config']['pub_options']['retain']:\n            try:\n                await persist_event(\n                    self.publish_topic,\n                    event,\n                    self.pool\n                )\n            except SystemError as error:\n                self.log.error(error)\n                return\n\n        loop = asyncio.get_event_loop()\n        producer = AIOKafkaProducer(\n            loop=loop,\n            bootstrap_servers=self.transport_host\n        )\n        await producer.start()\n\n        try:\n            event = json.dumps(event.__dict__).encode()\n            await producer.send_and_wait(\n                self.publish_topic,\n                event\n            )\n        finally:\n            await producer.stop()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nbuild LNode instance from Unit instance u and optional node to LNode instance toL.", "response": "def UnitToLNode(u: Unit, node: Optional[LNode]=None,\n                toL: Optional[dict]=None,\n                optimizations=[]) -> LNode:\n    \"\"\"\n    Build LNode instance from Unit instance\n\n    :attention: unit has to be synthesized\n    \"\"\"\n    if toL is None:\n        toL = {}\n    if node is None:\n        root = LNode(name=u._name, originObj=u, node2lnode=toL)\n    else:\n        root = node\n\n    stmPorts = {}\n\n    # {RtlSignal: NetCtx}\n    netCtx = NetCtxs(root)\n\n    # create subunits\n    for su in u._units:\n        n = root.addNode(name=su._name, originObj=su)\n        UnitToLNode(su, n, toL, optimizations)\n\n    # create subunits from statements\n    for stm in u._ctx.statements:\n        n = addStmAsLNode(root, stm, stmPorts, netCtx)\n\n    # create ports for this unit\n    for intf in u._interfaces:\n        addPort(root, intf)\n\n    # render content of statements\n    for stm in u._ctx.statements:\n        n = toL.get(stm, None)\n        if n is not None:\n            if isinstance(n, VirtualLNode):\n                # statement is not in wrap and does not need any port context\n                p = None\n            else:\n                # statement is in wrap and needs a port context\n                # to resolve port connections to wrap\n                p = stmPorts[n]\n\n            r = StatementRenderer(n, toL, p, netCtx)\n            r.renderContent()\n\n    # connect nets inside this unit\n    for s in u._ctx.signals:\n        if not s.hidden:\n            net, _ = netCtx.getDefault(s)\n            for e in s.endpoints:\n                if isinstance(e, PortItem):\n                    net.addEndpoint(toL[e])\n\n            for d in s.drivers:\n                if isinstance(d, PortItem):\n                    net.addDriver(toL[d])\n\n    netCtx.applyConnections(root)\n\n    for opt in optimizations:\n        opt(root)\n\n    isRootOfWholeGraph = root.parent is None\n    if not isRootOfWholeGraph:\n        for intf in u._interfaces:\n            # connect my external port to port on my container on parent\n            # also override toL to use this new port\n            ext_p = toL[originObjOfPort(intf)].parentNode\n            nodePort = addPortToLNode(root, intf)\n            # connect this node which represents port to port of this node\n            if intf._direction == INTF_DIRECTION.SLAVE:\n                src = nodePort\n                dst = ext_p.addPort(\"\", PortType.INPUT, PortSide.WEST)\n            else:\n                src = ext_p.addPort(\"\", PortType.OUTPUT, PortSide.EAST)\n                dst = nodePort\n\n            root.addEdge(src, dst, name=repr(intf), originObj=intf)\n\n    return root"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef deploy_hypervisor(self):\n        self.yum_install(['libvirt-daemon-driver-nwfilter', 'libvirt-client', 'libvirt-daemon-config-network', 'libvirt-daemon-driver-nodedev', 'libvirt-daemon-kvm', 'libvirt-python', 'libvirt-daemon-config-nwfilter', 'libvirt-glib', 'libvirt-daemon', 'libvirt-daemon-driver-storage', 'libvirt', 'libvirt-daemon-driver-network', 'libvirt-devel', 'libvirt-gobject', 'libvirt-daemon-driver-secret', 'libvirt-daemon-driver-qemu', 'libvirt-daemon-driver-interface', 'libguestfs-tools', 'virt-install', 'genisoimage', 'openstack-tripleo', 'instack-undercloud'])\n        self.run('sed -i \"s,#auth_unix_rw,auth_unix_rw,\" /etc/libvirt/libvirtd.conf')\n        self.run('systemctl start libvirtd')\n        self.run('systemctl status libvirtd')\n\n        self.install_base_packages()\n        self.clean_system()\n        self.yum_update()", "response": "Deploy the hypervisor and the base packages."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef build_undercloud_on_libvirt(self, image_path,\n                                    rhsm=None, repositories=[]):\n        \"\"\"Build the Undercloud by using instack-virt-setup script.\"\"\"\n        self.run('sysctl net.ipv4.ip_forward=1')\n        self.fetch_image(path=image_path, dest='/home/stack/guest_image.qcow2',\n                         user='stack')\n        # NOTE(Gon\u00e9ri): this is a hack for our OpenStack, the MTU of its outgoing route\n        # is 1400 and libvirt do not provide a mechanism to adjust the guests MTU.\n        self.run(\"LIBGUESTFS_BACKEND=direct virt-customize -a /home/stack/guest_image.qcow2 --run-command 'echo MTU=\\\"1400\\\" >> /etc/sysconfig/network-scripts/ifcfg-eth0'\")\n\n        env = Environment()\n        env.loader = FileSystemLoader(pkg_data_filename('template'))\n        template = env.get_template('virt-setup-env.j2')\n        self.run('mkdir -p /home/stack/DIB', user='stack')\n        self.run('cp -v /etc/yum.repos.d/*.repo /home/stack/DIB', user='stack')\n        # NOTE(Gon\u00e9ri): Hack to be sure DIB won't complain because of missing gpg files\n        # self.run('sed -i \"s,gpgcheck=1,gpgcheck=0,\" /home/stack/DIB/*.repo', user='stack')\n        dib_yum_repo_conf = self.run('find /home/stack/DIB -type f', user='stack')[0].split()\n        virt_setup_template = {\n            'dib_yum_repo_conf': dib_yum_repo_conf,\n            'node': {\n                'count': 2,\n                'mem': 6144,\n                'cpu': 2\n            },\n            'undercloud_node_mem': 8192,\n            'guest_image_name': '/home/stack/guest_image.qcow2'\n        }\n\n        if rhsm is not None:\n            virt_setup_template['rhsm'] = {\n                'login': rhsm.get('login'),\n                'password': rhsm.get('password', os.environ.get('RHN_PW')),\n                'pool_id': rhsm.get('pool_id', ''),\n                'repositories': [i['name'] for i in repositories if i['type'] == 'rhsm_channel']\n            }\n        virt_setup_env = template.render(virt_setup_template)\n        self.create_file('virt-setup-env', virt_setup_env, user='stack')\n        self.run('virsh destroy instack', ignore_error=True)\n        self.run('virsh undefine instack --remove-all-storage', ignore_error=True)\n        self.run('source virt-setup-env; instack-virt-setup', user='stack')\n        undercloud_ip = self.run(\n            '/sbin/ip n | grep $(tripleo get-vm-mac instack) | awk \\'{print $1;}\\'',\n            user='stack')[0]\n        assert undercloud_ip, 'undercloud should have an IP'\n        undercloud = Undercloud(hostname=undercloud_ip,\n                                via_ip=self.hostname,\n                                user='root',\n                                key_filename=self._key_filename)\n        return undercloud", "response": "Build the Undercloud by using instack - virt - setup script."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef login(config, api_key=\"\"):\n    if not api_key:\n        info_out(\n            \"If you don't have an API Key, go to:\\n\"\n            \"https://bugzilla.mozilla.org/userprefs.cgi?tab=apikey\\n\"\n        )\n        api_key = getpass.getpass(\"API Key: \")\n\n    # Before we store it, let's test it.\n    url = urllib.parse.urljoin(config.bugzilla_url, \"/rest/whoami\")\n    assert url.startswith(\"https://\"), url\n    response = requests.get(url, params={\"api_key\": api_key})\n    if response.status_code == 200:\n        if response.json().get(\"error\"):\n            error_out(\"Failed - {}\".format(response.json()))\n        else:\n            update(\n                config.configfile,\n                {\n                    \"BUGZILLA\": {\n                        \"bugzilla_url\": config.bugzilla_url,\n                        \"api_key\": api_key,\n                        # \"login\": login,\n                    }\n                },\n            )\n            success_out(\"Yay! It worked!\")\n    else:\n        error_out(\"Failed - {} ({})\".format(response.status_code, response.json()))", "response": "Store your Bugzilla API Key"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove and forget your Bugzilla credentials", "response": "def logout(config):\n    \"\"\"Remove and forget your Bugzilla credentials\"\"\"\n    state = read(config.configfile)\n    if state.get(\"BUGZILLA\"):\n        remove(config.configfile, \"BUGZILLA\")\n        success_out(\"Forgotten\")\n    else:\n        error_out(\"No stored Bugzilla credentials\")"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_hypergeometric_stats(N, indices):\n    assert isinstance(N, (int, np.integer))\n    assert isinstance(indices, np.ndarray) and \\\n            np.issubdtype(indices.dtype, np.uint16)\n\n    K = indices.size\n\n    pvals = np.empty(N+1, dtype=np.float64)\n    folds = np.empty(N+1, dtype=np.float64)\n    pvals[0] = 1.0\n    folds[0] = 1.0\n\n    n = 0\n    k = 0\n    p = 1.0\n    while n < N:\n        if k < K and indices[k] == n:\n            # \"add one\"\n            # calculate f(k+1; N,K,n+1) from f(k; N,K,n)\n            p *= (float((n+1) * (K-k)) / \\\n                  float((N-n) * (k+1)))\n            k += 1\n        else:\n            # \"add zero\"\n            # calculate f(k; N,K,n+1) from f(k; N,K,n)\n            p *= (float((n+1) * (N-K-n+k)) /\n                  float((N-n) * (n-k+1)))\n        n += 1\n        # calculate hypergeometric p-value\n        pvals[n] = get_hgp(p, k, N, K, n)\n        # calculate fold enrichment\n        folds[n] = k / (K*(n/float(N)))\n\n    return pvals, folds", "response": "Calculates the hypergeometric p - values and fold enrichments for all cutoffs."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_result_figure(\n        result, show_title=False, title=None, show_inset=True,\n        plot_fold_enrichment=False,\n        width=800, height=350, font_size=24, margin=None,\n        font_family='Computer Modern Roman, serif',\n        score_color='rgb(0,109,219)',\n        enrichment_color='rgb(219,109,0)',\n        cutoff_color='rgba(255, 52, 52, 0.7)',\n        line_width=2.0,\n        ymax=None,\n        mHG_label=False):\n    \"\"\"Visualize an XL-mHG test result.\n\n    Parameters\n    ----------\n    result : `mHGResult`\n        The test result.\n    show_title : bool, optional\n        Whether to include a title in the figure. If `title` is not\n        ``None``, this parameter is ignored. [False]\n    title : str or None, optional\n        Figure title. If not ``None``, `show_title` is ignored. [None]\n    show_inset : bool, optional\n        Whether to show test parameters and p-value as an inset. [True]\n    plot_fold_enrichment : bool, optional\n        Whether to plot the fold enrichment on a second axis. [False]\n    width : int, optional\n        The width of the figure (in pixels). [800]\n    height : int, optional\n        The height of the figure (in pixels). [350]\n    font_size : int, optional\n        The font size to use. [20]\n    margin : dict, optional\n        A dictionary specifying the figure margins (in pixels).\n        Valid keys are \"l\" (left), \"r\" (right), \"t\" (top), and \"b\" (bottom).\n        Missing keys are replaced by Plotly default values. If ``None``, will\n        be set to a dictionary specifying a left margin of 100 px, and a top\n        margin of 40 px. [None]\n    font_family : str, optional\n        The font family (name) to use. [\"Computer Modern Roman, serif\"]\n    score_color : str, optional\n        The color used for plotting the enrichment scores. [\"rgb(0,109,219)\"]\n    enrichment_color : str, optional\n        The color used for plotting the fold enrichment values (if enabled).\n        [\"rgb(219,109,0)\"]\n    cutoff_color : str, optional\n        The color used for indicating the XL-mHG test cutoff.\n        [\"rgba(255, 109,182,0.5)\"]\n    line_width : int or float, optional\n        The line width used for plotting. [2.0]\n    ymax : int or float or None, optional\n        The y-axis limit. If ``None``, determined automatically. [None]\n    mHG_label : bool, optional\n        If ``True``, label the p-value with \"mHG\" instead of \"XL-mHG\". [False]\n\n    Returns\n    -------\n    `plotly.graph_obs.Figure`\n        The Plotly figure.\n    \"\"\"\n\n    assert isinstance(result, mHGResult)\n    assert isinstance(show_title, bool)\n    if title is not None:\n        assert isinstance(title, (str, _oldstr))\n    assert isinstance(show_inset, bool)\n    assert isinstance(plot_fold_enrichment, bool)\n    assert isinstance(font_family, (str, _oldstr))\n    assert isinstance(width, int)\n    assert isinstance(height, int)\n    assert isinstance(font_size, (int, float))\n    if margin is not None:\n        assert isinstance(margin, dict)\n    assert isinstance(score_color, (str, _oldstr))\n    assert isinstance(enrichment_color, (str, _oldstr))\n    assert isinstance(line_width, (int, float))\n    if ymax is not None:\n        assert isinstance(ymax, (int, float))\n    assert isinstance(mHG_label, bool)\n\n    pvals, folds = get_hypergeometric_stats(result.N, result.indices)\n    pval_max = max(int(ceil(-np.log10(np.amin(pvals)))), 1.0)\n\n    if ymax is not None:\n        pval_max = ymax\n\n    pval_min = 0.0\n    X = result.X\n    L = result.L\n    N = result.N\n    K = result.K\n    fold_start = result.indices[0] + 1\n\n    data = []\n\n    # generate p-value trace\n    data.append(go.Scatter(\n        x=np.arange(N+1),\n        y=-np.log10(pvals),\n        mode='line',\n        line=dict(\n            color=score_color,\n            width=line_width,\n        ),\n        name='Enrichment score'\n    ))\n\n    # generate p-value axis\n    tick_color = None\n    if plot_fold_enrichment:\n        tick_color = score_color\n    yaxis = go.YAxis(\n        #title='-log<sub>10</sub>(hypergeom. p-value)',\n        title='Enrichment score',\n        tickfont=dict(\n            color=tick_color,\n        ),\n        autorange=False,\n        #range=[pval_min, pval_max],\n        range=[pval_min, pval_max],\n        showgrid=False,\n        #zeroline=False,\n        zeroline=False,\n        showline=True,\n        domain=[0.15, 1.0],\n        #mirror=True,\n    )\n\n    # additional y axis at the the bottom,\n    # showing the occurrences of the \"1's\"\n    yaxis3 = go.YAxis(\n        domain=[0, 0.1],\n        anchor='x',\n        mirror=True,\n        zeroline=False,\n        showline=False,\n        showgrid=False,\n        autorange=False,\n        range=[0, 1],\n        ticks='',\n        showticklabels=False,\n    )\n\n    # format p-value string\n    pval_str = '%.1e' % (result.pval)\n    e_idx = pval_str.index('e')\n    exponent = int(pval_str[(e_idx + 1):])\n    pval_str = pval_str[:e_idx] + '*10<sup>%d</sup>' % exponent\n\n    # fe_str = '%.1fx' % (result.fold_enrichment)\n\n    # if show_title:\n    if show_title and title is None:\n        title = 'XL-mHG test result (N=%d, K=%d)' % (N, K)\n\n    # specify margins (if not provided)\n    if margin is None:\n        t = 42\n        if title is None:\n            t = 22\n        margin = dict(\n            l=70,\n            t=t,\n            b=60,\n        )\n\n    if plot_fold_enrichment:\n        fold_min_int = -0.3\n        if np.log2(np.amin(folds[fold_start:])) < -0.3:\n            fold_min_int = int(floor(np.log2(np.amin(folds[fold_start:]))))\n        fold_max_int = max(int(ceil(np.log2(np.amax(folds)))), 2)\n\n        # generate fold enrichment trace\n        data.append(go.Scatter(\n            x=np.arange(fold_start, result.N + 1),\n            y=np.log2(folds[fold_start:]),\n            yaxis='y2',\n            mode='line',\n            line=dict(\n                color=enrichment_color,\n                width=line_width\n            ),\n        ))\n\n        # generate fold enrichment axis\n        yaxis2 = go.YAxis(\n            title='log<sub>2</sub>(Fold enrichment)',\n            # titlefont=dict(\n            #    color='rgb(148, 103, 189)'\n            # ),\n            tickfont=dict(\n                color=enrichment_color,\n            ),\n            range=[fold_min_int, fold_max_int],\n            overlaying='y',\n            side='right',\n            showgrid=False,\n            zeroline=False,\n            showline=True,\n        )\n\n    font = dict(\n        size=font_size,\n        family=font_family,\n    )\n\n    # rectangles showing which ranks are excluded\n    # in the calculation of the test statistic\n    # (due to X and L parameters)\n    rect_col = 'rgba(60,60,60,0.10)'\n\n    rect1_x1 = 0\n    if result.X > 0:\n        if result.X < result.K:\n            rect1_x1 = result.indices[result.X-1] + 0.5\n        else:\n            rect1_x1 = result.N\n    rect1 = {\n        'type': 'rect',\n        'x0': 0,\n        'y0': pval_min,\n        'x1': rect1_x1,\n        'y1': pval_max,\n        'line': dict(\n            width=0,\n        ),\n        'fillcolor': rect_col,\n    }\n    rect2 = {\n        'type': 'rect',\n        'x0': L+0.5,\n        'y0': pval_min,\n        'x1': N,\n        'y1': pval_max,\n        'line': dict(\n            width=0,\n        ),\n        'fillcolor': rect_col,\n    }\n\n    # bars in second Y axis symbolizing the occurrences of the \"1's\"\n    bars = []\n    for n in result.indices:\n        bars.append(dict(\n            type='line',\n            x0=n+1.0,\n            y0=0.0,\n            x1=n+1.0,\n            y1=1.0,\n            line=dict(\n                color='black',\n                width=line_width,\n            ),\n            yref='y3',\n            opacity=0.7,\n        ))\n\n    if not mHG_label:\n        # show XL-mHG p-value\n        pval_text = ('<b><i>p</i><sup>XL-mHG</sup> = '\n                     '%s</b><br>(X=%d, L=%d; %d/%d @ %d)') \\\n                    % (pval_str, result.X, result.L,\n                       result.k, result.K, result.cutoff)\n    else:\n        # show mHG p-value\n        pval_text = ('<b><i>p</i><sup>mHG</sup> = '\n                     '%s</b><br>(%d/%d @ %d)') \\\n                    % (pval_str,\n                       result.k, result.K, result.cutoff)\n\n    annotations = []\n    if show_inset:\n        annotations.append(\n            go.Annotation(\n                x=0.98,\n                y=0.96,\n                align='right',\n                showarrow=False,\n                text=pval_text,\n                xref='paper',\n                yref='paper',\n                xanchor='right',\n                yanchor='top',\n                font=font,\n            ),\n        )\n\n    line = {\n        'type': 'line',\n        'x0': result.cutoff,\n        'y0': pval_min,\n        'x1': result.cutoff,\n        'y1': pval_max,\n        'line': dict(\n            color=cutoff_color,\n            width=1.5*line_width,\n            dash='dash',\n        ),\n    }\n\n    line2 = {\n        'type': 'line',\n        'x0': 0,\n        'y0': 0,\n        'x1': result.N,\n        'y1': 0,\n        'line': dict(\n            color='black',\n            width=1.0,\n        ),\n    }\n\n    layout = go.Layout(\n        width=width,\n        height=height,\n        margin=margin,\n        xaxis=dict(\n            title='Rank cutoff',\n            zeroline=False,\n            range=[1.0, result.N],\n            showline=True,\n            anchor='y3',\n        ),\n        yaxis=yaxis,\n        yaxis3=yaxis3,\n        titlefont=dict(\n            size=font_size,\n            family=font_family,\n        ),\n        font=dict(\n            size=font_size,\n            family=font_family,\n        ),\n        showlegend=False,\n        shapes=[\n            rect1,\n            rect2,\n            line,\n            line2,\n        ] + bars,\n        title=title,\n        annotations=annotations,\n    )\n\n    if plot_fold_enrichment:\n        layout.yaxis2 = yaxis2\n\n    fig = go.Figure(\n        data=data,\n        layout=layout,\n    )\n\n    return fig", "response": "Returns a figure that can be used to display the test result."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse(self, prefix):\n\t\t# reset to default values\n\t\tself._prefix = \"\"\n\n\t\turl = re.sub(r'http://', '', prefix)\n\t\turl = re.sub(r'https://', '', url)\n\n\t\t# any prefix customization before parsing?\n\t\tcustom_prefix = self.detectCustomImportPaths(url)\n\t\tif custom_prefix != {}:\n\t\t\turl = custom_prefix[\"provider_prefix\"]\n\n\t\tinfo = self._parsePrefix(url)\n\n\t\tself._signature = info[\"signature\"]\n\t\tself._prefix = info[\"prefix\"]\n\n\t\treturn self", "response": "Parse import path into provider project repository and other recognizable parts\n\tand other recognizable parts\n\tself. _prefix is the prefix of the import path."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndetects custom import paths for a given prefix", "response": "def detectCustomImportPaths(self, prefix):\n\t\t\"\"\"\n\t\tSome prefixes does not reflect provider prefix\n\t\te.g. camlistore.org/pkg/googlestorage is actually at\n\t\tgithub.com/camlistore/camlistore repository under\n\t\tpkg/googlestorage directory.\n\t\t\"\"\"\n\t\tfor assignment in self.ip2pp_mapping:\n\t\t\tif prefix.startswith(assignment[\"ipprefix\"]):\n\t\t\t\treturn {\"prefix\": assignment[\"ipprefix\"], \"provider_prefix\": assignment[\"provider_prefix\"]}\n\n\t\treturn {}"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef detectKnownRepo(self, url):\n\t\tif url.startswith('github.com'):\n\t\t\treturn GITHUB\n\t\tif url.startswith('code.google.com/p'):\n\t\t\treturn GOOGLECODE\n\t\tif url.startswith('golang.org/x'):\n\t\t\treturn GOLANGORG\n\t\tif url.startswith('gopkg.in'):\n\t\t\treturn GOPKG\n\t\tif url.startswith('bitbucket.org'):\n\t\t\treturn BITBUCKET\n\t\tif url.startswith('google.golang.org'):\n\t\t\treturn GOOGLEGOLANGORG\n\n\t\treturn UNKNOWN", "response": "For given import path detect provider."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse a github import path into a dictionary.", "response": "def parseGithubImportPath(self, path):\n\t\t\"\"\"\n\t\tDefinition: github.com/<project>/<repo>\n\t\t\"\"\"\n\t\tparts = path.split(\"/\")\n\n\t\tif len(parts) < 3:\n\t\t\traise ValueError(\"Import path %s not in github.com/<project>/<repo> form\" % path)\n\n\t\trepo = {}\n\t\trepo[\"prefix\"] = \"/\".join(parts[:3])\n\t\trepo[\"signature\"] = {\"provider\": \"github\", \"username\": parts[1], \"project\": parts[2]}\n\n\t\treturn repo"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse a path into a tuple of gopkg. in and gopkg. in. <v > and gopkg. in. <repo >. <v >.", "response": "def parseGopkgImportPath(self, path):\n\t\t\"\"\"\n\t\tDefinition: gopkg.in/<v>/<repo> || gopkg.in/<repo>.<v> || gopkg.in/<project>/<repo>\n\t\t\"\"\"\n\t\tparts = path.split('/')\n\t\tif re.match('v[0-9]+', parts[1]):\n\t\t\tif len(parts) < 3:\n\t\t\t\traise ValueError(\"Import path %s is not in gopkg.in/<v>/<repo> form\" % path)\n\n\t\t\tproject = \"\"\n\t\t\trepository = parts[2]\n\t\t\tversion = parts[1]\n\t\t\tprefix = \"/\".join(parts[:3])\n\t\t\tprovider_prefix = \"gopkg.in/%s/%s\" % (parts[1], parts[2])\n\t\telse:\n\t\t\tif len(parts) < 2:\n\t\t\t\traise ValueError(\"Import path %s is not in gopkg.in/[<repo>.<v>|<project>/<repo>] form\" % path)\n\n\t\t\tdotparts = parts[1].split(\".\")\n\t\t\tif len(dotparts) == 1:\n\t\t\t\t# gopkg.in/<project>/<repo>\n\t\t\t\tif len(parts) != 3:\n\t\t\t\t\traise ValueError(\"Import path %s is not in gopkg.in/<project>/<repo> form\" % path)\n\t\t\t\tprefix = \"/\".join(parts[:3])\n\t\t\t\tproject = parts[1]\n\t\t\t\tdotparts = parts[2].split(\".\")\n\t\t\t\trepository = dotparts[0]\n\t\t\t\tif len(dotparts) == 0:\n\t\t\t\t\tversion = \"\"\n\t\t\t\telse:\n\t\t\t\t\tversion = dotparts[1]\n\n\t\t\t\tprovider_prefix = \"gopkg.in/%s/%s\" % (parts[1], parts[2])\n\n\t\t\telse:\n\t\t\t\tif len(dotparts) != 2:\n\t\t\t\t\traise ValueError(\"Import path %s is not in gopkg.in/<repo>.<v> form\" % path)\n\t\t\t\tprefix = \"/\".join(parts[:2])\n\t\t\t\tproject = \"\"\n\t\t\t\trepository = dotparts[0]\n\t\t\t\tversion = dotparts[1]\n\t\t\t\tprovider_prefix = \"gopkg.in/%s\" % parts[1]\n\n\t\trepo = {}\n\t\trepo[\"prefix\"] = prefix\n\t\trepo[\"signature\"] = {\"provider\": \"gopkg\", \"username\": project, \"project\": repository, \"version\": version}\n\n\t\treturn repo"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef generate(bits, progress_func=None):\n        signing_key = ECDSA.generate()\n        key = ECDSAKey(vals=(signing_key, signing_key.get_verifying_key()))\n        return key", "response": "This factory function can be used to generate a new private RSA key. This factory function can be used to generate a new private RSA key."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the qualifier dictionary based on the element s qualifier vocabulary.", "response": "def get_qualifier_dict(vocabularies, qualifier_vocab):\n    \"\"\"Get the qualifier dictionary based on the element's qualifier\n    vocabulary.\n    \"\"\"\n    # Raise exception if the vocabulary can't be found.\n    if vocabularies.get(qualifier_vocab, None) is None:\n        raise UNTLFormException(\n            'Could not retrieve qualifier vocabulary \"%s\" for the form.'\n            % (qualifier_vocab)\n        )\n    else:\n        # Return the sorted vocabulary.\n        return vocabularies.get(qualifier_vocab)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the content dictionary based on the element s content vocabulary.", "response": "def get_content_dict(vocabularies, content_vocab):\n    \"\"\"Get the content dictionary based on the element's content\n    vocabulary.\n    \"\"\"\n    # Raise exception if the vocabulary can't be found.\n    if vocabularies.get(content_vocab, None) is None:\n        raise UNTLFormException(\n            'Could not retrieve content vocabulary \"%s\" for the form.'\n            % (content_vocab)\n        )\n    else:\n        # Return the sorted vocabulary.\n        return vocabularies.get(content_vocab)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndetermining if the entire group of elements is hidden.", "response": "def get_group_hidden(self):\n        \"\"\"Determine if the entire group of elements is hidden\n        (decide whether to hide the entire group).\n        \"\"\"\n        # Loop through all the elements in the group.\n        for element in self.group_list:\n            # Handle element that is not hidden or has a form.\n            if element.form.view_type != 'none':\n                return False\n            # Loop through the children to make sure elements aren't hidden.\n            for child_element in element.children:\n                # Handle child element that is not hidden or has a form.\n                if child_element.form.view_type != 'none':\n                    return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the usage link for the group element.", "response": "def get_group_usage_link(self):\n        \"\"\"Get the usage link for the group element.\"\"\"\n        first_element = self.group_list[0]\n        usage_link = getattr(first_element.form, 'usage_link', None)\n        return usage_link"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate an adjustable form from an element dispatch table.", "response": "def get_adjustable_form(self, element_dispatch):\n        \"\"\"Create an adjustable form from an element dispatch table.\"\"\"\n        adjustable_form = {}\n        # Loop through the qualifiers to create the adjustable form.\n        for key in element_dispatch.keys():\n            adjustable_form[key] = element_dispatch[key]()\n        return adjustable_form"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_coverage_placeName(self):\n        if (self.solr_response\n                and self.solr_response != 'error'\n                and self.solr_response.response != 'error'):\n            location_list = self.solr_response.get_location_list_facet().facet_list\n        else:\n            location_list = []\n        form_dict = {\n            'view_type': 'prefill',\n            'value_json': json.dumps(location_list, ensure_ascii=False),\n            'value_py': location_list,\n        }\n        return form_dict", "response": "Determine the properties for the placeName coverage field."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndetermines the form attributes for the meta field.", "response": "def get_meta_attributes(self, **kwargs):\n        \"\"\"Determine the form attributes for the meta field.\"\"\"\n        superuser = kwargs.get('superuser', False)\n        if (self.untl_object.qualifier == 'recordStatus'\n                or self.untl_object.qualifier == 'system'):\n            if superuser:\n                self.editable = True\n                self.repeatable = True\n            else:\n                self.editable = False\n            self.view_type = 'qualified-input'\n        elif self.untl_object.qualifier == 'hidden':\n            self.label = 'Object Hidden'\n            self.view_type = 'radio'\n        else:\n            self.editable = False\n            self.view_type = 'qualified-input'"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _bit_mismatch(int1: int, int2: int) -> int:\n    for i in range(max(int1.bit_length(), int2.bit_length())):\n        if (int1 >> i) & 1 != (int2 >> i) & 1:\n            return i\n    return -1", "response": "Returns the index of the first different bit or - 1 if the values are the same."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsaves the host keys to a file.", "response": "def save_host_keys(self, filename):\n        \"\"\"\n        Save the host keys back to a file.  Only the host keys loaded with\n        `load_host_keys` (plus any added directly) will be saved -- not any\n        host keys loaded with `load_system_host_keys`.\n\n        :param str filename: the filename to save to\n\n        :raises IOError: if the file could not be written\n        \"\"\"\n\n        # update local host keys from file (in case other SSH clients\n        # have written to the known_hosts file meanwhile.\n        if self._host_keys_filename is not None:\n            self.load_host_keys(self._host_keys_filename)\n\n        with open(filename, 'w') as f:\n            for hostname, keys in self._host_keys.items():\n                for keytype, key in keys.items():\n                    f.write('%s %s %s\\n' % (hostname, keytype, key.get_base64()))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef connect(self, hostname, port=SSH_PORT, username=None, password=None, pkey=None,\n                key_filename=None, timeout=None, allow_agent=True, look_for_keys=True,\n                compress=False, sock=None):\n        \"\"\"\n        Connect to an SSH server and authenticate to it.  The server's host key\n        is checked against the system host keys (see `load_system_host_keys`)\n        and any local host keys (`load_host_keys`).  If the server's hostname\n        is not found in either set of host keys, the missing host key policy\n        is used (see `set_missing_host_key_policy`).  The default policy is\n        to reject the key and raise an `.SSHException`.\n\n        Authentication is attempted in the following order of priority:\n\n            - The ``pkey`` or ``key_filename`` passed in (if any)\n            - Any key we can find through an SSH agent\n            - Any \"id_rsa\" or \"id_dsa\" key discoverable in ``~/.ssh/``\n            - Plain username/password auth, if a password was given\n\n        If a private key requires a password to unlock it, and a password is\n        passed in, that password will be used to attempt to unlock the key.\n\n        :param str hostname: the server to connect to\n        :param int port: the server port to connect to\n        :param str username:\n            the username to authenticate as (defaults to the current local\n            username)\n        :param str password:\n            a password to use for authentication or for unlocking a private key\n        :param .PKey pkey: an optional private key to use for authentication\n        :param str key_filename:\n            the filename, or list of filenames, of optional private key(s) to\n            try for authentication\n        :param float timeout: an optional timeout (in seconds) for the TCP connect\n        :param bool allow_agent: set to False to disable connecting to the SSH agent\n        :param bool look_for_keys:\n            set to False to disable searching for discoverable private key\n            files in ``~/.ssh/``\n        :param bool compress: set to True to turn on compression\n        :param socket sock:\n            an open socket or socket-like object (such as a `.Channel`) to use\n            for communication to the target host\n\n        :raises BadHostKeyException: if the server's host key could not be\n            verified\n        :raises AuthenticationException: if authentication failed\n        :raises SSHException: if there was any other error connecting or\n            establishing an SSH session\n        :raises socket.error: if a socket error occurred while connecting\n        \"\"\"\n        if not sock:\n            for (family, socktype, proto, canonname, sockaddr) in socket.getaddrinfo(hostname, port, socket.AF_UNSPEC, socket.SOCK_STREAM):\n                if socktype == socket.SOCK_STREAM:\n                    af = family\n                    addr = sockaddr\n                    break\n            else:\n                # some OS like AIX don't indicate SOCK_STREAM support, so just guess. :(\n                af, _, _, _, addr = socket.getaddrinfo(hostname, port, socket.AF_UNSPEC, socket.SOCK_STREAM)\n            sock = socket.socket(af, socket.SOCK_STREAM)\n            if timeout is not None:\n                try:\n                    sock.settimeout(timeout)\n                except:\n                    pass\n            retry_on_signal(lambda: sock.connect(addr))\n\n        t = self._transport = Transport(sock)\n        t.use_compression(compress=compress)\n        if self._log_channel is not None:\n            t.set_log_channel(self._log_channel)\n        t.start_client()\n        ResourceManager.register(self, t)\n\n        server_key = t.get_remote_server_key()\n        keytype = server_key.get_name()\n\n        if port == SSH_PORT:\n            server_hostkey_name = hostname\n        else:\n            server_hostkey_name = \"[%s]:%d\" % (hostname, port)\n        our_server_key = self._system_host_keys.get(server_hostkey_name, {}).get(keytype, None)\n        if our_server_key is None:\n            our_server_key = self._host_keys.get(server_hostkey_name, {}).get(keytype, None)\n        if our_server_key is None:\n            # will raise exception if the key is rejected; let that fall out\n            self._policy.missing_host_key(self, server_hostkey_name, server_key)\n            # if the callback returns, assume the key is ok\n            our_server_key = server_key\n\n        if server_key != our_server_key:\n            raise BadHostKeyException(hostname, server_key, our_server_key)\n\n        if username is None:\n            username = getpass.getuser()\n\n        if key_filename is None:\n            key_filenames = []\n        elif isinstance(key_filename, string_types):\n            key_filenames = [key_filename]\n        else:\n            key_filenames = key_filename\n        self._auth(username, password, pkey, key_filenames, allow_agent, look_for_keys)", "response": "Connect to an SSH server and authenticate to it."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef searchRootOfTree(reducibleChildren: Set[LNode], nodeFromTree: LNode):\n\n    while True:\n        out_e = nodeFromTree.east[0].outgoingEdges\n        # node has no successors\n        if not out_e:\n            return nodeFromTree\n\n        nextNode = out_e[0].dsts[0].parentNode\n        if nextNode in reducibleChildren:\n            # can reduce node, walk the tree to root\n            nodeFromTree = nextNode\n        else:\n            # can not reduce, return last root of tree\n            return nodeFromTree", "response": "Search the tree of nodes to find the root of the tree."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncollect nodes which will be reduced and input nodes of tree of nodes.", "response": "def collectNodesInTree(treeRoot: LNode, reducibleChildren: Set[LNode]):\n    \"\"\"\n    Collect nodes which will be reduced and input nodes of tree for tree of nodes.\n\n    :param treeRoot: root node of tree\n    :param reducibleChildren: members of tree\n    :return: Tuple[reducedNodes, inputEdges] where reducedNodes is List[LNode]\n        and inputEdges is List[Tuple[LNode, LPort, LEdge]]\n    \"\"\"\n    # List[Tuple[LNode, LPort, LEdge]]\n    inputEdges = []\n    # List[LNode]\n    reducedNodes = []\n    # Set[LNode]\n    reducedNodesSet = set()\n    # An iterative process to print preorder traveral of tree\n    # List[Typle[LNode, LPort, LEdge]]\n    nodeStack = []\n    nodeStack.append((treeRoot, None, None))\n\n    # collect nodes in tree and input edges\n    while nodeStack:\n        # pop the node from stack and try to find it's children\n        node, p, e = nodeStack.pop()\n        if node in reducibleChildren and node not in reducedNodesSet:\n            reducedNodes.append(node)\n            reducedNodesSet.add(node)\n            # walk inputs and add child nodes to stack\n            for _p in node.west:\n                for _e in _p.iterEdges():\n                    # assert len(e.srcs) == 1 and len(e.dsts) == 1\n                    nodeStack.append((_e.srcs[0].parentNode, _p, _e))\n        else:\n            inputEdges.append((node, p, e))\n\n    return reducedNodes, inputEdges"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwalks all nodes and discover trees of nodes and reduce them to single node with multiple outputs", "response": "def flattenTrees(root, nodeSelector: Callable[[LNode], bool]):\n    \"\"\"\n    Walk all nodes and discover trees of nodes (usually operators)\n    and reduce them to single node with multiple outputs\n\n    :attention: selected nodes has to have single output\n                and has to be connected to nets with single driver\n    \"\"\"\n    for ch in root.children:\n        if ch.children:\n            flattenTrees(ch, nodeSelector)\n\n    # collect all nodes which can be potentialy reduced\n    reducibleChildren = set()\n    for ch in root.children:\n        if nodeSelector(ch):\n            reducibleChildren.add(ch)\n\n    while reducibleChildren:\n        # try to pick a node from random tree and search it's root\n        _treeRoot = reducibleChildren.pop()\n        reducibleChildren.add(_treeRoot)\n        # we need to keep order of inputs, use preorder\n        treeRoot = searchRootOfTree(reducibleChildren, _treeRoot)\n\n        reducedNodes, inputEdges = collectNodesInTree(treeRoot, reducibleChildren)\n        # if tree is big enoguh for reduction, reduce it to single node\n        if len(reducedNodes) > 1:\n            newName = reducedNodes[0].name\n            newNode = root.addNode(newName)\n\n            o = newNode.addPort(\"\", PortType.OUTPUT, PortSide.EAST)\n\n            oEdges = treeRoot.east[0].outgoingEdges\n            for outputedge in list(oEdges):\n                dsts = list(outputedge.dsts)\n                assert len(dsts) > 0\n                outputedge.remove()\n                root.addHyperEdge([o, ], dsts, originObj=outputedge.originObj)\n\n            for i, (iN, iP, iE) in enumerate(inputEdges):\n                name = None\n                index = len(inputEdges) - i - 1\n                if hasattr(iE.originObj, \"_dtype\"):\n                    w = iE.originObj._dtype.bit_length()\n                    if w > 1:\n                        name = \"[%d:%d]\" % ((index + 1) * w, index * w)\n                    else:\n                        name = None\n\n                if name is None:\n                    name = \"[%d]\" % (index)\n\n                inp = newNode.addPort(name,\n                                      PortType.INPUT, PortSide.WEST)\n                iE.removeTarget(iP)\n                iE.addTarget(inp)\n\n            for n in reducedNodes:\n                root.children.remove(n)\n                reducibleChildren.remove(n)\n        else:\n            reducibleChildren.remove(reducedNodes[0])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting lock on requests.", "response": "def __setLock(self, command):\n        \"\"\"Set lock on requests.\"\"\"\n        if command in (TURN_ON, TURN_OFF):\n            self._operation = command\n        elif command in INV_SOURCES:\n            self._operation = SOURCE\n        else:\n            self._operation = ALL\n        self._isLocked = True\n        self._timer = time.time()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nunlocking sending requests to projector.", "response": "def __unLock(self):\n        \"\"\"Unlock sending requests to projector.\"\"\"\n        self._operation = False\n        self._timer = 0\n        self._isLocked = False"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck if there is a lock pending and check if enough time has passed.", "response": "def __checkLock(self):\n        \"\"\"\n        Lock checking.\n\n        Check if there is lock pending and check if enough time\n        passed so requests can be unlocked.\n        \"\"\"\n        if self._isLocked:\n            if (time.time() - self._timer) > TIMEOUT_TIMES[self._operation]:\n                self.__unLock()\n                return False\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting property state from device.", "response": "async def get_property(self, command):\n        \"\"\"Get property state from device.\"\"\"\n        _LOGGER.debug(\"Getting property %s\", command)\n        if self.__checkLock():\n            return BUSY\n        timeout = self.__get_timeout(command)\n        response = await self.send_request(\n            timeout=timeout,\n            params=EPSON_KEY_COMMANDS[command],\n            type='json_query')\n        if not response:\n            return False\n        try:\n            return response['projector']['feature']['reply']\n        except KeyError:\n            return BUSY"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsending a command to the Epson.", "response": "async def send_command(self, command):\n        \"\"\"Send command to Epson.\"\"\"\n        _LOGGER.debug(\"Sending command to projector %s\", command)\n        if self.__checkLock():\n            return False\n        self.__setLock(command)\n        response = await self.send_request(\n            timeout=self.__get_timeout(command),\n            params=EPSON_KEY_COMMANDS[command],\n            type='directsend',\n            command=command)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsending request to Epson.", "response": "async def send_request(self, params, timeout,\n                           type='json_query', command=False):\n        \"\"\"Send request to Epson.\"\"\"\n        try:\n            with async_timeout.timeout(timeout):\n                url = '{url}{type}'.format(\n                    url=self._http_url,\n                    type=type)\n                async with self.websession.get(\n                    url=url, params=params,\n                        headers=self._headers) as response:\n                    if response.status != HTTP_OK:\n                        _LOGGER.warning(\n                            \"Error message %d from Epson.\", response.status)\n                        return False\n                    if command == TURN_ON and self._powering_on:\n                        self._powering_on = False\n                    if type == 'json_query':\n                        return await response.json()\n                    return response\n        except (aiohttp.ClientError, aiohttp.ClientConnectionError):\n            _LOGGER.error(\"Error request\")\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves all the instances on which their name start by a prefix.", "response": "def remove_instances_by_prefix(nova_api, prefix):\n    \"\"\"Remove all the instances on which their name start by a prefix.\"\"\"\n    for server in nova_api.servers.list():\n        if server.name.startswith(prefix):\n            LOG.info(\"Remove instance '%s'\" % server.name)\n            server.delete()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\npurge any trace of an existing OVB deployment.", "response": "def purge_existing_ovb(nova_api, neutron):\n    \"\"\"Purge any trace of an existing OVB deployment.\n    \"\"\"\n    LOG.info('Cleaning up OVB environment from the tenant.')\n    for server in nova_api.servers.list():\n        if server.name in ('bmc', 'undercloud'):\n            server.delete()\n        if server.name.startswith('baremetal_'):\n            server.delete()\n    for router in neutron.list_routers().get('routers'):\n        if router['name'] not in ('router', 'bmc_router'):\n            continue\n        for subnet in neutron.list_subnets().get('subnets'):\n            if not (subnet['name'].startswith('bmc_eth') or subnet['name'] == 'rdo-m-subnet'):\n                continue\n            try:\n                neutron.remove_interface_router(router['id'], {'subnet_id': subnet['id']})\n            except neutronclient.common.exceptions.NotFound:\n                pass\n    try:\n        bmc_router = neutron.list_routers(name='bmc_router').get('routers')[0]\n        for port in neutron.list_ports(device_id=bmc_router['id'])['ports']:\n            if port.get('device_owner') == 'network:router_gateway':\n                continue\n            info = {'id': router['id'],\n                    'port_id': port['id'],\n                    'tenant_id': bmc_router.get('tenant_id'),\n                    }\n            neutron.remove_interface_router(bmc_router['id'], info)\n        neutron.delete_router(bmc_router['id'])\n    except IndexError:  # already doesnt exist\n        pass\n\n    for _ in range(0, 5):\n        try:\n            for port in neutron.list_ports()['ports']:\n                if port['name'].endswith('_provision'):\n                    neutron.delete_port(port['id'])\n            for net in neutron.list_networks().get('networks'):\n                if not net['name'].startswith('provision_'):\n                    continue\n                for port in neutron.list_ports(network_id=net['id'])['ports']:\n                    if port.get('device_owner') == 'network:router_interface':\n                        continue\n                    try:\n                        neutron.delete_port(port['id'])\n                    except neutronclient.common.exceptions.PortNotFoundClient:\n                            pass\n                    for subnet in neutron.list_subnets(network_id=net['id'])['subnets']:\n                        neutron.delete_subnet(subnet['id'])\n                neutron.delete_network(net['id'])\n        except neutronclient.common.exceptions.Conflict:\n            LOG.debug('waiting for all the ports to be freed...')\n            time.sleep(5)\n        else:\n            return"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninitializes an OVB network called provision_bob.", "response": "def initialize_network(neutron):\n    \"\"\"Initialize an OVB network called provision_bob.\n    \"\"\"\n    body_sample = {\n        \"network\": {\n            \"name\": 'provision_bob',\n            \"admin_state_up\": True,\n        }\n    }\n    netw = neutron.create_network(body=body_sample)['network']\n    body_create_subnet = {\n        'subnets': [{\n            'name': 'rdo-m-subnet',\n            'cidr': '192.0.2.0/24',\n            'ip_version': 4,\n            'network_id': netw['id'],\n            'host_routes': [{\n                'destination': '169.254.169.254/32',\n                'nexthop': '192.0.2.240'\n            }],\n            'gateway_ip': '192.0.2.1',\n            'dns_nameservers': ['8.8.8.8', '8.8.4.4'],\n            'allocation_pools': [{'start': '192.0.2.30', 'end': '192.0.2.199'}]}]}\n    response = neutron.create_subnet(body=body_create_subnet)\n    subnet_id = response['subnets'][0]['id']\n    router = neutron.list_routers(name='router').get('routers')[0]\n    response = neutron.add_interface_router(router['id'], {'subnet_id': subnet_id})"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndirecting which class should be used based on the director qualifier.", "response": "def description_director(**kwargs):\n    \"\"\"Direct which class should be used based on the director\n     qualifier.\n    \"\"\"\n    description_type = {'physical': DCFormat}\n    qualifier = kwargs.get('qualifier')\n    # Determine the type of element needed, based on the qualifier.\n    element_class = description_type.get(qualifier, DCDescription)\n    # Create the element object of that element type.\n    element = element_class(\n        qualifier=qualifier,\n        content=kwargs.get('content'),\n    )\n    return element"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef identifier_director(**kwargs):\n    ark = kwargs.get('ark', None)\n    domain_name = kwargs.get('domain_name', None)\n    # Set default scheme if it is None or is not supplied.\n    scheme = kwargs.get('scheme') or 'http'\n    qualifier = kwargs.get('qualifier', None)\n    content = kwargs.get('content', '')\n    # See if the ark and domain name were given.\n    if ark and qualifier == 'ark':\n        content = 'ark: %s' % ark\n    if domain_name and ark and qualifier == 'permalink':\n        # Create the permalink URL.\n        if not domain_name.endswith('/'):\n            domain_name += '/'\n        permalink_url = '%s://%s%s' % (scheme, domain_name, ark)\n        # Make sure it has a trailing slash.\n        if not permalink_url.endswith('/'):\n            permalink_url += '/'\n        content = permalink_url\n    else:\n        if qualifier:\n            content = '%s: %s' % (string.lower(qualifier), content)\n    return DCIdentifier(content=content)", "response": "Direct how to handle the identifier element."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_child(self, child):\n        # Make sure the child exists before adding it.\n        if child:\n            # Append child if it is allowed to exist under the parent.\n            if child.tag in self.contained_children:\n                self.children.append(child)\n            else:\n                raise DC_StructureException(\n                    'Invalid child \"%s\" for parent \"%s\"' %\n                    (child.tag, self.tag)\n                )", "response": "This method adds a child object to the current object. It will check that the object is not already in the list of contained children."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef determine_vocab(self, qualifier):\n        vocab_value = VOCAB_INDEX.get(self.tag, None)\n        if isinstance(vocab_value, dict):\n            if qualifier is None:\n                qualifier = 'None'\n            # Find the value based on the qualifier.\n            return vocab_value.get(qualifier, None)\n        elif vocab_value is not None:\n            return vocab_value\n        else:\n            return None", "response": "Determine the vocab from the qualifier."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\npull the requested attribute based on the given vocabulary and content.", "response": "def resolver(self, vocab_data, attribute):\n        \"\"\"Pull the requested attribute based on the given vocabulary\n        and content.\n        \"\"\"\n        term_list = vocab_data.get(self.content_vocab, [])\n        # Loop through the terms from the vocabulary.\n        for term_dict in term_list:\n            # Match the name to the current content.\n            if term_dict['name'] == self.content:\n                return term_dict[attribute]\n        return self.content"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef rebase(config):\n    repo = config.repo\n\n    active_branch = repo.active_branch\n    if active_branch.name == \"master\":\n        error_out(\"You're already on the master branch.\")\n    active_branch_name = active_branch.name\n\n    if repo.is_dirty():\n        error_out(\n            'Repo is \"dirty\". ({})'.format(\n                \", \".join([repr(x.b_path) for x in repo.index.diff(None)])\n            )\n        )\n\n    state = read(config.configfile)\n    origin_name = state.get(\"ORIGIN_NAME\", \"origin\")\n    upstream_remote = None\n    for remote in repo.remotes:\n        if remote.name == origin_name:\n            upstream_remote = remote\n            break\n    if not upstream_remote:\n        error_out(\"No remote called {!r} found\".format(origin_name))\n\n    repo.heads.master.checkout()\n    repo.remotes[origin_name].pull(\"master\")\n\n    repo.heads[active_branch_name].checkout()\n\n    print(repo.git.rebase(\"master\"))\n    success_out(\"Rebased against {}/master\".format(origin_name))\n    info_out(\"If you wanto start interactive rebase run:\\n\\n\\tgit rebase -i master\\n\")", "response": "Rebase the current branch against origin"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of branches for given repository", "response": "def branches(self):\n\t\t\"\"\"Return a list of branches for given repository\n\n\t\t:return: [str]\n\t\t\"\"\"\n\t\t# get all remote branches\n\t\trefs = filter(lambda l: isinstance(l, git.RemoteReference), self.repo.references)\n\t\t# filter out HEAD branch\n\t\trefs = filter(lambda l: l.name != \"origin/HEAD\", refs)\n\t\t# filter out all branches not starting with 'origin/'\n\t\trefs = filter(lambda l: l.name.startswith(\"origin/\"), refs)\n\t\tfor ref in refs:\n\t\t\tself.refs[ref.name[7:]] = ref\n\n\t\t# remove 'origin/' prefix\n\t\treturn map(lambda l: l.name[7:], refs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting data from a commit object", "response": "def _commitData(self, commit):\n\t\t\"\"\"Get data from a commit object\n\n\t\t:param commit: commit object\n\t\t:type  commit: git.objects.commit.Commit\n\t\t\"\"\"\n\t\treturn {\n\t\t\t\"hexsha\": commit.hexsha,\n\t\t\t\"adate\": commit.authored_date,\n\t\t\t\"cdate\": commit.committed_date,\n\t\t\t\"author\": \"%s <%s>\" % (commit.author.name, commit.author.email),\n\t\t\t\"message\": commit.message\n\t\t}"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef commit(self, commit):\n\t\ttry:\n\t\t\treturn self._commitData(self.repo.commit(commit))\n\t\texcept (ValueError, KeyError, BadObject):\n\t\t\tif self._repo_info:\n\t\t\t\traise KeyError(\"Commit %s not found for %s\" % (commit, str(self._repo_info)))\n\t\t\telse:\n\t\t\t\traise KeyError(\"Commit %s not found\" % commit)", "response": "Get data for a given commit."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef head(self, file_path):\n        processor = lambda path, node, tail_only=True, append=False: self._handle_head(\n            path, node)\n\n        # Find items and go\n        for item in self._client._find_items([file_path], processor,\n                                             include_toplevel=True,\n                                             include_children=False, recurse=False):\n            if item:\n                return item", "response": "Return the first item in the file that is read"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef packageExists(self, package):\n\t\turl = \"%s/packages\" % self.base_url\n\t\tparams = {\"pattern\": package}\n\t\tresponse = requests.get(url, params=params)\n\t\tif response.status_code != requests.codes.ok:\n\t\t\treturn False\n\n\t\treturn True", "response": "Check if the package already exists in the database"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getGolangPackages(self):\n\n\t\tpackages = {}\n\n\t\t# get all packages\n\t\turl = \"%s/packages\" % self.base_url\n\t\tparams = {\"pattern\": \"golang-*\", \"limit\": 200}\n\t\tresponse = requests.get(url, params=params)\n\t\tif response.status_code != requests.codes.ok:\n\t\t\treturn {}\n\n\t\tdata = response.json()\n\t\tfor package in data[\"packages\"]:\n\t\t\tpackages[package[\"name\"]] = self._processPackageData(package)\n\n\t\t# accumulate packages from all pages\n\t\tfor page in range(2, data[\"page_total\"] + 1):\n\t\t\tparams = {\"pattern\": \"golang-*\", \"limit\": 200, \"page\": page}\n\t\t\tresponse = requests.get(url, params=params)\n\t\t\tif response.status_code != requests.codes.ok:\n\t\t\t\tcontinue\n\n\t\t\tdata = response.json()\n\t\t\tfor package in data[\"packages\"]:\n\t\t\t\tpackages[package[\"name\"]] = self._processPackageData(package)\n\n\t\t# get branches of all packages\n\t\tMAX_LEN = 30\n\t\t# break the list of packages into lists of at most 50 packages\n\t\tpackage_names = packages.keys()\n\n\t\tpackages_total = len(package_names)\n\t\tpackages_counter = 0\n\t\tlogger.info(\"%s packages to process\" % packages_total)\n\n\t\tfor i in range(0, packages_total, MAX_LEN):\n\t\t\tsublist = package_names[i:i+MAX_LEN]\n\t\t\tbranches = self._getPackageBranches(sublist)\n\t\t\tfor package in sublist:\n\t\t\t\tpackages[package][\"branches\"] = branches[package]\n\n\t\t\tpackages_counter = packages_counter + len(branches)\n\t\t\tlogger.info(\"%s/%s packages processed\" % (packages_counter, packages_total))\n\n\t\treturn packages", "response": "Get a list of all golang packages for all available branches"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads a private key file and return it as a string.", "response": "def _read_private_key_file(self, tag, filename, password=None):\n        \"\"\"\n        Read an SSH2-format private key file, looking for a string of the type\n        ``\"BEGIN xxx PRIVATE KEY\"`` for some ``xxx``, base64-decode the text we\n        find, and return it as a string.  If the private key is encrypted and\n        ``password`` is not ``None``, the given password will be used to decrypt\n        the key (otherwise `.PasswordRequiredException` is thrown).\n\n        :param str tag: ``\"RSA\"`` or ``\"DSA\"``, the tag used to mark the data block.\n        :param str filename: name of the file to read.\n        :param str password:\n            an optional password to use to decrypt the key file, if it's\n            encrypted.\n        :return: data blob (`str`) that makes up the private key.\n\n        :raises IOError: if there was an error reading the file.\n        :raises PasswordRequiredException: if the private key file is\n            encrypted, and ``password`` is ``None``.\n        :raises SSHException: if the key file is invalid.\n        \"\"\"\n        with open(filename, 'r') as f:\n            data = self._read_private_key(tag, f, password)\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def emit_event(self, event):\n        self.log.debug(\"publishing event on %s\", self.publish_topic)\n        if self.config.extra['config']['pub_options']['retain']:\n            try:\n                await persist_event(\n                    self.publish_topic,\n                    event,\n                    self.pool\n                )\n            except SystemError as error:\n                self.log.error(error)\n                return\n\n        try:\n            await self.publish(\n                self.publish_topic,\n                event.__dict__,\n                options=self.publish_options\n            )\n        except TransportLost as error:\n            for task in asyncio.Task.all_tasks():\n                task.cancel()\n            asyncio.get_event_loop().stop()\n            self.log.error(error)", "response": "Publish an event back to crossbar."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef onClose(self, wasClean):\n        self.log.error('lost connection to crossbar on session %' + str(self.session_id))\n        for task in asyncio.Task.all_tasks():\n            task.cancel()\n        asyncio.get_event_loop().stop()", "response": "Disconnect when connection to message broker is lost"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def show_sessions(self):\n        res = await self.call(\"wamp.session.list\")\n        for session_id in res:\n            session = await self.call(\"wamp.session.get\", session_id)\n            self.log.info(session)", "response": "Show the currently attached sessions."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def lookup_session(self, topic_name):\n        res = await self.call(\"wamp.subscription.lookup\", topic_name)\n        self.log.info(res)", "response": "Attempts to find the session id for a given topic"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef setup_runner(self):\n        runner = ApplicationRunner(\n            url=self.config['transport_host'],\n            realm=u'realm1',\n            extra={\n                'config': self.config,\n                'handlers': self.handlers,\n            }\n        )\n        return runner", "response": "Setup instance of runner"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nhandling reconnect logic if connection to crossbar is lost", "response": "def reconnect(self):\n        \"\"\"\n        Handle reconnect logic if connection\n        to crossbar is lost\n        \"\"\"\n        connect_attempt = 0\n        max_retries = self.config['max_reconnect_retries']\n        logging.info('attempting to reconnect to crossbar')\n        runner = self.setup_runner()\n        while True:\n\n            if connect_attempt == max_retries:\n                logging.info('max retries reached; stopping service')\n                sys.exit(1)\n            self.check_event_loop()\n\n            try:\n                logging.info('waiting 5 seconds')\n                time.sleep(5)\n                if self.check_transport_host():\n                    logging.info('waiting 10 seconds to ensure that crossbar has initialized before reconnecting')\n                    time.sleep(10)\n                    runner.run(Component)\n                else:\n                    logging.error('crossbar host port 8080 not available...')\n            except RuntimeError as error:\n                logging.error(error)\n            except ConnectionRefusedError as error:\n                logging.error(error)\n            except ConnectionError as error:\n                logging.error(error)\n            except KeyboardInterrupt:\n                logging.info('User initiated shutdown')\n                loop = asyncio.get_event_loop()\n                loop.stop()\n                sys.exit(1)\n            connect_attempt += 1"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef start(self, start_loop=True):\n        txaio.start_logging()\n        runner = self.setup_runner()\n        if start_loop:\n            try:\n                runner.run(Component)\n            except EventifyHandlerInitializationFailed as initError:\n                logging.error('Unable to initialize handler: %s.' % initError.message)\n                sys.exit(1)\n            except ConnectionRefusedError:\n                logging.error('Unable to connect to crossbar instance. Is it running?')\n                sys.exit(1)\n            except KeyboardInterrupt:\n                logging.info('User initiated shutdown')\n                loop = asyncio.get_event_loop()\n                loop.stop()\n                sys.exit(1)\n            self.check_event_loop()\n            self.reconnect()\n        else:\n            return runner.run(\n                Component,\n                start_loop=start_loop\n            )", "response": "Start a producer or consumer service."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncalculate the amount of water in a persons body", "response": "def calculate_bw(age, weight, height, sex):\n  \"\"\"Return the amount of water (in liter) in a persons body\"\"\"\n  if sex: # female\n    return 0.203 - (0.07 * age) + (0.1069 * height) + (0.2466 * weight)\n  else: # male\n    return 2.447 - (0.09516 * age) + (0.1074 * height) + (0.3362 * weight)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating the promille of a person with the given body stats and blood alcohol content.", "response": "def promille_to_gramm(bac, age, weight, height, sex):\n  \"\"\"Return the amount of alcohol (in gramm) for a person with the given\n     body stats and blood alcohol content (per mill)\n  \"\"\"\n  bw = calculate_bw(age, weight, height, sex)\n  return (bac * (PB * bw)) / W"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the promille content for a person with the given body stats and amount of alcohol content in gramm.", "response": "def gramm_to_promille(gramm, age, weight, height, sex):\n  \"\"\"Return the blood alcohol content (per mill) for a person with the\n     given body stats and amount of alcohol (in gramm) in blood\n  \"\"\"\n  bw = calculate_bw(age, weight, height, sex)\n  return (gramm * W) / (PB * bw)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_bac(age, weight, height, sex, volume, percent):\n  return gramm_to_promille(\n    calculate_alcohol(volume, percent),\n    age, weight, height, sex\n  )", "response": "Returns the Promille of the Alcohol Content after a drink with the given attributes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_degradation(age, weight, height, sex, minutes):\n  return gramm_to_promille(\n    calculate_degradation(weight, minutes),\n    age, weight, height, sex\n  )", "response": "Returns the degradation of a person with the given age weight height sex and minutes."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove assignments if it is only a direct connection and can be replaced with direct link", "response": "def reduceUselessAssignments(root: LNode):\n    \"\"\"\n    Remove assignments if it is only a direct connection and can be replaced with direct link\n    \"\"\"\n    for n in root.children:\n        if n.children:\n            reduceUselessAssignments(n)\n\n    do_update = False\n    for n in root.children:\n        if isinstance(n.originObj, Assignment)\\\n                and not n.originObj.indexes\\\n                and len(n.west) == 1:\n            src = n.originObj.src\n            if isinstance(src, RtlSignalBase) and src.hidden:\n                continue\n\n            if not do_update:\n                nodes = set(root.children)\n                do_update = True\n\n            nodes.remove(n)\n\n            srcPorts = []\n            dstPorts = []\n            edgesToRemove = []\n\n            inP = getSinglePort(n.west)\n            outP = getSinglePort(n.east)\n            for e in inP.incomingEdges:\n                sPort = e.src\n                srcPorts.append((sPort, e.originObj))\n                edgesToRemove.append(e)\n\n            for e in outP.outgoingEdges:\n                dPort = e.dst\n                dstPorts.append(dPort)\n                edgesToRemove.append(e)\n\n            for e in edgesToRemove:\n                e.remove()\n\n            for srcPort, originObj in srcPorts:\n                for dstPort in dstPorts:\n                    root.addEdge(srcPort, dstPort,\n                                 originObj=originObj)\n\n    if do_update:\n        root.children = list(nodes)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconstructs a qualified name for given type", "response": "def _constructTypeQualifiedName(self, type, full=False):\n\t\t\"\"\"\n\t\tFor given type construct its full qualified name.\n\n\t\tAnonymousField = [ \"*\" ] TypeName .\n\t\tTypeName  = identifier | QualifiedIdent .\n\t\tQualifiedIdent = PackageName \".\" identifier .\n\t\t\"\"\"\n\t\tt = type[\"type\"]\n\t\tif t == TYPE_IDENT:\n\t\t\treturn type[\"def\"]\n\t\telif t == TYPE_POINTER:\n\t\t\treturn self._constructTypeQualifiedName(type[\"def\"])\n\t\telif t == TYPE_SELECTOR:\n\t\t\tif full:\n\t\t\t\treturn \"%s.%s\" % (type[\"prefix\"], type[\"item\"])\n\t\t\telse:\n\t\t\t\treturn type[\"item\"]\n\t\telse:\n\t\t\traise ValueError(\"Type %s can not be used for FQN\" % t)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _read_file(name, encoding='utf-8') -> str:\n    with open(name, encoding=encoding) as f:\n        return f.read()", "response": "Read the contents of a file."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncrops an image to a specified bounding box.", "response": "def crop_to_bounding_box(image, offset_height, offset_width, target_height,\n                         target_width, dynamic_shape=False):\n  \"\"\"Crops an image to a specified bounding box.\n\n  This op cuts a rectangular part out of `image`. The top-left corner of the\n  returned image is at `offset_height, offset_width` in `image`, and its\n  lower-right corner is at\n  `offset_height + target_height, offset_width + target_width`.\n\n  Args:\n    image: 3-D tensor with shape `[height, width, channels]`\n    offset_height: Vertical coordinate of the top-left corner of the result in\n                   the input.\n    offset_width: Horizontal coordinate of the top-left corner of the result in\n                  the input.\n    target_height: Height of the result.\n    target_width: Width of the result.\n    dynamic_shape: Whether the input image has undertermined shape. If set to\n      `True`, shape information will be retrieved at run time. Default to\n      `False`.\n\n  Returns:\n    3-D tensor of image with shape `[target_height, target_width, channels]`\n\n  Raises:\n    ValueError: If the shape of `image` is incompatible with the `offset_*` or\n    `target_*` arguments, and `dynamic_shape` is set to `False`.\n  \"\"\"\n  image = ops.convert_to_tensor(image, name='image')\n  _Check3DImage(image, require_static=(not dynamic_shape))\n  height, width, _ = _ImageDimensions(image, dynamic_shape=dynamic_shape)\n\n  if not dynamic_shape:\n    if offset_width < 0:\n      raise ValueError('offset_width must be >= 0.')\n    if offset_height < 0:\n      raise ValueError('offset_height must be >= 0.')\n\n    if width < (target_width + offset_width):\n      raise ValueError('width must be >= target + offset.')\n    if height < (target_height + offset_height):\n      raise ValueError('height must be >= target + offset.')\n\n  cropped = array_ops.slice(image,\n                            array_ops.pack([offset_height, offset_width, 0]),\n                            array_ops.pack([target_height, target_width, -1]))\n\n  return cropped"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef pad_to_bounding_box(image, offset_height, offset_width, target_height,\n                        target_width, dynamic_shape=False):\n  \"\"\"Pad `image` with zeros to the specified `height` and `width`.\n\n  Adds `offset_height` rows of zeros on top, `offset_width` columns of\n  zeros on the left, and then pads the image on the bottom and right\n  with zeros until it has dimensions `target_height`, `target_width`.\n\n  This op does nothing if `offset_*` is zero and the image already has size\n  `target_height` by `target_width`.\n\n  Args:\n    image: 3-D tensor with shape `[height, width, channels]`\n    offset_height: Number of rows of zeros to add on top.\n    offset_width: Number of columns of zeros to add on the left.\n    target_height: Height of output image.\n    target_width: Width of output image.\n    dynamic_shape: Whether the input image has undertermined shape. If set to\n      `True`, shape information will be retrieved at run time. Default to\n      `False`.\n\n  Returns:\n    3-D tensor of shape `[target_height, target_width, channels]`\n  Raises:\n    ValueError: If the shape of `image` is incompatible with the `offset_*` or\n      `target_*` arguments, and `dynamic_shape` is set to `False`.\n  \"\"\"\n  image = ops.convert_to_tensor(image, name='image')\n  _Check3DImage(image, require_static=(not dynamic_shape))\n  height, width, depth = _ImageDimensions(image, dynamic_shape=dynamic_shape)\n\n  after_padding_width = target_width - offset_width - width\n  after_padding_height = target_height - offset_height - height\n\n  if not dynamic_shape:\n    if target_width < width:\n      raise ValueError('target_width must be >= width')\n    if target_height < height:\n      raise ValueError('target_height must be >= height')\n\n    if after_padding_width < 0:\n      raise ValueError('target_width not possible given '\n                       'offset_width and image width')\n    if after_padding_height < 0:\n      raise ValueError('target_height not possible given '\n                       'offset_height and image height')\n\n  # Do not pad on the depth dimensions.\n  if (dynamic_shape or offset_width or offset_height or\n      after_padding_width or after_padding_height):\n    paddings = array_ops.reshape(\n      array_ops.pack([offset_height, after_padding_height,\n                      offset_width, after_padding_width,\n                      0, 0]),\n      [3, 2])\n    padded = array_ops.pad(image, paddings)\n    if not dynamic_shape:\n      padded.set_shape([target_height, target_width, depth])\n  else:\n    padded = image\n\n  return padded", "response": "Pads an image with zeros to the specified height and width."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncrops and/or pads an image to a target width and height. Resizes an image to a target width and height by either centrally cropping the image or padding it evenly with zeros. If `width` or `height` is greater than the specified `target_width` or `target_height` respectively, this op centrally crops along that dimension. If `width` or `height` is smaller than the specified `target_width` or `target_height` respectively, this op centrally pads with 0 along that dimension. Args: image: 3-D tensor of shape [height, width, channels] target_height: Target height. target_width: Target width. dynamic_shape: Whether the input image has undertermined shape. If set to `True`, shape information will be retrieved at run time. Default to `False`. Raises: ValueError: if `target_height` or `target_width` are zero or negative. Returns: Cropped and/or padded image of shape `[target_height, target_width, channels]`", "response": "def resize_image_with_crop_or_pad(image, target_height, target_width,\n                                  dynamic_shape=False):\n  \"\"\"Crops and/or pads an image to a target width and height.\n\n  Resizes an image to a target width and height by either centrally\n  cropping the image or padding it evenly with zeros.\n\n  If `width` or `height` is greater than the specified `target_width` or\n  `target_height` respectively, this op centrally crops along that dimension.\n  If `width` or `height` is smaller than the specified `target_width` or\n  `target_height` respectively, this op centrally pads with 0 along that\n  dimension.\n\n  Args:\n    image: 3-D tensor of shape [height, width, channels]\n    target_height: Target height.\n    target_width: Target width.\n    dynamic_shape: Whether the input image has undertermined shape. If set to\n      `True`, shape information will be retrieved at run time. Default to\n      `False`.\n\n  Raises:\n    ValueError: if `target_height` or `target_width` are zero or negative.\n\n  Returns:\n    Cropped and/or padded image of shape\n    `[target_height, target_width, channels]`\n  \"\"\"\n  image = ops.convert_to_tensor(image, name='image')\n  _Check3DImage(image, require_static=(not dynamic_shape))\n  original_height, original_width, _ =     _ImageDimensions(image, dynamic_shape=dynamic_shape)\n\n  if target_width <= 0:\n    raise ValueError('target_width must be > 0.')\n  if target_height <= 0:\n    raise ValueError('target_height must be > 0.')\n\n  if dynamic_shape:\n    max_ = math_ops.maximum\n    min_ = math_ops.minimum\n  else:\n    max_ = max\n    min_ = min\n\n  width_diff = target_width - original_width\n  offset_crop_width = max_(-width_diff // 2, 0)\n  offset_pad_width = max_(width_diff // 2, 0)\n\n  height_diff = target_height - original_height\n  offset_crop_height = max_(-height_diff // 2, 0)\n  offset_pad_height = max_(height_diff // 2, 0)\n\n  # Maybe crop if needed.\n  cropped = crop_to_bounding_box(image, offset_crop_height, offset_crop_width,\n                                 min_(target_height, original_height),\n                                 min_(target_width, original_width),\n                                 dynamic_shape=dynamic_shape)\n\n  # Maybe pad if needed.\n  resized = pad_to_bounding_box(cropped, offset_pad_height, offset_pad_width,\n                                target_height, target_width,\n                                dynamic_shape=dynamic_shape)\n\n  if resized.get_shape().ndims is None:\n    raise ValueError('resized contains no shape.')\n  if not resized.get_shape()[0].is_compatible_with(target_height):\n    raise ValueError('resized height is not correct.')\n  if not resized.get_shape()[1].is_compatible_with(target_width):\n    raise ValueError('resized width is not correct.')\n  return resized"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the dimensions of an image tensor.", "response": "def _ImageDimensions(images, dynamic_shape=False):\n  \"\"\"Returns the dimensions of an image tensor.\n  Args:\n    images: 4-D Tensor of shape [batch, height, width, channels]\n    dynamic_shape: Whether the input image has undertermined shape. If set to\n      `True`, shape information will be retrieved at run time. Default to\n      `False`.\n\n  Returns:\n    list of integers [batch, height, width, channels]\n  \"\"\"\n  # A simple abstraction to provide names for each dimension. This abstraction\n  # should make it simpler to switch dimensions in the future (e.g. if we ever\n  # want to switch height and width.)\n  if dynamic_shape:\n    return array_ops.unpack(array_ops.shape(images))\n  else:\n    return images.get_shape().as_list()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _Check3DImage(image, require_static=True):\n  try:\n    image_shape = image.get_shape().with_rank(3)\n  except ValueError:\n    raise ValueError('\\'image\\' must be three-dimensional.')\n  if require_static and not image_shape.is_fully_defined():\n    raise ValueError('\\'image\\' must be fully defined.')\n  if any(x == 0 for x in image_shape):\n    raise ValueError('all dims of \\'image.shape\\' must be > 0: %s' %\n                     image_shape)", "response": "Checks that we are working with properly shaped image."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef determine_completeness(py_untl):\n    # Default values for the completeness dictionary.\n    completeness_dict = {\n        'title': {'present': False, 'weight': 10, },\n        'description': {'present': False, 'weight': 1, },\n        'language': {'present': False, 'weight': 1, },\n        'collection': {'present': False, 'weight': 10, },\n        'institution': {'present': False, 'weight': 10, },\n        'resourceType': {'present': False, 'weight': 5, },\n        'format': {'present': False, 'weight': 1, },\n        'subject': {'present': False, 'weight': 1, },\n        'meta': {'present': False, 'weight': 20, },\n    }\n\n    total_points = sum(item['weight'] for item in completeness_dict.values())\n    py_untl_object_score = 0.0\n\n    # Iterate through the attributes of the pyuntl record.\n    # This loop will toggle the Boolean for scoring.\n    for i in py_untl.children:\n        # Process attribute that is scorable and has content.\n        if i.tag in PYUNTL_COMPLETENESS_SCORED_ATTRIBUTES:\n            if i.content:\n                content = i.content.lower()\n                # Try and match against new default placeholders.\n                match = bool(DEFAULT_VALUE_REGEX.search(content))\n                # The content is not a legacy placeholder.\n                if content not in COMMON_DEFAULT_ATTRIBUTE_VALUES and not match:\n                    # Only consider <meta qualifier=\"system\"> records.\n                    if i.tag == 'meta':\n                        if i.qualifier == 'system':\n                            completeness_dict['%s' % i.tag]['present'] = True\n                    else:\n                        completeness_dict['%s' % i.tag]['present'] = True\n    # Get total score of the pyuntl object.\n    for k, v in completeness_dict.iteritems():\n        # If presence was toggled true, adjust score based on weight.\n        if v['present']:\n            py_untl_object_score += completeness_dict[k]['weight']\n    # Calculate the float score completeness.\n    completeness = py_untl_object_score / total_points\n    return completeness", "response": "Determines the completeness of a Python untl."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef read_config(config, prefix):\n    # Get all relevant config values from Flask application.\n    suffixes = ('SERVER', 'USER', 'PASSWORD', 'TOKEN', 'SECRET', 'CONSUMER', 'CERT')\n    config_server, config_user, config_password, config_token, config_secret, config_consumer, config_cert = [\n        config.get('{0}_{1}'.format(prefix, suffix)) for suffix in suffixes\n    ]\n    result = dict(options=dict(server=config_server))\n    # Gather authentication data.\n    basic = (config_user, config_password)\n    oauth = dict(\n        access_token=config_token,\n        access_token_secret=config_secret,\n        consumer_key=config_consumer,\n        key_cert=config_cert,\n    )\n    # Apply authentication data.\n    if any(oauth.values()):\n        result['oauth'] = oauth\n    elif all(basic):\n        result['basic_auth'] = basic\n    else:\n        raise ValueError('No/incomplete JIRA authentication settings specified in the Flask config.')\n    # Done.\n    return result", "response": "Read JIRA configuration values from Flask application config dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef init_app(self, app, config_prefix=None):\n        # Restore self.kill_session().\n        self.kill_session = self.original_kill_session\n\n        # Normalize the prefix and add this instance to app.extensions.\n        config_prefix = (config_prefix or 'JIRA').rstrip('_').upper()\n        if not hasattr(app, 'extensions'):\n            app.extensions = dict()\n        if config_prefix.lower() in app.extensions:\n            raise ValueError('Already registered config prefix {0!r}.'.format(config_prefix))\n        app.extensions[config_prefix.lower()] = _JIRAState(self, app)\n\n        # Read config.\n        args = read_config(app.config, config_prefix)\n\n        # Initialize fully.\n        try:\n            super(JIRA, self).__init__(**args)\n        except ConnectionError:\n            if not app.config.get('{0}_IGNORE_INITIAL_CONNECTION_FAILURE'.format(config_prefix)):\n                raise\n            LOG.exception('Ignoring ConnectionError.')", "response": "Initializes the JIRA instance with the given application instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef zip_dict(a: Dict[str, A], b: Dict[str, B]) \\\n        -> Dict[str, Tuple[Optional[A], Optional[B]]]:\n    \"\"\"\n    Combine the values within two dictionaries by key.\n\n    :param a: The first dictionary.\n    :param b: The second dictionary.\n    :return: A dictionary containing all keys that appear in the union of a and\n             b. Values are pairs where the first part is a's value for the key,\n             and right second part b's value.\n    \"\"\"\n    return {key: (a.get(key), b.get(key)) for key in a.keys() | b.keys()}", "response": "Combine the values within two dictionaries by key."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntakes an iterable of n elements from a presumably longer iterable and returns an iterable of n elements.", "response": "def chunk(iterable: Iterable[A], n: int) \\\n        -> Iterable[more_itertools.more.peekable]:\n    \"\"\"\n    Produce an iterable of interables of a maximum length from a (presumably\n    longer) iterable. This is useful when only so many elements can be\n    processed at once, such as an API that limits to n things per request.\n\n    :param iterable: The iterable to chunk into iterables of size up to n.\n    :param n: The maximum length of each iterable.\n    :return: An iterable of iterables. Each iterable will be of size n, except\n             possibly the last one which will contain fewer elements.\n    \"\"\"\n    iterator = iter(iterable)\n    while True:\n        chunk_ = more_itertools.peekable(itertools.islice(iterator, n))\n        try:\n            chunk_.peek()\n        except StopIteration:\n            return\n        yield chunk_"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nflatten a port into a single list of hierarchy.", "response": "def flattenPort(port: LPort):\n    \"\"\"\n    Flatten hierarchical ports\n    \"\"\"\n    yield port\n    if port.children:\n        for ch in port.children:\n            yield from flattenPort(ch)\n        port.children.clear()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nflattening hierarchical ports on node side", "response": "def _flattenPortsSide(side: List[LNode]) -> List[LNode]:\n    \"\"\"\n    Flatten hierarchical ports on node side\n    \"\"\"\n    new_side = []\n    for i in side:\n        for new_p in flattenPort(i):\n            new_side.append(new_p)\n    return new_side"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nflatten ports to simplify layout generation", "response": "def flattenPorts(root: LNode):\n    \"\"\"\n    Flatten ports to simplify layout generation\n\n    :attention: children property is destroyed, parent property stays same\n    \"\"\"\n    for u in root.children:\n        u.west = _flattenPortsSide(u.west)\n        u.east = _flattenPortsSide(u.east)\n        u.north = _flattenPortsSide(u.north)\n        u.south = _flattenPortsSide(u.south)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_missing_defaults(self):\n        if 'pub_options' not in self.config:\n            self.config['pub_options'] = {\n                'acknowledge': True,\n                'retain': True\n            }\n\n        if 'sub_options' not in self.config:\n            self.config['sub_options'] = {\n                'get_retained': False\n            }\n\n        if 'subscribed_topics' not in self.config:\n            self.config['subscribed_topics'] = None\n\n        if 'replay_events' not in self.config:\n            self.config['replay_events'] = False\n\n        if 'max_reconnect_retries' not in self.config:\n            self.config['max_reconnect_retries'] = 10", "response": "Ensure that minimal configuration is set and set defaults for missing values"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nbase configuration sanity checks", "response": "def config_sanity_check(self):\n        \"\"\"\n        Base configuration sanity checks\n        \"\"\"\n        if 'name' not in self.config:\n            raise EventifyConfigError(\n                \"\"\"Required configuration parameter missing!\n                Please configure \"name\" as a string in your\n                configuration.\"\"\")\n\n        if 'publish_topic' not in self.config:\n            raise EventifyConfigError(\n                \"\"\"Required configuration parameter missing!\n                Please configure \"public_topic\" as an object\n                in your configuration.\"\"\")\n\n        if 'topic' not in self.config['publish_topic']:\n            raise EventifyConfigError(\n                \"\"\"Required configuration parameter missing!\n                Please configure \"topic\" as a key in your\n                \"public_topic object.\"\"\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload the configuration for the service", "response": "def load_config(self):\n        \"\"\"\n        Load configuration for the service\n\n        Args:\n            config_file: Configuration file path\n        \"\"\"\n        logger.debug('loading config file: %s', self.config_file)\n        if os.path.exists(self.config_file):\n            with open(self.config_file) as file_handle:\n                return json.load(file_handle)\n        else:\n            logger.error('configuration file is required for eventify')\n        logger.error('unable to load configuration for service')\n        raise EventifyConfigError(\n            'Configuration is required! Missing: %s' % self.config_file\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if event loop is closed and create a new event loop", "response": "def check_event_loop():\n        \"\"\"\n        Check if event loop is closed and\n        create a new event loop\n        \"\"\"\n        loop = asyncio.get_event_loop()\n        if loop.is_closed():\n            asyncio.set_event_loop(asyncio.new_event_loop())"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if this is a tomodir", "response": "def is_tomodir(subdirectories):\n    \"\"\"provided with the subdirectories of a given directory, check if this is\n    a tomodir\n    \"\"\"\n    required = (\n        'exe',\n        'config',\n        'rho',\n        'mod',\n        'inv'\n    )\n    is_tomodir = True\n    for subdir in required:\n        if subdir not in subdirectories:\n            is_tomodir = False\n    return is_tomodir"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef check_if_needs_modeling(tomodir):\n    print('check for modeling', tomodir)\n    required_files = (\n        'config' + os.sep + 'config.dat',\n        'rho' + os.sep + 'rho.dat',\n        'grid' + os.sep + 'elem.dat',\n        'grid' + os.sep + 'elec.dat',\n        'exe' + os.sep + 'crmod.cfg',\n    )\n\n    not_allowed = (\n        'mod' + os.sep + 'volt.dat',\n    )\n    needs_modeling = True\n    for filename in not_allowed:\n        if os.path.isfile(tomodir + os.sep + filename):\n            needs_modeling = False\n\n    for filename in required_files:\n        full_file = tomodir + os.sep + filename\n        if not os.path.isfile(full_file):\n            print('does not exist: ', full_file)\n            needs_modeling = False\n\n    return needs_modeling", "response": "check if we need to run CRMod in a given tomodir"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_if_needs_inversion(tomodir):\n    required_files = (\n        'grid' + os.sep + 'elem.dat',\n        'grid' + os.sep + 'elec.dat',\n        'exe' + os.sep + 'crtomo.cfg',\n    )\n\n    needs_inversion = True\n\n    for filename in required_files:\n        if not os.path.isfile(tomodir + os.sep + filename):\n            needs_inversion = False\n\n    # check for crmod OR modeling capabilities\n    if not os.path.isfile(tomodir + os.sep + 'mod' + os.sep + 'volt.dat'):\n        if not check_if_needs_modeling(tomodir):\n            print('no volt.dat and no modeling possible')\n            needs_inversion = False\n\n    # check if finished\n    inv_ctr_file = tomodir + os.sep + 'inv' + os.sep + 'inv.ctr'\n    if os.path.isfile(inv_ctr_file):\n        inv_lines = open(inv_ctr_file, 'r').readlines()\n        print('inv_lines', inv_lines[-1])\n        if inv_lines[-1].startswith('***finished***'):\n            needs_inversion = False\n\n    return needs_inversion", "response": "check if we need to run CRTomo in a given tomodir"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking that there are no duplicate boundary coordinates.", "response": "def check_boundaries(boundaries):\n    # generate a complex number for each (x,y) pair\n    xy = boundaries[:, 0] + 1j * boundaries[:, 1]\n    \"\"\"\n    # for numpy > 1.9 , use:\n    unique_values, indices, indices_rev, counts = np.unique(\n        xy,\n        return_index=True,\n        return_inverse=True,\n        return_counts=True)\n    \"\"\"\n    # numpy 1.8 -->\n    unique_values, indices, indices_rev = np.unique(\n        xy,\n        return_index=True,\n        return_inverse=True)\n    # now bin the indices we use to reconstruct the original array. Each index\n    # that is present more than once will manifest in a bin with a number\n    # larger than one. Use as many bins as there are indices.\n    nr_bins = np.abs(indices_rev.min() - indices_rev.max()) + 1\n    counts, b = np.histogram(indices_rev, bins=nr_bins)\n    # <!-- numpy 1.8\n\n    doublets = np.where(counts > 1)\n    if doublets[0].size > 0:\n        print('ERROR: Duplicate boundary coordinates found!')\n        print('ERROR: Debug information')\n        for doublet in doublets[0]:\n            print('================')\n            print('x y type:')\n            print(boundaries[doublet, :])\n            print('lines: ')\n            print(np.where(indices_rev == doublet)[0])\n        raise Exception('Duplicate boundary coordinates found!')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_stabilizer_nodes(boundaries_raw, electrodes, nr_nodes_between):\n    boundaries = []\n\n    boundaries = boundaries_raw\n    # find first electrode in boundary\n    for nr in range(electrodes.shape[0] - 1):\n        index0 = np.where(\n            (boundaries[:, 0] == electrodes[nr, 0]) &\n            (boundaries[:, 1] == electrodes[nr, 1])\n        )[0]\n\n        index1 = np.where(\n            (boundaries[:, 0] == electrodes[nr + 1, 0]) &\n            (boundaries[:, 1] == electrodes[nr + 1, 1])\n        )[0]\n\n        index0 = index0[0]\n        index1 = index1[0]\n        if index1 - index0 < 0:\n            index0, index1 = index1, index0\n        running_index = index0\n        nr_nodes = index1 - index0 - 1\n        while nr_nodes < nr_nodes_between:\n            # determine line equation\n            xy0 = boundaries[running_index, 0:2]\n            xy1 = boundaries[running_index + 1, 0:2]\n\n            direction = xy1 - xy0\n            heading = direction / np.sqrt(np.sum(direction ** 2))\n\n            # new node\n            xy_new = xy0 + heading * direction / 2.0\n            a = boundaries[running_index, 2][np.newaxis]\n            xyb = np.hstack((xy_new, a))\n            boundaries = np.insert(boundaries, running_index + 1, xyb, axis=0)\n\n            # 2, because we have to count the new one\n            running_index += 2\n            index1 += 1\n            nr_nodes += 1\n\n            if running_index == index1:\n                running_index = index0\n\n    return boundaries", "response": "This function adds stabilizer nodes to the internal list of nodes that are not already in the internal list."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the id of the given point.", "response": "def get_point_id(self, p, char_length):\n        \"\"\"\n        Return the id of the given point (x,y) tuple.\n        \"\"\"\n        print('Checking point', p)\n        # TODO: This search loop NEEDS to be replaced with something sane\n        index = -1\n        for nr, i in enumerate(self.Points):\n            if(np.all(i == p)):\n                print('Point already in list at index {0}'.format(nr))\n                if self.Charlengths[nr] > char_length:\n                    print('Updating characteristic length')\n                    self.Charlengths[nr] = char_length\n                return nr\n\n        if(index == -1):\n            print('adding point:', p)\n            self.Points.append(p)\n            self.Charlengths.append(char_length)\n            return len(self.Points) - 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_boundary(self, p1, p2, btype):\n        index = self.add_line(p1, p2, self.char_lengths['boundary'])\n        # self.Boundaries.append((p1_id,p2_id,btype))\n        self.BoundaryIndices.append(index)\n        self.Boundaries.append((p1, p2, btype))", "response": "Add a boundary line to the set of boundary entries."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_line(self, p1, p2, char_length):\n        p1_id = self.get_point_id(p1, char_length)\n        p2_id = self.get_point_id(p2, char_length)\n        self.Lines.append((p1_id, p2_id))\n        return len(self.Lines)", "response": "Add a line to the list."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the index of the item in the list that is in the list. If the item is not in the list return - 1. Otherwise return - 1.", "response": "def is_in(self, search_list, pair):\n        \"\"\"\n        If pair is in search_list, return the index. Otherwise return -1\n        \"\"\"\n        index = -1\n        for nr, i in enumerate(search_list):\n            if(np.all(i == pair)):\n                return nr\n        return index"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read_electrodes(self, electrodes):\n        for nr, electrode in enumerate(electrodes):\n            index = self.get_point_id(\n                electrode, self.char_lengths['electrode'])\n            self.Electrodes.append(index)", "response": "Read in electrodes from the given list of electrodes."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading extra nodes from a file.", "response": "def read_extra_nodes(self, filename):\n        \"\"\"Read extra nodes in. Format: x y\n\n        What happens if we add nodes on the boundaries, which are not included\n        in the boundaries?\n        \"\"\"\n        data = np.atleast_2d(np.loadtxt(filename))\n        for nr, pair in enumerate(data):\n            index = self.get_point_id(pair, self.char_lengths['extra_node'])\n            self.ExtraNodes.append(index)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreads extra lines from the given file.", "response": "def read_extra_lines(self, filename):\n        \"\"\"Read extra lines from the given filename. Each line is defined in\n        one line with four coordinates: x1 y1 x2 y2. (x1,y1) denotes the\n        starting point, (x2, y2) the end point of the line.\n        \"\"\"\n        data = np.atleast_2d(np.loadtxt(filename))\n        for nr, coords in enumerate(data):\n            p1 = [coords[0], coords[1]]\n            p2 = [coords[2], coords[3]]\n            index = self.add_line(p1, p2, self.char_lengths['extra_line'])\n            self.ExtraLineIndices.append(index)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef write_electrodes(self, filename):\n        fid = open(filename, 'w')\n        for i in self.Electrodes:\n            fid.write('{0} {1}\\n'.format(self.Points[i][0], self.Points[i][1]))\n        fid.close()", "response": "Write X Y coordinates of electrodes to file"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef write_boundaries(self, filename):\n        fid = open(filename, 'w')\n        for i in self.Boundaries:\n            print(i)\n            # fid.write('{0} {1} {2}\\n'.format(i[0], i[1], i[2]))\n            fid.write(\n                '{0} {1} {2} {3} {4}\\n'.format(\n                    i[0][0], i[0][1], i[1][0], i[1][1], i[2]))\n        fid.close()", "response": "Write the boundaries of the current assessment to a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef read_char_lengths(self, filename, electrode_filename):\n\n        if os.path.isfile(filename):\n            data = np.atleast_1d(np.loadtxt(filename))\n            if data.size == 4:\n                characteristic_length = data\n                # check sign of first (electrode) length value\n                if characteristic_length[0] < 0:\n                    try:\n                        elec_positions = np.loadtxt(electrode_filename)\n                    except:\n                        raise IOError(\n                            'The was an error opening the electrode file')\n                    import scipy.spatial.distance\n                    distances = scipy.spatial.distance.pdist(elec_positions)\n                    characteristic_length[0] = min(distances) * np.abs(\n                        characteristic_length[0])\n                    if characteristic_length[0] == 0:\n                        raise Exception(\n                            'Error computing electrode ' +\n                            'distances (got a minimal distance of zero')\n\n            else:\n                characteristic_length = np.ones(4) * data[0]\n        else:\n            characteristic_length = np.ones(4)\n\n        if np.any(characteristic_length <= 0):\n            raise Exception('No negative characteristic lengths allowed ' +\n                            '(except for electrode length')\n\n        self.char_lengths = {}\n        for key, item in zip(('electrode',\n                              'boundary',\n                              'extra_line',\n                              'extra_node'),\n                             characteristic_length):\n            self.char_lengths[key] = item", "response": "Read the character lengths from the given file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef write_points(self, fid):\n        for nr, point in enumerate(self.Points):\n            fid.write(\n                'Point({0}) = {{{1}, {2}, 0, {3}}};\\n'.format(\n                    nr + 1, point[0], point[1], self.Charlengths[nr]))", "response": "Writes the grid points to the GMSH - command file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwriting the. geo file.", "response": "def write_geo_file(self, filename):\n        \"\"\"\n        Write the .geo file\n        \"\"\"\n        fid = open(filename, 'w')\n        # 2D mesh algorithm (1=MeshAdapt, 2=Automatic, 5=Delaunay, 6=Frontal,\n        # 7=bamg, 8=delquad)\n        # according to the GMSH-mailing list the frontal algorithm should be\n        # one of the best in terms of grid quality\n        fid.write('Mesh.Algorithm = 6;\\n')\n\n        self.write_points(fid)\n        self.write_lines(fid)\n\n        # fid.write('Coherence;\\n')\n        # write line loop\n        fid.write('Line Loop(1) = {')\n        fid.write(','.join(['{0}'.format(x) for x in self.BoundaryIndices]))\n        # for i in self.BoundaryIndices:\n        #     fid.write('{0},'.format(i))\n        fid.write('};\\n')\n        # # fid.write('{0}}};\\n'.format(len(self.Lines)))\n        fid.write('Plane Surface(7) = {1};\\n')\n\n        self.write_in_plane_nodes(fid)\n        # fid.write('Coherence;\\n')\n        self.write_extra_nodes(fid)\n        # fid.write('Coherence;\\n')\n        for index in self.ExtraLineIndices:\n            fid.write('Line {' + '{0}'.format(index) + '} In Surface {7};\\n')\n\n        # Lloyd mesh optimisation crashes\n        # fid.write('Mesh.Lloyd = 1;\\n')\n\n        # run the mesher\n        fid.write('Mesh 7;')\n\n        if os.path.isfile('../gmsh_commands.dat'):\n            fid2 = open('../gmsh_commands.dat', 'r')\n            additional_commands = fid2.read()\n            fid2.close()\n\n            fid.write('\\n')\n            fid.write(additional_commands)\n\n        fid.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nextracts the senza cli output from the response", "response": "def get_output(cls, response: requests.Response) -> str:\n        \"\"\"\n        Extracts the senza cli output from the response\n        \"\"\"\n        output = response.headers['X-Lizzy-Output']  # type: str\n        output = output.replace('\\\\n', '\\n')  # unescape new lines\n        lines = ('[AGENT] {}'.format(line) for line in output.splitlines())\n        return '\\n'.join(lines)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrequest a new stack.", "response": "def new_stack(self,\n                  keep_stacks: int,\n                  new_traffic: int,\n                  senza_yaml: dict,\n                  stack_version: str,\n                  disable_rollback: bool,\n                  parameters: List[str],\n                  region: Optional[str],\n                  dry_run: bool,\n                  tags: List[str]) -> (Dict[str, str], str):  # TODO put arguments in a more logical order\n        \"\"\"\n        Requests a new stack.\n        \"\"\"\n        header = make_header(self.access_token)\n        data = {'senza_yaml': yaml.dump(senza_yaml),\n                'stack_version': stack_version,\n                'disable_rollback': disable_rollback,\n                'dry_run': dry_run,\n                'keep_stacks': keep_stacks,\n                'new_traffic': new_traffic,\n                'parameters': parameters,\n                'tags': tags}\n        if region:\n            data['region'] = region\n\n        request = self.stacks_url.post(json=data, headers=header, verify=False)\n        request.raise_for_status()\n        return request.json(), self.get_output(request)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the analytical potential in distance r over a homogeneous half - space", "response": "def pot_ana(r, rho):\n    \"\"\"Return the analytical potential in distance r over a homogeneous\n    half-space\n    \"\"\"\n    I = 1.0\n    sigma = 1.0 / rho\n    phi = np.divide(I, (2.0 * np.pi * sigma * r))\n    return phi"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncomputes the potential superpositions of each current dipole in the given configs using the provided resistivity of half - space.", "response": "def compute_potentials_analytical_hs(grid, configs_raw, rho):\n    \"\"\"Compute the potential superpositions of each current dipole in the\n    configurations, using the provided resistivity\n\n    Parameters\n    ----------\n    grid:\n        crt_grid object with loaded FE grid. Used for the electrode positions\n    configs_raw: numpy.ndarray\n        Nx4 array containing N four-point spreads\n    rho: float\n        resistivity of half-space\n\n    Returns\n    -------\n    potentials: list\n        List containing N arrays, each of size M (nr of grid nodes)\n\n    \"\"\"\n    potentials = []\n    nodes_sorted = grid.nodes['sorted']\n    nodes_raw = grid.nodes['sorted']\n\n    for config in configs_raw:\n        print('potential configs', config)\n        # determine distance of all nodes to both electrodes\n        e1_node = grid.get_electrode_node(config[0])\n        print('e1_node', e1_node)\n        electrode1 = nodes_sorted[e1_node][1:3]\n        # electrode1 = nodes_sorted[config[0]][1:3]\n        r1 = np.sqrt(\n            (nodes_raw[:, 1] - electrode1[0]) ** 2 +\n            (nodes_raw[:, 2] - electrode1[1]) ** 2\n        )\n        # electrode2 = nodes_sorted[config[1]][1:3]\n        e2_node = grid.get_electrode_node(config[1])\n        print('e2_node', e2_node)\n        electrode2 = nodes_sorted[e2_node][1:3]\n        r2 = np.sqrt(\n            (nodes_raw[:, 1] - electrode2[0]) ** 2 +\n            (nodes_raw[:, 2] - electrode2[1]) ** 2\n        )\n        pot1 = pot_ana(r1, rho)\n        pot2 = - pot_ana(r2, rho)\n        pot12 = pot1 + pot2\n        potentials.append(pot12)\n    return potentials"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngives a list of potential distribution and corresponding four - point chains compute the voltages of the electrodes in the order they appear.", "response": "def compute_voltages(grid, configs_raw, potentials_raw):\n    \"\"\"Given a list of potential distribution and corresponding four-point\n    spreads, compute the voltages\n\n    Parameters\n    ----------\n    grid:\n        crt_grid object the grid is used to infer electrode positions\n    configs_raw: Nx4 array\n        containing the measurement configs (1-indexed)\n    potentials_raw: list with N entries\n        corresponding to each measurement, containing the node potentials of\n        each injection dipole.\n    \"\"\"\n    # we operate on 0-indexed arrays, config holds 1-indexed values\n    # configs = configs_raw - 1\n    voltages = []\n    for config, potentials in zip(configs_raw, potentials_raw):\n        print('config', config)\n        e3_node = grid.get_electrode_node(config[2])\n        e4_node = grid.get_electrode_node(config[3])\n        print(e3_node, e4_node)\n        print('pot1', potentials[e3_node])\n        print('pot2', potentials[e4_node])\n        voltage = potentials[e3_node] - potentials[e4_node]\n        voltages.append(voltage)\n    return voltages"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwriting the data in VCF format.", "response": "def vcf_writer(parser, keep, extract, args):\n    \"\"\"Writes the data in VCF format.\"\"\"\n    # The output\n    output = sys.stdout if args.output == \"-\" else open(args.output, \"w\")\n\n    try:\n        # Getting the samples\n        samples = np.array(parser.get_samples(), dtype=str)\n        k = _get_sample_select(samples=samples, keep=keep)\n\n        # Writing the VCF header\n        output.write(_VCF_HEADER.format(\n            date=datetime.today().strftime(\"%Y%m%d\"),\n            version=__version__,\n            samples=\"\\t\".join(samples[k]),\n        ))\n\n        # The data generator\n        generator = _get_generator(parser=parser, extract=extract, keep=k,\n                                   check_maf=args.maf)\n\n        # The number of markers extracted\n        nb_extracted = 0\n\n        for data in generator:\n            # Keeping only the required genotypes\n            genotypes = data.genotypes\n\n            # Computing the alternative allele frequency\n            af = np.nanmean(genotypes) / 2\n\n            print(data.variant.chrom, data.variant.pos, data.variant.name,\n                  data.reference, data.coded, \".\", \"PASS\", \"AF={}\".format(af),\n                  \"GT:DS\", sep=\"\\t\", end=\"\", file=output)\n\n            for geno in genotypes:\n                if np.isnan(geno):\n                    output.write(\"\\t./.:.\")\n                else:\n                    rounded_geno = int(round(geno, 0))\n                    output.write(\"\\t{}:{}\".format(\n                        _VCF_GT_MAP[rounded_geno], geno,\n                    ))\n\n            output.write(\"\\n\")\n            nb_extracted += 1\n\n        if nb_extracted == 0:\n            logger.warning(\"No markers matched the extract list\")\n\n    finally:\n        output.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwrites the data in CSV format.", "response": "def csv_writer(parser, keep, extract, args):\n    \"\"\"Writes the data in CSV format.\"\"\"\n    # The output\n    output = sys.stdout if args.output == \"-\" else open(args.output, \"w\")\n\n    try:\n        # Getting the samples\n        samples = np.array(parser.get_samples(), dtype=str)\n        k = _get_sample_select(samples=samples, keep=keep)\n\n        # Writing the CSV header\n        print(\"sample_id\", \"variant_id\", \"chromosome\", \"position\", \"reference\",\n              \"coded\", \"dosage\", \"hard_call\", sep=\",\", file=output)\n\n        # The data generator\n        generator = _get_generator(parser=parser, extract=extract, keep=k,\n                                   check_maf=args.maf)\n\n        # The number of markers extracted\n        nb_extracted = 0\n\n        for data in generator:\n            # Keeping only the required genotypes\n            genotypes = data.genotypes\n\n            # The hard call mapping\n            hard_call_mapping = {\n                0: \"{ref}/{ref}\".format(ref=data.reference),\n                1: \"{ref}/{alt}\".format(ref=data.reference, alt=data.coded),\n                2: \"{alt}/{alt}\".format(alt=data.coded),\n            }\n\n            for sample, geno in zip(samples[k], genotypes):\n                # Is the genotype missing\n                is_missing = np.isnan(geno)\n\n                # Hard coding (NaN values are empty string)\n                hard_coded = None\n                if is_missing:\n                    geno = \"\"\n                    hard_coded = \"\"\n                else:\n                    hard_coded = hard_call_mapping[int(round(geno, 0))]\n\n                print(sample, data.variant.name, data.variant.chrom,\n                      data.variant.pos, data.reference, data.coded,\n                      geno, hard_coded, sep=\",\", file=output)\n\n            nb_extracted += 1\n\n        if nb_extracted == 0:\n            logger.warning(\"No markers matched the extract list\")\n\n    finally:\n        output.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwrites the BED file containing the current set of markers and the FAM files.", "response": "def bed_writer(parser, keep, extract, args):\n    \"\"\"Writes BED/BIM/FAM files.\"\"\"\n    # The output bed and bim file\n    bim_fn = args.output + \".bim\"\n    with open(bim_fn, \"w\") as bim, PyPlink(args.output, \"w\") as bed:\n        # Getting the samples\n        samples = np.array(parser.get_samples(), dtype=str)\n        k = _get_sample_select(samples=samples, keep=keep)\n\n        # Writing the FAM file\n        with open(args.output + \".fam\", \"w\") as fam:\n            for sample in samples[k]:\n                print(sample, sample, \"0\", \"0\", \"0\", \"-1\", sep=\" \", file=fam)\n\n        # Getting the data generator\n        generator = _get_generator(parser=parser, extract=extract, keep=k,\n                                   check_maf=args.maf)\n\n        # The number of markers extracted\n        nb_extracted = 0\n\n        for data in generator:\n            # Keeping only the required genotypes, changing NaN to -1 and\n            # rounding to get a hard call\n            genotypes = data.genotypes\n            genotypes[np.isnan(genotypes)] = -1\n            genotypes = np.round(genotypes, 0)\n\n            # Writing the genotypes and the BIM file\n            bed.write_genotypes(genotypes)\n            print(\n                _PLINK_CHROM_ENCODE.get(str(data.variant.chrom),\n                                        data.variant.chrom),\n                data.variant.name, \"0\", data.variant.pos, data.coded,\n                data.reference, sep=\"\\t\", file=bim,\n            )\n            nb_extracted += 1\n\n        if nb_extracted == 0:\n            logger.warning(\"No markers matched the extract list\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_sample_select(samples, keep):\n    k = np.ones_like(samples, dtype=bool)\n    if keep is not None:\n        k = np.array([s in keep for s in samples], dtype=bool)\n        if np.sum(k) == 0:\n            logger.warning(\"No samples matched the keep list\")\n    return k", "response": "Returns a vector of True or False to keep samples."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating the data from the parser with extract markers and keep if required.", "response": "def _get_generator(parser, extract, keep, check_maf):\n    \"\"\"Generates the data (with extract markers and keep, if required.\"\"\"\n    if extract is not None:\n        parser = Extractor(parser, names=extract)\n\n    for data in parser.iter_genotypes():\n        data.genotypes = data.genotypes[keep]\n\n        # Checking the MAF, if required\n        if check_maf:\n            data.code_minor()\n\n        yield data"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck the arguments and options.", "response": "def check_args(args):\n    \"\"\"Checks the arguments and options.\"\"\"\n    # Checking that only VCF can have a - (stdout) as output\n    if args.output_format not in _streamable_format and args.output == \"-\":\n        logger.error(\"{} format cannot be streamed to standard output\"\n                     \"\".format(args.output_format))\n        sys.exit(1)\n\n    # Checking the file extensions\n    if args.output_format == \"vcf\" and args.output != \"-\":\n        if not args.output.endswith(\".vcf\"):\n            args.output += \".vcf\"\n\n    elif args.output_format == \"plink\":\n        if args.output.endswith(\".bed\"):\n            args.output = args.output[:-4]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_args():\n    parser = argparse.ArgumentParser(\n        prog=\"geneparse-extractor\",\n        description=\"Genotype file extractor. This tool will extract markers \"\n                    \"according to names or to genomic locations.\",\n        epilog=\"The parser arguments (PARSER_ARGS) are the same as the one in \"\n               \"the API. For example, the arguments for the Plink parser is \"\n               \"'prefix:PREFIX' (where PREFIX is the prefix of the \"\n               \"BED/BIM/FAM files).\",\n    )\n\n    # The input file format\n    group = parser.add_argument_group(\"Input Options\")\n    group.add_argument(\n        \"-f\", \"--format\", metavar=\"FORMAT\", required=True, type=str,\n        dest=\"input_format\", choices=set(parsers.keys()),\n        help=\"The input file format.\",\n    )\n\n    group.add_argument(\n        nargs=\"+\", dest=\"parser_args\", type=str, metavar=\"PARSER_ARGS\",\n        help=\"The arguments that will be passed to the genotype parsers.\",\n    )\n\n    # The extract options\n    group = parser.add_argument_group(\"Extract Options\")\n    group.add_argument(\n        \"-e\", \"--extract\", metavar=\"FILE\", type=argparse.FileType(\"r\"),\n        help=\"The list of markers to extract (one per line, no header).\",\n    )\n    group.add_argument(\n        \"-k\", \"--keep\", metavar=\"FILE\", type=argparse.FileType(\"r\"),\n        help=\"The list of samples to keep (one per line, no header).\",\n    )\n    group.add_argument(\n        \"--maf\", action=\"store_true\",\n        help=\"Check MAF and flip the allele coding if the MAF is higher \"\n             \"than 50%%.\",\n    )\n\n    # The output options\n    group = parser.add_argument_group(\"Output Options\")\n    group.add_argument(\n        \"-o\", \"--output\", metavar=\"FILE\", type=str, required=True,\n        help=\"The output file (can be '-' for STDOUT when using VCF or CSV as \"\n             \"output format).\",\n    )\n    group.add_argument(\n        \"--output-format\", metavar=\"FORMAT\", default=\"vcf\", type=str,\n        choices={\"vcf\", \"plink\", \"csv\"},\n        help=\"The output file format. Note that the extension will be added \"\n             \"if absent. Note that CSV is a long format (hence it might take \"\n             \"more disk space).\",\n    )\n\n    return parser.parse_args()", "response": "Parses the arguments and options and returns the arguments and options."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef bitterness(self, ibu_method, early_og, batch_size):\n        \"Calculate bitterness based on chosen method\"\n\n        if ibu_method == \"tinseth\":\n            bitterness = 1.65 * math.pow(0.000125, early_og - 1.0) * ((1 - math.pow(math.e, -0.04 * self.time)) / 4.15) * ((self.alpha / 100.0 * self.amount * 1000000) / batch_size) * self.utilization_factor()\n\n        elif ibu_method == \"rager\":\n            utilization = 18.11 + 13.86 * math.tanh((self.time - 31.32) / 18.27)\n            adjustment = max(0, (early_og - 1.050) / 0.2)\n            bitterness = self.amount * 100 * utilization * self.utilization_factor() * self.alpha / (batch_size * (1 + adjustment))\n\n        else:\n            raise Exception(\"Unknown IBU method %s!\" % ibu_method)\n\n        return bitterness", "response": "Calculate bitterness based on chosen method"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _check_error(response):\n        if (not response.ok) or (response.status_code != 200):\n            raise Exception(\n                response.json()['error'] + ': ' +\n                response.json()['error_description']\n            )", "response": "Raises an exception if the Spark Cloud returned an error."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nproceed to login to the Spark Cloud and returns an access token.", "response": "def _login(self, username, password):\n        \"\"\"Proceed to login to the Spark Cloud and returns an access token.\"\"\"\n        data = {\n            'username': username,\n            'password': password,\n            'grant_type': 'password'\n        }\n        r = self.spark_api.oauth.token.POST(auth=('spark', 'spark'), data=data, timeout=self.timeout)\n        self._check_error(r)\n        return r.json()['access_token']"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a dictionary of devices known to the user account.", "response": "def devices(self):\n        \"\"\"Create a dictionary of devices known to the user account.\"\"\"\n        params = {'access_token': self.access_token}\n        r = self.spark_api.GET(params=params, timeout=self.timeout)\n        self._check_error(r)\n        json_list = r.json()\n\n        devices_dict = {}\n        if json_list:\n            # it is possible the keys in json responses varies from one device to another: compute the set of all keys\n            allKeys = {'functions', 'variables', 'api', 'requires_deep_update', 'status'} # added by device_info\n            for device_json in json_list:\n                allKeys.update(device_json.keys())\n\n            Device = _BaseDevice.make_device_class(self, allKeys, timeout = self.timeout)\n                    \n            for d in json_list:\n                if d[\"connected\"]:\n                    info = self._get_device_info(d['id'])\n                    d['functions'] = info.get('functions')\n                    d['variables'] = info.get('variables')\n                    d['api'] = self.spark_api(d['id'])\n                    d['requires_deep_update'] = d.get('requires_deep_update', False)\n                    d['status'] = info.get('status')\n                # ensure the set of all keys is present in the dictionnary (Device constructor requires all keys present)\n                [d.setdefault(key, None) for key in allKeys]\n\n                devices_dict[d['name']] = Device(**d)\n                \n        return devices_dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nqueries the Spark Cloud for detailed information about a device.", "response": "def _get_device_info(self, device_id):\n        \"\"\"Queries the Spark Cloud for detailed information about a device.\"\"\"\n        params = {'access_token': self.access_token}\n        r = self.spark_api(device_id).GET(params=params, timeout=30)\n        self._check_error(r)\n        return r.json()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef make_device_class(spark_cloud, entries, timeout=30):\n        attrs = list(\n            set(\n                list(entries) + [\n                    'requires_deep_update', 'functions', 'variables', 'api', 'status'\n                ]\n            )\n        )\n        \n        return type(\n            'Device',\n            (_BaseDevice, namedtuple('Device', attrs)),\n            {'__slots__': (), 'spark_cloud': spark_cloud, 'timeout' : timeout}\n        )", "response": "Returns a dynamic Device class based on what a GET device list from\n        the Spark Cloud returns."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntries to report a metric to the Lizzy server", "response": "def report_metric(metric_name: str, value: int, fail_silently: bool=True):\n    \"\"\"\n    Tries to report a metric, ignoring all errors\n    \"\"\"\n    if metricz is None:\n        return\n\n    configuration = Configuration()\n\n    try:\n        lizzy_domain = urlparse(configuration.lizzy_url).netloc\n        lizzy_name, _ = lizzy_domain.split('.', 1)\n    except Exception:\n        lizzy_name = 'UNKNOWN'\n\n    tags = {\n        'version': VERSION,\n        'lizzy': lizzy_name\n    }\n\n    # noinspection PyBroadException\n    try:\n        writer = metricz.MetricWriter(url=configuration.token_url,\n                                      directory=configuration.credentials_dir,\n                                      fail_silently=False)\n        writer.write_metric(metric_name, value, tags, timeout=10)\n    except Exception:\n        if not fail_silently:\n            raise"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the bound field from the form with the given field name", "response": "def get_form_bound_field(form, field_name):\n    \"\"\"\n    Intends to get the bound field from the form regarding the field name\n\n    :param form: Django Form: django form instance\n    :param field_name: str: name of the field in form instance\n    :return: Django Form bound field\n    \"\"\"\n    field = form.fields[field_name]\n    field = field.get_bound_field(form, field_name)\n    return field"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread a particular config file from the specified module.", "response": "def read(self, module_name):\n        \"\"\"\n        Read a particular config file\n\n        Parameters\n        ----------\n        module_name: String\n            The analysis_path of the module for which a config is to be read (priors relate one to one with configs).\n        \"\"\"\n        self.parser.read(\"{}/{}.ini\".format(self.path, module_name.split(\".\")[-1]))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_for_nearest_ancestor(self, cls, attribute_name):\n        for family_cls in family(cls):\n            if self.has(family_cls.__module__, family_cls.__name__, attribute_name):\n                return self.get(family_cls.__module__, family_cls.__name__, attribute_name)\n\n        ini_filename = cls.__module__.split(\".\")[-1]\n        raise exc.PriorException(\n            \"The prior config at {}/{} does not contain {} in {} or any of its parents\".format(self.path,\n                                                                                               ini_filename,\n                                                                                               attribute_name,\n                                                                                               cls.__name__\n                                                                                               ))", "response": "Returns the prior with the given analysis_path for this class or one of its ancestors."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning True iff the option with the given name is present in the module class and attribute.", "response": "def has(self, module_name, class_name, attribute_name):\n        \"\"\"\n        Parameters\n        ----------\n        module_name: String\n            The analysis_path of the module\n        class_name: String\n            The analysis_path of the class\n        attribute_name: String\n            The analysis_path of the attribute\n\n        Returns\n        -------\n        has_prior: bool\n            True iff a prior exists for the module, class and attribute\n        \"\"\"\n        self.read(module_name)\n        return self.parser.has_option(class_name, attribute_name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fib(number: int) -> int:\n    if number < 2:\n        return number\n    return fib(number - 1) + fib(number - 2)", "response": "Simple Fibonacci function.\n\n    >>> fib(10)\n    55"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_data(self, data):\n        subdata = np.atleast_2d(data)\n\n        # we try to accommodate transposed input\n        if subdata.shape[1] != self.grid.nr_of_nodes:\n            if subdata.shape[0] == self.grid.nr_of_nodes:\n                subdata = subdata.T\n            else:\n                raise Exception(\n                    'Number of values does not match the number of ' +\n                    'nodes in the grid {0} grid nodes vs {1} data'.format(\n                        self.grid.nr_of_nodes, subdata.shape,\n                    )\n                )\n\n        return_ids = []\n        for dataset in subdata:\n            cid = self._get_next_index()\n            self.nodevals[cid] = dataset.copy()\n            return_ids.append(cid)\n\n        if len(return_ids) == 1:\n            return return_ids[0]\n        else:\n            return return_ids", "response": "Add data to the node value sets and return the ids of the new node value sets."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nlogging a given SQL input before executing it.", "response": "def _log_execute(self, cursor, sql, context=\"\"):\n        \"\"\"\n        Log a given SQL input (as string) before executing it.\n        \"\"\"\n        log.info(\"{} raw SQL:\\n{}\".format(context, sql))\n        cursor.execute(sql)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _build_list(self, matches, current_level='1'):\n        lines = ['<ul>']\n        while matches and current_level <= matches[0][0]:\n            # Build list items and indent each line by two spaces.\n            lines.extend('  ' + line for line in self._build_list_items(matches))\n        lines.append('</ul>')\n        return lines", "response": "Builds an unordered HTML list out of the list of matches."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _build_list_items(self, matches):\n        assert len(matches) > 0, \"Should be at least one match, by assumption\"\n\n        lines = []\n        current_level = matches[0][0]\n        while matches and current_level <= matches[0][0]:\n            level, _, tag_id, title = matches[0]\n            if current_level < level:\n                lines.extend(self._build_list(matches, level))\n                continue\n\n            if tag_id:\n                lines.append('<li><a href=\"#{0}\">{1}</a></li>'.format(tag_id, title))\n            else:\n                lines.append('<li>{0}</li>'.format(title))\n            matches.pop(0)\n        return lines", "response": "Builds the HTML list items for the next header that has a larger or equal header s level."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_highlights_docs(docs):\n        if not isinstance(docs, list):\n            docs = [docs]\n\n        for doc in docs:\n            if 'matched_sentence' in doc['_source']:\n                matched_sentences = doc['_source']['matched_sentence']\n                for sentence in matched_sentences:\n                    # also add matched sentence to knowledge graph\n                    doc['_source']['knowledge_graph']['matched_sentence'] = [{'key': sentence, 'value': sentence}]\n\n                paragraph = SimilarityScoreRerank.get_description(doc)\n                if paragraph:\n                    high_para = SimilarityScoreRerank.create_highlighted_sentences(matched_sentences, paragraph)\n                    if high_para:\n                        if 'highlight' not in doc:\n                            doc['highlight'] = dict()\n                        doc['highlight']['knowledge_graph.description.value'] = [high_para]\n        return docs", "response": "Adds highlights to the given list of docs."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef instance(cls, *args, **kwgs):\n        if not hasattr(cls, \"_instance\"):\n            cls._instance = cls(*args, **kwgs)\n        return cls._instance", "response": "Will be the only instance of this class"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_current_object(self):\n        if not hasattr(self.__local, '__release_local__'):\n            return self.__local()\n        try:\n            return getattr(self.__local, self.__name__)\n        except AttributeError:\n            raise RuntimeError('no object bound to %s' % self.__name__)", "response": "Return the current object."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconfigures the logger behvior for the simulations.", "response": "def configure_logger(logger, filename, folder, log_level):\n    '''Configure logging behvior for the simulations.\n    '''\n    fmt = logging.Formatter('%(asctime)s %(levelname)s: %(message)s')\n    if folder is not None:\n        log_file = os.path.join(folder, filename)\n        hdl = logging.FileHandler(log_file)\n        hdl.setFormatter(fmt)\n        hdl.setLevel(log_level)\n        logger.addHandler(hdl)\n    shdl = logging.StreamHandler()\n    shdl.setLevel(log_level)\n    shdl.setFormatter(fmt)\n    logger.addHandler(shdl)\n    logger.setLevel(log_level)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nnumbering of positional arguments values. Dynamically computed from the arguments attribute.", "response": "def _nargs(f) -> Optional[int]:\n    '''\n        number of positional arguments values. Dynamically computed from the arguments attribute.\n    '''\n    if isinstance(f, Function):\n        return f.nargs\n    spec = inspect.getfullargspec(f)\n    if spec.varargs is not None:\n        return None\n    return len(spec.args)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _ndefs(f):\n    '''\n        number of any default values for positional or keyword parameters\n    '''\n    if isinstance(f, Function):\n        return f.ndefs\n    spec = inspect.getfullargspec(f)\n    if spec.defaults is None:\n        return 0\n    return len(spec.defaults)", "response": "Returns the number of default values for positional or keyword parameters\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndecorate normal function to Function with ( optional ) number of arguments and outputs.", "response": "def func(nargs: Optional[int] = None, nouts: Optional[int] = None, ndefs: Optional[int] = None):\n    \"\"\"\n        decorates normal function to Function with (optional) number of arguments and outputs.\n\n        : func(nargs: Optional[int] = None, nouts: Optional[int] = None, ndefs: Optional[int] = None)\n    \"\"\"\n    return lambda f: wraps(f)(WrappedFunction(f, nargs=nargs, nouts=nouts, ndefs=ndefs))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef multidispatch(*, nargs=None, nouts=None):\n    def wrapper(f):\n        return wraps(f)(MultiDispatchFunction(f, nargs=nargs, nouts=nouts))\n\n    return wrapper", "response": "multidispatch decorator for functions that are called multiple times."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef flip(f: Callable) -> Function:\n    nargs_, nouts_, ndefs_ = nargs(f), nouts(f), ndefs(f)\n    return WrappedFunction(lambda *args, **kwargs: f(args[1], args[0], *args[2:], **kwargs),\n                           nargs=nargs_, nouts=nouts_, ndefs=ndefs_)", "response": "Flip order of first two arguments to function."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef tagfunc(nargs=None, ndefs=None, nouts=None):\n    def wrapper(f):\n        return wraps(f)(FunctionWithTag(f, nargs=nargs, nouts=nouts, ndefs=ndefs))\n\n    return wrapper", "response": "decorator for tagged function\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _(f, x):\n    result = {}\n    for k, v in x.items():\n        k_, v_ = f(k, v)\n        result[k_] = v_\n    return result", "response": "fmap for dict like not f should have signature f::key - > value - > key - > value"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwraps function for fmap of dict to concern only on keys.", "response": "def pass_key(f):\n    \"\"\"\n    helper function for fmap of dict to concern only on values.\n    `pass_key(f)` would return a function which shadow input `key` and combine it\n    with return of `f(value)` to `(key, f(value))`.\n    \"\"\"\n    @func(nargs=1, nouts=1)\n    def wrapper(k, v):\n        return (k, f(v))\n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfilters function version of filter", "response": "def filter_(f, x):\n    \"\"\"\n    function version of filter, when `x` is a Functor of Monoid, it will call:\n    `reduce(lambda e: e.extend, x.fmap(f))`\n    \"\"\"\n    return reduce(lambda e, v: e.extend(v), x.fmap(f))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfilter for dict, note `f` should have signature: `f::key->value->bool`", "response": "def _(f, x):\n    \"\"\"\n    filter for dict, note `f` should have signature: `f::key->value->bool`\n    \"\"\"\n    return {k: v for k, v in x.items() if f(k, v)}"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfunctions map for Wrapped Function. A forced transfermation to WrappedFunction would be applied.async def fmap(self, f: 'WrappedFunction') -> 'WrappedFunction'", "response": "def fmap(self, f: 'WrappedFunction') -> 'WrappedFunction':\n        '''\n            function map for Wrapped Function. A forced transfermation to WrappedFunction would be applied.async def \n\n            fmap(self, f: 'WrappedFunction') -> 'WrappedFunction'\n        '''\n        if not isinstance(f, WrappedFunction):\n            f = WrappedFunction(f)\n        return WrappedFunction(lambda *args, **kwargs: self(f(*args, **kwargs)), nargs=f.nargs, nouts=self.nouts)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef retrieve(pdb_id, cache_dir = None):\n        '''Creates a PDBML object by using a cached copy of the files if they exists or by retrieving the files from the RCSB.'''\n\n        pdb_contents = None\n        xml_contents = None\n        pdb_id = pdb_id.upper()\n\n        if cache_dir:\n            # Check to see whether we have a cached copy of the PDB file\n            filename = os.path.join(cache_dir, \"%s.pdb\" % pdb_id)\n            if os.path.exists(filename):\n                pdb_contents = read_file(filename)\n\n            # Check to see whether we have a cached copy of the XML file\n            filename = os.path.join(cache_dir, \"%s.xml\" % pdb_id)\n            if os.path.exists(filename):\n                xml_contents = read_file(filename)\n\n        # Get any missing files from the RCSB and create cached copies if appropriate\n        if not pdb_contents:\n            pdb_contents = rcsb.retrieve_pdb(pdb_id)\n            if cache_dir:\n                write_file(os.path.join(cache_dir, \"%s.pdb\" % pdb_id), pdb_contents)\n\n        if not xml_contents:\n            xml_contents = rcsb.retrieve_xml(pdb_id)\n            if cache_dir:\n                write_file(os.path.join(cache_dir, \"%s.xml\" % pdb_id), xml_contents)\n\n        # Return the object\n        return PDBML_slow(xml_contents, pdb_contents)", "response": "Creates a PDBML object by using a cached copy of the files if they exists or by retrieving the files from the RCSB."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_deprecation(self):\n        '''Checks to see if the PDB file has been deprecated and, if so, what the new ID is.'''\n        deprecation_tag = self.main_tag.getElementsByTagName(\"PDBx:pdbx_database_PDB_obs_sprCategory\")\n        assert(len(deprecation_tag) <= 1)\n        if deprecation_tag:\n            deprecation_tag = deprecation_tag[0]\n\n            deprecation_subtag = deprecation_tag.getElementsByTagName(\"PDBx:pdbx_database_PDB_obs_spr\")\n            assert(len(deprecation_subtag) == 1)\n            deprecation_subtag = deprecation_subtag[0]\n            assert(deprecation_subtag.hasAttribute('replace_pdb_id'))\n            assert(deprecation_subtag.hasAttribute('pdb_id'))\n            old_pdb_id = deprecation_subtag.getAttribute('replace_pdb_id').upper()\n            new_pdb_id = deprecation_subtag.getAttribute('pdb_id').upper()\n\n            if self.pdb_id == old_pdb_id:\n                self.deprecated = True\n                self.replacement_pdb_id = new_pdb_id\n            else:\n                assert(self.pdb_id == new_pdb_id)", "response": "Checks to see if the PDB file has been deprecated and what the new ID is."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_atoms(self):\n        '''All ATOM lines are parsed even though only one per residue needs to be parsed. The reason for parsing all the\n           lines is just to sanity-checks that the ATOMs within one residue are consistent with each other.'''\n\n        atom_site_header_tag = self.main_tag.getElementsByTagName(\"PDBx:atom_siteCategory\")\n        assert(len(atom_site_header_tag) == 1)\n        atom_site_header_tag = atom_site_header_tag[0]\n\n        atom_site_tags = atom_site_header_tag.getElementsByTagName(\"PDBx:atom_site\")\n\n        residue_map = {}\n        residues_read = {}\n        int_type = types.IntType\n        for t in atom_site_tags:\n            r, seqres, ResidueAA, Residue3AA = PDBML_slow.parse_atom_site(t, self.modified_residues)\n            if r:\n                # skip certain ACE residues\n                if not(self.pdb_id in cases_with_ACE_residues_we_can_ignore and Residue3AA == 'ACE'):\n                    full_residue_id = str(r)\n                    if residues_read.get(full_residue_id):\n                        assert(residues_read[full_residue_id] == (r.ResidueAA, seqres))\n                    else:\n                        residues_read[full_residue_id] = (r.ResidueAA, seqres)\n                        residue_map[r.Chain] = residue_map.get(r.Chain, {})\n                        assert(type(seqres) == int_type)\n                        residue_map[r.Chain][str(r)] = seqres\n\n        ## Create SequenceMap objects to map the ATOM Sequences to the SEQRES Sequences\n        atom_to_seqres_sequence_maps = {}\n        for chain_id, atom_seqres_mapping in residue_map.iteritems():\n            atom_to_seqres_sequence_maps[chain_id] = SequenceMap.from_dict(atom_seqres_mapping)\n\n        self.atom_to_seqres_sequence_maps = atom_to_seqres_sequence_maps", "response": "Parses all ATOM lines and creates a SequenceMap object for each ATOM residue."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a PDBML object by using a cached copy of the files if they exists or by retrieving the files from the RCSB.", "response": "def retrieve(pdb_id, cache_dir = None, bio_cache = None):\n        '''Creates a PDBML object by using a cached copy of the files if they exists or by retrieving the files from the RCSB.'''\n\n        pdb_contents = None\n        xml_contents = None\n        pdb_id = pdb_id.upper()\n\n        if bio_cache:\n            pdb_contents = bio_cache.get_pdb_contents(pdb_id)\n            xml_contents = bio_cache.get_pdbml_contents(pdb_id)\n\n        if cache_dir:\n            if not pdb_contents:\n                # Check to see whether we have a cached copy of the PDB file\n                filename = os.path.join(cache_dir, \"%s.pdb\" % pdb_id)\n                if os.path.exists(filename):\n                    pdb_contents = read_file(filename)\n\n            if not xml_contents:\n                # Check to see whether we have a cached copy of the XML file\n                filename = os.path.join(cache_dir, \"%s.xml\" % pdb_id)\n                if os.path.exists(filename):\n                    xml_contents = read_file(filename)\n\n        # Get any missing files from the RCSB and create cached copies if appropriate\n        if not pdb_contents:\n            pdb_contents = rcsb.retrieve_pdb(pdb_id)\n            if cache_dir:\n                write_file(os.path.join(cache_dir, \"%s.pdb\" % pdb_id), pdb_contents)\n\n        if not xml_contents:\n            xml_contents = rcsb.retrieve_xml(pdb_id)\n            if cache_dir:\n                write_file(os.path.join(cache_dir, \"%s.xml\" % pdb_id), xml_contents)\n\n        # Return the object\n        handler = PDBML(xml_contents, pdb_contents, bio_cache = bio_cache, pdb_id = pdb_id)\n        xml.sax.parseString(xml_contents, handler)\n        return handler"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks to see if the PDB file has been deprecated and what the new ID is.", "response": "def parse_deprecated_tags(self, name, attributes):\n        '''Checks to see if the PDB file has been deprecated and, if so, what the new ID is.'''\n        if name == 'PDBx:pdbx_database_PDB_obs_spr':\n            self.counters['PDBx:pdbx_database_PDB_obs_spr'] = self.counters.get('PDBx:pdbx_database_PDB_obs_spr', 0) + 1\n            old_pdb_id = attributes.get('replace_pdb_id').upper()\n            new_pdb_id = attributes.get('pdb_id').upper()\n            assert(old_pdb_id and new_pdb_id)\n\n            if self.pdb_id == old_pdb_id:\n                self.deprecated = True\n                self.replacement_pdb_id = new_pdb_id\n            else:\n                assert(self.pdb_id == new_pdb_id)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_atom_site(self, name, attributes):\n        '''Parse the atom tag attributes. Most atom tags do not have attributes.'''\n        if name == \"PDBx:pdbx_PDB_ins_code\":\n            assert(not(self.current_atom_site.ATOMResidueiCodeIsNull))\n            if attributes.get('xsi:nil') == 'true':\n                self.current_atom_site.ATOMResidueiCodeIsNull = True\n        if name == \"PDBx:auth_asym_id\":\n            assert(not(self.current_atom_site.PDBChainIDIsNull))\n            if attributes.get('xsi:nil') == 'true':\n                self.current_atom_site.PDBChainIDIsNull = True", "response": "Parse the atom tag attributes. Most atom tags do not have attributes."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses the atom tag data.", "response": "def parse_atom_tag_data(self, name, tag_content):\n        '''Parse the atom tag data.'''\n        current_atom_site = self.current_atom_site\n        if current_atom_site.IsHETATM:\n            # Early out - do not parse HETATM records\n            return\n\n        elif name == 'PDBx:atom_site':\n            # We have to handle the atom_site close tag here since we jump based on self._BLOCK first in end_element\n\n            #'''Add the residue to the residue map.'''\n            self._BLOCK = None\n            current_atom_site = self.current_atom_site\n            current_atom_site.validate()\n            if current_atom_site.IsATOM:\n                # Only parse ATOM records\n                r, seqres, ResidueAA, Residue3AA = current_atom_site.convert_to_residue(self.modified_residues)\n                if r:\n                    if not(self.pdb_id in cases_with_ACE_residues_we_can_ignore and Residue3AA == 'ACE'):\n                        # skip certain ACE residues\n                        full_residue_id = str(r)\n                        if self._residues_read.get(full_residue_id):\n                            assert(self._residues_read[full_residue_id] == (r.ResidueAA, seqres))\n                        else:\n                            self._residues_read[full_residue_id] = (r.ResidueAA, seqres)\n                            self._residue_map[r.Chain] = self._residue_map.get(r.Chain, {})\n                            assert(type(seqres) == int_type)\n                            self._residue_map[r.Chain][str(r)] = seqres\n\n        # Record type\n        elif name == 'PDBx:group_PDB':\n            # ATOM or HETATM\n            if tag_content == 'ATOM':\n                current_atom_site.IsATOM = True\n            elif tag_content == 'HETATM':\n                current_atom_site.IsHETATM = True\n            else:\n                raise Exception(\"PDBx:group_PDB was expected to be 'ATOM' or 'HETATM'. '%s' read instead.\" % tag_content)\n\n        # Residue identifier - chain ID, residue ID, insertion code\n        elif name == 'PDBx:auth_asym_id':\n            assert(not(current_atom_site.PDBChainID))\n            current_atom_site.PDBChainID = tag_content\n            if not tag_content:\n                assert(current_atom_site.PDBChainIDIsNull)\n                if self.pdb_id.upper() == '2MBP':\n                    current_atom_site.PDBChainID = 'A' # e.g. 2MBP\n                else:\n                    current_atom_site.PDBChainID = ' '\n\n        elif name == 'PDBx:auth_seq_id':\n            assert(not(current_atom_site.ATOMResidueID))\n            current_atom_site.ATOMResidueID = int(tag_content)\n        elif name == \"PDBx:pdbx_PDB_ins_code\":\n            if current_atom_site.ATOMResidueiCodeIsNull:\n                assert(len(tag_content) == 0)\n            else:\n                assert(current_atom_site.ATOMResidueiCode == ' ')\n                current_atom_site.ATOMResidueiCode = tag_content\n        elif name == \"PDBx:auth_comp_id\":\n            assert(not(current_atom_site.ATOMResidueAA))\n            current_atom_site.ATOMResidueAA = tag_content\n\n        elif name == \"PDBx:label_seq_id\":\n            assert(not(current_atom_site.SEQRESIndex))\n            current_atom_site.SEQRESIndex = int(tag_content)\n        elif name == \"PDBx:label_comp_id\":\n            assert(not(current_atom_site.ATOMSeqresResidueAA))\n            current_atom_site.ATOMSeqresResidueAA = tag_content"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_atom_data(self):\n        '''The atom site work is split into two parts. This function type-converts the tags.'''\n\n        current_atom_site = self.current_atom_site\n\n        # Only parse ATOM records\n        if current_atom_site.IsHETATM:\n            # Early out - do not parse HETATM records\n            return None, None, None, None\n        elif current_atom_site.IsATOM:\n            return current_atom_site.convert_to_residue(self.modified_residues)\n        else:\n            raise Exception('current_atom_site')", "response": "The atom site work is split into two parts. This function type - converts the tags."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_ranks(values):\n    '''\n    Converts raw values into ranks for rank correlation coefficients\n    :param values: list of values (int/float)\n    :return: a dict mapping value -> rank\n    '''\n    ranks = {}\n    sorted_values = sorted(values)\n    for i in range(len(sorted_values)):\n        value = sorted_values[i]\n        if value not in ranks:\n            ranks[value] = i + 1\n    return ranks", "response": "Converts raw values into ranks for rank correlation coefficients\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncalculate the Gamma correlation coefficient of a Goodman and Kruskal s current group.", "response": "def gamma(ranks_list1,ranks_list2):\n    '''\n    Goodman and Kruskal's gamma correlation coefficient\n    :param ranks_list1: a list of ranks (integers)\n    :param ranks_list2: a second list of ranks (integers) of equal length with corresponding entries\n    :return: Gamma correlation coefficient (rank correlation ignoring ties)\n    '''\n    num_concordant_pairs = 0\n    num_discordant_pairs = 0\n    num_tied_x = 0\n    num_tied_y = 0\n    num_tied_xy = 0\n    num_items = len(ranks_list1)\n    for i in range(num_items):\n        rank_1 = ranks_list1[i]\n        rank_2 = ranks_list2[i]\n        for j in range(i + 1, num_items):\n            diff1 = ranks_list1[j] - rank_1\n            diff2 = ranks_list2[j] - rank_2\n            if (diff1 > 0 and diff2 > 0) or (diff1 < 0 and diff2 < 0):\n                num_concordant_pairs += 1\n            elif (diff1 > 0 and diff2 < 0) or (diff1 < 0 and diff2 > 0):\n                num_discordant_pairs += 1\n            elif diff1 == 0 and diff2 == 0:\n                num_tied_xy += 1\n            elif diff1 == 0:\n                num_tied_x += 1\n            elif diff2 == 0:\n                num_tied_y += 1\n    try:\n        gamma_corr_coeff = float(num_concordant_pairs - num_discordant_pairs)/float(num_concordant_pairs + num_discordant_pairs)\n    except:\n        gamma_corr_coeff = 'n/a'\n    return [num_tied_x, num_tied_y, num_tied_xy, gamma_corr_coeff]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef import_source(module, path, pass_errors=False):\n    try:\n        m = imp.load_source(module, path)\n        return m\n    except Exception as e:\n        return None", "response": "Function imports a module given a full path"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfunctioning imports a module given a module name.", "response": "def import_module(module, pass_errors=False):\n    \"\"\"\n    Function imports a module given module name\n\n    Args\n    ----\n    module (string): the module name\n    pass_errors(boolean): the switch for function\n    to skip errors or not.\n\n    Returns\n    -------\n    module (module): the module object.\n\n    Raises\n    ------\n    exception (Exception): any kind of exceptions during importing.\n    import_error(ImportError): import errors during importing.\n\n    Note:\n    pass_errors switch will not pass any errors other than ImportError\n    \"\"\"\n    frm = module.split('.')\n    try:\n        m = __import__(module, fromlist=[frm[1]])\n        return m\n    except ImportError as e:\n        if pass_errors:\n            return None\n        else:\n            print(traceback.format_exc())\n            return None\n    except Exception as e:\n        print(traceback.format_exc())\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfunction recursively copies from source directory to destination directory.", "response": "def copytree(src, dst, symlinks=False, ignore=None):\n    \"\"\"\n    Function recursively copies from directory to directory.\n\n    Args\n    ----\n    src (string): the full path of source directory\n    dst (string): the full path of destination directory\n    symlinks (boolean): the switch for tracking symlinks\n    ignore (list): the ignore list\n    \"\"\"\n    if not os.path.exists(dst):\n        os.mkdir(dst)\n    try:\n        for item in os.listdir(src):\n            s = os.path.join(src, item)\n            d = os.path.join(dst, item)\n            if os.path.isdir(s):\n                shutil.copytree(s, d, symlinks, ignore)\n            else:\n                shutil.copy2(s, d)\n    except Exception as e:\n        raise FolderExistsError(\"Folder already exists in %s\" % dst)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfunction determines if the dict key exists and is empty", "response": "def empty(key, dict):\n    \"\"\"\n    Function determines if the dict key exists or it is empty\n\n    Args\n    ----\n    key (string): the dict key\n    dict (dict): the dict to be searched\n    \"\"\"\n    if key in dict.keys():\n        if dict[key]:\n            return False\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update(self, path, node):\n        '''Update the dict with a new color using a 'path' through the dict. You can either pass an existing path e.g.\n           'Scaffold.mutations' to override a color or part of the hierarchy or you can add a new leaf node or dict.'''\n        assert(type(path) == type(self.name))\n        assert(type(node) == type(self.name) or type(node) == type(predefined))\n\n        d = self.color_scheme\n        tokens = path.split('.')\n        for t in tokens[:-1]:\n            d = d.get(t)\n            if d == None:\n                raise Exception(\"Path '%s' not found.\")\n        d[tokens[-1]] = node", "response": "Update the dict with a new color using a path through the dict."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nlooking up a part of the color scheme. If used for looking up colors must_be_leaf should be True.", "response": "def lookup(self, path, must_be_leaf = False):\n        '''Looks up a part of the color scheme. If used for looking up colors, must_be_leaf should be True.'''\n        assert(type(path) == type(self.name))\n\n        d = self.color_scheme\n        tokens = path.split('.')\n        for t in tokens[:-1]:\n            d = d.get(t)\n            if d == None:\n                raise Exception(\"Path '%s' not found.\")\n        if must_be_leaf:\n            assert(type(d[tokens[-1]]) == type(self.name))\n        return d[tokens[-1]]"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nretrieves the real PID given a fetched PID.", "response": "def resolve_pid(fetched_pid):\n    \"\"\"Retrieve the real PID given a fetched PID.\n\n    :param pid: fetched PID to resolve.\n    \"\"\"\n    return PersistentIdentifier.get(\n        pid_type=fetched_pid.pid_type,\n        pid_value=fetched_pid.pid_value,\n        pid_provider=fetched_pid.provider.pid_provider\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\norders the query result on the relations s indexes.", "response": "def ordered(self, ord='desc'):\n        \"\"\"Order the query result on the relations' indexes.\"\"\"\n        if ord not in ('asc', 'desc', ):\n            raise\n        ord_f = getattr(PIDRelation.index, ord)()\n        return self.order_by(ord_f)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfilters the PIDs based on their status.", "response": "def status(self, status_in):\n        \"\"\"Filter the PIDs based on their status.\"\"\"\n        if isinstance(status_in, PIDStatus):\n            status_in = [status_in, ]\n        return self.filter(\n            self._filtered_pid_class.status.in_(status_in)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _resolved_pid(self):\n        if not isinstance(self.pid, PersistentIdentifier):\n            return resolve_pid(self.pid)\n        return self.pid", "response": "Resolve self. pid if it is a fetched pid."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_child_relation(self, child_pid):\n        return PIDRelation.query.filter_by(\n            parent=self._resolved_pid,\n            child=child_pid,\n            relation_type=self.relation_type.id).one()", "response": "Retrieve the relation between this node and a child PID."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _check_child_limits(self, child_pid):\n        if self.max_children is not None and \\\n                self.children.count() >= self.max_children:\n            raise PIDRelationConsistencyError(\n                \"Max number of children is set to {}.\".\n                format(self.max_children))\n        if self.max_parents is not None and \\\n                PIDRelation.query.filter_by(\n                    child=child_pid,\n                    relation_type=self.relation_type.id)\\\n                .count() >= self.max_parents:\n            raise PIDRelationConsistencyError(\n                \"This pid already has the maximum number of parents.\")", "response": "Check that inserting a child is within the limits."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _connected_pids(self, from_parent=True):\n        to_pid = aliased(PersistentIdentifier, name='to_pid')\n        if from_parent:\n            to_relation = PIDRelation.child_id\n            from_relation = PIDRelation.parent_id\n        else:\n            to_relation = PIDRelation.parent_id\n            from_relation = PIDRelation.child_id\n        query = PIDQuery(\n            [to_pid], db.session(), _filtered_pid_class=to_pid\n        ).join(\n            PIDRelation,\n            to_pid.id == to_relation\n        )\n        # accept both PersistentIdentifier models and fake PIDs with just\n        # pid_value, pid_type as they are fetched with the PID fetcher.\n        if isinstance(self.pid, PersistentIdentifier):\n            query = query.filter(from_relation == self.pid.id)\n        else:\n            from_pid = aliased(PersistentIdentifier, name='from_pid')\n            query = query.join(\n                from_pid,\n                from_pid.id == from_relation\n            ).filter(\n                from_pid.pid_value == self.pid.pid_value,\n                from_pid.pid_type == self.pid.pid_type,\n            )\n\n        return query", "response": "Follow a relationship to find connected PIDs. abs."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef insert_child(self, child_pid):\n        self._check_child_limits(child_pid)\n        try:\n            # TODO: Here add the check for the max parents and the max children\n            with db.session.begin_nested():\n                if not isinstance(child_pid, PersistentIdentifier):\n                    child_pid = resolve_pid(child_pid)\n                return PIDRelation.create(\n                    self._resolved_pid, child_pid, self.relation_type.id, None\n                )\n        except IntegrityError:\n            raise PIDRelationConsistencyError(\"PID Relation already exists.\")", "response": "Add the given PID to the list of children PIDs."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving a child from a PID concept.", "response": "def remove_child(self, child_pid):\n        \"\"\"Remove a child from a PID concept.\"\"\"\n        with db.session.begin_nested():\n            if not isinstance(child_pid, PersistentIdentifier):\n                child_pid = resolve_pid(child_pid)\n            relation = PIDRelation.query.filter_by(\n                parent=self._resolved_pid,\n                child=child_pid,\n                relation_type=self.relation_type.id).one()\n            db.session.delete(relation)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nindex of the child in the relation.", "response": "def index(self, child_pid):\n        \"\"\"Index of the child in the relation.\"\"\"\n        if not isinstance(child_pid, PersistentIdentifier):\n            child_pid = resolve_pid(child_pid)\n        relation = PIDRelation.query.filter_by(\n            parent=self._resolved_pid,\n            child=child_pid,\n            relation_type=self.relation_type.id).one()\n        return relation.index"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndetermine if pid is the latest version of a resource.", "response": "def is_last_child(self, child_pid):\n        \"\"\"\n        Determine if 'pid' is the latest version of a resource.\n\n        Resolves True for Versioned PIDs which are the oldest of its siblings.\n        False otherwise, also for Head PIDs.\n        \"\"\"\n        last_child = self.last_child\n        if last_child is None:\n            return False\n        return last_child == child_pid"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef last_child(self):\n        return self.children.filter(\n            PIDRelation.index.isnot(None)).ordered().first()", "response": "Return the last child of the head PID."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef next_child(self, child_pid):\n        relation = self._get_child_relation(child_pid)\n        if relation.index is not None:\n            return self.children.filter(\n                PIDRelation.index > relation.index\n            ).ordered(ord='asc').first()\n        else:\n            return None", "response": "Get the next child PID in the PID relation."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef insert_child(self, child_pid, index=-1):\n        self._check_child_limits(child_pid)\n        if index is None:\n            index = -1\n        try:\n            with db.session.begin_nested():\n                if not isinstance(child_pid, PersistentIdentifier):\n                    child_pid = resolve_pid(child_pid)\n                child_relations = self._resolved_pid.child_relations.filter(\n                    PIDRelation.relation_type == self.relation_type.id\n                ).order_by(PIDRelation.index).all()\n                relation_obj = PIDRelation.create(\n                    self._resolved_pid, child_pid, self.relation_type.id, None)\n                if index == -1:\n                    child_relations.append(relation_obj)\n                else:\n                    child_relations.insert(index, relation_obj)\n                for idx, c in enumerate(child_relations):\n                    c.index = idx\n        except IntegrityError:\n            raise PIDRelationConsistencyError(\"PID Relation already exists.\")", "response": "Insert a new child into a PID concept."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef remove_child(self, child_pid, reorder=False):\n        super(PIDNodeOrdered, self).remove_child(child_pid)\n        child_relations = self._resolved_pid.child_relations.filter(\n            PIDRelation.relation_type == self.relation_type.id).order_by(\n                PIDRelation.index).all()\n        if reorder:\n            for idx, c in enumerate(child_relations):\n                c.index = idx", "response": "Remove a child from a PID concept."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef safe_gz_unzip(contents):\n    ''' Takes a file's contents passed as a string (contents) and either gz-unzips the contents and returns the uncompressed data or else returns the original contents.\n        This function raises an exception if passed what appears to be gz-zipped data (from the magic number) but if gzip fails to decompress the contents.\n        A cleaner method would use zlib directly rather than writing a temporary file but zlib.decompress(contents, 16+zlib.MAX_WBITS) fix did not work for me immediately and I had things to get done!'''\n    if len(contents) > 1 and ord(contents[0]) == 31 and ord(contents[1]) == 139:\n        #contents = zlib.decompress(contents, 16+zlib.MAX_WBITS)\n        fname = write_temp_file('/tmp', contents)\n        try:\n            f = gzip.open(fname, 'rb')\n            contents = f.read()\n            f.close()\n        except:\n            os.remove(fname)\n            raise\n        return contents\n    else:\n        return contents", "response": "Takes a file s contents passed as a string and either gz - unzips the contents and returns the uncompressed data."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\naction function generator to create a link based on the context's current link, or on provided parameters :param origin: IRI/string, or list of same; origins for the created relationships. If None, the action context provides the parameter. :param rel: IRI/string, or list of same; IDs for the created relationships. If None, the action context provides the parameter. :param value: IRI/string, or list of same; values/targets for the created relationships. If None, the action context provides the parameter. :param source: pattern action to be executed, generating contexts to determine the output statements. If given, overrides specific origin, rel or value params :return: Versa action function to do the actual work", "response": "def link(origin=None, rel=None, value=None, attributes=None, source=None):\n    '''\n    Action function generator to create a link based on the context's current link, or on provided parameters\n\n    :param origin: IRI/string, or list of same; origins for the created relationships.\n    If None, the action context provides the parameter.\n\n    :param rel: IRI/string, or list of same; IDs for the created relationships.\n    If None, the action context provides the parameter.\n    \n    :param value: IRI/string, or list of same; values/targets for the created relationships.\n    If None, the action context provides the parameter.\n    \n    :param source: pattern action to be executed, generating contexts to determine the output statements. If given, overrides specific origin, rel or value params\n\n    :return: Versa action function to do the actual work\n    '''\n    attributes = attributes or {}\n    #rel = I(iri.absolutize(rel, ctx.base))\n    def _link(ctx):\n        if source:\n            if not callable(source):\n                raise ValueError('Link source must be a pattern action function')\n            contexts = source(ctx)\n            for ctx in contexts:\n                ctx.output_model.add(ctx.current_link[ORIGIN], ctx.current_link[RELATIONSHIP], ctx.current_link[TARGET], attributes)\n            return\n\n        (o, r, v, a) = ctx.current_link\n        _origin = origin(ctx) if callable(origin) else origin\n        o_list = [o] if _origin is None else (_origin if isinstance(_origin, list) else [_origin])\n        #_origin = _origin if isinstance(_origin, set) else set([_origin])\n        _rel = rel(ctx) if callable(rel) else rel\n        r_list = [r] if _rel is None else (_rel if isinstance(_rel, list) else [_rel])\n        #_rel = _rel if isinstance(_rel, set) else set([_rel])\n        _value = value(ctx) if callable(value) else value\n        v_list = [v] if _value is None else (_value if isinstance(_value, list) else [_value])\n        #_target = _target if isinstance(_target, set) else set([_target])\n        _attributes = attributes(ctx) if callable(attributes) else attributes\n\n        #(ctx_o, ctx_r, ctx_t, ctx_a) = ctx.current_link\n\n        #FIXME: Add test for IRI output via wrapper action function\n        for (o, r, v, a) in [ (o, r, v, a) for o in o_list for r in r_list for v in v_list ]:\n            ctx.output_model.add(o, r, v, attributes)\n\n        return\n    return _link"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning an attribute from the current link", "response": "def attr(aid):\n    '''\n    Action function generator to retrieve an attribute from the current link\n    '''\n    def _attr(ctx):\n        return ctx.current_link[ATTRIBUTES].get(aid)\n    return _attr"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef values(*rels):\n    '''\n    Action function generator to compute a set of relationships from criteria\n\n    :param rels: List of relationships to compute\n    :return: Versa action function to do the actual work\n    '''\n    #Action function generator to multiplex a relationship at processing time\n    def _values(ctx):\n        '''\n        Versa action function Utility to specify a list of relationships\n\n        :param ctx: Versa context used in processing (e.g. includes the prototype link\n        :return: Tuple of key/value tuples from the attributes; suitable for hashing\n        '''\n        computed_rels = [ rel(ctx) if callable(rel) else rel for rel in rels ]\n        return computed_rels\n    return _values", "response": "Returns a function that computes a set of key - value tuples from the attributes of the link holding the given list of relationships."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ifexists(test, value, alt=None):\n    '''\n    Action function generator providing an if/then/else type primitive\n    :param test: Expression to be tested to determine the branch path\n    :param value: Expression providing the result if test is true\n    :param alt: Expression providing the result if test is false\n    :return: Versa action function to do the actual work\n    '''\n    def _ifexists(ctx):\n        '''\n        Versa action function Utility to specify a list of relationships\n\n        :param ctx: Versa context used in processing (e.g. includes the prototype link)\n        :return: Value computed according to the test expression result\n        '''\n        _test = test(ctx) if callable(test) else test\n        if _test:\n            return value(ctx) if callable(value) else value\n        else:\n            return alt(ctx) if callable(alt) else alt\n    return _ifexists", "response": "This function returns a function that returns the value of the value of the value of the value of the value of the value of the value of the alt expression if test is True otherwise the alt expression of the value of the value of the value of the alt expression."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nactions function generator to compute a combination of links :return: Versa action function to do the actual work", "response": "def foreach(origin=None, rel=None, target=None, attributes=None):\n    '''\n    Action function generator to compute a combination of links\n\n    :return: Versa action function to do the actual work\n    '''\n    def _foreach(ctx):\n        '''\n        Versa action function utility to compute a list of values from a list of expressions\n\n        :param ctx: Versa context used in processing (e.g. includes the prototype link)\n        '''\n        _origin = origin(ctx) if callable(origin) else origin\n        _rel = rel(ctx) if callable(rel) else rel\n        _target = target(ctx) if callable(target) else target\n        _attributes = attributes(ctx) if callable(attributes) else attributes\n        (o, r, t, a) = ctx.current_link\n        o = [o] if _origin is None else (_origin if isinstance(_origin, list) else [_origin])\n        r = [r] if _rel is None else (_rel if isinstance(_rel, list) else [_rel])\n        t = [t] if _target is None else (_target if isinstance(_target, list) else [_target])\n        #a = [a] if _attributes is None else _attributes\n        a = [a] if _attributes is None else (_attributes if isinstance(_attributes, list) else [_attributes])\n        #print([(curr_o, curr_r, curr_t, curr_a) for (curr_o, curr_r, curr_t, curr_a)\n        #            in product(o, r, t, a)])\n        return [ ctx.copy(current_link=(curr_o, curr_r, curr_t, curr_a))\n                    for (curr_o, curr_r, curr_t, curr_a)\n                    in itertools.product(o, r, t, a) ]\n        #for (curr_o, curr_r, curr_t, curr_a) in product(origin or [o], rel or [r], target or [t], attributes or [a]):\n        #    newctx = ctx.copy(current_link=(curr_o, curr_r, curr_t, curr_a))\n            #ctx.output_model.add(I(objid), VTYPE_REL, I(iri.absolutize(_typ, ctx.base)), {})\n    return _foreach"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a new resource related to the origin :param typ: IRI of the type for the resource to be materialized, which becomes the target of the main link, and the origin of any additional links given in the links param :param rel: IRI of the relationship between the origin and the materialized target, or a list of relationship IRIs, each of which will be used to create a separate link, or a versa action function to derive this relationship or list of relationships at run time, or None. If none, use the action context. :param origin: Literal IRI or Versa action function for origin of the main generated link. If none, use the action context. :param unique: Versa action function to be invoked in order to derive a unique hash key input for the materialized resource, in the form of multiple key, value pairs (or key, list-of-values) :param links: Dictionary of links from the newly materialized resource. Each keys can be a relationship IRIs, a Versa action function returning a relationship IRI, a Versa action function returning a list of Versa contexts, which can be used to guide a sequence pattern of generated links, or a Versa action function returning None, which signals that the particular link is skipped entirely. :param postprocess: IRI or list of IRI queueing up actiona to be postprocessed for this materialized resource. None, the default, signals no special postprocessing For examples of all these scenarios see marcpatterns.py :return: Versa action function to do the actual work", "response": "def materialize(typ, rel=None, origin=None, unique=None, links=None, inverse=False, split=None, attributes=None):\n    '''\n    Create a new resource related to the origin\n\n    :param typ: IRI of the type for the resource to be materialized,\n    which becomes the target of the main link, and the origin of any\n    additional links given in the links param\n\n    :param rel: IRI of the relationship between the origin and the materialized\n    target, or a list of relationship IRIs, each of which will be used to create\n    a separate link, or a versa action function to derive this relationship or\n    list of relationships at run time, or None. If none, use the action context.\n\n    :param origin: Literal IRI or Versa action function for origin of the\n    main generated link. If none, use the action context.\n\n    :param unique: Versa action function to be invoked in order to\n    derive a unique hash key input for the materialized resource, in the form of\n    multiple key, value pairs (or key, list-of-values)\n\n    :param links: Dictionary of links from the newly materialized resource.\n    Each keys can be a relationship IRIs, a Versa action function returning\n    a relationship IRI, a Versa action function returning a list of Versa\n    contexts, which can be used to guide a sequence pattern of generated\n    links, or a Versa action function returning None, which signals that\n    the particular link is skipped entirely.\n\n    :param postprocess: IRI or list of IRI queueing up actiona to be postprocessed\n    for this materialized resource. None, the default, signals no special postprocessing\n\n    For examples of all these scenarios see marcpatterns.py\n\n    :return: Versa action function to do the actual work\n    '''\n    links = links or []\n    attributes = attributes or {}\n    def _materialize(ctx):\n        '''\n        Inserts at least two main links in the context's output_model, one or more for\n        the relationship from the origin to the materialized resource, one for the\n        type of the materialized resource, and links according to the links parameter\n\n        :param ctx: Runtime Versa context used in processing (e.g. includes the prototype link)\n        :return: None\n\n        This function is intricate in its use and shifting of Versa context, but the\n        intricacies are all designed to make the marcpatterns mini language more natural.\n        '''\n        #FIXME: Part of the datachef sorting out\n        if not ctx.idgen: ctx.idgen = idgen\n        _typ = typ(ctx) if callable(typ) else typ\n        _rel = rel(ctx) if callable(rel) else rel\n        _unique = unique(ctx) if callable(unique) else unique\n        (o, r, t, a) = ctx.current_link\n        #FIXME: On redesign implement split using function composition instead\n        targets = [ sub_t.strip() for sub_t in t.split(split) ] if split else [t]\n        #Conversions to make sure we end up with a list of relationships out of it all\n        if _rel is None:\n            _rel = [r]\n        rels = _rel if isinstance(_rel, list) else ([_rel] if _rel else [])\n        objids = []\n\n        #Botanical analogy\n        #The stem is the relationship from the original to the materialized resource \n        #The veins are any further relationships from materialized resource \n        for target in targets:\n            ctx_stem = ctx.copy(current_link=(o, r, target, a))\n            if origin:\n                #Have been given enough info to derive the origin from context. Ignore origin in current link\n                o = origin(ctx_stem)\n\n            computed_unique = [] if _unique else None\n            if _unique:\n                # strip None values from computed unique list, including pairs where v is None\n                for k, v in _unique:\n                    if None in (k, v): continue\n                    v = v if isinstance(v, list) else [v]\n                    for subitem in v:\n                        subval = subitem(ctx) if callable(subitem) else subitem\n                        if subval:\n                            subval = subval if isinstance(subval, list) else [subval]\n                            computed_unique.extend([(k, s) for s in subval])\n\n            objid = materialize_entity(ctx, _typ, unique=computed_unique)\n            objids.append(objid)\n            for curr_rel in rels:\n                #e.g. scenario if passed in rel=ifexists(...)\n                curr_rel = curr_rel(ctx) if callable(curr_rel) else curr_rel\n                #FIXME: Fix this properly, by slugifying & making sure slugify handles all numeric case (prepend '_')\n                curr_rel = '_' + curr_rel if curr_rel.isdigit() else curr_rel\n                if curr_rel:\n                    if inverse:\n                        ctx.output_model.add(I(objid), I(iri.absolutize(curr_rel, ctx.base)), I(o), {})\n                    else:\n                        ctx.output_model.add(I(o), I(iri.absolutize(curr_rel, ctx.base)), I(objid), {})\n            #print((objid, ctx_.existing_ids))\n            if objid not in ctx.existing_ids:\n                if _typ: ctx.output_model.add(I(objid), VTYPE_REL, I(iri.absolutize(_typ, ctx.base)), {})\n                #FIXME: Should we be using Python Nones to mark blanks, or should Versa define some sort of null resource?\n                #XXX: Note, links are only processed on new objects! This needs some thought\n                for k, v in links:\n                    new_current_link = (I(objid), k, ctx.current_link[TARGET], ctx.current_link[ATTRIBUTES])\n                    ctx_vein = ctx_stem.copy(current_link=new_current_link)\n                    k = k(ctx_vein) if callable(k) else k\n                    #If k is a list of contexts use it to dynamically execute functions\n                    if isinstance(k, list):\n                        if k and isinstance(k[0], context):\n                            for newctx in k:\n                                #The function in question will generate any needed links in the output model\n                                v(newctx)\n                            continue\n\n                    #import traceback; traceback.print_stack() #For looking up the call stack e.g. to debug nested materialize\n                    #Check that the links key is not None, which is a signal not to\n                    #generate the item. For example if the key is an ifexists and the\n                    #test expression result is False, it will come back as None,\n                    #and we don't want to run the v function\n                    if k:\n                        v = v(ctx_vein) if callable(v) else v\n\n                        #If k or v come from pipeline functions as None it signals to skip generating anything else for this link item\n                        if v is not None:\n                            v = v(ctx_vein) if callable(v) else v\n                            #FIXME: Fix properly, by slugifying & making sure slugify handles all-numeric case\n                            if k.isdigit(): k = '_' + k\n                            if isinstance(v, list):\n                                for valitems in v:\n                                    if valitems:\n                                        ctx.output_model.add(I(objid), I(iri.absolutize(k, ctx_vein.base)), valitems, {})\n                            else:\n                                ctx.output_model.add(I(objid), I(iri.absolutize(k, ctx_vein.base)), v, {})\n                ctx.existing_ids.add(objid)\n        return objids\n\n    return _materialize"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef res(arg):\n    '''\n    Convert the argument into an IRI ref\n    '''\n    def _res(ctx):\n        _arg = arg(ctx) if callable(arg) else arg\n        return I(arg)\n    return _res", "response": "Convert the argument into an IRI ref\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef compose(*funcs):\n    '''\n    Compose an ordered list of functions. Args of a,b,c,d evaluates as a(b(c(d(ctx))))\n    '''\n    def _compose(ctx):\n        # last func gets context, rest get result of previous func\n        _result = funcs[-1](ctx)\n        for f in reversed(funcs[:-1]):\n            _result = f(_result)\n\n        return _result\n    return _compose", "response": "Returns a function that returns the result of the last function in the list."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef static_singleton(*args, **kwargs):\n\n    def __static_singleton_wrapper(cls):\n        if cls not in __singleton_instances:\n            __singleton_instances[cls] = cls(*args, **kwargs)\n\n        return __singleton_instances[cls]\n\n    return __static_singleton_wrapper", "response": "A static singleton design pattern decorator that creates a new object of the same name and returns it."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a dict from any object with all attributes but not the ones starting with an underscore", "response": "def safe_dict(obj_or_func, **kwargs):\n    \"\"\"\n    Create a dict from any object with all attributes, but not the ones starting with an underscore _\n    Useful for objects or function that return an object that have no __dict__ attribute, like psutil functions.\n    \"\"\"\n    if callable(obj_or_func):\n        res = obj_or_func(**kwargs)\n    else:\n        res = obj_or_func\n    if hasattr(res, '__dict__'):\n        return res.__dict__\n\n    attributes = [i for i in dir(res) if not i.startswith('_')]\n    out = {}\n    for a in attributes:\n        val = getattr(res, a)\n        if val and not callable(val):\n            out[a] = val\n\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsorting a list of dictionaries based on the value of the sort_key", "response": "def sort_dictionary_list(dict_list, sort_key):\n    \"\"\"\n    sorts a list of dictionaries based on the value of the sort_key\n\n    dict_list - a list of dictionaries\n    sort_key - a string that  identifies the key to sort the dictionaries with.\n\n    Test sorting a list of dictionaries:\n        >>> sort_dictionary_list([{'b' : 1, 'value' : 2}, {'c' : 2, 'value' : 3}, {'a' : 3, 'value' : 1}], 'value')\n        [{'a': 3, 'value': 1}, {'b': 1, 'value': 2}, {'c': 2, 'value': 3}]\n    \"\"\"\n    if not dict_list or len(dict_list) == 0:\n        return dict_list\n    dict_list.sort(key=itemgetter(sort_key))\n    return dict_list"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the public information of the object.", "response": "def safe_info(self, dic=None):\n        \"\"\"\n        Returns public information of the object\n        \"\"\"\n        if dic is None and dic != {}:\n            dic = self.to_dict()\n        output = {}\n        for (key, value) in dic.items():\n            if key[0] != '_':\n                if isinstance(value, SerializableObject):\n                    output[key] = value.safe_info()\n                elif isinstance(value, dict):\n                    output[key] = self.safe_info(dic=value)\n                elif isinstance(value, list):\n                    output[key] = []\n                    for f in value:\n                        if isinstance(f, SerializableObject):\n                            output[key].append(f.safe_info())\n                        elif isinstance(f, dict):\n                            output[key].append(self.safe_info(dic=f))\n                        else:\n                            output[key].append(f)\n                else:\n                    output[key] = value\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nstart application - aware shell", "response": "def shell():\n    \"\"\" Start application-aware shell \"\"\"\n    app = bootstrap.get_app()\n    context = dict(app=app)\n\n    # and push app context\n    app_context = app.app_context()\n    app_context.push()\n\n    # got ipython?\n    ipython = importlib.util.find_spec(\"IPython\")\n\n    # run now\n    if ipython:\n        from IPython import embed\n        embed(user_ns=context)\n    else:\n        import code\n        code.interact(local=context)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nbuilds a response from the data.", "response": "def _build_response(data, renderer=None):\n    \"\"\"\n    Build a response using the renderer from the data\n    :return:\n    \"\"\"\n    if isinstance(data, Response) or isinstance(data, BaseResponse):\n        return data\n    if not renderer:\n        raise AttributeError(\" Renderer is required\")\n    if isinstance(data, dict) or data is None:\n        data = {} if data is None else data\n        for _ in __view_parsers:\n            data = _(data)\n        return renderer(data), 200\n    elif isinstance(data, tuple):\n        data, status, headers = _normalize_response_tuple(data)\n        for _ in __view_parsers:\n            data = _(data)\n        return renderer(data or {}), status, headers\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef json(func):\n    if inspect.isclass(func):\n        apply_function_to_members(func, json)\n        return func\n    else:\n        @functools.wraps(func)\n        def decorated_view(*args, **kwargs):\n            data = func(*args, **kwargs)\n            return _build_response(data, jsonify)\n        return decorated_view", "response": "Decorator to render as JSON\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwrapping JSONified output for JSONP requests.", "response": "def jsonp(func):\n    \"\"\"Wraps JSONified output for JSONP requests.\n    http://flask.pocoo.org/snippets/79/\n    \"\"\"\n\n    @functools.wraps(func)\n    def decorated_view(*args, **kwargs):\n        callback = request.args.get('callback', None)\n        if callback:\n            data = str(func(*args, **kwargs))\n            content = str(callback) + '(' + data + ')'\n            mimetype = 'application/javascript'\n            return current_app.response_class(content, mimetype=mimetype)\n        else:\n            return func(*args, **kwargs)\n    return decorated_view"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add(self, title, obj, **kwargs):\n        is_class = inspect.isclass(obj)\n        self._push(title=title,\n                   view=obj,\n                   class_name=obj.im_class.__name__ if not is_class else obj.__name__,\n                   is_class=is_class,\n                   **kwargs)", "response": "Add a title to the menu"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _push(self, title, view, class_name, is_class, **kwargs):\n\n        # Set the page title\n        set_view_attr(view, \"title\", title, cls_name=class_name)\n\n        module_name = view.__module__\n        method_name = view.__name__\n\n        _endpoint = build_endpoint_route_name(view, \"index\" if is_class else method_name, class_name)\n        endpoint = kwargs.pop(\"endpoint\", _endpoint)\n        kwargs.setdefault(\"endpoint_kwargs\", {})\n        order = kwargs.pop(\"order\", 0)\n\n        # Tags\n        _nav_tags = get_view_attr(view, \"nav_tags\", [\"default\"], cls_name=class_name)\n        tags = kwargs.pop(\"tags\", _nav_tags)\n        if not isinstance(tags, list):\n            _ = tags\n            tags = [_]\n        kwargs[\"tags\"] = tags\n\n        # visible: accepts a bool or list of callback to execute\n        visible = kwargs.pop(\"visible\", [True])\n        if not isinstance(visible, list):\n            visible = [visible]\n\n        if get_view_attr(view, \"nav_visible\", cls_name=class_name) is False:\n            visible = False\n\n        kwargs[\"view\"] = view\n        kwargs[\"visible\"] = visible\n        kwargs[\"active\"] = False\n        kwargs[\"key\"] = class_name\n\n        if is_class:  # class menu\n            kwargs[\"endpoint\"] = endpoint\n            kwargs[\"has_subnav\"] = True\n        else:\n            kwargs[\"has_subnav\"] = False\n            kwargs.update({\n                \"order\": order,\n                \"has_subnav\": False,\n                \"title\": title,\n                \"endpoint\": endpoint,\n            })\n\n        self._title_map[endpoint] = title\n\n        path = \"%s.%s\" % (module_name, method_name if is_class else class_name)\n        attach_to = kwargs.pop(\"attach_to\", [])\n        if not attach_to:\n            attach_to.append(path)\n\n        for path in attach_to:\n            if path not in self.MENU:\n                self.MENU[path] = {\n                    \"title\": None,\n                    \"endpoint\": None,\n                    \"endpoint_kwargs\": {},\n                    \"order\": None,\n                    \"subnav\": [],\n                    \"kwargs\": {}\n                }\n\n            if is_class:  # class menu\n                self.MENU[path][\"title\"] = title\n                self.MENU[path][\"order\"] = order\n                self.MENU[path][\"kwargs\"] = kwargs\n\n            else:  # sub menu\n                self.MENU[path][\"subnav\"].append(kwargs)", "response": "Pushes a new nav data item onto the stack."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef render(self):\n        menu_list = []\n        menu_index = 0\n        for _, menu in copy.deepcopy(self.MENU).items():\n            subnav = []\n\n            menu[\"kwargs\"][\"_id\"] = str(menu_index)\n            menu[\"kwargs\"][\"active\"] = False\n            if \"visible\" in menu[\"kwargs\"]:\n                menu[\"kwargs\"][\"visible\"] = self._test_visibility(menu[\"kwargs\"][\"visible\"])\n\n            for s in menu[\"subnav\"]:\n                if s[\"title\"]:\n                    s[\"title\"] = self._get_title(s[\"title\"])\n\n                if s[\"endpoint\"] == request.endpoint:\n                    s[\"active\"] = True\n                    menu[\"kwargs\"][\"active\"] = True\n                s[\"visible\"] = self._test_visibility(s[\"visible\"])\n                menu_index += 1\n                s[\"_id\"] = str(menu_index)\n                subnav.append(s)\n\n            _kwargs = menu[\"kwargs\"]\n\n            if menu[\"title\"]:\n                _kwargs.update({\n                    \"subnav\": self._sort(subnav),\n                    \"order\": menu[\"order\"],\n                    \"title\": self._get_title(menu[\"title\"])\n                })\n                menu_list.append(_kwargs)\n            else:\n                menu_list += subnav\n            menu_index += 1\n\n        return self._sort(menu_list)", "response": "Render the menu into a sorted by order multi dict"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding the number of QTLs found for a given marker.", "response": "def add_qtl_to_marker(marker, qtls):\n    \"\"\"Add the number of QTLs found for a given marker.\n\n    :arg marker, the marker we are looking for the QTL's.\n    :arg qtls, the list of all QTLs found.\n\n    \"\"\"\n    cnt = 0\n    for qtl in qtls:\n        if qtl[-1] == marker[0]:\n            cnt = cnt + 1\n\n    marker.append(str(cnt))\n    return marker"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef send_command(self, data, read_delay=None):\n        self._write(data)\n        if read_delay:\n            time.sleep(read_delay)\n        return self._read()", "response": "Send a command to the port and return the response form it"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef serialize_relations(pid):\n    data = {}\n    relations = PIDRelation.get_child_relations(pid).all()\n    for relation in relations:\n        rel_cfg = resolve_relation_type_config(relation.relation_type)\n        dump_relation(rel_cfg.api(relation.parent),\n                      rel_cfg, pid, data)\n    parent_relations = PIDRelation.get_parent_relations(pid).all()\n    rel_cfgs = set([resolve_relation_type_config(p) for p in parent_relations])\n    for rel_cfg in rel_cfgs:\n        dump_relation(rel_cfg.api(pid), rel_cfg, pid, data)\n    return data", "response": "Serialize the relations for given PID."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dump_relation(api, rel_cfg, pid, data):\n    schema_class = rel_cfg.schema\n    if schema_class is not None:\n        schema = schema_class()\n        schema.context['pid'] = pid\n        result, errors = schema.dump(api)\n        data.setdefault(rel_cfg.name, []).append(result)", "response": "Dump a specific relation to a data dict."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nround a datetime object to any time period in seconds.", "response": "def roundTime(dt=None, roundTo=1):\n    \"\"\"Round a datetime object to any time period (in seconds)\n    dt : datetime.datetime object, default now.\n    roundTo : Closest number of seconds to round to, default 1 second.\n    Author: Thierry Husson 2012 - Use it as you want but don't blame me.\n    http://stackoverflow.com/questions/3463930/how-to-round-the-minute-of-a-datetime-object-python/10854034#10854034\n    \"\"\"\n    if dt == None : dt = datetime.now()\n    seconds = total_seconds(dt - dt.min)\n    # // is a floor division, not a comment on following line:\n    rounding = (seconds+roundTo/2) // roundTo * roundTo\n    return dt + timedelta(0,rounding-seconds,-dt.microsecond)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_item(self, url, title=None, selection=None,\n                 jsonp=None, redirect=None, response_info=False):\n        \"\"\" Method to add a new item to a instapaper account\n\n            Parameters: url -> URL to add\n                        title -> optional title for the URL\n            Returns: (status as int, status error message)\n        \"\"\"\n        parameters = {\n                      'username' : self.user,\n                      'password' : self.password,\n                      'url' : url,\n                     }\n        # look for optional parameters title and selection\n        if title is not None:\n            parameters['title'] = title\n        else:\n            parameters['auto-title'] = 1\n        if selection is not None:\n            parameters['selection'] = selection\n        if redirect is not None:\n            parameters['redirect'] = redirect\n        if jsonp is not None:\n            parameters['jsonp'] = jsonp\n\n        # make query with the chosen parameters\n        status, headers = self._query(self.addurl, parameters)\n        # return the callback call if we want jsonp\n        if jsonp is not None:\n            return status\n        statustxt = self.add_status_codes[int(status)]\n        # if response headers are desired, return them also\n        if response_info:\n            return (int(status), statustxt, headers['title'], headers['location'])\n        else:\n            return (int(status), statustxt)", "response": "Method to add a new item to an instapaper account"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef auth(self, user=None, password=None, jsonp=None):\n        if not user:\n            user = self.user\n        if not password:\n            password = self.password\n        parameters = {\n                      'username' : self.user,\n                      'password' : self.password\n                     }\n        if jsonp is not None:\n            parameters['jsonp'] = jsonp\n        status, headers = self._query(self.authurl, parameters)\n        # return the callback call if we want jsonp\n        if jsonp is not None:\n            return status\n        return (int(status), self.auth_status_codes[int(status)])", "response": "authenticate with the instapaper. com service"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cors(*args, **kwargs):\n    def decorator(fn):\n        cors_fn = flask_cors.cross_origin(automatic_options=False, *args, **kwargs)\n        if inspect.isclass(fn):\n            apply_function_to_members(fn, cors_fn)\n        else:\n            return cors_fn(fn)\n        return fn\n    return decorator", "response": "A decorator around flask - cors cross_origin to act on classes\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef headers(params={}):\n    def decorator(f):\n\n        if inspect.isclass(f):\n            h = headers(params)\n            apply_function_to_members(f, h)\n            return f\n\n        @functools.wraps(f)\n        def decorated_function(*args, **kwargs):\n            resp = make_response(f(*args, **kwargs))\n            h = resp.headers\n            for header, value in params.items():\n                h[header] = value\n            return resp\n        return decorated_function\n    return decorator", "response": "This decorator adds the headers passed in to the response\n            http://www. pocoo. org / snippets / 100."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a sequence to the list of records.", "response": "def add_sequence(self, sequence_id, sequence, ignore_bad_chains = False):\n        '''If ignore_bad_chains is True then any chains containing all Xs as the sequence will be silently skipped.\n           The default behavior is to raise a MalformedSequenceException in this case.'''\n\n        # This is a sanity check. ClustalO allows ':' in the chain ID but ClustalW replaces ':' with '_' which breaks our parsing\n        # All callers to add_sequence now need to replace ':' with '_' so that we can use ClustalW\n        assert(sequence_id.find(':') == -1)\n\n        if sequence_id in self.sequence_ids.values():\n            raise Exception(\"Sequence IDs must be unique\")\n        if list(set(sequence)) == ['X']:\n            if ignore_bad_chains:\n                return\n            else:\n                raise MalformedSequenceException('The sequence contains only X characters. This will crash Clustal Omega.')\n        self.records.append(\">%s\\n%s\" % (sequence_id, \"\\n\".join([sequence[i:i+80] for i in range(0, len(sequence), 80)])))\n        self.sequence_ids[len(self.sequence_ids) + 1] = sequence_id"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a mapping between the sequences ONLY IF there are exactly two. This restriction makes the code much simpler.", "response": "def get_residue_mapping(self):\n        '''Returns a mapping between the sequences ONLY IF there are exactly two. This restriction makes the code much simpler.'''\n        if len(self.sequence_ids) == 2:\n            if not self.alignment_output:\n                self.align()\n            assert(self.alignment_output)\n            return self._create_residue_map(self._get_alignment_lines(), self.sequence_ids[1], self.sequence_ids[2])\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_alignment_lines(self):\n        ''' This function parses the Clustal Omega alignment output and returns the aligned sequences in a dict: sequence_id -> sequence_string.\n            The special key -1 is reserved for the match line (e.g. ' .:******* *').'''\n\n        # Strip the boilerplate lines\n        lines = self.alignment_output.split(\"\\n\")\n        assert(lines[0].startswith('CLUSTAL'))\n        lines = '\\n'.join(lines[1:]).lstrip().split('\\n')\n\n        # The sequence IDs should be unique. Reassert this here\n        assert(len(self.sequence_ids.values()) == len(set(self.sequence_ids.values())))\n\n        # Create the list of sequence IDs\n        id_list = [v for k, v in sorted(self.sequence_ids.iteritems())]\n\n        # Determine the indentation level\n        first_id = id_list[0]\n        header_regex = re.compile(\"(.*?\\s+)(.*)\")\n        alignment_regex = re.compile(\"^([A-Z\\-]+)\\s*$\")\n        mtchs = header_regex.match(lines[0])\n        assert(mtchs.group(1).strip() == first_id)\n        indentation = len(mtchs.group(1))\n        sequence = mtchs.group(2)\n        assert(sequence)\n        assert(alignment_regex.match(sequence))\n\n        # Create empty lists for the sequences\n        sequences = {}\n        for id in id_list:\n            sequences[id] = []\n        sequences[-1] = []\n\n        # Get the lists of sequences\n        num_ids = len(id_list)\n        for x in range(0, len(lines), num_ids + 2):\n            for y in range(num_ids):\n                id = id_list[y]\n                assert(lines[x + y][:indentation].strip() == id)\n                assert(lines[x + y][indentation - 1] == ' ')\n                sequence = lines[x + y][indentation:].strip()\n                assert(alignment_regex.match(sequence))\n                sequences[id].append(sequence)\n\n            # Get the length of the sequence lines\n            length_of_sequences = list(set(map(len, [v[-1] for k, v in sequences.iteritems() if k != -1])))\n            assert(len(length_of_sequences) == 1)\n            length_of_sequences = length_of_sequences[0]\n\n            # Parse the Clustal match line\n            assert(lines[x + num_ids][:indentation].strip() == '')\n            match_sequence = lines[x + num_ids][indentation:indentation + length_of_sequences]\n            assert(match_sequence.strip() == lines[x + num_ids].strip())\n            assert(lines[x + y][indentation - 1] == ' ')\n            sequences[-1].append(match_sequence)\n\n            # Check for the empty line\n            assert(lines[x + num_ids + 1].strip() == '')\n\n        # Create the sequences, making sure that all sequences are the same length\n        lengths = set()\n        for k, v in sequences.iteritems():\n            sequences[k] = \"\".join(v)\n            lengths.add(len(sequences[k]))\n        assert(len(lengths) == 1)\n\n        return sequences", "response": "This function parses the alignment output and returns the aligned sequences in a dict. The keys are the sequence IDs and the values are the sequence strings. The values are the sequences in the dictionary. The keys are the sequence IDs and the values are the sequences in the dictionary. The values are the sequences in the dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nalters the cut-off and run alignment again. This is much quicker than creating a new PDBUniParcSequenceAligner object as the UniParcEntry creation etc. in the constructor does not need to be repeated. The chains_to_skip argument (a Set) allows us to skip chains that were already matched which speeds up the alignment even more.", "response": "def realign(self, cut_off, chains_to_skip = set()):\n        ''' Alter the cut-off and run alignment again. This is much quicker than creating a new PDBUniParcSequenceAligner\n            object as the UniParcEntry creation etc. in the constructor does not need to be repeated.\n\n            The chains_to_skip argument (a Set) allows us to skip chains that were already matched which speeds up the alignment even more.\n        '''\n        if cut_off != self.cut_off:\n            self.cut_off = cut_off\n\n            # Wipe any existing information for chains not in chains_to_skip\n            for c in self.chains:\n                if c not in chains_to_skip:\n                    self.clustal_matches[c] = None\n                    self.substring_matches[c] = None\n                    if self.alignment.get(c):\n                        del self.alignment[c]\n                    if self.seqres_to_uniparc_sequence_maps.get(c):\n                        del self.seqres_to_uniparc_sequence_maps[c]\n\n            # Run alignment for the remaining chains\n            self._align_with_clustal(chains_to_skip = chains_to_skip)\n            self._align_with_substrings(chains_to_skip = chains_to_skip)\n            self._check_alignments(chains_to_skip = chains_to_skip)\n            self._get_residue_mapping(chains_to_skip = chains_to_skip)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _determine_representative_chains(self):\n        ''' Quotient the chains to get equivalence classes of chains. These will be used for the actual mapping.'''\n        # todo: This logic should be moved into the FASTA class or a more general module (maybe a fast exists which uses a C/C++ library?) but at present it is easier to write here since we do not need to worry about other PDB IDs.\n\n        equivalence_fiber = {}\n        matched_chains = set()\n        for chain_id, equivalent_chains in self.identical_sequences.iteritems():\n            matched_chains.add(chain_id)\n            equivalent_chain_ids = set()\n            for equivalent_chain in equivalent_chains:\n                assert(len(equivalent_chain) == 6)\n                assert((equivalent_chain[:5] == '%s_' % self.pdb_id) or (equivalent_chain[:5] == '%s:' % self.pdb_id)) # ClustalW changes e.g. 1KI1:A to 1KI1_A in its output\n                equivalent_chain_ids.add(equivalent_chain[5])\n            found = False\n            for equivalent_chain_id in equivalent_chain_ids:\n                if equivalence_fiber.get(equivalent_chain_id):\n                    found = True\n                    assert(equivalence_fiber[equivalent_chain_id] == equivalent_chain_ids.union(set([chain_id])))\n                    break\n            if not found:\n                equivalence_fiber[chain_id] = set(equivalent_chain_ids)\n                equivalence_fiber[chain_id].add(chain_id)\n\n        for c in self.chains:\n            if c not in matched_chains:\n                equivalence_fiber[c] = set([c])\n\n        self.equivalence_fiber = equivalence_fiber\n        self.representative_chains = equivalence_fiber.keys()", "response": "Quotient the chains to get equivalence classes of chains. These will be used for the actual mapping."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_uniparc_sequences_through_uniprot_ACs(self, mapping_pdb_id, uniprot_ACs, cache_dir):\n        '''Get the UniParc sequences associated with the UniProt accession number.'''\n\n        # Map the UniProt ACs to the UniParc IDs\n        m = uniprot_map('ACC', 'UPARC', uniprot_ACs, cache_dir = cache_dir)\n        UniParcIDs = []\n        for _, v in m.iteritems():\n            UniParcIDs.extend(v)\n\n        # Create a mapping from the mapping_pdb_id to the UniParcEntry objects. This must match the return type from pdb_to_uniparc.\n        mapping = {mapping_pdb_id : []}\n        for UniParcID in UniParcIDs:\n            entry = UniParcEntry(UniParcID, cache_dir = cache_dir)\n            mapping[mapping_pdb_id].append(entry)\n\n        return mapping", "response": "Get the UniParc sequences associated with the UniProt accession number."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _align_with_substrings(self, chains_to_skip = set()):\n        '''Simple substring-based matching'''\n        for c in self.representative_chains:\n            # Skip specified chains\n            if c not in chains_to_skip:\n                #colortext.pcyan(c)\n                #colortext.warning(self.fasta[c])\n                fasta_sequence = self.fasta[c]\n\n                substring_matches = {}\n\n                for uniparc_id, uniparc_sequence in sorted(self.uniparc_sequences.iteritems()):\n                    uniparc_sequence = str(uniparc_sequence)\n                    idx = uniparc_sequence.find(fasta_sequence)\n                    if idx != -1:\n                        substring_matches[uniparc_id] = 0\n                    elif len(fasta_sequence) > 30:\n                        idx = uniparc_sequence.find(fasta_sequence[5:-5])\n                        if idx != -1:\n                            substring_matches[uniparc_id] = 5\n                        else:\n                            idx = uniparc_sequence.find(fasta_sequence[7:-7])\n                            if idx != -1:\n                                substring_matches[uniparc_id] = 7\n                    elif len(fasta_sequence) > 15:\n                        idx = uniparc_sequence.find(fasta_sequence[3:-3])\n                        if idx != -1:\n                            substring_matches[uniparc_id] = 3\n\n                self.substring_matches[c] = substring_matches\n\n        # Restrict the matches to a given set of UniParc IDs. This can be used to remove ambiguity when the correct mapping has been determined e.g. from the SIFTS database.\n        colortext.pcyan('*' * 100)\n        pprint.pprint(self.substring_matches)\n        if self.restrict_to_uniparc_values:\n            for c in self.representative_chains:\n                #print('HERE!')\n                #print(c)\n                if set(map(str, self.substring_matches[c].keys())).intersection(set(self.restrict_to_uniparc_values)) > 0:\n                    # Only restrict in cases where there is at least one match in self.restrict_to_uniparc_values\n                    # Otherwise, chains which are not considered in self.restrict_to_uniparc_values may throw away valid matches\n                    # e.g. when looking for structures related to 1KTZ (A -> P10600 -> UPI000000D8EC, B -> P37173 -> UPI000011DD7E),\n                    #      we find the close match 2PJY. However, 2PJY has 3 chains: A -> P10600, B -> P37173, and C -> P36897 -> UPI000011D62A\n                    restricted_matches = dict((str(k), self.substring_matches[c][k]) for k in self.substring_matches[c].keys() if str(k) in self.restrict_to_uniparc_values)\n                    if len(restricted_matches) != len(self.substring_matches[c]):\n                        removed_matches = sorted(set(self.substring_matches[c].keys()).difference(set(restricted_matches)))\n                        # todo: see above re:quiet colortext.pcyan('Ignoring {0} as those chains were not included in the list self.restrict_to_uniparc_values ({1}).'.format(', '.join(removed_matches), ', '.join(self.restrict_to_uniparc_values)))\n                    self.substring_matches[c] = restricted_matches\n        #pprint.pprint(self.substring_matches)\n        #colortext.pcyan('*' * 100)\n\n        # Use the representatives' alignments for their respective equivalent classes\n        for c_1, related_chains in self.equivalence_fiber.iteritems():\n            for c_2 in related_chains:\n                self.substring_matches[c_2] = self.substring_matches[c_1]", "response": "Aligns the sequences in the representative chains with the substrings of the sequences in the representative chains."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a mapping between the residues of the chains and the associated UniParc entries.", "response": "def _get_residue_mapping(self, chains_to_skip = set()):\n        '''Creates a mapping between the residues of the chains and the associated UniParc entries.'''\n        for c in self.representative_chains:\n            # Skip specified chains\n            if c not in chains_to_skip:\n                if self.alignment.get(c):\n                    uniparc_entry = self.get_uniparc_object(c)\n                    sa = SequenceAligner()\n                    sa.add_sequence(c, self.fasta[c])\n                    sa.add_sequence(uniparc_entry.UniParcID, uniparc_entry.sequence)\n                    sa.align()\n                    residue_mapping, residue_match_mapping = sa.get_residue_mapping()\n\n                    # Create a SequenceMap\n                    s = PDBUniParcSequenceMap()\n                    assert(sorted(residue_mapping.keys()) == sorted(residue_match_mapping.keys()))\n                    for k, v in residue_mapping.iteritems():\n                        s.add(k, (uniparc_entry.UniParcID, v), residue_match_mapping[k])\n                    self.seqres_to_uniparc_sequence_maps[c] = s\n\n                else:\n                    self.seqres_to_uniparc_sequence_maps[c] = PDBUniParcSequenceMap()\n\n        # Use the representatives' alignments for their respective equivalent classes. This saves memory as the same SequenceMap is used.\n        for c_1, related_chains in self.equivalence_fiber.iteritems():\n            for c_2 in related_chains:\n                if self.seqres_to_uniparc_sequence_maps.get(c_1):\n                    self.seqres_to_uniparc_sequence_maps[c_2] = self.seqres_to_uniparc_sequence_maps[c_1]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef align(self, alignment_tool = 'clustalw', gap_opening_penalty = 0.2, ignore_bad_chains = False):\n        '''If ignore_bad_chains is True then any chains containing all Xs as the sequence will be silently skipped.\n           The default behavior is to raise a MalformedSequenceException in this case.'''\n        if len(self.pdb_chains) > 1:\n            sa = SequenceAligner(alignment_tool = alignment_tool, gap_opening_penalty = gap_opening_penalty)\n            for pdb_chain in self.pdb_chains:\n                sa.add_sequence('%s_%s' % (pdb_chain['pdb_id'], pdb_chain['chain_id']), pdb_chain['sequence'], ignore_bad_chains = ignore_bad_chains)\n            best_matches = sa.align()\n            return sa.alignment_output, best_matches\n        else:\n            raise Exception('Cannot align sequences - less than two chains were specified.')", "response": "Align the sequences in the PDB file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a mapping between chains of pdb_id_1 and pdb_id_2 and the set of mutations needed to transform each chain of pdb_id_1 into the respective chains of pdb_id_2.", "response": "def get_mutations(self, pdb_id_1, pdb_id_2, alignment_tool = 'clustalw', gap_opening_penalty = 0.2):\n        '''Returns a mapping chain_of_pdb_1 -> List[PDBMutationPair] representing the mutations needed to transform each chain of pdb_1 into the respective chains of pdb_2.\n           This function also sets self.seqres_sequence_maps, a mapping Tuple(pdb_id_1, chain ID in pdb_id_1) -> Tuple(pdb_id_2, chain ID in pdb_id_2) -> a SequenceMap representing the mapping of residues between the chains based on the alignment.\n\n           Warning: This function does not consider what happens if a chain in pdb_id_1 matches two chains in pdb_id_2\n                    which have differing sequences. In this case, an self-inconsistent set of mutations is returned.\n                    One solution would be to extend the mapping to:\n\n                        chain_m_of_pdb_1 -> common_mutations -> List[PDBMutationPair]\n                                         -> chain_x_of_pdb_2 -> List[PDBMutationPair]\n                                         -> chain_y_of_pdb_2 -> List[PDBMutationPair]\n                                         ...\n\n                    where common_mutations contains the set of mutations common to the mapping m->x and m->y etc. whereas the\n                    other two mappings contain the set of mutations from m->x or m->y etc. respectively which do not occur in\n                    common_mutations. In general, both chain_x_of_pdb_2 and chain_y_of_pdb_2 will be empty excepting the\n                    considered case where x and y differ in sequence.\n        '''\n\n        # Set up the objects\n        p1 = self.add_pdb(pdb_id_1)\n        p2 = self.add_pdb(pdb_id_2)\n        self.chain_map[pdb_id_1] = self.chain_map.get(pdb_id_1, {})\n\n        # Determine which chains map to which\n        alignment = self.get_alignment(pdb_id_1, pdb_id_2, alignment_tool = alignment_tool, gap_opening_penalty = gap_opening_penalty)\n        best_matches = alignment['best_matches']\n\n        # Create the list of mutations\n        mutations = {}\n        for from_chain, mtches in sorted(best_matches.iteritems()):\n\n            from_pdb_id, from_chain_id = from_chain.split('_')\n\n            # Only consider matches from pdb_id_1 to pdb_id_2\n            if from_pdb_id == pdb_id_1:\n\n                self.seqres_sequence_maps[(from_pdb_id, from_chain_id)] = {}\n\n                self.chain_map[from_pdb_id][from_chain_id] = self.chain_map[from_pdb_id].get(from_chain_id, {})\n\n                # Do not consider matches from pdb_id_1 to itself or matches with poor sequence similarity\n                restricted_mtchs = {}\n                for to_chain, similarity in sorted(mtches.iteritems()):\n                    if to_chain.split('_')[0] == pdb_id_2 and similarity >= self.acceptable_sequence_similarity:\n                        restricted_mtchs[to_chain] = similarity\n\n                # Take the best matching chains and create a list of mutations needed to transform from_chain to those chains\n                # Warning: This does NOT take into account whether the sequences of the best matches differ.\n                if restricted_mtchs:\n                    top_similarity = max(restricted_mtchs.values())\n\n                    #todo: if the sequences of the best matches differ, raise an Exception. Use 2ZNW and 1DQJ as an example (2ZNW chain A matches with 48% to both 1DQJ chain A and chain B)\n                    #top_matches = [to_chain for to_chain, similarity in sorted(restricted_mtchs.iteritems()) if similarity == top_similarity]\n                    #pprint.pprint(restricted_mtchs)\n                    #print(from_pdb_id, from_chain, 'top_matches', top_matches)\n                    #sys.exit(0)\n\n\n                    for to_chain, similarity in sorted(restricted_mtchs.iteritems()):\n                        to_pdb_id, to_chain_id = to_chain.split('_')\n                        if similarity == top_similarity:\n                            #print(from_pdb_id, from_chain_id)\n                            #print(restricted_mtchs)\n                            #print(to_pdb_id, to_chain, similarity)\n                            self.chain_map[from_pdb_id][from_chain_id][to_pdb_id] = self.chain_map[from_pdb_id][from_chain_id].get(to_pdb_id, set())\n                            self.chain_map[from_pdb_id][from_chain_id][to_pdb_id].add(to_chain)\n                            mutations[from_chain_id] = mutations.get(from_chain_id, [])\n                            chain_mutations = self.get_chain_mutations(from_pdb_id, from_chain_id, to_pdb_id, to_chain_id)\n                            mutations[from_chain_id].extend(chain_mutations)\n\n        # mutations can contain duplicates so we remove those\n        for chain_id, mlist in mutations.iteritems():\n            mutations[chain_id] = sorted(set(mlist))\n        return mutations"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_valid_fragment(original_residue_id, mapping, frag_sizes):\n    '''A function which determines whether a residue ID (original_residue_id) should be included in the nmer files generated by the mapping.'''\n    for r in mapping['segment_list']:\n        r = sorted(r)\n        if r[0] - frag_sizes + 1 <= original_residue_id <= r[1] + frag_sizes - 1:\n            return True\n    return False", "response": "A function which determines whether a residue ID should be included in the nmer files generated by the mapping."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_dict(self):\n        '''A representation of that publication data that matches the schema we use in our databases.'''\n\n        author_list = []\n        for author in self.authors:\n            author_list.append(\n                dict(\n                    AuthorOrder = author['AuthorOrder'] + 1, # we should always use 1-based indexing but since this is shared code, I do not want to change the logic above without checking to make sure I don't break dependencies\n                    FirstName = author['FirstName'],\n                    MiddleNames = ' '.join(author['MiddleNames']), # this is the main difference with the code above - the database expects a string, we maintain a list\n                    Surname = author['Surname']\n                )\n            )\n\n        pub_url = None\n        if self.url or self.doi:\n            pub_url = self.url or ('http://dx.doi.org/%s' % self.doi)\n\n        return dict(\n            Title = self.title,\n            PublicationName = self.journal,\n            Volume = self.volume,\n            Issue = self.issue,\n            StartPage = self.startpage,\n            EndPage = self.endpage,\n            PublicationYear = self.year,\n            PublicationDate = self.date,\n            RIS = self.RIS,\n            DOI = self.doi,\n            PubMedID = None,\n            URL = pub_url,\n            ISSN = None, # eight-digit number\n            authors = author_list,\n            #\n            RecordType = RISEntry.record_types.get(self.publication_type)\n        )", "response": "A representation of that publication data that matches the schema we use in our databases."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_pdb_contents_to_pose_residue_map(pdb_file_contents, rosetta_scripts_path, rosetta_database_path = None, pdb_id = None, extra_flags = ''):\n    '''Takes a string containing a PDB file, the RosettaScripts executable, and the Rosetta database and then uses the features database to map PDB residue IDs to pose residue IDs.\n       On success, (True, the residue mapping) is returned. On failure, (False, a list of errors) is returned.\n\n       Note: extra_flags should typically include '-ignore_zero_occupancy false' and '-ignore_unrecognized_res'.'''\n\n    filename = write_temp_file(\"/tmp\", pdb_file_contents)\n    success, mapping = get_pdb_to_pose_residue_map(filename, rosetta_scripts_path, rosetta_database_path = rosetta_database_path, pdb_id = pdb_id, extra_flags = extra_flags)\n    os.remove(filename)\n    return success, mapping", "response": "Takes a string containing a PDB file the RosettaScripts executable and the Rosetta database and uses the features database to map PDB residue IDs to Pose residue IDs."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntake a path to a PDB file the RosettaScripts executable and the Rosetta database and uses the features database to map residue IDs to Pose IDs.", "response": "def get_pdb_to_pose_residue_map(pdb_path, rosetta_scripts_path, rosetta_database_path = None, pdb_id = None, extra_flags = ''):\n    '''Takes a path to a PDB file, the RosettaScripts executable, and the Rosetta database and then uses the features database to map PDB residue IDs to pose residue IDs.\n       On success, (True, the residue mapping) is returned. On failure, (False, a list of errors) is returned.\n\n       The mapping maps residue IDs to a dict with the three letter residue code and the Rosetta pose id e.g.\n\n           mapping = {\n              u'B 435 ': {'name3': u'GLN', 'pose_residue_id': 370, 'res_type': u'GLN'},\n              ...\n           }\n\n       Note: extra_flags should typically include '-ignore_zero_occupancy false' and '-ignore_unrecognized_res'.'''\n\n    errors = []\n    exit_code = 0\n    F, script_path = tempfile.mkstemp(dir=\".\")\n    script_handle = os.fdopen(F, \"w\")\n\n    try:\n        db_path = script_path + \".db3\"\n        script_handle.write(script % db_path)\n        script_handle.close()\n        if rosetta_database_path:\n            command_line = '%s -database %s -constant_seed -in:file:s %s -parser:protocol %s -overwrite -out:nooutput %s' % (rosetta_scripts_path, rosetta_database_path, pdb_path, script_path, extra_flags)\n        else:\n            command_line = '%s -constant_seed -in:file:s %s -parser:protocol %s -overwrite -out:nooutput %s' % (rosetta_scripts_path, pdb_path, script_path, extra_flags)\n\n        exit_code, stdout = commands.getstatusoutput(command_line)\n        if exit_code != 0:\n            errors.append(\"An error occured during execution. The exit code was %d. The output was:\\n\\n%s\" % (exit_code, stdout))\n        else:\n            try:\n                mapping = get_mapping_from_db3_file( db_path )\n            except Exception, e:\n                errors.append(str(e))\n                errors.append(traceback.format_exc())\n                errors.append(\"The features database does not seem to have been correctly created. Check to see if the command '%s' is correct.\" % command_line)\n    except Exception, e:\n        errors.append(str(e))\n        errors.append(traceback.format_exc())\n        exit_code = 1\n\n    if errors and ((extra_flags.find('-ignore_zero_occupancy false') == -1) or (extra_flags.find('-ignore_unrecognized_res') == -1)):\n        errors.append(\"Note: extra_flags should typically include both '-ignore_zero_occupancy false' and '-ignore_unrecognized_res'.\")\n\n    if os.path.exists(script_path):\n        os.remove(script_path)\n    if os.path.exists(db_path):\n        os.remove(db_path)\n    if exit_code or errors:\n        return False, errors\n\n    return True, mapping"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread the Rosetta SQLite3. db3 file and returns the mapping from the PDB residues to the Rosetta residues", "response": "def get_mapping_from_db3_file( db_path ):\n    '''\n    Does the work of reading the Rosetta SQLite3 .db3 file to retrieve the mapping\n    '''\n    import sqlite3 # should be moved to the top but we do this here for CentOS 5 support\n\n    conn = sqlite3.connect(db_path)\n    results = conn.cursor().execute('''\n    SELECT chain_id, pdb_residue_number, insertion_code, residues.struct_id, residues.resNum, residues.name3, residues.res_type\n    FROM residue_pdb_identification\n    INNER JOIN residues ON residue_pdb_identification.struct_id=residues.struct_id AND residue_pdb_identification.residue_number=residues.resNum\n    ''')\n\n    # Create the mapping from PDB residues to Rosetta residues\n    rosetta_residue_ids = []\n    mapping = {}\n    for r in results:\n        mapping[\"%s%s%s\" % (r[0], str(r[1]).rjust(4), r[2])] = {'pose_residue_id' : r[4], 'name3' : r[5], 'res_type' : r[6]}\n        rosetta_residue_ids.append(r[4])\n\n    # Ensure that the the range of the map is exactly the set of Rosetta residues i.e. the map from (a subset of) the PDB residues to the Rosetta residues is surjective\n    raw_residue_list = [r for r in conn.cursor().execute('''SELECT resNum, name3 FROM residues ORDER BY resNum''')]\n    assert(sorted([r[0] for r in raw_residue_list]) == sorted(rosetta_residue_ids))\n\n    return mapping"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef strip_pdb(pdb_path, chains = [], strip_hetatms = False):\n    '''Takes a PDB file and strips all lines except ATOM and HETATM records. If chains is specified, only those chains are kept. If strip_hetatms is True then HETATM lines are also stripped.\n       Returns (True, a path to the stripped PDB file) on success and (False, a list of errors) on failure.'''\n    chains = set(chains)\n    contents = open(pdb_path).read().split(\"\\n\") # file handle should get garbage collected\n    if strip_hetatms:\n        if chains:\n            atom_lines = [l for l in contents if l.startswith(\"ATOM  \") and l[21] in chains]\n        else:\n            atom_lines = [l for l in contents if l.startswith(\"ATOM  \")]\n    else:\n        if chains:\n            atom_lines = [l for l in contents if (l.startswith(\"ATOM  \") or l.startswith(\"HETATM\")) and l[21] in chains]\n        else:\n            atom_lines = [l for l in contents if (l.startswith(\"ATOM  \") or l.startswith(\"HETATM\"))]\n    existing_chains = set([l[21] for l in atom_lines])\n    if chains.difference(existing_chains):\n        return False, [\"Error: The following chains do not exist in the PDB file - %s\" % \", \".join(list(chains.difference(existing_chains)))]\n\n    F, temp_pdb_path = tempfile.mkstemp(dir=\".\")\n    temp_pdb_handle = os.fdopen(F, \"w\")\n    temp_pdb_handle.write(\"\\n\".join(atom_lines))\n    temp_pdb_handle.close()\n    return True, temp_pdb_path", "response": "Takes a PDB file and strips all lines except ATOM and HETATM records."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntaking a path to an input PDB file the path to the RosettaScripts executable and Rosetta database and returns a mapping between the PDB file and the pose residue.", "response": "def get_stripped_pdb_to_pose_residue_map(input_pdb_path, rosetta_scripts_path, rosetta_database_path, chains = [], strip_hetatms = False):\n    '''Takes a path to an input PDB file, the path to the RosettaScripts executable and Rosetta database, an optional list of chains to strip the PDB down to, and an optional flag specifying whether HETATM lines should be stripped from the PDB.\n       On success, a pair (True, mapping between PDB and pose residues) is returned. On failure, a pair (False, a list of errors) is returned.'''\n    success, result = strip_pdb(input_pdb_path, chains = chains, strip_hetatms = strip_hetatms)\n    if success:\n        assert(os.path.exists(result))\n        success, mapping = get_pdb_to_pose_residue_map(result, rosetta_scripts_path, rosetta_database_path)\n        os.remove(result)\n        if success:\n            return True, mapping\n        else:\n            return False, mapping\n    return False, result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_lab_meeting(self, event_type, presenters, foodie = None, locked = False):\n        'Presenters can be a comma-separated list of presenters.'\n        e = self.initialize_tagged_copy()\n        summary_texts = {\n            'Lab meeting' : 'Kortemme Lab meeting',\n            'Kortemme/DeGrado joint meeting' : 'DeGrado/Kortemme labs joint meeting'\n        }\n        assert(summary_texts.get(event_type))\n        e['extendedProperties']['shared']['event_type'] = event_type\n        e['extendedProperties']['shared']['Presenters'] = presenters\n        e['extendedProperties']['shared']['Food'] = foodie\n        e['extendedProperties']['shared']['Locked meeting'] = locked\n        print(presenters)\n        print([[p for p in presenters.split(',')] + [foodie]])\n        participants = [p.strip() for p in ([p for p in presenters.split(',')] + [foodie]) if p and p.strip()]\n        participants = [p for p in [self.email_map.get(p) for p in participants] if p]\n        participant_names = [self.username_map.get(p.strip(), p.strip()) for p in presenters.split(',') if p.strip()]\n        if participants:\n            e['extendedProperties']['shared']['ParticipantList'] = ','.join(participants)\n        if not e['summary']:\n            e['summary'] = '%s: %s' % (summary_texts[event_type], ', '.join(participant_names))\n        e['description'] = e['description'] or e['summary']\n        return e", "response": "Presenters can be a comma - separated list of presenters."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_upcoming_event_lists_for_the_remainder_of_the_month(self, year = None, month = None):\n        '''Return the set of events as triple of (today's events, events for the remainder of the week, events for the remainder of the month).'''\n\n        events = []\n        if year == None and month == None:\n            now = datetime.now(tz=self.timezone) # timezone?\n        else:\n            now = datetime(year=year, month=month, day=1, hour=0, minute=0, second=0, tzinfo=self.timezone)\n\n        # Get today's events, including past events\n        start_time = datetime(year=now.year, month=now.month, day=now.day, hour=0, minute=0, second=0, tzinfo=self.timezone)\n        end_time = datetime(year = start_time.year, month = start_time.month, day = start_time.day, hour=23, minute=59, second=59, tzinfo=self.timezone)\n        events.append(self.get_events(start_time.isoformat(), end_time.isoformat()))\n\n        # Get this week's events\n        if now.weekday() < 6:\n            start_time = datetime(year=now.year, month=now.month, day=now.day + 1, hour=0, minute=0, second=0, tzinfo=self.timezone)\n            end_time = start_time + timedelta(days = 6 - now.weekday())\n            # We do still want to return events in the next month if they fall within this week. Otherwise\n            #if end_time.month != now.month:\n            #    end_time = end_time - timedelta(days = end_time.day)\n            #    end_time = datetime(year = end_time.year, month = end_time.month, day = end_time.day, hour=23, minute=59, second=59, tzinfo=self.timezone)\n            #else:\n            end_time = end_time + timedelta(seconds = -1)\n            #end_time = datetime(year = end_time.year, month = end_time.month, day = end_time.day - 1, hour=23, minute=59, second=59, tzinfo=self.timezone)\n            events.append(self.get_events(start_time.isoformat(), end_time.isoformat()))\n        else:\n            events.append([])\n\n        # Get this remaining events in the month\n        start_time = end_time + timedelta(seconds = 1)\n        if start_time.month == now.month:\n            if now.month == 12:\n                end_time = datetime(year = start_time.year, month = 12, day = 31, hour=23, minute=59, second=59, tzinfo=self.timezone)\n            else:\n                end_time = datetime(year = start_time.year, month = start_time.month + 1, day = 1, hour=0, minute=0, second=0, tzinfo=self.timezone)\n                end_time = end_time - timedelta(seconds = 1)\n            events.append(self.get_events(start_time.isoformat(), end_time.isoformat()))\n        else:\n            events.append([])\n\n        return events", "response": "Return the set of events as triple of ( today s events for the remainder of the month."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the events from the calendar for the next days_to_look_ahead days.", "response": "def get_upcoming_events_within_the_current_week(self):\n        '''Returns the events from the calendar for the next days_to_look_ahead days.'''\n        now = datetime.now(tz=self.timezone) # timezone?\n        start_time = datetime(year=now.year, month=now.month, day=now.day, hour=now.hour, minute=now.minute, second=now.second, tzinfo=self.timezone)\n        end_time = start_time + timedelta(days = 6 - now.weekday())\n        end_time = datetime(year = end_time.year, month = end_time.month, day = end_time.day, hour=23, minute=59, second=59, tzinfo=self.timezone)\n        assert(end_time.weekday() == 6)\n        start_time = start_time.isoformat()\n        end_time = end_time.isoformat()\n        return self.get_events(start_time, end_time)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_upcoming_events(self, days_to_look_ahead):\n        '''Returns the events from the calendar for the next days_to_look_ahead days.'''\n        now = datetime.now(tz=self.timezone) # timezone?\n        start_time = datetime(year=now.year, month=now.month, day=now.day, hour=now.hour, minute=now.minute, second=now.second, tzinfo=self.timezone)\n        end_time = start_time + timedelta(days = days_to_look_ahead)\n        start_time = start_time.isoformat()\n        end_time = end_time.isoformat()\n        return self.get_events(start_time, end_time)", "response": "Returns the events from the calendar for the next days_to_look_ahead days."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a company_name quarter event to the calendar. dt should be a date object. Returns True if the event was added.", "response": "def add_company_quarter(self, company_name, quarter_name, dt, calendar_id = 'notices'):\n        '''Adds a company_name quarter event to the calendar. dt should be a date object. Returns True if the event was added.'''\n\n        assert(calendar_id in self.configured_calendar_ids.keys())\n        calendarId = self.configured_calendar_ids[calendar_id]\n\n        quarter_name = quarter_name.title()\n        quarter_numbers = {\n            'Spring' : 1,\n            'Summer' : 2,\n            'Fall' : 3,\n            'Winter' : 4\n        }\n        assert(quarter_name in quarter_numbers.keys())\n\n        start_time = datetime(year=dt.year, month=dt.month, day=dt.day, hour=0, minute=0, second=0, tzinfo=self.timezone) + timedelta(days = -1)\n        end_time = start_time + timedelta(days = 3, seconds = -1)\n        summary = '%s %s Quarter begins' % (company_name, quarter_name)\n\n        # Do not add the quarter multiple times\n        events = self.get_events(start_time.isoformat(), end_time.isoformat(), ignore_cancelled = True)\n        for event in events:\n            if event.summary.find(summary) != -1:\n                return False\n\n        event_body = {\n            'summary' : summary,\n            'description' : summary,\n            'start' : {'date' : dt.isoformat(), 'timeZone' : self.timezone_string},\n            'end' : {'date' : dt.isoformat(), 'timeZone' : self.timezone_string},\n            'status' : 'confirmed',\n            'gadget' : {\n                'display' : 'icon',\n                'iconLink' : 'https://guybrush.ucsf.edu/images/Q%d_32.png' % quarter_numbers[quarter_name],\n                'title' : summary,\n            },\n            'extendedProperties' : {\n                'shared' : {\n                    'event_type' : '%s quarter' % company_name,\n                    'quarter_name' : quarter_name\n                }\n            }\n        }\n        colortext.warning('\\n%s\\n' % pprint.pformat(event_body))\n        created_event = self.service.events().insert(calendarId = self.configured_calendar_ids[calendar_id], body = event_body).execute()\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_holiday(self, start_dt, holiday_name, end_dt = None, calendar_id = 'notices'):\n        '''Adds a holiday event to the calendar. start_dt and end_dt (if supplied) should be date objects. Returns True if the event was added.'''\n\n        assert(calendar_id in self.configured_calendar_ids.keys())\n        calendarId = self.configured_calendar_ids[calendar_id]\n\n        # Note: end_date is one day ahead e.g. for the New Years' holiday Dec 31-Jan 1st, we specify the end_date as Jan 2nd. This is what the calendar expects.\n        if not end_dt:\n            end_dt = start_dt\n        start_date = date(year=start_dt.year, month=start_dt.month, day=start_dt.day)#, tzinfo=self.timezone)\n        end_date = date(year=end_dt.year, month=end_dt.month, day=end_dt.day) + timedelta(days = 1) #, tzinfo=self.timezone)\n        start_time = datetime(year=start_dt.year, month=start_dt.month, day=start_dt.day, hour=0, minute=0, second=0, tzinfo=self.timezone) + timedelta(days = -1)\n        end_time = datetime(year=end_dt.year, month=end_dt.month, day=end_dt.day, hour=23, minute=59, second=59, tzinfo=self.timezone) + timedelta(days = 2)\n\n        # Do not add the quarter multiple times\n        events = self.get_events((start_time + timedelta(days = -1)).isoformat(), (end_time + timedelta(days = 1)).isoformat(), ignore_cancelled = True)\n        for event in events:\n            if event.summary.find(holiday_name) != -1:\n                return False\n\n        event_body = {\n            'summary' : holiday_name,\n            'description' : holiday_name,\n            'start' : {'date' : start_date.isoformat(), 'timeZone' : self.timezone_string},\n            'end' : {'date' : end_date.isoformat(), 'timeZone' : self.timezone_string},\n            'status' : 'confirmed',\n            'extendedProperties' : {\n                'shared' : {\n                    'event_type' : 'Holiday'\n                }\n            }\n        }\n        if abs((end_date - start_date).days) > 7:\n            raise Exception('The range of dates from {0} to {1} is greater than expected. Please check to make sure that the dates are correct.'.format(start_date, end_date))\n        elif end_date < start_date:\n            raise Exception('Error: The end date {1} occurs before the start date ({0}).'.format(start_date, end_date))\n\n        created_event = self.service.events().insert(calendarId = self.configured_calendar_ids[calendar_id], body = event_body).execute()\n        return True", "response": "Adds a holiday event to the calendar. start_dt and end_dt should be date objects. Returns True if the event was added."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef remove_all_events(self, calendar_id):\n        '''Removes all events from a calendar. WARNING: Be very careful using this.'''\n        # todo: incomplete\n\n        now = datetime.now(tz=self.timezone) # timezone?\n        start_time = datetime(year=now.year - 1, month=now.month, day=now.day, hour=now.hour, minute=now.minute, second=now.second, tzinfo=self.timezone)\n        end_time = datetime(year=now.year + 1, month=now.month, day=now.day, hour=now.hour, minute=now.minute, second=now.second, tzinfo=self.timezone)\n        start_time = start_time.isoformat()\n        end_time = end_time.isoformat()\n\n\n        #events = self.service.events().list(calendarId = self.configured_calendar_ids[calendar_id], showDeleted = False).execute()\n        events = self.service.events().list(calendarId = self.configured_calendar_ids[calendar_id], timeMin = start_time, timeMax = end_time, showDeleted = False).execute()\n\n        print(len(events['items']))\n\n        for event in events['items']:\n            dt = None\n            nb = DeepNonStrictNestedBunch(event)\n            #print(event)\n            if (nb.summary or nb.description or '').find('presentation') != -1:\n                print(nb.id)\n                print(nb.summary or nb.description)\n                print(nb.start)", "response": "Removes all events from a calendar."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef tag_event(self, calendar_id, event_id, extendedProperties):\n        '''Add extendedProperties to a meeting. Warning: extendedProperties must contain only shared and private dicts and\n           their contents will overwrite anything in the event's extendedProperties i.e. we do *not* deep-merge the dicts.\n        '''\n        event_body = self.service.events().get(calendarId = self.configured_calendar_ids[calendar_id], eventId=event_id).execute()\n        event_body['extendedProperties'] = event_body.get('extendedProperties', {})\n        event_body['extendedProperties']['shared'] = event_body['extendedProperties'].get('shared', {})\n        event_body['extendedProperties']['private'] = event_body['extendedProperties'].get('private', {})\n        assert(sorted(set(extendedProperties.keys()).union(set(['shared', 'private']))) == ['private', 'shared'])\n        for k, v in extendedProperties['shared'].iteritems():\n            event_body['extendedProperties']['shared'][k] = v\n        for k, v in extendedProperties['private'].iteritems():\n            event_body['extendedProperties']['private'][k] = v\n        raise Exception('not tested yet')\n        updated_event = self.service.events().update(calendarId = self.configured_calendar_ids[calendar_id], eventId = event_id, body = event_body).execute()", "response": "Add extendedProperties to a meeting."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets up a new table space for the first time", "response": "def create_space(self):\n        '''Set up a new table space for the first time'''\n        cur = self._conn.cursor()\n        cur.executescript(SQL_MODEL)\n        self._conn.commit()\n        cur.close()\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef drop_space(self):\n        '''Dismantle an existing table space'''\n        cur = self._conn.cursor()\n        cur.executescript(DROP_SQL_MODEL)\n        self._conn.commit()\n        cur.close()\n        return", "response": "Dismantle an existing table space"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _process_db_rows_iter(self, cursor):\n        '''\n        Turn the low-level rows from the result of a standard query join\n        into higher-level statements, yielded iteratively. Note this might lead to\n        idle transaction errors?\n\n        '''\n        #Be aware of: http://packages.python.org/psycopg2/faq.html#problems-with-transactions-handling\n        #The results will come back grouped by the raw relationship IDs, in order\n        for relid, relgroup in groupby(cursor, itemgetter(0)):\n            rel = None\n            attrs = None\n            #Each relgroup are the DB rows corresponding to a single relationship,\n            #With redundant subject/predicate/object but the sequence of attributes\n            for row in relgroup:\n                (rawid, subj, pred, obj, a_name, a_val) = row\n                #self._logger.debug('Row: {0}'.format(repr(row)))\n                if not rel: rel = (subj, pred, obj)\n                if a_name:\n                    if not attrs:\n                        attrs = {}\n                        rel = (subj, pred, obj, attrs)\n                    attrs[a_name] = a_val\n            yield rel\n        cursor.close()\n        self._conn.rollback() #Finish with the transaction\n        return", "response": "Yields the low - level rows from the standard query join\n        into the iteratively - nested list of statements yielded iteratively."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds one relationship to the extent ArcGIS object.", "response": "def add(self, subj, pred, obj, attrs=None, rid=None):\n        '''\n        Add one relationship to the extent\n\n        subj - subject or origin of the relationship, an IRI coded as a unicode object\n        pred - predicate or type of the relationship, an IRI coded as a unicode object\n        obj - object of the relationship, a boolean, floating point or unicode object\n        attrs - optional attribute mapping of relationship metadata, i.e. {attrname1: attrval1, attrname2: attrval2}\n        rid - optional ID for the relationship in IRI form. If not specified one will be generated.\n\n        returns an ID (IRI) for the resulting relationship\n        '''\n        cur = self._conn.cursor()\n        #relationship.\n        if rid:\n            querystr = u\"INSERT INTO relationship (subj, pred, obj, rid) VALUES (?, ?, ?, ?);\"\n            cur.execute(querystr, (subj, pred, obj, rid))\n        else:\n            querystr = u\"INSERT INTO relationship (subj, pred, obj) VALUES (?, ?, ?);\"\n            cur.execute(querystr, (subj, pred, obj))\n        rawid = cur.lastrowid\n        for a_name, a_val in attrs.iteritems():\n            querystr = u\"INSERT INTO attribute (rawid, name, value) VALUES (?, ?, ?);\"\n            cur.execute(querystr, (rawid, a_name, a_val))\n        self._conn.commit()\n        cur.close()\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef eval(self, text):\n        program = Program(text, echo=self.echo, transforms=self.transforms)\n        tokens = program.gen_tokens()\n        for sentence in program.gen_sentences(tokens, self.aliases):\n            if self.echo:\n                self.terminal.debug(str(sentence))\n            program.interpret(sentence, self.commands)", "response": "Respond to text entered by the user."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef interact(self):\n        lines = \"\"\n        for line in self.read():\n            lines += line\n            try:\n                self.eval(lines)\n            except ValueError:\n                pass\n            except KeyboardInterrupt as e:\n                raise e\n            except:\n                self.terminal.error(traceback.format_exc())\n                break\n            else:\n                break", "response": "Get a command from the user and respond to it."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nhandling one interaction at a time until shutdown.", "response": "def serve_forever(self, banner=None):\n        \"\"\"Handle one interaction at a time until shutdown.\n\n        :param banner: (optional) the banner to print before the first\n                       interaction. Defaults to ``None``.\n        \"\"\"\n        if banner:\n            print(banner)\n        while True:\n            try:\n                self.interact()\n            except KeyboardInterrupt:  # program interrupted by the user\n                print  # do not print on the same line as ^C\n                pass\n            except SystemExit:  # exit from the interpreter\n                break"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef process_results(output_dir, config):\n    print('\\nanalyzing results...\\n')\n    res = output_results(output_dir, config)\n    if res:\n        print('created: %s/results.html\\n' % output_dir)\n    else:\n        print('results cannot be processed')", "response": "Process results and output them\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncopies current config file to output directory", "response": "def copy_config(project_path, output_dir):\n    \"\"\"Copy current config file to output directory\n    \"\"\"\n    project_config = os.path.join(project_path, 'config.json')\n    saved_config = os.path.join(output_dir, 'config.json')\n    shutil.copy(project_config, saved_config)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nstart a HQ object", "response": "def start_hq(output_dir, config, topic, is_master=True, **kwargs):\n    \"\"\"Start a HQ\n    \"\"\"\n    HightQuarter = get_hq_class(config.get('hq_class'))\n    hq = HightQuarter(output_dir, config, topic, **kwargs)\n    hq.setup()\n    if is_master:\n        hq.wait_turrets(config.get(\"min_turrets\", 1))\n    hq.run()\n    hq.tear_down()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates default output directory", "response": "def generate_output_path(args, project_path):\n    \"\"\"Generate default output directory\n    \"\"\"\n    milisec = datetime.now().microsecond\n    dirname = 'results_{}_{}'.format(time.strftime('%Y.%m.%d_%H.%M.%S', time.localtime()), str(milisec))\n    return os.path.join(project_path, 'results', dirname)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nstart an oct project", "response": "def run(args):\n    \"\"\"Start an oct project\n\n    :param Namespace args: the commande-line arguments\n    \"\"\"\n    kwargs = vars(args)\n\n    if 'func' in kwargs:\n        del kwargs['func']\n\n    project_path = kwargs.pop('project_path')\n    config = configure(project_path, kwargs.get('config_file'))\n\n    output_dir = kwargs.pop('output_dir', None) or generate_output_path(args, project_path)\n\n    stats_handler.init_stats(output_dir, config)\n\n    topic = args.publisher_channel or uuid.uuid4().hex\n    print(\"External publishing topic is %s\" % topic)\n\n    start_hq(output_dir, config, topic, **kwargs)\n\n    if not args.no_results:\n        process_results(output_dir, config)\n\n    copy_config(project_path, output_dir)\n    print('done.\\n')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncommand line interface to run oct tests.", "response": "def run_command(sp):\n    \"\"\"\n    Main function to run oct tests.\n    \"\"\"\n    parser = sp.add_parser('run', help=\"run an oct project\")\n    parser.add_argument('project_path', help=\"The project directory\")\n    parser.add_argument('-p', '--publisher-channel', dest='publisher_channel',\n                        help='the channel for the external publisher',\n                        default=None)\n    parser.add_argument('--no-results', action='store_true',\n                        help=\"if set, html report and graphs will not be generated\")\n    parser.add_argument('-o', '--output-dir', help=\"output directory for test results\")\n    parser.add_argument('--with-forwarder', action='store_true',\n                        help=\"Set if HQ should connect to external forwarder\")\n    parser.add_argument('--forwarder-address',\n                        help=\"with form ip:port. If not set and --with-forwarder flag present HQ will use default values\")\n    parser.add_argument('--config-file', default=None,\n                        help=\"configuration file to use, default is config.json in project directory\")\n    parser.set_defaults(func=run)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nguest access decorator Checks if public profiles option is enabled in config and checks access to profile pages based on that.", "response": "def guest_access(func):\n    \"\"\"\n    Guest access decorator\n    Checks if public profiles option is enabled in config and checks\n    access to profile pages based on that.\n    \"\"\"\n    def decorated(*_, **kwargs):\n        public_profiles = current_app.config['USER_PUBLIC_PROFILES']\n        if not public_profiles:\n            if not current_user.is_authenticated:\n                abort(401)\n            elif current_user.id != kwargs['id']:\n                abort(403)\n        return func(**kwargs)\n\n    return decorated"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprocessing and loads config file.", "response": "def load(config_file):\n    \"\"\"\n    Processes and loads config file.\n    \"\"\"\n    with open(config_file, \"r\") as f:\n\n        def env_get():\n            return dict(os.environ)\n        tmpl = Template(f.read())\n        return Config(yaml.load(tmpl.render(**env_get())))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_term_by_year_and_quarter(year, quarter):\n    url = \"{}/{},{}.json\".format(\n        term_res_url_prefix, year, quarter.lower())\n    return _json_to_term_model(get_resource(url))", "response": "Returns a uw_sws. models. Term object for the passed year and quarter."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_current_term():\n    url = \"{}/current.json\".format(term_res_url_prefix)\n    term = _json_to_term_model(get_resource(url))\n\n    # A term doesn't become \"current\" until 2 days before the start of\n    # classes.  That's too late to be useful, so if we're after the last\n    # day of grade submission window, use the next term resource.\n    if datetime.now() > term.grade_submission_deadline:\n        return get_next_term()\n\n    return term", "response": "Returns a uw_sws. models. Term object for the current term."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_term_before(aterm):\n    prev_year = aterm.year\n    prev_quarter = QUARTER_SEQ[QUARTER_SEQ.index(aterm.quarter) - 1]\n\n    if prev_quarter == \"autumn\":\n        prev_year -= 1\n\n    return get_term_by_year_and_quarter(prev_year, prev_quarter)", "response": "Returns a uw_sws. models. Term object for the term before the given term."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_term_after(aterm):\n    next_year = aterm.year\n    if aterm.quarter == \"autumn\":\n        next_quarter = QUARTER_SEQ[0]\n    else:\n        next_quarter = QUARTER_SEQ[QUARTER_SEQ.index(aterm.quarter) + 1]\n\n    if next_quarter == \"winter\":\n        next_year += 1\n\n    return get_term_by_year_and_quarter(next_year, next_quarter)", "response": "Returns a uw_sws. models. Term object for the term after the given term."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a term for the given datetime. date object given.", "response": "def get_term_by_date(date):\n    \"\"\"\n    Returns a term for the datetime.date object given.\n    \"\"\"\n    year = date.year\n\n    term = None\n    for quarter in ('autumn', 'summer', 'spring', 'winter'):\n        term = get_term_by_year_and_quarter(year, quarter)\n\n        if date >= term.first_day_quarter:\n            break\n\n    # If we're in a year, before the start of winter quarter, we need to go\n    # to the previous year's autumn term:\n    if date < term.first_day_quarter:\n        term = get_term_by_year_and_quarter(year - 1, 'autumn')\n\n    # Autumn quarter should always last through the end of the year,\n    # with winter of the next year starting in January.  But this makes sure\n    # we catch it if not.\n    term_after = get_term_after(term)\n    if term_after.first_day_quarter > date:\n        return term\n    else:\n        return term_after\n\n    pass"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a TermModel object from the passed json data.", "response": "def _json_to_term_model(term_data):\n    \"\"\"\n    Returns a term model created from the passed json data.\n    param: term_data loaded json data\n    \"\"\"\n\n    strptime = datetime.strptime\n    day_format = \"%Y-%m-%d\"\n    datetime_format = \"%Y-%m-%dT%H:%M:%S\"\n\n    term = TermModel()\n    term.year = term_data[\"Year\"]\n    term.quarter = term_data[\"Quarter\"]\n\n    term.last_day_add = parse_sws_date(term_data[\"LastAddDay\"])\n\n    term.first_day_quarter = parse_sws_date(term_data[\"FirstDay\"])\n\n    term.last_day_instruction = parse_sws_date(term_data[\"LastDayOfClasses\"])\n\n    term.last_day_drop = parse_sws_date(term_data[\"LastDropDay\"])\n\n    term.census_day = parse_sws_date(term_data[\"CensusDay\"])\n\n    if term_data[\"ATermLastDay\"] is not None:\n        term.aterm_last_date = parse_sws_date(term_data[\"ATermLastDay\"])\n\n    if term_data[\"BTermFirstDay\"] is not None:\n        term.bterm_first_date = parse_sws_date(term_data[\"BTermFirstDay\"])\n\n    if term_data[\"LastAddDayATerm\"] is not None:\n        term.aterm_last_day_add = parse_sws_date(term_data[\"LastAddDayATerm\"])\n\n    if term_data[\"LastAddDayBTerm\"] is not None:\n        term.bterm_last_day_add = parse_sws_date(term_data[\"LastAddDayBTerm\"])\n\n    term.last_final_exam_date = parse_sws_date(term_data[\"LastFinalExamDay\"])\n\n    try:\n        term.grading_period_open = strptime(\n            term_data[\"GradingPeriodOpen\"], datetime_format)\n    except (TypeError, ValueError):\n        logger.warn('Malformed term_data[\"GradingPeriodOpen\"]: {}'.format(\n            term_data[\"GradingPeriodOpen\"]))\n        term.grading_period_open = strptime(\n            '{}T08:00:00'.format(term_data['LastFinalExamDay']),\n            datetime_format)\n\n    if term_data[\"GradingPeriodOpenATerm\"] is not None:\n        term.aterm_grading_period_open = strptime(\n            term_data[\"GradingPeriodOpenATerm\"], datetime_format)\n\n    try:\n        term.grading_period_close = strptime(\n            term_data[\"GradingPeriodClose\"], datetime_format)\n    except (TypeError, ValueError):\n        logger.warn('Malformed term_data[\"GradingPeriodClose\"]: {}'.format(\n            term_data[\"GradingPeriodClose\"]))\n        term.grading_period_close = strptime(\n            '{}T17:00:00'.format(term_data['LastFinalExamDay']),\n            datetime_format)\n\n    try:\n        term.grade_submission_deadline = strptime(\n            term_data[\"GradeSubmissionDeadline\"], datetime_format)\n    except (TypeError, ValueError):\n        logger.warn(\n            'Malformed term_data[\"GradeSubmissionDeadline\"]: {}'.format(\n                term_data[\"GradeSubmissionDeadline\"]))\n        term.grade_submission_deadline = strptime(\n            '{}T17:00:00'.format(term_data['LastFinalExamDay']),\n            datetime_format)\n\n    if term_data[\"RegistrationServicesStart\"] is not None:\n        term.registration_services_start = parse_sws_date(\n            term_data[\"RegistrationServicesStart\"])\n\n    if term_data[\"RegistrationPeriods\"][0][\"StartDate\"] is not None:\n        term.registration_period1_start = parse_sws_date(\n            term_data[\"RegistrationPeriods\"][0][\"StartDate\"])\n\n    if term_data[\"RegistrationPeriods\"][0][\"EndDate\"] is not None:\n        term.registration_period1_end = parse_sws_date(\n            term_data[\"RegistrationPeriods\"][0][\"EndDate\"])\n\n    if term_data[\"RegistrationPeriods\"][1][\"StartDate\"] is not None:\n        term.registration_period2_start = parse_sws_date(\n            term_data[\"RegistrationPeriods\"][1][\"StartDate\"])\n\n    if term_data[\"RegistrationPeriods\"][1][\"EndDate\"] is not None:\n        term.registration_period2_end = parse_sws_date(\n            term_data[\"RegistrationPeriods\"][1][\"EndDate\"])\n\n    if term_data[\"RegistrationPeriods\"][2][\"StartDate\"] is not None:\n        term.registration_period3_start = parse_sws_date(\n            term_data[\"RegistrationPeriods\"][2][\"StartDate\"])\n\n    if term_data[\"RegistrationPeriods\"][2][\"EndDate\"] is not None:\n        term.registration_period3_end = parse_sws_date(\n            term_data[\"RegistrationPeriods\"][2][\"EndDate\"])\n\n    term.time_schedule_construction = {}\n    for campus in term_data[\"TimeScheduleConstruction\"]:\n        term.time_schedule_construction[campus.lower()] = True if (\n            term_data[\"TimeScheduleConstruction\"][campus]) else False\n\n    term.time_schedule_published = {}\n    for campus in term_data[\"TimeSchedulePublished\"]:\n        term.time_schedule_published[campus.lower()] = True if (\n            term_data[\"TimeSchedulePublished\"][campus]) else False\n\n    term.clean_fields()\n    return term"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the next non - summer term in the quarter after as the given term", "response": "def get_next_non_summer_term(term):\n    \"\"\"\n    Return the Term object for the quarter after\n    as the given term (skip the summer quarter)\n    \"\"\"\n    next_term = get_term_after(term)\n    if next_term.is_summer_quarter():\n        return get_next_autumn_term(next_term)\n    return next_term"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef logging_feature(app):\n\n    # this is important because otherwise only log warn, err and crit\n    app.logger.setLevel(logging.INFO)\n\n    # enable loggers\n    email_exceptions = app.config.get('LOGGING_EMAIL_EXCEPTIONS_TO_ADMINS')\n    if email_exceptions and not app.debug and not app.testing:\n        # config.debug=False\n        mail_handler = mail_logger(app)\n        app.logger.addHandler(mail_handler)\n\n    if not app.testing:\n        file_handler = file_logger(app)\n        app.logger.addHandler(file_handler)", "response": "Add logging feature for the application"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def rtm(self) -> AsyncIterator[Event]:\n        response = cast(RTMStart, await self.api(\"rtm.start\"))\n\n        self.me = Auto.generate(response.self_, \"Me\", recursive=False)\n        self.team = Auto.generate(response.team, \"Team\", recursive=False)\n        self.channels.fill(Channel.build(item) for item in response.channels)\n        self.users.fill(User.build(item) for item in response.users)\n        self.groups.fill(Group.build(item) for item in response.groups)\n\n        log.debug(\n            f\"received {len(self.users)} users, {len(self.channels)} channels \"\n            f\"and {len(self.groups)} groups from rtm.start\"\n        )\n\n        async with self.session.ws_connect(response[\"url\"]) as ws:\n            async for msg in ws:\n                event: Event = Event.generate(msg.json(), recursive=False)\n\n                if event.type == \"goodbye\":\n                    break\n\n                yield event", "response": "Connect to the realtime event API and start yielding events."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndecoding <id > and <!alias > into username.", "response": "def decode(self, text: str, prefix: str = \"@\") -> str:\n        \"\"\"Decode <@id> and <!alias> into @username.\"\"\"\n\n        def callback(match: Match) -> str:\n            m = match.groupdict()\n            if m[\"userid\"]:\n                user = self.users.get(m[\"userid\"], None)\n                if user is None:\n                    username = m[\"userid\"]\n                else:\n                    username = user.name\n            elif m[\"alias\"]:\n                username = m[\"alias\"]\n            return f\"{prefix}{username}\"\n\n        return self.decode_re.sub(callback, text)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nencoding username into <@id or <!alias >.", "response": "def encode(self, text: str) -> str:\n        \"\"\"Encode @username into <@id> or <!alias>.\"\"\"\n\n        def callback(match: Match) -> str:\n            name = match.group(\"name\").lower()\n            if name in [\"here\", \"everyone\", \"channel\"]:\n                return f\"<!{name}>\"\n            else:\n                for user in self.users.values():\n                    if user.name == name:\n                        return f\"<@{user.id}>\"\n            return match.group(0)\n\n        return self.encode_re.sub(callback, text)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef formgroup_factory(form_classes,\n                      formgroup=None,\n                      state_validators=None,\n                      ):\n    \"\"\"Return a FormGroup class for the given form[set] form_classes.\n\n    \"\"\"\n\n    base_class = formgroup or FormGroup\n    if state_validators is not None:\n        base_class = StateValidatorFormGroup\n\n    if not issubclass(base_class, FormGroup):\n        raise TypeError(\"Base formgroup class must subclass FormGroup.\")\n\n    return type(\n        'FormGroup',\n        (base_class,),\n        dict(\n            form_classes=form_classes,\n            state_validators=state_validators,\n        ),\n    )", "response": "Return a FormGroup class for the given form [ set ] form_classes."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _apply(self, method_name, *args, **kwargs):\n\n        return [\n            getattr(member, method_name)(*args, **kwargs)\n            for member in self.forms\n        ]", "response": "Call method_name with args and kwargs on each member and return a sequence of return values."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef html_id(self, field_name, form=None):\n\n        if form is None:\n            form = self\n\n        return form.auto_id % (form.add_prefix(field_name),)", "response": "Return the html ID for the given field_name."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef save(self):\n\n        # first call save with commit=False for all Forms\n        for form in self._forms:\n            if isinstance(form, BaseForm):\n                form.save(commit=False)\n\n        # call save on the instance\n        self.instance.save()\n\n        # call any post-commit hooks that have been stashed on Forms\n        for form in self.forms:\n            if isinstance(form, BaseForm):\n                if hasattr(form, 'save_m2m'):\n                    form.save_m2m()\n                if hasattr(form, 'save_related'):\n                    form.save_related()\n\n        # call save on any formsets\n        for form in self._forms:\n            if isinstance(form, BaseFormSet):\n                form.save(commit=True)\n\n        return self.instance", "response": "Save the changes to the instance and any related objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns True if all the validators for the specified states pass.", "response": "def is_valid(self, *states):\n        \"\"\"Returns True if no errors are thrown for the specified state.\"\"\"\n\n        # if no state is specified, fallback to the base FormGroup's is_valid\n        if not states:\n            return super(StateValidatorFormGroup, self).is_valid()\n\n        # see if the states pass for all forms that define state_validators\n        return all(form.is_valid(*states)\n                   for form in self.forms\n                   if isinstance(form, StateValidatorFormMixin)) and \\\n               all(self.state_validators[state].is_valid(self)\n                   for state in states)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef make_text(self, width):\n        def mformat(reslist):\n            _text = \"\"\n            _buffer = reslist[0]\n            for j in range(1, len(reslist)):\n                if (_buffer == \"\") or (len(_buffer) + len(reslist[j])) <= (width - len(filling)):\n                    if reslist[j][0] == '[' and reslist[j][-1] == ']':\n                        _buffer = '{0} {1}'.format(_buffer, reslist[j])\n                    else:\n                        _buffer = '{0}, {1}'.format(_buffer, reslist[j])\n                else:\n                    _text = '{0}{1}\\n{2}'.format(_text, _buffer, filling)\n                    _buffer = reslist[j]\n            _text = '{0}{1}'.format(_text, _buffer)\n            return _text\n\n        text = '\\n----- {0} -----\\n\\n'.format(self.title.strip())\n\n        if self.function == 'total':\n            width1 = max(len(res[0]) for res in self.results if res is not None)\n            for res in self.results:\n                padding = ' ' * (width1 - len(res[0]) + 1)\n                text = '{0}{1}{2}| {3}\\n'.format(text, res[0], padding, res[1])\n                \n        elif self.function == 'top':\n            if self.results[0] is not None:\n                width1 = max(len(res[0]) for res in self.results if res is not None)\n                width2 = min([width-width1-4,\n                              max(len(', '.join(res[1])) for res in self.results if res is not None)])\n\n                text = '{0}{1} | {2}\\n'.format(text, ' ' * width1, self.headers.strip('\"'))\n                text = '{0}{1}-+-{2}-\\n'.format(text, '-' * width1, '-' * width2)\n\n                for res in self.results:\n                    if res is not None:\n                        padding = ' ' * (width1 - len(res[0]) + 1)\n                        filling = '{0}| '.format(' ' * (width1 + 1))\n                        lastcol = mformat(res[1])\n                        text = '{0}{1}{2}| {3}\\n'.format(text, res[0], padding, lastcol)\n            else:\n                text = '{0} {1}\\n'.format(text, 'None')\n                    \n        elif self.function == 'table':\n            headers = re.split('\\s*,\\s*', self.headers)\n\n            colwidth = []\n            for i in range(len(headers)-1):\n                colwidth.append(max([len(headers[i]), max(len(res[i]) for res in self.results)]))\n\n            for i in range(len(headers)-1):\n                text = '{0}{1}{2}| '\\\n                            .format(text, headers[i].strip('\"'), ' ' * (colwidth[i]-len(headers[i])+2))\n\n            text = '{0}{1}\\n'.format(text, headers[-1].strip('\"'))\n            text = '{0}{1}\\n'.format(text, '-' * (width-1))\n\n            filling = \"\"\n            for i in range(len(headers)-1):\n                filling = '{0}{1}| '.format(filling, ' ' * colwidth[i])\n            \n            for res in sorted(self.results, key=lambda x: x[0]):\n                for i in range(len(headers)-1):\n                    text = '{0}{1}{2}| '.format(text, res[i], ' ' * (colwidth[i]-len(res[i])))\n                lastcol = get_fmt_results(res[-1], limit=5)\n                text = '{0}{1}\\n'.format(text, mformat(lastcol))\n        self.text = text", "response": "Make the text representation of a report data element."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmakes the text representation of a report element as html.", "response": "def make_html(self):\n        \"\"\"\n        Make the text representation of a report element as html.\n        \"\"\"\n        html = None\n        if self.function == 'total':\n            html = u'<table border=\"0\" width=\"100%\" rules=\"cols\" cellpadding=\"2\">\\n'\\\n                   '<tr><th colspan=\"2\" align=\"left\"><h3><font color=\"{1}\">'\\\n                   '{0}</font></h3></th></tr>\\n'\\\n                   .format(htmlsafe(self.title.strip()), self.color)\n\n            for res in self.results:\n                html = u'{0}<tr><td valign=\"top\" align=\"right\">{1}</td>'\\\n                       '<td valign=\"top\" width=\"90%\">{2}</td></tr>'\\\n                       .format(html, res[0], res[1])\n\n        elif self.function == 'top':\n            html = u'<table border=\"0\" width=\"100%\" rules=\"cols\" cellpadding=\"2\">\\n'\\\n                   '<tr><th colspan=\"2\" align=\"left\"><h3><font color=\"{1}\">'\\\n                   '{0}</font></h3></th></tr>\\n'\\\n                   .format(htmlsafe(self.title.strip()), self.color)\n\n            if self.results[0] is not None:\n                for res in self.results:\n                    if res is not None:\n                        html = u'{0}<tr><td valign=\"top\" align=\"right\">{1}</td>'\\\n                               '<td valign=\"top\" width=\"90%\">{2}</td></tr>'\\\n                               .format(html, res[0], ', '.join(res[1]))\n            else:\n                html = u'{0}<tr><td valign=\"top\" align=\"left\">{1}</td>'\\\n                       .format(html, \"None\")\n                \n        elif self.function == 'table':\n            html = u'<h3><font color=\"{1}\">{0}</font></h3>'\\\n                   '<table width=\"100%\" rules=\"cols\" cellpadding=\"2\">\\n'\\\n                   '<tr bgcolor=\"#aaaaaa\">'\\\n                   .format(htmlsafe(self.title.strip()), self.color)\n            \n            headers = re.split('\\s*,\\s*', self.headers)\n            for i in range(len(headers)):\n                html = '{0}<th align=\"center\" colspan=\"1\">'\\\n                       '<font color=\"black\">{1}</font></th>'\\\n                       .format(html, headers[i].strip('\"'))\n\n            html = u'{0}</tr>\\n'.format(html)\n            \n            oddflag = False\n            lastval = \"\"            \n            for res in sorted(self.results, key=lambda x: x[0]):\n                if lastval != res[0]:\n                    oddflag = not oddflag\n                    if oddflag:\n                        html = u'{0}<tr bgcolor=\"#dddddd\">'.format(html)\n                    else:\n                        html = u'{0}<tr>'.format(html)\n\n                    html = u'{0}<td valign=\"top\" width=\"15%\">{1}</td>'\\\n                           .format(html, res[0])\n                else:\n                    if oddflag:\n                        html = u'{0}<tr bgcolor=\"#dddddd\">'.format(html)\n                    else:\n                        html = u'{0}<tr>'.format(html)\n\n                    html = u'{0}<td valign=\"top\" width=\"15%\">&nbsp;</td>'.format(html)\n                lastval = res[0]\n                \n                for i in range(1, len(headers)-1):\n                    html = u'{0}<td valign=\"top\" width=\"15%\">{1}</td>'.format(html, res[i])\n                lastcol = get_fmt_results(res[-1], limit=10, fmt=u'<font color=\"darkred\">{0}</font>')\n\n                if lastcol[-1].find(u\" more skipped]\") > -1:\n                    html = u'{0}<td valign=\"top\" width=\"{1}%\">{2} {3}</td></tr>\\n'\\\n                           .format(html, 100-15*(len(headers)-1),\n                                   u', '.join(lastcol[:-1]), lastcol[-1])\n                else:\n                    html = u'{0}<td valign=\"top\" width=\"{1}%\">{2}</td></tr>\\n'\\\n                           .format(html, 100-15*(len(headers)-1), u', '.join(lastcol))\n\n        self.html = u'{0}</table>\\n<p>\\n'.format(html)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef make_csv(self):\n        import csv\n        try:\n            from StringIO import StringIO  # Python 2.7\n        except ImportError:\n            from io import StringIO\n\n        out = StringIO()\n        writer = csv.writer(out, delimiter='|', lineterminator='\\n', quoting=csv.QUOTE_MINIMAL)\n\n        if self.function == 'total':\n            writer.writerows(self.results)                \n\n        elif self.function == 'top':\n            rows = [['Value', self.headers.strip('\"')]]\n            if self.results[0] is not None:\n                for res in self.results:\n                    if res is not None:\n                        rows.append(tuple([res[0], ','.join(res[1])]))\n                writer.writerows(rows)\n                \n        elif self.function == 'table':\n            rows = [[header.strip('\"') for header in re.split('\\s*,\\s*', self.headers)]]\n\n            for res in sorted(self.results, key=lambda x: x[0]):\n                row = list(res[:-1])\n                lastcol = get_fmt_results(res[-1], limit=10)\n                if lastcol[-1][0] == '[' and lastcol[-1][-1] == ']':\n                    row.append(u'{0} {1}'.format(u', '.join(lastcol[:-1]), lastcol[-1]))\n                else:\n                    row.append(u', '.join(lastcol))\n                rows.append(row)\n            writer.writerows(rows)\n\n        self.csv = out.getvalue()", "response": "Make the text representation of a report element as csv."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmake subreport items from results.", "response": "def make(self, apps):\n        \"\"\"\n        Make subreport items from results.\n        \"\"\"\n        for (appname, app) in sorted(apps.items(), key=lambda x: (x[1].priority, x[0])):\n            logger.info('Getting report results from %r', appname)\n\n            for report_data in app.report_data:\n                if report_data.subreport != self.name:\n                    continue\n\n                if report_data.function == 'total':\n                    for opt in report_data:\n                        match = report_data.parse_report_data(opt)\n                        cond = match.group('condition')\n                        valfld = match.group('valfld')\n                        unit = match.group('unit')\n                        itemtitle = match.group('fields').strip('\"')\n\n                        total = report_data.rules[opt].total_events(cond, valfld)\n                        if total == 0:\n                            continue\n\n                        if unit is not None:\n                            total, unit = get_value_unit(total, unit, 'T')\n                            total = '{0} {1}'.format(total, unit)\n                        else:\n                            total = str(total)\n                        report_data.results.append(tuple([total, itemtitle]))\n\n                elif report_data.function == 'top':\n                    k = int(report_data.topnum)\n                    for opt in report_data:\n                        match = report_data.parse_report_data(opt)\n\n                        valfld = match.group('valfld')\n                        field = match.group('fields')\n                        usemax = match.group('add2res') is None\n\n                        toplist = report_data.rules[opt].top_events(k, valfld, usemax, field)\n                        report_data.results.extend(toplist)\n                        \n                elif report_data.function == 'table':\n                    cols = len(re.split('\\s*,\\s*', report_data.headers))\n                    for opt in report_data:\n                        match = report_data.parse_report_data(opt)\n                        cond = match.group('condition')\n                        fields = re.split('\\s*,\\s*', match.group('fields'))\n                        tablelist = report_data.rules[opt].list_events(cond, cols, fields)\n                        report_data.results.extend(tablelist)\n\n                if report_data.results:\n                    self.report_data.append(report_data)\n\n        # Sort and rewrite results as strings with units \n        for report_data in self.report_data:\n            if report_data.function == 'top':\n                # Sort values\n                report_data.results = sorted(report_data.results, key=lambda x: x[0], reverse=True)\n\n                # Get the unit if any and convert numeric results to strings\n                unit = None\n                for opt in report_data:\n                    match = report_data.parse_report_data(opt)\n                    unit = match.group('unit')\n                    if unit is not None:\n                        break\n\n                for res in report_data.results:\n                    if unit is not None:\n                        v, u = get_value_unit(res[0], unit, 'T')\n                        res[0] = '{0} {1}'.format(v, u)\n                    else:\n                        res[0] = str(res[0])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmake subreport text in a specified format", "response": "def make_format(self, fmt, width):\n        \"\"\"\n        Make subreport text in a specified format         \n        \"\"\"\n        if not self.report_data:\n            return\n        \n        for data_item in self.report_data:\n            if data_item.results:\n                if fmt is None or fmt == 'text':\n                    data_item.make_text(width)\n                elif fmt == 'html':\n                    data_item.make_html()\n                elif fmt == 'csv':\n                    data_item.make_csv()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef compact_tables(self):\n        items_to_del = set()\n        for i in range(len(self.report_data)):\n            if i in items_to_del:\n                continue\n            if self.report_data[i].function[0:5] == 'table':\n                for j in range(i+1, len(self.report_data)):\n                    if self.report_data[j].function[0:5] == 'table':\n                        if self.report_data[i] == self.report_data[j]:\n                            logger.debug('Merge of 2 identical report tables: {0}'\n                                         .format(self.report_data[i].title)) \n                            items_to_del.add(j)\n                            self.report_data[i].results.extend(self.report_data[j].results)\n        if items_to_del:\n            for i in reversed(sorted(items_to_del, key=lambda x: x)):\n                self.report_data.pop(i)", "response": "Compact report items of type table with same results type."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef make(self, apps):\n        for subreport in self.subreports:\n            logger.debug('Make subreport \"{0}\"'.format(subreport.name))\n            subreport.make(apps)\n\n        for subreport in self.subreports:\n            subreport.compact_tables()", "response": "Create the report from application results"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmaking report items in a specified format.", "response": "def get_report_parts(self, apps, formats):\n        \"\"\"\n        Make report item texts in a specified format.\n        \"\"\"\n        for fmt in formats:\n            width = 100 if fmt is not None else tui.get_terminal_size()[0]\n            for sr in self.subreports:\n                sr.make_format(fmt, width)\n\n        logger.debug('Build a map for arguments and run\\'s statistics ...')\n        value_mapping = {\n            'title': self.title,\n            'patterns': ', '.join([repr(pattern) for pattern in self.args.patterns]) or None,\n            'pattern_files': ', '.join(self.args.pattern_files) or None,\n            'hosts': ', '.join(self.args.hosts) or None,\n            'apps': u', '.join([\n                u'%s(%d)' % (app.name, app.matches) for app in apps.values() if app.matches > 0\n            ]),\n            'version': __version__\n        }\n\n        filters = []\n        for flt in self.args.filters:\n            filters.append(' AND '.join(['%s=%r' % (k, v.pattern) for k, v in flt.items()]))\n        if filters:\n            value_mapping['filters'] = ' OR '.join(['(%s)' % item for item in filters])\n        else:\n            value_mapping['filters'] = filters[0] if filters else None\n\n        value_mapping.update(self.stats)\n\n        report = []\n        for fmt in formats:\n            if fmt == 'text':\n                logger.info('appends a text page report')\n                report.append(self.make_text_page(value_mapping))\n            elif fmt == 'html':\n                logger.info('appends a html page report')\n                report.append(self.make_html_page(value_mapping))\n            elif fmt == 'csv':\n                logger.info('extends with a list of csv subreports')\n                report.extend(self.make_csv_tables())\n        return report"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting run statistics for the report.", "response": "def set_stats(self, run_stats):\n        \"\"\"\n        Set run statistics for the report.\n        \"\"\"\n        self.stats = run_stats.copy()\n        self.stats['files'] = ', '.join(self.stats['files'])\n        self.stats['tot_files'] = len(run_stats['files'])\n        self.stats['extra_tags'] = ', '.join(self.stats['extra_tags'])"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nbuilds the report as html page using the template page from file.", "response": "def make_html_page(self, valumap):\n        \"\"\"\n        Builds the report as html page, using the template page from file.\n        \"\"\"\n        logger.info('Making an html report using template %r.', self.html_template)\n        fh = open(self.html_template)\n        template = fh.read()\n        fh.close()\n\n        parts = []\n        for sr in self.subreports:\n            report_data = [item.html for item in sr.report_data if item.html]\n            if report_data:\n                parts.append('\\n<h2>{1}</h2>\\n'.format(sr.title, sr.reptext))\n                parts.extend(report_data)\n                parts.append('\\n<hr/>')\n        \n        valumap['subreports'] = '\\n'.join(parts) # or \"\\n<<NO SUBREPORT RELATED EVENTS>>\\n\"\n        html_page = Template(template).safe_substitute(valumap)\n        return TextPart(fmt='html', text=html_page, ext='html')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nbuild a text report page from the template file.", "response": "def make_text_page(self, valumap):\n        \"\"\"\n        Builds the report as text page, using the template page from file.\n        \"\"\"\n        logger.info('Making a text report page using template %r.', self.text_template)\n        fh = open(self.text_template)\n        template = fh.read()\n        fh.close()\n        \n        parts = []\n        for sr in self.subreports:\n            report_data = [item.text for item in sr.report_data if item.text]\n            if report_data:\n                parts.append('\\n{1}\\n***** {0} *****\\n{1}'.format(sr.title, '*' * (len(sr.title)+12)))\n                parts.extend(report_data)\n\n        valumap['subreports'] = '\\n'.join(parts) # \"\\n<<NO SUBREPORT RELATED EVENTS>>\\n\"\n        text_page = Template(template).safe_substitute(valumap)\n        return TextPart(fmt='text', text=text_page, ext='txt')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef make_csv_tables(self):\n        logger.info('Generate csv report tables')\n        report_parts = []\n        for sr in self.subreports:\n            for data_item in sr.report_data:\n                report_parts.append(TextPart(fmt='csv', text=data_item.csv, ext='csv'))\n        return report_parts", "response": "Builds the report as a list of csv tables with titles."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fetch_items(self):\n        offset = self.per_page * (self.page - 1)\n        items = self._query.limit(self.per_page).offset(offset).all()\n        return items", "response": "Fetch items based on current query and pagination settings."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning current collection as a dictionary", "response": "def dict(self):\n        \"\"\" Returns current collection as a dictionary \"\"\"\n        collection = dict(\n            page=self.page,\n            per_page=self.per_page,\n            total_items=self.total_items,\n            total_pages=self.total_pages,\n            pagination=self.pagination,\n            items=list(self.items)\n        )\n        return collection"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning True if there are items on the next page False otherwise", "response": "def next_page(self):\n        \"\"\"\n        Next page\n        Uses query object to fetch next slice of items unless on last page in\n        which case does nothing\n        \"\"\"\n        if self.is_last_page():\n            return False\n\n        self.page += 1\n        self.items = self.fetch_items()\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn True if this is the first page False otherwise", "response": "def previous_page(self):\n        \"\"\"\n        Previous page\n        Uses query object to fetch previous slice of items unless on first\n        page in which case does nothing\n        \"\"\"\n        if self.is_first_page():\n            return False\n\n        self.page -= 1\n        self.items = self.fetch_items()\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _make_spec_file(self):\n        spec_file = setuptools.command.bdist_rpm.bdist_rpm._make_spec_file(self)\n        spec_file.append('%config(noreplace) /etc/lograptor/lograptor.conf')\n        spec_file.append('%config(noreplace) /etc/lograptor/report_template.*')\n        spec_file.append('%config(noreplace) /etc/lograptor/conf.d/*.conf')\n        return spec_file", "response": "Customize spec file inserting %config section"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlogs user update event for user entities", "response": "def user_save_event(user):\n    \"\"\" Handle persist event for user entities \"\"\"\n    msg = 'User ({}){} updated/saved'.format(user.id, user.email)\n    current_app.logger.info(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef user_got_role_event(user, role):\n    msg = 'User ({}){} got new role [{}]'\n    current_app.logger.info(msg.format(user.id, user.email, role.handle))", "response": "Log user got new role"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef generate_hash(self, length=30):\n        import random, string\n        chars = string.ascii_letters + string.digits\n        ran = random.SystemRandom().choice\n        hash = ''.join(ran(chars) for i in range(length))\n        return hash", "response": "Generate random string of given length"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef gravatar(self, size):\n        hash = md5(self.email.encode('utf-8')).hexdigest()\n        url = 'http://www.gravatar.com/avatar/{}?d=mm&s={}'\n        return url.format(hash, size)", "response": "Get url to gravatar"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if the current account is locked and unlocks upon timeout.", "response": "def is_locked(self):\n        \"\"\"\n        Is locked?\n        Checks locking and possibly unlocks upon timeout if account was\n        previously locked.\n        \"\"\"\n        now = datetime.datetime.utcnow()\n        if self.locked_until and self.locked_until >= now:\n            return True\n        elif self.locked_until and self.locked_until < now:\n            self.unlock_account()\n            return False\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlock user account for a period", "response": "def lock_account(self, minutes=30):\n        \"\"\" Lock user account for a period \"\"\"\n        period = datetime.timedelta(minutes=minutes)\n        self.locked_until = datetime.datetime.utcnow() + period"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nincrements failed logins counter", "response": "def increment_failed_logins(self):\n        \"\"\" Increment failed logins counter\"\"\"\n        if not self.failed_logins:\n            self.failed_logins = 1\n        elif not self.failed_login_limit_reached():\n            self.failed_logins += 1\n        else:\n            self.reset_login_counter()\n            self.lock_account(30)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef failed_login_limit_reached(self):\n        login_limit = 10\n        if self.failed_logins and self.failed_logins >= login_limit:\n            return True\n        else:\n            return False", "response": "A boolean method to check if the failed login limit is reached"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef email_secure(self):\n        email = self._email\n        if not email: return ''\n        address, host = email.split('@')\n        if len(address) <= 2: return ('*' * len(address)) + '@' + host\n\n        import re\n        host = '@' + host\n        obfuscated = re.sub(r'[a-zA-z0-9]', '*', address[1:-1])\n        return address[:1] + obfuscated + address[-1:] + host", "response": "Obfuscated email used for display"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting email and generate confirmation", "response": "def email(self, email):\n        \"\"\" Set email and generate confirmation \"\"\"\n        if email == self.email:\n            return\n\n        email = email.lower()\n        if self._email is None:\n            self._email = email\n            self.require_email_confirmation()\n        else:\n            self.email_new = email\n            self.require_email_confirmation()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmark email as unconfirmed", "response": "def require_email_confirmation(self):\n        \"\"\" Mark email as  unconfirmed\"\"\"\n        self.email_confirmed = False\n        self.email_link = self.generate_hash(50)\n        now = datetime.datetime.utcnow()\n        self.email_link_expires = now + datetime.timedelta(hours=24)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncancel email change for new users and roll back data", "response": "def cancel_email_change(self):\n        \"\"\" Cancel email change for new users and roll back data \"\"\"\n        if not self.email_new:\n            return\n\n        self.email_new = None\n        self.email_confirmed = True\n        self.email_link = None\n        self.email_new = None\n        self.email_link_expires = None"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks if email link expired", "response": "def email_link_expired(self, now=None):\n        \"\"\" Check if email link expired \"\"\"\n        if not now: now = datetime.datetime.utcnow()\n        return self.email_link_expires < now"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef password(self, password):\n        from boiler.user.util.passlib import passlib_context\n        password = str(password)\n        encrypted = passlib_context.encrypt(password)\n        self._password = encrypted", "response": "Encode a string and set as password"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef verify_password(self, password):\n        if self.password is None:\n            return False\n\n        from boiler.user.util.passlib import passlib_context\n        return passlib_context.verify(str(password), self.password)", "response": "Verify a given string for being valid password"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating a link to reset password", "response": "def generate_password_link(self):\n        \"\"\" Generates a link to reset password \"\"\"\n        self.password_link = self.generate_hash(50)\n        now = datetime.datetime.utcnow()\n        self.password_link_expires = now + datetime.timedelta(hours=24)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if password link expired", "response": "def password_link_expired(self, now=None):\n        \"\"\" Check if password link expired \"\"\"\n        if not now: now = datetime.datetime.utcnow()\n        return self.password_link_expires < now"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a role to the user s list of roles.", "response": "def add_role(self, role):\n        \"\"\"\n        Add role to user\n        Role must be valid and saved first, otherwise will\n        raise an exception.\n        \"\"\"\n        schema = RoleSchema()\n        ok = schema.process(role)\n        if not ok or not role.id:\n            err = 'Role must be valid and saved before adding to user'\n            raise x.UserException(err)\n\n        self.__roles.append(role)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef remove_role(self, role):\n        if role in self.__roles:\n            self.__roles.remove(role)", "response": "Remove a role from the user"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if user has role", "response": "def has_role(self, role_or_handle):\n        \"\"\" Checks if user has role \"\"\"\n        if not isinstance(role_or_handle, str):\n            return role_or_handle in self.roles\n\n        has_role = False\n        for role in self.roles:\n            if role.handle == role_or_handle:\n                has_role = True\n                break\n\n        return has_role"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef roles(self):\n        roles = list(self.__roles)\n        default_role = Role(\n            handle='user',\n            title='User role',\n            description='All registered users get this role by default'\n        )\n\n        roles.append(default_role)\n        return tuple(roles)", "response": "Return a tuple of all roles."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nchange the working directory of a new object.", "response": "def cd(*args):\n    \"\"\"\n    An argument of - is equivalent to $OLDPWD. If - is the first argument, and\n    the directory change is successful, the absolute pathname of the new\n    working directory is written to the standard output.\n    \"\"\"\n    if args[0] == \"-\":\n        try:\n            newpwd, os.environ[\"OLDPWD\"] = os.environ[\"OLDPWD\"], os.getcwd()\n        except KeyError as e:  # $OLDPWD initially not set\n            raise e\n        else:\n            os.chdir(newpwd)\n            print(newpwd)\n    else:\n        os.environ[\"OLDPWD\"] = os.getcwd()\n        os.chdir(*args)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\npush changes from the remote repository to the given branch", "response": "def push(remote='origin', branch='master'):\n    \"\"\"git push commit\"\"\"\n    print(cyan(\"Pulling changes from repo ( %s / %s)...\" % (remote, branch)))\n    local(\"git push %s %s\" % (remote, branch))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\npulls changes from a remote branch", "response": "def pull(remote='origin', branch='master'):\n    \"\"\"git pull commit\"\"\"\n    print(cyan(\"Pulling changes from repo ( %s / %s)...\" % (remote, branch)))\n    local(\"git pull %s %s\" % (remote, branch))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get(key, node=None, default=None):\n    d = AppData.get_by_key(key)\n    if d:\n        data = utils.dict_dot(d)\n        return data.get(node, default) if node else data\n    return {}", "response": "Retrieve data from the object by node_key"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the value of the key in the App Data.", "response": "def set(key, value={}, reset=False, init=False):\n    \"\"\"\n    Set data\n    :param key: A unique to set, best to use __name__\n    :param value: dict - the value to save\n    :param reset: bool - If true, it will reset the value to the current one. \n                 if False, it will just update the stored value with the current\n                 one\n    :param init: bool - If True, it will create the entry if it doesn't exits\n                 next time invoked, it will not save anything\n    :return: \n    \"\"\"\n    if not isinstance(value, dict):\n        raise ValueError(\"App Data value must be a dict\")\n\n    k = AppData.get_by_key(key, True)\n    if not k:\n        AppData.create(key=make_key(key), value=value)\n    else:\n        if init is False:\n            if reset is False:\n                nv = copy.deepcopy(value)\n                value = copy.deepcopy(k.value)\n                value.update(nv)\n            k.update(value=value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates the attributes of a match attachment.", "response": "def update(tournament, match, attachment, **params):\n    \"\"\"Update the attributes of a match attachment.\"\"\"\n    api.fetch(\n        \"PUT\",\n        \"tournaments/%s/matches/%s/attachments/%s\" % (tournament, match, attachment),\n        \"match_attachment\",\n        **params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef count_row(engine, table):\n    return engine.execute(select([func.count()]).select_from(table)).fetchone()[0]", "response": "Return number of rows in a table."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of colors that can be used in ggplot2.", "response": "def ggplot_color_wheel(n, start = 15, saturation_adjustment = None, saturation = 0.65, lightness = 1.0, prefix = ''):\n    '''Returns a list of colors with the same distributed spread as used in ggplot2.\n       A saturation of 0.5 will leave the input color at the usual saturation e.g. if start is 240 (240/360 = 0.66 = blue) and saturation is 0.5 then #0000ff will be returned.\n    '''\n    hues = range(start, start + 360, 360/n)\n    rgbcolors = ['%.2x%.2x%.2x' % (255 * hlscol[0], 255 * hlscol[1], 255 * hlscol[2]) for hlscol in [colorsys.hls_to_rgb(float(h % 360) / 360.0, saturation, lightness) for h in hues]]\n    if saturation_adjustment:\n        return [saturate_hex_color(prefix + rgbcol, saturation_adjustment) for rgbcol in rgbcolors]\n    else:\n        return rgbcolors"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of colors with the same distributed spread as used in ggplot2 but shaken up a little so that adjacent series have differing hues for larger values of n.", "response": "def get_spaced_plot_colors(n, start = 45, saturation_adjustment = 0.7, saturation = 0.65, lightness = 1.0, prefix = ''):\n    '''Returns a list of colors with the same distributed spread as used in ggplot2 (color wheel) but shaken up a little\n       so that adjacent series have differing hues for larger values of n.'''\n\n    assert (n > 0)\n    if n <= 5:\n        # For small n, the color wheel will generate colors which naturally differ\n        return ggplot_color_wheel(n, start = start, saturation_adjustment = saturation_adjustment, saturation = saturation, lightness = lightness, prefix = prefix)\n    else:\n        # For larger values of n, generate n colors spaced\n        plot_colors = ggplot_color_wheel(n, start = start, saturation_adjustment = saturation_adjustment, saturation = saturation, lightness = lightness, prefix = prefix)\n        hp = dumb_relative_half_prime(n)\n        color_wheel = [plot_colors[x % n] for x in range(0, hp * n, hp)]\n        if not len(color_wheel) == len(set(color_wheel)):\n            raise Exception('The color wheel was not generated correctly. Are {0} and {1} relatively prime?'.format(n, hp))\n        return color_wheel"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_providers(self):\n        if self.providers:\n            return self.providers\n\n        providers = dict()\n        for provider in self.config:\n            configurator = provider.lower() + '_config'\n            if not hasattr(self, configurator):\n                err = 'Provider [{}] not recognized'.format(provider)\n                raise ValueError(err)\n\n            provider_config = self.config[provider]\n            configurator = getattr(self, configurator)\n            providers[provider] = configurator(\n                id=provider_config.get('id'),\n                secret=provider_config.get('secret'),\n                scope=provider_config.get('scope'),\n                offline=provider_config.get('offline')\n            )\n\n        self.providers = providers\n        return self.providers", "response": "Get OAuth providers and their associated resources"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef token_getter(provider, token=None):\n        session_key = provider + '_token'\n        if token is None:\n            token = session.get(session_key)\n        return token", "response": "Generic token getter for all the providers"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nregisters callback to retrieve token from session", "response": "def register_token_getter(self, provider):\n        \"\"\" Register callback to retrieve token from session \"\"\"\n        app = oauth.remote_apps[provider]\n        decorator = getattr(app, 'tokengetter')\n\n        def getter(token=None):\n            return self.token_getter(provider, token)\n\n        decorator(getter)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting config dictionary for vkontakte oauth", "response": "def vkontakte_config(self, id, secret, scope=None, offline=False, **_):\n        \"\"\" Get config dictionary for vkontakte oauth \"\"\"\n        if scope is None: scope = 'email,offline'\n        if offline: scope += ',offline'\n        token_params = dict(scope=scope)\n\n        config = dict(\n            request_token_url=None,\n            access_token_url='https://oauth.vk.com/access_token',\n            authorize_url='https://oauth.vk.com/authorize',\n            base_url='https://api.vk.com/method/',\n            consumer_key=id,\n            consumer_secret=secret,\n            request_token_params=token_params\n        )\n        return config"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef instagram_config(self, id, secret, scope=None, **_):\n        scope = scope if scope else 'basic'\n        token_params = dict(scope=scope)\n\n        config = dict(\n            # request_token_url=None,\n            access_token_url='/oauth/access_token/',\n            authorize_url='/oauth/authorize/',\n            base_url='https://api.instagram.com/',\n            consumer_key=id,\n            consumer_secret=secret,\n            request_token_params=token_params\n        )\n        return config", "response": "Get config dictionary for instagram oauth"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef convert(self, chain_id, residue_id, from_scheme, to_scheme):\n        '''The API conversion function. This converts between the different residue ID schemes.'''\n\n        # At the cost of three function calls, we ignore the case of the scheme parameters to be more user-friendly.\n        from_scheme = from_scheme.lower()\n        to_scheme = to_scheme.lower()\n        assert(from_scheme in ResidueRelatrix.schemes)\n        assert(to_scheme in ResidueRelatrix.schemes)\n        return self._convert(chain_id, residue_id, from_scheme, to_scheme)", "response": "The API conversion function. This converts between the different residue ID schemes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _convert(self, chain_id, residue_id, from_scheme, to_scheme):\n        '''The actual 'private' conversion function.'''\n\n        # There are 12 valid combinations but rather than write them all out explicitly, we will use recursion, sacrificing speed for brevity\n        if from_scheme == 'rosetta':\n            atom_id = self.rosetta_to_atom_sequence_maps.get(chain_id, {})[residue_id]\n            if to_scheme == 'atom':\n                return atom_id\n            else:\n                return self._convert(chain_id, atom_id, 'atom', to_scheme)\n        if from_scheme == 'atom':\n            if to_scheme == 'rosetta':\n                return self.atom_to_rosetta_sequence_maps.get(chain_id, {})[residue_id]\n            else:\n                seqres_id = self.atom_to_seqres_sequence_maps.get(chain_id, {})[residue_id]\n                if to_scheme == 'seqres':\n                    return seqres_id\n                return self.convert(chain_id, seqres_id, 'seqres', to_scheme)\n        if from_scheme == 'seqres':\n            if to_scheme == 'uniparc':\n                return self.seqres_to_uniparc_sequence_maps.get(chain_id, {})[residue_id]\n            else:\n                atom_id = self.seqres_to_atom_sequence_maps.get(chain_id, {})[residue_id]\n                if to_scheme == 'atom':\n                    return atom_id\n                return self.convert(chain_id, atom_id, 'atom', to_scheme)\n        if from_scheme == 'uniparc':\n            seqres_id = self.uniparc_to_seqres_sequence_maps.get(chain_id, {})[residue_id]\n            if to_scheme == 'seqres':\n                return seqres_id\n            else:\n                return self._convert(chain_id, seqres_id, 'seqres', to_scheme)\n\n        raise Exception(\"We should never reach this line.\")", "response": "The actual private conversion function."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef convert_from_rosetta(self, residue_id, to_scheme):\n        '''A simpler conversion function to convert from Rosetta numbering without requiring the chain identifier.'''\n\n        assert(type(residue_id) == types.IntType)\n\n        # Find the chain_id associated with the residue_id\n        # Scan *all* sequences without breaking out to make sure that we do not have any duplicate maps\n        chain_id = None\n        for c, sequence in self.rosetta_sequences.iteritems():\n            for id, r in sequence:\n                if r.ResidueID == residue_id:\n                    assert(chain_id == None)\n                    chain_id = c\n\n        if chain_id:\n            return self.convert(chain_id, residue_id, 'rosetta', to_scheme)\n        else:\n            return None", "response": "A simpler conversion function to convert from Rosetta numbering without requiring the chain identifier."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _validate_fasta_vs_seqres(self):\n        '''Check that the FASTA and SEQRES sequences agree (they sometimes differ)'''\n        pdb_id = self.pdb_id\n        for chain_id, sequence in self.pdb.seqres_sequences.iteritems():\n            if str(sequence) != self.FASTA[pdb_id][chain_id]:\n                if self.pdb_id in use_seqres_sequence_for_fasta_sequence:\n                    self.FASTA.replace_sequence(self.pdb_id, chain_id, str(sequence))\n                elif self.pdb_id in use_fasta_sequence_for_seqres_sequence:\n                    self.pdb.seqres_sequences[chain_id] = Sequence.from_sequence(chain_id, self.FASTA[pdb_id][chain_id], self.sequence_types[chain_id])\n                    sequence = self.FASTA[pdb_id][chain_id]\n                if str(sequence) != self.FASTA[pdb_id][chain_id]:\n                    raise colortext.Exception(\"The SEQRES and FASTA sequences disagree for chain %s in %s. This can happen but special-case handling (use_seqres_sequence_for_fasta_sequence) should be added to the file containing the %s class.\" % (chain_id, pdb_id, self.__class__.__name__))", "response": "Check that the FASTA and SEQRES sequences agree (th sometimes differ )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmaking sure the domains and ranges of the SequenceMaps match the Sequences.", "response": "def _validate_mapping_signature(self):\n        '''Make sure the domains and ranges of the SequenceMaps match the Sequences.'''\n\n        # rosetta_to_atom_sequence_maps\n        for chain_id, sequence_map in self.rosetta_to_atom_sequence_maps.iteritems():\n            # Check that all Rosetta residues have a mapping\n            assert(sorted(sequence_map.keys()) == sorted(self.rosetta_sequences[chain_id].ids()))\n\n            # Check that all ATOM residues in the mapping exist and that the mapping is injective\n            rng = set(sequence_map.values())\n            atom_residue_ids = set(self.atom_sequences[chain_id].ids())\n            assert(rng.intersection(atom_residue_ids) == rng)\n            assert(len(rng) == len(sequence_map.values()))\n\n        # atom_to_seqres_sequence_maps\n        for chain_id, sequence_map in self.atom_to_seqres_sequence_maps.iteritems():\n            # Check that all ATOM residues have a mapping\n            #print(sorted(sequence_map.keys()))\n            #print(sorted(self.atom_sequences[chain_id].ids()))\n            assert(sorted(sequence_map.keys()) == sorted(self.atom_sequences[chain_id].ids()))\n\n            # Check that all SEQRES residues in the mapping exist and that the mapping is injective\n            rng = set(sequence_map.values())\n            seqres_residue_ids = set(self.seqres_sequences[chain_id].ids())\n            assert(rng.intersection(seqres_residue_ids) == rng)\n            assert(len(rng) == len(sequence_map.values()))\n\n        # seqres_to_uniparc_sequence_maps\n        for chain_id, sequence_map in self.seqres_to_uniparc_sequence_maps.iteritems():\n            # Check that acceptable_sequence_percentage_match% of all SEQRES residues have a mapping (there may have been\n            # insertions or bad mismatches i.e. low BLOSUM62/PAM250 scores). I chose 80% arbitrarily but this can be overridden\n            #  with the acceptable_sequence_percentage_match argument to the constructor.\n            if self.sequence_types[chain_id] == 'Protein' or self.sequence_types[chain_id] == 'Protein skeleton':\n                if sequence_map:\n                    mapped_SEQRES_residues = set(sequence_map.keys())\n                    all_SEQRES_residues = set(self.seqres_sequences[chain_id].ids())\n                    if len(all_SEQRES_residues) >= 20:\n                        match_percentage = 100.0 * (float(len(mapped_SEQRES_residues))/float((len(all_SEQRES_residues))))\n                        if not (self.acceptable_sequence_percentage_match <= match_percentage <= 100.0):\n                            if not set(list(str(self.seqres_sequences[chain_id]))) == set(['X']):\n                                # Skip cases where all residues are unknown e.g. 1DEQ, chain M\n                                raise Exception(\"Chain %s in %s only had a match percentage of %0.2f%%\" % (chain_id, self.pdb_id, match_percentage))\n\n            # Check that all UniParc residues in the mapping exist and that the mapping is injective\n            if self.pdb_chain_to_uniparc_chain_mapping.get(chain_id):\n                rng = set([v[1] for v in sequence_map.values()])\n                uniparc_chain_id = self.pdb_chain_to_uniparc_chain_mapping[chain_id]\n                uniparc_residue_ids = set(self.uniparc_sequences[uniparc_chain_id].ids())\n                assert(rng.intersection(uniparc_residue_ids) == rng)\n                if len(rng) != len(sequence_map.values()):\n                    rng_vals = set()\n                    for x in sequence_map.values():\n                        if x[1] in rng_vals:\n                            err_msg = ['The SEQRES to UniParc map is not injective for %s, chain %s; the element %s occurs more than once in the range.' % (self.pdb_id, chain_id, str(x))]\n\n                            err_msg.append(colortext.make('The seqres_to_uniparc_sequence_maps mapping is:', color = 'green'))\n                            for k, v in sequence_map.map.iteritems():\n                                err_msg.append(' %s -> %s' % (str(k).ljust(7), str(v).ljust(20)))\n\n                            err_msg.append(colortext.make('The clustal_seqres_to_uniparc_sequence_maps mapping is:', color = 'green'))\n                            for k, v in self.clustal_seqres_to_uniparc_sequence_maps[chain_id].map.iteritems():\n                                err_msg.append(' %s -> %s' % (str(k).ljust(7), str(v).ljust(20)))\n\n                            err_msg.append(colortext.make('The sifts_seqres_to_uniparc_sequence_maps mapping is:', color = 'green'))\n                            for k, v in self.sifts_seqres_to_uniparc_sequence_maps[chain_id].map.iteritems():\n                                err_msg.append(' %s -> %s' % (str(k).ljust(7), str(v).ljust(20)))\n\n                            raise Exception('\\n'.join(err_msg))\n                        rng_vals.add(x[1])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _validate_id_types(self):\n        '''Check that the ID types are integers for Rosetta, SEQRES, and UniParc sequences and 6-character PDB IDs for the ATOM sequences.'''\n\n        for sequences in [self.uniparc_sequences, self.fasta_sequences, self.seqres_sequences, self.rosetta_sequences]:\n            for chain_id, sequence in sequences.iteritems():\n                sequence_id_types = set(map(type, sequence.ids()))\n                if sequence_id_types:\n                    assert(len(sequence_id_types) == 1)\n                    assert(sequence_id_types.pop() == types.IntType)\n\n        for chain_id, sequence in self.atom_sequences.iteritems():\n            sequence_id_types = set(map(type, sequence.ids()))\n            assert(len(sequence_id_types) == 1)\n            sequence_id_type = sequence_id_types.pop()\n            assert(sequence_id_type == types.StringType or sequence_id_type == types.UnicodeType)", "response": "Check that the ID types are integers for Rosetta SEQRES and UniParc sequences and 6 - character PDB IDs for the ATOM sequences."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmakes sure all the residue types map through translation.", "response": "def _validate_residue_types(self):\n        '''Make sure all the residue types map through translation.'''\n\n        for chain_id, sequence_map in self.rosetta_to_atom_sequence_maps.iteritems():\n            rosetta_sequence = self.rosetta_sequences[chain_id]\n            atom_sequence = self.atom_sequences[chain_id]\n            for rosetta_id, atom_id, _ in sequence_map:\n                assert(rosetta_sequence[rosetta_id].ResidueAA == atom_sequence[atom_id].ResidueAA)\n\n        for chain_id, sequence_map in self.atom_to_seqres_sequence_maps.iteritems():\n            atom_sequence = self.atom_sequences[chain_id]\n            seqres_sequence = self.seqres_sequences[chain_id]\n            for atom_id, seqres_id, _ in sorted(sequence_map):\n                assert(atom_sequence[atom_id].ResidueAA == seqres_sequence[seqres_id].ResidueAA)\n\n        for chain_id, sequence_map in self.seqres_to_uniparc_sequence_maps.iteritems():\n            if self.pdb_chain_to_uniparc_chain_mapping.get(chain_id):\n                seqres_sequence = self.seqres_sequences[chain_id]\n                uniparc_sequence = self.uniparc_sequences[self.pdb_chain_to_uniparc_chain_mapping[chain_id]]\n                for seqres_id, uniparc_id_resid_pair, substitution_match in sequence_map:\n                    uniparc_id = uniparc_id_resid_pair[1]\n                    # Some of the matches may not be identical but all the '*' Clustal Omega matches should be identical\n                    if substitution_match and substitution_match.clustal == 1:\n                        assert(seqres_sequence[seqres_id].ResidueAA == uniparc_sequence[uniparc_id].ResidueAA)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates the inverse mappings for the current class.", "response": "def _create_inverse_maps(self):\n        '''Create the inverse mappings (UniParc -> SEQRES -> ATOM -> Rosetta).'''\n\n        # We have already determined that the inverse maps are well-defined (the normal maps are injective). The inverse maps will be partial maps in general.\n\n        self.atom_to_rosetta_sequence_maps = {}\n        for chain_id, sequence_map in self.rosetta_to_atom_sequence_maps.iteritems():\n            s = SequenceMap()\n            for k, v, substitution_match in sequence_map:\n                s.add(v, k, substitution_match)\n            self.atom_to_rosetta_sequence_maps[chain_id] = s\n\n        self.seqres_to_atom_sequence_maps = {}\n        for chain_id, sequence_map in self.atom_to_seqres_sequence_maps.iteritems():\n            s = SequenceMap()\n            for k, v, substitution_match in sequence_map:\n                s.add(v, k, substitution_match)\n            self.seqres_to_atom_sequence_maps[chain_id] = s\n\n        # This map uses PDB chain IDs as PDB chains may map to zero or one UniParc IDs whereas UniParc IDs may map to many PDB chains\n        self.uniparc_to_seqres_sequence_maps = {}\n        for chain_id, sequence_map in self.seqres_to_uniparc_sequence_maps.iteritems():\n            s = UniParcPDBSequenceMap()\n            for k, v, substitution_match in sequence_map:\n                s.add(v, k, substitution_match)\n            self.uniparc_to_seqres_sequence_maps[chain_id] = s"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _create_sequence_maps(self):\n        '''Get all of the SequenceMaps - Rosetta->ATOM, ATOM->SEQRES/FASTA, SEQRES->UniParc.'''\n\n        if self.sifts:\n            self.sifts_atom_to_seqres_sequence_maps = self.sifts.atom_to_seqres_sequence_maps\n            self.sifts_seqres_to_uniparc_sequence_maps = self.sifts.seqres_to_uniparc_sequence_maps\n            self.sifts_atom_to_uniparc_sequence_maps = self.sifts.atom_to_uniparc_sequence_maps\n            if self.pdb_id in pdbs_with_do_not_use_SIFTS_for_these_chains:\n                for chain_id in self.sifts_atom_to_seqres_sequence_maps.keys() + self.sifts_seqres_to_uniparc_sequence_maps.keys() + self.sifts_atom_to_uniparc_sequence_maps.keys():\n                    if (self.pdb_id, chain_id) in do_not_use_SIFTS_for_these_chains:\n                        self.sifts_atom_to_seqres_sequence_maps[chain_id] = SequenceMap()\n                        self.sifts_seqres_to_uniparc_sequence_maps = SequenceMap()\n                        self.sifts_atom_to_uniparc_sequence_maps = SequenceMap()\n\n        if self.pdb_to_rosetta_residue_map_error:\n            self.rosetta_to_atom_sequence_maps = {}\n            for c in self.atom_sequences.keys():\n                self.rosetta_to_atom_sequence_maps[c] = SequenceMap()\n        else:\n            self.rosetta_to_atom_sequence_maps = self.pdb.rosetta_to_atom_sequence_maps\n\n        # If we removed atoms from the PDB file, we need to remove them from the maps so that our validations hold later on\n        self.pdbml_atom_to_seqres_sequence_maps = self.pdbml.atom_to_seqres_sequence_maps\n        if self.pdb_id in ROSETTA_HACKS_residues_to_remove:\n            for residue_to_remove in ROSETTA_HACKS_residues_to_remove[self.pdb_id]:\n                chain_id = residue_to_remove[0]\n                self.pdbml_atom_to_seqres_sequence_maps[chain_id].remove(residue_to_remove)\n                #if self.sifts:\n                #    self.sifts_atom_to_seqres_sequence_maps[chain_id].remove(residue_to_remove)\n\n        if self.pdb_id not in do_not_use_the_sequence_aligner:\n            self.clustal_seqres_to_uniparc_sequence_maps = self.PDB_UniParc_SA.seqres_to_uniparc_sequence_maps", "response": "Create all of the SequenceMaps - Rosetta - ATOM - FASTA - SEQRES - FASTA - UNIPARC."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmerge the SIFTS atom to seqres sequence maps.", "response": "def _merge_sifts_maps(self):\n        ''' Make sure that the pdbml_atom_to_seqres_sequence_maps and clustal_seqres_to_uniparc_sequence_maps agree with SIFTS and merge the maps.\n                SIFTS may have more entries since we discard PDB residues which break Rosetta.\n                SIFTS may have less entries for some cases e.g. 1AR1, chain C where SIFTS does not map ATOMs 99-118.\n                SIFTS does not seem to contain ATOM to SEQRES mappings for (at least some) DNA chains e.g. 1APL, chain A\n            Because of these cases, we just assert that the overlap agrees so that we can perform a gluing of maps.'''\n\n        if self.pdb_id in do_not_use_the_sequence_aligner:\n            assert(self.sifts)\n            self.atom_to_seqres_sequence_maps = self.sifts_atom_to_seqres_sequence_maps\n            self.seqres_to_uniparc_sequence_maps = self.sifts_seqres_to_uniparc_sequence_maps\n        elif self.sifts:\n            self.atom_to_seqres_sequence_maps = {}\n            self.seqres_to_uniparc_sequence_maps = {}\n            for c, seqmap in sorted(self.pdbml_atom_to_seqres_sequence_maps.iteritems()):\n                if self.sequence_types[c] == 'Protein' or self.sequence_types[c] == 'Protein skeleton':\n                    try:\n                        if self.sifts_atom_to_seqres_sequence_maps.get(c):\n                            assert(self.pdbml_atom_to_seqres_sequence_maps[c].matches(self.sifts_atom_to_seqres_sequence_maps[c]))\n                            self.atom_to_seqres_sequence_maps[c] = self.pdbml_atom_to_seqres_sequence_maps[c] + self.sifts_atom_to_seqres_sequence_maps[c]\n                        else:\n                            self.atom_to_seqres_sequence_maps[c] = self.pdbml_atom_to_seqres_sequence_maps[c]\n                    except Exception, e:\n                        raise colortext.Exception(\"Mapping cross-validation failed checking atom to seqres sequence maps between PDBML and SIFTS in %s, chain %s: %s\" % (self.pdb_id, c, str(e)))\n                else:\n                    self.atom_to_seqres_sequence_maps[c] = seqmap\n\n            for c, seqmap in sorted(self.clustal_seqres_to_uniparc_sequence_maps.iteritems()):\n                if self.sequence_types[c] == 'Protein' or self.sequence_types[c] == 'Protein skeleton':\n                    if (self.pdb_id, c) in use_SIFTS_match_for_seqres_sequence:\n                        #assert(seqres_sequence[seqres_id].ResidueAA == uniparc_sequence[uniparc_id].ResidueAA)\n                        if (self.pdb_id, c) not in known_bad_clustal_to_sifts_mappings:\n                            # Flag cases for manual inspection\n                            assert(self.clustal_seqres_to_uniparc_sequence_maps[c].keys() == self.sifts_seqres_to_uniparc_sequence_maps[c].keys())\n                        for k in self.clustal_seqres_to_uniparc_sequence_maps[c].keys():\n                            v_1 = self.clustal_seqres_to_uniparc_sequence_maps[c][k]\n                            v_2 = self.sifts_seqres_to_uniparc_sequence_maps[c][k]\n\n                            if (self.pdb_id, c) not in known_bad_clustal_to_sifts_mappings and v_2:\n                                # Make sure the UniParc IDs agree\n                                assert(v_1[0] == v_2[0])\n\n                            if (self.pdb_id, c) not in known_bad_clustal_to_sifts_mappings:\n                                # Make sure the residue types agree\n                                assert(self.uniparc_sequences[v_1[0]][v_1[1]].ResidueAA == self.uniparc_sequences[v_1[0]][v_2[1]].ResidueAA)\n\n                                # Copy the substitution scores over. Since the residue types agree, this is valid\n                                self.sifts_seqres_to_uniparc_sequence_maps[c].substitution_scores[k] = self.clustal_seqres_to_uniparc_sequence_maps[c].substitution_scores[k]\n\n                        self.clustal_seqres_to_uniparc_sequence_maps[c] = self.sifts_seqres_to_uniparc_sequence_maps[c]\n\n                    try:\n                        if self.sifts_seqres_to_uniparc_sequence_maps.get(c):\n                            if not self.clustal_seqres_to_uniparc_sequence_maps[c].matches(self.sifts_seqres_to_uniparc_sequence_maps[c]):\n                                mismatched_keys = self.clustal_seqres_to_uniparc_sequence_maps[c].get_mismatches(self.sifts_seqres_to_uniparc_sequence_maps[c])\n                                raise Exception(\"self.clustal_seqres_to_uniparc_sequence_maps[c].matches(self.sifts_seqres_to_uniparc_sequence_maps[c])\")\n                            self.seqres_to_uniparc_sequence_maps[c] = self.clustal_seqres_to_uniparc_sequence_maps[c] + self.sifts_seqres_to_uniparc_sequence_maps[c]\n                        else:\n                            self.seqres_to_uniparc_sequence_maps[c] = self.clustal_seqres_to_uniparc_sequence_maps[c]\n                    except Exception, e:\n                        colortext.warning(traceback.format_exc())\n                        colortext.error(str(e))\n                        raise colortext.Exception(\"Mapping cross-validation failed checking atom to seqres sequence maps between Clustal and SIFTS in %s, chain %s.\" % (self.pdb_id, c))\n                else:\n                    self.clustal_seqres_to_uniparc_sequence_maps[c] = seqmap\n        else:\n            self.atom_to_seqres_sequence_maps = self.pdbml_atom_to_seqres_sequence_maps\n            self.seqres_to_uniparc_sequence_maps = self.clustal_seqres_to_uniparc_sequence_maps"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\npruning the SIFTS maps so that they have elements in their respective sequence maps.", "response": "def _prune_maps_to_sequences(self):\n        ''' When we merge the SIFTS maps, we can extend the sequence maps such that they have elements in their domain that we removed\n            from the sequence e.g. 1A2P, residue 'B   3 ' is removed because Rosetta barfs on it. Here, we prune the maps so that their\n            domains do not have elements that were removed from sequences.'''\n\n        for c, seq in self.atom_sequences.iteritems():\n            res_ids = [r[0] for r in seq]\n            for_removal = []\n            for k, _, _ in self.atom_to_seqres_sequence_maps[c]:\n                if k not in res_ids:\n                    for_removal.append(k)\n            for res_id in for_removal:\n                self.atom_to_seqres_sequence_maps[c].remove(res_id)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets all of the Sequences - Rosetta ATOM SEQRES FASTA UniParc.", "response": "def _create_sequences(self):\n        '''Get all of the Sequences - Rosetta, ATOM, SEQRES, FASTA, UniParc.'''\n\n        # Create the Rosetta sequences and the maps from the Rosetta sequences to the ATOM sequences\n        try:\n            self.pdb.construct_pdb_to_rosetta_residue_map(self.rosetta_scripts_path, rosetta_database_path = self.rosetta_database_path, cache_dir = self.cache_dir)\n        except PDBMissingMainchainAtomsException:\n            self.pdb_to_rosetta_residue_map_error = True\n\n        # Get all the Sequences\n        if self.pdb_id not in do_not_use_the_sequence_aligner:\n            self.uniparc_sequences = self.PDB_UniParc_SA.uniparc_sequences\n        else:\n            self.uniparc_sequences = self.sifts.get_uniparc_sequences()\n\n        self.fasta_sequences = self.FASTA.get_sequences(self.pdb_id)\n        self.seqres_sequences = self.pdb.seqres_sequences\n        self.atom_sequences = self.pdb.atom_sequences\n\n        if self.pdb_to_rosetta_residue_map_error:\n            self.rosetta_sequences = {}\n            for c in self.atom_sequences.keys():\n                self.rosetta_sequences[c] = Sequence()\n        else:\n            self.rosetta_sequences = self.pdb.rosetta_sequences\n\n        # Update the chain types for the UniParc sequences\n        uniparc_pdb_chain_mapping = {}\n        if self.pdb_id not in do_not_use_the_sequence_aligner:\n            for pdb_chain_id, matches in self.PDB_UniParc_SA.clustal_matches.iteritems():\n                if matches:\n                    # we are not guaranteed to have a match e.g. the short chain J in 1A2C, chimeras, etc.\n                    uniparc_chain_id = matches.keys()[0]\n                    assert(len(matches) == 1)\n                    uniparc_pdb_chain_mapping[uniparc_chain_id] = uniparc_pdb_chain_mapping.get(uniparc_chain_id, [])\n                    uniparc_pdb_chain_mapping[uniparc_chain_id].append(pdb_chain_id)\n        else:\n            for pdb_chain_id, uniparc_chain_ids in self.sifts.get_pdb_chain_to_uniparc_id_map().iteritems():\n                for uniparc_chain_id in uniparc_chain_ids:\n                    uniparc_pdb_chain_mapping[uniparc_chain_id] = uniparc_pdb_chain_mapping.get(uniparc_chain_id, [])\n                    uniparc_pdb_chain_mapping[uniparc_chain_id].append(pdb_chain_id)\n\n        for uniparc_chain_id, pdb_chain_ids in uniparc_pdb_chain_mapping.iteritems():\n            sequence_type = set([self.seqres_sequences[p].sequence_type for p in pdb_chain_ids])\n            assert(len(sequence_type) == 1)\n            sequence_type = sequence_type.pop()\n            assert(self.uniparc_sequences[uniparc_chain_id].sequence_type == None)\n            self.uniparc_sequences[uniparc_chain_id].set_type(sequence_type)\n            for p in pdb_chain_ids:\n                self.pdb_chain_to_uniparc_chain_mapping[p] = uniparc_chain_id\n\n        # Update the chain types for the FASTA sequences\n        for chain_id, sequence in self.seqres_sequences.iteritems():\n            self.fasta_sequences[chain_id].set_type(sequence.sequence_type)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsearch the index for documents that belong to this class.", "response": "def search(cls,\n               query_string,\n               options=None,\n               enable_facet_discovery=False,\n               return_facets=None,\n               facet_options=None,\n               facet_refinements=None,\n               deadline=None,\n               **kwargs):\n        \"\"\"\n        Searches the index. Conveniently searches only for documents that belong to instances of this class.\n\n        :param query_string: The query to match against documents in the index. See search.Query() for details.\n        :param options: A QueryOptions describing post-processing of search results.\n        :param enable_facet_discovery: discovery top relevent facets to this search query and return them.\n        :param return_facets: An iterable of FacetRequest or basestring as facet name to\n                return specific facet with the result.\n        :param facet_options: A FacetOption describing processing of facets.\n        :param facet_refinements: An iterable of FacetRefinement objects or refinement\n                        token strings used to filter out search results based on a facet value.\n                        refinements for different facets will be conjunction and refinements for\n                        the same facet will be disjunction.\n        :param deadline: Deadline for RPC call in seconds; if None use the default.\n        :param kwargs: A SearchResults containing a list of documents matched, number returned\n              and number matched by the query.\n        :return: A SearchResults containing a list of documents matched, number returned\n              and number matched by the query.\n        :raises: QueryError: If the query string is not parseable.\n              TypeError: If any of the parameters have invalid types, or an unknown\n                attribute is passed.\n              ValueError: If any of the parameters have invalid values (e.g., a\n                negative deadline).\n        \"\"\"\n        search_class = cls.search_get_class_names()[-1]\n        query_string += ' ' + 'class_name:%s' % (search_class,)\n\n        q = search.Query(\n            query_string=query_string,\n            options=options,\n            enable_facet_discovery=enable_facet_discovery,\n            return_facets=return_facets,\n            facet_options=facet_options,\n            facet_refinements=facet_refinements\n            )\n        index = cls.search_get_index()\n        return index.search(q, deadline=deadline, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates the search index for this instance. This happens automatically on put.", "response": "def search_update_index(self):\n        \"\"\"\n        Updates the search index for this instance.\n\n        This happens automatically on put.\n        \"\"\"\n        doc_id = self.search_get_document_id(self.key)\n\n        fields = [search.AtomField('class_name', name) for name in self.search_get_class_names()]\n\n        index = self.search_get_index()\n\n        if self.searchable_fields is None:\n            searchable_fields = []\n\n            for field, prop in self._properties.items():\n                if field == 'class':\n                    continue\n                for class_, field_type in SEARCHABLE_PROPERTY_TYPES.items():\n                    if isinstance(prop, class_):\n                        searchable_fields.append(field)\n        else:\n            searchable_fields = self.searchable_fields\n\n        for f in set(searchable_fields):\n            prop = self._properties[f]\n            value = getattr(self, f)\n            field = None\n            field_found = False\n            for class_, field_type in SEARCHABLE_PROPERTY_TYPES.items():\n                if isinstance(prop, class_):\n                    field_found = True\n                    if value is not None:\n                        if isinstance(value, list) or isinstance(value, tuple) or isinstance(value, set):\n                            for v in value:\n                                field = field_type(name=f, value=v)\n                        elif isinstance(value, ndb.Key):\n                            field = field_type(name=f, value=value.urlsafe())\n                        else:\n                            field = field_type(name=f, value=value)\n            if not field_found:\n                raise ValueError('Cannot find field type for %r on %r' % (prop, self.__class__))\n\n            if field is not None:\n                fields.append(field)\n\n        document = search.Document(doc_id, fields=fields)\n        index.put(document)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef search_get_class_names(cls):\n        if hasattr(cls, '_class_key'):\n            class_names = []\n            for n in cls._class_key():\n                class_names.append(n)\n            return class_names\n        else:\n            return [cls.__name__]", "response": "Returns class names for use in document indexing."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn an instance of cls from a urlsafe string.", "response": "def from_urlsafe(cls, urlsafe):\n        \"\"\"\n        Returns an instance of the model from a urlsafe string.\n\n        :param urlsafe: urlsafe key\n        :return: Instance of cls\n        \"\"\"\n        try:\n            key = ndb.Key(urlsafe=urlsafe)\n        except:\n            return None\n        obj = key.get()\n        if obj and isinstance(obj, cls):\n            return obj"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_from_search_doc(cls, doc_id):\n        # If the document was passed instead of the doc_id, get the document.\n        if hasattr(doc_id, 'doc_id'):\n            doc_id = doc_id.doc_id\n        return cls.from_urlsafe(doc_id)", "response": "Returns an instance of the model from a search document id."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _pre_delete_hook(cls, key):\n        if cls.searching_enabled:\n            doc_id = cls.search_get_document_id(key)\n            index = cls.search_get_index()\n            index.delete(doc_id)", "response": "Remove instance from index."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef process_answer(self, user, item, asked, answered, time, answer, response_time, guess, **kwargs):\n        pass", "response": "This method is used during the answer streaming and is called after the answer streaming is called for each answer."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sudoers(self, enable):\n        f_sudoers = \"/isan/vdc_1/virtual-instance/guestshell+/rootfs/etc/sudoers\"\n\n        if enable is True:\n            sed_cmd = r\" 's/\\(^Defaults *requiretty\\)/#\\1/g' \"\n        elif enable is False:\n            sed_cmd = r\" 's/^#\\(Defaults *requiretty\\)/\\1/g' \"\n        else:\n            raise RuntimeError('enable must be True or False')\n\n        self.guestshell(\"run bash sudo sed -i\" + sed_cmd + f_sudoers)", "response": "This method is used to enable sudo commands running\n            through the guestshell virtual service."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the current resource allocations", "response": "def _get_sz_info(self):\n        \"\"\"\n        Obtains the current resource allocations, assumes that the\n        guestshell is in an 'Activated' state\n        \"\"\"\n        if 'None' == self._state:\n            return None\n\n        cmd = 'show virtual-service detail name guestshell+'\n        got = self.cli(cmd)\n        got = got['TABLE_detail']['ROW_detail']\n\n        sz_cpu = int(got['cpu_reservation'])\n        sz_disk = int(got['disk_reservation'])\n        sz_memory = int(got['memory_reservation'])\n\n        self.sz_has = _guestshell.Resources(\n            cpu=sz_cpu, memory=sz_memory, disk=sz_disk)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fractal_dimension(image):\n    '''Estimates the fractal dimension of an image with box counting.\n    Counts pixels with value 0 as empty and everything else as non-empty.\n    Input image has to be grayscale.\n\n    See, e.g `Wikipedia <https://en.wikipedia.org/wiki/Fractal_dimension>`_.\n\n    :param image: numpy.ndarray\n    :returns: estimation of fractal dimension\n    :rtype: float\n    '''\n    pixels = []\n    for i in range(image.shape[0]):\n        for j in range(image.shape[1]):\n            if image[i, j] > 0:\n                pixels.append((i, j))\n    lx = image.shape[1]\n    ly = image.shape[0]\n    pixels = np.array(pixels)\n    if len(pixels) < 2:\n        return 0\n    scales = np.logspace(1, 4, num=20, endpoint=False, base=2)\n    Ns = []\n    for scale in scales:\n        H, edges = np.histogramdd(pixels,\n                                  bins=(np.arange(0, lx, scale),\n                                        np.arange(0, ly, scale)))\n        H_sum = np.sum(H > 0)\n        if H_sum == 0:\n            H_sum = 1\n        Ns.append(H_sum)\n\n    coeffs = np.polyfit(np.log(scales), np.log(Ns), 1)\n    hausdorff_dim = -coeffs[0]\n\n    return hausdorff_dim", "response": "Estimates the fractal dimension of an image with box counting."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef channel_portion(image, channel):\n    '''Estimates the amount of a color relative to other colors.\n\n    :param image: numpy.ndarray\n    :param channel: int\n    :returns: portion of a channel in an image\n    :rtype: float\n    '''\n\n    # Separate color channels\n    rgb = []\n    for i in range(3):\n        rgb.append(image[:, :, i].astype(int))\n    ch = rgb.pop(channel)\n\n    relative_values = ch - np.sum(rgb, axis=0) / 2\n    relative_values = np.maximum(np.zeros(ch.shape), relative_values)\n\n    return float(np.average(relative_values) / 255)", "response": "Estimates the amount of a color relative to other colors."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalculating the average intensity of the pixels in an image.", "response": "def intensity(image):\n    '''Calculates the average intensity of the pixels in an image.\n    Accepts both RGB and grayscale images.\n\n    :param image: numpy.ndarray\n    :returns: image intensity\n    :rtype: float\n    '''\n    if len(image.shape) > 2:\n        # Convert to grayscale\n        image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) / 255\n    elif issubclass(image.dtype.type, np.integer):\n        image /= 255\n    return float(np.sum(image) / np.prod(image.shape))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sliding_window(sequence, win_size, step=1):\n    \n    # Verify the inputs\n    try:\n        it = iter(sequence)\n    except TypeError:\n        raise ValueError(\"sequence must be iterable.\")\n    if not isinstance(win_size, int):\n        raise ValueError(\"type(win_size) must be int.\")\n    if not isinstance(step, int):\n        raise ValueError(\"type(step) must be int.\")\n    if step > win_size:\n        raise ValueError(\"step must not be larger than win_size.\")\n    if win_size > len(sequence):\n        raise ValueError(\"win_size must not be larger than sequence length.\")\n    \n    # Pre-compute number of chunks to emit\n    num_chunks = ((len(sequence) - win_size) / step) + 1\n    \n    # Do the work\n    for i in range(0, num_chunks * step, step):\n        yield sequence[i:i+win_size]", "response": "Returns a generator that will iterate through the defined chunks of input sequence."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a compiled regular expression that will match any base at that position.", "response": "def dna_to_re(seq):\n    \"\"\"\n    Return a compiled regular expression that will match anything described by \n    the input sequence.  For example, a sequence that contains a 'N' matched \n    any base at that position.\n    \"\"\"\n\n    seq = seq.replace('K', '[GT]')\n    seq = seq.replace('M', '[AC]')\n    seq = seq.replace('R', '[AG]')\n    seq = seq.replace('Y', '[CT]')\n    seq = seq.replace('S', '[CG]')\n    seq = seq.replace('W', '[AT]')\n    seq = seq.replace('B', '[CGT]')\n    seq = seq.replace('V', '[ACG]')\n    seq = seq.replace('H', '[ACT]')\n    seq = seq.replace('D', '[AGT]')\n    seq = seq.replace('X', '[GATC]')\n    seq = seq.replace('N', '[GATC]')\n\n    return re.compile(seq)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nhighlight all instances of subseq in seq by making them uppercase and everything else lowercase.", "response": "def case_highlight(seq, subseq):\n    \"\"\"\n    Highlights all instances of subseq in seq by making them uppercase and \n    everything else lowercase.\n    \"\"\"\n    return re.subs(subseq.lower(), subseq.upper(), seq.lower())"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef index_relations(sender, pid_type, json=None,\n                    record=None, index=None, **kwargs):\n    \"\"\"Add relations to the indexed record.\"\"\"\n    if not json:\n        json = {}\n    pid = PersistentIdentifier.query.filter(\n        PersistentIdentifier.object_uuid == record.id,\n        PersistentIdentifier.pid_type == pid_type,\n    ).one_or_none()\n    relations = None\n    if pid:\n        relations = serialize_relations(pid)\n        if relations:\n            json['relations'] = relations\n    return json", "response": "Add relations to the indexed record."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nindex siblings of the passed pid.", "response": "def index_siblings(pid, include_pid=False, children=None,\n                   neighbors_eager=False, eager=False, with_deposits=True):\n    \"\"\"Send sibling records of the passed pid for indexing.\n\n    Note: By default does not index the 'pid' itself,\n          only zero or more siblings.\n\n    :param pid: PID (recid) of whose siblings are to be indexed.\n    :param children: Overrides children with a fixed list of PID.\n        Children should contain the 'pid' itself if 'neighbors_eager' is to\n        be used, otherwise the last child is treated as the only neighbor.\n    :param eager: Index all siblings immediately.\n    :param include_pid: If True, will index also the provided 'pid'\n           (default:False).\n    :param neighbors_eager: Index the neighboring PIDs w.r.t. 'pid'\n        immediately, and the rest with a bulk_index (default: False)\n    :param with_deposits: Reindex also corresponding record's deposits.\n    \"\"\"\n    assert not (neighbors_eager and eager), \\\n        \"\"\"Only one of the 'eager' and 'neighbors_eager' flags\n        can be set to True, not both\"\"\"\n    if children is None:\n        parent_pid = PIDNodeVersioning(pid=pid).parents.first()\n        children = PIDNodeVersioning(pid=parent_pid).children.all()\n    objid = str(pid.object_uuid)\n    children = [str(p.object_uuid) for p in children]\n\n    idx = children.index(objid) if objid in children else len(children)\n\n    # Split children (which can include the pid) into left and right siblings\n    # If 'pid' is not in children, idx is the length of list, so 'left'\n    # will be all children, and 'right' will be an empty list\n    # [X X X] X [X X X]\n\n    if include_pid:\n        # [X X X X] [X X X]  Includes pid to the 'left' set\n        left = children[:idx + 1]\n    else:\n        # [X X X] X [X X X]\n        left = children[:idx]\n    right = children[idx + 1:]\n\n    if eager:\n        eager_uuids = left + right\n        bulk_uuids = []\n    elif neighbors_eager:\n        # neighbors are last of 'left' and first or 'right' siblings\n        # X X [X] X [X] X X\n        eager_uuids = left[-1:] + right[:1]\n        # all of the siblings, except the neighbours\n        # [X X] X X X [X X]\n        bulk_uuids = left[:-1] + right[1:]\n    else:\n        eager_uuids = []\n        bulk_uuids = left + right\n\n    def get_dep_uuids(rec_uuids):\n        \"\"\"Get corresponding deposit UUIDs from record's UUIDs.\"\"\"\n        return [str(PersistentIdentifier.get(\n                    'depid',\n                    Record.get_record(id_)['_deposit']['id']).object_uuid)\n                for id_ in rec_uuids]\n\n    if with_deposits:\n        eager_uuids += get_dep_uuids(eager_uuids)\n        bulk_uuids += get_dep_uuids(bulk_uuids)\n\n    for id_ in eager_uuids:\n        RecordIndexer().index_by_id(id_)\n    if bulk_uuids:\n        RecordIndexer().bulk_index(bulk_uuids)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\niterates over the pathnames and return a set of items.", "response": "def iter_paths(self, pathnames=None, mapfunc=None):\n        \"\"\"\n        Special iteration on paths. Yields couples of path and items. If a expanded path\n        doesn't match with any files a couple with path and `None` is returned.\n\n        :param pathnames: Iterable with a set of pathnames. If is `None` uses the all \\\n        the stored pathnames.\n        :param mapfunc: A mapping function for building the effective path from various \\\n        wildcards (eg. time spec wildcards).\n        :return: Yields 2-tuples.\n        \"\"\"\n        pathnames = pathnames or self._pathnames\n        if self.recursive and not pathnames:\n            pathnames = ['.']\n        elif not pathnames:\n            yield []\n\n        if mapfunc is not None:\n            for mapped_paths in map(mapfunc, pathnames):\n                for path in mapped_paths:\n                    if self.recursive and (os.path.isdir(path) or os.path.islink(path)):\n                        for t in os.walk(path, followlinks=self.follow_symlinks):\n                            for filename, values in self.iglob(os.path.join(t[0], '*')):\n                                yield filename, values\n                    else:\n                        empty_glob = True\n                        for filename, values in self.iglob(path):\n                            yield filename, values\n                            empty_glob = False\n                        if empty_glob:\n                            yield path, None\n        else:\n            for path in pathnames:\n                if self.recursive and (os.path.isdir(path) or os.path.islink(path)):\n                    for t in os.walk(path, followlinks=self.follow_symlinks):\n                        for filename, values in self.iglob(os.path.join(t[0], '*')):\n                            yield filename, values\n                else:\n                    empty_glob = True\n                    for filename, values in self.iglob(path):\n                        yield filename, values\n                        empty_glob = False\n                    if empty_glob:\n                        yield path, None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck the stat information for excluding files not in datetime period.", "response": "def check_stat(self, path):\n        \"\"\"\n        Checks logfile stat information for excluding files not in datetime period.\n        On Linux it's possible to checks only modification time, because file creation info\n        are not available, so it's possible to exclude only older files.\n        In Unix BSD systems and windows information about file creation date and times are available,\n        so is possible to exclude too newer files.\n        \"\"\"\n        statinfo = os.stat(path)\n        st_mtime = datetime.fromtimestamp(statinfo.st_mtime)\n        if platform.system() == 'Linux':\n            check = st_mtime >= self.start_dt\n        else:\n            st_ctime = datetime.fromtimestamp(statinfo.st_ctime)\n            check = st_mtime >= self.start_dt and st_ctime <= self.end_dt\n\n        if not check:\n            logger.info(\"file %r not in datetime period!\", path)\n        return check"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add(self, files, items):\n        if isinstance(files, (str, bytes)):\n            files = iter([files])\n        for pathname in files:\n            try:\n                values = self._filemap[pathname]\n            except KeyError:\n                self._filemap[pathname] = items\n            else:\n                values.extend(items)", "response": "Add a list of files with a reference to a list of objects."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_node(self, network, participant):\n        if network.role == \"practice\" or network.role == \"catch\":\n            return RogersAgentFounder(network=network, participant=participant)\n        elif network.size(type=Agent) < network.generation_size:\n            return RogersAgentFounder(network=network, participant=participant)\n        else:\n            return RogersAgent(network=network, participant=participant)", "response": "Make a new node for participants."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef submission_successful(self, participant):\n        key = participant.uniqueid[0:5]\n\n        finished_participants = Participant.query.filter_by(status=101).all()\n        num_finished_participants = len(finished_participants)\n        current_generation = int((num_finished_participants - 1) /\n                                 float(self.generation_size))\n\n        if num_finished_participants % self.generation_size == 0:\n            if (current_generation + 1) % 10 == 0:\n                self.log(\"Participant was final particpant in generation {}: \\\n                          environment stepping\"\n                         .format(current_generation), key)\n                environments = Environment.query.all()\n                for e in environments:\n                    e.step()\n            else:\n                self.log(\"Participant was final participant in generation {}: \\\n                          not stepping\".format(current_generation), key)\n        else:\n            self.log(\"Participant was not final in generation {}: \\\n                      not stepping\".format(current_generation), key)", "response": "Run when a participant submits successfully."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate a participants bonus.", "response": "def bonus(self, participant=None):\n        \"\"\"Calculate a participants bonus.\"\"\"\n        if participant is None:\n            raise(ValueError(\"You must specify the participant to \\\n                              calculate the bonus.\"))\n        participant_id = participant.uniqueid\n        key = participant_id[0:5]\n\n        nodes = Node.query.join(Node.network)\\\n                    .filter(and_(Node.participant_id == participant_id,\n                                 Network.role == \"experiment\"))\\\n                    .all()\n\n        if len(nodes) == 0:\n            self.log(\"Participant has 0 nodes - cannot calculate bonus!\", key)\n            return 0\n        self.log(\"calculating bonus...\", key)\n        score = [node.score for node in nodes]\n        average = float(sum(score)) / float(len(score))\n        bonus = round(max(0.0, ((average - 0.5) * 2)) * self.bonus_payment, 2)\n        self.log(\"bonus calculated, returning {}\".format(bonus), key)\n        return bonus"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck a participant paid attention.", "response": "def attention_check(self, participant=None):\n        \"\"\"Check a participant paid attention.\"\"\"\n        participant_nodes = Node.query.join(Node.network)\\\n            .filter(and_(Node.participant_id == participant.uniqueid,\n                         Network.role == \"catch\"))\\\n            .all()\n        scores = [n.score for n in participant_nodes]\n\n        if participant_nodes:\n            avg = sum(scores) / float(len(scores))\n        else:\n            return True\n\n        is_passing = avg >= self.min_acceptable_performance\n        return is_passing"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef data_check(self, participant):\n        participant_id = participant.uniqueid\n\n        nodes = Node.query.filter_by(participant_id=participant_id).all()\n\n        if len(nodes) != self.experiment_repeats + self.practice_repeats:\n            print(\"Error: Participant has {} nodes. Data check failed\"\n                  .format(len(nodes)))\n            return False\n\n        nets = [n.network_id for n in nodes]\n        if len(nets) != len(set(nets)):\n            print \"Error: Participant participated in the same network \\\n                   multiple times. Data check failed\"\n            return False\n\n        if None in [n.fitness for n in nodes]:\n            print \"Error: some of participants nodes are missing a fitness. \\\n                   Data check failed.\"\n            return False\n\n        if None in [n.score for n in nodes]:\n            print \"Error: some of participants nodes are missing a score. \\\n                   Data check failed\"\n            return False\n        return True", "response": "Check a participants data."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding participant s node to a network.", "response": "def add_node_to_network(self, node, network):\n        \"\"\"Add participant's node to a network.\"\"\"\n        network.add_node(node)\n        node.receive()\n\n        environment = network.nodes(type=Environment)[0]\n        environment.connect(whom=node)\n\n        gene = node.infos(type=LearningGene)[0].contents\n        if (gene == \"social\"):\n            prev_agents = RogersAgent.query\\\n                .filter(and_(RogersAgent.failed == False,\n                             RogersAgent.network_id == network.id,\n                             RogersAgent.generation == node.generation - 1))\\\n                .all()\n            parent = random.choice(prev_agents)\n            parent.connect(whom=node)\n            parent.transmit(what=Meme, to_whom=node)\n        elif (gene == \"asocial\"):\n            environment.transmit(to_whom=node)\n        else:\n            raise ValueError(\"{} has invalid learning gene value of {}\"\n                             .format(node, gene))\n        node.receive()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef calculate_fitness(self):\n        if self.fitness is not None:\n            raise Exception(\"You are calculating the fitness of agent {}, \"\n                            .format(self.id) +\n                            \"but they already have a fitness\")\n        infos = self.infos()\n\n        said_blue = ([i for i in infos if\n                      isinstance(i, Meme)][0].contents == \"blue\")\n        proportion = float(\n            max(State.query.filter_by(network_id=self.network_id).all(),\n                key=attrgetter('creation_time')).contents)\n        self.proportion = proportion\n        is_blue = proportion > 0.5\n\n        if said_blue is is_blue:\n            self.score = 1\n        else:\n            self.score = 0\n\n        is_asocial = [\n            i for i in infos if isinstance(i, LearningGene)\n        ][0].contents == \"asocial\"\n        e = 2\n        b = 1\n        c = 0.3 * b\n        baseline = c + 0.0001\n\n        self.fitness = (baseline + self.score * b - is_asocial * c) ** e", "response": "Calculates the fitness of the agent."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates an environmental state.", "response": "def create_state(self, proportion):\n        \"\"\"Create an environmental state.\"\"\"\n        if random.random() < 0.5:\n            proportion = 1 - proportion\n        State(origin=self, contents=proportion)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprompting the environment to change.", "response": "def step(self):\n        \"\"\"Prompt the environment to change.\"\"\"\n        current_state = max(self.infos(type=State),\n                            key=attrgetter('creation_time'))\n        current_contents = float(current_state.contents)\n        new_contents = 1 - current_contents\n        info_out = State(origin=self, contents=new_contents)\n        transformations.Mutation(info_in=current_state, info_out=info_out)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef print_subprocess_output(subp):\n    '''Prints the stdout and stderr output.'''\n    if subp:\n        if subp.errorcode != 0:\n            print('<error errorcode=\"%s\">' % str(subp.errorcode))\n            print(subp.stderr)\n            print(\"</error>\")\n            print_tag('stdout', '\\n%s\\n' % subp.stdout)\n        else:\n            print_tag('success', '\\n%s\\n' % subp.stdout)\n            print_tag('warnings', '\\n%s\\n' % subp.stderr)", "response": "Prints the stdout and stderr output."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nretrieving the metadata for all items in this list from the server.", "response": "def get_all(self, force_download=False):\n        \"\"\" Retrieve the metadata for all items in this list from the server,\n        as Item objects\n\n        :rtype: List\n        :returns: a List of the corresponding Item objects\n        :type force_download: Boolean\n        :param force_download: True to download from the server\n            regardless of the cache's contents\n\n        :raises: APIError if the API request is not successful\n\n\n        \"\"\"\n        cl = self.client\n        return [cl.get_item(item, force_download) for item in self.item_urls]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_item(self, item_index, force_download=False):\n        return self.client.get_item(self.item_urls[item_index], force_download)", "response": "Retrieve the metadata for a specific item in this ItemGroup"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nrefreshes the item list by re - downloading it from the server and updating the list name", "response": "def refresh(self):\n        \"\"\" Update this ItemList by re-downloading it from the server\n\n        :rtype: ItemList\n        :returns: this ItemList, after the refresh\n\n        :raises: APIError if the API request is not successful\n\n\n        \"\"\"\n        refreshed = self.client.get_item_list(self.url())\n        self.item_urls = refreshed.urls()\n        self.list_name = refreshed.name()\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef append(self, items):\n        resp = self.client.add_to_item_list(items, self.url())\n        self.refresh()\n        return resp", "response": "Adds some items to the ItemList and saves the changes to the server"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the metadata for the specified document as a Document object", "response": "def get_document(self, index=0):\n        \"\"\" Return the metadata for the specified document, as a\n        Document object\n\n        :type index: int\n        :param index: the index of the document\n\n        :rtype: Document\n        :returns: the metadata for the specified document\n\n\n        \"\"\"\n        try:\n            return Document(self.metadata()['alveo:documents'][index], self.client)\n        except IndexError:\n            raise ValueError('No document exists for this item with index: '\n                             + str(index))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_primary_text(self, force_download=False):\n        return self.client.get_primary_text(self.url(), force_download)", "response": "Retrieve the primary text for this item from the server."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_annotations(self, atype=None, label=None):\n        return self.client.get_item_annotations(self.url(), atype, label)", "response": "Retrieve the annotations for this item from the server"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_content(self, force_download=False):\n        return self.client.get_document(self.url(), force_download)", "response": "Retrieve the content for this Document from the server"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndownloading the content for this document to a file.", "response": "def download_content(self, dir_path='', filename=None,\n                         force_download=False):\n        \"\"\" Download the content for this document to a file\n\n        :type dir_path: String\n        :param dir_path: the path to which to write the data\n        :type filename: String\n        :param filename: filename to write to (if None, defaults to the document's\n            name, as specified by its metadata\n        :type force_download: Boolean\n        :param force_download: True to download from the server\n            regardless of the cache's contents\n\n        :rtype: String\n        :returns: the path to the downloaded file\n\n        :raises: APIError if the API request is not successful\n\n\n        \"\"\"\n        if filename is None:\n            filename = self.get_filename()\n        path = os.path.join(dir_path, filename)\n        data = self.client.get_document(self.url(), force_download)\n        with open(path, 'wb') as f:\n            f.write(data)\n        return path"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef search(self):\n        self.log.debug('starting the ``get`` method')\n\n        sqlQuery = self._get_on_trixel_sources_from_database_query()\n\n        databaseRows = self._execute_query(sqlQuery)\n        matchIndies, matches = self._list_crossmatch(databaseRows)\n\n        from fundamentals.renderer import list_of_dictionaries\n        matches = list_of_dictionaries(\n            log=self.log,\n            listOfDictionaries=matches,\n            reDatetime=self.reDatetime\n        )\n\n        self.log.debug('completed the ``get`` method')\n        return matchIndies, matches", "response": "Returns the results of the database conesearch"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating the mysql query that returns the list of on - trixel sources that are present in the database", "response": "def _get_on_trixel_sources_from_database_query(\n            self):\n        \"\"\"*generate the mysql query before executing it*\n        \"\"\"\n        self.log.debug(\n            'completed the ````_get_on_trixel_sources_from_database_query`` method')\n\n        tableName = self.tableName\n        raCol = self.raCol\n        decCol = self.decCol\n        radiusArc = self.radius\n        radius = self.radius / (60. * 60.)\n\n        # GET ALL THE TRIXELS REQUIRED\n        trixelArray = self._get_trixel_ids_that_overlap_conesearch_circles()\n        if trixelArray.size > 50000 and self.htmDepth == 16:\n            self.htmDepth = 13\n            self.mesh = HTM(\n                depth=self.htmDepth,\n                log=self.log\n            )\n            trixelArray = self._get_trixel_ids_that_overlap_conesearch_circles()\n        if trixelArray.size > 50000 and self.htmDepth == 13:\n            self.htmDepth = 10\n            self.mesh = HTM(\n                depth=self.htmDepth,\n                log=self.log\n            )\n            trixelArray = self._get_trixel_ids_that_overlap_conesearch_circles()\n\n        htmLevel = \"htm%sID\" % self.htmDepth\n        if trixelArray.size > 150000:\n            self.log.info(\n                \"Your search radius of the `%(tableName)s` table may be too large (%(radiusArc)s arcsec)\" % locals())\n            minID = np.min(trixelArray)\n            maxID = np.max(trixelArray)\n            htmWhereClause = \"where %(htmLevel)s between %(minID)s and %(maxID)s  \" % locals(\n            )\n        else:\n            thesHtmIds = \",\".join(np.array(map(str, trixelArray)))\n            htmWhereClause = \"where %(htmLevel)s in (%(thesHtmIds)s)\" % locals(\n            )\n\n        cols = self.columns[:]\n        if cols != \"*\" and raCol.lower() not in cols.lower():\n            cols += \", \" + raCol\n        if cols != \"*\" and decCol.lower() not in cols.lower():\n            cols += \", \" + decCol\n\n        # FINALLY BUILD THE FULL QUERY\n        if self.distinct:\n            sqlQuery = \"\"\"select DISTINCT %(cols)s from %(tableName)s %(htmWhereClause)s\"\"\" % locals(\n            )\n        else:\n            sqlQuery = \"\"\"select %(cols)s from %(tableName)s %(htmWhereClause)s\"\"\" % locals(\n            )\n\n        if self.sqlWhere and len(self.sqlWhere):\n            sqlQuery += \" and \" + self.sqlWhere\n\n        self.log.debug(\n            'completed the ``_get_on_trixel_sources_from_database_query`` method')\n\n        return sqlQuery"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_trixel_ids_that_overlap_conesearch_circles(\n            self):\n        \"\"\"*Get an array of all of the trixels IDs that overlap the conesearch circles(s)*\n\n        **Return:**\n            - ``trixelArray`` -- an array of all the overlapping trixel ids\n        \"\"\"\n        self.log.debug(\n            'completed the ````_get_trixel_ids_that_overlap_conesearch_circles`` method')\n\n        trixelArray = np.array([], dtype='int16', ndmin=1, copy=False)\n        # FOR EACH RA, DEC SET IN THE NUMPY ARRAY, COLLECT THE OVERLAPPING HTM\n        # TRIXELS\n        r = self.radius / (60. * 60.)\n\n        trixelArray = []\n\n        trixelArray[:] = [self.mesh.intersect(\n            ra1, dec1, r, inclusive=True, convertCoordinates=False) for ra1, dec1 in zip(self.ra, self.dec)]\n\n        trixelArray = np.unique(np.concatenate(trixelArray))\n\n        self.log.debug(\n            'completed the ``_get_trixel_ids_that_overlap_conesearch_circles`` method')\n        return trixelArray", "response": "Return an array of all of the trixels IDs that overlap the conesearch circles."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nexecutes a sql query and trim the results", "response": "def _execute_query(\n            self,\n            sqlQuery):\n        \"\"\"* execute query and trim results*\n\n        **Key Arguments:**\n            - ``sqlQuery`` -- the sql database query to grab low-resolution results.\n\n        **Return:**\n            - ``databaseRows`` -- the database rows found on HTM trixles with requested IDs\n        \"\"\"\n        self.log.debug(\n            'completed the ````_execute_query`` method')\n\n        try:\n            databaseRows = readquery(\n                log=self.log,\n                sqlQuery=sqlQuery,\n                dbConn=self.dbConn\n            )\n        except Exception as e:\n            if \"Unknown column 'htm\" in str(e):\n                message = \"Please add and populate the HTM columns to this database table BEFORE running any conesearches. You can use HMpTy to do this: http://hmpty.readthedocs.io/en/stable/\"\n                self.log.error(message)\n                raise IOError(message)\n            elif \"Truncated incorrect DOUBLE value\" in str(e) or \"Truncated incorrect DECIMAL value\" in str(e):\n                databaseRows = readquery(\n                    log=self.log,\n                    sqlQuery=sqlQuery,\n                    dbConn=self.dbConn,\n                    quiet=True\n                )\n            else:\n                print sqlQuery\n                raise e\n\n        if self.distinct and (self.columns != \"*\" and (self.raCol.lower() not in self.columns.lower() or self.decCol.lower() not in self.columns.lower())):\n            distinctRows = []\n            theseKeys = []\n            for r in databaseRows:\n                constraintKey = \"\"\n                for k, v in r.iteritems():\n                    if k.lower() != self.raCol.lower() and k.lower() != self.decCol.lower():\n                        constraintKey += str(v)\n                if self.raCol.lower() in self.columns.lower():\n                    constraintKey += str(databaseRows[self.raCol])\n                if self.decCol.lower() in self.columns.lower():\n                    constraintKey += str(databaseRows[self.decCol])\n                if constraintKey not in theseKeys:\n                    theseKeys.append(constraintKey)\n                    distinctRows.append(r)\n            databaseRows = distinctRows\n\n        self.log.debug(\n            'completed the ``_execute_query`` method')\n        return databaseRows"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _list_crossmatch(\n            self,\n            dbRows):\n        \"\"\"*to a finer grain crossmatch of the input coordinates and the database results.*\n\n        **Key Arguments:**\n            - ``dbRows`` -- the rows return from the database on first crossmatch pass.\n\n        **Return:**\n            - ``matchIndices1`` -- indices of the coordinate in the original ra and dec lists\n            - ``matches`` -- the matched database rows\n        \"\"\"\n        self.log.debug('starting the ``_list_crossmatch`` method')\n\n        dbRas = []\n        dbRas[:] = [d[self.raCol] for d in dbRows]\n        dbDecs = []\n        dbDecs[:] = [d[self.decCol] for d in dbRows]\n\n        # 12 SEEMS TO BE GIVING OPTIMAL SPEED FOR MATCHES (VERY ROUGH SPEED\n        # TESTS)\n        mesh = HTM(\n            depth=12,\n            log=self.log\n        )\n\n        if self.closest:\n            maxmatch = 1\n        else:\n            maxmatch = 0\n        matchIndices1, matchIndices2, seps = mesh.match(\n            ra1=self.ra,\n            dec1=self.dec,\n            ra2=np.array(dbRas),\n            dec2=np.array(dbDecs),\n            radius=float(self.radius / (60. * 60.)),\n            maxmatch=maxmatch  # 1 = match closest 1, 0 = match all\n        )\n\n        matches = []\n\n        for m1, m2, s in zip(matchIndices1, matchIndices2, seps):\n            if self.separations:\n                dbRows[m2][\"cmSepArcsec\"] = s * (60. * 60.)\n            matches.append(dbRows[m2])\n\n        self.log.debug('completed the ``_list_crossmatch`` method')\n        return matchIndices1, matches", "response": "This method is used to list the cross - match of the input coordinates and the database results."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef generic_lazy_ref_formatter(view, context, model, name):\n    return generic_ref_formatter(view, context, model, name, True)", "response": "A generic ref formatter that returns a lazy version of the given model."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef generic_document_type_formatter(view, context, model, name):\n    _document_model = model.get('document').document_type\n    url = _document_model.get_admin_list_url()\n    return Markup('<a href=\"%s\">%s</a>' % (url, _document_model.__name__))", "response": "Return AdminLog. document field wrapped in URL to its list view."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef multicategory_scatterplot(output_directory, file_prefix, df,\n                              x_series_index, y_series_index, category_series_index,\n                              series_color, plot_title = '',\n                              x_axis_label = '', y_axis_label = '',\n                              min_predicted_ddg = None, max_predicted_ddg = None, min_experimental_ddg = None, max_experimental_ddg = None):\n    '''This function was adapted from the covariation benchmark.'''\n\n    # todo: Abstract this graph from the current usage (DDG measurements).\n    # todo: make the capped value for unquantified but classified measurements (e.g. DDG > 7 kcal/mol) parameterizable\n    # todo: add an option to identify outliers by standard deviations (over the set of errors |x - y|) rather than by fixed value\n    # todo: add an option to use geom_text_repel to avoid/reduce overlapping text\n    # todo: allow users to provide colors for the facets / categories\n\n    # Changeset\n    # todo: Change it to take in a pandas dataframe instead of the data_table_headers + data_table parameters.\n    # todo: Add exception if number of cases > 2 so the general case can be implemented once we have test data.\n    # todo: use one column as the category e.g. \"PDB\". assert that there is a maximum number of categories. Test with > 2 categories\n    # todo: remove all references to SNX27 and NHERF1 below and loop over the set of categories instead\n\n    #print(df[facet_index])\n    color_map = {}\n    categories = list(df.ix[:, category_series_index].unique())\n    print(type(categories))\n    num_categories = len(categories)\n    category_colors = get_spaced_plot_colors(num_categories)\n    for x in xrange(num_categories):\n        color_map[categories[x]] = '#' + category_colors[x]\n\n    df['CategorizationColor'] = df.apply(lambda r: color_map[r[category_series_index]], axis = 1)\n    categorization_color_index = len(df.columns.values) - 1\n\n    # Monday: continue here\n    print(df)\n    sys.exit(0)\n    try: os.mkdir(output_directory)\n    except: pass\n    assert(os.path.exists(output_directory))\n\n\n    df['Categorization'] = df.apply(lambda r: _determine_fraction_correct_class(r[x_series_index], r[y_series_index])[0], axis = 1)\n    categorization_index = len(df.columns.values) - 1\n    df['CategorizationShape'] = df.apply(lambda r: _determine_fraction_correct_class(r[x_series_index], r[y_series_index])[1], axis = 1)\n    categorization_shape_index = len(df.columns.values) - 1\n\n\n\n\n    # Create the R script\n    boxplot_r_script = '''\nlibrary(ggplot2)\nlibrary(gridExtra)\nlibrary(scales)\nlibrary(qualV)\n\n# PNG generation\npng('%(file_prefix)s.png', width=2560, height=2048, bg=\"white\", res=600)\ntxtalpha <- 0.6\nredtxtalpha <- 0.6\n\n%(png_plot_commands)s\n    '''\n\n    xy_table_filename = '{0}.txt'.format(file_prefix)\n    xy_table_filepath = os.path.join(output_directory, xy_table_filename)\n    write_file(xy_table_filepath, '\\n'.join(','.join(map(str, line)) for line in [data_table_headers] + data_table))\n\n    single_plot_commands = '''\n# Set the margins\npar(mar=c(5, 5, 1, 1))\n\nxy_data <- read.csv('%(xy_table_filename)s', header=T)\n\nnames(xy_data)[%(x_series_index)d + 1] <- \"xvalues\"\nnames(xy_data)[%(y_series_index)d + 1] <- \"yvalues\"\n\n# coefs contains two values: (Intercept) and yvalues\ncoefs <- coef(lm(xvalues~yvalues, data = xy_data))\nfitcoefs = coef(lm(xvalues~0 + yvalues, data = xy_data))\nfitlmv_yvalues <- as.numeric(fitcoefs[1])\nlmv_intercept <- as.numeric(coefs[1])\nlmv_yvalues <- as.numeric(coefs[2])\nlm(xy_data$yvalues~xy_data$xvalues)\n\nxlabel <- \"%(x_axis_label)s\"\nylabel <- \"%(y_axis_label)s\"\nplot_title <- \"%(plot_title)s\"\nrvalue <- cor(xy_data$yvalues, xy_data$xvalues)\nrvalue\nxy_data\n\n#3QDO = SNX27\n#1G9O = NHERF1\n\nvalid_xy_data <- xy_data[which(xy_data$xvalues < 6.99),]\nrvalue <- cor(valid_xy_data$yvalues, valid_xy_data$xvalues)\nrvalue\nvalid_xy_data\n\nvalid_xy_data_NHERF1 <- xy_data[which(xy_data$xvalues < 6.99 & xy_data$PDB == '1G9O'),]\nrvalue_NHERF1 <- cor(valid_xy_data_NHERF1$yvalues, valid_xy_data_NHERF1$xvalues)\nrvalue_NHERF1\nvalid_xy_data_NHERF1\n\ncoefs_NHERF1 <- coef(lm(xvalues~yvalues, data = valid_xy_data_NHERF1))\nlmv_intercept_NHERF1 <- as.numeric(coefs_NHERF1[1])\nlmv_yvalues_NHERF1 <- as.numeric(coefs_NHERF1[2])\n\nvalid_xy_data_SNX27 <- xy_data[which(xy_data$xvalues < 6.99 & xy_data$PDB == '3QDO'),]\nrvalue_SNX27 <- cor(valid_xy_data_SNX27$yvalues, valid_xy_data_SNX27$xvalues)\nrvalue_SNX27\nvalid_xy_data_SNX27\n\ncoefs_SNX27 <- coef(lm(xvalues~yvalues, data = valid_xy_data_SNX27))\nlmv_intercept_SNX27 <- as.numeric(coefs_SNX27[1])\nlmv_yvalues_SNX27 <- as.numeric(coefs_SNX27[2])\n\nlmv_intercept\nlmv_yvalues\nlmv_intercept_NHERF1\nlmv_yvalues_NHERF1\nlmv_intercept_SNX27\nlmv_yvalues_SNX27\n\n# Set graph limits and the position for the correlation value\n\nminx <- min(0.0, min(xy_data$xvalues) - 0.1)\nminy <- min(0.0, min(xy_data$yvalues) - 0.1)\nmaxx <- max(1.0, max(xy_data$xvalues) + 0.1)\nmaxy <- max(1.0, max(xy_data$yvalues) + 0.1)\n    '''\n\n    if min_predicted_ddg != None:\n        single_plot_commands += '''\nminy <- min(miny  - 0.2, %(min_predicted_ddg)f  - 0.2)\n    '''\n    if max_predicted_ddg != None:\n        single_plot_commands += '''\nmaxy <- max(maxy + 0.5, %(max_predicted_ddg)f  + 0.5)\n\nminy <- -6\nmaxy <- 12.5\n\n    '''\n    if min_experimental_ddg != None:\n        single_plot_commands += '''\n    minx <- min(minx, %(min_experimental_ddg)f)\n        '''\n    if max_experimental_ddg != None:\n        single_plot_commands += '''\n    maxx <- max(maxx, %(max_experimental_ddg)f) + 0.2\n        '''\n\n    single_plot_commands += '''\nxpos <- minx + 0.2\nypos <- maxy - 1\nypos_SNX27 <- ypos - 1\nypos_NHERF1 <- ypos_SNX27 - 1\n\nlrt <- expression('R'^tst)\n\np <- qplot(main=\"\", xvalues, yvalues, data=xy_data, xlab=xlabel, ylab=ylabel, shape = PDB, alpha = I(txtalpha)) +\n        geom_point(aes(color = PDB), alpha = 0.6) +\n        scale_colour_manual(name=\"\", values = c(\"1G9O\"=\"orange\", \"3QDO\"=\"blue\", \"3\"=\"red\", \"value3\"=\"grey\", \"value2\"=\"black\")) +\n        labs(title = \"%(plot_title)s\") +\n        theme(plot.title = element_text(color = \"#555555\", size=rel(0.75))) +\n\n        # Correlation fit lines (global + one per facet\n        geom_abline(size = 0.125, color=\"black\", intercept = lmv_intercept, slope = lmv_yvalues, alpha=0.2) +\n        geom_abline(size = 0.125, color=\"orange\", intercept = lmv_intercept_NHERF1, slope = lmv_yvalues_NHERF1, alpha=0.4) +\n        geom_abline(size = 0.125, color=\"blue\", intercept = lmv_intercept_SNX27, slope = lmv_yvalues_SNX27, alpha=0.4) +\n\n        geom_abline(slope=1, intercept=0, linetype=3, size=0.25, alpha=0.4) + # add a diagonal (dotted)\n        coord_cartesian(xlim = c(minx, maxx), ylim = c(miny, maxy)) + # set the graph limits\n\n        geom_text(hjust = 0, size=1.5, color=\"#000000\", alpha=0.6, data=subset(xy_data, abs(yvalues - xvalues) > 2 & xvalues <= 0), aes(xvalues, yvalues+0.35, label=Origin_of_peptide), check_overlap = TRUE) + # label outliers\n        geom_text(hjust = 1, size=1.5, color=\"#000000\", alpha=0.6, data=subset(xy_data, abs(yvalues - xvalues) > 2 & xvalues > 0), aes(xvalues, yvalues+0.35, label=Origin_of_peptide), check_overlap = TRUE) + # label outliers\n        geom_text(hjust=0, size=2, colour=\"black\", aes(x = xpos, y = ypos, label = sprintf(\"R == %%0.2f\", round(rvalue, digits = 4))), parse = TRUE) +\n        geom_text(hjust=0, size=2, colour=\"darkorange\", aes(x = xpos, y = ypos_NHERF1, label = sprintf(\"R[NHERF] == %%0.2f\", round(rvalue_NHERF1, digits = 4))), parse = TRUE) +\n        geom_text(hjust=0, size=2, colour=\"blue\", aes(x = xpos, y = ypos_SNX27, label = sprintf(\"R[SNX27] == %%0.2f\", round(rvalue_SNX27, digits = 4))), parse = TRUE) +\n        theme(legend.position = \"none\")\n#       geom_text(hjust=0, size=2, colour=\"black\", aes(xpos, ypos, fontface=\"plain\", family = \"sans\", label=paste(sprintf(\"R = %%0.2f%%s\", round(rvalue, digits = 4), lrt), expression('R'[3])  ))) # add correlation text; hjust=0 sets left-alignment\n\n#geom_text(hjust=0, size=3, colour=\"black\", aes(xpos, ypos, fontface=\"plain\", family = \"sans\", label=sprintf(\"R = %%0.2f\", round(rvalue, digits = 4)))) # add correlation text; hjust=0 sets left-alignment\n#       geom_text(hjust=0, size=3, colour=\"black\", aes(xpos, ypos, fontface=\"plain\", family = \"sans\", label=sprintf(\"R = %%0.2f\", round(rvalue, digits = 4)))) # add correlation text; hjust=0 sets left-alignment\n\n# Plot graph\np\ndev.off()\n        '''\n\n\n    #geom_point(aes(color = C)) +\n    #color = \"%(series_color)s\"\n\n    # Create the R script\n    plot_type = 'png'\n    png_plot_commands = single_plot_commands % locals()\n    boxplot_r_script = boxplot_r_script % locals()\n    r_script_filename = '{0}.R'.format(file_prefix)\n    r_script_filepath = os.path.join(output_directory, r_script_filename)\n    write_file(r_script_filepath, boxplot_r_script)\n\n    # Run the R script\n    run_r_script(r_script_filename, cwd = output_directory)", "response": "This function is adapted from the covariation benchmark."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a generic success response.", "response": "def success_response(field=None, data=None, request_type=\"\"):\n    \"\"\"Return a generic success response.\"\"\"\n    data_out = {}\n    data_out[\"status\"] = \"success\"\n    if field:\n        data_out[field] = data\n    print(\"{} request successful.\".format(request_type))\n    js = dumps(data_out, default=date_handler)\n    return Response(js, status=200, mimetype='application/json')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef error_response(error_type=\"Internal server error\",\n                   error_text=None,\n                   status=400,\n                   participant=None):\n    \"\"\"Return a generic server error response.\"\"\"\n    traceback.print_exc()\n    print(\"Error: {}.\".format(error_type))\n\n    page = error_page(\n        error_text=error_text,\n        error_type=error_type,\n        participant=participant)\n\n    data = {\n        \"status\": \"error\",\n        \"html\": page\n    }\n    return Response(dumps(data), status=status, mimetype='application/json')", "response": "Return a generic server error response."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef return_page(page):\n    try:\n        hit_id = request.args['hit_id']\n        assignment_id = request.args['assignment_id']\n        worker_id = request.args['worker_id']\n        mode = request.args['mode']\n        return render_template(\n            page,\n            hit_id=hit_id,\n            assignment_id=assignment_id,\n            worker_id=worker_id,\n            mode=mode\n        )\n    except:\n        try:\n            participant_id = request.args['participant_id']\n            return render_template(page, participant_id=participant_id)\n        except:\n            return error_response(error_type=\"{} args missing\".format(page))", "response": "Return a rendered template."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef error_page(participant=None, error_text=None, compensate=True,\n               error_type=\"default\"):\n    \"\"\"Render HTML for error page.\"\"\"\n    if error_text is None:\n\n        error_text = \"\"\"There has been an error and so you are unable to\n        continue, sorry! If possible, please return the assignment so someone\n        else can work on it.\"\"\"\n\n    if compensate:\n        error_text += \"\"\" Please use the information below to contact us\n        about compensation\"\"\"\n\n    if participant is not None:\n        hit_id = participant.hit_id,\n        assignment_id = participant.assignment_id,\n        worker_id = participant.worker_id\n    else:\n        hit_id = 'unknown'\n        assignment_id = 'unknown'\n        worker_id = 'unknown'\n\n    return render_template(\n        'error_wallace.html',\n        error_text=error_text,\n        compensate=compensate,\n        contact_address=config.get(\n            'HIT Configuration', 'contact_email_on_error'),\n        error_type=error_type,\n        hit_id=hit_id,\n        assignment_id=assignment_id,\n        worker_id=worker_id\n    )", "response": "Render the error page."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef summary():\n    exp = experiment(session)\n    return success_response(field=\"summary\",\n                            data=exp.log_summary(),\n                            request_type=\"summary\")", "response": "Summarize the participants status codes."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef quitter():\n    exp = experiment(session)\n    exp.log(\"Quitter route was hit.\")\n\n    return Response(\n        dumps({\"status\": \"success\"}),\n        status=200,\n        mimetype='application/json')", "response": "Overide the psiTurk quitter route."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef experiment_property(prop):\n    exp = experiment(session)\n    p = getattr(exp, prop)\n    return success_response(field=prop, data=p, request_type=prop)", "response": "Get a property of the experiment by name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ad_address(mode, hit_id):\n    if mode == \"debug\":\n        address = '/complete'\n    elif mode in [\"sandbox\", \"live\"]:\n        username = os.getenv('psiturk_access_key_id',\n                             config.get(\"psiTurk Access\",\n                                        \"psiturk_access_key_id\"))\n        password = os.getenv('psiturk_secret_access_id',\n                             config.get(\"psiTurk Access\",\n                                        \"psiturk_secret_access_id\"))\n        try:\n            req = requests.get(\n                'https://api.psiturk.org/api/ad/lookup/' + hit_id,\n                auth=(username, password))\n        except:\n            raise ValueError('api_server_not_reachable')\n        else:\n            if req.status_code == 200:\n                hit_address = req.json()['ad_id']\n            else:\n                raise ValueError(\"something here\")\n        if mode == \"sandbox\":\n            address = ('https://sandbox.ad.psiturk.org/complete/' +\n                       str(hit_address))\n        elif mode == \"live\":\n            address = 'https://ad.psiturk.org/complete/' + str(hit_address)\n    else:\n        raise ValueError(\"Unknown mode: {}\".format(mode))\n    return success_response(field=\"address\",\n                            data=address,\n                            request_type=\"ad_address\")", "response": "Get the address of the ad on AWS."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nassign properties to an object.", "response": "def assign_properties(thing):\n    \"\"\"Assign properties to an object.\n\n    When creating something via a post request (e.g. a node), you can pass the\n    properties of the object in the request. This function gets those values\n    from the request and fills in the relevant columns of the table.\n    \"\"\"\n    for p in range(5):\n        property_name = \"property\" + str(p + 1)\n        property = request_parameter(parameter=property_name, optional=True)\n        if property:\n            setattr(thing, property_name, property)\n\n    session.commit()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_participant(worker_id, hit_id, assignment_id, mode):\n    # check this worker hasn't already taken part\n    parts = models.Participant.query.filter_by(worker_id=worker_id).all()\n    if parts:\n        print \"participant already exists!\"\n        return Response(status=200)\n\n    # make the participant\n    participant = models.Participant(worker_id=worker_id,\n                                     assignment_id=assignment_id,\n                                     hit_id=hit_id,\n                                     mode=mode)\n    session.add(participant)\n    session.commit()\n\n    # make a psiturk participant too, for now\n    from psiturk.models import Participant as PsiturkParticipant\n    psiturk_participant = PsiturkParticipant(workerid=worker_id,\n                                             assignmentid=assignment_id,\n                                             hitid=hit_id)\n    session_psiturk.add(psiturk_participant)\n    session_psiturk.commit()\n\n    # return the data\n    return success_response(field=\"participant\",\n                            data=participant.__json__(),\n                            request_type=\"participant post\")", "response": "Create a participant.\n\n    This route will be hit very early on as any nodes the participant creates\n    will be defined in reference to the participant object.\n    You must specify the worker_id, hit_id, assignment_id and mode in the url."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_participant(participant_id):\n    try:\n        ppt = models.Participant.query.filter_by(id=participant_id).one()\n    except NoResultFound:\n        return error_response(\n            error_type=\"/participant GET: no participant found\",\n            status=403)\n\n    # return the data\n    return success_response(field=\"participant\",\n                            data=ppt.__json__(),\n                            request_type=\"participant get\")", "response": "Get the participant with the given id."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the network with the given id.", "response": "def get_network(network_id):\n    \"\"\"Get the network with the given id.\"\"\"\n    try:\n        net = models.Network.query.filter_by(id=network_id).one()\n    except NoResultFound:\n        return error_response(\n            error_type=\"/network GET: no network found\",\n            status=403)\n\n    # return the data\n    return success_response(field=\"network\",\n                            data=net.__json__(),\n                            request_type=\"network get\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_question(participant_id):\n    # Get the participant.\n    try:\n        ppt = models.Participant.query.filter_by(id=participant_id).one()\n    except NoResultFound:\n        return error_response(error_type=\"/question POST no participant found\",\n                              status=403)\n\n    # Make sure the participant status is \"working\"\n    if ppt.status != \"working\":\n        error_type = \"/question POST, status = {}\".format(ppt.status)\n        return error_response(error_type=error_type,\n                              participant=ppt)\n\n    question = request_parameter(parameter=\"question\")\n    response = request_parameter(parameter=\"response\")\n    number = request_parameter(parameter=\"number\",\n                                    parameter_type=\"int\")\n    for x in [question, response, number]:\n        if type(x) == Response:\n            return x\n\n    try:\n        # execute the request\n        models.Question(participant=ppt, question=question,\n                        response=response, number=number)\n        session.commit()\n    except:\n        return error_response(error_type=\"/question POST server error\",\n                              status=403)\n\n    # return the data\n    return success_response(request_type=\"question post\")", "response": "Create a new question in the question table."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the node s neighbors", "response": "def node_neighbors(node_id):\n    \"\"\"Send a GET request to the node table.\n\n    This calls the neighbours method of the node\n    making the request and returns a list of descriptions of\n    the nodes (even if there is only one).\n    Required arguments: participant_id, node_id\n    Optional arguments: type, failed, connection\n\n    After getting the neighbours it also calls\n    exp.node_get_request()\n    \"\"\"\n    exp = experiment(session)\n\n    # get the parameters\n    node_type = request_parameter(parameter=\"node_type\",\n                                  parameter_type=\"known_class\",\n                                  default=models.Node)\n    failed = request_parameter(parameter=\"failed\",\n                               parameter_type=\"bool\",\n                               default=False)\n    connection = request_parameter(parameter=\"connection\", default=\"to\")\n    for x in [node_type, failed, connection]:\n        if type(x) == Response:\n            return x\n\n    # make sure the node exists\n    node = models.Node.query.get(node_id)\n    if node is None:\n        return error_response(\n            error_type=\"/node/neighbors, node does not exist\",\n            error_text=\"/node/{}/neighbors, node {} does not exist\"\n            .format(node_id))\n\n    # get its neighbors\n    nodes = node.neighbours(\n        type=node_type,\n        failed=failed,\n        connection=connection)\n\n    try:\n        # ping the experiment\n        exp.node_get_request(\n            node=node,\n            nodes=nodes)\n        session.commit()\n    except:\n        return error_response(error_type=\"exp.node_get_request\")\n\n    return success_response(field=\"nodes\",\n                            data=[n.__json__() for n in nodes],\n                            request_type=\"neighbors\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new node for the participant.", "response": "def create_node(participant_id):\n    \"\"\"Send a POST request to the node table.\n\n    This makes a new node for the participant, it calls:\n        1. exp.get_network_for_participant\n        2. exp.create_node\n        3. exp.add_node_to_network\n        4. exp.node_post_request\n    \"\"\"\n    exp = experiment(session)\n\n    # Get the participant.\n    try:\n        participant = models.Participant.\\\n            query.filter_by(id=participant_id).one()\n    except NoResultFound:\n        return error_response(error_type=\"/node POST no participant found\",\n                              status=403)\n\n    # replace any duplicate assignments\n    check_for_duplicate_assignments(participant)\n\n    # Make sure the participant status is working\n    if participant.status != \"working\":\n        error_type = \"/node POST, status = {}\".format(participant.status)\n        return error_response(error_type=error_type,\n                              participant=participant)\n\n    try:\n        # execute the request\n        network = exp.get_network_for_participant(participant=participant)\n\n        if network is None:\n            return Response(dumps({\"status\": \"error\"}), status=403)\n\n        node = exp.create_node(\n            participant=participant,\n            network=network)\n\n        assign_properties(node)\n\n        exp.add_node_to_network(\n            node=node,\n            network=network)\n\n        session.commit()\n\n        # ping the experiment\n        exp.node_post_request(participant=participant, node=node)\n        session.commit()\n    except:\n        return error_response(error_type=\"/node POST server error\",\n                              status=403,\n                              participant=participant)\n\n    # return the data\n    return success_response(field=\"node\",\n                            data=node.__json__(),\n                            request_type=\"/node POST\")"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef connect(node_id, other_node_id):\n    exp = experiment(session)\n\n    # get the parameters\n    direction = request_parameter(parameter=\"direction\", default=\"to\")\n    if type(direction == Response):\n        return direction\n\n    # check the nodes exist\n    node = models.Node.query.get(node_id)\n    if node is None:\n        return error_response(error_type=\"/node/connect, node does not exist\")\n\n    other_node = models.Node.query.get(other_node_id)\n    if other_node is None:\n        return error_response(\n            error_type=\"/node/connect, other node does not exist\",\n            participant=node.participant)\n\n    # execute the request\n    try:\n        vectors = node.connect(whom=other_node, direction=direction)\n        for v in vectors:\n            assign_properties(v)\n\n        # ping the experiment\n        exp.vector_post_request(\n            node=node,\n            vectors=vectors)\n\n        session.commit()\n    except:\n        return error_response(error_type=\"/vector POST server error\",\n                              status=403,\n                              participant=node.participant)\n\n    return success_response(field=\"vectors\",\n                            data=[v.__json__() for v in vectors],\n                            request_type=\"vector post\")", "response": "Connect to another node."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting a specific info.", "response": "def get_info(node_id, info_id):\n    \"\"\"Get a specific info.\n\n    Both the node and info id must be specified in the url.\n    \"\"\"\n    exp = experiment(session)\n\n    # check the node exists\n    node = models.Node.query.get(node_id)\n    if node is None:\n        return error_response(error_type=\"/info, node does not exist\")\n\n    # execute the experiment method:\n    info = models.Info.query.get(info_id)\n    if info is None:\n        return error_response(error_type=\"/info GET, info does not exist\",\n                              participant=node.participant)\n    elif (info.origin_id != node.id and\n          info.id not in\n            [t.info_id for t in node.transmissions(direction=\"incoming\",\n                                                   status=\"received\")]):\n        return error_response(error_type=\"/info GET, forbidden info\",\n                              status=403,\n                              participant=node.participant)\n\n    try:\n        # ping the experiment\n        exp.info_get_request(node=node, infos=info)\n        session.commit()\n    except:\n        return error_response(error_type=\"/info GET server error\",\n                              status=403,\n                              participant=node.participant)\n\n    # return the data\n    return success_response(field=\"info\",\n                            data=info.__json__(),\n                            request_type=\"info get\")"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef node_transmit(node_id):\n    exp = experiment(session)\n\n    what = request_parameter(parameter=\"what\", optional=True)\n    to_whom = request_parameter(parameter=\"to_whom\", optional=True)\n\n    # check the node exists\n    node = models.Node.query.get(node_id)\n    if node is None:\n        return error_response(error_type=\"/node/transmit, node does not exist\")\n\n    # create what\n    if what is not None:\n        try:\n            what = int(what)\n            what = models.Info.get(what)\n            if what is None:\n                return error_response(\n                    error_type=\"/node/transmit POST, info does not exist\",\n                    participant=node.participant)\n        except:\n            try:\n                what = exp.known_classes[what]\n            except:\n                return error_response(\n                    error_type=\"/node/transmit POST, info does not exist\",\n                    participant=node.participant)\n\n    # create to_whom\n    if to_whom is not None:\n        try:\n            to_whom = int(to_whom)\n            to_whom = models.Node.get(to_whom)\n            if what is None:\n                return error_response(\n                    error_type=\"/node/transmit POST, info does not exist\",\n                    participant=node.participant)\n        except:\n            try:\n                to_whom = exp.known_classes[to_whom]\n            except:\n                return error_response(\n                    error_type=\"/node/transmit POST, info does not exist\",\n                    participant=node.participant)\n\n    # execute the request\n    try:\n        transmissions = node.transmit(what=what, to_whom=to_whom)\n        for t in transmissions:\n            assign_properties(t)\n        session.commit()\n        # ping the experiment\n        exp.transmission_post_request(\n            node=node,\n            transmissions=transmissions)\n        session.commit()\n    except:\n        return error_response(error_type=\"/node/transmit POST, server error\",\n                              participant=node.participant)\n\n    # return the data\n    return success_response(field=\"transmissions\",\n                            data=[t.__json__() for t in transmissions],\n                            request_type=\"transmit\")", "response": "Transmit a node to another node."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef transformation_get(node_id):\n    exp = experiment(session)\n\n    # get the parameters\n    transformation_type = request_parameter(parameter=\"transformation_type\",\n                                            parameter_type=\"known_class\",\n                                            default=models.Transformation)\n    if type(transformation_type) == Response:\n        return transformation_type\n\n    # check the node exists\n    node = models.Node.query.get(node_id)\n    if node is None:\n        return error_response(\n            error_type=\"/node/transformations, node does not exist\")\n\n    # execute the request\n    transformations = node.transformations(\n        transformation_type=transformation_type)\n    try:\n        # ping the experiment\n        exp.transformation_get_request(node=node,\n                                       transformations=transformations)\n        session.commit()\n    except:\n        return error_response(error_type=\"/node/tranaformations GET failed\",\n                              participant=node.participant)\n\n    # return the data\n    return success_response(field=\"transformations\",\n                            data=[t.__json__() for t in transformations],\n                            request_type=\"transformations\")", "response": "Get all the transformations of a node."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef transformation_post(node_id, info_in_id, info_out_id):\n    exp = experiment(session)\n\n    # Get the parameters.\n    transformation_type = request_parameter(parameter=\"transformation_type\",\n                                            parameter_type=\"known_class\",\n                                            default=models.Transformation)\n    if type(transformation_type) == Response:\n        return transformation_type\n\n    # Check that the node etc. exists.\n    node = models.Node.query.get(node_id)\n    if node is None:\n        return error_response(\n            error_type=\"/transformation POST, node does not exist\")\n\n    info_in = models.Info.query.get(info_in_id)\n    if info_in is None:\n        return error_response(\n            error_type=\"/transformation POST, info_in does not exist\",\n            participant=node.participant)\n\n    info_out = models.Info.query.get(info_out_id)\n    if info_out is None:\n        return error_response(\n            error_type=\"/transformation POST, info_out does not exist\",\n            participant=node.participant)\n\n    try:\n        # execute the request\n        transformation = transformation_type(info_in=info_in,\n                                             info_out=info_out)\n        assign_properties(transformation)\n        session.commit()\n\n        # ping the experiment\n        exp.transformation_post_request(node=node,\n                                        transformation=transformation)\n        session.commit()\n    except:\n        return error_response(error_type=\"/tranaformation POST failed\",\n                              participant=node.participant)\n\n    # return the data\n    return success_response(field=\"transformation\",\n                            data=transformation.__json__(),\n                            request_type=\"transformation post\")", "response": "Transform an info.\n\n    The ids of the node, info in and info out must all be in the url.\n    You can also pass transformation_type."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef api_notifications():\n    event_type = request.values['Event.1.EventType']\n    assignment_id = request.values['Event.1.AssignmentId']\n\n    # Add the notification to the queue.\n    db.logger.debug('rq: Queueing %s with id: %s for worker_function',\n                    event_type, assignment_id)\n    q.enqueue(worker_function, event_type, assignment_id, None)\n    db.logger.debug('rq: Submitted Queue Length: %d (%s)', len(q),\n                    ', '.join(q.job_ids))\n\n    return success_response(request_type=\"notification\")", "response": "Receive MTurk REST notifications."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\npreparing a statement into a triple ready for rdflib", "response": "def prep(link):\n    '''\n    Prepare a statement into a triple ready for rdflib\n    '''\n    s, p, o = link[:3]\n    s = URIRef(s)\n    p = URIRef(p)\n    o = URIRef(o) if isinstance(o, I) else Literal(o)\n    return s, p, o"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef process(source, target, rdfsonly, base=None, logger=logging):\n    '''\n    Prepare a statement into a triple ready for rdflib graph\n\n    '''\n    for link in source.match():\n        s, p, o = link[:3]\n        #SKip docheader statements\n        if s == (base or '') + '@docheader': continue\n        if p in RESOURCE_MAPPING: p = RESOURCE_MAPPING[p]\n        if o in RESOURCE_MAPPING: o = RESOURCE_MAPPING[o]\n        if p == VERSA_BASEIRI + 'refines':\n            tlinks = list(source.match(s, TYPE_REL))\n            if tlinks:\n                if tlinks[0][TARGET] == VERSA_BASEIRI + 'Resource':\n                    p = I(RDFS_NAMESPACE + 'subClassOf')\n                elif tlinks[0][TARGET] == VERSA_BASEIRI + 'Property':\n                    p = I(RDFS_NAMESPACE + 'subPropertyOf')\n        if p == VERSA_BASEIRI + 'properties':\n            suri = I(iri.absolutize(s, base)) if base else s\n            target.add((URIRef(o), URIRef(RDFS_NAMESPACE + 'domain'), URIRef(suri)))\n            continue\n        if p == VERSA_BASEIRI + 'value':\n            if o not in ['Literal', 'IRI']:\n                ouri = I(iri.absolutize(o, base)) if base else o\n                target.add((URIRef(s), URIRef(RDFS_NAMESPACE + 'range'), URIRef(ouri)))\n                continue\n        s = URIRef(s)\n        #Translate v:type to rdf:type\n        p = RDF.type if p == TYPE_REL else URIRef(p)\n        o = URIRef(o) if isinstance(o, I) else Literal(o)\n        if not rdfsonly or p.startswith(RDF_NAMESPACE) or p.startswith(RDFS_NAMESPACE):\n            target.add((s, p, o))\n    return", "response": "Process a single statement into a triple ready for rdflib graph"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwrites a list of models to a graph.", "response": "def write(models, base=None, graph=None, rdfsonly=False, prefixes=None, logger=logging):\n    '''\n    See the command line help\n    '''\n    prefixes = prefixes or {}\n    g = graph or rdflib.Graph()\n    #g.bind('bf', BFNS)\n    #g.bind('bfc', BFCNS)\n    #g.bind('bfd', BFDNS)\n    g.bind('v', VNS)\n    for k, v in prefixes.items():\n        g.bind(k, v)\n    for m in models:\n        base_out = m.base\n        process(m, g, rdfsonly, base=base_out, logger=logger)\n    return g"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding routing feature for application", "response": "def routing_feature(app):\n    \"\"\"\n    Add routing feature\n    Allows to define application routes un urls.py file and use lazy views.\n    Additionally enables regular exceptions in route definitions\n    \"\"\"\n    # enable regex routes\n    app.url_map.converters['regex'] = RegexConverter\n\n    urls = app.name.rsplit('.', 1)[0] + '.urls.urls'\n\n    # important issue ahead\n    # see: https://github.com/projectshift/shift-boiler/issues/11\n    try:\n        urls = import_string(urls)\n    except ImportError as e:\n        err = 'Failed to import {}. If it exists, check that it does not '\n        err += 'import something non-existent itself! '\n        err += 'Try to manually import it to debug.'\n        raise ImportError(err.format(urls))\n\n    # add routes now\n    for route in urls.keys():\n        route_options = urls[route]\n        route_options['rule'] = route\n        app.add_url_rule(**route_options)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef undoable(method):\n    def undoable_method(self, *args):\n        return self.do(Command(self, method, *args))\n    return undoable_method", "response": "Decorator undoable allows an instance method to be undone."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets a restore point and call the method.", "response": "def do(self):\n        \"\"\"\n        Set a restore point (copy the object), then call the method.\n        :return: obj.do_method(*args)\n        \"\"\"\n        self.restore_point = self.obj.copy()\n        return self.do_method(self.obj, *self.args)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget path to migrations templates", "response": "def get_template_directory(self):\n        \"\"\"\n        Get path to migrations templates\n        This will get used when you run the db init command\n        \"\"\"\n        dir = os.path.join(os.path.dirname(__file__), 'templates')\n        return dir"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfunctions used when agent is lazy. It is being processed only when agent is lazy.", "response": "def ready(self):\n        \"\"\"\n        Function used when agent is `lazy`.\n        It is being processed only when `ready` condition is satisfied\n        \"\"\"\n        logger = self.get_logger()\n        now = current_ts()\n        logger.trace(\"Current time: {0}\".format(now))\n        logger.trace(\"Last Run: {0}\".format(self._last_run))\n        delta = (now - self._last_run)\n        logger.trace(\"Delta: {0}, Interval: {1}\"\n                     .format(delta, self.interval * 1000))\n        return delta > self.interval * 1000"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_jwt_secret():\n    secret_key = __options__.get(\"jwt_secret\") or config(\"JWT_SECRET\") or config(\"SECRET_KEY\")\n    if not secret_key:\n        raise exceptions.AuthError(\"Missing config JWT/SECRET_KEY\")\n    return secret_key", "response": "Get the JWT secret"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_user(username, password=None, email=None, first_name=\"\", last_name=\"\",\n                role=\"MEMBER\", login_method=None):\n    \"\"\"\n    Create a new user\n    :param username:\n    :param password:\n    :param email:\n    :param first_name:\n    :param last_name:\n    :param role: str\n    :return: AuthUser\n    \"\"\"\n\n    if not login_method:\n        login_method = \"email\" if \"@\" in username else \"username\"\n\n    def cb():\n        return _user(models.AuthUser.new(username=username,\n                                         password=password,\n                                         email=email,\n                                         first_name=first_name,\n                                         last_name=last_name,\n                                         login_method=login_method,\n                                         role=role))\n\n    return signals.create_user(cb)", "response": "Create a new user in the cluster."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nretrieve the user based on the data provided", "response": "def get_user(id=None, username=None, email=None, federated_id=None, provider=None, jwt=None):\n    \"\"\"\n    Retrieve the user based on the data provided\n     \n    :param id: \n    :param username: \n    :param email: \n    :param federated_id: \n    :param provider:\n    :param jwt: \n    :return: AuthUser\n    \"\"\"\n    if id:\n        return _user(models.AuthUser.get(id))\n    elif username:\n        return _user(models.AuthUser.get_by_username(username))\n    elif email:\n        return _user(models.AuthUser.get_by_email(email))\n    elif federated_id and provider:\n        user = models.AuthUserFederation.get_user(provider, federated_id)\n        return _user(user) if user else None\n    elif jwt:\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the AuthUser associated to the token. If token is not provided it will pull it from the headers.", "response": "def get_user_by_auth_token(token=None):\n    \"\"\"\n    Return the AuthUser associated to the token, otherwise it will return None.\n    If token is not provided, it will pull it from the headers: Authorization\n\n    Exception:\n    Along with AuthError, it may\n    :param token:\n    :return: AuthUser\n    \"\"\"\n    if not token:\n        token = request.get_auth_token()\n    secret_key = get_jwt_secret()\n    s = utils.unsign_jwt(token=token,\n                         secret_key=secret_key,\n                         salt=get_jwt_salt())\n    if \"id\" not in s:\n        raise exceptions.AuthError(\"Invalid Authorization Bearer Token\")\n    return get_user_by_id(int(s[\"id\"]))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the user by action token", "response": "def get_user_by_action_token(action, token):\n    \"\"\"\n    Get the user by action token\n    :param action: str\n    :param token: str\n    :return: AuthUser\n    \"\"\"\n    data = utils.unsign_url_safe(token,\n                                 secret_key=get_jwt_secret(),\n                                 salt=action)\n    if data is None:\n        raise exceptions.AuthError(\"Invalid Token\")\n    return get_user_by_id(int(data))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef with_username(username, password):\n    user = models.AuthUser.get_by_username(username)\n    return _user(user) if user and user.password_matched(password) else None", "response": "Returns a UserModel containing a username and password."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates the login session", "response": "def create_session(user):\n    \"\"\"\n    Create the login session \n    :param user: UserModel\n    :return:\n    \"\"\"\n\n    def cb():\n        if user:\n            if __options__.get(\"require_email_verification\") and not user.email_verified:\n                raise exceptions.VerifyEmailError()\n            if flask_login.login_user(user):\n                user.update(last_login_at=utc_now())\n                return user\n        return None\n\n    return signals.user_login(cb)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _url_for_email(endpoint, base_url=None, **kw):\n    base_url = base_url or config(\"MAIL_EXTERNAL_BASE_URL\")\n    _external = True if not base_url else False\n    url = url_for(endpoint, _external=_external, **kw)\n    if base_url and not _external:\n        url = \"%s/%s\" % (base_url.strip(\"/\"), url.lstrip(\"/\"))\n    return url", "response": "Create an external url_for by using a custom base_url different from the domain we\n    is on"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nchange username of user", "response": "def change_username(self, username):\n        \"\"\"\n        Change user's login email\n        :param user: AuthUser\n        :param email:\n        :return:\n        \"\"\"\n\n        def cb():\n\n            if self.login_method == \"username\" and \"@\" in username:\n                raise exceptions.AuthError(_(\"Username can't be an email\"))\n            elif self.login_method == \"email\" and \"@\" not in username:\n                raise exceptions.AuthError(_(\"Invalid email login\"))\n            if \"@\" in username:\n                if not utils.is_email_valid(username):\n                    raise exceptions.AuthError(\"Email address invalid\")\n            elif not utils.is_username_valid(username):\n                raise exceptions.AuthError(\"Username invalid\")\n\n            # Change both email and\n            if self.login_method == \"email\":\n                if not models.AuthUser.get_by_username(username) \\\n                        and not models.AuthUser.get_by_email(username):\n                    self.user.change_username(username)\n                    self.user.change_email(username)\n            else:\n                self.user.change_username(username)\n            return username\n\n        return signals.user_update(self, ACTIONS[\"USERNAME\"], cb)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef change_email(self, email):\n\n        def cb():\n            if not utils.is_email_valid(email):\n                raise exceptions.AuthError(\"Email address invalid\")\n            self.user.change_email(email)\n            return email\n\n        return signals.user_update(self, ACTIONS[\"EMAIL\"], cb,\n                                   {\"email\": self.email})", "response": "Change user s login email"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update_info(self, _action=None, **kwargs):\n\n        def cb():\n            kwargs.pop(\"email\", None)\n            kwargs.pop(\"username\", None)\n            kwargs.pop(\"password_hash\", None)\n            kwargs.pop(\"require_password_change\", None)\n            self.user.update(**kwargs)\n            return kwargs\n\n        _action = ACTIONS[\"UPDATE\"] if _action is None else _action\n        return signals.user_update(self, _action, cb, data=self.to_dict())", "response": "UPdate info\n        :param user:\n        :param email:\n        :return:"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef change_password(self, password):\n\n        def cb():\n            if not utils.is_password_valid(password):\n                raise exceptions.AuthError(\"Invalid Password\")\n            self.user.change_password(password)\n            return True\n\n        return signals.user_update(self, ACTIONS[\"PASSWORD\"], cb)", "response": "Change a user s password"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nresetting the user s password", "response": "def reset_password(self):\n        \"\"\"\n        Return the new random password that has been reset\n        :param user_login: AuthUserLogin\n        :return: string - the new password\n        \"\"\"\n\n        def cb():\n            password = get_random_password()\n            self.change_password(password)\n            return password\n\n        return signals.user_update(self, ACTIONS[\"PASSWORD\"], cb)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nchange the status of the user.", "response": "def change_status(self, status):\n        \"\"\"\n        Change the user's status\n        :param user:\n        :param email:\n        :return:\n        \"\"\"\n\n        def cb():\n            self.user.update(status=status)\n            return status\n\n        return signals.user_update(self, ACTIONS[\"STATUS\"], cb,\n                                   data={\"status\": self.status})"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_jwt(self, expires_in=None):\n        s = utils.sign_jwt(data={\"id\": self.user.id},\n                           secret_key=get_jwt_secret(),\n                           salt=get_jwt_salt(),\n                           expires_in=expires_in or get_jwt_ttl())\n        return s", "response": "Create a secure timed JWT token that can be passed to the user"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_action_token(self, action, expires_in):\n        return utils.sign_url_safe(self.user.id,\n                                   secret_key=get_jwt_secret(),\n                                   salt=action,\n                                   expires_in=expires_in)", "response": "Create a url safe action token attached to the user"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsign a user data.", "response": "def sign_data(self, data, expires_in=None, url_safe=True):\n        \"\"\"\n        To safely sign a user data. It will be signed with the user key\n        :param data: mixed\n        :param expires_in: The time for it to expire\n        :param url_safe: bool. If true it will allow it to be passed in URL\n        :return: str -  the token/signed data\n        \"\"\"\n        if url_safe:\n            return utils.sign_url_safe(data,\n                                       secret_key=self.secret_key,\n                                       salt=self.user_salt,\n                                       expires_in=expires_in)\n        else:\n            return utils.sign_data(data,\n                                   secret_key=self.secret_key,\n                                   salt=self.user_salt,\n                                   expires_in=expires_in)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef unsign_data(self, data, url_safe=True):\n        if url_safe:\n            return utils.unsign_url_safe(data,\n                                         secret_key=self.secret_key,\n                                         salt=self.user_salt)\n        else:\n            return utils.unsign_data(data,\n                                     secret_key=self.secret_key,\n                                     salt=self.user_salt)", "response": "Retrieve the signed data."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsee if a data matched a signed oneova", "response": "def signed_data_match(self, data, matched_data, url_safe=True):\n        \"\"\"\n        See if a data matched a signed one\n        :param data:\n        :param matched_data:\n        :param url_safe:\n        :return:\n        \"\"\"\n        try:\n            u_data = self.unsign_data(data, url_safe=url_safe)\n            return u_data == matched_data\n        except Exception as e:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef send_email(self, template, **kwargs):\n        user_data = {\n            \"id\": self.id,\n            \"username\": self.username,\n            \"name\": self.name,\n            \"first_name\": self.first_name,\n            \"last_name\": self.last_name,\n            \"email\": self.email\n        }\n        kwargs.pop(\"user\", None)\n        send_mail(to=self.email, template=template, user=user_data, **kwargs)", "response": "Send email to user"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef send_password_reset(self, base_url=None, view_class=None, **kw):\n\n        view = view_class or views.auth.Login\n        endpoint_reset = getattr(view, \"reset_password\")\n        endpoint_login = getattr(view, \"login\")\n        action = \"reset-password\"\n\n        method = __options__.get(\"reset_password_method\", \"TOKEN\")\n        template = __options__.get(\"email_templates.reset_password\",\n                                   \"auth/reset-password.txt\")\n        new_password = None\n\n        if method.upper() == \"TOKEN\":\n            expires_in = __options__.get(\"reset_password_token_ttl\", 1)\n            action_token = self.create_action_token(action, expires_in)\n            signed_data = self.sign_data(action, expires_in=expires_in)\n            url = _url_for_email(endpoint_reset,\n                                 base_url=base_url,\n                                 action_token=action_token,\n                                 signed_data=signed_data)\n        else:\n            new_password = self.reset_password()\n            url = _url_for_email(endpoint_login, base_url=base_url)\n\n        self.send_email(template=template,\n                        action={\n                            \"reset_method\": method.upper(),\n                            \"url\": url,\n                            \"new_password\": new_password\n                        },\n                        data=kw)", "response": "Send an email to reset a password and return the user s id"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _create_verify_email_token_url(self, base_url=None, view_class=None):\n        view = view_class or views.auth.Login\n        endpoint = getattr(view, \"verify_email\")\n        action = \"verify-email\"\n        expires_in = __options__.get(\"verify_email_token_ttl\") or (60 * 24)\n        action_token = self.create_action_token(action, expires_in)\n        signed_data = self.sign_data(action, expires_in=expires_in)\n        url = _url_for_email(endpoint,\n                             base_url=base_url,\n                             action_token=action_token,\n                             signed_data=signed_data)\n        return url", "response": "Create a verify email token url for the user"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_federation(self, provider, federated_id):\n        models.AuthUserFederation.new(user=self,\n                                      provider=provider,\n                                      federated_id=federated_id)", "response": "Add federated login to the current user s user cache"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef show_one(request, post_process_fun, object_class, id, template='common_json.html'):\n    obj = get_object_or_404(object_class, pk=id)\n    json = post_process_fun(request, obj)\n    return render_json(request, json, template=template, help_text=show_one.__doc__)", "response": "Show one object of the given type with the specified identifier."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef show_more(request, post_process_fun, get_fun, object_class, should_cache=True, template='common_json.html', to_json_kwargs=None):\n    if not should_cache and 'json_orderby' in request.GET:\n        return render_json(request, {\n            'error': \"Can't order the result according to the JSON field, because the caching for this type of object is turned off. See the documentation.\"\n            },\n            template='questions_json.html', help_text=show_more.__doc__, status=501)\n    if not should_cache and 'all' in request.GET:\n        return render_json(request, {\n            'error': \"Can't get all objects, because the caching for this type of object is turned off. See the documentation.\"\n            },\n            template='questions_json.html', help_text=show_more.__doc__, status=501)\n    if to_json_kwargs is None:\n        to_json_kwargs = {}\n    time_start = time_lib()\n    limit = min(int(request.GET.get('limit', 10)), 100)\n    page = int(request.GET.get('page', 0))\n    try:\n        objs = get_fun(request, object_class)\n        if 'db_orderby' in request.GET:\n            objs = objs.order_by(('-' if 'desc' in request.GET else '') + request.GET['db_orderby'].strip('/'))\n        if 'all' not in request.GET and 'json_orderby' not in request.GET:\n            objs = objs[page * limit:(page + 1) * limit]\n        cache_key = 'proso_common_sql_json_%s' % hashlib.sha1((str(objs.query) + str(to_json_kwargs)).encode()).hexdigest()\n        cached = cache.get(cache_key)\n        if should_cache and cached:\n            list_objs = json_lib.loads(cached)\n        else:\n            list_objs = [x.to_json(**to_json_kwargs) for x in list(objs)]\n            if should_cache:\n                cache.set(cache_key, json_lib.dumps(list_objs), 60 * 60 * 24 * 30)\n        LOGGER.debug('loading objects in show_more view took %s seconds', (time_lib() - time_start))\n        json = post_process_fun(request, list_objs)\n        if 'json_orderby' in request.GET:\n            time_before_json_sort = time_lib()\n            json.sort(key=lambda x: (-1 if 'desc' in request.GET else 1) * x[request.GET['json_orderby']])\n            if 'all' not in request.GET:\n                json = json[page * limit:(page + 1) * limit]\n            LOGGER.debug('sorting objects according to JSON field took %s seconds', (time_lib() - time_before_json_sort))\n        return render_json(request, json, template=template, help_text=show_more.__doc__)\n    except EmptyResultSet:\n        return render_json(request, [], template=template, help_text=show_more.__doc__)", "response": "Returns a list of objects of the given type."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef log(request):\n    if request.method == \"POST\":\n        log_dict = json_body(request.body.decode(\"utf-8\"))\n        if 'message' not in log_dict:\n            return HttpResponseBadRequest('There is no message to log!')\n        levels = {\n            'debug': JAVASCRIPT_LOGGER.debug,\n            'info': JAVASCRIPT_LOGGER.info,\n            'warn': JAVASCRIPT_LOGGER.warn,\n            'error': JAVASCRIPT_LOGGER.error,\n        }\n        log_fun = JAVASCRIPT_LOGGER.info\n        if 'level' in log_dict:\n            log_fun = levels[log_dict['level']]\n        log_fun(log_dict['message'], extra={\n            'request': request,\n            'user': request.user.id if request.user.is_authenticated() else None,\n            'client_data': json_lib.dumps(log_dict.get('data', {})),\n        })\n        return HttpResponse('ok', status=201)\n    else:\n        return render_json(request, {}, template='common_log_service.html', help_text=log.__doc__)", "response": "Logs an event from the client to the server."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef custom_config(request):\n    if request.method == 'POST':\n        config_dict = json_body(request.body.decode('utf-8'))\n        CustomConfig.objects.try_create(\n            config_dict['app_name'],\n            config_dict['key'],\n            config_dict['value'],\n            request.user.id,\n            config_dict.get('condition_key') if config_dict.get('condition_key') else None,\n            urllib.parse.unquote(config_dict.get('condition_value')) if config_dict.get('condition_value') else None\n        )\n        return config(request)\n    else:\n        return render_json(request, {}, template='common_custom_config.html', help_text=custom_config.__doc__)", "response": "Custom configuration for a specific user - specific configuration property."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef languages(request):\n    return render_json(request,\n                       settings.LANGUAGE_DOMAINS if hasattr(settings, 'LANGUAGE_DOMAINS') else\n                       {\"error\": \"Languages are not set. (Set LANGUAGE_DOMAINS in settings.py)\"},\n                       template='common_json.html', help_text=languages.__doc__)", "response": "Returns a list of languages that are available in the system."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert a Slack channel to an ID.", "response": "def channel_to_id(slack, channel):\n    \"\"\" Surely there's a better way to do this... \"\"\"\n    channels = slack.api_call('channels.list').get('channels') or []\n    groups = slack.api_call('groups.list').get('groups') or []\n\n    if not channels and not groups:\n        raise RuntimeError(\"Couldn't get channels and groups.\")\n\n    ids = [c['id'] for c in channels + groups if c['name'] == channel]\n\n    if not ids:\n        raise ValueError(f\"Couldn't find #{channel}\")\n\n    return ids[0]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef send_message(slack):\n    channel = input('Which channel would you like to message? ')\n    message = input('What should the message be? ')\n    channel_id = channel_to_id(slack, channel)\n\n    print(f\"Sending message to #{channel} (id: {channel_id})!\")\n    slack.rtm_send_message(channel_id, message)", "response": "Prompt for and send a message to a channel."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef main():\n    '''\n        Main part of command line utility\n    '''\n    arguments = docopt.docopt(__doc__, version='Naval Fate 2.0')\n\n    if arguments['show_diag']:\n        diag.show()\n\n    if arguments['show_reporting']:\n        diag.reporting()\n        diag.show()\n\n    if arguments['ping_couchdb']:\n        try:\n            if couchdb.ping():\n                print 'OK'\n            else:\n                print 'KO'\n        except:\n            print 'KO'\n\n    if arguments['get_admin']:\n        (username, password) = couchdb.get_admin()\n        print 'Username: {}'.format(username)\n        print 'Password: {}'.format(password)\n\n    if arguments['get_couchdb_admins']:\n        admins = couchdb.get_couchdb_admins()\n        print 'CouchDB admins:'\n        for admin in admins:\n            print '- {}'.format(admin)\n\n    if arguments['delete_token']:\n        couchdb.delete_token()\n\n    if arguments['create_token']:\n        print couchdb.create_token()\n\n    if arguments['create_cozy_db']:\n        if arguments['--name']:\n            db_name = arguments.get('<name>', 'cozy')\n        else:\n            db_name = 'cozy'\n        couchdb.create_cozy_db(db_name)\n        print '{} DB is ready'.format(db_name)\n\n    if arguments['reset_token']:\n        couchdb.reset_token()\n        print 'New tokens:'\n        print couchdb.get_admin()[0]\n\n    if arguments['get_cozy_param']:\n        print couchdb.get_cozy_param(arguments['<name>'])\n\n    if arguments['normalize_cert_dir']:\n        ssl.normalize_cert_dir()\n\n    if arguments['get_crt_common_name']:\n        filename = arguments['<filename>']\n        if filename:\n            print ssl.get_crt_common_name(filename)\n        else:\n            print ssl.get_crt_common_name()\n\n    if arguments['clean_links']:\n        ssl.clean_links()\n\n    if arguments['make_links']:\n        ssl.make_links(arguments['<common_name>'])\n\n    if arguments['generate_certificate']:\n        common_name = arguments['<common_name>']\n\n        if arguments['--size']:\n            key_size = int(arguments['<size>'])\n        else:\n            key_size = ssl.DEFAULT_KEY_SIZE\n\n        print 'Generate certificate for {} with {} key size'.format(common_name, key_size)\n        ssl.generate_certificate(common_name, key_size)\n\n    if arguments['sign_certificate']:\n        common_name = arguments['<common_name>']\n\n        print \"Sign certificate for {} with Let's Encrypt\".format(common_name)\n        ssl.acme_sign_certificate(common_name)\n\n    if arguments['renew_certificates']:\n        ssl.acme_renew_certificates()\n\n    if arguments['compare_version']:\n        current = arguments['<current>']\n        operator = arguments['<operator>']\n        reference = arguments['<reference>']\n        compare_version.compare(current, operator, reference)\n\n    if arguments['is_cozy_registered']:\n        print couchdb.is_cozy_registered()\n\n    if arguments['unregister_cozy']:\n        couchdb.unregister_cozy()\n\n    if arguments['fix_oom_scores']:\n        process.fix_oom_scores()\n\n    if arguments['get_oom_scores']:\n        process.get_oom_scores()\n\n    if arguments['rebuild_app']:\n        if arguments['--not-force']:\n            force = False\n        else:\n            force = True\n        if arguments['--restart']:\n            restart = True\n        else:\n            restart = False\n        migration.rebuild_app(arguments['<app>'], force=force, restart=restart)\n\n    if arguments['rebuild_all_apps']:\n        if arguments['--not-force']:\n            force = False\n        else:\n            force = True\n        if arguments['--restart']:\n            restart = True\n        else:\n            restart = False\n        migration.rebuild_all_apps(force=force, restart=restart)\n\n    if arguments['migrate_2_node4']:\n        migration.migrate_2_node4()\n\n    if arguments['install_requirements']:\n        migration.install_requirements()\n\n    if arguments['install_cozy']:\n        migration.install_cozy()\n\n    if arguments['wait_couchdb']:\n        helpers.wait_couchdb()\n\n    if arguments['wait_cozy_stack']:\n        helpers.wait_cozy_stack()\n\n    if arguments['check_lsb_codename']:\n        sys.exit(diag.check_lsb_codename())\n\n    if arguments['emulate_smtp']:\n        ip = '127.0.0.1'\n        port = '25'\n        if arguments['--bind']:\n            ip = arguments['<ip>']\n        if arguments['--port']:\n            if arguments['<port>']:  # a bug in docopt?\n                port = arguments['<port>']\n            else:\n                port = arguments['<ip>']\n\n        print 'Emulate SMTP server on {}:{}'.format(ip, port)\n        smtpd.DebuggingServer(tuple([ip, int(port)]), None)\n        asyncore.loop()\n\n    if arguments['backup']:\n        if arguments['<backup_filename>']:\n            backup_filename = arguments['<backup_filename>']\n        else:\n            backup_filename = None\n        backup.backup(backup_filename)\n\n    if arguments['restore']:\n        backup.restore(arguments['<backup_filename>'])\n\n    if arguments['install_weboob'] or arguments['update_weboob']:\n        weboob.install()\n\n    if arguments['update_weboob_modules']:\n        weboob.update()", "response": "This function is the entry point for the Naval Fate 2. 0 command line utility. It is the entry point for the Naval Fate 2. 0 command line utility."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse all the lines of a device block.", "response": "def parse_device(lines):\n    \"\"\"Parse all the lines of a device block.\n\n    A device block is composed of a header line with the name of the device and\n    at least one extra line describing the device and its status.  The extra\n    lines have a varying format depending on the status and personality of the\n    device (e.g. RAID1 vs RAID5, healthy vs recovery/resync).\n\n    \"\"\"\n    name, status_line, device = parse_device_header(lines.pop(0))\n\n    # There are edge cases when the device list is empty and the status line is\n    # merged with the header line, in those cases, the status line is returned\n    # from parse_device_header(), the rest of the time, it's the next line.\n    if not status_line:\n        status_line = lines.pop(0)\n\n    status = parse_device_status(status_line, device[\"personality\"])\n    bitmap = None\n    resync = None\n\n    for line in lines:\n        if line.startswith(\"      bitmap:\"):\n            bitmap = parse_device_bitmap(line)\n        elif line.startswith(\"      [\"):\n            resync = parse_device_resync_progress(line)\n        elif line.startswith(\"      \\tresync=\"):\n            resync = parse_device_resync_standby(line)\n        else:\n            raise NotImplementedError(\"unknown device line: {0}\".format(line))\n\n    device.update({\n        \"status\": status,\n        \"bitmap\": bitmap,\n        \"resync\": resync,\n    })\n\n    return (name, device)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_etag_header(header):\n    m = etag_header_re.match(header.strip())\n    if not m:\n        return []\n    if m.group(1):  # star\n        return m.group(1)\n    else:  # list of entity tags\n        return etag_re.findall(header)", "response": "Parse an ETag header."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef match_etag(etag, header, weak=False):\n    if etag is None:\n        return False\n    m = etag_re.match(etag)\n    if not m:\n        raise ValueError(\"Not a well-formed ETag: '%s'\" % etag)\n    (is_weak, etag) = m.groups()\n    parsed_header = parse_etag_header(header)\n    if parsed_header == '*':\n        return True\n    if is_weak and not weak:\n        return False\n    if weak:\n        return etag in [t[1] for t in parsed_header]\n    else:\n        return etag in [t[1] for t in parsed_header if not t[0]]", "response": "Try to match an ETag against a header value."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts datetime. datetime or Unix timestamp to HTTP date.", "response": "def datetime_to_httpdate(dt):\n    \"\"\"Convert datetime.datetime or Unix timestamp to HTTP date.\"\"\"\n    if isinstance(dt, (int, float)):\n        return format_date_time(dt)\n    elif isinstance(dt, datetime):\n        return format_date_time(datetime_to_timestamp(dt))\n    else:\n        raise TypeError(\"expected datetime.datetime or timestamp (int/float),\"\n                        \" got '%s'\" % dt)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert datetime. timedelta or number of seconds to HTTP date.", "response": "def timedelta_to_httpdate(td):\n    \"\"\"Convert datetime.timedelta or number of seconds to HTTP date.\n\n    Returns an HTTP date in the future.\n    \"\"\"\n    if isinstance(td, (int, float)):\n        return format_date_time(time.time() + td)\n    elif isinstance(td, timedelta):\n        return format_date_time(time.time() + total_seconds(td))\n    else:\n        raise TypeError(\"expected datetime.timedelta or number of seconds\"\n                        \"(int/float), got '%s'\" % td)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating the value for a Cache - Control header.", "response": "def cache_control(max_age=None, private=False, public=False, s_maxage=None,\n        must_revalidate=False, proxy_revalidate=False, no_cache=False,\n        no_store=False):\n    \"\"\"Generate the value for a Cache-Control header.\n\n    Example:\n\n        >>> from rhino.http import cache_control as cc\n        >>> from datetime import timedelta\n        >>> cc(public=1, max_age=3600)\n        'public, max-age=3600'\n        >>> cc(public=1, max_age=timedelta(hours=1))\n        'public, max-age=3600'\n        >>> cc(private=True, no_cache=True, no_store=True)\n        'private, no-cache, no-store'\n\n    \"\"\"\n    if all([private, public]):\n        raise ValueError(\"'private' and 'public' are mutually exclusive\")\n    if isinstance(max_age, timedelta):\n        max_age = int(total_seconds(max_age))\n    if isinstance(s_maxage, timedelta):\n        s_maxage = int(total_seconds(s_maxage))\n    directives = []\n    if public: directives.append('public')\n    if private: directives.append('private')\n    if max_age is not None: directives.append('max-age=%d' % max_age)\n    if s_maxage is not None: directives.append('s-maxage=%d' % s_maxage)\n    if no_cache: directives.append('no-cache')\n    if no_store: directives.append('no-store')\n    if must_revalidate: directives.append('must-revalidate')\n    if proxy_revalidate: directives.append('proxy-revalidate')\n    return ', '.join(directives)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the incidents of the current page.", "response": "def get_incidents(self) -> Union[list, bool]:\n        \"\"\" Get today's incidents. \"\"\"\n        brotts_entries_left = True\n        incidents_today = []\n        url = self.url\n\n        while brotts_entries_left:\n\n            requests_response = requests.get(\n                url, params=self.parameters)\n\n            rate_limited = requests_response.headers.get('x-ratelimit-reset')\n            if rate_limited:\n                print(\"You have been rate limited until \" +\n                      time.strftime(\n                          '%Y-%m-%d %H:%M:%S%z',\n                          time.localtime(rate_limited)\n                      ))\n                return False\n\n            requests_response = requests_response.json()\n\n            incidents = requests_response.get(\"data\")\n            if not incidents:\n                break\n\n            datetime_today = datetime.date.today()\n            datetime_today_as_time = time.strptime(\n                str(datetime_today), \"%Y-%m-%d\"\n            )\n            today_date_ymd = self._get_datetime_as_ymd(datetime_today_as_time)\n\n            for incident in incidents:\n                incident_pubdate = incident[\"pubdate_iso8601\"]\n                incident_date = time.strptime(\n                    incident_pubdate, \"%Y-%m-%dT%H:%M:%S%z\"\n                )\n                incident_date_ymd = self._get_datetime_as_ymd(incident_date)\n\n                if today_date_ymd == incident_date_ymd:\n                    incidents_today.append(incident)\n                else:\n                    brotts_entries_left = False\n                    break\n\n            if requests_response.get(\"links\"):\n                url = requests_response[\"links\"][\"next_page_url\"]\n            else:\n                break\n\n        return incidents_today"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a new oct project from a template file", "response": "def from_template(args):\n    \"\"\"Create a new oct project from existing template\n\n    :param Namespace args: command line arguments\n    \"\"\"\n    project_name = args.name\n    template = args.template\n\n    with tarfile.open(template) as tar:\n        prefix = os.path.commonprefix(tar.getnames())\n        check_template(tar.getnames(), prefix)\n        tar.extractall(project_name, members=get_members(tar, prefix))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_oct(args):\n    project_name = args.name\n    env = Environment(loader=PackageLoader('oct.utilities', 'templates'))\n\n    config_content = env.get_template('configuration/config.json').render(script_name='v_user.py')\n    script_content = env.get_template('scripts/v_user.j2').render()\n\n    try:\n        os.makedirs(project_name)\n        os.makedirs(os.path.join(project_name, 'test_scripts'))\n        os.makedirs(os.path.join(project_name, 'templates'))\n        os.makedirs(os.path.join(project_name, 'templates', 'img'))\n\n        shutil.copytree(os.path.join(BASE_DIR, 'templates', 'css'),\n                        os.path.join(project_name, 'templates', 'css'))\n        shutil.copytree(os.path.join(BASE_DIR, 'templates', 'javascript'),\n                        os.path.join(project_name, 'templates', 'scripts'))\n        shutil.copytree(os.path.join(BASE_DIR, 'templates', 'fonts'),\n                        os.path.join(project_name, 'templates', 'fonts'))\n\n        shutil.copy(os.path.join(BASE_DIR, 'templates', 'html', 'report.html'),\n                    os.path.join(project_name, 'templates'))\n    except OSError:\n        print('ERROR: can not create directory for %r' % project_name, file=sys.stderr)\n        raise\n    with open(os.path.join(project_name, 'config.json'), 'w') as f:\n        f.write(config_content)\n    with open(os.path.join(project_name, 'test_scripts', 'v_user.py'), 'w') as f:\n        f.write(script_content)", "response": "Create a new oct project containing all the necessary information."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef as_data_frame(self) -> pandas.DataFrame:\n        header_gene = {}\n        header_multiplex = {}\n        headr_transitions = {}\n        for gene in self.influence_graph.genes:\n            header_gene[gene] = repr(gene)\n            header_multiplex[gene] = f\"active multiplex on {gene!r}\"\n            headr_transitions[gene] = f\"K_{gene!r}\"\n        \n        columns = defaultdict(list)\n        for state in self.table.keys():\n            for gene in self.influence_graph.genes:\n                columns[header_gene[gene]].append(state[gene])\n                columns[header_multiplex[gene]].append(self._repr_multiplexes(gene, state))\n                columns[headr_transitions[gene]].append(self._repr_transition(gene, state))\n\n        header = list(header_gene.values()) + list(header_multiplex.values()) + list(headr_transitions.values())\n        return pandas.DataFrame(columns, columns=header)", "response": "Create a panda DataFrame representation of the resource table."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _associate_short_long(notices):\n    for notice in notices:\n        if notice.notice_type is not None and\\\n                notice.notice_category == \"StudentFinAid\" and\\\n                notice.notice_type.endswith(\"Short\"):\n            notice.long_notice = _find_notice_by_type(notices,\n                                                      notice.notice_type[:-5])\n    return notices", "response": "Associate a Short notice with its Long notice."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create(self, r, r_, R=200):\n        '''Create new spirograph image with given arguments. Returned image is\n        scaled to agent's preferred image size.\n        '''\n        x, y = give_dots(R, r, r_, spins=20)\n        xy = np.array([x, y]).T\n        xy = np.array(np.around(xy), dtype=np.int64)\n        xy = xy[(xy[:, 0] >= -250) & (xy[:, 1] >= -250) &\n                (xy[:, 0] < 250) & (xy[:, 1] < 250)]\n        xy = xy + 250\n        img = np.ones([500, 500], dtype=np.uint8)\n        img[:] = 255\n        img[xy[:, 0], xy[:, 1]] = 0\n        img = misc.imresize(img, [self.img_size, self.img_size])\n        fimg = img / 255.0\n        return fimg", "response": "Create new spirograph image with given arguments. Returned image is\n        scaled to agent s preferred image size."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef randomize_args(self):\n        '''Get new parameters for spirograph generation near agent's current\n        location (*spiro_args*).\n        '''\n        args = self.spiro_args + np.random.normal(0, self.move_radius,\n                                                  self.spiro_args.shape)\n        np.clip(args, -199, 199, args)\n        while args[0] == 0 or args[1] == 0:\n            args = self.spiro_args + np.random.normal(0, self.move_radius,\n                                                      self.spiro_args.shape)\n            np.clip(args, -199, 199, args)\n        return args", "response": "Get new parameters for spirograph generation near agent s current\n        location."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef hedonic_value(self, novelty):\n        '''Given the agent's desired novelty, how good the novelty value is.\n\n        Not used if *desired_novelty*=-1\n        '''\n        lmax = gaus_pdf(self.desired_novelty, self.desired_novelty, 4)\n        pdf = gaus_pdf(novelty, self.desired_novelty, 4)\n        return pdf / lmax", "response": "Given the agent s desired novelty returns how good the novelty value is."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nimages s distance to the agent s short - term memory. Usually distance to the closest object model in the memory.", "response": "def novelty(self, img):\n        '''Image's distance to the agent's short-term memory. Usually distance\n        to the closest object/prototypical object model in the memory.\n        '''\n        dist = self.stmem.distance(img.flatten())\n        return dist"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nevaluate the artifact with respect to the agents short term memory. Returns value in [ 0 1 )", "response": "def evaluate(self, artifact):\n        '''Evaluate the artifact with respect to the agents short term memory.\n\n        Returns value in [0, 1].\n        '''\n        if self.desired_novelty > 0:\n            return self.hedonic_value(self.novelty(artifact.obj))\n        return self.novelty(artifact.obj) / self.img_size, None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninvent new spirograph by taking n random steps from current position and selecting the best one based on the agent s evaluation function.", "response": "def invent(self, n):\n        '''Invent new spirograph by taking n random steps from current position\n        (spirograph generation parameters) and selecting the best one based\n        on the agent's evaluation (hedonic function).\n\n        :param int n: how many spirographs are created for evaluation\n        :returns: Best created artifact.\n        :rtype: :py:class:`~creamas.core.agent.Artifact`\n        '''\n        args = self.randomize_args()\n        img = self.create(args[0], args[1])\n        best_artifact = SpiroArtifact(self, img, domain='image')\n        ev, _ = self.evaluate(best_artifact)\n        best_artifact.add_eval(self, ev, fr={'args': args})\n        for i in range(n-1):\n            args = self.randomize_args()\n            img = self.create(args[0], args[1])\n            artifact = SpiroArtifact(self, img, domain='image')\n            ev, _ = self.evaluate(artifact)\n            artifact.add_eval(self, ev, fr={'args': args})\n            if ev > best_artifact.evals[self.name]:\n                best_artifact = artifact\n        self.spiro_args = best_artifact.framings[self.name]['args']\n        best_artifact.in_domain = False\n        best_artifact.self_criticism = 'reject'\n        best_artifact.creation_time = self.age\n        return best_artifact"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef learn(self, spiro, iterations=1):\n        '''Train short term memory with given spirograph.\n\n        :param spiro:\n            :py:class:`SpiroArtifact` object\n        '''\n        for i in range(iterations):\n            self.stmem.train_cycle(spiro.obj.flatten())", "response": "Train short term memory with given spirograph."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nplot places where the agent has been generated a spirograph.", "response": "def plot_places(self):\n        '''Plot places where the agent has been and generated a spirograph.\n        '''\n        from matplotlib import pyplot as plt\n        fig, ax = plt.subplots()\n        x = []\n        y = []\n\n        if len(self.arg_history) > 1:\n            xs = []\n            ys = []\n            for p in self.arg_history:\n                xs.append(p[0])\n                ys.append(p[1])\n            ax.plot(xs, ys, color=(0.0, 0.0, 1.0, 0.1))\n\n        for a in self.A:\n            if a.self_criticism == 'pass':\n                args = a.framings[a.creator]['args']\n                x.append(args[0])\n                y.append(args[1])\n\n        sc = ax.scatter(x, y, marker=\"x\", color='red')\n        ax.set_xlim([-200, 200])\n        ax.set_ylim([-200, 200])\n\n        agent_vars = \"{}_{}_{}{}_last={}_stmem=list{}_veto={}_sc={}_jump={}_sw={}_mr={}_maxN\".format(\n            self.name, self.age, self.env_learning_method, self.env_learning_amount, self.env_learn_on_add,\n            self.stmem.length, self._novelty_threshold, self._own_threshold,\n            self.jump, self.search_width, self.move_radius)\n\n        if self.logger is not None:\n            imname = os.path.join(self.logger.folder, '{}.png'.format(agent_vars))\n            plt.savefig(imname)\n            plt.close()\n\n            fname = os.path.join(self.logger.folder, '{}.txt'.format(agent_vars))\n            with open(fname, \"w\") as f:\n                f.write(\" \".join([str(e) for e in xs]))\n                f.write(\"\\n\")\n                f.write(\" \".join([str(e) for e in ys]))\n                f.write(\"\\n\")\n                f.write(\" \".join([str(e) for e in x]))\n                f.write(\"\\n\")\n                f.write(\" \".join([str(e) for e in y]))\n                f.write(\"\\n\")\n        else:\n            plt.show()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef plot_places(self):\n        '''Plot places (in the parameter space) of all the generated artifacts\n        and the artifacts accepted to the domain.\n        '''\n        from matplotlib import pyplot as plt\n        fig, ax = plt.subplots()\n        title = \"Agent places, artifacts and env artifacts ({} env artifacts)\".format(len(self.artifacts))\n\n        x = []\n        y = []\n        for a in self.get_agents():\n            args = a.arg_history\n            x = x + [e[0] for e in args]\n            y = y + [e[1] for e in args]\n        sc = ax.scatter(x, y, marker='.', color=(0, 0, 1, 0.1), label='agent place')\n\n        x = []\n        y = []\n        for a in self.get_agents():\n            arts = a.A\n            for ar in arts:\n                if ar.self_criticism == 'pass':\n                    args = ar.framings[ar.creator]['args']\n                    x.append(args[0])\n                    y.append(args[1])\n        sc = ax.scatter(x, y, marker=\"x\", color=(0, 0, 1, 0.3), label='agent artifact')\n\n        x = []\n        y = []\n        for a in self.artifacts:\n            args = a.framings[a.creator]['args']\n            x.append(args[0])\n            y.append(args[1])\n\n        sc = ax.scatter(x, y, marker=\"x\", color='red', label='env artifact',\n                        s=40)\n        ax.set_xlim([-200, 200])\n        ax.set_ylim([-200, 200])\n        ax.set_xlabel('r')\n        ax.set_ylabel('r_')\n        ax.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=10)\n        ax.set_title(title)\n        plt.tight_layout(rect=(0,0,0.8,1))\n\n        if self.logger is not None and self.logger.folder is not None:\n            imname = os.path.join(self.logger.folder, 'arts_a{}_i{}_v{}.png'\n                                  .format(len(self.get_agents()), self.age,\n                                          self.voting_method))\n            plt.savefig(imname)\n            plt.close()\n        else:\n            plt.show()", "response": "Plot places of all the generated artifacts\n        and the artifacts accepted to the domain."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef destroy(self, folder=None):\n        '''Destroy the environment and the subprocesses.\n        '''\n        ameans = [(0, 0, 0) for _ in range(3)]\n        ret = [self.save_info(folder, ameans)]\n        aiomas.run(until=self.stop_slaves(folder))\n        # Close and join the process pool nicely.\n        self._pool.close()\n        self._pool.terminate()\n        self._pool.join()\n        self._env.shutdown()\n        return ret", "response": "Destroy the environment and the subprocesses."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef translate_codons(sequence):\n    '''Return the translated protein from 'sequence' assuming +1 reading frame\n       Source - http://adamcoster.com/2011/01/13/python-clean-up-and-translate-nucleotide-sequences/\n    '''\n    return ''.join([gencode.get(sequence[3*i:3*i+3],'X') for i in range(len(sequence)//3)])", "response": "Return the translated protein from sequence assuming + 1 reading frame\n       Source - http://adamcoster. com / 2013 - 01 - 13 / python - clean - up - and - translate - nucleotide - sequences"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pdb_atom_name_to_element(s):\n    '''s should be a string taken from columns 12-15 (zero-indexed) inclusive of a PDB coordinate line.'''\n    assert(len(s) == 4)\n    if len(s.strip()) == 4:\n        assert(s[0] == 'H' or s[0] == 'C' or s[0] == 'O') # \"If the name of a hydrogen has four characters, it is left-justified starting in column 13; if it has fewer than four characters, it is left-justified starting in column 14. If the name of a hydrogen has four characters, it is left-justified starting in column 13; if it has fewer than four characters, it is left-justified starting in column 14.\"\n        return s[0] # I think this works for hydrogen - I do not know if it is generally correct for carbon and oxygen but something like this is necessary - see CE11 in 1DAN. The correct approach is described somewhere in the  IUPAC recommendations (Pure Appl Chem 70:117 (1998), http://www.iupac.org/publications/pac/1998/pdf/7001x0117.pdf.\n    else:\n        return s[:2].strip()", "response": "Returns the element ID of the given atom name."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef mutation_combinations(mutations):\n    '''A generator which returns all non-empty combinations of ChainMutation objects, respecting residue position i.e. if two residues\n       have the same chain and residue ID then we do not return a combination with both residues.\n       Note: You need to use ChainMutation objects here as their equality considers the chain id.\n    '''\n    mutations = sorted(mutations)\n    combntn = itertools.chain.from_iterable(itertools.combinations(mutations, x) for x in range(len(mutations) + 1))\n    for c in combntn:\n        if len(c) > 0: # filter out the empty combination\n            positions = ['%s%s' % (m.Chain, m.ResidueID.strip()) for m in c]\n            if len(positions) == len(set(positions)): # filter out combinations where\n                yield c", "response": "A generator which returns all non - empty combinations of ChainMutation objects respecting residue position i. e. all residues in the chain are in the same residue ID."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add(self, r):\n        '''Takes an id and a Residue r and adds them to the Sequence.'''\n        id = r.get_residue_id()\n        if self.order:\n            last_id = self.order[-1]\n\n            # KAB - allow for multiresidue noncanonicals\n            if id in self.order:\n                raise colortext.Exception('Warning: using code to \"allow for multiresidue noncanonicals\" - check this case manually.')\n                id = '%s.%d'%(str(id),self.special_insertion_count)\n                self.special_insertion_count += 1\n\n            assert(r.Chain == self.sequence[last_id].Chain)\n            assert(r.residue_type == self.sequence[last_id].residue_type)\n        self.order.append(id)\n        self.sequence[id] = r", "response": "Takes an id and a Residue r and adds them to the Sequence."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_type(self, sequence_type):\n        '''Set the type of a Sequence if it has not been set.'''\n        if not(self.sequence_type):\n            for id, r in self.sequence.iteritems():\n                assert(r.residue_type == None)\n                r.residue_type = sequence_type\n            self.sequence_type = sequence_type", "response": "Set the type of a Sequence if it has not been set."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef from_sequence(chain, list_of_residues, sequence_type = None):\n        '''Takes in a chain identifier and protein sequence and returns a Sequence object of Residues, indexed from 1.'''\n        s = Sequence(sequence_type)\n        count = 1\n        for ResidueAA in list_of_residues:\n            s.add(Residue(chain, count, ResidueAA, sequence_type))\n            count += 1\n        return s", "response": "Takes in a chain identifier and protein sequence and returns a Sequence object of Residues indexed from 1."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks to make sure that the substitution scores agree.", "response": "def substitution_scores_match(self, other):\n        '''Check to make sure that the substitution scores agree. If one map has a null score and the other has a non-null score, we trust the other's score and vice versa.'''\n        overlap = set(self.substitution_scores.keys()).intersection(set(other.substitution_scores.keys()))\n        for k in overlap:\n            if not(self.substitution_scores[k] == None or other.substitution_scores[k] == None):\n                if self.substitution_scores[k] != other.substitution_scores[k]:\n                    return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmerge two element counters. For all elements we take the max count from both counters. For all elements we take the max count from both counters. For all elements we take the max count from both counters. For all elements we take the max count from both counters.", "response": "def merge(self, other):\n        '''Merge two element counters. For all elements, we take the max count from both counters.'''\n        our_element_frequencies = self.items\n        their_element_frequencies = other.items\n        for element_name, freq in sorted(our_element_frequencies.iteritems()):\n            our_element_frequencies[element_name] = max(our_element_frequencies.get(element_name, 0), their_element_frequencies.get(element_name, 0))\n        for element_name, freq in sorted(their_element_frequencies.iteritems()):\n            if element_name not in our_element_frequencies:\n                our_element_frequencies[element_name] = their_element_frequencies[element_name]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nserializing obj as an avro - format byte stream to the provided fp file - like object stream.", "response": "def dump(self, obj, fp):\n        \"\"\"\n        Serializes obj as an avro-format byte stream to the provided\n        fp file-like object stream.\n        \"\"\"\n        if not validate(obj, self._raw_schema):\n            raise AvroTypeException(self._avro_schema, obj)\n        fastavro_write_data(fp, obj, self._raw_schema)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nserializes obj to an avro - format byte array and returns it.", "response": "def dumps(self, obj):\n        \"\"\"\n        Serializes obj to an avro-format byte array and returns it.\n        \"\"\"\n        out = BytesIO()\n        try:\n            self.dump(obj, out)\n            return out.getvalue()\n        finally:\n            out.close()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse the phone intervals in a TextGrid and return a list of Phone objects.", "response": "def parse_phones(self):\n        \"\"\"Parse TextGrid phone intervals.\n        \n        This method parses the phone intervals in a TextGrid to extract each\n        phone and each phone's start and end times in the audio recording. For\n        each phone, it instantiates the class Phone(), with the phone and its\n        start and end times as attributes of that class instance.\n        \n        \"\"\"\n        phones = []\n        \n        for i in self.phone_intervals:\n            start = float(i[i.index('xmin = ')+7:\n                            i.index('xmin = ')+12].strip('\\t').strip('\\n'))\n            end = float(i[i.index('xmax = ')+7:\n                          i.index('xmax = ')+12].strip('\\t').strip('\\n'))\n            phone = i[i.index('\\\"')+1:i.index(\"$\")]\n            phones.append(Phone(phone, start, end))\n            \n        return phones"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse the word intervals in a TextGrid and return a list of Word objects.", "response": "def parse_words(self):\n        \"\"\"Parse TextGrid word intervals.\n        \n        This method parses the word intervals in a TextGrid to extract each\n        word and each word's start and end times in the audio recording. For\n        each word, it instantiates the class Word(), with the word and its\n        start and end times as attributes of that class instance. Further, it\n        appends the class instance's attribute 'phones' for each phone that\n        occurs in that word. (It does this by checking which phones' start and\n        end times are subsumed by the start and end times of the word.)\n        \n        \"\"\"\n        phones = self.parse_phones()\n        words = []\n        \n        for i in self.word_intervals:\n            start = float(i[i.index('xmin = ')+7:\n                            i.index('xmin = ')+12].strip('\\t').strip('\\n'))\n            end = float(i[i.index('xmax = ')+7:\n                          i.index('xmax = ')+12].strip('\\t').strip('\\n'))\n            word = i[i.index('\\\"')+1:i.index(\"$\")]\n            words.append(Word(word, start, end))\n            \n        for word in words:\n            for phone in phones:\n                if phone.start >= word.start and phone.end <= word.end:\n                    word.phones.append(phone)\n            \n        return words"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a PID relation for given parent and child.", "response": "def create(cls, parent, child, relation_type, index=None):\n        \"\"\"Create a PID relation for given parent and child.\"\"\"\n        try:\n            with db.session.begin_nested():\n                obj = cls(parent_id=parent.id,\n                          child_id=child.id,\n                          relation_type=relation_type,\n                          index=index)\n                db.session.add(obj)\n        except IntegrityError:\n            raise Exception(\"PID Relation already exists.\")\n            # msg = \"PIDRelation already exists: \" \\\n            #       \"{0} -> {1} ({2})\".format(\n            #         parent_pid, child_pid, relation_type)\n            # logger.exception(msg)\n            # raise Exception(msg)\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef relation_exists(self, parent, child, relation_type):\n        return PIDRelation.query.filter_by(\n            child_pid_id=child.id,\n            parent_pid_id=parent.id,\n            relation_type=relation_type).count() > 0", "response": "Determine if given relation already exists."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef df(unit = 'GB'):\n    '''A wrapper for the df shell command.'''\n    details = {}\n    headers = ['Filesystem', 'Type', 'Size', 'Used', 'Available', 'Capacity', 'MountedOn']\n    n = len(headers)\n\n    unit = df_conversions[unit]\n    p = subprocess.Popen(args = ['df', '-TP'], stdout = subprocess.PIPE) # -P prevents line wrapping on long filesystem names\n    stdout, stderr = p.communicate()\n\n    lines = stdout.split(\"\\n\")\n    lines[0] = lines[0].replace(\"Mounted on\", \"MountedOn\").replace(\"1K-blocks\", \"Size\").replace(\"1024-blocks\", \"Size\")\n    assert(lines[0].split() == headers)\n\n    lines = [l.strip() for l in lines if l.strip()]\n    for line in lines[1:]:\n        tokens = line.split()\n        if tokens[0] == 'none': # skip uninteresting entries\n            continue\n\n        assert(len(tokens) == n)\n        d = {}\n        for x in range(1, len(headers)):\n            d[headers[x]] = tokens[x]\n        d['Size'] = float(d['Size']) / unit\n        assert(d['Capacity'].endswith(\"%\"))\n        d['Use%'] = d['Capacity']\n        d['Used'] = float(d['Used']) / unit\n        d['Available'] = float(d['Available']) / unit\n        d['Using'] = 100*(d['Used']/d['Size']) # same as Use% but with more precision\n\n        if d['Type'].startswith('ext'):\n            pass\n            d['Using'] += 5 # ext2, ext3, and ext4 reserve 5% by default\n        else:\n            ext3_filesystems = ['ganon:', 'kortemmelab:', 'albana:']\n            for e3fs in ext3_filesystems:\n                if tokens[0].find(e3fs) != -1:\n                    d['Using'] += 5 # ext3 reserves 5%\n                    break\n\n        details[tokens[0]] = d\n\n    return details", "response": "A wrapper for the df shell command."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreplacing the field in the GET params of the object", "response": "def url_replace(context, field, value):\n    \"\"\"\n    To avoid GET params losing\n\n    :param context: context_obj\n    :param field: str\n    :param value: str\n    :return: dict-like object\n    \"\"\"\n\n    query_string = context['request'].GET.copy()\n    query_string[field] = value\n\n    return query_string.urlencode()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn ellipsis or number depending on current page", "response": "def ellipsis_or_number(context, paginator, current_page):\n    \"\"\"\n    To avoid display a long pagination bar\n\n    :param context: template context\n    :param paginator: paginator_obj\n    :param current_page: int\n    :return: str or None\n    \"\"\"\n\n    # Checks is it first page\n    chosen_page = int(context['request'].GET['page']) if 'page' in context['request'].GET else 1\n\n    if current_page in (chosen_page + 1, chosen_page + 2, chosen_page - 1, chosen_page - 2,\n                        paginator.num_pages, paginator.num_pages - 1, 1, 2, chosen_page):\n        return current_page\n\n    if current_page in (chosen_page + 3, chosen_page - 3):\n        return '...'"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_items(sender, instance, **kwargs):\n    if instance.item_id is None and instance.item is None:\n        item = Item()\n        if hasattr(instance, 'active'):\n            item.active = getattr(instance, 'active')\n        item.save()\n        instance.item = item", "response": "When one of the items is created initialize also its item."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_parent(sender, instance, **kwargs):\n    if not kwargs['created']:\n        return\n    for att in ['task', 'context']:\n        parent = getattr(instance, att).item_id\n        child = instance.item_id\n        ItemRelation.objects.get_or_create(\n            parent_id=parent,\n            child_id=child,\n            visible=True,\n        )", "response": "When a task instance is created create also an item relation."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\naligns the species to the species of the other species.", "response": "def align_to_other(self, other, mapping, self_root_pair, other_root_pair = None):\n        '''\n        root atoms are atom which all other unmapped atoms will be mapped off of\n        '''\n        if other_root_pair == None:\n            other_root_pair = self_root_pair\n\n        assert( len(self_root_pair) == len(other_root_pair) )\n\n        unmoved_atom_names = []\n        new_coords = [ None for x in xrange( len(self_root_pair) ) ]\n        for atom in self.names:\n            if atom in self_root_pair:\n                i = self_root_pair.index(atom)\n                assert( new_coords[i] == None )\n                new_coords[i] = self.get_coords_for_name(atom)\n\n            if atom in mapping:\n                other_atom = mapping[atom]\n                self.set_coords_for_name( atom, other.get_coords_for_name(other_atom) )\n            else:\n                unmoved_atom_names.append(atom)\n\n        # Move unmoved coordinates after all other atoms have been moved (so that\n        # references will have been moved already)\n        if None in new_coords:\n            print new_coords\n            assert( None not in new_coords )\n        ref_coords = [other.get_coords_for_name(x) for x in other_root_pair]\n\n        # Calculate translation and rotation matrices\n        U, new_centroid, ref_centroid = calc_rotation_translation_matrices( ref_coords, new_coords )\n        for atom in unmoved_atom_names:\n            original_coord = self.get_coords_for_name(atom)\n            self.set_coords_for_name( atom, rotate_and_translate_coord(original_coord, U, new_centroid, ref_centroid) )\n        self.chain = other.chain"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pumper(html_generator):\n    source = html_generator()\n    parser = etree.HTMLPullParser(\n        events=('start', 'end'),\n        remove_comments=True\n    )\n    while True:\n        for element in parser.read_events():\n            yield element\n        try:\n            parser.feed(next(source))\n        except StopIteration:\n            # forces close of any unclosed tags\n            parser.feed('</html>')\n            for element in parser.read_events():\n                yield element\n            break", "response": "Yields DOM elements from source generator."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse(self, parent):\n\n        last_child = None\n\n        for event, element in self.stream:\n\n            tag = element.tag\n\n            if event == 'start':\n\n                last_child = element\n\n                if isinstance(parent.behavior, Table):\n\n                    # these are not direct descendants of <table>, add missing parent\n\n                    if tag in ('td', 'th', 'tr'):\n                        parent = parent.behavior.tbody or self.make_child(parent, 'tbody', {})\n\n                    elif tag == 'col':\n                        parent = parent.behavior.columns or self.make_child(parent, 'colgroup', {})\n\n                elif isinstance(parent.behavior, TableRowGroup):\n\n                    # these are not direct descendants of <tbody>, add missing parent\n\n                    if tag in ('td', 'th'):\n                        parent = self.make_child(parent, 'tr', {})\n\n                node = self.make_child(parent, tag, element.attrib)\n\n                if isinstance(node.behavior, Table) and self.table_columns:\n                    measurements_data = self.table_columns.pop(0)\n                    node.behavior.columns.behavior.measurements = measurements_data['maximums']\n                    node.behavior.columns.behavior.span = measurements_data['span']\n\n                if isinstance(node.behavior, Table) and parent.tag == 'body':\n                    yield from self.parse(node)\n\n                else:\n\n                    # root tables are a very special case\n                    # where the table and row groups\n                    # are not yielded but the table rows\n                    # themselves are yielded as \"root nodes\"\n\n                    skip_root_table_meta_groups = (  # don't yield <colgroup>, <thead>, <tbody>, <tfoot>\n                        parent.parent and parent.parent.tag == 'body' and\n                        isinstance(node.behavior, (TableRowGroup, TableColumnGroup, TableCaption))\n                    )\n\n                    yield_root_table_rows = (  # do yield <tr> that's inside <tbody>\n                        skip_root_table_meta_groups and\n                        node.style.display == 'table-row-group'\n                    )\n\n                    position = 0\n                    position_of_type = {}\n\n                    for previous, (child_element, child_node), last in iter_previous_current_last(self.parse(node)):\n                        if previous is not None:\n                            if node.text_allowed and previous[0].tail:\n                                # insert text between previous node and current node\n                                node.insert(len(node.children)-2, previous[0].tail)\n                        position_of_type.setdefault(child_node.tag, 0)\n                        child_node.position = position = position + 1\n                        child_node.position_of_type = position_of_type[child_node.tag] = position_of_type[child_node.tag] + 1\n                        child_node.last = last\n                        if yield_root_table_rows and isinstance(child_node.behavior, TableRow):\n                            self.css.apply_recursively(child_node)\n                            yield child_element, child_node\n\n                    if node.text_allowed and element.text:\n                        node.insert(0, element.text)\n\n                    if not skip_root_table_meta_groups:\n                        yield element, node\n\n            else:\n\n                if parent.text_allowed and last_child is not None and last_child.tail:\n                    parent.add(last_child.tail)\n\n                break", "response": "Parse the XML tree."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef date_to_long_form_string(dt, locale_ = 'en_US.utf8'):\n    '''dt should be a datetime.date object.'''\n    if locale_:\n        old_locale = locale.getlocale()\n        locale.setlocale(locale.LC_ALL, locale_)\n    v = dt.strftime(\"%A %B %d %Y\")\n    if locale_:\n        locale.setlocale(locale.LC_ALL, old_locale)\n    return v", "response": "converts a datetime. date object to a long form string."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrebuilding cozy apps with deletion of npm directory & new npm build", "response": "def rebuild_app(app_name, quiet=False, force=True, without_exec=False,\n                restart=False):\n    '''\n        Rebuild cozy apps with deletion of npm directory & new npm build\n    '''\n    user = 'cozy-{app_name}'.format(app_name=app_name)\n    home = '{prefix}/{app_name}'.format(prefix=PREFIX, app_name=app_name)\n    command_line = 'cd {home}'.format(home=home)\n    command_line += ' && git pull'\n    if force:\n        command_line += ' && ([ -d node_modules ] && rm -rf node_modules || true)'\n        command_line += ' && ([ -d .node-gyp ] && rm -rf .node-gyp || true)'\n        command_line += ' && ([ -d .npm ] && rm -rf .npm || true)'\n    command_line += ' && chown -R {user}:{user} .'.format(user=user)\n    command_line += ' && sudo -u {user} env HOME={home} npm install --production'.format(\n        user=user,\n        home=home\n    )\n    if restart:\n        command_line += ' && cozy-monitor update {app_name}'.format(\n            app_name=app_name)\n        command_line += ' && cozy-monitor restart {app_name}'.format(\n            app_name=app_name)\n\n    if not quiet:\n        print 'Execute:'\n        print command_line\n\n    if not without_exec:\n        result = helpers.cmd_exec(command_line)\n        print result['stdout']\n        print result['stderr']\n        print result['error']"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef rebuild_all_apps(force=True, restart=False):\n    '''\n        Get all cozy apps & rebuild npm repository\n    '''\n    cozy_apps = monitor.status(only_cozy=True)\n    for app in cozy_apps.keys():\n        rebuild_app(app, force=force, restart=restart)", "response": "Rebuild npm repository for all cozy apps"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrestart all apps in stopped state Restart all apps in stopped state", "response": "def restart_stopped_apps():\n    '''\n        Restart all apps in stopped state\n    '''\n    cozy_apps = monitor.status(only_cozy=True)\n    for app in cozy_apps.keys():\n        state = cozy_apps[app]\n        if state == 'up':\n            next\n        elif state == 'down':\n            print 'Start {}'.format(app)\n            rebuild_app(app, force=False)\n            monitor.start(app)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmigrates existing cozy to node4 cozy", "response": "def migrate_2_node4():\n    '''\n        Migrate existing cozy to node4\n    '''\n    helpers.cmd_exec('npm install -g cozy-monitor cozy-controller',\n                     show_output=True)\n    helpers.cmd_exec('update-cozy-stack', show_output=True)\n    helpers.cmd_exec('update-all', show_output=True)\n    helpers.cmd_exec('rm /etc/supervisor/conf.d/cozy-indexer.conf',\n                     show_output=True)\n    helpers.cmd_exec('supervisorctl reload', show_output=True)\n    helpers.wait_cozy_stack()\n    ssl.normalize_cert_dir()\n    helpers.cmd_exec('apt-get update', show_output=True)\n    helpers.cmd_exec(\n        'echo \"cozy cozy/nodejs_apt_list text \" | debconf-set-selections',\n        show_output=True)\n    helpers.cmd_exec('apt-get install -y cozy-apt-node-list', show_output=True)\n    helpers.cmd_exec('apt-get update', show_output=True)\n    helpers.cmd_exec('apt-get remove -y nodejs-legacy', show_output=True)\n    helpers.cmd_exec('apt-get remove -y nodejs-dev', show_output=True)\n    helpers.cmd_exec('apt-get remove -y npm', show_output=True)\n    helpers.cmd_exec('apt-get install -y nodejs', show_output=True)\n    helpers.cmd_exec('apt-get install -y cozy', show_output=True)\n    helpers.cmd_exec('npm install -g cozy-monitor cozy-controller',\n                     show_output=True)\n    rebuild_app('data-system')\n    rebuild_app('home')\n    rebuild_app('proxy')\n    helpers.cmd_exec('supervisorctl restart cozy-controller', show_output=True)\n    helpers.wait_cozy_stack()\n    rebuild_all_apps(restart=True)\n    restart_stopped_apps()\n    helpers.cmd_exec('apt-get install -y cozy', show_output=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a message with an optional type.", "response": "def add_message(self, text, type=None):\n        \"\"\"Add a message with an optional type.\"\"\"\n        key = self._msg_key\n        self.setdefault(key, [])\n        self[key].append(message(type, text))\n        self.save()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nretrieve stored messages and remove them from the session.", "response": "def pop_messages(self, type=None):\n        \"\"\"Retrieve stored messages and remove them from the session.\n\n        Return all messages with a specific type, or all messages when `type`\n        is None. Messages are returned in the order they were added. All\n        messages returned in this way are removed from the session and will not\n        be returned in subsequent calls.\n\n        Returns a list of namedtuples with the fields (type, text).\n        \"\"\"\n        key = self._msg_key\n        messages = []\n        if type is None:\n            messages = self.pop(key, [])\n        else:\n            keep_messages = []\n            for msg in self.get(key, []):\n                if msg.type == type:\n                    messages.append(msg)\n                else:\n                    keep_messages.append(msg)\n            if not keep_messages and key in self:\n                del self[key]\n            else:\n                self[key] = keep_messages\n        if messages:\n            self.save()\n\n        return messages"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nselects random winners from the candidates. This voting method bypasses the given votes completely. :param candidates: All candidates in the vote :param votes: Votes from the agents :param int n_winners: The number of vote winners", "response": "def vote_random(candidates, votes, n_winners):\n    \"\"\"Select random winners from the candidates.\n\n    This voting method bypasses the given votes completely.\n\n    :param candidates: All candidates in the vote\n    :param votes: Votes from the agents\n    :param int n_winners: The number of vote winners\n    \"\"\"\n    rcands = list(candidates)\n    shuffle(rcands)\n    rcands = rcands[:min(n_winners, len(rcands))]\n    best = [(i, 0.0) for i in rcands]\n    return best"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nselecting the least worst artifact as the winner of the vote.", "response": "def vote_least_worst(candidates, votes, n_winners):\n    \"\"\"Select \"least worst\" artifact as the winner of the vote.\n\n    Least worst artifact is the artifact with the best worst evaluation, i.e.\n    its worst evaluation is the best among all of the artifacts.\n\n    Ties are resolved randomly.\n\n    :param candidates: All candidates in the vote\n    :param votes: Votes from the agents\n    :param int n_winners: The number of vote winners\n    \"\"\"\n    worsts = {str(c): 100000000.0 for c in candidates}\n    for v in votes:\n        for e in v:\n            if worsts[str(e[0])] > e[1]:\n                worsts[str(e[0])] = e[1]\n    s = sorted(worsts.items(), key=lambda x: x[1], reverse=True)\n    best = s[:min(n_winners, len(candidates))]\n    d = []\n    for e in best:\n        for c in candidates:\n            if str(c) == e[0]:\n                d.append((c, e[1]))\n    return d"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nselecting the artifact with the single best evaluation as the winner of", "response": "def vote_best(candidates, votes, n_winners):\n    \"\"\"Select the artifact with the single best evaluation as the winner of\n    the vote.\n\n    Ties are resolved randomly.\n\n    :param candidates: All candidates in the vote\n    :param votes: Votes from the agents\n    :param int n_winners: The number of vote winners\n    \"\"\"\n    best = [votes[0][0]]\n    for v in votes[1:]:\n        if v[0][1] > best[0][1]:\n            best = [v[0]]\n    return best"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _remove_zeros(votes, fpl, cl, ranking):\n    for v in votes:\n        for r in v:\n            if r not in fpl:\n                v.remove(r)\n    for c in cl:\n        if c not in fpl:\n            if c not in ranking:\n                ranking.append((c, 0))", "response": "Remove zeros in IRV voting."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _remove_last(votes, fpl, cl, ranking):\n    for v in votes:\n        for r in v:\n            if r == fpl[-1]:\n                v.remove(r)\n    for c in cl:\n        if c == fpl[-1]:\n            if c not in ranking:\n                ranking.append((c, len(ranking) + 1))", "response": "Remove the last candidate in the list of votes."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nperforms IRV voting based on votes.", "response": "def vote_IRV(candidates, votes, n_winners):\n    \"\"\"Perform IRV voting based on votes.\n\n    Ties are resolved randomly.\n\n    :param candidates: All candidates in the vote\n    :param votes: Votes from the agents\n    :param int n_winners: The number of vote winners\n    \"\"\"\n    # TODO: Check what is wrong in here.\n    votes = [[e[0] for e in v] for v in votes]\n    f = lambda x: Counter(e[0] for e in x).most_common()\n    cl = list(candidates)\n    ranking = []\n    fp = f(votes)\n    fpl = [e[0] for e in fp]\n\n    while len(fpl) > 1:\n        _remove_zeros(votes, fpl, cl, ranking)\n        _remove_last(votes, fpl, cl, ranking)\n        cl = fpl[:-1]\n        fp = f(votes)\n        fpl = [e[0] for e in fp]\n\n    ranking.append((fpl[0], len(ranking) + 1))\n    ranking = list(reversed(ranking))\n    return ranking[:min(n_winners, len(ranking))]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef vote_mean(candidates, votes, n_winners):\n    sums = {str(candidate): [] for candidate in candidates}\n    for vote in votes:\n        for v in vote:\n            sums[str(v[0])].append(v[1])\n    for s in sums:\n        sums[s] = sum(sums[s]) / len(sums[s])\n    ordering = list(sums.items())\n    ordering.sort(key=operator.itemgetter(1), reverse=True)\n    best = ordering[:min(n_winners, len(ordering))]\n    d = []\n    for e in best:\n        for c in candidates:\n            if str(c) == e[0]:\n                d.append((c, e[1]))\n    return d", "response": "Perform mean voting based on votes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nranking artifact candidates based on the decision function.", "response": "def vote(self, candidates):\n        \"\"\"Rank artifact candidates.\n\n        The voting is needed for the agents living in societies using\n        social decision making. The function should return a sorted list\n        of (candidate, evaluation)-tuples. Depending on the social choice\n        function used, the evaluation might be omitted from the actual decision\n        making, or only a number of (the highest ranking) candidates may be\n        used.\n\n        This basic implementation ranks candidates based on\n        :meth:`~creamas.core.agent.CreativeAgent.evaluate`.\n\n        :param candidates:\n            list of :py:class:`~creamas.core.artifact.Artifact` objects to be\n            ranked\n\n        :returns:\n            Ordered list of (candidate, evaluation)-tuples\n        \"\"\"\n        ranks = [(c, self.evaluate(c)[0]) for c in candidates]\n        ranks.sort(key=operator.itemgetter(1), reverse=True)\n        return ranks"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_candidate(self, artifact):\n        self.candidates.append(artifact)\n        self._log(logging.DEBUG, \"CANDIDATES appended:'{}'\"\n                  .format(artifact))", "response": "Add candidate artifact to the list of candidates."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef validate_candidates(self, candidates):\n        valid_candidates = set(candidates)\n        for a in self.get_agents(addr=False):\n            vc = set(a.validate(candidates))\n            valid_candidates = valid_candidates.intersection(vc)\n\n        return list(valid_candidates)", "response": "Validate the candidate artifacts with the agents in the environment."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngathering votes for the given candidates from the agents in the environment.", "response": "def gather_votes(self, candidates):\n        \"\"\"Gather votes for the given candidates from the agents in the\n        environment.\n\n        Returned votes are anonymous, i.e. they cannot be tracked to any\n        individual agent afterwards.\n\n        :returns:\n            A list of votes. Each vote is a list of ``(artifact, preference)``\n            -tuples sorted in a preference order of a single agent.\n        \"\"\"\n        votes = []\n        for a in self.get_agents(addr=False):\n            vote = a.vote(candidates)\n            votes.append(vote)\n        return votes"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the managers for the slave environments.", "response": "def get_managers(self):\n        \"\"\"Get managers for the slave environments.\n        \"\"\"\n        if self._single_env:\n            return None\n        if not hasattr(self, '_managers'):\n            self._managers = self.env.get_slave_managers()\n        return self._managers"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef gather_votes(self):\n        async def slave_task(addr, candidates):\n            r_manager = await self.env.connect(addr)\n            return await r_manager.gather_votes(candidates)\n\n        if len(self.candidates) == 0:\n            self._log(logging.DEBUG, \"Could not gather votes because there \"\n                      \"are no candidates!\")\n            self._votes = []\n            return\n        self._log(logging.DEBUG, \"Gathering votes for {} candidates.\"\n                  .format(len(self.candidates)))\n\n        if self._single_env:\n            self._votes = self.env.gather_votes(self.candidates)\n        else:\n            mgrs = self.get_managers()\n            tasks = create_tasks(slave_task, mgrs, self.candidates)\n            self._votes = run(tasks)", "response": "Gather votes from all the underlying slave environments for the\n        current list of candidates."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngathering candidates from the slave environments.", "response": "def gather_candidates(self):\n        \"\"\"Gather candidates from the slave environments.\n\n        The candidates are stored in :attr:`candidates`, overriding any\n        previous candidates.\n        \"\"\"\n        async def slave_task(addr):\n            r_manager = await self.env.connect(addr)\n            return await r_manager.get_candidates()\n\n        if self._single_env:\n            self._candidates = self.env.candidates\n        else:\n            mgrs = self.get_managers()\n            tasks = create_tasks(slave_task, mgrs)\n            self._candidates = run(tasks)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef clear_candidates(self, clear_env=True):\n        async def slave_task(addr):\n            r_manager = await self.env.connect(addr)\n            return await r_manager.clear_candidates()\n\n        self._candidates = []\n        if clear_env:\n            if self._single_env:\n                self.env.clear_candidates()\n            else:\n                mgrs = self.get_managers()\n                run(create_tasks(slave_task, mgrs))", "response": "Clears the current candidates."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef validate_candidates(self):\n        async def slave_task(addr, candidates):\n            r_manager = await self.env.connect(addr)\n            return await r_manager.validate_candidates(candidates)\n\n        self._log(logging.DEBUG, \"Validating {} candidates\"\n                  .format(len(self.candidates)))\n\n        candidates = self.candidates\n        if self._single_env:\n            self._candidates = self.env.validate_candidates(candidates)\n        else:\n            mgrs = self.get_managers()\n            tasks = create_tasks(slave_task, mgrs, candidates, flatten=False)\n            rets = run(tasks)\n            valid_candidates = set(self.candidates)\n            for r in rets:\n                valid_candidates = valid_candidates.intersection(set(r))\n            self._candidates = list(valid_candidates)\n\n        self._log(logging.DEBUG, \"{} candidates after validation\"\n                  .format(len(self.candidates)))", "response": "Validate the current candidates."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompute the results of voting_method on the current set of candidate entries votes and winners.", "response": "def compute_results(self, voting_method, votes=None, winners=1, **kwargs):\n        \"\"\"Compute voting results to decide the winner(s) from the\n        :attr:`votes`.\n\n        The votes should have been made for the current\n        :attr:`~creamas.vote.VoteOrganizer.candidates`.\n\n        :param voting_method:\n            A function which computes the results from the votes. Should\n            accept at least three parameters: candidates, votes and number of\n            vote winners. The function should return at least a list of vote\n            winners. See, e.g. :func:`~creamas.vote.vote_mean` or\n            :func:`~creamas.vote.vote_best`. Additional ``**kwargs`` are passed\n            down to the voting method.\n\n        :param list votes:\n            A list of votes by which the voting is performed. Each vote should\n            have the same set of artifacts in them. If ``None`` the results\n            are computed for the current list of\n            :attr:`~creamas.vote.VoteOrganizer.votes`.\n\n        :param int winners:\n            The number of vote winners\n\n        :returns:\n            list of :py:class:`~creamas.core.artifact.Artifact` objects,\n            the winning artifacts. Some voting methods may also return a score\n            associated with each winning artifact.\n\n        :rtype: list\n        \"\"\"\n        if votes is None:\n            votes = self.votes\n\n        if len(votes) == 0:\n            self._log(logging.DEBUG, \"Could not compute results as there are \"\n                      \"no votes!\")\n            return []\n\n        self._log(logging.DEBUG, \"Computing results from {} votes.\"\n                  .format(len(votes)))\n        return voting_method(self.candidates, votes, winners, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite Versa models to a file.", "response": "def write(models, out=None, base=None, logger=logging):\n    '''\n    models - one or more input Versa models from which output is generated.\n    '''\n    assert out is not None #Output stream required\n    if not isinstance(models, list): models = [models]\n    for m in models:\n        for link in m.match():\n            s, p, o = link[:3]\n            #Skip docheader statements\n            if s == (base or '') + '@docheader': continue\n            if p in RESOURCE_MAPPING: p = RESOURCE_MAPPING[p]\n            if o in RESOURCE_MAPPING: o = RESOURCE_MAPPING[o]\n            \n            if p == VERSA_TYPE_REL: p = RDF_TYPE_REL\n            print(strconv(s), strconv(p), strconv(o), '.', file=out)\n    return"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nstart a device in the cluster.", "response": "def start_device(name, frontend, backend):\n    \"\"\"Start specified device\n\n    :param str name: name of the device, MUST match one of ['forwarder', 'streamer']\n    :param int frontend: frontend bind port for device\n    :param int backend: backend bind port for device\n    \"\"\"\n    device = getattr(devices, name)\n    device(frontend, backend)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncommand line interface for oct device", "response": "def run_device_command(sp):\n    \"\"\"\n    Main function to run oct tests.\n    \"\"\"\n    parser = sp.add_parser('run-device', help=\"run an oct device for multi-HQ tests\")\n    parser.add_argument('device', help=\"The project directory\", choices=['forwarder', 'streamer'])\n    parser.add_argument('-f', '--frontend', help=\"frontend port\", type=int, required=True)\n    parser.add_argument('-b', '--backend', help=\"backend port\", type=int, required=True)\n\n    parser.set_defaults(func=run_device)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\npublish start message to all turrets", "response": "def start(self, transaction_context=None):\n        \"\"\"Publish start message to all turrets\n        \"\"\"\n        transaction_context = transaction_context or {}\n        context_cmd = {'command': 'set_transaction_context',\n                       'msg': transaction_context}\n        self.publish(context_cmd)\n        self.publish(self.START)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef process_message(self, message, is_started=False):\n        if not self.master:\n            return False\n\n        if 'status' not in message:\n            return False\n        message['name'] = message['turret']\n        del message['turret']\n        if not self.add(message, is_started):\n            return self.update(message)\n        return True", "response": "Process a message from the master"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a turret object to the current turrets configuration", "response": "def add(self, turret_data, is_started=False):\n        \"\"\"Add a turret object to current turrets configuration\n\n        :param dict turret_data: the data of the turret to add\n        :param bool is_started: tell if test are already runing\n        \"\"\"\n        if turret_data.get('uuid') in self.turrets:\n            return False\n\n        turret = Turret(**turret_data)\n        self.write(turret)\n        self.turrets[turret.uuid] = turret\n\n        if is_started:\n            self.publish(self.START, turret.uuid)\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate a given turret with the given data", "response": "def update(self, turret_data):\n        \"\"\"Update a given turret\n\n        :param dict turret_data: the data of the turret to update\n        \"\"\"\n        if turret_data.get('uuid') not in self.turrets:\n            return False\n        turret = self.turrets[turret_data.get('uuid')]\n        turret.update(**turret_data)\n        self.write(turret)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef publish(self, message, channel=None):\n        if not self.master:\n            return\n        channel = channel or ''\n        data = json.dumps(message)\n        self.publisher.send_string(\"%s %s\" % (channel, data))", "response": "Publish a message to all turrets"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef open_recruitment(self, n=1):\n        from psiturk.amt_services import MTurkServices, RDSServices\n        from psiturk.psiturk_shell import PsiturkNetworkShell\n        from psiturk.psiturk_org_services import PsiturkOrgServices\n\n        psiturk_access_key_id = os.getenv(\n            \"psiturk_access_key_id\",\n            self.config.get(\"psiTurk Access\", \"psiturk_access_key_id\"))\n\n        psiturk_secret_access_id = os.getenv(\n            \"psiturk_secret_access_id\",\n            self.config.get(\"psiTurk Access\", \"psiturk_secret_access_id\"))\n\n        web_services = PsiturkOrgServices(\n            psiturk_access_key_id,\n            psiturk_secret_access_id)\n\n        aws_rds_services = RDSServices(\n            self.aws_access_key_id,\n            self.aws_secret_access_key,\n            self.aws_region)\n\n        self.amt_services = MTurkServices(\n            self.aws_access_key_id,\n            self.aws_secret_access_key,\n            self.config.getboolean(\n                'Shell Parameters', 'launch_in_sandbox_mode'))\n\n        self.shell = PsiturkNetworkShell(\n            self.config, self.amt_services, aws_rds_services, web_services,\n            self.server,\n            self.config.getboolean(\n                'Shell Parameters', 'launch_in_sandbox_mode'))\n\n        try:\n            participants = Participant.query.all()\n            assert(participants)\n\n        except Exception:\n            # Create the first HIT.\n            self.shell.hit_create(\n                n,\n                self.config.get('HIT Configuration', 'base_payment'),\n                self.config.get('HIT Configuration', 'duration'))\n\n        else:\n            # HIT was already created, no need to recreate it.\n            print \"Reject recruitment reopening: experiment has started.\"", "response": "Open recruitment for the first HIT unless it s already open."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef reward_bonus(self, assignment_id, amount, reason):\n        from psiturk.amt_services import MTurkServices\n\n        self.amt_services = MTurkServices(\n            self.aws_access_key_id,\n            self.aws_secret_access_key,\n            self.config.getboolean(\n                'Shell Parameters', 'launch_in_sandbox_mode'))\n        return self.amt_services.bonus_worker(assignment_id, amount, reason)", "response": "Reward the Turker with a bonus."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef keys(cls):\n        if cls._cache_keys is None:\n            cls._cache_keys = [c.name for c in cls.__table__._columns]\n        return cls._cache_keys", "response": "return list of all declared columns"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef glance(self):  # pragma: no cover\n        if self._settings_major_attrs is None:\n            msg = (\"Please specify attributes you want to include \"\n                   \"in `class._settings_major_attrs`!\")\n            raise NotImplementedError(msg)\n\n        kwargs = [\n            (attr, getattr(self, attr))\n            for attr in self._settings_major_attrs\n        ]\n\n        text = \"{classname}({kwargs})\".format(\n            classname=self.__class__.__name__,\n            kwargs=\", \".join([\n                \"%s=%r\" % (attr, value)\n                for attr, value in kwargs\n            ])\n        )\n\n        print(text)", "response": "Print itself only display attributes defined in\n           "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef absorb(self, other, ignore_none=True):\n        if not isinstance(other, self.__class__):\n            raise TypeError(\"`other` has to be a instance of %s!\" %\n                            self.__class__)\n\n        if ignore_none:\n            for attr, value in other.items():\n                if value is not None:\n                    setattr(self, attr, deepcopy(value))\n        else:\n            for attr, value in other.items():\n                setattr(self, attr, deepcopy(value))\n\n        return self", "response": "This method absorbs the current object with the contents of the other object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef revise(self, data, ignore_none=True):\n        if not isinstance(data, dict):\n            raise TypeError(\"`data` has to be a dict!\")\n\n        if ignore_none:\n            for key, value in data.items():\n                if value is not None:\n                    setattr(self, key, deepcopy(value))\n        else:\n            for key, value in data.items():\n                setattr(self, key, deepcopy(value))\n\n        return self", "response": "Revise attributes value with dictionary data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef random(cls, engine_or_session, limit=5):\n        ses, auto_close = ensure_session(engine_or_session)\n        result = ses.query(cls).order_by(func.random()).limit(limit).all()\n        if auto_close:  # pragma: no cover\n            ses.close()\n        return result", "response": "Return random ORM instance."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing a HTML source with the given model and return a tuple of the resulting HTML.", "response": "def toversa(htmlsource, model, source_uri):\n    '''\n    >>> import urllib\n    >>> from versa.reader import rdfalite\n    >>> from versa.driver import memory\n    >>> m = memory.connection()\n    >>> burl = 'http://link.delawarelibrary.org/'\n    >>> with urllib.request.urlopen(burl) as resourcefp: rdfalite.toversa(resourcefp.read(), m, burl)\n\n    '''\n    sink = versalinks(model)\n    next(sink) #Prime the coroutine\n    return parse(htmlsource, sink, source_uri)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn True if the multiplex is active in the given state False otherwise.", "response": "def is_active(self, state: 'State') -> bool:\n        \"\"\" Return True if the multiplex is active in the given state, false otherwise. \"\"\"\n        # Remove the genes which does not contribute to the multiplex\n        sub_state = state.sub_state_by_gene_name(*self.expression.variables)\n        # If this state is not in the cache\n        if sub_state not in self._is_active:\n            params = self._transform_state_to_dict(sub_state)\n            # We add the result of the expression for this state of the multiplex to the cache\n            self._is_active[sub_state] = self.expression.evaluate(**params)\n        return self._is_active[sub_state]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfunctioning deeply gets the key with. notation Returns None if no such key exists", "response": "def get(self, key):\n        \"\"\"\n        Function deeply gets the key with \".\" notation\n\n        Args\n        ----\n          key (string): A key with the \".\" notation.\n\n        Returns\n        -------\n          reg (unknown type): Returns a dict or a primitive\n            type.\n        \"\"\"\n        try:\n            layers = key.split('.')\n            value = self.registrar\n            for key in layers:\n                value = value[key]\n            return value\n        except:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfunction deeply sets the key with. notation", "response": "def set(self, key, value):\n        \"\"\"\n        Function deeply sets the key with \".\" notation\n\n        Args\n        ----\n          key (string): A key with the \".\" notation.\n          value (unknown type): A dict or a primitive type.\n        \"\"\"\n        target = self.registrar\n        for element in key.split('.')[:-1]:\n            target = target.setdefault(element, dict())\n        target[key.split(\".\")[-1]] = value"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef boot(cls, *args, **kwargs):\n        if cls.accessor is not None:\n            if cls.instance is None:\n                cls.instance = cls.accessor(*args, **kwargs)", "response": "Function creates the instance of the class with the given arguments."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef register(cls, config={}):\n        if cls.accessor is not None:\n            if cls.instance is None:\n                cls.instance = cls.accessor(config)", "response": "Register a new instance of the class with the given configuration dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a CommercialInvoice object for the given action data center environment and transport service.", "response": "def commercial_invoice(self, action, data_center, environment, transport_service, tagging_scheme=None):\n        \"\"\"\n        :param action:\n        :param data_center:\n        :param environment:\n        :param transport_service:\n        :param tagging_scheme:\n        :return:\n        \"\"\"\n        if action not in ACTIONS_SCHEME:\n            raise LookupError(logger.error(\"{0} isn't a support action.\".format(action)))\n\n        config_value = self._config.get(environment, 'environments')\n        if config_value is None:\n            raise LookupError(logger.error(\"Was unable to find environment: {0} in the config.\".format(environment)))\n        else:\n            environment = config_value\n\n        config_value = self._config.get(data_center, 'environments', environment.name)\n        if config_value is None:\n            raise LookupError(\n                logger.error(\"Was unable to find data center: {0} in environment: {1}\".format(data_center, environment.name))\n            )\n        else:\n            data_center = config_value\n\n        config_value = self._config.get(transport_service, 'environments', environment.name, data_center.name, action)\n        if config_value is None:\n                raise LookupError(\n                    logger.error('Was unable to find the service: {0} attempting to be transported.'.format(transport_service))\n                )\n        else:\n            transport_service = config_value\n\n        # if we're exporting we need to use other services deploy definitions to avoid issues\n        if action == 'export':\n            services = self.__get_services('deploy', data_center, environment)\n            services[transport_service.name] = transport_service\n        else:\n            services = self.__get_services(action, data_center, environment)\n\n        return CommercialInvoice(\n            team=self.team,\n            project=self.project,\n            services=services,\n            hosts=self._config.get('hosts', 'environments', environment.name, data_center.name, action),\n            transport_service=transport_service.alias,\n            transport_method=action,\n            data_center=data_center.alias,\n            environment=environment.alias,\n            registries=self._config.get('registries'),\n            tags=self._config.get('tags', 'environments', environment.name, data_center.name, action),\n            tagging_scheme=tagging_scheme\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndeploy containers to specific container ship.", "response": "def deploy_containers(self, commercial_invoice, tag=None, env=None):\n        \"\"\"\n        Deploy containers to specific container ship.\n        'restart_policy' = {\"maximum_retry_count\": 5, \"name\": \"always\"}\n        \"\"\"\n        commercial_invoice = self.__validate_commercial_invoice(commercial_invoice, 'deploy')\n\n        fleet = self.__assemble_fleet(commercial_invoice)\n        logger.info('Running deploy.')\n\n        try:\n            for address, container_ship in six.iteritems(fleet):\n                # write state file\n                self.__write_state_file(address, commercial_invoice.data_center, commercial_invoice.environment)\n\n                # get new transport service for each container ship\n                transport_service = commercial_invoice.transport_service\n\n                # if source tag is provided override what was parsed in image.\n                if tag:\n                    transport_service.source_tag = tag\n\n                # if env is provided merge what has been passed.\n                if env:\n                    transport_service.container_config.merge_env(env)\n\n                # during a deploy always restart containers on failure. if detach is true.\n                if transport_service.container_config.detach:\n                    transport_service.host_config.restart_policy = {\"maximum_retry_count\": 5, \"name\": \"always\"}\n\n                # validate service configs for deployment\n                self.__service_deployment_validation(transport_service)\n\n                # check with dispatch to see if its okay to export.\n                self.__wait_for_dispatch(address)\n\n                logger.info(\"dispatching service: {0} on host: {1}.\".format(transport_service.alias, address))\n                self.__dispatch(container_ship, transport_service)\n\n                if self._bill_of_lading.get('failures'):\n                    container_ship.recall_service(transport_service)\n                else:\n                    container_ship.offload_previous_containers(transport_service)\n                    # clean up service expired service cargo.\n                    container_ship.offload_expired_service_cargo(transport_service)\n\n            return False if self._bill_of_lading.get('failures') else True\n        finally:\n            # complete distribution and delete state file.\n            self.__complete_distribution(commercial_invoice)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef quality_control(self, commercial_invoice, attach=False, clean=None, test=None, configs=None, use_cache=False, env=None):\n        commercial_invoice = self.__validate_commercial_invoice(commercial_invoice, 'quality_control')\n\n        fleet = self.__assemble_fleet(commercial_invoice)\n        logger.info('Running quality control.')\n\n        try:\n            for address, container_ship in six.iteritems(fleet):\n                # write state file\n                self.__write_state_file(address, commercial_invoice.data_center, commercial_invoice.environment)\n\n                # get new transport service\n                transport_service = commercial_invoice.transport_service\n\n                # if env is provided merge what has been passed.\n                if env is not None:\n                    transport_service.container_config.merge_env(env)\n\n                # share some host info with user.\n                container_ship.report()\n\n                # check with dispatch to see if its okay to export.\n                self.__wait_for_dispatch(address)\n\n                logger.info('dispatching service: {0} on host: {1}.'.format(\n                    transport_service.alias,\n                    address\n                ))\n\n                # TODO: need to inject on all services during qc if configs == true\n                if configs:\n                    container_ship.injector = commercial_invoice.injector if configs else None\n\n                if attach:\n                    dependents = False\n                else:\n                    dependents = True\n\n                self.__dispatch(container_ship, transport_service, attach, configs, dependents, test, use_cache)\n\n                if clean:\n                    # delete containers.\n                    container_ship.offload_service_containers(transport_service)\n\n                    # delete images\n                    container_ship.offload_service_cargo(transport_service)\n                else:\n                    # clean up previous containers\n                    container_ship.offload_previous_containers(transport_service)\n\n                    # clean up service expired service cargo.\n                    container_ship.offload_expired_service_cargo(transport_service)\n\n            # TODO: Do something with failures / return bill of lading\n            return False if self._bill_of_lading.get('failures') else True\n        finally:\n            # complete distribution and delete state file.\n            self.__complete_distribution(commercial_invoice)", "response": "This method is used to run the quality control process."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_pdb_set(self, pdb_names, lchains, rchains, is_complex, notes = None):\n        '''lchains and rchains should be lists of pairs (p, c, n) where p is a PDB object (bio/pdb.py:PDB), c is a chain\n           identifier, and n is the NMR model number (or zero if this is not applicable).\n           (character). This allows us to represent combinations of unbound chains.\n           is_complex should be set to True if the PDB chains collectively form a complex.'''\n\n        # If PDB objects differ and is_complex is set, raise an exception\n        # This is not foolproof - we use the PDB object reference which could differ if the same PDB were loaded more than\n        # once and passed in. However, that would be bad practice and this check is much cheaper than comparing the PDB content.\n        if len(set([pc[0] for pc in lchains + rchains])) > 1 and is_complex:\n            raise Exception('The PDB set cannot be marked as a complex as it is defined using multiple PDB objects.')\n\n        # Check for unique occurrences of PDB chains (same caveat applies as above)\n        all_chains = [(pc[0], pc[1]) for pc in lchains + rchains]\n        if not len(all_chains) == len(set(all_chains)):\n            raise Exception('Each PDB chain should be included at most once.')\n\n        # Make sure that the chains exist in the PDB objects\n        for pc in lchains + rchains:\n            assert(pc[0] in pdb_names)\n            assert(pc[1] in pc[0].atom_sequences)\n\n        # Create the metadata\n        set_number = len(self.pdb_sets)\n        pdb_set = dict(\n            set_number = set_number,\n            is_complex = is_complex,\n            notes = notes,\n            chains = dict(L = [], R = []),\n            pdb_set_id = None\n        )\n\n        # Add the PDB chains\n        pdb_set_id = []\n        for chain_set_def in ((lchains, 'L'), (rchains, 'R')):\n            for pc in sorted(chain_set_def[0]):\n                chain_set = pdb_set['chains'][chain_set_def[1]]\n                nmr_model = None\n                if len(pc) > 2:\n                    nmr_model = pc[2]\n                chain_set.append(dict(\n                    chain_index = len(chain_set),\n                    pdb_file_id = pdb_names[pc[0]],\n                    chain_id = pc[1],\n                    nmr_model = nmr_model,\n                ))\n                pdb_set_id.append('{0}:{1}:{2}:{3}'.format(chain_set_def[0], pdb_names[pc[0]], pc[1], nmr_model))\n        pdb_set['pdb_set_id'] = sorted(pdb_set_id)\n        print(pdb_set['pdb_set_id'])\n\n        # Make sure we do not already have this set defined (the Complex should contain a unique list of bags of chains).\n        if pdb_set['pdb_set_id'] in [ps['pdb_set_id'] for ps in self.pdb_sets]:\n            raise Exception('This PDB set has already been defined (same PDB chains/NMR models).')\n\n        self.pdb_sets.append(pdb_set)", "response": "Add a PDB set to the metadata."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the record for the complex definition to be used for database storage.", "response": "def get_complex(self):\n        '''Returns the record for the complex definition to be used for database storage.'''\n        d = dict(\n            LName = self.lname,\n            LShortName = self.lshortname,\n            LHTMLName = self.lhtmlname,\n            RName = self.rname,\n            RShortName = self.rshortname,\n            RHTMLName = self.rhtmlname,\n            FunctionalClassID = self.functional_class_id,\n            PPDBMFunctionalClassID = self.functional_class_id_ppdbm,\n            PPDBMDifficulty = self.difficulty_ppdbm,\n            IsWildType = self.is_wildtype,\n            WildTypeComplexID = self.wildtype_complex,\n            Notes = self.notes,\n            Warnings = self.warnings,\n        )\n        if self.id:\n            d['ID'] = self.id\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of dictionaries containing the information for each PDB set in the database. This only makes sense if self. id is set. See usage example above.", "response": "def get_pdb_sets(self):\n        '''Return a record to be used for database storage. This only makes sense if self.id is set. See usage example\n           above.'''\n\n        assert(self.id != None)\n\n        data = []\n        for pdb_set in self.pdb_sets:\n\n            pdb_set_record = dict(\n                PPComplexID = self.id,\n                SetNumber = pdb_set['set_number'],\n                IsComplex = pdb_set['is_complex'],\n                Notes = pdb_set['notes'],\n            )\n\n            chain_records = []\n            for side, chain_details in sorted(pdb_set['chains'].iteritems()):\n                chain_records.append(dict(\n                    PPComplexID = self.id,\n                    SetNumber = pdb_set['set_number'],\n                    Side = side,\n                    ChainIndex = chain_details['chain_index'],\n                    PDBFileID = chain_details['pdb_file_id'],\n                    Chain = chain_details['chain_id'],\n                    NMRModel = chain_details['nmr_model'],\n                ))\n\n            data.append(dict(pdb_set = pdb_set_record, chain_records = chain_records))\n\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses the sole floating point value with name tag_name in tag t. Heavy - handed with the asserts.", "response": "def parse_singular_float(t, tag_name):\n    '''Parses the sole floating point value with name tag_name in tag t. Heavy-handed with the asserts.'''\n    pos = t.getElementsByTagName(tag_name)\n    assert(len(pos) == 1)\n    pos = pos[0]\n    assert(len(pos.childNodes) == 1)\n    return float(pos.childNodes[0].data)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing the sole integer value with name tag_name in tag t. Heavy - handed with the asserts.", "response": "def parse_singular_int(t, tag_name):\n    '''Parses the sole integer value with name tag_name in tag t. Heavy-handed with the asserts.'''\n    pos = t.getElementsByTagName(tag_name)\n    assert(len(pos) == 1)\n    pos = pos[0]\n    assert(len(pos.childNodes) == 1)\n    v = pos.childNodes[0].data\n    assert(v.isdigit()) # no floats allowed\n    return int(v)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses the sole alphabetic character value with name tag_name in tag t. Heavy - handed with the asserts.", "response": "def parse_singular_alphabetic_character(t, tag_name):\n    '''Parses the sole alphabetic character value with name tag_name in tag t. Heavy-handed with the asserts.'''\n    pos = t.getElementsByTagName(tag_name)\n    assert(len(pos) == 1)\n    pos = pos[0]\n    assert(len(pos.childNodes) == 1)\n    v = pos.childNodes[0].data\n    assert(len(v) == 1 and v >= 'A' and 'v' <= 'z') # no floats allowed\n    return v"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses the sole string value with name tag_name in tag t. Heavy - handed with the asserts.", "response": "def parse_singular_string(t, tag_name):\n    '''Parses the sole string value with name tag_name in tag t. Heavy-handed with the asserts.'''\n    pos = t.getElementsByTagName(tag_name)\n    assert(len(pos) == 1)\n    pos = pos[0]\n    assert(len(pos.childNodes) == 1)\n    return pos.childNodes[0].data"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef roulette(weights, n):\n    if n > len(weights):\n        raise Exception(\"Can't choose {} samples from {} items\".format(n, len(weights)))\n    if any(map(lambda w: w <= 0, weights.values())):\n        raise Exception(\"The weight can't be a non-positive number.\")\n    items = weights.items()\n    chosen = set()\n    for i in range(n):\n        total = sum(list(zip(*items))[1])\n        dice = random.random() * total\n        running_weight = 0\n        chosen_item = None\n        for item, weight in items:\n            if dice < running_weight + weight:\n                chosen_item = item\n                break\n            running_weight += weight\n        chosen.add(chosen_item)\n        items = [(i, w) for (i, w) in items if i != chosen_item]\n    return list(chosen)", "response": "Choose randomly the given number of items."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nbuild command line arguments for command.", "response": "def _build_arguments(self):\n        \"\"\"\n        build arguments for command.\n        \"\"\"\n        self._parser.add_argument(\n            '-a', '--alias',\n            required=False,\n            default='default',\n            type=str,\n            help='registry alias created in freight-forwarder.yml. Example: tune_dev'\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nbuilds the command line arguments for the command.", "response": "def _build_arguments(self):\n        \"\"\"\n        build arguments for command.\n        \"\"\"\n        self._parser.add_argument(\n            'image_name',\n            metavar='IMAGE_NAME',\n            type=six.text_type,\n            help='Name of the image example: \\\"namespace/repository\\\"'\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the URI object as a dictionary", "response": "def as_dict(self):\n        \"\"\" Return the URI object as a dictionary\"\"\"\n        d = {k:v for (k,v) in self.__dict__.items()}\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_title(self, group=None):\n        title = super(CommentsPlugin, self).get_title()\n        if group is not None:\n            count = GroupComments.objects.filter(group=group).count()\n        else:\n            count = None\n        if count:\n            title = u'%s (%d)' % (title, count)\n        return title", "response": "Adds number of comments to title."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndisplaying and store comments.", "response": "def view(self, request, group, **kwargs):\n        \"\"\"Display and store comments.\"\"\"\n        if request.method == 'POST':\n            message = request.POST.get('message')\n            if message is not None and message.strip():\n                comment = GroupComments(group=group, author=request.user,\n                                        message=message.strip())\n                comment.save()\n                msg = _(u'Comment added.')\n                if request.POST.get('sendmail', ''):\n                    self._send_mail(comment, group)\n                if 'postresolve' in request.POST:\n                    self._resolve_group(request, group)\n                    msg = _(u'Comment added and event marked as resolved.')\n                messages.success(request, msg)\n                return HttpResponseRedirect(request.path)\n        query = GroupComments.objects.filter(group=group).order_by('-created')\n        return self.render('sentry_comments/index.html', {\n            'comments': query,\n            'group': group,\n        })"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates all reports from original dataframe containing raw and compiled results", "response": "def generate_graphs(data, name, results_dir):\n    \"\"\"Generate all reports from original dataframe\n\n    :param dic data: dict containing raw and compiled results dataframes\n    :param str name: name for prefixing graphs output\n    :param str results_dir: results output directory\n    \"\"\"\n    graphs.resp_graph_raw(data['raw'], name + '_response_times.svg', results_dir)\n    graphs.resp_graph(data['compiled'], name + '_response_times_intervals.svg', results_dir)\n    graphs.tp_graph(data['compiled'], name + '_throughput.svg', results_dir)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprint informations in standard output", "response": "def print_infos(results):\n    \"\"\"Print informations in standard output\n\n    :param ReportResults results: the report result containing all compiled informations\n    \"\"\"\n    print('transactions: %i' % results.total_transactions)\n    print('timers: %i' % results.total_timers)\n    print('errors: %i' % results.total_errors)\n    print('test start: %s' % results.start_datetime)\n    print('test finish: %s\\n' % results.finish_datetime)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrite the html template", "response": "def write_template(data, results_dir, parent):\n    \"\"\"Write the html template\n\n    :param dict data: the dict containing all data for output\n    :param str results_dir: the ouput directory for results\n    :param str parent: the parent directory\n    \"\"\"\n    print(\"Generating html report...\")\n    partial = time.time()\n    j_env = Environment(loader=FileSystemLoader(os.path.join(results_dir, parent, 'templates')))\n    template = j_env.get_template('report.html')\n\n    report_writer = ReportWriter(results_dir, parent)\n    report_writer.write_report(template.render(data))\n    print(\"HTML report generated in {} seconds\\n\".format(time.time() - partial))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef output(results_dir, config, parent='../../'):\n    start = time.time()\n    print(\"Compiling results...\")\n    results_dir = os.path.abspath(results_dir)\n    results = ReportResults(config['run_time'], config['results_ts_interval'])\n    results.compile_results()\n    print(\"Results compiled in {} seconds\\n\".format(time.time() - start))\n\n    if results.total_transactions == 0:\n        print(\"No results, cannot create report\")\n        return False\n\n    print_infos(results)\n\n    data = {\n        'report': results,\n        'run_time': config['run_time'],\n        'ts_interval': config['results_ts_interval'],\n        'turrets_config': results.turrets,\n        'results': {\"all\": results.main_results, \"timers\": results.timers_results}\n    }\n\n    print(\"Generating graphs...\")\n    partial = time.time()\n    generate_graphs(results.main_results, 'All_Transactions', results_dir)\n\n    for key, value in results.timers_results.items():\n        generate_graphs(value, key, results_dir)\n    print(\"All graphs generated in {} seconds\\n\".format(time.time() - partial))\n\n    write_template(data, results_dir, parent)\n    print(\"Full report generated in {} seconds\".format(time.time() - start))\n    return True", "response": "Write the results output for the given test\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwrapping around os. mkdir which does not raise an error.", "response": "def safeMkdir(p, permissions = permissions755):\n\t'''Wrapper around os.mkdir which does not raise an error if the directory exists.'''\n\ttry:\n\t\tos.mkdir(p)\n\texcept OSError:\n\t\tpass\n\tos.chmod(p, permissions)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getSubdirectories(d):\n\t'''Returns a list of subdirectories in a directory.\n\t\tThis function performed three times better for me than \n\t\t\"for root, dirs, files in os.walk(d):\n\t\t\treturn dirs\"\n\t'''\n\treturn [f for f in os.listdir(d) if os.path.isdir(os.path.join(d, f)) ]", "response": "Returns a list of subdirectories in a directory. This function performs three times better for me than \n\treturn dirs"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef computeMD5(filepath, relativepath = \"\"):\n\t'''Computes an MD5 checksum.\n\t\tDepending on the file size, we either run the computation in Python or spawn a subprocess.\n\t\tThe implementation is slower in Python than the tested OS but there is an overhead associated with the spawning.\n\t\tOn my one-machine test (CentOS release 5.4 final on the webserver), @2MB was where the times converged.\n\t\t'''\n\tfilename = os.path.basename(filepath)\n\tchecksum = None\n\t\n\tsz = os.path.getsize(filepath)\n\tif sz < 2 * 1024 * 1024:\n\t\tchecksum = md5.new()\n\t\tF = open(filepath, 'rb')\n\t\twhile True:\n\t\t\tbytes = F.read(65536)\n\t\t\tif len(bytes) == 0:\n\t\t\t\tbreak # end of file\n\t\t\tchecksum.update(bytes)\n\t\tchecksum = checksum.hexdigest()\n\t\t\n\telse:\n\t\tp = subprocess.Popen([\"md5sum\", filepath], stdout = subprocess.PIPE, stderr = subprocess.PIPE)\n\t\tstdoutdata, stderrdata = p.communicate()\n\t\tif stderrdata:\n\t\t\traise Exception(stderrdata)\n\t\tstdoutdata = stdoutdata.split()\n\t\tchecksum = stdoutdata[0]\n\t\tfilename = os.path.basename(stdoutdata[1])\n\n\treturn \"%s  %s\" % (checksum, os.path.join(relativepath, filename))", "response": "Compute an MD5 checksum of a file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef version():\n    echo(green('\\nshift-boiler:'))\n    echo(green('-' * 40))\n    echo(yellow('Version: ') + '{}'.format(boiler_version))\n    echo(yellow('GitHub: ') + 'https://github.com/projectshift/shift-boiler')\n    echo(yellow('PyPi: ') + 'https://pypi.org/project/shiftboiler/')\n    echo()", "response": "Version of shift - boiler"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsigning a Python interpreter using self - signed certificate", "response": "def sign_python():\n    \"\"\"\n    Sign python (MacOS)\n    Signing your python interpreter using self-signed certificate is used to\n    get rid of annoying firewall questions about whether to allow incoming\n    connections to the interpreter that happen on each app restart. This only\n    makes sense on Mac. In order to use this command you must first create\n    a certificate to sign your code with. To do it:\n\n      1. Open Keychain Access\n      2. Choose: Keychain Access > Certificate Assistant > Create Certificate\n      3. Important: Use your current username for certificate name (id -un)\n      4. Select Certificate Type: Code Signing\n      5. Select Type: Self Signed Root\n      6. Check 'Let me override defaults' box\n      7. Click Continue, and give it a serial number (maximum randomness)\n      8. Accept defaults for the rest\n\n    You will only need to do this once. After this is done you can use\n    generated certificate to sign your Python in any project.\n    \"\"\"\n    from subprocess import check_output\n    from os import system\n\n    echo(green('\\nSign python:'))\n    echo(green('-' * 40))\n\n    # get python\n    python = check_output(['which', 'python']).decode().replace('\\n', '')\n    echo('Interpreter: ' + yellow(python))\n\n    # get certificate name\n    username = check_output(['id', '-un']).decode().replace('\\n', '')\n    echo('Using certificate: ' + yellow(username) + '\\n')\n\n    # signing\n    cert = '\"{}\"'.format(username)\n    cmd = \"codesign -s {cert} -f {python}\".format(cert=cert, python=python)\n    system(cmd)\n\n    echo(green('\\nDONE\\n'))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef init(destination, force=False, skip=True):\n    import os\n    from uuid import uuid1\n    import fileinput\n\n    ignores = ['.DS_Store', '__pycache__', ]\n\n    echo(green('\\nInitialise project:'))\n    echo(green('-' * 40))\n\n    destination = os.path.realpath(destination)\n    source = os.path.realpath(os.path.dirname(__file__) + '/../boiler_template')\n\n    # dry run first\n    exist_in_dst = []\n    for path, dirs, files in os.walk(source):\n        for dir in dirs:\n            if dir in ignores:\n                continue\n            dst = os.path.join(path, dir).replace(source, destination)\n            if os.path.exists(dst):\n                exist_in_dst.append(dst)\n\n        for file in files:\n            if file in ignores:\n                continue\n            dst = os.path.join(path, file).replace(source, destination)\n            if os.path.exists(dst):\n                exist_in_dst.append(dst)\n\n    # require force option if existing files found\n    if exist_in_dst and not force and not skip:\n\n        msg = 'The following objects were found in destination.'\n        msg += 'What do you want to do with these?'\n        echo(red(msg))\n        echo(red('Use either --force or --skip option \\n'))\n\n        for index,path in enumerate(exist_in_dst):\n            echo(yellow('{}. {}'.format(index, path)))\n\n        echo()\n        return\n\n    for path, dirs, files in os.walk(source):\n        for dir in dirs:\n            if dir in ignores:\n                continue\n            src = os.path.join(path, dir)\n            dst = src.replace(source, destination)\n            if('__pycache__' in src):\n                continue\n\n            if dst in exist_in_dst and force:\n                echo(red('OVERWRITING: ' + dst))\n                if os.path.exists(dst):\n                    shutil.rmtree(dst, ignore_errors=True)\n                os.makedirs(dst)\n            elif dst in exist_in_dst and skip:\n                echo(yellow('SKIPPING: ' + dst))\n            else:\n                echo('CREATING: ' + dst)\n                os.makedirs(dst)\n\n        for file in files:\n            if file in ignores:\n                continue\n            src = os.path.join(path, file)\n            dst = src.replace(source, destination)\n            if('__pycache__' in src):\n                continue\n\n            if dst in exist_in_dst and force:\n                echo(red('OVERWRITING: ' + dst))\n                if os.path.exists(dst):\n                    os.remove(dst)\n                shutil.copy(src, dst)\n            elif dst in exist_in_dst and skip:\n                echo(yellow('SKIPPING: ' + dst))\n            else:\n                echo('CREATING: ' + dst)\n                shutil.copy(src, dst)\n\n    # create secret keys\n    path = os.path.join(os.getcwd(), 'dist.env')\n    secrets = ['USER_JWT_SECRET', 'SECRET_KEY']\n    for line in fileinput.input(path, inplace=True):\n        line = line.strip('\\n')\n        found = False\n        for secret in secrets:\n            if secret in line:\n                found = True\n                break\n\n        if not found:\n            echo(line)\n        else:\n            echo(line.replace('SET_ME', '\\'' + str(uuid1()) + '\\''))\n\n    # create .env\n    dotenv_dist = os.path.join(os.getcwd(), 'dist.env')\n    dotenv = os.path.join(os.getcwd(), '.env')\n\n    if not os.path.isfile(dotenv):\n        shutil.copy(dotenv_dist, dotenv)\n\n    # rename gitignore\n    ignore_src = os.path.join(os.getcwd(), 'dist.gitignore')\n    ignore_dst = os.path.join(os.getcwd(), '.gitignore')\n    if os.path.isfile(ignore_src) and not os.path.exists(ignore_dst):\n        shutil.move(ignore_src, ignore_dst)\n\n    # create requirements file\n    reqs = os.path.join(os.getcwd(), 'requirements.txt')\n    if not os.path.exists(reqs):\n        with open(reqs, 'a') as file:\n            file.write('shiftboiler=={}\\n'.format(boiler_version))\n\n\n    echo()\n    return", "response": "Initialise a new project."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef install_dependencies(feature=None):\n    import subprocess\n\n    echo(green('\\nInstall dependencies:'))\n    echo(green('-' * 40))\n\n    req_path = os.path.realpath(os.path.dirname(__file__) + '/../_requirements')\n\n    # list all features if no feature name\n    if not feature:\n        echo(yellow('Please specify a feature to install. \\n'))\n        for index, item in enumerate(os.listdir(req_path)):\n            item = item.replace('.txt', '')\n            echo(green('{}. {}'.format(index + 1, item)))\n\n        echo()\n        return\n\n    # install if got feature name\n    feature_file = feature.lower() + '.txt'\n    feature_reqs = os.path.join(req_path, feature_file)\n\n    # check existence\n    if not os.path.isfile(feature_reqs):\n        msg = 'Unable to locate feature requirements file [{}]'\n        echo(red(msg.format(feature_file)) + '\\n')\n        return\n\n    msg = 'Now installing dependencies for \"{}\" feature...'.format(feature)\n    echo(yellow(msg))\n\n    subprocess.check_call([\n        sys.executable, '-m', 'pip', 'install', '-r', feature_reqs]\n    )\n\n    # update requirements file with dependencies\n    reqs = os.path.join(os.getcwd(), 'requirements.txt')\n    if os.path.exists(reqs):\n        with open(reqs) as file:\n            existing = [x.strip().split('==')[0] for x in file.readlines() if x]\n\n        lines = ['\\n']\n        with open(feature_reqs) as file:\n            incoming = file.readlines()\n\n            for line in incoming:\n                if not(len(line)) or line.startswith('#'):\n                    lines.append(line)\n                    continue\n\n                package = line.strip().split('==')[0]\n                if package not in existing:\n                    lines.append(line)\n\n        with open(reqs, 'a') as file:\n            file.writelines(lines)\n\n    echo(green('DONE\\n'))", "response": "Install dependencies for a feature"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef by_pdb(self, pdb_id, take_top_percentile = 30.0, cut_off = None, matrix = None, sequence_identity_cut_off = None, silent = None):\n        '''Returns a list of all PDB files which contain protein sequences similar to the protein sequences of pdb_id.\n           Only protein chains are considered in the matching so e.g. some results may have DNA or RNA chains or ligands\n           while some may not.\n        '''\n\n        self.log('BLASTing {0}'.format(pdb_id), silent, colortext.pcyan)\n\n        # Preamble\n        matrix = matrix or self.matrix\n        cut_off = cut_off or self.cut_off\n        sequence_identity_cut_off = sequence_identity_cut_off or self.sequence_identity_cut_off\n\n        # Parse PDB file\n        p = self.bio_cache.get_pdb_object(pdb_id)\n\n        chain_ids = sorted(p.seqres_sequences.keys())\n        assert(chain_ids)\n\n        # Run BLAST over all chains\n        hits = set(self.blast_by_pdb_chain(pdb_id, chain_ids[0], cut_off = cut_off, matrix = matrix, sequence_identity_cut_off = sequence_identity_cut_off, take_top_percentile = take_top_percentile, silent = silent))\n        for chain_id in chain_ids[1:]:\n            chain_hits = self.blast_by_pdb_chain(pdb_id, chain_id, cut_off = cut_off, matrix = matrix, sequence_identity_cut_off = sequence_identity_cut_off, take_top_percentile = take_top_percentile)\n            if chain_hits != None:\n                # None suggests that the chain was not a protein chain whereas an empty list suggest a protein chain with no hits\n                hits = hits.intersection(set(chain_hits))\n        return sorted(hits)", "response": "Returns a list of all PDB files which contain the same protein sequences similar to the protein sequences of the given PDB ID."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef simple_hashstring(obj, bits=64):\n    '''\n    Creates a simple hash in brief string form from obj\n    bits is an optional bit width, defaulting to 64, and should be in multiples of 8 with a maximum of 64\n\n    >>> from bibframe.contrib.datachefids import simple_hashstring\n    >>> simple_hashstring(\"The quick brown fox jumps over the lazy dog\")\n    'bBsHvHu8S-M'\n    >>> simple_hashstring(\"The quick brown fox jumps over the lazy dog\", bits=48)\n    'B7x7vEvj'\n    '''\n    #Useful discussion of techniques here: http://stackoverflow.com/questions/1303021/shortest-hash-in-python-to-name-cache-files\n    #Use MurmurHash3\n    #Get a 64-bit integer, the first half of the 128-bit tuple from mmh and then bit shift it to get the desired bit length\n    basis = mmh3.hash64(str(obj))[0] >> (64-bits)\n    if bits == 64:\n        raw_hash = struct.pack('!q', basis)\n    else:\n        raw_hash = struct.pack('!q', basis)[:-int((64-bits)/8)]\n    hashstr = base64.urlsafe_b64encode(raw_hash).rstrip(b\"=\")\n    return hashstr.decode('ascii')", "response": "Returns a simple hash string from obj"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a slug from a title", "response": "def create_slug(title, plain_len=None):\n    '''\n    Tries to create a slug from a title, trading off collision risk with readability and minimized cruft\n\n    title - a unicode object with a title to use as basis of the slug\n    plain_len - the maximum character length preserved (from the beginning) of the title\n\n    >>> from versa.contrib.datachefids import create_slug\n    >>> create_slug(u\"The  quick brown fox jumps over the lazy dog\")\n    'the_quick_brown_fox_jumps_over_the_lazy_dog'\n    >>> create_slug(u\"The  quick brown fox jumps over the lazy dog\", 20)\n    'the_quick_brown_fox'\n    '''\n    if plain_len: title = title[:plain_len]\n    pass1 = OMIT_FROM_SLUG_PAT.sub('_', title).lower()\n    return NORMALIZE_UNDERSCORES_PAT.sub('_', pass1)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef slugify(value, hyphenate=True, lower=True):\n    import unicodedata\n    value = unicodedata.normalize('NFKD', value).strip()\n    replacement = '-' if hyphenate else ''\n    if lower: value = value.lower()\n    return _CHANGEME_RE.sub(replacement, value)", "response": "Returns a slug of the given string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating an IRI as a hash of given information, or just make one up if None given idbase -- Base URI for generating links tint -- String that affects the sequence of IDs generated if sent None >>> from bibframe.contrib.datachefids import idgen >>> g = idgen(None) >>> next(g) #Or g.send(None) 'gKNG1b7eySo' >>> next(g) 'cXx7iv67-3E' >>> g.send('spam') 'OZxOEos8e-k' >>> next(g) 'mCFhsaWQ1_0' >>> g.send('spam') 'OZxOEos8e-k' >>> g.send('eggs') 'xQAd4Guk040' >>> g.send('') 'AAAAAAAAAAA'", "response": "def idgen(idbase, tint=None, bits=64):\n    '''\n    Generate an IRI as a hash of given information, or just make one up if None given\n    idbase -- Base URI for generating links\n    tint -- String that affects the sequence of IDs generated if sent None\n\n    >>> from bibframe.contrib.datachefids import idgen\n    >>> g = idgen(None)\n    >>> next(g) #Or g.send(None)\n    'gKNG1b7eySo'\n    >>> next(g)\n    'cXx7iv67-3E'\n    >>> g.send('spam')\n    'OZxOEos8e-k'\n    >>> next(g)\n    'mCFhsaWQ1_0'\n    >>> g.send('spam')\n    'OZxOEos8e-k'\n    >>> g.send('eggs')\n    'xQAd4Guk040'\n    >>> g.send('')\n    'AAAAAAAAAAA'\n    '''\n    counter = -1\n    to_hash = None\n    while True:\n        if to_hash is None:\n            to_hash = str(counter)\n            if tint: to_hash += tint\n        to_hash = simple_hashstring(to_hash, bits=bits)\n        to_hash = yield iri.absolutize(to_hash, idbase) if idbase else to_hash\n        counter += 1"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef http_method_formatter(view, context, model, name):\n    method_map = {\n        'GET': 'label-success',\n        'PUT': 'label-info',\n        'POST': 'label-primary',\n        'DELETE': 'label-danger',\n    }\n    return Markup(\n        '<span class=\"label {}\">{}</span>'.format(\n            method_map.get(model[name], 'label-default'), model[name]\n        )\n    )", "response": "Wrap HTTP method value in a bs3 label."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwrapping HTTP method value in a bs3 label.", "response": "def profiling_request_formatter(view, context, model, name):\n    \"\"\"Wrap HTTP method value in a bs3 label.\"\"\"\n    document = model[name]\n    return Markup(\n        ''.join(\n            [\n                '<p class=\"profiling-request\">',\n                '<a href=\"{}\">'.format(document.get_admin_url(_external=True)),\n                http_method_formatter(view, context, document, 'method'),\n                '&nbsp;',\n                document.path,\n                '</a>',\n                '</p>',\n            ]\n        )\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef profiling_query_formatter(view, context, query_document, name):\n    return Markup(\n        ''.join(\n            [\n                '<div class=\"pymongo-query row\">',\n                '<div class=\"col-md-1\">',\n                '<a href=\"{}\">'.format(query_document.get_admin_url(_external=True)),\n                mongo_command_name_formatter(\n                    view, context, query_document, 'command_name'\n                ),\n                # '<span class=\"label {}\">{}</span>'.format(\n                #     command_name_map.get(query_document.command_name, 'label-default'),\n                #     query_document.command_name,\n                # ),\n                '</div>',\n                '<div class=\"col-md-10\">',\n                profiling_pure_query_formatter(\n                    None, None, query_document, 'command', tag='pre'\n                ),\n                '</div>',\n                '<div class=\"col-md-1\">',\n                '<small>{} ms</small>'.format(query_document.duration),\n                '</a>',\n                '</div>',\n                '</div>',\n            ]\n        )\n    )", "response": "Formats a ProfilingQuery entry for a ProfilingRequest detail field."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntries to coerce an object into a Response object.", "response": "def make_response(obj):\n    \"\"\"Try to coerce an object into a Response object.\"\"\"\n    if obj is None:\n        raise TypeError(\"Handler return value cannot be None.\")\n    if isinstance(obj, Response):\n        return obj\n    return Response(200, body=obj)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nselecting a suitable handler to handle the request.", "response": "def resolve_handler(request, view_handlers):\n    \"\"\"Select a suitable handler to handle the request.\n\n    Returns a (handler, vary) tuple, where handler is a handler_metadata tuple\n    and vary is a set containing header names that were used during content\n    negotiation and that should be included in the 'Vary' header of the\n    outgoing response.\n\n    When no suitable handler exists, raises NotFound, MethodNotAllowed,\n    UnsupportedMediaType or NotAcceptable.\n    \"\"\"\n    view = None\n    if request._context:  # Allow context to be missing for easier testing\n        route_name = request._context[-1].route.name\n        if route_name and VIEW_SEPARATOR in route_name:\n            view = route_name.split(VIEW_SEPARATOR, 1)[1] or None\n\n    if view not in view_handlers:\n        raise NotFound\n\n    method_handlers = view_handlers[view]\n\n    verb = request.method\n    if verb not in method_handlers:\n        if verb == 'HEAD' and 'GET' in method_handlers:\n            verb = 'GET'\n        else:\n            allowed_methods = set(method_handlers.keys())\n            if 'HEAD' not in allowed_methods and 'GET' in allowed_methods:\n                allowed_methods.add('HEAD')\n            allow = ', '.join(sorted(allowed_methods))\n            raise MethodNotAllowed(allow=allow)\n\n    handlers = method_handlers[verb]\n    vary = set()\n    if len(set(h.provides for h in handlers if h.provides is not None)) > 1:\n        vary.add('Accept')\n    if len(set(h.accepts for h in handlers)) > 1:\n        vary.add('Content-Type')\n\n    content_type = request.content_type\n    if content_type:\n        handlers = negotiate_content_type(content_type, handlers)\n        if not handlers:\n            raise UnsupportedMediaType\n\n    accept = request.headers.get('Accept')\n    if accept:\n        handlers = negotiate_accept(accept, handlers)\n        if not handlers:\n            raise NotAcceptable\n\n    return handlers[0], vary"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfiltering handlers that accept a given content - type and return those handlers that accept it.", "response": "def negotiate_content_type(content_type, handlers):\n    \"\"\"Filter handlers that accept a given content-type.\n\n    Finds the most specific media-range that matches `content_type`, and\n    returns those handlers that accept it.\n    \"\"\"\n    accepted = [h.accepts for h in handlers]\n    scored_ranges = [(mimeparse.fitness_and_quality_parsed(content_type,\n        [mimeparse.parse_media_range(mr)]), mr) for mr in accepted]\n\n    # Sort by fitness, then quality parsed (higher is better)\n    scored_ranges.sort(reverse=True)\n    best_score = scored_ranges[0][0]  # (fitness, quality)\n    if best_score == MIMEPARSE_NO_MATCH or not best_score[1]:\n        return []\n\n    media_ranges = [pair[1] for pair in scored_ranges if pair[0] == best_score]\n    best_range = media_ranges[0]\n    return [h for h in handlers if h.accepts == best_range]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef negotiate_accept(accept, handlers):\n    provided = [h.provides for h in handlers]\n    if None in provided:\n        # Not all handlers are annotated - disable content-negotiation\n        # for Accept.\n        # TODO: We could implement an \"optimistic mode\": If a fully qualified\n        # mime-type was requested and we have a specific handler that provides\n        # it, choose that handler instead of the default handler (depending on\n        # 'q' value).\n        return [h for h in handlers if h.provides is None]\n    else:\n        # All handlers are annotated with the mime-type they\n        # provide: find the best match.\n        #\n        # mimeparse.best_match expects the supported mime-types to be sorted\n        # in order of increasing desirability. By default, we use the order in\n        # which handlers were added (earlier means better).\n        # TODO: add \"priority\" parameter for user-defined priorities.\n        best_match = mimeparse.best_match(reversed(provided), accept)\n        return [h for h in handlers if h.provides == best_match]", "response": "Filter handlers that provide an acceptable mime - type and returns a list of handlers that provide the matching mime - type."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the first value for a key.", "response": "def get(self, key, default=None, type=None):\n        \"\"\"Returns the first value for a key.\n\n        If `type` is not None, the value will be converted by calling\n        `type` with the value as argument. If type() raises `ValueError`, it\n        will be treated as if the value didn't exist, and `default` will be\n        returned instead.\n        \"\"\"\n        try:\n            value = self[key]\n            if type is not None:\n                return type(value)\n            return value\n        except (KeyError, ValueError):\n            return default"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getall(self, key, type=None):\n        values = []\n        for k, v in self._items:\n            if k == key:\n                if type is not None:\n                    try:\n                        values.append(type(v))\n                    except ValueError:\n                        pass\n                else:\n                    values.append(v)\n        return values", "response": "Return a list of values for the given key."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef url_for(*args, **kw):\n        # Allow passing 'self' as named parameter\n        self, target, args = args[0], args[1], list(args[2:])\n        query = kw.pop('_query', None)\n        relative = kw.pop('_relative', False)\n        url = build_url(self._context, target, args, kw)\n        if query:\n            if isinstance(query, dict):\n                query = sorted(query.items())\n            query_part = urllib.urlencode(query)\n            query_sep = '&' if '?' in url else '?'\n            url = url + query_sep + query_part\n        if relative:\n            return url\n        else:\n            return urlparse.urljoin(self.application_uri, url)", "response": "Builds the URL for a named route."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef query(self):\n        if self._query is None:\n            query_string = self.environ.get('QUERY_STRING')\n            self._query = QueryDict([\n                (k.decode('utf-8'), v.decode('utf-8'))\n                for k, v in urlparse.parse_qsl(\n                    query_string, keep_blank_values=True)\n            ])\n        return self._query", "response": "A QueryDict object holding the query parameters."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef url(self):\n        if self._url is None:\n            self._url = request_uri(self.environ, include_query=1)\n        return self._url", "response": "The reconstructed request URL ( absolute )."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef input(self):\n        if self._input is None:\n            input_file = self.environ['wsgi.input']\n            content_length = self.content_length or 0\n            self._input = WsgiInput(input_file, self.content_length)\n        return self._input", "response": "Returns a file - like object representing the request body."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreads and returns the entire request body.", "response": "def body(self):\n        \"\"\"Reads and returns the entire request body.\n\n        On first access, reads `content_length` bytes from `input` and stores\n        the result on the request object. On subsequent access, returns the\n        cached value.\n        \"\"\"\n        if self._body is None:\n            if self._body_reader is None:\n                self._body = self.input.read(self.content_length or 0)\n            else:\n                self._body = self._body_reader(self.input)\n        return self._body"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef form(self):\n        if self._form is None:\n            # Make sure FieldStorage always parses the form content,\n            # and never the query string.\n            environ = self.environ.copy()\n            environ['QUERY_STRING'] = ''\n            environ['REQUEST_METHOD'] = 'POST'\n            fs = cgi.FieldStorage(\n                fp=self.input,\n                environ=environ,\n                keep_blank_values=True)\n            # File upload field handling copied from WebOb\n            fields = []\n            for f in fs.list or []:\n                if f.filename:\n                    f.filename = f.filename.decode('utf-8')\n                    fields.append((f.name.decode('utf-8'), f))\n                else:\n                    fields.append(\n                        (f.name.decode('utf-8'), f.value.decode('utf-8'))\n                    )\n            self._form = QueryDict(fields)\n        return self._form", "response": "Reads the request body and parses it as a web form."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cookies(self):\n        if self._cookies is None:\n            c = SimpleCookie(self.environ.get('HTTP_COOKIE'))\n            self._cookies = dict([\n                (k.decode('utf-8'), v.value.decode('utf-8'))\n                for k, v in c.items()\n            ])\n        return self._cookies", "response": "Returns a dictionary mapping cookie names to their values."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nformats an error message for missing positional arguments.", "response": "def _format_parameter_error_message(name: str, sig: Signature,\n                                    num_params: int) -> str:\n    \"\"\"\n    Format an error message for missing positional arguments.\n\n    Args:\n        name: The function name.\n        sig: The function's signature.\n        num_params: The number of function parameters.\n\n    Returns:\n        str: A formatted error message.\n    \"\"\"\n    if num_params == 0:\n        plural = 's'\n        missing = 2\n        arguments = \"'slack' and 'event'\"\n    else:\n        plural = ''\n        missing = 1\n        arguments = \"'event'\"\n\n    return (f\"{name}{sig} missing {missing} required positional \"\n            f\"argument{plural}: {arguments}\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a SlackClient with a token from an env var.", "response": "def _create_slack_with_env_var(env_var: EnvVar) -> SlackClient:\n    \"\"\" Create a :obj:`SlackClient` with a token from an env var. \"\"\"\n    token = os.getenv(env_var)\n    if token:\n        return SlackClient(token=token)\n    raise MissingToken(f\"Could not acquire token from {env_var}\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _create_slack_with_token(token: Token) -> SlackClient:\n    if token != Token(''):\n        return SlackClient(token=token)\n    raise MissingToken(\"The empty string is an invalid Slack API token\")", "response": "Create a SlackClient with a provided token."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef connect_with_retry(self) -> None:\n        if self.is_connected():\n            log.debug('Already connected to the Slack API')\n            return\n\n        for retry in range(1, self.retries + 1):\n            self.connect()\n            if self.is_connected():\n                log.debug('Connected to the Slack API')\n                return\n            else:\n                interval = self.backoff(retry)\n                log.debug(\"Waiting %.3fs before retrying\", interval)\n                time.sleep(interval)\n\n        raise FailedConnection('Failed to connect to the Slack API')", "response": "Attempts to connect to the Slack API. Retry on failures."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fetch_events(self) -> List[dict]:\n        try:\n            return self.inner.rtm_read()\n\n        # TODO: The TimeoutError could be more elegantly resolved by making\n        # a PR to the websocket-client library and letting them coerce that\n        # exception to a WebSocketTimeoutException that could be caught by\n        # the slackclient library and then we could just use auto_reconnect.\n        except TimeoutError:\n            log.debug('Lost connection to the Slack API, attempting to '\n                      'reconnect')\n            self.connect_with_retry()\n            return []", "response": "Fetch RTM events from the API."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef handle(self, type: str, *, kwargs: dict = None) -> Callable:\n        def decorator(fn: Callable) -> Callable:\n            # Validate that the wrapped callable is a suitable event handler.\n            sig = signature(fn)\n            num_params = len(sig.parameters)\n            if num_params < 2:\n                raise TypeError(_format_parameter_error_message(\n                    fn.__name__, sig, num_params))\n\n            # Register a tuple of the callable and its kwargs, if any.\n            self._handlers[type].append((fn, kwargs or {}))\n            return fn\n\n        return decorator", "response": "Decorator that registers a callable as a suitable event handler."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nensuring we have a SlackClient.", "response": "def _ensure_slack(self, connector: Any, retries: int,\n                      backoff: Callable[[int], float]) -> None:\n        \"\"\" Ensure we have a SlackClient. \"\"\"\n        connector = self._env_var if connector is None else connector\n        slack: SlackClient = _create_slack(connector)\n        self._slack = _SlackClientWrapper(\n            slack=slack,\n            retries=retries,\n            backoff=backoff\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef run(self, *,\n            connector: Union[EnvVar, Token, SlackClient, None] = None,\n            interval: float = 0.5, retries: int = 16,\n            backoff: Callable[[int], float] = None,\n            until: Callable[[List[dict]], bool] = None) -> None:\n        \"\"\"\n        Connect to the Slack API and run the event handler loop.\n\n        Args:\n            connector: A means of connecting to the Slack API. This can be an\n                API :obj:`Token`, an :obj:`EnvVar` from which a token can be\n                retrieved, or an established :obj:`SlackClient` instance. If\n                absent an attempt will be made to use the ``LAYABOUT_TOKEN``\n                environment variable.\n            interval: The number of seconds to wait between fetching events\n                from the Slack API.\n            retries: The number of retry attempts to make if a connection to\n                Slack is not established or is lost.\n            backoff: The strategy used to determine how long to wait between\n                retries. Must take as input the number of the current retry and\n                output a :obj:`float`. The retry count begins at 1 and\n                continues up to ``retries``. If absent a\n                `truncated exponential backoff`_ strategy will be used.\n            until: The condition used to evaluate whether this method\n                terminates. Must take as input a :obj:`list` of :obj:`dict`\n                representing Slack RTM API events and return a :obj:`bool`. If\n                absent this method will run forever.\n\n        Raises:\n            TypeError: If an unsupported connector is given.\n            MissingToken: If no API token is available.\n            FailedConnection: If connecting to the Slack API fails.\n\n        .. _truncated exponential backoff:\n            https://cloud.google.com/storage/docs/exponential-backoff\n        \"\"\"\n        backoff = backoff or _truncated_exponential\n        until = until or _forever\n\n        self._ensure_slack(\n            connector=connector,\n            retries=retries,\n            backoff=backoff\n        )\n        assert self._slack is not None\n\n        while True:\n            events = self._slack.fetch_events()\n\n            if not until(events):\n                log.debug('Exiting event loop')\n                break\n\n            # Handle events!\n            for event in events:\n                type_ = event.get('type', '')\n                for handler in self._handlers[type_] + self._handlers['*']:\n                    fn, kwargs = handler\n                    fn(self._slack.inner, event, **kwargs)\n\n            # Maybe don't pester the Slack API too much.\n            time.sleep(interval)", "response": "Runs the event handler loop."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef install():\n    '''\n        Install weboob system-wide\n    '''\n    tmp_weboob_dir = '/tmp/weboob'\n\n    # Check that the directory does not already exists\n    while (os.path.exists(tmp_weboob_dir)):\n        tmp_weboob_dir += '1'\n\n    # Clone the repository\n    print 'Fetching sources in temporary dir {}'.format(tmp_weboob_dir)\n    result = cmd_exec('git clone {} {}'.format(WEBOOB_REPO, tmp_weboob_dir))\n    if (result['error']):\n        print result['stderr']\n        print 'Weboob installation failed: could not clone repository'\n        exit()\n\n    print 'Sources fetched, will now process to installation'\n\n    # Launch the installation\n    result = cmd_exec('cd {} && ./setup.py install'.format(tmp_weboob_dir))\n\n    # Remove the weboob directory\n    shutil.rmtree(tmp_weboob_dir)\n\n    if (result['error']):\n        print result['stderr']\n        print 'Weboob installation failed: setup failed'\n        exit()\n\n    print result['stdout']\n\n    # Check weboob version\n    weboob_version = get_weboob_version()\n    if (not weboob_version):\n        print 'Weboob installation failed: version not detected'\n        exit()\n\n    print 'Weboob (version: {}) installation succeeded'.format(weboob_version)\n    update()", "response": "Installs the weboob system - wide wevables in a temporary directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef copy(self, contents=True):\n        '''Create a copy of this model, optionally without contents (i.e. just configuration)'''\n        cp = connection(self._baseiri, self._attr_cls, self._logger)\n        if contents: cp.add_many(self._relationships)\n\n        return cp", "response": "Create a copy of this model optionally without contents ( i. e. just configuration )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef match(self, origin=None, rel=None, target=None, attrs=None, include_ids=False):\n        '''\n        Iterator over relationship IDs that match a pattern of components\n\n        origin - (optional) origin of the relationship (similar to an RDF subject). If omitted any origin will be matched.\n        rel - (optional) type IRI of the relationship (similar to an RDF predicate). If omitted any relationship will be matched.\n        target - (optional) target of the relationship (similar to an RDF object), a boolean, floating point or unicode object. If omitted any target will be matched.\n        attrs - (optional) attribute mapping of relationship metadata, i.e. {attrname1: attrval1, attrname2: attrval2}. If any attribute is specified, an exact match is made (i.e. the attribute name and value must match).\n        include_ids - If true include statement IDs with yield values\n        '''\n        #Can't use items or we risk client side RuntimeError: dictionary changed size during iteration\n        for index, curr_rel in enumerate(self._relationships):\n            matches = True\n            if origin and origin != curr_rel[ORIGIN]:\n                matches = False\n                continue\n            if rel and rel != curr_rel[RELATIONSHIP]:\n                matches = False\n                continue\n            if target and target != curr_rel[TARGET]:\n                matches = False\n                continue\n            if attrs:\n                for k, v in attrs.items():\n                    if k not in curr_rel[ATTRIBUTES] or curr_rel[ATTRIBUTES].get(k) != v:\n                        matches = False\n            if matches:\n                if include_ids:\n                    yield index, (curr_rel[0], curr_rel[1], curr_rel[2], curr_rel[3].copy())\n                else:\n                    yield (curr_rel[0], curr_rel[1], curr_rel[2], curr_rel[3].copy())\n        return", "response": "Yields the set of identifiers that match a pattern of components of components."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds one relationship to the extent", "response": "def add(self, origin, rel, target, attrs=None, index=None):\n        '''\n        Add one relationship to the extent\n\n        origin - origin of the relationship (similar to an RDF subject)\n        rel - type IRI of the relationship (similar to an RDF predicate)\n        target - target of the relationship (similar to an RDF object), a boolean, floating point or unicode object\n        attrs - optional attribute mapping of relationship metadata, i.e. {attrname1: attrval1, attrname2: attrval2}\n        index - optional position for the relationship to be inserted\n        '''\n        #FIXME: return an ID (IRI) for the resulting relationship?\n\n        if not origin: \n            raise ValueError('Relationship origin cannot be null')\n        if not rel: \n            raise ValueError('Relationship ID cannot be null')\n\n        # convert attribute class to the expected type\n        if type(attrs) != type(self._attr_cls):\n            attrs = self._attr_cls(attrs or {})\n\n        #No, could be an I instance, fails assertion\n        #assert isinstance(origin, str) and isinstance(origin, str) and isinstance(origin, str) and isinstance(origin, dict), (origin, rel, target, attrs)\n\n        item = (origin, rel, target, attrs)\n        if index is not None:\n            rid = index\n            self._relationships.insert(index, item)\n        else:\n            rid = self.size()\n            self._relationships.append(item)\n        return rid"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a list of relationships to the extent.", "response": "def add_many(self, rels):\n        '''\n        Add a list of relationships to the extent\n\n        rels - a list of 0 or more relationship tuples, e.g.:\n        [\n            (origin, rel, target, {attrname1: attrval1, attrname2: attrval2}),\n        ]\n\n        origin - origin of the relationship (similar to an RDF subject)\n        rel - type IRI of the relationship (similar to an RDF predicate)\n        target - target of the relationship (similar to an RDF object), a boolean, floating point or unicode object\n        attrs - optional attribute mapping of relationship metadata, i.e. {attrname1: attrval1, attrname2: attrval2}\n\n        you can omit the dictionary of attributes if there are none, as long as you are not specifying a statement ID\n        '''\n        for curr_rel in rels:\n            attrs = self._attr_cls()\n            if len(curr_rel) == 2: # handle __iter__ output for copy()\n                origin, rel, target, attrs = curr_rel[1]\n            elif len(curr_rel) == 3:\n                origin, rel, target = curr_rel\n            elif len(curr_rel) == 4:\n                origin, rel, target, attrs = curr_rel\n            else:\n                raise ValueError\n            assert rel\n            self.add(origin, rel, target, attrs)\n        return"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nexport is the entry point for exporting docker images.", "response": "def _quality_control(self, args, **extra_args):\n        \"\"\"\n        Export is the entry point for exporting docker images.\n        \"\"\"\n        if not isinstance(args, argparse.Namespace):\n            raise Exception(\"args should of an instance of argparse.Namespace\")\n\n        # create new freight forwarder object\n        # config_override=manifest_override\n        freight_forwarder = FreightForwarder()\n\n        # create commercial invoice this is the contact given to freight forwarder dispatch containers and images\n        commercial_invoice = freight_forwarder.commercial_invoice(\n            'quality_control',\n            args.data_center,\n            args.environment,\n            args.service\n        )\n\n        # call quality control with commercial invoice and additional arguments\n        bill_of_lading = freight_forwarder.quality_control(\n            commercial_invoice,\n            attach=args.attach,\n            clean=args.clean,\n            test=args.test,\n            configs=args.configs,\n            use_cache=args.use_cache,\n            env=args.env\n        )\n\n        # pretty lame... Need to work on return values through to app to make them consistent.\n        exit_code = 0 if bill_of_lading else 1\n\n        if exit_code != 0:\n            exit(exit_code)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef restart_program():\n    logging.debug(\"Restarting program...\")\n    python = sys.executable\n    os.execl(python, python, * sys.argv)", "response": "Restarts the current program."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef call_repeatedly(func, interval, *args, **kwargs):\n    main_thead = threading.current_thread()\n    stopped = threading.Event()\n\n    def loop():\n        while not stopped.wait(interval) and main_thead.is_alive():  # the first call is in `interval` secs\n            func(*args, **kwargs)\n\n        return\n\n    timer_thread = threading.Thread(target=loop, daemon=True)\n    timer_thread.start()\n\n    atexit.register(stopped.set)\n\n    return timer_thread, stopped.set", "response": "Call a function at interval returns a thread object and the loop stopper Event."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef synchronized_limit(lock):\n    def wrap(f):\n        def synchronize(*args, **kw):\n            if lock[1] < 10:\n                lock[1] += 1\n                lock[0].acquire()\n                try:\n                    return f(*args, **kw)\n                finally:\n                    lock[1] -= 1\n                    lock[0].release()\n            else:\n                raise Exception('Too busy')\n        return synchronize\n    return wrap", "response": "Decorator that provides thread - safe locking on a function\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef execute(command, return_output=True, log_file=None, log_settings=None, error_logfile=None, timeout=None, line_function=None, poll_timing = 0.01, logger=None, working_folder=None, env=None):\n\n    tmp_log = False\n    if log_settings:\n        log_folder = log_settings.get('LOG_FOLDER')\n    else:\n        tmp_log = True\n        log_folder = tempfile.mkdtemp()\n\n    if not log_file:\n        log_file = os.path.join(log_folder, \"commands\", \"execute-command-logfile-%s.log\" % UUID.uuid4())\n        try:\n            if not os.path.isdir(os.path.join(log_folder, \"commands\")):\n                os.makedirs(os.path.join(log_folder, \"commands\"))\n        except:\n            pass\n    if not logger:\n        logger = logging.getLogger('command_execute')\n\n    logfile_writer = open(log_file, 'a')\n    header = \"%s - Executing command (timeout=%s) :\\n\\t%s\\n\\n\\n\" % (datetime.now().isoformat(), timeout, command)\n    logfile_writer.write(header)\n    logfile_writer.flush()\n\n    logfile_reader = open(log_file, 'rb')\n    logfile_reader.seek(0, os.SEEK_END)\n    logfile_start_position = logfile_reader.tell()\n\n    if error_logfile:\n        err_logfile_writer = open(error_logfile, 'a')\n    else:\n        err_logfile_writer = logfile_writer\n\n    start = datetime.now()\n    timeout_string = \"\"\n    if timeout:\n        timeout_string = \"(timeout=%s)\" % timeout\n    logger.info(u\"Executing command %s :\\n\\t\\t%s\" % (timeout_string, command) )\n\n    # We use \"exec <command>\" as Popen launches a shell, that runs the command.\n    # It will transform the child process \"sh\" into the \"command exectable\" because of the \"exec\".\n    # Said more accuratly, it won't fork to create launch the command in a sub sub process.\n    # Therefore, when you kill the child process, you kill the \"command\" process and not the unecessary \"sh\" parent process.\n    if sys.platform != 'win32':\n        command = u\"exec %s\" % text_utils.uni(command)\n    process = subprocess.Popen(command, stdout=logfile_writer, stderr=err_logfile_writer, bufsize=1, shell=True, cwd=working_folder, env=env)\n\n    while process.poll() == None:\n        # In order to avoid unecessary cpu usage, we wait for \"poll_timing\" seconds ( default: 0.1 sec )\n        time.sleep(poll_timing)\n\n        # Timeout check\n        if timeout != None:\n            now = datetime.now()\n            if (now - start).seconds> timeout:\n                #process.terminate() ??\n                os.kill(process.pid, signal.SIGKILL)\n                os.waitpid(-1, os.WNOHANG)\n                raise Exception(\"Command execution timed out (took more than %s seconds...)\" % timeout)\n\n        # Line function call:\n        #   => if line_function is defined, we call it on each new line of the file.\n        if line_function:\n            o = text_utils.uni(logfile_reader.readline()).rstrip()\n            while o != '':\n                line_function(o)\n                o = text_utils.uni(logfile_reader.readline()).rstrip()\n\n    if not return_output:\n        # Return result code and ensure we have waited for the end of sub process\n        return process.wait()\n\n    logfile_reader.seek(logfile_start_position, os.SEEK_SET) #back to the beginning of the file\n\n    res = text_utils.uni(logfile_reader.read())\n\n    try:\n        logfile_reader.close()\n        logfile_writer.close()\n        err_logfile_writer.close()\n\n        if tmp_log:\n            shutil.rmtree(log_folder, ignore_errors=True)\n    except:\n        logger.exception(\"Error while cleaning after tbx.execute() call.\")\n\n    return res", "response": "Execute a command and return the return code."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef daemonize(umask=0, work_dir=\"/\", max_fd=1024, redirect=\"/dev/null\"):\n    if not redirect:\n        redirect = \"/dev/null\"\n\n    if hasattr(os, \"devnull\"):\n        redirect = os.devnull\n\n    try:\n        pid = os.fork()\n    except OSError as e:\n        raise Exception(\"%s [%d]\" % (e.strerror, e.errno))\n\n    # first child\n    if pid == 0:\n        os.setsid()\n\n        try:\n            # Fork a second child.\n            pid = os.fork()\n        except OSError as e:\n            raise Exception(\"%s [%d]\" % (e.strerror, e.errno))\n\n        # The second child.\n        if pid == 0:\n            os.chdir(work_dir)\n            os.umask(umask)\n        else:\n            # exit first child\n            os._exit(0)\n    else:\n        # Exit parent\n        os._exit(0)\n\n    #killing inherited file descriptors\n    import resource\n    maxfd = resource.getrlimit(resource.RLIMIT_NOFILE)[1]\n    if maxfd == resource.RLIM_INFINITY:\n        maxfd = max_fd\n\n    # close all file descriptors.\n    for fd in range(0, maxfd):\n        try:\n            os.close(fd)\n        except OSError:\n            # ignored\n            pass\n\n    os.open(redirect, os.O_RDWR) # standard input\n\n    # Duplicate standard\n    os.dup2(0, 1)\t\t\t# standard output (1)\n    os.dup2(0, 2)\t\t\t# standard error (2)\n\n    return os.getpid()", "response": "Daemonize the current process."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef log(self, msg, lvl = 0):\n        '''Log messages according to the logging level (0 is highest priority).'''\n        if self.log_level >= lvl:\n            self.log_fn(msg)", "response": "Log messages according to the logging level."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the series names corresponding to column_indices and column_names.", "response": "def get_series_names(self, column_indices = [], column_names = []):\n        '''Returns the series' names corresponding to column_indices and column_names.\n           \"names\" here are:\n              - strings for single-indexed dataframes; or\n              - tuples for multi-indexed dataframes.\n\n           If both parameters are empty then all column names are returned.\n        '''\n        n = []\n        if not column_indices and not column_names:\n            for k, v in sorted(self.series_names.iteritems()):\n                # Iterate by index to preserve document order\n                if v != self.reference_series:\n                    n.append(k)\n        else:\n            s = set([self.series_names[x] for x in column_indices])\n            t = set([self.series_index[x] for x in column_names])\n            n = sorted(s.union(t))\n        assert(n)\n        return [self.series_names[x] for x in n]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _analyze(self):\n        '''Run-once function to generate analysis over all series, considering both full and partial data.\n           Initializes the self.analysis dict which maps:\n               (non-reference) column/series -> 'full' and/or 'partial' -> stats dict returned by get_xy_dataset_statistics\n        '''\n\n        if not self.analysis:\n            for dseries in self.data_series:\n\n                # Count number of non-NaN rows\n                dseries_count = self.df[dseries].count()\n                assert(len(self.df_pruned) <= dseries_count <= len(self.df) or dseries_count)\n                self.analysis[dseries] = dict(\n                    partial = None,\n                    full = None,\n                )\n\n                # Compute the statistics for the common records\n                stats = get_xy_dataset_statistics_pandas(self.df_pruned, self.reference_series, dseries,\n                                                         fcorrect_x_cutoff = 1.0, fcorrect_y_cutoff = 1.0,\n                                                         bootstrap_data = False,\n                                                         x_fuzzy_range = 0.1,\n                                                         y_scalar = 1.0, ignore_null_values = True)\n\n                if (len(self.df_pruned) == len(self.df)):\n                    # There are no pruned records so these are actually the full stats\n                    self.analysis[dseries]['full'] = dict(data = stats, description = format_stats(stats, floating_point_format = '%0.3f', sci_notation_format = '%.2E', return_string = True))\n                else:\n                    # Store the results for the partial dataset\n                    self.analysis[dseries]['partial'] = dict(data = stats, description = format_stats(stats, floating_point_format = '%0.3f', sci_notation_format = '%.2E', return_string = True))\n                    if dseries_count > len(self.df_pruned):\n                        # This dataset has records which are not in the pruned dataset\n                        stats = get_xy_dataset_statistics_pandas(self.df, self.reference_series, dseries,\n                                                                 fcorrect_x_cutoff = 1.0, fcorrect_y_cutoff = 1.0,\n                                                                 bootstrap_data = False,\n                                                                 x_fuzzy_range = 0.1,\n                                                                 y_scalar = 1.0, ignore_null_values = True)\n                        self.analysis[dseries]['full'] = dict(data = stats, description = format_stats(stats, floating_point_format = '%0.3f', sci_notation_format = '%.2E', return_string = True))\n\n        return self.analysis", "response": "Run - once function to generate analysis over all series and store the results for the common records in the self. analysis dictionary."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn summary analysis from the dataframe as a DataTable object.", "response": "def tabulate(self, restricted_predicted_column_indices = [], restricted_predicted_column_names = [], dataset_name = None):\n        '''Returns summary analysis from the dataframe as a DataTable object.\n           DataTables are wrapped pandas dataframes which can be combined if the have the same width. This is useful for combining multiple analyses.\n           DataTables can be printed to terminal as a tabular string using their representation function (i.e. print(data_table)).\n           This function (tabulate) looks at specific analysis; this class (DatasetDataFrame) can be subclassed for custom tabulation.'''\n\n        self._analyze()\n\n        data_series = self.get_series_names(column_indices = restricted_predicted_column_indices, column_names = restricted_predicted_column_names)\n\n        # Determine the multi-index headers\n        group_names = []\n        for l in self.index_layers:\n            group_names.append(l)\n\n        # Set up the table headers\n        headers = ['Dataset'] + group_names + ['n', 'R', 'rho', 'MAE', 'Fraction correct  ', 'FC sign', 'SB sensitivity', 'SB specificity']\n        table_rows = []\n        for dseries in data_series:\n            if isinstance(dseries, tuple):\n                dseries_l = list(dseries)\n            else:\n                assert(isinstance(dseries, basestring))\n                dseries_l = [dseries]\n\n            results = []\n            assert (len(self.index_layers) == len(dseries))\n            if self.analysis.get(dseries, {}).get('partial') and self.analysis.get(dseries, {}).get('full'):# data_series in self.analysis[dseries]['full']:\n                results.append((dseries_l[:-1] + [dseries_l[-1] + '*'], self.analysis[dseries]['partial']))\n                results.append((dseries_l[:-1] + [dseries_l[-1]], self.analysis[dseries]['full']))\n            elif (self.analysis.get(dseries, {}).get('partial')):\n                results.append((dseries_l[:-1] + [dseries_l[-1] + '*'], self.analysis[dseries]['partial']))\n            elif (self.analysis.get(dseries, {}).get('full')):\n                results = [(dseries, self.analysis[dseries]['full'])]\n\n            for result in results:\n                n = result[1]['data']['n']\n                R = result[1]['data']['pearsonr'][0]\n                rho = result[1]['data']['spearmanr'][0]\n                mae = result[1]['data']['MAE']\n                fraction_correct = result[1]['data']['fraction_correct']\n                accuracy = result[1]['data']['accuracy']\n                SBSensitivity = '{0:.3f} / {1}'.format(result[1]['data']['significant_beneficient_sensitivity'][0], result[1]['data']['significant_beneficient_sensitivity'][1])\n                SBSpecificity = '{0:.3f} / {1}'.format(result[1]['data']['significant_beneficient_specificity'][0], result[1]['data']['significant_beneficient_specificity'][1])\n\n                method = result[0]\n                if isinstance(method, tuple):\n                    method = list(method)\n\n                table_rows.append([dataset_name or self.reference_dataset_name] + method +\n                                  [n, R, rho, mae, fraction_correct, accuracy, SBSensitivity, SBSpecificity])\n\n        # Convert the lists into a (wrapped) pandas dataframe to make use of the pandas formatting code to save reinventing the wheel...\n        return DataTable(pandas.DataFrame(table_rows, columns = headers), self.index_layers)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupdate the configuration of the current project with the information from the conf. py.", "response": "def update_configuration(app):\n    \"\"\"Update parameters which are dependent on information from the\n    project-specific conf.py (including its location on the filesystem)\"\"\"\n    config = app.config\n    project = config.project\n    config_dir = app.env.srcdir\n    sys.path.insert(0, os.path.join(config_dir, '..'))\n\n    config.html_theme_path.append(os.path.relpath(os.path.join(os.path.abspath(os.path.dirname(__file__)), 'themes'), config_dir))\n    if not config.html_logo:\n        config.html_logo = os.path.relpath(os.path.join(STATIC_PATH, 'safari_logo.png'), config_dir)\n    if not config.html_favicon:\n        config.html_favicon = os.path.relpath(os.path.join(STATIC_PATH, 'favicon.ico'), config_dir)\n    config.html_static_path.append(os.path.relpath(STATIC_PATH, config_dir))\n    if not config.htmlhelp_basename:\n        config.htmlhelp_basename = '%sdoc' % project\n    if not config.latex_logo:\n        config.latex_logo = os.path.relpath(os.path.join(STATIC_PATH, 'safari_logo.png'), config_dir)\n    if not config.epub_title:\n        config.epub_title = u'%s Documentation' % project\n    if not config.epub_publisher:\n        config.epub_publisher = config.epub_author\n    if not config.epub_copyright:\n        config.epub_copyright = config.copyright\n\n    config.latex_documents.append(\n        (master_doc,\n         '%s.tex' % project,\n         u'%s Documentation' % project,\n         u'Safari',\n         'manual'))\n    config.man_pages.append(\n        (master_doc,\n         project,\n         u'%s Documentation' % project,\n         [u'Safari'],\n         1))\n    config.texinfo_documents.append(\n        (master_doc,\n         project,\n         u'%s Documentation' % project,\n         u'Safari',\n         project,\n         'One line description of project.',\n         'Miscellaneous'))\n\n    # Parse the version number from setup.py without actually running setup()\n    with open(os.path.join(config_dir, '..', 'setup.py'), 'r') as f:\n        content = f.read()\n        match = re.search(r\"version\\s*=\\s*['\\\"]([\\d\\.]+)['\\\"]\", content)\n        if match:\n            config.version = match.group(1)\n            config.release = config.version"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndeleting a role from the cache.", "response": "def delete(self, role, commit=True):\n        \"\"\" Delete a role \"\"\"\n        events.role_deleted_event.send(role)\n        return super().delete(role, commit)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _build_arguments(self):\n        self._parser.add_argument(\n            '--clean',\n            type=bool,\n            required=False,\n            default=False,\n            help=\"clean up everything that was created by freight forwarder at the end.\"\n        )\n\n        self._parser.add_argument(\n            '--configs',\n            type=bool,\n            required=False,\n            default=False,\n            help=\"Would you like to inject configuration files?\"\n        )\n\n        self._parser.add_argument(\n            '--test',\n            type=bool,\n            required=False,\n            default=False,\n            help=\"Run tests.\"\n        )\n\n        self._parser.add_argument(\n            '-t', '--tag',\n            required=False,\n            type=six.text_type,\n            action='append',\n            help='list of tags applied to the image being exported. example: sh1hash'\n        )\n\n        self._parser.add_argument(\n            '--use-cache',\n            required=False,\n            action='store_true',\n            default=False,\n            help='Allow build to use cached image layers.'\n        )\n\n        self._parser.add_argument(\n            '--no-tagging-scheme',\n            required=False,\n            action='store_true',\n            default=False,\n            help='Turn off freight forwarders tagging scheme.'\n        )\n\n        self._parser.add_argument(\n            '--no-validation',\n            action=\"store_true\",\n            required=False,\n            default=False,\n            help='**UNSAFE**. The image will be built, NOT started, and pushed to the registry'\n        )\n\n        self._parser.add_argument(\n            '-y',\n            required=False,\n            action='store_true',\n            default=False,\n            help='**UNSAFE**. Turn off `--no-validation` interaction during export'\n        )", "response": "Build the command line arguments for the freight forwarder command."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nexport is the entry point for exporting docker images.", "response": "def _export(self, args, **extra_args):\n        \"\"\"\n        Export is the entry point for exporting docker images.\n        \"\"\"\n        if not isinstance(args, argparse.Namespace):\n            raise TypeError(logger.error(\"args should of an instance of argparse.Namespace\"))\n\n        # Warn the consumer about unsafe Docker Practices\n        if args.no_validation:\n            logger.warning(\"#######################################################\\n\"\n                           \"Validation has been disabled for this export operation.\\n\"\n                           \"This is an unsafe operation and does not verify the \"\n                           \"run time nature of the container.\\n\"\n                           \"Any docker image created in this manner will not \"\n                           \"be verified to start. Do not ship broken code.\\n\"\n                           \"#######################################################\\n\",\n                           extra={'formatter': 'cli-warning'})\n\n            # Require the consumer to verify their actions\n            if not args.y:\n                validation_input = six.moves.input(\"Please type \\'yes\\' to export the container without validation: \")\n\n                if not (isinstance(validation_input, six.string_types) and ('yes' == validation_input)):\n                    raise ValueError(\"Incorrect type defined. Required value: yes\")\n\n        # create new freight forwarder to create a commercial_invoice and export goods.\n        freight_forwarder = FreightForwarder()\n\n        # create commercial invoice this is the contact given to freight forwarder dispatch containers and images\n        commercial_invoice = freight_forwarder.commercial_invoice(\n            'export',\n            args.data_center,\n            args.environment,\n            args.service,\n            tagging_scheme=not args.no_tagging_scheme\n        )\n\n        # create commercial_invoice\n        bill_of_lading = freight_forwarder.export(\n            commercial_invoice,\n            clean=args.clean,\n            configs=args.configs,\n            tags=args.tag,\n            test=args.test,\n            use_cache=args.use_cache,\n            validate=not args.no_validation\n        )\n\n        # pretty lame... Need to work on return values through to app to make them consistent.\n        exit_code = 0 if bill_of_lading else 1\n\n        if exit_code != 0:\n            exit(exit_code)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nretrieves the version attribute for Layabout.", "response": "def get_version(string):\n    \"\"\" Retrieve the ``__version__`` attribute for Layabout. \"\"\"\n    flags = re.S\n    pattern = r\".*__version__ = '(.*?)'\"\n    match = re.match(pattern=pattern, string=string, flags=flags)\n\n    if match:\n        return match.group(1)\n\n    raise RuntimeError('No version string could be matched')"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngives a row containing the peak of the QTL and all the rows of the linkage group of the said QTL (splitted per trait), determine the QTL interval and find the start and stop marker of the said interval. The interval is a LOD 2 interval. The approach is conservative in the way it takes the first and last marker within the interval. :arg peak, a list containing the row information for the peak marker :arg block, a hash containing per column, all the rows in the linkage group of this QTL, splitted per trait. :arg headers, the first row of the QTL matrix file, used to determine which block to look at for each trait process.", "response": "def _extrac_qtl(peak, block, headers):\n    \"\"\" Given a row containing the peak of the QTL and all the rows of\n    the linkage group of the said QTL (splitted per trait), determine\n    the QTL interval and find the start and stop marker of the said\n    interval.\n    The interval is a LOD 2 interval.\n    The approach is conservative in the way it takes the first and last\n    marker within the interval.\n\n    :arg peak, a list containing the row information for the peak marker\n    :arg block, a hash containing per column, all the rows in the\n        linkage group of this QTL, splitted per trait.\n    :arg headers, the first row of the QTL matrix file, used to determine\n        which block to look at for each trait process.\n\n    \"\"\"\n    qtls = []\n    if not peak:\n        return qtls\n    threshold = 2\n    for trait in peak:\n        blockcnt = headers.index(trait)\n        local_block = block[blockcnt]\n        lod2_threshold = float(peak[trait][-1]) - float(threshold)\n        # Search QTL start\n        cnt = local_block.index(peak[trait])\n        start = local_block[cnt]\n        while cnt >= 0:\n            start = local_block[cnt]\n            if re.match(r'c\\d+\\.loc[\\d\\.]+', local_block[cnt][0]):\n                cnt = cnt - 1\n                continue\n            if float(local_block[cnt][-1]) < lod2_threshold:\n                break\n            cnt = cnt - 1\n\n        # Search QTL end\n        end = []\n        cnt = local_block.index(peak[trait])\n        end = local_block[cnt]\n        while cnt < len(local_block):\n            end = local_block[cnt]\n            if re.match(r'c\\d+\\.loc[\\d\\.]+', local_block[cnt][0]):\n                cnt += 1\n                continue\n            if float(local_block[cnt][-1]) < lod2_threshold:\n                break\n            cnt = cnt + 1\n\n        qtl = QTL()\n        qtl.trait = trait\n        qtl.start_mk = start[0]\n        qtl.start_position = start[2]\n        qtl.peak_mk = peak[trait][0]\n        qtl.peak_start_position = peak[trait][2]\n        qtl.peak_stop_position = peak[trait][2]\n        qtl.stop_mk = end[0]\n        qtl.stop_position = end[2]\n        qtls.append(qtl)\n    return qtls"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef generate_map_chart_file(qtl_matrix, lod_threshold,\n                            map_chart_file='MapChart.map'):\n    \"\"\" This function converts our QTL matrix file into a MapChart input\n    file.\n\n    :arg qtl_matrix: the path to the QTL matrix file generated by\n        the plugin.\n    :arg lod_threshold: threshold used to determine if a given LOD value\n        is reflective the presence of a QTL.\n    :kwarg map_chart_file: name of the output file containing the\n        MapChart information.\n\n    \"\"\"\n\n    qtl_matrix = read_input_file(qtl_matrix, sep=',')\n    tmp_dic = {}\n    cnt = 1\n    tmp = {}\n    block = {}\n    for row in qtl_matrix[1:]:\n        linkgrp = qtl_matrix[cnt - 1][1]\n        if cnt == 1:\n            linkgrp = qtl_matrix[cnt][1]\n\n        if not linkgrp in tmp_dic:\n            tmp_dic[linkgrp] = [[], []]\n\n        infos = row[0:3]\n        if qtl_matrix[cnt][1] != linkgrp:\n            if tmp:\n                qtls = _extrac_qtl(tmp, block, qtl_matrix[0])\n                tmp_dic[linkgrp][1] = qtls\n            linkgrp = qtl_matrix[cnt][1]\n            tmp_dic[linkgrp] = [[], []]\n            tmp = {}\n            block = {}\n\n        tmp_dic[linkgrp][0].append([row[0], row[2]])\n\n        colcnt = 3\n        for cel in row[3:-1]:\n            blockrow = infos[:]\n            blockrow.extend([qtl_matrix[0][colcnt], cel])\n            if colcnt in block:\n                block[colcnt].append(blockrow)\n            else:\n                block[colcnt] = [blockrow]\n            if cel.strip() != '' and float(cel) >= float(lod_threshold):\n                temp = infos[:]\n                if not tmp\\\n                        or (qtl_matrix[0][colcnt] in tmp\n                            and float(cel) >= float(\n                                tmp[qtl_matrix[0][colcnt]][-1])\n                            ) \\\n                        or qtl_matrix[0][colcnt] not in tmp:\n                    temp.extend([qtl_matrix[0][colcnt], cel])\n                    tmp[qtl_matrix[0][colcnt]] = temp\n            colcnt = colcnt + 1\n        cnt = cnt + 1\n\n    qtl_info = {}\n\n    try:\n        stream = open(map_chart_file, 'w')\n        keys = list(tmp_dic.keys())\n        ## Remove unknown group, reason:\n        # The unlinked markers, if present, are always put in group U by\n        # MapQTL. If you don't omit them and there are many (often), then\n        # their names take so much space that it is difficult to fit them\n        # on the page.\n        if 'U' in keys:\n            keys.remove('U')\n        # Try to convert all the groups to int, which would result in\n        # a better sorting. If that fails, fail silently.\n        try:\n            keys = [int(key) for key in keys]\n        except ValueError:\n            pass\n        keys.sort()\n        for key in keys:\n            key = str(key)  # Needed since we might have converted them to int\n            if tmp_dic[key]:\n                if key == 'U':  # pragma: no cover\n                    # We removed the key before, we should not be here\n                    continue\n                stream.write('group %s\\n' % key)\n                for entry in _order_linkage_group(tmp_dic[key][0]):\n                    stream.write('  '.join(entry) + '\\n')\n                if tmp_dic[key][1]:\n                    stream.write('\\n')\n                    stream.write('qtls\\n')\n                    for qtl in tmp_dic[key][1]:\n                        qtl_info[qtl.peak_mk] = qtl.get_flanking_markers()\n                        stream.write('%s \\n' % qtl.to_string())\n                stream.write('\\n')\n                stream.write('\\n')\n    except IOError as err:  # pragma: no cover\n        LOG.info('An error occured while writing the map chart map '\n                 'to the file %s' % map_chart_file)\n        LOG.debug(\"Error: %s\" % err)\n    finally:\n        stream.close()\n    LOG.info('Wrote MapChart map in file %s' % map_chart_file)\n\n    return qtl_info", "response": "This function converts our QTL matrix file into a MapChart file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef append_flanking_markers(qtls_mk_file, flanking_markers):\n    matrix = read_input_file(qtls_mk_file, sep=',')\n    output = []\n    cnt = 0\n    for row in matrix:\n        if cnt == 0:\n            markers = ['LOD2 interval start', 'LOD2 interval end']\n        elif row[3] in flanking_markers:\n            markers = flanking_markers[row[3]]\n        else:\n            markers = ['NA', 'NA']\n        cnt += 1\n        row.extend(markers)\n        output.append(row)\n    write_matrix(qtls_mk_file, output)", "response": "Append the flanking markers extracted in the process of\n    generating the MapChart to the QTL list file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_info(self):\n        'Retrieve the data from CrossRef.'\n        escaped_doi = urllib2.quote(self.doi, '')\n        html = get_resource(\"www.crossref.org\", '/guestquery?queryType=doi&restype=unixref&doi=%s&doi_search=Search' % escaped_doi)\n\n        xml_matches = []\n        for m in re.finditer('(<doi_records>.*?</doi_records>)', html, re.DOTALL):\n            xml_matches.append(m.group(0))\n\n        if len(xml_matches) == 0:\n            raise DOIRetrievalException('No matches found for the DOI \"%s\".' % self.doi)\n        elif len(xml_matches) == 1:\n            return xml_matches[0]\n        else:\n            raise DOIRetrievalException('Multiple (%d) matches found for the DOI \"%s\".' % (len(xml_matches), self.doi))", "response": "Retrieve the data from CrossRef."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nensuring that a session is created from the given engine or session.", "response": "def ensure_session(engine_or_session):\n    \"\"\"\n    If it is an engine, then create a session from it. And indicate that\n    this session should be closed after the job done.\n\n    :type engine_or_session: Union[Engine, Session]\n    :rtype: Tuple[Session, bool]\n    \"\"\"\n    if isinstance(engine_or_session, Engine):\n        engine_id = id(engine_or_session)\n        if id(engine_id) in session_klass_cache: # pragma: no cover\n            SessionClass = session_klass_cache[engine_id]\n        else:  # pragma: no cover\n            SessionClass = sessionmaker(bind=engine_or_session)\n        ses = SessionClass()\n        auto_close = True\n        return ses, auto_close\n    elif isinstance(engine_or_session, Session):\n        ses = engine_or_session\n        auto_close = False\n        return ses, auto_close"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_backbone_atoms_linearly(self, start_residue, end_residue, insertion_residues, insertion_residue_map):\n        '''This function returns the PDB content for a structure with the missing backbone atoms - i.e. it adds the\n           N, Ca, C atoms spaced evenly between the last existing backbone atom of start_residue and the first existing\n           backbone atom of end_residue. O-atoms are not currently added although we could arbitrarily add them at 90\n           degrees to the plane: If resiC_x + x = resjC_x and resiC_y + y = resjC_y, i + 1 = j, then the resiO atom could\n           have coordinates (resiC_x - y,  resiC_y + x).\n\n           Adds backbone atoms for insertion_residues in a straight line from start_residue to end_residue. This is useful\n           for some computational methods which do not require the atoms to be in the correct coordinates but expect N, CA, and C backbone atoms\n           to exist for all residues (O-atoms are currently ignored here).\n\n           start_residue and end_residue are Residue objects. insertion_residues is a list of PDB residue IDs (columns 22-27\n           of ATOM lines in the PDB format). insertion_residue_map is a mapping from PDB residue IDs to 1-letter amino acid\n           codes. The keys of insertion_residue_map must be insertion_residues.\n\n           start_residue and end_residue must exist in insertion_residues and the PDB file. There is no technical requirement for this;\n           we just do not handle the alternate case yet. residue_ids are presumed to be ordered in sequence (N -> C) order.\n           Existing N, CA, and C atoms corresponding to these two residues will be retained as long as their atoms which\n           connect to the side of those residues not identified by residue_ids are present e.g.\n              - if the CA atom of the first residue is present, it will be kept as long as the N atom is present and regardless of whether the C atom is present\n              - if the CA atom of the last residue is present, it will be kept as long as the C atom is present and regardless of whether the N atom is present\n           All O atoms of residues in residue_ids are discarded. ANISOU records corresponding to any removed ATOMS will be removed.\n\n                   1st    2nd          n-1      n\n             ... N-CA-C- N-CA-C- ... N-CA-C- N-CA-C- ..\n\n           Note: This function currently only supports canonical amino acids.\n        '''\n\n        assert(sorted(insertion_residues) == sorted(insertion_residue_map.keys()))\n        assert(start_residue.chain + start_residue.residue_id in insertion_residues)\n        assert(end_residue.chain + end_residue.residue_id in insertion_residues)\n        assert(start_residue.chain == end_residue.chain)\n\n        atoms_to_remove = []\n\n        discarded_atoms = []\n\n        # Remove atoms from the segment's N-terminus residue\n        # if N and CA and C, keep C else discard C\n        start_res_atoms_ids = self.get_atom_serial_numbers_from_pdb_residue_ids([insertion_residues[0]])\n        start_res_atoms = [self.atoms[id] for id in start_res_atoms_ids]\n        start_res_atom_types = [a.name for a in start_res_atoms]\n        start_atoms = [None, None, None]\n        for a in start_res_atoms:\n            if a.name == 'N': start_atoms[0] = a\n            elif a.name == 'CA': start_atoms[1] = a\n            elif a.name == 'C': start_atoms[2] = a\n            else: discarded_atoms.append(a.serial_number)\n        if 'C' in start_res_atom_types and 'CA' not in start_res_atom_types:\n            discarded_atoms += start_atoms[2].serial_number\n            start_atoms[2] = None\n        if not start_atoms[0]:\n            raise Exception('The N atom for the start residue must exist.')\n        start_atoms = [a for a in start_atoms if a]\n        start_atom = start_atoms[-1]\n\n        # Remove atoms from the segment's C-terminus residue\n        # if N and CA and C, keep N else discard N\n        end_res_atoms_ids = self.get_atom_serial_numbers_from_pdb_residue_ids([insertion_residues[-1]])\n        end_res_atoms = [self.atoms[id] for id in end_res_atoms_ids]\n        end_res_atom_types = [a.name for a in end_res_atoms]\n        end_atoms = [None, None, None]\n        for a in end_res_atoms:\n            if a.name == 'N': end_atoms[0] = a\n            elif a.name == 'CA': end_atoms[1] = a\n            elif a.name == 'C': end_atoms[2] = a\n            else: discarded_atoms.append(a.serial_number)\n        if 'N' in end_res_atom_types and 'CA' not in end_res_atom_types:\n            discarded_atoms += end_atoms[0].serial_number\n            end_atoms[0] = None\n        if not end_atoms[-1]:\n            raise Exception('The C atom for the end residue must exist.')\n        end_atoms = [a for a in end_atoms if a]\n        end_atom = end_atoms[0]\n\n        # Remove all atoms from the remainder of the segment\n        discarded_atoms += self.get_atom_serial_numbers_from_pdb_residue_ids(insertion_residues[1:-1])\n\n        # Remove the atoms from the PDB\n        bonsai_pdb_content, cutting_pdb_content, PSE_file, PSE_script = self.prune(set(discarded_atoms), generate_pymol_session = False)\n        self.__init__(bonsai_pdb_content, buffer = self.buffer, bin_size = self.bin_size, safe_mode = self.safe_mode)\n\n        # Create a list of all N, CA, C atoms for the insertion residues not including those present in the start and end residue\n        # Find last of N CA C of first residue\n        # Find last of N CA C of first residue\n        new_atoms = []\n        assert(len(start_atoms) >= 1) # N is guaranteed to exist\n        if len(start_atoms) == 2:\n            # add a C atom\n            residue_id = insertion_residues[0]\n            residue_type = insertion_residue_map[residue_id]\n            assert(residue_type != 'X' and residue_type in residue_type_1to3_map)\n            new_atoms.append((residue_id, residue_type_1to3_map[residue_type], 'C'))\n        for insertion_residue in insertion_residues[1:-1]:\n            # add an N, CA, C atoms\n            residue_type = insertion_residue_map[insertion_residue]\n            assert(residue_type != 'X' and residue_type in residue_type_1to3_map)\n            residue_type = residue_type_1to3_map[residue_type]\n            new_atoms.append((insertion_residue, residue_type, 'N'))\n            new_atoms.append((insertion_residue, residue_type, 'CA'))\n            new_atoms.append((insertion_residue, residue_type, 'C'))\n        assert(len(end_atoms) >= 1) # C is guaranteed to exist\n        if len(end_atoms) == 2:\n            # add an N atom\n            residue_id = insertion_residues[-1]\n            residue_type = insertion_residue_map[residue_id]\n            assert(residue_type != 'X' and residue_type in residue_type_1to3_map)\n            new_atoms.append((residue_id, residue_type_1to3_map[residue_type], 'N'))\n\n        return self.add_atoms_linearly(start_atom, end_atom, new_atoms)", "response": "This function returns the PDB content for a structure with the missing backbone atoms - i. e. it adds the backbone atoms for start_residue and end_residue."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_atoms_linearly(self, start_atom, end_atom, new_atoms, jitterbug = 0.2):\n        '''A low-level function which adds new_atoms between start_atom and end_atom. This function does not validate the\n           input i.e. the calling functions are responsible for ensuring that the insertion makes sense.\n\n           Returns the PDB file content with the new atoms added. These atoms are given fresh serial numbers, starting\n           from the first serial number larger than the current serial numbers i.e. the ATOM serial numbers do not now\n           necessarily increase in document order.\n\n           The jitter adds some X, Y, Z variability to the new atoms. This is important in the Rosetta software suite when\n           placing backbone atoms as colinearly placed atoms will break the dihedral angle calculations (the dihedral angle\n           over 4 colinear atoms is undefined).\n           '''\n\n        atom_name_map = {\n            'CA' : ' CA ',\n            'C' :  ' C  ',\n            'N' :  ' N  ',\n            'O' :  ' O  ',\n        }\n\n        assert(start_atom.residue.chain == end_atom.residue.chain)\n        chain_id = start_atom.residue.chain\n\n        # Initialize steps\n        num_new_atoms = float(len(new_atoms))\n        X, Y, Z = start_atom.x, start_atom.y, start_atom.z\n        x_step = (end_atom.x - X) / (num_new_atoms + 1.0)\n        y_step = (end_atom.y - Y) / (num_new_atoms + 1.0)\n        z_step = (end_atom.z - Z) / (num_new_atoms + 1.0)\n        D = math.sqrt(x_step * x_step + y_step * y_step + z_step * z_step)\n        jitter = 0\n        if jitterbug:\n            jitter = (((x_step + y_step + z_step) / 3.0) * jitterbug) / D\n\n        new_lines = []\n        next_serial_number = max(sorted(self.atoms.keys())) + 1\n        round = 0\n        for new_atom in new_atoms:\n            X, Y, Z = X + x_step, Y + y_step, Z + z_step\n            if jitter:\n                if round % 3 == 0:\n                    X, Y = X + jitter, Y - jitter\n                elif round % 3 == 1:\n                    Y, Z = Y + jitter, Z - jitter\n                elif round % 3 == 2:\n                    Z, X = Z + jitter, X - jitter\n                round += 1\n            residue_id, residue_type, atom_name = new_atom\n            assert(len(residue_type) == 3)\n            assert(len(residue_id) == 6)\n            new_lines.append('ATOM  {0} {1} {2} {3}   {4:>8.3f}{5:>8.3f}{6:>8.3f}  1.00  0.00              '.format(str(next_serial_number).rjust(5), atom_name_map[atom_name], residue_type, residue_id, X, Y, Z))\n            next_serial_number += 1\n\n        new_pdb = []\n        in_start_residue = False\n        for l in self.indexed_lines:\n            if l[0] and l[3].serial_number == start_atom.serial_number:\n                in_start_residue = True\n            if in_start_residue and l[3].serial_number != start_atom.serial_number:\n                new_pdb.extend(new_lines)\n                #colortext.warning('\\n'.join(new_lines))\n                in_start_residue = False\n            if l[0]:\n                #print(l[2])\n                new_pdb.append(l[2])\n            else:\n                #print(l[1])\n                new_pdb.append(l[1])\n\n        return '\\n'.join(new_pdb)", "response": "A low - level function which adds new_atoms between start_atom and end_atom. This function is used to add new_atoms to the PDB file content."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_string(self):\n        return '%s   %s %s %s %s' % (\n            self.trait, self.start_position, self.peak_start_position,\n            self.peak_stop_position, self.stop_position)", "response": "Return the string representation of the object as it should be presented in a MapChart\n        input file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning vector of one hot", "response": "def one_hot(cls, n, l):\n        \"\"\"\n        n: position of \"hot\"\n        l: lenght of vector\n        \"\"\"\n        v = [0.0] * l\n        v[n] = 1.0\n        return Vector(v)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfunction creates an app given an environment", "response": "def make_app(env, commandadapter=None):\n    \"\"\"\n    Function creates an app given environment\n    \"\"\"\n    mconfig = import_module('app.config.%s' % env, pass_errors=True)\n    if mconfig is None and paths.app_exists():\n        print(colored('Configuration for \"%s\" environment is not found' % env, 'red'))\n        return None\n    mstart = import_module('app.start')\n    mroutes = import_module('app.routes')\n    mcontrollers = import_module('app.controllers')\n    before = mstart.before\n\n    return Glim(commandadapter, mconfig, mroutes, mcontrollers, env, before)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates the url for the callback for this provider", "response": "def callback(self):\n        \"\"\" Generate callback url for provider \"\"\"\n        next = request.args.get('next') or None\n        endpoint = 'social.{}.handle'.format(self.provider)\n        return url_for(endpoint, _external=True, next=next)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef next(self):\n        next = request.args.get('next')\n        if next is None:\n            params = self.default_redirect_params\n            next = url_for(self.default_redirect_endpoint, **params)\n        return next", "response": "Where to redirect after authorization"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndispatch the request to the provider and returns the response.", "response": "def dispatch_request(self):\n        \"\"\" Handle redirect back from provider \"\"\"\n        if current_user.is_authenticated:\n            return redirect(self.next)\n\n        # clear previous!\n        if 'social_data' in session:\n            del session['social_data']\n\n        res = self.app.authorized_response()\n        if res is None:\n            if self.flash: flash(self.auth_failed_msg, 'danger')\n            return redirect(self.next)\n\n        # retrieve profile\n        data = self.get_profile_data(res)\n        if data is None:\n            if self.flash: flash(self.data_failed_msg, 'danger')\n            return redirect(self.next)\n\n        # attempt login\n        try:\n            ok = user_service.attempt_social_login(self.provider, data['id'])\n            if ok:\n                if self.flash:\n                    flash(self.logged_in_msg.format(self.provider), 'success')\n                return redirect(self.logged_in)\n        except x.AccountLocked as locked:\n            msg = self.lock_msg.format(locked.locked_until)\n            if self.flash: flash(msg, 'danger')\n            url = url_for(self.lock_redirect, **self.lock_redirect_params)\n            return redirect(url)\n        except x.EmailNotConfirmed:\n            return redirect(url_for(self.unconfirmed_email_endpoint))\n\n        # get data\n        email = data.get('email')\n        provider = data.get('provider')\n        id = data.get('id')\n        id_column = '{}_id'.format(provider)\n\n        # user exists: add social id to profile\n        user = user_service.first(email=email)\n        if user:\n            setattr(user, id_column, id)\n            user_service.save(user)\n\n        # no user: register\n        if not user:\n            cfg = current_app.config\n            send_welcome = cfg.get('USER_SEND_WELCOME_MESSAGE')\n            base_confirm_url = cfg.get('USER_BASE_EMAIL_CONFIRM_URL')\n            if not base_confirm_url:\n                endpoint = 'user.confirm.email.request'\n                base_confirm_url = url_for(endpoint, _external=True)\n\n            data = dict(email=email)\n            data[id_column] = id\n            user = user_service.register(\n                user_data=data,\n                send_welcome=send_welcome,\n                base_confirm_url=base_confirm_url\n            )\n\n        # email confirmed?\n        if user_service.require_confirmation and not user.email_confirmed:\n            return redirect(url_for(self.ok_endpoint, **self.ok_params))\n\n        # otherwise just login\n        user_service.force_login(user)\n        return redirect(self.force_login_redirect)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nretrieving profile data from provider", "response": "def get_profile_data(self, auth_response):\n        \"\"\" Retrieve profile data from provider \"\"\"\n        res = auth_response\n        token = res.get('access_token')\n        expires = res.get('expires_in')\n        expires = datetime.utcnow() + timedelta(seconds=int(expires))\n\n        session[self.session_key] = (token, expires)\n\n        me = oauth.facebook.get('me?fields=email,name')\n        if me.status != 200:\n            return None\n\n        me = me.data\n        email = me.get('email')\n        id = me.get('id')\n        if not id:\n            raise x.UserException('Facebook must return a user id')\n\n        data = dict(\n            provider=self.provider,\n            email=email,\n            id=id,\n            token=token,\n            expires=expires\n        )\n\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nretrieves profile data from provider", "response": "def get_profile_data(self, auth_response):\n        \"\"\" Retrieve profile data from provider \"\"\"\n        res = auth_response\n        token = res.get('access_token')\n        me = res.get('user')\n\n        if not me.get('id'):\n            raise x.UserException('Instagram must return a user id')\n\n        data = dict(\n            provider=self.provider,\n            email=None,\n            id=me.get('id'),\n            token=token,\n        )\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef project(v, n):\n    return v - matmul(v, n) * n / (norm(n) ** 2.0)", "response": "Project vector v onto plane with normal vector n."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses the command line arguments to the application.", "response": "def parse_args():\n    \"\"\"Parse the arguments to the application\"\"\"\n    parser = argparse.ArgumentParser(\n        description=HELPTEXT,\n        epilog=\"This application is powered by elks with superpowers!\")\n    parser.add_argument('--version', action='store_true',\n                        help=\"Display elkme version and exit\")\n    parser.add_argument('-v', '--verbose', action='count',\n                        help=\"Debug output\", default=0)\n    parser.add_argument('message', metavar='message', type=str, nargs='*',\n                        help=\"The message to be sent (<160 characters)\")\n    parser.add_argument('-f', '--file', metavar='file', action='store',\n                        help=\"\"\"File to read message from (only the\n                        first 160 characters are sent)\"\"\")\n    parser.add_argument('-t', '--to', dest='to', action='store',\n                        help=\"Phone number to receive the text message\")\n    parser.add_argument('-s', '--sender', '--from', dest='sender',\n                        action='store', help=\"\"\"\n                        Sender of the message. See 46elks' API documentation\n                        for valid formats\"\"\")\n    parser.add_argument('-u', '--username', dest='username', action='store',\n                        help=\"Your API username from https://www.46elks.com/\")\n    parser.add_argument('-p', '--password', dest='password', action='store',\n                        help=\"Your API password from https://www.46elks.com/\")\n    parser.add_argument('--flash', action='store_true',\n                        help=\"Send SMS as a flash-SMS\")\n    parser.add_argument('-l', '--length', metavar='length',\n            action='store', type=int, default=160,\n            help='Maximum length of the message')\n    parser.add_argument('-c', '--config', dest='configfile',\n                        help=\"\"\"Location of the custom configuration file\"\"\")\n    parser.add_argument('--saveconf', dest='saveconf',\n                        action='count', help=\"\"\"\n                        Generates a configuration file from the commandline\n                        options and exits.\"\"\")\n    parser.add_argument('--editconf', action='store_true', help=\"\"\"\n                        Opens the configuration file in your $EDITOR\"\"\")\n    return parser.parse_args()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _transform_state_to_string(self, state: State) -> str:\n        return ''.join(str(state[gene]) for gene in self.model.genes)", "response": "Private method which transform a state to a string."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef as_dot(self) -> str:\n        return nx.drawing.nx_pydot.to_pydot(self._graph).to_string()", "response": "Return the dot version of the graph."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef export_to_dot(self, filename: str = 'output') -> None:\n        with open(filename + '.dot', 'w') as output:\n            output.write(self.as_dot())", "response": "Export the current node to the dot file filename. dot."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse the input file path and runs the duration measure algorithm.", "response": "def get_duration_measures(source_file_path,\n                          output_path=None,\n                          phonemic=False,\n                          semantic=False,\n                          quiet=False,\n                          similarity_file = None,\n                          threshold = None):\n    \"\"\"Parses input arguments and runs clustering algorithm.\n\n    :param source_file_path: Required. Location of the .csv or .TextGrid file to be\n        analyzed.\n    :param output_path: Path to which to write the resultant csv file. If left None,\n        path will be set to the source_file_path.  If set to False, no file will be\n        written.\n    :param phonemic: The letter used for phonetic clustering. Note: should be False if\n        semantic clustering is being used.\n    :param semantic: The word category used for semantic clustering. Note: should be\n        False if phonetic clustering is being used.\n    :param quiet: Set to True if you want to suppress output to the screen during processing.\n    :param similarity_file (optional): When doing semantic processing, this is the path of\n        a file containing custom term similarity scores that will be used for clustering.\n        If a custom file is used, the default LSA-based clustering will not be performed.\n    :param threshold (optional): When doing semantic processing, this threshold is used\n        in conjunction with a custom similarity file. The value is used as a semantic\n        similarity cutoff in clustering. This argument is required if a custom similarity\n        file is specified.  This argument can also be used to override the built-in\n        cluster/chain thresholds.\n\n    :return data: A dictionary of measures derived by clustering the input response.\n\n    \"\"\"\n\n    #validate arguments here rather than where they're first passed in, in case this is used as a package\n    args = Args()\n    args.output_path = output_path\n    args.phonemic = phonemic\n    args.semantic = semantic\n    args.source_file_path = source_file_path\n    args.quiet = quiet\n    args.similarity_file = similarity_file\n    args.threshold = threshold\n    args = validate_arguments(args)\n\n    if args.phonemic:\n        response_category = args.phonemic\n        output_prefix = os.path.basename(args.source_file_path).split('.')[0] + \"_vfclust_phonemic_\" + args.phonemic\n    elif args.semantic:\n        response_category = args.semantic\n        output_prefix = os.path.basename(args.source_file_path).split('.')[0] + \"_vfclust_semantic_\" + args.semantic\n    else:\n        response_category = \"\"\n        output_prefix = \"\"\n\n    if args.output_path:\n        #want to output csv file\n        target_file_path = os.path.join(args.output_path, output_prefix + '.csv')\n    else:\n        #no output to system\n        target_file_path = False\n\n    engine = VFClustEngine(response_category=response_category,\n                      response_file_path=args.source_file_path,\n                      target_file_path=target_file_path,\n                      quiet = args.quiet,\n                      similarity_file = args.similarity_file,\n                      threshold = args.threshold\n    )\n\n\n    return dict(engine.measures)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef validate_arguments(args):\n\n    #check arguments\n    print\n    print \"Checking input...\",\n\n    semantic_tests = [\"animals\", \"custom\"]\n    phonemic_tests = [\"a\", \"p\", \"s\", \"f\"]\n    if args.similarity_file:\n        print\n        print \"Custom similarity file was specified...\"\n        args.semantic = \"custom\"\n\n    if args.threshold:\n        try:\n            args.threshold = float(args.threshold)\n        except ValueError:\n            raise VFClustException('Custom threshold (--threshold argument) must be a number.')\n\n\n    if not (args.source_file_path.lower().endswith('csv') or args.source_file_path.lower().endswith('textgrid')):\n        raise VFClustException('The input must be either a .TextGrid or .csv file!\\nYou provided ' + args.source_file_path.lower())\n    if not os.path.isfile(args.source_file_path):\n        raise VFClustException('The input file path you provided does not exist on your system!')\n\n    #if no output path provided, write to source file path\n    if args.output_path == None:\n        args.output_path = args.source_path\n    #if output_path is False, don't output anything\n    elif args.output_path == False:\n        pass\n    else:\n        #verify/make folders for output\n        if len(args.output_path) == 0:\n            args.output_path = os.path.abspath(os.path.dirname(args.source_file_path))\n        try:\n            if not os.path.isdir(args.output_path):\n                os.mkdir(args.output_path)\n        except:\n            print \"Error creating folder for program output. \" \\\n                  \"Make sure you have write permissions to the folder you provided. \" \\\n                  \"You can change the folder with the -o option.\" \\\n                  \"The output directory will be the same as the input directory.\"\n\n\n    #make phonemic and semantic args lower case\n    if (args.semantic): args.semantic = args.semantic.lower()\n    if (args.phonemic): args.phonemic = args.phonemic.lower()\n\n    #must choose either semantic or phonemic\n    if not (args.semantic or args.phonemic):\n        print \"DEBUG\", args.semantic, args.similarity_file\n        raise VFClustException(\n            '''You must specify at least one phonemic or semantic test to run using -p or -s, followed by the test type.\n            Alternatively, provide a custom similarity file using the --similarity-file and --threshold options.''')\n\n    #make sure semantic arguments are legit\n    if args.semantic and args.semantic not in semantic_tests:\n        raise VFClustException(\"Currently only \" + \",\".join(semantic_tests) + \" are supported for semantic testing. \" \\\n                                                       \"You provided \" + args.semantic)\n\n    if args.phonemic and args.phonemic not in phonemic_tests:\n        raise VFClustException(\"Currently only \" + \",\".join(phonemic_tests) + \" are supported for phonemic testing.  \" \\\n                                                       \"You provided \" + args.phonemic)\n\n\n    if (args.phonemic and args.semantic):\n        raise VFClustException(\"You must choose EITHER semantic OR phonemic clustering.\")\n\n    #make paths absolute\n    args.source_file_path = os.path.abspath(args.source_file_path)\n    if args.output_path:\n        args.output_path = os.path.abspath(args.output_path)\n\n    #using custom similarity file\n    if args.similarity_file: #if it's not None\n        if not os.path.isfile(args.similarity_file):\n            raise VFClustException('The custom similarity file path you provided does not exist on your system!')\n        if not args.threshold:\n            raise VFClustException('You must specify a clustering threshold when using a custom similarity file. Use --threshold X, where X is the threshold number.')\n        try:\n            args.threshold = float(args.threshold)\n        except:\n            raise VFClustException('Error reading the custom threshold you provided. It must be a number, e.g. --threshold 6.7 or --threshold 10')\n        args.similarity_file = os.path.abspath(args.similarity_file)\n\n    print \"OK!\"\n    print\n    print \"Parsed arguments:\"\n    print_table([(k, str(vars(args)[k])) for k in vars(args)])\n\n    return args", "response": "Makes sure arguments are valid."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a ParsedResponse object from a list of words and tokens in a. csv file.", "response": "def create_from_csv(self,token_list):\n        \"\"\" Fills the ParsedResponse object with a list of words/tokens originally from a .csv file.\n\n        :param list token_list: List of strings corresponding to words in the subject response.\n\n        Modifies:\n            - self.timing_included: csv files do not include timing information\n            - self.unit_list: fills it with Unit objects derived from the token_list argument.\n                If the type is 'SEMANTIC', the words in these units are automatically lemmatized and\n                made into compound words where appropriate.\n        \"\"\"\n        self.timing_included = False\n        for entry in token_list:\n            self.unit_list.append(Unit(entry, format = \"csv\", type = self.type))\n\n        # combine compound words, remove pluralizations, etc\n        if self.type == \"SEMANTIC\":\n            self.lemmatize()\n            self.tokenize()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a ParsedResponse object from a list of TextGrid. Word objects generated from the words in the subject response.", "response": "def create_from_textgrid(self,word_list):\n        \"\"\" Fills the ParsedResponse object with a list of TextGrid.Word objects originally from a .TextGrid file.\n\n        :param list word_list: List of TextGrid.Word objects corresponding to words/tokens in the subject response.\n\n        Modifies:\n            - self.timing_included: TextGrid files include timing information\n            - self.unit_list: fills it with Unit objects derived from the word_list argument.\n                If the type is 'SEMANTIC', the words in these units are automatically lemmatized and\n                made into compound words where appropriate.\n        \"\"\"\n        self.timing_included = True\n        for i, entry in enumerate(word_list):\n            self.unit_list.append(Unit(entry, format=\"TextGrid\",\n                                       type=self.type,\n                                       index_in_timed_response=i))\n\n        # combine compound words, remove pluralizations, etc\n        if self.type == \"SEMANTIC\":\n            self.lemmatize()\n            self.tokenize()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef lemmatize(self):\n        for unit in self.unit_list:\n            if lemmatizer.lemmatize(unit.text) in self.lemmas:\n                    unit.text = lemmatizer.lemmatize(unit.text)", "response": "Lemmatize all Units in self. unit_list."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncombine two Units in self. unit_list to make a compound word token.", "response": "def make_compound_word(self, start_index, how_many):\n        \"\"\"Combines two Units in self.unit_list to make a compound word token.\n\n        :param int start_index: Index of first Unit in self.unit_list to be combined\n        :param int how_many: Index of how many Units in self.unit_list to be combined.\n\n        Modifies:\n                - self.unit_list: Modifies the Unit corresponding to the first word\n                    in the compound word. Changes the .text property to include .text\n                    properties from subsequent Units, separted by underscores. Modifies\n                    the .original_text property to record each componentword separately.\n                    Modifies the .end_time property to be the .end_time of the final unit\n                    in the compound word.  Finally, after extracting the text and timing\n                    information, it removes all units in the compound word except for the\n                    first.\n\n        .. note: This method is only used with semantic processing, so we don't need to worry\n            about the phonetic representation of Units.\n\n        \"\"\"\n        if not self.quiet:\n            compound_word = \"\"\n            for word in self.unit_list[start_index:start_index + how_many]:\n                compound_word += \" \" + word.text\n            print compound_word.strip(), \"-->\",\"_\".join(compound_word.split())\n\n        #combine text\n        for other_unit in range(1, how_many):\n            self.unit_list[start_index].original_text.append(self.unit_list[start_index + other_unit].text)\n            self.unit_list[start_index].text += \"_\" + self.unit_list[start_index + other_unit].text\n\n        #start time is the same. End time is the end time of the LAST word\n        self.unit_list[start_index].end_time = self.unit_list[start_index + how_many - 1].end_time\n\n        #shorten unit_list\n        self.unit_list = self.unit_list[:start_index + 1] + self.unit_list[start_index + how_many:]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef remove_unit(self, index):\n        '''Removes the unit at the given index in self.unit_list. Does not modify any other units.'''\n        if not self.quiet:\n            print \"Removing\", self.unit_list[index].text\n        self.unit_list.pop(index)", "response": "Removes the unit at the given index in self. unit_list. Does not modify any other units."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncombine adjacent words with the same stem into a single unit.", "response": "def combine_same_stem_units(self, index):\n        \"\"\"Combines adjacent words with the same stem into a single unit.\n\n        :param int index: Index of Unit in self.unit_list to be combined with the\n            subsequent Unit.\n\n        Modifies:\n                - self.unit_list: Modifies the .original_text property of the Unit\n                    corresponding to the index.  Changes the .end_time property to be the\n                    .end_time of the next Unit, as Units with the same stem are considered\n                     as single Unit inc lustering. Finally, after extracting the text and timing\n                    information, it removes the unit at index+1.\n\n        \"\"\"\n\n        if not self.quiet:\n            combined_word = \"\"\n            for word in self.unit_list[index:index + 2]:\n                for original_word in word.original_text:\n                    combined_word += \" \" + original_word\n            print combined_word.strip(), \"-->\",\"/\".join(combined_word.split())\n\n        # edit word list to reflect what words are represented by this unit\n        self.unit_list[index].original_text.append(self.unit_list[index + 1].text)\n\n        #start time is the same. End time is the end time of the LAST word\n        self.unit_list[index].end_time = self.unit_list[index + 1].end_time\n\n        # remove word with duplicate stem\n        self.unit_list.pop(index + 1)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef display(self):\n\n        table_list = []\n        table_list.append((\"Text\",\"Orig. Text\",\"Start time\",\"End time\", \"Phonetic\"))\n        for unit in self.unit_list:\n            table_list.append((unit.text,\n                               \"/\".join(unit.original_text),\n                               unit.start_time,\n                               unit.end_time,\n                               unit.phonetic_representation))\n        print_table(table_list)", "response": "Pretty - prints the ParsedResponse to the screen."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating a phonetic representation for a word.", "response": "def generate_phonetic_representation(self, word):\n        \"\"\"\n        Returns a generated phonetic representation for a word.\n\n        :param str word: a word to be phoneticized.\n        :return: A list of phonemes representing the phoneticized word.\n\n        This method is used for words for which there is no pronunication\n        entry in the CMU dictionary. The function generates a\n        pronunication for the word in the standard CMU format. This can then\n        be converted to a compact phonetic representation using\n        modify_phonetic_representation().\n\n        \"\"\"\n        with NamedTemporaryFile() as temp_file:\n            # Write the word to a temp file\n            temp_file.write(word)\n            #todo - clean up this messy t2p path\n            t2pargs = [os.path.abspath(os.path.join(os.path.dirname(__file__),'t2p/t2p')),\n                       '-transcribe', os.path.join(data_path, 'cmudict.0.7a.tree'),\n                       temp_file.name]\n            temp_file.seek(0)\n            output, error = subprocess.Popen(\n                t2pargs, stdout=subprocess.PIPE,\n                stderr=subprocess.PIPE\n            ).communicate()\n            output = output.split()\n            phonetic_representation = output[1:]\n\n        return phonetic_representation"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a compact phonetic representation given a CMUdict - formatted representation.", "response": "def modify_phonetic_representation(self, phonetic_representation):\n        \"\"\" Returns a compact phonetic representation given a CMUdict-formatted representation.\n\n        :param list phonetic_representation: a phonetic representation in standard\n            CMUdict formatting, i.e. a list of phonemes like ['HH', 'EH0', 'L', 'OW1']\n        :returns: A string representing a custom phonetic representation, where each phoneme is\n            mapped to a single ascii character.\n\n        Changing the phonetic representation from a list to a string is useful for calculating phonetic\n        simlarity scores.\n        \"\"\"\n\n        for i in range(len(phonetic_representation)):\n            # Remove numerical stress indicators\n            phonetic_representation[i] = re.sub('\\d+', '', phonetic_representation[i])\n\n        multis = ['AA', 'AE', 'AH', 'AO', 'AW', 'AY', 'CH', 'DH', 'EH', 'ER',\n                  'EY', 'HH', 'IH', 'IY', 'JH', 'NG', 'OW', 'OY', 'SH',\n                  'TH', 'UH', 'UW', 'ZH']\n\n        singles = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',\n                   'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w']\n\n        for i in range(len(phonetic_representation)):\n            # Convert multicharacter phone symbols to arbitrary\n            # single-character symbols\n            if phonetic_representation[i] in multis:\n                phonetic_representation[i] = singles[multis.index(phonetic_representation[i])]\n        phonetic_representation = ''.join(phonetic_representation)\n\n        return phonetic_representation"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove any Units that are not applicable given the current semantic or phonetic category. Modifies: - self.unit_list: Removes Units from this list that do not fit into the clustering category. it does by by either combining units to make compound words, combining units with the same stem, or eliminating units altogether if they do not conform to the category. If the type is phonetic, this method also generates phonetic clusters for all Unit objects in self.unit_list. This method performs three main tasks: 1. Removes words that do not conform to the clustering category (i.e. start with the wrong letter, or are not an animal). 2. Combine adjacent words with the same stem into a single unit. The NLTK Porter Stemmer is used for determining whether stems are the same. http://www.nltk.org/_modules/nltk/stem/porter.html 3. In the case of PHONETIC clustering, compute the phonetic representation of each unit.", "response": "def clean(self):\n        \"\"\" Removes any Units that are not applicable given the current semantic or phonetic category.\n\n        Modifies:\n            - self.unit_list: Removes Units from this list that do not fit into the clustering category.\n                it does by by either combining units to make compound words, combining units with the\n                same stem, or eliminating units altogether if they do not conform to the category.\n                 If the type is phonetic, this method also generates phonetic clusters for all Unit\n                 objects in self.unit_list.\n\n\n        This method performs three main tasks:\n            1. Removes words that do not conform to the clustering category (i.e. start with the\n                wrong letter, or are not an animal).\n            2. Combine adjacent words with the same stem into a single unit. The NLTK Porter Stemmer\n                is used for determining whether stems are the same.\n                http://www.nltk.org/_modules/nltk/stem/porter.html\n            3. In the case of PHONETIC clustering, compute the phonetic representation of each unit.\n\n        \"\"\"\n\n        if not self.quiet:\n            print\n            print \"Preprocessing input...\"\n            print \"Raw response:\"\n            print self.display()\n\n        if not self.quiet:\n            print\n            print \"Cleaning words...\"\n\n        #weed out words not starting with the right letter or in the right category\n        current_index = 0\n        while current_index < len(self.unit_list):\n            word = self.unit_list[current_index].text\n            if self.type == \"PHONETIC\":\n                test = (word.startswith(self.letter_or_category) and  #starts with required letter\n                        not word.endswith('-') and  # Weed out word fragments\n                            '_' not in word and # Weed out, e.g., 'filledpause_um'\n                        word.lower() in self.english_words) #make sure the word is english\n            elif self.type == \"SEMANTIC\":\n                test = word in self.permissible_words\n            if not test: #if test fails remove word\n                self.remove_unit(index = current_index)\n            else: # otherwise just increment, but check to see if you're at the end of the list\n                current_index += 1\n\n        #combine words with the same stem\n        current_index = 0\n        finished = False\n        while current_index < len(self.unit_list) - 1:\n            #don't combine for lists of length 0, 1\n            if stemmer.stem(self.unit_list[current_index].text) == \\\n                stemmer.stem(self.unit_list[current_index + 1].text):\n                #if same stem as next, merge next unit with current unit\n                self.combine_same_stem_units(index = current_index)\n            else: # if not same stem, increment index\n                current_index += 1\n\n        #get phonetic representations\n        if self.type == \"PHONETIC\":\n            for unit in self.unit_list:\n                word = unit.text\n\n                #get phonetic representation\n                if word in self.cmudict:\n                    # If word in CMUdict, get its phonetic representation\n                    phonetic_representation = self.cmudict[word]\n                if word not in self.cmudict:\n                    # Else, generate a phonetic representation for it\n                    phonetic_representation = self.generate_phonetic_representation(word)\n                    phonetic_representation = self.modify_phonetic_representation(phonetic_representation)\n\n                unit.phonetic_representation = phonetic_representation\n\n        if not self.quiet:\n            print\n            print \"Cleaned response:\"\n            print self.display()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads a dictionary that maps permissible words to their LSA term vectors.", "response": "def load_lsa_information(self):\n        \"\"\"Loads a dictionary from disk that maps permissible words to their LSA term vectors.\"\"\"\n\n        if not (49 < int(self.clustering_parameter) < 101):\n            raise Exception('Only LSA dimensionalities in the range 50-100' +\n                            ' are supported.')\n        if not self.quiet:\n            print \"Loading LSA term vectors...\"\n        #the protocol2 used the pickle highest protocol and this one is a smaller file\n        with open(os.path.join(data_path, self.category + '_' +\n                os.path.join('term_vector_dictionaries',\n                             'term_vectors_dict' +\n                                     str(self.clustering_parameter) + '_cpickle.dat')),\n                  'rb') as infile:\n            self.term_vectors = pickle.load(infile)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_similarity_measures(self):\n        if not self.quiet:\n            print\n            print \"Computing\", self.current_similarity_measure, \"similarity...\"\n\n        self.compute_similarity_scores()", "response": "Helper function for computing similarity measures."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_raw_counts(self):\n\n        #for making the table at the end\n        words = []\n        labels = []\n        words_said = set()\n\n        # Words like \"polar_bear\" as one semantically but two phonetically\n        # Uncategorizable words are counted as asides\n        for unit in self.parsed_response:\n            word = unit.text\n            test = False\n            if self.type == \"PHONETIC\":\n                test = (word.startswith(self.letter) and\n                        \"T_\" not in word and \"E_\" not in word and \"!\" not in word and # Weed out tags\n                        \"FILLEDPAUSE_\" not in word and # Weed out filled pauses\n                        not word.endswith('-') and # Weed out false starts\n                        word.lower() in self.english_words)  #weed out non-words\n            elif self.type == \"SEMANTIC\":\n                #automatically weed out all non-semantically-appropriate responses\n                test = (word in self.permissible_words)\n\n            if test:\n                self.measures['COUNT_total_words'] += 1\n                self.measures['COUNT_permissible_words'] += 1\n                if any(word == w for w in words_said):\n                    self.measures['COUNT_exact_repetitions'] += 1\n                    labels.append('EXACT REPETITION')\n                elif any(stemmer.stem(word) == stemmer.stem(w) for w in words_said):\n                    self.measures['COUNT_stem_repetitions'] += 1\n                    labels.append('STEM REPETITION')\n                else:\n                    labels.append('PERMISSIBLE WORD')\n                words_said.add(word)\n                words.append(word)\n            elif word.lower().startswith('e_'):\n                self.measures['COUNT_examiner_words'] += 1\n                words.append(word)\n                labels.append('EXAMINER WORD')\n            elif word.endswith('-'):\n                self.measures['COUNT_word_fragments'] += 1\n                words.append(word)\n                labels.append('WORD FRAGMENT')\n            elif word.lower().startswith('filledpause'):\n                self.measures['COUNT_filled_pauses'] += 1\n                words.append(word)\n                labels.append('FILLED PAUSE')\n            elif word.lower() not in ['!sil', 't_noise', 't_cough', 't_lipsmack', 't_breath']:\n                self.measures['COUNT_total_words'] += 1\n                self.measures['COUNT_asides'] += 1\n                words.append(word)\n                labels.append('ASIDE')\n\n        if not self.quiet:\n            print\n            print \"Labels:\"\n            print_table([(word,label) for word,label in zip(words,labels)])\n\n        self.measures['COUNT_unique_permissible_words'] = \\\n            self.measures['COUNT_permissible_words'] - \\\n            self.measures['COUNT_exact_repetitions'] - \\\n            self.measures['COUNT_stem_repetitions']\n\n        if not self.quiet:\n            print\n            print \"Counts:\"\n            collection_measures = [x for x in self.measures if x.startswith(\"COUNT_\")]\n            collection_measures.sort()\n            if not self.quiet:\n                print_table([(k, str(self.measures[k])) for k in collection_measures])", "response": "Determines the counts for unique words that are spoken by the subject and the subject that are not part of the test criteria."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the similarity score between two words. The type of similarity scoring method used depends on the currently active method and clustering type. :param unit1: Unit object corresponding to the first word. :type unit1: Unit :param unit2: Unit object corresponding to the second word. :type unit2: Unit :return: Number indicating degree of similarity of the two input words. The maximum value is 1, and a higher value indicates that the words are more similar. :rtype : Float The similarity method used depends both on the type of test being performed (SEMANTIC or PHONETIC) and the similarity method currently assigned to the self.current_similarity_measure property of the VFClustEngine object. The similarity measures used are the following: - PHONETIC/\"phone\": the phonetic similarity score (PSS) is calculated between the phonetic representations of the input units. It is equal to 1 minus the Levenshtein distance between two strings, normalized to the length of the longer string. The strings should be compact phonetic representations of the two words. (This method is a modification of a Levenshtein distance function available at http://hetland.org/coding/python/levenshtein.py.) - PHONETIC/\"biphone\": the binary common-biphone score (CBS) depends on whether two words share their initial and/or final biphone (i.e., set of two phonemes). A score of 1 indicates that two words have the same intial and/or final biphone; a score of 0 indicates that two words have neither the same initial nor final biphone. This is also calculated using the phonetic representation of the two words. - SEMANTIC/\"lsa\": a semantic relatedness score (SRS) is calculated as the COSINE of the respective term vectors for the first and second word in an LSA space of the specified clustering_parameter. Unlike the PHONETIC methods, this method uses the .text property of the input Unit objects.", "response": "def compute_similarity_score(self, unit1, unit2):\n        \"\"\" Returns the similarity score between two words.\n\n         The type of similarity scoring method used depends on the currently active\n         method and clustering type.\n\n        :param unit1: Unit object corresponding to the first word.\n        :type unit1: Unit\n        :param unit2: Unit object corresponding to the second word.\n        :type unit2: Unit\n        :return: Number indicating degree of similarity of the two input words.\n            The maximum value is 1, and a higher value indicates that the words\n            are more similar.\n        :rtype : Float\n\n        The similarity method used depends both on the type of test being performed\n        (SEMANTIC or PHONETIC) and the similarity method currently assigned to the\n        self.current_similarity_measure property of the VFClustEngine object.  The\n        similarity measures used are the following:\n            - PHONETIC/\"phone\": the phonetic similarity score (PSS) is calculated\n                between the phonetic representations of the input units. It is equal\n                to 1 minus the Levenshtein distance between two strings, normalized\n                to the length of the longer string. The strings should be compact\n                phonetic representations of the two words.\n                (This method is a modification of a Levenshtein distance function\n                available at http://hetland.org/coding/python/levenshtein.py.)\n            - PHONETIC/\"biphone\": the binary common-biphone score (CBS) depends\n                on whether two words share their initial and/or final biphone\n                (i.e., set of two phonemes). A score of 1 indicates that two words\n                have the same intial and/or final biphone; a score of 0 indicates\n                that two words have neither the same initial nor final biphone.\n                This is also calculated using the phonetic representation of the\n                two words.\n            - SEMANTIC/\"lsa\": a semantic relatedness score (SRS) is calculated\n                as the COSINE of the respective term vectors for the first and\n                second word in an LSA space of the specified clustering_parameter.\n                Unlike the PHONETIC methods, this method uses the .text property\n                of the input Unit objects.\n\n        \"\"\"\n\n        if self.type == \"PHONETIC\":\n            word1 = unit1.phonetic_representation\n            word2 = unit2.phonetic_representation\n            if self.current_similarity_measure == \"phone\":\n                word1_length, word2_length = len(word1), len(word2)\n                if word1_length > word2_length:\n                    # Make sure n <= m, to use O(min(n,m)) space\n                    word1, word2 = word2, word1\n                    word1_length, word2_length = word2_length, word1_length\n                current = range(word1_length + 1)\n                for i in range(1, word2_length + 1):\n                    previous, current = current, [i] + [0] * word1_length\n                    for j in range(1, word1_length + 1):\n                        add, delete = previous[j] + 1, current[j - 1] + 1\n                        change = previous[j - 1]\n                        if word1[j - 1] != word2[i - 1]:\n                            change += 1\n                        current[j] = min(add, delete, change)\n                phonetic_similarity_score = 1 - current[word1_length] / word2_length\n                return phonetic_similarity_score\n\n            elif self.current_similarity_measure == \"biphone\":\n                if word1[:2] == word2[:2] or word1[-2:] == word2[-2:]:\n                    common_biphone_score = 1\n                else:\n                    common_biphone_score = 0\n                return common_biphone_score\n\n        elif self.type == \"SEMANTIC\":\n            word1 = unit1.text\n            word2 = unit2.text\n            if self.current_similarity_measure == \"lsa\":\n                w1_vec = self.term_vectors[word1]\n                w2_vec = self.term_vectors[word2]\n                # semantic_relatedness_score = (numpy.dot(w1_vec, w2_vec) /\n                #                               numpy.linalg.norm(w1_vec) /\n                #                               numpy.linalg.norm(w2_vec))\n                dot = sum([w1*w2 for w1,w2 in zip(w1_vec, w2_vec)])\n                norm1 = sqrt(sum([w*w for w in w1_vec]))\n                norm2 = sqrt(sum([w*w for w in w2_vec]))\n                semantic_relatedness_score =  dot/(norm1 * norm2)\n                return semantic_relatedness_score\n            elif self.current_similarity_measure == \"custom\":\n                #look it up in dict\n                try:\n                    similarity = self.custom_similarity_scores[(word1,word2)]\n                except KeyError:\n                    try:\n                        similarity = self.custom_similarity_scores[(word2,word1)]\n                    except KeyError:\n                        if word1 == word2:\n                            return self.same_word_similarity\n                            #if they're the same word, they pass.  This should only happen when checking with\n                            # non-adjacent words in the same cluster\n                        else:\n                            return 0 #if words aren't found, they are defined as dissimilar\n                return similarity\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef compute_similarity_scores(self):\n\n        for i,unit in enumerate(self.parsed_response):\n            if i < len(self.parsed_response) - 1:\n                next_unit = self.parsed_response[i + 1]\n                self.similarity_scores.append(self.compute_similarity_score(unit, next_unit))\n\n        if not self.quiet:\n            print self.current_similarity_measure, \"similarity scores (adjacent) -- higher is closer:\"\n            table = [(\"Word 1\", \"Word 2\", \"Score\")] + \\\n                    [(self.parsed_response[i].text, self.parsed_response[i + 1].text,\n                      \"{0:.3f}\".format(round(self.similarity_scores[i], 2)))\n                     for i in range(len(self.parsed_response)-1)]\n            print_table(table)", "response": "Compute the similarity scores between adjacent words and each other."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef compute_collections(self):\n        if self.custom_threshold:\n            self.similarity_threshold = self.custom_threshold\n        elif self.type == \"PHONETIC\":\n            if self.current_similarity_measure == \"phone\":\n                phonetic_similarity_thresholds = {'a': 0.222222222222,\n                                                  'b': 0.3,\n                                                  'c': 0.2857142857134,\n                                                  'd': 0.3,\n                                                  'e': 0.25,\n                                                  'f': 0.333333333333,\n                                                  'g': 0.2857142857142857,\n                                                  'h': 0.333333333333,\n                                                  'i': 0.3,\n                                                  'j': 0.3,\n                                                  'k': 0.3,\n                                                  'l': 0.333333333333,\n                                                  'm': 0.333333333333,\n                                                  'n': 0.2857142857142857,\n                                                  'o': 0.222222222222,\n                                                  'p': 0.2857142857134,\n                                                  'q': 0.4285714285714286,\n                                                  'r': 0.3,\n                                                  's': 0.2857142857134,\n                                                  't': 0.2857142857134,\n                                                  'u': 0.3076923076923077,\n                                                  'v': 0.333333333333,\n                                                  'w': 0.333333333333,\n                                                  'x': 0.2857142857134,\n                                                  'y': 0.333333333333,\n                                                  'z': 0.333333333333}\n                self.similarity_threshold = phonetic_similarity_thresholds[self.letter]\n            elif self.current_similarity_measure == \"biphone\":\n                self.similarity_threshold = 1\n\n        elif self.type == \"SEMANTIC\":\n            if self.current_similarity_measure == \"lsa\":\n                if self.category == 'animals':\n                    thresholds = {'50': 0.229306542684, '51': 0.22594687203200001,\n                                  '52': 0.22403235205800001, '53': 0.214750475853,\n                                  '54': 0.210178113675, '55': 0.209214667474,\n                                  '56': 0.204037629443, '57': 0.203801260742,\n                                  '58': 0.203261303516, '59': 0.20351336452999999,\n                                  '60': 0.19834361415999999, '61': 0.19752806852999999,\n                                  '62': 0.191322450624, '63': 0.194312302459,\n                                  '64': 0.188165419858, '65': 0.18464545450299999,\n                                  '66': 0.18478136731399999, '67': 0.178950849271,\n                                  '68': 0.17744175606199999, '69': 0.17639888996299999,\n                                  '70': 0.17537403274400001, '71': 0.17235091169799999,\n                                  '72': 0.17115875396499999, '73': 0.17262141635100001,\n                                  '74': 0.16580303697500001, '75': 0.16416843492800001,\n                                  '76': 0.166395146381, '77': 0.162961462955,\n                                  '78': 0.161888890545, '79': 0.160416925579,\n                                  '80': 0.157132807023, '81': 0.15965395155699999,\n                                  '82': 0.155974588379, '83': 0.15606832182700001,\n                                  '84': 0.14992240019899999, '85': 0.15186462595399999,\n                                  '86': 0.14976638614599999, '87': 0.14942388535199999,\n                                  '88': 0.14740916274999999, '89': 0.14821336952600001,\n                                  '90': 0.14188941422699999, '91': 0.14039515298300001,\n                                  '92': 0.14125100827199999, '93': 0.140135804694,\n                                  '94': 0.13933483465099999, '95': 0.139679588617,\n                                  '96': 0.13569859464199999, '97': 0.135394351192,\n                                  '98': 0.13619473881800001, '99': 0.136671316751,\n                                  '100': 0.135307208304}\n\n                    self.similarity_threshold = thresholds[str(self.clustering_parameter)]\n            elif self.current_similarity_measure == \"custom\":\n                self.similarity_threshold = self.custom_threshold\n\n        if not self.quiet:\n            print \"Similarity threshold:\", self.similarity_threshold\n\n        for index, unit in enumerate(self.parsed_response):\n            next_word_index = index + 1\n            collection = [unit] # begin current collection\n            collection_index = [index] # begin current collection index list\n            collection_terminus_found = False\n            while not collection_terminus_found:\n                if next_word_index < len(self.parsed_response):\n                    # Check whether last word in attempt has been read\n                    test = False\n                    if self.current_collection_type == \"cluster\":\n                        # Check whether next word is related to\n                        # every other word in cluster\n                        unit2 = self.parsed_response[next_word_index]\n                        test = all([self.compute_similarity_score(unit2, other_unit) >= self.similarity_threshold \\\n                                for other_unit in collection])\n                    elif self.current_collection_type == \"chain\":\n                        #check whether the word is related to the one before it\n                        #remember that we're testing words at the end of the chain, and creating new links\n                        unit1 = self.parsed_response[next_word_index - 1]\n                        unit2 = self.parsed_response[next_word_index]\n                        test = self.compute_similarity_score(unit1,unit2) >= self.similarity_threshold\n                    if test:\n                        #add NEXT word\n                        collection.append(self.parsed_response[next_word_index])\n                        collection_index.append(next_word_index)\n                        next_word_index += 1\n                    else:\n\n                        # Check whether cluster is subsequence of cluster\n                        # already added to list\n                        collection_index = ' '.join([str(w) for w in collection_index])\n                        if collection_index not in str(self.collection_indices):\n                            self.collection_indices.append(collection_index)\n                            self.collection_sizes.append(len(collection))\n                        collection_terminus_found = True\n                else:\n                    # Execute if word is last word in attempt\n                    collection_index = ' '.join([str(w) for w in collection_index])\n                    if collection_index not in str(self.collection_indices):\n                        self.collection_indices.append(collection_index)\n                        self.collection_sizes.append(len(collection))\n                    collection_terminus_found = True\n\n        # Get a list of collections and their positions in the response.\n        for index in self.collection_indices:\n            collection = []\n            for i in index.split():\n                collection.append(self.parsed_response[int(i)])\n            self.collection_list.append(collection)", "response": "Computes the collections for the current entry in the resource."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomputing the average pairwise similarity score between all pairs of Units.", "response": "def compute_pairwise_similarity_score(self):\n        \"\"\"Computes the average pairwise similarity score between all pairs of Units.\n\n        The pairwise similarity is calculated as the sum of similarity scores for all pairwise\n        word pairs in a response -- except any pair composed of a word and\n        itself -- divided by the total number of words in an attempt. I.e.,\n        the mean similarity for all pairwise word pairs.\n\n        Adds the following measures to the self.measures dictionary:\n            - COLLECTION_collection_pairwise_similarity_score_mean: mean of pairwise similarity scores\n\n        .. todo: divide by (count-1)?\n        \"\"\"\n        pairs = []\n        all_scores = []\n        for i, unit in enumerate(self.parsed_response):\n            for j, other_unit in enumerate(self.parsed_response):\n                if i != j:\n                    pair = (i, j)\n                    rev_pair = (j, i)\n                    if pair not in pairs and rev_pair not in pairs:\n                        score = self.compute_similarity_score(unit, other_unit)\n                        pairs.append(pair)\n                        pairs.append(rev_pair)\n                        all_scores.append(score)\n\n        #remove any \"same word\" from the mean\n        all_scores = [i for i in all_scores if i != self.same_word_similarity]\n        self.measures[\"COLLECTION_\" + self.current_similarity_measure + \"_pairwise_similarity_score_mean\"] = get_mean(\n            all_scores) \\\n            if len(pairs) > 0 else 'NA'"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef compute_collection_measures(self, no_singletons=False):\n\n        prefix = \"COLLECTION_\" + self.current_similarity_measure + \"_\" + self.current_collection_type + \"_\"\n\n        if no_singletons:\n            prefix += \"no_singletons_\"\n\n        if no_singletons:\n            collection_sizes_temp = [x for x in self.collection_sizes if x != 1]\n        else: #include singletons\n            collection_sizes_temp = self.collection_sizes\n\n        self.measures[prefix + 'count'] = len(collection_sizes_temp)\n\n        self.measures[prefix + 'size_mean'] = get_mean(collection_sizes_temp) \\\n            if self.measures[prefix + 'count'] > 0 else 0\n\n        self.measures[prefix + 'size_max'] = max(collection_sizes_temp) \\\n            if len(collection_sizes_temp) > 0 else 0\n\n        self.measures[prefix + 'switch_count'] = self.measures[prefix + 'count'] - 1", "response": "Computes the summary of the measures for the current cluster and stores them in the self. measures dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef compute_response_vowel_duration(self, prefix):\n        durations = []\n        for word in self.full_timed_response:\n            if word.phones:\n                for phone in word.phones:\n                    if phone.string in self.vowels:\n                        durations.append(phone.end - phone.start)\n\n        self.measures[prefix + 'response_vowel_duration_mean'] = get_mean(durations) \\\n            if len(durations) > 0 else 'NA'\n\n        if not self.quiet:\n            print \"Mean response vowel duration:\", self.measures[prefix + 'response_vowel_duration_mean']", "response": "Computes the mean vowel duration in all vowels in the response."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef compute_between_collection_interval_duration(self, prefix):\n\n        durations = []  # duration of each collection\n        for collection in self.collection_list:\n            # Entry, with timing, in timed_response for first word in collection\n            start = collection[0].start_time\n            # Entry, with timing, in timed_response for last word in collection\n            end = collection[-1].end_time\n            durations.append((start, end))\n\n        # calculation between-duration intervals\n        interstices = [durations[i + 1][0] - durations[i][1] for i, d in enumerate(durations[:-1])]\n\n        # Replace negative interstices (for overlapping clusters) with\n        # interstices of duration 0\n        for i, entry in enumerate(interstices):\n            if interstices[i] < 0:\n                interstices[i] = 0\n\n        self.measures[prefix + 'between_collection_interval_duration_mean'] = get_mean(interstices) \\\n            if len(interstices) > 0 else 'NA'\n\n        if not self.quiet:\n            print\n            print self.current_similarity_measure + \" between-\" + self.current_collection_type + \" durations\"\n            table = [(self.current_collection_type + \" 1 (start,end)\", \"Interval\",\n                      self.current_collection_type + \" 2 (start,end)\")] + \\\n                    [(str(d1), str(i1), str(d2)) for d1, i1, d2 in zip(durations[:-1], interstices, durations[1:])]\n            print_table(table)\n            print\n            print \"Mean \" + self.current_similarity_measure + \" between-\" + self.current_collection_type + \" duration\", \\\n                self.measures[prefix + 'between_collection_interval_duration_mean']", "response": "Calculates the duration of each interval between the current collection and measure type\n            and takes their mean."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef compute_within_collection_interval_duration(self, prefix):\n\n        interstices = []\n        for cluster in self.collection_list:\n            # Make sure cluster is not a singleton\n            if len(cluster) > 1:\n                for i in range(len(cluster)):\n                    if i != len(cluster) - 1:\n                        interstice = cluster[i+1].start_time - cluster[i].end_time\n                        interstices.append(interstice)\n\n        self.measures[prefix + 'within_collection_interval_duration_mean'] = get_mean(interstices) \\\n            if len(interstices) > 0 else 'NA'\n\n        if not self.quiet:\n            print \"Mean within-\" + self.current_similarity_measure + \"-\" + self.current_collection_type + \\\n                  \" between-word duration:\", self.measures[prefix + 'within_collection_interval_duration_mean']", "response": "Calculates the mean between - word duration WITHIN collections."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomputing the mean duration of vowels from Units within clusters.", "response": "def compute_within_collection_vowel_duration(self, prefix, no_singletons=False):\n        \"\"\" Computes the mean duration of vowels from Units within clusters.\n\n        :param str prefix: Prefix for the key entry in self.measures\n        :param bool no_singletons: If False, excludes collections of length 1 from calculations\n            and adds \"no_singletons\" to the prefix\n\n        Adds the following measures to the self.measures dictionary:\n            - TIMING_(similarity_measure)_(collection_type)_within_collection_vowel_duration_mean\n        \"\"\"\n\n        if no_singletons:\n            min_size = 2\n        else:\n            prefix += \"no_singletons_\"\n            min_size = 1\n\n        durations = []\n        for cluster in self.collection_list:\n            if len(cluster) >= min_size:\n                for word in cluster:\n                    word = self.full_timed_response[word.index_in_timed_response]\n                    for phone in word.phones:\n                        if phone.string in self.vowels:\n                            durations.append(phone.end - phone.start)\n\n        self.measures[prefix + 'within_collection_vowel_duration_mean'] = get_mean(durations) \\\n            if len(durations) > 0 else 'NA'\n\n        if not self.quiet:\n            if no_singletons:\n                print \"Mean within-\" + self.current_similarity_measure + \"-\" + self.current_collection_type + \\\n                      \" vowel duration, excluding singletons:\", \\\n                    self.measures[prefix + 'within_collection_vowel_duration_mean']\n            else:\n                print \"Mean within-\" + self.current_similarity_measure + \"-\" + self.current_collection_type + \\\n                      \" vowel duration, including singletons:\", \\\n                    self.measures[prefix + 'within_collection_vowel_duration_mean']"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nprinting final list of measures to screen a. csv file.", "response": "def print_output(self):\n        \"\"\" Outputs final list of measures to screen a csv file.\n\n        The .csv file created has the same name as the input file, with\n        \"vfclust_TYPE_CATEGORY\" appended to the filename, where TYPE indicates\n        the type of task performed done (SEMANTIC or PHONETIC) and CATEGORY\n        indicates the category requirement of the stimulus (i.e. 'f' or 'animals'\n        for phonetic and semantic fluency test, respectively.\n        \"\"\"\n        if self.response_format == \"csv\":\n            for key in self.measures:\n                if \"TIMING_\" in key:\n                    self.measures[key] = \"NA\"\n\n        if not self.quiet:\n            print\n            print self.type.upper() + \" RESULTS:\"\n\n            keys = [e for e in self.measures if 'COUNT_' in e]\n            keys.sort()\n            print \"Counts:\"\n            print_table([(entry, str(self.measures[entry])) for entry in keys])\n\n            keys = [e for e in self.measures if 'COLLECTION_' in e]\n            keys.sort()\n            print\n            print \"Collection measures:\"\n            print_table([(entry, str(self.measures[entry])) for entry in keys])\n\n            if self.response_format == \"TextGrid\":\n                keys = [e for e in self.measures if 'TIMING_' in e]\n                keys.sort()\n                print\n                print \"Time-based measures:\"\n                print_table([(entry, str(self.measures[entry])) for entry in keys])\n\n        #write to CSV file\n        if self.target_file:\n            with open(self.target_file, 'w') as outfile:\n                header = ['file_id'] + \\\n                         [self.type + \"_\" + e for e in self.measures if 'COUNT_' in e] + \\\n                         [self.type + \"_\" + e for e in self.measures if 'COLLECTION_' in e] + \\\n                         [self.type + \"_\" + e for e in self.measures if 'TIMING_' in e]\n                writer = csv.writer(outfile, quoting=csv.QUOTE_MINIMAL)\n                writer.writerow(header)\n                #the split/join gets rid of the type appended just above\n                writer.writerow([self.measures[\"file_id\"]] +\n                                [self.measures[\"_\".join(e.split('_')[1:])] for e in header[1:]])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninsert a Version child PID.", "response": "def insert_child(self, child_pid, index=-1):\n        \"\"\"Insert a Version child PID.\"\"\"\n        if child_pid.status != PIDStatus.REGISTERED:\n            raise PIDRelationConsistencyError(\n                \"Version PIDs should have status 'REGISTERED'. Use \"\n                \"insert_draft_child to insert 'RESERVED' draft PID.\")\n        with db.session.begin_nested():\n            # if there is a draft and \"child\" is inserted as the last version,\n            # it should be inserted before the draft.\n            draft = self.draft_child\n            if draft and index == -1:\n                index = self.index(draft)\n            super(PIDNodeVersioning, self).insert_child(child_pid, index=index)\n            self.update_redirect()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving a Version child PID.", "response": "def remove_child(self, child_pid):\n        \"\"\"Remove a Version child PID.\n\n        Extends the base method call by redirecting from the parent to the\n        last child.\n        \"\"\"\n        if child_pid.status == PIDStatus.RESERVED:\n            raise PIDRelationConsistencyError(\n                \"Version PIDs should not have status 'RESERVED'. Use \"\n                \"remove_draft_child to remove a draft PID.\")\n        with db.session.begin_nested():\n            super(PIDNodeVersioning, self).remove_child(child_pid,\n                                                        reorder=True)\n            self.update_redirect()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef draft_child(self):\n        return super(PIDNodeVersioning, self).children.status(\n            PIDStatus.RESERVED\n        ).one_or_none()", "response": "Get the draft child."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninserting a draft child to versioning.", "response": "def insert_draft_child(self, child_pid):\n        \"\"\"Insert a draft child to versioning.\"\"\"\n        if child_pid.status != PIDStatus.RESERVED:\n            raise PIDRelationConsistencyError(\n                \"Draft child should have status 'RESERVED'\")\n\n        if not self.draft_child:\n            with db.session.begin_nested():\n                super(PIDNodeVersioning, self).insert_child(child_pid,\n                                                            index=-1)\n        else:\n            raise PIDRelationConsistencyError(\n                \"Draft child already exists for this relation: {0}\".format(\n                    self.draft_child))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef remove_draft_child(self):\n        if self.draft_child:\n            with db.session.begin_nested():\n                super(PIDNodeVersioning, self).remove_child(self.draft_child,\n                                                            reorder=True)", "response": "Remove the draft child from versioning."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_redirect(self):\n        if self.last_child:\n            self._resolved_pid.redirect(self.last_child)\n        elif any(map(lambda pid: pid.status not in [PIDStatus.DELETED,\n                                                    PIDStatus.REGISTERED,\n                                                    PIDStatus.RESERVED],\n                     super(PIDNodeVersioning, self).children.all())):\n            raise PIDRelationConsistencyError(\n                \"Invalid relation state. Only REGISTERED, RESERVED \"\n                \"and DELETED PIDs are supported.\"\n            )", "response": "Update the parent redirect to the current last child."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsend feedback to the authors of the system.", "response": "def feedback(request):\n    \"\"\"\n    Send feedback to the authors of the system.\n\n    GET parameters:\n        html\n            turn on the HTML version of the API\n\n    POST parameters (JSON):\n        text:\n            the main feedback content\n        email (optional):\n            user's e-mail\n        username (optional):\n            user's name\n    \"\"\"\n    if request.method == 'GET':\n        return render(request, 'feedback_feedback.html', {}, help_text=feedback.__doc__)\n    if request.method == 'POST':\n        feedback_data = json_body(request.body.decode(\"utf-8\"))\n        feedback_data['user_agent'] = Session.objects.get_current_session().http_user_agent.content\n        if not feedback_data.get('username'):\n            feedback_data['username'] = request.user.username\n        if not feedback_data.get('email'):\n            feedback_data['email'] = request.user.email\n        comment = Comment.objects.create(\n            username=feedback_data['username'],\n            email=feedback_data['email'],\n            text=feedback_data['text'])\n        if get_config('proso_feedback', 'send_emails', default=True):\n            feedback_domain = get_config('proso_feedback', 'domain', required=True)\n            feedback_to = get_config('proso_feedback', 'to', required=True)\n            if is_likely_worthless(feedback_data):\n                mail_from = 'spam@' + feedback_domain\n            else:\n                mail_from = 'feedback@' + feedback_domain\n            text_content = render_to_string(\"emails/feedback.plain.txt\", {\n                \"feedback\": feedback_data,\n                \"user\": request.user,\n            })\n            html_content = render_to_string(\"emails/feedback.html\", {\n                \"feedback\": feedback_data,\n                \"user\": request.user,\n            })\n            subject = feedback_domain + ' feedback ' + str(comment.id)\n            mail = EmailMultiAlternatives(\n                subject,\n                text_content,\n                mail_from,\n                feedback_to,\n            )\n            mail.attach_alternative(html_content, \"text/html\")\n            mail.send()\n            LOGGER.debug(\"email sent %s\\n\", text_content)\n        return HttpResponse('ok', status=201)\n    else:\n        return HttpResponseBadRequest(\"method %s is not allowed\".format(request.method))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrate the current practice.", "response": "def rating(request):\n    \"\"\"\n    Rate the current practice.\n\n    GET parameters:\n        html\n            turn on the HTML version of the API\n\n    POST parameters (JSON):\n        value:\n            one of the following numbers (how difficult questions are?):\n                (1) too easy,\n                (2) appropriate,\n                (3) too difficult\n            or one of the following numbers (how difficult questions should be?):\n                (4) much easier\n                (5) bit easier\n                (6) the same\n                (7) bit harder\n                (8) much harder\n    \"\"\"\n    if request.method == 'GET':\n        return render(request, 'feedback_rating.html', {}, help_text=rating.__doc__)\n    if request.method == 'POST':\n        data = json_body(request.body.decode(\"utf-8\"))\n        if data['value'] not in list(range(1, 9)):\n            return render_json(\n                request,\n                {'error': _('The given value is not valid.'), 'error_type': 'invalid_value'},\n                template='feedback_json.html', status=400\n            )\n        rating_object = Rating(\n            user=request.user,\n            value=data['value'],\n        )\n        rating_object.save()\n        return HttpResponse('ok', status=201)\n    else:\n        return HttpResponseBadRequest(\"method %s is not allowed\".format(request.method))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pretty_date(time=False):\n    from datetime import datetime\n    from django.utils import timezone\n    now = timezone.now()\n    if isinstance(time, int):\n        diff = now - datetime.fromtimestamp(time)\n    elif isinstance(time, datetime):\n        diff = now - time\n    elif not time:\n        diff = now - now\n    second_diff = diff.seconds\n    day_diff = diff.days\n\n    if day_diff < 0:\n        return ''\n\n    if day_diff == 0:\n        if second_diff < 10:\n            return \"just now\"\n        if second_diff < 60:\n            return str(second_diff) + \" seconds ago\"\n        if second_diff < 120:\n            return \"a minute ago\"\n        if second_diff < 3600:\n            return str(second_diff // 60) + \" minutes ago\"\n        if second_diff < 7200:\n            return \"an hour ago\"\n        if second_diff < 86400:\n            return str(second_diff // 3600) + \" hours ago\"\n    if day_diff == 1:\n        return \"Yesterday\"\n    if day_diff < 7:\n        return str(day_diff) + \" days ago\"\n    if day_diff < 31:\n        return str(day_diff // 7) + \" weeks ago\"\n    if day_diff < 365:\n        return str(day_diff // 30) + \" months ago\"\n    return str(day_diff // 365) + \" years ago\"", "response": "Returns a pretty string of the date in the a\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getFiltersFromArgs(kwargs):\n    '''\n        getFiltersFromArgs - Returns a dictionary of each filter type, and the corrosponding field/value\n\n        @param kwargs <dict> - Dictionary of filter arguments\n\n\n        @return - Dictionary of each filter type (minus the ones that are optimized into others), each containing a list of tuples, (fieldName, matchingValue)\n    '''\n\n    # Create a copy of each possible filter in FILTER_TYPES and link to empty list.\n    #  This object will be filled with all of the filters requested\n    ret = { filterType : list() for filterType in FILTER_TYPES }\n\n    for key, value in kwargs.items():\n        matchObj = FILTER_PARAM_RE.match(key)\n        if not matchObj:\n\n            # Default ( no __$oper) is eq\n            filterType = 'eq'\n            field = key\n\n        else:\n\n            # We have an operation defined, extract it, and optimize if possible\n            #  (like if op is a case-insensitive, lowercase the value here)\n            groupDict = matchObj.groupdict()\n\n            filterType = groupDict['filterType']\n            field = groupDict['field']\n\n\n            if filterType not in FILTER_TYPES:\n                raise ValueError('Unknown filter type: %s. Choices are: (%s)' %(filterType, ', '.join(FILTER_TYPES)))\n\n\n            if filterType == 'isnull':\n                # Convert \"isnull\" to one of the \"is\" or \"isnot\" filters against None\n                if type(value) is not bool:\n                    raise ValueError('Filter type \"isnull\" requires True/False.')\n\n                if value is True:\n                    filterType = \"is\"\n                else:\n                    filterType = \"isnot\"\n\n                value = None\n            elif filterType in ('in', 'notin'):\n                # Try to make more efficient by making a set. Fallback to just using what they provide, could be an object implementing \"in\"\n                try:\n                    value = set(value)\n                except:\n                    pass\n            # Optimization - if case-insensitive, lowercase the comparison value here\n            elif filterType in ('ieq', 'ine', 'icontains', 'noticontains'):\n                value = value.lower()\n            elif filterType.startswith('split'):\n                if (not issubclass(type(value), tuple) and not issubclass(type(value), list)) or len(value) != 2:\n                    raise ValueError('Filter type %s expects a tuple of two params. (splitBy, matchPortion)' %(filterType,))\n\n\n\n        ret[filterType].append( (field, value) )\n\n    return ret", "response": "Returns a dictionary of each filter type and the corrosponding field and matching value."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\napplying a custom filter to elements and return a QueryableList of matches", "response": "def customFilter(self, filterFunc):\n        '''\n            customFilter - Apply a custom filter to elements and return a QueryableList of matches\n\n            @param filterFunc <lambda/function< - A lambda/function that is passed an item, and\n               returns True if the item matches (will be returned), otherwise False.\n\n            @return - A QueryableList object of the same type, with only the matching objects returned.\n        '''\n        ret = self.__class__()\n        for item in self:\n            if filterFunc(item):\n                ret.append(item)\n\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sort_by(self, fieldName, reverse=False):\n        '''\n            sort_by - Return a copy of this collection, sorted by the given fieldName.\n\n              The fieldName is accessed the same way as other filtering, so it supports custom properties, etc.\n\n              @param fieldName <str> - The name of the field on which to sort by\n\n              @param reverse <bool> Default False - If True, list will be in reverse order.\n\n              @return <QueryableList> - A QueryableList of the same type with the elements sorted based on arguments.\n        '''\n        return self.__class__(\n            sorted(self, key = lambda item : self._get_item_value(item, fieldName), reverse=reverse)\n        )", "response": "Returns a copy of this collection sorted by the given fieldName."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef filterAnd(self, **kwargs):\n        '''\n            filter/filterAnd - Performs a filter and returns a QueryableList object of the same type.\n\n                All the provided filters must match for the item to be returned.\n\n            @params are in the format of fieldName__operation=value  where fieldName is the name of the field on any given item, \"operation\" is one of the given operations (@see main documentation) (e.x. eq, ne, isnull), and value is what is used in the operation.\n\n            @return - A QueryableList object of the same type, with only the matching objects returned.\n        '''\n        filters = getFiltersFromArgs(kwargs)\n        ret = self.__class__()\n\n        if USE_CACHED:\n            caches = [dict() for i in range(len(self))]\n            get_item_value = self._getItemValueFunction(caches, self._get_item_value)\n        else:\n            get_item_value = self._get_item_value\n\n        # AND loop - for each item in this collection, run through each of the filter types.\n        # If any of the filter types do not match, move on to next item\n        # If all filters match, add item to the return set\n        for item in self:\n            keepIt = True\n\n            # Do is/isnot first (and implicitly, isnull)\n            for fieldName, value in filters['is']:\n                if get_item_value(item, fieldName) is not value:\n                    keepIt = False\n                    break\n\n            if keepIt is False:\n                continue\n\n            for fieldName, value in filters['isnot']:\n                if get_item_value(item, fieldName) is value:\n                    keepIt = False\n                    break\n\n            if keepIt is False:\n                continue\n\n            for fieldName, matchFunc in filters['customMatch']:\n                val = get_item_value(item, fieldName)\n                if not matchFunc(val):\n                    keepIt = False\n                    break\n\n            if keepIt is False:\n                continue\n\n            for fieldName, value in filters['in']:\n                if get_item_value(item, fieldName) not in value:\n                    keepIt = False\n                    break\n\n            if keepIt is False:\n                continue\n\n            for fieldName, value in filters['notin']:\n                if get_item_value(item, fieldName) in value:\n                    keepIt = False\n                    break\n\n            if keepIt is False:\n                continue\n\n\n            for fieldName, value in filters['eq']:\n                if get_item_value(item, fieldName) != value:\n                    keepIt = False\n                    break\n\n            if keepIt is False:\n                continue\n\n            for fieldName, value in filters['ieq']:\n                # If we can't lowercase the item's value, it obviously doesn't match whatever we previously could.\n                # Reminder: the \"i\" filter's values have already been lowercased\n                itemValue = get_item_value(item, fieldName)\n                try:\n                    itemValueLower = itemValue.lower()\n                except:\n                    keepIt = False\n                    break\n\n                if itemValueLower != value:\n                    keepIt = False\n                    break\n\n            if keepIt is False:\n                continue\n\n            for fieldName, value in filters['ne']:\n                if get_item_value(item, fieldName) == value:\n                    keepIt = False\n                    break\n\n            if keepIt is False:\n                continue\n\n            for fieldName, value in filters['ine']:\n                itemValue = get_item_value(item, fieldName)\n                try:\n                    itemValueLower = itemValue.lower()\n                except:\n                    # If we can't convert the field value to lowercase, it does not equal the other.\n                    continue\n\n                if itemValueLower == value:\n                    keepIt = False\n                    break\n\n            if keepIt is False:\n                continue\n\n            for fieldName, value in filters['lt']:\n                if get_item_value(item, fieldName) >= value:\n                    keepIt = False\n                    break\n\n            if keepIt is False:\n                continue\n\n            for fieldName, value in filters['lte']:\n                if get_item_value(item, fieldName) > value:\n                    keepIt = False\n                    break\n\n            if keepIt is False:\n                continue\n\n            for fieldName, value in filters['gt']:\n                if get_item_value(item, fieldName) <= value:\n                    keepIt = False\n                    break\n\n            if keepIt is False:\n                continue\n\n\n            for fieldName, value in filters['gte']:\n                if get_item_value(item, fieldName) < value:\n                    keepIt = False\n                    break\n\n            if keepIt is False:\n                continue\n\n            for fieldName, value in filters['contains']:\n                itemValue = get_item_value(item, fieldName)\n                try:\n                    if value not in itemValue:\n                        keepIt = False\n                        break\n                except:\n                    # If field does not support \"in\", it does not contain the item.\n                    keepIt = False\n                    break\n\n            if keepIt is False:\n                continue\n\n            for fieldName, value in filters['icontains']:\n                itemValue = get_item_value(item, fieldName)\n                try:\n                    itemValue = itemValue.lower()\n\n                    if value not in itemValue:\n                        keepIt = False\n                        break\n                except:\n                    keepIt = False\n                    break\n\n            if keepIt is False:\n                continue\n\n            for fieldName, value in filters['notcontains']:\n                itemValue = get_item_value(item, fieldName)\n                try:\n                    if value in itemValue:\n                        keepIt = False\n                        break\n                except:\n                    # If field does not support \"in\", it does not contain the item.\n                    continue\n\n            if keepIt is False:\n                continue\n\n            for fieldName, value in filters['noticontains']:\n                itemValue = get_item_value(item, fieldName)\n                try:\n                    itemValue = itemValue.lower()\n\n                    if value in itemValue:\n                        keepIt = False\n                        break\n                except:\n                    continue\n\n\n            if keepIt is False:\n                continue\n\n            for fieldName, value in filters['containsAny']:\n                itemValue = get_item_value(item, fieldName)\n\n                if itemValue is None:\n                    # Cannot split None\n                    keepIt = False\n                    break\n\n                didContain = False\n                for maybeContains in value:\n                    if maybeContains in itemValue:\n                        didContain = True\n                        break\n                if didContain is False:\n                    keepIt = False\n                    break\n\n            if keepIt is False:\n                continue\n\n            for fieldName, value in filters['notcontainsAny']:\n                itemValue = get_item_value(item, fieldName)\n\n                if itemValue is None:\n                    # Cannot split None, so it is a match..\n                    continue\n\n                didContain = False\n                for maybeContains in value:\n                    if maybeContains in itemValue:\n                        didContain = True\n                        break\n                if didContain is True:\n                    keepIt = False\n                    break\n\n            if keepIt is False:\n                continue\n\n            # IDEA: Could implement a dict here of last several splits, incase we have repeated splits on same large field.\n            #   I think this may be more lossy in the general case to support a corner case though.\n\n            for fieldName, value in filters['splitcontains']:\n                (splitBy, maybeContains) = value\n\n                itemValue = get_item_value(item, fieldName)\n\n                if itemValue is None:\n                    # Cannot split, no match\n                    keepIt = False\n                    break\n\n                try:\n                    itemValue = itemValue.split(splitBy)\n                    if maybeContains not in itemValue:\n                        keepIt = False\n                        break\n                except:\n                    # If field does not supprt \"in\", or cannot be split, it does not contain the item.\n                    keepIt = False\n                    break\n\n            if keepIt is False:\n                continue\n\n            for fieldName, value in filters['splitnotcontains']:\n                (splitBy, maybeContains) = value\n\n                itemValue = get_item_value(item, fieldName)\n\n                if itemValue is None:\n                    # Cannot split, so does not contain and is a match.\n                    continue\n\n                try:\n                    itemValue = itemValue.split(splitBy)\n                    if maybeContains in itemValue:\n                        keepIt = False\n                        break\n                except:\n                    # If field does not supprt \"in\", or cannot be split, it does not contain the item and thus matches here.\n                    continue\n\n            if keepIt is False:\n                continue\n\n            for fieldName, value in filters['splitcontainsAny']:\n                (splitBy, maybeContainsLst) = value\n\n                itemValue = get_item_value(item, fieldName)\n\n                if itemValue is None:\n                    # Cannot split, so it does not contain a match\n                    keepIt = False\n                    break\n\n                try:\n                    itemValue = itemValue.split(splitBy)\n                except:\n                    # Cannot split, does not match.\n                    keepIt = False\n                    break\n\n\n                didContain = False\n                for maybeContains in maybeContainsLst:\n                    if maybeContains in itemValue:\n                        didContain = True\n                        break\n                if didContain is False:\n                    keepIt = False\n                    break\n\n            if keepIt is False:\n                continue\n\n            for fieldName, value in filters['splitnotcontainsAny']:\n                (splitBy, maybeContainsLst) = value\n\n                itemValue = get_item_value(item, fieldName)\n\n                if itemValue is None:\n                    # Cannot split, so it must not contain any (and is a match)\n                    continue\n\n                try:\n                    itemValue = itemValue.split(splitBy)\n                except:\n                    # Cannot split, so must not contain any (and is a match)\n                    continue\n\n                didContain = False\n                for maybeContains in maybeContainsLst:\n                    if maybeContains in itemValue:\n                        didContain = True\n                        break\n                if didContain is True:\n                    keepIt = False\n                    break\n\n            if keepIt is False:\n                continue\n\n            # All the way through all filters, the item matches.\n            ret.append(item)\n\n        return ret", "response": "Filter and return a new list of items with only the matching items."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns sqlalchemy connect string URI.", "response": "def uri(self):\n        \"\"\"\n        Return sqlalchemy connect string URI.\n        \"\"\"\n        return self.uri_template.format(\n            host=self.host,\n            port=\"\" if self.port is None else self.port,\n            database=self.database,\n            username=self.username,\n            password=\"\" if self.password is None else self.password,\n            has_password=\"\" if self.password is None else \":\",\n            has_port=\"\" if self.port is None else \":\",\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef from_json(cls, json_file, json_path=None, key_mapping=None):\n        cls._validate_key_mapping(key_mapping)\n        with open(json_file, \"rb\") as f:\n            data = json.loads(f.read().decode(\"utf-8\"))\n            return cls._from_json_data(data, json_path, key_mapping)", "response": "Load a new instance of the class from a json file."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads credential from home. db. json file.", "response": "def from_home_db_json(cls, identifier, key_mapping=None):  # pragma: no cover\n        \"\"\"\n        Read credential from $HOME/.db.json file.\n\n        :type identifier: str\n        :param identifier: str, database identifier.\n\n        :type key_mapping: Dict[str, str]\n        :param key_mapping: dict\n\n        ``.db.json````::\n\n            {\n                \"identifier1\": {\n                    \"host\": \"example.com\",\n                    \"port\": 1234,\n                    \"database\": \"test\",\n                    \"username\": \"admin\",\n                    \"password\": \"admin\",\n                },\n                \"identifier2\": {\n                    ...\n                }\n            }\n        \"\"\"\n        return cls.from_json(\n            json_file=cls.path_db_json, json_path=identifier, key_mapping=key_mapping)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload database credential from json on s3.", "response": "def from_s3_json(cls, bucket_name, key,\n                     json_path=None, key_mapping=None,\n                     aws_profile=None,\n                     aws_access_key_id=None,\n                     aws_secret_access_key=None,\n                     region_name=None):  # pragma: no cover\n        \"\"\"\n        Load database credential from json on s3.\n\n        :param bucket_name: str\n        :param key: str\n        :param aws_profile: if None, assume that you are using this from\n            AWS cloud. (service on the same cloud doesn't need profile name)\n        :param aws_access_key_id: str, not recommend to use\n        :param aws_secret_access_key: str, not recommend to use\n        :param region_name: str\n        \"\"\"\n        import boto3\n\n        ses = boto3.Session(\n            aws_access_key_id=aws_access_key_id,\n            aws_secret_access_key=aws_secret_access_key,\n            region_name=region_name,\n            profile_name=aws_profile,\n        )\n        s3 = ses.resource(\"s3\")\n        bucket = s3.Bucket(bucket_name)\n        object = bucket.Object(key)\n        data = json.loads(object.get()[\"Body\"].read().decode(\"utf-8\"))\n        return cls._from_json_data(data, json_path, key_mapping)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload database credential from environment variable.", "response": "def from_env(cls, prefix, kms_decrypt=False, aws_profile=None):\n        \"\"\"\n        Load database credential from env variable.\n\n        - host: ENV.{PREFIX}_HOST\n        - port: ENV.{PREFIX}_PORT\n        - database: ENV.{PREFIX}_DATABASE\n        - username: ENV.{PREFIX}_USERNAME\n        - password: ENV.{PREFIX}_PASSWORD\n\n        :param prefix: str\n        :param kms_decrypt: bool\n        :param aws_profile: str\n        \"\"\"\n        if len(prefix) < 1:\n            raise ValueError(\"prefix can't be empty\")\n\n        if len(set(prefix).difference(set(string.ascii_uppercase + \"_\"))):\n            raise ValueError(\"prefix can only use [A-Z] and '_'!\")\n\n        if not prefix.endswith(\"_\"):\n            prefix = prefix + \"_\"\n\n        data = dict(\n            host=os.getenv(prefix + \"HOST\"),\n            port=os.getenv(prefix + \"PORT\"),\n            database=os.getenv(prefix + \"DATABASE\"),\n            username=os.getenv(prefix + \"USERNAME\"),\n            password=os.getenv(prefix + \"PASSWORD\"),\n        )\n        if kms_decrypt is True:  # pragma: no cover\n            import boto3\n            from base64 import b64decode\n\n            if aws_profile is not None:\n                kms = boto3.client(\"kms\")\n            else:\n                ses = boto3.Session(profile_name=aws_profile)\n                kms = ses.client(\"kms\")\n\n            def decrypt(kms, text):\n                return kms.decrypt(\n                    CiphertextBlob=b64decode(text.encode(\"utf-8\"))\n                )[\"Plaintext\"].decode(\"utf-8\")\n\n            data = {\n                key: value if value is None else decrypt(kms, str(value))\n                for key, value in data.items()\n            }\n\n        return cls(**data)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting credentials into a dict.", "response": "def to_dict(self):\n        \"\"\"\n        Convert credentials into a dict.\n        \"\"\"\n        return dict(\n            host=self.host,\n            port=self.port,\n            database=self.database,\n            username=self.username,\n            password=self.password,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_sqlite(cls, path=\":memory:\", **kwargs):\n        return sa.create_engine(\"sqlite:///{path}\".format(path=path), **kwargs)", "response": "Create an engine for storing the current session s database entries."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_postgresql(self, **kwargs):\n        return self._ce(\n            self._ccs(self.DialectAndDriver.psql), **kwargs\n        )", "response": "create a Postgresql engine"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_postgresql_psycopg2(self, **kwargs):\n        return self._ce(\n            self._ccs(self.DialectAndDriver.psql_psycopg2), **kwargs\n        )", "response": "create an Engine object for PostgreSQL PSY copg2"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate an Engine object for PostgreSQL PG8000", "response": "def create_postgresql_pg8000(self, **kwargs):\n        \"\"\"\n        :rtype: Engine\n        \"\"\"\n        return self._ce(\n            self._ccs(self.DialectAndDriver.psql_pg8000), **kwargs\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _create_postgresql_pygresql(self, **kwargs):\n        return self._ce(\n            self._ccs(self.DialectAndDriver.psql_pygresql), **kwargs\n        )", "response": "Create an Engine object for PostgreSQL and PySQL."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_postgresql_psycopg2cffi(self, **kwargs):\n        return self._ce(\n            self._ccs(self.DialectAndDriver.psql_psycopg2cffi), **kwargs\n        )", "response": "create an Engine object for PostgreSQL PSY CFFI"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate an Engine object for PostgreSQL and PySQL", "response": "def create_postgresql_pypostgresql(self, **kwargs):\n        \"\"\"\n        :rtype: Engine\n        \"\"\"\n        return self._ce(\n            self._ccs(self.DialectAndDriver.psql_pypostgresql), **kwargs\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn an Engine instance for the given mysql data.", "response": "def create_mysql(self, **kwargs):\n        \"\"\"\n        :rtype: Engine\n        \"\"\"\n        return self._ce(\n            self._ccs(self.DialectAndDriver.mysql), **kwargs\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_mysql_mysqldb(self, **kwargs):\n        return self._ce(\n            self._ccs(self.DialectAndDriver.mysql_mysqldb), **kwargs\n        )", "response": "Returns an Engine object for the MySQL database."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a new MySQL connector instance.", "response": "def create_mysql_mysqlconnector(self, **kwargs):\n        \"\"\"\n        :rtype: Engine\n        \"\"\"\n        return self._ce(\n            self._ccs(self.DialectAndDriver.mysql_mysqlconnector), **kwargs\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning an Engine object for the mysql_oursql column.", "response": "def create_mysql_oursql(self, **kwargs):\n        \"\"\"\n        :rtype: Engine\n        \"\"\"\n        return self._ce(\n            self._ccs(self.DialectAndDriver.mysql_oursql), **kwargs\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_mysql_pymysql(self, **kwargs):\n        return self._ce(\n            self._ccs(self.DialectAndDriver.mysql_pymysql), **kwargs\n        )", "response": "Returns an Engine\n            for MySQL_PYMYSQL."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning an Engine for the given mysql_cymysql.", "response": "def create_mysql_cymysql(self, **kwargs):\n        \"\"\"\n        :rtype: Engine\n        \"\"\"\n        return self._ce(\n            self._ccs(self.DialectAndDriver.mysql_cymysql), **kwargs\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning an Engine object for the given database entry.", "response": "def create_oracle(self, **kwargs):\n        \"\"\"\n        :rtype: Engine\n        \"\"\"\n        return self._ce(\n            self._ccs(self.DialectAndDriver.oracle), **kwargs\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_oracle_cx_oracle(self, **kwargs):\n        return self._ce(\n            self._ccs(self.DialectAndDriver.oracle_cx_oracle), **kwargs\n        )", "response": "Returns an Engine object for the Oracle CX oracle."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning an Engine object for the mssql_pymssql dialect.", "response": "def create_mssql_pymssql(self, **kwargs):\n        \"\"\"\n        :rtype: Engine\n        \"\"\"\n        return self._ce(\n            self._ccs(self.DialectAndDriver.mssql_pymssql), **kwargs\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns an instance of the Redshift Engine.", "response": "def create_redshift(self, **kwargs):\n        \"\"\"\n        :rtype: Engine\n        \"\"\"\n        return self._ce(\n            self._ccs(self.DialectAndDriver.redshift_psycopg2), **kwargs\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef start_debugging():\n    exc_type, exc_value, exc_tb = sys.exc_info()\n\n    # If the exception has been annotated to be re-raised, raise the exception\n    if hasattr(exc_value, '_ipdbugger_let_raise'):\n        raise_(*sys.exc_info())\n\n    print()\n    for line in traceback.format_exception(exc_type, exc_value, exc_tb):\n        print(colored(line, 'red'), end=' ')\n\n    # Get the frame with the error.\n    test_frame = sys._getframe(-1).f_back\n\n    from ipdb.__main__ import wrap_sys_excepthook\n    wrap_sys_excepthook()\n    IPDBugger(exc_info=sys.exc_info()).set_trace(test_frame)", "response": "Start a debugging session after catching an exception. This prints the traceback and starts ipdb session in the frame of the error."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef do_raise(self, arg):\n        self.do_continue(arg)\n\n        # Annotating the exception for a continual re-raise\n        _, exc_value, _ = self.exc_info\n        exc_value._ipdbugger_let_raise = True\n\n        raise_(*self.exc_info)", "response": "Raise the last exception caught."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreruns the previous command.", "response": "def do_retry(self, arg):\n        \"\"\"Rerun the previous command.\"\"\"\n        prev_line = self.curframe.f_lineno - 1\n        # Make sure not to jump to the middle of the previous statement\n        while True:\n            try:\n                self.curframe.f_lineno = prev_line\n                break\n\n            except ValueError:\n                prev_line -= 1\n\n        self.do_jump(prev_line)\n        self.do_continue(arg)\n        return 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dispatch_line(self, frame):\n        callback = TerminalPdb.dispatch_line(self, frame)\n\n        # If the ipdb session ended, don't return a callback for the next line\n        if self.stoplineno == -1:\n            return None\n\n        return callback", "response": "Handle line action and return the next line callback."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef wrap_with_try(self, node):\n        handlers = []\n\n        if self.ignore_exceptions is None:\n            handlers.append(ast.ExceptHandler(type=None,\n                                              name=None,\n                                              body=[ast.Raise()]))\n\n        else:\n            ignores_nodes = self.ignore_exceptions\n\n            handlers.append(ast.ExceptHandler(type=ast.Tuple(ignores_nodes,\n                                                             ast.Load()),\n                                              name=None,\n                                              body=[ast.Raise()]))\n\n            if self.catch_exception is None or \\\n                    get_node_value(self.catch_exception) not in \\\n                    (get_node_value(ast_node)\n                     for ast_node in self.ignore_exceptions):\n\n                call_extra_parameters = [] if IS_PYTHON_3 else [None, None]\n                start_debug_cmd = ast.Expr(\n                    value=ast.Call(ast.Name(\"start_debugging\", ast.Load()),\n                                   [], [], *call_extra_parameters))\n\n                catch_exception_type = None\n                if self.catch_exception is not None:\n                    catch_exception_type = self.catch_exception\n\n                handlers.append(ast.ExceptHandler(type=catch_exception_type,\n                                                  name=None,\n                                                  body=[start_debug_cmd]))\n\n        try_except_extra_params = {\"finalbody\": []} if IS_PYTHON_3 else {}\n\n        new_node = self.ast_try_except(orelse=[], body=[node],\n                                       handlers=handlers,\n                                       **try_except_extra_params)\n\n        return ast.copy_location(new_node, node)", "response": "Wrap an ast node in a try node to enter debug on exception."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef visit_Call(self, node):\n        if self.depth == 0:\n            return node\n\n        if self.ignore_exceptions is None:\n            ignore_exceptions = ast.Name(\"None\", ast.Load())\n\n        else:\n            ignore_exceptions = ast.List(self.ignore_exceptions, ast.Load())\n\n        catch_exception_type = self.catch_exception \\\n            if self.catch_exception else \"None\"\n\n        catch_exception = ast.Name(catch_exception_type, ast.Load())\n        depth = ast.Num(self.depth - 1 if self.depth > 0 else -1)\n\n        debug_node_name = ast.Name(\"debug\", ast.Load())\n        call_extra_parameters = [] if IS_PYTHON_3 else [None, None]\n        node.func = ast.Call(debug_node_name,\n                             [node.func, ignore_exceptions,\n                              catch_exception, depth],\n                             [], *call_extra_parameters)\n\n        return node", "response": "Propagate debug wrapper into inner function calls if needed."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsurround node statement with a try block to catch errors.", "response": "def generic_visit(self, node):\n        \"\"\"Surround node statement with a try/except block to catch errors.\n\n        This method is called for every node of the parsed code, and only\n        changes statement lines.\n\n        Args:\n            node (ast.AST): node statement to surround.\n        \"\"\"\n        if (isinstance(node, ast.stmt) and\n                not isinstance(node, ast.FunctionDef)):\n\n            new_node = self.wrap_with_try(node)\n\n            # handling try except statement\n            if isinstance(node, self.ast_try_except):\n                self.try_except_handler(node)\n                return new_node\n\n            # Run recursively on all sub nodes\n            super(ErrorsCatchTransformer, self).generic_visit(node)\n\n            return new_node\n\n        # Run recursively on all sub nodes\n        return super(ErrorsCatchTransformer, self).generic_visit(node)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_csv_file(inputfile):\n    try:\n        stream = open(inputfile)\n        row = stream.readline()\n    except (IOError, UnicodeDecodeError):  # pragma: no cover\n        return False\n    finally:\n        stream.close()\n    content = row.strip().split(',')\n    return inputfile.endswith('.csv') and len(content) >= 4", "response": "Return whether the provided file is a CSV file or not."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_qtls_from_rqtl_data(matrix, lod_threshold):\n    t_matrix = list(zip(*matrix))\n    qtls = [['Trait', 'Linkage Group', 'Position', 'Exact marker', 'LOD']]\n    # row 0: markers\n    # row 1: chr\n    # row 2: pos\n    for row in t_matrix[3:]:\n        lgroup = None\n        max_lod = None\n        peak = None\n        cnt = 1\n        while cnt < len(row):\n            if lgroup is None:\n                lgroup = t_matrix[1][cnt]\n\n            if lgroup == t_matrix[1][cnt]:\n                if max_lod is None:\n                    max_lod = float(row[cnt])\n                if float(row[cnt]) > float(max_lod):\n                    max_lod = float(row[cnt])\n                    peak = cnt\n            else:\n                if max_lod \\\n                        and float(max_lod) > float(lod_threshold) \\\n                        and peak:\n                    qtl = [row[0],             # trait\n                           t_matrix[1][peak],  # LG\n                           t_matrix[2][peak],  # pos\n                           t_matrix[0][peak],  # marker\n                           max_lod,            # LOD value\n                           ]\n                    qtls.append(qtl)\n                lgroup = None\n                max_lod = None\n                peak = cnt\n            cnt = cnt + 1\n    return qtls", "response": "Retrieve the list of significants QTLs for the given input\n    matrix and using the specified LOD threshold."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_map_matrix(inputfile):\n    matrix = read_input_file(inputfile, sep=',', noquote=True)\n    output = [['Locus', 'Group', 'Position']]\n    for row in matrix:\n        if row[0] and not re.match(r'c\\d+\\.loc[\\d\\.]+', row[0]):\n            output.append([row[0], row[1], row[2]])\n    return output", "response": "Returns the matrix representation of the genetic map."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_files(cls, folder):\n        filelist = []\n        if folder is None or not os.path.isdir(folder):\n            return filelist\n        for root, dirs, files in os.walk(folder):\n            for filename in files:\n                filename = os.path.join(root, filename)\n                if is_csv_file(filename):\n                    filelist.append(filename)\n        return filelist", "response": "Retrieve the list of files that can be used in the plugin."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting the input files present in the given folder or inputfile. This method creates the matrix representation of the QTLs results providing for each marker position the LOD value found for each trait as well as a representation of the genetic map used in the experiment. The genetic map should be cleared of any markers added by the QTL mapping software. :kwarg folder: the path to the folder containing the files to check. This folder may contain sub-folders. :kwarg inputfile: the path to the input file to use :kwarg session: the session identifier used to identify which session to process :kwarg lod_threshold: the LOD threshold to apply to determine if a QTL is significant or not :kwarg qtls_file: a csv file containing the list of all the significant QTLs found in the analysis. The matrix is of type: trait, linkage group, position, Marker, LOD other columns :kwarg matrix_file: a csv file containing a matrix representation of the QTL data. This matrix is of type: marker, linkage group, position, trait1 lod, trait2, lod :kwarg map_file: a csv file containing the genetic map used in this experiment. The map is of structure: marker, linkage group, position", "response": "def convert_inputfiles(cls,\n                           folder=None,\n                           inputfile=None,\n                           session=None,\n                           lod_threshold=None,\n                           qtls_file='qtls.csv',\n                           matrix_file='qtls_matrix.csv',\n                           map_file='map.csv'):\n        \"\"\" Convert the input files present in the given folder or\n        inputfile.\n        This method creates the matrix representation of the QTLs\n        results providing for each marker position the LOD value found\n        for each trait as well as a representation of the genetic map\n        used in the experiment.\n        The genetic map should be cleared of any markers added by the\n        QTL mapping software.\n\n        :kwarg folder: the path to the folder containing the files to\n            check. This folder may contain sub-folders.\n        :kwarg inputfile: the path to the input file to use\n        :kwarg session: the session identifier used to identify which\n            session to process\n        :kwarg lod_threshold: the LOD threshold to apply to determine if\n            a QTL is significant or not\n        :kwarg qtls_file: a csv file containing the list of all the\n            significant QTLs found in the analysis.\n            The matrix is of type:\n               trait, linkage group, position, Marker, LOD other columns\n        :kwarg matrix_file: a csv file containing a matrix representation\n            of the QTL data. This matrix is of type:\n               marker, linkage group, position, trait1 lod, trait2, lod\n        :kwarg map_file: a csv file containing the genetic map used\n            in this experiment. The map is of structure:\n               marker, linkage group, position\n\n        \"\"\"\n        if folder is None and inputfile is None:\n            raise MQ2Exception('You must specify either a folder or an '\n                               'input file')\n\n        if folder is not None:  # pragma: no cover\n            if not os.path.isdir(folder):\n                raise MQ2Exception('The specified folder is actually '\n                                   'not a folder')\n            else:\n                inputfiles = cls.get_files(folder)\n\n        if inputfile is not None:  # pragma: no cover\n            if os.path.isdir(inputfile):\n                raise MQ2Exception('The specified input file is actually '\n                                   'a folder')\n            else:\n                inputfiles = [inputfile]\n\n        if len(inputfiles) == 0:  # pragma: no cover\n            raise MQ2Exception('No files correspond to this plugin')\n\n        if len(inputfiles) > 1:  # pragma: no cover\n            raise MQ2Exception(\n                'This plugin can only process one file at a time')\n\n        try:\n            lod_threshold = float(lod_threshold)\n        except ValueError:\n            raise MQ2Exception('LOD threshold should be a number')\n\n        inputfile = inputfiles[0]\n\n        # QTL matrix and QTL files\n        qtls = []\n        matrix = read_input_file(inputfile, sep=',', noquote=True)\n        qtls.extend(get_qtls_from_rqtl_data(matrix, lod_threshold))\n        # format QTLs and write down the selection\n        write_matrix(qtls_file, qtls)\n\n        # Write down the QTL matrix\n        write_matrix(matrix_file, matrix)\n\n        # Map matrix\n        map_matrix = get_map_matrix(inputfile)\n        write_matrix(map_file, map_matrix)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsave session if requested via g. stateless_sessions", "response": "def save_session(self, *args, **kwargs):\n        \"\"\"\n        Save session\n        Skip setting session cookie if requested via g.stateless_sessions\n        \"\"\"\n\n        # do not send session cookie\n        if g.get('stateless_sessions'):\n            return\n\n        # send cookie\n        return super(BoilerSessionInterface, self).save_session(\n            *args,\n            **kwargs\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef send_report(self, report_parts):\n        logger.info('Creating an email message')\n        report_parts = sorted(\n            filter(lambda x: x.fmt in self.formats, report_parts),\n            key=lambda x: self.formats.index(x.fmt)\n        )\n        fmtname = '{0}-{1}.{2}' if len(report_parts) > 1 else '{0}.{2}'\n        root_part = MIMEMultipart('mixed')\n        root_part.preamble = 'This is a multi-part message in MIME format.'\n\n        logger.debug('Creating the text/\"text_type\" parts')\n        for i, text_part in enumerate(report_parts):\n            attachment_name = fmtname.format(socket.gethostname(), i, text_part.ext)\n            attach_part = MIMEText(text_part.text, text_part.ext, 'utf-8')\n            attach_part.add_header('Content-Disposition', 'attachment', filename=attachment_name)\n            root_part.attach(attach_part)\n\n        if self.rawlogs:\n            out = BytesIO()\n            do_chunked_gzip(self.rawfh, out, filename=u'raw.log.gz')\n            out.seek(0, os.SEEK_END)\n            size = out.tell()\n\n            if size > self.rawlogs_limit:\n                logger.warning('%d is over the defined max of %r', size, self.rawlogs_limit)\n                logger.warning('Not attaching the raw logs')\n            else:\n                logger.debug('Creating the application/x-gzip part')\n                attach_part = MIMEBase('application', 'x-gzip')\n                attach_part.set_payload(out.getvalue())\n\n                from email.encoders import encode_base64\n\n                logger.debug('Encoding the gzipped raw logs with base64')\n                encode_base64(attach_part)\n                attach_part.add_header('Content-Disposition', 'attachment', filename='raw.log.gz')\n                root_part.attach(attach_part)\n\n        if self.gpg_encrypt:\n            import gpgme\n            try:\n                if self.gpg_keyringdir and os.path.exists(self.gpg_keyringdir):\n                    logger.debug('Setting keyring dir to %r', self.gpg_keyringdir)\n                    os.environ['GNUPGHOME'] = self.gpg_keyringdir\n\n                cleartext = BytesIO(root_part.as_string().encode())\n                ciphertext = BytesIO()\n\n                ctx = gpgme.Context()\n                ctx.armor = True\n\n                if self.gpg_recipients:\n                    recipients = [ctx.get_key(recipient) for recipient in self.gpg_recipients]\n                else:\n                    recipients = []\n                    for key in ctx.keylist():\n                        for subkey in key.subkeys:\n                            if subkey.can_encrypt:\n                                logger.debug('Found can_encrypt key = %d', subkey.keyid)\n                                recipients.append(key)\n                                break\n\n                signers = [ctx.get_key(signer) for signer in self.gpg_signers]\n                if signers:\n                    logger.info('Encrypting and signing the report')\n                    ctx.signers = signers\n                    ctx.encrypt_sign(recipients, gpgme.ENCRYPT_ALWAYS_TRUST, cleartext, ciphertext)\n                else:\n                    logger.info('Encrypting the report')\n                    ctx.encrypt(recipients, gpgme.ENCRYPT_ALWAYS_TRUST, cleartext, ciphertext)\n\n                logger.debug('Creating the MIME envelope for PGP')\n\n                gpg_envelope_part = MIMEMultipart('encrypted')\n                gpg_envelope_part.set_param('protocol', 'application/pgp-encrypted', header='Content-Type')\n                gpg_envelope_part.preamble = 'This is an OpenPGP/MIME encrypted message (RFC 2440 and 3156)'\n\n                gpg_mime_version_part = MIMEBase('application', 'pgp-encrypted')\n                gpg_mime_version_part.add_header('Content-Disposition', 'PGP/MIME version identification')\n                gpg_mime_version_part.set_payload('Version: 1')\n\n                gpg_payload_part = MIMEBase('application', 'octet-stream', name='encrypted.asc')\n                gpg_payload_part.add_header('Content-Disposition', 'OpenPGP encrypted message')\n                gpg_payload_part.add_header('Content-Disposition', 'inline', filename='encrypted.asc')\n                gpg_payload_part.set_payload(ciphertext.getvalue())\n\n                gpg_envelope_part.attach(gpg_mime_version_part)\n                gpg_envelope_part.attach(gpg_payload_part)\n\n                # envelope becomes the new root part\n                root_part = gpg_envelope_part\n\n            except ImportError:\n                logger.error('Need crypto libraries for gpg_encrypt.')\n                logger.error('Install pygpgme for GPG encryption support.')\n                logger.error('Not mailing the report out of caution.')\n                return\n\n        # Define headers\n        root_part['Date'] = formatdate()\n        root_part['From'] = self.email_address\n        root_part['To'] = ', '.join(self.mailto)\n        root_part['Subject'] = '{0} system events: {1}'.format(\n                socket.gethostname(), time.strftime('%c', time.localtime())\n        )\n        root_part['Message-Id'] = make_msgid()\n        root_part['X-Mailer'] = u'{0}-{1}'.format(package_name, __version__)\n        \n        mail_message(self.smtp_server, root_part.as_string(), self.email_address, self.mailto)\n        print('Mailed the report to: {0}'.format(','.join(self.mailto)))", "response": "Send a report by e - mail by sending it by e - mail."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef prune_old(self):\n        path = self.pubdir\n        dirmask = self.dirmask\n        expire = self.expire\n        expire_limit = int(time.time()) - (86400 * expire)\n\n        logger.info('Pruning directories older than %d days', expire)\n\n        if not os.path.isdir(path):\n            logger.warning('Dir %r not found -- skipping pruning', path)\n            return\n\n        for entry in os.listdir(path):\n            logger.debug('Found: %r', entry)\n            if os.path.isdir(os.path.join(path, entry)):\n                try: \n                    stamp = time.mktime(time.strptime(entry, dirmask))\n                except ValueError as e:\n                    logger.info('Dir %r did not match dirmask %r: %r', entry, dirmask, e)\n                    logger.info('Skipping %r', entry)\n                    continue\n\n                if stamp < expire_limit:\n                    shutil.rmtree(os.path.join(path, entry))\n                    logger.info('File Publisher: Pruned old dir: %r', entry)\n                else:\n                    logger.info('%r is still active', entry)\n            else:\n                logger.info('%r is not a directory. Skipping.', entry)\n\n        logger.info('Finished with pruning')", "response": "Removes the directories that are older than a certain date."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsending the report parts to local files.", "response": "def send_report(self, report_parts):\n        \"\"\"\n        Publish the report parts to local files. Each report part is a text\n        with a title and specific extension. For html and plaintext sending\n        the report part is unique, for csv send also the stats and unparsed\n        string are plain text and report items are csv texts.\n        \"\"\"\n        logger.info('Checking and creating the report directory')\n\n        report_parts = sorted(\n            filter(lambda x: x.fmt in self.formats, report_parts),\n            key=lambda x: self.formats.index(x.fmt)\n        )\n        workdir = os.path.join(self.pubdir, self.dirname)\n        if not os.path.isdir(workdir):\n            try: \n                os.makedirs(workdir)\n            except OSError as e:\n                logger.error('Error creating directory \"{0}\": {0}'.format(workdir, e))\n                return\n\n        fmtname = '{0}-{1}-{2}.{3}' if len(report_parts) > 1 else '{0}-{2}.{3}'\n\n        for i, text_part in enumerate(filter(lambda x: x.fmt in self.formats, report_parts)):\n            filename = fmtname.format(self.filename, i, socket.gethostname(), text_part.ext)\n            repfile = os.path.join(workdir, filename)\n            logger.info('Dumping the report part %d into %r', i, repfile)\n            fh = open(repfile, 'w')\n            fh.write(text_part.text)\n            fh.close()\n            print('Report part saved in: %r' % repfile)\n\n        if self.notify:\n            logger.info('Creating an email message')\n            email_address = self.config.get('main', 'email_address')\n            smtp_server = self.config.get('main', 'smtp_server')\n            publoc = os.path.join(self.pubroot, self.dirname)\n\n            eml = MIMEText('New lograptor report is available at:\\r\\n{0}'.format(publoc))\n            eml['Subject'] = '{0} system events: {1} (report notification)'.format(\n                socket.gethostname(), time.strftime('%c', time.localtime())\n            )\n            eml['Date'] = formatdate()\n            eml['From'] = email_address\n            eml['To'] = ', '.join(self.notify)\n            eml['X-Mailer'] = u'{0}-{1}'.format(package_name, __version__)\n\n            mail_message(smtp_server, eml.as_string(), email_address, self.notify)\n            print('Notification mailed to: {0}'.format(','.join(self.notify)))\n\n        if self.rawlogs:\n            logfilename = '{0}.log'.format(self.filename)\n            logfile = os.path.join(workdir, '{0}.gz'.format(logfilename))\n\n            logger.info('Gzipping logs and writing them to %r', logfilename)\n            outfh = open(logfile, 'w+b')\n            do_chunked_gzip(self.rawfh, outfh, logfilename)\n            outfh.close()\n            print('Gzipped logs saved in: {0}'.format(logfile))\n\n        # Purge old reports\n        self.prune_old()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_email_valid(email):\n    pattern = re.compile(r'[\\w\\.-]+@[\\w\\.-]+[.]\\w+')\n    return bool(pattern.match(email))", "response": "Check if email is valid"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if a password is valid", "response": "def is_password_valid(password):\n    \"\"\"\n    Check if a password is valid\n    \"\"\"\n    pattern = re.compile(r\"^.{4,75}$\")\n    return bool(pattern.match(password))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_username_valid(username):\n    pattern = re.compile(r\"^[a-zA-Z0-9_.-]+$\")\n    return bool(pattern.match(username))", "response": "Check if a valid username."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate MD5 :param value: :return:", "response": "def md5(value):\n    \"\"\"\n    Create MD5\n    :param value:\n    :return:\n    \"\"\"\n    m = hashlib.md5()\n    m.update(value)\n    return str(m.hexdigest())"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef chunk_list(items, size):\n    size = max(1, size)\n    return [items[i:i + size] for i in range(0, len(items), size)]", "response": "Returns a list of chunks of size"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef list_replace(subject_list, replacement, string):\n    for s in subject_list:\n        string = string.replace(s, replacement)\n    return string", "response": "Replace a list of items by a single replacement"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreplace a dict key to its value in the stirng", "response": "def dict_replace(subject_dict, string):\n    \"\"\"\n    Replace a dict map, key to its value in the stirng\n    :param subject_dict: dict\n    :param string: string\n    :return: string\n    \"\"\"\n    for i, j in subject_dict.items():\n        string = string.replace(i, j)\n    return string"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a signed JWT using the secret key and the given key and the given expires in.", "response": "def sign_jwt(data, secret_key, expires_in, salt=None, **kw):\n    \"\"\"\n    To create a signed JWT\n    :param data:\n    :param secret_key:\n    :param expires_in:\n    :param salt:\n    :param kw:\n    :return: string\n    \"\"\"\n    s = itsdangerous.TimedJSONWebSignatureSerializer(secret_key=secret_key,\n                                                     expires_in=expires_in,\n                                                     salt=salt,\n                                                      **kw)\n    return s.dumps(data)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef unsign_jwt(token, secret_key, salt=None, **kw):\n    s = itsdangerous.TimedJSONWebSignatureSerializer(secret_key, salt=salt, **kw)\n    return s.loads(token)", "response": "Unsign a JWT token"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef sign_url_safe(data, secret_key, expires_in=None, salt=None, **kw):\n    if expires_in:\n        expires_in *= 60\n        s = URLSafeTimedSerializer2(secret_key=secret_key,\n                                    expires_in=expires_in,\n                                    salt=salt,\n                                    **kw)\n    else:\n        s = itsdangerous.URLSafeSerializer(secret_key=secret_key,\n                                           salt=salt,\n                                           **kw)\n    return s.dumps(data)", "response": "Signs data in url safe format."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncalculate the age of the current node in the tree.", "response": "def how_old(dob):\n    \"\"\"\n    Calculate the age\n    :param dob: datetime object\n    :return: int\n    \"\"\"\n    today = datetime.date.today()\n    return today.year - dob.year - ((today.month, today.day) < (dob.month, dob.day))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the value of the key in the object.", "response": "def get(self, key, default=None):\n        \"\"\"\n        Access data via\n        :param key:\n        :param default: the default value\n        :return:\n        \"\"\"\n        try:\n            val = self\n            if \".\" not in key:\n                return self[key]\n            for k in key.split('.'):\n                if k.isdigit():\n                    k = int(k)\n                val = val[k]\n            return val\n        except (TypeError, KeyError, IndexError) as e:\n            return default"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse the method and return a list of all the decorators found", "response": "def parse(self):\n        \"\"\"\n        Return the list of string of all the decorators found\n        \"\"\"\n        self._parse(self.method)\n        return list(set([deco for deco in self.decos if deco]))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfilters a list of headers to include in a 304 Not Modified response.", "response": "def filter_304_headers(headers):\n    \"\"\"Filter a list of headers to include in a \"304 Not Modified\" response.\"\"\"\n    return [(k, v) for k, v in headers if k.lower() not in _filter_from_304]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef response(code, body='', etag=None, last_modified=None, expires=None, **kw):\n    if etag is not None:\n        if not (etag[0] == '\"' and etag[-1] == '\"'):\n            etag = '\"%s\"' % etag\n        kw['etag'] = etag\n\n    if last_modified is not None:\n        kw['last_modified'] = datetime_to_httpdate(last_modified)\n\n    if expires is not None:\n        if isinstance(expires, datetime):\n            kw['expires'] = datetime_to_httpdate(expires)\n        else:\n            kw['expires'] = timedelta_to_httpdate(expires)\n\n    headers = [(k.replace('_', '-').title(), v) for k, v in sorted(kw.items())]\n    return Response(code, headers, body)", "response": "Returns a new Response object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef body(self):\n        if self._body is None:\n            raw_body = self._raw_body\n            if self._body_writer is None:\n                self._body = raw_body() if callable(raw_body) else raw_body\n            else:\n                self._body = self._body_writer(raw_body)\n\n        return self._body", "response": "Seralizes and returns the response body. On subsequent access returns the cached value. On subsequent access returns the cached value."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset a response cookie.", "response": "def set_cookie(self, key, value='', max_age=None, path='/', domain=None,\n                   secure=False, httponly=False, expires=None):\n        \"\"\"Set a response cookie.\n\n        Parameters:\n\n        key\n          : The cookie name.\n        value\n          : The cookie value.\n        max_age\n          : The maximum age of the cookie in seconds, or as a\n            datetime.timedelta object.\n        path\n          : Restrict the cookie to this path (default: '/').\n        domain\n          : Restrict the cookie to his domain.\n        secure\n          : When True, instruct the client to only sent the cookie over HTTPS.\n        httponly\n          : When True, instruct the client to disallow javascript access to\n            the cookie.\n        expires\n          : Another way of specifying the maximum age of the cookie. Accepts\n            the same values as max_age (number of seconds, datetime.timedelta).\n            Additionaly accepts a datetime.datetime object.\n            Note: a value of type int or float is interpreted as a number of\n            seconds in the future, *not* as Unix timestamp.\n        \"\"\"\n        key, value = key.encode('utf-8'), value.encode('utf-8')\n        cookie = SimpleCookie({key: value})\n        m = cookie[key]\n        if max_age is not None:\n            if isinstance(max_age, timedelta):\n                m['max-age'] = int(total_seconds(max_age))\n            else:\n                m['max-age'] = int(max_age)\n        if path is not None: m['path'] = path.encode('utf-8')\n        if domain is not None: m['domain'] = domain.encode('utf-8')\n        if secure: m['secure'] = True\n        if httponly: m['httponly'] = True\n        if expires is not None:\n            # 'expires' expects an offset in seconds, like max-age\n            if isinstance(expires, datetime):\n                expires = total_seconds(expires - datetime.utcnow())\n            elif isinstance(expires, timedelta):\n                expires = total_seconds(expires)\n            m['expires'] = int(expires)\n\n        self.headers.add_header('Set-Cookie', m.OutputString())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndeleting a cookie by setting it to a blank value.", "response": "def delete_cookie(self, key, path='/', domain=None):\n        \"\"\"Delete a cookie (by setting it to a blank value).\n\n        The path and domain values must match that of the original cookie.\n        \"\"\"\n        self.set_cookie(key, value='', max_age=0, path=path, domain=domain,\n                        expires=datetime.utcfromtimestamp(0))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef conditional_to(self, request):\n        if not self.code == 200:\n            return self\n\n        request_headers = request.headers\n        response_headers = self.headers\n\n        if_none_match = request_headers.get('If-None-Match')\n        if_modified_since = request_headers.get('If-Modified-Since')\n\n        etag_ok, date_ok = False, False\n\n        if if_none_match:\n            etag = response_headers.get('ETag')\n            if etag and match_etag(etag, if_none_match, weak=True):\n                etag_ok = True\n\n        if if_modified_since:\n            last_modified = response_headers.get('Last-Modified')\n            if last_modified:\n                try:\n                    modified_ts = httpdate_to_timestamp(last_modified)\n                    last_valid_ts = httpdate_to_timestamp(if_modified_since)\n                    if modified_ts <= last_valid_ts:\n                        date_ok = True\n                except:\n                    pass  # Ignore invalid dates\n\n        if if_none_match and not etag_ok:\n            return self\n        elif if_modified_since and not date_ok:\n            return self\n        elif etag_ok or date_ok:\n            headers = filter_304_headers(self.headers.items())\n            if 'Date' not in self.headers:\n                headers.append(('Date', datetime_to_httpdate(time.time())))\n            return Response(status=304, headers=headers, body='')\n        return self", "response": "Return a new Response object that is conditional to a given request."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndetect if a ROOT Minuit2 is a standalone Minuit2 and returns True if it is a standalone Minuit2.", "response": "def is_secretly_root(lib):\n    \"\"\"\n    Detect an edge case where ROOT Minuit2 is detected as standalone\n    because $ROOTSYS/lib is in LD_LIBRARY_PATH, and suggest\n    appropriate countermeasures.\n    \"\"\"\n    from distutils import ccompiler\n    libdir = os.path.dirname(lib)\n    cc = ccompiler.new_compiler()\n    for rootlib in (\"Core\",\"MathCore\"):\n        if not cc.find_library_file([libdir], rootlib):\n            return False\n        else:\n            try:\n                root_config('libdir')\n                return True\n            except OSError:\n                raise RuntimeError(\"Found %s, which appears to be part of ROOT, but could not find root-config in PATH! To build against the standalone Minuit2, remove $ROOTSYS/lib from LD_LIBRARY_PATH; to build against the ROOT version, add $ROOTSYS/bin to your PATH\" % lib)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _parse_ukko_report(report):\n    '''Parse Ukko's report for available (non-reserved) nodes and their current\n    loads. The nodes that have load marked as '-' in report are not returned.\n\n    :returns: List of available ukko-nodes sorted in order of their current\n    load (nodes with least load are first).\n    '''\n    lines = report.split(\"\\\\n\")\n    cc = r'ukko[0-9]{3}.hpc.cs.helsinki.fi'\n    nodes = []\n    for line in lines:\n        if re.match(cc, line) and not re.search('Reserved', line):\n            # This is a line for ukko-node which is not reserved\n            sline = line.split(maxsplit=10)\n            try:\n                load = float(sline[5])\n            except:\n                # Could not parse load, node might not accept SSH-connections,\n                #etc. Continue to next line.\n                continue\n            nodes.append((sline[0], load))\n    return [n[0] for n in sorted(nodes, key=operator.itemgetter(1))]", "response": "Parse Ukko s report for available ukko - nodes and their current\n    loads."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_ukko_report():\n    '''Get Ukko's report from the fixed URL.\n    '''\n    with urllib.request.urlopen(URL_UKKO_REPORT) as response:\n        ret = str(response.read())\n    return ret", "response": "Get Ukko s report from the fixed URL."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting Ukko nodes with the least amount of load.", "response": "def get_nodes(n=8, exclude=[], loop=None):\n    '''Get Ukko nodes with the least amount of load.\n\n    May return less than *n* nodes if there are not as many nodes available,\n    the nodes are reserved or the nodes are on the exclude list.\n\n    :param int n: Number of Ukko nodes to return.\n    :param list exclude: Nodes to exclude from the returned list.\n    :param loop:\n        asyncio's event loop to test if each returned node is currently\n        loggable. The test is done by trying to connect to the node with\n        (async)ssh.\n\n    :rtype list:\n    :returns: Locations of Ukko nodes with the least amount of load\n    '''\n    report = _get_ukko_report()\n    nodes = _parse_ukko_report(report)\n    ret = []\n    while len(ret) < n and len(nodes) > 0:\n        node = nodes[0]\n        if node not in exclude:\n            reachable = True\n            if loop is not None:\n                reachable = loop.run_until_complete(_test_node(node))\n            if reachable:\n                ret.append(node)\n        nodes = nodes[1:]\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef md5sum(self):\n        cmd = 'show file {dir}:{bin} md5sum'.format(\n            dir=self.DESTDIR, bin=self.image)\n\n        run = self.device.api.exec_opcmd\n        try:\n            got = run(cmd)\n            return got.get('file_content_md5sum').strip()\n        except:  # NOQA\n            return None", "response": "Check to see if the file exists on the device and return the md5sum"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef copy_from(self, location, timeout=10 * 60):\n\n        cmd = 'copy {location} {dir}: vrf {vrf_name}'.format(\n            location=location, dir=self.DESTDIR, vrf_name=self.VRF_NAME)\n\n        run = self.device.api.exec_opcmd\n        run(cmd, msg_type='cli_show_ascii', timeout=timeout)", "response": "This method will copy the image from the device - side to the specified location."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef extend(self, xs: Union['List[T]', typing.List[T]]) -> 'List[T]':  # type: ignore\n        return type(self)(self.unbox() + List(xs).unbox())", "response": "A wrapper for the above method to extend a list with another list."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a new list where each element in self is mapped to f.", "response": "def fmap(self, f: Callable[[T], B]) -> 'List[B]':\n        \"\"\"doufo.List.fmap: map `List`  \n        Args:  \n            `self`:  \n            `f` (`Callable[[T], B]`): any callable funtion  \n        Returns:  \n            return (`List[B]`): A `List` of objected from `f`.  \n        Raises:\n        \"\"\"\n        return List([f(x) for x in self.unbox()])"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a new list with only elements that satisfy the given function f.", "response": "def filter(self, f: Callable[[A], B]) -> 'List[T]':\n        \"\"\"doufo.List.filter: filter this `List` obj with input `f` function  \n        Args:  \n            `self`:  \n            f (`Callable[[A],B]`): function that tells `True` or `False`  \n        Returns:  \n            return (`List[T]`): Filtered List  \n        Raises:\n        \"\"\"\n        return List([x for x in self.unbox() if f(x) is True])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_terminal_size():\n    import platform\n   \n    current_os = platform.system()\n    tuple_xy = None\n    if current_os == 'Windows':\n        tuple_xy = get_windows_terminal_size()\n        if tuple_xy is None:\n            tuple_xy = get_unix_tput_terminal_size()  # needed for window's python in cygwin's xterm!\n    elif current_os == 'Linux' or current_os == 'Darwin' or current_os.startswith('CYGWIN'):\n        tuple_xy = get_unix_ioctl_terminal_size()\n\n    if tuple_xy is None:\n        tuple_xy = (80, 25)  # default value\n    return tuple_xy", "response": "Get the terminal size in width and height. Works on Linux Mac OS X Windows Cygwin Linux and Windows."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_unix_tput_terminal_size():\n    import subprocess\n    try:\n        proc = subprocess.Popen([\"tput\", \"cols\"], stdin=subprocess.PIPE, stdout=subprocess.PIPE)\n        output = proc.communicate(input=None)\n        cols = int(output[0])\n        proc = subprocess.Popen([\"tput\", \"lines\"], stdin=subprocess.PIPE, stdout=subprocess.PIPE)\n        output = proc.communicate(input=None)\n        rows = int(output[0])\n        return cols, rows\n    except (IOError, OSError):\n        return None", "response": "Get the terminal size of a UNIX terminal using tput."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the terminal size using the ioctl UNIX command.", "response": "def get_unix_ioctl_terminal_size():\n    \"\"\"Get the terminal size of a UNIX terminal using the ioctl UNIX command.\"\"\"\n    def ioctl_gwinsz(fd):\n        try:\n            import fcntl\n            import termios\n            import struct\n            return struct.unpack('hh', fcntl.ioctl(fd, termios.TIOCGWINSZ, '1234'))\n        except (IOError, OSError):\n            return None\n\n    cr = ioctl_gwinsz(0) or ioctl_gwinsz(1) or ioctl_gwinsz(2)\n    if not cr:\n        try:\n            f = open(os.ctermid())\n            cr = ioctl_gwinsz(f.fileno())\n            f.close()\n        except (IOError, OSError):\n            pass\n    if not cr:\n        try:\n            cr = (os.environ['LINES'], os.environ['COLUMNS'])\n        except KeyError:\n            return None\n    return int(cr[1]), int(cr[0])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_marker_to_qtl(qtl, map_list):\n    closest = ''\n    diff = None\n    for marker in map_list:\n        if qtl[1] == marker[1]:\n            tmp_diff = float(qtl[2]) - float(marker[2])\n            if diff is None or abs(diff) > abs(tmp_diff):\n                diff = tmp_diff\n                closest = marker\n    if closest != '':\n        closest = closest[0]\n    return closest", "response": "Adds the closest marker to the given QTL."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nexecutes the series of filters on the provided list.", "response": "def execute(self, lst):\n        '''\n            execute - Execute the series of filters, in order, on the provided list.\n\n            @param lst <list/ A QueryableList type> - The list to filter. If you already know the types of items within\n                the list, you can pick a QueryableList implementing class to get faster results. Otherwise, if a list type that does\n                not extend QueryableListBase is provided, QueryableListMixed will be used (Supports both object-like and dict-like items)\n\n            @return - QueryableList of results. If you provided #lst as a QueryableList type already, that same type will be returned.\n                Otherwise, a QueryableListMixed will be returned.\n        '''\n        from . import QueryableListMixed\n        if not issubclass(lst.__class__, QueryableListBase):\n            lst = QueryableListMixed(lst)\n        filters = copy.copy(self.filters)\n        nextFilter = filters.popleft()\n        while nextFilter:\n            (filterMethod, filterArgs) = nextFilter\n            lst = self._applyFilter(lst, filterMethod, filterArgs)\n            if len(lst) == 0:\n                return lst\n            try:\n                nextFilter = filters.popleft()\n            except:\n                break\n        return lst"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a copy of this query.", "response": "def copy(self):\n        '''\n            copy - Create a copy of this query.\n        \n            @return <QueryBuilder> - a copy of this query\n        '''\n        ret = QueryBuilder()\n        ret.filters = copy.copy(self.filters)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _applyFilter(lst, filterMethod, filterArgs):\n        '''\n            _applyFilter - Applies the given filter method on a set of args\n\n             private method - used by execute\n\n             @return QueryableList - a QueryableList containing the elements of the resulting filter\n        '''\n        if filterMethod == FILTER_METHOD_AND:\n            return lst.filterAnd(**filterArgs)\n        else: # ALready validated in addFIlter that type is AND or OR\n            return lst.filterOr(**filterArgs)", "response": "Internal function that applies the given filter method on a set of args\n\n             and returns a new list containing the elements of the resulting list."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nraising error based on last reported error from the SDK", "response": "def _raise_corsair_error(self, error=None, message=\"\"):\n        \"\"\"\n        Raise error message based on the last reported error from the SDK\n\n        :param error: specify error type\n        :type error: int\n        :param message: specify error message\n        :type message: str\n        \"\"\"\n        if error is None:\n            error = self.last_error()\n        raise error(message)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef device_count(self):\n        device_count = get_device_count(self.corsair_sdk)\n        if device_count == -1:\n            self._raise_corsair_error()\n        return device_count", "response": "Find amount of devices in the CUE system"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the id of a led by the letter Only between A - Z", "response": "def led_id_from_char(self, char):\n        \"\"\"\n        Get id of a led by the letter\n        Only between A-Z\n\n        :param char: Character to find led_id from\n        :type char: str\n        :returns: id for led\n        :rtype: int\n        \"\"\"\n        led_id = get_led_id_for_key_name(self.corsair_sdk, bytes(char))\n        if led_id == 0:\n            self._raise_corsair_error()\n        return led_id"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting color of an led", "response": "def set_led(self, led_id, color):\n        \"\"\"\n        Set color of an led\n\n        :param led_id: id of led to set color\n        :type led_id: int\n        :param color: list of rgb values of new colors. eg. [255, 255, 255]\n        :type color: list\n        :returns: true if successful\n        :rtype: bool\n        \"\"\"\n        if not set_leds_color(self.corsair_sdk, LedColor(led_id, *color)):\n            self._raise_corsair_error()\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrequest exclusive control of a specific resource.", "response": "def request_control(self, device_id, access_mode=True):\n        \"\"\"\n        Request exclusive control of device\n\n        :param device_id: id of device\n        :type device_id: int\n        :param access_mode: True=exclusive, False=shared\n        :type access_mode: bool\n        :returns: true if successful\n        :rtype: bool\n        \"\"\"\n        if access_mode:\n            if not request_control(self.corsair_sdk, device_id):\n                self._raise_corsair_error()\n            return True\n        else:\n            self.reload()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef device(self, device_id, *args, **kwargs):\n        return Device(device_id, self.corsair_sdk, self._corsair_sdk_path, *args, **kwargs)", "response": "Return a Device object based on id\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn device information for a specific device_id", "response": "def device_info(self, device_id=None):\n        \"\"\"\n        Return device information, if device_id is not specified, return for this device\n\n        :param device_id: id of device\n        :type device_id: int\n        :returns: dict containing information about device\n        :rtype: dict\n        \"\"\"\n        if device_id is None:\n            device_id = self.device_id\n        return get_device_info(self.corsair_sdk, device_id)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _extract_all_sets_from_list(\n            self):\n        \"\"\"*Extract all of the sets from the list of coordinates*\n\n        **Return:**\n            - ``allMatches`` -- a list of lists. All of the assocaited sets of sources\n        \"\"\"\n        self.log.debug('starting the ``_extract_all_sets_from_list`` method')\n\n        from HMpTy import HTM\n        mesh = HTM(\n            depth=12,\n            log=self.log\n        )\n\n        matchIndices1, matchIndices2, seps = mesh.match(\n            ra1=self.ra,\n            dec1=self.dec,\n            ra2=self.ra,\n            dec2=self.dec,\n            radius=self.radius,\n            maxmatch=0,  # 1 = match closest 1, 0 = match all,\n            convertToArray=self.convertToArray\n        )\n\n        anchorIndicies = []\n        childIndicies = []\n        allMatches = []\n        thisMatch = None\n        for m1, m2, s in zip(matchIndices1, matchIndices2, seps):\n            if m1 not in anchorIndicies and m1 not in childIndicies:\n                if thisMatch:\n                    allMatches.append(thisMatch)\n                thisMatch = [self.sourceList[m1]]\n                anchorIndicies.append(m1)\n            if m2 not in anchorIndicies and m2 not in childIndicies:\n                childIndicies.append(m2)\n                thisMatch.append(self.sourceList[m2])\n        if thisMatch:\n            allMatches.append(thisMatch)\n\n        self.log.debug('completed the ``_extract_all_sets_from_list`` method')\n        return allMatches", "response": "This method extracts all of the sets from the list of coordinates and returns a list of lists."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntrying to determine the UniParc ID for obsolete ACCs which are not returned using uniprot_map.", "response": "def get_obsolete_acc_to_uniparc(acc):\n    ''' Tries to determine the UniParc ID for obsolete ACCs which are not returned using uniprot_map.\n\n        :param acc: The UniProt accession number.\n        :return: The corresponding UniParc ID.\n\n        Warning: This is a fragile function as the underlying website generation or URL could change.\n    '''\n    contents = http_get('www.uniprot.org/uniparc/?query={0}'.format(acc))\n    mtchs = re.findall(r'\"UPI[A-Z0-9]+?\"', contents, re.DOTALL)\n    uniparc_id = set([m[1:-1] for m in mtchs])\n    if len(uniparc_id) == 1:\n        return uniparc_id.pop()\n    elif len(uniparc_id) > 1:\n        raise Exception('Multiple UPI identifiers found.')\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmap from one ID scheme to another using UniProt service.", "response": "def uniprot_map(from_scheme, to_scheme, list_of_from_ids, cache_dir = None, silent = True):\n    '''Maps from one ID scheme to another using the UniProt service.\n        list_of_ids should be a list of strings.\n        This function was adapted from http://www.uniprot.org/faq/28#id_mapping_examples which also gives examples of\n        valid values for from_scheme and to_scheme.\n        Note that some conversions are not directly possible e.g. PDB_ID (PDB) to UPARC (UniParc). They need to go through\n        an intermediary format like ACC (UniProtKB AC) or ID (UniProtKB ID).\n        This function returns a dict mapping the IDs in from_scheme to a list of sorted IDs in to_scheme.\n    '''\n    try:\n        assert(hasattr(list_of_from_ids, '__iter__'))\n    except:\n        raise Exception('The list_of_from_ids argument should be an iterable type (e.g. list).')\n    full_mapping = {}\n    cached_mapping_file = None\n    if cache_dir:\n        cached_mapping_file = os.path.join(cache_dir, '%s.%s' % (from_scheme, to_scheme))\n        if os.path.exists(cached_mapping_file):\n            full_mapping = simplejson.loads(read_file(cached_mapping_file))\n    list_of_from_ids = set(list_of_from_ids)\n\n    requested_mapping = {}\n    remaining_ids = []\n    for id in list_of_from_ids:\n        if full_mapping.get(id):\n            requested_mapping[id] = full_mapping[id]\n        else:\n            remaining_ids.append(id)\n    assert(set(remaining_ids + requested_mapping.keys()) == set(list_of_from_ids))\n\n    if remaining_ids:\n        if not silent:\n            print(\"Getting %s->%s mapping\" % (from_scheme, to_scheme))\n        url = 'http://www.uniprot.org/mapping/'\n        params = {\n            'from'      : from_scheme,\n            'to'        : to_scheme,\n            'format'    : 'tab',\n            'query'     : ' '.join(sorted(list(list_of_from_ids))),\n        }\n\n        data = urllib.urlencode(params)\n        request = urllib2.Request(url, data)\n        contact = \"\" # Please set your email address here to help us debug in case of problems.\n        request.add_header('User-Agent', 'Python %s' % contact)\n        response = urllib2.urlopen(request)\n        page = response.read(200000)\n        lines = page.split(\"\\n\")\n\n        assert(lines[-1] == '')\n        assert(lines[0].split(\"\\t\") == ['From', 'To'])\n        for line in lines[1:-1]:\n            tokens = line.split(\"\\t\")\n            assert(len(tokens) == 2)\n            assert(tokens[0] in list_of_from_ids)\n            full_mapping[tokens[0]] = full_mapping.get(tokens[0], [])\n            full_mapping[tokens[0]].append(tokens[1])\n            requested_mapping[tokens[0]] = requested_mapping.get(tokens[0], [])\n            requested_mapping[tokens[0]].append(tokens[1])\n\n    # Sort the IDs\n    for k, v in requested_mapping.iteritems():\n        #assert(len(v) == len(set(v)))\n        requested_mapping[k] = sorted(set(v))\n    for k, v in full_mapping.iteritems():\n        #assert(len(v) == len(set(v)))\n        full_mapping[k] = sorted(set(v))\n\n    if remaining_ids and cached_mapping_file:\n        write_file(cached_mapping_file, simplejson.dumps(full_mapping))\n    return requested_mapping"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a mapping from PDB IDs to UniProtKB UniParc IDs.", "response": "def pdb_to_uniparc(pdb_ids, silent = True, cache_dir = None, manual_additions = {}):\n    ''' Returns a mapping {PDB ID -> List(UniParcEntry)}\n        The UniParcEntry objects have a to_dict() method which may be useful.\n    '''\n\n    # Map PDB IDs to UniProtKB AC\n    if not silent:\n        colortext.write(\"Retrieving PDB to UniProtKB AC mapping: \", 'cyan')\n    pdb_ac_mapping = uniprot_map('PDB_ID', 'ACC', pdb_ids, cache_dir = cache_dir, silent = silent)\n\n    for k, v in manual_additions.iteritems():\n        if k in pdb_ids:\n            if pdb_ac_mapping.get(k):\n                pdb_ac_mapping[k].extend(v)\n                pdb_ac_mapping[k] = list(set(pdb_ac_mapping[k]))\n            else:\n                pdb_ac_mapping[k] = v\n\n    if not silent:\n        colortext.write(\"done\\n\", 'green')\n\n    # Get a list of AC_IDs\n    if not silent:\n        colortext.write(\"Retrieving UniProtKB AC to UniProtKB ID mapping: \", 'cyan')\n    AC_IDs = set()\n    for k, v in pdb_ac_mapping.iteritems():\n        AC_IDs = AC_IDs.union(set(v))\n    AC_IDs = list(AC_IDs)\n    if not silent:\n        colortext.write(\"done\\n\", 'green')\n\n    # Map UniProtKB ACs to UniParc IDs\n    if not silent:\n        colortext.write(\"Retrieving UniProtKB AC to UniParc ID mapping: \", 'cyan')\n    ac_uniparc_mapping = uniprot_map('ACC', 'UPARC', AC_IDs, cache_dir = cache_dir, silent = silent)\n    for k, v in ac_uniparc_mapping.iteritems():\n        assert(len(v) == 1)\n        ac_uniparc_mapping[k] = v[0]\n    if not silent:\n        colortext.write(\"done\\n\", 'green')\n\n    # Map UniProtKB ACs to UniProtKB IDs\n    ac_id_mapping = uniprot_map('ACC', 'ID', AC_IDs, cache_dir = cache_dir, silent = silent)\n\n    for k, v in ac_id_mapping.iteritems():\n        assert(len(v) == 1)\n        ac_id_mapping[k] = v[0]\n\n    # Create mapping from PDB IDs to UniParcEntry objects\n    m = {}\n    if not silent:\n        colortext.message(\"\\nRetrieving FASTA sequences for the %d PDB IDs.\" % len(pdb_ids))\n    for pdb_id, ACs in pdb_ac_mapping.iteritems():\n        if not silent:\n            colortext.write(\"%s: \" % pdb_id, \"orange\")\n        m[pdb_id] = []\n        for AC in ACs:\n            entry = UniParcEntry(ac_uniparc_mapping[AC], [AC], [ac_id_mapping[AC]], cache_dir = cache_dir)\n            m[pdb_id].append(entry)\n            if not silent:\n                colortext.write(\".\", \"green\")\n        if not silent:\n            print(\"\")\n    return m"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_common_PDB_IDs(pdb_id, cache_dir = None, exception_on_failure = True):\n    '''This function takes a PDB ID, maps it to UniProt ACCs, then returns the common set of PDB IDs related to those ACCs.\n       The purpose is to find any PDB files related to pdb_id, particularly for complexes, such that the other PDB files\n       contain identical sequences or mutant complexes.'''\n    m = pdb_to_uniparc([pdb_id], cache_dir = cache_dir)\n    UniProtACs = []\n    if pdb_id in m:\n        for entry in m[pdb_id]:\n            if entry.UniProtACs:\n                UniProtACs.extend(entry.UniProtACs)\n            elif exception_on_failure:\n                raise Exception('No UniProtAC for one entry.Lookup failed.')\n    elif exception_on_failure:\n        raise Exception('Lookup failed.')\n\n    if not UniProtACs:\n        if exception_on_failure:\n            raise Exception('Lookup failed.')\n        else:\n            return None\n    common_set = set(uniprot_map('ACC', 'PDB_ID', [UniProtACs[0]], cache_dir = cache_dir).get(UniProtACs[0], []))\n    for acc in UniProtACs[1:]:\n         common_set = common_set.intersection(set(uniprot_map('ACC', 'PDB_ID', [acc], cache_dir = cache_dir).get(acc, [])))\n    return sorted(common_set)", "response": "This function takes a PDB ID maps it to UniProt ACCs then returns the common set of PDB IDs related to those ACCs."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses the sequence and atomic mass.", "response": "def _parse_sequence_tag(self):\n        '''Parses the sequence and atomic mass.'''\n        #main_tags = self._dom.getElementsByTagName(\"uniprot\")\n        #assert(len(main_tags) == 1)\n        #entry_tags = main_tags[0].getElementsByTagName(\"entry\")\n        #assert(len(entry_tags) == 1)\n        #entry_tags[0]\n\n        entry_tag = self.entry_tag\n        # only get sequence tags that are direct children of the entry tag (sequence tags can also be children of entry.comment.conflict)\n        sequence_tags = [child for child in entry_tag.childNodes if child.nodeType == child.ELEMENT_NODE and child.tagName == 'sequence']\n        assert(len(sequence_tags) == 1)\n        sequence_tag = sequence_tags[0]\n\n        # atomic mass, sequence, CRC64 digest\n        self.atomic_mass = float(sequence_tag.getAttribute(\"mass\"))\n        self.sequence = \"\".join(sequence_tag.firstChild.nodeValue.strip().split(\"\\n\"))\n        self.sequence_length = int(sequence_tag.getAttribute(\"length\"))\n        self.CRC64Digest = sequence_tag.getAttribute(\"checksum\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing the protein tag to get the names and EC numbers.", "response": "def _parse_organism_tag(self):\n        '''Parses the protein tag to get the names and EC numbers.'''\n        organism_name_types = UniProtACEntry.organism_name_types\n        self.organisms = []\n        organism_tags = [child for child in self.entry_tag.childNodes if child.nodeType == child.ELEMENT_NODE and child.tagName == 'organism']\n        assert(len(organism_tags) == 1)\n        for organism_tag in organism_tags:\n            names = dict.fromkeys(organism_name_types, None)\n            for name_tag in [child for child in organism_tag.childNodes if child.nodeType == child.ELEMENT_NODE and child.tagName == 'name']:\n                name_type = name_tag.getAttribute(\"type\")\n                assert(name_type in organism_name_types)\n                names[name_type] = name_tag.firstChild.nodeValue.strip()\n            assert(names.get('scientific'))\n            self.organisms.append(names)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing the protein tag to get the names and EC numbers.", "response": "def _parse_protein_tag(self):\n        '''Parses the protein tag to get the names and EC numbers.'''\n\n        protein_nodes = self._dom.getElementsByTagName('protein')\n        assert(len(protein_nodes) == 1)\n        self.protein_node = protein_nodes[0]\n\n        self._get_recommended_name()\n        self._get_submitted_names()\n        self._get_alternative_names()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cool_paginate(context, **kwargs) -> dict:\n\n    names = (\n        'size',\n        'next_name',\n        'previous_name',\n        'elastic',\n        'page_obj',\n    )\n\n    return_dict = {name: value for name, value in zip(names, map(kwargs.get, names))}\n\n    if context.get('request'):\n        return_dict['request'] = context['request']\n    else:\n        raise RequestNotExists(\n            'Unable to find request in your template context,'\n            'please make sure that you have the request context processor enabled'\n        )\n\n    if not return_dict.get('page_obj'):\n        if context.get('page_obj'):\n            return_dict['page_obj'] = context['page_obj']\n        else:\n            raise PageNotSpecified(\n                'You customized paginator standard name, '\n                \"but haven't specified it in {% cool_paginate %} tag.\"\n            )\n\n    if not return_dict.get('elastic'):\n        return_dict['elastic'] = getattr(settings, 'COOL_PAGINATOR_ELASTIC', 10)\n\n    return return_dict", "response": "Main function for pagination process."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef time_restarts(data_path):\n    path = os.path.join(data_path, 'last_restarted')\n    if not os.path.isfile(path):\n        with open(path, 'a'):\n            os.utime(path, None)\n\n    last_modified = os.stat(path).st_mtime\n\n    with open(path, 'a'):\n        os.utime(path, None)\n\n    now = os.stat(path).st_mtime\n    dif = round(now - last_modified, 2)\n    last_restart = datetime.fromtimestamp(now).strftime('%H:%M:%S')\n    result = 'LAST RESTART WAS {} SECONDS AGO at {}'.format(dif, last_restart)\n    print(style(fg='green', bg='red', text=result))", "response": "When called will create a file and measure its mtime on restarts"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nexecutes a query in form of texture clause return the result in form of :class : PrettyTable.", "response": "def from_stmt(stmt, engine, **kwargs):\n    \"\"\"\n    Execute a query in form of texture clause, return the result in form of\n\n    :class:`PrettyTable`.\n\n    :type stmt: TextClause\n    :param stmt:\n\n    :type engine: Engine\n    :param engine:\n\n    :rtype: PrettyTable\n    \"\"\"\n    result_proxy = engine.execute(stmt, **kwargs)\n    return from_db_cursor(result_proxy.cursor)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a PrettyTable from a sqlalchemy. select. Select object.", "response": "def from_sql(sql, engine, limit=None, **kwargs):\n    \"\"\"\n    Create a :class:`prettytable.PrettyTable` from :class:`sqlalchemy.select`.\n\n    :type sql: Select\n    :param sql: a ``sqlalchemy.sql.selectable.Select`` object.\n\n    :type engine: Engine\n    :param engine: an ``sqlalchemy.engine.base.Engine`` object.\n\n    :type limit: int\n    :param limit: int, limit rows to return.\n\n    :rtype: PrettyTable\n\n    **\u4e2d\u6587\u6587\u6863**\n\n    \u5c06sqlalchemy\u7684sql expression query\u7ed3\u679c\u653e\u5165prettytable\u4e2d.\n\n    .. note::\n\n        \u6ce8\u610f, from_db_cursor\u662f\u4ece\u539f\u751f\u7684\u6570\u636e\u5e93\u6e38\u6807\u901a\u8fc7\u8c03\u7528fetchall()\u65b9\u6cd5\u6765\u83b7\u53d6\u6570\u636e\u3002\n        \u800csqlalchemy\u8fd4\u56de\u7684\u662fResultProxy\u7c7b\u3002\u6240\u4ee5\u6211\u4eec\u9700\u8981\u4ece\u4e2d\u83b7\u53d6\u6e38\u6807\n        \u81f3\u4e8e\u4e3a\u4ec0\u4e48\u4e0d\u80fd\u76f4\u63a5\u4f7f\u7528 from_db_cursor(engine.execute(sql).cursor) \u7684\u8bed\u6cd5\n        \u6211\u4e5f\u4e0d\u77e5\u9053\u4e3a\u4ec0\u4e48.\n    \"\"\"\n    if limit is not None:\n        sql = sql.limit(limit)\n    result_proxy = engine.execute(sql)\n    return from_db_cursor(result_proxy.cursor)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nexecutes an SQLAlchemy query and return the result as a PrettyTable object.", "response": "def from_query(query, engine_or_session=None, limit=None, **kwargs):\n    \"\"\"\n    Execute an ORM style query, and return the result in\n    :class:`prettytable.PrettyTable`.\n\n    :type query: Query\n    :param query: an ``sqlalchemy.orm.Query`` object.\n\n    :type engine: Any\n    :param engine: query is always associated with a session, this parameter\n        just reserve the arg place.\n\n    :type limit: int\n    :param limit: int, limit rows to return.\n\n    :rtype: PrettyTable\n    :return: a ``prettytable.PrettyTable`` object\n\n    **\u4e2d\u6587\u6587\u6863**\n\n    \u5c06\u901a\u8fc7 ORM \u7684\u67e5\u8be2\u7ed3\u679c\u4e2d\u7684\u6570\u636e\u653e\u5165 :class:`PrettyTable` \u4e2d.\n    \"\"\"\n    if limit is not None:\n        query = query.limit(limit)\n    result_proxy = execute_query_return_result_proxy(query)\n    return from_db_cursor(result_proxy.cursor)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a PrettyTable from an object.", "response": "def from_object(orm_class, engine_or_session, limit=None, **kwargs):\n    \"\"\"\n    Select data from the table defined by a ORM class, and put into prettytable\n\n    :param orm_class: an orm class inherit from\n        ``sqlalchemy.ext.declarative.declarative_base()``\n\n    :type engine_or_session: Union[Engine, Session]\n    :param engine_or_session: the engine or session used to execute the query.\n\n    :type limit: int\n    :param limit: int, limit rows to return.\n\n    :rtype: PrettyTable\n\n    **\u4e2d\u6587\u6587\u6863**\n\n    \u5c06\u6570\u636e\u5bf9\u8c61\u7684\u6570\u636e\u653e\u5165 PrettyTable \u4e2d.\n\n    \u5e38\u7528\u4e8e\u5feb\u901f\u9884\u89c8\u67d0\u4e2a\u5bf9\u8c61\u80cc\u540e\u7684\u6570\u636e.\n    \"\"\"\n\n    ses, auto_close = ensure_session(engine_or_session)\n    query = ses.query(orm_class)\n    if limit is not None:\n        query = query.limit(limit)\n    result_proxy = execute_query_return_result_proxy(query)\n    if auto_close:\n        ses.close()\n    return from_db_cursor(result_proxy.cursor)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconstruct a Prettytable from any kinds of sqlalchemy query.", "response": "def from_everything(everything, engine_or_session, limit=None, **kwargs):\n    \"\"\"\n    Construct a Prettytable from any kinds of sqlalchemy query.\n\n    :type engine_or_session: Union[Engine, Session]\n\n    :rtype: PrettyTable\n\n    Usage::\n\n        from sqlalchemy import select\n\n        sql = select([t_user])\n        print(from_everything(sql, engine))\n\n        query = session.query(User)\n        print(from_everything(query, session))\n\n        session.query(User)\n    \"\"\"\n    if isinstance(everything, TextClause):\n        return from_stmt(everything, engine_or_session, **kwargs)\n\n    if isinstance(everything, Table):\n        return from_table(everything, engine_or_session, limit=limit, **kwargs)\n\n    if type(everything) is DeclarativeMeta:\n        return from_object(everything, engine_or_session, limit=limit, **kwargs)\n\n    if isinstance(everything, Query):\n        return from_query(everything, engine_or_session, limit=limit, **kwargs)\n\n    if isinstance(everything, Select):\n        return from_sql(everything, engine_or_session, limit=limit, **kwargs)\n\n    if isinstance(everything, ResultProxy):\n        return from_resultproxy(everything, **kwargs)\n\n    if isinstance(everything, list):\n        return from_data(everything, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a matrix that contains one hot entries for the given entry", "response": "def one_hot(cls, ij, sz):\n        \"\"\"\n        ij: postion\n        sz: size of matrix\n        \"\"\"\n        if isinstance(sz, int):\n            sz = (sz, sz)\n        if isinstance(ij, int):\n            ij = (ij, ij)\n        m = np.zeros(sz)\n        m[ij[0], ij[1]] = 1.0\n        return Matrix(m)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\naliases for full_analysis in multiprocessing pool.", "response": "def _full_analysis_mp_alias(br_obj, analysis_set, output_directory, unique_name, verbose, quick_plots):\n    \"\"\"\n    Alias for instance method that allows the method to be called in a\n    multiprocessing pool. Needed as multiprocessing does not otherwise work\n    on object instance methods.\n    \"\"\"\n    return (br_obj, unique_name, br_obj.full_analysis(analysis_set, output_directory, verbose = verbose, compile_pdf = verbose, quick_plots = quick_plots))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _compare_mp_alias(br_i, br_j, analysis_set, analysis_set_subdir, unique_ajps, verbose):\n    return br_i.compare(br_j, analysis_set, analysis_set_subdir, unique_ajps, verbose = verbose, compile_pdf = verbose)", "response": "Alias for instance method that allows the method to be called in multiprocessing pool. Needed as multiprocessing does not allow the method to be called in multiprocessing pool."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncalculate the stability classification for this case.", "response": "def compute_stability_classification(self, predicted_data, record, dataframe_record):\n        '''Calculate the stability classification for this case.'''\n        stability_classification, stability_classication_x_cutoff, stability_classication_y_cutoff = None, self.stability_classication_x_cutoff, self.stability_classication_y_cutoff\n        if record['DDG'] != None:\n            stability_classification = fraction_correct([record['DDG']], [predicted_data[self.ddg_analysis_type]], x_cutoff = stability_classication_x_cutoff, y_cutoff = stability_classication_y_cutoff)\n            stability_classification = int(stability_classification)\n            assert(stability_classification == 0 or stability_classification == 1)\n        dataframe_record['StabilityClassification'] = stability_classification"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef compute_absolute_error(self, predicted_data, record, dataframe_record):\n        '''Calculate the absolute error for this case.'''\n        absolute_error = abs(record['DDG'] - predicted_data[self.ddg_analysis_type])\n        dataframe_record['AbsoluteError'] = absolute_error", "response": "Calculate the absolute error for this case."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncounting the number of residues in the chains for the case.", "response": "def count_residues(self, record, pdb_record):\n        '''Count the number of residues in the chains for the case.'''\n        mutations = self.get_record_mutations(record)\n        pdb_chains = set([m['Chain'] for m in mutations])\n        assert(len(pdb_chains) == 1) # we expect monomeric cases\n        pdb_chain = pdb_chains.pop()\n        return len(pdb_record.get('Chains', {}).get(pdb_chain, {}).get('Sequence', ''))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_dataframe_row(self, dataset_cases, predicted_data, pdb_data, record_id, additional_prediction_data_columns):\n        '''Create a dataframe row for a prediction.'''\n\n        # Ignore derived mutations if appropriate\n        record = dataset_cases[record_id]\n        if self.is_this_record_a_derived_mutation(record) and not self.include_derived_mutations:\n            return None\n\n        amino_acid_details, CAA, PAA, HAA = self.amino_acid_details, self.CAA, self.PAA, self.HAA\n        burial_cutoff = self.burial_cutoff\n\n        # Initialize variables. For ambiguous cases where the set of distinct values has multiple values, we default to None\n        residue_charge, residue_charges = None, set()\n        exposure, exposures = None, set()\n        volume_change, volume_changes = None, set()\n        record_wtaa, wtaas = None, set()\n        record_mutaa, mutaas = None, set()\n        DSSPSimpleSSType, DSSPSimpleSSTypes = None, set()\n        DSSPType, DSSPTypes = None, set()\n        DSSPExposure, DSSPExposures = None, set()\n        scops = set()\n        mutation_string = []\n        num_derivative_errors = predicted_data.get('Errors', {}).get('Derivative error count', 0)\n        run_time = predicted_data.get('RunTime', None)\n        max_memory = predicted_data.get('MaxMemory', None)\n\n        mutations = self.get_record_mutations(record)\n        for m in mutations:\n\n            wtaa = m['WildTypeAA']\n            mutaa = m['MutantAA']\n            mutation_string.append('{0} {1}{2}{3}'.format(m['Chain'], m['WildTypeAA'], m['ResidueID'], m['MutantAA']))\n\n            # Residue types and chain\n            wtaas.add(wtaa)\n            mutaas.add(mutaa)\n            if m.get('SCOP class'):\n                scops.add(m['SCOP class'])\n            DSSPSimpleSSTypes.add(m['DSSPSimpleSSType'])\n            DSSPTypes.add(m['DSSPType'])\n            DSSPExposures.add(m['DSSPExposure'])\n\n            # Burial\n            if m['DSSPExposure'] != None:\n                if m['DSSPExposure'] > burial_cutoff:\n                    exposures.add('E')\n                else:\n                    exposures.add('B')\n            else:\n                exposures.add(None)\n\n            # Volume\n            if amino_acid_details[wtaa]['van der Waals volume'] < amino_acid_details[mutaa]['van der Waals volume']:\n                volume_changes.add('SL')\n            elif amino_acid_details[wtaa]['van der Waals volume'] > amino_acid_details[mutaa]['van der Waals volume']:\n                volume_changes.add('LS')\n            elif amino_acid_details[wtaa]['van der Waals volume'] == amino_acid_details[mutaa]['van der Waals volume']:\n                volume_changes.add('XX')\n\n            # Charge\n            if ((wtaa in CAA or wtaa in PAA) and (mutaa in HAA)) or ((mutaa in CAA or mutaa in PAA) and (wtaa in HAA)):\n                residue_charges.add('Change')\n            elif (wtaa in CAA or wtaa in PAA) and (mutaa in CAA or mutaa in PAA):\n                residue_charges.add('Polar/Charged')\n            elif (wtaa in HAA) and (mutaa in HAA):\n                residue_charges.add('Hydrophobic/Non-polar')\n            else:\n                 raise colortext.Exception('Should not reach here.')\n\n        # Create a string representing the mutations (useful for labeling rather than analysis)\n        mutation_string = '; '.join(mutation_string)\n\n        # Taking unique values, determine the residue charges of the wildtype and mutant residues, the wildtype residue exposure, and the relative change in van der Waals volume\n        if len(residue_charges) == 1: residue_charge = residue_charges.pop()\n        if len(exposures) == 1: exposure = exposures.pop()\n        if len(volume_changes) == 1: volume_change = volume_changes.pop()\n\n        # Taking unique values, determine the wildtype and mutant residue types\n        all_residues = wtaas.union(mutaas)\n        if len(wtaas) == 1: record_wtaa = wtaas.pop()\n        if len(mutaas) == 1: record_mutaa = mutaas.pop()\n\n        # Taking unique values, determine the secondary structure and residue exposures from the DSSP data in the dataset\n        if len(DSSPSimpleSSTypes) == 1: DSSPSimpleSSType = DSSPSimpleSSTypes.pop()\n        if len(DSSPTypes) == 1: DSSPType = DSSPTypes.pop()\n        if len(DSSPExposures) == 1: DSSPExposure = DSSPExposures.pop()\n\n        # Determine the SCOP classification from the SCOPe data in the dataset\n        full_scop_classification, scop_class, scop_fold = None, None, None\n        if len(scops) > 1:\n            self.log('Warning: There is more than one SCOPe class for record {0}.'.format(record_id), colortext.warning)\n        elif len(scops) == 1:\n            full_scop_classification = scops.pop()\n            scop_tokens = full_scop_classification.split('.')\n            scop_class = scop_tokens[0]\n            if len(scop_tokens) > 1:\n                scop_fold = '.'.join(scop_tokens[0:2])\n\n        # Partition the data by PDB resolution with bins: N/A, <1.5, 1.5-<2.0, 2.0-<2.5, >=2.5\n        pdb_record = pdb_data.get(self.get_record_pdb_file_id(record).upper())\n        pdb_resolution_bin = None\n        pdb_resolution = pdb_record.get('Resolution')\n        if pdb_resolution != None:\n            if pdb_resolution < 1.5:\n                pdb_resolution_bin = '<1.5'\n            elif pdb_resolution < 2.0:\n                pdb_resolution_bin = '1.5-2.0'\n            elif pdb_resolution < 2.5:\n                pdb_resolution_bin = '2.0-2.5'\n            else:\n                pdb_resolution_bin = '>=2.5'\n        pdb_resolution_bin = pdb_resolution_bin or 'N/A'\n\n        # Mark mutations involving glycine or proline\n        has_gp_mutation = 'G' in all_residues or 'P' in all_residues\n\n        # Create the data matrix\n        dataframe_record = dict(\n            DatasetID = record_id,\n            PDBFileID = self.get_record_pdb_file_id(record),\n            Mutations = mutation_string,\n            NumberOfMutations = len(mutations),\n            Predicted = predicted_data[self.ddg_analysis_type],\n            ResidueCharges = residue_charge,\n            VolumeChange = volume_change,\n            HasGPMutation = int(has_gp_mutation),\n            WildTypeDSSPType = DSSPType,\n            WildTypeDSSPSimpleSSType = DSSPSimpleSSType,\n            WildTypeDSSPExposure = DSSPExposure,\n            WildTypeSCOPClass = scop_class,\n            WildTypeSCOPFold = scop_fold,\n            WildTypeSCOPClassification = full_scop_classification,\n            WildTypeExposure = exposure,\n            WildTypeAA = record_wtaa,\n            MutantAA = record_mutaa,\n            PDBResolution = pdb_record.get('Resolution'),\n            PDBResolutionBin = pdb_resolution_bin,\n            NumberOfResidues = self.count_residues(record, pdb_record) or None,\n            NumberOfDerivativeErrors = num_derivative_errors,\n            RunTime = run_time,\n            MaxMemory = max_memory,\n            )\n        for c in additional_prediction_data_columns:\n            dataframe_record[c] = predicted_data.get(c)\n\n        if self.contains_experimental_data:\n            # These fields are particular to dataframes containing experimental values e.g. for benchmarking runs or for\n            # datasets where we have associated experimental values\n            self.get_experimental_ddg_values(record, dataframe_record)\n            self.compute_stability_classification(predicted_data, record, dataframe_record)\n            self.compute_absolute_error(predicted_data, record, dataframe_record)\n\n        return dataframe_record", "response": "Create a dataframe row for a prediction."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef full_analysis(self, analysis_set, output_directory, verbose = True, compile_pdf = True, quick_plots = False):\n        '''Combines calculate_metrics, write_dataframe_to_csv, and plot'''\n        if not os.path.isdir(output_directory):\n            os.makedirs(output_directory)\n        self.analysis_directory = output_directory\n        self.calculate_metrics(analysis_set = analysis_set, analysis_directory = output_directory, verbose = verbose)\n        self.write_dataframe_to_csv( os.path.join(output_directory, 'data.csv') )\n\n        # Return latex_report\n        return self.plot(analysis_set = analysis_set, analysis_directory = output_directory, matplotlib_plots = True, verbose = verbose, compile_pdf = compile_pdf, quick_plots = quick_plots)", "response": "Combines calculate_metrics write_dataframe_to_csv and plot"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_definitive_name(self, unique_ajps, join_character = '-', prepend_label = True):\n        name = ''\n        for ajp in unique_ajps:\n            if len(name) > 0:\n                name += join_character\n            if prepend_label:\n                name += str(ajp) + '_'\n            name += str(self.additional_join_parameters[ajp]['short_name'])\n        if name == '':\n            name = 'ddg-benchmark'\n        return name", "response": "Generates a definitive name based on the unique AJPS and the additional join parameters."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_unique_ajps( benchmark_runs ):\n        br_ajps = {}\n        for br in benchmark_runs:\n            for ajp in br.additional_join_parameters:\n                if ajp not in br_ajps:\n                    br_ajps[ajp] = set()\n                br_ajps[ajp].add( br.additional_join_parameters[ajp]['short_name'] )\n        unique_ajps = []\n        for ajp in br_ajps:\n            if len( br_ajps[ajp] ) > 1:\n                unique_ajps.append( ajp )\n        return unique_ajps", "response": "Determines which join parameters are unique"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef compare(self, other, analysis_set, output_directory, unique_ajps, verbose = True, compile_pdf = True):\n        self_unique_name = self.get_definitive_name(unique_ajps)\n        other_unique_name = other.get_definitive_name(unique_ajps)\n\n        output_directory = os.path.join(output_directory, os.path.join(self_unique_name, other_unique_name) )\n        assert( not os.path.isdir( output_directory ) )\n\n        subplot_directory = os.path.join(output_directory, 'plots')\n        if not os.path.isdir(subplot_directory):\n            os.makedirs(subplot_directory)\n\n        report = lr.LatexReport( table_of_contents = False )\n\n        # Construct dataframe comparing our predictions to other's predictions\n        both_predictions = pandas.concat(\n            [\n                self.add_identifying_columns_to_df(self.dataframe[['Predicted']], unique_ajps),\n                other.add_identifying_columns_to_df(other.dataframe[['Predicted']], unique_ajps),\n            ],\n            join = 'outer',\n        ).sort_index()\n        both_predictions_subtracted = subtract_row_pairs_for_display(\n            both_predictions,\n            output_csv = os.path.join(output_directory, 'predictions_v_predictions.csv'),\n            merge_df = self.dataframe,\n            verbose = verbose,\n        )\n\n        # Construct dataframe comparing our diff with experimental values to other's\n        self_diff = self.get_pred_minus_exp_dataframe(analysis_set, unique_ajps)\n        other_diff = other.get_pred_minus_exp_dataframe(analysis_set, unique_ajps)\n        diffs_df = pandas.concat(\n            [self_diff, other_diff],\n            join = 'outer',\n        )\n\n        diffs_df = subtract_row_pairs_for_display(\n            diffs_df,\n            output_csv = os.path.join(output_directory, 'diffs_v_diffs.csv'),\n            merge_df = self.dataframe,\n            verbose = verbose,\n        )\n\n        report.set_title_page(\n            '%s vs %s' % (\n                self.get_definitive_name(unique_ajps, join_character = '\\n'),\n                other.get_definitive_name(unique_ajps, join_character = '\\n')\n            )\n        )\n        predictions_v_predictions_df = self.dataframe[['Predicted']].merge(\n            other.dataframe[['Predicted']],\n            left_index = True,\n            right_index = True,\n        )\n        predictions_v_predictions_df.columns = [self_unique_name, other_unique_name]\n        report.add_plot( general_matplotlib.make_corr_plot(predictions_v_predictions_df, predictions_v_predictions_df.columns.values[0], predictions_v_predictions_df.columns.values[1], output_directory = subplot_directory, plot_title = 'Prediction comparison', axis_label_size = 8.0, output_name = 'vs_scatter', fig_height = 7, fig_width = 8, verbose = verbose, plot_11_line = True ), plot_title = 'Experimental vs. Predicted scatterplot (with density binning)' )\n\n        diff_v_diff_dataframe = self.get_pred_minus_exp_dataframe(analysis_set).merge(\n            other.get_pred_minus_exp_dataframe(analysis_set),\n            left_index = True,\n            right_index = True,\n        )\n        report.add_section_page( title = 'Plots' )\n        diff_v_diff_dataframe.columns = [self_unique_name, other_unique_name]\n        report.add_plot( general_matplotlib.make_corr_plot(diff_v_diff_dataframe, diff_v_diff_dataframe.columns.values[0], diff_v_diff_dataframe.columns.values[1], output_directory = subplot_directory, plot_title = 'Error v. Error', axis_label_size = 7.0, output_name = 'diff_vs_scatter', fig_height = 7, fig_width = 8, verbose = verbose, plot_11_line = True ), plot_title = 'Outliers --- Error (Predicted - Experimental) v. error. \\\\ x-axis=%s \\\\ y-axis=%s' % (diff_v_diff_dataframe.columns.values[0], diff_v_diff_dataframe.columns.values[1]) )\n\n        report.add_section_page( title = 'Tables' )\n\n        report.content.append( lr.LatexPandasTable(\n            diffs_df, float_format = float_format_2sigfig,\n            caption_text = 'Outliers --- Comparison of error (Predicted - Experimental) for first prediction set (%s) vs second set of predictions (%s). Values sorted by descending absolute delta.' % (self_unique_name, other_unique_name),\n        ) )\n\n        report.content.append( lr.LatexPandasTable(\n            both_predictions_subtracted, float_format = float_format_2sigfig,\n            caption_text = 'Direct comparison of predicted values. Values sorted by descending absolute delta.',\n        ) )\n\n        # Get joined stats comparison dataframe\n        for case_table in BenchmarkRun.make_case_description_tables(BenchmarkRun.get_stats_comparison_dataframe(\n                [self, other], unique_ajps,\n                output_csv = os.path.join(output_directory, 'comparison_metrics.csv'),\n        )):\n            report.content.append( case_table )\n\n        report.generate_pdf_report(\n            os.path.join(output_directory, 'comparison.pdf'),\n            verbose = verbose,\n            compile_pdf = compile_pdf,\n        )\n        if verbose:\n            print 'Comparison report saved to:', os.path.join(output_directory, 'comparison.pdf')\n        return report", "response": "Generate a comparison latex report for this analysis set and other analysis set."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef calculate_metrics(self, analysis_set = '', analysis_directory = None, drop_missing = True, case_n_cutoff = 5, verbose = True):\n        '''Calculates the main metrics for the benchmark run and writes them to file and LaTeX object.'''\n\n        dataframe = self.dataframe\n        if drop_missing:\n            dataframe = dataframe.dropna(subset=['Predicted'])\n\n        if self.calculate_scalar_adjustments:\n            scalar_adjustment = self.scalar_adjustments[analysis_set]\n        experimental_field = BenchmarkRun.get_analysis_set_fieldname('Experimental', analysis_set)\n\n        self.metric_latex_objects.append( lr.LatexPageSection('Data tables', None, True) )\n        intro_text = lr.LatexText( text = self.ddg_analysis_type_description )\n        header_row = ['Statistic name', '{Value}', 'p-value']\n        stats_column_format = ['l', 'S[table-format=3.2]', 'l']\n\n        if self.include_derived_mutations:\n            running_analysis_str = '\\nDerived mutations in analysis are included):'\n        else:\n            running_analysis_str = '\\nDerived mutations in analysis are omitted):'\n        intro_text.add_text(running_analysis_str)\n        if verbose:\n            self.report(running_analysis_str, fn = colortext.message)\n\n        classification_cutoffs_str = 'The stability classification cutoffs are: Experimental=%0.2f kcal/mol, Predicted=%0.2f energy units.' % (self.stability_classication_x_cutoff, self.stability_classication_y_cutoff)\n        intro_text.add_text( classification_cutoffs_str )\n        if verbose:\n            self.report(classification_cutoffs_str, fn = colortext.warning)\n\n        self.metric_latex_objects.append( intro_text )\n\n        amino_acid_details, CAA, PAA, HAA = self.amino_acid_details, self.CAA, self.PAA, self.HAA\n\n        # This dict is used for the print-statement below\n        volume_groups = {}\n        for aa_code, aa_details in amino_acid_details.iteritems():\n            v = int(aa_details['van der Waals volume']) # Note: I only convert to int here to match the old script behavior and because all volumes are integer values so it does not do any harm\n            volume_groups[v] = volume_groups.get(v, [])\n            volume_groups[v].append(aa_code)\n\n        section_latex_objs = []\n        section_latex_objs.append( lr.LatexSubSection(\n            'Breakdown by volume',\n            'A case is considered a small-to-large (resp. large-to-small) mutation if all of the wildtype residues have a smaller (resp. larger) van der Waals volume than the corresponding mutant residue. The order is defined as %s so some cases are considered to have no change in volume e.g. MET -> LEU.' % (' < '.join([''.join(sorted(v)) for k, v in sorted(volume_groups.iteritems())]))\n        ) )\n        for subcase in ('XX', 'SL', 'LS'):\n            subcase_dataframe = dataframe[dataframe['VolumeChange'] == subcase]\n            table_header = 'Statistics - %s (%d cases)' % (BenchmarkRun.by_volume_descriptions[subcase], len(subcase_dataframe))\n            if len(subcase_dataframe) >= 8:\n                list_stats = format_stats(get_xy_dataset_statistics_pandas(subcase_dataframe, experimental_field, 'Predicted', fcorrect_x_cutoff = self.stability_classication_x_cutoff, fcorrect_y_cutoff = self.stability_classication_y_cutoff, ignore_null_values = True, run_standardized_analysis = False), return_string = False)\n                section_latex_objs.append( lr.LatexTable(\n                    header_row,\n                    list_stats,\n                    column_format = stats_column_format,\n                    header_text = table_header\n                ))\n                self.add_stored_metric_to_df(BenchmarkRun.by_volume_descriptions[subcase], len(subcase_dataframe), list_stats)\n            else:\n                section_latex_objs.append( lr.LatexText(\n                    'Not enough data for analysis of mutations ''%s'' (at least 8 cases are required).' % BenchmarkRun.by_volume_descriptions[subcase]\n                ))\n        if verbose:\n            self.report('\\n'.join([x.generate_plaintext() for x in section_latex_objs]), fn = colortext.sprint)\n        self.metric_latex_objects.extend( section_latex_objs )\n\n\n        section_latex_objs = []\n        section_latex_objs.append( lr.LatexSubSection(\n            'Mutations to alanine',\n            'And mutations not to alanine'\n        ))\n        subcase_dataframe = dataframe[dataframe['MutantAA'] == 'A']\n        if len(subcase_dataframe) > 0:\n            table_header = 'Statistics - all mutations to alanine (including multiple mutations, if they are all to alanine) (%d cases)' % len(subcase_dataframe)\n            list_stats = format_stats(get_xy_dataset_statistics_pandas(subcase_dataframe, experimental_field, 'Predicted', fcorrect_x_cutoff = self.stability_classication_x_cutoff, fcorrect_y_cutoff = self.stability_classication_y_cutoff, ignore_null_values = True, run_standardized_analysis = False), return_string = False)\n            section_latex_objs.append( lr.LatexTable(\n                header_row,\n                list_stats,\n                column_format = stats_column_format,\n                header_text = table_header\n            ))\n            self.add_stored_metric_to_df('all mutations to alanine', len(subcase_dataframe), list_stats)\n\n        subcase_dataframe = dataframe[(dataframe['MutantAA'] == 'A') & (dataframe['NumberOfMutations'] == 1)]\n        if len(subcase_dataframe) > 0:\n            table_header = 'Statistics - single mutations to alanine (%d cases)' % len(subcase_dataframe)\n            list_stats = format_stats(get_xy_dataset_statistics_pandas(subcase_dataframe, experimental_field, 'Predicted', fcorrect_x_cutoff = self.stability_classication_x_cutoff, fcorrect_y_cutoff = self.stability_classication_y_cutoff, ignore_null_values = True, run_standardized_analysis = False), return_string = False)\n            section_latex_objs.append( lr.LatexTable(\n                header_row,\n                list_stats,\n                column_format = stats_column_format,\n                header_text = table_header\n            ))\n            self.add_stored_metric_to_df('single mutations to alanine', len(subcase_dataframe), list_stats)\n\n        subcase_dataframe = dataframe[(dataframe['MutantAA'] == 'A') & (dataframe['NumberOfMutations'] != 1)]\n        if len(subcase_dataframe) > 0:\n            table_header = 'Statistics - multiple mutations to alanine (%d cases)' % len(subcase_dataframe)\n            list_stats = format_stats(get_xy_dataset_statistics_pandas(subcase_dataframe, experimental_field, 'Predicted', fcorrect_x_cutoff = self.stability_classication_x_cutoff, fcorrect_y_cutoff = self.stability_classication_y_cutoff, ignore_null_values = True, run_standardized_analysis = False), return_string = False)\n            section_latex_objs.append( lr.LatexTable(\n                header_row,\n                list_stats,\n                column_format = stats_column_format,\n                header_text = table_header\n            ))\n            self.add_stored_metric_to_df('multiple mutations to alanine', len(subcase_dataframe), list_stats)\n\n        subcase_dataframe = dataframe[dataframe['MutantAA'] != 'A']\n        if len(subcase_dataframe) > 0:\n            table_header = 'Statistics - mutations to anything other than alanine (including multiple mutations that include a non-alanine mutation) (%d cases)' % len(subcase_dataframe)\n            list_stats = format_stats(get_xy_dataset_statistics_pandas(subcase_dataframe, experimental_field, 'Predicted', fcorrect_x_cutoff = self.stability_classication_x_cutoff, fcorrect_y_cutoff = self.stability_classication_y_cutoff, ignore_null_values = True, run_standardized_analysis = False), return_string = False)\n            section_latex_objs.append( lr.LatexTable(\n                header_row,\n                list_stats,\n                column_format = stats_column_format,\n                header_text = table_header\n            ))\n            self.add_stored_metric_to_df('mutations not to alanine', len(subcase_dataframe), list_stats)\n        if verbose and len(section_latex_objs) > 0:\n            self.report('\\n'.join([x.generate_plaintext() for x in section_latex_objs]), fn = colortext.sprint)\n        self.metric_latex_objects.extend( section_latex_objs )\n\n\n        section_latex_objs = []\n        subcase_dataframe = dataframe[dataframe['HasGPMutation'] == 1]\n        if len(subcase_dataframe) > 0:\n            table_header = 'Statistics - cases with G or P (%d cases)' % len(subcase_dataframe)\n            list_stats = format_stats(get_xy_dataset_statistics_pandas(subcase_dataframe, experimental_field, 'Predicted', fcorrect_x_cutoff = self.stability_classication_x_cutoff, fcorrect_y_cutoff = self.stability_classication_y_cutoff, ignore_null_values = True, run_standardized_analysis = False), return_string = False)\n            section_latex_objs.append( lr.LatexTable(\n                header_row,\n                list_stats,\n                column_format = stats_column_format,\n                header_text = table_header\n            ))\n            self.add_stored_metric_to_df('cases with G or P', len(subcase_dataframe), list_stats)\n\n        subcase_dataframe = dataframe[dataframe['HasGPMutation'] == 0]\n        if len(subcase_dataframe) > 0:\n            table_header = 'Statistics - cases without G or P (%d cases)' % len(subcase_dataframe)\n            list_stats = format_stats(get_xy_dataset_statistics_pandas(subcase_dataframe, experimental_field, 'Predicted', fcorrect_x_cutoff = self.stability_classication_x_cutoff, fcorrect_y_cutoff = self.stability_classication_y_cutoff, ignore_null_values = True, run_standardized_analysis = False), return_string = False)\n            section_latex_objs.append( lr.LatexTable(\n                header_row,\n                list_stats,\n                column_format = stats_column_format,\n                header_text = table_header\n            ))\n            self.add_stored_metric_to_df('cases without G or P', len(subcase_dataframe), list_stats)\n\n        if len(section_latex_objs) > 0:\n            section_latex_objs.insert( 0, lr.LatexSubSection(\n                'Separating out mutations involving glycine or proline.',\n                'This cases may involve changes to secondary structure so we separate them out here.'\n            ))\n\n        if verbose and len(section_latex_objs) > 0:\n            self.report('\\n'.join([x.generate_plaintext() for x in section_latex_objs]), fn = colortext.sprint)\n        self.metric_latex_objects.extend( section_latex_objs )\n\n        #### Single mutations\n        section_latex_objs = []\n        section_latex_objs.append( lr.LatexSubSection(\n            'Number of mutations',\n        ))\n        subcase_dataframe = dataframe[dataframe['NumberOfMutations'] == 1]\n        if len(subcase_dataframe) >= case_n_cutoff:\n            table_header = 'Statistics - single mutations (%d cases)' % len(subcase_dataframe)\n            list_stats = format_stats(get_xy_dataset_statistics_pandas(subcase_dataframe, experimental_field, 'Predicted', fcorrect_x_cutoff = self.stability_classication_x_cutoff, fcorrect_y_cutoff = self.stability_classication_x_cutoff, ignore_null_values = True, run_standardized_analysis = False), return_string = False)\n            section_latex_objs.append( lr.LatexTable(\n                header_row,\n                list_stats,\n                column_format = stats_column_format,\n                header_text = table_header\n            ))\n            self.add_stored_metric_to_df('single mutations', len(subcase_dataframe), list_stats)\n        subcase_dataframe = dataframe[dataframe['NumberOfMutations'] > 1]\n        if len(subcase_dataframe) >= case_n_cutoff:\n            table_header = 'Statistics - multiple mutations (%d cases)' % len(subcase_dataframe)\n            list_stats = format_stats(get_xy_dataset_statistics_pandas(subcase_dataframe, experimental_field, 'Predicted', fcorrect_x_cutoff = self.stability_classication_x_cutoff, fcorrect_y_cutoff = self.stability_classication_x_cutoff, ignore_null_values = True, run_standardized_analysis = False), return_string = False)\n            section_latex_objs.append( lr.LatexTable(\n                header_row,\n                list_stats,\n                column_format = stats_column_format,\n                header_text = table_header\n            ))\n            self.add_stored_metric_to_df('multiple mutations', len(subcase_dataframe), list_stats)\n        # subcase_dataframe = dataframe[(dataframe.NumberOfMutations >= 2) & (dataframe.NumberOfMutations <= 5)]\n        # if len(subcase_dataframe) >= case_n_cutoff:\n        #     table_header = 'Statistics - 2-4 mutations (%d cases)' % len(subcase_dataframe)\n        #     list_stats = format_stats(get_xy_dataset_statistics_pandas(subcase_dataframe, experimental_field, 'Predicted', fcorrect_x_cutoff = self.stability_classication_x_cutoff, fcorrect_y_cutoff = self.stability_classication_x_cutoff, ignore_null_values = True, run_standardized_analysis = False), return_string = False)\n        #     section_latex_objs.append( LatexTable(\n        #         header_row,\n        #         list_stats,\n        #         column_format = stats_column_format,\n        #         header_text = table_header\n        #     ))\n        #     self.add_stored_metric_to_df('2-4 mutations', len(subcase_dataframe), list_stats)\n        # mutation_cutoffs = [5, 10, 20, 50, 100, 200]\n        # for i, mutation_cutoff in enumerate(mutation_cutoffs):\n        #     if len(mutation_cutoffs) - 1 == i:\n        #         break\n        #     next_cutoff = mutation_cutoffs[i+1]\n        #     subcase_dataframe = dataframe[(dataframe.NumberOfMutations >= mutation_cutoff) & (dataframe.NumberOfMutations <= next_cutoff)]\n        #     if len(subcase_dataframe) >= case_n_cutoff:\n        #         table_header = 'Statistics - %d $<=$ number of mutations $<=$ %d (%d cases)' % (mutation_cutoff, next_cutoff, len(subcase_dataframe))\n        #         list_stats = format_stats(get_xy_dataset_statistics_pandas(subcase_dataframe, experimental_field, 'Predicted', fcorrect_x_cutoff = self.stability_classication_x_cutoff, fcorrect_y_cutoff = self.stability_classication_x_cutoff, ignore_null_values = True, run_standardized_analysis = False), return_string = False)\n        #         section_latex_objs.append( LatexTable(\n        #             header_row,\n        #             list_stats,\n        #             column_format = stats_column_format,\n        #             header_text = table_header\n        #         ))\n        #         self.add_stored_metric_to_df('%d <= mutations<= %d' % (mutation_cutoff, next_cutoff), len(subcase_dataframe), list_stats)\n        if verbose:\n            self.report('\\n'.join([x.generate_plaintext() for x in section_latex_objs]), fn = colortext.sprint)\n        self.metric_latex_objects.extend( section_latex_objs )\n        ####\n\n        #### Complete dataset (scaled)\n        if self.calculate_scalar_adjustments:\n            section_latex_objs = []\n            section_latex_objs.append( lr.LatexSubSection(\n                'Entire dataset using a scaling factor of 1/%.03f to improve the fraction correct metric.' % scalar_adjustment,\n                'Warning: Results in this section use an averaged scaling factor to improve the value for the fraction correct metric. This scalar will vary over benchmark runs so these results should not be interpreted as performance results; they should be considered as what could be obtained if the predicted values were scaled by a \"magic\" value.'\n            ))\n            table_header = 'Statistics - complete dataset (scaled) (%d cases)' % len(dataframe)\n            # For these statistics, we assume that we have reduced any scaling issues and use the same cutoff for the Y-axis as the user specified for the X-axis\n            list_stats = format_stats(get_xy_dataset_statistics_pandas(dataframe, experimental_field, BenchmarkRun.get_analysis_set_fieldname('Predicted_adj', analysis_set), fcorrect_x_cutoff = self.stability_classication_x_cutoff, fcorrect_y_cutoff = self.stability_classication_x_cutoff, ignore_null_values = True, run_standardized_analysis = False), return_string = False)\n            section_latex_objs.append( lr.LatexTable(\n                header_row,\n                list_stats,\n                column_format = stats_column_format,\n                header_text = table_header\n            ))\n            self.add_stored_metric_to_df('complete dataset (scaled)', len(dataframe), list_stats)\n            if verbose:\n                self.report('\\n'.join([x.generate_plaintext() for x in section_latex_objs]), fn = colortext.sprint)\n            self.metric_latex_objects.extend( section_latex_objs )\n        ####\n\n        section_latex_objs = []\n        section_latex_objs.append( lr.LatexSubSection(\n            'Entire dataset',\n            'Overall statistics'\n        ))\n        table_header = 'Statistics - complete dataset (%d cases)' % len(dataframe)\n        # For these statistics, we assume that we have reduced any scaling issues and use the same cutoff for the Y-axis as the user specified for the X-axis\n        list_stats = format_stats(get_xy_dataset_statistics_pandas(dataframe, experimental_field, 'Predicted', fcorrect_x_cutoff = self.stability_classication_x_cutoff, fcorrect_y_cutoff = self.stability_classication_x_cutoff, ignore_null_values = True, run_standardized_analysis = False), return_string = False)\n        section_latex_objs.append( lr.LatexTable(\n            header_row,\n            list_stats,\n            column_format = stats_column_format,\n            header_text = table_header\n        ))\n        self.add_stored_metric_to_df('complete dataset', len(dataframe), list_stats)\n        if verbose:\n            self.report('\\n'.join([x.generate_plaintext() for x in section_latex_objs]), fn = colortext.sprint)\n        self.metric_latex_objects.extend( section_latex_objs )\n\n        # There is probably a better way of writing the pandas code here\n        record_with_most_errors = (dataframe[['PDBFileID', 'NumberOfDerivativeErrors', 'Mutations']].sort_values(by = 'NumberOfDerivativeErrors')).tail(1)\n        record_index = record_with_most_errors.index.tolist()[0]\n        pdb_id, num_errors, mutation_str = dataframe.loc[record_index, 'PDBFileID'], dataframe.loc[record_index, 'NumberOfDerivativeErrors'], dataframe.loc[record_index, 'Mutations']\n        if num_errors > 0:\n            error_detection_text = '\\n\\nDerivative errors were found in the run. Record #{0} - {1}, {2} - has the most amount ({3}) of derivative errors.'.format(record_index, pdb_id, mutation_str, num_errors)\n            self.metric_latex_objects.append( lr.LatexText(error_detection_text, color = 'red') )\n            if verbose:\n                self.report(error_detection_text, fn = colortext.warning)\n\n        # Write the analysis to file\n        self.create_analysis_directory(analysis_directory)\n        self.metrics_filepath = os.path.join(self.analysis_directory, '{0}_metrics.txt'.format(self.benchmark_run_name))\n        write_file(self.metrics_filepath, '\\n'.join([x.generate_plaintext() for x in self.metric_latex_objects]))", "response": "Calculates the main metrics for the benchmark run and writes them to file and LaTeX object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef determine_optimum_fraction_correct_cutoffs(self, analysis_set, dataframe, stability_classication_x_cutoff):\n        '''Determines the value of stability_classication_y_cutoff which approximately maximizes the fraction correct\n           measurement w.r.t. a fixed stability_classication_x_cutoff. This function uses discrete sampling and so it\n           may miss the actual maximum. We use two rounds of sampling: i) a coarse-grained sampling (0.1 energy unit\n           intervals); and ii) finer sampling (0.01 unit intervals).\n           In both rounds, we choose the one corresponding to a lower value for the cutoff in cases of multiple maxima.'''\n\n        # Determine the value for the fraction correct y-value (predicted) cutoff which will approximately yield the\n        # maximum fraction-correct value\n\n        fraction_correct_range = []\n        experimental_field = BenchmarkRun.get_analysis_set_fieldname('Experimental', analysis_set)\n\n        # Round 1 : Coarse sampling. Test 0.5 -> 8.0 in 0.1 increments\n        for z in range(5, 80):\n            w = float(z) / 10.0\n            fraction_correct_range.append((w, fraction_correct_pandas(dataframe, experimental_field, 'Predicted', x_cutoff = stability_classication_x_cutoff, y_cutoff = w, ignore_null_values = True)))\n\n        max_value_cutoff, max_value = fraction_correct_range[0][0], fraction_correct_range[0][1]\n        for p in fraction_correct_range:\n            if p[1] > max_value:\n                max_value_cutoff, max_value = p[0], p[1]\n\n        # Round 2 : Finer sampling. Test max_value_cutoff - 0.1 -> max_value_cutoff + 0.1 in 0.01 increments\n        for z in range(int((max_value_cutoff - 0.1) * 100), int((max_value_cutoff + 0.1) * 100)):\n            w = float(z) / 100.0\n            fraction_correct_range.append((w, fraction_correct_pandas(dataframe, experimental_field, 'Predicted', x_cutoff = stability_classication_x_cutoff, y_cutoff = w, ignore_null_values = True)))\n        fraction_correct_range = sorted(set(fraction_correct_range)) # sort so that we find the lowest cutoff value in case of duplicate fraction correct values\n        max_value_cutoff, max_value = fraction_correct_range[0][0], fraction_correct_range[0][1]\n        for p in fraction_correct_range:\n            if p[1] > max_value:\n                max_value_cutoff, max_value = p[0], p[1]\n\n        return max_value_cutoff, max_value, fraction_correct_range", "response": "Determines the value of stability_classication_y_cutoff which approximately maximizes the fraction correct\n           measurement w. r. t. a fixed stability_classication_x_cutoff."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef plot_optimum_prediction_fraction_correct_cutoffs_over_range(self, analysis_set, min_stability_classication_x_cutoff, max_stability_classication_x_cutoff, suppress_plot = False, analysis_file_prefix = None, verbose = True):\n        '''Plots the optimum cutoff for the predictions to maximize the fraction correct metric over a range of experimental cutoffs.\n           Returns the average scalar corresponding to the best value of fraction correct over a range of cutoff values for the experimental cutoffs.'''\n\n        # Filenames\n        analysis_set_prefix = ''\n        #if analysis_set:\n        #    analysis_set_prefix = '_{0}'.format(analysis_set)\n        plot_filename = None\n        if not suppress_plot:\n            output_filename_prefix = '{0}{1}optimum_fraction_correct_at_varying_kcal_mol'.format(analysis_file_prefix, analysis_set_prefix)\n            plot_filename = output_filename_prefix + '.png'\n            csv_filename = output_filename_prefix + '.txt'\n\n        # Create CSV input\n        lines = ['ExperimentalCutoff,BestPredictionCutoff']\n        x_cutoff = min_stability_classication_x_cutoff\n        x_values = []\n        y_values = []\n        avg_scale = 0\n        plot_graph = self.generate_plots and not(suppress_plot)\n        while x_cutoff < max_stability_classication_x_cutoff + 0.1:\n            max_value_cutoff, max_value, fraction_correct_range = self.determine_optimum_fraction_correct_cutoffs(analysis_set, self.dataframe, x_cutoff)\n            if plot_graph:\n                lines.append(','.join(map(str, (x_cutoff, max_value_cutoff))))\n            x_values.append(x_cutoff)\n            y_values.append(max_value_cutoff)\n            avg_scale += max_value_cutoff / x_cutoff\n            x_cutoff += 0.1\n\n        if plot_graph:\n            write_file(csv_filename, '\\n'.join(lines))\n\n        # Determine the average scalar needed to fit the plot\n        avg_scale = avg_scale / len(x_values)\n        x_values = numpy.array(x_values)\n        y_values = numpy.array(y_values)\n        scalars = y_values / x_values\n        average_scalar = numpy.mean(scalars)\n        plot_label_1 = 'Scalar == %0.2f' % average_scalar\n        plot_label_2 = 'sigma == %0.2f' % numpy.std(scalars)\n\n        # Create plot\n        if plot_graph:\n            if not(os.path.exists(plot_filename) and not(self.recreate_graphs)):\n                if verbose:\n                    self.log('Saving scatterplot to %s.' % plot_filename)\n                    self.log('Saving plot of approximate optimal fraction correct cutoffs over varying experimental cutoffs to %s.' % plot_filename)\n\n                title = 'Optimum cutoff for fraction correct metric at varying experimental cutoffs'\n                if analysis_set:\n                    title += ' for {0}'.format(analysis_set)\n                r_script = '''library(ggplot2)\nlibrary(gridExtra)\nlibrary(scales)\nlibrary(qualV)\n\npng('%(plot_filename)s', height=4096, width=4096, bg=\"white\", res=600)\nplot_data <- read.csv('%(csv_filename)s', header=T)\n\nmax_y = max(plot_data$BestPredictionCutoff)\np <- ggplot(data = plot_data, aes(x = ExperimentalCutoff, y = BestPredictionCutoff)) +\n xlab(\"Experimental cutoff (kcal/mol)\") +\n ylab(\"Optimal prediction cutoff (energy units)\") +\n ggtitle(\"%(title)s\") +\n geom_point() +\n geom_line() +\n geom_smooth() +\n geom_text(hjust=0, size=4, color=\"black\", aes(0.5, max_y, fontface=\"plain\", family = \"sans\", label=\"%(plot_label_1)s\"), parse = T) +\n geom_text(hjust=0, size=4, color=\"black\", aes(0.5, max_y - 0.5, fontface=\"plain\", family = \"sans\", label=\"%(plot_label_2)s\"), parse = T)\np\ndev.off()'''\n                RInterface._runRScript(r_script % locals())\n\n        return average_scalar, plot_filename", "response": "Plots the optimum cutoff for the predictions to maximize the fraction correct metric over a range of experimental cutoffs."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef scatterplot_charges(self, title, csv_filename, analysis_set = ''):\n        '''Scatterplot by residue charge.'''\n\n        # Create CSV input\n        new_dataframe = self.dataframe.copy()\n        experimental_field = BenchmarkRun.get_analysis_set_fieldname('Experimental', analysis_set)\n        new_dataframe = new_dataframe[[experimental_field, 'Predicted', 'ResidueCharges']]\n        new_dataframe['Opacity'] = 0.4\n        new_dataframe = new_dataframe.dropna(subset = [experimental_field, 'Predicted'])\n        new_dataframe.to_csv(csv_filename, sep = ',', header = True)\n\n        plot_scale = '''\nplot_scale <- scale_color_manual(\n    values = c( \"None\" = '#777777', \"Change\" = '%(cornflower_blue)s', \"Polar/Charged\" = 'magenta', \"Hydrophobic/Non-polar\" = 'green'),\n    labels = c( \"None\" = \"N/A\", \"Change\" = \"Change\", \"Polar/Charged\" = \"Polar/Charged\", \"Hydrophobic/Non-polar\" = \"Hydrophobic/Non-polar\"))''' % plot_colors\n        return self.scatterplot_color_by_series(xseries = experimental_field, colorseries = \"ResidueCharges\", title = title, plot_scale = plot_scale, point_opacity = 0.6, analysis_set = analysis_set)", "response": "Scatterplot by residue charge."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_this_record_a_derived_mutation(self, record):\n        '''Returns True if a record is marked as a derived record i.e. the DDG value is calculated from one source (\"reverse\"\n           mutation) or two sources (a \"mutation triangle\") without a separate experiment having taken place. This property\n           is marked in the Kortemme lab database when we have determined that this is indeed the case. Otherwise, return\n           False.\n           For purely computational dataframes, we should always return False.'''\n        if self.contains_experimental_data:\n            for analysis_set in self.get_analysis_sets(record):\n                ddg_details = record['DDG'][analysis_set]\n                if ddg_details and ddg_details['IsDerivedValue']:\n                    return True\n            return False\n        else:\n            # Computational dataframe case\n            return False", "response": "Returns True if a record is marked as a derived record i. e. the DDG value is calculated from one source or two sources with a separate experiment having taken place."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_experimental_ddg_values(self, record, dataframe_record):\n        '''Adds the mean experimental value associated with each analysis set to the dataframe row.'''\n        new_idxs = []\n        for analysis_set in self.get_analysis_sets(record):\n            ddg_details = record['DDG'][analysis_set]\n            exp_ddg_fieldname = BenchmarkRun.get_analysis_set_fieldname('Experimental', analysis_set)\n            new_idxs.append(exp_ddg_fieldname)\n            dataframe_record[exp_ddg_fieldname] = None\n            if ddg_details:\n                dataframe_record[exp_ddg_fieldname] = ddg_details['MeanDDG']\n\n        # Update the CSV headers\n        try:\n            idx = self.csv_headers.index('Experimental')\n            self.csv_headers = self.csv_headers[:idx] + new_idxs + self.csv_headers[idx + 1:]\n        except ValueError, e: pass", "response": "Adds the mean experimental value associated with each analysis set to the dataframe row."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef compute_stability_classification(self, predicted_data, record, dataframe_record):\n        '''Calculate the stability classification for the analysis cases. Must be called after get_experimental_ddg_values.'''\n\n        new_idxs = []\n        stability_classication_x_cutoff, stability_classication_y_cutoff = self.stability_classication_x_cutoff, self.stability_classication_y_cutoff\n        for analysis_set in self.get_analysis_sets(record):\n            ddg_details = record['DDG'][analysis_set]\n            exp_ddg_fieldname = BenchmarkRun.get_analysis_set_fieldname('Experimental', analysis_set)\n            stability_classification_fieldname = BenchmarkRun.get_analysis_set_fieldname('StabilityClassification', analysis_set)\n            new_idxs.append(stability_classification_fieldname)\n            dataframe_record[stability_classification_fieldname] = None\n\n            if ddg_details:\n                stability_classification = None\n                if dataframe_record[exp_ddg_fieldname] != None:\n                    stability_classification = fraction_correct([dataframe_record[exp_ddg_fieldname]], [predicted_data[self.ddg_analysis_type]], x_cutoff = stability_classication_x_cutoff, y_cutoff = stability_classication_y_cutoff)\n                    stability_classification = int(stability_classification)\n                    assert(stability_classification == 0 or stability_classification == 1)\n                dataframe_record[stability_classification_fieldname] = stability_classification\n\n        # Update the CSV headers\n        try:\n            idx = self.csv_headers.index('StabilityClassification')\n            self.csv_headers = self.csv_headers[:idx] + new_idxs + self.csv_headers[idx + 1:]\n        except ValueError, e: pass", "response": "Calculate the stability classification for the analysis cases. Must be called after get_experimental_ddg_values."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate the absolute error for the analysis cases. Must be called after get_experimental_ddg_values.", "response": "def compute_absolute_error(self, predicted_data, record, dataframe_record):\n        '''Calculate the absolute error for the analysis cases. Must be called after get_experimental_ddg_values.'''\n\n        new_idxs = []\n        for analysis_set in self.get_analysis_sets(record):\n            ddg_details = record['DDG'][analysis_set]\n            exp_ddg_fieldname = BenchmarkRun.get_analysis_set_fieldname('Experimental', analysis_set)\n            absolute_error_fieldname = BenchmarkRun.get_analysis_set_fieldname('AbsoluteError', analysis_set)\n            new_idxs.append(absolute_error_fieldname)\n            dataframe_record[absolute_error_fieldname] = None\n\n            if ddg_details and predicted_data[self.ddg_analysis_type] != None:\n                absolute_error = abs(dataframe_record[exp_ddg_fieldname] - predicted_data[self.ddg_analysis_type])\n                dataframe_record[absolute_error_fieldname] = absolute_error\n\n        # Update the CSV headers\n        try:\n            idx = self.csv_headers.index('AbsoluteError')\n            self.csv_headers = self.csv_headers[:idx] + new_idxs + self.csv_headers[idx + 1:]\n        except ValueError, e: pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_result(self, values):\r\n        idx = [values['host']]\r\n        for gid in self.key_gids[1:]:\r\n            idx.append(values[gid])\r\n        idx = tuple(idx)\r\n\r\n        try:\r\n            self.results[idx] += 1\r\n        except KeyError:\r\n            self.results[idx] = 1\r\n        self._last_idx = idx", "response": "Add a tuple or increment the value of an existing one\r\n            in the rule results dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef increase_last(self, k):\r\n        idx = self._last_idx\r\n        if idx is not None:\r\n            self.results[idx] += k", "response": "Increase the last result by k."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef total_events(self, cond, valfld=None):\r\n        results = self.results\r\n\r\n        if cond == \"*\" and valfld is None:\r\n            return sum(results.values())\r\n        val = self.key_gids.index(valfld) if valfld is not None else None\r\n\r\n        if cond == \"*\":\r\n            tot = 0\r\n            for key in results:\r\n                tot += results[key] * int(key[val])\r\n            return tot\r\n            \r\n        match = re.search(\"(\\w+)(!=|==)\\\"([^\\\"]*)\\\"\", cond)\r\n        condpos = self.key_gids.index(match.group(1))\r\n        invert = (match.group(2) == '!=')\r\n        recond = re.compile(match.group(3))\r\n\r\n        tot = 0\r\n        for key in results:\r\n            match = recond.search(key[condpos])\r\n            if (not invert and match is not None) or (invert and match is None):\r\n                if valfld is None:\r\n                    tot += results[key]\r\n                else:\r\n                    tot += results[key] * int(key[val])\r\n        return tot", "response": "Returns the total number of events in the rule s result set. A condition could be provided to select the events to count. A value field can be provided to select the events to count."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef top_events(self, num, valfld, usemax, gid):\r\n        def classify():\r\n            if value is None:\r\n                return\r\n\r\n            for j in range(num):\r\n                if top[j] is None:\r\n                    top[j] = [tot, [value]]\r\n                    break\r\n                elif tot == top[j][0]:\r\n                    top[j][1].append(value)\r\n                    break\r\n                elif tot > top[j][0]:\r\n                    top.insert(j, [tot, [value]])\r\n                    break\r\n\r\n        if not self.results:\r\n            return []\r\n\r\n        results = self.results\r\n        top = [None] * num\r\n        pos = self.key_gids.index(gid)\r\n\r\n        # Compute top(max) if a value fld is provided\r\n        if valfld is not None:\r\n            val = self.key_gids.index(valfld)\r\n            if usemax:\r\n                i = 0 \r\n                for key in sorted(results.keys(), key=lambda x: (int(x[val]), x[pos]),\r\n                                  reverse=True)[:num]:\r\n                    top[i] = [int(key[val]), [key[pos]]]\r\n                    i += 1\r\n                return [res for res in top if res is not None]\r\n                \r\n        value = None\r\n        tot = 0\r\n        for key in sorted(results.keys(), key=lambda x: (x[pos])):\r\n            if value is None or value != key[pos]:\r\n                classify()\r\n                value = key[pos]\r\n                tot = results[key] if valfld is None else results[key] * int(key[val])\r\n                continue\r\n            tot += results[key] if valfld is None else results[key] * int(key[val])\r\n        else:\r\n            classify()\r\n\r\n        del top[num:]\r\n        return [res for res in top if res is not None]", "response": "Returns a list with the top NUM list of events. Each list element contains a value indicating the number of events and a list of occurrences of a value field matching the value field with events."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the list of events that match the condition and the specified fields.", "response": "def list_events(self, cond, cols, fields):\r\n        \"\"\"\r\n        Return the list of events, with a specific order and filtered by a condition.\r\n        An element of the list is a tuple with three component. The first is the main\r\n        attribute (first field). The second the second field/label, usually a string\r\n        that identify the service. The third is a dictionary with a key-tuple composed\r\n        by all other fields and values indicating the number of events associated.\r\n        \"\"\"\r\n\r\n        def insert_row():\r\n            \"\"\"\r\n            Internal function to flush results for a single tabkey to result list.\r\n            \"\"\"\r\n            row = list(row_template)\r\n            j = 0\r\n            for n in range(cols):\r\n                if row[n] is None:\r\n                    if j == keylen:\r\n                        row[n] = tabvalues\r\n                    else:\r\n                        row[n] = tabkey[j]\r\n                    j += 1\r\n            reslist.append(row)\r\n\r\n        if not self.results:\r\n            return []\r\n\r\n        # Set local variables\r\n        results = self.results\r\n        pos = [self.key_gids.index(gid) for gid in fields if gid[0] != '\"']\r\n        has_cond = cond != \"*\"\r\n\r\n        # If a condition is passed then compile a pattern matching object\r\n        if has_cond:\r\n            match = re.search(\"(\\w+)(!=|==)\\\"([^\\\"]*)\\\"\", cond)\r\n            condpos = self.key_gids.index(match.group(1))\r\n            invert = (match.group(2) == '!=')\r\n            recond = re.compile(match.group(3))\r\n        else:\r\n            recond = condpos = None\r\n\r\n        # Define the row template with places for values and fixed strings\r\n        row_template = []\r\n        for i in range(cols):\r\n            if fields[i][0] == '\"':\r\n                row_template.append(fields[i].strip('\"'))\r\n            else:\r\n                row_template.append(None)\r\n\r\n        # Set the processing table and reduced key length\r\n        keylen = len(pos) - (len(fields) - cols) - 1\r\n        tabvalues = dict()\r\n        tabkey = None\r\n\r\n        reslist = []\r\n        for key in sorted(results, key=lambda x: x[pos[0]]):\r\n            # Skip results that don't satisfy the condition\r\n            if has_cond:\r\n                try:\r\n                    match = recond.search(key[condpos])\r\n                except TypeError:\r\n                    continue\r\n                if ((match is None) and not invert) or ((match is not None) and invert):\r\n                    continue\r\n\r\n            new_tabkey = [key[pos[i]] for i in range(keylen)]\r\n            if tabkey is None:\r\n                tabkey = new_tabkey\r\n            elif tabkey != new_tabkey:\r\n                insert_row()\r\n                tabvalues = dict()\r\n                tabkey = [key[pos[i]] for i in range(keylen)]\r\n\r\n            value = tuple([key[k] for k in pos[keylen:]])\r\n            if value in tabvalues:\r\n                tabvalues[value] += results[key]\r\n            else:\r\n                tabvalues[value] = results[key]\r\n\r\n        if tabvalues:\r\n            insert_row()\r\n        return reslist"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_rules(self):\r\n        # Load patterns: an app is removed when has no defined patterns.\r\n        try:\r\n            rule_options = self.config.items('rules')\r\n        except configparser.NoSectionError:\r\n            raise LogRaptorConfigError(\"the app %r has no defined rules!\" % self.name)\r\n\r\n        rules = []\r\n        for option, value in rule_options:\r\n            pattern = value.replace('\\n', '')  # Strip newlines for multi-line declarations\r\n            if not self.args.filters:\r\n                # No filters case: substitute the filter fields with the corresponding patterns.\r\n                pattern = string.Template(pattern).safe_substitute(self.fields)\r\n                rules.append(AppRule(option, pattern, self.args))\r\n                continue\r\n\r\n            for filter_group in self.args.filters:\r\n                _pattern, filter_keys = exact_sub(pattern, filter_group)\r\n                _pattern = string.Template(_pattern).safe_substitute(self.fields)\r\n                if len(filter_keys) >= len(filter_group):\r\n                    rules.append(AppRule(option, _pattern, self.args, filter_keys))\r\n                elif self._thread:\r\n                    rules.append(AppRule(option, _pattern, self.args))\r\n        return rules", "response": "Parse the rules from the config file and return a list of rules."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nincreases the counter of the last matched rule by k.", "response": "def increase_last(self, k):\r\n        \"\"\"\r\n        Increase the counter of the last matched rule by k.\r\n        \"\"\"\r\n        rule = self._last_rule\r\n        if rule is not None:\r\n            rule.increase_last(k)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprocess a log line data message with app s pattern rules.", "response": "def match_rules(self, log_data):\r\n        \"\"\"\r\n        Process a log line data message with app's pattern rules.\r\n        Return a tuple with this data:\r\n\r\n            Element #0 (app_matched): True if a rule match, False otherwise;\r\n            Element #1 (has_full_match): True if a rule match and is a filter or the\r\n                app has not filters; False if a rule match but is not a filter;\r\n                None otherwise;\r\n            Element #2 (app_thread): Thread value if a rule match and it has a \"thread\"\r\n                group, None otherwise;\r\n            Element #3 (output_data): Mapping dictionary if a rule match and a map\r\n                of output is requested (--anonymize/--ip/--uid options).\r\n        \"\"\"\r\n        for rule in self.rules:\r\n            match = rule.regexp.search(log_data.message)\r\n            if match is not None:\r\n                gids = rule.regexp.groupindex\r\n                self._last_rule = rule\r\n                if self.name_cache is not None:\r\n                    values = self.name_cache.match_to_dict(match, rule.key_gids)\r\n                    values['host'] = self.name_cache.map_value(log_data.host, 'host')\r\n                    output_data = {\r\n                        'host': values['host'],\r\n                        'message': self.name_cache.match_to_string(match, gids, values),\r\n                    }\r\n                else:\r\n                    values = {'host': log_data.host}\r\n                    for gid in gids:\r\n                        values[gid] = match.group(gid)\r\n                    output_data = None\r\n\r\n                if self._thread and 'thread' in rule.regexp.groupindex:\r\n                    thread = match.group('thread')\r\n                    if rule.filter_keys is not None and \\\r\n                            any([values[key] is None for key in rule.filter_keys]):\r\n                        return False, None, None, None\r\n                    if self._report:\r\n                        rule.add_result(values)\r\n                    return True, rule.full_match, thread, output_data\r\n                else:\r\n                    if rule.filter_keys is not None and \\\r\n                            any([values[key] is None for key in rule.filter_keys]):\r\n                        return False, None, None, None\r\n                    elif self._report or (rule.filter_keys is not None or not self.has_filters):\r\n                        rule.add_result(values)\r\n                    return True, rule.full_match, None, output_data\r\n\r\n        # No rule match: the application log message is not parsable with enabled rules.\r\n        self._last_rule = None\r\n        return False, None, None, None"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a single structure PSE file for the scaffold model and design structures. Returns this session and the script which generated it.", "response": "def create_single_structure_pse(structure_name, structure_content, residue_ids_of_interest, pymol_executable = 'pymol', settings = {}):\n    ''' Generates the PyMOL session for the scaffold, model, and design structures.\n        Returns this session and the script which generated it.'''\n    b = BatchBuilder(pymol_executable = pymol_executable)\n    PSE_files = b.run(SingleStructureBuilder, [{structure_name : PDBContainer(structure_name, structure_content, residue_ids_of_interest)}], settings = settings)\n    return PSE_files[0], b.PSE_scripts[0]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of uw_sws. models. SectionReference objects for the passed person and term.", "response": "def get_sections_by_delegate_and_term(person,\n                                      term,\n                                      future_terms=0,\n                                      include_secondaries=True,\n                                      transcriptable_course='yes',\n                                      delete_flag=['active']):\n    \"\"\"\n    Returns a list of uw_sws.models.SectionReference objects\n    for the passed grade submission delegate and term.\n    @param: future_terms: 0..400\n    @param: transcriptable_course: 'yes', 'no', 'all'\n    @param: delete_flag: ['active', 'suspended', 'withdrawn']\n    \"\"\"\n    data = _get_sections_by_person_and_term(person,\n                                            term,\n                                            \"GradeSubmissionDelegate\",\n                                            include_secondaries,\n                                            future_terms,\n                                            transcriptable_course,\n                                            delete_flag)\n    return _json_to_sectionref(data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of uw_sws. models. SectionReference objects for the passed curriculum and term.", "response": "def get_sections_by_curriculum_and_term(curriculum, term):\n    \"\"\"\n    Returns a list of uw_sws.models.SectionReference objects\n    for the passed curriculum and term.\n    \"\"\"\n    url = \"{}?{}\".format(\n        section_res_url_prefix,\n        urlencode([(\"curriculum_abbreviation\", curriculum.label,),\n                   (\"quarter\", term.quarter.lower(),),\n                   (\"year\", term.year,), ]))\n    return _json_to_sectionref(get_resource(url))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of uw_sws. models. SectionReference objects for the passed building and term.", "response": "def get_sections_by_building_and_term(building, term):\n    \"\"\"\n    Returns a list of uw_sws.models.SectionReference objects\n    for the passed building and term.\n    \"\"\"\n    url = \"{}?{}\".format(\n        section_res_url_prefix,\n        urlencode([(\"quarter\", term.quarter.lower(),),\n                   (\"facility_code\", building,),\n                   (\"year\", term.year,), ]))\n    return _json_to_sectionref(get_resource(url))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _json_to_sectionref(data):\n    section_term = None\n    sections = []\n    for section_data in data.get(\"Sections\", []):\n        if (section_term is None or\n                section_data[\"Year\"] != section_term.year or\n                section_data[\"Quarter\"] != section_term.quarter):\n            section_term = get_term_by_year_and_quarter(\n                section_data[\"Year\"], section_data[\"Quarter\"])\n        section = SectionReference(\n            term=section_term,\n            curriculum_abbr=section_data[\"CurriculumAbbreviation\"],\n            course_number=section_data[\"CourseNumber\"],\n            section_id=section_data[\"SectionID\"],\n            url=section_data[\"Href\"])\n        sections.append(section)\n    return sections", "response": "Returns a list of SectionReference objects created from the passed json data."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the response data for a search request containing the passed person and term.", "response": "def _get_sections_by_person_and_term(person,\n                                     term,\n                                     course_role,\n                                     include_secondaries,\n                                     future_terms,\n                                     transcriptable_course,\n                                     delete_flag):\n    \"\"\"\n    Returns the response data for a search request containing the\n    passed course_role and term (including secondaries).\n    @param: future_terms: 0..400\n    @param: transcriptable_course: 'yes', 'no', 'all'\n    @param: delete_flag: ['active', 'suspended', 'withdrawn']\n    \"\"\"\n    params = [\n        (\"reg_id\", person.uwregid,),\n        (\"search_by\", course_role,),\n        (\"quarter\", term.quarter.lower(),),\n        (\"include_secondaries\", 'on' if include_secondaries else ''),\n        (\"year\", term.year,),\n        (\"future_terms\", future_terms,),\n        (\"transcriptable_course\", transcriptable_course,),\n    ]\n\n    if delete_flag is not None:\n        if not isinstance(delete_flag, list):\n            raise ValueError(\"delete_flag must be a list\")\n        params.append((\"delete_flag\", ','.join(sorted(delete_flag)),))\n\n    url = \"{}?{}\".format(section_res_url_prefix, urlencode(params))\n    return get_resource(url)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a uw_sws. models. Section object for the passed url.", "response": "def get_section_by_url(url,\n                       include_instructor_not_on_time_schedule=True):\n    \"\"\"\n    Returns a uw_sws.models.Section object\n    for the passed section url.\n    \"\"\"\n    if not course_url_pattern.match(url):\n        raise InvalidSectionURL(url)\n\n    return _json_to_section(\n        get_resource(url),\n        include_instructor_not_on_time_schedule=(\n            include_instructor_not_on_time_schedule))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_section_by_label(label,\n                         include_instructor_not_on_time_schedule=True):\n    \"\"\"\n    Returns a uw_sws.models.Section object for\n    the passed section label.\n    \"\"\"\n    validate_section_label(label)\n\n    url = \"{}/{}.json\".format(course_res_url_prefix,\n                              encode_section_label(label))\n\n    return get_section_by_url(url,\n                              include_instructor_not_on_time_schedule)", "response": "Returns a uw_sws. models. Section object for the passed section label."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_linked_sections(section,\n                        include_instructor_not_on_time_schedule=True):\n    \"\"\"\n    Returns a list of uw_sws.models.Section objects,\n    representing linked sections for the passed section.\n    \"\"\"\n    linked_sections = []\n\n    for url in section.linked_section_urls:\n        section = get_section_by_url(url,\n                                     include_instructor_not_on_time_schedule)\n        linked_sections.append(section)\n\n    return linked_sections", "response": "Returns a list of uw_sws. models. Section objects representing linked sections for the passed section."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a list of uw_sws. models. Section objects representing joint sections for the passed section.", "response": "def get_joint_sections(section,\n                       include_instructor_not_on_time_schedule=True):\n    \"\"\"\n    Returns a list of uw_sws.models.Section objects,\n    representing joint sections for the passed section.\n    \"\"\"\n    joint_sections = []\n\n    for url in section.joint_section_urls:\n        section = get_section_by_url(url,\n                                     include_instructor_not_on_time_schedule)\n        joint_sections.append(section)\n\n    return joint_sections"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_prefetch_for_section_data(section_data):\n    prefetch = []\n    for meeting_data in section_data[\"Meetings\"]:\n        for instructor_data in meeting_data[\"Instructors\"]:\n            pdata = instructor_data[\"Person\"]\n            if \"RegID\" in pdata and pdata[\"RegID\"] is not None:\n                prefetch.append([\"person-{}\".format(pdata[\"RegID\"]),\n                                 generic_prefetch(UWPWS.get_person_by_regid,\n                                                  [pdata[\"RegID\"]])])\n\n    return prefetch", "response": "This function returns a list of methods that can be called to prefetch the content of the given section."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a new object for the passed json.", "response": "def _json_to_section(section_data,\n                     term=None,\n                     include_instructor_not_on_time_schedule=True):\n    \"\"\"\n    Returns a section model created from the passed json.\n    \"\"\"\n    section = Section()\n    if term is not None and (\n            term.year == int(section_data[\"Course\"][\"Year\"]) and\n            term.quarter == section_data[\"Course\"][\"Quarter\"]):\n        section.term = term\n    else:\n        section.term = get_term_by_year_and_quarter(\n            section_data[\"Course\"][\"Year\"],\n            section_data[\"Course\"][\"Quarter\"])\n\n    section.curriculum_abbr = section_data[\"Course\"][\n        \"CurriculumAbbreviation\"]\n    section.course_number = section_data[\"Course\"][\"CourseNumber\"]\n    section.course_title = section_data[\"CourseTitle\"]\n    section.course_title_long = section_data[\"CourseTitleLong\"]\n    section.course_campus = section_data[\"CourseCampus\"]\n    section.course_description = section_data[\"CourseDescription\"]\n    section.section_id = section_data[\"SectionID\"]\n    section.eos_cid = section_data.get(\"EOS_CID\", None)\n    section.institute_name = section_data.get(\"InstituteName\", \"\")\n    section.metadata = section_data.get(\"Metadata\", \"\")\n    section.primary_lms = section_data.get(\"PrimaryLMS\", None)\n    section.lms_ownership = section_data.get(\"LMSOwnership\", None)\n    section.is_independent_start = section_data.get(\"IsIndependentStart\",\n                                                    False)\n    section.section_type = section_data[\"SectionType\"]\n    if \"independent study\" == section.section_type or\\\n       \"IS\" == section.section_type:\n        is_independent_study = True\n    else:\n        is_independent_study = False\n\n    section.is_independent_study = section_data.get(\n        \"IndependentStudy\", is_independent_study)\n\n    section.credit_control = section_data.get(\"CreditControl\", \"\")\n\n    if \"StartDate\" in section_data and\\\n       len(section_data[\"StartDate\"]) > 0:\n        section.start_date = parse(section_data[\"StartDate\"]).date()\n\n    if \"EndDate\" in section_data and\\\n       len(section_data[\"EndDate\"]) > 0:\n        section.end_date = parse(section_data[\"EndDate\"]).date()\n\n    section.class_website_url = section_data[\"ClassWebsiteUrl\"]\n\n    if is_valid_sln(section_data[\"SLN\"]):\n        section.sln = int(section_data[\"SLN\"])\n    else:\n        section.sln = 0\n\n    if \"SummerTerm\" in section_data:\n        section.summer_term = section_data[\"SummerTerm\"]\n    else:\n        section.summer_term = \"\"\n\n    section.delete_flag = section_data[\"DeleteFlag\"]\n    section.current_enrollment = int(section_data['CurrentEnrollment'])\n    section.limit_estimate_enrollment = int(\n        section_data['LimitEstimateEnrollment'])\n    section.limit_estimate_enrollment_indicator = section_data[\n        'LimitEstimateEnrollmentIndicator']\n\n    section.auditors = int(section_data['Auditors'])\n    section.allows_secondary_grading = section_data[\"SecondaryGradingOption\"]\n\n    primary_section = section_data[\"PrimarySection\"]\n    if (primary_section is not None and\n            primary_section[\"SectionID\"] != section.section_id):\n        section.is_primary_section = False\n        section.primary_section_href = primary_section[\"Href\"]\n        section.primary_section_id = primary_section[\"SectionID\"]\n        section.primary_section_curriculum_abbr = primary_section[\n            \"CurriculumAbbreviation\"]\n        section.primary_section_course_number = primary_section[\n            \"CourseNumber\"]\n    else:\n        section.is_primary_section = True\n\n    section.linked_section_urls = []\n    for linked_section_type in section_data[\"LinkedSectionTypes\"]:\n        for linked_section_data in linked_section_type[\"LinkedSections\"]:\n            url = linked_section_data[\"Section\"][\"Href\"]\n            section.linked_section_urls.append(url)\n\n    section.joint_section_urls = []\n    for joint_section_data in section_data.get(\"JointSections\", []):\n        url = joint_section_data[\"Href\"]\n        section.joint_section_urls.append(url)\n\n    section.grading_system = section_data['GradingSystem']\n    section.grade_submission_delegates = []\n    for del_data in section_data[\"GradeSubmissionDelegates\"]:\n        delegate = GradeSubmissionDelegate(\n            person=UWPWS.get_person_by_regid(del_data[\"Person\"][\"RegID\"]),\n            delegate_level=del_data[\"DelegateLevel\"])\n        section.grade_submission_delegates.append(delegate)\n\n    section.meetings = []\n    for meeting_data in section_data[\"Meetings\"]:\n        meeting = SectionMeeting()\n        meeting.section = section\n        meeting.term = section.term\n        meeting.meeting_index = meeting_data[\"MeetingIndex\"]\n        meeting.meeting_type = meeting_data[\"MeetingType\"]\n\n        meeting.building = meeting_data[\"Building\"]\n        if meeting_data[\"BuildingToBeArranged\"]:\n            meeting.building_to_be_arranged = True\n        else:\n            meeting.building_to_be_arranged = False\n\n        meeting.room_number = meeting_data[\"RoomNumber\"]\n        if meeting_data[\"RoomToBeArranged\"]:\n            meeting.room_to_be_arranged = True\n        else:\n            meeting.room_to_be_arranged = False\n\n        if meeting_data[\"DaysOfWeekToBeArranged\"]:\n            meeting.days_to_be_arranged = True\n        else:\n            meeting.days_to_be_arranged = False\n\n        for day_data in meeting_data[\"DaysOfWeek\"][\"Days\"]:\n            attribute = \"meets_{}\".format(day_data[\"Name\"].lower())\n            setattr(meeting, attribute, True)\n\n        if (len(meeting_data[\"StartTime\"]) and\n                meeting_data[\"StartTime\"] != \"00:00:00\"):\n            meeting.start_time = meeting_data[\"StartTime\"]\n            # in case of \"18:00:00\", only keep hh:mm\n            if len(meeting.start_time) > 5:\n                meeting.start_time = meeting.start_time[:5]\n\n        if (len(meeting_data[\"EndTime\"]) and\n                meeting_data[\"EndTime\"] != \"00:00:00\"):\n            meeting.end_time = meeting_data[\"EndTime\"]\n            if len(meeting.end_time) > 5:\n                meeting.end_time = meeting.end_time[:5]\n\n        if (meeting_data.get(\"EOS_StartDate\", None) and\n                meeting_data.get(\"EOS_EndDate\", None)):\n            meeting.eos_start_date = parse(\n                meeting_data[\"EOS_StartDate\"]).date()\n            meeting.eos_end_date = parse(\n                meeting_data[\"EOS_EndDate\"]).date()\n\n        meeting.instructors = []\n        for instructor_data in meeting_data[\"Instructors\"]:\n            # TSPrint: True\n            # Instructor information currently listed on the Time Schedule\n            if (instructor_data[\"TSPrint\"] or\n                    include_instructor_not_on_time_schedule):\n                pdata = instructor_data[\"Person\"]\n\n                if \"RegID\" in pdata and pdata[\"RegID\"] is not None:\n                    try:\n                        instructor = UWPWS.get_person_by_regid(pdata[\"RegID\"])\n                    except Exception:\n                        instructor = Person(uwregid=pdata[\"RegID\"],\n                                            display_name=pdata[\"Name\"])\n                    instructor.TSPrint = instructor_data[\"TSPrint\"]\n                    meeting.instructors.append(instructor)\n\n        section.meetings.append(meeting)\n\n    section.final_exam = None\n    if \"FinalExam\" in section_data and section_data[\"FinalExam\"] is not None:\n        if \"MeetingStatus\" in section_data[\"FinalExam\"]:\n            final_exam = FinalExam()\n            final_data = section_data[\"FinalExam\"]\n            status = final_data[\"MeetingStatus\"]\n            # MeetingStatus values:\n            # 0 - default final exam meeting date/time has not been confirmed\n            # 1 - no final exam or no traditional final exam\n            # 2 - confirmed, at the default final exam date/time/location\n            # 3 - confirmed, but at a different date/time/location\n\n            final_exam.no_exam_or_nontraditional = False\n            final_exam.is_confirmed = False\n\n            if (status == \"2\") or (status == \"3\"):\n                final_exam.is_confirmed = True\n            elif status == \"1\":\n                final_exam.no_exam_or_nontraditional = True\n\n            final_exam.building = final_data[\"Building\"]\n            final_exam.room_number = final_data[\"RoomNumber\"]\n\n            final_format = \"%Y-%m-%d : %H:%M\"\n\n            strptime = datetime.strptime\n            if final_data[\"Date\"] and final_data[\"Date\"] != \"0000-00-00\":\n                if final_data[\"StartTime\"]:\n                    start_string = \"{} : {}\".format(final_data[\"Date\"],\n                                                    final_data[\"StartTime\"])\n                    final_exam.start_date = strptime(start_string,\n                                                     final_format)\n\n                if final_data[\"EndTime\"]:\n                    end_string = \"{} : {}\".format(final_data[\"Date\"],\n                                                  final_data[\"EndTime\"])\n                    try:\n                        final_exam.end_date = strptime(\n                            end_string, final_format)\n                    except ValueError:\n                        logger.info('bad final EndTime: {}'.format(end_string))\n                        final_exam.end_date = None\n\n            final_exam.clean_fields()\n            section.final_exam = final_exam\n\n    return section"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_chain_details_by_related_pdb_chains(self, pdb_id, chain_id, pfam_accs):\n        ''' Returns a dict of SCOPe details using info\n            This returns Pfam-level information for a PDB chain i.e. no details on the protein, species, or domain will be returned.\n            If there are SCOPe entries for the associated Pfam accession numbers which agree then this function returns\n            pretty complete information.\n        '''\n\n        if not pfam_accs:\n            return None\n\n        associated_pdb_chains = set()\n        pfam_api = self.get_pfam_api()\n        for pfam_acc in pfam_accs:\n            associated_pdb_chains = associated_pdb_chains.union(pfam_api.get_pdb_chains_from_pfam_accession_number(pfam_acc))\n\n        hits = []\n        #class_count = {}\n\n        pfam_scop_mapping = {}\n        for pdb_chain_pair in associated_pdb_chains:\n            ass_pdb_id, ass_chain_id = pdb_chain_pair[0], pdb_chain_pair[1]\n            hit = self.get_chain_details(ass_pdb_id, chain = ass_chain_id, internal_function_call = True, pfam_scop_mapping = pfam_scop_mapping)\n            if hit and hit.get('chains'):\n                assert(len(hit['chains']) == 1)\n                hits.append(hit['chains'][ass_chain_id])\n                #for k, v in hit.iteritems():\n                    #class_count[v['sccs']] = class_count.get(v['sccs'], 0)\n                    #class_count[v['sccs']] += 1\n                    #print(' %s, %s: %s' % (v['pdb_id'], k, v['sccs']))\n        #pprint.pprint(class_count)\n        allowed_scop_domains = map(int, map(set.intersection, pfam_scop_mapping.values())[0])\n        allowed_scop_domains = list(set((allowed_scop_domains or []) + (self.get_sunid_for_pfam_accs(pfam_accs) or [])))\n\n\n        filtered_hits = []\n        print(pfam_accs)\n        print(allowed_scop_domains)\n        print('%d hits' % len(hits))\n        for hit in hits:\n            domains_to_ignore = []\n            for k, v in hit['domains'].iteritems():\n                if v['sunid'] in allowed_scop_domains:\n                    filtered_hits.append(v)\n        print('%d filtered_hits' % len(filtered_hits))\n\n        if not filtered_hits:\n            return None\n\n        d = self.get_basic_pdb_chain_information(pdb_id, chain_id)\n        d.update(self.get_common_fields(filtered_hits))\n        d.update(dict(\n            SCOPe_sources = 'Pfam + SCOPe',\n            SCOPe_search_fields = 'Pfam + link_pdb.pdb_chain_id',\n            SCOPe_trust_level = 3\n        ))\n        # Add the lowest common classification over all related Pfam families\n        for k, v in sorted(self.levels.iteritems()):\n            d[v] = None\n        d.update(dict(self.get_common_hierarchy(filtered_hits)))\n        return d", "response": "Returns a dict of SCOPe details using info\n            This returns a dict of SCOPe details using info\n            This returns a dict of SCOPe details using info\n            This returns a dict of SCOPe details using info\n           "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_chain_details_by_pfam(self, pdb_id, chain = None):\n        ''' Returns a dict pdb_id -> chain(s) -> chain and SCOPe details.\n            This returns Pfam-level information for a PDB chain i.e. no details on the protein, species, or domain will be returned.\n            If there are SCOPe entries for the associated Pfam accession numbers which agree then this function returns\n            pretty complete information.\n        '''\n        pfam_api = self.get_pfam_api()\n        if chain:\n            pfam_accs = pfam_api.get_pfam_accession_numbers_from_pdb_chain(pdb_id, chain)\n            if pfam_accs:\n                pfam_accs = {chain : pfam_accs}\n        else:\n            pfam_accs = pfam_api.get_pfam_accession_numbers_from_pdb_id(pdb_id)\n\n        if not pfam_accs:\n            # There were no associated Pfam accession numbers so we return\n            return None\n\n        d = {}\n        for chain_id, pfam_acc_set in pfam_accs.iteritems():\n            family_details = []\n            for pfam_accession in pfam_acc_set:\n                family_details.append(self.get_pfam_details(pfam_accession))\n\n            family_details = [f for f in family_details if f]\n            if not family_details:\n                if self.fallback_on_failures:\n                    # Fallback - There were no associated SCOPe entries with the associated Pfam accession numbers so we will\n                    #            search all PDB chains associated with those Pfam accession numbers instead\n                    d[chain_id] = self.get_chain_details_by_related_pdb_chains(pdb_id, chain_id, pfam_accs.get(chain_id))\n                else:\n                    d[chain_id] = None\n                continue\n\n            # Get the common SCOPe fields. For the sccs class, we take the longest common prefix\n\n\n            d[chain_id] = self.get_basic_pdb_chain_information(pdb_id, chain_id)\n            d[chain_id].update(self.get_common_fields(family_details))\n            d[chain_id].update(dict(\n                SCOPe_sources = 'Pfam + SCOPe',\n                SCOPe_search_fields = 'Pfam + link_pfam.pfam_accession',\n                SCOPe_trust_level = 2\n            ))\n            # Add the lowest common classification over all related Pfam families\n            for k, v in sorted(self.levels.iteritems()):\n                d[chain_id][v] = None\n            d[chain_id].update(dict(self.get_common_hierarchy(family_details)))\n        return d", "response": "Returns a dict pdb_id -> chain and SCOPe details. This function returns a dict pdb_id -> chain and SCOPe details."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a dict pdb_id - > chain and SCOPe details.", "response": "def get_chain_details(self, pdb_id, chain = None, internal_function_call = False, pfam_scop_mapping = {}):\n        ''' Returns a dict pdb_id -> chain(s) -> chain and SCOPe details.\n            This is the main function for getting details for a PDB chain. If there is an associated SCOPe entry for this\n            chain then this function returns the most information.\n            internal_function_call is used to prevent potential infinite loops\n        '''\n\n        query = '''\n            SELECT DISTINCT scop_node.id AS scop_node_id, scop_node.*, pdb_entry.code, pdb_chain_id, pdb_chain.chain, pdb_chain.is_polypeptide, pdb_entry.description AS ChainDescription, pdb_release.resolution\n            FROM `link_pdb`\n            INNER JOIN scop_node on node_id=scop_node.id\n            INNER JOIN pdb_chain ON pdb_chain_id = pdb_chain.id\n            INNER JOIN pdb_release ON pdb_release_id = pdb_release.id\n            INNER JOIN pdb_entry ON pdb_entry_id = pdb_entry.id\n            WHERE pdb_entry.code=%s'''\n        if chain:\n            query += ' AND pdb_chain.chain=%s'\n            parameters=(pdb_id, chain)\n        else:\n            parameters = (pdb_id, )\n        query += ' ORDER BY release_id DESC'\n\n        results = self.execute_select(query, parameters = parameters)\n        if not results:\n            if self.fallback_on_failures and not internal_function_call:\n                # Fallback - use any Pfam accession numbers associated with the chain to get partial information\n                #            Note: this fallback has another fallback in case none of the Pfam entries exist in SCOPe\n                searched_deeper = True\n                return self.get_chain_details_by_pfam(pdb_id, chain)\n            else:\n                return None\n\n        # I am making the assumption here that sids are consistent through releases i.e. that if d1aqt_1 is used in release\n        # 3 then it will be used for any other releases where the domain is named\n        sid_map = {}\n        for r in results:\n            sid = r['sid']\n            c_id = r['chain']\n            if not(sid_map.get(sid)) or sid_map[sid] == ' ':\n                sid_map[sid] = c_id\n        chain_to_sid_map = {}\n        for k, v in sid_map.iteritems():\n            chain_to_sid_map[v] = chain_to_sid_map.get(v, set())\n            chain_to_sid_map[v].add(k)\n\n        leaf_node_chains = set()\n        searched_deeper = False\n        if pdb_id and chain:\n            leaf_node_chains.add(chain)\n        else:\n            pdb_chain_ids = self.get_list_of_pdb_chains(pdb_id)\n            if pdb_chain_ids:\n                leaf_node_chains = pdb_chain_ids\n            else:\n                return None\n\n        leaf_nodes = {}\n        for c in leaf_node_chains:\n            if c in chain_to_sid_map:\n                for sid in chain_to_sid_map[c]:\n                    leaf_nodes[(c, sid)] = None\n\n\n        # Only consider the most recent records\n        for r in results:\n            chain_id = r['chain']\n            sid = r['sid']\n            k = (chain_id, sid)\n            if (not leaf_nodes.get(k)) or (r['release_id'] > leaf_nodes[k]['release_id']):\n                leaf_nodes[k] = r\n\n        # Older revisions of SCOPe have blank chain IDs for some records while newer revisions have the chain ID\n        # The best solution to avoid redundant results seems to be to remove all blank chain records if at least one\n        # more recent named chain exists. There could be some nasty cases - we only keep the most recent unnamed chain\n        # but this may correspond to many chains if the PDB has multiple chains since we only look at the chain ID.\n        # I think that it should be *unlikely* that we will have much if any bad behavior though.\n        for k1, v2 in leaf_nodes.iteritems():\n            if k1[0] == ' ':\n                release_id_of_blank_record = leaf_nodes[k1]['release_id']\n                for k2, v2 in leaf_nodes.iteritems():\n                    if k2[0] != ' ':\n                        assert(k2[0].isalpha() and len(k2[0]) == 1)\n                        if v2['release_id'] > release_id_of_blank_record:\n                            del leaf_nodes[k1] # we are modifying a structure while iterating over it but we break immediately afterwards\n                            break\n\n        d = {}\n        for chain_sid_pair, details in leaf_nodes.iteritems():\n            chain_id = chain_sid_pair[0]\n            sid = chain_sid_pair[1]\n            if sid.strip() == '':\n                colortext.warning('FOUND AN EMPTY SID FIELD')\n            assert(sid == details['sid'])\n\n            # Get the details for all chains\n            if details:\n\n                if d.get('resolution'):\n                    assert(d['resolution'] == details['resolution'])\n                else:\n                    d['resolution'] = details['resolution']\n\n                d['chains'] = d.get('chains', {})\n                if d['chains'].get(chain_id):\n                    assert(d['chains'][chain_id]['is_polypeptide'] == details['is_polypeptide'])\n                    assert(d['chains'][chain_id]['chain_description'] == details['ChainDescription'])\n                else:\n                    d['chains'][chain_id] = {}\n                    d['chains'][chain_id]['is_polypeptide'] = details['is_polypeptide']\n                    d['chains'][chain_id]['chain_description'] = details['ChainDescription']\n\n                d['chains'][chain_id]['domains'] = d['chains'][chain_id].get('domains', {})\n                domain_information = dict(\n                    #pdb_id = details['code'],\n                    #chain = details['chain'],\n                    #is_polypeptide = details['is_polypeptide'],\n                    #chain_description = details['ChainDescription'],\n                    sunid = details['sunid'],\n                    sccs = details['sccs'],\n                    sid = details['sid'],\n                    scop_release_id = details['release_id'],\n                    SCOPe_sources = 'SCOPe',\n                    SCOPe_search_fields = 'link_pdb.pdb_chain_id',\n                    SCOPe_trust_level = 1\n                )\n\n                for k, v in sorted(self.levels.iteritems()):\n                    domain_information[v] = None\n\n                pfam = None\n                level, parent_node_id = details['level_id'], details['parent_node_id']\n                pfam = pfam or self.get_pfam_for_node(details['scop_node_id'])\n\n                # Store the top-level description\n                domain_information[self.levels[level]] = details['description']\n\n                # Wind up the level hierarchy and retrieve the descriptions\n                c = 0\n                while level > 2:\n                    parent_details = self.execute_select('SELECT * FROM scop_node WHERE id=%s', parameters = (parent_node_id,))\n                    assert(len(parent_details) <= 1)\n                    if parent_details:\n                        parent_details = parent_details[0]\n                        level, parent_node_id = parent_details['level_id'], parent_details['parent_node_id']\n                        pfam = pfam or self.get_pfam_for_node(parent_details['id'])\n                        domain_information[self.levels[level]] = parent_details['description']\n                    else:\n                        break\n                    # This should never trigger but just in case...\n                    c += 1\n                    if c > 20:\n                        raise Exception('There is a logical error in the script or database which may result in an infinite lookup loop.')\n                domain_information['Pfam'] = pfam\n\n                # Fill in the residue range data\n                domain_information['pdbe_residue_range'] = None\n                sifts_object = self.get_sifts(pdb_id)\n                if sifts_object:\n                    colortext.message(pdb_id)\n                    region_mapping = sifts_object.region_mapping\n                    ps_map = sifts_object.pfam_scop_mapping or {}\n                    for k, v in ps_map.iteritems():\n                        pfam_scop_mapping[k] = pfam_scop_mapping.get(k, set())\n                        pfam_scop_mapping[k] = pfam_scop_mapping[k].union(v.get_matches('SCOP'))\n\n                    residue_ranges = region_mapping.get(chain_id, {}).get('SCOP', {}).get(str(details['sunid']))\n                    if residue_ranges:\n                        residue_ranges = ', '.join(['%d-%d' % (t[0], t[1]) for t in residue_ranges])\n                    domain_information['pdbe_residue_range'] = residue_ranges\n\n                d['chains'][chain_id]['domains'][sid] = domain_information\n\n            else:\n                if self.fallback_on_failures and not(internal_function_call) and not(searched_deeper):\n                    fallback_results = self.get_chain_details_by_pfam(pdb_id, chain_id)\n                    if fallback_results and fallback_results.get(chain_id):\n                        domain_information = fallback_results[chain_id]\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a dict pdb_id -> chain ( s ) -> chain and SCOPe details.", "response": "def get_pfam_details(self, pfam_accession):\n        '''Returns a dict pdb_id -> chain(s) -> chain and SCOPe details.'''\n\n        results = self.execute_select('''\n            SELECT DISTINCT scop_node.*, scop_node.release_id AS scop_node_release_id,\n            pfam.release_id AS pfam_release_id, pfam.name AS pfam_name, pfam.accession, pfam.description AS pfam_description, pfam.length AS pfam_length,\n            pfam_type.description AS pfam_type_description\n            FROM `link_pfam`\n            INNER JOIN scop_node on node_id=scop_node.id\n            INNER JOIN pfam ON link_pfam.pfam_accession = pfam.accession\n            INNER JOIN pfam_type ON pfam.pfam_type_id = pfam_type.id\n            WHERE pfam.accession=%s ORDER BY scop_node.release_id DESC''', parameters = (pfam_accession,))\n\n        if not results:\n            return None\n\n        # Only consider the most recent Pfam releases and most recent SCOPe records, giving priority to SCOPe revisions over Pfam revisions\n        most_recent_record = None\n        for r in results:\n            accession = r['accession']\n            if (not most_recent_record) or (r['scop_node_release_id'] > most_recent_record['scop_node_release_id']):\n                most_recent_record = r\n            elif r['pfam_release_id'] > most_recent_record['pfam_release_id']:\n                most_recent_record = r\n\n        d = dict(\n            pfam_accession = most_recent_record['accession'],\n            pfam_name = most_recent_record['pfam_name'],\n            pfam_description = most_recent_record['pfam_description'],\n            pfam_type_description = most_recent_record['pfam_type_description'],\n            pfam_length = most_recent_record['pfam_length'],\n            pfam_release_id = most_recent_record['pfam_release_id'],\n            sunid = most_recent_record['sunid'],\n            sccs = most_recent_record['sccs'],\n            sid = most_recent_record['sid'],\n            scop_release_id = most_recent_record['scop_node_release_id'],\n            SCOPe_sources = 'SCOPe',\n            SCOPe_search_fields = 'link_pfam.pfam_accession',\n            SCOPe_trust_level = 1\n        )\n\n        for k, v in sorted(self.levels.iteritems()):\n            d[v] = None\n\n        level, parent_node_id = most_recent_record['level_id'], most_recent_record['parent_node_id']\n\n        # Store the top-level description\n        d[self.levels[level]] = most_recent_record['description']\n\n        # Wind up the level hierarchy and retrieve the descriptions\n        c = 0\n        while level > 2 :\n            parent_details = self.execute_select('SELECT * FROM scop_node WHERE id=%s', parameters = (parent_node_id,))\n            assert(len(parent_details) <= 1)\n            if parent_details:\n                parent_details = parent_details[0]\n                level, parent_node_id = parent_details['level_id'], parent_details['parent_node_id']\n                d[self.levels[level]] = parent_details['description']\n            else:\n                break\n            # This should never trigger but just in case...\n            c += 1\n            if c > 20:\n                raise Exception('There is a logical error in the script or database which may result in an infinite lookup loop.')\n\n        assert(d['Protein'] == d['Species'] == d['PDB Entry Domain'] == None)\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef recall_service(self, service):\n        if not isinstance(service, Service):\n            raise TypeError(\"service must be of type Service.\")\n\n        logger.warning(\"The deployment for {0} on {1} failed starting the rollback.\".format(service.alias, self.url.geturl()))\n\n        def anonymous(anonymous_service):\n            if not isinstance(anonymous_service, Service):\n                raise TypeError(\"service must be an instance of Service.\")\n\n            containers = self.find_previous_service_containers(anonymous_service)\n            if containers:\n                for name in list(anonymous_service.containers.keys()):\n                    del anonymous_service.containers[name]\n\n                anonymous_service.cargo.delete()\n\n                for name, container in six.iteritems(containers):\n                    # TODO: add function to container obj to see if its running.\n                    if container.state().get('running'):\n                        logger.info(\n                            \"is already running... Might want to investigate.\",\n                            extra={'formatter': 'container', 'container': container.name}\n                        )\n                    else:\n                        if container.start():\n                            logger.info(\n                                \"is restarted and healthy.\",\n                                extra={'formatter': 'container', 'container': container.name}\n                            )\n                        else:\n                            logger.error(\n                                \"failed to start.\",\n                                extra={'formatter': 'container', 'container': container.name}\n                            )\n\n                            container.dump_logs()\n                            raise Exception(\n                                \"The deployment for {0} on {1} went horribly wrong\".format(container.name, self.url.geturl())\n                            )\n\n        self._service_map(service, anonymous, descending=False)", "response": "This method assumes that its a roll back during a deployment.  If not used during a deployment session\n\n        This method should be extended later to be more useful."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_containers(self, service, configs, use_cache):\n        if not isinstance(service, Service):\n            raise TypeError(\"service must be and instance of service.  {0} was passed.\".format(service))\n\n        if not self.healthy():\n            logger.error(\"unable to connect to container ship.\")\n            raise Exception('lost comms with our container ship')\n\n        self._load_service_containers(service, configs, use_cache)", "response": "Load containers from a service."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncleaning up all dangling images.", "response": "def clean_up_dangling_images(self):\n        \"\"\"\n        Clean up all dangling images.\n        \"\"\"\n        cargoes = Image.all(client=self._client_session, filters={'dangling': True})\n        for id, cargo in six.iteritems(cargoes):\n            logger.info(\"Removing dangling image: {0}\".format(id))\n            cargo.delete()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef offload_all_service_cargo(self, service):\n        def anonymous(anonymous_service):\n            if not isinstance(anonymous_service, Service):\n                raise TypeError(\"service must be an instance of Service.\")\n\n            cargoes = Image.find_all_by_name(\n                self._client_session,\n                \"{0}/{1}\".format(anonymous_service.repository, anonymous_service.namespace)\n            )\n\n            if cargoes:\n                logger.info(\"Offloading all images for {0}.\".format(anonymous_service.alias))\n                for cargo in six.itervalues(cargoes):\n                    cargo.delete(force=True)\n\n        self._service_map(service, anonymous, descending=True)", "response": "Remove all docker images for a specific service."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef offload_expired_service_cargo(self, service):\n        # TODO: move offload cargo logic to this method\n        self._service_map(service, self._offload_cargo, descending=True)", "response": "Remove docker images for a specific service."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\noffloading containers for a service.", "response": "def offload_service_containers(self, service):\n        \"\"\"\n        :param service:\n        :return:\n        \"\"\"\n        def anonymous(anonymous_service):\n            if not isinstance(anonymous_service, Service):\n                raise TypeError(\"service must be an instance of Service.\")\n\n            if anonymous_service.containers:\n                logger.info(\"Deleting service: {0} containers.\".format(anonymous_service.name))\n                for container_name in list(anonymous_service.containers.keys()):\n                    del anonymous_service.containers[container_name]\n\n        self._service_map(service, anonymous, descending=True)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndeletes all containers related to the service.", "response": "def offload_all_service_containers(self, service):\n        \"\"\"Deletes all containers related to the service.\n        \"\"\"\n        def anonymous(anonymous_service):\n            if not isinstance(anonymous_service, Service):\n                raise TypeError(\"service must be an instance of Service.\")\n\n            containers = self.find_service_containers(anonymous_service)\n            if containers:\n                logger.info(\"Deleting service: {0} containers.\".format(anonymous_service.name))\n                for container in six.itervalues(containers):\n                    container.delete()\n\n        self._service_map(service, anonymous, descending=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef start_service_containers(self, service, attach):\n        if not isinstance(service, Service):\n            TypeError(\"Service must be a instance of Service.\")\n\n        if not service.containers:\n            raise AttributeError(\"Must load containers before attempting to start them.\")\n\n        containers = self.find_service_containers(service)\n        if containers:\n            for name, container in six.iteritems(containers):\n                # TODO: add function to container obj to see if its running.\n                if container.state().get('running'):\n                    container.stop()\n\n        for name, container in six.iteritems(service.containers):\n            if not container.start(attach=attach):\n                logger.error(\"service container: {0} failed to start.\".format(name))\n                container.dump_logs()\n\n                return False\n\n        return True", "response": "Start all the containers for a given service."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks for an available name and return that to the caller.", "response": "def _container_registration(self, alias):\n        \"\"\"\n        Check for an available name and return that to the caller.\n        \"\"\"\n        containers = Container.find_by_name(self._client_session, alias)\n\n        def validate_name(name):\n            valid = True\n            if name in containers:\n                valid = False\n\n            return valid\n\n        count = 1\n        container_name = \"{0}-0{1}\".format(alias, count)\n        while not validate_name(container_name):\n            count += 1\n            container_index = count if count > 10 else \"0{0}\".format(count)\n            container_name = \"{0}-{1}\".format(alias, container_index)\n\n        return container_name"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\noffload the containers of a service.", "response": "def _offload_service_containers(self, service):\n        \"\"\"\n        :param service:\n        :return:\n        \"\"\"\n        if not isinstance(service, Service):\n            raise TypeError(\"service must be an instance of Service\")\n\n        if service.containers:\n            for key in list(service.containers.keys()):\n                if key in service.containers:\n                    del service.containers[key]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload the service s cargo.", "response": "def _load_service_cargo(self, service, inject_configs, use_cache=False):\n        \"\"\"\n        :param service:\n        :return None:\n        \"\"\"\n        if not isinstance(service, Service):\n            raise TypeError(\"service must of an instance of Service\")\n\n        repository = \"{0}/{1}\".format(service.repository, service.namespace)\n\n        if service.source_registry:\n            if service.source_tag:\n                repository = \"{0}:{1}\".format(repository, service.source_tag)\n\n            if service.source_registry.auth:\n                self._request_auth(service.source_registry)\n\n            service.cargo = Image.pull(\n                self._client_session,\n                service.source_registry,\n                repository\n            )\n        elif service.docker_file:\n            service.cargo = Image.build(\n                self._client_session,\n                repository,\n                service.docker_file,\n                use_cache=use_cache\n            )\n        else:\n            raise LookupError(\"Couldn't locate image or Dockerfile. Every service is required to have one or the other.\")\n\n        # dynamically inject configuration files if required.\n        if inject_configs is True and self._injector:\n            self._injector.inject(self._client_session, service)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload the service containers.", "response": "def _load_service_containers(self, service, configs, use_cache):\n        \"\"\"\n        :param service:\n        :return:\n        \"\"\"\n        if not isinstance(service, Service):\n            raise TypeError(\"service must of an instance of Service\")\n\n        if not service.containers:\n            container_name = self._container_registration(service.alias)\n\n            if service.dependencies:\n                self._load_dependency_containers(service)\n\n            if not service.cargo:\n                self._load_service_cargo(service, configs, use_cache)\n\n            self._update_container_host_config(service)\n            service.containers[container_name] = Container(\n                self._client_session,\n                container_name,\n                service.cargo.id,\n                container_config=service.container_config.to_dict(),\n                host_config=service.host_config.to_dict()\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _update_container_host_config(self, service):\n        if not isinstance(service, Service):\n            raise TypeError(\"service must be an instance of Service\")\n\n        if service.dependencies:\n\n            self._load_dependency_containers(service)\n\n            if service.host_config.links:\n                self._update_links(service)\n\n            if service.host_config.volumes_from:\n                self._update_volumes_from(service)", "response": "Updates the host config of a container."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nrequests auth for a specific user", "response": "def _request_auth(self, registry):\n        \"\"\"\n             self, username, password=None, email=None, registry=None,\n              reauth=False, insecure_registry=False, dockercfg_path=None):\n        \"\"\"\n        if registry:\n            if registry.auth:\n                registry.auth.load_dockercfg()\n\n            try:\n                self._client_session.login(username=registry.auth.user,\n                                           password=registry.auth.passwd,\n                                           dockercfg_path=registry.auth.config_path,\n                                           reauth=True if registry.auth.auth_type == 'registry_rubber' else False,\n                                           registry=registry.auth.registry)\n            except Exception:\n                raise\n        else:\n            raise Exception(\"a registry is required when requesting auth.\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef statement_prep(link):\n    '''\n    Prepare a statement into a triple ready for rdflib\n    '''\n    from rdflib import URIRef, Literal\n    from rdflib import BNode\n    s, p, o = link[:3]\n    if not isinstance(s, BNode): s = URIRef(s)\n    p = URIRef(p)\n    if not isinstance(o, BNode): o = URIRef(o) if isinstance(o, I) else Literal(o)\n    return s, p, o", "response": "Prepare a statement into a triple ready for rdflib\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef teardown_databases(self, old_config, options):\n        if len(old_config) > 1:\n            old_names, mirrors = old_config\n        else:\n            old_names = old_config\n        for connection, old_name, destroy in old_names:\n            if destroy:\n                connection.creation.destroy_test_db(old_name, options['verbosity'])", "response": "Destroys all the non - mirror databases."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate OEmbed link {{ url | oembed }} :param url: :param class_: :return:", "response": "def oembed(url, class_=\"\"):\n    \"\"\"\n    Create OEmbed link\n\n    {{ url | oembed }}\n    :param url:\n    :param class_:\n    :return:\n    \"\"\"\n    o = \"<a href=\\\"{url}\\\" class=\\\"oembed {class_}\\\" ></a>\".format(url=url,\n                                                                   class_=class_)\n    return Markup(o)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates an image src tag", "response": "def img_src(url, class_=\"\", responsive=False, lazy_load=False, id_=\"\"):\n    \"\"\"\n    Create an image src\n\n    {{ xyz.jpg | img_src }}\n\n    :param url:\n    :param class_:\n    :param responsive:\n    :param lazy_load:\n    :param id_:\n    :return:\n    \"\"\"\n    if not url.startswith(\"http://\") and not url.startswith(\"https://\"):\n        url = static_url(url)\n\n    data_src = \"\"\n    if responsive:\n        class_ += \" responsive\"\n    if lazy_load:\n        data_src = url\n        # 1x1 image\n        url = \"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNgYAAAAAMAASsJTYQAAAAASUVORK5CYII=\"\n        class_ += \" lazy\"\n\n    img = \"<img src=\\\"{src}\\\" class=\\\"{class_}\\\" id=\\\"{id_}\\\" data-src={data_src}>\" \\\n        .format(src=url, class_=class_, id_=id_, data_src=data_src)\n    return Markup(img)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef give_dots_yield(R, r, r_, resolution=2*PI/1000, spins=50):\n    '''Generate Spirograph dots without numpy using yield.\n    '''\n    def x(theta):\n        return (R-r) * math.cos(theta) + r_*math.cos((R-r) / r * theta)\n\n    def y(theta):\n        return (R-r) * math.sin(theta) - r_*math.sin((R-r) / r * theta)\n\n    theta = 0.0\n    while theta < 2*PI*spins:\n        yield (x(theta), y(theta))\n        theta += resolution", "response": "Generate Spirograph dots with numpy using yield."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate dots with numpy.", "response": "def give_dots(R, r, r_, resolution=2*PI/1000, spins=50):\n    '''Generate Spirograph dots with numpy.\n    '''\n    thetas = np.arange(0, 2*PI*spins, resolution)\n    Rr = R - r\n    x = Rr * np.cos(thetas) + r_*np.cos(Rr / r * thetas)\n    y = Rr * np.sin(thetas) - r_*np.sin(Rr / r * thetas)\n    return x, y"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef spiro_image(R, r, r_, resolution=2*PI/1000, spins=50, size=[32, 32]):\n    '''Create image with given Spirograph parameters using numpy and scipy.\n    '''\n    x, y = give_dots(200, r, r_, spins=20)\n    xy = np.array([x, y]).T\n    xy = np.array(np.around(xy), dtype=np.int64)\n    xy = xy[(xy[:, 0] >= -250) & (xy[:, 1] >= -250) &\n            (xy[:, 0] < 250) & (xy[:, 1] < 250)]\n    xy = xy + 250\n    img = np.ones([500, 500], dtype=np.uint8)\n    img[:] = 255\n    img[xy[:, 0], xy[:, 1]] = 0\n    img = misc.imresize(img, size)\n    fimg = img / 255.0\n    return fimg", "response": "Create image with given Spirograph parameters using numpy and scipy.\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef html(text, lazy_images=False):\n    extensions = [\n        'markdown.extensions.nl2br',\n        'markdown.extensions.sane_lists',\n        'markdown.extensions.toc',\n        'markdown.extensions.tables',\n        OEmbedExtension()\n    ]\n    if lazy_images:\n        extensions.append(LazyImageExtension())\n\n    return markdown.markdown(text, extensions=extensions)", "response": "Render a markdown format text into HTML."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef toc(text):\n    extensions = ['markdown.extensions.toc']\n    mkd = markdown.Markdown(extensions=extensions)\n    html = mkd.convert(text)\n    return mkd.toc", "response": "Return a table of context list of text"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef extract_images(text):\n    extensions = [ExtractImagesExtension()]\n    mkd = markdown.Markdown(extensions=extensions)\n    html = mkd.convert(text)\n    return mkd.images", "response": "Extract all images in the content\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nextracting Table of Content of MD", "response": "def get_toc(text):\n    \"\"\"\n    Extract Table of Content of MD\n    :param text:\n    :return:\n    \"\"\"\n    mkd.convert(text)\n    toc = mkd.toc\n    mkd.reset()\n    return toc"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding all images and append to markdown. images.", "response": "def run(self, root):\n        \"Find all images and append to markdown.images. \"\n        self.markdown.images = []\n        for image in root.getiterator(\"img\"):\n            self.markdown.images.append(image.attrib[\"src\"])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sorted_items(d, key=__identity, reverse=False):\n\t# wrap the key func so it operates on the first element of each item\n\tdef pairkey_key(item):\n\t\treturn key(item[0])\n\treturn sorted(d.items(), key=pairkey_key, reverse=reverse)", "response": "Return the items of the dictionary sorted by the keys\n\t"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngive a dictionary return another dictionary with keys and values switched.", "response": "def invert_map(map):\n\t\"\"\"\n\tGiven a dictionary, return another dictionary with keys and values\n\tswitched. If any of the values resolve to the same key, raises\n\ta ValueError.\n\n\t>>> numbers = dict(a=1, b=2, c=3)\n\t>>> letters = invert_map(numbers)\n\t>>> letters[1]\n\t'a'\n\t>>> numbers['d'] = 3\n\t>>> invert_map(numbers)\n\tTraceback (most recent call last):\n\t...\n\tValueError: Key conflict in inverted mapping\n\t\"\"\"\n\tres = dict((v, k) for k, v in map.items())\n\tif not len(res) == len(map):\n\t\traise ValueError('Key conflict in inverted mapping')\n\treturn res"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngive a key return the actual key stored in self that matches.", "response": "def matching_key_for(self, key):\n\t\t\"\"\"\n\t\tGiven a key, return the actual key stored in self that matches.\n\t\tRaise KeyError if the key isn't found.\n\t\t\"\"\"\n\t\ttry:\n\t\t\treturn next(e_key for e_key in self.keys() if e_key == key)\n\t\texcept StopIteration:\n\t\t\traise KeyError(key)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef backup(backup_filename=None):\n    '''\n        Backup a Cozy\n    '''\n    timestamp = time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n\n    if not backup_filename:\n        if not os.path.isdir(BACKUPS_PATH):\n            print 'Need to create {}'.format(BACKUPS_PATH)\n            os.makedirs(BACKUPS_PATH, 0700)\n        backup_filename = '{backups_path}/cozy-{timestamp}.tgz'.format(\n            backups_path=BACKUPS_PATH,\n            timestamp=timestamp\n        )\n    elif os.path.exists(backup_filename):\n        print 'Backup file already exists: {}'.format(backup_filename)\n        return\n\n    couchdb_path = _get_couchdb_path()\n\n    cmd = 'tar cvzf {backup_filename}'\n    cmd += ' --exclude stack.token'\n    cmd += ' --exclude couchdb.login'\n    cmd += ' --exclude self-hosting.json'\n    cmd += ' /etc/cozy /usr/local/var/cozy {couchdb_path}/cozy.couch'\n    cmd = cmd.format(backup_filename=backup_filename,\n                     couchdb_path=couchdb_path)\n    helpers.cmd_exec(cmd, show_output=True)\n    print 'Backup file: {}'.format(backup_filename)", "response": "Backup a Cozycozy object"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrestore a CozyMacroEntry from a file.", "response": "def restore(backup_file):\n    '''\n        Restore a Cozy\n        backup_file: path to .tar.gz\n    '''\n    if not os.path.isfile(backup_file) and not os.path.islink(backup_file):\n        print 'Missing backup file: {}'.format(backup_file)\n    else:\n        couchdb_path = _get_couchdb_path()\n\n        print 'Restore Cozy:'\n        cmd = 'supervisorctl stop cozy-controller ; sleep 10'\n        cmd += ' ; service couchdb stop ; service nginx stop'\n        cmd += ' ; rm -rf {couchdb_path}/.cozy_design'\n        cmd += ' {couchdb_path}/_replicator.couch'\n        cmd += ' ; tar xvzf {backup_file} -C /'\n        cmd += ' ; service couchdb start ; service nginx start'\n        cmd = cmd.format(backup_file=backup_file, couchdb_path=couchdb_path)\n        helpers.cmd_exec(cmd, show_output=True)\n        helpers.wait_couchdb(10)\n        cmd = 'supervisorctl start cozy-controller'\n        helpers.cmd_exec(cmd, show_output=True)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_config():\n    from boiler.migrations.config import MigrationsConfig\n\n    # used for errors\n    map = dict(\n        path='MIGRATIONS_PATH',\n        db_url='SQLALCHEMY_DATABASE_URI',\n        metadata='SQLAlchemy metadata'\n    )\n\n    app = bootstrap.get_app()\n    params = dict()\n    params['path'] = app.config.get(map['path'], 'migrations')\n    params['db_url'] = app.config.get(map['db_url'])\n    params['metadata'] = db.metadata\n\n    for param, value in params.items():\n        if not value:\n            msg = 'Configuration error: [{}] is undefined'\n            raise Exception(msg.format(map[param]))\n\n    config = MigrationsConfig(**params)\n    return config", "response": "Prepare and return alembic config"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninitialize new migrations directory", "response": "def init():\n    \"\"\" Initialize new migrations directory \"\"\"\n    try:\n        config = get_config()\n        print(config.dir)\n        alembic_command.init(config, config.dir, 'project')\n    except CommandError as e:\n        click.echo(red(str(e)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef revision(revision, path, branch_label, splice, head, sql, autogenerate, message):\n    alembic_command.revision(\n        config=get_config(),\n        rev_id=revision,\n        version_path=path,\n        branch_label=branch_label,\n        splice=splice,\n        head=head,\n        sql=sql,\n        autogenerate=autogenerate,\n        message=message\n    )", "response": "Create a new revision file"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmerging two revision together create new revision file", "response": "def merge(revision, branch_label, message, list_revisions=''):\n    \"\"\" Merge two revision together, create new revision file \"\"\"\n    alembic_command.merge(\n        config=get_config(),\n        revisions=list_revisions,\n        message=message,\n        branch_label=branch_label,\n        rev_id=revision\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef up(tag, sql, revision):\n    alembic_command.upgrade(\n        config=get_config(),\n        revision=revision,\n        sql=sql,\n        tag=tag\n    )", "response": "Upgrades the current version of the current page to the given revision."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef history(verbose, range):\n    alembic_command.history(\n        config=get_config(),\n        rev_range=range,\n        verbose=verbose\n    )", "response": "List revision changesets chronologically"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef stamp(revision, sql, tag):\n    alembic_command.stamp(\n        config=get_config(),\n        revision=revision,\n        sql=sql,\n        tag=tag\n    )", "response": "Stamp the database to given revision without migrating."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef row_to_dict(r, keep_relationships = False):\n    '''Converts an SQLAlchemy record to a Python dict. We assume that _sa_instance_state exists and is the only value we do not care about.\n       If DeclarativeBase is passed then all DeclarativeBase objects (e.g. those created by relationships) are also removed.\n    '''\n    d = {}\n    if not keep_relationships:\n        # only returns the table columns\n        t = r.__table__\n        for c in [c.name for c in list(sqlalchemy_inspect(t).columns)]:\n            d[c] = getattr(r, c)\n        return d\n    else:\n        # keeps all objects including those of type DeclarativeBase or InstrumentedList and the _sa_instance_state object\n        return copy.deepcopy(r.__dict__)", "response": "Converts an SQLAlchemy record to a Python dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nuses the SQLAlchemy model to retrieve an existing record based on the supplied field values or, if there is no existing record, to create a new database record. :param tsession: An SQLAlchemy transactioned session :param model: The name of the SQLAlchemy class representing the table :param values: A dict of values which will be used to populate the fields of the model :param missing_columns: Elements of missing_columns are expected to be fields in the model but are left blank regardless of whether they exist in values. This is useful for auto_increment fields. :param updatable_columns: If these are specified, they are treated as missing columns in the record matching and if a record is found, these fields will be updated :param variable_columns: If these are specified, they are treated as missing columns in the record matching but are not updated. A good use of these are for datetime fields which default to the current datetime :param read_only: If this is set then we query the database and return an instance if one exists but we do not create a new record. :return: Note: This function is a convenience function and is NOT efficient. The \"tsession.query(model).filter_by(**pruned_values)\" call is only (sometimes) efficient if an index exists on the keys of pruned_values. If any of the fields of pruned_values are large (even if otherwise deferred/loaded lazily) then you will incur a performance hit on lookup. You may need to reconsider any calls to this function in inner loops of your code.", "response": "def get_or_create_in_transaction(tsession, model, values, missing_columns = [], variable_columns = [], updatable_columns = [], only_use_supplied_columns = False, read_only = False):\n    '''\n    Uses the SQLAlchemy model to retrieve an existing record based on the supplied field values or, if there is no\n    existing record, to create a new database record.\n\n    :param tsession: An SQLAlchemy transactioned session\n    :param model: The name of the SQLAlchemy class representing the table\n    :param values: A dict of values which will be used to populate the fields of the model\n    :param missing_columns: Elements of missing_columns are expected to be fields in the model but are left blank regardless of whether they exist in values. This is useful for auto_increment fields.\n    :param updatable_columns: If these are specified, they are treated as missing columns in the record matching and if a record is found, these fields will be updated\n    :param variable_columns: If these are specified, they are treated as missing columns in the record matching but are not updated. A good use of these are for datetime fields which default to the current datetime\n    :param read_only: If this is set then we query the database and return an instance if one exists but we do not create a new record.\n    :return:\n\n    Note: This function is a convenience function and is NOT efficient. The \"tsession.query(model).filter_by(**pruned_values)\"\n          call is only (sometimes) efficient if an index exists on the keys of pruned_values. If any of the fields of pruned_values are\n          large (even if otherwise deferred/loaded lazily) then you will incur a performance hit on lookup. You may need\n          to reconsider any calls to this function in inner loops of your code.'''\n\n\n    values = copy.deepcopy(values) # todo: this does not seem to be necessary since we do not seem to be writing\n\n    fieldnames = [c.name for c in list(sqlalchemy_inspect(model).columns)]\n    for c in missing_columns:\n        fieldnames.remove(c)\n    for c in updatable_columns:\n        fieldnames.remove(c)\n    for c in variable_columns:\n        if c in fieldnames:\n            fieldnames.remove(c)\n\n    if only_use_supplied_columns:\n        fieldnames = sorted(set(fieldnames).intersection(set(values.keys())))\n    else:\n        unexpected_fields = set(values.keys()).difference(set(fieldnames)).difference(set(variable_columns)).difference(set(updatable_columns))\n        if unexpected_fields:\n            raise Exception(\"The fields '{0}' were passed but not found in the schema for table {1}.\".format(\"', '\".join(sorted(unexpected_fields)), model.__dict__['__tablename__']))\n\n    pruned_values = {}\n    for k in set(values.keys()).intersection(set(fieldnames)):\n        v = values[k]\n        pruned_values[k] = v\n\n    instance = tsession.query(model).filter_by(**pruned_values)\n    if instance.count() > 1:\n        raise Exception('Multiple records were found with the search criteria.')\n    instance = instance.first()\n\n    if instance:\n        if read_only == False:\n            for c in updatable_columns:\n                setattr(instance, c, values[c])\n            tsession.flush()\n        return instance\n    else:\n        if read_only == False:\n            if sorted(pruned_values.keys()) != sorted(fieldnames):\n                # When adding new records, we require that all necessary fields are present\n                raise Exception('Some required fields are missing: {0}. Either supply these fields or add them to the missing_columns list.'.format(set(fieldnames).difference(pruned_values.keys())))\n            instance = model(**pruned_values)\n            tsession.add(instance)\n            tsession.flush()\n            return instance\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_or_create_in_transaction_wrapper(tsession, model, values, missing_columns = [], variable_columns = [], updatable_columns = [], only_use_supplied_columns = False, read_only = False):\n    '''This function can be used to determine which calling method is spending time in get_or_create_in_transaction when profiling the database API.\n       Switch out calls to get_or_create_in_transaction to get_or_create_in_transaction_wrapper in the suspected functions to determine where the pain lies.'''\n    return get_or_create_in_transaction(tsession, model, values, missing_columns = missing_columns, variable_columns = variable_columns, updatable_columns = updatable_columns, only_use_supplied_columns = only_use_supplied_columns, read_only = read_only)", "response": "This function is used to determine which calling method is spending time in get_or_create_in_transaction when profiling the database API."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the weight for rule in the internal list.", "response": "def set_weight(self, rule, weight):\n        \"\"\"Set weight for rule in :attr:`R`.\n\n        Adds the rule if it is not in :attr:`R`.\n        \"\"\"\n        if not issubclass(rule.__class__, (Rule, RuleLeaf)):\n            raise TypeError(\"Rule to set weight ({}) is not subclass \"\n                            \"of {} or {}.\".format(rule, Rule, RuleLeaf))\n        assert (weight >= -1.0 and weight <= 1.0)\n        try:\n            ind = self._R.index(rule)\n            self._W[ind] = weight\n        except:\n            self.add_rule(rule, weight)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget weight for rule.", "response": "def get_weight(self, rule):\n        \"\"\"Get weight for rule.\n\n        If rule is not in :attr:`R`, returns ``None``.\n        \"\"\"\n        if not issubclass(rule.__class__, (Rule, RuleLeaf)):\n            raise TypeError(\"Rule to get weight ({}) is not subclass \"\n                            \"of {} or {}.\".format(rule, Rule, RuleLeaf))\n        try:\n            ind = self._R.index(rule)\n            return self._W[ind]\n        except:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_rule(self, rule, weight):\n        if not issubclass(rule.__class__, (Rule, RuleLeaf)):\n            raise TypeError(\n                \"Rule to add ({}) must be derived from {} or {}.\"\n                .format(rule.__class__, Rule, RuleLeaf))\n        if rule not in self._R:\n            self._R.append(rule)\n            self._W.append(weight)\n            return True\n        return False", "response": "Adds a rule to the list of available rules."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving a rule from the internal list R and its corresponding weight from the internal list W.", "response": "def remove_rule(self, rule):\n        \"\"\"Remove rule from :attr:`R` and its corresponding weight from\n        :attr:`W`.\n\n        :param rule: rule to remove\n        :type rule:\n            :class:`~creamas.rules.rule.Rule` or\n            :class:`~creamas.rules.rule.RuleLeaf`\n        :raises TypeError:\n            If rule is not derived from :class:`Rule` or :class:`RuleLeaf`.\n        :returns:\n            ``True`` if the rule was successfully removed, otherwise ``False``.\n        :rtype bool:\n        \"\"\"\n        if not issubclass(rule.__class__, (Rule, RuleLeaf)):\n            raise TypeError(\n                \"Rule to remove ({}) is not subclass of {} or {}.\"\n                .format(rule.__class__, Rule, RuleLeaf))\n        try:\n            ind = self._R.index(rule)\n            del self._R[ind]\n            del self._W[ind]\n            return True\n        except:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _init_dates(self):\n        if self.total_transactions == 0:\n            return None\n        self.epoch_start = Result.select(Result.epoch).order_by(Result.epoch.asc()).limit(1).get().epoch\n        self.epoch_finish = Result.select(Result.epoch).order_by(Result.epoch.desc()).limit(1).get().epoch\n        self.start_datetime = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(self.epoch_start))\n        self.finish_datetime = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(self.epoch_finish))", "response": "Initialize all dates properties"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninitialise the main dataframe for the results and the custom timers dataframes", "response": "def _init_dataframes(self):\n        \"\"\"Initialise the main dataframe for the results and the custom timers dataframes\n        \"\"\"\n        df = pd.read_sql_query(\"SELECT elapsed, epoch, scriptrun_time, custom_timers FROM result ORDER BY epoch ASC\",\n                               db.get_conn())\n\n        self._get_all_timers(df)\n        self.main_results = self._get_processed_dataframe(df)\n\n        # create all custom timers dataframes\n        for key, value in six.iteritems(self._timers_values):\n            df = pd.DataFrame(value, columns=['epoch', 'scriptrun_time'])\n            df.index = pd.to_datetime(df['epoch'], unit='s')\n            timer_results = self._get_processed_dataframe(df)\n            self.timers_results[key] = timer_results\n\n        # clear memory\n        del self._timers_values"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_all_timers(self, dataframe):\n        s = dataframe['custom_timers'].apply(json.loads)\n        s.index = dataframe['epoch']\n        for index, value in s.iteritems():\n            if not value:\n                continue\n            for key, value in six.iteritems(value):\n                self._timers_values[key].append((index, value))\n                self.total_timers += 1\n        del dataframe['custom_timers']\n        del s", "response": "Get all timers and set them in the _timers_values property"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_processed_dataframe(self, dataframe):\n        dataframe.index = pd.to_datetime(dataframe['epoch'], unit='s', utc=True)\n        del dataframe['epoch']\n        summary = dataframe.describe(percentiles=[.80, .90, .95]).transpose().loc['scriptrun_time']\n        df_grp = dataframe.groupby(pd.TimeGrouper('{}S'.format(self.interval)))\n        df_final = df_grp.apply(lambda x: x.describe(percentiles=[.80, .90, .95])['scriptrun_time'])\n\n        return {\n            \"raw\": dataframe.round(2),\n            \"compiled\": df_final.round(2),\n            \"summary\": summary.round(2)\n        }", "response": "Generate required dataframe for results from original dataframe"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompile all results for the current testset", "response": "def compile_results(self):\n        \"\"\"Compile all results for the current test\n        \"\"\"\n        self._init_dataframes()\n\n        self.total_transactions = len(self.main_results['raw'])\n        self._init_dates()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncalculate the centroid from a matrix X", "response": "def centroid(X):\n    \"\"\"\n    Calculate the centroid from a matrix X\n    \"\"\"\n    C = np.sum(X, axis=0) / len(X)\n    return C"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\naligns a list of coordinates with the Bakan - Bahar model", "response": "def bakan_bahar_ensemble_align(coords, tolerance = 0.001, verbose = False ):\n    '''\n    input: a list of coordinates in the format:\n    [\n      [ (x, y, z), (x, y, z), (x, y, z) ], # atoms in model 1\n      [ (x, y, z), (x, y, z), (x, y, z) ], # atoms in model 2\n      # etc.\n    ]\n    '''\n    rmsd_tolerance = float(\"inf\")\n    average_struct_coords = np.array( random.choice(coords) )\n    cycle_count = 0\n    while( rmsd_tolerance > tolerance ):\n        if verbose:\n            print 'Cycle %d alignment, current tolerance: %.4f (threshold %.4f)' % (cycle_count, rmsd_tolerance, tolerance)\n        old_average_struct_coords = average_struct_coords\n        coords = np.array([ kabsch( average_struct_coords, x ) for x in coords ])\n        average_struct_coords = np.mean( coords, axis = 0 )\n        rmsd_tolerance = rmsd( old_average_struct_coords, average_struct_coords )\n        cycle_count += 1\n    return coords"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget a specific device object from the given target.", "response": "def get_device(target=None, user='admin', passwd='admin', nos_only=False):\n    \"\"\"\n    Automatically determine device type based on device interrogation.\n    :param target: IP address or hostname of target\n    :param user: Username to login to target\n    :param passwd: Password to login to target\n    :param nos_only: Only check for device nos and return as string, do not return device object\n    :return: Device object\n    \"\"\"\n    dev_table = {\n        'nxos': aeon.nxos.device.Device,\n        'eos': aeon.eos.device.Device,\n        'cumulus': aeon.cumulus.device.Device,\n        'ubuntu': aeon.ubuntu.device.Device,\n        'centos': aeon.centos.device.Device\n    }\n    try:\n        # Use paramiko to check if device is reachable because pxssh is bad at that.\n        ssh = paramiko.SSHClient()\n        ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n        ssh.connect(target, username=user, password=passwd, timeout=5)\n        ssh.close()\n    except socket.error:\n        raise TargetError('Device unreachable: %s' % target)\n    except paramiko.AuthenticationException:\n        raise TargetError('Authentication error: %s' % target)\n    except paramiko.SSHException:\n        raise TargetError('Error logging in: %s' % target)\n\n    try:\n        nos = ''\n        session = pxssh.pxssh(timeout=10, options={'StrictHostKeyChecking': \"no\",\n                                       'UserKnownHostsFile': \"/dev/null\"})\n        session.force_password = True\n        session.PROMPT = '\\r\\n.*#|\\r\\n.*$'\n        session.login(target, user, password=passwd, auto_prompt_reset=False, login_timeout=10)\n        session.sendline('show version')\n        i = session.expect(['Cisco', 'Arista', 'command not found', 'not installed', pexpect.TIMEOUT], timeout=10)\n        if i == 0:\n            nos = 'nxos'\n        if i == 1:\n            nos = 'eos'\n\n        if i == 2 or i == 3:\n            session.sendline('cat /proc/version')\n            i = session.expect(['cumulus', 'Ubuntu', 'Red Hat', pexpect.TIMEOUT], timeout=5)\n            if i == 0:\n                nos = 'cumulus'\n            if i == 1:\n                nos = 'ubuntu'\n            if i == 2:\n                nos = 'centos'\n            if i == 3:\n                session.sendline('[ -f /etc/opx/opx-environment.sh ] && echo \"device is OPX\" || echo \"Not found\"')\n                i = session.expect(['Not found', 'device is OPX', pexpect.TIMEOUT], timeout=5)\n                if i == 0 or i == 2:\n                    raise TargetError('Unable to determine device type for %s' % target)\n                if i == 1:\n                    nos = 'opx'\n        if i == 4:\n            raise TargetError('Unable to determine device type for %s' % target)\n\n    except pxssh.ExceptionPxssh as e:\n        raise TargetError(\"Error logging in to {target} : {error}\".format(target=target, error=e))\n\n    finally:\n        session.close()\n\n    if nos_only:\n        return nos\n    else:\n        return dev_table[nos](target, user=user, passwd=passwd)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_valid(self, *states):\n\n        # if no state is specified, fallback to the base Form's is_valid\n        if not states:\n            return super(StateValidatorFormMixin, self).is_valid()\n\n        return all(self.state_validators[state].is_valid(self)\n                   for state in states)", "response": "Returns True if no errors are thrown for the specified state."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_valid(self, instance):\n\n        errors = self.errors(instance)\n\n        if isinstance(errors, list):\n            return not any(errors)\n\n        return not bool(errors)", "response": "Return True if the instance is valid."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _validate(self, data):\n\n        errors = {}\n\n        # if the validator is not enabled, return the empty error dict\n        if not self._enabled:\n            return errors\n\n        for field in self.validators:\n\n            field_errors = []\n\n            for validator in self.validators[field]:\n                try:\n                    validator(data.get(field, None))\n                except ValidationError as e:\n                    field_errors += e.messages\n\n            # if there were errors, cast to ErrorList for output convenience\n            if field_errors:\n                errors[field] = ErrorList(field_errors)\n\n        return errors", "response": "Helper to run validators on the field data."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef errors(self, instance):\n\n        if isinstance(instance, dict):\n            return self._validate(instance)\n\n        elif isinstance(instance, forms.BaseForm):\n            if instance.is_bound and instance.is_valid():\n                return self._validate(instance.cleaned_data)\n\n            return self._validate(dict(\n                [\n                    (f, instance.initial.get(f, instance[f].value()))\n                    for f in self.validators\n                    ]\n                ))\n\n        elif isinstance(instance, formsets.BaseFormSet):\n            if instance.can_delete:\n                validate_forms = [\n                    form for form in instance.initial_forms\n                    if not instance._should_delete_form(form)\n                    ] + [\n                    form for form in instance.extra_forms\n                    if (form.has_changed() and\n                        not instance._should_delete_form(form))\n                    ]\n\n                return [\n                    self.errors(f)\n                    for f in validate_forms\n                    ]\n            else:\n                validate_forms = instance.initial_forms + [\n                    form for form in instance.extra_forms\n                    if form.has_changed()\n                    ]\n                return [self.errors(f) for f in validate_forms]\n\n        elif isinstance(instance, models.Model):\n            return self._validate(dict(\n                [(f, getattr(instance, f)) for f in self.validators]\n                ))", "response": "Run all field validators and return a dict of errors."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nshow computed fields based on QuerySet s.", "response": "def qs_field(\n    model_class,\n    field,\n    filters=None,\n    formatter=queryset_formatter,\n    manager_name='objects',\n):\n    \"\"\"\n    Show computed fields based on QuerySet's.\n\n    This is a workaround since sometimes some filtering is involved to see if a user\n    owns and object, is a student, etc.\n\n    Example\n    -------\n    class MyModel(ModelView):\n        details_extra_columns = [\n            ('courses_owned', 'Courses (Owner of)'),\n        ]\n        column_formatters_detail = {\n            'courses_owner': qs_field(model.Course, 'owner'),\n        ]\n    \"\"\"\n    if filters is None:\n        filters = {}\n\n    def _(view, context, _model, name):\n        filters[field] = _model  # e.g. students: user\n\n        # e.g. User.objects, User.deleted_objects\n        manager = getattr(model_class, manager_name)\n        return formatter(manager(**filters))\n\n    return _"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_pdb_id(self, elem, **kwargs):\n        '''If self.restrict_to_transmembrane_proteins is False then this adds all ids to self.ids. Otherwise, only transmembrane protein ids are added.'''\n        id = elem.attrib['ID']\n        if self.restrict_to_transmembrane_proteins:\n            tmp = elem.attrib['TMP']\n            assert(tmp == 'no' or tmp == 'yes' or tmp == 'not')\n            if tmp == 'yes':\n                self.ids[id] = PDBTM._get_tm_type(elem)\n        else:\n            self.ids[id] = self.ids.get(id, 0) + 1", "response": "Get the PDB ID from the XML element."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a dict mapping PDB IDs to PDB IDs.", "response": "def get_pdb_id_map(self):\n        ''' Returns a dict mapping PDB IDs to:\n                i) their number of associated records, if self.restrict_to_transmembrane_proteins is False;\n               ii) the type of transmembrane protein if self.restrict_to_transmembrane_proteins is True.\n            At the time of writing this (2014-12-03), there were 106,094 PDB IDs and 106,090 unique IDs.\n            These records had duplicate entries: '2amk', '2ar1', '3b4r', '4k5y'.'''\n        self.ids = {}\n        context = etree.iterparse(io.BytesIO(self.xml_contents), events=('end',), tag=self.PDBTM_entry_tag_type)\n        fast_iter(context, self._get_pdb_id)\n        return self.ids"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_membrane_xml(self, pdb_id):\n        ''' Returns the <MEMBRANE> tag XML for pdb_id if the tag exists.'''\n        self.tmp_string = None\n        context = etree.iterparse(io.BytesIO(self.xml_contents), events=('end',), tag=self.PDBTM_entry_tag_type)\n        try:\n            fast_iter(context, self._get_membrane_xml, pdb_id = pdb_id.upper())\n        except EarlyOut: pass\n        return self.tmp_string", "response": "Returns the XML for the MEBRANE tag for pdb_id if the tag exists."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_xml(self, pdb_id):\n        ''' Returns the XML for pdb_id if the tag exists.'''\n        self.tmp_string = None\n        context = etree.iterparse(io.BytesIO(self.xml_contents), events=('end',), tag=self.PDBTM_entry_tag_type)\n        try:\n            fast_iter(context, self._get_xml, pdb_id = pdb_id.upper())\n        except EarlyOut: pass\n        return self.tmp_string", "response": "Returns the XML for pdb_id if the tag exists."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef copy(self, contents=True):\n        '''Create a copy of this model, optionally without contents (i.e. just configuration)'''\n        cp = connection(collection=self._db_coll, baseiri=self._baseiri)\n        if contents: cp.add_many(self._relationships)\n        return cp", "response": "Create a copy of this model optionally without contents ( i. e. just configuration )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef size(self):\n        '''Return the number of links in the model'''\n        count = 0\n        cursor = self._db_coll.find()\n        for item in cursor:\n            if item['origin'] == '@_abbreviations':\n                continue\n            count += len(item['rels'])\n        return count", "response": "Return the number of links in the model"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nyields the set of identifiers that match a pattern of components.", "response": "def match(self, origin=None, rel=None, target=None, attrs=None, include_ids=False):\n        '''\n        Iterator over relationship IDs that match a pattern of components\n\n        origin - (optional) origin of the relationship (similar to an RDF subject). If omitted any origin will be matched.\n        rel - (optional) type IRI of the relationship (similar to an RDF predicate). If omitted any relationship will be matched.\n        target - (optional) target of the relationship (similar to an RDF object), a boolean, floating point or unicode object. If omitted any target will be matched.\n        attrs - (optional) attribute mapping of relationship metadata, i.e. {attrname1: attrval1, attrname2: attrval2}. If any attribute is specified, an exact match is made (i.e. the attribute name and value must match).\n        include_ids - If true include statement IDs with yield values\n        '''\n        abbrevs = self._abbreviations()\n        index = 0\n        if origin is None:\n            cursor = self._db_coll.find()\n        else:\n            cursor = self._db_coll.find({'origin': origin})\n            \n        for item in cursor:\n            if item['origin'] == '@_abbreviations':\n                continue\n            if origin != item['origin']:\n                continue\n            for xrel_obj in item['rels']:\n                xrelid = xrel_obj['rid'].format(**abbrevs)\n                if rel and rel != xrelid:\n                    continue\n                for xtarget, xattrs in xrel_obj['instances']:\n                    xtarget = xtarget.format(**abbrevs)\n                    if target and target != xtarget:\n                        continue\n                    matches = True\n                    if attrs:\n                        for k, v in attrs.items():\n                            if k not in xattrs or xattrs.get(k) != v:\n                                matches = False\n                    if matches:\n                        yield index, (origin, xrelid, xtarget, xattrs)\n                        index += 1\n\n                    #if matches:\n                    #    if include_ids:\n                    #        yield index, (curr_rel[0], curr_rel[1], curr_rel[2], curr_rel[3].copy())\n                    #    else:\n                    #        yield (curr_rel[0], curr_rel[1], curr_rel[2], curr_rel[3].copy())\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add(self, origin, rel, target, attrs=None):\n        '''\n        Add one relationship to the model\n\n        origin - origin of the relationship (similar to an RDF subject)\n        rel - type IRI of the relationship (similar to an RDF predicate)\n        target - target of the relationship (similar to an RDF object), a boolean, floating point or unicode object\n        attrs - optional attribute mapping of relationship metadata, i.e. {attrname1: attrval1, attrname2: attrval2}\n        '''\n        if not origin: \n            raise ValueError('Relationship origin cannot be null')\n        if not rel: \n            raise ValueError('Relationship ID cannot be null')\n\n        attrs = attrs or {}\n\n        origin_item = self._db_coll.find_one({'origin': origin})\n        rel = self._abbreviate(rel)\n        target = self._abbreviate(target)\n        rel_info = {'rid': rel, 'instances': [[target, attrs]]}\n        if origin_item is None:\n            self._db_coll.insert_one(\n                {\n                    'origin': origin,\n                    'rels': [rel_info],\n                }\n            )\n        else:\n            origin_item['rels'].append(rel_info)\n            self._db_coll.replace_one(\n                {'origin': origin}, origin_item\n            )\n        return", "response": "Add one relationship to the model"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove one or more relationship by index from the extent", "response": "def remove(self, index):\n        '''\n        Delete one or more relationship, by index, from the extent\n\n        index - either a single index or a list of indices\n        '''\n        raise NotImplementedError\n        if hasattr(index, '__iter__'):\n            ind = set(index)\n        else:\n            ind = [index]\n\n        # Rebuild relationships, excluding the provided indices\n        self._relationships = [r for i, r in enumerate(self._relationships) if i not in ind]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nabbreviate a relationship or resource ID target for efficient storage.", "response": "def _abbreviate(self, rid):\n        '''\n        Abbreviate a relationship or resource ID target for efficient storage\n        in the DB. Works only with a prefix/suffix split of hierarchical HTTP-like IRIs,\n        e.g. 'http://example.org/spam/eggs' becomes something like '{a23}eggs'\n        and afterward there will be an entry in the prefix map from 'a23' to 'http://example.org/spam/'\n        The map can then easily be used with str.format\n        '''\n        if not isinstance(rid, str) or not iri.matches_uri_syntax(rid): return rid\n        head, tail = rid.rsplit('/', 1)\n        head += '/'\n        abbrev_obj = self._db_coll.find_one({'origin': '@_abbreviations'})\n        assert abbrev_obj is not None\n        pmap = abbrev_obj['map']\n        #FIXME: probably called too often to do this every time\n        inv_pmap = {v: k for k, v in pmap.items()}\n        if head in inv_pmap:\n            prefix = inv_pmap[head]\n        else:\n            prefix = f'a{self._abbr_index}'\n            pmap[prefix] = head\n            self._abbr_index += 1\n            self._db_coll.replace_one(\n                {'origin': '@_abbreviations'},\n                {'origin': '@_abbreviations', 'map': pmap}\n            )\n        post_rid = '{' + prefix + '}' + tail\n        return post_rid"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def act(self):\n        '''Agent's main method to create new spirographs.\n\n        See Simulation and CreativeAgent documentation for details.\n        '''\n        # Learn from domain artifacts.\n        self.age += 1\n        self.added_last = False\n        self.learn_from_domain(method=self.env_learning_method,\n                               amount=self.env_learning_amount)\n        # Invent new artifact\n        artifact = self.invent(self.search_width)\n        args = artifact.framings[self.name]['args']\n        val = artifact.evals[self.name]\n        self._log(logging.DEBUG, \"Created spirograph with args={}, val={}\"\n                  .format(args, val))\n        self.spiro_args = args\n        self.arg_history.append(self.spiro_args)\n        self.add_artifact(artifact)\n        if val >= self._own_threshold:\n            artifact.self_criticism = 'pass'\n            # Train SOM with the invented artifact\n            self.learn(artifact, self.teaching_iterations)\n            # Save images if logger is defined\n            # Add created artifact to voting candidates in the environment\n            self.add_candidate(artifact)\n            self.added_last = True\n        elif self.jump == 'random':\n            largs = self.spiro_args\n            self.spiro_args = np.random.uniform(-199, 199,\n                                                self.spiro_args.shape)\n            self._log(logging.DEBUG, \"Jumped from {} to {}\"\n                      .format(largs, self.spiro_args))\n        self.save_images(artifact)", "response": "Create new spirograph and train the SOM with the invented environment."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef learn_from_domain(self, method='random', amount=10):\n        '''Learn SOM from artifacts introduced to the environment.\n\n        :param str method:\n            learning method, should be either 'random' or 'closest', where\n            'random' chooses **amount** random artifacts, and 'closest' samples\n            closest artifacts based on spirograph generation artifacts.\n        :param int amount:\n            Maximum amount of artifacts sampled\n        :param bool last:\n            Learn from last domain artifact in any case\n        '''\n        if method == 'none':\n            return\n        arts = self.env.artifacts\n        if len(arts) == 0:\n            return\n        if 'random' in method:\n            samples = min(len(arts), amount)\n            ars = np.random.choice(arts, samples, replace=False)\n            for a in ars:\n                self.learn(a, self.teaching_iterations)\n        if 'closest' in method:\n            ars = arts\n            dists = []\n            for a in ars:\n                args = a.framings[a.creator]['args']\n                d = np.sqrt(np.sum(np.square(args - self.spiro_args)))\n                dists.append((d,a))\n            dists.sort(key=operator.itemgetter(0))\n            for d,a in dists[:amount]:\n                self.learn(a, self.teaching_iterations)", "response": "Learn SOM from artifacts introduced to the environment."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nplots distances of the generated spirographs w. r. t. the previously generated spirogaphs.", "response": "def plot_distances(self, mean_dist, distances, indeces):\n        '''Plot distances of the generated spirographs w.r.t. the previously\n        generated spirogaphs.\n        '''\n        from matplotlib import pyplot as plt\n        x = np.arange(len(distances))\n        y = [mean_dist for i in x]\n        fig, ax = plt.subplots()\n        data_line = ax.plot(indeces, distances, label='Min Distance to previous',\n                        marker='.', color='black', linestyle=\"\")\n        mean_line = ax.plot(indeces, y, label='Mean', linestyle='--', color='green')\n        if len(distances) > 0:\n            z = np.poly1d(np.polyfit(x,distances,2))\n            f = [z(i) for i in x]\n            mean_line = ax.plot(indeces, f, label='Fitted', linestyle='-', color='red')\n        legend = ax.legend(loc='upper right', prop={'size':8})\n        agent_vars = \"{}_{}_{}{}_last={}_stmem=list{}_veto={}_sc={}_jump={}_sw={}_mr={}_maxN\".format(\n            self.sanitized_name(), self.age, self.env_learning_method, self.env_learning_amount, self.env_learn_on_add,\n            self.stmem.length, self._novelty_threshold, self._own_threshold,\n            self.jump, self.search_width, self.move_radius)\n        ax.set_title(\"{} min distances: env_learn={} {}\"\n                     .format(self.name, self.env_learning_method,\n                             self.env_learning_amount))\n        ax.set_ylabel('min distance to preceding artifact')\n        ax.set_xlabel('iteration')\n        if self.logger is not None:\n            imname = os.path.join(self.logger.folder, '{}_dists.png'.format(agent_vars))\n            plt.savefig(imname)\n            plt.close()\n        else:\n            plt.show()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef init_app(self, app):\n        self.init_config(app)\n        app.extensions['invenio-pidrelations'] = _InvenioPIDRelationsState(app)", "response": "Initialize the Flask application."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_qtls_matrix(qtl_matrix, matrix, inputfile):\n    trait_name = inputfile.split(')_', 1)[1].split('.mqo')[0]\n    matrix = list(zip(*matrix))\n    if matrix[4][0] != 'LOD':\n        raise MQ2Exception(\n            'The file \"%s\" is not supported by MQ2. It may contain an '\n            'analysis which does not return LOD values '\n            '(such as Kruskal-Wallis or permutation test).' % inputfile)\n\n    if not qtl_matrix:\n        qtl_matrix = matrix[:4]\n    else:\n        if matrix[:4] != qtl_matrix[:4]:\n            raise MQ2NoMatrixException(\n                'The map used in the file \"%s\" does not'\n                ' correspond to the map used in at least one other file.'\n                % inputfile)\n    tmp = list(matrix[4])\n    tmp[0] = trait_name\n    qtl_matrix.append(tmp)\n    return qtl_matrix", "response": "This function extracts for each position the LOD value obtained and saves it in a\n    matrix."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the matrix representation of the genetic map.", "response": "def get_map_matrix(inputfile):\n    \"\"\" Return the matrix representation of the genetic map.\n\n    :arg inputfile: the path to the input file from which to retrieve the\n        genetic map.\n\n    \"\"\"\n    matrix = read_input_file(inputfile)\n    output = []\n    for row in matrix:\n        if row[3]:\n            output.append([row[3], row[1], row[2]])\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nextracts the QTLs found by MapQTL reading its file.", "response": "def get_qtls_from_mapqtl_data(matrix, threshold, inputfile):\n    \"\"\"Extract the QTLs found by MapQTL reading its file.\n    This assume that there is only one QTL per linkage group.\n\n    :arg matrix, the MapQTL file read in memory\n    :arg threshold, threshold used to determine if a given LOD value is\n        reflective the presence of a QTL.\n    :arg inputfile, name of the inputfile in which the QTLs have been\n        found\n\n    \"\"\"\n    trait_name = inputfile.split(')_', 1)[1].split('.mqo')[0]\n    qtls = []\n    qtl = None\n    for entry in matrix[1:]:\n        if qtl is None:\n            qtl = entry\n        if qtl[1] != entry[1]:\n            if float(qtl[4]) > float(threshold):\n                qtl[0] = trait_name\n                qtls.append(qtl)\n            qtl = entry\n        if entry[4] == '':  # pragma: no cover\n            entry[4] = 0\n        if qtl[4] == '':  # pragma: no cover\n            qtl[4] = 0\n        if float(entry[4]) > float(qtl[4]):\n            qtl = entry\n\n    if float(qtl[4]) > float(threshold):\n        qtl[0] = trait_name\n        if qtl not in qtls:\n            qtls.append(qtl)\n\n    return qtls"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if the provided file is a valid file for this plugin.", "response": "def valid_file(cls, filename):\n        \"\"\" Check if the provided file is a valid file for this plugin.\n\n        :arg filename: the path to the file to check.\n\n        \"\"\"\n        return not os.path.isdir(filename) \\\n            and os.path.basename(filename).startswith('Session ') \\\n            and filename.endswith('.mqo')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nretrieve the list of files that can be used to check the MapQTL output.", "response": "def get_files(cls, folder, session_id=''):\n        \"\"\" Retrieve the list of files the plugin can work on.\n        Find this list based on the files name, files extension or even\n        actually by reading in the file.\n        If a session identifier is specified it will restrict the list\n        of files returned to those with this session identifier in their\n        name.\n\n        :arg folder: the path to the folder containing the files to\n            check. This folder may contain sub-folders.\n        :kwarg session_id: the session identifier of the MapQTL output\n            to process.\n\n        \"\"\"\n        filelist = []\n        if folder is None or not os.path.isdir(folder):\n            return filelist\n        if session_id is None:\n            session_id = ''\n        for root, dirs, files in os.walk(folder):\n            for filename in files:\n                if filename.startswith('Session %s' % session_id) \\\n                        and filename.endswith('.mqo'):\n                    filename = os.path.join(root, filename)\n                    filelist.append(filename)\n        return filelist"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_session_identifiers(cls, folder=None, inputfile=None):\n        sessions = []\n        if folder is None or not os.path.isdir(folder):\n            return sessions\n        for root, dirs, files in os.walk(folder):\n            for filename in files:\n                if filename.startswith('Session ') \\\n                        and filename.endswith('.mqo'):\n                    session = filename.split()[1]\n                    if session not in sessions:\n                        sessions.append(session)\n        return sessions", "response": "Retrieve the list of session identifiers contained in the\n            check folder."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert the input files present in the given folder or inputfile. This method creates the matrix representation of the QTLs results providing for each marker position the LOD value found for each trait as well as a representation of the genetic map used in the experiment. The genetic map should be cleared of any markers added by the QTL mapping software. :kwarg folder: the path to the folder containing the files to check. This folder may contain sub-folders. :kwarg inputfile: the path to the input file to use :kwarg session: the session identifier used to identify which session to process :kwarg lod_threshold: the LOD threshold to apply to determine if a QTL is significant or not :kwarg qtls_file: a csv file containing the list of all the significant QTLs found in the analysis. The matrix is of type: trait, linkage group, position, Marker, LOD other columns :kwarg matrix_file: a csv file containing a matrix representation of the QTL data. This matrix is of type: marker, linkage group, position, trait1 lod, trait2, lod :kwarg map_file: a csv file containing the genetic map used in this experiment. The map is of structure: marker, linkage group, position", "response": "def convert_inputfiles(cls,\n                           folder=None,\n                           inputfile=None,\n                           session=None,\n                           lod_threshold=None,\n                           qtls_file='qtls.csv',\n                           matrix_file='qtls_matrix.csv',\n                           map_file='map.csv'):\n        \"\"\" Convert the input files present in the given folder or\n        inputfile.\n        This method creates the matrix representation of the QTLs\n        results providing for each marker position the LOD value found\n        for each trait as well as a representation of the genetic map\n        used in the experiment.\n        The genetic map should be cleared of any markers added by the\n        QTL mapping software.\n\n        :kwarg folder: the path to the folder containing the files to\n            check. This folder may contain sub-folders.\n        :kwarg inputfile: the path to the input file to use\n        :kwarg session: the session identifier used to identify which\n            session to process\n        :kwarg lod_threshold: the LOD threshold to apply to determine if\n            a QTL is significant or not\n        :kwarg qtls_file: a csv file containing the list of all the\n            significant QTLs found in the analysis.\n            The matrix is of type:\n               trait, linkage group, position, Marker, LOD other columns\n        :kwarg matrix_file: a csv file containing a matrix representation\n            of the QTL data. This matrix is of type:\n               marker, linkage group, position, trait1 lod, trait2, lod\n        :kwarg map_file: a csv file containing the genetic map used\n            in this experiment. The map is of structure:\n               marker, linkage group, position\n\n        \"\"\"\n        if folder is None and inputfile is None:\n            raise MQ2Exception('You must specify either a folder or an '\n                               'input file')\n\n        sessions = cls.get_session_identifiers(folder)\n        if session is None:\n            raise MQ2NoSessionException(\n                'The MapQTL plugin requires a session identifier to '\n                'identify the session to process.'\n                'Sessions are: %s' % ','.join(sessions))\n        elif str(session) not in sessions:\n            raise MQ2NoSuchSessionException(\n                'The MapQTL session provided (%s) could not be found in the '\n                'dataset. '\n                'Sessions are: %s' % (session, ','.join(sessions)))\n\n        if folder is not None:\n            if not os.path.isdir(folder):  # pragma: no cover\n                raise MQ2Exception('The specified folder is actually '\n                                   'not a folder')\n            else:\n                inputfiles = cls.get_files(folder, session_id=session)\n\n        if inputfile is not None:  # pragma: no cover\n            if os.path.isdir(inputfile):\n                raise MQ2Exception('The specified input file is actually '\n                                   'a folder')\n            else:\n                inputfiles = [inputfile]\n\n        try:\n            lod_threshold = float(lod_threshold)\n        except ValueError:\n            raise MQ2Exception('LOD threshold should be a number')\n\n        inputfiles.sort()\n\n        # QTL matrix and QTL files\n        qtl_matrix = []\n        qtls = []\n        filename = None\n        for filename in inputfiles:\n            matrix = read_input_file(filename)\n            headers = matrix[0]\n            qtl_matrix = get_qtls_matrix(qtl_matrix, matrix, filename)\n            qtls.extend(get_qtls_from_mapqtl_data(matrix, lod_threshold,\n                        filename))\n        # format QTLs and write down the selection\n        headers[0] = 'Trait name'\n        qtls.insert(0, headers)\n        write_matrix(qtls_file, qtls)\n\n        # Write down the QTL matrix\n        del(qtl_matrix[0])\n        # Reorganize a couple of columns\n        qtl_matrix.insert(0, qtl_matrix[2])\n        del(qtl_matrix[3])\n        # write output\n        qtl_matrix = list(zip(*qtl_matrix))\n        write_matrix(matrix_file, qtl_matrix)\n\n        # Map matrix\n        map_matrix = get_map_matrix(inputfiles[0])\n        write_matrix(map_file, map_matrix)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing the string s which contains indices and ranges and returns the explicit list of integers defined by s. Written by Laurens Kraal 2014. Written by Laurens Kraal 2014. Written by Laurens Kraal 2014. Written by Laurens Kraal 2014. Written by Laurens Kraal 2014. Written by Laurens Kraal 2014.", "response": "def parse_range(s, range_separator = '-'):\n    ''' Parses the string s which contains indices and ranges and returns the explicit list of integers defined by s.\n        Written by Laurens Kraal 2014.\n    '''\n    return reduce(lambda x,y: x+y, (map(lambda r: (range(int(r.split(range_separator)[0]), int(r.split(range_separator)[1])+1)) if range_separator in r else [int(r)], s.split(','))))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_range_pairs(s, range_separator = '-', convert_to_tuple = True):\n    ''' Based on parse_range but instead returns a list of lists with the ranges. A single index n is returned as a range (n, n)\n        whereas a range m-n is returned as (m, n) if m <= n, else (n, m).\n    '''\n    result = map(sorted,\n       map(lambda r:\n            (int(r.split(range_separator)[0]), int(r.split(range_separator)[1])) if range_separator in r\n            else (int(r), int(r)),\n            s.split(',')))\n    if convert_to_tuple:\n        return tuple(map(tuple, result))\n    return result", "response": "Based on parse_range but instead returns a list of lists with the ranges."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef merge_range_pairs(prs):\n    '''Takes in a list of pairs specifying ranges and returns a sorted list of merged, sorted ranges.'''\n    new_prs = []\n    sprs = [sorted(p) for p in prs]\n    sprs = sorted(sprs)\n    merged = False\n    x = 0\n    while x < len(sprs):\n        newx = x + 1\n        new_pair = list(sprs[x])\n        for y in range(x + 1, len(sprs)):\n            if new_pair[0] <= sprs[y][0] - 1 <= new_pair[1]:\n                new_pair[0] = min(new_pair[0], sprs[y][0])\n                new_pair[1] = max(new_pair[1], sprs[y][1])\n                newx = y + 1\n        if new_pair not in new_prs:\n            new_prs.append(new_pair)\n        x = newx\n    return new_prs", "response": "Takes in a list of pairs specifying ranges and returns a sorted list of merged sorted ranges."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef split_pdb_residue(s):\n    '''Splits a PDB residue into the numeric and insertion code components.'''\n    if s.isdigit():\n        return (int(s), ' ')\n    else:\n        assert(s[:-1].isdigit())\n        return ((s[:-1], s[-1]))", "response": "Splits a PDB residue into the numeric and insertion code components."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntake in a list of PDB residue IDs including insertion codes and returns a sorted list of merged ranges.", "response": "def merge_pdb_range_pairs(prs):\n    '''Takes in a list of PDB residue IDs (including insertion codes) specifying ranges and returns a sorted list of merged, sorted ranges.\n       This works as above but we have to split the residues into pairs as  \"1A\" > \"19\".\n    '''\n    new_prs = []\n    sprs = [sorted((split_pdb_residue(p[0]), split_pdb_residue(p[1]))) for p in prs]\n    sprs = sorted(sprs)\n    merged = False\n    x = 0\n    from klab import colortext\n    while x < len(sprs):\n        newx = x + 1\n        new_pair = list(sprs[x])\n        for y in range(x + 1, len(sprs)):\n            if new_pair[0] <= (sprs[y][0][0] - 1, sprs[y][0][1]) <= new_pair[1]:\n                new_pair[0] = min(new_pair[0], sprs[y][0])\n                new_pair[1] = max(new_pair[1], sprs[y][1])\n                newx = y + 1\n        if new_pair not in new_prs:\n            new_prs.append(new_pair)\n        x = newx\n    return new_prs"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef mail_message(smtp_server, message, from_address, rcpt_addresses):\n    if smtp_server[0] == '/':\n        # Sending the message with local sendmail\n        p = os.popen(smtp_server, 'w')\n        p.write(message)\n        p.close()\n    else:\n        # Sending the message using a smtp server\n        import smtplib\n\n        server = smtplib.SMTP(smtp_server)\n        server.sendmail(from_address, rcpt_addresses, message)\n        server.quit()", "response": "Send a message using the SMTP server"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a human - readable value with unit specification.", "response": "def get_value_unit(value, unit, prefix):\n    \"\"\"\n    Return a human-readable value with unit specification. Try to\n    transform the unit prefix to the one passed as parameter. When\n    transform to higher prefix apply nearest integer round. \n    \"\"\"\n    prefixes = ('', 'K', 'M', 'G', 'T')\n\n    if len(unit):\n        if unit[:1] in prefixes:\n            valprefix = unit[0] \n            unit = unit[1:]\n        else:\n            valprefix = ''\n    else:\n        valprefix = ''\n    \n    while valprefix != prefix:\n        uidx = prefixes.index(valprefix)\n\n        if uidx > prefixes.index(prefix):\n            value *= 1024\n            valprefix = prefixes[uidx-1]\n        else:\n            if value < 10240:\n                return value, '{0}{1}'.format(valprefix, unit)\n            value = int(round(value/1024.0))\n            valprefix = prefixes[uidx+1]\n    return value, '{0}{1}'.format(valprefix, unit)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a string that can be used as an HTML snippet.", "response": "def htmlsafe(unsafe):\n    \"\"\"\n    Escapes all x(ht)ml control characters.\n    \"\"\"\n    unsafe = unsafe.replace('&', '&amp;')\n    unsafe = unsafe.replace('<', '&lt;')\n    unsafe = unsafe.replace('>', '&gt;')\n    return unsafe"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of formatted strings representation on a result dictionary.", "response": "def get_fmt_results(results, limit=5, sep='::', fmt=None):\n    \"\"\"\n    Return a list of formatted strings representation on a result dictionary.\n    The elements of the key are divided by a separator string. The result is\n    appended after the key between parentheses. Apply a format transformation\n    to odd elements of the key if a fmt parameter is passed.\n    \"\"\"\n    result_list = []\n    for key in sorted(results, key=lambda x: results[x], reverse=True):\n        if len(result_list) >= limit and results[key] <= 1:\n            break\n        if fmt is not None:\n            fmtkey = []\n            for i in range(len(key)):\n                if i % 2 == 1:\n                    fmtkey.append(fmt.format(key[i]))\n                else:\n                    fmtkey.append(key[i])\n            result_list.append(u'{0}({1})'.format(sep.join(fmtkey), results[key]))\n        else:\n            result_list.append(u'{0}({1})'.format(sep.join(key), results[key]))\n    else:\n        return result_list\n    if fmt is not None:\n        result_list.append(fmt.format(u'[%d more skipped]' % (len(results) - len(result_list))))\n    else:\n        result_list.append(u'[%d more skipped]' % (len(results) - len(result_list)))\n    return result_list"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsafes string template expansion.", "response": "def safe_expand(template, mapping):\n    \"\"\"\n    Safe string template expansion. Raises an error if the provided substitution mapping has circularities.\n    \"\"\"\n    for _ in range(len(mapping) + 1):\n        _template = template\n        template = string.Template(template).safe_substitute(mapping)\n        if template == _template:\n            return template\n    else:\n        raise ValueError(\"circular mapping provided!\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef protected_property(func):\n    if func.__name__.startswith('_'):\n        raise ValueError(\"%r: Cannot decorate a protected method!\" % func)\n\n    @property\n    @wraps(func)\n    def proxy_wrapper(self):\n        try:\n            return getattr(self, '_%s' % func.__name__)\n        except AttributeError:\n            pass\n        return func(self)\n\n    return proxy_wrapper", "response": "A protected property decorator that creates a property that returns the protected attribute\n    or the value returned by the wrapped method."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nopen a resource in binary reading mode.", "response": "def open_resource(source):\n    \"\"\"\n    Opens a resource in binary reading mode. Wraps the resource with a\n    context manager when it doesn't have one.\n\n    :param source: a filepath or an URL.\n    \"\"\"\n    try:\n        return open(source, mode='rb')\n    except (IOError, OSError) as err:\n        try:\n            resource = urlopen(source)\n        except ValueError:\n            pass\n        else:\n            resource.name = resource.url\n            if hasattr(resource, '__enter__'):\n                return resource\n            else:\n                return closing(resource)\n        raise err\n    except TypeError:\n        if hasattr(source, 'read') and hasattr(source, 'readlines'):\n            return source  # Source is already a file-like object\n        raise"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef devices(self, value):\n\n        if value is None:\n            self._devices = None\n\n        elif isinstance(value, list):\n            results = []\n            delimiter = ':'\n\n            for device in value:\n                if not isinstance(device, six.string_types):\n                    raise TypeError(\"each device must be a str. {0} was passed\".format(device))\n\n                occurrences = device.count(delimiter)\n                permissions = 'rwm'\n\n                if occurrences is 0:\n                    path_on_host = device\n                    path_in_container = device\n\n                elif occurrences is 1:\n                    path_on_host, path_in_container = device.split(delimiter)\n\n                elif occurrences is 2:\n                    path_on_host, path_in_container, permissions = device.split(delimiter)\n\n                    if permissions not in 'rwm':\n                        raise ValueError(\"only permissions supported for devices are any combination of  'r' 'w' 'm'.\")\n                else:\n                    raise ValueError(\n                        \"\"\"When passing devices they must be in one of the\n                        following formats: path_on_host, path_on_host:path_in_container,\n                        or path_on_host:path_in_container:permissions\"\"\"\n                    )\n\n                results.append(\"{0}:{1}:{2}\".format(path_on_host, path_in_container, permissions))\n\n            self._devices = results\n        else:\n            raise TypeError(\"devices must be a list or None.\")", "response": "Set the _devices attribute of the object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef log_config(self, value):\n        if not isinstance(value, dict):\n            raise TypeError(\"log_config must be a dict. {0} was passed\".format(value))\n\n        config      = value.get('config')\n        driver_type = value.get('type')\n\n        if driver_type not in VALID_LOG_DRIVER_TYPES:\n            raise ValueError(\"type must be one of the support drivers {0}\".format(\", \".join(VALID_LOG_DRIVER_TYPES)))\n\n        if config and not isinstance(config, dict):\n            raise ValueError(\"log_config.config must be a dict.\")\n\n        if driver_type == 'syslog':\n            config = {\n                'syslog-facility': config.get('syslog_facility', config.get('syslog-facility')),\n                'syslog-tag': config.get('syslog_tag', config.get('syslog-tag'))\n            }\n\n        self._log_config = {'type': driver_type, 'config': config or {}}", "response": "Set the log_config of the log entry."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the port bindings of the related user s log entry.", "response": "def port_bindings(self, value):\n        \"\"\"\n            {\n                u'8080/tcp': [\n                    {\n                        u'host_port': u'8080',\n                        u'host_ip': u''\n                    }\n                ]\n            }\n        \"\"\"\n        if isinstance(value, (list, dict)):\n                self._port_bindings = self._convert_port_bindings(value)\n        elif value is None:\n            self._port_bindings = None\n        else:\n            raise TypeError('port bindings must be a dict, list, or None. {0} was passed.'.format(type(value)))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the _extra_hosts attribute of the object.", "response": "def extra_hosts(self, value):\n        \"\"\"\n        :param value:\n        :return None:\n        \"\"\"\n        if value is None:\n            self._extra_hosts = value\n        elif isinstance(value, list):\n            # TODO: better validation\n            self._extra_hosts = value\n        elif isinstance(value, dict):\n            converted_extra_hosts = []\n            for k, v in sorted(six.iteritems(value)):\n                if not is_valid_hostname(k):\n                    raise ValueError(\"each key in extra hosts is required to be a valid hostname. {0} was passed\".format(k))\n\n                if not is_valid_ip(v):\n                    raise ValueError(\"each value in extra hosts is required to be a valid ip address. {0} was passed\".format(v))\n\n                converted_extra_hosts.append('{0}:{1}'.format(k, v))\n\n            self._extra_hosts = converted_extra_hosts\n        else:\n            raise TypeError(\"extra hosts must be a dict, list, or None. {0} was passed\".format(value))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef volumes_from(self, value):\n        volumes_from = []\n\n        if isinstance(value, list):\n            for volume_from in value:\n                if not isinstance(volume_from, six.string_types):\n                    raise TypeError(\"each bind must be a str. {0} was passed\".format(volume_from))\n\n                volumes_from.append(self._convert_volume_from(volume_from))\n        elif isinstance(value, six.string_types):\n            volumes_from.append(self._convert_volume_from(value))\n        elif value is None:\n            pass\n        else:\n            raise ValueError(\n                \"\"\"When passing binds they must be in one of the\n                following formats: container_path, host_path:container_path,\n                or host_path:container_path:permissions\"\"\"\n            )\n\n        self._volumes_from = volumes_from", "response": "Set the internal _volumes_from field of the object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting a volume_from string to a key - value string.", "response": "def _convert_volume_from(self, volume_from):\n        \"\"\"\n        :param volume_from:\n        :return:\n        \"\"\"\n        if ':' in volume_from:\n            container, permissions = volume_from.split(':')\n        else:\n            container = volume_from\n            permissions = 'rw'\n\n        if permissions not in ('ro', 'rw'):\n            raise ValueError(\"only permissions supported for volumes_from are rw and ro.\")\n\n        return \"{0}:{1}\".format(container, permissions)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a list of DNS entries for a given DNS entry.", "response": "def _create_dns_list(self, dns):\n        \"\"\"\n        :param dns:\n        :return:\n        \"\"\"\n        if not dns:\n            return None\n\n        dns_list = []\n\n        if isinstance(dns, six.string_types):\n            if is_valid_ip(dns):\n                dns_list.append(dns)\n            else:\n                raise ValueError(\"dns is required to be a valid ip adress. {0} was passed.\".format(dns))\n        elif isinstance(dns, list):\n            for dns_entry in dns:\n                if is_valid_ip(dns_entry):\n                    dns_list.append(dns_entry)\n            else:\n                raise ValueError(\"dns is required to be a valid ip adress. {0} was passed.\".format(dns))\n\n        else:\n            raise ValueError(\"dns and dns search must be a list or string. {0} was passed.\".format(dns))\n\n        return dns_list"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _convert_port_bindings(self, value):\n        converted = {}\n\n        if not value:\n            return converted\n\n        if isinstance(value, list):\n            value = self._convert_port_bindings_from_list(value)\n\n        if isinstance(value, dict):\n            for port_protocol, host_bindings in six.iteritems(value):\n                if '/' in port_protocol:\n                    port, protocol = port_protocol.split('/')\n\n                    if protocol not in ('tcp', 'udp'):\n                        raise ValueError('only supported protocols are tcp and udp. {0} was passed.'.format(protocol))\n                else:\n                    port_protocol = \"{0}/tcp\".format(port_protocol)\n\n                converted[port_protocol] = []\n\n                if isinstance(host_bindings, list):\n                    for host_binding in host_bindings:\n                        if isinstance(host_binding, dict):\n                            if \"host_port\" not in host_binding:\n                                raise ValueError(\"host_port must be provided.\")\n\n                            if 'host_ip' not in host_binding:\n                                host_binding['host_ip'] = ''\n\n                            converted[port_protocol].append(host_binding)\n                        else:\n                            raise TypeError(\"The host binding information must be a dict.\")\n                else:\n                    raise TypeError(\"The host binding information in port bindings must be in a list.\")\n\n        return converted", "response": "Convert port bindings to a dict."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef streamer(frontend, backend):\n    try:\n        context = zmq.Context()\n\n        front_pull = context.socket(zmq.PULL)\n        front_pull.set_hwm(0)\n        front_pull.bind(\"tcp://*:%d\" % frontend)\n\n        back_push = context.socket(zmq.PUSH)\n        back_push.bind(\"tcp://*:%d\" % backend)\n\n        print(\"streamer started, backend on port : %d\\tfrontend on port: %d\" % (backend, frontend))\n        zmq.proxy(front_pull, back_push)\n    except Exception as e:\n        print(e)\n    finally:\n        front_pull.close()\n        back_push.close()\n        context.term()", "response": "Simple push/pull streamer\n\n    :param int frontend: fontend zeromq port\n    :param int backend: backend zeromq port"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load(stream, fmt='lha'):\n    if fmt == 'lha':\n        return pylha.load(stream)\n    elif fmt == 'json':\n        if isinstance(stream, str):\n            return json.loads(stream)\n        else:\n            return json.load(stream)\n    elif fmt == 'yaml':\n        return yaml.load(stream)", "response": "Load a parameter file in DSixTools SLHA - like format or its JSON or\n    YAML representation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a matrix given a list of values of the form [[ 1 2 2... ] referring to the 1 - element etc.", "response": "def lha2matrix(values, shape):\n    \"\"\"Return a matrix given a list of values of the form\n    [[1, 1, float], [1, 2, float], ...]\n    referring to the (1,1)-element etc.\n    `shape` is the shape of the final matrix. All elements not provided\n    will be assumed to be zero. Also works for higher-rank tensors.\"\"\"\n    M = np.zeros(shape)\n    for v in values:\n        M[tuple([int(i-1) for i in v[:-1]])] = v[-1]\n    return M"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef matrix2lha(M):\n    l = []\n    ind = np.indices(M.shape).reshape(M.ndim, M.size).T\n    for i in ind:\n        l.append([j+1 for j in i] + [M[tuple(i)]])\n    return l", "response": "Inverse function to lha2matrix : return a LHA - like list given a tensor."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting a dictionary returned by pylha from a DSixTools SM input file into a dictionary of SM values.", "response": "def sm_lha2dict(lha):\n    \"\"\"Convert a dictionary returned by pylha from a DSixTools SM input file\n    into a dictionary of SM values.\"\"\"\n    d = OrderedDict()\n    v = dict(lha['BLOCK']['GAUGE']['values'])\n    d['g'] = v[1]\n    d['gp'] = v[2]\n    d['gs'] = v[3]\n    v = dict(lha['BLOCK']['SCALAR']['values'])\n    d['Lambda'] = v[1]\n    d['m2'] = v[2]\n    d['Gu'] = lha2matrix(lha['BLOCK']['GU']['values'], (3,3))\n    if 'IMGU' in lha['BLOCK']:\n        d['Gu'] = d['Gu'] + 1j*lha2matrix(lha['BLOCK']['IMGU']['values'], (3,3))\n    d['Gd'] = lha2matrix(lha['BLOCK']['GD']['values'], (3,3))\n    if 'IMGD' in lha['BLOCK']:\n        d['Gd'] = d['Gd'] + 1j*lha2matrix(lha['BLOCK']['IMGD']['values'], (3,3))\n    d['Ge'] = lha2matrix(lha['BLOCK']['GE']['values'], (3,3))\n    if 'IMGE' in lha['BLOCK']:\n        d['Ge'] = d['Ge'] + 1j*lha2matrix(lha['BLOCK']['IMGE']['values'], (3,3))\n    # thetas default to 0\n    if 'THETA' in lha['BLOCK']:\n        v = dict(lha['BLOCK']['THETA']['values'])\n        d['Theta'] = v.get(1, 0)\n        d['Thetap'] = v.get(2, 0)\n        d['Thetas'] = v.get(3, 0)\n    else:\n        d['Theta'] = 0\n        d['Thetap'] = 0\n        d['Thetas'] = 0\n    return d"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sm_dict2lha(d):\n    blocks = OrderedDict([\n        ('GAUGE', {'values': [[1, d['g'].real], [2, d['gp'].real], [3, d['gs'].real]]}),\n        ('SCALAR', {'values': [[1, d['Lambda'].real], [2, d['m2'].real]]}),\n        ('GU', {'values': matrix2lha(d['Gu'].real)}),\n        ('IMGU', {'values': matrix2lha(d['Gu'].imag)}),\n        ('GD', {'values': matrix2lha(d['Gd'].real)}),\n        ('IMGD', {'values': matrix2lha(d['Gd'].imag)}),\n        ('GE', {'values': matrix2lha(d['Ge'].real)}),\n        ('IMGE', {'values': matrix2lha(d['Ge'].imag)}),\n        ('THETA', {'values': [[1, d['Theta'].real], [2, d['Thetap'].real], [3, d['Thetas'].real]]}),\n        ])\n    return {'BLOCK': blocks}", "response": "Convert a dictionary of SM parameters into\n    a dictionary that pylha can convert into a DSixTools SM output file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef wc_lha2dict(lha):\n    C = OrderedDict()\n    # try to read all WCs with 0, 2, or 4 fermions; if not found, set to zero\n    for k, (block, i) in WC_dict_0f.items():\n        try:\n            C[k] = dict(lha['BLOCK'][block]['values'])[i]\n        except KeyError:\n            C[k] = 0\n    for k in definitions.WC_keys_2f:\n        try:\n            C[k] = lha2matrix(lha['BLOCK']['WC' + k.upper()]['values'], (3,3)).real\n        except KeyError:\n            C[k] = np.zeros((3,3))\n        try: # try to add imaginary part\n            C[k] = C[k] + 1j*lha2matrix(lha['BLOCK']['IMWC' + k.upper()]['values'], (3,3))\n        except KeyError:\n            pass\n    for k in definitions.WC_keys_4f:\n        try:\n            C[k] = lha2matrix(lha['BLOCK']['WC' + k.upper()]['values'], (3,3,3,3))\n        except KeyError:\n            C[k] = np.zeros((3,3,3,3))\n        try: # try to add imaginary part\n            C[k] = C[k] + 1j*lha2matrix(lha['BLOCK']['IMWC' + k.upper()]['values'], (3,3,3,3))\n        except KeyError:\n            pass\n    return C", "response": "Convert a dictionary returned by pylha from a DSixTools WC input file\n    into a dictionary of Wilson coefficients."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef wc_dict2lha(wc, skip_redundant=True, skip_zero=True):\n    d = OrderedDict()\n    for name, (block, i) in WC_dict_0f.items():\n        if block not in d:\n            d[block] = defaultdict(list)\n        if wc[name] != 0:\n            d[block]['values'].append([i, wc[name].real])\n    for name in definitions.WC_keys_2f:\n        reblock = 'WC'+name.upper()\n        imblock = 'IMWC'+name.upper()\n        if reblock not in d:\n            d[reblock] = defaultdict(list)\n        if imblock not in d:\n            d[imblock] = defaultdict(list)\n        for i in range(3):\n            for j in range(3):\n                if (i, j) in definitions.redundant_elements[name] and skip_redundant:\n                    # skip redundant elements\n                    continue\n                if wc[name][i, j].real != 0 or not skip_zero:\n                    d[reblock]['values'].append([i+1, j+1, float(wc[name][i, j].real)])\n                if wc[name][i, j].imag != 0 or not skip_zero:\n                    # omit Im parts that have to vanish by symmetry\n                    if (i, j) not in definitions.vanishing_im_parts[name]:\n                        d[imblock]['values'].append([i+1, j+1, float(wc[name][i, j].imag)])\n    for name in definitions.WC_keys_4f:\n        reblock = 'WC'+name.upper()\n        imblock = 'IMWC'+name.upper()\n        if reblock not in d:\n            d[reblock] = defaultdict(list)\n        if imblock not in d:\n            d[imblock] = defaultdict(list)\n        for i in range(3):\n            for j in range(3):\n                for k in range(3):\n                    for l in range(3):\n                        if (i, j, k, l) in definitions.redundant_elements[name] and skip_redundant:\n                            # skip redundant elements\n                            continue\n                        if wc[name][i, j, k, l].real != 0 or not skip_zero:\n                            d[reblock]['values'].append([i+1, j+1, k+1, l+1, float(wc[name][i, j, k, l].real)])\n                        if wc[name][i, j, k, l].imag != 0 or not skip_zero:\n                            # omit Im parts that have to vanish by symmetry\n                            if (i, j, k, l) not in definitions.vanishing_im_parts[name]:\n                                d[imblock]['values'].append([i+1, j+1, k+1, l+1, float(wc[name][i, j, k, l].imag)])\n    # remove empty blocks\n    empty = []\n    for block in d:\n        if d[block] == {}:\n            empty.append(block)\n    for block in empty:\n        del d[block]\n    return {'BLOCK': d}", "response": "Convert a dictionary of Wilson coefficients into a dictionary of DSixTools WC output file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef compute_rmsd_by_matrix(dataframe_1, dataframe_2, use_assertion = False):\n    '''Computes the RMSD of two pandas dataframes. The dataframes are expected to be of equal dimensions and use_assertion\n       can be set to assert that the row indices match. '''\n    if use_assertion: assert([i for i in dataframe_1.index] == [i for i in dataframe_2.index]) # Note: this assertion creates garbage memory allocations\n    num_points = dataframe_1.shape[0]\n    return numpy.linalg.norm(dataframe_1 - dataframe_2) / numpy.sqrt(num_points)", "response": "Computes the RMSD of two pandas dataframes."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nenabling custom templating extensions", "response": "def jinja_extensions_feature(app):\n    \"\"\" Enables custom templating extensions \"\"\"\n\n    # register jinja filters\n    app.jinja_env.globals['momentjs'] = MomentJsFilters\n    app.jinja_env.filters.update(MomentJsFilters().get_filters())\n    app.jinja_env.filters.update(DateFilters().get_filters())\n    app.jinja_env.filters.update(HumanizeFilters().get_filters())\n\n    # register custom jinja functions\n    app.jinja_env.globals.update(dict(\n        asset=functions.asset,\n        dev_proxy=functions.dev_proxy\n    ))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef log(msg, level=0):\n    '''\n    Logs a message to the console, with optional level paramater\n\n    Args:\n        - msg (str): message to send to console\n        - level (int): log level; 0 for info, 1 for error (default = 0)\n    '''\n\n    red = '\\033[91m'\n    endc = '\\033[0m'\n\n    # configure the logging module\n    cfg = {\n        'version': 1,\n        'disable_existing_loggers': False,\n        'formatters': {\n            'stdout': {\n                'format': '[%(levelname)s]: %(asctime)s - %(message)s',\n                'datefmt': '%x %X'\n            },\n            'stderr': {\n                'format': red + '[%(levelname)s]: %(asctime)s - %(message)s' + endc,\n                'datefmt': '%x %X'\n            }\n        },\n        'handlers': {\n            'stdout': {\n                'class': 'logging.StreamHandler',\n                'level': 'DEBUG',\n                'formatter': 'stdout'\n            },\n            'stderr': {\n                'class': 'logging.StreamHandler',\n                'level': 'ERROR',\n                'formatter': 'stderr'\n            }\n        },\n        'loggers': {\n            'info': {\n                'handlers': ['stdout'],\n                'level': 'INFO',\n                'propagate': True\n            },\n            'error': {\n                'handlers': ['stderr'],\n                'level': 'ERROR',\n                'propagate': False\n            }\n        }\n    }\n\n    dictConfig(cfg)\n\n    lg = 'info' if level == 0 else 'error'\n    lvl = 20 if level == 0 else 40\n\n    logger = logging.getLogger(lg)\n    logger.log(lvl, msg)", "response": "Logs a message to the console with optional level paramater\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_quantity(q):\n    units_s = str(q['value'])\n    for u in q['unitToPower']:\n        units_s = units_s + \"*\" + u['key'].lower()\n        power = u['value']\n        if not power == 1:\n            units_s = units_s + \"**\" + str(power)\n    return units_s", "response": "Parse an OnShape units definition into a string that can be converted to any other unit engine."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef insert(self, part):\n        params = {k: str(v) for k,v in part.params.items()}\n        res=c.create_assembly_instance(self.uri.as_dict(), part.uri.as_dict(), params)\n        return res", "response": "Insert a part into this assembly."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_http_scheme(uri):\n    regex = re.compile(\n        r'^(?:http)s?://',\n        flags=re.IGNORECASE\n    )\n    match = regex.match(uri)\n\n    return match.group(0) if match else 'http://'", "response": "Parse the URI to get the HTTP scheme."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse the stream from the Docker - py lib and displays it to the user.", "response": "def parse_stream(response):\n    \"\"\"\n    take stream from docker-py lib and display it to the user.\n\n    this also builds a stream list and returns it.\n    \"\"\"\n    stream_data = []\n    stream = stdout\n\n    for data in response:\n        if data:\n            try:\n                data = data.decode('utf-8')\n            except AttributeError as e:\n                logger.exception(\"Unable to parse stream, Attribute Error Raised: {0}\".format(e))\n                stream.write(data)\n                continue\n\n            try:\n                normalized_data = normalize_keys(json.loads(data))\n            except ValueError:\n                stream.write(data)\n                continue\n            except TypeError:\n                stream.write(data)\n                continue\n\n            if 'progress' in normalized_data:\n                stream_data.append(normalized_data)\n                _display_progress(normalized_data, stream)\n\n            elif 'error' in normalized_data:\n                _display_error(normalized_data, stream)\n\n            elif 'status' in normalized_data:\n                stream_data.append(normalized_data)\n                _display_status(normalized_data, stream)\n\n            elif 'stream' in normalized_data:\n                stream_data.append(normalized_data)\n                _display_stream(normalized_data, stream)\n            else:\n                stream.write(data)\n\n    stream.flush()\n    return stream_data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef normalize_keys(suspect, snake_case=True):\n    if not isinstance(suspect, dict):\n        raise TypeError('you must pass a dict.')\n\n    for key in list(suspect):\n        if not isinstance(key, six.string_types):\n            continue\n\n        if snake_case:\n            s1 = first_cap_re.sub(r'\\1_\\2', key)\n            new_key = all_cap_re.sub(r'\\1_\\2', s1).lower()  # .replace('-', '_')\n        else:\n            new_key = key.lower()\n\n        value = suspect.pop(key)\n        if isinstance(value, dict):\n            suspect[new_key] = normalize_keys(value, snake_case)\n        elif isinstance(value, list):\n            for i in range(0, len(value)):\n                if isinstance(value[i], dict):\n                    normalize_keys(value[i], snake_case)\n\n            suspect[new_key] = value\n        else:\n            suspect[new_key] = value\n\n    return suspect", "response": "take a dict and turn all of its type string keys into snake_case\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nnormalize the value of a node - level resource list entry.", "response": "def normalize_value(value, snake_case=True):\n    \"\"\"\n    :param value:\n    :return value:\n    \"\"\"\n    if not isinstance(value, six.string_types):\n        raise TypeError(\"the value passed to value must be a string\")\n\n    if snake_case:\n        s1 = first_cap_re.sub(r'\\1_\\2', value)\n        new_value = all_cap_re.sub(r'\\1_\\2', s1).lower()  # .replace('-', '_')\n    else:\n        new_value = value.lower()\n\n    return new_value"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef capitalize_keys(suspect):\n    if not isinstance(suspect, dict):\n        raise TypeError('you must pass a dict.')\n\n    converted = {}\n\n    for key in list(suspect):\n        if not isinstance(key, six.string_types):\n            continue\n\n        if key[0].isupper():\n            continue\n\n        if '_' in key:\n            new_key = ''.join([chunk.capitalize() for index, chunk in enumerate(key.split('_'))])\n        else:\n            new_key = key.capitalize()\n\n        value = suspect.get(key)\n        if type(value) is dict:\n            converted[new_key] = capitalize_keys(value)\n        elif type(value) is list:\n            converted[new_key] = [capitalize_keys(x) if isinstance(x, dict) else x for x in value]\n        else:\n            converted[new_key] = value\n\n    return converted", "response": "Convert all keys in a dict to capitalized ones."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndisplay the current progress of the current object in a single line.", "response": "def _display_progress(data, stream):\n    \"\"\"\n    expecting the following data scheme:\n        {\n            u'status': u'Pushing',\n            u'progressDetail': {\n                                    u'current': 655337,\n                                    u'start': 1413994898,\n                                    u'total': 20412416\n                                },\n            u'id': u'51783549ce98',\n            u'progress': u'[=>                                                 ] 655.3 kB/20.41 MB 30s'\n        }\n\n        {\n            u'status': u'Buffering to disk',\n            u'progressDetail': {\n                                    u'current': 13369344,\n                                    u'start': 1413994898\n                               },\n            u'id': u'51783549ce98',\n            u'progress': u'13.37 MB'\n        }\n    \"\"\"\n    if type(data) is not dict:\n        raise TypeError(\"data should be of type dict. the following was passed: {0}\".format(data))\n\n    stream.write(\"\\r%s %s\" % (data['status'], data['progress']))\n\n    if 'Pushing' in data['status']:\n        if data['progress_detail']['current'] == data['progress_detail'].get('total'):\n            stream.write(\"\\n\")\n\n    stream.flush()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _display_error(normalized_data, stream):\n    # TODO: need to revisit this later.\n    error = normalized_data['error']\n    if 'error_detail' in normalized_data:\n        stream.write(\"exit code: {0}\\n\".format(normalized_data['error_detail'].get('code'),\n                                               'There was no exit code provided'))\n\n        stream.write(normalized_data['error_detail'].get('message', 'There were no message details provided.'))\n\n    raise DockerStreamException(error)", "response": "Display the error message from the Docker stream and raise an exception."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _display_status(normalized_data, stream):\n    if 'Pull complete' in normalized_data['status'] or 'Download complete' in normalized_data['status']:\n        stream.write(\"\\n\")\n\n    if 'id' in normalized_data:\n        stream.write(\"%s - \" % normalized_data['id'])\n\n    stream.write(\"{0}\\n\".format(normalized_data['status']))", "response": "Display the status of the current page."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndisplay stream message from docker - py stream.", "response": "def _display_stream(normalized_data, stream):\n    \"\"\"\n    print stream message from docker-py stream.\n    \"\"\"\n    try:\n        stream.write(normalized_data['stream'])\n    except UnicodeEncodeError:\n        stream.write(normalized_data['stream'].encode(\"utf-8\"))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef version(self) -> str:\n        '''Show the version number of Android Debug Bridge.'''\n        output, _ = self._execute('version')\n        return output.splitlines()[0].split()[-1]", "response": "Show the version number of Android Debug Bridge."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef devices_l(self) -> Dict:\n        '''List connected devices (-l for long output).'''\n        output, _ = self._execute('devices', '-l')\n        devices = output.split()[4::6]\n        models = output.split()[7::6]\n        return dict(zip(devices, models))", "response": "List connected devices (-l for long output)."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef connect(self, host: str = '192.168.0.3', port: Union[int, str] = 5555) -> None:\n        '''Connect to a device via TCP/IP directly.'''\n        self.device_sn = f'{host}:{port}'\n        if not is_connectable(host, port):\n            raise ConnectionError(f'Cannot connect to {self.device_sn}.')\n        self._execute('connect', self.device_sn)", "response": "Connect to a device via TCP or IP directly."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndisconnects from given TCP / IP device [ default port = 5555.", "response": "def disconnect(self, host: str = '192.168.0.3', port: Union[int, str] = 5555) -> None:\n        '''Disconnect from given TCP/IP device [default port=5555].'''\n        self.device_sn = None\n        self._execute('disconnect', f'{host}:{port}')"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the current state of the system.", "response": "def get_state(self) -> str:\n        '''offline | bootloader | device'''\n        output, error = self._execute('get-state')\n        if error:\n            raise DeviceConnectionException(error.split(':', 1)[-1].strip())\n        return output.strip()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a scatterplot of error versus error intended to show which computational method (X or Y) has the least amount of error relative to a reference series. The difference vectors (reference_series - x_series, reference_series - y_series) are created and these differences (errors) are plotted against each other. :param output_directory: The output directory. :param file_prefix: A prefix for the generated files. A CSV file with the plot points, the R script, and the R output is saved along with the plot itself. :param df: A pandas dataframe. Note: The dataframe is zero-indexed. :param reference_series_index: The numerical index of the reference series e.g. experimental data. :param x_series_index: The numerical index of the X-axis series e.g. predictions from a computational method. :param y_series_index: The numerical index of the Y-axis series e.g. predictions from a second computational method. :param x_color: The color of the \"method X is better\" points. :param y_color: The color of the \"method Y is better\" points. :param x_series_name: A name for the X-series which is used in the the classification legend. :param y_series_name: A name for the Y-series which is used in the the classification legend. :param plot_title: Plot title. :param x_axis_label: X-axis label. :param y_axis_label: Y-axis label. :param similarity_range: A point (x, y) is considered as similar if |x - y| <= similarity_range. :param add_similarity_range_annotation: If true then the similarity range is included in the plot. :param shape_by_category: Boolean. If set then points are shaped by the column identified with shape_category_series_index. Otherwise, points are shaped by classification (\"X is better\", \"Y is better\", or \"Similar\") :param shape_category_series_index: The numerical index of the series used to choose point shapes. :param shape_category_title: The title of the shape legend. :param label_series_index: The numerical index of the series label_series_index :param label_outliers: Boolean. If set then label outliers using the column identified with label_series_index. :param use_geom_text_repel: Boolean. If set then the ggrepel package is used to avoid overlapping labels. This function was adapted from the Kortemme Lab covariation benchmark (https://github.com/Kortemme-Lab/covariation). todo: I need to check that ggplot2 is respecting the color choices. It may be doing its own thing.", "response": "def error_by_error_scatterplot(output_directory, file_prefix, df,\n                             reference_series_index, x_series_index, y_series_index,\n                             x_color, y_color,\n                             x_series_name = None, y_series_name = None,\n                             plot_title = '', x_axis_label = '', y_axis_label = '', similarity_range = 0.25,\n                             add_similarity_range_annotation = True,\n                             shape_by_category = False, shape_category_series_index = None, shape_category_title = 'Case',\n                             label_series_index = None, label_outliers = True,\n                             use_geom_text_repel = True,\n                             ):\n\n    \"\"\" Creates a scatterplot of error versus error intended to show which computational method (X or Y) has the least amount of error relative to a reference series.\n\n        The difference vectors (reference_series - x_series, reference_series - y_series) are created and these differences (errors)\n        are plotted against each other.\n\n        :param output_directory: The output directory.\n        :param file_prefix: A prefix for the generated files. A CSV file with the plot points, the R script, and the R output is saved along with the plot itself.\n        :param df: A pandas dataframe. Note: The dataframe is zero-indexed.\n        :param reference_series_index: The numerical index of the reference series e.g. experimental data.\n        :param x_series_index: The numerical index of the X-axis series e.g. predictions from a computational method.\n        :param y_series_index: The numerical index of the Y-axis series e.g. predictions from a second computational method.\n        :param x_color: The color of the \"method X is better\" points.\n        :param y_color: The color of the \"method Y is better\" points.\n        :param x_series_name: A name for the X-series which is used in the the classification legend.\n        :param y_series_name: A name for the Y-series which is used in the the classification legend.\n        :param plot_title: Plot title.\n        :param x_axis_label: X-axis label.\n        :param y_axis_label: Y-axis label.\n        :param similarity_range: A point (x, y) is considered as similar if |x - y| <= similarity_range.\n        :param add_similarity_range_annotation: If true then the similarity range is included in the plot.\n        :param shape_by_category: Boolean. If set then points are shaped by the column identified with shape_category_series_index. Otherwise, points are shaped by classification (\"X is better\", \"Y is better\", or \"Similar\")\n        :param shape_category_series_index: The numerical index of the series used to choose point shapes.\n        :param shape_category_title: The title of the shape legend.\n        :param label_series_index: The numerical index of the series label_series_index\n        :param label_outliers: Boolean. If set then label outliers using the column identified with label_series_index.\n        :param use_geom_text_repel: Boolean. If set then the ggrepel package is used to avoid overlapping labels.\n\n        This function was adapted from the Kortemme Lab covariation benchmark (https://github.com/Kortemme-Lab/covariation).\n        todo: I need to check that ggplot2 is respecting the color choices. It may be doing its own thing.\n    \"\"\"\n    try:\n        os.mkdir(output_directory)\n    except:\n        pass\n    assert (os.path.exists(output_directory))\n\n    if not isinstance(shape_category_series_index, int):\n        shape_by_category = False\n    if not isinstance(label_series_index, int):\n        label_outliers = False\n    assert(x_series_name != None and y_series_name != None)\n\n    df = df.copy()\n    headers = df.columns.values\n\n    num_categories = len(set(df.ix[:, shape_category_series_index].values))\n    legal_shapes = range(15,25+1) + range(0,14+1)\n    if num_categories > len(legal_shapes):\n        colortext.warning('Too many categories ({0}) to plot using meaningful shapes.'.format(num_categories))\n        shape_by_category = False\n    else:\n        legal_shapes = legal_shapes[:num_categories]\n\n    df['X_error'] = abs(df[headers[reference_series_index]] - df[headers[x_series_index]])\n    x_error_index = len(df.columns.values) - 1\n    df['Y_error'] = abs(df[headers[reference_series_index]] - df[headers[y_series_index]])\n    y_error_index = len(df.columns.values) - 1\n\n    # Get the list of domains common to both runs\n    df['Classification'] = df.apply(lambda r: _classify_smallest_error(r['X_error'], r['Y_error'], similarity_range, x_series_name, y_series_name), axis = 1)\n    error_classification_index = len(df.columns.values) - 1\n\n    # Create the R script\n    boxplot_r_script = '''\nlibrary(ggplot2)\nlibrary(gridExtra)\nlibrary(scales)\nlibrary(qualV)\nlibrary(grid)'''\n    if use_geom_text_repel:\n        boxplot_r_script +='''\nlibrary(ggrepel) # install with 'install.packages(\"ggrepel\")' inside the R interactive shell.\n'''\n    boxplot_r_script += '''\n\n# PNG generation\npng('%(file_prefix)s.png', width=2560, height=2048, bg=\"white\", res=600)\ntxtalpha <- 0.8\nredtxtalpha <- 0.8\n\n%(png_plot_commands)s\n        '''\n\n    xy_table_filename = '{0}.txt'.format(file_prefix)\n    xy_table_filepath = os.path.join(output_directory, xy_table_filename)\n\n    data_table = df.to_csv(header = True, index = False)\n    write_file(xy_table_filepath, data_table)\n\n    main_plot_script = '''\n# Set the margins\npar(mar=c(5, 5, 1, 1))\n\nxy_data <- read.csv('%(xy_table_filename)s', header=T)\n\nnames(xy_data)[%(x_error_index)d + 1] <- \"xerrors\"\nnames(xy_data)[%(y_error_index)d + 1] <- \"yerrors\"\n'''\n\n    if label_outliers:\n        main_plot_script +='''names(xy_data)[%(label_series_index)d + 1] <- \"outlier_labels\"'''\n    main_plot_script +='''\nnames(xy_data)[%(shape_category_series_index)d + 1] <- \"categories\"\n\nxy_data[%(x_error_index)d + 1]\nxy_data[%(y_error_index)d + 1]\n\n# coefs contains two values: (Intercept) and yerrors\ncoefs <- coef(lm(xerrors~yerrors, data = xy_data))\nfitcoefs = coef(lm(xerrors~0 + yerrors, data = xy_data))\nfitlmv_yerrors <- as.numeric(fitcoefs[1])\nlmv_intercept <- as.numeric(coefs[1])\nlmv_yerrors <- as.numeric(coefs[2])\nlm(xy_data$yerrors~xy_data$xerrors)\n\nxlabel <- \"%(x_axis_label)s\"\nylabel <- \"%(y_axis_label)s\"\nplot_title <- \"%(plot_title)s\"\nrvalue <- cor(xy_data$yerrors, xy_data$xerrors)\n\n# Alphabetically, \"Similar\" < \"X\" < \"Y\" so the logic below works\ncountsim <- paste(\"Similar =\", dim(subset(xy_data, Classification==\"Similar\"))[1])\ncountX <- paste(\"%(x_series_name)s =\", dim(subset(xy_data, Classification==\"%(x_series_name)s\"))[1])\ncountY <- paste(\"%(y_series_name)s =\", dim(subset(xy_data, Classification==\"%(y_series_name)s\"))[1])\n\ncountX\ncountY\ncountsim\n\n# Set graph limits and the position for the correlation value\n\nminx <- min(0.0, min(xy_data$xerrors) - 0.1)\nminy <- min(0.0, min(xy_data$yerrors) - 0.1)\nmaxx <- max(1.0, max(xy_data$xerrors) + 0.1)\nmaxy <- max(1.0, max(xy_data$yerrors) + 0.1)\n\n# Create a square plot (x-range = y-range)\nminx <- min(minx, miny)\nminy <- minx\nmaxx <- max(maxx, maxy)\nmaxy <- maxx\n\nxpos <- maxx / 25.0\nypos <- maxy - (maxy / 25.0)\nypos_2 <- maxy - (2 * maxy / 25.0)\n\n\nplot_scale <- scale_color_manual(\n    \"Counts\",\n    values = c( \"Similar\" = '#444444', \"%(x_series_name)s\" = '%(x_color)s', \"%(y_series_name)s\" ='%(y_color)s'),\n    labels = c( \"Similar\" = countsim,  \"%(x_series_name)s\" = countX,        \"%(y_series_name)s\" = countY) )'''\n\n    if add_similarity_range_annotation:\n        main_plot_script += '''\n# Polygon denoting the similarity range. We turn off plot clipping below (gt$layout$clip) so we need to be more exact than using 4 points when defining the region\nboxy_mc_boxface <- data.frame(\n  X = c(minx - 0,                        maxx - %(similarity_range)f, maxx + 0, maxx + 0,                       0 + %(similarity_range)f, 0),\n  Y = c(minx - 0 + %(similarity_range)f, maxx + 0,                    maxx + 0, maxx + 0 -%(similarity_range)f, 0, 0 )\n)'''\n    else:\n        main_plot_script += '''\n# Polygon denoting the similarity range. We turn off plot clipping below (gt$layout$clip) so we need to be more exact than using 4 points when defining the region\nboxy_mc_boxface <- data.frame(\n  X = c(minx - 1, maxx + 1, maxx + 1, minx - 1),\n  Y = c(minx - 1 + %(similarity_range)f, maxx + 1 + %(similarity_range)f, maxx + 1 - %(similarity_range)f, minx - 1 - %(similarity_range)f)\n)'''\n\n    if shape_by_category:\n        main_plot_script += '''\n# Plot\np <- qplot(main=\"\", xerrors, yerrors, data=xy_data, xlab=xlabel, ylab=ylabel, alpha = I(txtalpha), shape=factor(categories), col=factor(Classification)) +'''\n    else:\n        main_plot_script += '''\n# Plot\np <- qplot(main=\"\", xerrors, yerrors, data=xy_data, xlab=xlabel, ylab=ylabel, alpha = I(txtalpha), shape=factor(Classification), col=factor(Classification)) +'''\n\n    main_plot_script += '''\ngeom_polygon(data=boxy_mc_boxface, aes(X, Y), fill = \"#bbbbbb\", alpha = 0.4, color = \"darkseagreen\", linetype=\"blank\", inherit.aes = FALSE, show.legend = FALSE) +\nplot_scale +\ngeom_point() +\nguides(col = guide_legend()) +\nlabs(title = \"%(plot_title)s\") +\ntheme(plot.title = element_text(color = \"#555555\", size=rel(0.75))) +\ntheme(axis.title = element_text(color = \"#555555\", size=rel(0.6))) +\ntheme(legend.title = element_text(color = \"#555555\", size=rel(0.45)), legend.text = element_text(color = \"#555555\", size=rel(0.4))) +\ncoord_cartesian(xlim = c(minx, maxx), ylim = c(miny, maxy)) + # set the graph limits\nannotate(\"text\", hjust=0, size = 2, colour=\"#222222\", x = xpos, y = ypos, label = sprintf(\"R = %%0.2f\", round(rvalue, digits = 4))) + # add correlation text; hjust=0 sets left-alignment. Using annotate instead of geom_text avoids blocky text caused by geom_text being run multiple times over the series'''\n\n    if label_outliers:\n        if use_geom_text_repel:\n            main_plot_script += '''\n\n# Label outliers\ngeom_text_repel(size=1.5, segment.size = 0.15, color=\"#000000\", alpha=0.6, data=subset(xy_data, abs(yerrors - xerrors) > maxx/3 & xerrors <= maxx / 2 & yerrors >=maxy/2), aes(xerrors, yerrors-maxy/100, label=outlier_labels)) +\ngeom_text_repel(size=1.5, segment.size = 0.15, color=\"#000000\", alpha=0.6, data=subset(xy_data, abs(yerrors - xerrors) > maxx/3 & xerrors <= maxx / 2 & yerrors < maxy/2), aes(xerrors, yerrors+2*maxy/100, label=outlier_labels)) +\ngeom_text_repel(size=1.5, segment.size = 0.15, color=\"#000000\", alpha=0.6, data=subset(xy_data, abs(yerrors - xerrors) > maxx/3 & xerrors > maxx / 2 & yerrors >=maxy/2), aes(xerrors, yerrors-maxy/100, label=outlier_labels)) +\ngeom_text_repel(size=1.5, segment.size = 0.15, color=\"#000000\", alpha=0.6, data=subset(xy_data, abs(yerrors - xerrors) > maxx/3 & xerrors > maxx / 2 & yerrors < maxy/2), aes(xerrors, yerrors+2*maxy/100, label=outlier_labels)) +'''\n        else:\n            main_plot_script += '''\n\n# Label outliers\ngeom_text(hjust = 0, size=1.5, color=\"#000000\", alpha=0.6, data=subset(xy_data, abs(yerrors - xerrors) > maxx/3 & xerrors <= maxx / 2 & yerrors >=maxy/2), aes(xerrors, yerrors-maxy/100, label=outlier_labels)) +\ngeom_text(hjust = 0, size=1.5, color=\"#000000\", alpha=0.6, data=subset(xy_data, abs(yerrors - xerrors) > maxx/3 & xerrors <= maxx / 2 & yerrors < maxy/2), aes(xerrors, yerrors+2*maxy/100, label=outlier_labels)) +\ngeom_text(hjust = 1, size=1.5, color=\"#000000\", alpha=0.6, data=subset(xy_data, abs(yerrors - xerrors) > maxx/3 & xerrors > maxx / 2 & yerrors >=maxy/2), aes(xerrors, yerrors-maxy/100, label=outlier_labels)) +\ngeom_text(hjust = 1, size=1.5, color=\"#000000\", alpha=0.6, data=subset(xy_data, abs(yerrors - xerrors) > maxx/3 & xerrors > maxx / 2 & yerrors < maxy/2), aes(xerrors, yerrors+2*maxy/100, label=outlier_labels)) +'''\n\n        counts_title = 'Counts'\n        if add_similarity_range_annotation:\n            counts_title += '*'\n\n        main_plot_script += '''\n\n\n#geom_text(hjust = 0, size=1.5, color=\"#000000\", alpha=0.6, data=subset(xy_data, abs(yvalues - xvalues) > 2 & xvalues <= 0), aes(xvalues, yvalues+0.35, label=Origin_of_peptide), check_overlap = TRUE) + # label outliers\n#geom_text(hjust = 1, size=1.5, color=\"#000000\", alpha=0.6, data=subset(xy_data, abs(yvalues - xvalues) > 2 & xvalues > 0), aes(xvalues, yvalues+0.35, label=Origin_of_peptide), check_overlap = TRUE) + # label outliers\n\n\n\n\nscale_colour_manual('%(counts_title)s', values = c('#444444', '%(x_color)s', '%(y_color)s'),\n                    labels = c( \"Similar\" = countsim,  \"%(x_series_name)s\" = countX,        \"%(y_series_name)s\" = countY)) +'''\n\n    if shape_by_category:\n        legal_shapes_str = ', '.join(map(str, legal_shapes))\n        main_plot_script += '''\nscale_shape_manual('%(shape_category_title)s', values = c(%(legal_shapes_str)s),\n                    labels = c( \"Similar\" = countsim,  \"%(x_series_name)s\" = countX,        \"%(y_series_name)s\" = countY))'''\n\n    else:\n        main_plot_script += '''\nscale_shape_manual('%(counts_title)s', values = c(18, 16, 15),\n                    labels = c( \"Similar\" = countsim,  \"%(x_series_name)s\" = countX,        \"%(y_series_name)s\" = countY))'''\n\n    if add_similarity_range_annotation:\n        main_plot_script += '''+\n    # Add a caption\n    annotation_custom(grob = textGrob(gp = gpar(fontsize = 5), hjust = 0, sprintf(\"* Similar \\\\u225d \\\\u00b1 %%0.2f\", round(%(similarity_range)f, digits = 2))), xmin = maxx + (2 * maxx / 10), ymin = -1, ymax = -1)'''\n\n    main_plot_script += '''\n\n# Plot graph\np\n    '''\n    if add_similarity_range_annotation:\n        main_plot_script += '''\n# Code to override clipping\ngt <- ggplot_gtable(ggplot_build(p))\ngt$layout$clip[gt$layout$name==\"panel\"] <- \"off\"\ngrid.draw(gt)'''\n\n    main_plot_script +='''\ndev.off()\n'''\n\n    # Create the R script\n    plot_type = 'png'\n    png_plot_commands = main_plot_script % locals()\n    boxplot_r_script = boxplot_r_script % locals()\n    r_script_filename = '{0}.R'.format(file_prefix)\n    r_script_filepath = os.path.join(output_directory, r_script_filename)\n    write_file(r_script_filepath, boxplot_r_script)\n\n    # Run the R script\n    run_r_script(r_script_filename, cwd = output_directory)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef generate_certificate(common_name, size=DEFAULT_KEY_SIZE):\n    '''\n        Generate private key and certificate for https\n    '''\n\n    private_key_path = '{}/{}.key'.format(CERTIFICATES_PATH, common_name)\n    certificate_path = '{}/{}.crt'.format(CERTIFICATES_PATH, common_name)\n    if not os.path.isfile(certificate_path):\n        print 'Create {}'.format(certificate_path)\n        cmd = 'openssl req -x509 -nodes -newkey rsa:{size} -keyout {private_key_path} -out {certificate_path} -days 3650 -subj \"/CN={common_name}\"'.format(\n            size=size, private_key_path=private_key_path,\n            certificate_path=certificate_path, common_name=common_name)\n        p = subprocess.Popen(cmd,\n                             shell=True,\n                             stdout=subprocess.PIPE,\n                             close_fds=True)\n        p.communicate()\n        helpers.file_rights(private_key_path, mode=0400, uid=0, gid=0)\n        helpers.file_rights(certificate_path, mode=0444, uid=0, gid=0)\n    else:\n        print 'Already exist: {}'.format(certificate_path)\n\n    clean_links()\n    make_links(common_name)", "response": "Generate private key and certificate for the given common name."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsigning a new certificate with acme_tiny for let s encrypt it", "response": "def acme_sign_certificate(common_name, size=DEFAULT_KEY_SIZE):\n    '''\n        Sign certificate with acme_tiny for let's encrypt\n    '''\n    private_key_path = '{}/{}.key'.format(CERTIFICATES_PATH, common_name)\n    certificate_path = '{}/{}.crt'.format(CERTIFICATES_PATH, common_name)\n    certificate_request_path = '{}/{}.csr'.format(CERTIFICATES_PATH,\n                                                  common_name)\n    signed_cert = '{certificates_path}/{common_name}-signed.crt'.format(\n        certificates_path=CERTIFICATES_PATH,\n        common_name=common_name)\n\n    generate_certificate(common_name, size)\n\n    cmd = 'openssl req -new -sha256 -key {private_key_path}'\n    cmd += ' -subj \"/CN={common_name}\" -out {certificate_request_path}'\n    cmd = cmd.format(\n        private_key_path=private_key_path,\n        common_name=common_name,\n        certificate_request_path=certificate_request_path\n    )\n    p = subprocess.Popen(cmd,\n                         shell=True,\n                         stdout=subprocess.PIPE,\n                         close_fds=True)\n    p.communicate()\n\n    _internal_sign_certificate(certificate_path, certificate_request_path,\n                              signed_cert)\n\n    cron = \"/etc/cron.monthly/acme-renew\"\n    if not os.path.exists(cron):\n        with open(cron, \"w\") as file:\n            file.write(\"#!/bin/bash\\ncozy_management renew_certificates\\n\")\n        st = os.stat(cron)\n        os.chmod(cron, st.st_mode | S_IXUSR)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef acme_renew_certificates():\n    '''\n        Renew certificates with acme_tiny for let's encrypt\n    '''\n\n    for csr in glob(os.path.join(CERTIFICATES_PATH, '*.csr')):\n        common_name = os.path.basename(csr)\n        common_name = os.path.splitext(common_name)[0]\n\n        certificate_path = \"{}.crt\".format(common_name)\n        certificate_path = os.path.join(CERTIFICATES_PATH, certificate_path)\n\n        with open(certificate_path) as file:\n            crt = OpenSSL.crypto.load_certificate(OpenSSL.crypto.FILETYPE_PEM,\n                                                    file.read())\n            expiration = crt.get_notAfter()\n            expiration = _parse_asn1_generalized_date(expiration)\n            remaining = expiration - datetime.utcnow()\n            if remaining > timedelta(days=30):\n                print \"No need to renew {} ({})\".format(certificate_path, remaining)\n                continue\n            print \"Renewing {} ({})\".format(certificate_path, remaining)\n\n        certificate_request_path = \"{}.csr\".format(common_name)\n        certificate_request_path = os.path.join(CERTIFICATES_PATH,\n                                                certificate_request_path)\n\n        signed_cert = \"{}-signed.crt\".format(common_name)\n        signed_cert = os.path.join(CERTIFICATES_PATH,\n                                    signed_cert)\n\n        _internal_sign_certificate(certificate_path, certificate_request_path,\n                                    signed_cert)", "response": "Renew certificates with acme_tiny for let s encrypt\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate private key and certificate for the current page of the page.", "response": "def generate_certificate_pure_python(common_name, size=DEFAULT_KEY_SIZE,\n                                        digest=DEFAULT_DIGEST):\n    '''\n        Generate private key and certificate for https\n    '''\n    private_key = OpenSSL.crypto.PKey()\n    private_key.generate_key(TYPE_RSA, size)\n\n    request = OpenSSL.crypto.X509Req()\n    subject = request.get_subject()\n    setattr(subject, 'CN', common_name)\n    request.set_pubkey(private_key)\n    request.sign(private_key, digest)\n\n    certificate = OpenSSL.crypto.X509()\n    certificate.set_serial_number(0)\n    certificate.gmtime_adj_notBefore(0)\n    certificate.gmtime_adj_notAfter(60 * 60 * 24 * 365 * 5)\n    certificate.set_issuer(request.get_subject())\n    certificate.set_subject(request.get_subject())\n    certificate.set_pubkey(request.get_pubkey())\n    certificate.sign(private_key, digest)\n\n    private_key_path = '{}/{}.key'.format(CERTIFICATES_PATH, common_name)\n    if not os.path.isfile(private_key_path):\n        print 'Write {}'.format(private_key_path)\n        with open(private_key_path, 'w+') as private_key_file:\n            private_key_file.write(\n                OpenSSL.crypto.dump_privatekey(FILETYPE_PEM,\n                                               private_key).decode('utf-8')\n            )\n        helpers.file_rights(private_key_path, mode=0400, uid=0, gid=0)\n    else:\n        print 'Already exist: {}'.format(private_key_path)\n\n    certificate_path = '{}/{}.crt'.format(CERTIFICATES_PATH, common_name)\n    if not os.path.isfile(certificate_path):\n        print 'Write {}'.format(certificate_path)\n        with open(certificate_path, 'w+') as certificate_file:\n            certificate_file.write(\n                OpenSSL.crypto.dump_certificate(FILETYPE_PEM,\n                                                certificate).decode('utf-8')\n            )\n        helpers.file_rights(certificate_path, mode=0444, uid=0, gid=0)\n    else:\n        print 'Already exist: {}'.format(certificate_path)\n\n    clean_links()\n    make_links(common_name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_crt_common_name(certificate_path=OLD_CERTIFICATE_PATH):\n    '''\n        Get CN from certificate\n    '''\n    try:\n        certificate_file = open(certificate_path)\n        crt = OpenSSL.crypto.load_certificate(OpenSSL.crypto.FILETYPE_PEM,\n                                              certificate_file.read())\n        return crt.get_subject().commonName\n    except IOError:\n        return None", "response": "Get CN from certificate\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nput old cerfificate form to new one", "response": "def normalize_cert_dir():\n    '''\n        Put old cerfificate form to new one\n    '''\n    current_cn = get_crt_common_name()\n\n    if not os.path.isdir(COZY_CONFIG_PATH):\n        print 'Need to create {}'.format(COZY_CONFIG_PATH)\n        os.mkdir(COZY_CONFIG_PATH, 0755)\n\n    if not os.path.isdir(CERTIFICATES_PATH):\n        print 'Need to create {}'.format(CERTIFICATES_PATH)\n        os.mkdir(CERTIFICATES_PATH, 0755)\n\n    if not os.path.isdir(ACME_PRIVATE_PATH):\n        print 'Need to create {}'.format(ACME_PRIVATE_PATH)\n        os.mkdir(ACME_PRIVATE_PATH, 0700)\n\n    if os.path.isfile(OLD_CERTIFICATE_PATH) and \\\n            not os.path.islink(OLD_CERTIFICATE_PATH):\n        target = '{}/{}.crt'.format(CERTIFICATES_PATH, current_cn)\n        print 'Move {} to {}'.format(CERTIFICATES_PATH, target)\n        os.rename(OLD_CERTIFICATE_PATH, target)\n    else:\n        print 'Nothing to do for {}'.format(OLD_CERTIFICATE_PATH)\n\n    if os.path.isfile(OLD_PRIVATE_KEY_PATH) and \\\n            not os.path.islink(OLD_PRIVATE_KEY_PATH):\n        target = '{}/{}.key'.format(CERTIFICATES_PATH, current_cn)\n        print 'Move {} to {}'.format(OLD_PRIVATE_KEY_PATH, target)\n        os.rename(OLD_PRIVATE_KEY_PATH, target)\n    else:\n        print 'Nothing to do for {}'.format(OLD_PRIVATE_KEY_PATH)\n\n    if current_cn:\n        make_links(current_cn)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncleans symlink for nginx", "response": "def clean_links():\n    '''\n        Clean symlink for nginx\n    '''\n    if os.path.isfile(CURRENT_CERTIFICATE_PATH):\n        print 'Delete symlink {}'.format(CURRENT_CERTIFICATE_PATH)\n        os.remove(CURRENT_CERTIFICATE_PATH)\n\n    if os.path.isfile(CURRENT_PRIVATE_KEY_PATH):\n        print 'Delete symlink {}'.format(CURRENT_PRIVATE_KEY_PATH)\n        os.remove(CURRENT_PRIVATE_KEY_PATH)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create(self, agent_cls=None, n_agents=10, agent_kwargs={},\n               env_cls=Environment, env_kwargs={}, callback=None, conns=0,\n               log_folder=None):\n        \"\"\"A convenience function to create simple simulations.\n\n        Method first creates environment, then instantiates agents into it\n        with give arguments, and finally creates simulation for the\n        environment.\n\n        :param agent_cls:\n            class for agents, or list of classes. If list, then **n_agents**\n            and **agent_kwargs** are expected to be lists also.\n\n        :param n_agents:\n            amount of agents for simulation, or list of amounts\n\n        :param agent_kwargs:\n            keyword arguments passed to agents at creation time, or list of\n            keyword arguments.\n\n        :param env_cls:\n            environment class for simulation\n\n        :type env_cls:\n            :py:class:`~creamas.core.environment.Environment`\n\n        :param dict env_kwargs:\n            keyword arguments passed to environment at creation time\n\n        :param callable callback:\n            optional callable to call after each simulation step\n\n        :param conns:\n            Create **conns** amount of initial (random) connections for agents\n            in the simulation environment.\n\n        :param str log_folder:\n            folder for possible logging. This overwrites *log_folder* keyword\n            argument from **agent_kwargs** and **env_kwargs**.\n        \"\"\"\n        if not issubclass(env_cls, Environment):\n            raise TypeError(\"Environment class must be derived from ({}\"\n                            .format(Environment.__class__.__name__))\n        if callback is not None and not hasattr(callback, '__call__'):\n            raise TypeError(\"Callback must be callable.\")\n\n        if hasattr(agent_cls, '__iter__'):\n            for e in agent_cls:\n                if not issubclass(e, CreativeAgent):\n                    raise TypeError(\"All agent classes must be derived from {}\"\n                                    .format(CreativeAgent.__class__.__name__))\n        else:\n            if not issubclass(agent_cls, CreativeAgent):\n                raise TypeError(\"Agent class must be derived from {}\"\n                                .format(CreativeAgent.__class__.__name__))\n\n        env = env_cls.create(**env_kwargs)\n\n        agents = []\n        if hasattr(agent_cls, '__iter__'):\n            for i in range(len(n_agents)):\n                agent_kwargs[i]['environment'] = env\n                agent_kwargs[i]['log_folder'] = log_folder\n                agents = agents + [agent_cls[i](**agent_kwargs[i]) for e in\n                                   range(n_agents[i])]\n        else:\n            agent_kwargs['environment'] = env\n            agent_kwargs['log_folder'] = log_folder\n            agents = [agent_cls(**agent_kwargs) for e in range(n_agents)]\n\n        if conns > 0:\n            env.create_random_connections(n=conns)\n\n        return Simulation(env, callback, log_folder)", "response": "A convenience method to create a simple simulation for the environment."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _init_step(self):\n        self._age += 1\n        self.env.age = self._age\n        self._log(logging.INFO, \"\")\n        self._log(logging.INFO, \"\\t***** Step {:0>4} *****\". format(self.age))\n        self._log(logging.INFO, \"\")\n        self._agents_to_act = self._get_order_agents()\n        self._step_processing_time = 0.0\n        self._step_start_time = time.time()", "response": "Initialize next simulation step."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfinalize simulation step after all agents have acted for the current iteration.", "response": "def _finalize_step(self):\n        \"\"\"Finalize simulation step after all agents have acted for the current\n        step.\n        \"\"\"\n        t = time.time()\n        if self._callback is not None:\n            self._callback(self.age)\n        t2 = time.time()\n        self._step_processing_time += t2 - t\n        self._log(logging.INFO, \"Step {} run in: {:.3f}s ({:.3f}s of \"\n                  \"actual processing time used)\"\n                  .format(self.age, self._step_processing_time,\n                          t2 - self._step_start_time))\n        self._processing_time += self._step_processing_time"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprogresses simulation by running all agents * n * times asynchronously.", "response": "def async_steps(self, n):\n        \"\"\"Progress simulation by running all agents *n* times asynchronously.\n        \"\"\"\n        assert len(self._agents_to_act) == 0\n        for _ in range(n):\n            self.async_step()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef async_step(self):\n        assert len(self._agents_to_act) == 0\n        self._init_step()\n        t = time.time()\n        aiomas.run(until=self.env.trigger_all())\n        self._agents_to_act = []\n        self._step_processing_time = time.time() - t\n        self._finalize_step()", "response": "Progress simulation by running all agents once asynchronously."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef steps(self, n):\n        assert len(self._agents_to_act) == 0\n        for _ in range(n):\n            self.step()", "response": "Progress simulation with given amount of steps."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef step(self):\n        assert len(self._agents_to_act) == 0\n        self.next()\n        while len(self._agents_to_act) > 0:\n            self.next()", "response": "This method is called by the simulation with a single step."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntrigger next agent to : py : meth : ~creamas. core. CreativeAgent. act in the current step.", "response": "def next(self):\n        \"\"\"Trigger next agent to :py:meth:`~creamas.core.CreativeAgent.act` in\n        the current step.\n        \"\"\"\n        # all agents acted, init next step\n        t = time.time()\n        if len(self._agents_to_act) == 0:\n            self._init_step()\n\n        addr = self._agents_to_act.pop(0)\n        aiomas.run(until=self.env.trigger_act(addr=addr))\n        t2 = time.time()\n        self._step_processing_time += t2 - t\n\n        # all agents acted, finalize current step\n        if len(self._agents_to_act) == 0:\n            self._finalize_step()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nends the simulation and destroy the current simulation environment.", "response": "def end(self, folder=None):\n        \"\"\"End the simulation and destroy the current simulation environment.\n        \"\"\"\n        ret = self.env.destroy(folder=folder)\n        self._end_time = time.time()\n        self._log(logging.DEBUG, \"Simulation run with {} steps took {:.3f}s to\"\n                  \" complete, while actual processing time was {:.3f}s.\"\n                  .format(self.age, self._end_time - self._start_time,\n                          self._processing_time))\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_unique_record(self, sql, parameters = None, quiet = False, locked = False):\n        '''I use this pattern a lot. Return the single record corresponding to the query.'''\n        results = self.execute_select(sql, parameters = parameters, quiet = quiet, locked = locked)\n        assert(len(results) == 1)\n        return results[0]", "response": "I use this pattern a lot. Return the single record corresponding to the query."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncall a MySQL stored procedure procname and returns the return values. This uses DictCursor. to get the return values back out of a stored procedure.", "response": "def callproc(self, procname, parameters=(), quiet=False, expect_return_value=False):\n        \"\"\"Calls a MySQL stored procedure procname and returns the return values. This uses DictCursor.\n            To get return values back out of a stored procedure, prefix the parameter with a @ character.\n        \"\"\"\n        self.procedures_run += 1\n        i = 0\n        errcode = 0\n        caughte = None\n\n        out_param_indices = []\n        for j in range(len(parameters)):\n            p = parameters[j]\n            if type(p) == type('') and p[0] == '@':\n                assert(p.find(' ') == -1)\n                out_param_indices.append(j)\n\n        if procname not in self.list_stored_procedures():\n            raise Exception(\"The stored procedure '%s' does not exist.\" % procname)\n        if not re.match(\"^\\s*\\w+\\s*$\", procname):\n            raise Exception(\"Expected a stored procedure name in callproc but received '%s'.\" % procname)\n        while i < self.numTries:\n            i += 1\n            try:\n                self._get_connection()\n                cursor = self.connection.cursor()\n                if type(parameters) != type(()):\n                    parameters = (parameters,)\n                errcode = cursor.callproc(procname, parameters)\n                self.lastrowid = int(cursor.lastrowid)\n                cursor.close()\n\n                # Get the out parameters\n                out_param_results = []\n                if out_param_indices:\n                    out_param_results = self.execute('SELECT %s' % \", \".join(['@_%s_%d AS %s' % (procname, pindex, parameters[pindex][1:]) for pindex in out_param_indices]))\n\n                return out_param_results\n            except MySQLdb.OperationalError, e:\n                self._close_connection()\n                errcode = e[0]\n                caughte = e\n                continue\n            except:\n                self._close_connection()\n                traceback.print_exc()\n                break\n\n        if not quiet:\n            sys.stderr.write(\"\\nSQL execution error call stored procedure %s at %s:\" % (\n            procname, datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")))\n            sys.stderr.write(\"\\nErrorcode/Error: %d - '%s'.\\n\" % (errcode, str(caughte)))\n            sys.stderr.flush()\n        raise MySQLdb.OperationalError(caughte)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_insert_dict_string(self, tblname, d, PKfields=[], fields=None, check_existing = False):\n        '''The main function of the insert_dict functions.\n           This creates and returns the SQL query and parameters used by the other functions but does not insert any data into the database.\n\n           Simple function for inserting a dictionary whose keys match the fieldnames of tblname. The function returns two values, the\n           second of which is a dict containing the primary keys of the record. If a record already exists then no insertion is performed and\n           (False, the dictionary of existing primary keys) is returned. Otherwise, the record is inserted into the database and (True, d)\n           is returned.'''\n\n        if type(PKfields) == type(\"\"):\n            PKfields = [PKfields]\n\n        if fields == None:\n            fields = sorted(d.keys())\n        values = None\n        SQL = None\n        try:\n            # Search for existing records\n            wherestr = []\n            PKvalues = []\n            for PKfield in PKfields:\n                if d[PKfield] == None:\n                    wherestr.append(\"%s IS NULL\" % PKfield)\n                else:\n                    wherestr.append(\"%s=%%s\" % PKfield)\n                    PKvalues.append(d[PKfield])\n            PKfields = join(PKfields, \",\")\n            wherestr = join(wherestr, \" AND \")\n\n            record_exists = None\n            if check_existing:\n                record_exists = not(not(self.execute_select(\"SELECT %s FROM %s\" % (PKfields, tblname) + \" WHERE %s\" % wherestr, parameters=tuple(PKvalues), locked = False)))\n\n            SQL = 'INSERT INTO %s (%s) VALUES (%s)' % (\n            tblname, join(fields, \", \"), join(['%s' for x in range(len(fields))], ','))\n            values = tuple([d[k] for k in fields])\n            return SQL, values, record_exists\n        except Exception, e:\n            raise Exception(\"Error occurred during database insertion: '%s'. %s\" % (str(e), traceback.format_exc()))", "response": "Create a SQL query and parameters used by the insert_dict functions."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npaginating a single node of the cluster.", "response": "def paginate(page, total_items, total_pages, slice_size=5):\n    \"\"\"\n    Paginate\n    Does some maths to generate ranged pagination. Returns a dictionary\n    of page numbers to be used in url builders that allows to go to first\n    page, previous page, next page, last page and one of the pages in\n    range around current page with possibility to jump in slices. The\n    result will look like this:\n\n        {\n            page: 2,\n            total_pages: 100,\n            total_items: 1000,\n            pagination: {\n                first: 1\n                previous: 1,\n                previous_slice: 1\n                pages: [1, 2, 3, 4, 5, 6, 7 ... etc]\n                next_slice: 14\n                next: 3,\n                last: 100\n            }\n\n        }\n    :return: boiler.collections.paginated_collection.PaginatedCollection\n    \"\"\"\n    if slice_size > total_pages:\n        slice_size = total_pages\n\n    # paginate (can be out of bounds for now)\n    first = 1\n    previous = page - 1\n    next = page + 1\n    last = total_pages\n    previous_slice = page - slice_size\n    next_slice = page + slice_size\n\n    # assemble\n    links = dict(\n        first=None,\n        previous=None,\n        next=None,\n        last=None\n    )\n\n    # previous/next\n    if total_pages > 1:\n        if page == 1:\n            links['next'] = next\n            links['last'] = last\n        elif page == total_pages:\n            links['first'] = first\n            links['previous'] = previous\n        else:\n            links['first'] = first\n            links['previous'] = previous\n            links['next'] = next\n            links['last'] = last\n\n    # previous_slice\n    links['previous_slice'] = previous_slice\n    if page - slice_size <= 0:\n        links['previous_slice'] = None\n        if page != 1:\n            links['previous_slice'] = first\n\n    # next slice\n    links['next_slice'] = next_slice\n    if page + slice_size > total_pages:\n        links['next_slice'] = None\n        if page != total_pages and total_pages != 0:\n            links['next_slice'] = last\n\n    # slice pages\n    delta = math.ceil(slice_size / 2)\n    if page - delta > total_pages - slice_size:\n        left_bound = total_pages - slice_size + 1\n        right_bound = total_pages\n    else:\n        if page - delta < 0:\n            delta = page\n\n        offset = page - delta\n        left_bound = offset + 1\n        right_bound = offset + slice_size\n\n    # append page range\n    links['pages'] = list(range(left_bound, right_bound + 1))\n\n    # discard slice navigation if no next/prev slice\n    if links['pages']:\n        if links['previous_slice'] == links['pages'][0]:\n            links['previous_slice'] = None\n        if links['next_slice'] == links['pages'][-1]:\n            links['next_slice'] = None\n\n    # and return\n    pagination = dict(\n        page=page,\n        total_pages=total_pages,\n        total_items=total_items,\n        pagination=links\n    )\n\n    return pagination"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of PFAM accession numbers for a given PDB ID.", "response": "def get_pfam_accession_numbers_from_pdb_id(self, pdb_id):\n        '''Note: an alternative is to use the RCSB API e.g. http://www.rcsb.org/pdb/rest/hmmer?structureId=1cdg.'''\n        pdb_id = pdb_id.lower()\n        if self.pdb_chain_to_pfam_mapping.get(pdb_id):\n            return self.pdb_chain_to_pfam_mapping[pdb_id].copy()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_pfam_accession_numbers_from_pdb_chain(self, pdb_id, chain):\n        '''Note: an alternative is to use the RCSB API e.g. http://www.rcsb.org/pdb/rest/hmmer?structureId=1cdg.'''\n        return self.pdb_chain_to_pfam_mapping.get(pdb_id.lower(), {}).get(chain)", "response": "Get the PFAM accession numbers for a given PDB ID and chain."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef flavor_rotation(C_in, Uq, Uu, Ud, Ul, Ue, sm_parameters=True):\n    C = {}\n    if sm_parameters:\n        # shift of theta terms, see 0907.4763\n        C['Thetas'] = C_in['Thetas'] - 2*argdet(Uq) + argdet(Uu) + argdet(Ud)\n        C['Theta'] = C_in['Theta'] - 3*argdet(Uq) - argdet(Ul)\n        C['Thetap'] = ( C_in['Thetap'] - (1/6)*argdet(Uq) + (4/3)*argdet(Uu) + (1/3)*argdet(Ud)\n                                       - (1/2)*argdet(Ul) + argdet(Ue))\n        # nothing to do for scalar SM parameters\n        for k in ['g', 'gp', 'gs', 'Lambda', 'm2']:\n            C[k] = C_in[k]\n        C['Ge'] = Ul.conj().T @ C_in['Ge'] @ Ue\n        C['Gu'] = Uq.conj().T @ C_in['Gu'] @ Uu\n        C['Gd'] = Uq.conj().T @ C_in['Gd'] @ Ud\n    # nothing to do for purely bosonic operators\n    for k in WC_keys_0f:\n        C[k] = C_in[k]\n    # see 1704.03888 table 4 (but staying SU(2) invariant here)\n    # LR\n    for k in ['ephi', 'eW', 'eB']:\n        C[k] = Ul.conj().T @ C_in[k] @ Ue\n    for k in ['uphi', 'uW', 'uB', 'uG']:\n        C[k] = Uq.conj().T @ C_in[k] @ Uu\n    for k in ['dphi', 'dW', 'dB', 'dG']:\n        C[k] = Uq.conj().T @ C_in[k] @ Ud\n    # LL\n    for k in ['phil1', 'phil3']:\n        C[k] = Ul.conj().T @ C_in[k] @ Ul\n    for k in ['phiq1', 'phiq3']:\n        C[k] = Uq.conj().T @ C_in[k] @ Uq\n    C['llphiphi'] = Ul.T @ C_in['llphiphi'] @ Ul\n    # RR\n    C['phie'] = Ue.conj().T @ C_in['phie'] @ Ue\n    C['phiu'] = Uu.conj().T @ C_in['phiu'] @ Uu\n    C['phid'] = Ud.conj().T @ C_in['phid'] @ Ud\n    C['phiud'] = Uu.conj().T @ C_in['phiud'] @ Ud\n    # 4-fermion\n    C['ll'] = np.einsum('jb,ld,ia,kc,ijkl->abcd', Ul, Ul, Ul.conj(), Ul.conj(), C_in['ll'])\n    C['ee'] = np.einsum('jb,ld,ia,kc,ijkl->abcd', Ue, Ue, Ue.conj(), Ue.conj(), C_in['ee'])\n    C['le'] = np.einsum('jb,ld,ia,kc,ijkl->abcd', Ul, Ue, Ul.conj(), Ue.conj(), C_in['le'])\n    C['qq1'] = np.einsum('jb,ld,ia,kc,ijkl->abcd', Uq, Uq, Uq.conj(), Uq.conj(), C_in['qq1'])\n    C['qq3'] = np.einsum('jb,ld,ia,kc,ijkl->abcd', Uq, Uq, Uq.conj(), Uq.conj(), C_in['qq3'])\n    C['dd'] = np.einsum('jb,ld,ia,kc,ijkl->abcd', Ud, Ud, Ud.conj(), Ud.conj(), C_in['dd'])\n    C['uu'] = np.einsum('jb,ld,ia,kc,ijkl->abcd', Uu, Uu, Uu.conj(), Uu.conj(), C_in['uu'])\n    C['ud1'] = np.einsum('jb,ld,ia,kc,ijkl->abcd', Uu, Ud, Uu.conj(), Ud.conj(), C_in['ud1'])\n    C['ud8'] = np.einsum('jb,ld,ia,kc,ijkl->abcd', Uu, Ud, Uu.conj(), Ud.conj(), C_in['ud8'])\n    C['qu1'] = np.einsum('jb,ld,ia,kc,ijkl->abcd', Uq, Uu, Uq.conj(), Uu.conj(), C_in['qu1'])\n    C['qu8'] = np.einsum('jb,ld,ia,kc,ijkl->abcd', Uq, Uu, Uq.conj(), Uu.conj(), C_in['qu8'])\n    C['qd1'] = np.einsum('jb,ld,ia,kc,ijkl->abcd', Uq, Ud, Uq.conj(), Ud.conj(), C_in['qd1'])\n    C['qd8'] = np.einsum('jb,ld,ia,kc,ijkl->abcd', Uq, Ud, Uq.conj(), Ud.conj(), C_in['qd8'])\n    C['quqd1'] = np.einsum('jb,ld,ia,kc,ijkl->abcd', Uu, Ud, Uq.conj(), Uq.conj(), C_in['quqd1'])\n    C['quqd8'] = np.einsum('jb,ld,ia,kc,ijkl->abcd', Uu, Ud, Uq.conj(), Uq.conj(), C_in['quqd8'])\n    C['lq1'] = np.einsum('jb,ld,ia,kc,ijkl->abcd', Ul, Uq, Ul.conj(), Uq.conj(), C_in['lq1'])\n    C['lq3'] = np.einsum('jb,ld,ia,kc,ijkl->abcd', Ul, Uq, Ul.conj(), Uq.conj(), C_in['lq3'])\n    C['ld'] = np.einsum('jb,ld,ia,kc,ijkl->abcd', Ul, Ud, Ul.conj(), Ud.conj(), C_in['ld'])\n    C['lu'] = np.einsum('jb,ld,ia,kc,ijkl->abcd', Ul, Uu, Ul.conj(), Uu.conj(), C_in['lu'])\n    C['qe'] = np.einsum('jb,ld,ia,kc,ijkl->abcd', Uq, Ue, Uq.conj(), Ue.conj(), C_in['qe'])\n    C['ed'] = np.einsum('jb,ld,ia,kc,ijkl->abcd', Ue, Ud, Ue.conj(), Ud.conj(), C_in['ed'])\n    C['eu'] = np.einsum('jb,ld,ia,kc,ijkl->abcd', Ue, Uu, Ue.conj(), Uu.conj(), C_in['eu'])\n    C['ledq'] = np.einsum('jb,ld,ia,kc,ijkl->abcd', Ue, Uq, Ul.conj(), Ud.conj(), C_in['ledq'])\n    C['lequ1'] = np.einsum('jb,ld,ia,kc,ijkl->abcd', Ue, Uu, Ul.conj(), Uq.conj(), C_in['lequ1'])\n    C['lequ3'] = np.einsum('jb,ld,ia,kc,ijkl->abcd', Ue, Uu, Ul.conj(), Uq.conj(), C_in['lequ3'])\n    C['duql'] = np.einsum('jb,ld,ia,kc,ijkl->abcd', Uu, Ul, Ud, Uq, C_in['duql'])\n    C['qque'] = np.einsum('jb,ld,ia,kc,ijkl->abcd', Uq, Ue, Uq, Uu, C_in['qque'])\n    C['qqql'] = np.einsum('jb,ld,ia,kc,ijkl->abcd', Uq, Ul, Uq, Uq, C_in['qqql'])\n    C['duue'] = np.einsum('jb,ld,ia,kc,ijkl->abcd', Uu, Ue, Ud, Uu, C_in['duue'])\n    return C", "response": "Flavor rotation of all Wilson coefficients and SM parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts a byte array to an integer.", "response": "def bytes_to_int(byte_array, big_endian=True, signed=False):\n    \"\"\"\n    Converts a byte array to an integer.\n    \"\"\"\n    if six.PY3:\n        order = 'little'\n        if big_endian:\n            order = 'big'\n        return int.from_bytes(byte_array, byteorder=order, signed=signed)\n    else:\n        length = len(byte_array)\n        if length == 1:\n            code = 'B'\n        elif length == 2:\n            code = 'H'\n        elif length == 4:\n            code = 'L'\n        elif length == 8:\n            code = 'Q'\n        else:\n            raise Exception(\"bytes_to_int : length of byte_array should be 1, 2, 4, or 8\")\n        if big_endian:\n            code = '>'+code\n        else:\n            code = '<'+code\n\n        if signed:\n            code = code.lower()\n        return struct.unpack(code, byte_array)[0]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting a byte array to a list of uuids.", "response": "def bytes_to_uuid_list(byte_array):\n    \"\"\"\n    Converts a byte array to a list of uuids. Cuts the byte array by packets of 16 bytes and parse each as uuid.\n    :param byte_array: a byte array of length n*16\n    :return: a list of uuid objects\n    \"\"\"\n    result = []\n    for i in range(0, len(byte_array)//16):\n        result.append(uuid.UUID(bytes=bytes(byte_array[i*16:i*16+16])))\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef batch(byte_array, funcs):\n    result = []\n    length = bytes_to_int(byte_array[0:4])\n    item_size = bytes_to_int(byte_array[4:8])\n    for i in range(0, length):\n        chunk = byte_array[8+i*item_size:8+(i+1)*item_size]\n        for f in funcs:\n            f(chunk)\n    return result", "response": "Converts a batch of bytes to a list of uuid objects."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nencode some text or string to a byte array", "response": "def text_to_bytes(text, encoding='UTF-8', size=None):\n    \"\"\"\n    Encode some text or string to a byte array\n    :param text: text to encode to bytes\n    :param encoding: optional encoding of the passed string. default to utf-8.\n    :param size: optional, if given the text will be padded with 0x00 to the right size\n    :return: a bytes object\n    \"\"\"\n    res = str(text).encode(encoding)\n    if size:\n        res = res.rjust(size, b'\\x00')\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts an integer to a byte array.", "response": "def int_to_bytes(val, bit=32, signed=False, big_endian=True):\n    \"\"\"\n    Converts an int to a byte array (bytes).\n    :param val: value to encode\n    :param bit: bit length of the integer to encode\n    :param signed: encode as unsigned int if false\n    :param big_endian: encode with big or little endian\n    :return:\n    \"\"\"\n    val = int(val) #ensure it is an int\n\n    if six.PY3:\n        order = 'little'\n        if big_endian:\n            order = 'big'\n        return val.to_bytes(length=bit//8, byteorder=order, signed=signed)\n\n    if bit == 8:\n        code = 'B'\n    elif bit == 16:\n        code = 'H'\n    elif bit == 32:\n        code = 'I'\n    elif bit == 64:\n        code = 'Q'\n    else:\n        raise Exception(\"int_to_bytes : size parameter value should be 8, 16, 32, or 64\")\n\n    if big_endian:\n        code = '>'+code\n    else:\n        code = '<'+code\n\n    if signed or val < 0:\n        code = code.lower()\n\n    return struct.pack(code, val)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert an IP given as a string to a byte sequence", "response": "def ip_to_bytes(ip_str, big_endian=True):\n    \"\"\"\n    Converts an IP given as a string to a byte sequence\n    \"\"\"\n    if big_endian:\n        code = '>L'\n    else:\n        code = '<L'\n    return bytes(struct.unpack(code, socket.inet_aton(ip_str))[0])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndecoding a ber length byte array into an integer WorkItem", "response": "def decode_ber(ber):\n    \"\"\"\n    Decodes a ber length byte array into an integer\n    return: (length, bytes_read) - a tuple of values\n    \"\"\"\n    ber = bytearray(ber)\n    length = ber[0]\n    bytes_read = 1\n    if length > 127:\n        bytes_read += length & 127 # Strip off the high bit\n        length = 0\n        for i in range(1, bytes_read):\n            length += ber[i] << (8 * (bytes_read - i - 1))\n    return length, bytes_read"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ber_from_socket(s):\n    if isinstance(s, network.SocketClient):\n        recv = s.receive\n    else:\n        recv = s.recv\n    data = recv(1)\n\n    length = data[0]\n    bytes_read = 1\n    if length > 127:\n        bytes_read += length & 127 # Strip off the high bit\n        data += recv(bytes_read - 1)\n        length = 0\n        for i in range(1, bytes_read):\n            length += data[i] << (8 * (bytes_read - i - 1))\n    return length, bytes_read, data", "response": "Reads a ber length from a socket."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nencodes an integer to ber length.", "response": "def encode_ber(value, ber_length=0):\n    \"\"\"\n    Encodes an integer to ber length\n    You can set the ber_length manually.\n    return: bitearray object\n    \"\"\"\n    if not ber_length:\n        if value < 127: # 1 byte case\n            return bytearray([value])\n        ber_length = 1\n        while value >= pow(2, 8*ber_length):\n            ber_length += 1\n        ber_length += 1\n\n\n    ber = bytearray(ber_length)\n    ber[0] = 127 + ber_length #ber length byte\n    for i in range(1, ber_length):\n        ber[i] = (value >> (8 * (ber_length - 1 - i))) & 255\n    return ber"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns absolute path to logging file for obj s attribute.", "response": "def get_file(self, attr_name):\n        '''Return absolute path to logging file for obj's attribute.'''\n        return os.path.abspath(os.path.join(self.folder, \"{}.log\"\n                                            .format(attr_name)))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlog attribute to file and pass the message to underlying logger.", "response": "def log_attr(self, level, attr_name):\n        '''Log attribute to file and pass the message to underlying logger.\n\n        :param int level: logging level\n        :param str attr_name: attribute's name to be logged\n        '''\n        msg = self.write(attr_name)\n        self.log(level, msg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef write(self, attr_name, prefix=None):\n        '''Write attribute's value to a file.\n\n        :param str attr_name:\n            Attribute's name to be logged\n\n        :param str prefix:\n            Optional. Attribute's name that is prefixed to logging message,\n            defaults to ``None``.\n\n        :returns: message written to file\n        :rtype: str\n        '''\n        if self._folder is None:\n            return\n\n        separator = \"\\t\"\n        attr = getattr(self.obj, attr_name)\n        if hasattr(attr, '__iter__'):\n            msg = separator.join([str(e) for e in attr])\n        else:\n            msg = str(attr)\n\n        if prefix is not None:\n            msg = \"{}\\t{}\".format(getattr(self.obj, prefix), msg)\n\n        path = self.get_file(attr_name)\n        with open(path, 'a') as f:\n            f.write(\"{}\\n\".format(msg))\n\n        return msg", "response": "Writes the value of an attribute to a file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_lambda(fun):\n    return isinstance(fun, type(LAMBDA)) and fun.__name__ == LAMBDA.__name__", "response": "Check whether the given function is a lambda function."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the least fixed point when it can be computed piecewise.", "response": "def fixed_point(is_zero, plus, minus, f, x):\n    \"\"\"\n    Get the least fixed point when it can be computed piecewise.\n\n    .. testsetup::\n\n        from proso.func import fixed_point\n\n    .. doctest::\n\n        >>> sorted(fixed_point(\n        ...    is_zero=lambda xs: len(xs) == 0,\n        ...    plus=lambda xs, ys: xs + ys,\n        ...    minus=lambda xs, ys: [x for x in xs if x not in ys],\n        ...    f=lambda xs: [x + 1 for x in xs if x < 10],\n        ...    x=[0, 5, 8]\n        ... ))\n        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n\n    Args:\n        is_zero: function returning True if the given value is zero\n        plus: function taking two values and returning their addition\n        minus: function taking two values and returning ther difference\n        f: function computing the expected value\n        x: initial value\n\n    Returns:\n        The least fixed point.\n    \"\"\"\n\n    @memo_Y\n    def _fixed_point(fixed_point_fun):\n        def __fixed_point(collected, new):\n            diff = minus(new, collected)\n            if is_zero(diff):\n                return collected\n            return fixed_point_fun(plus(collected, diff), f(diff))\n        return __fixed_point\n\n    return _fixed_point(x, f(x))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef install(application, default_content_type, encoding=None):\n    try:\n        settings = application.settings[SETTINGS_KEY]\n    except KeyError:\n        settings = application.settings[SETTINGS_KEY] = ContentSettings()\n        settings.default_content_type = default_content_type\n        settings.default_encoding = encoding\n    return settings", "response": "Install the media type management settings into the application s settings dictionary."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_settings(application, force_instance=False):\n    try:\n        return application.settings[SETTINGS_KEY]\n    except KeyError:\n        if not force_instance:\n            return None\n    return install(application, None)", "response": "Retrieves the media type settings for an application."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a handler for a binary content type.", "response": "def add_binary_content_type(application, content_type, pack, unpack):\n    \"\"\"\n    Add handler for a binary content type.\n\n    :param tornado.web.Application application: the application to modify\n    :param str content_type: the content type to add\n    :param pack: function that packs a dictionary to a byte string.\n        ``pack(dict) -> bytes``\n    :param unpack: function that takes a byte string and returns a\n        dictionary.  ``unpack(bytes) -> dict``\n\n    \"\"\"\n    add_transcoder(application,\n                   handlers.BinaryContentHandler(content_type, pack, unpack))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a handler for a text content type.", "response": "def add_text_content_type(application, content_type, default_encoding,\n                          dumps, loads):\n    \"\"\"\n    Add handler for a text content type.\n\n    :param tornado.web.Application application: the application to modify\n    :param str content_type: the content type to add\n    :param str default_encoding: encoding to use when one is unspecified\n    :param dumps: function that dumps a dictionary to a string.\n        ``dumps(dict, encoding:str) -> str``\n    :param loads: function that loads a dictionary from a string.\n        ``loads(str, encoding:str) -> dict``\n\n    Note that the ``charset`` parameter is stripped from `content_type`\n    if it is present.\n\n    \"\"\"\n    parsed = headers.parse_content_type(content_type)\n    parsed.parameters.pop('charset', None)\n    normalized = str(parsed)\n    add_transcoder(application,\n                   handlers.TextContentHandler(normalized, dumps, loads,\n                                               default_encoding))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_transcoder(application, transcoder, content_type=None):\n    settings = get_settings(application, force_instance=True)\n    settings[content_type or transcoder.content_type] = transcoder", "response": "Adds a transcoder to the list of available transcoders for a specific content type."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_default_content_type(application, content_type, encoding=None):\n    settings = get_settings(application, force_instance=True)\n    settings.default_content_type = content_type\n    settings.default_encoding = encoding", "response": "Store the default content type for an application."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfigures out what content type will be used in the response.", "response": "def get_response_content_type(self):\n        \"\"\"Figure out what content type will be used in the response.\"\"\"\n        if self._best_response_match is None:\n            settings = get_settings(self.application, force_instance=True)\n            acceptable = headers.parse_accept(\n                self.request.headers.get(\n                    'Accept',\n                    settings.default_content_type\n                    if settings.default_content_type else '*/*'))\n            try:\n                selected, _ = algorithms.select_content_type(\n                    acceptable, settings.available_content_types)\n                self._best_response_match = '/'.join(\n                    [selected.content_type, selected.content_subtype])\n                if selected.content_suffix is not None:\n                    self._best_response_match = '+'.join(\n                        [self._best_response_match, selected.content_suffix])\n            except errors.NoMatch:\n                self._best_response_match = settings.default_content_type\n\n        return self._best_response_match"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfetches the request body as a dictionary.", "response": "def get_request_body(self):\n        \"\"\"\n        Fetch (and cache) the request body as a dictionary.\n\n        :raise web.HTTPError:\n            - if the content type cannot be matched, then the status code\n              is set to 415 Unsupported Media Type.\n            - if decoding the content body fails, then the status code is\n              set to 400 Bad Syntax.\n\n        \"\"\"\n        if self._request_body is None:\n            settings = get_settings(self.application, force_instance=True)\n            content_type_header = headers.parse_content_type(\n                self.request.headers.get('Content-Type',\n                                         settings.default_content_type))\n            content_type = '/'.join([content_type_header.content_type,\n                                     content_type_header.content_subtype])\n            if content_type_header.content_suffix is not None:\n                content_type = '+'.join([content_type,\n                                         content_type_header.content_suffix])\n            try:\n                handler = settings[content_type]\n            except KeyError:\n                raise web.HTTPError(415, 'cannot decode body of type %s',\n                                    content_type)\n\n            try:\n                self._request_body = handler.from_bytes(self.request.body)\n            except Exception:\n                self._logger.exception('failed to decode request body')\n                raise web.HTTPError(400, 'failed to decode request')\n\n        return self._request_body"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nserialize and send the body in the response.", "response": "def send_response(self, body, set_content_type=True):\n        \"\"\"\n        Serialize and send ``body`` in the response.\n\n        :param dict body: the body to serialize\n        :param bool set_content_type: should the :http:header:`Content-Type`\n            header be set?  Defaults to :data:`True`\n\n        \"\"\"\n        settings = get_settings(self.application, force_instance=True)\n        handler = settings[self.get_response_content_type()]\n        content_type, data_bytes = handler.to_bytes(body)\n        if set_content_type:\n            self.set_header('Content-Type', content_type)\n            self.add_header('Vary', 'Accept')\n        self.write(data_bytes)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef connections_from_graph(env, G, edge_data=False):\n    if not issubclass(G.__class__, (Graph, DiGraph)):\n        raise TypeError(\"Graph structure must be derived from Networkx's \"\n                        \"Graph or DiGraph.\")\n    if not hasattr(env, 'get_agents'):\n        raise TypeError(\"Parameter 'env' must have get_agents.\")\n\n    addrs = env.get_agents(addr=True)\n    if len(addrs) != len(G):\n        raise ValueError(\"The number of graph nodes and agents in the \"\n                         \"environment (excluding the manager agent) must \"\n                         \"match. Now got {} nodes and {} agents.\"\n                         .format(len(G), len(addrs)))\n    # Sort agent addresses to the order they were added to the environment.\n    addrs = sort_addrs(addrs)\n    _addrs2nodes(addrs, G)\n    conn_map = _edges2conns(G, edge_data)\n    env.create_connections(conn_map)", "response": "Create connections for agents in the given environment from the given NetworkX graph structure."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef graph_from_connections(env, directed=False):\n    G = DiGraph() if directed else Graph()\n    conn_list = env.get_connections(data=True)\n    for agent, conns in conn_list:\n        G.add_node(agent)\n        ebunch = []\n        for nb, data in conns.items():\n            ebunch.append((agent, nb, data))\n        if len(ebunch) > 0:\n            G.add_edges_from(ebunch)\n    return G", "response": "Create a NetworkX graph from agent connections in a given environment."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _addrs2nodes(addrs, G):\n    for i, n in enumerate(G.nodes()):\n        G.node[n]['addr'] = addrs[i]", "response": "Map agent addresses to nodes in the graph."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _edges2conns(G, edge_data=False):\n    cm = {}\n    for n in G.nodes(data=True):\n        if edge_data:\n            cm[n[1]['addr']] = [(G.node[nb]['addr'], G[n[0]][nb])\n                                for nb in G[n[0]]]\n        else:\n            cm[n[1]['addr']] = [(G.node[nb]['addr'], {}) for nb in G[n[0]]]\n    return cm", "response": "Create a mapping from edges to agent connections."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef profile(request, status=200):\n    if request.method == 'GET':\n        if request.GET.get(\"username\", False):\n            try:\n                user_profile = User.objects.get(username=request.GET.get(\"username\"),\n                                                userprofile__public=True).userprofile\n            except ObjectDoesNotExist:\n                raise Http404(\"user not found or have not public profile\")\n        else:\n            user_id = get_user_id(request)\n            if get_config('proso_user', 'google.openid.migration', default=True) and not is_user_id_overridden(request):\n                migrated_user = migrate_google_openid_user(request.user)\n                if migrated_user is not None:\n                    auth.logout(request)\n                    migrated_user.backend = 'social.backends.google.GoogleOAuth2'\n                    auth.login(request, migrated_user)\n            user_profile = get_object_or_404(UserProfile, user_id=user_id)\n        return render_json(\n            request, user_profile, status=status,\n            template='user_profile.html', help_text=profile.__doc__)\n    elif request.method == 'POST':\n        with transaction.atomic():\n            to_save = json_body(request.body.decode(\"utf-8\"))\n            user_id = get_user_id(request)\n            user_profile = get_object_or_404(UserProfile, user_id=user_id)\n            user = to_save.get('user', None)\n            if 'send_emails' in to_save:\n                user_profile.send_emails = bool(to_save['send_emails'])\n            if 'public' in to_save:\n                user_profile.public = bool(to_save['public'])\n            if user:\n                error = _save_user(request, user, new=False)\n                if error:\n                    return render_json(request, error, template='user_json.html', status=400)\n            if 'properties' in to_save:\n                user_profile.save_properties(to_save['properties'])\n            user_profile.save()\n        request.method = \"GET\"\n        return profile(request, status=202)\n    else:\n        return HttpResponseBadRequest(\"method %s is not allowed\".format(request.method))", "response": "Returns a list of user s profile."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef login(request):\n    if request.method == 'GET':\n        return render(request, 'user_login.html', {}, help_text=login.__doc__)\n    elif request.method == 'POST':\n        credentials = json_body(request.body.decode(\"utf-8\"))\n        user = auth.authenticate(\n            username=credentials.get('username', ''),\n            password=credentials.get('password', ''),\n        )\n        if user is None:\n            return render_json(request, {\n                'error': _('Password or username does not match.'),\n                'error_type': 'password_username_not_match'\n            }, template='user_json.html', status=401)\n        if not user.is_active:\n            return render_json(request, {\n                'error': _('The account has not been activated.'),\n                'error_type': 'account_not_activated'\n            }, template='user_json.html', status=401)\n        auth.login(request, user)\n        request.method = \"GET\"\n        return profile(request)\n    else:\n        return HttpResponseBadRequest(\"method %s is not allowed\".format(request.method))", "response": "Log in the user and return the user s profile."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a new user with the given credentials.", "response": "def signup(request):\n    \"\"\"\n    Create a new user with the given credentials.\n\n    GET parameters:\n        html\n            turn on the HTML version of the API\n\n    POST parameters (JSON):\n        username:\n            user's name\n        email:\n            user's e-mail\n        password:\n            user's password\n        password_check:\n            user's password again to check it\n        first_name (optional):\n            user's first name\n        last_name (optional):\n            user's last name\n    \"\"\"\n    if request.method == 'GET':\n        return render(request, 'user_signup.html', {}, help_text=signup.__doc__)\n    elif request.method == 'POST':\n        if request.user.is_authenticated() and hasattr(request.user, \"userprofile\"):\n            return render_json(request, {\n                'error': _('User already logged in'),\n                'error_type': 'username_logged'\n            }, template='user_json.html', status=400)\n        credentials = json_body(request.body.decode(\"utf-8\"))\n        error = _save_user(request, credentials, new=True)\n        if error is not None:\n            return render_json(request, error, template='user_json.html', status=400)\n        else:\n            auth.login(request, request.user)\n            request.method = \"GET\"\n            return profile(request, status=201)\n    else:\n        return HttpResponseBadRequest(\"method %s is not allowed\".format(request.method))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef session(request):\n\n    if request.user.id is None:  # Google Bot\n        return render_json(request, {\n            'error': _('There is no user available to create a session.'),\n            'error_type': 'user_undefined'\n        }, status=400, template='user_json.html')\n\n    if request.method == 'GET':\n        return render_json(\n            request,\n            Session.objects.get_current_session(),\n            template='user_session.html', help_text=session.__doc__)\n    elif request.method == 'POST':\n        current_session = Session.objects.get_current_session()\n        if current_session is None:\n            return HttpResponseBadRequest(\"there is no current session to modify\")\n        data = json_body(request.body.decode(\"utf-8\"))\n        locale = data.get('locale', None)\n        time_zone = data.get('time_zone', None)\n        display_width = data.get('display_width', None)\n        display_height = data.get('display_height', None)\n        if locale:\n            current_session.locale = locale\n        if time_zone:\n            current_session.time_zone = TimeZone.objects.from_content(time_zone)\n        if display_width:\n            current_session.display_width = display_width\n        if display_height:\n            current_session.display_height = display_height\n        current_session.save()\n        return HttpResponse('ok', status=202)\n    else:\n        return HttpResponseBadRequest(\"method %s is not allowed\".format(request.method))", "response": "Returns the current session or modify the current session."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef initmobile_view(request):\n    if 'username' in request.GET and 'password' in request.GET:\n        username = request.GET['username']\n        password = request.GET['password']\n        user = auth.authenticate(username=username, password=password)\n        if user is not None:\n            if user.is_active:\n                login(request, user)\n    else:\n        user = request.user\n    response = {\n        'username': user.username,\n        'csrftoken': get_token(request),\n    }\n    if not user.has_usable_password():\n        password = User.objects.make_random_password()\n        user.set_password(password)\n        user.save()\n        response['password'] = password\n    return HttpResponse(json.dumps(response))", "response": "Create lazy user with a random password. Used from the Android app."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_device_disk(token):\n    name, token = token.split(\"[\", 1)\n    number, flags = token.split(\"]\", 1)\n\n    return name, {\n        \"number\": int(number),\n        \"write_mostly\": \"W\" in flags,\n        \"faulty\": \"F\" in flags,\n        \"spare\": \"S\" in flags,\n        \"replacement\": \"R\" in flags,\n    }", "response": "Parse a single disk from the header line."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef group_by(what, by):\n    return proso.dict.group_keys_by_values({x: by(x) for x in what})", "response": "Takes a list and applies the given function on each value then group the values by the function on each its value"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef copy_resource_dir(src, dest):\n    package_name = \"mocha\"\n    dest = (dest + \"/\" + os.path.basename(src)).rstrip(\"/\")\n    if pkg_resources.resource_isdir(package_name, src):\n        if not os.path.isdir(dest):\n            os.makedirs(dest)\n        for res in pkg_resources.resource_listdir(__name__, src):\n            copy_resource_dir(src + \"/\" + res, dest)\n    else:\n        if not os.path.isfile(dest) and os.path.splitext(src)[1] not in [\".pyc\"]:\n            copy_resource_file(src, dest)", "response": "Copy a resource directory to a destination"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef init():\n\n    mochapyfile = os.path.join(os.path.join(CWD, \"brew.py\"))\n\n    header(\"Initializing Mocha ...\")\n    if os.path.isfile(mochapyfile):\n        print(\"WARNING: It seems like Mocha is already setup!\")\n        print(\"*\" * 80)\n    else:\n        print(\"\")\n        print(\"Copying files to the current directory...\")\n        copy_resource_dir(SKELETON_DIR + \"/create/\", CWD)\n        print(\"\")\n\n        _npm_install_static()\n        print(\"\")\n        print(\"----- Your Mocha is ready! ----\")\n        print(\"\")\n        print(\"> What's next?\")\n        print(\"- Edit the config [ application/config.py ] \")\n        print(\"- If necessary setup your model database [ mocha :initdb ]\")\n        print(\"- Launch app on development mode, run [ mocha :serve ]\")\n        print(\"\")\n        print(\"*\" * 80)", "response": "Initialize Mocha in the current directory"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a new view and template page", "response": "def add_view(name, no_template):\n    \"\"\" Create a new view and template page \"\"\"\n\n    app_dest = APPLICATION_DIR\n    viewsrc = \"%s/create-view/view.py\" % SKELETON_DIR\n    tplsrc = \"%s/create-view/template.jade\" % SKELETON_DIR\n    viewdest_dir = os.path.join(app_dest, \"views\")\n    viewdest = os.path.join(viewdest_dir, \"%s.py\" % name)\n    tpldest_dir = os.path.join(app_dest, \"templates/%s/Index\" % name)\n    tpldest = os.path.join(tpldest_dir, \"index.jade\")\n\n    header(\"Adding New View\")\n    print(\"View: %s\" % viewdest.replace(CWD, \"\"))\n    if not no_template:\n        print(\"Template: %s\" % tpldest.replace(CWD, \"\"))\n    else:\n        print(\"* Template will not be created because of the flag --no-template| -t\")\n    if os.path.isfile(viewdest) or os.path.isfile(tpldest):\n        print(\"*** ERROR: View or Template file exist already\")\n    else:\n        if not os.path.isdir(viewdest_dir):\n            utils.make_dirs(viewdest_dir)\n        copy_resource_file(viewsrc, viewdest)\n        with open(viewdest, \"r+\") as vd:\n            content = vd.read()\\\n                .replace(\"%ROUTE%\", name.lower())\\\n                .replace(\"%NAV_TITLE%\", name.capitalize())\n            vd.seek(0)\n            vd.write(content)\n            vd.truncate()\n\n        if not no_template:\n            if not os.path.isdir(tpldest_dir):\n                utils.make_dirs(tpldest_dir)\n            copy_resource_file(tplsrc, tpldest)\n\n    print(\"\")\n    print(\"*\" * 80)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef server(port):\n\n    header(\"Serving application in development mode ... \")\n    print(\"\")\n    print(\"- Port: %s\" % port)\n    print(\"\")\n    cwd_to_sys_path()\n    application.app.run(debug=True, host='0.0.0.0', port=port)", "response": "Serve application in development mode"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the flask_alembic module to the global extension", "response": "def _set_flask_alembic():\n    from flask_alembic import Alembic\n\n    \"\"\" Add the SQLAlchemy object in the global extension \"\"\"\n    application.app.extensions[\"sqlalchemy\"] = type('', (), {\"db\": db})\n    alembic = Alembic()\n    alembic.init_app(application.app)\n    return alembic"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupload assets files to S3", "response": "def assets2s3():\n    \"\"\" Upload assets files to S3 \"\"\"\n    import flask_s3\n\n    header(\"Assets2S3...\")\n    print(\"\")\n    print(\"Building assets files...\" )\n    print(\"\")\n    build_assets(application.app)\n    print(\"\")\n    print(\"Uploading assets files to S3 ...\")\n    flask_s3.create_all(application.app)\n    print(\"\")"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cmd():\n    global application\n\n    mochapyfile = os.path.join(os.path.join(CWD, \"brew.py\"))\n    if os.path.isfile(mochapyfile):\n        cwd_to_sys_path()\n        application = import_string(\"brew\")\n    else:\n        print(\"-\" * 80)\n        print(\"** Missing << 'brew.py' >> @ %s\" % CWD)\n        print(\"-\" * 80)\n\n    [cmd(cli.command, click) for cmd in Manager.__subclasses__()]\n    cli()", "response": "Help to run the command line\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninitializes the base class with some data.", "response": "def initialize__(cls):\n        \"\"\"\n        Mocha specific\n        To setup some models data after\n        :return:\n        \"\"\"\n        [cls.new(level=r[0], name=r[1]) for r in cls.ROLES]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef new(cls,\n            username,\n            password=None,\n            email=None,\n            first_name=\"\",\n            last_name=\"\",\n            login_method=None,\n            role=\"MEMBER\"\n            ):\n        \"\"\"\n        Create a new user\n        :param username: str\n        :param password: str\n        :param email: str\n        :param first_name: str\n        :param last_name: str\n        :param login_method: str\n        :param role: str\n        :return: AuthUser\n        \"\"\"\n        data = {\n            \"first_name\": first_name,\n            \"last_name\": last_name,\n            \"email\": email\n        }\n\n        if not password:\n            password = utils.generate_random_string()\n\n        username = username.strip().lower()\n        if \"@\" in username and not email:\n            if not utils.is_email_valid(username):\n                exceptions.AuthError(_(\"Invalid username\"))\n            data[\"email\"] = username\n        elif email:\n            if not utils.is_email_valid(email):\n                exceptions.AuthError(_(\"Invalid username\"))\n\n        if not utils.is_username_valid(username):\n            exceptions.AuthError(_(\"Invalid username\"))\n        if not utils.is_password_valid(password):\n            raise exceptions.AuthError(_(\"Password is invalid\"))\n\n        if cls.get_by_username(username):\n            raise exceptions.AuthError(_(\"Username exists already\"))\n        _email = data.get(\"email\")\n        if _email:\n            if cls.get_by_email(_email):\n                raise exceptions.AuthError(_(\"Email address exists already\"))\n\n        role = AuthUserRole.get_by_name(role or \"MEMBER\")\n        if not role:\n            raise exceptions.AuthError(_(\"Invalid user role\"))\n\n        data.update({\n            \"username\": username,\n            \"password_hash\": cls.encrypt_password(password),\n            \"email_verified\": False,\n            \"login_method\": login_method,\n            \"role\": role,\n            \"status\": cls.STATUS_ACTIVE\n        })\n        user = cls.create(**data)\n        user.reset_secret_key()\n        return user", "response": "Create a new user in the database."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_by_username(cls, username):\n        return cls.query().filter(cls.username == username).first()", "response": "Return a User by username"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_by_email(cls, email):\n        return cls.query().filter(cls.email == email).first()", "response": "Return a User by email address"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef search_by_name(cls, query, name):\n        query = query.filter(db.or_(cls.first_name.contains(name),\n                                    cls.last_name.contains(name)))\n        return query", "response": "Make a search\n        query by name"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchanging username of the user.", "response": "def change_username(self, username):\n        \"\"\"\n        Change username\n        :param username: email or str\n        :return:\n        \"\"\"\n        username = username.lower()\n        if self.username != username:\n            if self.get_by_username(username):\n                raise exceptions.AuthError(\"Username exists already\")\n            self.update(username=username)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nchange the email of the user.", "response": "def change_email(self, email, as_username=False):\n        \"\"\"\n        Change account email\n        :param email:\n        :param as_username\n        :return: the email provided\n        \"\"\"\n        email = email.lower()\n        data = {\"email\": email}\n        if self.email != email:\n            if self.get_by_email(email):\n                raise exceptions.AuthError(\"Email exists already\")\n            if as_username:\n                if self.username != email:\n                    if self.get_by_username(email):\n                        raise exceptions.AuthError(\"Username exists already\")\n                data[\"username\"] = email\n\n            self.update(**data)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchanges the password of the current node.", "response": "def change_password(self, password):\n        \"\"\"\n        Change the password.\n        :param password:\n        :return:\n        \"\"\"\n        self.update(password_hash=self.encrypt_password(password),\n                    require_password_change=False)\n\n        # Whenever the password is changed, reset the secret key to invalidate\n        # any tokens in the wild\n        self.reset_secret_key()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_options(self, **kwargs):\n        options = self.options\n        options.update(kwargs)\n        self.update(options=options)", "response": "Set the options. Existing value will persist\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef has_any_roles(self, *roles):\n        roles = map(utils.slugify, list(roles))\n\n        return True \\\n            if AuthUserRole.query() \\\n            .join(AuthUser) \\\n            .filter(AuthUserRole.name.in_(roles)) \\\n            .filter(AuthUser.id == self.id) \\\n            .count() \\\n            else False", "response": "Check if user has any of the requested roles"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef new(cls, user, provider, federated_id):\n        if cls.get_user(provider, federated_id):\n            raise exceptions.AuthError(\"Federation already\")\n\n        return cls.create(user_id=user.id,\n                          provider=provider,\n                          federated_id=federated_id)", "response": "Create a new login - related recordset."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef launch(thing,title=False):\r\n    html=htmlFromThing(thing,title=title)\r\n    if not html:\r\n        print(\"no HTML was generated.\")\r\n        return\r\n    fname=\"%s/%s.html\"%(tempfile.gettempdir(),str(time.time()))\r\n    with open(fname,'w') as f:\r\n        f.write(html)\r\n    webbrowser.open(fname)", "response": "analyze a thing create a nice HTML document and launch it."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef exceptionToString(e):\r\n    exc_type, exc_obj, exc_tb = sys.exc_info()\r\n    s=\"EXCEPTION THROWN UNEXPECTEDLY\"\r\n    s+=\"  FILE: %s\\n\"%os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\r\n    s+=\"  LINE: %s\\n\"%exc_tb.tb_lineno\r\n    s+=\"  TYPE: %s\\n\"%exc_type\r\n    return s", "response": "when you except Exception as e give me the e and I ll give you a string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef analyzeThing(originalThing2):\r\n    originalThing = copy.copy(originalThing2)\r\n    things={}\r\n    for name in sorted(dir(originalThing)):\r\n        print(\"analyzing\",name)\r\n        thing = copy.copy(originalThing)\r\n        if name in webinspect.blacklist or name.lower() in webinspect.blacklist:\r\n            item=\"DID NOT EVALUATE (this will appear as a string)\"\r\n        else:\r\n            item=getattr(thing,name)\r\n        itemType=type(item).__name__\r\n        itemStr=thingToString(item)\r\n        itemEval=\"\"\r\n        if \"method\" in itemStr:\r\n            if name in webinspect.blacklist or name.lower() in webinspect.blacklist:\r\n                itemEval=\"DID NOT EVALUATE\"\r\n            else:\r\n                print(\"executing %s()\"%name)\r\n                print(\"I'm about to try...\")\r\n                try:\r\n                    itemEval=thingToString(getattr(thing,name)())\r\n                except Exception as e:\r\n                    exceptionToString(e)\r\n\r\n\r\n        #print(\"[%s] (%s) %s {%s}\"%(name,itemType,itemStr,itemEval))\r\n        things[name]=[itemType,itemStr,itemEval]\r\n    return things", "response": "analyze an object and all its attirbutes. Returns a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef websafe(s):\r\n    s=s.replace(\"<\",\"&lt;\").replace(\">\",\"&gt;\")\r\n    s=s.replace(r'\\x',r' \\x')\r\n    s=s.replace(\"\\n\",\"<br>\")\r\n    return s", "response": "return a string with HTML - safe text"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef htmlFromThing(thing,title):\r\n    try:\r\n        thing2 = copy.copy(thing)\r\n    except:\r\n        print(\"crashed copying the thing! I can't document it.\")\r\n        return False\r\n    stuff=analyzeThing(thing2)\r\n    names2=list(stuff.keys())\r\n    for i,name in enumerate(names2):\r\n        if name.startswith(\"_\"):\r\n            names2[i]=\"zzzzzzzzzz\"+name\r\n\r\n    html=\"\"\"<html><head><style>\r\n    body {font-family: courier, monospace;}\r\n    .name {font-weight: bold;}\r\n    .type {font-style: italic; font-family: serif; color: #AAA;}\r\n    .desc {}\r\n    .itemEval {background-color: #DDFFDD;}\r\n    .itemEvalFail {}\r\n    table {font-size: .8em;\r\n           margin-top: 20px;\r\n           border-collapse: collapse;}\r\n    tr {border: 1px solid #CCC; vertical-align: text-top;}\r\n    td {padding: 2px 10px 2px 10px;}\r\n    .credits {text-align: center;\r\n              opacity: 0.5;\r\n              margin-top: 50px;\r\n              font-size: .8em;\r\n              font-family: sans-serif;}\r\n    </style></head><body>\"\"\"\r\n\r\n    if title:\r\n        html+='<span style=\"color: #CCC;\">title: </span>%s<br>'%title\r\n    textTitle=\"\"\r\n    textType=\"\"\r\n    try:\r\n        textTitle=websafe(str(thing))\r\n        textType=websafe(type(thing).__name__)\r\n    except:\r\n        pass\r\n    html+='<span style=\"color: #CCC;\">value: </span>%s<br>'%textTitle\r\n    html+='<span style=\"color: #CCC;\">&nbsp;type: </span>%s<br>'%textType\r\n    html+='<table cellpadding=3 align=\"center\">'\r\n    html+='<tr style=\"background-color: #000; color: #FFF; font-weight: bold;\">'\r\n    html+='<td>property</td><td>type</td><td>value</td>'\r\n    html+='<td>evaluated (without arguments)</td></tr>'\r\n    for name in sorted(names2):\r\n        if name.startswith(\"zzzzzzzzzz\"):\r\n            name=name[10:]\r\n        itemName=str(name)\r\n        itemType=websafe(stuff[name][0])\r\n        itemStr=websafe(stuff[name][1])\r\n        itemEval=websafe(stuff[name][2])\r\n        color=\"DDDDFF\"\r\n        color2=\"\"\r\n        if \"method\" in itemType:\r\n            itemName+=\"()\"\r\n            color=\"FFDDDD\"\r\n        if itemName.startswith(\"_\"):\r\n            color=\"EEEEEE\"\r\n        if itemStr.startswith(\"&lt;\") and not \", \" in itemStr:\r\n            itemStr=\"\"\"<span style=\"color: #CCC; font-family: serif;\r\n                font-style: italic;\">%s</span>\"\"\"%itemStr\r\n        else:\r\n            color2=\"DDFFDD\"\r\n            if itemEval==\"\":\r\n                itemEval=\"FAILED TO EVALUATE\"\r\n        html+='<tr>'\r\n        html+='<td class=\"name\" style=\"background-color: #%s;\">%s</td>'%(color,itemName)\r\n        html+='<td class=\"type\">%s</td>'%(itemType)\r\n        html+='<td class=\"itemStr\" style=\"background-color: #%s;\">%s</td>'%(color2,itemStr)\r\n        if itemEval==\"FAILED TO EVALUATE\":\r\n            html+='<td class=\"itemEvalFail\"></td>'\r\n        else:\r\n            html+='<td class=\"itemEval\">%s</td>'%(itemEval)\r\n        html+='</tr>'\r\n\r\n    dt=datetime.datetime.now()\r\n    html+=\"\"\"</table><p class=\"credits\">\r\n    page automatically generated by\r\n    <a href=\"https://pypi.python.org/pypi/webinspect/\">webinspect</a>\r\n    (version %s) %s</p>\r\n    </body></html>\"\"\"%(__version__,dt.strftime(\"at %I:%M %p on %B %d, %Y\"))\r\n\r\n    return html", "response": "create pretty formatted HTML from a dictionary of things."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsubscribes to the data of the current node.", "response": "def subscribe_to_data(\n        self,\n        subscriber: Callable[[bytes], bool],\n    ) -> None:\n        \"\"\"\n        Not thread-safe.\n\n        \"\"\"\n        self._data_subscribers.append(subscriber)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsubscribes to chat messages.", "response": "def subscribe_to_chat(\n        self,\n        subscriber: Callable[[events.ChatMessageWasReceived], None],\n    ) -> None:\n        \"\"\"\n        Not thread-safe.\n\n        \"\"\"\n        self._chat_subscribers.append(subscriber)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nhandles a chat event.", "response": "def _handle_chat_event(self, event: events.ChatMessageWasReceived) -> None:\n        \"\"\"\n        Not thread-safe.\n\n        \"\"\"\n        for subscriber in self._chat_subscribers:\n            try:\n                subscriber(event)\n            except Exception:\n                LOG.exception(self._prefix_log_message(\n                    f\"failed to send chat event {event} to \"\n                    f\"subscriber {subscriber}\"\n                ))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef subscribe_to_human_connection_events(\n        self,\n        subscriber: Callable[[events.HumanConnectionEvent], None],\n    ) -> None:\n        \"\"\"\n        Not thread-safe.\n\n        \"\"\"\n        self._human_connection_subscribers.append(subscriber)", "response": "Subscribe to human - connection events."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nhandling human connection events.", "response": "def _handle_human_connection_event(\n        self,\n        event: events.HumanConnectionEvent,\n    ) -> None:\n        \"\"\"\n        Not thread-safe.\n\n        \"\"\"\n        for subscriber in self._human_connection_subscribers:\n            try:\n                subscriber(event)\n            except Exception:\n                LOG.exception(self._prefix_log_message(\n                    f\"failed to send human connection event {event} to \"\n                    f\"subscriber {subscriber}\"\n                ))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef slugify(text, delim='-'):\n    punctuation_re = re.compile(r'[\\t !\"#$%&\\'()*\\-/<=>?@\\[\\\\\\]^_`{|},.:]+')\n\n    result = []\n    for word in punctuation_re.split(text.lower()):\n        word = normalize_text(word)\n        if word:\n            result.append(word)\n    return delim.join(result)", "response": "Generates an slightly worse ASCII - only slug."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef javascript_escape(s, quote_double_quotes=True):\n    ustring_re = re.compile(u\"([\\u0080-\\uffff])\")\n\n    def fix(match):\n        return r\"\\u%04x\" % ord(match.group(1))\n\n    if type(s) == str:\n        s = s.decode('utf-8')\n    elif type(s) != six.text_type:\n        raise TypeError(s)\n    s = s.replace('\\\\', '\\\\\\\\')\n    s = s.replace('\\r', '\\\\r')\n    s = s.replace('\\n', '\\\\n')\n    s = s.replace('\\t', '\\\\t')\n    s = s.replace(\"'\", \"\\\\'\")\n    if quote_double_quotes:\n        s = s.replace('\"', '&quot;')\n    return str(ustring_re.sub(fix, s))", "response": "Escape characters for javascript strings."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsending an email with attachments.", "response": "def send_mail(send_from, send_to, subject, text, server, mime='plain', files=None):\n    \"\"\"\n    Send an email with attachments.\n    :param send_from: from email adress\n    :param send_to: to email adress\n    :param subject: email subject\n    :param text: text of the email in html\n    :param server: SMTP server\n    :param files: files to attach\n    :return: None\n    \"\"\"\n    if not files:\n        files = []\n\n    assert type(send_to) == list\n    assert type(files) == list\n\n    msg = MIMEMultipart()\n    msg['From'] = send_from\n    msg['To'] = COMMASPACE.join(send_to)\n    msg['Date'] = formatdate(localtime=True)\n    msg['Subject'] = subject\n\n    msg.attach(MIMEText(text, mime))\n\n    for f in files:\n        part = MIMEBase('application', \"octet-stream\")\n        fp = open(f, \"rb\")\n        file_content = fp.read()\n        part.set_payload(file_content)\n        encoders.encode_base64(part)\n        part.add_header('Content-Disposition', 'attachment; filename=\"%s\"' % os.path.basename(f))\n        msg.attach(part)\n\n    smtp = smtplib.SMTP(server)\n    smtp.sendmail(send_from, send_to, msg.as_string())\n    smtp.close()\n    return"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert string hh : mm : ss. ssssss. ssssss to seconds", "response": "def hms_to_seconds(time_string):\n    \"\"\"\n    Converts string 'hh:mm:ss.ssssss' as a float\n    \"\"\"\n    s = time_string.split(':')\n    hours = int(s[0])\n    minutes = int(s[1])\n    secs = float(s[2])\n    return hours * 3600 + minutes * 60 + secs"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef seconds_to_hms_verbose(t):\n    hours = int((t / 3600))\n    mins = int((t / 60) % 60)\n    secs = int(t % 60)\n    return ' '.join([\n        (hours + ' hour' + ('s' if hours > 1 else '')) if hours > 0 else '',\n        (mins + ' minute' + ('s' if mins > 1 else '')) if mins > 0 else '',\n        (secs + ' second' + ('s' if secs > 1 else '')) if secs > 0 else ''\n    ])", "response": "Converts seconds float to H hours 8 minutes 30 seconds format"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef seconds_to_hms(seconds):\n    hours = int(seconds / 3600.0)\n    minutes = int((seconds / 60.0) % 60.0)\n    secs = float(seconds % 60.0)\n    return \"{0:02d}:{1:02d}:{2:02.6f}\".format(hours, minutes, secs)", "response": "Converts seconds float to hh : mm : ss. ssssss format."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pretty_render(data, format='text', indent=0):\n    if format == 'json':\n        return render_json(data)\n    elif format == 'html':\n        return render_html(data)\n    elif format == 'xml':\n        return render_xml(data)\n    else:\n        return dict_to_plaintext(data, indent=indent)", "response": "Render a dict based on a format"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert a dictionary to an XML ElementTree Element", "response": "def dict_to_xml(xml_dict):\n    \"\"\"\n    Converts a dictionary to an XML ElementTree Element\n    \"\"\"\n    import lxml.etree as etree\n    root_tag = list(xml_dict.keys())[0]\n    root = etree.Element(root_tag)\n    _dict_to_xml_recurse(root, xml_dict[root_tag])\n    return root"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting a text to unicode.", "response": "def uni(text):\n    \"\"\"\n    Tries to force to convert to unicode a text.\n    REALLY DIRTY HACK TO TRY TO DETECT ENCODINGS...\n    :param text: text to convert\n    :return: unicode text\n    \"\"\"\n    if type(text) == six.text_type:\n        for encoding in ['latin_1', 'ascii', 'utf-8']:\n            try:\n                strtext = text.encode(encoding)\n            except:\n                pass\n            else:\n                break\n        text = strtext\n\n    unitext = text\n    for encoding in ['utf-8', 'ascii', 'latin_1']:\n        try:\n            unitext = text.decode(encoding)\n        except:\n            pass\n        else:\n            break\n    return unitext"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the tag data for the first instance of the named tag or for all instances of the named tag.", "response": "def xml_get_tag(xml, tag, parent_tag=None, multi_line=False):\n    \"\"\"\n    Returns the tag data for the first instance of the named tag, or for all instances if multi is true.\n    If a parent tag is specified, then that will be required before the tag.\n    \"\"\"\n    expr_str = '[<:]' + tag + '.*?>(?P<matched_text>.+?)<'\n    if parent_tag:\n        expr_str = '[<:]' + parent_tag + '.*?>.*?' + expr_str\n    expr = re.compile(expr_str, re.DOTALL | re.IGNORECASE)\n    if multi_line:\n        return expr.findall(xml)\n    else:\n        if expr.search(xml):\n            return expr.search(xml).group('matched_text').strip()\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nextract key info from the request.", "response": "def _extract_key_info(self, request):\n        \"\"\"\n        \u4ece\u6b32\u4e0b\u8f7d\u8d44\u6e90\u7684request\u4e2d, \u83b7\u5f97\u8d44\u6e90\u4e0a\u4f20\u4e03\u725b\u65f6\u7684bucket\u548ckey\n        \"\"\"\n        from scrapy.utils.request import request_fingerprint\n\n        key_generator = request.meta.get('qiniu_key_generator')\n        if key_generator:\n            tmp = key_generator(request.url)\n            bucket = tmp['bucket'] or self.bucket\n            key = tmp['key']\n        else:\n            bucket = self.bucket\n            key = '%s%s' % (self.key_prefix, request_fingerprint(request))\n\n        return {'bucket': bucket, 'key': key}"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef file_path(self, request, response=None, info=None):\n        return json.dumps(self._extract_key_info(request))", "response": "Returns the path to the file that is used to store the object."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert a positive integer to a base36 string.", "response": "def _to_base36(number):\n    \"\"\"\n    Convert a positive integer to a base36 string.\n\n    Taken from Stack Overflow and modified.\n    \"\"\"\n    if number < 0:\n        raise ValueError(\"Cannot encode negative numbers\")\n\n    chars = \"\"\n    while number != 0:\n        number, i = divmod(number, 36)  # 36-character alphabet\n        chars = _alphabet[i] + chars\n\n    return chars or \"0\""}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _pad(string, size):\n    strlen = len(string)\n    if strlen == size:\n        return string\n    if strlen < size:\n        return _padding[0:size-strlen] + string\n    return string[-size:]", "response": "Pad a string with leading zeroes to fit the given size truncating\n    if necessary."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating a random string of BLOCK_SIZE length.", "response": "def _random_block():\n    \"\"\"\n    Generate a random string of `BLOCK_SIZE` length.\n    \"\"\"\n    # TODO: Use a better RNG than random.randint\n    random_number = random.randint(0, DISCRETE_VALUES)\n    random_string = _to_base36(random_number)\n    return _pad(random_string, BLOCK_SIZE)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_process_fingerprint():\n    pid = os.getpid()\n    hostname = socket.gethostname()\n    padded_pid = _pad(_to_base36(pid), 2)\n    hostname_hash = sum([ord(x) for x in hostname]) + len(hostname) + 36\n    padded_hostname = _pad(_to_base36(hostname_hash), 2)\n    return padded_pid + padded_hostname", "response": "Extract a unique fingerprint for the current process."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef counter(self):\n        self._counter += 1\n        if self._counter >= DISCRETE_VALUES:\n            self._counter = 0\n        return self._counter", "response": "Return a rolling counter that ensures same - machine and same - time cuids don t collide."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates a full - length cuid as a string.", "response": "def cuid(self):\n        \"\"\"\n        Generate a full-length cuid as a string.\n        \"\"\"\n        # start with a hardcoded lowercase c\n        identifier = \"c\"\n        # add a timestamp in milliseconds since the epoch, in base 36\n        millis = int(time.time() * 1000)\n        identifier += _to_base36(millis)\n        # use a counter to ensure no collisions on the same machine\n        # in the same millisecond\n        count = _pad(_to_base36(self.counter), BLOCK_SIZE)\n        identifier += count\n        # add the process fingerprint\n        identifier += self.fingerprint\n        # add a couple of random blocks\n        identifier += _random_block()\n        identifier += _random_block()\n\n        return identifier"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef slug(self):\n        identifier = \"\"\n        # use a truncated timestamp\n        millis = int(time.time() * 1000)\n        millis_string = _to_base36(millis)\n        identifier += millis_string[-2:]\n        # use a truncated counter\n        count = _pad(_to_base36(self.counter), 1)\n        identifier += count\n        # use a truncated fingerprint\n        identifier += self.fingerprint[0]\n        identifier += self.fingerprint[-1]\n        # use some truncated random data\n        random_data = _random_block()\n        identifier += random_data[-2:]\n\n        return identifier", "response": "Generate a short ( 7 - character ) cuid as a bytestring."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn whether the provided file is a CSV file or not.", "response": "def is_excel_file(inputfile):\n    \"\"\" Return whether the provided file is a CSV file or not.\n    This checks if the first row of the file can be splitted by ',' and\n    if the resulting line contains more than 4 columns (Markers, linkage\n    group, chromosome, trait).\n\n    \"\"\"\n    try:\n        xlrd.open_workbook(inputfile)\n    except Exception as err:\n        print(err)\n        return False\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading an Excel file and returns a matrix containing all the information present in the specified excel sheet.", "response": "def read_excel_file(inputfile, sheet_name):\n    \"\"\" Return a matrix containing all the information present in the\n    excel sheet of the specified excel document.\n\n    :arg inputfile: excel document to read\n    :arg sheetname: the name of the excel sheet to return\n\n    \"\"\"\n    workbook = xlrd.open_workbook(inputfile)\n    output = []\n    found = False\n    for sheet in workbook.sheets():\n        if sheet.name == sheet_name:\n            found = True\n            for row in range(sheet.nrows):\n                values = []\n                for col in range(sheet.ncols):\n                    values.append(sheet.cell(row, col).value)\n                output.append(values)\n    if not found:  # pragma: no cover\n        raise MQ2Exception('Invalid session identifier provided')\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_map_matrix(inputfile, sheet_name):\n    matrix = read_excel_file(inputfile, sheet_name)\n    output = [['Locus', 'Group', 'Position']]\n    for row in matrix:\n        if row[0] and not re.match(r'c\\d+\\.loc[\\d\\.]+', row[0]):\n            output.append([row[0], row[1], row[2]])\n    return output", "response": "Returns the matrix representation of the genetic map."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef valid_file(cls, filename):\n        file_ex = os.path.splitext(filename)[1].replace('.', '', 1)\n        return file_ex in SUPPORTED_FILES and is_excel_file(filename)", "response": "Check if the provided file is a valid file for this plugin."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_files(cls, folder):\n        filelist = []\n        if folder is None or not os.path.isdir(folder):\n            return filelist\n        for root, dirs, files in os.walk(folder):\n            for filename in files:\n                for ext in SUPPORTED_FILES:\n                    filename = os.path.join(root, filename)\n                    if filename.endswith(ext) and is_excel_file(filename):\n                        filelist.append(filename)\n        return filelist", "response": "Retrieve the list of files that can be used in the plugin."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_session_identifiers(cls, folder=None, inputfile=None):\n        sessions = []\n        if inputfile and folder:\n            raise MQ2Exception(\n                'You should specify either a folder or a file')\n        if folder:\n            if not os.path.isdir(folder):\n                return sessions\n            for root, dirs, files in os.walk(folder):\n                for filename in files:\n                    filename = os.path.join(root, filename)\n                    for ext in SUPPORTED_FILES:\n                        if filename.endswith(ext):\n                            wbook = xlrd.open_workbook(filename)\n                            for sheet in wbook.sheets():\n                                if sheet.name not in sessions:\n                                    sessions.append(sheet.name)\n        elif inputfile:\n            if os.path.isdir(inputfile):\n                return sessions\n            for ext in SUPPORTED_FILES:\n                if inputfile.endswith(ext):\n                    wbook = xlrd.open_workbook(inputfile)\n                    for sheet in wbook.sheets():\n                        if sheet.name not in sessions:\n                            sessions.append(sheet.name)\n        return sessions", "response": "Retrieve the list of session identifiers contained in the folder or the inputfile."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef convert_inputfiles(cls,\n                           folder=None,\n                           inputfile=None,\n                           session=None,\n                           lod_threshold=None,\n                           qtls_file='qtls.csv',\n                           matrix_file='qtls_matrix.csv',\n                           map_file='map.csv'):\n        \"\"\" Convert the input files present in the given folder or\n        inputfile.\n        This method creates the matrix representation of the QTLs\n        results providing for each marker position the LOD value found\n        for each trait as well as a representation of the genetic map\n        used in the experiment.\n        The genetic map should be cleared of any markers added by the\n        QTL mapping software.\n\n        :kwarg folder: the path to the folder containing the files to\n            check. This folder may contain sub-folders.\n        :kwarg inputfile: the path to the input file to use\n        :kwarg session: the session identifier used to identify which\n            session to process\n        :kwarg lod_threshold: the LOD threshold to apply to determine if\n            a QTL is significant or not\n        :kwarg qtls_file: a csv file containing the list of all the\n            significant QTLs found in the analysis.\n            The matrix is of type:\n               trait, linkage group, position, Marker, LOD other columns\n        :kwarg matrix_file: a csv file containing a matrix representation\n            of the QTL data. This matrix is of type:\n               marker, linkage group, position, trait1 lod, trait2, lod\n        :kwarg map_file: a csv file containing the genetic map used\n            in this experiment. The map is of structure:\n               marker, linkage group, position\n\n        \"\"\"\n        if folder is None and inputfile is None:\n            raise MQ2Exception('You must specify either a folder or an '\n                               'input file')\n\n        if folder is not None:  # pragma: no cover\n            if not os.path.isdir(folder):\n                raise MQ2Exception('The specified folder is actually '\n                                   'not a folder')\n            else:\n                inputfiles = cls.get_files(folder)\n\n        if inputfile is not None:  # pragma: no cover\n            if os.path.isdir(inputfile):\n                raise MQ2Exception('The specified input file is actually '\n                                   'a folder')\n            else:\n                inputfiles = [inputfile]\n\n        sessions = cls.get_session_identifiers(\n            folder=folder, inputfile=inputfile)\n\n        if session is None:\n            raise MQ2NoSessionException(\n                'The Excel plugin requires a sheet identifier to '\n                'identify the sheet of the workbook to process. '\n                'Sheets are: %s' % ','.join(sessions))\n        elif str(session) not in sessions:\n            raise MQ2NoSuchSessionException(\n                'The Excel sheet provided (%s) could not be found in the '\n                'workbook. '\n                'Sheets are: %s' % (session, ','.join(sessions)))\n\n        if len(inputfiles) > 1:  # pragma: no cover\n            raise MQ2Exception(\n                'This plugin can only process one file at a time')\n\n        try:\n            lod_threshold = float(lod_threshold)\n        except ValueError:\n            raise MQ2Exception('LOD threshold should be a number')\n\n        inputfile = inputfiles[0]\n\n        # QTL matrix and QTL files\n        qtls = []\n        matrix = read_excel_file(inputfile, sheet_name=session)\n        qtls.extend(get_qtls_from_rqtl_data(matrix, lod_threshold))\n        # format QTLs and write down the selection\n        write_matrix(qtls_file, qtls)\n\n        # Write down the QTL matrix\n        write_matrix(matrix_file, matrix)\n\n        # Map matrix\n        map_matrix = get_map_matrix(inputfile, session)\n        write_matrix(map_file, map_matrix)", "response": "This method converts the input files present in the folder or inputfile into a genetic map."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef init_from_wave_file(wavpath):\n\n        try:\n            samplerate, data =  SW.read(wavpath)\n            nframes = data.shape[0]\n        except:\n            # scipy cannot handle 24 bit wav files\n            # and wave cannot handle 32 bit wav files\n            try:\n                w = wave.open(wavpath)\n                samplerate = w.getframerate()\n                nframes = w.getnframes()\n            except:\n                raise Exception('Cannot decode wavefile ' + wavpath)\n\n        return SVEnv(samplerate, nframes, wavpath)", "response": "Initialize a sonic visualiser environment structure based the analysis \n        of the main audio file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_spectrogram(self, view=None):\n        spectrolayer = self.__add_spectrogram(0)\n        spectroruler = self.__add_time_ruler()\n        if view is None:\n            view = self.__add_view()\n        self.__add_layer_reference(view, spectroruler)\n        self.__add_layer_reference(view, spectrolayer)\n        return view", "response": "Adds a spectrogram layer to the environment"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a continous annotation layer to the environment.", "response": "def add_continuous_annotations(self, x, y, colourName='Purple', colour='#c832ff', name='', view=None, vscale=None, presentationName=None):\n        \"\"\"\n        add a continous annotation layer\n\n        Args:\n          x (float iterable): temporal indices of the dataset\n          y (float iterable): values of the dataset\n\n        Kwargs:\n          view (<DOM Element: view>): environment view used to display the spectrogram, if set to None, a new view is created\n\n        Returns:\n          <DOM Element: view>: the view used to store the spectrogram\n\n        \"\"\"\n        \n        model = self.data.appendChild(self.doc.createElement('model'))\n        imodel = self.nbdata\n        \n        for atname, atval in [('id', imodel + 1),\n                              ('dataset', imodel),\n                              ('name', name),\n                              ('sampleRate', self.samplerate),\n                              ('start', int(min(x) * self.samplerate)),\n                              ('end', int(max(x) * self.samplerate)),\n                              ('type', 'sparse'),\n                              ('dimensions', '2'),\n                              ('resolution', '1'),\n                              ('notifyOnAdd', 'true'),\n                              ('minimum', min(y)),\n                              ('maximum', max(y)),\n                              ('units', '')\n                              ]:\n            model.setAttribute(atname, str(atval))\n\n        # dataset = self.data.appendChild(self.doc.createElement('dataset'))\n        # dataset.setAttribute('id', str(imodel))\n        # dataset.setAttribute('dimensions', '2')\n        # self.nbdata += 2\n        \n        # datasetnode = SVDataset2D(self.doc, str(imodel), self.samplerate)\n        # datasetnode.set_data_from_iterable(map(int, np.array(x) * self.samplerate), y)\n        # data = dataset.appendChild(datasetnode)\n        dataset = self.data.appendChild(SVDataset2D(self.doc, str(imodel), self.samplerate))\n        dataset.set_data_from_iterable(map(int, np.array(x) * self.samplerate), y)\n        self.nbdata += 2\n\n        ###### add layers\n        valruler = self.__add_time_ruler()\n        vallayer = self.__add_val_layer(imodel + 1)\n        vallayer.setAttribute('colourName', colourName)\n        vallayer.setAttribute('colour', colour)\n        if presentationName:\n            vallayer.setAttribute('presentationName', presentationName)\n        if vscale is None:\n            vallayer.setAttribute('verticalScale', '0')\n            vallayer.setAttribute('scaleMinimum', str(min(y)))\n            vallayer.setAttribute('scaleMaximum', str(max(y)))\n        else:\n            vallayer.setAttribute('verticalScale', '0')\n            vallayer.setAttribute('scaleMinimum', str(vscale[0]))\n            vallayer.setAttribute('scaleMaximum', str(vscale[1]))\n\n        if view is None:\n            view = self.__add_view()\n        self.__add_layer_reference(view, valruler)\n        self.__add_layer_reference(view, vallayer)\n        return view"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd an interval annotation layer to the data model.", "response": "def add_interval_annotations(self, temp_idx, durations, labels, values=None, colourName='Purple', colour='#c832ff', name='', view=None, presentationName = None):\n        \"\"\"\n        add a labelled interval annotation layer\n\n        Args:\n          temp_idx (float iterable): The temporal indices of invervals\n          durations (float iterable): intervals durations\n          labels (string iterable): interval labels\n          values (int iterable): interval numeric values, if set to None, values are set to 0\n\n        Kwargs:\n          view (<DOM Element: view>): environment view used to display the spectrogram, if set to None, a new view is created\n\n        \"\"\"\n\n        model = self.data.appendChild(self.doc.createElement('model'))\n        imodel = self.nbdata\n        for atname, atval in [('id', imodel + 1),\n                              ('dataset', imodel),\n                              ('name', name),\n                              ('sampleRate', self.samplerate),\n                              ('type', 'sparse'),\n                              ('dimensions', '3'),\n                              ('subtype', 'region'),\n                              ('resolution', '1'),\n                              ('notifyOnAdd', 'true'),\n                              ('units', ''),\n                              ('valueQuantization', '0')\n                              ]:\n            model.setAttribute(atname, str(atval))\n\n        dataset = self.data.appendChild(SVDataset3D(self.doc, str(imodel), self.samplerate))\n        if values is None:\n            values = ([0] * len(temp_idx))\n        dataset.set_data_from_iterable(map(int, np.array(temp_idx) * self.samplerate), values, map(int, np.array(durations) * self.samplerate), labels)\n        \n\n        # dataset = self.data.appendChild(self.doc.createElement('dataset'))\n        # dataset.setAttribute('id', str(imodel))\n        # dataset.setAttribute('dimensions', '3')\n        self.nbdata+= 2\n        \n        valruler = self.__add_time_ruler()\n        vallayer = self.__add_region_layer(imodel + 1, name)\n        vallayer.setAttribute('colourName', colourName)\n        vallayer.setAttribute('colour', colour)\n        if presentationName:\n            vallayer.setAttribute('presentationName', presentationName)        \n\n        if view is None:\n            view = self.__add_view()\n        self.__add_layer_reference(view, valruler)\n        self.__add_layer_reference(view, vallayer)\n\n        # if values is None:\n        #     values = ([0] * len(temp_idx))\n        # for t, d, l, v in zip(temp_idx, durations, labels, values):\n        #     point = dataset.appendChild(self.doc.createElement('point'))\n        #     point.setAttribute('label', l)\n        #     point.setAttribute('frame', str(int(t * self.samplerate)))\n        #     point.setAttribute('duration', str(int(d * self.samplerate)))\n        #     point.setAttribute('value', str(v))\n        return view"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsaves the environment of a sv file to be used with soniv visualiser", "response": "def save(self, outfname):\n        \"\"\"\n        Save the environment of a sv file to be used with soniv visualiser\n        \n        Args:\n          outfname(str): full path to the file storing the environment\n        \"\"\"\n        f = BZ2File(outfname, 'w')\n        self.doc.writexml(f, addindent='  ', newl='\\n')\n        f.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_initial(self, C_in, scale_in, scale_high):\n        self.C_in = C_in\n        self.scale_in = scale_in\n        self.scale_high = scale_high", "response": "Set the initial values for parameters and Wilson coefficients at\n        the scale scale_in and scale_high."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load_initial(self, streams):\n        d = {}\n        for stream in streams:\n            s = io.load(stream)\n            if 'BLOCK' not in s:\n                raise ValueError(\"No BLOCK found\")\n            d.update(s['BLOCK'])\n        d = {'BLOCK': d}\n        C = io.wc_lha2dict(d)\n        sm = io.sm_lha2dict(d)\n        C.update(sm)\n        C = definitions.symmetrize(C)\n        self.C_in = C", "response": "Load the initial values for parameters and Wilson coefficients from one or several files."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_initial_wcxf(self, wc, scale_high=None, get_smpar=False):\n        import wcxf\n        if wc.eft != 'SMEFT':\n            raise ValueError(\"Wilson coefficients use wrong EFT.\")\n        if wc.basis != 'Warsaw':\n            raise ValueError(\"Wilson coefficients use wrong basis.\")\n        if scale_high is not None:\n            self.scale_high = scale_high\n        elif self.scale_high is None:\n            self.scale_high = wc.scale\n        C = wcxf.translators.smeft.wcxf2arrays(wc.dict)\n        keys_dim5 = ['llphiphi']\n        keys_dim6 = list(set(definitions.WC_keys_0f + definitions.WC_keys_2f + definitions.WC_keys_4f) - set(keys_dim5))\n        self.scale_in = wc.scale\n        for k in keys_dim5:\n            if k in C:\n                C[k] = C[k]*self.scale_high\n        for k in keys_dim6:\n            if k in C:\n                C[k] = C[k]*self.scale_high**2\n        C = definitions.symmetrize(C)\n        # fill in zeros for missing WCs\n        for k, s in definitions.C_keys_shape.items():\n            if k not in C and k not in definitions.SM_keys:\n                if s == 1:\n                    C[k] = 0\n                else:\n                    C[k] = np.zeros(s)\n        if self.C_in is None:\n            self.C_in = C\n        else:\n            self.C_in.update(C)\n        if get_smpar:\n            self.C_in.update(self._get_sm_scale_in())", "response": "Load the initial values for the Wilson coefficients from a WCxf instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload the initial values for Wilson coefficients from a file - like object or a string in WCxf format.", "response": "def load_wcxf(self, stream, get_smpar=True):\n        \"\"\"Load the initial values for Wilson coefficients from\n        a file-like object or a string in WCxf format.\n\n        Note that Standard Model parameters have to be provided separately\n        and are assumed to be in the weak basis used for the Warsaw basis as\n        defined in WCxf, i.e. in the basis where the down-type and charged\n        lepton mass matrices are diagonal.\"\"\"\n        import wcxf\n        wc = wcxf.WC.load(stream)\n        self.set_initial_wcxf(wc, get_smpar=get_smpar)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dump(self, C_out, scale_out=None, stream=None, fmt='lha', skip_redundant=True):\n        C = OrderedDict()\n        if scale_out is not None:\n            C['SCALES'] = {'values': [[1, self.scale_high], [2, scale_out]]}\n        else:\n            C['SCALES'] = {'values': [[1, self.scale_high]]}\n        sm = io.sm_dict2lha(C_out)['BLOCK']\n        C.update(sm)\n        wc = io.wc_dict2lha(C_out, skip_redundant=skip_redundant)['BLOCK']\n        C.update(wc)\n        return pylha.dump({'BLOCK': C}, fmt=fmt, stream=stream)", "response": "Return a string representation of the parameters and Wilson\n        coefficients C_out in DSixTools output format."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the Wilson coefficients C_out as a wcxf. WC instance.", "response": "def get_wcxf(self, C_out, scale_out):\n        \"\"\"Return the Wilson coefficients `C_out` as a wcxf.WC instance.\n\n        Note that the Wilson coefficients are rotated into the Warsaw basis\n        as defined in WCxf, i.e. to the basis where the down-type and charged\n        lepton mass matrices are diagonal.\"\"\"\n        import wcxf\n        C = self.rotate_defaultbasis(C_out)\n        d = wcxf.translators.smeft.arrays2wcxf(C)\n        basis = wcxf.Basis['SMEFT', 'Warsaw']\n        d = {k: v for k, v in d.items() if k in basis.all_wcs and v != 0}\n        keys_dim5 = ['llphiphi']\n        keys_dim6 = list(set(definitions.WC_keys_0f + definitions.WC_keys_2f\n                             + definitions.WC_keys_4f) - set(keys_dim5))\n        for k in d:\n            if k.split('_')[0] in keys_dim5:\n                d[k] = d[k] / self.scale_high\n        for k in d:\n            if k.split('_')[0] in keys_dim6:\n                d[k] = d[k] / self.scale_high**2\n        d = wcxf.WC.dict2values(d)\n        wc = wcxf.WC('SMEFT', 'Warsaw', scale_out, d)\n        return wc"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndumps the Wilson coefficients C_out into a string representation of the Wilson coefficients in WCxf format.", "response": "def dump_wcxf(self, C_out, scale_out, fmt='yaml', stream=None, **kwargs):\n        \"\"\"Return a string representation of the Wilson coefficients `C_out`\n        in WCxf format. If `stream` is specified, export it to a file.\n        `fmt` defaults to `yaml`, but can also be `json`.\n\n        Note that the Wilson coefficients are rotated into the Warsaw basis\n        as defined in WCxf, i.e. to the basis where the down-type and charged\n        lepton mass matrices are diagonal.\"\"\"\n        wc = self.get_wcxf(C_out, scale_out)\n        return wc.dump(fmt=fmt, stream=stream, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsolves the SMEFT RGEs from the initial scale to scale_out.", "response": "def rgevolve(self, scale_out, **kwargs):\n        \"\"\"Solve the SMEFT RGEs from the initial scale to `scale_out`.\n        Returns a dictionary with parameters and Wilson coefficients at\n        `scale_out`. Additional keyword arguments will be passed to\n        the ODE solver `scipy.integrate.odeint`.\"\"\"\n        self._check_initial()\n        return rge.smeft_evolve(C_in=self.C_in,\n                            scale_high=self.scale_high,\n                            scale_in=self.scale_in,\n                            scale_out=scale_out,\n                            **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef rgevolve_leadinglog(self, scale_out):\n        self._check_initial()\n        return rge.smeft_evolve_leadinglog(C_in=self.C_in,\n                            scale_high=self.scale_high,\n                            scale_in=self.scale_in,\n                            scale_out=scale_out)", "response": "Compute the leading logarithmix approximation to the solution\n        of the SMEFT RGEs from the initial scale to scale_out."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if initial values and scale as well as the new physics scale have been set.", "response": "def _check_initial(self):\n        \"\"\"Check if initial values and scale as well as the new physics scale\n        have been set.\"\"\"\n        if self.C_in is None:\n            raise Exception(\"You have to specify the initial conditions first.\")\n        if self.scale_in is None:\n            raise Exception(\"You have to specify the initial scale first.\")\n        if self.scale_high is None:\n            raise Exception(\"You have to specify the high scale first.\")"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the SM parameters at the EW scale using an estimate C_out and run them to the input scale.", "response": "def _run_sm_scale_in(self, C_out, scale_sm=91.1876):\n        \"\"\"Get the SM parameters at the EW scale, using an estimate `C_out`\n        of the Wilson coefficients at that scale, and run them to the\n        input scale.\"\"\"\n        # initialize an empty SMEFT instance\n        smeft_sm = SMEFT()\n        C_in_sm = beta.C_array2dict(np.zeros(9999))\n        # set the SM parameters to the values obtained from smpar.smeftpar\n        C_SM = smpar.smeftpar(scale_sm, self.scale_high, C_out, basis='Warsaw')\n        C_SM = {k: v for k, v in C_SM.items() if k in definitions.SM_keys}\n        # set the Wilson coefficients at the EW scale to C_out\n        C_in_sm.update(C_out)\n        C_in_sm.update(C_SM)\n        smeft_sm.set_initial(C_in_sm, scale_sm, scale_high=self.scale_high)\n        # run up (with 1% relative precision, ignore running of Wilson coefficients)\n        C_SM_high = smeft_sm.rgevolve(self.scale_in, newphys=False, rtol=0.01, atol=1)\n        return {k: v for k, v in C_SM_high.items() if k in definitions.SM_keys}"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_sm_scale_in(self, scale_sm=91.1876):\n        # intialize a copy of ourselves\n        _smeft = SMEFT()\n        _smeft.set_initial(self.C_in, self.scale_in, self.scale_high)\n        # Step 1: run the SM up, using the WCs at scale_input as (constant) estimate\n        _smeft.C_in.update(self._run_sm_scale_in(self.C_in, scale_sm=scale_sm))\n        # Step 2: run the WCs down in LL approximation\n        C_out = _smeft.rgevolve_leadinglog(scale_sm)\n        # Step 3: run the SM up again, this time using the WCs at scale_sm as (constant) estimate\n        return self._run_sm_scale_in(C_out, scale_sm=scale_sm)", "response": "Run the SM down in LL approximation at the input scale."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninitializes the peewee database with the given configuration", "response": "def set_database(db_url, proxy, config):\n    \"\"\"Initialize the peewee database with the given configuration\n\n    If the given db_url is a regular file, it will be used as sqlite database\n\n    :param str db_url: the connection string for database or path if sqlite file\n    :param peewee.Proxy proxy: the peewee proxy to initialise\n    :param dict config: the configuration dictionnary\n    \"\"\"\n    db_config = config.get('results_database', {}).get('params', {})\n\n    if 'testing' in config and config['testing'] is True:\n        database = connect('sqlite:////tmp/results.sqlite', check_same_thread=False, threadlocals=True)\n    else:\n        if os.path.isfile(db_url) or os.path.isdir(os.path.dirname(db_url)):\n            db_url = \"sqlite:///\" + db_url\n            db_config.update(check_same_thread=False, threadlocals=True)\n        database = connect(db_url, **db_config)\n    proxy.initialize(database)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sh(cmd):\n\n    # Figure out what local variables are defined in the calling scope.\n\n    import inspect\n    frame = inspect.currentframe()\n    try: locals = frame.f_back.f_locals\n    finally: del frame\n\n    # Run the given command in a shell.  Return everything written to stdout if\n    # the command returns an error code of 0, otherwise raise an exception.\n\n    from subprocess import Popen, PIPE, CalledProcessError\n    process = Popen(cmd.format(**locals), shell=True, stdout=PIPE)\n    stdout, unused_stderr = process.communicate()\n    retcode = process.poll()\n    if retcode:\n        error = subprocess.CalledProcessError(retcode, cmd)\n        error.output = stdout\n        raise error\n    return stdout.strip()", "response": "Run a given command in a shell."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_curricula_by_department(\n        department, future_terms=0, view_unpublished=False):\n    \"\"\"\n    Returns a list of restclients.Curriculum models, for the passed\n    Department model.\n    \"\"\"\n    if not isinstance(future_terms, int):\n        raise ValueError(future_terms)\n\n    if future_terms < 0 or future_terms > 2:\n        raise ValueError(future_terms)\n\n    view_unpublished = \"true\" if view_unpublished else \"false\"\n\n    url = \"{}?{}\".format(\n        curriculum_search_url_prefix,\n        urlencode([(\"department_abbreviation\", department.label,),\n                   (\"future_terms\", future_terms,),\n                   (\"view_unpublished\", view_unpublished,)]))\n    return _json_to_curricula(get_resource(url))", "response": "Returns a list of restclients. Curriculum models for the passed crawler. Department is a string representing the label of the crawler."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of restclients. Curriculum models for the passed Term model.", "response": "def get_curricula_by_term(term, view_unpublished=False):\n    \"\"\"\n    Returns a list of restclients.Curriculum models, for the passed\n    Term model.\n    \"\"\"\n    view_unpublished = \"true\" if view_unpublished else \"false\"\n    url = \"{}?{}\".format(\n        curriculum_search_url_prefix,\n        urlencode([\n                   (\"quarter\", term.quarter.lower(),),\n                   (\"year\", term.year,),\n                   (\"view_unpublished\", view_unpublished,)]))\n    return _json_to_curricula(get_resource(url))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating BLEU for a single sentence comment by atma", "response": "def bleu(candidate, references, weights):\n    \"\"\"\n    Calculate BLEU for a single sentence, comment by atma\n    The result of this code is same as the most popular perl script\n    eg:\n        weight = [0.25, 0.25, 0.25, 0.25]\n        can = 'It is a guide to action which ensures that the military always obeys the commands of the party'.lower().split()\n        ref1 = 'It is a guide to action that ensures that the military will forever heed Party commands'.lower().split()\n        ref2 = 'It is the guiding principle which guarantees the military forces always being under the command of the Party'.lower().split()\n        ref = [ref1, ref2]\n        print bleu(can, ref, weight)\n    :param candidate: word list of one sentence, eg: ['I', 'like', 'eat', 'apple']\n    :param references: list of ref, each is a list of word, eg [['I', 'like', 'eat', 'apple'],['I', 'like', 'apple']]\n    :param weights: a list of weight\n    :return: return the bleu score\n    \"\"\"\n    p_ns = ( MP(candidate, references, i) for i, _ in enumerate(weights, start=1))\n    s = []\n    for w, p_n in zip(weights, p_ns):\n        try:\n            s.append(w * math.log(p_n))\n        except ValueError:\n            s.append(0)\n    s = math.fsum(s)\n\n    bp = BP(candidate, references)\n    return bp * math.exp(s)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert a URL template to a regular expression.", "response": "def template2regex(template, ranges=None):\n    \"\"\"Convert a URL template to a regular expression.\n\n    Converts a template, such as /{name}/ to a regular expression, e.g.\n    /(?P<name>[^/]+)/ and a list of the named parameters found in the template\n    (e.g. ['name']). Ranges are given after a colon in a template name to\n    indicate a restriction on the characters that can appear there. For\n    example, in the template:\n\n        \"/user/{id:alpha}\"\n\n    The `id` must contain only characters from a-zA-Z. Other characters there\n    will cause the pattern not to match.\n\n    The ranges parameter is an optional dictionary that maps range names to\n    regular expressions. New range names can be added, or old range names can\n    be redefined using this parameter.\n\n    Example:\n\n    >>> import rhino.mapper\n    >>> rhino.mapper.template2regex(\"{fred}\")\n    ('^(?P<fred>[^/]+)$', ['fred'])\n\n    \"\"\"\n    if len(template) and -1 < template.find('|') < len(template) - 1:\n        raise InvalidTemplateError(\"'|' may only appear at the end, found at position %d in %s\" % (template.find('|'), template))\n    if ranges is None:\n        ranges = DEFAULT_RANGES\n    anchor = True\n    state = S_PATH\n    if len(template) and template[-1] == '|':\n        anchor = False\n    params = []\n\n    bracketdepth = 0\n    result = ['^']\n    name = \"\"\n    pattern = \"[^/]+\"\n    rangename = None\n    for c in template_splitter.split(template):\n        if state == S_PATH:\n            if len(c) > 1:\n                result.append(re.escape(c))\n            elif c == '[':\n                result.append(\"(\")\n                bracketdepth += 1\n            elif c == ']':\n                bracketdepth -= 1\n                if bracketdepth < 0:\n                    raise InvalidTemplateError(\"Mismatched brackets in %s\" % template)\n                result.append(\")?\")\n            elif c == '{':\n                name = \"\"\n                state = S_TEMPLATE\n            elif c == '}':\n                raise InvalidTemplateError(\"Mismatched braces in %s\" % template)\n            elif c == '|':\n                pass\n            else:\n                result.append(re.escape(c))\n        else:\n            if c == '}':\n                if rangename and rangename in ranges:\n                    result.append(\"(?P<%s>%s)\" % (name, ranges[rangename]))\n                else:\n                    result.append(\"(?P<%s>%s)\" % (name, pattern))\n                params.append(name)\n                state = S_PATH\n                rangename = None\n            else:\n                name = c\n                if name.find(\":\") > -1:\n                    name, rangename = name.split(\":\")\n    if bracketdepth != 0:\n        raise InvalidTemplateError(\"Mismatched brackets in %s\" % template)\n    if state == S_TEMPLATE:\n        raise InvalidTemplateError(\"Mismatched braces in %s\" % template)\n    if anchor:\n        result.append('$')\n    return \"\".join(result), params"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef template2path(template, params, ranges=None):\n    if len(template) and -1 < template.find('|') < len(template) - 1:\n        raise InvalidTemplateError(\"'|' may only appear at the end, found at position %d in %s\" % (template.find('|'), template))\n    if ranges is None:\n        ranges = DEFAULT_RANGES\n\n    # Stack for path components. A new list is added for each '[]' block\n    # encountered. When the closing ']' is reached, the last element is\n    # removed and either merged into the previous one (we keep the\n    # block) or discarded (we skip the block). At the end, this should\n    # contain a flat list of strings as its single element.\n    stack = [[]]\n    pattern = \"[^/]+\"    # default range\n    name = \"\"            # name of the current parameter\n    bracketdepth = 0     # current level of nested brackets\n    skip_to_depth = 0    # if > 1, skip until we're back at this bracket level\n    state = S_PATH\n    rangename = None     # range name for the current parameter\n    seen_name = [False]  # have we seen a named param in bracket level (index)?\n\n    for c in template_splitter.split(template):\n        if state == S_PATH:\n            if len(c) > 1:\n                stack[-1].append(c)\n            elif c == '[':\n                bracketdepth += 1\n                stack.append([])\n                seen_name.append(False)\n            elif c == ']':\n                bracketdepth -= 1\n                if bracketdepth < 0:\n                    raise InvalidTemplateError(\"Mismatched brackets in %s\" % template)\n                last_elem = stack.pop()\n                if seen_name.pop():\n                    stack[-1].extend(last_elem)\n                    seen_name[-1] = True\n            elif c == '{':\n                name = \"\"\n                state = S_TEMPLATE\n            elif c == '}':\n                raise InvalidTemplateError(\"Mismatched braces in %s\" % template)\n            elif c == '|':\n                pass\n            else:\n                stack[-1].append(c)\n        elif state == S_SKIP:\n            if c == '[':\n                bracketdepth += 1\n                seen_name.append(False)\n            elif c == ']':\n                if bracketdepth == skip_to_depth:\n                    stack.pop()\n                    skip_to_depth = 0\n                    state = S_PATH\n                bracketdepth -= 1\n                seen_name.pop()\n        else:  # state == S_TEMPLATE\n            if c == '}':\n                if name not in params:\n                    if bracketdepth:\n                        # We're missing a parameter, but it's ok since\n                        # we're inside a '[]' block. Skip everything\n                        # until we reach the end of the current block.\n                        skip_to_depth = bracketdepth\n                        state = S_SKIP\n                    else:\n                        raise InvalidArgumentError(\"Missing parameter '%s' in %s\" % (name, template))\n                else:\n                    if rangename and rangename in ranges:\n                        regex = ranges[rangename]\n                    else:\n                        regex = pattern\n                    value_bytes = unicode(params[name]).encode('utf-8')\n                    value = urllib.quote(value_bytes, safe='/:;')\n                    if not re.match('^' + regex + '$', value):\n                        raise InvalidArgumentError(\"Value '%s' for parameter '%s' does not match '^%s$' in %s\" % (value, name, regex, template))\n                    stack[-1].append(value)\n                    state = S_PATH\n                rangename = None\n            else:\n                name = c\n                if name.find(\":\") > -1:\n                    name, rangename = name.split(\":\")\n                seen_name[bracketdepth] = True\n\n    if bracketdepth != 0:\n        raise InvalidTemplateError(\"Mismatched brackets in %s\" % template)\n    if state == S_TEMPLATE:\n        raise InvalidTemplateError(\"Mismatched braces in %s\" % template)\n    # None of these Should Ever Happen [TM]\n    if state == S_SKIP:     # pragma: no cover\n        raise MapperException(\"Internal error: end state is S_SKIP\")\n    if len(stack) > 1:      # pragma: no cover\n        raise MapperException(\"Internal error: stack not empty\")\n    if len(seen_name) != 1: # pragma: no cover\n        raise MapperException(\"Internal error: seen_name not empty\")\n\n    return \"\".join(stack[0])", "response": "Converts a template and a dictionary of parameters to a URL path fragment."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_callback(self, phase, fn):\n        try:\n            self.__callbacks[phase].append(fn)\n        except KeyError:\n            raise KeyError(\"Invalid callback phase '%s'. Must be one of %s\" % (phase, _callback_phases))", "response": "Adds a callback to the context."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a property to the Context.", "response": "def add_property(self, name, fn, cached=True):\n        \"\"\"Adds a property to the Context.\n\n        See `Mapper.add_ctx_property`, which uses this method to install\n        the properties added on the Mapper level.\n        \"\"\"\n        if name in self.__properties:\n            raise KeyError(\"Trying to add a property '%s' that already exists on this %s object.\" % (name, self.__class__.__name__))\n        self.__properties[name] = (fn, cached)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nbuilds the URL path fragment for this route.", "response": "def path(self, args, kw):\n        \"\"\"Builds the URL path fragment for this route.\"\"\"\n        params = self._pop_params(args, kw)\n        if args or kw:\n            raise InvalidArgumentError(\"Extra parameters (%s, %s) when building path for %s\" % (args, kw, self.template))\n        return self.build_url(**params)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add(self, template, resource, name=None):\n        # Special case for standalone handler functions\n        if hasattr(resource, '_rhino_meta'):\n            route = Route(\n                    template, Resource(resource), name=name, ranges=self.ranges)\n        else:\n            route = Route(\n                    template, resource, name=name, ranges=self.ranges)\n        obj_id = id(resource)\n        if obj_id not in self._lookup:\n            # It's ok to have multiple routes for the same object id, the\n            # lookup will return the first one.\n            self._lookup[obj_id] = route\n        if name is not None:\n            if name in self.named_routes:\n                raise InvalidArgumentError(\"A route named '%s' already exists in this %s object.\"\n                        % (name, self.__class__.__name__))\n            self.named_routes[name] = route\n        self.routes.append(route)", "response": "Add a route to a resource."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninstall a context property.", "response": "def add_ctx_property(self, name, fn, cached=True):\n        \"\"\"Install a context property.\n\n        A context property is a factory function whos return value will be\n        available as a property named `name` on `Context` objects passing\n        through this mapper. The result will be cached unless `cached` is\n        False.\n\n        The factory function will be called without arguments, or with the\n        context object if it requests an argument named 'ctx'.\n        \"\"\"\n        if name in [item[0] for item in self._ctx_properties]:\n             raise InvalidArgumentError(\"A context property name '%s' already exists.\" % name)\n        self._ctx_properties.append([name, (fn, cached)])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef path(self, target, args, kw):\n        if type(target) in string_types:\n            if ':' in target:\n                # Build path a nested route name\n                prefix, rest = target.split(':', 1)\n                route = self.named_routes[prefix]\n                prefix_params = route._pop_params(args, kw)\n                prefix_path = route.path([], prefix_params)\n                next_mapper = route.resource\n                return prefix_path + next_mapper.path(rest, args, kw)\n            else:\n                # Build path for a named route\n                return self.named_routes[target].path(args, kw)\n        elif isinstance(target, Route):\n            # Build path for a route instance, used by build_url('.')\n            for route in self.routes:\n                if route is target:\n                    return route.path(args, kw)\n            raise InvalidArgumentError(\"Route '%s' not found in this %s object.\" % (target, self.__class__.__name__))\n        else:\n            # Build path for resource by object id\n            target_id = id(target)\n            if target_id in self._lookup:\n                return self._lookup[target_id].path(args, kw)\n            raise InvalidArgumentError(\"No Route found for target '%s' in this %s object.\" % (target, self.__class__.__name__))", "response": "Builds a URL path fragment for a resource or route."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nimplements the mapper s WSGI interface.", "response": "def wsgi(self, environ, start_response):\n        \"\"\"Implements the mapper's WSGI interface.\"\"\"\n        request = Request(environ)\n        ctx = Context(request)\n        try:\n            try:\n                response = self(request, ctx)\n                ctx._run_callbacks('finalize', (request, response))\n                response = response.conditional_to(request)\n            except HTTPException as e:\n                response = e.response\n            except Exception:\n                self.handle_error(request, ctx)\n                response = InternalServerError().response\n\n            response.add_callback(lambda: ctx._run_callbacks('close'))\n            return response(environ, start_response)\n        finally:\n            ctx._run_callbacks('teardown', log_errors=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef start_server(self, host='localhost', port=9000, app=None):\n        from wsgiref.simple_server import make_server\n        if app is None:\n            app = self.wsgi\n        server = make_server(host, port, app)\n        server_addr = \"%s:%s\" % (server.server_name, server.server_port)\n        print \"Server listening at http://%s/\" % server_addr\n        server.serve_forever()", "response": "Start a wsgiref. simple_server based server to run this mapper."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a Registry object.", "response": "def Registry(address='https://index.docker.io', **kwargs):\n    \"\"\"\n    :return:\n    \"\"\"\n    registry = None\n    try:\n        try:\n            registry = V1(address, **kwargs)\n            registry.ping()\n        except RegistryException:\n            registry = V2(address, **kwargs)\n            registry.ping()\n    except OSError:\n        logger.warning(\n            'Was unable to verify certs for a registry @ {0}. '\n            'Will not be able to interact with it for any operations until the certs can be validated.'.format(address)\n        )\n\n    return registry"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef search(self, terms):\n        images   = {}\n        response = self._request_builder('GET', 'search', params={'q': terms})\n\n        if self._validate_response(response):\n            body = json.loads(response.content.decode('utf-8'))['results']\n            for image in body:\n                images[image['name']] = image\n\n        return images", "response": "search for images by terms"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef generate_docs(app):\n    config = app.config\n    config_dir = app.env.srcdir\n    source_root = os.path.join(config_dir, config.apidoc_source_root)\n    output_root = os.path.join(config_dir, config.apidoc_output_root)\n    execution_dir = os.path.join(config_dir, '..')\n\n    # Remove any files generated by earlier builds\n    cleanup(output_root)\n\n    command = ['sphinx-apidoc', '-f', '-o', output_root, source_root]\n    # Exclude anything else we were specifically asked to\n    for exclude in config.apidoc_exclude:\n        command.append(os.path.join(source_root, exclude))\n    process = Popen(command, cwd=execution_dir)\n    process.wait()", "response": "Run sphinx - apidoc to generate Python API documentation for the project."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cleanup(output_root):\n    if os.path.exists(output_root):\n        if os.path.isdir(output_root):\n            rmtree(output_root)\n        else:\n            os.remove(output_root)", "response": "Remove any reST files which were generated by this extension"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef build(cls: Type[T], data: Generic) -> T:\n        fields = fields_dict(cls)\n        kwargs: Dict[str, Any] = {}\n        for key, value in data.items():\n            if key in fields:\n                if isinstance(value, Mapping):\n                    t = fields[key].type\n                    if issubclass(t, Auto):\n                        value = t.build(value)\n                    else:\n                        value = Auto.generate(value, name=key.title())\n                kwargs[key] = value\n            else:\n                log.debug(f\"got unknown attribute {key} for {cls.__name__}\")\n        return cls(**kwargs)", "response": "Build objects from dictionaries recursively."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef generate(\n        cls: Type[T], data: Generic, name: str = None, *, recursive: bool = True\n    ) -> T:\n        \"\"\"Build dataclasses and objects from dictionaries, recursively.\"\"\"\n        if name is None:\n            name = cls.__name__\n        kls = make_class(name, {k: ib(default=None) for k in data}, bases=(cls,))\n        data = {\n            k: (\n                cls.generate(v, k.title())\n                if recursive and isinstance(v, Mapping)\n                else v\n            )\n            for k, v in data.items()\n        }\n        return kls(**data)", "response": "Build dataclasses and objects from dictionaries recursively."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef emit_answer_event(sender, instance, **kwargs):\n    if not issubclass(sender, Answer) or not kwargs['created']:\n        return\n    logger = get_events_logger()\n    logger.emit('answer', {\n        \"user_id\": instance.user_id,\n        \"is_correct\": instance.item_asked_id == instance.item_answered_id,\n        \"context_id\": [instance.context_id] if instance.context_id else [],\n        \"item_id\": instance.item_id,\n        \"response_time_ms\": instance.response_time,\n        \"params\": {\n            \"session_id\": instance.session_id,\n            \"guess\": instance.guess,\n            \"practice_set_id\": instance.practice_set_id,\n            \"config_id\": instance.config_id,\n        }}\n    )", "response": "Save answer event to log file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget all available leaves.", "response": "def get_all_available_leaves(self, language=None, forbidden_item_ids=None):\n        \"\"\"\n        Get all available leaves.\n        \"\"\"\n        return self.get_all_leaves(language=language, forbidden_item_ids=forbidden_item_ids)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nproviding the same functionality as .. py:method:: ItemManager.filter_all_reachable_leaves(), but for more filters in the same time. Args: identifier_filters: list of identifier filters language (str): language used for further filtering (some objects for different languages share the same item Returns: list: list of list of item ids", "response": "def filter_all_reachable_leaves_many(self, identifier_filters, language, forbidden_identifiers=None):\n        \"\"\"\n        Provides the same functionality as .. py:method:: ItemManager.filter_all_reachable_leaves(),\n        but for more filters in the same time.\n\n        Args:\n            identifier_filters: list of identifier filters\n            language (str): language used for further filtering (some objects\n                for different languages share the same item\n\n        Returns:\n            list: list of list of item ids\n        \"\"\"\n        for i, identifier_filter in enumerate(identifier_filters):\n            if len(identifier_filter) == 1 and not isinstance(identifier_filter[0], list):\n                identifier_filters[i] = [identifier_filter]\n        item_identifiers = [\n            identifier[1:] if identifier.startswith('-') else identifier\n            for identifier_filter in identifier_filters\n            for identifier in set(flatten(identifier_filter))\n        ]\n        if forbidden_identifiers is None:\n            forbidden_identifiers = []\n        for identifier in forbidden_identifiers:\n            item_identifiers.append(identifier)\n        translated = self.translate_identifiers(item_identifiers, language)\n        forbidden_item_ids = {translated[identifier] for identifier in forbidden_identifiers}\n        leaves = self.get_leaves({translated[i] for i in item_identifiers}, language=language, forbidden_item_ids=forbidden_item_ids)\n        result = []\n        for identifier_filter in identifier_filters:\n            if len(identifier_filter) == 0:\n                result.append(self.get_all_available_leaves(language=language, forbidden_item_ids=forbidden_item_ids))\n                continue\n            filter_result = None\n            filter_neg_result = set()\n            for inner_filter in identifier_filter:\n                inner_result = None\n                inner_neg_result = None\n                if len(inner_filter) == 0:\n                    raise Exception('Empty nested filters are not allowed.')\n                for identifier in inner_filter:\n                    if inner_neg_result is not None:\n                        raise Exception('Nested filters can not contain multiple statements.')\n                    if identifier.startswith('-'):\n                        inner_neg_result = set(leaves[translated[identifier[1:]]])\n                    else:\n                        if inner_result is None:\n                            inner_result = set()\n                        inner_result |= set(leaves[translated[identifier]])\n                if inner_result is not None:\n                    if filter_result is None:\n                        filter_result = inner_result\n                    else:\n                        filter_result &= inner_result\n                if inner_neg_result is not None:\n                    filter_neg_result != inner_neg_result\n            result.append(sorted(list(filter_result - filter_neg_result)))\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfilter all leaves corresponding to the given filter", "response": "def filter_all_reachable_leaves(self, identifier_filter, language, forbidden_identifiers=None):\n        \"\"\"\n        Get all leaves corresponding to the given filter:\n\n        * the filter is a list of lists;\n        * each of the inner list carries identifiers;\n        * for each identifier, we find an item and all its reachable leaf items;\n        * within the inner list we union the reachable items;\n        * with the outer list we intersect the reachable items;\n        * when an identifier starts with the prfix '-', we find its reachable\n          leaf items and then complement them\n\n        Example::\n\n                A\n               / \\\\\n              B   C\n             / \\ / \\\\\n            D   E   F\n\n            [[A], [C]] ----> [D, F]\n            [[B], [C]] ----> [E]\n            [[B], [-C]] ---> [D]\n            [[A], [-D], [-F]] ---> [E]\n            [[-C]] ---> []\n\n        Args::\n            identifier_filter (list): list of lists of identifiers (some of them\n                can start with the prefix '-')\n            language (str): language used for further filtering (some objects\n                for different languages share the same item\n\n        Returns:\n            list: list of item ids\n        \"\"\"\n        return self.filter_all_reachable_leaves_many([identifier_filter], language, forbidden_identifiers=forbidden_identifiers)[0]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a subgraph of items reachable from the given set of items through the child relation.", "response": "def get_children_graph(self, item_ids=None, language=None, forbidden_item_ids=None):\n        \"\"\"\n        Get a subgraph of items reachable from the given set of items through\n        the 'child' relation.\n\n        Args:\n            item_ids (list): items which are taken as roots for the reachability\n            language (str): if specified, filter out items which are not\n                available in the given language\n\n        Returns:\n            dict: item id -> list of items (child items), root items are\n            referenced by None key\n        \"\"\"\n        if forbidden_item_ids is None:\n            forbidden_item_ids = set()\n\n        def _children(item_ids):\n            if item_ids is None:\n                items = Item.objects.filter(active=True).prefetch_related('children')\n            else:\n                item_ids = [ii for iis in item_ids.values() for ii in iis]\n                items = Item.objects.filter(id__in=item_ids, active=True).prefetch_related('children')\n            return {\n                item.id: sorted([\n                    _item.id for _item in item.children.all()\n                    if _item.active and _item.id not in forbidden_item_ids\n                ])\n                for item in items if item.id not in forbidden_item_ids\n            }\n\n        if item_ids is None:\n            return self._reachable_graph(None, _children, language=language)\n        else:\n            graph = self.get_children_graph(None, language, forbidden_item_ids=forbidden_item_ids)\n            return self._subset_graph(graph, set(item_ids) - set(forbidden_item_ids))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a subgraph of items reachable from the given set of items through the parent relation.", "response": "def get_parents_graph(self, item_ids, language=None):\n        \"\"\"\n        Get a subgraph of items reachable from the given set of items through\n        the 'parent' relation.\n\n        Args:\n            item_ids (list): items which are taken as roots for the reachability\n            language (str): if specified, filter out items which are not\n                available in the given language\n\n        Returns:\n            dict: item id -> list of items (parent items), root items are\n            referenced by None key\n        \"\"\"\n        def _parents(item_ids):\n            if item_ids is None:\n                items = Item.objects.filter(active=True).prefetch_related('parents')\n            else:\n                item_ids = [ii for iis in item_ids.values() for ii in iis]\n                items = Item.objects.filter(id__in=item_ids, active=True).prefetch_related('parents')\n            return {item.id: sorted([_item.id for _item in item.parents.all()]) for item in items}\n        return self._reachable_graph(item_ids, _parents, language=language)\n\n        if item_ids is None:\n            return self._reachable_graph(None, _parents, language=language)\n        else:\n            graph = self.get_parents_graph(None, language)\n            return self._subset_graph(graph, item_ids)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_graph(self, item_ids, language=None):\n        def _related(item_ids):\n            if item_ids is None:\n                items = Item.objects.filter(active=True).prefetch_related('parents', 'children')\n            else:\n                item_ids = [ii for iis in item_ids.values() for ii in iis]\n                items = Item.objects.filter(id__in=item_ids, active=True).prefetch_related('parents', 'children')\n            return {item.id: sorted([_item.id for rel in [item.parents.all(), item.children.all()] for _item in rel]) for item in items}\n        if item_ids is None:\n            return self._reachable_graph(None, _related, language=language)\n        else:\n            graph = self.get_graph(None, language)\n            return self._subset_graph(graph, item_ids)", "response": "Returns a subgraph of items reachable from the given set of items through the given language."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef translate_identifiers(self, identifiers, language):\n        result = {}\n        identifiers = set(identifiers)\n        item_types = ItemType.objects.get_all_types()\n        for item_type_id, type_identifiers in proso.list.group_by(identifiers, by=lambda identifier: self.get_item_type_id_from_identifier(identifier, item_types)).items():\n            to_find = {}\n            for identifier in type_identifiers:\n                identifier_split = identifier.split('/')\n                to_find[identifier_split[1]] = identifier\n            kwargs = {'identifier__in': list(to_find.keys())}\n            item_type = ItemType.objects.get_all_types()[item_type_id]\n            model = ItemType.objects.get_model(item_type_id)\n            if 'language' in item_type:\n                kwargs[item_type['language']] = language\n            for identifier, item_id in model.objects.filter(**kwargs).values_list('identifier', item_type['foreign_key']):\n                result[to_find[identifier]] = item_id\n        if len(result) != len(identifiers):\n            raise HttpError(404, \"Can't translate the following identifiers: {}\".format(set(identifiers) - set(result.keys())), 'identifier_not_found')\n        return result", "response": "Translate a list of identifiers to item ids."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget an ID of item type for the given identifier.", "response": "def get_item_type_id_from_identifier(self, identifier, item_types=None):\n        \"\"\"\n        Get an ID of item type for the given identifier. Identifier is a string of\n        the following form:\n\n        <model_prefix>/<model_identifier>\n\n        where <model_prefix> is any suffix of database table of the given model\n        which uniquely specifies the table, and <model_identifier> is\n        identifier of the object.\n\n        Args:\n            identifier (str): item identifier\n            item_types (dict): ID -> item type JSON\n\n        Returns:\n            int: ID of the corresponding item type\n        \"\"\"\n        if item_types is None:\n            item_types = ItemType.objects.get_all_types()\n        identifier_type, _ = identifier.split('/')\n        item_types = [it for it in item_types.values() if it['table'].endswith(identifier_type)]\n        if len(item_types) > 1:\n            raise Exception('There is more than one item type for name \"{}\".'.format(identifier_type))\n        if len(item_types) == 0:\n            raise Exception('There is no item type for name \"{}\".'.format(identifier_type))\n        return item_types[0]['id']"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntranslate a list of item ids to JSON objects which reference them.", "response": "def translate_item_ids(self, item_ids, language, is_nested=None):\n        \"\"\"\n        Translate a list of item ids to JSON objects which reference them.\n\n        Args:\n            item_ids (list[int]): item ids\n            language (str): language used for further filtering (some objects\n                for different languages share the same item)\n            is_nested (function): mapping from item ids to booleans, where the\n                boolean value indicates whether the item is nested\n\n        Returns:\n            dict: item id -> JSON object\n        \"\"\"\n        if is_nested is None:\n            def is_nested_fun(x):\n                return True\n        elif isinstance(is_nested, bool):\n            def is_nested_fun(x):\n                return is_nested\n        else:\n            is_nested_fun = is_nested\n        all_item_type_ids = ItemType.objects.get_all_item_type_ids()\n        groupped = proso.list.group_by(item_ids, by=lambda item_id: all_item_type_ids[item_id])\n        result = {}\n        for item_type_id, items in groupped.items():\n            with timeit('translating item type {}'.format(item_type_id)):\n                item_type = ItemType.objects.get_all_types()[item_type_id]\n                model = ItemType.objects.get_model(item_type_id)\n                kwargs = {'{}__in'.format(item_type['foreign_key']): items}\n                if 'language' in item_type:\n                    kwargs[item_type['language']] = language\n                if any([not is_nested_fun(item_id) for item_id in items]) and hasattr(model.objects, 'prepare_related'):\n                    objs = model.objects.prepare_related()\n                elif hasattr(model.objects, 'prepare'):\n                    objs = model.objects.prepare()\n                else:\n                    objs = model.objects\n                for obj in objs.filter(**kwargs):\n                    item_id = getattr(obj, item_type['foreign_key'])\n                    result[item_id] = obj.to_json(nested=is_nested_fun(item_id))\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_leaves(self, item_ids=None, language=None, forbidden_item_ids=None):\n        forbidden_item_ids = set() if forbidden_item_ids is None else set(forbidden_item_ids)\n        children = self.get_children_graph(item_ids, language=language, forbidden_item_ids=forbidden_item_ids)\n        counts = self.get_children_counts(active=None)\n        if item_ids is None:\n            # not leaves\n            item_ids = set(children.keys())\n\n        def _get_leaves(item_id):\n            leaves = set()\n\n            def __search(item_ids):\n                result = set(flatten([children.get(item_id, []) for item_id in item_ids]))\n                new_leaves = {item_id for item_id in result if item_id not in children.keys()}\n                leaves.update(new_leaves)\n                return result - new_leaves\n\n            fixed_point(\n                is_zero=lambda to_visit: len(to_visit) == 0,\n                minus=lambda to_visit, visited: to_visit - visited,\n                plus=lambda visited_x, visited_y: visited_x | visited_y,\n                f=__search,\n                x={item_id}\n            )\n            leaves = {leaf for leaf in leaves if counts[leaf] == 0}\n            if len(leaves) > 0:\n                return leaves\n            if counts[item_id] == 0 and item_id not in forbidden_item_ids:\n                return {item_id}\n            return set()\n\n        return {item_id: _get_leaves(item_id) for item_id in item_ids}", "response": "Get mapping of items to their reachable leaves."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets all leaves reachable from the given set of items.", "response": "def get_all_leaves(self, item_ids=None, language=None, forbidden_item_ids=None):\n        \"\"\"\n        Get all leaves reachable from the given set of items. Leaves having\n        inactive relations to other items are omitted.\n\n        Args:\n            item_ids (list): items which are taken as roots for the reachability\n            language (str): if specified, filter out items which are not\n                available in the given language\n\n        Returns:\n            set: leaf items which are reachable from the given set of items\n        \"\"\"\n        return sorted(set(flatten(self.get_leaves(item_ids, language=language, forbidden_item_ids=forbidden_item_ids).values())))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_reference_fields(self, exclude_models=None):\n        if exclude_models is None:\n            exclude_models = []\n        result = []\n        for django_model in django.apps.apps.get_models():\n            if any([issubclass(django_model, m) for m in exclude_models]):\n                continue\n            for django_field in django_model._meta.fields:\n                if isinstance(django_field, models.ForeignKey) and django_field.related.to == Item:\n                    result = [(m, f) for (m, f) in result if not issubclass(django_model, m)]\n                    result.append((django_model, django_field))\n        return result", "response": "Get all Django model fields which reference the Item model."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef override_parent_subgraph(self, parent_subgraph, invisible_edges=None):\n        with transaction.atomic():\n            if invisible_edges is None:\n                invisible_edges = set()\n            children = list(parent_subgraph.keys())\n            all_old_relations = dict(proso.list.group_by(\n                list(ItemRelation.objects.filter(child_id__in=children)),\n                by=lambda relation: relation.child_id\n            ))\n            to_delete = set()\n            for child_id, parents in parent_subgraph.items():\n                old_relations = {\n                    relation.parent_id: relation\n                    for relation in all_old_relations.get(child_id, [])\n                }\n                for parent_id in parents:\n                    if parent_id not in old_relations:\n                        ItemRelation.objects.create(\n                            parent_id=parent_id,\n                            child_id=child_id,\n                            visible=(child_id, parent_id) not in invisible_edges\n                        )\n                    elif old_relations[parent_id].visible != ((child_id, parent_id) not in invisible_edges):\n                        old_relations[parent_id].visible = (child_id, parent_id) not in invisible_edges\n                        old_relations[parent_id].save()\n                to_delete |= {old_relations[parent_id].pk for parent_id in set(old_relations.keys()) - set(parents)}\n            ItemRelation.objects.filter(pk__in=to_delete).delete()", "response": "Override the parent subgraph with the given subgraph."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef query_api(self, data=None, endpoint='SMS'):\n        url = self.api_url % endpoint\n        if data:\n            response = requests.post(\n                url,\n                data=data,\n                auth=self.auth\n            )\n        else:\n            response = requests.get(\n                url,\n                auth=self.auth\n            )\n        try:\n            response.raise_for_status()\n        except HTTPError as e:\n            raise HTTPError('HTTP %s\\n%s' %\n                    (response.status_code, response.text))\n        return response.text", "response": "Send a request to the 46elks API."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if a number looks like a E. 164 number.", "response": "def validate_number(self, number):\n        \"\"\" Checks if a number looks somewhat like a E.164 number. Not an\n        exhaustive check, as the API takes care of that\n        \"\"\"\n        if not isinstance(number, str):\n            raise ElksException('Recipient phone number may not be empty')\n        if number[0] == '+' and len(number) > 2 and len(number) < 16:\n            return True\n        else:\n            raise ElksException(\"Phone number must be of format +CCCXXX...\")"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsend a text message to a configuration conf containing the message in the message paramter", "response": "def send_sms(self, message, to, sender='elkme', options=[]):\n        \"\"\"Sends a text message to a configuration conf containing the message\n        in the message paramter\"\"\"\n        sms = self.format_sms_payload(message=message,\n            to=to,\n            sender=sender,\n            options=options)\n        return self.query_api(sms)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget all available types. This function is a coroutine.", "response": "async def get_types(self):\n        \"\"\"Gets all available types.\n\n        This function is a coroutine.\n\n        Return Type: `list`\"\"\"\n        async with aiohttp.ClientSession() as session:\n            async with session.get('https://api.weeb.sh/images/types', headers=self.__headers) as resp:\n                if resp.status == 200:\n                    return (await resp.json())['types']\n                else:\n                    raise Exception((await resp.json())['message'])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def get_image(self, imgtype=None, tags=None, nsfw=None, hidden=None, filetype=None):\n        if not imgtype and not tags:\n            raise MissingTypeOrTags(\"'get_image' requires at least one of either type or tags.\")\n        if imgtype and not isinstance(imgtype, str):\n            raise TypeError(\"type of 'imgtype' must be str.\")\n        if tags and not isinstance(tags, list):\n            raise TypeError(\"type of 'tags' must be list or None.\")\n        if hidden and not isinstance(hidden, bool):\n            raise TypeError(\"type of 'hidden' must be bool or None.\")\n        if nsfw and not isinstance(nsfw, bool) and (isinstance(nsfw, str) and nsfw == 'only'):\n            raise TypeError(\"type of 'nsfw' must be str, bool or None.\")\n        if filetype and not isinstance(filetype, str):\n            raise TypeError(\"type of 'filetype' must be str.\")\n        url = 'https://api.weeb.sh/images/random' + (f'?type={imgtype}' if imgtype else '') + (\n            f'{\"?\" if not imgtype else \"&\"}tags={\",\".join(tags)}' if tags else '') + (\n              f'&nsfw={nsfw.lower()}' if nsfw else '') + (f'&hidden={hidden}' if hidden else '') + (\n              f'&filetype={filetype}' if filetype else '')\n        async with aiohttp.ClientSession() as session:\n            async with session.get(url, headers=self.__headers) as resp:\n                if resp.status == 200:\n                    js = await resp.json()\n                    return [js['url'], js['id'], js['fileType']]\n                else:\n                    raise Exception((await resp.json())['message'])", "response": "Request an image from weeb. sh."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def generate_image(self, imgtype, face=None, hair=None):\n        if not isinstance(imgtype, str):\n            raise TypeError(\"type of 'imgtype' must be str.\")\n        if face and not isinstance(face, str):\n            raise TypeError(\"type of 'face' must be str.\")\n        if hair and not isinstance(hair, str):\n            raise TypeError(\"type of 'hair' must be str.\")\n        if (face or hair) and imgtype != 'awooo':\n            raise InvalidArguments('\\'face\\' and \\'hair\\' are arguments only available on the \\'awoo\\' image type')\n        url = f'https://api.weeb.sh/auto-image/generate?type={imgtype}' + (\"&face=\"+face if face else \"\")+ (\"&hair=\"+hair if hair else \"\")\n        async with aiohttp.ClientSession() as session:\n            async with session.get(url, headers=self.__headers) as resp:\n                if resp.status == 200:\n                    return await resp.read()\n                else:\n                    raise Exception((await resp.json())['message'])", "response": "This function generates a basic image using the auto - image endpoint of weeb. sh."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def generate_status(self, status, avatar=None):\n        if not isinstance(status, str):\n            raise TypeError(\"type of 'status' must be str.\")\n        if avatar and not isinstance(avatar, str):\n            raise TypeError(\"type of 'avatar' must be str.\")\n        url = f'https://api.weeb.sh/auto-image/discord-status?status={status}' + (f'&avatar={urllib.parse.quote(avatar, safe=\"\")}' if avatar else '')\n        async with aiohttp.ClientSession() as session:\n            async with session.get(url, headers=self.__headers) as resp:\n                if resp.status == 200:\n                    return await resp.read()\n                else:\n                    raise Exception((await resp.json())['message'])", "response": "Generate a discord status icon below the image provided."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating a waifu insult image. This function is a coroutine. Parameters: avatar: str - http/s url pointing to an image, has to have proper headers and be a direct link to an image Return Type: image data", "response": "async def generate_waifu_insult(self, avatar):\n        \"\"\"Generate a waifu insult image.\n\n        This function is a coroutine.\n\n        Parameters:\n            avatar: str - http/s url pointing to an image, has to have proper headers and be a direct link to an image\n\n        Return Type: image data\"\"\"\n        if not isinstance(avatar, str):\n            raise TypeError(\"type of 'avatar' must be str.\")\n        async with aiohttp.ClientSession() as session:\n            async with session.post(\"https://api.weeb.sh/auto-image/waifu-insult\", headers=self.__headers, data={\"avatar\": avatar}) as resp:\n                if resp.status == 200:\n                    return await resp.read()\n                else:\n                    raise Exception((await resp.json())['message'])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating a license. This function is a coroutine. Parameters: title: str - title of the license avatar: str - http/s url pointing to an image, has to have proper headers and be a direct link to an image badges: list - list of 1-3 direct image urls. Same requirements as avatar (optional) widgets: list - list of 1-3 strings to fill the three boxes with (optional) Return Type: image data", "response": "async def generate_license(self, title, avatar, badges=None, widgets=None):\n        \"\"\"Generate a license.\n\n        This function is a coroutine.\n\n        Parameters:\n            title: str - title of the license\n            avatar: str - http/s url pointing to an image, has to have proper headers and be a direct link to an image\n            badges: list - list of 1-3 direct image urls. Same requirements as avatar (optional)\n            widgets: list - list of 1-3 strings to fill the three boxes with (optional)\n\n        Return Type: image data\"\"\"\n        if not isinstance(title, str):\n            raise TypeError(\"type of 'title' must be str.\")\n        if not isinstance(avatar, str):\n            raise TypeError(\"type of 'avatar' must be str.\")\n        if badges and not isinstance(badges, list):\n            raise TypeError(\"type of 'badges' must be list.\")\n        if widgets and not isinstance(widgets, list):\n            raise TypeError(\"type of 'widgets' must be list.\")\n        data = {\"title\": title, \"avatar\": avatar}\n        if badges and len(badges) <= 3:\n            data['badges'] = badges\n        if widgets and len(widgets) <= 3:\n            data['widgets'] = widgets\n        async with aiohttp.ClientSession() as session:\n            async with session.post(\"https://api.weeb.sh/auto-image/license\", headers=self.__headers, data=data) as resp:\n                if resp.status == 200:\n                    return await resp.read()\n                else:\n                    raise Exception((await resp.json())['message'])"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates a love ship. This function is a coroutine. Parameters: target_one: str - http/s url pointing to an image, has to have proper headers and be a direct link to an image, image will be on the left side. target_two: str - http/s url pointing to an image, has to have proper headers and be a direct link to an image, image will be on the left side. Return Type: image data", "response": "async def generate_love_ship(self, target_one, target_two):\n        \"\"\"Generate a love ship.\n\n        This function is a coroutine.\n\n        Parameters:\n            target_one: str - http/s url pointing to an image, has to have proper headers and be a direct link to an image, image will be on the left side.\n            target_two: str - http/s url pointing to an image, has to have proper headers and be a direct link to an image, image will be on the left side.\n\n        Return Type: image data\"\"\"\n        if not isinstance(target_one, str):\n            raise TypeError(\"type of 'target_one' must be str.\")\n        if not isinstance(target_two, str):\n            raise TypeError(\"type of 'target_two' must be str.\")\n        data = {\"targetOne\": target_one, \"targetTwo\": target_two}\n        async with aiohttp.ClientSession() as session:\n            async with session.post(\"https://api.weeb.sh/auto-image/love-ship\", headers=self.__headers, data=data) as resp:\n                if resp.status == 200:\n                    return await resp.read()\n                else:\n                    raise Exception((await resp.json())['message'])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef launch_command(command, parameter=''):\n    '''Can launch a cozy-monitor command\n\n    :param command: The cozy-monitor command to launch\n    :param parameter: The parameter to push on cozy-monitor if needed\n    :returns: the command string\n    '''\n    result = ''\n\n    # Transform into an array if it not one\n    if not isinstance(parameter, list):\n        parameter = [parameter]\n\n    # Iterate on all parameter with action & put them in result string\n    for name in parameter:\n        result += subprocess.Popen('cozy-monitor {} {}'.format(command, name),\n                                   shell=True,\n                                   stdout=subprocess.PIPE).stdout.read()\n    return result", "response": "Launch a cozy - monitor command"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef status(app_name=None, only_cozy=False, as_boolean=False):\n    '''Get apps status\n\n    :param app_name: If pass app name return this app status\n    :return: dict with all apps status or str with one app status\n    '''\n    apps = {}\n    # Get all apps status & slip them\n    apps_status = subprocess.Popen('cozy-monitor status',\n                                   shell=True,\n                                   stdout=subprocess.PIPE).stdout.read()\n    apps_status = apps_status.split('\\n')\n\n    # Parse result to store them in apps dictionary\n    for app_status in apps_status:\n        if app_status:\n            app_status = ANSI_ESCAPE.sub('', app_status).split(': ')\n            if len(app_status) == 2:\n                current_status = app_status[1]\n                if as_boolean:\n                    if app_status[1] == 'up':\n                        current_status = True\n                    else:\n                        current_status = False\n                if only_cozy and app_status[0] not in SYSTEM_APPS:\n                    apps[app_status[0]] = current_status\n                else:\n                    apps[app_status[0]] = current_status\n\n    # Return app status if get as param or return all apps status\n    if app_name:\n        return apps.get(app_name, None)\n    else:\n        return apps", "response": "Get status of all apps and slip them"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate the transitive closure over a transitive relationship in depth - first fashion.", "response": "def transitive_closure(m, orig, rel):\n    '''\n    Generate the closure over a transitive relationship in depth-first fashion\n    '''\n    #FIXME: Broken for now\n    links = list(m.match(orig, rel))\n    for link in links:\n        yield link[0][TARGET]\n        yield from transitive_closure(m, target, rel)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef all_origins(m):\n    '''\n    Generate all unique statement origins in the given model\n    '''\n    seen = set()\n    for link in m.match():\n        origin = link[ORIGIN]\n        if origin not in seen:\n            seen.add(origin)\n            yield origin", "response": "Generate all unique statement origins in the given model"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef column(m, linkpart):\n    '''\n    Generate all parts of links according to the parameter\n    '''\n    assert linkpart in (0, 1, 2, 3)\n    seen = set()\n    for link in m.match():\n        val = link[linkpart]\n        if val not in seen:\n            seen.add(val)\n            yield val", "response": "Generate all the parts of links according to the parameter\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a list of Versa types for a resource", "response": "def resourcetypes(rid, model):\n    '''\n    Return a list of Versa types for a resource\n    '''\n    types = []\n    for o, r, t, a in model.match(rid, VTYPE_REL):\n        types.append(t)\n    return types"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef replace_values(in_m, out_m, map_from=(), map_to=()):\n    '''\n    Make a copy of a model with one value replaced with another\n    '''\n    for link in in_m.match():\n        new_link = list(link)\n        if map_from:\n            if link[ORIGIN] in map_from: new_link[ORIGIN] = map_to[map_from.index(link[ORIGIN])]\n        new_link[ATTRIBUTES] = link[ATTRIBUTES].copy()\n        out_m.add(*new_link)\n    return", "response": "Replace values in in_m with values in out_m."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef replace_entity_resource(model, oldres, newres):\n    '''\n    Replace one entity in the model with another with the same links\n\n    :param model: Versa model to be updated\n    :param oldres: old/former resource IRI to be replaced\n    :param newres: new/replacement resource IRI\n    :return: None\n    '''\n    oldrids = set()\n    for rid, link in model:\n        if link[ORIGIN] == oldres or link[TARGET] == oldres or oldres in link[ATTRIBUTES].values():\n            oldrids.add(rid)\n            new_link = (newres if o == oldres else o, r, newres if t == oldres else t, dict((k, newres if v == oldres else v) for k, v in a.items()))\n            model.add(*new_link)\n    model.delete(oldrids)\n    return", "response": "Replace one entity in the model with another with the same links."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntakes links with a given origin and create duplicate links with the same information but a new origin.", "response": "def duplicate_statements(model, oldorigin, neworigin, rfilter=None):\n    '''\n    Take links with a given origin, and create duplicate links with the same information but a new origin\n\n    :param model: Versa model to be updated\n    :param oldres: resource IRI to be duplicated\n    :param newres: origin resource IRI for duplication\n    :return: None\n    '''\n    for o, r, t, a in model.match(oldorigin):\n        if rfilter is None or rfilter(o, r, t, a):\n            model.add(I(neworigin), r, t, a)\n    return"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving all duplicate relationships", "response": "def uniquify(model):\n    '''\n    Remove all duplicate relationships\n    '''\n    seen = set()\n    to_remove = set()\n    for ix, (o, r, t, a) in model:\n        hashable_link = (o, r, t) + tuple(sorted(a.items()))\n        #print(hashable_link)\n        if hashable_link in seen:\n            to_remove.add(ix)\n        seen.add(hashable_link)\n\n    model.remove(to_remove)\n    return"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads Versa model dumped into JSON form either raw or canonical", "response": "def jsonload(model, fp):\n    '''\n    Load Versa model dumped into JSON form, either raw or canonical\n    '''\n    dumped_list = json.load(fp)\n    for link in dumped_list:\n        if len(link) == 2:\n            sid, (s, p, o, a) = link\n        elif len(link) == 4: #canonical\n            (s, p, o, a) = link\n            tt = a.get('@target-type')\n            if tt == '@iri-ref':\n                o = I(o)\n            a.pop('@target-type', None)\n        else:\n            continue\n        model.add(s, p, o, a)\n    return"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef jsondump(model, fp):\n    '''\n    Dump Versa model into JSON form\n    '''\n    fp.write('[')\n    links_ser = []\n    for link in model:\n        links_ser.append(json.dumps(link))\n    fp.write(',\\n'.join(links_ser))\n    fp.write(']')", "response": "Dump Versa model into JSON form"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfunctions to numerically determine the parameters of the Higgs potential given the physical Higgs VEV and mass.", "response": "def vMh2_to_m2Lambda(v, Mh2, C, scale_high):\n    \"\"\"Function to numerically determine the parameters of the Higgs potential\n    given the physical Higgs VEV and mass.\"\"\"\n    if C['phi'] == 0 and C['phiBox'] == 0 and C['phiD'] == 0:\n        return _vMh2_to_m2Lambda_SM(v, Mh2)\n    else:\n        def f0(x):  # we want the root of this function\n            m2, Lambda = x\n            d = m2Lambda_to_vMh2(m2=m2.real, Lambda=Lambda.real,\n                                 C=C, scale_high=scale_high)\n            return np.array([d['v'] - v, d['Mh2'] - Mh2])\n        dSM = _vMh2_to_m2Lambda_SM(v, Mh2)\n        x0 = np.array([dSM['m2'], dSM['Lambda']])\n        try:\n            xres = scipy.optimize.newton_krylov(f0, x0)\n        except scipy.optimize.nonlin.NoConvergence:\n            raise ValueError(\"No solution for m^2 and Lambda found\")\n        return {'m2': xres[0], 'Lambda': xres[1]}"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update(self, u):\n        ''' Works like dict.update(dict) but handles nested dicts.\n            From http://stackoverflow.com/questions/3232943/update-value-of-a-nested-dictionary-of-varying-depth.\n        '''\n        for k, v in u.iteritems():\n            if isinstance(v, collections.Mapping):\n                r = nested_dict.from_dict(self.get(k, {}))\n                r.update(v)\n                self[k] = r\n            elif isinstance(self, collections.Mapping):\n                self[k] = u[k]\n            else:\n                self.__dict__ = dict(k = u[k])", "response": "Updates the internal dictionary with the contents of u."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates statics directory and copy files in it", "response": "def set_statics(self):\n        \"\"\"Create statics directory and copy files in it\n        \"\"\"\n        if not os.path.exists(self.results_dir):\n            return None\n        try:\n            shutil.copytree(os.path.join(self.templates_dir, 'css'), os.path.join(self.results_dir, 'css'))\n            shutil.copytree(os.path.join(self.templates_dir, 'scripts'), os.path.join(self.results_dir, 'scripts'))\n            shutil.copytree(os.path.join(self.templates_dir, 'fonts'), os.path.join(self.results_dir, 'fonts'))\n        except OSError as e:\n            if e.errno == 17:  # File exists\n                print(\"WARNING : existing output directory for static files, will not replace them\")\n            else:  # in all other cases, re-raise exceptions\n                raise\n        try:\n            shutil.copytree(os.path.join(self.templates_dir, 'img'), os.path.join(self.results_dir, 'img'))\n        except OSError as e:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef write_report(self, template):\n        with open(self.fn, 'w') as f:\n            f.write(template)", "response": "Write the compiled jinja template to the results file\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget raw input register value by name.", "response": "def get_raw_input_register(self, name):\n        \"\"\"Get raw register value by name.\"\"\"\n        if self._update_on_read:\n            self.update()\n        return self._input_regs[name]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_raw_holding_register(self, name):\n        if self._update_on_read:\n            self.update()\n        return self._holding_regs[name]", "response": "Get the raw value of a holding register by name."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwriting to register by name.", "response": "def set_raw_holding_register(self, name, value):\n        \"\"\"Write to register by name.\"\"\"\n        self._conn.write_register(\n            unit=self._slave,\n            address=(self._holding_regs[name]['addr']),\n            value=value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of all files in a folder and its subfolders.", "response": "def full_file_list(scan_path):\n    \"\"\"\n    Returns a list of all files in a folder and its subfolders (only files).\n    \"\"\"\n    file_list = []\n    path = os.path.abspath(scan_path)\n    for root, dirs, files in os.walk(path):\n        if len(files) != 0 and not '.svn' in root and not '.git' in root:\n            for f in files:\n                file_list.append(os.path.join(root, f))\n    return file_list"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of all files in a folder without subfolders.", "response": "def list_files(scan_path, contains=None):\n    \"\"\"\n    Returns a list of all files in a folder, without subfolders (only files).\n    \"\"\"\n    file_list = []\n    path = os.path.abspath(scan_path)\n    for f in sorted(os.listdir(path)):\n        if contains and f.find(contains) < 0:\n            continue\n        filepath = os.path.join(path, f)\n        if os.path.isfile(filepath):\n            file_list.append(filepath)\n    return file_list"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of all files in a folder and its subfolders with sequence number.", "response": "def full_file_list_with_sequence(scan_path):\n    \"\"\"\n    Returns a list of all files in a folder and its subfolders (only files).\n    \"\"\"\n    \n    file_list = []\n    path = os.path.abspath(scan_path)\n    \n    for root, dirs, files in os.walk(path):\n        if len(files) != 0 and not '.svn' in root and not '.git' in root:\n            try:\n                sc = sequential.SequentialFolder(str(root))\n                if sc.sequence:\n                    file_list.append(sc)\n                    continue\n            except Exception as e:\n                pass\n                \n            for f in files:\n                file_list.append(os.path.join(root, f))\n    return file_list"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn an absolute path for the destination of a symlink", "response": "def readlinkabs(l):\n    \"\"\"\n    Return an absolute path for the destination \n    of a symlink\n    \"\"\"\n    assert (os.path.islink(l))\n    p = os.readlink(l)\n    if os.path.isabs(p):\n        return os.path.abspath(p)\n    return os.path.abspath(os.path.join(os.path.dirname(l), p))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nunzipping an archive file", "response": "def unzip(filepath, output_path):\n    \"\"\"\n    Unzip an archive file\n    \"\"\"\n    filename = os.path.split(filepath)[1]\n    (name, extension) = os.path.splitext(filename)\n    extension = extension[1:].lower()\n    extension2 = os.path.splitext(name)[1][1:].lower()\n\n    if extension not in ZIP_EXTENSIONS:\n        raise Exception(\"Impossible to extract archive file %s\" % filepath)\n\n    extract_command = \"unzip\"\n    output_args = \"-d\"\n    if extension == 'bz2' and extension2 == 'tar':\n        extract_command = \"tar -xjf\"\n        output_args = \"-C\"\n    elif extension == 'gz' and extension2 == 'tar':\n        extract_command = \"tar -xzf\"\n        output_args = \"-C\"\n    elif extension == 'xz' and extension2 == 'tar':\n        extract_command = \"tar -xJf\"\n        output_args = \"-C\"\n    elif extension == 'bz2':\n        extract_command = \"bunzip2 -dc \"\n        output_args = \">\"\n        output_path = os.path.join(output_path, name)\n    elif extension == 'rar':\n        extract_command = \"unrar x\"\n        output_args = \"\"\n    elif extension == 'gz':\n        extract_command = \"gunzip\"\n        output_args = \"\"\n    elif extension == 'tar':\n        extract_command = \"tar -xf\"\n        output_args = \"-C\"\n    elif extension == 'tbz2':\n        extract_command = \"tar -xjf\"\n        output_args = \"-C\"\n    elif extension == 'tgz':\n        extract_command = \"tar -xzf\"\n        output_args = \"-C\"\n    elif extension == 'zip':\n        extract_command = \"unzip\"\n        output_args = \"-d\"\n    elif extension == 'Z':\n        extract_command = \"uncompress\"\n        output_args = \"\"\n    elif extension == '7z':\n        extract_command = \"7z x\"\n        output_args = \"\"\n    elif extension == 'xz':\n        extract_command = \"unxz\"\n        output_args = \"\"\n    elif extension == 'ace':\n        extract_command = \"unace\"\n        output_args = \"\"\n    elif extension == 'iso':\n        extract_command = \"7z x\"\n        output_args = \"\"\n    elif extension == 'arj':\n        extract_command = \"7z x\"\n        output_args = \"\"\n\n    command = \"\"\"%(extract_command)s \"%(filepath)s\" %(output_args)s \"%(output_folder)s\" \"\"\"\n    params = {\n        'extract_command': extract_command,\n        'filepath': filepath,\n        'output_folder': output_path,\n        'output_args': output_args,\n    }\n    result = os.system(command % params)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _configure_sockets(self, config, with_streamer=False, with_forwarder=False):\n        rc_port = config.get('rc_port', 5001)\n\n        self.result_collector.set_hwm(0)\n        self.result_collector.bind(\"tcp://*:{}\".format(rc_port))\n\n        self.poller.register(self.result_collector, zmq.POLLIN)", "response": "Configure sockets for HQ\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef wait_turrets(self, wait_for):\n        print(\"Waiting for %d turrets\" % (wait_for - len(self.turrets_manager.turrets)))\n\n        while len(self.turrets_manager.turrets) < wait_for:\n            self.turrets_manager.status_request()\n\n            socks = dict(self.poller.poll(2000))\n\n            if self.result_collector in socks:\n                data = self.result_collector.recv_json()\n                self.turrets_manager.process_message(data)\n\n                print(\"Waiting for %d turrets\" % (wait_for - len(self.turrets_manager.turrets)))", "response": "Wait until wait_for turrets are connected and ready"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning the hight quarter lunch the turrets and wait for results", "response": "def run(self):\n        \"\"\"Run the hight quarter, lunch the turrets and wait for results\n        \"\"\"\n        elapsed = 0\n        run_time = self.config['run_time']\n        start_time = time.time()\n        t = time.time\n        self.turrets_manager.start(self.transaction_context)\n        self.started = True\n\n        while elapsed <= run_time:\n            try:\n                self._run_loop_action()\n                self._print_status(elapsed)\n                elapsed = t() - start_time\n            except (Exception, KeyboardInterrupt):\n                print(\"\\nStopping test, sending stop command to turrets\")\n                self.turrets_manager.stop()\n                self.stats_handler.write_remaining()\n                traceback.print_exc()\n                break\n\n        self.turrets_manager.stop()\n        print(\"\\n\\nProcessing all remaining messages... This could take time depending on message volume\")\n        t = time.time()\n        self.result_collector.unbind(self.result_collector.LAST_ENDPOINT)\n        self._clean_queue()\n        print(\"took %s\" % (time.time() - t))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef submit(command_filename, workingdir, send_mail = False, username = None):\n    '''Submit the given command filename to the queue. Adapted from the qb3 example.'''\n    return sge_interface.submit(command_filename, workingdir, send_mail = send_mail, username = username)", "response": "Submit the given command filename to the queue."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nqueries the jobs in the specified log file.", "response": "def query(logfile, jobID = None):\n    \"\"\"If jobID is an integer then return False if the job has finished and True if it is still running.\n       Otherwise, returns a table of jobs run by the user.\"\"\"\n    \n    joblist = logfile.readFromLogfile()\n    if jobID and type(jobID) == type(1):\n        command = ['qstat', '-j', str(jobID)]\n    else:\n        command = ['qstat']\n\n    processoutput = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE).communicate()\n    output = processoutput[0]\n    serror = processoutput[1]\n    # Form command\n    jobs = {}\n    if type(jobID) == type(1):\n        if serror.find(\"Following jobs do not exist\") != -1:\n            return False\n        else:\n            return True\n\n    if not output.strip():\n        colorprinter.message(\"No jobs running at present.\")\n    output = output.strip().split(\"\\n\")\n    if len(output) > 2:\n        for line in output[2:]:\n            # We assume that our script names contain no spaces for the parsing below to work\n            tokens = line.split()\n            jid = int(tokens[0])\n            jobstate = tokens[4]\n\n            details = {  \"jobid\" : jid,\n                         \"prior\" : tokens[1],\n                         \"name\" : tokens[2],\n                         \"user\" : tokens[3],\n                         \"state\" : jobstate,\n                         \"submit/start at\" : \"%s %s\" % (tokens[5], tokens[6])\n                         }\n            jataskID = 0\n            if jobstate == \"r\":\n                details[\"queue\"] = tokens[7]\n                details[\"slots\"] = tokens[8]\n            elif jobstate == \"qw\":\n                details[\"slots\"] = tokens[7]\n                if len(tokens) >= 9:\n                    jataskID = tokens[8]\n                    details[\"ja-task-ID\"] = jataskID\n\n            if len(tokens) > 9:\n                jataskID = tokens[9]\n                details[\"ja-task-ID\"] = jataskID\n\n            jobs[jid] = jobs.get(jid) or {}\n            jobs[jid][jataskID] = details\n            if joblist.get(jid):\n                jobdir = joblist[jid][\"Directory\"]\n                jobtime = joblist[jid][\"TimeInSeconds\"]\n                colorprinter.message(\"Job %d submitted %d minutes ago. Status: '%s'. Destination directory: %s.\" % (jid, jobtime / 60, jobstate, jobdir))\n            else:\n                colorprinter.message(\"Job %d submitted at %s %s. Status: '%s'. Destination directory unknown.\" % (jid, tokens[5], tokens[6], jobstate))\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef main(arguments=None):\n    # setup the command-line util settings\n    su = tools(\n        arguments=arguments,\n        docString=__doc__,\n        logLevel=\"DEBUG\",\n        options_first=False,\n        projectName=\"HMpTy\"\n    )\n    arguments, settings, log, dbConn = su.setup()\n\n    # unpack remaining cl arguments using `exec` to setup the variable names\n    # automatically\n    for arg, val in arguments.iteritems():\n        if arg[0] == \"-\":\n            varname = arg.replace(\"-\", \"\") + \"Flag\"\n        else:\n            varname = arg.replace(\"<\", \"\").replace(\">\", \"\")\n        if isinstance(val, str) or isinstance(val, unicode):\n            exec(varname + \" = '%s'\" % (val,))\n        else:\n            exec(varname + \" = %s\" % (val,))\n        if arg == \"--dbConn\":\n            dbConn = val\n        log.debug('%s = %s' % (varname, val,))\n\n    ## START LOGGING ##\n    startTime = times.get_now_sql_datetime()\n    log.info(\n        '--- STARTING TO RUN THE cl_utils.py AT %s' %\n        (startTime,))\n\n    if hostFlag:\n        dbSettings = {\n            'host': hostFlag,\n            'user': userFlag,\n            'password': passwdFlag,\n            'db': dbNameFlag\n        }\n    elif settings:\n        dbSettings = settings[\"database settings\"]\n\n    # CALL FUNCTIONS/OBJECTS\n    if index:\n        add_htm_ids_to_mysql_database_table(\n            raColName=raCol,\n            declColName=decCol,\n            tableName=tableName,\n            dbConn=dbConn,\n            log=log,\n            primaryIdColumnName=primaryIdCol,\n            reindex=forceFlag,\n            dbSettings=dbSettings\n        )\n\n    if search:\n        cs = conesearch(\n            log=log,\n            dbConn=dbConn,\n            tableName=tableName,\n            columns=False,\n            ra=ra,\n            dec=dec,\n            radiusArcsec=float(radius),\n            separations=True,\n            distinct=False,\n            sqlWhere=False\n        )\n        matchIndies, matches = cs.search()\n        if not renderFlag:\n            print matches.table()\n        elif renderFlag == \"json\":\n            print matches.json()\n        elif renderFlag == \"csv\":\n            print matches.csv()\n        elif renderFlag == \"yaml\":\n            print matches.yaml()\n        elif renderFlag == \"md\":\n            print matches.markdown()\n        elif renderFlag == \"table\":\n            print matches.markdown()\n        elif renderFlag == \"mysql\":\n            print matches.mysql(tableName=resultsTable)\n\n    if level:\n        from HMpTy import HTM\n        mesh = HTM(\n            depth=int(level),\n            log=log\n        )\n\n        htmids = mesh.lookup_id(ra, dec)\n        print htmids[0]\n\n    if \"dbConn\" in locals() and dbConn:\n        dbConn.commit()\n        dbConn.close()\n    ## FINISH LOGGING ##\n    endTime = times.get_now_sql_datetime()\n    runningTime = times.calculate_time_difference(startTime, endTime)\n    log.info('-- FINISHED ATTEMPT TO RUN THE cl_utils.py AT %s (RUNTIME: %s) --' %\n             (endTime, runningTime, ))\n\n    return", "response": "This function is the main function used by the cl_utils. py module."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_tmp_folder():\n    output = \"%s\" % datetime.datetime.now()\n    for char in [' ', ':', '.', '-']:\n        output = output.replace(char, '')\n    output.strip()\n    tmp_folder = os.path.join(tempfile.gettempdir(), output)\n    return tmp_folder", "response": "Create a temporary folder using the current time in which\n    the zip can be extracted and which should be destroyed afterward."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef extract_zip(filename, extract_dir):\n    LOG.info(\"Extracting %s in %s \" % (filename, extract_dir))\n    if not os.path.exists(extract_dir):\n        try:\n            os.mkdir(extract_dir)\n        except IOError as err:  # pragma: no cover\n            LOG.info(\"Could not generate the folder %s\" % extract_dir)\n            LOG.debug(\"Error: %s\" % err)\n            return\n\n    if zipfile.is_zipfile(filename):\n        try:\n            zfile = zipfile.ZipFile(filename, \"r\")\n            for name in zfile.namelist():\n                if os.path.dirname(name):\n                    curdir = os.path.join(extract_dir, os.path.dirname(name))\n                    if not os.path.exists(curdir):\n                        os.mkdir(curdir)\n                        continue\n                outfile = open(os.path.join(extract_dir, name), 'wb')\n                outfile.write(zfile.read(name))\n                outfile.flush()\n                outfile.close()\n            zfile.close()\n        except IOError as err:  # pragma: no cover\n            LOG.info(\"Error while extracting the zip archive.\")\n            LOG.debug(\"Error: %s\" % err)\n    else:\n        try:  # pragma: no cover  We only have zipfile to test with\n            tar = tarfile.open(filename)\n            tar.extractall(extract_dir)\n            tar.close()\n        except tarfile.ReadError as err:  # pragma: no cover\n            LOG.info(\"Error while extracting the tarball.\")\n            LOG.debug(\"Error: %s\" % err)\n\n    return extract_dir", "response": "Extract the sources from a zip file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading in a matrix file and returns the number of rows and columns.", "response": "def get_matrix_dimensions(filename):\n    \"\"\" Reads in a matrix file (comma separated) and returns the number\n    of rows and columns.\n    :arg filename, the full path to the file to read.\n    \"\"\"\n    stream = None\n    try:\n        stream = open(filename, 'r')\n        length = len(stream.readlines())\n        stream.seek(0)\n        width = len(stream.readline().split(','))\n        return (length, width)\n    except IOError as err:  # pragma: no cover\n        LOG.info(\"Something wrong happend while reading the file %s \"\n                 % filename)\n        LOG.debug(\"ERROR: %s\" % err)\n    finally:\n        if stream:\n            stream.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads a given inputfile and returns a list of lists.", "response": "def read_input_file(filename, sep='\\t', noquote=False):\n    \"\"\"Reads a given inputfile (tab delimited) and returns a matrix\n    (list of list).\n    arg: filename, the complete path to the inputfile to read\n    \"\"\"\n    output = []\n    stream = None\n    try:\n        stream = open(filename, 'r')\n        for row in stream:\n            row = row.strip()\n            if noquote:\n                row = row.replace('\"', '')\n            output.append(row.split(sep))\n    except IOError as err:  # pragma: no cover\n        LOG.info(\"Something wrong happend while reading the file %s \"\n                 % filename)\n        LOG.debug(\"ERROR: %s\" % err)\n    finally:\n        if stream:\n            stream.close()\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef write_matrix(outputfile, matrix):\n\n    try:\n        stream = open(outputfile, 'w')\n        for row in matrix:\n            if isinstance(row, list) or isinstance(row, tuple):\n                row = [str(el).strip() for el in row]\n                stream.write(','.join(row) + '\\n')\n            else:\n                stream.write(row + '\\n')\n    except IOError as err:  # pragma: no cover\n        LOG.info('An error occured while writing the file %s'\n                 % outputfile)\n        LOG.debug(\"Error: %s\" % err)\n    finally:\n        stream.close()\n    LOG.info('Wrote QTLs in file %s' % outputfile)", "response": "Write down the provided matrix of QTLs in the specified outputfile."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef file_logger(app, level=None):\n    path = os.path.join(os.getcwd(), 'var', 'logs',  'app.log')\n\n    max_bytes = 1024 * 1024 * 2\n    file_handler = RotatingFileHandler(\n        filename=path,\n        mode='a',\n        maxBytes=max_bytes,\n        backupCount=10\n    )\n\n    if level is None: level = logging.INFO\n    file_handler.setLevel(level)\n\n    log_format  = '%(asctime)s %(levelname)s: %(message)s'\n    log_format += ' [in %(pathname)s:%(lineno)d]'\n    file_handler.setFormatter(logging.Formatter(log_format))\n\n    return file_handler", "response": "Returns a RotatingFileHandler that will log the file at the specified level."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef tag(self, repository_tag, tags=[]):\n        if not isinstance(repository_tag, six.string_types):\n            raise TypeError('repository_tag must be a string')\n\n        if not isinstance(tags, list):\n            raise TypeError('tags must be a list.')\n\n        if ':' in repository_tag:\n            repository, tag = repository_tag.split(':')\n            tags.append(tag)\n        else:\n            repository = repository_tag\n\n            if not tags:\n                tags.append('latest')\n\n        for tag in tags:\n            repo_tag = \"{0}:{1}\".format(repository, tag)\n\n            if repo_tag not in self.repo_tags:\n                logger.info(\"Tagging Image: {0} Repo Tag: {1}\".format(self.identifier, repo_tag))\n                self.repo_tags = self.repo_tags + (repo_tag, )\n\n                # always going to force tags until a feature is added to allow users to specify.\n                try:\n                    self.client.tag(self.id, repository, tag)\n                except:\n                    self.client.tag(self.id, repository, tag, force=True)", "response": "Tags image with one or more tags."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef build(client, repository_tag, docker_file, tag=None, use_cache=False):\n        if not isinstance(client, docker.Client):\n            raise TypeError(\"client needs to be of type docker.Client.\")\n\n        if not isinstance(docker_file, six.string_types) or not os.path.exists(docker_file):\n            # TODO: need to add path stuff for git and http etc.\n            raise Exception(\"docker file path doesn't exist: {0}\".format(docker_file))\n\n        if not isinstance(repository_tag, six.string_types):\n            raise TypeError('repository must be a string')\n\n        if not tag:\n            tag = 'latest'\n\n        if not isinstance(use_cache, bool):\n            raise TypeError(\"use_cache must be a bool. {0} was passed.\".format(use_cache))\n\n        no_cache = not use_cache\n\n        if ':' not in repository_tag:\n            repository_tag = \"{0}:{1}\".format(repository_tag, tag)\n        file_obj = None\n        try:\n            if os.path.isfile(docker_file):\n                path = os.getcwd()\n                docker_file = \"./{0}\".format(os.path.relpath(docker_file))\n\n                # TODO: support using file_obj in the future. Needed for post pre hooks and the injector.\n                # with open(docker_file) as Dockerfile:\n                #     testing = Dockerfile.read()\n                #     file_obj = BytesIO(testing.encode('utf-8'))\n\n                response = client.build(\n                    path=path,\n                    nocache=no_cache,\n                    # custom_context=True,\n                    dockerfile=docker_file,\n                    # fileobj=file_obj,\n                    tag=repository_tag,\n                    rm=True,\n                    stream=True\n                )\n            else:\n                response = client.build(path=docker_file, tag=repository_tag, rm=True, nocache=no_cache, stream=True)\n        except Exception as e:\n            raise e\n        finally:\n            if file_obj:\n                file_obj.close()\n\n        parse_stream(response)\n        client.close()\n\n        return Image(client, repository_tag)", "response": "Build a docker image and return the ID of the image."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a StudentGrades model for the regid and term.", "response": "def get_grades_by_regid_and_term(regid, term):\n    \"\"\"\n    Returns a StudentGrades model for the regid and term.\n    \"\"\"\n    url = \"{}/{},{},{}.json\".format(enrollment_res_url_prefix,\n                                    term.year,\n                                    term.quarter,\n                                    regid)\n    return _json_to_grades(get_resource(url), regid, term)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsearches for an enrollment list.", "response": "def _enrollment_search(regid, verbose, transcriptable, changed_since_date):\n    \"\"\"\n    See SWS Enrollment search resource spec at:\n    https://wiki.cac.washington.edu/x/_qjeAw\n    :return: search result json data\n    \"\"\"\n    url = \"{}{}&{}\".format(enrollment_search_url_prefix,\n                           regid,\n                           urlencode(\n                               {\"verbose\": verbose,\n                                \"transcriptable_course\": transcriptable,\n                                \"changed_since_date\": changed_since_date}))\n    return get_resource(url)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef enrollment_search_by_regid(regid,\n                               verbose='true',\n                               transcriptable_course='all',\n                               changed_since_date='',\n                               include_unfinished_pce_course_reg=True):\n    \"\"\"\n    :return: a dictionary of {Term: Enrollment}\n    \"\"\"\n    return _json_to_term_enrollment_dict(\n        _enrollment_search(regid, verbose, transcriptable_course,\n                           changed_since_date),\n        include_unfinished_pce_course_reg)", "response": "Search for an enrollment by the given regid."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the list of Enrollment objects that are in the registry.", "response": "def get_enrollment_history_by_regid(regid,\n                                    verbose='true',\n                                    transcriptable_course='all',\n                                    changed_since_date='',\n                                    include_unfinished_pce_course_reg=False):\n    \"\"\"\n    :return: a complete chronological list of all the enrollemnts\n    [Enrollment], where the Enrollment object has a term element.\n    \"\"\"\n    return _json_to_enrollment_list(\n        _enrollment_search(regid, verbose, transcriptable_course,\n                           changed_since_date),\n        include_unfinished_pce_course_reg)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if a refresh of the token is needed", "response": "def _requires_refresh_token(self):\n        \"\"\"\n        Check if a refresh of the token is needed\n        \"\"\"\n        expires_on = datetime.datetime.strptime(\n            self.login_data['token']['expiresOn'], '%Y-%m-%dT%H:%M:%SZ')\n        refresh = datetime.datetime.utcnow() + datetime.timedelta(seconds=30)\n        return expires_on < refresh"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrequesting a new auth token from the API.", "response": "def _request_token(self, force=False):\n        \"\"\"\n        Request a new auth token\n        \"\"\"\n        if self.login_data is None:\n            raise RuntimeError(\"Don't have a token to refresh\")\n\n        if not force:\n            if not self._requires_refresh_token():\n                # no need to refresh as token is valid\n                return True\n\n        headers = {\n            \"Accept\": \"application/json\",\n            'Authorization':\n                'Bearer ' + self.login_data['token']['accessToken']\n        }\n\n        url = self.api_base_url + \"account/RefreshToken\"\n\n        response = requests.get(url, headers=headers, timeout=10)\n\n        if response.status_code != 200:\n            return False\n\n        refresh_data = response.json()\n\n        if 'token' not in refresh_data:\n            return False\n\n        self.login_data['token']['accessToken'] = refresh_data['accessToken']\n        self.login_data['token']['issuedOn'] = refresh_data['issuedOn']\n        self.login_data['token']['expiresOn'] = refresh_data['expiresOn']\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nlogin using username and password and get the first auth token", "response": "def _login(self):\n        \"\"\"\n        Login using username / password and get the first auth token\n        \"\"\"\n        headers = {\n            \"Content-Type\": \"application/x-www-form-urlencoded\",\n            \"Accept\": \"application/json\"\n        }\n\n        url = self.api_base_url + \"account/directlogin\"\n\n        data = {'Email': self.username,\n                'Password': self.password,\n                'RememberMe': 'True'}\n\n        response = requests.post(url, data=data, headers=headers, timeout=10)\n\n        if response.status_code != 200:\n            return False\n\n        self.login_data = response.json()\n        if not self.login_data['isSuccess']:\n            self.login_data = None\n            return False\n\n        if ('token' in self.login_data\n                and 'accessToken' in self.login_data['token']):\n            self.home_id = self.login_data['token']['currentHomeId']\n            self.user_id = self.login_data['token']['userId']\n            return True\n\n        self.login_data = None\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_home(self, home_id=None):\n        now = datetime.datetime.utcnow()\n        if self.home and now < self.home_refresh_at:\n            return self.home\n\n        if not self._do_auth():\n            raise RuntimeError(\"Unable to login\")\n\n        if home_id is None:\n            home_id = self.home_id\n\n        url = self.api_base_url + \"Home/GetHomeById\"\n\n        params = {\n            \"homeId\": home_id\n        }\n\n        headers = {\n            \"Accept\": \"application/json\",\n            'Authorization':\n                'bearer ' + self.login_data['token']['accessToken']\n        }\n\n        response = requests.get(\n            url, params=params, headers=headers, timeout=10)\n\n        if response.status_code != 200:\n            raise RuntimeError(\n                \"{} response code when getting home\".format(\n                    response.status_code))\n\n        home = response.json()\n\n        if self.cache_home:\n            self.home = home\n            self.home_refresh_at = (datetime.datetime.utcnow()\n                                    + datetime.timedelta(minutes=5))\n\n        return home", "response": "Get the data about a home."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_zones(self):\n        home_data = self.get_home()\n        if not home_data['isSuccess']:\n            return []\n\n        zones = []\n\n        for receiver in home_data['data']['receivers']:\n            for zone in receiver['zones']:\n                zones.append(zone)\n\n        return zones", "response": "Get all zones in the home data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_zone_names(self):\n        zone_names = []\n        for zone in self.get_zones():\n            zone_names.append(zone['name'])\n\n        return zone_names", "response": "Get the name of all zones in the current session."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_zone(self, zone_name):\n        for zone in self.get_zones():\n            if zone_name == zone['name']:\n                return zone\n\n        raise RuntimeError(\"Unknown zone\")", "response": "Get the information about a particular zone"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks if a zone is active", "response": "def is_zone_active(self, zone_name):\n        \"\"\"\n        Check if a zone is active\n        \"\"\"\n        zone = self.get_zone(zone_name)\n        if zone is None:\n            raise RuntimeError(\"Unable to get zone\")\n\n        return zone['isCurrentlyActive']"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_zone_temperature(self, zone_name):\n        zone = self.get_zone(zone_name)\n\n        if zone is None:\n            raise RuntimeError(\"Unknown zone\")\n\n        return zone['currentTemperature']", "response": "Get the temperature for a zone"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking if a zone is boost active", "response": "def is_boost_active(self, zone_name):\n        \"\"\"\n        Check if a zone is active\n        \"\"\"\n        zone = self.get_zone(zone_name)\n\n        if zone is None:\n            raise RuntimeError(\"Unknown zone\")\n\n        return zone['isBoostActive']"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if target temperature is reached in a zone.", "response": "def is_target_temperature_reached(self, zone_name):\n        \"\"\"\n        Check if a zone is active\n        \"\"\"\n        zone = self.get_zone(zone_name)\n\n        if zone is None:\n            raise RuntimeError(\"Unknown zone\")\n\n        return zone['isTargetTemperatureReached']"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the target temperature for a zone by id", "response": "def set_target_temperature_by_id(self, zone_id, target_temperature):\n        \"\"\"\n        Set the target temperature for a zone by id\n        \"\"\"\n        if not self._do_auth():\n            raise RuntimeError(\"Unable to login\")\n\n        data = {\n            \"ZoneId\": zone_id,\n            \"TargetTemperature\": target_temperature\n        }\n\n        headers = {\n            \"Accept\": \"application/json\",\n            \"Content-Type\": \"application/json\",\n            'Authorization':\n                'Bearer ' + self.login_data['token']['accessToken']\n        }\n\n        url = self.api_base_url + \"Home/ZoneTargetTemperature\"\n\n        response = requests.post(url, data=json.dumps(\n            data), headers=headers, timeout=10)\n\n        if response.status_code != 200:\n            return False\n\n        zone_change_data = response.json()\n\n        return zone_change_data.get(\"isSuccess\", False)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_target_temperture_by_name(self, zone_name, target_temperature):\n        zone = self.get_zone(zone_name)\n\n        if zone is None:\n            raise RuntimeError(\"Unknown zone\")\n\n        return self.set_target_temperature_by_id(zone[\"zoneId\"],\n                                                 target_temperature)", "response": "Set the target temperature for a zone by name"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef activate_boost_by_id(self, zone_id, target_temperature, num_hours=1):\n        if not self._do_auth():\n            raise RuntimeError(\"Unable to login\")\n\n        zones = [zone_id]\n        data = {\n            \"ZoneIds\": zones,\n            \"NumberOfHours\": num_hours,\n            \"TargetTemperature\": target_temperature\n        }\n\n        headers = {\n            \"Accept\": \"application/json\",\n            \"Content-Type\": \"application/json\",\n            'Authorization':\n                'Bearer ' + self.login_data['token']['accessToken']\n        }\n\n        url = self.api_base_url + \"Home/ActivateZoneBoost\"\n\n        response = requests.post(url, data=json.dumps(\n            data), headers=headers, timeout=10)\n\n        if response.status_code != 200:\n            return False\n\n        boost_data = response.json()\n\n        return boost_data.get(\"isSuccess\", False)", "response": "Activate boost for a zone based on the numeric id"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef activate_boost_by_name(self,\n                               zone_name,\n                               target_temperature,\n                               num_hours=1):\n        \"\"\"\n        Activate boost by the name of the zone\n        \"\"\"\n\n        zone = self.get_zone(zone_name)\n        if zone is None:\n            raise RuntimeError(\"Unknown zone\")\n\n        return self.activate_boost_by_id(zone[\"zoneId\"],\n                                         target_temperature, num_hours)", "response": "Activate boost by the name of the zone."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef deactivate_boost_by_name(self, zone_name):\n\n        zone = self.get_zone(zone_name)\n        if zone is None:\n            raise RuntimeError(\"Unknown zone\")\n\n        return self.deactivate_boost_by_id(zone[\"zoneId\"])", "response": "Deactivate boost by the name of the zone."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_mode_by_id(self, zone_id, mode):\n        if not self._do_auth():\n            raise RuntimeError(\"Unable to login\")\n\n        data = {\n            \"ZoneId\": zone_id,\n            \"mode\": mode.value\n        }\n\n        headers = {\n            \"Accept\": \"application/json\",\n            \"Content-Type\": \"application/json\",\n            'Authorization':\n                'Bearer ' + self.login_data['token']['accessToken']\n        }\n\n        url = self.api_base_url + \"Home/SetZoneMode\"\n        response = requests.post(url, data=json.dumps(\n            data), headers=headers, timeout=10)\n\n        if response.status_code != 200:\n            return False\n\n        mode_data = response.json()\n\n        return mode_data.get(\"isSuccess\", False)", "response": "Set the mode by using the zone id"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_mode_by_name(self, zone_name, mode):\n        zone = self.get_zone(zone_name)\n        if zone is None:\n            raise RuntimeError(\"Unknown zone\")\n\n        return self.set_mode_by_id(zone[\"zoneId\"], mode)", "response": "Set the mode by using the name of the zone."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the mode for a zone", "response": "def get_zone_mode(self, zone_name):\n        \"\"\"\n        Get the mode for a zone\n        \"\"\"\n        zone = self.get_zone(zone_name)\n\n        if zone is None:\n            raise RuntimeError(\"Unknown zone\")\n\n        return ZoneMode(zone['mode'])"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _remove_comment(line):\n    # First find just quotes and their indexes.\n    quote_indexes = []\n    hash_indexes = []\n    for i, ch in enumerate(line):\n        if ch == '\"':\n            quote_indexes.append(i)\n            if i > 0 and line[i - 1] == \"\\\\\":\n                quote_indexes.pop()\n        elif ch == '#':\n            hash_indexes.append(i)\n\n    comment_marker_index = -1\n    for hash_index in hash_indexes:\n        quote_index_ranges = [quote_indexes[i:i + 2] for i in range(0, len(quote_indexes), 2)]\n        if not _check_index_within_index_pairs(hash_index, quote_index_ranges):\n            comment_marker_index = hash_index\n            break\n\n    if comment_marker_index >= 0:\n        line = line[:comment_marker_index]\n    return line", "response": "Removes any comments from a line."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking whether the given index falls within the set of index pairs.", "response": "def _check_index_within_index_pairs(index, index_ranges):\n    \"\"\"\n    Check that the index 'index' lies within the set of indexes.\n    :param index: Index to determine whether it falls within the range or index pairs.\n    :param index_ranges: A list of index pairs, monotonically increasing pairs.\n    :return: True if the given index lies within a range specified by an index pair, False otherwise.\n    \"\"\"\n    in_range = False\n    for index_range in index_ranges:\n        if index_range[0] < index < index_range[1]:\n            in_range = True\n    return in_range"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _convertToElementList(elements_list):\n    elements = []\n    current_element = []\n    for node_index in elements_list:\n        if node_index == -1:\n            elements.append(current_element)\n            current_element = []\n        else:\n            current_element.append(node_index)\n\n    return elements", "response": "Convert a list of element node indexes deliminated by - 1 into a list of element node indexes list."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_VRML_node(name):\n    known_nodes = _get_known_nodes()\n    index = known_nodes.index(name)\n    return _BaseNode.__subclasses__()[index]()", "response": "Returns the VRML Node object that matches the given name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_locale(self):\n        if not self.locale:\n            try:\n                import flask_babel as babel\n                self.locale = str(babel.get_locale()).lower()\n            except ImportError:\n                from flask import current_app\n                self.locale = current_app.config['DEFAULT_LOCALE'].lower\n\n        return self.locale", "response": "Get locale from babel and current app config"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_language(self):\n        locale = self.get_locale()\n        language = locale\n        if '_' in locale:\n            language = locale[0:locale.index('_')]\n        return language", "response": "Get language from locale"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef localize_humanize(self):\n        import humanize\n        language = self.get_language()\n        if language != 'en':\n            humanize.i18n.activate(language)", "response": "Setts current language to humanize"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a dictionary of filters", "response": "def get_filters(self):\n        \"\"\" Returns a dictionary of filters \"\"\"\n        filters = dict()\n        for filter in self.get_filter_names():\n            filters[filter] = getattr(self, filter)\n        return filters"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef date_fromnow(self, value):\n        import humanize\n        language = self.get_language()\n        if language != 'en':\n            humanize.i18n.activate(language)\n        return Markup(humanize.naturaltime(value))", "response": "Displays a humanized date from the given time since"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _render(self, value, format):\n        template = '<script>\\ndocument.write(moment(\\\"{t}\\\").{f});\\n</script>'\n        return Markup(template.format(t=value, f=format))", "response": "Writes javascript to call momentjs function"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_filters(self):\n        return dict(\n            moment_format=self.format,\n            moment_calendar=self.calendar,\n            moment_fromnow=self.from_now,\n        )", "response": "Returns a collection of momentjs filters"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a JSON response of the user stats of the user", "response": "def user_stats(request):\n    \"\"\"\n    JSON of user stats of the user\n\n    GET parameters:\n      html (bool):\n        turn on the HTML version of the API, defaults to false\n      user (int):\n        identifier of the user, defaults to logged user\n      concepts (list):\n        list of identifiers of concepts, defaults to all concepts\n      lang (str):\n        language of requested concepts, defaults to language from django\n    \"\"\"\n    user = get_user_id(request)\n    language = get_language(request)\n\n    concepts = None    # meaning all concept\n    if \"concepts\" in request.GET:\n        concepts = Concept.objects.filter(lang=language, active=True,\n                                          identifier__in=load_query_json(request.GET, \"concepts\"))\n    data = UserStat.objects.get_user_stats(user, language, concepts)\n    return render_json(request, data, template='concepts_json.html', help_text=user_stats.__doc__)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef user_stats_bulk(request):\n\n    language = get_language(request)\n    users = load_query_json(request.GET, \"users\")\n    if request.user.is_staff:\n        if not hasattr(request.user, 'userprofile') or User.objects.filter(pk__in=users,\n                       userprofile__classes__owner=request.user.userprofile).count() < len(users):\n            return render_json(request, {\n                'error': _('Some requested users are not in owned classes'),\n                'error_type': 'permission_denied'\n            }, template='concepts_json.html', status=401)\n    since = None\n    if 'since' in request.GET:\n        since = datetime.datetime.fromtimestamp(int(request.GET['since']))\n    concepts = None\n    if \"concepts\" in request.GET:\n        concepts = Concept.objects.filter(lang=language, active=True,\n                                          identifier__in=load_query_json(request.GET, \"concepts\"))\n    stats = UserStat.objects.get_user_stats(users, language, concepts=concepts, since=since)\n    data = {\"users\": []}\n    for user, s in stats.items():\n        data[\"users\"].append({\n            \"user_id\": user,\n            \"concepts\": s,\n        })\n    return render_json(request, data, template='concepts_json.html', help_text=user_stats_bulk.__doc__)", "response": "Get statistics for selected users and concepts"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef user_stats_api(request, provider):\n\n    if 'key' not in request.GET or provider not in settings.USER_STATS_API_KEY \\\n            or request.GET['key'] != settings.USER_STATS_API_KEY[provider]:\n        return HttpResponse('Unauthorized', status=401)\n    since = None\n    if 'since' in request.GET:\n        since = datetime.datetime.fromtimestamp(int(request.GET['since']))\n\n    social_users = list(UserSocialAuth.objects.filter(provider=provider).select_related('user'))\n    user_map = {u.user.id: u for u in social_users}\n    stats = UserStat.objects.get_user_stats([u.user for u in social_users], lang=None, since=since, recalculate=False)\n    data = {\"users\": []}\n    for user, s in stats.items():\n        data[\"users\"].append({\n            \"user_id\": user_map[user].uid,\n            \"concepts\": s,\n        })\n    return render_json(request, data, template='concepts_json.html', help_text=user_stats_bulk.__doc__)", "response": "Get statistics for selected Edookit users\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef tag_values(request):\n\n    data = defaultdict(lambda: {\"values\": {}})\n    for tag in Tag.objects.filter(lang=get_language(request)):\n        data[tag.type][\"name\"] = tag.type_name\n        data[tag.type][\"values\"][tag.value] = tag.value_name\n\n    return render_json(request, data, template='concepts_json.html', help_text=tag_values.__doc__)", "response": "Get tags types and values with localized names\n      language"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def send(self, card, msg):\n        addr = self.neighbors[card]\n        if addr is None:\n            return None\n        try:\n            r_agent = await self.env.connect(addr, timeout=10)\n            return await r_agent.rcv(msg)\n        except:\n            self._log(logging.WARNING, \"Could not connect to agent in {}:\\n{}\"\n                      .format(addr, traceback.format_exc()))\n        return None", "response": "Send a message to the neighboring agent in the given cardinal direction."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning True if the grid is fully populated with agents.", "response": "def is_full(self):\n        \"\"\":class:`GridEnvironment` is full when its **grid** is fully\n        populated with agents.\n\n        :returns:\n            True if the grid is full, False otherwise. Will also return False\n            for uninitialized grids with (0,0) grid size.\n        \"\"\"\n        if len(self.grid) == 0:\n            return False\n\n        for i in range(len(self.grid)):\n            for j in range(len(self.grid[0])):\n                if self.grid[i][j] is None:\n                    return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding an agent to the next available spot in the grid.", "response": "def add_to_grid(self, agent):\n        '''Add agent to the next available spot in the grid.\n\n        :returns:\n            (x,y) of the agent in the grid. This is the agent's overall\n            coordinate in the grand grid (i.e. the actual coordinate of the\n            agent w.t.r **origin**).\n\n        :raises: `ValueError` if the grid is full.\n        '''\n        for i in range(len(self.grid)):\n            for j in range(len(self.grid[0])):\n                if self.grid[i][j] is None:\n                    x = self.origin[0] + i\n                    y = self.origin[1] + j\n                    self.grid[i][j] = agent\n                    return (x, y)\n\n        raise ValueError(\"Trying to add an agent to a full grid.\"\n                         .format(len(self._grid[0]), len(self._grid[1])))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_xy(self, xy, addr=True):\n        x = xy[0]\n        y = xy[1]\n        if x < self.origin[0] or x >= self.origin[0] + self.gs[0]:\n            raise ValueError(\"x-coordinate inappropriate ({})\".format(x))\n        if y < self.origin[1] or y >= self.origin[1] + self.gs[1]:\n            raise ValueError(\"y-coordinate inappropriate ({})\".format(y))\n\n        i = x - self.origin[0]\n        j = y - self.origin[1]\n        if addr:\n            return self.grid[i][j].addr\n        return self.grid[i][j]", "response": "Get the agent with xy - coordinate in the environment s grid."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def set_agent_neighbors(self):\n        '''Set neighbors for each agent in each cardinal direction.\n\n        This method assumes that the neighboring :class:`GridEnvironment` of\n        this grid environment have already been set.\n        '''\n        for i in range(len(self.grid)):\n            for j in range(len(self.grid[0])):\n                agent = self.grid[i][j]\n                xy = (self.origin[0] + i, self.origin[1] + j)\n                nxy = _get_neighbor_xy('N', xy)\n                exy = _get_neighbor_xy('E', xy)\n                sxy = _get_neighbor_xy('S', xy)\n                wxy = _get_neighbor_xy('W', xy)\n                if j == 0:\n                    naddr = await self._get_xy_address_from_neighbor('N', nxy)\n                else:\n                    naddr = self.get_xy(nxy, addr=True)\n                if i == 0:\n                    waddr = await self._get_xy_address_from_neighbor('W', wxy)\n                else:\n                    waddr = self.get_xy(wxy, addr=True)\n                if j == len(self.grid[0]) - 1:\n                    saddr = await self._get_xy_address_from_neighbor('S', sxy)\n                else:\n                    saddr = self.get_xy(sxy, addr=True)\n                if i == len(self.grid) - 1:\n                    eaddr = await self._get_xy_address_from_neighbor('E', exy)\n                else:\n                    eaddr = self.get_xy(exy, addr=True)\n                agent.neighbors['N'] = naddr\n                agent.neighbors['E'] = eaddr\n                agent.neighbors['S'] = saddr\n                agent.neighbors['W'] = waddr", "response": "Set neighbors for each agent in each cardinal direction."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nspawn n agents to the managed environment.", "response": "async def spawn_n(self, agent_cls, n, *args, **kwargs):\n        '''Spawn *n* agents to the managed environment. This is a convenience\n        function so that one does not have to repeatedly make connections to\n        the environment to spawn multiple agents with the same parameters.\n\n        See :py:meth:`~creamas.mp.EnvManager.spawn` for details.\n        '''\n        rets = []\n        for _ in range(n):\n            ret = await self.spawn(agent_cls, *args, **kwargs)\n            rets.append(ret)\n        return rets"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def set_slave_params(self):\n        '''Set origin and grid size for each slave environment.\n\n        This method needs to be called before slave environments are populated\n        and agents' and slave environments' neighbors are set.\n        '''\n        self._slave_origins = []\n        cur_x = self.origin[0]\n        for addr in self.addrs:\n            new_origin = (cur_x, self.origin[1])\n            await self.set_origin(addr, new_origin)\n            await self.set_gs(addr, self._gs)\n            self._slave_origins.append((new_origin, addr))\n            new_x = cur_x + self.gs[0]\n            cur_x = new_x", "response": "Set origin and grid size for each slave environment."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the manager address for the environment which should have the agent with given xy coordinate.", "response": "def get_xy_environment(self, xy):\n        '''Get manager address for the environment which should have the agent\n        with given *xy* coordinate, or None if no such environment is in this\n        multi-environment.\n        '''\n        x = xy[0]\n        y = xy[1]\n        for origin, addr in self._slave_origins:\n            ox = origin[0]\n            oy = origin[1]\n            if ox <= x < ox + self.gs[0] and oy <= y < oy + self.gs[1]:\n                return addr\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def get_xy_address(self, xy):\n        '''Get address of the agent residing in *xy* coordinate, or ``None``\n        if no such agent is in this multi-environment.\n        '''\n        manager_addr = self.get_xy_environment(xy)\n        if manager_addr is None:\n            return None\n        else:\n            r_agent = await self._env.connect(manager_addr)\n            xy_addr = await r_agent.get_xy_address(xy)\n            return xy_addr", "response": "Get address of the agent residing in xy * coordinate or None if no such agent is in this multi - environment."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def set_slave_neighbors(self):\n        '''Set neighbor environments for all the slave environments. Assumes\n        that :attr:`neighbors` are set for this multi-environment.\n        '''\n        for i, elem in enumerate(self._slave_origins):\n            o, addr = elem\n            r_slave = await self.env.connect(addr)\n            nxy = _get_neighbor_xy('N', o)\n            exy = _get_neighbor_xy('E', (o[0] + self.gs[0] - 1, o[1]))\n            sxy = _get_neighbor_xy('S', (o[0], o[1] + self.gs[1] - 1))\n            wxy = _get_neighbor_xy('W', o)\n            if i == 0 and self.neighbors['W'] is not None:\n                m_addr = self.neighbors['W']\n                r_manager = await self.env.connect(m_addr)\n                n_addr = await r_manager.get_xy_environment(wxy)\n                await r_slave.set_grid_neighbor('W', n_addr)\n            elif i == self._n_slaves - 1 and self.neighbors['E'] is not None:\n                m_addr = self.neighbors['E']\n                r_manager = await self.env.connect(m_addr)\n                n_addr = await r_manager.get_xy_environment(exy)\n                await r_slave.set_grid_neighbor('E', n_addr)\n            else:\n                w_addr = self.get_xy_environment(wxy)\n                e_addr = self.get_xy_environment(exy)\n                await r_slave.set_grid_neighbor('W', w_addr)\n                await r_slave.set_grid_neighbor('E', e_addr)\n\n            if self.neighbors['N'] is not None:\n                m_addr = self.neighbors['N']\n                r_manager = await self.env.connect(m_addr)\n                n_addr = await r_manager.get_xy_environment(nxy)\n                await r_slave.set_grid_neighbor('N', n_addr)\n\n            if self.neighbors['S'] is not None:\n                m_addr = self.neighbors['S']\n                r_manager = await self.env.connect(m_addr)\n                n_addr = await r_manager.get_xy_environment(sxy)\n                await r_slave.set_grid_neighbor('S', n_addr)", "response": "Set neighbor environments for all the slave environments. Assumes that self. neighbors is set for this multi - environment."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def set_agent_neighbors(self):\n        '''Set neighbors for all the agents in all the slave environments.\n        Assumes that all the slave environments have their neighbors set.\n        '''\n        for addr in self.addrs:\n            r_manager = await self.env.connect(addr)\n            await r_manager.set_agent_neighbors()", "response": "Set neighbors for all the agents in all the slave environments."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\npopulates all the slave grid environments with agents. Assumes that agents have been spawned yet to the slave environment managers.", "response": "async def populate(self, agent_cls, *args, **kwargs):\n        '''Populate all the slave grid environments with agents. Assumes that\n        no agents have been spawned yet to the slave environment grids. This\n        excludes the slave environment managers as they are not in the grids.)\n        '''\n        n = self.gs[0] * self.gs[1]\n        tasks = []\n        for addr in self.addrs:\n            task = asyncio.ensure_future(self._populate_slave(addr, agent_cls,\n                                                              n, *args,\n                                                              **kwargs))\n            tasks.append(task)\n        rets = await asyncio.gather(*tasks)\n        return rets"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting originating coordinates for the which manager is in given address.", "response": "async def set_origin(self, mgr_addr, origin):\n        '''Set originating coordinates for :py:class:`GridEnvironment` which\n        manager is in given address.\n\n        :param str mgr_addr: Address of the manager agent\n\n        :param origin:\n            New origin of the grid environment, iterable with length 2.\n        '''\n        remote_manager = await self.env.connect(mgr_addr)\n        await remote_manager.set_origin(origin)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def set_gs(self, mgr_addr, gs):\n        '''Set grid size for :py:class:`GridEnvironment` which manager is in\n        given address.\n\n        :param str mgr_addr: Address of the manager agent\n\n        :param gs:\n            New grid size of the grid environment, iterable with length 2.\n        '''\n        remote_manager = await self.env.connect(mgr_addr)\n        await remote_manager.set_gs(gs)", "response": "Set the grid size for the manager in manager_addr."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates the reST documentation files for the JavaScript code.", "response": "def generate_docs(app):\n    \"\"\" Generate the reST documentation files for the JavaScript code \"\"\"\n    # Figure out the correct directories to use\n    config = app.config\n    config_dir = app.env.srcdir\n    javascript_root = os.path.join(config_dir, config.jsdoc_source_root)\n    if javascript_root[-1] != os.path.sep:\n        javascript_root += os.path.sep\n    if not javascript_root:\n        return\n    output_root = os.path.join(config_dir, config.jsdoc_output_root)\n    execution_dir = os.path.join(config_dir, '..')\n    exclude = config.jsdoc_exclude\n\n    # Remove any files generated by earlier builds\n    cleanup(output_root)\n\n    # Generate the actual reST files\n    jsdoc_toolkit_dir = os.path.join(SOURCE_PATH, 'jsdoc-toolkit')\n    jsdoc_rst_dir = os.path.join(SOURCE_PATH, 'jsdoc-toolkit-rst-template')\n    build_xml_path = os.path.join(jsdoc_rst_dir, 'build.xml')\n    command = ['ant', '-f', build_xml_path,\n               '-Djsdoc-toolkit.dir=%s' % jsdoc_toolkit_dir,\n               '-Djs.src.dir=%s' % javascript_root,\n               '-Djs.rst.dir=%s' % output_root]\n    if exclude:\n        exclude_args = ['--exclude=\\\\\"%s\\\\\"' % path for path in exclude]\n        command.append('-Djs.exclude=\"%s\"' % ' '.join(exclude_args))\n    try:\n        process = Popen(command, cwd=execution_dir)\n        process.wait()\n    except OSError:\n        raise JSDocError('Error running ant; is it installed?')\n\n    # Convert the absolute paths in the file listing to relative ones\n    path = os.path.join(output_root, 'files.rst')\n    with open(path, 'r') as f:\n        content = f.read()\n    content = content.replace(javascript_root, '')\n    with open(path, 'w') as f:\n        f.write(content)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef print_validation_errors(result):\n    click.echo(red('\\nValidation failed:'))\n    click.echo(red('-' * 40))\n    messages = result.get_messages()\n    for property in messages.keys():\n        click.echo(yellow(property + ':'))\n        for error in messages[property]:\n            click.echo(red('* ' + error))\n        click.echo('')", "response": "Prints validation errors to the console."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_user(search_params):\n    user = None\n    params = {prop: value for prop, value in search_params.items() if value}\n    if 'id' in params or 'email' in params:\n        user = user_service.first(**params)\n    return user", "response": "Finds a user by a set of search params."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create(email, password):\n    with get_app().app_context():\n        user = User(email=email, password=password)\n        result = user_service.save(user)\n        if not isinstance(result, User):\n            print_validation_errors(result)\n            return\n\n        click.echo(green('\\nUser created:'))\n        click.echo(green('-' * 40))\n        click.echo(str(user) + '\\n')", "response": "Create a new user record"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfinds user by id or email", "response": "def find(*_, **kwargs):\n    \"\"\" Find user by id/email\"\"\"\n    click.echo(green('\\nFind user:'))\n    click.echo(green('-' * 40))\n\n    with get_app().app_context():\n        user = find_user(kwargs)\n\n    if not user:\n        click.echo(red('Not found\\n'))\n        return\n\n    click.echo(str(user) + '\\n')\n    return"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchanges email for a user", "response": "def change_email(*_, user_id=None, new_email=None):\n    \"\"\" Change email for a user \"\"\"\n    click.echo(green('\\nChange email:'))\n    click.echo(green('-' * 40))\n\n    with get_app().app_context():\n        user = find_user(dict(id=user_id))\n        if not user:\n            click.echo(red('User not found\\n'))\n            return\n\n        user.email = new_email\n        result = user_service.save(user)\n        if not isinstance(result, User):\n            print_validation_errors(result)\n            return\n\n        user.confirm_email()\n        user_service.save(user)\n        msg = 'Change email for user {} to {} \\n'\n        click.echo(green(msg.format(user.email, new_email)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_role(*_, role_handle=None, user_id=None):\n    click.echo(green('\\nAdding role to user:'))\n    click.echo(green('-' * 40))\n    with get_app().app_context():\n        user = find_user(dict(id=user_id))\n        if not user:\n            click.echo(red('User not found\\n'))\n            return\n\n        role = role_service.first(handle=role_handle)\n        if not role:\n            click.echo(red('No such role ({})\\n'.format(role_handle)))\n            return\n\n        user_service.add_role_to_user(user, role)\n        msg = 'Added role \"{}\" to user \"{}\"'.format(role.handle, user.email)\n        click.echo(green(msg))\n        return", "response": "Add a role to a user"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nremoves a role from a user", "response": "def remove_role(*_, role_handle=None, user_id=None):\n    \"\"\" Remove role from user \"\"\"\n    click.echo(green('\\nRemoving role from user:'))\n    click.echo(green('-' * 40))\n    with get_app().app_context():\n        user = find_user(dict(id=user_id))\n        if not user:\n            click.echo(red('User not found\\n'))\n            return\n\n        remove_role = None\n        for role in user.roles:\n            if role.handle == role_handle:\n                remove_role = role\n\n        if not remove_role:\n            click.echo(red('User does not have such role\\n'))\n            return\n\n        user_service.remove_role_from_user(user, remove_role)\n        msg = 'Role \"{}\" removed from user \"{}\"\\n'.format(\n            remove_role.handle,\n            user.email\n        )\n        click.echo(green(msg))\n        return"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates an object with current info.", "response": "async def update(self):\n        '''Update an object with current info.'''\n        if self.client.session.closed:\n            async with core.Client() as client:\n                data = await client.request(self.url)\n        else:\n            data = await self.client.request(self.url)\n\n        self.raw_data = data\n        self.from_data(data)\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef clan_badge_url(self):\n        '''Returns clan badge url'''\n        if self.clan_tag is None:\n            return None\n        url = self.raw_data.get('clan').get('badge').get('url')\n        if not url:\n            return None\n        return \"http://api.cr-api.com\" + url", "response": "Returns clan badge url"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_chest(self, index=0):\n        '''Get your current chest +- the index'''\n        \n        index += self.chest_cycle.position\n\n        if index == self.chest_cycle.super_magical:\n            return 'Super Magical'\n        if index == self.chest_cycle.epic:\n            return 'Epic'\n        if index == self.chest_cycle.legendary:\n            return 'Legendary'\n\n        return CHESTS[index % len(CHESTS)]", "response": "Get your current chest + - the index"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nexecute init tasks for all components.", "response": "def init():\n    \"\"\"Execute init tasks for all components (virtualenv, pip).\"\"\"\n    if not os.path.isdir('venv'):\n        print(cyan('\\nCreating the virtual env...'))\n\n        local('pyvenv-3.4 venv')\n\n        print(green('Virtual env created.'))\n\n    print(green('Virtual Environment ready.'))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update():\n    with settings(warn_only=True):\n        print(cyan('\\nInstalling/Updating required packages...'))\n\n        pip = local('venv/bin/pip install -U --allow-all-external --src libs -r requirements.txt', capture=True)\n        if pip.failed:\n            print(red(pip))\n            abort(\"pip exited with return code %i\" % pip.return_code)\n\n        print(green('Packages requirements updated.'))", "response": "Update virtual env with requirements packages."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _detect_devices(self) -> None:\n        '''Detect whether devices connected.'''\n        devices_num = len(self.devices_list)\n        if devices_num == 0:\n            raise DeviceConnectionException(\n                'No devices are connected. Please connect the device with USB or via WLAN and turn on the USB debugging option.')\n        elif not self.device_sn and devices_num > 1:\n            raise DeviceConnectionException(\n                f\"Multiple devices detected: {' | '.join(self.devices_list)}, please specify device serial number or host.\")\n        else:\n            self.device_sn = self.devices_list[0]\n        if self.get_state() == 'offline':\n            raise DeviceConnectionException(\n                'The device is offline. Please reconnect.')", "response": "Detect whether devices connected."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nshow device battery information.", "response": "def get_battery_info(self) -> dict:\n        '''Show device battery information.\n\n        Returns:\n            A dict. For example:\n\n                {'AC powered': 'false',\n                'Charge counter': '0',\n                'Max charging current': '0',\n                'Max charging voltage': '0',\n                'USB powered': 'false',\n                'Wireless powered': 'false',\n                'health': '2',\n                'level': '67',\n                'present': 'true',\n                'scale': '100',\n                'status': '3',\n                'technology': 'Li-poly',\n                'temperature': '310',\n                'voltage': '3965'}\n        '''\n        output, _ = self._execute(\n            '-s', self.device_sn, 'shell', 'dumpsys', 'battery')\n        battery_status = re.split('\\n  |: ', output[33:].strip())\n        return dict(zip(battery_status[::2], battery_status[1::2]))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_screen_density(self) -> str:\n        '''Show device screen density (PPI).'''\n        output, _ = self._execute(\n            '-s', self.device_sn, 'shell', 'wm', 'density')\n        return output.split()[2]", "response": "Show device screen density ( PPI).'"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_cpu_info(self) -> str:\n        '''Show device CPU information.'''\n        output, _ = self._execute(\n            '-s', self.device_sn, 'shell', 'cat', '/proc/cpuinfo')\n        return output", "response": "Show device CPU information."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nshows device memory information.", "response": "def get_memory_info(self) -> str:\n        '''Show device memory information.'''\n        output, _ = self._execute(\n            '-s', self.device_sn, 'shell', 'cat', '/proc/meminfo')\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nshow Android SDK version.", "response": "def get_sdk_version(self) -> str:\n        '''Show Android SDK version.'''\n        output, _ = self._execute(\n            '-s', self.device_sn, 'shell', 'getprop', 'ro.build.version.sdk')\n        return output.strip()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef root(self) -> None:\n        '''Restart adbd with root permissions.'''\n        output, _ = self._execute('-s', self.device_sn, 'root')\n        if not output:\n            raise PermissionError(\n                f'{self.device_sn!r} does not have root permission.')", "response": "Restart adbd with root permissions."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef tcpip(self, port: int or str = 5555) -> None:\n        '''Restart adb server listening on TCP on PORT.'''\n        self._execute('-s', self.device_sn, 'tcpip', str(port))", "response": "Restart adb server listening on TCP on PORT."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef auto_connect(self, port: int or str =5555) -> None:\n        '''Connect to a device via TCP/IP automatically.'''\n        host = self.get_ip_addr()\n        self.tcpip(port)\n        self.connect(host, port)\n        print('Now you can unplug the USB cable, and control your device via WLAN.')", "response": "Connect to a device via TCP or IP automatically."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncopy local files to device.", "response": "def push(self, local: _PATH = 'LICENSE', remote: _PATH = '/sdcard/LICENSE') -> None:\n        '''Copy local files/directories to device.'''\n        if not os.path.exists(local):\n            raise FileNotFoundError(f'Local {local!r} does not exist.')\n        self._execute('-s', self.device_sn, 'push', local, remote)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pull(self, remote: _PATH, local: _PATH) -> None:\n        '''Copy files/directories from device.'''\n        output, _ = self._execute('-s', self.device_sn, 'pull', remote, local)\n        if 'error' in output:\n            raise FileNotFoundError(f'Remote {remote!r} does not exist.')", "response": "Copy files and directories from device."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nlisting but don t copy.", "response": "def sync_l(self, option: str = 'all') -> None:\n        '''List but don't copy.\n\n        Args:\n            option: 'system', 'vendor', 'oem', 'data', 'all'\n        '''\n        if option in ['system', 'vendor', 'oem', 'data', 'all']:\n            self._execute('-s', self.device_sn, 'sync', '-l', option)\n        else:\n            raise ValueError('There is no option named: {!r}.'.format(option))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\npushes package to the device and install it.", "response": "def install(self, package: str, option: str = '-r') -> None:\n        '''Push package to the device and install it.\n\n        Args:\n            option:\n                -l: forward lock application\n                -r: replace existing application\n                -t: allow test packages\n                -s: install application on sdcard\n                -d: allow version code downgrade (debuggable packages only)\n                -g: grant all runtime permissions\n        '''\n        if not os.path.isfile(package):\n            raise FileNotFoundError(f'{package!r} does not exist.')\n        for i in option:\n            if i not in '-lrtsdg':\n                raise ValueError(f'There is no option named: {option!r}.')\n        self._execute('-s', self.device_sn, 'install', option, package)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef uninstall(self, package: str) -> None:\n        '''Remove this app package from the device.'''\n        if package not in self.view_packgets_list():\n            raise NoSuchPackageException(\n                f'There is no such package {package!r}.')\n        self._execute('-s', self.device_sn, 'uninstall', package)", "response": "Remove this app package from the device."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nshow all packages. Args: option: -f see their associated file -d filter to only show disabled packages -e filter to only show enabled packages -s filter to only show system packages -3 filter to only show third party packages -i see the installer for the packages -u also include uninstalled packages -keyword: optionally only those whose name contains the text in keyword", "response": "def view_packgets_list(self, option: str = '-e', keyword: str = '') -> list:\n        '''Show all packages.\n\n        Args:\n            option:\n                -f see their associated file\n                -d filter to only show disabled packages\n                -e filter to only show enabled packages\n                -s filter to only show system packages\n                -3 filter to only show third party packages\n                -i see the installer for the packages\n                -u also include uninstalled packages\n                -keyword: optionally only those whose name contains the text in keyword\n        '''\n        if option not in ['-f', '-d', '-e', '-s', '-3', '-i', '-u']:\n            raise ValueError(f'There is no option called {option!r}.')\n        output, _ = self._execute(\n            '-s', self.device_sn, 'shell', 'pm', 'list', 'packages', option, keyword)\n        return list(map(lambda x: x[8:], output.splitlines()))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef view_package_path(self, package: str) -> _PATH:\n        '''Print the path to the APK of the given.'''\n        if package not in self.view_packgets_list():\n            raise NoSuchPackageException(\n                f'There is no such package {package!r}.')\n        output, _ = self._execute(\n            '-s', self.device_sn, 'shell', 'pm', 'path', package)\n        return output[8:-1]", "response": "Print the path to the APK of the given."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nviewing package detail information.", "response": "def view_package_info(self, package: str='') -> str:\n        '''View package detail information.'''\n        output, _ = self._execute(\n            '-s', self.device_sn, 'shell', 'dumpsys', 'package', package)\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef view_current_app_behavior(self) -> str:\n        '''View application behavior in the current window.'''\n        output, _ = self._execute(\n            '-s', self.device_sn, 'shell', 'dumpsys', 'window', 'windows')\n        return re.findall(r'mCurrentFocus=.+(com[a-zA-Z0-9\\.]+/.[a-zA-Z0-9\\.]+)', output)[0]", "response": "View application behavior in the current window."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef view_surface_app_activity(self) -> str:\n        '''Get package with activity of applications that are running in the foreground.'''\n        output, error = self._execute(\n            '-s', self.device_sn, 'shell', 'dumpsys', 'window', 'w')\n        return re.findall(r\"name=([a-zA-Z0-9\\.]+/.[a-zA-Z0-9\\.]+)\", output)", "response": "Get package with activity of applications that are running in the foreground."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntrimming memory. Args: level: HIDDEN | RUNNING_MODERATE | BACKGROUNDRUNNING_LOW | \\ MODERATE | RUNNING_CRITICAL | COMPLETE", "response": "def app_trim_memory(self, pid: int or str, level: str = 'RUNNING_LOW') -> None:\n        '''Trim memory.\n\n        Args:\n            level: HIDDEN | RUNNING_MODERATE | BACKGROUNDRUNNING_LOW | \\\n                     MODERATE | RUNNING_CRITICAL | COMPLETE\n        '''\n        _, error = self._execute('-s', self.device_sn, 'shell',\n                                 'am', 'send-trim-memory', str(pid), level)\n        if error and error.startswith('Error'):\n            raise ApplicationsException(error.split(':', 1)[-1].strip())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef app_start_up_time(self, package: str) -> str:\n        '''Get the time it took to launch your application.'''\n        output, _ = self._execute(\n            '-s', self.device_sn, 'shell', 'am', 'start', '-W', package)\n        return re.findall('TotalTime: \\d+', output)[0]", "response": "Get the time it took to launch your application."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pull_screencap(self, remote: _PATH = '/sdcard/screencap.png', local: _PATH = 'screencap.png') -> None:\n        '''Taking a screenshot of a device display, then copy it to your computer.'''\n        self.screencap(remote)\n        self.pull(remote, local)", "response": "Pulls a screenshot of a device display then copies it to your computer."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntakes a screenshot of a device display then copy it to your computer.", "response": "def screencap_exec(self, filename: _PATH = 'screencap.png') -> None:\n        '''Taking a screenshot of a device display, then copy it to your computer.'''\n        self._execute('-s', self.device_sn, 'exec-out',\n                      'screencap', '-p', '>', filename, shell=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrecord the display of devices running Android 4. 4 and higher.", "response": "def screenrecord(self, bit_rate: int = 5000000, time_limit: int = 180, filename: _PATH = '/sdcard/demo.mp4') -> None:\n        '''Recording the display of devices running Android 4.4 (API level 19) and higher.\n\n        Args:\n            bit_rate:You can increase the bit rate to improve video quality, but doing so results in larger movie files.\n            time_limit: Sets the maximum recording time, in seconds, and the maximum value is 180 (3 minutes).\n        '''\n        self._execute('-s', self.device_sn, 'shell',\n                      'screenrecord', '--bit-rate', str(bit_rate), '--time-limit', str(time_limit), filename)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pull_screenrecord(self, bit_rate: int = 5000000, time_limit: int = 180, remote: _PATH = '/sdcard/demo.mp4', local: _PATH = 'demo.mp4') -> None:\n        '''Recording the display of devices running Android 4.4 (API level 19) and higher. Then copy it to your computer.\n\n        Args:\n            bit_rate:You can increase the bit rate to improve video quality, but doing so results in larger movie files.\n            time_limit: Sets the maximum recording time, in seconds, and the maximum value is 180 (3 minutes).\n        '''\n        self.screenrecord(bit_rate, time_limit, filename=remote)\n        self.pull(remote, local)", "response": "Pulls a screenrecord from the remote computer to the local computer."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef swipe(self, x1: int, y1: int, x2: int, y2: int, duration: int = 100) -> None:\n        '''Simulate finger swipe. (1000ms = 1s)'''\n        self._execute('-s', self.device_sn, 'shell',\n                      'input', 'swipe', str(x1), str(y1), str(x2), str(y2), str(duration))", "response": "Simulate finger swipe. (1000ms = 1s)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef long_press(self, x: int, y: int, duration: int = 1000) -> None:\n        '''Simulate finger long press somewhere. (1000ms = 1s)'''\n        self._execute('-s', self.device_sn, 'shell',\n                      'input', 'swipe', str(x), str(y), str(x), str(y), str(duration))", "response": "Simulate finger long press somewhere."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsimulating typing keyevents long press.", "response": "def send_keyevents_long_press(self, keyevent: int) -> None:\n        '''Simulates typing keyevents long press.'''\n        self._execute('-s', self.device_sn, 'shell',\n                      'input', 'keyevent', '--longpress', str(keyevent))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef uidump(self, local: _PATH = None) -> None:\n        '''Get the current interface layout file.'''\n        local = local if local else self._temp\n        self._execute('-s', self.device_sn, 'shell', 'uiautomator',\n                      'dump', '--compressed', '/data/local/tmp/uidump.xml')\n        self.pull('/data/local/tmp/uidump.xml', local)\n        ui = html.fromstring(open(local, 'rb').read())\n        self._nodes = ui.iter(tag=\"node\")", "response": "Get the current interface layout file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef find_element(self, value, by=By.ID, update=False) -> Elements:\n        '''Find a element or the first element.'''\n        if update or not self._nodes:\n            self.uidump()\n        for node in self._nodes:\n            if node.attrib[by] == value:\n                bounds = node.attrib['bounds']\n                coord = list(map(int, re.findall(r'\\d+', bounds)))\n                click_point = (coord[0] + coord[2]) / \\\n                    2, (coord[1] + coord[3]) / 2\n                return self._element_cls(self, node.attrib, by, value, coord, click_point)\n        raise NoSuchElementException(f'No such element: {by}={value!r}.')", "response": "Find a element or the first element."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding an element by id.", "response": "def find_element_by_id(self, id_, update=False) -> Elements:\n        '''Finds an element by id.\n\n        Args:\n            id_: The id of the element to be found.\n            update: If the interface has changed, this option should be True.\n\n        Returns:\n            The element if it was found.\n\n        Raises:\n            NoSuchElementException - If the element wasn't found.\n\n        Usage:\n            element = driver.find_element_by_id('foo')\n        '''\n        return self.find_element(by=By.ID, value=id_, update=update)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find_elements_by_id(self, id_, update=False) -> Elements:\n        '''Finds multiple elements by id.\n\n        Args:\n            id_: The id of the elements to be found.\n            update: If the interface has changed, this option should be True.\n\n        Returns:\n            A list with elements if any was found. An empty list if not.\n\n        Raises:\n            NoSuchElementException - If the element wasn't found.\n\n        Usage:\n            elements = driver.find_elements_by_id('foo')\n        '''\n        return self.find_elements(by=By.ID, value=id_, update=update)", "response": "Finds multiple elements by id."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_element_by_name(self, name, update=False) -> Elements:\n        '''Finds an element by name.\n\n        Args:\n            name: The name of the element to be found.\n            update: If the interface has changed, this option should be True.\n\n        Returns:\n            The element if it was found.\n\n        Raises:\n            NoSuchElementException - If the element wasn't found.\n\n        Usage:\n            element = driver.find_element_by_name('foo')\n        '''\n        return self.find_element(by=By.NAME, value=name, update=update)", "response": "Finds an element by name."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find_elements_by_name(self, name, update=False) -> Elements:\n        '''Finds multiple elements by name.\n\n        Args:\n            name: The name of the elements to be found.\n            update: If the interface has changed, this option should be True.\n\n        Returns:\n            A list with elements if any was found. An empty list if not.\n\n        Raises:\n            NoSuchElementException - If the element wasn't found.\n\n        Usage:\n            elements = driver.find_elements_by_name('foo')\n        '''\n        return self.find_elements(by=By.NAME, value=name, update=update)", "response": "Finds multiple elements by name."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding an element by class.", "response": "def find_element_by_class(self, class_, update=False) -> Elements:\n        '''Finds an element by class.\n\n        Args:\n            class_: The class of the element to be found.\n            update: If the interface has changed, this option should be True.\n\n        Returns:\n            The element if it was found.\n\n        Raises:\n            NoSuchElementException - If the element wasn't found.\n\n        Usage:\n            element = driver.find_element_by_class('foo')\n        '''\n        return self.find_element(by=By.CLASS, value=class_, update=update)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef find_elements_by_class(self, class_, update=False) -> Elements:\n        '''Finds multiple elements by class.\n\n        Args:\n            class_: The class of the elements to be found.\n            update: If the interface has changed, this option should be True.\n\n        Returns:\n            A list with elements if any was found. An empty list if not.\n\n        Raises:\n            NoSuchElementException - If the element wasn't found.\n\n        Usage:\n            elements = driver.find_elements_by_class('foo')\n        '''\n        return self.find_elements(by=By.CLASS, value=class_, update=update)", "response": "Finds multiple elements by class."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef swipe_right(self, width: int = 1080, length: int = 1920) -> None:\n        '''Swipe right.'''\n        self.swipe(0.2*width, 0.5*length, 0.8*width, 0.5*length)", "response": "Swipe to the right."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nregistering the class with the app.", "response": "def _register(cls, app, **kwargs):\n        \"\"\" Reset some params \"\"\"\n\n        # nav\n        nav = __options__.get(\"nav\", {})\n        nav.setdefault(\"title\", \"Contact\")\n        nav.setdefault(\"visible\", True)\n        nav.setdefault(\"order\", 100)\n        title = nav.pop(\"title\")\n        render.nav.add(title, cls.page, **nav)\n\n        # route\n        kwargs[\"base_route\"] = __options__.get(\"route\", \"/contact/\")\n\n        # App Option\n        data = {\n            \"recipients\": __options__.get(\"recipients\"),\n            \"success_message\": __options__.get(\"success_message\",\n                                               \"Message sent. Thanks!\")\n        }\n\n        @app.before_first_request\n        def setup():\n            if db._IS_OK_:\n                try:\n                    app_data.set(APP_DATA_KEY, data, init=True)\n                except Exception as ex:\n                    logging.fatal(\"mocha.contrib.app_data has not been setup. Need to run `mocha :dbsync`\")\n                    abort(500)\n\n        # Call the register\n        super(cls, cls)._register(app, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nclasses decorator to generate all six rich comparison methods, based on a ``__key__`` method. Many simple classes are wrappers for very simple data, and want to defer comparisons to that data. Rich comparison is very flexible and powerful, but makes this simple case tedious to set up. There's the standard library's ``total_ordering`` decorator, but it still requires you to write essentially the same method twice, and doesn't correctly handle ``NotImplemented`` before 3.4. It also doesn't automatically generate ``__ne__`` from ``__eq__``, which is a common gotcha. With this decorator, comparisons will be done on the return value of ``__key__``, in much the same way as the ``key`` argument to ``sorted``. For example, if you have a class representing a span of time: .. code-block:: python @keyed_ordering class TimeSpan(object): def __init__(self, start, end): self.start = start self.end = end def __key__(self): return (self.start, self.end) This is equivalent to the following, assuming 3.4's ``total_ordering``: .. code-block:: python @total_ordering class TimeSpan(object): def __init__(self, start, end): self.start = start self.end = end def __eq__(self, other): if not isinstance(other, TimeSpan): return NotImplemented return (self.start, self.end) == (other.start, other.end) def __ne__(self, other): if not isinstance(other, TimeSpan): return NotImplemented return (self.start, self.end) != (other.start, other.end) def __lt__(self, other): if not isinstance(other, TimeSpan): return NotImplemented return (self.start, self.end) < (other.start, other.end) The ``NotImplemented`` check is based on the class being decorated, so subclassses can still be correctly compared. You may also implement some of the rich comparison methods in the decorated class, in which case they'll be left alone.", "response": "def keyed_ordering(cls):\n    \"\"\"Class decorator to generate all six rich comparison methods, based on a\n    ``__key__`` method.\n\n    Many simple classes are wrappers for very simple data, and want to defer\n    comparisons to that data.  Rich comparison is very flexible and powerful,\n    but makes this simple case tedious to set up.  There's the standard\n    library's ``total_ordering`` decorator, but it still requires you to write\n    essentially the same method twice, and doesn't correctly handle\n    ``NotImplemented`` before 3.4.  It also doesn't automatically generate\n    ``__ne__`` from ``__eq__``, which is a common gotcha.\n\n    With this decorator, comparisons will be done on the return value of\n    ``__key__``, in much the same way as the ``key`` argument to ``sorted``.\n    For example, if you have a class representing a span of time:\n\n    .. code-block:: python\n\n        @keyed_ordering\n        class TimeSpan(object):\n            def __init__(self, start, end):\n                self.start = start\n                self.end = end\n\n            def __key__(self):\n                return (self.start, self.end)\n\n    This is equivalent to the following, assuming 3.4's ``total_ordering``:\n\n    .. code-block:: python\n\n        @total_ordering\n        class TimeSpan(object):\n            def __init__(self, start, end):\n                self.start = start\n                self.end = end\n\n            def __eq__(self, other):\n                if not isinstance(other, TimeSpan):\n                    return NotImplemented\n                return (self.start, self.end) == (other.start, other.end)\n\n            def __ne__(self, other):\n                if not isinstance(other, TimeSpan):\n                    return NotImplemented\n                return (self.start, self.end) != (other.start, other.end)\n\n            def __lt__(self, other):\n                if not isinstance(other, TimeSpan):\n                    return NotImplemented\n                return (self.start, self.end) < (other.start, other.end)\n\n    The ``NotImplemented`` check is based on the class being decorated, so\n    subclassses can still be correctly compared.\n\n    You may also implement some of the rich comparison methods in the decorated\n    class, in which case they'll be left alone.\n    \"\"\"\n    if '__key__' not in cls.__dict__:\n        raise TypeError(\"keyed_ordering requires a __key__ method\")\n\n    for name in ('__eq__', '__ne__', '__lt__', '__gt__', '__le__', '__ge__'):\n        if name in cls.__dict__:\n            continue\n        method = _keyed_ordering_impl(name, cls)\n        setattr(cls, name, method)\n\n    return cls"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef login_required(func):\n    if inspect.isclass(func):\n        apply_function_to_members(func, login_required)\n        return func\n    else:\n        @functools.wraps(func)\n        def decorated_view(*args, **kwargs):\n            if \"login_not_required\" not in utils.get_decorators_list(func) \\\n                    and not_authenticated():\n                return login_manager.unauthorized()\n            return func(*args, **kwargs)\n\n        return decorated_view", "response": "Decorator to mark a view as login_required."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef login_not_required(func):\n\n    @functools.wraps(func)\n    def decorated_view(*args, **kwargs):\n        return func(*args, **kwargs)\n\n    return decorated_view", "response": "Decorator to make sure that login is not required"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef logout_user(f):\n\n    @functools.wraps(f)\n    def deco(*a, **kw):\n        signals.user_logout(lambda: flask_login.current_user)\n        flask_login.logout_user()\n        return f(*a, **kw)\n\n    return deco", "response": "Decorator to logout user\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef require_login_allowed(f):\n\n    @functools.wraps(f)\n    def deco(*a, **kw):\n        if not __options__.get(\"allow_login\"):\n            abort(403, \"Login not allowed. Contact admin if it's a mistake\")\n        return f(*a, **kw)\n\n    return deco", "response": "Decorator to abort if login is not allowed."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking if the Authorization barer exists. Otherwise throw 401 :param func: :return:", "response": "def jwt_required(func):\n    \"\"\"\n    Checks if the Authorization barer exists. Otherwise throw 401\n    :param func:\n    :return:\n    \"\"\"\n    if inspect.isclass(func):\n        apply_function_to_members(func, jwt_required)\n        return func\n    else:\n        @functools.wraps(func)\n        def deco(*a, **kw):\n            if not \"Authorization\" in request.headers:\n                abort(401, \"Not Authorized\")\n            return func(*a, **kw)\n\n        return deco"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntaking in an RGB color in 6 - character hexadecimal with an optional preceding hash character. Returns the RGB color in the same format adjusted by the second parameter.", "response": "def saturateHexColor(hexcolor, adjustment = 1.0):\n\t'''Takes in an RGB color in 6-character hexadecimal with an optional preceding hash character.\n\t   Returns the RGB color in the same format adjusted by saturation by the second parameter.'''\n\tassert(adjustment >= 0 and len(hexcolor) >= 1)\n\tprefix = \"\"\n\tif hexcolor[0] == '#':\n\t\thexcolor = hexcolor[1:]\n\t\tprefix = \"#\"\n\tassert(len(hexcolor) == 6)\n\t\n\tif adjustment == 1.0:\n\t\treturn \"%s%s\" % (prefix, hexcolor)\n\telse:\n\t\thsvColor = list(colorsys.rgb_to_hsv(int(hexcolor[0:2], 16)/255.0, int(hexcolor[2:4], 16)/255.0, int(hexcolor[4:6], 16)/255.0))\n\t\thsvColor[1] = min(1.0, hsvColor[1] * adjustment)\n\t\trgbColor = [min(255, 255 * v) for v in colorsys.hsv_to_rgb(hsvColor[0], hsvColor[1], hsvColor[2])]\n\t\treturn \"%s%.2x%.2x%.2x\" % (prefix, rgbColor[0], rgbColor[1], rgbColor[2])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def get_profile(self, *tags):\n        '''Get a profile object using tag(s)'''\n        url = '{0.BASE}/profile/{1}'.format(self, ','.join(tags))\n\n        data = await self.request(url)\n                \n        if isinstance(data, list):\n            return [Profile(self, c) for c in data]\n        else:\n            return Profile(self, data)", "response": "Get a profile object using tag list"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting a clan object using tag ( s )", "response": "async def get_clan(self, *tags):\n        '''Get a clan object using tag(s)'''\n        url = '{0.BASE}/clan/{1}'.format(self, ','.join(tags))\n\n        data = await self.request(url)\n                \n        if isinstance(data, list):\n            return [Clan(self, c) for c in data]\n        else:\n            return Clan(self, data)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def get_constants(self):\n        '''Get clash royale constants.'''\n        url = self.BASE + '/constants'\n\n        data = await self.request(url)\n\n        return Constants(self, data)", "response": "Get clash royale constants."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a list of top clans info is only brief", "response": "async def get_top_clans(self):\n        '''Get a list of top clans, info is only brief, \n        call get_clan() on each of the ClanInfo objects \n        to get full clan info'''\n        url = self.BASE + '/top/clans'\n\n        data = await self.request(url)\n\n        return [ClanInfo(self, c) for c in data.get('clans')]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the URL of the current list with the given model field value.", "response": "def get_list_url_filtered_by_field_value(view, model, name, reverse=False):\n    \"\"\"Get the URL if a filter of model[name] value was appended.\n\n    This allows programatically adding filters. This is used in the specialized case\n    of filtering deeper into a list by a field's value.\n\n    For instance, since there can be multiple assignments in a list of handins. The\n    assignment column can have a URL generated by get_filter_url to filter the handins\n    to show only ones for that assignment.\n\n    Parameters\n    ----------\n    view : View instance\n    model : document (model instance, not the class itself)\n    name : field name\n    reverse : bool\n        Whether to *remove* an applied filter from url\n\n    Returns\n    -------\n    string : URL of current list args + filtering on field value\n    \"\"\"\n\n    view_args = view._get_list_extra_args()\n\n    def create_filter_arg(field_name, value):\n        i, flt = next(\n            (\n                v\n                for k, v in view._filter_args.items()\n                if k == '{}_equals'.format(field_name)\n            ),\n            None,\n        )\n        return (i, flt.name, value)\n\n    new_filter = create_filter_arg(name, model[name])\n    filters = view_args.filters\n\n    if new_filter in view_args.filters:  # Filter already applied\n        if not reverse:\n            return None\n        else:  # Remove filter\n            filters.remove(new_filter)\n\n    if not reverse:  # Add Filter\n        filters.append(new_filter)\n\n    # Example of an activated filter: (u'view_args.filters', [(7, u'Path', u'course')])\n    return view._get_list_url(\n        view_args.clone(filters=filters, page=0)  # Reset page to 0\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef search_relative_field(model_class, fields, term):\n    offset = 0\n    limit = 500\n    query = model_class.objects\n\n    criteria = None\n\n    # If an ObjectId pattern, see if we can get an instant lookup.\n    if re.match(RE_OBJECTID, term):\n        q = query.filter(id=bson.ObjectId(term)).only('id')\n        if q.count() == 1:  # Note: .get doesn't work, they need a QuerySet\n            return q\n\n    for field in fields:\n        flt = {u'%s__icontains' % field: term}\n\n        if not criteria:\n            criteria = mongoengine.Q(**flt)\n        else:\n            criteria |= mongoengine.Q(**flt)\n\n    query = query.filter(criteria)\n\n    if offset:\n        query = query.skip(offset)\n\n    return query.limit(limit).only('id').all()", "response": "Searches a ReferenceField s fields returning a list of IDs to be used in __in\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pack_turret(turret, temp_files, base_config_path, path=None):\n    file_name = turret['name']\n    files = temp_files[:]\n    for fname in turret.get('extra_files', []):\n        if os.path.isabs(fname) or path is None:\n            files.append(fname)\n        else:\n            files.append(os.path.join(path, fname))\n    if path is not None:\n        file_name = os.path.join(path, file_name)\n    tar_file = tarfile.open(file_name + \".tar.gz\", 'w:gz')\n\n    for f in files:\n        tar_file.add(os.path.abspath(f), arcname=os.path.basename(f))\n\n    script_path = os.path.join(os.path.abspath(base_config_path), turret['script'])\n    tar_file.add(script_path, arcname=turret['script'])\n\n    for f in tar_file.getnames():\n        print(\"Added %s\" % f)\n    tar_file.close()\n    print(\"Archive %s created\" % (tar_file.name))\n    print(\"=========================================\")", "response": "pack a turret into a tar file based on the turret configuration"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nclears the text if it s a text entry element.", "response": "def clear(self) -> None:\n        \"\"\"Clears the text if it's a text entry element.\"\"\"\n        self.click()\n        for i in self.text:\n            self._parent.send_keyevents(Keys.DEL)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef retrieve_file_from_EBI(resource, silent = True):\n    '''Retrieve a file from the RCSB.'''\n    #import sys\n    #import traceback\n    #print(resource)\n    #print('\\n'.join(traceback.format_stack()))\n    #sys.exit(0)\n    if not silent:\n        colortext.printf(\"Retrieving %s from EBI\" % os.path.split(resource)[1], color = \"aqua\")\n    attempts = 10\n    while attempts > 0:\n        try:\n            return get_insecure_resource(\"ftp.ebi.ac.uk\", resource)\n        except:\n            print('FAILED, RETRYING')\n            attempts -= 1\n            time.sleep(3)", "response": "Retrieve a file from the RCSB."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add(self, domain_accession, domain_type, match_quality):\n        '''match_quality should be a value between 0 and 1.'''\n        self.matches[domain_type] = self.matches.get(domain_type, {})\n        self.matches[domain_type][domain_accession] = match_quality", "response": "Add a new entry to the matches dictionary."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef retrieve(pdb_id, cache_dir = None, acceptable_sequence_percentage_match = 70.0, require_uniprot_residue_mapping = True, bio_cache = None):\n        '''Creates a PDBML object by using a cached copy of the files if they exists or by retrieving the files from the RCSB.\n           bio_cache should be a klab.bio.cache.py::BioCache object and is used to avoid reading/downloading cached files repeatedly.\n        '''\n\n        pdb_contents = None\n        xml_contents = None\n        pdb_id = pdb_id.upper()\n\n        l_pdb_id = pdb_id.lower()\n\n        if len(pdb_id) != 4 or not pdb_id.isalnum():\n            raise Exception(\"Bad PDB identifier '%s'.\" % pdb_id)\n\n        if bio_cache:\n            pdb_contents = bio_cache.get_pdb_contents(pdb_id)\n            xml_contents = bio_cache.get_sifts_xml_contents(pdb_id)\n\n        if cache_dir:\n            if not pdb_contents:\n                # Check to see whether we have a cached copy of the PDB file\n                filename = os.path.join(cache_dir, \"%s.pdb\" % pdb_id)\n                if os.path.exists(filename):\n                    pdb_contents = read_file(filename)\n\n            if not xml_contents:\n                # Check to see whether we have a cached copy of the XML file\n                filename = os.path.join(cache_dir, \"%s.sifts.xml.gz\" % l_pdb_id)\n                if os.path.exists(filename):\n                    xml_contents = read_file(filename)\n\n        # Get any missing files from the RCSB and create cached copies if appropriate\n        if not pdb_contents:\n            pdb_contents = rcsb.retrieve_pdb(pdb_id)\n            if cache_dir:\n                write_file(os.path.join(cache_dir, \"%s.pdb\" % pdb_id), pdb_contents)\n\n        if not xml_contents:\n            try:\n                xml_contents = retrieve_xml(pdb_id, silent = False)\n                if cache_dir:\n                    write_file(os.path.join(cache_dir, \"%s.sifts.xml.gz\" % l_pdb_id), xml_contents)\n            except FTPException550:\n                raise MissingSIFTSRecord('The file \"%s.sifts.xml.gz\" could not be found on the EBI FTP server.' % l_pdb_id)\n\n        xml_contents = xml_contents\n\n        # Return the object\n        handler = SIFTS(xml_contents, pdb_contents, acceptable_sequence_percentage_match = acceptable_sequence_percentage_match, cache_dir = cache_dir, require_uniprot_residue_mapping = require_uniprot_residue_mapping, bio_cache = bio_cache, pdb_id = pdb_id)\n        xml.sax.parseString(xml_contents, handler)\n        return handler", "response": "Creates a PDBML object by using a cached copy of the files if they exists or by retrieving the XML files from the RCSB."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntest that the maps agree through composition.", "response": "def _validate(self):\n        '''Tests that the maps agree through composition.'''\n\n        # I used to use the assertion \"self.atom_to_uniparc_sequence_maps.keys() == self.atom_to_seqres_sequence_maps.keys() == self.seqres_to_uniparc_sequence_maps.keys()\"\n        # but that failed for 2IMM where \"self.atom_to_uniparc_sequence_maps.keys() == self.seqres_to_uniparc_sequence_maps.keys() == []\" but THAT fails for 1IR3 so I removed\n        # the assertions entirely.\n        for c, m in self.atom_to_seqres_sequence_maps.iteritems():\n            if self.seqres_to_uniparc_sequence_maps.keys():\n                atom_uniparc_keys = set(self.atom_to_uniparc_sequence_maps.get(c, {}).keys())\n                atom_seqres_keys = set(self.atom_to_seqres_sequence_maps.get(c, {}).keys())\n                assert(atom_uniparc_keys.intersection(atom_seqres_keys) == atom_uniparc_keys)\n                for k, v in m.map.iteritems():\n                    uparc_id_1, uparc_id_2 = None, None\n                    try:\n                        uparc_id_1 = self.seqres_to_uniparc_sequence_maps[c].map[v]\n                        uparc_id_2 = self.atom_to_uniparc_sequence_maps[c].map[k]\n                    except:\n                        continue\n                    assert(uparc_id_1 == uparc_id_2)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget all classes of current user", "response": "def classes(request):\n    \"\"\"Get all classes of current user\"\"\"\n\n    if not request.user.is_authenticated() or not hasattr(request.user, \"userprofile\"):\n        return render_json(request, {\n            'error': _('User is not logged in'),\n            'error_type': 'user_unauthorized'\n        }, template='user_json.html', status=401)\n    clss = [c.to_json() for c in Class.objects.filter(owner=request.user.userprofile)]\n\n    return render_json(request, clss, status=200, template='user_json.html', help_text=classes.__doc__)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a new class in the class hierarchy.", "response": "def create_class(request):\n    \"\"\"Create new class\n\n    POST parameters (JSON):\n        name:\n            Human readable name of class\n        code (optional):\n            unique code of class used for joining to class\n    \"\"\"\n\n    if request.method == 'GET':\n        return render(request, 'classes_create.html', {}, help_text=create_class.__doc__)\n\n    if request.method == 'POST':\n        if not request.user.is_authenticated() or not hasattr(request.user, \"userprofile\"):\n            return render_json(request, {\n                'error': _('User is not logged in.'),\n                'error_type': 'user_unauthorized'\n            }, template='classes_create.html', status=401)\n\n        data = json_body(request.body.decode(\"utf-8\"))\n        if 'code' in data and Class.objects.filter(code=data['code']).exists():\n            return render_json(request, {\n                'error': _('A class with this code already exists.'),\n                'error_type': 'class_with_code_exists'\n            }, template='classes_create.html', status=400)\n\n        if 'name' not in data or not data['name']:\n            return render_json(request, {'error': _('Class name is missing.'), 'error_type': 'missing_class_name'},\n                               template='classes_create.html', status=400)\n\n        cls = Class(name=data['name'], owner=request.user.userprofile)\n        if 'code' in data:\n            cls.code = data['code']\n        cls.save()\n        return render_json(request, cls.to_json(), template='classes_create.html', status=201)\n    else:\n        return HttpResponseBadRequest(\"method %s is not allowed\".format(request.method))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\njoins a class in a class tree.", "response": "def join_class(request):\n    \"\"\"Join a class\n\n    POST parameters (JSON):\n        code:\n            code of the class\n    \"\"\"\n\n    if request.method == 'GET':\n        return render(request, 'classes_join.html', {}, help_text=join_class.__doc__)\n\n    if request.method == 'POST':\n        if not request.user.is_authenticated() or not hasattr(request.user, \"userprofile\"):\n            return render_json(request, {\n                'error': _('User is not logged in.'),\n                'error_type': 'user_unauthorized'\n            }, template='classes_join.html', status=401)\n\n        data = json_body(request.body.decode(\"utf-8\"))\n\n        if 'code' not in data or not data['code']:\n            return render_json(request, {'error': _('Class code is missing.'), 'error_type': 'missing_class_code'},\n                               template='classes_join.html', status=400)\n\n        try:\n            cls = Class.objects.get(code=data['code'])\n        except Class.DoesNotExist:\n            return render_json(request, {\n                'error': _('Class with given code not found.'),\n                'error_type': 'class_not_found',\n            }, template='classes_join.html', status=404)\n\n        cls.members.add(request.user.userprofile)\n        return render_json(request, cls.to_json(), template='classes_join.html', status=200)\n    else:\n        return HttpResponseBadRequest(\"method %s is not allowed\".format(request.method))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates new user in class Arc using POST parameters.", "response": "def create_student(request):\n    \"\"\" Create new user in class\n\n    POST parameters (JSON):\n        class:\n            id of the class\n        username (optional):\n            username of student, if not provided username is create based on name\n        password (optional):\n            password of student\n        first_name:\n            first_name of student\n        last_name (optional):\n            last_name of student\n        email (optional):\n           e-mail of student\n    \"\"\"\n\n    if not get_config('proso_user', 'allow_create_students', default=False):\n        return render_json(request, {\n            'error': _('Creation of new users is not allowed.'),\n            'error_type': 'student_creation_not_allowed'\n        }, template='class_create_student.html', help_text=create_student.__doc__, status=403)\n\n    if request.method == 'GET':\n        return render(request, 'class_create_student.html', {}, help_text=create_student.__doc__)\n    if request.method == 'POST':\n        if not request.user.is_authenticated() or not hasattr(request.user, \"userprofile\"):\n            return render_json(request, {\n                'error': _('User is not logged in.'),\n                'error_type': 'user_unauthorized'\n            }, template='class_create_student.html', status=401)\n        data = json_body(request.body.decode(\"utf-8\"))\n        try:\n            cls = Class.objects.get(pk=data['class'], owner=request.user.userprofile)\n        except (Class.DoesNotExist, KeyError):\n            return render_json(request, {\n                'error': _('Class with given id not found.'),\n                'error_type': 'class_not_found',\n            }, template='class_create_student.html', status=404)\n\n        if 'first_name' not in data or not data['first_name']:\n            return render_json(request, {\n                'error': _('First name code is missing.'),\n                'error_type': 'missing_first_name'\n            }, template='class_create_student.html', status=400)\n\n        user = User(first_name=data['first_name'])\n        if data.get('last_name'):\n            user.last_name = data['last_name']\n        if data.get('email'):\n            if User.objects.filter(email=data['email']).exists():\n                return render_json(request, {\n                    'error': _('There is already a user with the given e-mail.'),\n                    'error_type': 'email_exists'\n                }, template='class_create_student.html', status=400)\n            user.email = data['email']\n        if data.get('username'):\n            if User.objects.filter(username=data['username']).exists():\n                return render_json(request, {\n                    'error': _('There is already a user with the given username.'),\n                    'error_type': 'username_exists'\n                }, template='class_create_student.html', status=400)\n            user.username = data['username']\n        else:\n            user.username = get_unused_username(user)\n        if data.get('password'):\n            user.set_password(data['password'])\n\n        user.save()\n        cls.members.add(user.userprofile)\n\n        return render_json(request, user.userprofile.to_json(nested=True), template='class_create_student.html', status=201)\n    else:\n        return HttpResponseBadRequest(\"method %s is not allowed\".format(request.method))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlogs in student POST parameters (JSON): student: profile id of the student", "response": "def login_student(request):\n    \"\"\"\n    Log in student\n\n    POST parameters (JSON):\n        student:\n            profile id of the student\n    \"\"\"\n    if not get_config('proso_user', 'allow_login_students', default=False):\n        return render_json(request, {\n            'error': _('Log in as student is not allowed.'),\n            'error_type': 'login_student_not_allowed'\n        }, template='class_create_student.html', help_text=login_student.__doc__, status=403)\n\n    if request.method == 'GET':\n        return render(request, 'class_login_student.html', {}, help_text=login_student.__doc__)\n    elif request.method == 'POST':\n        if not request.user.is_authenticated() or not hasattr(request.user, \"userprofile\"):\n            return render_json(request, {\n                'error': _('User is not logged in.'),\n                'error_type': 'user_unauthorized'\n            }, template='class_create_student.html', status=401)\n        data = json_body(request.body.decode(\"utf-8\"))\n        try:\n            student = User.objects.get(userprofile=data.get('student'),\n                                       userprofile__classes__owner=request.user.userprofile)\n        except User.DoesNotExist:\n            return render_json(request, {\n                'error': _('Student not found'),\n                'error_type': 'student_not_found'\n            }, template='class_login_student.html', status=401)\n        if not student.is_active:\n            return render_json(request, {\n                'error': _('The account has not been activated.'),\n                'error_type': 'account_not_activated'\n            }, template='class_login_student.html', status=401)\n        student.backend = 'django.contrib.auth.backends.ModelBackend'\n        login(request, student)\n        request.method = \"GET\"\n        return profile(request)\n    else:\n        return HttpResponseBadRequest(\"method %s is not allowed\".format(request.method))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create(tournament, name, **params):\n    params.update({\"name\": name})\n\n    return api.fetch_and_parse(\n        \"POST\",\n        \"tournaments/%s/participants\" % tournament,\n        \"participant\",\n        **params)", "response": "Add a participant to a tournament."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef bulk_add(tournament, names, **params):\n    params.update({\"name\": names})\n\n    return api.fetch_and_parse(\n        \"POST\",\n        \"tournaments/%s/participants/bulk_add\" % tournament,\n        \"participants[]\",\n        **params)", "response": "Bulk add participants to a tournament."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses a matcharglist into a list of tokens", "response": "def p_matcharglist(p):\n    '''\n    matcharglist : matcharg\n                 | matcharglist COMMA matcharg\n    '''\n    if len(p) == 2:\n        p[0] = [p[1]]\n\n    else:\n        p[0] = p[1]\n        p[0].append(p[3])"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_local_time(index):\n    dt = index.to_pydatetime()\n    dt = dt.replace(tzinfo=pytz.utc)\n    return dt.astimezone(tzlocal()).time()", "response": "Localize datetime for better output in graphs\n   "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef resp_graph_raw(dataframe, image_name, dir='./'):\n    factor = int(len(dataframe) / 10)\n    df = dataframe.reset_index()\n    fig = pygal.Dot(stroke=False,\n                    x_label_rotation=25,\n                    x_title='Elapsed Time In Test (secs)',\n                    y_title='Average Response Time (secs)',\n                    js=('scripts/pygal-tooltip.min.js',))\n    try:\n        grp = df.groupby(pd.cut(df.index, np.arange(0, len(df), factor)))\n        fig.x_labels = [x for x in grp.first()['epoch']]\n        fig.title = image_name.split('.')[0]\n        fig.add('Time', [x for x in grp.describe()['scriptrun_time'].unstack()['mean'].round(2)])\n    except ZeroDivisionError:\n        print(\"Not enough data for raw graph\")\n    fig.render_to_file(filename=os.path.join(dir, image_name))", "response": "Generate a response time graph for raw data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef resp_graph(dataframe, image_name, dir='./'):\n    fig = pygal.TimeLine(x_title='Elapsed Time In Test (secs)',\n                         y_title='Response Time (secs)',\n                         x_label_rotation=25,\n                         js=('scripts/pygal-tooltip.min.js',))\n    fig.add('AVG', [(get_local_time(index), row['mean'] if pd.notnull(row['mean']) else None)\n                    for index, row in dataframe.iterrows()])\n    fig.add('90%', [(get_local_time(index), row['90%'] if pd.notnull(row['90%']) else None)\n                    for index, row in dataframe.iterrows()])\n    fig.add('80%', [(get_local_time(index), row['80%'] if pd.notnull(row['80%']) else None)\n                    for index, row in dataframe.iterrows()])\n    fig.render_to_file(filename=os.path.join(dir, image_name))", "response": "Response time graph for bucketed data"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef tp_graph(dataframe, image_name, dir='./'):\n    fig = pygal.TimeLine(x_title='Elapsed Time In Test (secs)',\n                         x_label_rotation=25,\n                         y_title='Transactions Per Second (count)',\n                         human_readable=True,\n                         js=('scripts/pygal-tooltip.min.js',))\n    fig.add('Transactions per second', [(get_local_time(index), row['count'])\n                                        for index, row in dataframe.iterrows()])\n    fig.render_to_file(filename=os.path.join(dir, image_name))", "response": "This function creates a throughput graph from a pandas. DataFrame dataframe containing all data and outputs it in a single image."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the number of links in the model", "response": "def size(self):\n        '''Return the number of links in the model'''\n        cur = self._conn.cursor()\n        querystr = \"SELECT COUNT(*) FROM relationship;\"\n        cur.execute(querystr)\n        result = cur.fetchone()\n        return result[0]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nyield the low - level rows from the result of a standard query join into yielded iteratively.", "response": "def _process_db_rows_iter(self, cursor):\n        '''\n        Turn the low-level rows from the result of a standard query join\n        into higher-level statements, yielded iteratively. Note this might lead to\n        idle transaction errors?\n\n        '''\n        #Be aware of: http://packages.python.org/psycopg2/faq.html#problems-with-transactions-handling\n        #The results will come back grouped by the raw relationship IDs, in order\n        for relid, relgroup in groupby(cursor, itemgetter(0)):\n            curr_rel = None\n            attrs = None\n            #Each relgroup are the DB rows corresponding to a single relationship,\n            #With redundant origin/rel/target but the sequence of attributes\n            for row in relgroup:\n                (rawid, origin, rel, target, a_name, a_val) = row\n                #self._logger.debug('Row: {0}'.format(repr(row)))\n                if not curr_rel: curr_rel = (origin, rel, target)\n                if a_name:\n                    if not attrs:\n                        attrs = {}\n                        curr_rel = (origin, rel, target, attrs)\n                    attrs[a_name] = a_val\n            yield curr_rel\n        cursor.close()\n        self._conn.rollback() #Finish with the transaction\n        return"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add(self, origin, rel, target, attrs=None, rid=None):\n        '''\n        Add one relationship to the extent\n\n        origin - origin of the relationship (similar to an RDF subject)\n        rel - type IRI of the relationship (similar to an RDF predicate)\n        target - target of the relationship (similar to an RDF object), a boolean, floating point or unicode object\n        attrs - optional attribute mapping of relationship metadata, i.e. {attrname1: attrval1, attrname2: attrval2}\n        rid - optional ID for the relationship in IRI form. If not specified one will be generated.\n\n        '''\n        #FIXME no it doesn't re:\n        #returns an ID (IRI) for the resulting relationship\n        cur = self._conn.cursor()\n        #relationship.\n        if rid:\n            querystr = \"INSERT INTO relationship (origin, rel, target, rid) VALUES (%s, %s, %s, %s) RETURNING rawid;\"\n            cur.execute(querystr, (origin, rel, target, rid))\n        else:\n            querystr = \"INSERT INTO relationship (origin, rel, target) VALUES (%s, %s, %s) RETURNING rawid;\"\n            cur.execute(querystr, (origin, rel, target))\n        rawid = cur.fetchone()[0]\n        for a_name, a_val in attrs.items():\n            querystr = \"INSERT INTO attribute (rawid, name, value) VALUES (%s, %s, %s);\"\n            cur.execute(querystr, (rawid, a_name, a_val))\n        self._conn.commit()\n        cur.close()\n        return", "response": "Add one relationship to the extent."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_eval(self, agent, e, fr=None):\n        self._evals[agent.name] = e\n        self._framings[agent.name] = fr", "response": "Add or change agent s evaluation of the artifact with given framing\n        information."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nattaches the current instance to the service container.", "response": "def attach(self, stdout=True, stderr=True, stream=True, logs=False):\n        \"\"\"\n        Keeping this simple until we need to extend later.\n        \"\"\"\n\n        try:\n            data = parse_stream(self.client.attach(self.id, stdout, stderr, stream, logs))\n        except KeyboardInterrupt:\n            logger.warning(\n                \"service container: {0} has been interrupted. \"\n                \"The container will be stopped but will not be deleted.\".format(self.name)\n            )\n            data = None\n            self.stop()\n\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nstart a container. If the container is running it will return itself. returns a running Container.", "response": "def start(self, attach=False):\n        \"\"\"\n        Start a container.  If the container is running it will return itself.\n\n        returns a running Container.\n        \"\"\"\n        if self.state()['running']:\n            logger.info('is already running.', extra={'formatter': 'container', 'container': self.name})\n            return True\n        else:\n            try:\n                logger.info(\n                    'is being started.', extra={'formatter': 'container', 'container': self.name}\n                )\n\n                # returns None on success\n                self.client.start(self.id)\n                if self._transcribe:\n                    self.start_transcribing()\n\n            except APIError as e:\n                #\n                # This is some bs... I assume that its needed because of dockers changes in 1.18 api.\n                # I will resolve this next week when we stop passing properties to start.\n\n                if e.response.status_code == 500:\n                    self.client.start(self.id)\n                else:\n                    raise RuntimeError(\"Docker Error: {0}\".format(e.explanation))\n\n            if attach:\n                self.attach()\n                exit_code = self.wait()\n\n            else:\n                exit_code = self._wait_for_exit_code()\n\n            return True if exit_code == 0 else False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef state(self):\n        response = normalize_keys(self.client.inspect_container(self.id))\n        return response['state']", "response": "Get the state of the user."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndumps all logs of the current instance to stdout", "response": "def dump_logs(self):\n        \"\"\"dump entirety of the container logs to stdout\n\n            :returns None\n        \"\"\"\n        msg = \"log dump: \\n\"\n        if self._transcribe:\n            if self._transcribe_queue:\n                while not self._transcribe_queue.empty():\n                    logs = self._transcribe_queue.get()\n\n                    if isinstance(logs, six.binary_type):\n                        logs = logs.decode(encoding='UTF-8', errors=\"ignore\")\n\n                    msg = '{0} {1}'.format(msg, logs)\n        else:\n            logs = self.client.logs(self.id, stdout=True, stderr=True, stream=False, timestamps=False, tail='all')\n            if isinstance(logs, six.binary_type):\n                logs = logs.decode(encoding='UTF-8', errors=\"ignore\")\n\n            msg = '{0}{1}'.format(msg, logs)\n\n        logger.error(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _find_by_id(self, id):\n\n        if not isinstance(id, six.string_types):\n            raise TypeError('must supply a string as the id')\n\n        # TODO: We should probably catch container not found error and return out own errors.\n        response = normalize_keys(self.client.inspect_container(id))\n        # TODO: normalize response to change - to _\n        self.id          = response['id']\n        self.name        = response['name'].replace('/', '')\n        self.image       = response['image']\n        # come back and figure the timezone stuff out later.\n        self.created_at  = dateutil.parser.parse(response['created'], ignoretz=True)\n        self.config      = ContainerConfig(response['config'])\n        self.host_config = HostConfig(response['host_config'])\n\n        if self._transcribe:\n            self.start_transcribing()", "response": "Find a specific instance of a specific ID."}
