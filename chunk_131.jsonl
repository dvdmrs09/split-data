{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd the item to the control associating the given data if not None.", "response": "def append(self, a_string, data=None):\r\n        \"Adds the item to the control, associating the given data if not None.\"\r\n        self.wx_obj.Append(a_string, data)\r\n        # reverse association:\r\n        self._items_dict[data] = a_string"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndeleting the item at the zero - based index n from the control.", "response": "def delete(self, a_position):\r\n        \"Deletes the item at the zero-based index 'n' from the control.\"\r\n        self.wx_obj.Delete(a_position)\r\n        data = self.get_data()\r\n        if data in self._items_dict:\r\n            del self._items_dict[data]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef represent(obj, prefix, parent=\"\", indent=0, context=False, max_cols=80):\r\n    \"Construct a string representing the object\"\r\n    try:\r\n        name = getattr(obj, \"name\", \"\")\r\n        class_name = \"%s.%s\" % (prefix, obj.__class__.__name__)\r\n        padding = len(class_name) + 1 + indent * 4 + (5 if context else 0)\r\n        params = []\r\n        for (k, spec) in sorted(obj._meta.specs.items(), key=get_sort_key):\r\n            if k == \"index\":        # index is really defined by creation order\r\n                continue            # also, avoid infinite recursion\r\n            if k == \"parent\" and parent != \"\":\r\n                v = parent\r\n            else:\r\n                v = getattr(obj, k, \"\")\r\n                if (not isinstance(spec, InternalSpec) \r\n                    and v != spec.default\r\n                    and (k != 'id' or v > 0) \r\n                    and isinstance(v, \r\n                         (basestring, int, long, float, bool, dict, list, \r\n                          decimal.Decimal, \r\n                          datetime.datetime, datetime.date, datetime.time,\r\n                          Font, Color))                \r\n                    and repr(v) != 'None'\r\n                    ):\r\n                    v = repr(v)\r\n                else:\r\n                    v = None\r\n            if v is not None:\r\n                params.append(\"%s=%s\" % (k, v)) \r\n        param_lines = []\r\n        line = \"\"\r\n        for param in params:\r\n            if len(line + param) + 3 > max_cols - padding:\r\n                param_lines.append(line)\r\n                line = \"\"\r\n            line += param + \", \"\r\n        param_lines.append(line)\r\n        param_str = (\"\\n%s\" % (\" \" * padding)).join(param_lines)\r\n        return \"%s(%s)\" % (class_name, param_str)\r\n    except:\r\n        raise\r\n        # uninitialized, use standard representation to not break debuggers\r\n        return object.__repr__(obj)", "response": "Construct a string representing the object"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfinds an object already created", "response": "def get(obj_name, init=False):\r\n    \"Find an object already created\"\r\n    wx_parent = None\r\n    # check if new_parent is given as string (useful for designer!)\r\n    if isinstance(obj_name, basestring):\r\n        # find the object reference in the already created gui2py objects\r\n        # TODO: only useful for designer, get a better way\r\n        obj_parent = COMPONENTS.get(obj_name)\r\n        if not obj_parent:\r\n            # try to find window (it can be a plain wx frame/control)\r\n            wx_parent = wx.FindWindowByName(obj_name)\r\n            if wx_parent:\r\n                # store gui object (if any)\r\n                obj_parent = getattr(wx_parent, \"obj\") \r\n            else:\r\n                # fallback using just object name (backward compatibility)\r\n                for obj in COMPONENTS.values():\r\n                    if obj.name==obj_name:\r\n                        obj_parent = obj \r\n    else:\r\n        obj_parent = obj_name     # use the provided parent (as is)\r\n    return obj_parent or wx_parent"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nrecreates ( if needed ) the wx_obj and apply new properties", "response": "def rebuild(self, recreate=True, force=False, **kwargs):\r\n        \"Recreate (if needed) the wx_obj and apply new properties\"\r\n        # detect if this involves a spec that needs to recreate the wx_obj:\r\n        needs_rebuild = any([isinstance(spec, (StyleSpec, InitSpec)) \r\n                             for spec_name, spec in self._meta.specs.items()\r\n                             if spec_name in kwargs])\r\n        # validate if this gui object needs and support recreation\r\n        if needs_rebuild and recreate or force:\r\n            if DEBUG: print \"rebuilding window!\"\r\n            # recreate the wx_obj! warning: it will call Destroy()\r\n            self.__init__(**kwargs)       \r\n        else:\r\n            if DEBUG: print \"just setting attr!\"\r\n            for name, value in kwargs.items():\r\n                setattr(self, name, value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef destroy(self):\r\n        \"Remove event references and destroy wx object (and children)\"\r\n        # unreference the obj from the components map and parent\r\n        if self._name:\r\n            del COMPONENTS[self._get_fully_qualified_name()]\r\n            if DEBUG: print \"deleted from components!\"\r\n            if isinstance(self._parent, Component):\r\n                del self._parent[self._name]\r\n                if DEBUG: print \"deleted from parent!\"\r\n        # destroy the wx_obj (only if sure that reference is not needed!)\r\n        if self.wx_obj:\r\n            self.wx_obj.Destroy()\r\n            for child in self:\r\n                print \"destroying child\", \r\n                child.destroy()\r\n        # destroy the designer selection marker (if any)\r\n        if hasattr(self, 'sel_marker') and self.sel_marker:\r\n            self.sel_marker.destroy()\r\n        if hasattr(self, 'facade') and self.facade:\r\n            self.facade.destroy()", "response": "Remove event references and destroy wx object and children"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef duplicate(self, new_parent=None):\r\n        \"Create a new object exactly similar to self\"\r\n        kwargs = {}\r\n        for spec_name, spec in self._meta.specs.items():\r\n            value = getattr(self, spec_name)\r\n            if isinstance(value, Color):\r\n                print \"COLOR\", value, value.default\r\n                if value.default:\r\n                    value = None\r\n            if value is not None:\r\n                kwargs[spec_name] = value\r\n        del kwargs['parent'] \r\n        new_id = wx.NewId()\r\n        kwargs['id'] = new_id\r\n        kwargs['name'] = \"%s_%s\" % (kwargs['name'], new_id)\r\n        new_obj = self.__class__(new_parent or self.get_parent(), **kwargs)\r\n        # recursively create a copy of each child (in the new parent!)\r\n        for child in self:\r\n            child.duplicate(new_obj)\r\n        return new_obj", "response": "Create a new object exactly similar to self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef reindex(self, z=None):\r\n        \"Raises/lower the component in the window hierarchy (Z-order/tab order)\"\r\n        # z=0: lowers(first index), z=-1: raises (last)\r\n        # actually, only useful in design mode\r\n        if isinstance(self._parent, Component):\r\n            # get the current index (z-order)\r\n            if not self in self._parent._children_list:\r\n                return len(self._parent._children_list)\r\n            i = self._parent._children_list.index(self)\r\n            if z is None:\r\n                return i\r\n            if not hasattr(self, \"designer\") and not self.designer:\r\n                raise RuntimeError(\"reindexing can only be done on design mode\")\r\n            # delete the element reference from the list\r\n            del self._parent._children_list[i]\r\n            # insert as last element\r\n            if z < 0:\r\n                self._parent._children_list.append(self)\r\n            else:\r\n                self._parent._children_list.insert(z, self)", "response": "Raises / lower the component in the window hierarchy ( Z - order / tab order )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstoring the gui / wx object parent for this component", "response": "def set_parent(self, new_parent, init=False):\r\n        \"Store the gui/wx object parent for this component\"\r\n        # set init=True if this is called from the constructor\r\n        self._parent = get(new_parent, init)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_parent_name(self):\r\n        \"Return parent window name (used in __repr__ parent spec)\"\r\n        parent = self.get_parent()\r\n        parent_names = []\r\n        while parent:\r\n            if isinstance(parent, Component):\r\n                parent_name = parent.name\r\n                # Top Level Windows has no parent!\r\n                if parent_name:\r\n                    parent_names.insert(0, parent_name)\r\n                parent = parent.get_parent()\r\n            else:\r\n                break\r\n        if not parent_names:\r\n            return None\r\n        else:\r\n            return '.'.join(parent_names)", "response": "Return parent window name ( used in __repr__ parent spec )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn full parents name + self name ( useful as key )", "response": "def _get_fully_qualified_name(self):\r\n        \"return full parents name + self name (useful as key)\"\r\n        parent_name = self._get_parent_name()\r\n        if not parent_name:\r\n            return self._name\r\n        else:\r\n            return \"%s.%s\" % (parent_name, self._name)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef snapshot(self):\r\n        \"Capture the screen appearance of the control (to be used as facade)\"\r\n        width, height = self.wx_obj.GetSize()\r\n        bmp = wx.EmptyBitmap(width, height)\r\n        wdc = wx.ClientDC(self.wx_obj)\r\n        mdc = wx.MemoryDC(bmp)\r\n        mdc.Blit(0, 0, width, height, wdc, 0, 0)\r\n        #bmp.SaveFile(\"test.bmp\", wx.BITMAP_TYPE_BMP)\r\n        wdc.Destroy()\r\n        mdc.Destroy()\r\n        return bmp", "response": "Capture the screen appearance of the control ( to be used as facade )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncall when adding a control to the window", "response": "def _sizer_add(self, child):\r\n        \"called when adding a control to the window\"\r\n        if self.sizer:\r\n            if DEBUG: print \"adding to sizer:\", child.name\r\n            border = None\r\n            if not border:\r\n                border = child.sizer_border\r\n            flags = child._sizer_flags\r\n            if child.sizer_align:\r\n                flags |= child._sizer_align\r\n            if child.sizer_expand:\r\n                flags |= wx.EXPAND\r\n            if 'grid' in self.sizer:\r\n                self._sizer.Add(child.wx_obj, flag=flags, border=border, \r\n                                pos=(child.sizer_row, child.sizer_col), \r\n                                span=(child.sizer_rowspan, child.sizer_colspan))\r\n            else:\r\n                self._sizer.Add(child.wx_obj, 0, flags, border)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_parent(self, new_parent, init=False):\r\n        \"Re-parent a child control with the new wx_obj parent\"\r\n        Component.set_parent(self, new_parent, init)\r\n        # if not called from constructor, we must also reparent in wx:\r\n        if not init:\r\n            if DEBUG: print \"reparenting\", ctrl.name\r\n            if hasattr(self.wx_obj, \"Reparent\"):\r\n                self.wx_obj.Reparent(self._parent.wx_obj)", "response": "Re - parent a child control with the new wx_obj parent"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalculates final pos and size ( auto absolute in pixels & relativa", "response": "def _calc_dimension(self, dim_val, dim_max, font_dim):\r\n        \"Calculate final pos and size (auto, absolute in pixels & relativa)\"\r\n        if dim_val is None:\r\n            return -1   # let wx automatic pos/size\r\n        elif isinstance(dim_val, int):\r\n            return dim_val  # use fixed pixel value (absolute)\r\n        elif isinstance(dim_val, basestring):\r\n            if dim_val.endswith(\"%\"):\r\n                # percentaje, relative to parent max size:\r\n                dim_val = int(dim_val[:-1])\r\n                dim_val = dim_val / 100.0 * dim_max\r\n            elif dim_val.endswith(\"em\"):\r\n                # use current font size (suport fractions):\r\n                dim_val = float(dim_val[:-2])\r\n                dim_val = dim_val * font_dim\r\n            elif dim_val.endswith(\"px\"):\r\n                # fixed pixels\r\n                dim_val = dim_val[:-2]\r\n            elif dim_val == \"\" or dim_val == \"auto\":\r\n                dim_val = -1\r\n            return int(dim_val)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __tile_background(self, dc):\r\n        \"make several copies of the background bitmap\"\r\n        sz = self.wx_obj.GetClientSize()\r\n        bmp = self._bitmap.get_bits()\r\n        w = bmp.GetWidth()\r\n        h = bmp.GetHeight()\r\n\r\n        if isinstance(self, wx.ScrolledWindow):\r\n            # adjust for scrolled position\r\n            spx, spy = self.wx_obj.GetScrollPixelsPerUnit()\r\n            vsx, vsy = self.wx_obj.GetViewStart()\r\n            dx,  dy  = (spx * vsx) % w, (spy * vsy) % h\r\n        else:\r\n            dx, dy = (w, h)\r\n\r\n        x = -dx\r\n        while x < sz.width:\r\n            y = -dy\r\n            while y < sz.height:\r\n                dc.DrawBitmap(bmp, x, y)\r\n                y = y + h\r\n            x = x + w", "response": "make several copies of the background bitmap"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndraw the image as background", "response": "def __on_erase_background(self, evt):\r\n        \"Draw the image as background\"\r\n        if self._bitmap:\r\n            dc = evt.GetDC()\r\n            \r\n            if not dc:\r\n                dc = wx.ClientDC(self)\r\n                r = self.wx_obj.GetUpdateRegion().GetBox()\r\n                dc.SetClippingRegion(r.x, r.y, r.width, r.height)\r\n                                                           \r\n            if self._background_tiling:\r\n                self.__tile_background(dc)\r\n            else:\r\n                dc.DrawBitmapPoint(self._bitmap.get_bits(), (0, 0))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_parent(self, new_parent, init=False):\r\n        \"Associate the component to the control (it could be recreated)\"\r\n        # store gui reference inside of wx object (this will enable rebuild...)\r\n        self._parent = get(new_parent, init=False)    # store new parent\r\n        if init:\r\n            self._parent[self._name] = self", "response": "Associate the component to the control ( it could be recreated"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef rebuild(self, **kwargs):\r\n        \"Update a property value with (used by the designer)\"\r\n        for name, value in kwargs.items():\r\n            setattr(self, name, value)", "response": "Update a property value with ( used by the designer )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef __on_paint(self, event):\r\n        \"Custom draws the label when transparent background is needed\"\r\n        # use a Device Context that supports anti-aliased drawing \r\n        # and semi-transparent colours on all platforms\r\n        dc = wx.GCDC(wx.PaintDC(self.wx_obj))\r\n        dc.SetFont(self.wx_obj.GetFont())\r\n        dc.SetTextForeground(self.wx_obj.GetForegroundColour())\r\n        dc.DrawText(self.wx_obj.GetLabel(), 0, 0)", "response": "Custom draws the label when transparent background is needed"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef find_modules(rootpath, skip):\r\n\r\n    INITPY = '__init__.py'\r\n\r\n    rootpath = os.path.normpath(os.path.abspath(rootpath))\r\n    if INITPY in os.listdir(rootpath):\r\n        root_package = rootpath.split(os.path.sep)[-1]\r\n        print \"Searching modules in\", rootpath\r\n    else:\r\n        print \"No modules in\", rootpath\r\n        return\r\n\r\n    def makename(package, module):\r\n        \"\"\"Join package and module with a dot.\"\"\"\r\n        if package:\r\n            name = package\r\n            if module:\r\n                name += '.' + module\r\n        else:\r\n            name = module\r\n        return name\r\n\r\n    skipall = []\r\n    for m in skip.keys():\r\n        if skip[m] is None: skipall.append(m)\r\n\r\n    \r\n\r\n    tree = {}\r\n    saved = 0\r\n    found = 0\r\n    def save(module, submodule):\r\n        name = module+ \".\"+ submodule\r\n        \r\n        for s in skipall:\r\n            if name.startswith(s):\r\n                print \"Skipping \"+name\r\n                return False\r\n        if skip.has_key(module):\r\n            if submodule in skip[module]:\r\n                print \"Skipping \"+name\r\n                return False\r\n        if not tree.has_key(module):\r\n            tree[module] = []\r\n        tree[module].append(submodule)\r\n        return True\r\n                    \r\n    for root, subs, files in os.walk(rootpath):\r\n        py_files = sorted([f for f in files if os.path.splitext(f)[1] == '.py'])\r\n                    \r\n        if INITPY in py_files:\r\n            subpackage = root[len(rootpath):].lstrip(os.path.sep).\\\r\n                replace(os.path.sep, '.')\r\n            full = makename(root_package, subpackage)\r\n            part = full.rpartition('.')\r\n            base_package, submodule = part[0], part[2]\r\n            found += 1\r\n            if save(base_package, submodule): saved += 1\r\n            \r\n            py_files.remove(INITPY)    \r\n            for py_file in py_files:\r\n                found += 1\r\n                module = os.path.splitext(py_file)[0]\r\n                if save(full, module): saved += 1\r\n    for item in tree.keys():\r\n        tree[item].sort()\r\n    print \"%s contains %i submodules, %i skipped\" % \\\r\n          (root_package, found, found-saved)\r\n\r\n    return tree", "response": "Find all modules in a directory and return a dict of the names of the modules that are found."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of children sub - components that are column headings", "response": "def _get_column_headings(self):\r\n        \"Return a list of children sub-components that are column headings\"\r\n        # return it in the same order as inserted in the Grid\r\n        headers = [ctrl for ctrl in self if isinstance(ctrl, GridColumn)]\r\n        return sorted(headers, key=lambda ch: ch.index)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _set_row_label(self, value):\r\n        \"Set the row label format string (empty to hide)\"\r\n        if not value:\r\n            self.wx_obj.SetRowLabelSize(0)\r\n        else:\r\n            self.wx_obj._table._row_label = value", "response": "Set the row label format string ( empty to hide )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ResetView(self, grid):\r\n        \"Update the grid if rows and columns have been added or deleted\"\r\n        grid.BeginBatch()\r\n\r\n        for current, new, delmsg, addmsg in [\r\n            (self._rows, self.GetNumberRows(), \r\n             gridlib.GRIDTABLE_NOTIFY_ROWS_DELETED, \r\n             gridlib.GRIDTABLE_NOTIFY_ROWS_APPENDED),\r\n            (self._cols, self.GetNumberCols(), \r\n             gridlib.GRIDTABLE_NOTIFY_COLS_DELETED,\r\n             gridlib.GRIDTABLE_NOTIFY_COLS_APPENDED),\r\n        ]:\r\n\r\n            if new < current:\r\n                msg = gridlib.GridTableMessage(self,delmsg,new,current-new)\r\n                grid.ProcessTableMessage(msg)\r\n            elif new > current:\r\n                msg = gridlib.GridTableMessage(self,addmsg,new-current)\r\n                grid.ProcessTableMessage(msg)\r\n                self.UpdateValues(grid)\r\n\r\n        grid.EndBatch()\r\n\r\n        self._rows = self.GetNumberRows()\r\n        self._cols = self.GetNumberCols()\r\n        # update the column rendering plugins\r\n        self._updateColAttrs(grid)\r\n\r\n        # update the scrollbars and the displayed part of the grid\r\n        grid.AdjustScrollbars()\r\n        grid.ForceRefresh()", "response": "Update the grid if rows and columns have been added or deleted"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating all displayed values", "response": "def UpdateValues(self, grid):\r\n        \"Update all displayed values\"\r\n        # This sends an event to the grid table to update all of the values\r\n        msg = gridlib.GridTableMessage(self, \r\n                                    gridlib.GRIDTABLE_REQUEST_VIEW_GET_VALUES)\r\n        grid.ProcessTableMessage(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _updateColAttrs(self, grid):\r\n        \"update the column attributes to add the appropriate renderer\"\r\n        col = 0\r\n\r\n        for column in self.columns:\r\n            attr = gridlib.GridCellAttr()\r\n            if False:  # column.readonly\r\n                attr.SetReadOnly()\r\n            if False:  # column.renderer\r\n                attr.SetRenderer(renderer)\r\n            grid.SetColSize(col, column.width)\r\n            grid.SetColAttr(col, attr)\r\n            col += 1", "response": "update the column attributes to add the appropriate renderer"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_parent(self, new_parent, init=False):\r\n        \"Associate the header to the control (it could be recreated)\"\r\n        self._created = False\r\n        SubComponent.set_parent(self, new_parent, init)\r\n        # if index not given, append the column at the last position:\r\n        if self.index == -1 or self.index >= len(self._parent.columns):\r\n            self.index = len(self._parent.columns) - 1\r\n        # insert the column in the listview:\r\n        self._parent.wx_obj.AppendCols(1)\r\n        #self._parent.wx_obj.SetColLabelValue(self.index, self.text)\r\n        #self.SetColLabel(self.index, self.align)\r\n        #self._parent.wx_obj.SetColSize(self.index, self.width)\r\n        self._created = True", "response": "Associate the header to the control ( it could be recreated )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef insert(self, pos, values):\r\n        \"Insert a number of rows into the grid (and associated table)\"\r\n        if isinstance(values, dict):\r\n            row = GridRow(self, **values)\r\n        else:\r\n            row = GridRow(self, *values)\r\n        list.insert(self, pos, row)\r\n        self._grid_view.wx_obj.InsertRows(pos, numRows=1)", "response": "Insert a number of rows into the grid ( and associated table )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef append(self, values):\r\n        \"Insert a number of rows into the grid (and associated table)\"\r\n        if isinstance(values, dict):\r\n            row = GridRow(self, **values)\r\n        else:\r\n            row = GridRow(self, *values)\r\n        list.append(self, row)\r\n        self._grid_view.wx_obj.AppendRows(numRows=1)", "response": "Insert a number of rows into the grid ( and associated table )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef clear(self):\r\n        \"Remove all rows and reset internal structures\"\r\n        ## list has no clear ... remove items in reverse order\r\n        for i in range(len(self)-1, -1, -1):\r\n            del self[i]\r\n        self._key = 0\r\n        if hasattr(self._grid_view, \"wx_obj\"):\r\n            self._grid_view.wx_obj.ClearGrid()", "response": "Remove all rows and reset internal structures"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncall to create the control which must derive from wxControl. wxComboBox. wxSize", "response": "def Create(self, parent, id, evtHandler):\r\n        \"Called to create the control, which must derive from wxControl.\"        \r\n        self._tc = wx.ComboBox(parent, id, \"\", (100, 50))\r\n        self.SetControl(self._tc)\r\n        # pushing a different event handler instead evtHandler:\r\n        self._tc.PushEventHandler(wx.EvtHandler())\r\n        self._tc.Bind(wx.EVT_COMBOBOX, self.OnChange)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef SetSize(self, rect):\r\n        \"Called to position/size the edit control within the cell rectangle.\"\r\n        self._tc.SetDimensions(rect.x, rect.y, rect.width+2, rect.height+2,\r\n                               wx.SIZE_ALLOW_MINUS_ONE)", "response": "Called to position / size the edit control within the cell rectangle."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfetches the value from the table and prepare the edit control", "response": "def BeginEdit(self, row, col, grid):\r\n        \"Fetch the value from the table and prepare the edit control\"\r\n        self.startValue = grid.GetTable().GetValue(row, col)\r\n        choices = grid.GetTable().columns[col]._choices\r\n        self._tc.Clear()\r\n        self._tc.AppendItems(choices)\r\n        self._tc.SetStringSelection(self.startValue)\r\n        self._tc.SetFocus()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef EndEdit(self, row, col, grid, val=None):\r\n        \"Complete the editing of the current cell. Returns True if changed\"\r\n        changed = False\r\n        val = self._tc.GetStringSelection()\r\n        print \"val\", val, row, col, self.startValue\r\n        if val != self.startValue:\r\n            changed = True\r\n            grid.GetTable().SetValue(row, col, val) # update the table\r\n        self.startValue = ''\r\n        self._tc.SetStringSelection('')\r\n        return changed", "response": "Complete the editing of the current cell. Returns True if changed"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning True to allow the given key to start editing", "response": "def IsAcceptedKey(self, evt):\r\n        \"Return True to allow the given key to start editing\"\r\n        ## Oops, there's a bug here, we'll have to do it ourself..\r\n        ##return self.base_IsAcceptedKey(evt)\r\n        return (not (evt.ControlDown() or evt.AltDown()) and\r\n                evt.GetKeyCode() != wx.WXK_SHIFT)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef StartingKey(self, evt):\r\n        \"This will be called to let the editor do something with the first key\"\r\n        key = evt.GetKeyCode()\r\n        ch = None\r\n        if key in [wx.WXK_NUMPAD0, wx.WXK_NUMPAD1, wx.WXK_NUMPAD2, wx.WXK_NUMPAD3, wx.WXK_NUMPAD4,\r\n                   wx.WXK_NUMPAD5, wx.WXK_NUMPAD6, wx.WXK_NUMPAD7, wx.WXK_NUMPAD8, wx.WXK_NUMPAD9]:\r\n            ch = ch = chr(ord('0') + key - wx.WXK_NUMPAD0)\r\n        elif key < 256 and key >= 0 and chr(key) in string.printable:\r\n            ch = chr(key)\r\n            if not evt.ShiftDown():\r\n                ch = ch.lower()\r\n        if ch is not None:\r\n            self._tc.SetStringSelection(ch)\r\n        else:\r\n            evt.Skip()", "response": "This will be called to let the editor do something with the first key"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nenables or disable all menu items", "response": "def Enable(self, value):\r\n        \"enable or disable all menu items\"\r\n        for i in range(self.GetMenuItemCount()):\r\n            it = self.FindItemByPosition(i) \r\n            it.Enable(value)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef IsEnabled(self, *args, **kwargs):\r\n        \"check if all menu items are enabled\"\r\n        for i in range(self.GetMenuItemCount()):\r\n            it = self.FindItemByPosition(i) \r\n            if not it.IsEnabled():\r\n                return False\r\n        return True", "response": "check if all menu items are enabled"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find(self, item_id=None):\r\n        \"Recursively find a menu item by its id (useful for event handlers)\"\r\n        for it in self:\r\n            if it.id == item_id:\r\n                return it\r\n            elif isinstance(it, Menu):\r\n                found = it.find(item_id)\r\n                if found:\r\n                    return found", "response": "Recursively find a menu item by its id ( useful for event handlers )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef Enable(self, value):\r\n        \"enable or disable all top menus\"\r\n        for i in range(self.GetMenuCount()):\r\n            self.EnableTop(i, value)", "response": "enable or disable all top menus"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef IsEnabled(self, *args, **kwargs):\r\n        \"check if all top menus are enabled\"\r\n        for i in range(self.GetMenuCount()):\r\n            if not self.IsEnabledTop(i):\r\n                return False\r\n        return True", "response": "check if all top menus are enabled"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef RemoveItem(self, menu):\r\n        \"Helper method to remove a menu avoiding using its position\"\r\n        menus = self.GetMenus()     # get the list of (menu, title)\r\n        menus = [submenu for submenu in menus if submenu[0] != menu]\r\n        self.SetMenus(menus)", "response": "Helper method to remove a menu avoiding using its position"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef build_data_set(self):\n        \"Construct a sequence of name/value pairs from controls\"\n        data = {}\n        for field in self.fields:\n            if field.name:# and field.enabled: !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n                val = field.get_value()\n                if val is None:\n                    continue\n                elif isinstance(val, unicode):\n                    # web2py string processing\n                    # requires utf-8 encoded text\n                    val = val.encode(\"utf-8\")                    \n                data[field.name] = val\n        return data", "response": "Construct a sequence of name / value pairs from controls"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef setObjectTag(self, object, tag):\n        object._attributes = {}\n        object._name = tag.GetName().lower()\n        for name in self.attributes:\n            object._attributes[\"_%s\" % name] = tag.GetParam(name)\n            if object._attributes[\"_%s\" % name] == \"\":\n                object._attributes[\"_%s\" % name] = None", "response": "Add a tag attribute to the wx object"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ninserting items described in autosummary:: to the TOC tree but not generate the TOC tree.", "response": "def process_autosummary_toc(app, doctree):\n    \"\"\"Insert items described in autosummary:: to the TOC tree, but do\n    not generate the toctree:: list.\n    \"\"\"\n    env = app.builder.env\n    crawled = {}\n    def crawl_toc(node, depth=1):\n        crawled[node] = True\n        for j, subnode in enumerate(node):\n            try:\n                if (isinstance(subnode, autosummary_toc)\n                    and isinstance(subnode[0], addnodes.toctree)):\n                    env.note_toctree(env.docname, subnode[0])\n                    continue\n            except IndexError:\n                continue\n            if not isinstance(subnode, nodes.section):\n                continue\n            if subnode not in crawled:\n                crawl_toc(subnode, depth+1)\n    crawl_toc(doctree)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef autosummary_table_visit_html(self, node):\n    try:\n        tbody = node[0][0][-1]\n        for row in tbody:\n            col1_entry = row[0]\n            par = col1_entry[0]\n            for j, subnode in enumerate(list(par)):\n                if isinstance(subnode, nodes.Text):\n                    new_text = unicode(subnode.astext())\n                    new_text = new_text.replace(u\" \", u\"\\u00a0\")\n                    par[j] = nodes.Text(new_text)\n    except IndexError:\n        pass", "response": "Make the first column of the table non - breakinging."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting an autodoc. Documenter class suitable for documenting the given obj and parent.", "response": "def get_documenter(obj, parent):\n    \"\"\"Get an autodoc.Documenter class suitable for documenting the given\n    object.\n\n    *obj* is the Python object to be documented, and *parent* is an\n    another Python object (e.g. a module or a class) to which *obj*\n    belongs to.\n    \"\"\"\n    from sphinx.ext.autodoc import AutoDirective, DataDocumenter, \\\n         ModuleDocumenter\n\n    if inspect.ismodule(obj):\n        # ModuleDocumenter.can_document_member always returns False\n        return ModuleDocumenter\n\n    # Construct a fake documenter for *parent*\n    if parent is not None:\n        parent_doc_cls = get_documenter(parent, None)\n    else:\n        parent_doc_cls = ModuleDocumenter\n\n    if hasattr(parent, '__name__'):\n        parent_doc = parent_doc_cls(FakeDirective(), parent.__name__)\n    else:\n        parent_doc = parent_doc_cls(FakeDirective(), \"\")\n\n    # Get the corrent documenter class for *obj*\n    classes = [cls for cls in AutoDirective._registry.values()\n               if cls.can_document_member(obj, '', False, parent_doc)]\n    if classes:\n        classes.sort(key=lambda cls: cls.priority)\n        return classes[-1]\n    else:\n        return DataDocumenter"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef mangle_signature(sig, max_chars=30):\n    s = re.sub(r\"^\\((.*)\\)$\", r\"\\1\", sig).strip()\n\n    # Strip strings (which can contain things that confuse the code below)\n    s = re.sub(r\"\\\\\\\\\", \"\", s)\n    s = re.sub(r\"\\\\'\", \"\", s)\n    s = re.sub(r\"'[^']*'\", \"\", s)\n\n    # Parse the signature to arguments + options\n    args = []\n    opts = []\n\n    opt_re = re.compile(r\"^(.*, |)([a-zA-Z0-9_*]+)=\")\n    while s:\n        m = opt_re.search(s)\n        if not m:\n            # The rest are arguments\n            args = s.split(', ')\n            break\n\n        opts.insert(0, m.group(2))\n        s = m.group(1)[:-2]\n\n    # Produce a more compact signature\n    sig = limited_join(\", \", args, max_chars=max_chars-2)\n    if opts:\n        if not sig:\n            sig = \"[%s]\" % limited_join(\", \", opts, max_chars=max_chars-4)\n        elif len(sig) < max_chars - 4 - 2 - 3:\n            sig += \"[, %s]\" % limited_join(\", \", opts,\n                                           max_chars=max_chars-len(sig)-4-2)\n\n    return u\"(%s)\" % sig", "response": "Reformat a function signature to a more compact form."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef limited_join(sep, items, max_chars=30, overflow_marker=\"...\"):\n    full_str = sep.join(items)\n    if len(full_str) < max_chars:\n        return full_str\n\n    n_chars = 0\n    n_items = 0\n    for j, item in enumerate(items):\n        n_chars += len(item) + len(sep)\n        if n_chars < max_chars - len(overflow_marker):\n            n_items += 1\n        else:\n            break\n\n    return sep.join(list(items[:n_items]) + [overflow_marker])", "response": "Join a number of strings to one limiting the length to max_chars."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_import_prefixes_from_env(env):\n    prefixes = [None]\n\n    currmodule = env.temp_data.get('py:module')\n    if currmodule:\n        prefixes.insert(0, currmodule)\n\n    currclass = env.temp_data.get('py:class')\n    if currclass:\n        if currmodule:\n            prefixes.insert(0, currmodule + \".\" + currclass)\n        else:\n            prefixes.insert(0, currclass)\n\n    return prefixes", "response": "Obtain current Python import prefixes from env."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef import_by_name(name, prefixes=[None]):\n    tried = []\n    for prefix in prefixes:\n        try:\n            if prefix:\n                prefixed_name = '.'.join([prefix, name])\n            else:\n                prefixed_name = name\n            obj, parent = _import_by_name(prefixed_name)\n            return prefixed_name, obj, parent\n        except ImportError:\n            tried.append(prefixed_name)\n    raise ImportError('no module named %s' % ' or '.join(tried))", "response": "Import a Python object that has the given name under one of the given prefixes."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _import_by_name(name):\n    try:\n        name_parts = name.split('.')\n\n        # try first interpret `name` as MODNAME.OBJ\n        modname = '.'.join(name_parts[:-1])\n        if modname:\n            try:\n                __import__(modname)\n                mod = sys.modules[modname]\n                return getattr(mod, name_parts[-1]), mod\n            except (ImportError, IndexError, AttributeError):\n                pass\n\n        # ... then as MODNAME, MODNAME.OBJ1, MODNAME.OBJ1.OBJ2, ...\n        last_j = 0\n        modname = None\n        for j in reversed(range(1, len(name_parts)+1)):\n            last_j = j\n            modname = '.'.join(name_parts[:j])\n            try:\n                __import__(modname)\n            except:# ImportError:\n                continue\n            if modname in sys.modules:\n                break\n\n        if last_j < len(name_parts):\n            parent = None\n            obj = sys.modules[modname]\n            for obj_name in name_parts[last_j:]:\n                parent = obj\n                obj = getattr(obj, obj_name)\n            return obj, parent\n        else:\n            return sys.modules[modname], None\n    except (ValueError, ImportError, AttributeError, KeyError), e:\n        raise ImportError(*e.args)", "response": "Import a Python object given its full name."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsmart linking role. Expands to ':obj:`text`' if `text` is an object that can be imported; otherwise expands to '*text*'.", "response": "def autolink_role(typ, rawtext, etext, lineno, inliner,\n                  options={}, content=[]):\n    \"\"\"Smart linking role.\n\n    Expands to ':obj:`text`' if `text` is an object that can be imported;\n    otherwise expands to '*text*'.\n    \"\"\"\n    env = inliner.document.settings.env\n    r = env.get_domain('py').role('obj')(\n        'obj', rawtext, etext, lineno, inliner, options, content)\n    pnode = r[0][0]\n\n    prefixes = get_import_prefixes_from_env(env)\n    try:\n        name, obj, parent = import_by_name(pnode['reftarget'], prefixes)\n    except ImportError:\n        content = pnode[0]\n        r[0][0] = nodes.emphasis(rawtext, content[0].astext(),\n                                 classes=content['classes'])\n    return r"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_items(self, names):\n        env = self.state.document.settings.env\n\n        prefixes = get_import_prefixes_from_env(env)\n\n        items = []\n\n        max_item_chars = 50\n\n        for name in names:\n            display_name = name\n            if name.startswith('~'):\n                name = name[1:]\n                display_name = name.split('.')[-1]\n\n            try:\n                real_name, obj, parent = import_by_name(name, prefixes=prefixes)\n            except ImportError:\n                self.warn('failed to import %s' % name)\n                items.append((name, '', '', name))\n                continue\n\n            # NB. using real_name here is important, since Documenters\n            #     handle module prefixes slightly differently\n            documenter = get_documenter(obj, parent)(self, real_name)\n            if not documenter.parse_name():\n                self.warn('failed to parse name %s' % real_name)\n                items.append((display_name, '', '', real_name))\n                continue\n            if not documenter.import_object():\n                self.warn('failed to import object %s' % real_name)\n                items.append((display_name, '', '', real_name))\n                continue\n\n            # -- Grab the signature\n\n            sig = documenter.format_signature()\n            if not sig:\n                sig = ''\n            else:\n                max_chars = max(10, max_item_chars - len(display_name))\n                sig = mangle_signature(sig, max_chars=max_chars)\n                sig = sig.replace('*', r'\\*')\n\n            # -- Grab the summary\n\n            doc = list(documenter.process_doc(documenter.get_doc()))\n\n            while doc and not doc[0].strip():\n                doc.pop(0)\n            m = re.search(r\"^([A-Z][^A-Z]*?\\.\\s)\", \" \".join(doc).strip())\n            if m:\n                summary = m.group(1).strip()\n            elif doc:\n                summary = doc[0].strip()\n            else:\n                summary = ''\n\n            items.append((display_name, sig, summary, real_name))\n\n        return items", "response": "Try to import the given names and return a list of tuples of names signature summary_string real_name."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates a proper list of table nodes for autosummary:: directive.", "response": "def get_table(self, items):\n        \"\"\"Generate a proper list of table nodes for autosummary:: directive.\n\n        *items* is a list produced by :meth:`get_items`.\n        \"\"\"\n        table_spec = addnodes.tabular_col_spec()\n        table_spec['spec'] = 'll'\n\n        table = autosummary_table('')\n        real_table = nodes.table('', classes=['longtable'])\n        table.append(real_table)\n        group = nodes.tgroup('', cols=2)\n        real_table.append(group)\n        group.append(nodes.colspec('', colwidth=10))\n        group.append(nodes.colspec('', colwidth=90))\n        body = nodes.tbody('')\n        group.append(body)\n\n        def append_row(*column_texts):\n            row = nodes.row('')\n            for text in column_texts:\n                node = nodes.paragraph('')\n                vl = ViewList()\n                vl.append(text, '<autosummary>')\n                self.state.nested_parse(vl, 0, node)\n                try:\n                    if isinstance(node[0], nodes.paragraph):\n                        node = node[0]\n                except IndexError:\n                    pass\n                row.append(nodes.entry('', node))\n            body.append(row)\n\n        for name, sig, summary, real_name in items:\n            qualifier = 'obj'\n            if 'nosignatures' not in self.options:\n                col1 = ':%s:`%s <%s>`\\ %s' % (qualifier, name, real_name, sig)\n            else:\n                col1 = ':%s:`%s <%s>`' % (qualifier, name, real_name)\n            col2 = summary\n            append_row(col1, col2)\n\n        return [table_spec, table]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nshow a simple pop - up modal dialog", "response": "def alert(message, title=\"\", parent=None, scrolled=False, icon=\"exclamation\"):\r\n    \"Show a simple pop-up modal dialog\"\r\n    if not scrolled:\r\n        icons = {'exclamation': wx.ICON_EXCLAMATION, 'error': wx.ICON_ERROR,\r\n             'question': wx.ICON_QUESTION, 'info': wx.ICON_INFORMATION}\r\n        style = wx.OK | icons[icon]\r\n        result = dialogs.messageDialog(parent, message, title, style)\r\n    else:\r\n        result = dialogs.scrolledMessageDialog(parent, message, title)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef confirm(message=\"\", title=\"\", default=False, ok=False, cancel=False,\r\n            parent=None):\r\n    \"Ask for confirmation (yes/no or ok and cancel), returns True or False\"\r\n    style = wx.CENTRE\r\n    if ok:\r\n        style |= wx.OK \r\n    else:\r\n        style |= wx.YES | wx.NO\r\n        if default:\r\n            style |= wx.YES_DEFAULT\r\n        else:\r\n            style |= wx.NO_DEFAULT\r\n    if cancel:\r\n        style |= wx.CANCEL\r\n    result = dialogs.messageDialog(parent, message, title, style)\r\n    if cancel and result.returned == wx.ID_CANCEL:\r\n        return None\r\n    return result.accepted", "response": "Ask for confirmation ( yes / no or ok and cancel returns True or False"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef select_font(message=\"\", title=\"\", font=None, parent=None):\r\n    \"Show a dialog to select a font\"\r\n    if font is not None:\r\n        wx_font = font._get_wx_font()                   # use as default\r\n    else:\r\n        wx_font = None\r\n        font = Font()                                   # create an empty font\r\n    result = dialogs.fontDialog(parent, font=wx_font)\r\n    if result.accepted:\r\n        font_data = result.fontData\r\n        result.color = result.fontData.GetColour().Get()\r\n        wx_font = result.fontData.GetChosenFont()\r\n        font.set_wx_font(wx_font)\r\n        wx_font = None\r\n        return font", "response": "Show a dialog to select a font"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nshows a dialog to pick a color", "response": "def select_color(message=\"\", title=\"\", color=None, parent=None):\r\n    \"Show a dialog to pick a color\"\r\n    result = dialogs.colorDialog(parent, color=color)\r\n    return result.accepted and result.color"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef open_file(title=\"Open\",  directory='', filename='', \r\n              wildcard='All Files (*.*)|*.*', multiple=False, parent=None):\r\n    \"Show a dialog to select files to open, return path(s) if accepted\"\r\n    style = wx.OPEN \r\n    if multiple:\r\n        style |= wx.MULTIPLE\r\n    result = dialogs.fileDialog(parent, title, directory, filename, wildcard, \r\n                                style)\r\n    if result.paths and not multiple:\r\n        return result.paths[0]\r\n    else:\r\n        return result.paths", "response": "Show a dialog to select files to open return path(s ) if accepted"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef save_file(title=\"Save\",  directory='', filename='', \r\n              wildcard='All Files (*.*)|*.*', overwrite=False, parent=None):\r\n    \"Show a dialog to select file to save, return path(s) if accepted\"\r\n    style = wx.SAVE \r\n    if not overwrite:\r\n        style |= wx.OVERWRITE_PROMPT\r\n    result = dialogs.fileDialog(parent, title, directory, filename, wildcard, \r\n                                style)\r\n    return result.paths", "response": "Show a dialog to select file to save return path(s ) if accepted"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef choose_directory(message='Choose a directory', path=\"\", parent=None):\r\n    \"Show a dialog to choose a directory\"\r\n    result = dialogs.directoryDialog(parent, message, path)\r\n    return result.path", "response": "Show a dialog to choose a directory"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find(default='', whole_words=0, case_sensitive=0, parent=None):\r\n    \"Shows a find text dialog\"\r\n    result = dialogs.findDialog(parent, default, whole_words, case_sensitive)\r\n    return {'text': result.searchText, 'whole_words': result.wholeWordsOnly,\r\n            'case_sensitive': result.caseSensitive}", "response": "Shows a find text dialog"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef clear(self):\r\n        \"Remove all items and reset internal structures\"\r\n        dict.clear(self)\r\n        self._key = 0\r\n        if hasattr(self._tree_view, \"wx_obj\"):\r\n            self._tree_view.wx_obj.DeleteAllItems()", "response": "Remove all items and reset internal structures"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_has_children(self, has_children=True):\r\n        \"Force appearance of the button next to the item\"\r\n        # This is useful to allow the user to expand the items which don't have\r\n        # any children now, but instead adding them only when needed, thus \r\n        # minimizing memory usage and loading time.\r\n        self._tree_model._tree_view.wx_obj.SetItemHasChildren(self.wx_item, \r\n                                                              has_children)", "response": "Force appearance of the button next to the item"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the type of an image from the file extension", "response": "def bitmap_type(filename):\r\n    \"\"\"\r\n    Get the type of an image from the file's extension ( .jpg, etc. )\r\n    \"\"\"\r\n\r\n    if filename == '':\r\n        return None\r\n\r\n    name, ext = os.path.splitext(filename)\r\n    ext = ext[1:].upper()\r\n    if ext == 'BMP':\r\n        return wx.BITMAP_TYPE_BMP\r\n    elif ext == 'GIF':\r\n        return wx.BITMAP_TYPE_GIF\r\n    elif ext == 'JPG' or ext == 'JPEG':\r\n        return wx.BITMAP_TYPE_JPEG\r\n    elif ext == 'PCX':\r\n        return wx.BITMAP_TYPE_PCX\r\n    elif ext == 'PICT':\r\n        return wx.BITMAP_TYPE_PICT\r\n    elif ext == 'PNG':\r\n        return wx.BITMAP_TYPE_PNG\r\n    elif ext == 'PNM':\r\n        return wx.BITMAP_TYPE_PNM\r\n    elif ext == 'TIF' or ext == 'TIFF':\r\n        return wx.BITMAP_TYPE_TIF\r\n    elif ext == 'XBM':\r\n        return wx.BITMAP_TYPE_XBM\r\n    elif ext == 'XPM':\r\n        return wx.BITMAP_TYPE_XPM\r\n    else:\r\n        # KEA 2001-10-10\r\n        # rather than throw an exception, we could try and have wxPython figure out the image\r\n        # type by returning wxBITMAP_TYPE_ANY\r\n        raise RuntimeErro('invalid graphics format')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _getbitmap_type( self, filename ) :\r\n        # KEA 2001-07-27\r\n        # was\r\n        #name, ext = filename.split( '.' )\r\n        #ext = ext.upper()\r\n        if filename is None or filename == '':\r\n            return None\r\n\r\n        name, ext = os.path.splitext(filename)\r\n        ext = ext[1:].upper()\r\n        if ext == 'BMP':\r\n            return wx.BITMAP_TYPE_BMP\r\n        elif ext == 'GIF':\r\n            return wx.BITMAP_TYPE_GIF\r\n        elif ext == 'JPG' or ext == 'JPEG':\r\n            return wx.BITMAP_TYPE_JPEG\r\n        elif ext == 'PCX':\r\n            return wx.BITMAP_TYPE_PCX\r\n        #elif ext == 'PICT':\r\n        #    return wx.BITMAP_TYPE_PICT\r\n        elif ext == 'PNG':\r\n            return wx.BITMAP_TYPE_PNG\r\n        elif ext == 'PNM':\r\n            return wx.BITMAP_TYPE_PNM\r\n        elif ext == 'TIF' or ext == 'TIFF':\r\n            return wx.BITMAP_TYPE_TIF\r\n        elif ext == 'XBM':\r\n            return wx.BITMAP_TYPE_XBM\r\n        elif ext == 'XPM':\r\n            return wx.BITMAP_TYPE_XPM\r\n        else:\r\n            # KEA 2001-10-10\r\n            # rather than throw an exception, we could try and have wxPython figure out the image\r\n            # type by returning wxBITMAP_TYPE_ANY\r\n            raise RuntimeError('invalid graphics format')", "response": "Returns the type of an image from the file extension"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _set_icon(self, icon=None):\r\n        if icon is not None:\r\n            try:\r\n                wx_icon = wx.Icon(icon, wx.BITMAP_TYPE_ICO)\r\n                self.wx_obj.SetIcon(wx_icon)\r\n            except:\r\n                pass", "response": "Set icon based on resource values"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndisplaying or hide the window optionally disabling all other windows", "response": "def show(self, value=True, modal=None):\r\n        \"Display or hide the window, optionally disabling all other windows\"\r\n        self.wx_obj.Show(value)\r\n        if modal:\r\n            # disable all top level windows of this application (MakeModal)\r\n            disabler = wx.WindowDisabler(self.wx_obj)\r\n            # create an event loop to stop execution \r\n            eventloop = wx.EventLoop()\r\n            def on_close_modal(evt):\r\n                evt.Skip()\r\n                eventloop.Exit()\r\n            self.wx_obj.Bind(wx.EVT_CLOSE, on_close_modal)\r\n            # start the event loop to wait user interaction \r\n            eventloop.Run()\r\n            # reenable the windows disabled and return control to the caller\r\n            del disabler"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef draw_arc(self, x1y1, x2y2, xcyc):\n\n        self._buf_image.DrawArcPoint(x1y1, x2y2, xcyc)\n        if self.auto_refresh:\n            dc = wx.ClientDC(self.wx_obj)\n            dc.BlitPointSize((0, 0), (self._size[0], self._size[1]), self._buf_image, (0, 0))", "response": "Draws an arc of a circle centered on x1 y1 and x2 y2."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nopen read and eval the resource from the source file", "response": "def parse(filename=\"\"):\n    \"Open, read and eval the resource from the source file\"\n    # use the provided resource file:\n    s = open(filename).read()\n    ##s.decode(\"latin1\").encode(\"utf8\")\n    import datetime, decimal\n    rsrc = eval(s)\n    return rsrc"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsaving the resource to the source file", "response": "def save(filename, rsrc):\n    \"Save the resource to the source file\"\n    s = pprint.pformat(rsrc)\n    ## s = s.encode(\"utf8\")\n    open(filename, \"w\").write(s)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating the GUI objects defined in the resource ( filename or python struct )", "response": "def load(controller=None, filename=\"\", name=None, rsrc=None):\n    \"Create the GUI objects defined in the resource (filename or python struct)\"\n    # if no filename is given, search for the rsrc.py with the same module name:\n    if not filename and not rsrc:\n        if isinstance(controller, types.ClassType):\n            # use the controller class module (to get __file__ for rsrc.py)\n            mod_dict = util.get_class_module_dict(controller)\n        elif isinstance(controller, types.ModuleType):\n            # use the module provided as controller\n            mod_dict = controller.__dict__\n        elif isinstance(controller, Controller):\n            # use the instance provided as controller\n            mod_dict = util.get_class_module_dict(controller)\n        else:\n            # use the caller module (no controller explicitelly provided)\n            mod_dict = util.get_caller_module_dict()\n            # do not use as controller if it was explicitly False or empty\n            if controller is None:\n                controller = mod_dict\n        if util.main_is_frozen():\n            # running standalone\n            if '__file__' in mod_dict:\n                filename = os.path.split(mod_dict['__file__'])[1]\n            else:\n                # __main__ has not __file__ under py2exe!\n                filename = os.path.split(sys.argv[0])[-1]\n            filename = os.path.join(util.get_app_dir(), filename)\n        else:\n            # figure out the .rsrc.py filename based on the module name\n            filename = mod_dict['__file__']\n        # chop the .pyc or .pyo from the end\n        base, ext = os.path.splitext(filename)\n        filename = base + \".rsrc.py\"\n    # when rsrc is a file name, open, read and eval it:\n    if isinstance(filename, basestring):\n        rsrc = parse(filename)\n    ret = []\n    # search over the resource to create the requested object (or all)\n    for win in rsrc:\n        if not name or win['name'] == name:\n            ret.append(build_window(win))\n    # associate event handlers\n    if ret and controller:\n        connect(ret[0], controller)        \n        # return the first instance created (if any):\n        return ret[0]\n    else:\n        # return all the instances created -for the designer- (if any):\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef build_window(res):\n    \"Create a gui2py window based on the python resource\"\n    \n    # windows specs (parameters)\n    kwargs = dict(res.items())\n    wintype = kwargs.pop('type')\n    menubar = kwargs.pop('menubar', None)\n    components = kwargs.pop('components')\n    panel = kwargs.pop('panel', {})\n    \n    from gui import registry\n    import gui\n    \n    winclass = registry.WINDOWS[wintype]\n    win = winclass(**kwargs)\n\n    # add an implicit panel by default (as pythoncard had)\n    if False and panel is not None:\n        panel['name'] = 'panel'\n        p = gui.Panel(win, **panel)\n    else:\n        p = win\n        \n    if components:\n        for comp in components:\n            build_component(comp, parent=p)\n\n    if menubar:\n        mb = gui.MenuBar(name=\"menu\", parent=win)\n        for menu in menubar:\n            build_component(menu, parent=mb)\n    return win", "response": "Create a gui2py window based on the python resource"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef build_component(res, parent=None):\n    \"Create a gui2py control based on the python resource\"\n    # control specs (parameters)\n    kwargs = dict(res.items())\n    comtype = kwargs.pop('type')\n    if 'components' in res:\n        components = kwargs.pop('components')\n    elif comtype == 'Menu' and 'items' in res:\n        components = kwargs.pop('items')\n    else:\n        components = []\n\n    from gui import registry\n\n    if comtype in registry.CONTROLS:\n        comclass = registry.CONTROLS[comtype]\n    elif comtype in registry.MENU:\n        comclass = registry.MENU[comtype]\n    elif comtype in registry.MISC:\n        comclass = registry.MISC[comtype]\n    else:\n        raise RuntimeError(\"%s not in registry\" % comtype)\n        \n    # Instantiate the GUI object\n    com = comclass(parent=parent, **kwargs)\n    \n    for comp in components:\n        build_component(comp, parent=com)\n\n    return com", "response": "Create a gui2py control based on the python resource"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dump(obj):\n    \"Recursive convert a live GUI object to a resource list/dict\"\n    \n    from .spec import InitSpec, DimensionSpec, StyleSpec, InternalSpec\n    import decimal, datetime\n    from .font import Font\n    from .graphic import Bitmap, Color\n    from . import registry\n\n    ret = {'type': obj.__class__.__name__}\n    \n    for (k, spec) in obj._meta.specs.items():\n        if k == \"index\":        # index is really defined by creation order\n            continue            # also, avoid infinite recursion\n        v = getattr(obj, k, \"\")\n        if (not isinstance(spec, InternalSpec) \n            and v != spec.default\n            and (k != 'id' or v > 0) \n            and isinstance(v, \n                 (basestring, int, long, float, bool, dict, list, \n                  decimal.Decimal, \n                  datetime.datetime, datetime.date, datetime.time,\n                  Font, Color))                \n            and repr(v) != 'None'\n            and k != 'parent'\n            ):\n            ret[k] = v \n            \n    for ctl in obj:\n        if ret['type'] in registry.MENU:\n            ret.setdefault('items', []).append(dump(ctl))\n        else:\n            res = dump(ctl)\n            if 'menubar' in res:\n                ret.setdefault('menubar', []).append(res.pop('menubar'))\n            else:\n                ret.setdefault('components', []).append(res)\n    \n    return ret", "response": "Recursive convert a live GUI object to a resource list / dict"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntranslate gui2py attribute name from pythoncard legacy code", "response": "def convert(self, name):\n        \"translate gui2py attribute name from pythoncard legacy code\"\n        new_name = PYTHONCARD_PROPERTY_MAP.get(name)\n        if new_name:\n            print \"WARNING: property %s should be %s (%s)\" % (name, new_name, self.obj.name)\n            return new_name\n        else:\n            return name"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_data():\n    \"Read from the clipboard content, return a suitable object (string or bitmap)\"\n    data = None\n    try:\n        if wx.TheClipboard.Open():\n            if wx.TheClipboard.IsSupported(wx.DataFormat(wx.DF_TEXT)):\n                do = wx.TextDataObject()\n                wx.TheClipboard.GetData(do)\n                data = do.GetText()\n            elif wx.TheClipboard.IsSupported(wx.DataFormat(wx.DF_BITMAP)):\n                do = wx.BitmapDataObject()\n                wx.TheClipboard.GetData(do)\n                data = do.GetBitmap()\n            wx.TheClipboard.Close()\n    except:\n        data = None\n    return data", "response": "Read from the clipboard content return a suitable object ( string or bitmap )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwriting content to the clipboard data can be either a string or a bitmap", "response": "def set_data(data):\n    \"Write content to the clipboard, data can be either a string or a bitmap\" \n    try:\n        if wx.TheClipboard.Open():\n            if isinstance(data, (str, unicode)):\n                do = wx.TextDataObject()\n                do.SetText(data)\n                wx.TheClipboard.SetData(do)\n            elif isinstance(data, wx.Bitmap):\n                do = wx.BitmapDataObject()\n                do.SetBitmap(data)\n                wx.TheClipboard.SetData(do)\n            wx.TheClipboard.Close()\n    except:\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfind out what items are documented in source. rst. See find_autosummary_in_lines.", "response": "def find_autosummary_in_files(filenames):\n    \"\"\"Find out what items are documented in source/*.rst.\n\n    See `find_autosummary_in_lines`.\n    \"\"\"\n    documented = []\n    for filename in filenames:\n        f = open(filename, 'r')\n        lines = f.read().splitlines()\n        documented.extend(find_autosummary_in_lines(lines, filename=filename))\n        f.close()\n    return documented"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef find_autosummary_in_docstring(name, module=None, filename=None):\n    try:\n        real_name, obj, parent = import_by_name(name)\n        lines = pydoc.getdoc(obj).splitlines()\n        return find_autosummary_in_lines(lines, module=name, filename=filename)\n    except AttributeError:\n        pass\n    except ImportError, e:\n        print \"Failed to import '%s': %s\" % (name, e)\n    return []", "response": "Find what items are documented in the given object s docstring."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find_autosummary_in_lines(lines, module=None, filename=None):\n    autosummary_re = re.compile(r'^(\\s*)\\.\\.\\s+autosummary::\\s*')\n    automodule_re = re.compile(\n        r'^\\s*\\.\\.\\s+automodule::\\s*([A-Za-z0-9_.]+)\\s*$')\n    module_re = re.compile(\n        r'^\\s*\\.\\.\\s+(current)?module::\\s*([a-zA-Z0-9_.]+)\\s*$')\n    autosummary_item_re = re.compile(r'^\\s+(~?[_a-zA-Z][a-zA-Z0-9_.]*)\\s*.*?')\n    toctree_arg_re = re.compile(r'^\\s+:toctree:\\s*(.*?)\\s*$')\n    template_arg_re = re.compile(r'^\\s+:template:\\s*(.*?)\\s*$')\n\n    documented = []\n\n    toctree = None\n    template = None\n    current_module = module\n    in_autosummary = False\n    base_indent = \"\"\n\n    for line in lines:\n        if in_autosummary:\n            m = toctree_arg_re.match(line)\n            if m:\n                toctree = m.group(1)\n                if filename:\n                    toctree = os.path.join(os.path.dirname(filename),\n                                           toctree)\n                continue\n\n            m = template_arg_re.match(line)\n            if m:\n                template = m.group(1).strip()\n                continue\n\n            if line.strip().startswith(':'):\n                continue # skip options\n\n            m = autosummary_item_re.match(line)\n            if m:\n                name = m.group(1).strip()\n                if name.startswith('~'):\n                    name = name[1:]\n                if current_module and \\\n                       not name.startswith(current_module + '.'):\n                    name = \"%s.%s\" % (current_module, name)\n                documented.append((name, toctree, template))\n                continue\n\n            if not line.strip() or line.startswith(base_indent + \" \"):\n                continue\n\n            in_autosummary = False\n\n        m = autosummary_re.match(line)\n        if m:\n            in_autosummary = True\n            base_indent = m.group(1)\n            toctree = None\n            template = None\n            continue\n\n        m = automodule_re.search(line)\n        if m:\n            current_module = m.group(1).strip()\n            # recurse into the automodule docstring\n            documented.extend(find_autosummary_in_docstring(\n                current_module, filename=filename))\n            continue\n\n        m = module_re.match(line)\n        if m:\n            current_module = m.group(2)\n            continue\n\n    return documented", "response": "Find out what items appear in the given lines."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding the object and all their childs", "response": "def load_object(self, obj=None):\n        \"Add the object and all their childs\"\n        # if not obj is given, do a full reload using the current root\n        if obj:\n            self.root_obj = obj\n        else:\n            obj = self.root_obj\n        self.tree.DeleteAllItems()\n        self.root = self.tree.AddRoot(\"application\")\n        self.tree.SetItemText(self.root, \"App\", 1)\n        self.tree.SetItemText(self.root, \"col 2 root\", 2)\n        #self.tree.SetItemImage(self.root, fldridx, which = wx.TreeItemIcon_Normal)\n        #self.tree.SetItemImage(self.root, fldropenidx, which = wx.TreeItemIcon_Expanded)\n\n        self.build_tree(self.root, obj)\n        self.tree.Expand(self.root)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nselecting the object and show its properties", "response": "def inspect(self, obj, context_menu=False, edit_prop=False, mouse_pos=None):\n        \"Select the object and show its properties\"\n        child = self.tree.FindItem(self.root, obj.name)\n        if DEBUG: print \"inspect child\", child\n        if child:\n            self.tree.ScrollTo(child)\n            self.tree.SetCurrentItem(child)\n            self.tree.SelectItem(child)\n            child.Selected = True\n            self.activate_item(child, edit_prop)\n            if context_menu:\n                self.show_context_menu(child, mouse_pos)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading the selected item in the property editor", "response": "def activate_item(self, child, edit_prop=False, select=False):\n        \"load the selected item in the property editor\"\n        d = self.tree.GetItemData(child)\n        if d:\n            o = d.GetData()\n            self.selected_obj = o\n            callback = lambda o=o, **kwargs: self.update(o, **kwargs)\n            self.propeditor.load_object(o, callback)\n            if edit_prop:\n                wx.CallAfter(self.propeditor.edit)\n            if select and self.designer:\n                self.designer.select(o)\n        else:\n            self.selected_obj = None"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate the tree item when the object name changes", "response": "def update(self, obj, **kwargs):\n        \"Update the tree item when the object name changes\"\n        # search for the old name:\n        child = self.tree.FindItem(self.root, kwargs['name'])\n        if DEBUG: print \"update child\", child, kwargs\n        if child:\n            self.tree.ScrollTo(child)\n            self.tree.SetCurrentItem(child)\n            self.tree.SelectItem(child)\n            child.Selected = True\n            # update the new name\n            self.tree.SetItemText(child, obj.name, 0)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef show_context_menu(self, item, mouse_pos=None):\n        \"Open a popup menu with options regarding the selected object\"\n        if item:\n            d = self.tree.GetItemData(item)\n            if d:\n                obj = d.GetData()\n                if obj:\n                    # highligh and store the selected object:\n                    self.highlight(obj.wx_obj)\n                    self.obj = obj\n                    \n                    # make the context menu\n                    menu = wx.Menu()\n                    id_del, id_dup, id_raise, id_lower = [wx.NewId() for i\n                                                            in range(4)]\n                    menu.Append(id_del, \"Delete\")\n                    menu.Append(id_dup, \"Duplicate\")\n                    menu.Append(id_raise, \"Bring to Front\")\n                    menu.Append(id_lower, \"Send to Back\")\n\n                    # make submenu!\n                    sm = wx.Menu()\n                    for ctrl in sorted(obj._meta.valid_children,\n                                       key=lambda c: \n                                            registry.ALL.index(c._meta.name)):\n                        new_id = wx.NewId()\n                        sm.Append(new_id, ctrl._meta.name)\n                        self.Bind(wx.EVT_MENU, \n                                  lambda evt, ctrl=ctrl: self.add_child(ctrl, mouse_pos), \n                                  id=new_id)\n                        \n                    menu.AppendMenu(wx.NewId(), \"Add child\", sm)\n\n                    self.Bind(wx.EVT_MENU, self.delete, id=id_del)\n                    self.Bind(wx.EVT_MENU, self.duplicate, id=id_dup)\n                    self.Bind(wx.EVT_MENU, self.bring_to_front, id=id_raise)\n                    self.Bind(wx.EVT_MENU, self.send_to_back, id=id_lower)\n\n                    self.PopupMenu(menu)\n                    menu.Destroy()\n                    self.load_object(self.root_obj)", "response": "Open a popup menu with options regarding the selected object"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_parent(self, new_parent, init=False):\n        \"Re-parent a child control with the new wx_obj parent (owner)\"\n        ##SubComponent.set_parent(self, new_parent, init)\n        self.wx_obj.SetOwner(new_parent.wx_obj.GetEventHandler())", "response": "Re - parent a child control with the new wx_obj parent ( owner"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nperforming the actual serialization.", "response": "def to_representation(self, value):\n        \"\"\"\n        Perform the actual serialization.\n\n        Args:\n            value: the image to transform\n        Returns:\n            a url pointing at a scaled and cached image\n        \"\"\"\n        if not value:\n            return None\n\n        image = get_thumbnail(value, self.geometry_string, **self.options)\n\n        try:\n            request = self.context.get('request', None)\n            return request.build_absolute_uri(image.url)\n        except:\n            try:\n                return super(HyperlinkedSorlImageField, self).to_representation(image)\n            except AttributeError:  # NOQA\n                return super(HyperlinkedSorlImageField, self).to_native(image.url)  # NOQA"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nbuilding and registers a :class:`Selector` object with the given name and configuration. Args: name (str): The name of the selector. Yields: SelectorFactory: The factory that will build the :class:`Selector`.", "response": "def add_selector(name):\n    \"\"\"\n    Builds and registers a :class:`Selector` object with the given name and configuration.\n\n    Args:\n        name (str): The name of the selector.\n\n    Yields:\n        SelectorFactory: The factory that will build the :class:`Selector`.\n    \"\"\"\n\n    factory = SelectorFactory(name)\n    yield factory\n    selectors[name] = factory.build_selector()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the expression filters for this selector.", "response": "def expression_filters(self):\n        \"\"\" Dict[str, ExpressionFilter]: Returns the expression filters for this selector. \"\"\"\n\n        return {\n            name: filter for name, filter in iter(self.filters.items())\n            if isinstance(filter, ExpressionFilter)}"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef node_filters(self):\n\n        return {\n            name: filter for name, filter in iter(self.filters.items())\n            if isinstance(filter, NodeFilter)}", "response": "Returns the node filters for this selector."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef expression_filter(self, name, **kwargs):\n\n        def decorator(func):\n            self.filters[name] = ExpressionFilter(name, func, **kwargs)\n\n        return decorator", "response": "Returns a decorator function for adding an expression filter."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a function that adds a node filter.", "response": "def node_filter(self, name, **kwargs):\n        \"\"\"\n        Returns a decorator function for adding a node filter.\n\n        Args:\n            name (str): The name of the filter.\n            **kwargs: Variable keyword arguments for the filter.\n\n        Returns:\n            Callable[[Callable[[Element, Any], bool]]]: A decorator function for adding a node\n                filter.\n        \"\"\"\n\n        def decorator(func):\n            self.filters[name] = NodeFilter(name, func, **kwargs)\n\n        return decorator"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds filters from a particular global filter set.", "response": "def filter_set(self, name):\n        \"\"\"\n        Adds filters from a particular global :class:`FilterSet`.\n\n        Args:\n            name (str): The name of the set whose filters should be added.\n        \"\"\"\n\n        filter_set = filter_sets[name]\n        for name, filter in iter(filter_set.filters.items()):\n            self.filters[name] = filter\n        self.descriptions += filter_set.descriptions"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nbuild a new Selector instance with the current configuration.", "response": "def build_selector(self):\n        \"\"\" Selector: Returns a new :class:`Selector` instance with the current configuration. \"\"\"\n\n        kwargs = {\n            'label': self.label,\n            'descriptions': self.descriptions,\n            'filters': self.filters}\n        if self.format == \"xpath\":\n            kwargs['xpath'] = self.func\n        if self.format == \"css\":\n            kwargs['css'] = self.func\n\n        return Selector(self.name, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nresolves this query relative to the given node.", "response": "def resolves_for(self, node):\n        \"\"\"\n        Resolves this query relative to the given node.\n\n        Args:\n            node (node.Base): The node to be evaluated.\n\n        Returns:\n            int: The number of matches found.\n        \"\"\"\n\n        self.node = node\n        self.actual_styles = node.style(*self.expected_styles.keys())\n\n        return all(\n            toregex(value).search(self.actual_styles[style])\n            for style, value in iter(self.expected_styles.items()))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nasserts that the page has the given path.", "response": "def assert_current_path(self, path, **kwargs):\n        \"\"\"\n        Asserts that the page has the given path. By default this will compare against the\n        path+query portion of the full URL.\n\n        Args:\n            path (str | RegexObject): The string or regex that the current \"path\" should match.\n            **kwargs: Arbitrary keyword arguments for :class:`CurrentPathQuery`.\n\n        Returns:\n            True\n\n        Raises:\n            ExpectationNotMet: If the assertion hasn't succeeded during the wait time.\n        \"\"\"\n\n        query = CurrentPathQuery(path, **kwargs)\n\n        @self.document.synchronize\n        def assert_current_path():\n            if not query.resolves_for(self):\n                raise ExpectationNotMet(query.failure_message)\n        assert_current_path()\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nassert that the page doesn t have the given path.", "response": "def assert_no_current_path(self, path, **kwargs):\n        \"\"\"\n        Asserts that the page doesn't have the given path.\n\n        Args:\n            path (str | RegexObject): The string or regex that the current \"path\" should match.\n            **kwargs: Arbitrary keyword arguments for :class:`CurrentPathQuery`.\n\n        Returns:\n            True\n\n        Raises:\n            ExpectationNotMet: If the assertion hasn't succeeded during the wait time.\n        \"\"\"\n\n        query = CurrentPathQuery(path, **kwargs)\n\n        @self.document.synchronize\n        def assert_no_current_path():\n            if query.resolves_for(self):\n                raise ExpectationNotMet(query.negative_failure_message)\n\n        assert_no_current_path()\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef has_current_path(self, path, **kwargs):\n\n        try:\n            return self.assert_current_path(path, **kwargs)\n        except ExpectationNotMet:\n            return False", "response": "Checks if the page has the given path."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef has_no_current_path(self, path, **kwargs):\n\n        try:\n            return self.assert_no_current_path(path, **kwargs)\n        except ExpectationNotMet:\n            return False", "response": "Checks if the page doesn t have the given path."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nretrieves the text of the element.", "response": "def text(self):\n        \"\"\"\n        Retrieve the text of the element. If :data:`capybara.ignore_hidden_elements` is ``True``,\n        which it is by default, then this will return only text which is visible. The exact\n        semantics of this may differ between drivers, but generally any text within elements with\n        ``display: none`` is ignored.\n\n        Returns:\n            str: The text of the element.\n        \"\"\"\n\n        if capybara.ignore_hidden_elements or capybara.visible_text_only:\n            return self.visible_text\n        else:\n            return self.all_text"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef select_option(self):\n        if self.disabled:\n            warn(\"Attempt to select disabled option: {}\".format(self.value or self.text))\n        self.base.select_option()", "response": "Select this node if it is an option element inside a select tag."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the given expression filtered by the given value.", "response": "def apply_filter(self, expr, value):\n        \"\"\"\n        Returns the given expression filtered by the given value.\n\n        Args:\n            expr (xpath.expression.AbstractExpression): The expression to filter.\n            value (object): The desired value with which the expression should be filtered.\n\n        Returns:\n            xpath.expression.AbstractExpression: The filtered expression.\n        \"\"\"\n\n        if self.skip(value):\n            return expr\n\n        if not self._valid_value(value):\n            msg = \"Invalid value {value} passed to filter {name} - \".format(\n                value=repr(value),\n                name=self.name)\n\n            if self.default is not None:\n                warn(msg + \"defaulting to {}\".format(self.default))\n                value = self.default\n            else:\n                warn(msg + \"skipping\")\n                return expr\n\n        return self.func(expr, value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_browser(browser_name, capabilities=None, **options):\n\n    if browser_name == \"chrome\":\n        return webdriver.Chrome(desired_capabilities=capabilities, **options)\n    if browser_name == \"edge\":\n        return webdriver.Edge(capabilities=capabilities, **options)\n    if browser_name in [\"ff\", \"firefox\"]:\n        return webdriver.Firefox(capabilities=capabilities, **options)\n    if browser_name in [\"ie\", \"internet_explorer\"]:\n        return webdriver.Ie(capabilities=capabilities, **options)\n    if browser_name == \"phantomjs\":\n        return webdriver.PhantomJS(desired_capabilities=capabilities, **options)\n    if browser_name == \"remote\":\n        return webdriver.Remote(desired_capabilities=capabilities, **options)\n    if browser_name == \"safari\":\n        return webdriver.Safari(desired_capabilities=capabilities, **options)\n\n    raise ValueError(\"unsupported browser: {}\".format(repr(browser_name)))", "response": "Returns an instance of the given browser with the given capabilities."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the keyword arguments that this query was initialized.", "response": "def kwargs(self):\n        \"\"\" Dict[str, Any]: The keyword arguments with which this query was initialized. \"\"\"\n        kwargs = {}\n        kwargs.update(self.options)\n        kwargs.update(self.filter_options)\n        return kwargs"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef description(self):\n\n        description = self.label\n\n        if self.locator:\n            description += \" {}\".format(desc(self.locator))\n        if self.options[\"text\"] is not None:\n            description += \" with text {}\".format(desc(self.options[\"text\"]))\n\n        description += self.selector.description(self.filter_options)\n\n        return description", "response": "A long description of this query."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the XPath query for this selector.", "response": "def xpath(self, exact=None):\n        \"\"\"\n        Returns the XPath query for this selector.\n\n        Args:\n            exact (bool, optional): Whether to exactly match text.\n\n        Returns:\n            str: The XPath query for this selector.\n        \"\"\"\n\n        exact = exact if exact is not None else self.exact\n\n        if isinstance(self.expression, AbstractExpression):\n            expression = self._apply_expression_filters(self.expression)\n\n            return to_xpath(expression, exact=exact)\n        else:\n            return str_(self.expression)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nresolves this query relative to the given node.", "response": "def resolve_for(self, node, exact=None):\n        \"\"\"\n        Resolves this query relative to the given node.\n\n        Args:\n            node (node.Base): The node relative to which this query should be resolved.\n            exact (bool, optional): Whether to exactly match text.\n\n        Returns:\n            list[Element]: A list of elements matched by this query.\n        \"\"\"\n\n        from capybara.driver.node import Node\n        from capybara.node.element import Element\n        from capybara.node.simple import Simple\n\n        @node.synchronize\n        def resolve():\n            if self.selector.format == \"css\":\n                children = node._find_css(self.css())\n            else:\n                children = node._find_xpath(self.xpath(exact))\n\n            def wrap(child):\n                if isinstance(child, Node):\n                    return Element(node.session, child, node, self)\n                else:\n                    return Simple(child)\n\n            children = [wrap(child) for child in children]\n\n            return Result(children, self)\n\n        return resolve()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns whether the given node matches all filters.", "response": "def matches_filters(self, node):\n        \"\"\"\n        Returns whether the given node matches all filters.\n\n        Args:\n            node (Element): The node to evaluate.\n\n        Returns:\n            bool: Whether the given node matches.\n        \"\"\"\n\n        visible = self.visible\n\n        if self.options[\"text\"]:\n            if isregex(self.options[\"text\"]):\n                regex = self.options[\"text\"]\n            elif self.exact_text is True:\n                regex = re.compile(r\"\\A{}\\Z\".format(re.escape(self.options[\"text\"])))\n            else:\n                regex = toregex(self.options[\"text\"])\n\n            text = normalize_text(\n                node.all_text if visible == \"all\" else node.visible_text)\n\n            if not regex.search(text):\n                return False\n\n        if isinstance(self.exact_text, (bytes_, str_)):\n            regex = re.compile(r\"\\A{}\\Z\".format(re.escape(self.exact_text)))\n\n            text = normalize_text(\n                node.all_text if visible == \"all\" else node.visible_text)\n\n            if not regex.search(text):\n                return False\n\n        if visible == \"visible\":\n            if not node.visible:\n                return False\n        elif visible == \"hidden\":\n            if node.visible:\n                return False\n\n        for name, node_filter in iter(self._node_filters.items()):\n            if name in self.filter_options:\n                if not node_filter.matches(node, self.filter_options[name]):\n                    return False\n            elif node_filter.has_default:\n                if not node_filter.matches(node, node_filter.default):\n                    return False\n\n        if self.options[\"filter\"] and not self.options[\"filter\"](node):\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef current_scope(self):\n        scope = self._scopes[-1]\n        if scope in [None, \"frame\"]:\n            scope = self.document\n        return scope", "response": "Returns the current scope of the current node."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef current_host(self):\n\n        if not self.current_url:\n            return\n\n        result = urlparse(self.current_url)\n        scheme, netloc = result.scheme, result.netloc\n        host = netloc.split(\":\")[0] if netloc else None\n        return \"{0}://{1}\".format(scheme, host) if host else None", "response": "str - Host of the current page."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef visit(self, visit_uri):\n\n        self.raise_server_error()\n\n        visit_uri = urlparse(visit_uri)\n\n        if capybara.app_host:\n            uri_base = urlparse(capybara.app_host)\n        elif self.server:\n            uri_base = urlparse(\"http://{}:{}\".format(self.server.host, self.server.port))\n        else:\n            uri_base = None\n\n        visit_uri = ParseResult(\n            scheme=visit_uri.scheme or (uri_base.scheme if uri_base else \"\"),\n            netloc=visit_uri.netloc or (uri_base.netloc if uri_base else \"\"),\n            path=visit_uri.path,\n            params=visit_uri.params,\n            query=visit_uri.query,\n            fragment=visit_uri.fragment)\n\n        self.driver.visit(visit_uri.geturl())", "response": "Navigate to the given URL."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef scope(self, *args, **kwargs):\n\n        new_scope = args[0] if isinstance(args[0], Base) else self.find(*args, **kwargs)\n        self._scopes.append(new_scope)\n        try:\n            yield\n        finally:\n            self._scopes.pop()", "response": "A context manager that finds and returns the elements that are in the given selector."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nexecutes the wrapped code within the given iframe.", "response": "def frame(self, locator=None, *args, **kwargs):\n        \"\"\"\n        Execute the wrapped code within the given iframe using the given frame or frame name/id.\n        May not be supported by all drivers.\n\n        Args:\n            locator (str | Element, optional): The name/id of the frame or the frame's element.\n                Defaults to the only frame in the document.\n        \"\"\"\n\n        self.switch_to_frame(self._find_frame(locator, *args, **kwargs))\n        try:\n            yield\n        finally:\n            self.switch_to_frame(\"parent\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef switch_to_frame(self, frame):\n\n        if isinstance(frame, Element):\n            self.driver.switch_to_frame(frame)\n            self._scopes.append(\"frame\")\n        elif frame == \"parent\":\n            if self._scopes[-1] != \"frame\":\n                raise ScopeError(\"`switch_to_frame(\\\"parent\\\")` cannot be called \"\n                                 \"from inside a descendant frame's `scope` context.\")\n            self._scopes.pop()\n            self.driver.switch_to_frame(\"parent\")\n        elif frame == \"top\":\n            if \"frame\" in self._scopes:\n                idx = self._scopes.index(\"frame\")\n                if any([scope not in [\"frame\", None] for scope in self._scopes[idx:]]):\n                    raise ScopeError(\"`switch_to_frame(\\\"top\\\")` cannot be called \"\n                                     \"from inside a descendant frame's `scope` context.\")\n                self._scopes = self._scopes[:idx]\n                self.driver.switch_to_frame(\"top\")\n        else:\n            raise ValueError(\n                \"You must provide a frame element, \\\"parent\\\", or \\\"top\\\" \"\n                \"when calling switch_to_frame\")", "response": "Switches the current locale to the given frame."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef switch_to_window(self, window, wait=None):\n\n        if len(self._scopes) > 1:\n            raise ScopeError(\n                \"`switch_to_window` is not supposed to be invoked from \"\n                \"within `scope`s, `frame`s, or other `window`s.\")\n\n        if isinstance(window, Window):\n            self.driver.switch_to_window(window.handle)\n            return window\n        else:\n            @self.document.synchronize(errors=(WindowError,), wait=wait)\n            def switch_and_get_matching_window():\n                original_window_handle = self.driver.current_window_handle\n                try:\n                    for handle in self.driver.window_handles:\n                        self.driver.switch_to_window(handle)\n                        result = window()\n                        if result:\n                            return Window(self, handle)\n                except Exception:\n                    self.driver.switch_to_window(original_window_handle)\n                    raise\n\n                self.driver.switch_to_window(original_window_handle)\n                raise WindowError(\"Could not find a window matching lambda\")\n\n            return switch_and_get_matching_window()", "response": "Switches to a window."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef window(self, window):\n\n        original = self.current_window\n        if window != original:\n            self.switch_to_window(window)\n        self._scopes.append(None)\n        try:\n            yield\n        finally:\n            self._scopes.pop()\n            if original != window:\n                self.switch_to_window(original)", "response": "Context manager for the given window."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef window_opened_by(self, trigger_func, wait=None):\n\n        old_handles = set(self.driver.window_handles)\n        trigger_func()\n\n        @self.document.synchronize(wait=wait, errors=(WindowError,))\n        def get_new_window():\n            opened_handles = set(self.driver.window_handles) - old_handles\n            if len(opened_handles) != 1:\n                raise WindowError(\"lambda passed to `window_opened_by` \"\n                                  \"opened {0} windows instead of 1\".format(len(opened_handles)))\n            return Window(self, list(opened_handles)[0])\n\n        return get_new_window()", "response": "Get the window that has been opened by the passed lambda."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef execute_script(self, script, *args):\n\n        args = [arg.base if isinstance(arg, Base) else arg for arg in args]\n        self.driver.execute_script(script, *args)", "response": "Execute a JavaScript script and return a result."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nevaluating the given JavaScript and returns the result.", "response": "def evaluate_script(self, script, *args):\n        \"\"\"\n        Evaluate the given JavaScript and return the result. Be careful when using this with\n        scripts that return complex objects, such as jQuery statements. :meth:`execute_script`\n        might be a better alternative.\n\n        Args:\n            script (str): A string of JavaScript to evaluate.\n            *args: Variable length argument list to pass to the executed JavaScript string.\n\n        Returns:\n            object: The result of the evaluated JavaScript (may be driver specific).\n        \"\"\"\n\n        args = [arg.base if isinstance(arg, Base) else arg for arg in args]\n        result = self.driver.evaluate_script(script, *args)\n        return self._wrap_element_script_result(result)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nexecutes the wrapped code accepting an alert.", "response": "def accept_alert(self, text=None, wait=None):\n        \"\"\"\n        Execute the wrapped code, accepting an alert.\n\n        Args:\n            text (str | RegexObject, optional): Text to match against the text in the modal.\n            wait (int | float, optional): Maximum time to wait for the modal to appear after\n                executing the wrapped code.\n\n        Raises:\n            ModalNotFound: If a modal dialog hasn't been found.\n        \"\"\"\n\n        wait = wait or capybara.default_max_wait_time\n        with self.driver.accept_modal(\"alert\", text=text, wait=wait):\n            yield"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef accept_confirm(self, text=None, wait=None):\n\n        with self.driver.accept_modal(\"confirm\", text=text, wait=wait):\n            yield", "response": "Execute the wrapped code accepting a confirm."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nexecutes the wrapped code dismissing a modal.", "response": "def dismiss_confirm(self, text=None, wait=None):\n        \"\"\"\n        Execute the wrapped code, dismissing a confirm.\n\n        Args:\n            text (str | RegexObject, optional): Text to match against the text in the modal.\n            wait (int | float, optional): Maximum time to wait for the modal to appear after\n                executing the wrapped code.\n\n        Raises:\n            ModalNotFound: If a modal dialog hasn't been found.\n        \"\"\"\n\n        with self.driver.dismiss_modal(\"confirm\", text=text, wait=wait):\n            yield"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nexecutes the wrapped code accepting a prompt optionally responding to the prompt.", "response": "def accept_prompt(self, text=None, response=None, wait=None):\n        \"\"\"\n        Execute the wrapped code, accepting a prompt, optionally responding to the prompt.\n\n        Args:\n            text (str | RegexObject, optional): Text to match against the text in the modal.\n            response (str, optional): Response to provide to the prompt.\n            wait (int | float, optional): Maximum time to wait for the modal to appear after\n                executing the wrapped code.\n\n        Raises:\n            ModalNotFound: If a modal dialog hasn't been found.\n        \"\"\"\n\n        with self.driver.accept_modal(\"prompt\", text=text, response=response, wait=wait):\n            yield"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dismiss_prompt(self, text=None, wait=None):\n\n        with self.driver.dismiss_modal(\"prompt\", text=text, wait=wait):\n            yield", "response": "Execute the wrapped code dismissing a prompt."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef save_page(self, path=None):\n\n        path = _prepare_path(path, \"html\")\n\n        with open(path, \"wb\") as f:\n            f.write(encode_string(self.body))\n\n        return path", "response": "Save a snapshot of the page."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsave a screenshot of the page.", "response": "def save_screenshot(self, path=None, **kwargs):\n        \"\"\"\n        Save a screenshot of the page.\n\n        If invoked without arguments, it will save a file to :data:`capybara.save_path` and the\n        file will be given a randomly generated filename. If invoked with a relative path, the path\n        will be relative to :data:`capybara.save_path`.\n\n        Args:\n            path (str, optional): The path to where it should be saved.\n            **kwargs: Arbitrary keywords arguments for the driver.\n\n        Returns:\n            str: The path to which the file was saved.\n        \"\"\"\n\n        path = _prepare_path(path, \"png\")\n        self.driver.save_screenshot(path, **kwargs)\n        return path"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nresetting the session and return the current session s cookie.", "response": "def reset(self):\n        \"\"\"\n        Reset the session (i.e., remove cookies and navigate to a blank page).\n\n        This method does not:\n        * accept modal dialogs if they are present (the Selenium driver does, but others may not),\n        * clear the browser cache/HTML 5 local storage/IndexedDB/Web SQL database/etc., or\n        * modify the state of the driver/underlying browser in any other way\n\n        as doing so would result in performance downsides and it's not needed to do everything\n        from the list above for most apps.\n\n        If you want to do anything from the list above on a general basis you can write a test\n        teardown method.\n        \"\"\"\n\n        self.driver.reset()\n        if self.server:\n            self.server.wait_for_pending_requests()\n        self.raise_server_error()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef raise_server_error(self):\n        if self.server and self.server.error:\n            try:\n                if capybara.raise_server_errors:\n                    raise self.server.error\n            finally:\n                self.server.reset_error()", "response": "Raise errors encountered by the server."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn whether the given node matches the filter rule with the given value.", "response": "def matches(self, node, value):\n        \"\"\"\n        Returns whether the given node matches the filter rule with the given value.\n\n        Args:\n            node (Element): The node to filter.\n            value (object): The desired value with which the node should be evaluated.\n\n        Returns:\n            bool: Whether the given node matches.\n        \"\"\"\n\n        if self.skip(value):\n            return True\n\n        if not self._valid_value(value):\n            msg = \"Invalid value {value} passed to filter {name} - \".format(\n                value=repr(value),\n                name=self.name)\n\n            if self.default is not None:\n                warn(msg + \"defaulting to {}\".format(self.default))\n                value = self.default\n            else:\n                warn(msg + \"skipping\")\n                return True\n\n        return self.func(node, value)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_version():\n\n    global_vars = {}\n\n    # Compile and execute the individual file to prevent\n    # the package from being automatically loaded.\n    source = read(os.path.join(\"capybara\", \"version.py\"))\n    code = compile(source, \"version.py\", \"exec\")\n    exec(code, global_vars)\n\n    return global_vars['__version__']", "response": "Returns the package version."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nresolves this query relative to the given node.", "response": "def resolves_for(self, node):\n        \"\"\"\n        Resolves this query relative to the given node.\n\n        Args:\n            node (node.Document): The node to be evaluated.\n\n        Returns:\n            bool: Whether the given node matches this query.\n        \"\"\"\n\n        self.actual_title = normalize_text(node.title)\n        return bool(self.search_regexp.search(self.actual_title))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef frame_title(self):\n        elements = self._find_xpath(\"/html/head/title\")\n        titles = [element.all_text for element in elements]\n        return titles[0] if len(titles) else \"\"", "response": "str - The title for the current frame."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef value(self):\n\n        if self.tag_name == \"textarea\":\n            return inner_content(self.native)\n        elif self.tag_name == \"select\":\n            if self[\"multiple\"] == \"multiple\":\n                selected_options = self._find_xpath(\".//option[@selected='selected']\")\n                return [_get_option_value(option) for option in selected_options]\n            else:\n                options = (\n                    self._find_xpath(\".//option[@selected='selected']\") +\n                    self._find_xpath(\".//option\"))\n                return _get_option_value(options[0]) if options else None\n        elif self.tag_name == \"input\" and self[\"type\"] in [\"checkbox\", \"radio\"]:\n            return self[\"value\"] or \"on\"\n        else:\n            return self[\"value\"]", "response": "str - The value of the form element."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_filter_set(name):\n\n    factory = FilterSetFactory(name)\n    yield factory\n    filter_sets[name] = factory.build_filter_set()", "response": "A context manager that builds and registers a global filter set."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the current session if needed.", "response": "def current_session():\n    \"\"\"\n    Returns the :class:`Session` for the current driver and app, instantiating one if needed.\n\n    Returns:\n        Session: The :class:`Session` for the current driver and app.\n    \"\"\"\n\n    driver = current_driver or default_driver\n\n    session_key = \"{driver}:{session}:{app}\".format(\n        driver=driver, session=session_name, app=str(id(app)))\n    session = _session_pool.get(session_key, None)\n\n    if session is None:\n        from capybara.session import Session\n        session = Session(driver, app)\n        _session_pool[session_key] = session\n\n    return session"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef has_all_of_selectors(self, selector, *locators, **kwargs):\n\n        return self.assert_all_of_selectors(selector, *locators, **kwargs)", "response": "Tests if all of the provided selectors are present on the current page or descendants of the current node."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntesting if none of the provided selectors are present on the current page or descendants of the current page.", "response": "def has_none_of_selectors(self, selector, *locators, **kwargs):\n        \"\"\"\n        Checks if none of the provided selectors are present on the given page or descendants of the\n        current node. If options are provided, the assertion will check that each locator is present\n        with those options as well (other than ``wait``). ::\n\n            page.has_none_of_selectors(\"custom\", \"Tom\", \"Joe\", visible=\"all\")\n            page.has_none_of_selectors(\"css\", \"#my_div\", \"a.not_clicked\")\n\n        It accepts all options that :meth:`find_all` accepts, such as ``text`` and ``visible``.\n\n        The ``wait`` option applies to all of the selectors as a group, so none of the locators must\n        be present with ``wait`` (defaults to :data:`capybara.default_max_wait_time`) seconds.\n\n        If the given selector is not a valid selector, the first argument is assumed to be a locator\n        and the default selector will be used.\n\n        Args:\n            selector (str, optional): The name of the selector to use. Defaults to\n                :data:`capybara.default_selector`.\n            *locators (str): Variable length list of locators.\n            **kwargs: Arbitrary keyword arguments for :class:`SelectorQuery`.\n        \"\"\"\n\n        return self.assert_none_of_selectors(selector, *locators, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef assert_selector(self, *args, **kwargs):\n\n        query = SelectorQuery(*args, **kwargs)\n\n        @self.synchronize(wait=query.wait)\n        def assert_selector():\n            result = query.resolve_for(self)\n\n            if not (result.matches_count and\n                    (len(result) > 0 or expects_none(query.options))):\n                raise ExpectationNotMet(result.failure_message)\n\n            return True\n\n        return assert_selector()", "response": "Assert that a given selector is on the page or a descendant of the current node."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef assert_style(self, styles, **kwargs):\n\n        query = StyleQuery(styles, **kwargs)\n\n        @self.synchronize(wait=query.wait)\n        def assert_style():\n            if not query.resolves_for(self):\n                raise ExpectationNotMet(query.failure_message)\n\n            return True\n\n        return assert_style()", "response": "Assert that an element has the specified CSS styles."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nassert that all of the provided selectors are present on the given page or descendants of the current node. If options are provided, the assertion will check that each locator is present with those options as well (other than ``wait``). :: page.assert_all_of_selectors(\"custom\", \"Tom\", \"Joe\", visible=\"all\") page.assert_all_of_selectors(\"css\", \"#my_dif\", \"a.not_clicked\") It accepts all options that :meth:`find_all` accepts, such as ``text`` and ``visible``. The ``wait`` option applies to all of the selectors as a group, so all of the locators must be present within ``wait`` (defaults to :data:`capybara.default_max_wait_time`) seconds. If the given selector is not a valid selector, the first argument is assumed to be a locator and the default selector will be used. Args: selector (str, optional): The name of the selector to use. Defaults to :data:`capybara.default_selector`. *locators (str): Variable length list of locators. **kwargs: Arbitrary keyword arguments for :class:`SelectorQuery`.", "response": "def assert_all_of_selectors(self, selector, *locators, **kwargs):\n        \"\"\"\n        Asserts that all of the provided selectors are present on the given page or descendants of\n        the current node. If options are provided, the assertion will check that each locator is\n        present with those options as well (other than ``wait``). ::\n\n            page.assert_all_of_selectors(\"custom\", \"Tom\", \"Joe\", visible=\"all\")\n            page.assert_all_of_selectors(\"css\", \"#my_dif\", \"a.not_clicked\")\n\n        It accepts all options that :meth:`find_all` accepts, such as ``text`` and ``visible``.\n\n        The ``wait`` option applies to all of the selectors as a group, so all of the locators must\n        be present within ``wait`` (defaults to :data:`capybara.default_max_wait_time`) seconds.\n\n        If the given selector is not a valid selector, the first argument is assumed to be a locator\n        and the default selector will be used.\n\n        Args:\n            selector (str, optional): The name of the selector to use. Defaults to\n                :data:`capybara.default_selector`.\n            *locators (str): Variable length list of locators.\n            **kwargs: Arbitrary keyword arguments for :class:`SelectorQuery`.\n        \"\"\"\n\n        wait = kwargs['wait'] if 'wait' in kwargs else capybara.default_max_wait_time\n\n        if not isinstance(selector, Hashable) or selector not in selectors:\n            locators = (selector,) + locators\n            selector = capybara.default_selector\n\n        @self.synchronize(wait=wait)\n        def assert_all_of_selectors():\n            for locator in locators:\n                self.assert_selector(selector, locator, **kwargs)\n\n            return True\n\n        return assert_all_of_selectors()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nasserting that none of the provided selectors are present on the given page or descendants of the current node. If options are provided, the assertion will check that each locator is present with those options as well (other than ``wait``). :: page.assert_none_of_selectors(\"custom\", \"Tom\", \"Joe\", visible=\"all\") page.assert_none_of_selectors(\"css\", \"#my_div\", \"a.not_clicked\") It accepts all options that :meth:`find_all` accepts, such as ``text`` and ``visible``. The ``wait`` option applies to all of the selectors as a group, so none of the locators must be present with ``wait`` (defaults to :data:`capybara.default_max_wait_time`) seconds. If the given selector is not a valid selector, the first argument is assumed to be a locator and the default selector will be used. Args: selector (str, optional): The name of the selector to use. Defaults to :data:`capybara.default_selector`. *locators (str): Variable length list of locators. **kwargs: Arbitrary keyword arguments for :class:`SelectorQuery`.", "response": "def assert_none_of_selectors(self, selector, *locators, **kwargs):\n        \"\"\"\n        Asserts that none of the provided selectors are present on the given page or descendants of\n        the current node. If options are provided, the assertion will check that each locator is\n        present with those options as well (other than ``wait``). ::\n\n            page.assert_none_of_selectors(\"custom\", \"Tom\", \"Joe\", visible=\"all\")\n            page.assert_none_of_selectors(\"css\", \"#my_div\", \"a.not_clicked\")\n\n        It accepts all options that :meth:`find_all` accepts, such as ``text`` and ``visible``.\n\n        The ``wait`` option applies to all of the selectors as a group, so none of the locators must\n        be present with ``wait`` (defaults to :data:`capybara.default_max_wait_time`) seconds.\n\n        If the given selector is not a valid selector, the first argument is assumed to be a locator\n        and the default selector will be used.\n\n        Args:\n            selector (str, optional): The name of the selector to use. Defaults to\n                :data:`capybara.default_selector`.\n            *locators (str): Variable length list of locators.\n            **kwargs: Arbitrary keyword arguments for :class:`SelectorQuery`.\n        \"\"\"\n        wait = kwargs['wait'] if 'wait' in kwargs else capybara.default_max_wait_time\n\n        if not isinstance(selector, Hashable) or selector not in selectors:\n            locators = (selector,) + locators\n            selector = capybara.default_selector\n\n        @self.synchronize(wait=wait)\n        def assert_none_of_selectors():\n            for locator in locators:\n                self.assert_no_selector(selector, locator, **kwargs)\n\n            return True\n\n        return assert_none_of_selectors()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nasserting that a given selector is not on the page or a descendant of the current node. Usage is identical to :meth:`assert_selector`. Query options such as ``count``, ``minimum``, and ``between`` are considered to be an integral part of the selector. This will return True, for example, if a page contains 4 anchors but the query expects 5:: page.assert_no_selector(\"a\", minimum=1) # Found, raises ExpectationNotMet page.assert_no_selector(\"a\", count=4) # Found, raises ExpectationNotMet page.assert_no_selector(\"a\", count=5) # Not Found, returns True Args: *args: Variable length argument list for :class:`SelectorQuery`. **kwargs: Arbitrary keyword arguments for :class:`SelectorQuery`. Returns: True Raises: ExpectationNotMet: The given selector matched.", "response": "def assert_no_selector(self, *args, **kwargs):\n        \"\"\"\n        Asserts that a given selector is not on the page or a descendant of the current node. Usage\n        is identical to :meth:`assert_selector`.\n\n        Query options such as ``count``, ``minimum``, and ``between`` are considered to be an\n        integral part of the selector. This will return True, for example, if a page contains 4\n        anchors but the query expects 5::\n\n            page.assert_no_selector(\"a\", minimum=1)  # Found, raises ExpectationNotMet\n            page.assert_no_selector(\"a\", count=4)    # Found, raises ExpectationNotMet\n            page.assert_no_selector(\"a\", count=5)    # Not Found, returns True\n\n        Args:\n            *args: Variable length argument list for :class:`SelectorQuery`.\n            **kwargs: Arbitrary keyword arguments for :class:`SelectorQuery`.\n\n        Returns:\n            True\n\n        Raises:\n            ExpectationNotMet: The given selector matched.\n        \"\"\"\n\n        query = SelectorQuery(*args, **kwargs)\n\n        @self.synchronize(wait=query.wait)\n        def assert_no_selector():\n            result = query.resolve_for(self)\n\n            if result.matches_count and (\n                   len(result) > 0 or expects_none(query.options)):\n                raise ExpectationNotMet(result.negative_failure_message)\n\n            return True\n\n        return assert_no_selector()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nasserts that the current node matches a given selector.", "response": "def assert_matches_selector(self, *args, **kwargs):\n        \"\"\"\n        Asserts that the current node matches a given selector. ::\n\n            node.assert_matches_selector(\"p#foo\")\n            node.assert_matches_selector(\"xpath\", \"//p[@id='foo']\")\n\n        It also accepts all options that :meth:`find_all` accepts, such as ``text`` and\n        ``visible``. ::\n\n            node.assert_matches_selector(\"li\", text=\"Horse\", visible=True)\n\n        Args:\n            *args: Variable length argument list for :class:`SelectorQuery`.\n            **kwargs: Arbitrary keyword arguments for :class:`SelectorQuery`.\n\n        Returns:\n            True\n\n        Raises:\n            ExpectationNotMet: If the selector does not match.\n        \"\"\"\n\n        query = SelectorQuery(*args, **kwargs)\n\n        @self.synchronize(wait=query.wait)\n        def assert_matches_selector():\n            result = query.resolve_for(self.find_first(\"xpath\", \"./parent::*\", minimum=0) or self.query_scope)\n\n            if self not in result:\n                raise ExpectationNotMet(\"Item does not match the provided selector\")\n\n            return True\n\n        return assert_matches_selector()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks if the page or current node has a radio button or checkbox with the given label name or id or id that is currently checked.", "response": "def has_checked_field(self, locator, **kwargs):\n        \"\"\"\n        Checks if the page or current node has a radio button or checkbox with the given label,\n        value, or id, that is currently checked.\n\n        Args:\n            locator (str): The label, name, or id of a checked field.\n            **kwargs: Arbitrary keyword arguments for :class:`SelectorQuery`.\n\n        Returns:\n            bool: Whether it exists.\n        \"\"\"\n\n        kwargs[\"checked\"] = True\n        return self.has_selector(\"field\", locator, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef has_no_checked_field(self, locator, **kwargs):\n\n        kwargs[\"checked\"] = True\n        return self.has_no_selector(\"field\", locator, **kwargs)", "response": "Checks if the page or current node has no radio button or checkbox with the given label name or id or id that is currently checked."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef has_unchecked_field(self, locator, **kwargs):\n\n        kwargs[\"checked\"] = False\n        return self.has_selector(\"field\", locator, **kwargs)", "response": "Checks if the page or current node has a radio button or checkbox with the given label name or id or id that is currently unchecked."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef has_no_unchecked_field(self, locator, **kwargs):\n\n        kwargs[\"checked\"] = False\n        return self.has_no_selector(\"field\", locator, **kwargs)", "response": "Checks if the page or current node has no radio button or checkbox with the given label name or id or id."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef assert_text(self, *args, **kwargs):\n\n        query = TextQuery(*args, **kwargs)\n\n        @self.synchronize(wait=query.wait)\n        def assert_text():\n            count = query.resolve_for(self)\n\n            if not (matches_count(count, query.options) and\n                    (count > 0 or expects_none(query.options))):\n                raise ExpectationNotMet(query.failure_message)\n\n            return True\n\n        return assert_text()", "response": "Assert that the page or current node has the given text content ignoring any HTML tags."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nasserts that the page or current node doesn t have the given text content.", "response": "def assert_no_text(self, *args, **kwargs):\n        \"\"\"\n        Asserts that the page or current node doesn't have the given text content, ignoring any\n        HTML tags.\n\n        Args:\n            *args: Variable length argument list for :class:`TextQuery`.\n            **kwargs: Arbitrary keyword arguments for :class:`TextQuery`.\n\n        Returns:\n            True\n\n        Raises:\n            ExpectationNotMet: If the assertion hasn't succeeded during the wait time.\n        \"\"\"\n\n        query = TextQuery(*args, **kwargs)\n\n        @self.synchronize(wait=query.wait)\n        def assert_no_text():\n            count = query.resolve_for(self)\n\n            if matches_count(count, query.options) and (\n                   count > 0 or expects_none(query.options)):\n                raise ExpectationNotMet(query.negative_failure_message)\n\n            return True\n\n        return assert_no_text()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nasserts that the page has the given title.", "response": "def assert_title(self, title, **kwargs):\n        \"\"\"\n        Asserts that the page has the given title.\n\n        Args:\n            title (str | RegexObject): The string or regex that the title should match.\n            **kwargs: Arbitrary keyword arguments for :class:`TitleQuery`.\n\n        Returns:\n            True\n\n        Raises:\n            ExpectationNotMet: If the assertion hasn't succeeded during the wait time.\n        \"\"\"\n\n        query = TitleQuery(title, **kwargs)\n\n        @self.synchronize(wait=query.wait)\n        def assert_title():\n            if not query.resolves_for(self):\n                raise ExpectationNotMet(query.failure_message)\n\n            return True\n\n        return assert_title()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nasserting that the page doesn t have the given title.", "response": "def assert_no_title(self, title, **kwargs):\n        \"\"\"\n        Asserts that the page doesn't have the given title.\n\n        Args:\n            title (str | RegexObject): The string that the title should include.\n            **kwargs: Arbitrary keyword arguments for :class:`TitleQuery`.\n\n        Returns:\n            True\n\n        Raises:\n            ExpectationNotMet: If the assertion hasn't succeeded during the wait time.\n        \"\"\"\n\n        query = TitleQuery(title, **kwargs)\n\n        @self.synchronize(wait=query.wait)\n        def assert_no_title():\n            if query.resolves_for(self):\n                raise ExpectationNotMet(query.negative_failure_message)\n\n            return True\n\n        return assert_no_title()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck if the page has the given title.", "response": "def has_title(self, title, **kwargs):\n        \"\"\"\n        Checks if the page has the given title.\n\n        Args:\n            title (str | RegexObject): The string or regex that the title should match.\n            **kwargs: Arbitrary keyword arguments for :class:`TitleQuery`.\n\n        Returns:\n            bool: Whether it matches.\n        \"\"\"\n\n        try:\n            self.assert_title(title, **kwargs)\n            return True\n        except ExpectationNotMet:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef has_no_title(self, title, **kwargs):\n\n        try:\n            self.assert_no_title(title, **kwargs)\n            return True\n        except ExpectationNotMet:\n            return False", "response": "Checks if the page doesn t have the given title."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinding all elements on the page matching the given selector and options.", "response": "def find_all(self, *args, **kwargs):\n        \"\"\"\n        Find all elements on the page matching the given selector and options.\n\n        Both XPath and CSS expressions are supported, but Capybara does not try to automatically\n        distinguish between them. The following statements are equivalent::\n\n            page.find_all(\"css\", \"a#person_123\")\n            page.find_all(\"xpath\", \"//a[@id='person_123']\")\n\n        If the type of selector is left out, Capybara uses :data:`capybara.default_selector`. It's\n        set to ``\"css\"`` by default. ::\n\n            page.find_all(\"a#person_123\")\n\n            capybara.default_selector = \"xpath\"\n            page.find_all(\"//a[@id='person_123']\")\n\n        The set of found elements can further be restricted by specifying options. It's possible to\n        select elements by their text or visibility::\n\n            page.find_all(\"a\", text=\"Home\")\n            page.find_all(\"#menu li\", visible=True)\n\n        By default if no elements are found, an empty list is returned; however, expectations can be\n        set on the number of elements to be found which will trigger Capybara's waiting behavior for\n        the expectations to match. The expectations can be set using::\n\n            page.assert_selector(\"p#foo\", count=4)\n            page.assert_selector(\"p#foo\", maximum=10)\n            page.assert_selector(\"p#foo\", minimum=1)\n            page.assert_selector(\"p#foo\", between=range(1, 11))\n\n        See :func:`capybara.result.Result.matches_count` for additional information about count\n        matching.\n\n        Args:\n            *args: Variable length argument list for :class:`SelectorQuery`.\n            **kwargs: Arbitrary keyword arguments for :class:`SelectorQuery`.\n\n        Returns:\n            Result: A collection of found elements.\n\n        Raises:\n            ExpectationNotMet: The matched results did not meet the expected criteria.\n        \"\"\"\n\n        query = SelectorQuery(*args, **kwargs)\n\n        @self.synchronize(wait=query.wait)\n        def find_all():\n            result = query.resolve_for(self)\n\n            if not result.matches_count:\n                raise ExpectationNotMet(result.failure_message)\n\n            return result\n\n        return find_all()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfinds the first element on the page matching the given selector and options.", "response": "def find_first(self, *args, **kwargs):\n        \"\"\"\n        Find the first element on the page matching the given selector and options, or None if no\n        element matches.\n\n        By default, no waiting behavior occurs. However, if ``capybara.wait_on_first_by_default``\n        is set to true, it will trigger Capybara's waiting behavior for a minimum of 1 matching\n        element to be found.\n\n        Args:\n            *args: Variable length argument list for :class:`SelectorQuery`.\n            **kwargs: Arbitrary keyword arguments for :class:`SelectorQuery`.\n\n        Returns:\n            Element: The found element or None.\n        \"\"\"\n\n        if capybara.wait_on_first_by_default:\n            kwargs.setdefault(\"minimum\", 1)\n\n        try:\n            result = self.find_all(*args, **kwargs)\n            return result[0] if len(result) > 0 else None\n        except ExpectationNotMet:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef resolve_for(self, node):\n\n        self.node = node\n        self.actual_text = normalize_text(\n            node.visible_text if self.query_type == \"visible\" else node.all_text)\n        self.count = len(re.findall(self.search_regexp, self.actual_text))\n\n        return self.count", "response": "Resolves this query relative to the given node."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the inner content of a given XML node including tags.", "response": "def inner_content(node):\n    \"\"\"\n    Returns the inner content of a given XML node, including tags.\n\n    Args:\n        node (lxml.etree.Element): The node whose inner content is desired.\n\n    Returns:\n        str: The inner content of the node.\n    \"\"\"\n\n    from lxml import etree\n\n    # Include text content at the start of the node.\n    parts = [node.text]\n\n    for child in node.getchildren():\n        # Include the child serialized to raw XML.\n        parts.append(etree.tostring(child, encoding=\"utf-8\"))\n\n        # Include any text following the child.\n        parts.append(child.tail)\n\n    # Discard any non-existent text parts and return.\n    return \"\".join(filter(None, parts))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the inner text of a given XML node excluding tags.", "response": "def inner_text(node):\n    \"\"\"\n    Returns the inner text of a given XML node, excluding tags.\n\n    Args:\n        node: (lxml.etree.Element): The node whose inner text is desired.\n\n    Returns:\n        str: The inner text of the node.\n    \"\"\"\n\n    from lxml import etree\n\n    # Include text content at the start of the node.\n    parts = [node.text]\n\n    for child in node.getchildren():\n        # Include the raw text content of the child.\n        parts.append(etree.tostring(child, encoding=\"utf-8\", method=\"text\"))\n\n        # Include any text following the child.\n        parts.append(child.tail)\n\n    # Discard any non-existent text parts and return.\n    return \"\".join(map(decode_bytes, filter(None, parts)))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nnormalizing the given URL with all query keys properly escaped.", "response": "def normalize_url(url):\n    \"\"\"\n    Returns the given URL with all query keys properly escaped.\n\n    Args:\n        url (str): The URL to normalize.\n\n    Returns:\n        str: The normalized URL.\n    \"\"\"\n\n    uri = urlparse(url)\n    query = uri.query or \"\"\n\n    pairs = parse_qsl(query)\n    decoded_pairs = [(unquote(key), value) for key, value in pairs]\n    encoded_pairs = [(quote(key), value) for key, value in decoded_pairs]\n    normalized_query = urlencode(encoded_pairs)\n\n    return ParseResult(\n        scheme=uri.scheme,\n        netloc=uri.netloc,\n        path=uri.path,\n        params=uri.params,\n        query=normalized_query,\n        fragment=uri.fragment).geturl()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndefines a write - only property that provides a setter function that provides the given setter function. This is a decorator that provides a setter function that can be used to set the value of the object s _handler property.", "response": "def setter_decorator(fset):\n    \"\"\"\n    Define a write-only property that, in addition to the given setter function, also\n    provides a setter decorator defined as the property's getter function.\n\n    This allows one to set the property either through traditional assignment, as a\n    method argument, or through decoration::\n\n        class Widget(object):\n            @setter_decorator\n            def handler(self, value):\n                self._handler = value\n\n        widget = Widget()\n\n        # Method 1: Traditional assignment\n        widget.handler = lambda input: process(input)\n\n        # Method 2: Assignment via method argument\n        widget.handler(lambda input: process(input))\n\n        # Method 3: Assignment via decoration\n        @widget.handler\n        def handler(input):\n            return process(input)\n\n        # Method 3b: Assignment via decoration with extraneous parens\n        @widget.handler()\n        def handler(input):\n            return process(input)\n    \"\"\"\n\n    def fget(self):\n        def inner(value):\n            fset(self, value)\n\n        def outer(value=None):\n            if value:\n                # We are being called with the desired value, either directly or\n                # as a decorator.\n                inner(value)\n            else:\n                # Assume we are being called as a decorator with extraneous parens,\n                # so return the setter as the actual decorator.\n                return inner\n\n        return outer\n\n    fdoc = fset.__doc__\n\n    return property(fget, fset, None, fdoc)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn True if the given value is valid.", "response": "def _valid_value(self, value):\n        \"\"\" bool: Whether the given value is valid. \"\"\"\n\n        if not self.valid_values:\n            return True\n\n        valid_values = (self.valid_values if isinstance(self.valid_values, list)\n                        else list(self.valid_values))\n        return value in valid_values"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfinds a file field on the page and attach a file given its path.", "response": "def attach_file(self, locator_or_path, path=None, **kwargs):\n        \"\"\"\n        Find a file field on the page and attach a file given its path. The file field can be found\n        via its name, id, or label text. ::\n\n            page.attach_file(locator, \"/path/to/file.png\")\n\n        Args:\n            locator_or_path (str): Which field to attach the file to, or the path of the file that\n                will be attached.\n            path (str, optional): The path of the file that will be attached. Defaults to\n                ``locator_or_path``.\n            **kwargs: Arbitrary keyword arguments for :class:`SelectorQuery`.\n\n        Raises:\n            FileNotFound: No file exists at the given path.\n        \"\"\"\n\n        if path is None:\n            locator, path = None, locator_or_path\n        else:\n            locator = locator_or_path\n\n        if not os.path.isfile(path):\n            raise FileNotFound(\"cannot attach file, {0} does not exist\".format(path))\n\n        self.find(\"file_field\", locator, **kwargs).set(path)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck the contents of the specified check box.", "response": "def check(self, locator=None, allow_label_click=None, **kwargs):\n        \"\"\"\n        Find a check box and mark it as checked. The check box can be found via name, id, or label\n        text. ::\n\n            page.check(\"German\")\n\n        Args:\n            locator (str, optional): Which check box to check.\n            allow_label_click (bool, optional): Attempt to click the label to toggle state if\n                element is non-visible. Defaults to :data:`capybara.automatic_label_click`.\n            **kwargs: Arbitrary keyword arguments for :class:`SelectorQuery`.\n        \"\"\"\n\n        self._check_with_label(\n            \"checkbox\", True, locator=locator, allow_label_click=allow_label_click, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfind a radio button and mark it as checked. The radio button can be found via name, id, or label text. :: page.choose(\"Male\") Args: locator (str, optional): Which radio button to choose. allow_label_click (bool, optional): Attempt to click the label to toggle state if element is non-visible. Defaults to :data:`capybara.automatic_label_click`. **kwargs: Arbitrary keyword arguments for :class:`SelectorQuery`.", "response": "def choose(self, locator=None, allow_label_click=None, **kwargs):\n        \"\"\"\n        Find a radio button and mark it as checked. The radio button can be found via name, id, or\n        label text. ::\n\n            page.choose(\"Male\")\n\n        Args:\n            locator (str, optional): Which radio button to choose.\n            allow_label_click (bool, optional): Attempt to click the label to toggle state if\n                element is non-visible. Defaults to :data:`capybara.automatic_label_click`.\n            **kwargs: Arbitrary keyword arguments for :class:`SelectorQuery`.\n        \"\"\"\n\n        self._check_with_label(\n            \"radio_button\", True, locator=locator, allow_label_click=allow_label_click, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fill_in(self, locator=None, current_value=None, value=None, fill_options=None, **kwargs):\n\n        if current_value is not None:\n            kwargs[\"value\"] = current_value\n\n        fill_options = fill_options or {}\n\n        self.find(\"fillable_field\", locator, **kwargs).set(value, **fill_options)", "response": "Fills in the given value in the given field."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef select(self, value=None, field=None, **kwargs):\n\n        if field:\n            self.find(\"select\", field, **kwargs).find(\"option\", value, **kwargs).select_option()\n        else:\n            self.find(\"option\", value, **kwargs).select_option()", "response": "Select the option from the current scope."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding a check box and uncheck it. The check box can be found via name, id, or label text. :: page.uncheck(\"German\") Args: locator (str, optional): Which check box to uncheck. allow_label_click (bool, optional): Attempt to click the label to toggle state if element is non-visible. Defaults to :data:`capybara.automatic_label_click`. **kwargs: Arbitrary keyword arguments for :class:`SelectorQuery`.", "response": "def uncheck(self, locator=None, allow_label_click=None, **kwargs):\n        \"\"\"\n        Find a check box and uncheck it. The check box can be found via name, id, or label text. ::\n\n            page.uncheck(\"German\")\n\n        Args:\n            locator (str, optional): Which check box to uncheck.\n            allow_label_click (bool, optional): Attempt to click the label to toggle state if\n                element is non-visible. Defaults to :data:`capybara.automatic_label_click`.\n            **kwargs: Arbitrary keyword arguments for :class:`SelectorQuery`.\n        \"\"\"\n\n        self._check_with_label(\n            \"checkbox\", False, locator=locator, allow_label_click=allow_label_click, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfinds a select box on the page and unselect a particular option from it. If the select box is a multiple select, ``unselect`` can be called multiple times to unselect more than one option. The select box can be found via its name, id, or label text. :: page.unselect(\"March\", field=\"Month\") Args: value (str, optional): Which option to unselect. field (str, optional): The id, name, or label of the select box. **kwargs: Arbitrary keyword arguments for :class:`SelectorQuery`.", "response": "def unselect(self, value=None, field=None, **kwargs):\n        \"\"\"\n        Find a select box on the page and unselect a particular option from it. If the select box is\n        a multiple select, ``unselect`` can be called multiple times to unselect more than one\n        option. The select box can be found via its name, id, or label text. ::\n\n            page.unselect(\"March\", field=\"Month\")\n\n        Args:\n            value (str, optional): Which option to unselect.\n            field (str, optional): The id, name, or label of the select box.\n            **kwargs: Arbitrary keyword arguments for :class:`SelectorQuery`.\n        \"\"\"\n\n        if field:\n            self.find(\"select\", field, **kwargs).find(\"option\", value, **kwargs).unselect_option()\n        else:\n            self.find(\"option\", value, **kwargs).unselect_option()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _check_with_label(self, selector, checked, locator=None, allow_label_click=None, visible=None, wait=None,\n                          **kwargs):\n        \"\"\"\n        Args:\n            selector (str): The selector for the type of element that should be checked/unchecked.\n            checked (bool): Whether the element should be checked.\n            locator (str, optional): Which element to check.\n            allow_label_click (bool, optional): Attempt to click the label to toggle state if\n                element is non-visible. Defaults to :data:`capybara.automatic_label_click`.\n            visible (bool | str, optional): The desired element visibility. Defaults to\n                :data:`capybara.ignore_hidden_elements`.\n            wait (int | float, optional): The number of seconds to wait to check the element.\n                Defaults to :data:`capybara.default_max_wait_time`.\n            **kwargs: Arbitrary keyword arguments for :class:`SelectorQuery`.\n        \"\"\"\n\n        if allow_label_click is None:\n            allow_label_click = capybara.automatic_label_click\n\n        @self.synchronize(wait=BaseQuery.normalize_wait(wait))\n        def check_with_label():\n            element = None\n            try:\n                element = self.find(selector, locator, visible=visible, **kwargs)\n                element.set(checked)\n            except Exception as e:\n                if not allow_label_click or not self._should_catch_error(e):\n                    raise\n                try:\n                    if not element:\n                        element = self.find(selector, locator, visible=\"all\", **kwargs)\n                    label = self.find(\"label\", field=element, visible=True)\n                    if element.checked != checked:\n                        label.click()\n                except Exception:\n                    raise e\n\n        check_with_label()", "response": "Check the element with the specified label."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef synchronize(self, func=None, wait=None, errors=()):\n\n        def decorator(func):\n            @wraps(func)\n            def outer(*args, **kwargs):\n                seconds = wait if wait is not None else capybara.default_max_wait_time\n\n                def inner():\n                    return func(*args, **kwargs)\n\n                if self.session.synchronized:\n                    return inner()\n                else:\n                    timer = Timer(seconds)\n                    self.session.synchronized = True\n                    try:\n                        while True:\n                            try:\n                                return inner()\n                            except Exception as e:\n                                self.session.raise_server_error()\n\n                                if not self._should_catch_error(e, errors):\n                                    raise\n                                if timer.expired:\n                                    raise\n\n                                sleep(0.05)\n\n                                if timer.stalled:\n                                    raise FrozenInTime(\n                                        \"time appears to be frozen, Capybara does not work with \"\n                                        \"libraries which freeze time, consider using time \"\n                                        \"traveling instead\")\n                                if capybara.automatic_reload:\n                                    self.reload()\n                    finally:\n                        self.session.synchronized = False\n\n            return outer\n\n        if func:\n            return decorator(func)\n        else:\n            return decorator", "response": "This method is used to synchronize a function with Capybara s primary defense against asynchronicity problems."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns whether the given error should be caught.", "response": "def _should_catch_error(self, error, errors=()):\n        \"\"\"\n        Returns whether to catch the given error.\n\n        Args:\n            error (Exception): The error to consider.\n            errors (Tuple[Type[Exception], ...], optional): The exception types that should be\n                caught. Defaults to :class:`ElementNotFound` plus any driver-specific invalid\n                element errors.\n\n        Returns:\n            bool: Whether to catch the given error.\n        \"\"\"\n\n        caught_errors = (\n            errors or\n            self.session.driver.invalid_element_errors + (ElementNotFound,))\n\n        return isinstance(error, caught_errors)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef compare_count(self):\n\n        if self.query.options[\"count\"] is not None:\n            count_opt = int(self.query.options[\"count\"])\n            self._cache_at_least(count_opt + 1)\n            return cmp(len(self._result_cache), count_opt)\n\n        if self.query.options[\"minimum\"] is not None:\n            min_opt = int(self.query.options[\"minimum\"])\n            if not self._cache_at_least(min_opt):\n                return -1\n\n        if self.query.options[\"maximum\"] is not None:\n            max_opt = int(self.query.options[\"maximum\"])\n            if self._cache_at_least(max_opt + 1):\n                return 1\n\n        if self.query.options[\"between\"] is not None:\n            between = self.query.options[\"between\"]\n            min_opt, max_opt = between[0], between[-1]\n            if not self._cache_at_least(min_opt):\n                return -1\n            if self._cache_at_least(max_opt + 1):\n                return 1\n            return 0\n\n        return 0", "response": "Returns how the result count compares to the query options."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef failure_message(self):\n\n        message = failure_message(self.query.description, self.query.options)\n\n        if len(self) > 0:\n            message += \", found {count} {matches}: {results}\".format(\n                count=len(self),\n                matches=declension(\"match\", \"matches\", len(self)),\n                results=\", \".join([desc(node.text) for node in self]))\n        else:\n            message += \" but there were no matches\"\n\n        if self._rest:\n            elements = \", \".join([desc(element.text) for element in self._rest])\n            message += (\". Also found {}, which matched the selector\"\n                        \" but not all filters.\".format(elements))\n\n        return message", "response": "str - A message describing the query failure."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nattempting to fill the result cache with at least the given size. Returns True if the result cache contains at least the given size.", "response": "def _cache_at_least(self, size):\n        \"\"\"\n        Attempts to fill the result cache with at least the given number of results.\n\n        Returns:\n            bool: Whether the cache contains at least the given size.\n        \"\"\"\n\n        try:\n            while len(self._result_cache) < size:\n                self._result_cache.append(next(self._result_iter))\n            return True\n        except StopIteration:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef desc(value):\n\n    def normalize_strings(value):\n        if isinstance(value, list):\n            value = [normalize_strings(e) for e in value]\n\n        if isinstance(value, dict):\n            value = {normalize_strings(k): normalize_strings(v) for k, v in iter(value.items())}\n\n        if isregex(value):\n            value = value.pattern\n\n        if isbytes(value):\n            value = decode_bytes(value)\n\n        if PY2:\n            if isstring(value):\n                # In Python 2, strings (``unicode`` objects) represent as ``u'...'``, so ensure\n                # the string is encoded (as a ``str`` object) for cleaner representation.\n                value = encode_string(value)\n\n        return value\n\n    value = normalize_strings(value)\n\n    return repr(value)", "response": "str - A normalized representation for a user - provided value."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef expects_none(options):\n\n    if any(options.get(key) is not None for key in [\"count\", \"maximum\", \"minimum\", \"between\"]):\n        return matches_count(0, options)\n    else:\n        return False", "response": "Returns whether the given query options expect a possible count of zero."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef failure_message(description, options):\n\n    message = \"expected to find {}\".format(description)\n\n    if options[\"count\"] is not None:\n        message += \" {count} {times}\".format(\n            count=options[\"count\"],\n            times=declension(\"time\", \"times\", options[\"count\"]))\n    elif options[\"between\"] is not None:\n        between = options[\"between\"]\n        if between:\n            first, last = between[0], between[-1]\n        else:\n            first, last = None, None\n\n        message += \" between {first} and {last} times\".format(\n            first=first,\n            last=last)\n    elif options[\"maximum\"] is not None:\n        message += \" at most {maximum} {times}\".format(\n            maximum=options[\"maximum\"],\n            times=declension(\"time\", \"times\", options[\"maximum\"]))\n    elif options[\"minimum\"] is not None:\n        message += \" at least {minimum} {times}\".format(\n            minimum=options[\"minimum\"],\n            times=declension(\"time\", \"times\", options[\"minimum\"]))\n\n    return message", "response": "Returns a expectation failure message for the given query description."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef matches_count(count, options):\n\n    if options.get(\"count\") is not None:\n        return count == int(options[\"count\"])\n    if options.get(\"maximum\") is not None and int(options[\"maximum\"]) < count:\n        return False\n    if options.get(\"minimum\") is not None and int(options[\"minimum\"]) > count:\n        return False\n    if options.get(\"between\") is not None and count not in options[\"between\"]:\n        return False\n    return True", "response": "Returns whether the given count matches the given query options."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef normalize_text(value):\n\n    if value is None:\n        return \"\"\n\n    text = decode_bytes(value) if isbytes(value) else str_(value)\n\n    return normalize_whitespace(text)", "response": "Normalizes the given value to a string of text with extra whitespace removed."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nnormalizes the given text with outer whitespace removed inner whitespace collapsed.", "response": "def normalize_whitespace(text):\n    \"\"\"\n    Returns the given text with outer whitespace removed and inner whitespace collapsed.\n\n    Args:\n        text (str): The text to normalize.\n\n    Returns:\n        str: The normalized text.\n    \"\"\"\n\n    return re.sub(r\"\\s+\", \" \", text, flags=re.UNICODE).strip()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a compiled regular expression for the given text.", "response": "def toregex(text, exact=False):\n    \"\"\"\n    Returns a compiled regular expression for the given text.\n\n    Args:\n        text (str | RegexObject): The text to match.\n        exact (bool, optional): Whether the generated regular expression should match exact\n            strings. Defaults to False.\n\n    Returns:\n        RegexObject: A compiled regular expression that will match the text.\n    \"\"\"\n\n    if isregex(text):\n        return text\n\n    escaped = re.escape(normalize_text(text))\n    if exact:\n        escaped = r\"\\A{}\\Z\".format(escaped)\n\n    return re.compile(escaped)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef resolves_for(self, session):\n\n        if self.url:\n            self.actual_path = session.current_url\n        else:\n            result = urlparse(session.current_url)\n\n            if self.only_path:\n                self.actual_path = result.path\n            else:\n                request_uri = result.path\n                if result.query:\n                    request_uri += \"?{0}\".format(result.query)\n\n                self.actual_path = request_uri\n\n        if isregex(self.expected_path):\n            return self.expected_path.search(self.actual_path)\n        else:\n            return normalize_url(self.actual_path) == normalize_url(self.expected_path)", "response": "Returns whether this query resolves for the given session."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nboots a server for the app.", "response": "def boot(self):\n        \"\"\"\n        Boots a server for the app, if it isn't already booted.\n\n        Returns:\n            Server: This server.\n        \"\"\"\n\n        if not self.responsive:\n            # Remember the port so we can reuse it if we try to serve this same app again.\n            type(self)._ports[self.port_key] = self.port\n\n            init_func = capybara.servers[capybara.server_name]\n            init_args = (self.middleware, self.port, self.host)\n\n            self.server_thread = Thread(target=init_func, args=init_args)\n\n            # Inform Python that it shouldn't wait for this thread to terminate before\n            # exiting. (It will still be appropriately terminated when the process exits.)\n            self.server_thread.daemon = True\n\n            self.server_thread.start()\n\n            # Make sure the server actually starts and becomes responsive.\n            timer = Timer(60)\n            while not self.responsive:\n                if timer.expired:\n                    raise RuntimeError(\"WSGI application timed out during boot\")\n                self.server_thread.join(0.1)\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef responsive(self):\n\n        if self.server_thread and self.server_thread.join(0):\n            return False\n\n        try:\n            # Try to fetch the endpoint added by the middleware.\n            identify_url = \"http://{0}:{1}/__identify__\".format(self.host, self.port)\n\n            with closing(urlopen(identify_url)) as response:\n                body, status_code = response.read(), response.getcode()\n\n                if str(status_code)[0] == \"2\" or str(status_code)[0] == \"3\":\n                    return decode_bytes(body) == str(id(self.app))\n        except URLError:\n            pass\n\n        return False", "response": "Returns True if the server is up and responsive."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cgetter(self, fcget: typing.Optional[typing.Callable[[typing.Any], typing.Any]]) -> \"AdvancedProperty\":\n        self.__fcget = fcget\n        return self", "response": "Descriptor to change the class - wide getter on a property."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the descriptor to change the instance method.", "response": "def instance_method(self, imeth: typing.Optional[typing.Callable[..., typing.Any]]) -> \"SeparateClassMethod\":\n        \"\"\"Descriptor to change instance method.\n\n        :param imeth: New instance method.\n        :type imeth: typing.Optional[typing.Callable]\n        :return: SeparateClassMethod\n        :rtype: SeparateClassMethod\n        \"\"\"\n        self.__instance_method = imeth\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the class method to be used for this class.", "response": "def class_method(self, cmeth: typing.Optional[typing.Callable[..., typing.Any]]) -> \"SeparateClassMethod\":\n        \"\"\"Descriptor to change class method.\n\n        :param cmeth: New class method.\n        :type cmeth: typing.Optional[typing.Callable]\n        :return: SeparateClassMethod\n        :rtype: SeparateClassMethod\n        \"\"\"\n        self.__class_method = cmeth\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget outer traceback text for logging.", "response": "def __traceback(self) -> str:\n        \"\"\"Get outer traceback text for logging.\"\"\"\n        if not self.log_traceback:\n            return \"\"\n        exc_info = sys.exc_info()\n        stack = traceback.extract_stack()\n        exc_tb = traceback.extract_tb(exc_info[2])\n        full_tb = stack[:1] + exc_tb  # cut decorator and build full traceback\n        exc_line: typing.List[str] = traceback.format_exception_only(*exc_info[:2])\n        # Make standard traceback string\n        tb_text = \"\\nTraceback (most recent call last):\\n\" + \"\".join(traceback.format_list(full_tb)) + \"\".join(exc_line)\n        return tb_text"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __get_obj_source(self, instance: typing.Any, owner: typing.Optional[type] = None) -> str:\n        if self.log_object_repr:\n            return f\"{instance!r}\"\n        return f\"<{owner.__name__ if owner is not None else instance.__class__.__name__}() at 0x{id(instance):X}>\"", "response": "Get object repr block."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_logger_for_instance(self, instance: typing.Any) -> logging.Logger:\n        if self.logger is not None:  # pylint: disable=no-else-return\n            return self.logger\n        elif hasattr(instance, \"logger\") and isinstance(instance.logger, logging.Logger):\n            return instance.logger\n        elif hasattr(instance, \"log\") and isinstance(instance.log, logging.Logger):\n            return instance.log\n        return _LOGGER", "response": "Get the logger for the given instance."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef logger(self, logger: typing.Union[logging.Logger, str, None]) -> None:\n        if logger is None or isinstance(logger, logging.Logger):\n            self.__logger = logger\n        else:\n            self.__logger = logging.getLogger(logger)", "response": "Set the logger instance to use as override."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_simple_vars_from_src(src):\n    ast_data = (ast.Str, ast.Num, ast.List, ast.Set, ast.Dict, ast.Tuple, ast.Bytes, ast.NameConstant)\n\n    tree = ast.parse(src)\n\n    result = collections.OrderedDict()\n\n    for node in ast.iter_child_nodes(tree):\n        if not isinstance(node, ast.Assign):  # We parse assigns only\n            continue\n        try:\n            if isinstance(node.value, ast_data):\n                value = ast.literal_eval(node.value)\n            else:\n                continue\n        except ValueError:\n            continue\n        for tgt in node.targets:\n            if isinstance(tgt, ast.Name) and isinstance(tgt.ctx, ast.Store):\n                result[tgt.id] = value\n    return result", "response": "Get simple variable names and values from source code."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run(self):\n        try:\n            build_ext.build_ext.run(self)\n\n            # Copy __init__.py back to repair package.\n            build_dir = os.path.abspath(self.build_lib)\n            root_dir = os.path.abspath(os.path.join(__file__, \"..\"))\n            target_dir = build_dir if not self.inplace else root_dir\n\n            src_file = os.path.join(\"advanced_descriptors\", \"__init__.py\")\n\n            src = os.path.join(root_dir, src_file)\n            dst = os.path.join(target_dir, src_file)\n\n            if src != dst:\n                shutil.copyfile(src, dst)\n        except (\n            distutils.errors.DistutilsPlatformError,\n            FileNotFoundError,\n        ):\n            raise BuildFailed()", "response": "Runs the extension build."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _call_api(self, method, params=None):\n        url = self.url.format(method=method)\n        if not params:\n            params = {'token': self.token}\n        else:\n            params['token'] = self.token\n        logger.debug('Send request to %s', url)\n        response = requests.get(url, params=params).json()\n        if self.verify:\n            if not response['ok']:\n                msg = 'For {url} API returned this bad response {response}'\n                raise Exception(msg.format(url=url, response=response))\n        return response", "response": "Call the Slack API."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of all channels in this slack team", "response": "def channels(self):\n        \"\"\"\n        List of channels of this slack team\n        \"\"\"\n        if not self._channels:\n            self._channels = self._call_api('channels.list')['channels']\n        return self._channels"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef users(self):\n        if not self._users:\n            self._users = self._call_api('users.list')['members']\n        return self._users", "response": "Returns a list of users of this slack team"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the channel dict given by human - readable name", "response": "def channel_from_name(self, name):\n        \"\"\"\n        Return the channel dict given by human-readable {name}\n        \"\"\"\n        try:\n            channel = [channel for channel in self.channels\n                       if channel['name'] == name][0]\n        except IndexError:\n            raise ValueError('Unknown channel for name: \"{}\"'.format(name))\n        return channel"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef make_message(self, text, channel):\n        try:\n            channel_id = self.slack.channel_from_name(channel)['id']\n        except ValueError:\n            channel_id = channel\n        return pack({\n            'text': text,\n            'type': 'message',\n            'channel': channel_id,\n            'id': self.message_id,\n        })", "response": "High - level function for creating messages. Return packed bytes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntranslate machine identifiers into human - readable ones.", "response": "def translate(self, message):\n        \"\"\"\n        Translate machine identifiers into human-readable\n        \"\"\"\n        # translate user\n        try:\n            user_id = message.pop('user')\n            user = self.slack.user_from_id(user_id)\n            message[u'user'] = user['name']\n        except (KeyError, IndexError, ValueError):\n            pass\n        # translate channel\n        try:\n            if type(message['channel']) == str:\n                channel_id = message.pop('channel')\n            else:\n                channel_id = message.pop('channel')['id']\n                self.slack.reload_channels()\n            channel = self.slack.channel_from_id(channel_id)\n            message[u'channel'] = channel['name']\n        except (KeyError, IndexError, ValueError):\n            pass\n        return message"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsends the payload onto the {slack.[payload['type]'} channel. The message is transalated from IDs to human-readable identifiers. Note: The slack API only sends JSON, isBinary will always be false.", "response": "def onMessage(self, payload, isBinary):\n        \"\"\"\n        Send the payload onto the {slack.[payload['type]'} channel.\n        The message is transalated from IDs to human-readable identifiers.\n\n        Note: The slack API only sends JSON, isBinary will always be false.\n        \"\"\"\n        msg = self.translate(unpack(payload))\n        if 'type' in msg:\n            channel_name = 'slack.{}'.format(msg['type'])\n            print('Sending on {}'.format(channel_name))\n            channels.Channel(channel_name).send({'text': pack(msg)})"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsending a Slack message to Slack", "response": "def sendSlack(self, message):\n        \"\"\"\n        Send message to Slack\n        \"\"\"\n        channel = message.get('channel', 'general')\n        self.sendMessage(self.make_message(message['text'], channel))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading the available messages and send them through the protocol.", "response": "def read_channel(self):\n        \"\"\"\n        Get available messages and send through to the protocol\n        \"\"\"\n        channel, message = self.protocol.channel_layer.receive_many([u'slack.send'], block=False)\n        delay = 0.1\n        if channel:\n            self.protocols[0].sendSlack(message)\n        reactor.callLater(delay, self.read_channel)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nruns the Slack API.", "response": "def run(self, args):\n        \"\"\"\n        Pass in raw arguments, instantiate Slack API and begin client.\n        \"\"\"\n        args = self.parser.parse_args(args)\n        if not args.token:\n            raise ValueError('Supply the slack token through --token or setting DJANGOBOT_TOKEN')\n\n        # Import the channel layer\n        sys.path.insert(0, \".\")\n        module_path, object_path = args.channel_layer.split(':', 1)\n        channel_layer = importlib.import_module(module_path)\n        for part in object_path.split('.'):\n            channel_layer = getattr(channel_layer, part)\n\n        # Boot up the client\n        Client(\n            channel_layer=channel_layer,\n            token=args.token,\n        ).run()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _set_affiliation(self, v, load=False):\n        if hasattr(v, \"_utype\"):\n            v = v._utype(v)\n        try:\n            t = YANGDynClass(\n                v,\n                base=RestrictedClassType(\n                    base_type=unicode,\n                    restriction_type=\"dict_key\",\n                    restriction_arg={\n                        u\"napalm-star-wars:EMPIRE\": {\n                            \"@namespace\": u\"https://napalm-yang.readthedocs.io/napalm-star-wars\",\n                            \"@module\": u\"napalm-star-wars\",\n                        },\n                        u\"EMPIRE\": {\n                            \"@namespace\": u\"https://napalm-yang.readthedocs.io/napalm-star-wars\",\n                            \"@module\": u\"napalm-star-wars\",\n                        },\n                        u\"napalm-star-wars:REBEL_ALLIANCE\": {\n                            \"@namespace\": u\"https://napalm-yang.readthedocs.io/napalm-star-wars\",\n                            \"@module\": u\"napalm-star-wars\",\n                        },\n                        u\"REBEL_ALLIANCE\": {\n                            \"@namespace\": u\"https://napalm-yang.readthedocs.io/napalm-star-wars\",\n                            \"@module\": u\"napalm-star-wars\",\n                        },\n                    },\n                ),\n                is_leaf=True,\n                yang_name=\"affiliation\",\n                parent=self,\n                path_helper=self._path_helper,\n                extmethods=self._extmethods,\n                register_paths=True,\n                namespace=\"https://napalm-yang.readthedocs.io/napalm-star-wars\",\n                defining_module=\"napalm-star-wars\",\n                yang_type=\"identityref\",\n                is_config=True,\n            )\n        except (TypeError, ValueError):\n            raise ValueError(\n                {\n                    \"error-string\": \"\"\"affiliation must be of a type compatible with identityref\"\"\",\n                    \"defined-type\": \"napalm-star-wars:identityref\",\n                    \"generated-type\": \"\"\"YANGDynClass(base=RestrictedClassType(base_type=unicode, restriction_type=\"dict_key\", restriction_arg={u'napalm-star-wars:EMPIRE': {'@namespace': u'https://napalm-yang.readthedocs.io/napalm-star-wars', '@module': u'napalm-star-wars'}, u'EMPIRE': {'@namespace': u'https://napalm-yang.readthedocs.io/napalm-star-wars', '@module': u'napalm-star-wars'}, u'napalm-star-wars:REBEL_ALLIANCE': {'@namespace': u'https://napalm-yang.readthedocs.io/napalm-star-wars', '@module': u'napalm-star-wars'}, u'REBEL_ALLIANCE': {'@namespace': u'https://napalm-yang.readthedocs.io/napalm-star-wars', '@module': u'napalm-star-wars'}},), is_leaf=True, yang_name=\"affiliation\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, namespace='https://napalm-yang.readthedocs.io/napalm-star-wars', defining_module='napalm-star-wars', yang_type='identityref', is_config=True)\"\"\",\n                }\n            )\n\n        self.__affiliation = t\n        if hasattr(self, \"_set\"):\n            self._set()", "response": "Sets the affiliation of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef dict_diff(prv, nxt):\n    keys = set(prv.keys() + nxt.keys())\n    result = {}\n    for k in keys:\n        if prv.get(k) != nxt.get(k):\n            result[k] = (prv.get(k), nxt.get(k))\n    return result", "response": "Return a dict of keys that differ with another config object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngive a string add necessary codes to format the string.", "response": "def colorize(msg, color):\n    \"\"\"Given a string add necessary codes to format the string.\"\"\"\n    if DONT_COLORIZE:\n        return msg\n    else:\n        return \"{}{}{}\".format(COLORS[color], msg, COLORS[\"endc\"])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef v2_playbook_on_task_start(self, task, **kwargs):\n        self.last_task_name = task.get_name()\n        self.printed_last_task = False", "response": "Run when a task starts."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef v2_runner_on_ok(self, result, **kwargs):\n        failed = \"failed\" in result._result\n        unreachable = \"unreachable\" in result._result\n\n        if (\n            \"print_action\" in result._task.tags\n            or failed\n            or unreachable\n            or self._display.verbosity > 1\n        ):\n            self._print_task()\n            self.last_skipped = False\n            msg = unicode(result._result.get(\"msg\", \"\")) or unicode(\n                result._result.get(\"reason\", \"\")\n            ) or unicode(\n                result._result.get(\"message\", \"\")\n            )\n\n            stderr = [\n                result._result.get(\"exception\", None),\n                result._result.get(\"module_stderr\", None),\n            ]\n            stderr = \"\\n\".join([e for e in stderr if e]).strip()\n\n            self._print_host_or_item(\n                result._host,\n                result._result.get(\"changed\", False),\n                msg,\n                result._result.get(\"diff\", None),\n                is_host=True,\n                error=failed or unreachable,\n                stdout=result._result.get(\"module_stdout\", None),\n                stderr=stderr.strip(),\n            )\n\n            if \"results\" in result._result:\n                for r in result._result[\"results\"]:\n                    failed = \"failed\" in r\n\n                    stderr = [r.get(\"exception\", None), r.get(\"module_stderr\", None)]\n                    stderr = \"\\n\".join([e for e in stderr if e]).strip()\n\n                    self._print_host_or_item(\n                        r[\"item\"],\n                        r.get(\"changed\", False),\n                        unicode(r.get(\"msg\", \"\")),\n                        r.get(\"diff\", None),\n                        is_host=False,\n                        error=failed,\n                        stdout=r.get(\"module_stdout\", None),\n                        stderr=stderr.strip(),\n                    )\n        else:\n            self.last_skipped = True\n            print(\".\", end=\"\")", "response": "Run when a task finishes correctly."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndisplays info about playbook statistics.", "response": "def v2_playbook_on_stats(self, stats):\n        \"\"\"Display info about playbook statistics.\"\"\"\n        print()\n        self.printed_last_task = False\n        self._print_task(\"STATS\")\n\n        hosts = sorted(stats.processed.keys())\n        for host in hosts:\n            s = stats.summarize(host)\n\n            if s[\"failures\"] or s[\"unreachable\"]:\n                color = \"failed\"\n            elif s[\"changed\"]:\n                color = \"changed\"\n            else:\n                color = \"ok\"\n\n            msg = \"{}    : ok={}\\tchanged={}\\tfailed={}\\tunreachable={}\".format(\n                host, s[\"ok\"], s[\"changed\"], s[\"failures\"], s[\"unreachable\"]\n            )\n            print(colorize(msg, color))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrunning when a task is skipped.", "response": "def v2_runner_on_skipped(self, result, **kwargs):\n        \"\"\"Run when a task is skipped.\"\"\"\n        if self._display.verbosity > 1:\n            self._print_task()\n            self.last_skipped = False\n\n            line_length = 120\n            spaces = \" \" * (31 - len(result._host.name) - 4)\n\n            line = \"  * {}{}- {}\".format(\n                colorize(result._host.name, \"not_so_bold\"),\n                spaces,\n                colorize(\"skipped\", \"skipped\"),\n            )\n\n            reason = result._result.get(\"skipped_reason\", \"\") or result._result.get(\n                \"skip_reason\", \"\"\n            )\n            if len(reason) < 50:\n                line += \" -- {}\".format(reason)\n                print(\"{} {}---------\".format(line, \"-\" * (line_length - len(line))))\n            else:\n                print(\"{} {}\".format(line, \"-\" * (line_length - len(line))))\n                print(self._indent_text(reason, 8))\n                print(reason)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef prefix_to_addrmask(value, sep=\" \"):\n    prefix = netaddr.IPNetwork(value)\n    return \"{}{}{}\".format(prefix.ip, sep, prefix.netmask)", "response": "Converts a CIDR formatted prefix into an address netmask representation."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the keepalive interval of the current node.", "response": "def _set_keepalive_interval(self, v, load=False):\n        \"\"\"\n    Setter method for keepalive_interval, mapped from YANG variable /network_instances/network_instance/protocols/protocol/bgp/peer_groups/peer_group/timers/state/keepalive_interval (decimal64)\n    If this variable is read-only (config: false) in the\n    source YANG file, then _set_keepalive_interval is considered as a private\n    method. Backends looking to populate this variable should\n    do so via calling thisObj._set_keepalive_interval() directly.\n\n    YANG Description: Time interval in seconds between transmission of keepalive\nmessages to the neighbor.  Typically set to 1/3 the\nhold-time.\n    \"\"\"\n        if hasattr(v, \"_utype\"):\n            v = v._utype(v)\n        try:\n            t = YANGDynClass(\n                v,\n                base=RestrictedPrecisionDecimalType(precision=2),\n                default=Decimal(30),\n                is_leaf=True,\n                yang_name=\"keepalive-interval\",\n                parent=self,\n                path_helper=self._path_helper,\n                extmethods=self._extmethods,\n                register_paths=True,\n                namespace=\"http://openconfig.net/yang/network-instance\",\n                defining_module=\"openconfig-network-instance\",\n                yang_type=\"decimal64\",\n                is_config=False,\n            )\n        except (TypeError, ValueError):\n            raise ValueError(\n                {\n                    \"error-string\": \"\"\"keepalive_interval must be of a type compatible with decimal64\"\"\",\n                    \"defined-type\": \"decimal64\",\n                    \"generated-type\": \"\"\"YANGDynClass(base=RestrictedPrecisionDecimalType(precision=2), default=Decimal(30), is_leaf=True, yang_name=\"keepalive-interval\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, namespace='http://openconfig.net/yang/network-instance', defining_module='openconfig-network-instance', yang_type='decimal64', is_config=False)\"\"\",\n                }\n            )\n\n        self.__keepalive_interval = t\n        if hasattr(self, \"_set\"):\n            self._set()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a model to the class.", "response": "def add_model(self, model, force=False):\n        \"\"\"\n        Add a model.\n\n        The model will be asssigned to a class attribute with the YANG name of the model.\n\n        Args:\n            model (PybindBase): Model to add.\n            force (bool): If not set, verify the model is in SUPPORTED_MODELS\n\n        Examples:\n\n            >>> import napalm_yang\n            >>> config = napalm_yang.base.Root()\n            >>> config.add_model(napalm_yang.models.openconfig_interfaces)\n            >>> config.interfaces\n            <pyangbind.lib.yangtypes.YANGBaseClass object at 0x10bef6680>\n        \"\"\"\n        if isinstance(model, str):\n            self._load_model(model)\n            return\n\n        try:\n            model = model()\n        except Exception:\n            pass\n\n        if model._yang_name not in [a[0] for a in SUPPORTED_MODELS] and not force:\n            raise ValueError(\n                \"Only models in SUPPORTED_MODELS can be added without `force=True`\"\n            )\n\n        for k, v in model:\n            self._elements[k] = v\n            setattr(self, k, v)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(self, filter=False):\n        result = {}\n\n        for k, v in self.elements().items():\n            intermediate = v.get(filter=filter)\n            if intermediate:\n                result[k] = intermediate\n\n        return result", "response": "Returns a dictionary with the values of the YANG classes."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads a dictionary into the model.", "response": "def load_dict(self, data, overwrite=False, auto_load_model=True):\n        \"\"\"\n        Load a dictionary into the model.\n\n        Args:\n            data(dict): Dictionary to load\n            overwrite(bool): Whether the data present in the model should be overwritten by the\n                data in the dict or not.\n            auto_load_model(bool): If set to true models will be loaded as they are needed\n\n        Examples:\n\n            >>> vlans_dict = {\n            >>>     \"vlans\": { \"vlan\": { 100: {\n            >>>                             \"config\": {\n            >>>                                 \"vlan_id\": 100, \"name\": \"production\"}},\n            >>>                          200: {\n            >>>                             \"config\": {\n            >>>                                 \"vlan_id\": 200, \"name\": \"dev\"}}}}}\n            >>> config.load_dict(vlans_dict)\n            >>> print(config.vlans.vlan.keys())\n            ... [200, 100]\n            >>> print(100, config.vlans.vlan[100].config.name)\n            ... (100, u'production')\n            >>> print(200, config.vlans.vlan[200].config.name)\n            ... (200, u'dev')\n        \"\"\"\n        for k, v in data.items():\n            if k not in self._elements.keys() and not auto_load_model:\n                raise AttributeError(\"Model {} is not loaded\".format(k))\n\n            elif k not in self._elements.keys() and auto_load_model:\n                self._load_model(k)\n\n            attr = getattr(self, k)\n            _load_dict(attr, v)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a dictionary with the values of the model.", "response": "def to_dict(self, filter=True):\n        \"\"\"\n        Returns a dictionary with the values of the model. Note that the values\n        of the leafs are evaluated to python types.\n\n        Args:\n            filter (bool): If set to ``True``, show only values that have been set.\n\n        Returns:\n            dict: A dictionary with the values of the model.\n\n        Example:\n\n            >>> pretty_print(config.to_dict(filter=True))\n            >>> {\n            >>>     \"interfaces\": {\n            >>>         \"interface\": {\n            >>>             \"et1\": {\n            >>>                 \"config\": {\n            >>>                     \"description\": \"My description\",\n            >>>                     \"mtu\": 1500\n            >>>                 },\n            >>>                 \"name\": \"et1\"\n            >>>             },\n            >>>             \"et2\": {\n            >>>                 \"config\": {\n            >>>                     \"description\": \"Another description\",\n            >>>                     \"mtu\": 9000\n            >>>                 },\n            >>>                 \"name\": \"et2\"\n            >>>             }\n            >>>         }\n            >>>     }\n            >>> }\n\n        \"\"\"\n        result = {}\n        for k, v in self:\n            r = _to_dict(v, filter)\n            if r:\n                result[k] = r\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_config(self, device=None, profile=None, native=None, attrs=None):\n        if attrs is None:\n            attrs = self.elements().values()\n\n        for v in attrs:\n            parser = Parser(\n                v, device=device, profile=profile, native=native, is_config=True\n            )\n            parser.parse()", "response": "Parse the configuration file into the corresponding models."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_state(self, device=None, profile=None, native=None, attrs=None):\n        if attrs is None:\n            attrs = self.elements().values()\n\n        for v in attrs:\n            parser = Parser(\n                v, device=device, profile=profile, native=native, is_config=False\n            )\n            parser.parse()", "response": "Parse the state of the junos system into the corresponding models."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef translate_config(self, profile, merge=None, replace=None):\n        result = []\n        for k, v in self:\n            other_merge = getattr(merge, k) if merge else None\n            other_replace = getattr(replace, k) if replace else None\n            translator = Translator(\n                v, profile, merge=other_merge, replace=other_replace\n            )\n            result.append(translator.translate())\n\n        return \"\\n\".join(result)", "response": "Translate the object to native configuration."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_filters():\n    all_filters = {}\n    for m in JINJA_FILTERS:\n        if hasattr(m, \"filters\"):\n            all_filters.update(m.filters())\n    return all_filters", "response": "Loads and returns all filters."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _parse_list_nested_recursive(\n        cls, data, path, iterators, list_vars, cur_vars=None\n    ):\n        \"\"\"\n        This helps parsing shit like:\n\n            <protocols>\n                <bgp>\n                    <group>\n                        <name>my_peers</name>\n                        <neighbor>\n                            <name>192.168.100.2</name>\n                            <description>adsasd</description>\n                            <peer-as>65100</peer-as>\n                        </neighbor>\n                        <neighbor>\n                            <name>192.168.100.3</name>\n                            <peer-as>65100</peer-as>\n                        </neighbor>\n                    </group>\n                    <group>\n                        <name>my_other_peers</name>\n                        <neighbor>\n                            <name>172.20.0.1</name>\n                            <peer-as>65200</peer-as>\n                        </neighbor>\n                    </group>\n                </bgp>\n            </protocols>\n\n        \"\"\"\n        cur_vars = dict(cur_vars) if cur_vars else {}\n        if path:\n            p = path[0]\n            path = path[1:]\n        else:\n            for _ in data:\n                list_vars.append(cur_vars)\n            iterators.append(data)\n            return data\n\n        if p.startswith(\"?\"):\n            for x in data:\n                key, var_path = p.split(\".\")\n                cur_vars.update({key.lstrip(\"?\"): x.xpath(var_path)[0].text})\n                cls._parse_list_nested_recursive(\n                    x, path, iterators, list_vars, cur_vars\n                )\n        else:\n            x = data.xpath(p)\n            cls._parse_list_nested_recursive(x, path, iterators, list_vars, cur_vars)", "response": "Recursively parse the xml data for a nested list of objects."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_trunk_vlans(self, v, load=False):\n        if hasattr(v, \"_utype\"):\n            v = v._utype(v)\n        try:\n            t = YANGDynClass(\n                v,\n                base=TypedListType(\n                    allowed_type=[\n                        RestrictedClassType(\n                            base_type=RestrictedClassType(\n                                base_type=int,\n                                restriction_dict={\"range\": [\"0..65535\"]},\n                                int_size=16,\n                            ),\n                            restriction_dict={\"range\": [\"1..4094\"]},\n                        ),\n                        RestrictedClassType(\n                            base_type=six.text_type,\n                            restriction_dict={\n                                \"pattern\": \"(409[0-4]|40[0-8][0-9]|[1-3][0-9]{3}|[1-9][0-9]{1,2}|[1-9])\\\\.\\\\.(409[0-4]|40[0-8][0-9]|[1-3][0-9]{3}|[1-9][0-9]{1,2}|[1-9])\"\n                            },\n                        ),\n                        RestrictedClassType(\n                            base_type=six.text_type,\n                            restriction_dict={\n                                \"pattern\": \"(409[0-4]|40[0-8][0-9]|[1-3][0-9]{3}|[1-9][0-9]{1,2}|[1-9])\\\\.((409[0-4]|40[0-8][0-9]|[1-3][0-9]{3}|[1-9][0-9]{1,2}|[1-9])|\\\\*)\"\n                            },\n                        ),\n                        RestrictedClassType(\n                            base_type=six.text_type,\n                            restriction_dict={\n                                \"pattern\": \"(409[0-4]|40[0-8][0-9]|[1-3][0-9]{3}|[1-9][0-9]{1,2}|[1-9])\\\\.\\\\.(409[0-4]|40[0-8][0-9]|[1-3][0-9]{3}|[1-9][0-9]{1,2}|[1-9])\\\\.((409[0-4]|40[0-8][0-9]|[1-3][0-9]{3}|[1-9][0-9]{1,2}|[1-9])|\\\\*)\"\n                            },\n                        ),\n                        RestrictedClassType(\n                            base_type=six.text_type,\n                            restriction_dict={\n                                \"pattern\": \"(\\\\*|(409[0-4]|40[0-8][0-9]|[1-3][0-9]{3}|[1-9][0-9]{1,2}|[1-9]))\\\\.(409[0-4]|40[0-8][0-9]|[1-3][0-9]{3}|[1-9][0-9]{1,2}|[1-9])\\\\.\\\\.(409[0-4]|40[0-8][0-9]|[1-3][0-9]{3}|[1-9][0-9]{1,2}|[1-9])\"\n                            },\n                        ),\n                    ]\n                ),\n                is_leaf=False,\n                yang_name=\"trunk-vlans\",\n                parent=self,\n                path_helper=self._path_helper,\n                extmethods=self._extmethods,\n                register_paths=True,\n                namespace=\"http://openconfig.net/yang/vlan\",\n                defining_module=\"openconfig-vlan\",\n                yang_type=\"union\",\n                is_config=False,\n            )\n        except (TypeError, ValueError):\n            raise ValueError(\n                {\n                    \"error-string\": \"\"\"trunk_vlans must be of a type compatible with union\"\"\",\n                    \"defined-type\": \"openconfig-vlan:union\",\n                    \"generated-type\": \"\"\"YANGDynClass(base=TypedListType(allowed_type=[RestrictedClassType(base_type=RestrictedClassType(base_type=int, restriction_dict={'range': ['0..65535']},int_size=16), restriction_dict={'range': ['1..4094']}),RestrictedClassType(base_type=six.text_type, restriction_dict={'pattern': '(409[0-4]|40[0-8][0-9]|[1-3][0-9]{3}|[1-9][0-9]{1,2}|[1-9])\\\\.\\\\.(409[0-4]|40[0-8][0-9]|[1-3][0-9]{3}|[1-9][0-9]{1,2}|[1-9])'}),RestrictedClassType(base_type=six.text_type, restriction_dict={'pattern': '(409[0-4]|40[0-8][0-9]|[1-3][0-9]{3}|[1-9][0-9]{1,2}|[1-9])\\\\.((409[0-4]|40[0-8][0-9]|[1-3][0-9]{3}|[1-9][0-9]{1,2}|[1-9])|\\\\*)'}),RestrictedClassType(base_type=six.text_type, restriction_dict={'pattern': '(409[0-4]|40[0-8][0-9]|[1-3][0-9]{3}|[1-9][0-9]{1,2}|[1-9])\\\\.\\\\.(409[0-4]|40[0-8][0-9]|[1-3][0-9]{3}|[1-9][0-9]{1,2}|[1-9])\\\\.((409[0-4]|40[0-8][0-9]|[1-3][0-9]{3}|[1-9][0-9]{1,2}|[1-9])|\\\\*)'}),RestrictedClassType(base_type=six.text_type, restriction_dict={'pattern': '(\\\\*|(409[0-4]|40[0-8][0-9]|[1-3][0-9]{3}|[1-9][0-9]{1,2}|[1-9]))\\\\.(409[0-4]|40[0-8][0-9]|[1-3][0-9]{3}|[1-9][0-9]{1,2}|[1-9])\\\\.\\\\.(409[0-4]|40[0-8][0-9]|[1-3][0-9]{3}|[1-9][0-9]{1,2}|[1-9])'}),]), is_leaf=False, yang_name=\"trunk-vlans\", parent=self, path_helper=self._path_helper, extmethods=self._extmethods, register_paths=True, namespace='http://openconfig.net/yang/vlan', defining_module='openconfig-vlan', yang_type='union', is_config=False)\"\"\",\n                }\n            )\n\n        self.__trunk_vlans = t\n        if hasattr(self, \"_set\"):\n            self._set()", "response": "Sets the value of the trunk_vlans property of the base node."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfind the necessary file for the given profile and filename.", "response": "def find_yang_file(profile, filename, path):\n    \"\"\"\n    Find the necessary file for the given test case.\n\n    Args:\n        device(napalm device connection): for which device\n        filename(str): file to find\n        path(str): where to find it relative to where the module is installed\n    \"\"\"\n    # Find base_dir of submodule\n    module_dir = os.path.dirname(__file__)\n    full_path = os.path.join(module_dir, \"mappings\", profile, path, filename)\n\n    if os.path.exists(full_path):\n        return full_path\n    else:\n        msg = \"Couldn't find parsing file: {}\".format(full_path)\n        logger.error(msg)\n        raise IOError(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef model_to_dict(model, mode=\"\", show_defaults=False):\n\n    def is_mode(obj, mode):\n        if mode == \"\":\n            return True\n        elif mode == \"config\":\n            return obj._yang_name == \"config\" or obj._is_config\n        elif mode == \"state\":\n            return obj._yang_name == \"state\" or not obj._is_config\n        else:\n            raise ValueError(\n                \"mode can only be config, state or ''. Passed: {}\".format(mode)\n            )\n\n    def get_key(key, model, parent_defining_module, show_defaults):\n        if not show_defaults:\n            # No need to display rw/ro when showing the defaults.\n            key = \"{} {}\".format(key, \"[rw]\" if model._is_config else \"[ro]\")\n        if parent_defining_module != model._defining_module:\n            key = \"{}:{}\".format(model._defining_module, key)\n        return key\n\n    if model._yang_type in (\"container\", \"list\"):\n        cls = model if model._yang_type in (\"container\",) else model._contained_class()\n        result = {}\n        for k, v in cls:\n            r = model_to_dict(v, mode=mode, show_defaults=show_defaults)\n            if r:\n                result[get_key(k, v, model._defining_module, show_defaults)] = r\n        return result\n    else:\n        if show_defaults:\n            if model._default is False:\n                if model._yang_type != \"boolean\":\n                    # Unless the datatype is bool, when the _default attribute\n                    # is False, it means there is not default value defined in\n                    # the YANG model.\n                    return None\n            return model._default\n        return model._yang_type if is_mode(model, mode) else None", "response": "Given a model return a dictionary representation of the model."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the difference between two models.", "response": "def diff(f, s):\n    \"\"\"\n    Given two models, return the difference between them.\n\n    Args:\n\n        f (Pybindbase): First element.\n        s (Pybindbase): Second element.\n\n    Returns:\n\n        dict: A dictionary highlighting the differences.\n\n    Examples:\n\n        >>> diff = napalm_yang.utils.diff(candidate, running)\n        >>> pretty_print(diff)\n        >>> {\n        >>>     \"interfaces\": {\n        >>>         \"interface\": {\n        >>>             \"both\": {\n        >>>                 \"Port-Channel1\": {\n        >>>                     \"config\": {\n        >>>                         \"mtu\": {\n        >>>                             \"first\": \"0\",\n        >>>                             \"second\": \"9000\"\n        >>>                         }\n        >>>                     }\n        >>>                 }\n        >>>             },\n        >>>             \"first_only\": [\n        >>>                 \"Loopback0\"\n        >>>             ],\n        >>>             \"second_only\": [\n        >>>                 \"Loopback1\"\n        >>>             ]\n        >>>         }\n        >>>     }\n        >>> }\n    \"\"\"\n    if isinstance(f, base.Root) or f._yang_type in (\"container\", None):\n        result = _diff_root(f, s)\n    elif f._yang_type in (\"list\",):\n        result = _diff_list(f, s)\n    else:\n        result = {}\n        first = \"{}\".format(f)\n        second = \"{}\".format(s)\n        if first != second:\n            result = {\"first\": first, \"second\": second}\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\npost to URL and get result as a response object.", "response": "def http_post(self, url, data=None):\n        \"\"\"POST to URL and get result as a response object.\n\n        :param url: URL to POST.\n        :type url: str\n        :param data: Data to send in the form body.\n        :type data: str\n        :rtype: requests.Response\n        \"\"\"\n        if not url.startswith('https://'):\n            raise ValueError('Protocol must be HTTPS, invalid URL: %s' % url)\n        return requests.post(url, data, verify=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_authorization_code_uri(self, **params):\n        if 'response_type' not in params:\n            params['response_type'] = self.default_response_type\n        params.update({'client_id': self.client_id,\n                       'redirect_uri': self.redirect_uri})\n        return utils.build_url(self.authorization_uri, params)", "response": "Construct a full URL that can be used to obtain an authorization code from the provider authorization_uri."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets an access token from the provider token URI.", "response": "def get_token(self, code, **params):\n        \"\"\"Get an access token from the provider token URI.\n\n        :param code: Authorization code.\n        :type code: str\n        :return: Dict containing access token, refresh token, etc.\n        :rtype: dict\n        \"\"\"\n        params['code'] = code\n        if 'grant_type' not in params:\n            params['grant_type'] = self.default_grant_type\n        params.update({'client_id': self.client_id,\n                       'client_secret': self.client_secret,\n                       'redirect_uri': self.redirect_uri})\n        response = self.http_post(self.token_uri, params)\n        try:\n            return response.json()\n        except TypeError:\n            return response.json"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the query parameters as a dict from the specified URL.", "response": "def url_query_params(url):\n    \"\"\"Return query parameters as a dict from the specified URL.\n\n    :param url: URL.\n    :type url: str\n    :rtype: dict\n    \"\"\"\n    return dict(urlparse.parse_qsl(urlparse.urlparse(url).query, True))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef url_dequery(url):\n    url = urlparse.urlparse(url)\n    return urlparse.urlunparse((url.scheme,\n                                url.netloc,\n                                url.path,\n                                url.params,\n                                '',\n                                url.fragment))", "response": "Return a URL with the query component removed."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconstructing a URL based off of base containing all parameters in the query portion of base plus any additional parameters.", "response": "def build_url(base, additional_params=None):\n    \"\"\"Construct a URL based off of base containing all parameters in\n    the query portion of base plus any additional parameters.\n\n    :param base: Base URL\n    :type base: str\n    ::param additional_params: Additional query parameters to include.\n    :type additional_params: dict\n    :rtype: str\n    \"\"\"\n    url = urlparse.urlparse(base)\n    query_params = {}\n    query_params.update(urlparse.parse_qsl(url.query, True))\n    if additional_params is not None:\n        query_params.update(additional_params)\n        for k, v in additional_params.iteritems():\n            if v is None:\n                query_params.pop(k)\n\n    return urlparse.urlunparse((url.scheme,\n                                url.netloc,\n                                url.path,\n                                url.params,\n                                urllib.urlencode(query_params),\n                                url.fragment))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nhandling an internal exception that was caught and suppressed.", "response": "def _handle_exception(self, exc):\n        \"\"\"Handle an internal exception that was caught and suppressed.\n\n        :param exc: Exception to process.\n        :type exc: Exception\n        \"\"\"\n        logger = logging.getLogger(__name__)\n        logger.exception(exc)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a Response object from the given parameters.", "response": "def _make_response(self, body='', headers=None, status_code=200):\n        \"\"\"Return a response object from the given parameters.\n\n        :param body: Buffer/string containing the response body.\n        :type body: str\n        :param headers: Dict of headers to include in the requests.\n        :type headers: dict\n        :param status_code: HTTP status code.\n        :type status_code: int\n        :rtype: requests.Response\n        \"\"\"\n        res = Response()\n        res.status_code = status_code\n        if headers is not None:\n            res.headers.update(headers)\n        res.raw = StringIO(body)\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _make_redirect_error_response(self, redirect_uri, err):\n        params = {\n            'error': err,\n            'response_type': None,\n            'client_id': None,\n            'redirect_uri': None\n        }\n        redirect = utils.build_url(redirect_uri, params)\n        return self._make_response(headers={'Location': redirect},\n                                   status_code=302)", "response": "Create a HTTP 302 redirect response object containing the error."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _make_json_response(self, data, headers=None, status_code=200):\n        response_headers = {}\n        if headers is not None:\n            response_headers.update(headers)\n        response_headers['Content-Type'] = 'application/json;charset=UTF-8'\n        response_headers['Cache-Control'] = 'no-store'\n        response_headers['Pragma'] = 'no-cache'\n        return self._make_response(json.dumps(data),\n                                   response_headers,\n                                   status_code)", "response": "Return a response object from the given JSON data."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating and return an authorization code HTTP response.", "response": "def get_authorization_code(self,\n                               response_type,\n                               client_id,\n                               redirect_uri,\n                               **params):\n        \"\"\"Generate authorization code HTTP response.\n\n        :param response_type: Desired response type. Must be exactly \"code\".\n        :type response_type: str\n        :param client_id: Client ID.\n        :type client_id: str\n        :param redirect_uri: Client redirect URI.\n        :type redirect_uri: str\n        :rtype: requests.Response\n        \"\"\"\n\n        # Ensure proper response_type\n        if response_type != 'code':\n            err = 'unsupported_response_type'\n            return self._make_redirect_error_response(redirect_uri, err)\n\n        # Check redirect URI\n        is_valid_redirect_uri = self.validate_redirect_uri(client_id,\n                                                           redirect_uri)\n        if not is_valid_redirect_uri:\n            return self._invalid_redirect_uri_response()\n\n        # Check conditions\n        is_valid_client_id = self.validate_client_id(client_id)\n        is_valid_access = self.validate_access()\n        scope = params.get('scope', '')\n        is_valid_scope = self.validate_scope(client_id, scope)\n\n        # Return proper error responses on invalid conditions\n        if not is_valid_client_id:\n            err = 'unauthorized_client'\n            return self._make_redirect_error_response(redirect_uri, err)\n\n        if not is_valid_access:\n            err = 'access_denied'\n            return self._make_redirect_error_response(redirect_uri, err)\n\n        if not is_valid_scope:\n            err = 'invalid_scope'\n            return self._make_redirect_error_response(redirect_uri, err)\n\n        # Generate authorization code\n        code = self.generate_authorization_code()\n\n        # Save information to be used to validate later requests\n        self.persist_authorization_code(client_id=client_id,\n                                        code=code,\n                                        scope=scope)\n\n        # Return redirection response\n        params.update({\n            'code': code,\n            'response_type': None,\n            'client_id': None,\n            'redirect_uri': None\n        })\n        redirect = utils.build_url(redirect_uri, params)\n        return self._make_response(headers={'Location': redirect},\n                                   status_code=302)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef refresh_token(self,\n                      grant_type,\n                      client_id,\n                      client_secret,\n                      refresh_token,\n                      **params):\n        \"\"\"Generate access token HTTP response from a refresh token.\n\n        :param grant_type: Desired grant type. Must be \"refresh_token\".\n        :type grant_type: str\n        :param client_id: Client ID.\n        :type client_id: str\n        :param client_secret: Client secret.\n        :type client_secret: str\n        :param refresh_token: Refresh token.\n        :type refresh_token: str\n        :rtype: requests.Response\n        \"\"\"\n\n        # Ensure proper grant_type\n        if grant_type != 'refresh_token':\n            return self._make_json_error_response('unsupported_grant_type')\n\n        # Check conditions\n        is_valid_client_id = self.validate_client_id(client_id)\n        is_valid_client_secret = self.validate_client_secret(client_id,\n                                                             client_secret)\n        scope = params.get('scope', '')\n        is_valid_scope = self.validate_scope(client_id, scope)\n        data = self.from_refresh_token(client_id, refresh_token, scope)\n        is_valid_refresh_token = data is not None\n\n        # Return proper error responses on invalid conditions\n        if not (is_valid_client_id and is_valid_client_secret):\n            return self._make_json_error_response('invalid_client')\n\n        if not is_valid_scope:\n            return self._make_json_error_response('invalid_scope')\n\n        if not is_valid_refresh_token:\n            return self._make_json_error_response('invalid_grant')\n\n        # Discard original refresh token\n        self.discard_refresh_token(client_id, refresh_token)\n\n        # Generate access tokens once all conditions have been met\n        access_token = self.generate_access_token()\n        token_type = self.token_type\n        expires_in = self.token_expires_in\n        refresh_token = self.generate_refresh_token()\n\n        # Save information to be used to validate later requests\n        self.persist_token_information(client_id=client_id,\n                                       scope=scope,\n                                       access_token=access_token,\n                                       token_type=token_type,\n                                       expires_in=expires_in,\n                                       refresh_token=refresh_token,\n                                       data=data)\n\n        # Return json response\n        return self._make_json_response({\n            'access_token': access_token,\n            'token_type': token_type,\n            'expires_in': expires_in,\n            'refresh_token': refresh_token\n        })", "response": "Generate an access token HTTP response from a refresh token."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_token(self,\n                  grant_type,\n                  client_id,\n                  client_secret,\n                  redirect_uri,\n                  code,\n                  **params):\n        \"\"\"Generate access token HTTP response.\n\n        :param grant_type: Desired grant type. Must be \"authorization_code\".\n        :type grant_type: str\n        :param client_id: Client ID.\n        :type client_id: str\n        :param client_secret: Client secret.\n        :type client_secret: str\n        :param redirect_uri: Client redirect URI.\n        :type redirect_uri: str\n        :param code: Authorization code.\n        :type code: str\n        :rtype: requests.Response\n        \"\"\"\n\n        # Ensure proper grant_type\n        if grant_type != 'authorization_code':\n            return self._make_json_error_response('unsupported_grant_type')\n\n        # Check conditions\n        is_valid_client_id = self.validate_client_id(client_id)\n        is_valid_client_secret = self.validate_client_secret(client_id,\n                                                             client_secret)\n        is_valid_redirect_uri = self.validate_redirect_uri(client_id,\n                                                           redirect_uri)\n\n        scope = params.get('scope', '')\n        is_valid_scope = self.validate_scope(client_id, scope)\n        data = self.from_authorization_code(client_id, code, scope)\n        is_valid_grant = data is not None\n\n        # Return proper error responses on invalid conditions\n        if not (is_valid_client_id and is_valid_client_secret):\n            return self._make_json_error_response('invalid_client')\n\n        if not is_valid_grant or not is_valid_redirect_uri:\n            return self._make_json_error_response('invalid_grant')\n\n        if not is_valid_scope:\n            return self._make_json_error_response('invalid_scope')\n\n        # Discard original authorization code\n        self.discard_authorization_code(client_id, code)\n\n        # Generate access tokens once all conditions have been met\n        access_token = self.generate_access_token()\n        token_type = self.token_type\n        expires_in = self.token_expires_in\n        refresh_token = self.generate_refresh_token()\n\n        # Save information to be used to validate later requests\n        self.persist_token_information(client_id=client_id,\n                                       scope=scope,\n                                       access_token=access_token,\n                                       token_type=token_type,\n                                       expires_in=expires_in,\n                                       refresh_token=refresh_token,\n                                       data=data)\n\n        # Return json response\n        return self._make_json_response({\n            'access_token': access_token,\n            'token_type': token_type,\n            'expires_in': expires_in,\n            'refresh_token': refresh_token\n        })", "response": "Generate access token HTTP response."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting authorization code response from a URI. This method will ignore the domain and path of the request, instead automatically parsing the query string parameters. :param uri: URI to parse for authorization information. :type uri: str :rtype: requests.Response", "response": "def get_authorization_code_from_uri(self, uri):\n        \"\"\"Get authorization code response from a URI. This method will\n        ignore the domain and path of the request, instead\n        automatically parsing the query string parameters.\n\n        :param uri: URI to parse for authorization information.\n        :type uri: str\n        :rtype: requests.Response\n        \"\"\"\n        params = utils.url_query_params(uri)\n        try:\n            if 'response_type' not in params:\n                raise TypeError('Missing parameter response_type in URL query')\n\n            if 'client_id' not in params:\n                raise TypeError('Missing parameter client_id in URL query')\n\n            if 'redirect_uri' not in params:\n                raise TypeError('Missing parameter redirect_uri in URL query')\n\n            return self.get_authorization_code(**params)\n        except TypeError as exc:\n            self._handle_exception(exc)\n\n            # Catch missing parameters in request\n            err = 'invalid_request'\n            if 'redirect_uri' in params:\n                u = params['redirect_uri']\n                return self._make_redirect_error_response(u, err)\n            else:\n                return self._invalid_redirect_uri_response()\n        except StandardError as exc:\n            self._handle_exception(exc)\n\n            # Catch all other server errors\n            err = 'server_error'\n            u = params['redirect_uri']\n            return self._make_redirect_error_response(u, err)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_token_from_post_data(self, data):\n        try:\n            # Verify OAuth 2.0 Parameters\n            for x in ['grant_type', 'client_id', 'client_secret']:\n                if not data.get(x):\n                    raise TypeError(\"Missing required OAuth 2.0 POST param: {0}\".format(x))\n            \n            # Handle get token from refresh_token\n            if 'refresh_token' in data:\n                return self.refresh_token(**data)\n\n            # Handle get token from authorization code\n            for x in ['redirect_uri', 'code']:\n                if not data.get(x):\n                    raise TypeError(\"Missing required OAuth 2.0 POST param: {0}\".format(x))            \n            return self.get_token(**data)\n        except TypeError as exc:\n            self._handle_exception(exc)\n\n            # Catch missing parameters in request\n            return self._make_json_error_response('invalid_request')\n        except StandardError as exc:\n            self._handle_exception(exc)\n\n            # Catch all other server errors\n            return self._make_json_error_response('server_error')", "response": "Get a token from POST data."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget authorization object representing status of authentication.", "response": "def get_authorization(self):\n        \"\"\"Get authorization object representing status of authentication.\"\"\"\n        auth = self.authorization_class()\n        header = self.get_authorization_header()\n        if not header or not header.split:\n            return auth\n        header = header.split()\n        if len(header) > 1 and header[0] == 'Bearer':\n            auth.is_oauth = True\n            access_token = header[1]\n            self.validate_access_token(access_token, auth)\n            if not auth.is_valid:\n                auth.error = 'access_denied'\n        return auth"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef open(self, bus):\n        # Close the device if it's already open.\n        if self._device is not None:\n            self.close()\n        # Try to open the file for the specified bus.  Must turn off buffering\n        # or else Python 3 fails (see: https://bugs.python.org/issue20074)\n        self._device = open('/dev/i2c-{0}'.format(bus), 'r+b', buffering=0)", "response": "Open the smbus interface on the specified bus."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read_byte(self, addr):\n        assert self._device is not None, 'Bus must be opened before operations are made against it!'\n        self._select_device(addr)\n        return ord(self._device.read(1))", "response": "Read a single byte from the specified device."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read_bytes(self, addr, number):\n        assert self._device is not None, 'Bus must be opened before operations are made against it!'\n        self._select_device(addr)\n        return self._device.read(number)", "response": "Read many bytes from the specified device."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef read_byte_data(self, addr, cmd):\n        assert self._device is not None, 'Bus must be opened before operations are made against it!'\n        # Build ctypes values to marshall between ioctl and Python.\n        reg = c_uint8(cmd)\n        result = c_uint8()\n        # Build ioctl request.\n        request = make_i2c_rdwr_data([\n            (addr, 0, 1, pointer(reg)),             # Write cmd register.\n            (addr, I2C_M_RD, 1, pointer(result))    # Read 1 byte as result.\n        ])\n        # Make ioctl call and return result data.\n        ioctl(self._device.fileno(), I2C_RDWR, request)\n        return result.value", "response": "Read a single byte from the specified cmd register of the device."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read_word_data(self, addr, cmd):\n        assert self._device is not None, 'Bus must be opened before operations are made against it!'\n        # Build ctypes values to marshall between ioctl and Python.\n        reg = c_uint8(cmd)\n        result = c_uint16()\n        # Build ioctl request.\n        request = make_i2c_rdwr_data([\n            (addr, 0, 1, pointer(reg)),             # Write cmd register.\n            (addr, I2C_M_RD, 2, cast(pointer(result), POINTER(c_uint8)))   # Read word (2 bytes).\n        ])\n        # Make ioctl call and return result data.\n        ioctl(self._device.fileno(), I2C_RDWR, request)\n        return result.value", "response": "Read a word from the specified cmd register of the device."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nperforming a read from the specified cmd register of device.", "response": "def read_i2c_block_data(self, addr, cmd, length=32):\n        \"\"\"Perform a read from the specified cmd register of device.  Length number\n        of bytes (default of 32) will be read and returned as a bytearray.\n        \"\"\"\n        assert self._device is not None, 'Bus must be opened before operations are made against it!'\n        # Build ctypes values to marshall between ioctl and Python.\n        reg = c_uint8(cmd)\n        result = create_string_buffer(length)\n        # Build ioctl request.\n        request = make_i2c_rdwr_data([\n            (addr, 0, 1, pointer(reg)),             # Write cmd register.\n            (addr, I2C_M_RD, length, cast(result, POINTER(c_uint8)))   # Read data.\n        ])\n        # Make ioctl call and return result data.\n        ioctl(self._device.fileno(), I2C_RDWR, request)\n        return bytearray(result.raw)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrite a single byte to the specified device.", "response": "def write_quick(self, addr):\n        \"\"\"Write a single byte to the specified device.\"\"\"\n        # What a strange function, from the python-smbus source this appears to\n        # just write a single byte that initiates a write to the specified device\n        # address (but writes no data!).  The functionality is duplicated below\n        # but the actual use case for this is unknown.\n        assert self._device is not None, 'Bus must be opened before operations are made against it!'\n        # Build ioctl request.\n        request = make_i2c_rdwr_data([\n            (addr, 0, 0, None),  # Write with no data.\n        ])\n        # Make ioctl call and return result data.\n        ioctl(self._device.fileno(), I2C_RDWR, request)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite a single byte to the specified device.", "response": "def write_byte(self, addr, val):\n        \"\"\"Write a single byte to the specified device.\"\"\"\n        assert self._device is not None, 'Bus must be opened before operations are made against it!'\n        self._select_device(addr)\n        data = bytearray(1)\n        data[0] = val & 0xFF\n        self._device.write(data)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwriting many bytes to the specified device.", "response": "def write_bytes(self, addr, buf):\n        \"\"\"Write many bytes to the specified device. buf is a bytearray\"\"\"\n        assert self._device is not None, 'Bus must be opened before operations are made against it!'\n        self._select_device(addr)\n        self._device.write(buf)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef write_byte_data(self, addr, cmd, val):\n        assert self._device is not None, 'Bus must be opened before operations are made against it!'\n        # Construct a string of data to send with the command register and byte value.\n        data = bytearray(2)\n        data[0] = cmd & 0xFF\n        data[1] = val & 0xFF\n        # Send the data to the device.\n        self._select_device(addr)\n        self._device.write(data)", "response": "Write a byte to the specified command register of the device."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrite a 2 byte word of data to the specified cmd register of the specified device.", "response": "def write_word_data(self, addr, cmd, val):\n        \"\"\"Write a word (2 bytes) of data to the specified cmd register of the\n        device.  Note that this will write the data in the endianness of the\n        processor running Python (typically little endian)!\n        \"\"\"\n        assert self._device is not None, 'Bus must be opened before operations are made against it!'\n        # Construct a string of data to send with the command register and word value.\n        data = struct.pack('=BH', cmd & 0xFF, val & 0xFFFF)\n        # Send the data to the device.\n        self._select_device(addr)\n        self._device.write(data)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrite a block of data to the specified cmd register.", "response": "def write_block_data(self, addr, cmd, vals):\n        \"\"\"Write a block of data to the specified cmd register of the device.\n        The amount of data to write should be the first byte inside the vals\n        string/bytearray and that count of bytes of data to write should follow\n        it.\n        \"\"\"\n        # Just use the I2C block data write to write the provided values and\n        # their length as the first byte.\n        data = bytearray(len(vals)+1)\n        data[0] = len(vals) & 0xFF\n        data[1:] = vals[0:]\n        self.write_i2c_block_data(addr, cmd, data)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwriting a buffer of data to the specified command register of the device.", "response": "def write_i2c_block_data(self, addr, cmd, vals):\n        \"\"\"Write a buffer of data to the specified cmd register of the device.\n        \"\"\"\n        assert self._device is not None, 'Bus must be opened before operations are made against it!'\n        # Construct a string of data to send, including room for the command register.\n        data = bytearray(len(vals)+1)\n        data[0] = cmd & 0xFF  # Command register at the start.\n        data[1:] = vals[0:]   # Copy in the block data (ugly but necessary to ensure\n                              # the entire write happens in one transaction).\n        # Send the data to the device.\n        self._select_device(addr)\n        self._device.write(data)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef process_call(self, addr, cmd, val):\n        assert self._device is not None, 'Bus must be opened before operations are made against it!'\n        # Build ctypes values to marshall between ioctl and Python.\n        data = create_string_buffer(struct.pack('=BH', cmd, val))\n        result = c_uint16()\n        # Build ioctl request.\n        request = make_i2c_rdwr_data([\n            (addr, 0, 3, cast(pointer(data), POINTER(c_uint8))),          # Write data.\n            (addr, I2C_M_RD, 2, cast(pointer(result), POINTER(c_uint8)))  # Read word (2 bytes).\n        ])\n        # Make ioctl call and return result data.\n        ioctl(self._device.fileno(), I2C_RDWR, request)\n        # Note the python-smbus code appears to have a rather serious bug and\n        # does not return the result value!  This is fixed below by returning it.\n        return result.value", "response": "Perform a smbus process call by writing a word to the specified register of the device and then reading a word of response\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cdn_url(self):\n        return '{cdn_base}{path}'.format(cdn_base=conf.cdn_base,\n                                         path=self.cdn_path(self.default_effects))", "response": "Returns file s CDN url."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn file s store aware datetime in UTC format.", "response": "def datetime_stored(self):\n        \"\"\"Returns file's store aware *datetime* in UTC format.\n\n        It might do API request once because it depends on ``info()``.\n\n        \"\"\"\n        if self.info().get('datetime_stored'):\n            return dateutil.parser.parse(self.info()['datetime_stored'])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef datetime_removed(self):\n        if self.info().get('datetime_removed'):\n            return dateutil.parser.parse(self.info()['datetime_removed'])", "response": "Returns file s remove aware *datetime* in UTC format."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn file s upload aware *datetime* in UTC format.", "response": "def datetime_uploaded(self):\n        \"\"\"Returns file's upload aware *datetime* in UTC format.\n\n        It might do API request once because it depends on ``info()``.\n\n        \"\"\"\n        if self.info().get('datetime_uploaded'):\n            return dateutil.parser.parse(self.info()['datetime_uploaded'])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef copy(self, effects=None, target=None):\n        warning = \"\"\"File.copy method is deprecated and will be\n            removed in 4.0.0.\n            Please use `create_local_copy`\n            and `create_remote_copy` instead.\n        \"\"\"\n        logger.warn('API Warning: {0}'.format(warning))\n\n        if target is not None:\n            return self.create_remote_copy(target, effects)\n        else:\n            return self.create_local_copy(effects)", "response": "Creates a File Copy on Uploadcare or Custom Storage."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_local_copy(self, effects=None, store=None):\n        effects = self._build_effects(effects)\n        store = store or ''\n        data = {\n            'source': self.cdn_path(effects)\n        }\n        if store:\n            data['store'] = store\n        return rest_request('POST', 'files/', data=data)", "response": "Creates a Local File Copy on Uploadcare Storage."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a remote copy of a file to a custom storage.", "response": "def create_remote_copy(self, target, effects=None, make_public=None,\n                           pattern=None):\n        \"\"\"Creates file copy in remote storage.\n\n        Args:\n            - target:\n                Name of a custom storage connected to the project.\n            - effects:\n                Adds CDN image effects to ``self.default_effects`` if any.\n            - make_public:\n                To forbid public from accessing your files on the storage set\n                ``make_public`` option to be False.\n                Default value is None. Files have public access by default.\n            - pattern:\n                Specify ``pattern`` option to set S3 object key name.\n                Takes precedence over pattern set in project settings.\n                If neither is specified defaults to\n                `${uuid}/${filename}${effects}${ext}`.\n\n        For more information on each of the options above please refer to\n        REST API docs https://uploadcare.com/docs/api_reference/rest/accessing_files/.\n\n        Following example copies a file to custom storage named ``samplefs``:\n\n             >>> file = File('e8ebfe20-8c11-4a94-9b40-52ecad7d8d1a')\n             >>> file.create_remote_copy(target='samplefs',\n             >>>                         make_public=True,\n             >>>                         pattern='${uuid}/${filename}${ext}')\n\n        Now custom storage ``samplefs`` contains publicly available file\n        with original filename billmurray.jpg in\n        in the directory named ``e8ebfe20-8c11-4a94-9b40-52ecad7d8d1a``.\n\n        \"\"\"\n        effects = self._build_effects(effects)\n        data = {\n            'source': self.cdn_path(effects),\n            'target': target\n        }\n\n        if make_public is not None:\n            data['make_public'] = make_public\n        if pattern is not None:\n            data['pattern'] = pattern\n        return rest_request('POST', 'files/', data=data)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconstructing a new File instance from file info.", "response": "def construct_from(cls, file_info):\n        \"\"\"Constructs ``File`` instance from file information.\n\n        For example you have result of\n        ``/files/1921953c-5d94-4e47-ba36-c2e1dd165e1a/`` API request::\n\n            >>> file_info = {\n                    # ...\n                    'uuid': '1921953c-5d94-4e47-ba36-c2e1dd165e1a',\n                    # ...\n                }\n            >>> File.construct_from(file_info)\n            <uploadcare.File 1921953c-5d94-4e47-ba36-c2e1dd165e1a>\n\n        \"\"\"\n        file_ = cls(file_info['uuid'])\n        file_.default_effects = file_info.get('default_effects')\n        file_._info_cache = file_info\n        return file_"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nuploading a file to a specific node and returns a File instance.", "response": "def upload(cls, file_obj, store=None):\n        \"\"\"Uploads a file and returns ``File`` instance.\n\n        Args:\n            - file_obj: file object to upload to\n            - store (Optional[bool]): Should the file be automatically stored\n                upon upload. Defaults to None.\n                - False - do not store file\n                - True - store file (can result in error if autostore\n                               is disabled for project)\n                - None - use project settings\n\n        Returns:\n            ``File`` instance\n\n        \"\"\"\n        if store is None:\n            store = 'auto'\n        elif store:\n            store = '1'\n        else:\n            store = '0'\n\n        data = {\n            'UPLOADCARE_STORE': store,\n        }\n\n        files = uploading_request('POST', 'base/', data=data,\n                                  files={'file': file_obj})\n        file_ = cls(files['file'])\n        return file_"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nuploading file from given url and returns FileFromUrl instance.", "response": "def upload_from_url(cls, url, store=None, filename=None):\n        \"\"\"Uploads file from given url and returns ``FileFromUrl`` instance.\n\n        Args:\n            - url (str): URL of file to upload to\n            - store (Optional[bool]): Should the file be automatically stored\n                upon upload. Defaults to None.\n                - False - do not store file\n                - True - store file (can result in error if autostore\n                               is disabled for project)\n                - None - use project settings\n            - filename (Optional[str]): Name of the uploaded file. If this not\n                specified the filename will be obtained from response headers\n                or source URL. Defaults to None.\n\n        Returns:\n            ``FileFromUrl`` instance\n\n        \"\"\"\n        if store is None:\n            store = 'auto'\n        elif store:\n            store = '1'\n        else:\n            store = '0'\n\n        data = {\n            'source_url': url,\n            'store': store,\n        }\n        if filename:\n            data['filename'] = filename\n\n        result = uploading_request('POST', 'from_url/',\n                                   data=data)\n        if 'token' not in result:\n            raise APIError(\n                'could not find token in result: {0}'.format(result)\n            )\n        file_from_url = cls.FileFromUrl(result['token'])\n        return file_from_url"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef upload_from_url_sync(cls, url, timeout=30, interval=0.3,\n                             until_ready=False, store=None, filename=None):\n        \"\"\"Uploads file from given url and returns ``File`` instance.\n\n        Args:\n            - url (str): URL of file to upload to\n            - store (Optional[bool]): Should the file be automatically stored\n                upon upload. Defaults to None.\n                - False - do not store file\n                - True - store file (can result in error if autostore\n                               is disabled for project)\n                - None - use project settings\n            - filename (Optional[str]): Name of the uploaded file. If this not\n                specified the filename will be obtained from response headers\n                or source URL. Defaults to None.\n            - timeout (Optional[int]): seconds to wait for successful upload.\n                Defaults to 30.\n            - interval (Optional[float]): interval between upload status checks.\n                Defaults to 0.3.\n            - until_ready (Optional[bool]): should we wait until file is\n                available via CDN. Defaults to False.\n\n        Returns:\n            ``File`` instance\n\n        Raises:\n            ``TimeoutError`` if file wasn't uploaded in time\n\n        \"\"\"\n        ffu = cls.upload_from_url(url, store, filename)\n        return ffu.wait(timeout=timeout, interval=interval,\n                        until_ready=until_ready)", "response": "Uploads file from given url and returns File instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef file_cdn_urls(self):\n        file_cdn_urls = []\n        for file_index in six.moves.xrange(len(self)):\n            file_cdn_url = '{group_cdn_url}nth/{file_index}/'.format(\n                group_cdn_url=self.cdn_url,\n                file_index=file_index\n            )\n            file_cdn_urls.append(file_cdn_url)\n        return file_cdn_urls", "response": "Returns a list of all files from group without API requesting."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn file group s create aware *datetime* in UTC format.", "response": "def datetime_created(self):\n        \"\"\"Returns file group's create aware *datetime* in UTC format.\"\"\"\n        if self.info().get('datetime_created'):\n            return dateutil.parser.parse(self.info()['datetime_created'])"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconstructs a FileGroup instance from group information.", "response": "def construct_from(cls, group_info):\n        \"\"\"Constructs ``FileGroup`` instance from group information.\"\"\"\n        group = cls(group_info['id'])\n        group._info_cache = group_info\n        return group"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create(cls, files):\n        data = {}\n        for index, file_ in enumerate(files):\n            if isinstance(file_, File):\n                file_index = 'files[{index}]'.format(index=index)\n                data[file_index] = six.text_type(file_)\n            else:\n                raise InvalidParamError(\n                    'all items have to be ``File`` instance'\n                )\n        if not data:\n            raise InvalidParamError('set of files is empty')\n\n        group_info = uploading_request('POST', 'group/', data=data)\n\n        group = cls.construct_from(group_info)\n        return group", "response": "Creates a new file group and returns it."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _base_opration(self, method):\n        uuids = self.uuids()\n\n        while True:\n            chunk = list(islice(uuids, 0, self.chunk_size))\n\n            if not chunk:\n                return\n\n            rest_request(method, self.storage_url, chunk)", "response": "Base method for storage operations."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nextracts uuid from each item of specified sequence.", "response": "def uuids(self):\n        \"\"\" Extract uuid from each item of specified ``seq``.\n        \"\"\"\n        for f in self._seq:\n            if isinstance(f, File):\n                yield f.uuid\n            elif isinstance(f, six.string_types):\n                yield f\n            else:\n                raise ValueError(\n                    'Invalid type for sequence item: {0}'.format(type(f)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _list(api_list_class, arg_namespace, **extra):\n    if arg_namespace.starting_point:\n        ordering_field = (arg_namespace.ordering or '').lstrip('-')\n        if ordering_field in ('', 'datetime_uploaded', 'datetime_created'):\n            arg_namespace.starting_point = parser.parse(\n                arg_namespace.starting_point)\n\n    items = api_list_class(\n        starting_point=arg_namespace.starting_point,\n        ordering=arg_namespace.ordering,\n        limit=arg_namespace.limit,\n        request_limit=arg_namespace.request_limit,\n        **extra\n    )\n    items.constructor = lambda x: x\n\n    try:\n        pprint(list(items))\n    except ValueError as e:\n        print(e)", "response": "A common function for building methods of the list showing."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef bar(iter_content, parts, title=''):\n    parts = max(float(parts), 1.0)\n    cells = 10\n    progress = 0\n    step = cells / parts\n\n    draw = lambda progress: sys.stdout.write(\n        '\\r[{0:10}] {1:.2f}% {2}'.format(\n            '#'*int(progress), progress * cells, title))\n\n    for chunk in iter_content:\n        yield chunk\n\n        progress += step\n        draw(progress)\n        sys.stdout.flush()\n\n    draw(cells)\n    print('')", "response": "Draw a progress bar for each element in iter_content."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef rest_request(verb, path, data=None, timeout=conf.DEFAULT,\n                 retry_throttled=conf.DEFAULT):\n    \"\"\"Makes REST API request and returns response as ``dict``.\n\n    It provides auth headers as well and takes settings from ``conf`` module.\n\n    Make sure that given ``path`` does not contain leading slash.\n\n    Usage example::\n\n        >>> rest_request('GET', 'files/?limit=10')\n        {\n            'next': 'https://api.uploadcare.com/files/?limit=10&page=2',\n            'total': 1241,\n            'page': 1,\n            'pages': 125,\n            'per_page': 10,\n            'previous': None,\n            'results': [\n                # ...\n                {\n                    # ...\n                    'uuid': 1921953c-5d94-4e47-ba36-c2e1dd165e1a,\n                    # ...\n                },\n                # ...\n            ]\n        }\n\n    \"\"\"\n    if retry_throttled is conf.DEFAULT:\n        retry_throttled = conf.retry_throttled\n\n    path = path.lstrip('/')\n    url = urljoin(conf.api_base, path)\n    url_parts = urlsplit(url)\n\n    if url_parts.query:\n        path = url_parts.path + '?' + url_parts.query\n    else:\n        path = url_parts.path\n\n    content = ''\n    if data is not None:\n        content = json.dumps(data)\n\n    content_type = 'application/json'\n    content_md5 = hashlib.md5(content.encode('utf-8')).hexdigest()\n\n    def _request():\n        date = email.utils.formatdate(usegmt=True)\n        sign_string = '\\n'.join([\n            verb,\n            content_md5,\n            content_type,\n            date,\n            path,\n        ])\n        sign_string_as_bytes = sign_string.encode('utf-8')\n\n        try:\n            secret_as_bytes = conf.secret.encode('utf-8')\n        except AttributeError:\n            secret_as_bytes = bytes()\n        sign = hmac.new(secret_as_bytes, sign_string_as_bytes, hashlib.sha1) \\\n            .hexdigest()\n\n        headers = {\n            'Authorization': 'Uploadcare {0}:{1}'.format(conf.pub_key, sign),\n            'Date': date,\n            'Content-Type': content_type,\n            'Accept': 'application/vnd.uploadcare-v{0}+json'.format(\n                conf.api_version),\n            'User-Agent': _build_user_agent(),\n        }\n        logger.debug('''sent:\n            verb: {0}\n            path: {1}\n            headers: {2}\n            data: {3}'''.format(verb, path, headers, content))\n\n        try:\n            response = session.request(verb, url, allow_redirects=True,\n                                       verify=conf.verify_api_ssl,\n                                       headers=headers, data=content,\n                                       timeout=_get_timeout(timeout))\n        except requests.RequestException as exc:\n            raise APIConnectionError(exc.args[0])\n\n        logger.debug(\n            'got: {0} {1}'.format(response.status_code, response.text)\n        )\n\n        if 'warning' in response.headers:\n            match = re.search('\"(.+)\"', response.headers['warning'])\n            if match:\n                for warning in match.group(1).split('; '):\n                    logger.warn('API Warning: {0}'.format(warning))\n\n        # No content.\n        if response.status_code == 204:\n            return {}\n        if verb.lower() == 'options':\n            return ''\n\n        if 200 <= response.status_code < 300:\n            if _content_type_from_response(response).endswith(('/json', '+json')):\n                if verb.lower() == 'head':\n                    return ''\n                try:\n                    return response.json()\n                except ValueError as exc:\n                    raise APIError(exc.args[0])\n\n        if response.status_code in (401, 403):\n            raise AuthenticationError(response.content)\n\n        if response.status_code in (400, 404):\n            raise InvalidRequestError(response.content)\n\n        if response.status_code == 429:\n            raise ThrottledRequestError(response)\n\n        # Not json or unknown status code.\n        raise APIError(response.content)\n\n    while True:\n        try:\n            return _request()\n        except ThrottledRequestError as e:\n            if retry_throttled:\n                logger.debug('Throttled, retry in {0} seconds'.format(e.wait))\n                time.sleep(e.wait)\n                retry_throttled -= 1\n                continue\n            else:\n                raise", "response": "Makes REST API request and returns response as dict."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmake a HTTP request and returns response as dict.", "response": "def uploading_request(verb, path, data=None, files=None, timeout=conf.DEFAULT):\n    \"\"\"Makes Uploading API request and returns response as ``dict``.\n\n    It takes settings from ``conf`` module.\n\n    Make sure that given ``path`` does not contain leading slash.\n\n    Usage example::\n\n        >>> file_obj = open('photo.jpg', 'rb')\n        >>> uploading_request('POST', 'base/', files={'file': file_obj})\n        {\n            'file': '9b9f4483-77b8-40ae-a198-272ba6280004'\n        }\n        >>> File('9b9f4483-77b8-40ae-a198-272ba6280004')\n\n    \"\"\"\n    path = path.lstrip('/')\n    url = urljoin(conf.upload_base, path)\n\n    if data is None:\n        data = {}\n    data['pub_key'] = conf.pub_key\n    data['UPLOADCARE_PUB_KEY'] = conf.pub_key\n\n    headers = {\n        'User-Agent': _build_user_agent(),\n    }\n\n    try:\n        response = session.request(\n            str(verb), url, allow_redirects=True,\n            verify=conf.verify_upload_ssl, data=data, files=files,\n            headers=headers, timeout=_get_timeout(timeout),\n        )\n    except requests.RequestException as exc:\n        raise APIConnectionError(exc.args[0])\n\n    # No content.\n    if response.status_code == 204:\n        return {}\n\n    if 200 <= response.status_code < 300:\n        if _content_type_from_response(response).endswith(('/json', '+json')):\n            try:\n                return response.json()\n            except ValueError as exc:\n                raise APIError(exc.args[0])\n\n    if response.status_code in (400, 404):\n        raise InvalidRequestError(response.content)\n\n    # Not json or unknown status code.\n    raise APIError(response.content)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the state of Home Mode", "response": "def home_mode_set_state(self, state, **kwargs):\n        \"\"\"Set the state of Home Mode\"\"\"\n\n        # It appears that surveillance station needs lowercase text\n        # true/false for the on switch\n        if state not in (HOME_MODE_ON, HOME_MODE_OFF):\n            raise ValueError('Invalid home mode state')\n\n        api = self._api_info['home_mode']\n        payload = dict({\n            'api': api['name'],\n            'method': 'Switch',\n            'version': api['version'],\n            'on': state,\n            '_sid': self._sid,\n        }, **kwargs)\n        response = self._get_json_with_retry(api['url'], payload)\n\n        if response['success']:\n            return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef home_mode_status(self, **kwargs):\n        api = self._api_info['home_mode']\n        payload = dict({\n            'api': api['name'],\n            'method': 'GetInfo',\n            'version': api['version'],\n            '_sid': self._sid\n        }, **kwargs)\n        response = self._get_json_with_retry(api['url'], payload)\n\n        return response['data']['on']", "response": "Returns the status of Home Mode"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of cameras.", "response": "def camera_list(self, **kwargs):\n        \"\"\"Return a list of cameras.\"\"\"\n        api = self._api_info['camera']\n        payload = dict({\n            '_sid': self._sid,\n            'api': api['name'],\n            'method': 'List',\n            'version': api['version'],\n        }, **kwargs)\n        response = self._get_json_with_retry(api['url'], payload)\n\n        cameras = []\n\n        for data in response['data']['cameras']:\n            cameras.append(Camera(data, self._video_stream_url))\n\n        return cameras"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef camera_info(self, camera_ids, **kwargs):\n        api = self._api_info['camera']\n        payload = dict({\n            '_sid': self._sid,\n            'api': api['name'],\n            'method': 'GetInfo',\n            'version': api['version'],\n            'cameraIds': ', '.join(str(id) for id in camera_ids),\n        }, **kwargs)\n        response = self._get_json_with_retry(api['url'], payload)\n\n        cameras = []\n\n        for data in response['data']['cameras']:\n            cameras.append(Camera(data, self._video_stream_url))\n\n        return cameras", "response": "Return a list of cameras matching camera_ids."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn bytes of camera image.", "response": "def camera_snapshot(self, camera_id, **kwargs):\n        \"\"\"Return bytes of camera image.\"\"\"\n        api = self._api_info['camera']\n        payload = dict({\n            '_sid': self._sid,\n            'api': api['name'],\n            'method': 'GetSnapshot',\n            'version': api['version'],\n            'cameraId': camera_id,\n        }, **kwargs)\n        response = self._get(api['url'], payload)\n\n        return response.content"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef camera_event_motion_enum(self, camera_id, **kwargs):\n        api = self._api_info['camera_event']\n        payload = dict({\n            '_sid': self._sid,\n            'api': api['name'],\n            'method': 'MotionEnum',\n            'version': api['version'],\n            'camId': camera_id,\n        }, **kwargs)\n        response = self._get_json_with_retry(api['url'], payload)\n\n        return MotionSetting(camera_id, response['data']['MDParam'])", "response": "Return motion settings matching camera_id."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate motion settings matching camera_id with keyword args.", "response": "def camera_event_md_param_save(self, camera_id, **kwargs):\n        \"\"\"Update motion settings matching camera_id with keyword args.\"\"\"\n        api = self._api_info['camera_event']\n        payload = dict({\n            '_sid': self._sid,\n            'api': api['name'],\n            'method': 'MDParamSave',\n            'version': api['version'],\n            'camId': camera_id,\n        }, **kwargs)\n        response = self._get_json_with_retry(api['url'], payload)\n\n        return response['data']['camId']"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update(self):\n        cameras = self._api.camera_list()\n        self._cameras_by_id = {v.camera_id: v for i, v in enumerate(cameras)}\n\n        motion_settings = []\n        for camera_id in self._cameras_by_id.keys():\n            motion_setting = self._api.camera_event_motion_enum(camera_id)\n            motion_settings.append(motion_setting)\n\n        self._motion_settings_by_id = {\n            v.camera_id: v for i, v in enumerate(motion_settings)}", "response": "Update cameras and motion settings with latest from API."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the state of Home Mode", "response": "def set_home_mode(self, state):\n        \"\"\"Set the state of Home Mode\"\"\"\n        state_parameter = HOME_MODE_OFF\n        if state:\n            state_parameter = HOME_MODE_ON\n        return self._api.home_mode_set_state(state_parameter)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreplaces the extension of a file path with a new one.", "response": "def replace_ext(file_path, new_ext):\n    \"\"\"\n    >>> replace_ext('one/two/three.four.doc', '.html')\n    'one/two/three.four.html'\n    >>> replace_ext('one/two/three.four.DOC', '.html')\n    'one/two/three.four.html'\n    >>> replace_ext('one/two/three.four.DOC', 'html')\n    'one/two/three.four.html'\n    \"\"\"\n    if not new_ext.startswith(os.extsep):\n        new_ext = os.extsep + new_ext\n    index = file_path.rfind(os.extsep)\n    return file_path[:index] + new_ext"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndetermining if a list item is the last list item for a given list item.", "response": "def is_last_li(li, meta_data, current_numId):\n    \"\"\"\n    Determine if ``li`` is the last list item for a given list\n    \"\"\"\n    if not is_li(li, meta_data):\n        return False\n    w_namespace = get_namespace(li, 'w')\n    next_el = li\n    while True:\n        # If we run out of element this must be the last list item\n        if next_el is None:\n            return True\n\n        next_el = next_el.getnext()\n        # Ignore elements that are not a list item\n        if not is_li(next_el, meta_data):\n            continue\n\n        new_numId = get_numId(next_el, w_namespace)\n        if current_numId != new_numId:\n            return True\n        # If we have gotten here then we have found another list item in the\n        # current list, so ``li`` is not the last li in the list.\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nyielding all the data that is in a single list node.", "response": "def get_single_list_nodes_data(li, meta_data):\n    \"\"\"\n    Find consecutive li tags that have content that have the same list id.\n    \"\"\"\n    yield li\n    w_namespace = get_namespace(li, 'w')\n    current_numId = get_numId(li, w_namespace)\n    starting_ilvl = get_ilvl(li, w_namespace)\n    el = li\n    while True:\n        el = el.getnext()\n        if el is None:\n            break\n        # If the tag has no content ignore it.\n        if not has_text(el):\n            continue\n\n        # Stop the lists if you come across a list item that should be a\n        # heading.\n        if _is_top_level_upper_roman(el, meta_data):\n            break\n\n        if (\n                is_li(el, meta_data) and\n                (starting_ilvl > get_ilvl(el, w_namespace))):\n            break\n\n        new_numId = get_numId(el, w_namespace)\n        if new_numId is None or new_numId == -1:\n            # Not a p tag or a list item\n            yield el\n            continue\n        # If the list id of the next tag is different that the previous that\n        # means a new list being made (not nested)\n        if current_numId != new_numId:\n            # Not a subsequent list.\n            break\n        if is_last_li(el, meta_data, current_numId):\n            yield el\n            break\n        yield el"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the ilvl of a li tag in the given namespace", "response": "def get_ilvl(li, w_namespace):\n    \"\"\"\n    The ilvl on an li tag tells the li tag at what level of indentation this\n    tag is at. This is used to determine if the li tag needs to be nested or\n    not.\n    \"\"\"\n    ilvls = li.xpath('.//w:ilvl', namespaces=li.nsmap)\n    if len(ilvls) == 0:\n        return -1\n    return int(ilvls[0].get('%sval' % w_namespace))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the numId of a list item.", "response": "def get_numId(li, w_namespace):\n    \"\"\"\n    The numId on an li tag maps to the numbering dictionary along side the ilvl\n    to determine what the list should look like (unordered, digits, lower\n    alpha, etc)\n    \"\"\"\n    numIds = li.xpath('.//w:numId', namespaces=li.nsmap)\n    if len(numIds) == 0:\n        return -1\n    return numIds[0].get('%sval' % w_namespace)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_list(list_type):\n    list_types = {\n        'bullet': 'ul',\n    }\n    el = etree.Element(list_types.get(list_type, 'ol'))\n    # These are the supported list style types and their conversion to css.\n    list_type_conversions = {\n        'decimal': DEFAULT_LIST_NUMBERING_STYLE,\n        'decimalZero': 'decimal-leading-zero',\n        'upperRoman': 'upper-roman',\n        'lowerRoman': 'lower-roman',\n        'upperLetter': 'upper-alpha',\n        'lowerLetter': 'lower-alpha',\n        'ordinal': DEFAULT_LIST_NUMBERING_STYLE,\n        'cardinalText': DEFAULT_LIST_NUMBERING_STYLE,\n        'ordinalText': DEFAULT_LIST_NUMBERING_STYLE,\n    }\n    if list_type != 'bullet':\n        el.set(\n            'data-list-type',\n            list_type_conversions.get(list_type, DEFAULT_LIST_NUMBERING_STYLE),\n        )\n    return el", "response": "Create a list object based on the passed in list_type."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the vMerge element of the tc element.", "response": "def get_v_merge(tc):\n    \"\"\"\n    vMerge is what docx uses to denote that a table cell is part of a rowspan.\n    The first cell to have a vMerge is the start of the rowspan, and the vMerge\n    will be denoted with 'restart'. If it is anything other than restart then\n    it is a continuation of another rowspan.\n    \"\"\"\n    if tc is None:\n        return None\n    v_merges = tc.xpath('.//w:vMerge', namespaces=tc.nsmap)\n    if len(v_merges) != 1:\n        return None\n    v_merge = v_merges[0]\n    return v_merge"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_grid_span(tc):\n    w_namespace = get_namespace(tc, 'w')\n    grid_spans = tc.xpath('.//w:gridSpan', namespaces=tc.nsmap)\n    if len(grid_spans) != 1:\n        return 1\n    grid_span = grid_spans[0]\n    return int(grid_span.get('%sval' % w_namespace))", "response": "Get the number of rows in a table cell."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns True if the style is not set to false.", "response": "def style_is_false(style):\n    \"\"\"\n    For bold, italics and underline. Simply checking to see if the various tags\n    are present will not suffice. If the tag is present and set to False then\n    the style should not be present.\n    \"\"\"\n    if style is None:\n        return False\n    w_namespace = get_namespace(style, 'w')\n    return style.get('%sval' % w_namespace) != 'false'"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning True if the tag passed in is considered bold.", "response": "def is_bold(r):\n    \"\"\"\n    The function will return True if the r tag passed in is considered bold.\n    \"\"\"\n    w_namespace = get_namespace(r, 'w')\n    rpr = r.find('%srPr' % w_namespace)\n    if rpr is None:\n        return False\n    bold = rpr.find('%sb' % w_namespace)\n    return style_is_false(bold)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_italics(r):\n    w_namespace = get_namespace(r, 'w')\n    rpr = r.find('%srPr' % w_namespace)\n    if rpr is None:\n        return False\n    italics = rpr.find('%si' % w_namespace)\n    return style_is_false(italics)", "response": "Returns True if the tag passed in is considered\n    italicized."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_underlined(r):\n    w_namespace = get_namespace(r, 'w')\n    rpr = r.find('%srPr' % w_namespace)\n    if rpr is None:\n        return False\n    underline = rpr.find('%su' % w_namespace)\n    return style_is_false(underline)", "response": "Returns True if the tag passed in is considered\n    underlined."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn True if the passed in p tag is considered a title.", "response": "def is_title(p):\n    \"\"\"\n    Certain p tags are denoted as ``Title`` tags. This function will return\n    True if the passed in p tag is considered a title.\n    \"\"\"\n    w_namespace = get_namespace(p, 'w')\n    styles = p.xpath('.//w:pStyle', namespaces=p.nsmap)\n    if len(styles) == 0:\n        return False\n    style = styles[0]\n    return style.get('%sval' % w_namespace) == 'Title'"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the text run content data.", "response": "def get_text_run_content_data(r):\n    \"\"\"\n    It turns out that r tags can contain both t tags and drawing tags. Since we\n    need both, this function will return them in the order in which they are\n    found.\n    \"\"\"\n    w_namespace = get_namespace(r, 'w')\n    valid_elements = (\n        '%st' % w_namespace,\n        '%sdrawing' % w_namespace,\n        '%spict' % w_namespace,\n        '%sbr' % w_namespace,\n    )\n    for el in r:\n        if el.tag in valid_elements:\n            yield el"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck to see if the whole line is bold or italics. Returns a tuple of boolean 1 if the whole line is bold False otherwise.", "response": "def whole_line_styled(p):\n    \"\"\"\n    Checks to see if the whole p tag will end up being bold or italics. Returns\n    a tuple (boolean, boolean). The first boolean will be True if the whole\n    line is bold, False otherwise. The second boolean will be True if the whole\n    line is italics, False otherwise.\n    \"\"\"\n    r_tags = p.xpath('.//w:r', namespaces=p.nsmap)\n    tags_are_bold = [\n        is_bold(r) or is_underlined(r) for r in r_tags\n    ]\n    tags_are_italics = [\n        is_italics(r) for r in r_tags\n    ]\n    return all(tags_are_bold), all(tags_are_italics)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_numbering_info(tree):\n    if tree is None:\n        return {}\n    w_namespace = get_namespace(tree, 'w')\n    num_ids = {}\n    result = defaultdict(dict)\n    # First find all the list types\n    for list_type in tree.findall('%snum' % w_namespace):\n        list_id = list_type.get('%snumId' % w_namespace)\n\n        # Each list type is assigned an abstractNumber that defines how lists\n        # should look.\n        abstract_number = list_type.find('%sabstractNumId' % w_namespace)\n        num_ids[abstract_number.get('%sval' % w_namespace)] = list_id\n\n    # Loop through all the abstractNumbers\n    for abstract_number in tree.findall('%sabstractNum' % w_namespace):\n        abstract_num_id = abstract_number.get('%sabstractNumId' % w_namespace)\n        # If we find an abstractNumber that is not being used in the document\n        # then ignore it.\n        if abstract_num_id not in num_ids:\n            continue\n\n        # Get the level of the abstract number.\n        for lvl in abstract_number.findall('%slvl' % w_namespace):\n            ilvl = int(lvl.get('%silvl' % w_namespace))\n            lvl_format = lvl.find('%snumFmt' % w_namespace)\n            list_style = lvl_format.get('%sval' % w_namespace)\n            # Based on the list type and the ilvl (indentation level) store the\n            # needed style.\n            result[num_ids[abstract_num_id]][ilvl] = list_style\n    return result", "response": "Get the numbering info for a tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_style_dict(tree):\n    # This is a partial document and actual h1 is the document title, which\n    # will be displayed elsewhere.\n    headers = {\n        'heading 1': 'h2',\n        'heading 2': 'h3',\n        'heading 3': 'h4',\n        'heading 4': 'h5',\n        'heading 5': 'h6',\n        'heading 6': 'h6',\n        'heading 7': 'h6',\n        'heading 8': 'h6',\n        'heading 9': 'h6',\n        'heading 10': 'h6',\n    }\n    if tree is None:\n        return {}\n    w_namespace = get_namespace(tree, 'w')\n    result = {}\n    for el in tree:\n        style_id = el.get('%sstyleId' % w_namespace)\n        el_result = {\n            'header': False,\n            'font_size': None,\n            'based_on': None,\n        }\n        # Get the header info\n        name = el.find('%sname' % w_namespace)\n        if name is None:\n            continue\n        value = name.get('%sval' % w_namespace).lower()\n        if value in headers:\n            el_result['header'] = headers[value]\n\n        # Get the size info.\n        rpr = el.find('%srPr' % w_namespace)\n        if rpr is None:\n            continue\n        size = rpr.find('%ssz' % w_namespace)\n        if size is None:\n            el_result['font_size'] = None\n        else:\n            el_result['font_size'] = size.get('%sval' % w_namespace)\n\n        # Get based on info.\n        based_on = el.find('%sbasedOn' % w_namespace)\n        if based_on is None:\n            el_result['based_on'] = None\n        else:\n            el_result['based_on'] = based_on.get('%sval' % w_namespace)\n        result[style_id] = el_result\n    return result", "response": "Get the style of the tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_relationship_info(tree, media, image_sizes):\n    if tree is None:\n        return {}\n    result = {}\n    # Loop through each relationship.\n    for el in tree.iter():\n        el_id = el.get('Id')\n        if el_id is None:\n            continue\n        # Store the target in the result dict.\n        target = el.get('Target')\n        if any(\n                target.lower().endswith(ext) for\n                ext in IMAGE_EXTENSIONS_TO_SKIP):\n            continue\n        if target in media:\n            image_size = image_sizes.get(el_id)\n            target = convert_image(media[target], image_size)\n        # cgi will replace things like & < > with &amp; &lt; &gt;\n        result[el_id] = cgi.escape(target)\n\n    return result", "response": "Get the relationship info for a tree."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_document_data(f, image_handler=None):\n    '''\n    ``f`` is a ``ZipFile`` that is open\n    Extract out the document data, numbering data and the relationship data.\n    '''\n    if image_handler is None:\n        def image_handler(image_id, relationship_dict):\n            return relationship_dict.get(image_id)\n\n    document_xml = None\n    numbering_xml = None\n    relationship_xml = None\n    styles_xml = None\n    parser = etree.XMLParser(strip_cdata=False)\n    path, _ = os.path.split(f.filename)\n    media = {}\n    image_sizes = {}\n    # Loop through the files in the zip file.\n    for item in f.infolist():\n        # This file holds all the content of the document.\n        if item.filename == 'word/document.xml':\n            xml = f.read(item.filename)\n            document_xml = etree.fromstring(xml, parser)\n        # This file tells document.xml how lists should look.\n        elif item.filename == 'word/numbering.xml':\n            xml = f.read(item.filename)\n            numbering_xml = etree.fromstring(xml, parser)\n        elif item.filename == 'word/styles.xml':\n            xml = f.read(item.filename)\n            styles_xml = etree.fromstring(xml, parser)\n        # This file holds the targets for hyperlinks and images.\n        elif item.filename == 'word/_rels/document.xml.rels':\n            xml = f.read(item.filename)\n            try:\n                relationship_xml = etree.fromstring(xml, parser)\n            except XMLSyntaxError:\n                relationship_xml = etree.fromstring('<xml></xml>', parser)\n        if item.filename.startswith('word/media/'):\n            # Strip off the leading word/\n            media[item.filename[len('word/'):]] = f.extract(\n                item.filename,\n                path,\n            )\n    # Close the file pointer.\n    f.close()\n\n    # Get dictionaries for the numbering and the relationships.\n    numbering_dict = get_numbering_info(numbering_xml)\n    image_sizes = get_image_sizes(document_xml)\n    relationship_dict = get_relationship_info(\n        relationship_xml,\n        media,\n        image_sizes\n    )\n    styles_dict = get_style_dict(styles_xml)\n    font_sizes_dict = defaultdict(int)\n    if DETECT_FONT_SIZE:\n        font_sizes_dict = get_font_sizes_dict(document_xml, styles_dict)\n    meta_data = MetaData(\n        numbering_dict=numbering_dict,\n        relationship_dict=relationship_dict,\n        styles_dict=styles_dict,\n        font_sizes_dict=font_sizes_dict,\n        image_handler=image_handler,\n        image_sizes=image_sizes,\n    )\n    return document_xml, meta_data", "response": "Extract out the document data numbering data and relationship data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_ordered_list_type(meta_data, numId, ilvl):\n\n    # Early return if numId or ilvl are not valid\n    numbering_dict = meta_data.numbering_dict\n    if numId not in numbering_dict:\n        return DEFAULT_LIST_NUMBERING_STYLE\n    if ilvl not in numbering_dict[numId]:\n        return DEFAULT_LIST_NUMBERING_STYLE\n    return meta_data.numbering_dict[numId][ilvl]", "response": "Return the list type for the given numId and ilvl"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbuilding the list structure and returns the root list.", "response": "def build_list(li_nodes, meta_data):\n    \"\"\"\n    Build the list structure and return the root list\n    \"\"\"\n    # Need to keep track of all incomplete nested lists.\n    ol_dict = {}\n\n    # Need to keep track of the current indentation level.\n    current_ilvl = -1\n\n    # Need to keep track of the current list id.\n    current_numId = -1\n\n    # Need to keep track of list that new li tags should be added too.\n    current_ol = None\n\n    # Store the first list created (the root list) for the return value.\n    root_ol = None\n    visited_nodes = []\n    list_contents = []\n\n    def _build_li(list_contents):\n        data = '<br />'.join(t for t in list_contents if t is not None)\n        return etree.XML('<li>%s</li>' % data)\n\n    def _build_non_li_content(el, meta_data):\n        w_namespace = get_namespace(el, 'w')\n        if el.tag == '%stbl' % w_namespace:\n            new_el, visited_nodes = build_table(el, meta_data)\n            return etree.tostring(new_el), visited_nodes\n        elif el.tag == '%sp' % w_namespace:\n            return get_element_content(el, meta_data), [el]\n        if has_text(el):\n            raise UnintendedTag('Did not expect %s' % el.tag)\n\n    def _merge_lists(ilvl, current_ilvl, ol_dict, current_ol):\n        for i in reversed(range(ilvl, current_ilvl)):\n            # Any list that is more indented that ilvl needs to\n            # be merged to the list before it.\n            if i not in ol_dict:\n                continue\n            if ol_dict[i] is not current_ol:\n                if ol_dict[i] is current_ol:\n                    continue\n                ol_dict[i][-1].append(current_ol)\n                current_ol = ol_dict[i]\n\n        # Clean up finished nested lists.\n        for key in list(ol_dict):\n            if key > ilvl:\n                del ol_dict[key]\n        return current_ol\n\n    for li_node in li_nodes:\n        w_namespace = get_namespace(li_node, 'w')\n        if not is_li(li_node, meta_data):\n            # Get the content and visited nodes\n            new_el, el_visited_nodes = _build_non_li_content(\n                li_node,\n                meta_data,\n            )\n            list_contents.append(new_el)\n            visited_nodes.extend(el_visited_nodes)\n            continue\n        if list_contents:\n            li_el = _build_li(list_contents)\n            list_contents = []\n            current_ol.append(li_el)\n        # Get the data needed to build the current list item\n        list_contents.append(get_element_content(\n            li_node,\n            meta_data,\n        ))\n        ilvl = get_ilvl(li_node, w_namespace)\n        numId = get_numId(li_node, w_namespace)\n        list_type = get_ordered_list_type(meta_data, numId, ilvl)\n\n        # If the ilvl is greater than the current_ilvl or the list id is\n        # changing then we have the first li tag in a nested list. We need to\n        # create a new list object and update all of our variables for keeping\n        # track.\n        if (ilvl > current_ilvl) or (numId != current_numId):\n            # Only create a new list\n            ol_dict[ilvl] = create_list(list_type)\n            current_ol = ol_dict[ilvl]\n            current_ilvl = ilvl\n            current_numId = numId\n        # Both cases above are not True then we need to close all lists greater\n        # than ilvl and then remove them from the ol_dict\n        else:\n            # Merge any nested lists that need to be merged.\n            current_ol = _merge_lists(\n                ilvl=ilvl,\n                current_ilvl=current_ilvl,\n                ol_dict=ol_dict,\n                current_ol=current_ol,\n            )\n\n        # Set the root list after the first list is created.\n        if root_ol is None:\n            root_ol = current_ol\n\n        # Set the current list.\n        if ilvl in ol_dict:\n            current_ol = ol_dict[ilvl]\n        else:\n            # In some instances the ilvl is not in the ol_dict, if that is the\n            # case, create it here (not sure how this happens but it has\n            # before.) Only do this if the current_ol is not the root_ol,\n            # otherwise etree will crash.\n\n            if current_ol is not root_ol:\n\n                # Merge the current_ol into the root_ol. _merge_lists is not\n                # equipped to handle this situation since the only way to get\n                # into this block of code is to have mangled ilvls.\n                root_ol[-1].append(current_ol)\n\n                # Reset the current_ol\n                current_ol = create_list(list_type)\n\n        # Create the li element.\n        visited_nodes.extend(list(li_node.iter()))\n\n    # If a list item is the last thing in a document, then you will need to add\n    # it here. Should probably figure out how to get the above logic to deal\n    # with it.\n    if list_contents:\n        li_el = _build_li(list_contents)\n        list_contents = []\n        current_ol.append(li_el)\n\n    # Merge up any nested lists that have not been merged.\n    current_ol = _merge_lists(\n        ilvl=0,\n        current_ilvl=current_ilvl,\n        ol_dict=ol_dict,\n        current_ol=current_ol,\n    )\n\n    return root_ol, visited_nodes"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nbuilding a single tr element.", "response": "def build_tr(tr, meta_data, row_spans):\n    \"\"\"\n    This will return a single tr element, with all tds already populated.\n    \"\"\"\n\n    # Create a blank tr element.\n    tr_el = etree.Element('tr')\n    w_namespace = get_namespace(tr, 'w')\n    visited_nodes = []\n    for el in tr:\n        if el in visited_nodes:\n            continue\n        visited_nodes.append(el)\n        # Find the table cells.\n        if el.tag == '%stc' % w_namespace:\n            v_merge = get_v_merge(el)\n            # If there is a v_merge and it is not restart then this cell can be\n            # ignored.\n            if (\n                    v_merge is not None and\n                    v_merge.get('%sval' % w_namespace) != 'restart'):\n                continue\n\n            # Loop through each and build a list of all the content.\n            texts = []\n            for td_content in el:\n                # Since we are doing look-a-heads in this loop we need to check\n                # again to see if we have already visited the node.\n                if td_content in visited_nodes:\n                    continue\n\n                # Check to see if it is a list or a regular paragraph.\n                if is_li(td_content, meta_data):\n                    # If it is a list, create the list and update\n                    # visited_nodes.\n                    li_nodes = get_single_list_nodes_data(\n                        td_content,\n                        meta_data,\n                    )\n                    list_el, list_visited_nodes = build_list(\n                        li_nodes,\n                        meta_data,\n                    )\n                    visited_nodes.extend(list_visited_nodes)\n                    texts.append(etree.tostring(list_el))\n                elif td_content.tag == '%stbl' % w_namespace:\n                    table_el, table_visited_nodes = build_table(\n                        td_content,\n                        meta_data,\n                    )\n                    visited_nodes.extend(table_visited_nodes)\n                    texts.append(etree.tostring(table_el))\n                elif td_content.tag == '%stcPr' % w_namespace:\n                    # Do nothing\n                    visited_nodes.append(td_content)\n                    continue\n                else:\n                    text = get_element_content(\n                        td_content,\n                        meta_data,\n                        is_td=True,\n                    )\n                    texts.append(text)\n\n            data = '<br />'.join(t for t in texts if t is not None)\n            td_el = etree.XML('<td>%s</td>' % data)\n            # if there is a colspan then set it here.\n            colspan = get_grid_span(el)\n            if colspan > 1:\n                td_el.set('colspan', '%d' % colspan)\n            v_merge = get_v_merge(el)\n\n            # If this td has a v_merge and it is restart then set the rowspan\n            # here.\n            if (\n                    v_merge is not None and\n                    v_merge.get('%sval' % w_namespace) == 'restart'):\n                rowspan = next(row_spans)\n                td_el.set('rowspan', '%d' % rowspan)\n\n            tr_el.append(td_el)\n    return tr_el"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef build_table(table, meta_data):\n\n    # Create a blank table element.\n    table_el = etree.Element('table')\n    w_namespace = get_namespace(table, 'w')\n\n    # Get the rowspan values for cells that have a rowspan.\n    row_spans = get_rowspan_data(table)\n    for el in table:\n        if el.tag == '%str' % w_namespace:\n            # Create the tr element.\n            tr_el = build_tr(\n                el,\n                meta_data,\n                row_spans,\n            )\n            # And append it to the table.\n            table_el.append(tr_el)\n\n    visited_nodes = list(table.iter())\n    return table_el, visited_nodes", "response": "This returns a table object with all rows and cells correctly populated."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate the string data that for this particular t tag.", "response": "def get_t_tag_content(\n        t, parent, remove_bold, remove_italics, meta_data):\n    \"\"\"\n    Generate the string data that for this particular t tag.\n    \"\"\"\n    if t is None or t.text is None:\n        return ''\n\n    # Need to escape the text so that we do not accidentally put in text\n    # that is not valid XML.\n    # cgi will replace things like & < > with &amp; &lt; &gt;\n    text = cgi.escape(t.text)\n\n    # Wrap the text with any modifiers it might have (bold, italics or\n    # underline)\n    el_is_bold = not remove_bold and (\n        is_bold(parent) or\n        is_underlined(parent)\n    )\n    el_is_italics = not remove_italics and is_italics(parent)\n    if el_is_bold:\n        text = '<strong>%s</strong>' % text\n    if el_is_italics:\n        text = '<em>%s</em>' % text\n    return text"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves all tags with the given tag name from the tree.", "response": "def _strip_tag(tree, tag):\n    \"\"\"\n    Remove all tags that have the tag name ``tag``\n    \"\"\"\n    for el in tree.iter():\n        if el.tag == tag:\n            el.getparent().remove(el)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts a file to html.", "response": "def convert(file_path, image_handler=None, fall_back=None, converter=None):\n    \"\"\"\n    ``file_path`` is a path to the file on the file system that you want to be\n        converted to html.\n    ``image_handler`` is a function that takes an image_id and a\n        relationship_dict to generate the src attribute for images. (see readme\n        for more details)\n    ``fall_back`` is a function that takes a ``file_path``. This function will\n        only be called if for whatever reason the conversion fails.\n    ``converter`` is a function to convert a document that is not docx to docx\n        (examples in docx2html.converters)\n\n    Returns html extracted from ``file_path``\n    \"\"\"\n    file_base, extension = os.path.splitext(os.path.basename(file_path))\n\n    if extension == '.html' or extension == '.htm':\n        return read_html_file(file_path)\n\n    # Create the converted file as a file in the same dir with the\n    # same name only with a .docx extension\n    docx_path = replace_ext(file_path, '.docx')\n    if extension == '.docx':\n        # If the file is already html, just leave it in place.\n        docx_path = file_path\n    else:\n        if converter is None:\n            raise FileNotDocx('The file passed in is not a docx.')\n        converter(docx_path, file_path)\n        if not os.path.isfile(docx_path):\n            if fall_back is None:\n                raise ConversionFailed('Conversion to docx failed.')\n            else:\n                return fall_back(file_path)\n\n    try:\n        # Docx files are actually just zip files.\n        zf = get_zip_file_handler(docx_path)\n    except BadZipfile:\n        raise MalformedDocx('This file is not a docx')\n\n    # Need to populate the xml based on word/document.xml\n    tree, meta_data = _get_document_data(zf, image_handler)\n    return create_html(tree, meta_data)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find(dataset, url):\n    '''Find the location of a dataset on disk, downloading if needed.'''\n    fn = os.path.join(DATASETS, dataset)\n    dn = os.path.dirname(fn)\n    if not os.path.exists(dn):\n        print('creating dataset directory: %s', dn)\n        os.makedirs(dn)\n    if not os.path.exists(fn):\n        if sys.version_info < (3, ):\n            urllib.urlretrieve(url, fn)\n        else:\n            urllib.request.urlretrieve(url, fn)\n    return fn", "response": "Find the location of a dataset on disk downloading if needed."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload the MNIST digits dataset.", "response": "def load_mnist(flatten=True, labels=False):\n    '''Load the MNIST digits dataset.'''\n    fn = find('mnist.pkl.gz', 'http://deeplearning.net/data/mnist/mnist.pkl.gz')\n    h = gzip.open(fn, 'rb')\n    if sys.version_info < (3, ):\n        (timg, tlab), (vimg, vlab), (simg, slab) = pickle.load(h)\n    else:\n        (timg, tlab), (vimg, vlab), (simg, slab) = pickle.load(h, encoding='bytes')\n    h.close()\n    if not flatten:\n        timg = timg.reshape((-1, 28, 28, 1))\n        vimg = vimg.reshape((-1, 28, 28, 1))\n        simg = simg.reshape((-1, 28, 28, 1))\n    if labels:\n        return ((timg, tlab.astype('i')),\n                (vimg, vlab.astype('i')),\n                (simg, slab.astype('i')))\n    return (timg, ), (vimg, ), (simg, )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load_cifar(flatten=True, labels=False):\n    '''Load the CIFAR10 image dataset.'''\n    def extract(name):\n        print('extracting data from {}'.format(name))\n        h = tar.extractfile(name)\n        if sys.version_info < (3, ):\n            d = pickle.load(h)\n        else:\n            d = pickle.load(h, encoding='bytes')\n            for k in list(d):\n                d[k.decode('utf8')] = d[k]\n        h.close()\n        img = d['data'].reshape(\n            (-1, 3, 32, 32)).transpose((0, 2, 3, 1)).astype('f') / 128 - 1\n        if flatten:\n            img = img.reshape((-1, 32 * 32 * 3))\n        d['data'] = img\n        return d\n\n    fn = find('cifar10.tar.gz', 'http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz')\n    tar = tarfile.open(fn)\n\n    imgs = []\n    labs = []\n    for i in range(1, 6):\n        d = extract('cifar-10-batches-py/data_batch_{}'.format(i))\n        imgs.extend(d['data'])\n        labs.extend(d['labels'])\n    timg = np.asarray(imgs[:40000])\n    tlab = np.asarray(labs[:40000], 'i')\n    vimg = np.asarray(imgs[40000:])\n    vlab = np.asarray(labs[40000:], 'i')\n\n    d = extract('cifar-10-batches-py/test_batch')\n    simg = d['data']\n    slab = d['labels']\n\n    tar.close()\n\n    if labels:\n        return (timg, tlab), (vimg, vlab), (simg, slab)\n    return (timg, ), (vimg, ), (simg, )", "response": "Load the CIFAR10 image dataset."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef plot_images(imgs, loc, title=None, channels=1):\n    '''Plot an array of images.\n\n    We assume that we are given a matrix of data whose shape is (n*n, s*s*c) --\n    that is, there are n^2 images along the first axis of the array, and each\n    image is c squares measuring s pixels on a side. Each row of the input will\n    be plotted as a sub-region within a single image array containing an n x n\n    grid of images.\n    '''\n    n = int(np.sqrt(len(imgs)))\n    assert n * n == len(imgs), 'images array must contain a square number of rows!'\n    s = int(np.sqrt(len(imgs[0]) / channels))\n    assert s * s == len(imgs[0]) / channels, 'images must be square!'\n\n    img = np.zeros(((s+1) * n - 1, (s+1) * n - 1, channels), dtype=imgs[0].dtype)\n    for i, pix in enumerate(imgs):\n        r, c = divmod(i, n)\n        img[r * (s+1):(r+1) * (s+1) - 1,\n            c * (s+1):(c+1) * (s+1) - 1] = pix.reshape((s, s, channels))\n\n    img -= img.min()\n    img /= img.max()\n\n    ax = plt.gcf().add_subplot(loc)\n    ax.xaxis.set_visible(False)\n    ax.yaxis.set_visible(False)\n    ax.set_frame_on(False)\n    ax.imshow(img.squeeze(), cmap=plt.cm.gray)\n    if title:\n        ax.set_title(title)", "response": "Plot an array of images."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef plot_layers(weights, tied_weights=False, channels=1):\n    '''Create a plot of weights, visualized as \"bottom-level\" pixel arrays.'''\n    if hasattr(weights[0], 'get_value'):\n        weights = [w.get_value() for w in weights]\n    k = min(len(weights), 9)\n    imgs = np.eye(weights[0].shape[0])\n    for i, weight in enumerate(weights[:-1]):\n        imgs = np.dot(weight.T, imgs)\n        plot_images(imgs,\n                    100 + 10 * k + i + 1,\n                    channels=channels,\n                    title='Layer {}'.format(i+1))\n    weight = weights[-1]\n    n = weight.shape[1] / channels\n    if int(np.sqrt(n)) ** 2 != n:\n        return\n    if tied_weights:\n        imgs = np.dot(weight.T, imgs)\n        plot_images(imgs,\n                    100 + 10 * k + k,\n                    channels=channels,\n                    title='Layer {}'.format(k))\n    else:\n        plot_images(weight,\n                    100 + 10 * k + k,\n                    channels=channels,\n                    title='Decoding weights')", "response": "Create a plot of weights visualized as bottom - level pixel arrays."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef plot_filters(filters):\n    '''Create a plot of conv filters, visualized as pixel arrays.'''\n    imgs = filters.get_value()\n\n    N, channels, x, y = imgs.shape\n    n = int(np.sqrt(N))\n    assert n * n == N, 'filters must contain a square number of rows!'\n    assert channels == 1 or channels == 3, 'can only plot grayscale or rgb filters!'\n\n    img = np.zeros(((y+1) * n - 1, (x+1) * n - 1, channels), dtype=imgs[0].dtype)\n    for i, pix in enumerate(imgs):\n        r, c = divmod(i, n)\n        img[r * (y+1):(r+1) * (y+1) - 1,\n            c * (x+1):(c+1) * (x+1) - 1] = pix.transpose((1, 2, 0))\n\n    img -= img.min()\n    img /= img.max()\n\n    ax = plt.gcf().add_subplot(111)\n    ax.xaxis.set_visible(False)\n    ax.yaxis.set_visible(False)\n    ax.set_frame_on(False)\n    ax.imshow(img.squeeze(), cmap=plt.cm.gray)", "response": "Create a plot of conv filters visualized as pixel arrays."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a callable that generates samples from a dataset in batches of size batch_size.", "response": "def batches(arrays, steps=100, batch_size=64, rng=None):\n    '''Create a callable that generates samples from a dataset.\n\n    Parameters\n    ----------\n    arrays : list of ndarray (time-steps, data-dimensions)\n        Arrays of data. Rows in these arrays are assumed to correspond to time\n        steps, and columns to variables. Multiple arrays can be given; in such\n        a case, these arrays usually correspond to [input, output]---for\n        example, for a recurrent regression problem---or [input, output,\n        weights]---for a weighted regression or classification problem.\n    steps : int, optional\n        Generate samples of this many time steps. Defaults to 100.\n    batch_size : int, optional\n        Generate this many samples per call. Defaults to 64. This must match the\n        batch_size parameter that was used when creating the recurrent network\n        that will process the data.\n    rng : :class:`numpy.random.RandomState` or int, optional\n        A random number generator, or an integer seed for a random number\n        generator. If not provided, the random number generator will be created\n        with an automatically chosen seed.\n\n    Returns\n    -------\n    callable :\n        A callable that can be used inside a dataset for training a recurrent\n        network.\n    '''\n    assert batch_size >= 2, 'batch_size must be at least 2!'\n    assert isinstance(arrays, (tuple, list)), 'arrays must be a tuple or list!'\n\n    if rng is None or isinstance(rng, int):\n        rng = np.random.RandomState(rng)\n\n    def sample():\n        xs = [np.zeros((batch_size, steps, a.shape[1]), a.dtype) for a in arrays]\n        for i in range(batch_size):\n            j = rng.randint(len(arrays[0]) - steps)\n            for x, a in zip(xs, arrays):\n                x[i] = a[j:j+steps]\n        return xs\n\n    return sample"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef encode(self, txt):\n        '''Encode a text string by replacing characters with alphabet index.\n\n        Parameters\n        ----------\n        txt : str\n            A string to encode.\n\n        Returns\n        -------\n        classes : list of int\n            A sequence of alphabet index values corresponding to the given text.\n        '''\n        return list(self._fwd_index.get(c, 0) for c in txt)", "response": "Encode a text string by replacing characters with alphabet index."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a callable that returns a batch of training data.", "response": "def classifier_batches(self, steps, batch_size, rng=None):\n        '''Create a callable that returns a batch of training data.\n\n        Parameters\n        ----------\n        steps : int\n            Number of time steps in each batch.\n        batch_size : int\n            Number of training examples per batch.\n        rng : :class:`numpy.random.RandomState` or int, optional\n            A random number generator, or an integer seed for a random number\n            generator. If not provided, the random number generator will be\n            created with an automatically chosen seed.\n\n        Returns\n        -------\n        batch : callable\n            A callable that, when called, returns a batch of data that can be\n            used to train a classifier model.\n        '''\n        assert batch_size >= 2, 'batch_size must be at least 2!'\n\n        if rng is None or isinstance(rng, int):\n            rng = np.random.RandomState(rng)\n\n        T = np.arange(steps)\n\n        def batch():\n            inputs = np.zeros((batch_size, steps, 1 + len(self.alpha)), 'f')\n            outputs = np.zeros((batch_size, steps), 'i')\n            for b in range(batch_size):\n                offset = rng.randint(len(self.text) - steps - 1)\n                enc = self.encode(self.text[offset:offset + steps + 1])\n                inputs[b, T, enc[:-1]] = 1\n                outputs[b, T] = enc[1:]\n            return [inputs, outputs]\n\n        return batch"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndraws a sequential sample of class labels from this network.", "response": "def predict_sequence(self, labels, steps, streams=1, rng=None):\n        '''Draw a sequential sample of class labels from this network.\n\n        Parameters\n        ----------\n        labels : list of int\n            A list of integer class labels to get the classifier started.\n        steps : int\n            The number of time steps to sample.\n        streams : int, optional\n            Number of parallel streams to sample from the model. Defaults to 1.\n        rng : :class:`numpy.random.RandomState` or int, optional\n            A random number generator, or an integer seed for a random number\n            generator. If not provided, the random number generator will be\n            created with an automatically chosen seed.\n\n        Yields\n        ------\n        label(s) : int or list of int\n            Yields at each time step an integer class label sampled sequentially\n            from the model. If the number of requested streams is greater than\n            1, this will be a list containing the corresponding number of class\n            labels.\n        '''\n        if rng is None or isinstance(rng, int):\n            rng = np.random.RandomState(rng)\n        offset = len(labels)\n        batch = max(2, streams)\n        inputs = np.zeros((batch, offset + steps, self.layers[0].output_size), 'f')\n        inputs[:, np.arange(offset), labels] = 1\n        for i in range(offset, offset + steps):\n            chars = []\n            for pdf in self.predict_proba(inputs[:i])[:, -1]:\n                try:\n                    c = rng.multinomial(1, pdf).argmax(axis=-1)\n                except ValueError:\n                    # sometimes the pdf triggers a normalization error. just\n                    # choose greedily in this case.\n                    c = pdf.argmax(axis=-1)\n                chars.append(int(c))\n            inputs[np.arange(batch), i, chars] = 1\n            yield chars[0] if streams == 1 else chars"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_conv_weights(self, name, mean=0, std=None, sparsity=0):\n        '''Add a convolutional weight array to this layer's parameters.\n\n        Parameters\n        ----------\n        name : str\n            Name of the parameter to add.\n        mean : float, optional\n            Mean value for randomly-initialized weights. Defaults to 0.\n        std : float, optional\n            Standard deviation of initial matrix values. Defaults to\n            :math:`1 / sqrt(n_i + n_o)`.\n        sparsity : float, optional\n            Fraction of weights to set to zero. Defaults to 0.\n        '''\n        nin = self.input_size\n        nout = self.output_size\n        mean = self.kwargs.get(\n            'mean_{}'.format(name),\n            self.kwargs.get('mean', mean))\n        std = self.kwargs.get(\n            'std_{}'.format(name),\n            self.kwargs.get('std', std or 1 / np.sqrt(nin + nout)))\n        sparsity = self.kwargs.get(\n            'sparsity_{}'.format(name),\n            self.kwargs.get('sparsity', sparsity))\n        arr = np.zeros((nout, nin) + self.filter_size, util.FLOAT)\n        for r in range(self.filter_size[0]):\n            for c in range(self.filter_size[1]):\n                arr[:, :, r, c] = util.random_matrix(\n                    nout, nin, mean, std, sparsity=sparsity, rng=self.rng)\n        self._params.append(theano.shared(arr, name=self._fmt(name)))", "response": "Add a convolutional weight array to this layer s parameters."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef encode(self, x, layer=None, sample=False, **kwargs):\n        '''Encode a dataset using the hidden layer activations of our network.\n\n        Parameters\n        ----------\n        x : ndarray\n            A dataset to encode. Rows of this dataset capture individual data\n            points, while columns represent the variables in each data point.\n\n        layer : str, optional\n            The name of the hidden layer output to use. By default, we use\n            the \"middle\" hidden layer---for example, for a 4,2,4 or 4,3,2,3,4\n            autoencoder, we use the layer with size 2.\n\n        sample : bool, optional\n            If True, then draw a sample using the hidden activations as\n            independent Bernoulli probabilities for the encoded data. This\n            assumes the hidden layer has a logistic sigmoid activation function.\n\n        Returns\n        -------\n        ndarray :\n            The given dataset, encoded by the appropriate hidden layer\n            activation.\n        '''\n        enc = self.feed_forward(x, **kwargs)[self._find_output(layer)]\n        if sample:\n            return np.random.binomial(n=1, p=enc).astype(np.uint8)\n        return enc", "response": "Encode a dataset using the hidden layer activations of our network."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndecode an encoded dataset by computing the output layer activation.", "response": "def decode(self, z, layer=None, **kwargs):\n        '''Decode an encoded dataset by computing the output layer activation.\n\n        Parameters\n        ----------\n        z : ndarray\n            A matrix containing encoded data from this autoencoder.\n        layer : int or str or :class:`Layer <layers.Layer>`, optional\n            The index or name of the hidden layer that was used to encode `z`.\n\n        Returns\n        -------\n        decoded : ndarray\n            The decoded dataset.\n        '''\n        key = self._find_output(layer)\n        if key not in self._functions:\n            regs = regularizers.from_kwargs(self, **kwargs)\n            outputs, updates = self.build_graph(regs)\n            self._functions[key] = theano.function(\n                [outputs[key]],\n                [outputs[self.layers[-1].output_name]],\n                updates=updates)\n        return self._functions[key](z)[0]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _find_output(self, layer):\n        '''Find a layer output name for the given layer specifier.\n\n        Parameters\n        ----------\n        layer : None, int, str, or :class:`theanets.layers.Layer`\n            A layer specification. If this is None, the \"middle\" layer in the\n            network will be used (i.e., the layer at the middle index in the\n            list of network layers). If this is an integer, the corresponding\n            layer in the network's layer list will be used. If this is a string,\n            the layer with the corresponding name will be returned.\n\n        Returns\n        -------\n        name : str\n            The fully-scoped output name for the desired layer.\n        '''\n        if layer is None:\n            layer = len(self.layers) // 2\n        if isinstance(layer, int):\n            layer = self.layers[layer]\n        if isinstance(layer, util.basestring):\n            try:\n                layer = [l for l in self.layers if l.name == layer][0]\n            except IndexError:\n                pass\n        if isinstance(layer, layers.Layer):\n            layer = layer.output_name\n        return layer", "response": "Find a layer output name for the given layer specifier."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef score(self, x, w=None, **kwargs):\n        '''Compute R^2 coefficient of determination for a given input.\n\n        Parameters\n        ----------\n        x : ndarray (num-examples, num-inputs)\n            An array containing data to be fed into the network. Multiple\n            examples are arranged as rows in this array, with columns containing\n            the variables for each example.\n\n        Returns\n        -------\n        r2 : float\n            The R^2 correlation between the prediction of this netork and its\n            input. This can serve as one measure of the information loss of the\n            autoencoder.\n        '''\n        return super(Autoencoder, self).score(x, x, w=w, **kwargs)", "response": "Compute R^2 coefficient of determination for a given input."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn expressions that should be computed to monitor training.", "response": "def monitors(self, **kwargs):\n        '''Return expressions that should be computed to monitor training.\n\n        Returns\n        -------\n        monitors : list of (name, expression) pairs\n            A list of named monitor expressions to compute for this network.\n        '''\n        monitors = super(Classifier, self).monitors(**kwargs)\n        regs = regularizers.from_kwargs(self, **kwargs)\n        outputs, _ = self.build_graph(regs)\n        return monitors + [('acc', self.losses[0].accuracy(outputs))]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef predict(self, x, **kwargs):\n        '''Compute a greedy classification for the given set of data.\n\n        Parameters\n        ----------\n        x : ndarray (num-examples, num-variables)\n            An array containing examples to classify. Examples are given as the\n            rows in this array.\n\n        Returns\n        -------\n        k : ndarray (num-examples, )\n            A vector of class index values, one per row of input data.\n        '''\n        outputs = self.feed_forward(x, **kwargs)\n        return outputs[self.layers[-1].output_name].argmax(axis=-1)", "response": "Compute a greedy classification for the given set of data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncomputing class posterior probabilities for the given set of data.", "response": "def predict_proba(self, x, **kwargs):\n        '''Compute class posterior probabilities for the given set of data.\n\n        Parameters\n        ----------\n        x : ndarray (num-examples, num-variables)\n            An array containing examples to predict. Examples are given as the\n            rows in this array.\n\n        Returns\n        -------\n        p : ndarray (num-examples, num-classes)\n            An array of class posterior probability values, one per row of input\n            data.\n        '''\n        return self.feed_forward(x, **kwargs)[self.layers[-1].output_name]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompute the logit values that underlie the softmax output.", "response": "def predict_logit(self, x, **kwargs):\n        '''Compute the logit values that underlie the softmax output.\n\n        Parameters\n        ----------\n        x : ndarray (num-examples, num-variables)\n            An array containing examples to classify. Examples are given as the\n            rows in this array.\n\n        Returns\n        -------\n        l : ndarray (num-examples, num-classes)\n            An array of posterior class logit values, one row of logit values\n            per row of input data.\n        '''\n        return self.feed_forward(x, **kwargs)[self.layers[-1].full_name('pre')]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef score(self, x, y, w=None, **kwargs):\n        '''Compute the mean accuracy on a set of labeled data.\n\n        Parameters\n        ----------\n        x : ndarray (num-examples, num-variables)\n            An array containing examples to classify. Examples are given as the\n            rows in this array.\n        y : ndarray (num-examples, )\n            A vector of integer class labels, one for each row of input data.\n        w : ndarray (num-examples, )\n            A vector of weights, one for each row of input data.\n\n        Returns\n        -------\n        score : float\n            The (possibly weighted) mean accuracy of the model on the data.\n        '''\n        eq = y == self.predict(x, **kwargs)\n        if w is not None:\n            return (w * eq).sum() / w.sum()\n        return eq.mean()", "response": "Compute the mean accuracy on a set of labeled data."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nextracts a single batch of data to pass to the model being trained.", "response": "def batch_at(features, labels, seq_begins, seq_lengths):\n    '''Extract a single batch of data to pass to the model being trained.\n\n    Parameters\n    ----------\n    features, labels : ndarray\n        Arrays of the input features and target labels.\n    seq_begins : ndarray\n        Array of the start offsets of the speech segments to include.\n    seq_lengths : ndarray\n        Array of the lengths of the speech segments to include in the batch.\n\n    Returns\n    -------\n    features, labels, mask : ndarrays\n        A triple of arrays for training a network. The first element contains\n        input features, the second contains target labels, and the third\n        contains a \"mask\" consisting of ones where there is valid data and zeros\n        everywhere else.\n    '''\n    length = seq_lengths.max()\n    feat = np.zeros((BATCH_SIZE, length, features.shape[-1]), 'f')\n    labl = np.zeros((BATCH_SIZE, length), 'i')\n    mask = np.zeros((BATCH_SIZE, length), 'f')\n    for b, (begin, length) in enumerate(zip(seq_begins, seq_lengths)):\n        feat[b, :length] = features[begin:begin+length]\n        labl[b, :length] = labels[begin:begin+length]\n        mask[b, :length] = 1\n    return [feat, labl, mask]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef batches(dataset):\n    '''Returns a callable that chooses sequences from netcdf data.'''\n    seq_lengths = dataset.variables['seqLengths'].data\n    seq_begins = np.concatenate(([0], np.cumsum(seq_lengths)[:-1]))\n\n    def sample():\n        chosen = np.random.choice(\n            list(range(len(seq_lengths))), BATCH_SIZE, replace=False)\n        return batch_at(dataset.variables['inputs'].data,\n                        dataset.variables['targetClasses'].data,\n                        seq_begins[chosen],\n                        seq_lengths[chosen])\n\n    return sample", "response": "Returns a callable that chooses sequences from netcdf data."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load(self, path):\n        '''Load a saved network from a pickle file on disk.\n\n        This method sets the ``network`` attribute of the experiment to the\n        loaded network model.\n\n        Parameters\n        ----------\n        filename : str\n            Load the keyword arguments and parameters of a network from a pickle\n            file at the named path. If this name ends in \".gz\" then the input\n            will automatically be gunzipped; otherwise the input will be treated\n            as a \"raw\" pickle.\n\n        Returns\n        -------\n        network : :class:`Network <graph.Network>`\n            A newly-constructed network, with topology and parameters loaded\n            from the given pickle file.\n        '''\n        self.network = graph.Network.load(path)\n        return self.network", "response": "Load a saved network from a pickle file on disk."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef random_matrix(rows, cols, mean=0, std=1, sparsity=0, radius=0, diagonal=0, rng=None):\n    '''Create a matrix of randomly-initialized weights.\n\n    Parameters\n    ----------\n    rows : int\n        Number of rows of the weight matrix -- equivalently, the number of\n        \"input\" units that the weight matrix connects.\n    cols : int\n        Number of columns of the weight matrix -- equivalently, the number\n        of \"output\" units that the weight matrix connects.\n    mean : float, optional\n        Draw initial weight values from a normal with this mean. Defaults to 0.\n    std : float, optional\n        Draw initial weight values from a normal with this standard deviation.\n        Defaults to 1.\n    sparsity : float in (0, 1), optional\n        If given, ensure that the given fraction of the weight matrix is\n        set to zero. Defaults to 0, meaning all weights are nonzero.\n    radius : float, optional\n        If given, rescale the initial weights to have this spectral radius.\n        No scaling is performed by default.\n    diagonal : float, optional\n        If nonzero, create a matrix containing all zeros except for this value\n        along the diagonal. If nonzero, other arguments (except for rows and\n        cols) will be ignored.\n    rng : :class:`numpy.random.RandomState` or int, optional\n        A random number generator, or an integer seed for a random number\n        generator. If not provided, the random number generator will be created\n        with an automatically chosen seed.\n\n    Returns\n    -------\n    matrix : numpy array\n        An array containing random values. These often represent the weights\n        connecting each \"input\" unit to each \"output\" unit in a layer.\n    '''\n    if rng is None or isinstance(rng, int):\n        rng = np.random.RandomState(rng)\n    arr = mean + std * rng.randn(rows, cols)\n    if 1 > sparsity > 0:\n        k = min(rows, cols)\n        mask = rng.binomial(n=1, p=1 - sparsity, size=(rows, cols)).astype(bool)\n        mask[:k, :k] |= np.eye(k).astype(bool)\n        arr *= mask\n    if radius > 0:\n        # rescale weights to have the appropriate spectral radius.\n        u, s, vT = np.linalg.svd(arr, full_matrices=False)\n        arr = np.dot(np.dot(u, np.diag(radius * s / abs(s[0]))), vT)\n    if diagonal != 0:\n        # generate a diagonal weight matrix. ignore other options.\n        arr = diagonal * np.eye(max(rows, cols))[:rows, :cols]\n    return arr.astype(FLOAT)", "response": "Create a random matrix of the given size."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a vector of randomly - initialized values.", "response": "def random_vector(size, mean=0, std=1, rng=None):\n    '''Create a vector of randomly-initialized values.\n\n    Parameters\n    ----------\n    size : int\n        Length of vecctor to create.\n    mean : float, optional\n        Mean value for initial vector values. Defaults to 0.\n    std : float, optional\n        Standard deviation for initial vector values. Defaults to 1.\n    rng : :class:`numpy.random.RandomState` or int, optional\n        A random number generator, or an integer seed for a random number\n        generator. If not provided, the random number generator will be created\n        with an automatically chosen seed.\n\n    Returns\n    -------\n    vector : numpy array\n        An array containing random values. This often represents the bias for a\n        layer of computation units.\n    '''\n    if rng is None or isinstance(rng, int):\n        rng = np.random.RandomState(rng)\n    return (mean + std * rng.randn(size)).astype(FLOAT)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef outputs_matching(outputs, patterns):\n    '''Get the outputs from a network that match a pattern.\n\n    Parameters\n    ----------\n    outputs : dict or sequence of (str, theano expression)\n        Output expressions to filter for matches. If this is a dictionary, its\n        ``items()`` will be processed for matches.\n    patterns : sequence of str\n        A sequence of glob-style patterns to match against. Any parameter\n        matching any pattern in this sequence will be included in the match.\n\n    Yields\n    ------\n    matches : pair of str, theano expression\n        Generates a sequence of (name, expression) pairs. The name is the name\n        of the output that matched, and the expression is the symbolic output in\n        the network graph.\n    '''\n    if isinstance(patterns, basestring):\n        patterns = (patterns, )\n    if isinstance(outputs, dict):\n        outputs = outputs.items()\n    for name, expr in outputs:\n        for pattern in patterns:\n            if fnmatch.fnmatch(name, pattern):\n                yield name, expr\n                break", "response": "Get the outputs from a network that match a pattern."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the parameters from a network that match a pattern.", "response": "def params_matching(layers, patterns):\n    '''Get the parameters from a network that match a pattern.\n\n    Parameters\n    ----------\n    layers : list of :class:`theanets.layers.Layer`\n        A list of network layers to retrieve parameters from.\n    patterns : sequence of str\n        A sequence of glob-style patterns to match against. Any parameter\n        matching any pattern in this sequence will be included in the match.\n\n    Yields\n    ------\n    matches : pair of str, theano expression\n        Generates a sequence of (name, expression) pairs. The name is the name\n        of the parameter that matched, and the expression represents the\n        parameter symbolically.\n    '''\n    if isinstance(patterns, basestring):\n        patterns = (patterns, )\n    for layer in layers:\n        for param in layer.params:\n            name = param.name\n            for pattern in patterns:\n                if fnmatch.fnmatch(name, pattern):\n                    yield name, param\n                    break"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconstruct a common regularizer from a set of keyword arguments.", "response": "def from_kwargs(graph, **kwargs):\n    '''Construct common regularizers from a set of keyword arguments.\n\n    Keyword arguments not listed below will be passed to\n    :func:`Regularizer.build` if they specify the name of a registered\n    :class:`Regularizer`.\n\n    Parameters\n    ----------\n    graph : :class:`theanets.graph.Network`\n        A network graph to regularize.\n\n    regularizers : dict or tuple/list of :class:`Regularizer`, optional\n        If this is a list or a tuple, the contents of the list will be returned\n        as the regularizers. This is to permit custom lists of regularizers to\n        be passed easily.\n\n        If this is a dict, its contents will be added to the other keyword\n        arguments passed in.\n\n    rng : int or theano RandomStreams, optional\n        If an integer is provided, it will be used to seed the random number\n        generators for the dropout or noise regularizers. If a theano\n        RandomStreams object is provided, it will be used directly. Defaults to\n        13.\n\n    input_dropout : float, optional\n        Apply dropout to input layers in the network graph, with this dropout\n        rate. Defaults to 0 (no dropout).\n\n    hidden_dropout : float, optional\n        Apply dropout to hidden layers in the network graph, with this dropout\n        rate. Defaults to 0 (no dropout).\n\n    output_dropout : float, optional\n        Apply dropout to the output layer in the network graph, with this\n        dropout rate. Defaults to 0 (no dropout).\n\n    input_noise : float, optional\n        Apply noise to input layers in the network graph, with this standard\n        deviation. Defaults to 0 (no noise).\n\n    hidden_noise : float, optional\n        Apply noise to hidden layers in the network graph, with this standard\n        deviation. Defaults to 0 (no noise).\n\n    output_noise : float, optional\n        Apply noise to the output layer in the network graph, with this\n        standard deviation. Defaults to 0 (no noise).\n\n    Returns\n    -------\n    regs : list of :class:`Regularizer`\n        A list of regularizers to apply to the given network graph.\n    '''\n    if 'regularizers' in kwargs:\n        regs = kwargs['regularizers']\n        if isinstance(regs, (tuple, list)):\n            return regs\n        if isinstance(regs, dict):\n            kwargs.update(regs)\n\n    regs = []\n\n    rng = kwargs.get('rng', 13)\n\n    def pattern(ls):\n        return tuple(l.output_name for l in ls)\n\n    inputs = pattern([l for l in graph.layers if isinstance(l, layers.Input)])\n    hiddens = pattern(graph.layers[1:-1])\n    outputs = pattern([graph.layers[-1]])\n\n    # create regularizers for different types of canned dropout.\n    spec = {inputs: kwargs.get('input_dropout', 0),\n            hiddens: kwargs.get('hidden_dropout', 0),\n            outputs: kwargs.get('output_dropout', 0)}\n    spec.update(kwargs.get('dropout', {}))\n    for pattern, w in spec.items():\n        if w:\n            regs.append(BernoulliDropout(pattern=pattern, weight=w, rng=rng))\n\n    # create regularizers for different types of canned noise.\n    spec = {inputs: kwargs.get('input_noise', 0),\n            hiddens: kwargs.get('hidden_noise', 0),\n            outputs: kwargs.get('output_noise', 0)}\n    spec.update(kwargs.get('noise', {}))\n    for pattern, w in spec.items():\n        if w:\n            regs.append(GaussianNoise(pattern=pattern, weight=w, rng=rng))\n\n    # create regularizers based on other keyword arguments.\n    for key, value in kwargs.items():\n        if Regularizer.is_registered(key):\n            if not isinstance(value, dict):\n                value = dict(weight=value)\n            regs.append(Regularizer.build(key, **value))\n\n    return regs"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef variables(self):\n        '''A list of Theano variables used in this loss.'''\n        result = [self._target]\n        if self._weights is not None:\n            result.append(self._weights)\n        return result", "response": "A list of Theano variables used in this loss."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nbuilds a Theano expression for computing the accuracy of the graph output.", "response": "def accuracy(self, outputs):\n        '''Build a Theano expression for computing the accuracy of graph output.\n\n        Parameters\n        ----------\n        outputs : dict of Theano expressions\n            A dictionary mapping network output names to Theano expressions\n            representing the outputs of a computation graph.\n\n        Returns\n        -------\n        acc : Theano expression\n            A Theano expression representing the accuracy of the output compared\n            to the target data.\n        '''\n        output = outputs[self.output_name]\n        predict = TT.argmax(output, axis=-1)\n        correct = TT.eq(predict, self._target)\n        acc = correct.mean()\n        if self._weights is not None:\n            acc = (self._weights * correct).sum() / self._weights.sum()\n        return acc"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _scan(self, inputs, outputs, name='scan', step=None, constants=None):\n        '''Helper method for defining a basic loop in theano.\n\n        Parameters\n        ----------\n        inputs : sequence of theano expressions\n            Inputs to the scan operation.\n        outputs : sequence of output specifiers\n            Specifiers for the outputs of the scan operation. This should be a\n            sequence containing:\n            - None for values that are output by the scan but not tapped as\n              inputs,\n            - an integer or theano scalar (``ndim == 0``) indicating the batch\n              size for initial zero state,\n            - a theano tensor variable (``ndim > 0``) containing initial state\n              data, or\n            - a dictionary containing a full output specifier. See\n              ``outputs_info`` in the Theano documentation for ``scan``.\n        name : str, optional\n            Name of the scan variable to create. Defaults to ``'scan'``.\n        step : callable, optional\n            The callable to apply in the loop. Defaults to :func:`self._step`.\n        constants : sequence of tensor, optional\n            A sequence of parameters, if any, needed by the step function.\n\n        Returns\n        -------\n        output(s) : theano expression(s)\n            Theano expression(s) representing output(s) from the scan.\n        updates : sequence of update tuples\n            A sequence of updates to apply inside a theano function.\n        '''\n        init = []\n        for i, x in enumerate(outputs):\n            ndim = getattr(x, 'ndim', -1)\n            if x is None or isinstance(x, dict) or ndim > 0:\n                init.append(x)\n                continue\n            if isinstance(x, int) or ndim == 0:\n                init.append(TT.repeat(theano.shared(\n                    np.zeros((1, self.output_size), util.FLOAT),\n                    name=self._fmt('init{}'.format(i))), x, axis=0))\n                continue\n            raise ValueError('cannot handle input {} for scan!'.format(x))\n        return theano.scan(\n            step or self._step,\n            name=self._fmt(name),\n            sequences=inputs,\n            outputs_info=init,\n            non_sequences=constants,\n            go_backwards='back' in self.kwargs.get('direction', '').lower(),\n            truncate_gradient=self.kwargs.get('bptt_limit', -1),\n        )", "response": "This method is used to define a basic loop in theano."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a rate parameter for a recurrent layer.", "response": "def _create_rates(self, dist='uniform', size=None, eps=1e-4):\n        '''Create a rate parameter (usually for a recurrent network layer).\n\n        Parameters\n        ----------\n        dist : {'uniform', 'log'}, optional\n            Distribution of rate values. Defaults to ``'uniform'``.\n        size : int, optional\n            Number of rates to create. Defaults to ``self.output_size``.\n        eps : float, optional\n            A \"buffer\" preventing rate values from getting too close to 0 or 1.\n            Defaults to 1e-4.\n\n        Returns\n        -------\n        rates : theano shared or None\n            A vector of rate parameters for certain types of recurrent layers.\n        '''\n        if size is None:\n            size = self.output_size\n        if dist == 'uniform':\n            z = np.random.uniform(eps, 1 - eps, size=size).astype(util.FLOAT)\n            return theano.shared(z, name=self._fmt('rate'))\n        if dist == 'log':\n            z = np.random.uniform(-6, -eps, size=size).astype(util.FLOAT)\n            return theano.shared(np.exp(z), name=self._fmt('rate'))\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconstructing an activation function by name.", "response": "def build(name, layer, **kwargs):\n    '''Construct an activation function by name.\n\n    Parameters\n    ----------\n    name : str or :class:`Activation`\n        The name of the type of activation function to build, or an\n        already-created instance of an activation function.\n    layer : :class:`theanets.layers.Layer`\n        The layer to which this activation will be applied.\n    kwargs : dict\n        Additional named arguments to pass to the activation constructor.\n\n    Returns\n    -------\n    activation : :class:`Activation`\n        A neural network activation function instance.\n    '''\n    if isinstance(name, Activation):\n        return name\n\n    if '+' in name:\n        return functools.reduce(\n            Compose, (build(n, layer, **kwargs) for n in name.split('+')))\n\n    act = COMMON.get(name)\n    if act is not None:\n        act.name = name\n        act.params = []\n        return act\n\n    if name.lower().startswith('maxout') and ':' in name:\n        name, pieces = name.split(':', 1)\n        kwargs['pieces'] = int(pieces)\n    kwargs['name'] = name\n    kwargs['layer'] = layer\n    return Activation.build(name, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntraining a model using a training and validation set.", "response": "def itertrain(self, train, valid=None, **kwargs):\n        '''Train a model using a training and validation set.\n\n        This method yields a series of monitor values to the caller. After every\n        iteration, a pair of monitor dictionaries is generated: one evaluated on\n        the training dataset, and another evaluated on the validation dataset.\n        The validation monitors might not be updated during every training\n        iteration; in this case, the most recent validation monitors will be\n        yielded along with the training monitors.\n\n        Parameters\n        ----------\n        train : :class:`Dataset <theanets.dataset.Dataset>`\n            A set of training data for computing updates to model parameters.\n        valid : :class:`Dataset <theanets.dataset.Dataset>`\n            A set of validation data for computing monitor values and\n            determining when the loss has stopped improving.\n\n        Yields\n        ------\n        training : dict\n            A dictionary mapping monitor names to values, evaluated on the\n            training dataset.\n        validation : dict\n            A dictionary containing monitor values evaluated on the validation\n            dataset.\n        '''\n        for monitors in downhill.build(\n                algo=self.algo,\n                loss=self.network.loss(**kwargs),\n                updates=self.network.updates(**kwargs),\n                monitors=self.network.monitors(**kwargs),\n                inputs=self.network.variables,\n                params=self.network.params,\n                monitor_gradients=kwargs.get('monitor_gradients', False),\n        ).iterate(train, valid=valid, **kwargs):\n            yield monitors"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef reservoir(xs, n, rng):\n        '''Select a random sample of n items from xs.'''\n        pool = []\n        for i, x in enumerate(xs):\n            if len(pool) < n:\n                pool.append(x / np.linalg.norm(x))\n                continue\n            j = rng.randint(i + 1)\n            if j < n:\n                pool[j] = x / np.linalg.norm(x)\n        # if the pool still has fewer than n items, pad with distorted random\n        # duplicates from the source data.\n        L = len(pool)\n        S = np.std(pool, axis=0)\n        while len(pool) < n:\n            x = pool[rng.randint(L)]\n            pool.append(x + S * rng.randn(*x.shape))\n        return np.array(pool, dtype=pool[0].dtype)", "response": "Select a random sample of n items from xs."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntrain a model using a training and validation set.", "response": "def itertrain(self, train, valid=None, **kwargs):\n        '''Train a model using a training and validation set.\n\n        This method yields a series of monitor values to the caller. After every\n        iteration, a pair of monitor dictionaries is generated: one evaluated on\n        the training dataset, and another evaluated on the validation dataset.\n        The validation monitors might not be updated during every training\n        iteration; in this case, the most recent validation monitors will be\n        yielded along with the training monitors.\n\n        Parameters\n        ----------\n        train : :class:`Dataset <theanets.dataset.Dataset>`\n            A set of training data for computing updates to model parameters.\n        valid : :class:`Dataset <theanets.dataset.Dataset>`\n            A set of validation data for computing monitor values and\n            determining when the loss has stopped improving.\n\n        Yields\n        ------\n        training : dict\n            A dictionary mapping monitor names to values, evaluated on the\n            training dataset.\n        validation : dict\n            A dictionary containing monitor values evaluated on the validation\n            dataset.\n        '''\n        ifci = itertools.chain.from_iterable\n\n        def first(x):\n            return x[0] if isinstance(x, (tuple, list)) else x\n\n        def last(x):\n            return x[-1] if isinstance(x, (tuple, list)) else x\n\n        odim = idim = None\n        for t in train:\n            idim = first(t).shape[-1]\n            odim = last(t).shape[-1]\n\n        rng = kwargs.get('rng')\n        if rng is None or isinstance(rng, int):\n            rng = np.random.RandomState(rng)\n\n        # set output (decoding) weights on the network.\n        samples = ifci(last(t) for t in train)\n        for param in self.network.layers[-1].params:\n            shape = param.get_value(borrow=True).shape\n            if len(shape) == 2 and shape[1] == odim:\n                arr = np.vstack(SampleTrainer.reservoir(samples, shape[0], rng))\n                util.log('setting {}: {}', param.name, shape)\n                param.set_value(arr / np.sqrt((arr * arr).sum(axis=1))[:, None])\n\n        # set input (encoding) weights on the network.\n        samples = ifci(first(t) for t in train)\n        for layer in self.network.layers:\n            for param in layer.params:\n                shape = param.get_value(borrow=True).shape\n                if len(shape) == 2 and shape[0] == idim:\n                    arr = np.vstack(SampleTrainer.reservoir(samples, shape[1], rng)).T\n                    util.log('setting {}: {}', param.name, shape)\n                    param.set_value(arr / np.sqrt((arr * arr).sum(axis=0)))\n                    samples = ifci(self.network.feed_forward(\n                        first(t))[i-1] for t in train)\n\n        yield dict(loss=0), dict(loss=0)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntraining a model using a training and validation set.", "response": "def itertrain(self, train, valid=None, **kwargs):\n        '''Train a model using a training and validation set.\n\n        This method yields a series of monitor values to the caller. After every\n        iteration, a pair of monitor dictionaries is generated: one evaluated on\n        the training dataset, and another evaluated on the validation dataset.\n        The validation monitors might not be updated during every training\n        iteration; in this case, the most recent validation monitors will be\n        yielded along with the training monitors.\n\n        Parameters\n        ----------\n        train : :class:`Dataset <theanets.dataset.Dataset>`\n            A set of training data for computing updates to model parameters.\n        valid : :class:`Dataset <theanets.dataset.Dataset>`\n            A set of validation data for computing monitor values and\n            determining when the loss has stopped improving.\n\n        Yields\n        ------\n        training : dict\n            A dictionary mapping monitor names to values, evaluated on the\n            training dataset.\n        validation : dict\n            A dictionary containing monitor values evaluated on the validation\n            dataset.\n        '''\n        net = self.network\n        original = list(net.layers)\n        output_name = original[-1].output_name\n        tied = any(isinstance(l, layers.Tied) for l in original)\n        L = 1 + len(original) // 2 if tied else len(original) - 1\n        for i in range(1, L):\n            tail = []\n            if i == L - 1:\n                net.layers = original\n            elif tied:\n                net.layers = original[:i+1]\n                for j in range(i):\n                    prev = tail[-1] if tail else net.layers[-1]\n                    tail.append(layers.Layer.build(\n                        'tied', partner=original[i-j].name, inputs=prev.name))\n                net.layers = original[:i+1] + tail\n            else:\n                tail.append(layers.Layer.build(\n                    'feedforward',\n                    name='lwout',\n                    inputs=original[i].output_name,\n                    size=original[-1].output_size,\n                    activation=original[-1].kwargs['activation']))\n                net.layers = original[:i+1] + tail\n            util.log('layerwise: training {}',\n                     ' -> '.join(l.name for l in net.layers))\n            [l.bind(net, initialize=False) for l in net.layers]\n            [l.setup() for l in tail]\n            net.losses[0].output_name = net.layers[-1].output_name\n            trainer = DownhillTrainer(self.algo, net)\n            for monitors in trainer.itertrain(train, valid, **kwargs):\n                yield monitors\n        net.layers = original\n        net.losses[0].output_name = output_name"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntrain a model using a training and validation set.", "response": "def itertrain(self, train, valid=None, **kwargs):\n        '''Train a model using a training and validation set.\n\n        This method yields a series of monitor values to the caller. After every\n        iteration, a pair of monitor dictionaries is generated: one evaluated on\n        the training dataset, and another evaluated on the validation dataset.\n        The validation monitors might not be updated during every training\n        iteration; in this case, the most recent validation monitors will be\n        yielded along with the training monitors.\n\n        Parameters\n        ----------\n        train : :class:`Dataset <theanets.dataset.Dataset>`\n            A set of training data for computing updates to model parameters.\n        valid : :class:`Dataset <theanets.dataset.Dataset>`\n            A set of validation data for computing monitor values and\n            determining when the loss has stopped improving.\n\n        Yields\n        ------\n        training : dict\n            A dictionary mapping monitor names to values, evaluated on the\n            training dataset.\n        validation : dict\n            A dictionary containing monitor values evaluated on the validation\n            dataset.\n        '''\n        from . import feedforward\n\n        original_layer_names = set(l.name for l in self.network.layers[:-1])\n\n        # construct a \"shadow\" of the input network, using the original\n        # network's encoding layers, with tied weights in an autoencoder\n        # configuration.\n        layers_ = list(l.to_spec() for l in self.network.layers[:-1])\n        for i, l in enumerate(layers_[::-1][:-2]):\n            layers_.append(dict(\n                form='tied', partner=l['name'], activation=l['activation']))\n        layers_.append(dict(\n            form='tied', partner=layers_[1]['name'], activation='linear'))\n\n        util.log('creating shadow network')\n        ae = feedforward.Autoencoder(layers=layers_)\n\n        # train the autoencoder using the supervised layerwise pretrainer.\n        pre = SupervisedPretrainer(self.algo, ae)\n        for monitors in pre.itertrain(train, valid, **kwargs):\n            yield monitors\n\n        # copy trained parameter values back to our original network.\n        for param in ae.params:\n            l, p = param.name.split('.')\n            if l in original_layer_names:\n                util.log('copying pretrained parameter {}', param.name)\n                self.network.find(l, p).set_value(param.get_value())\n\n        util.log('completed unsupervised pretraining')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_layer(self, layer=None, **kwargs):\n        '''Add a :ref:`layer <layers>` to our network graph.\n\n        Parameters\n        ----------\n        layer : int, tuple, dict, or :class:`Layer <theanets.layers.base.Layer>`\n            A value specifying the layer to add. For more information, please\n            see :ref:`guide-creating-specifying-layers`.\n        '''\n        # if the given layer is a Layer instance, just add it and move on.\n        if isinstance(layer, layers.Layer):\n            self.layers.append(layer)\n            return\n\n        form = kwargs.pop('form', 'ff' if self.layers else 'input').lower()\n\n        if isinstance(layer, util.basestring):\n            if not layers.Layer.is_registered(layer):\n                raise util.ConfigurationError('unknown layer type: {}'.format(layer))\n            form = layer\n            layer = None\n\n        # if layer is a tuple/list of integers, assume it's a shape.\n        if isinstance(layer, (tuple, list)) and all(isinstance(x, int) for x in layer):\n            kwargs['shape'] = tuple(layer)\n            layer = None\n\n        # if layer is some other tuple/list, assume it's a list of:\n        # - the name of a layers.Layer class (str)\n        # - the name of an activation function (str)\n        # - the number of units in the layer (int)\n        if isinstance(layer, (tuple, list)):\n            for el in layer:\n                if isinstance(el, util.basestring) and layers.Layer.is_registered(el):\n                    form = el\n                elif isinstance(el, util.basestring):\n                    kwargs['activation'] = el\n                elif isinstance(el, int):\n                    if 'size' in kwargs:\n                        raise util.ConfigurationError(\n                            'duplicate layer sizes! {}'.format(kwargs))\n                    kwargs['size'] = el\n            layer = None\n\n        # if layer is a dictionary, try to extract a form for the layer, and\n        # override our default keyword arguments with the rest.\n        if isinstance(layer, dict):\n            for key, value in layer.items():\n                if key == 'form':\n                    form = value.lower()\n                else:\n                    kwargs[key] = value\n            layer = None\n\n        # if neither shape nor size have been specified yet, check that the\n        # \"layer\" param is an int and use it for \"size\".\n        if 'shape' not in kwargs and 'size' not in kwargs and isinstance(layer, int):\n            kwargs['size'] = layer\n\n        # if it hasn't been provided in some other way yet, set input\n        # dimensionality based on the model.\n        if form == 'input' and 'shape' not in kwargs:\n            kwargs.setdefault('ndim', self.INPUT_NDIM)\n\n        # set some default layer parameters.\n        if form != 'input':\n            kwargs.setdefault('inputs', self.layers[-1].output_name)\n            kwargs.setdefault('rng', self._rng)\n\n        if form.lower() == 'tied' and 'partner' not in kwargs:\n            # we look backward through our list of layers for a partner.\n            # any \"tied\" layer that we find increases a counter by one,\n            # and any \"untied\" layer decreases the counter by one. our\n            # partner is the first layer we find with count zero.\n            #\n            # this is intended to handle the hopefully common case of a\n            # (possibly deep) tied-weights autoencoder.\n            tied = 1\n            partner = None\n            for l in self.layers[::-1]:\n                tied += 1 if isinstance(l, layers.Tied) else -1\n                if tied == 0:\n                    partner = l.name\n                    break\n            else:\n                raise util.ConfigurationError(\n                    'cannot find partner for \"{}\"'.format(kwargs))\n            kwargs['partner'] = partner\n\n        layer = layers.Layer.build(form, **kwargs)\n\n        # check that graph inputs have unique names.\n        if isinstance(layer, layers.Input):\n            if any(layer.name == i.name for i in self.inputs):\n                raise util.ConfigurationError(\n                    '\"{}\": duplicate input name!'.format(layer.name))\n\n        self.layers.append(layer)", "response": "Adds a layer to the internal network."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_loss(self, loss=None, **kwargs):\n        '''Add a :ref:`loss function <losses>` to the model.\n\n        Parameters\n        ----------\n        loss : str, dict, or :class:`theanets.losses.Loss`\n            A loss function to add. If this is a Loss instance, it will be added\n            immediately. If this is a string, it names a loss function to build\n            and add. If it is a dictionary, it should contain a ``'form'`` key\n            whose string value names the loss function to add. Other arguments\n            will be passed to :func:`theanets.losses.Loss.build`.\n        '''\n        if isinstance(loss, losses.Loss):\n            self.losses.append(loss)\n            return\n\n        form = loss or 'mse'\n        if 'form' in kwargs:\n            form = kwargs.pop('form').lower()\n\n        kw = dict(target=self.INPUT_NDIM, output_name=self.layers[-1].output_name)\n        kw.update(kwargs)\n\n        if isinstance(loss, dict):\n            loss = dict(loss)\n            if 'form' in loss:\n                form = loss.pop('form').lower()\n            kw.update(loss)\n\n        self.losses.append(losses.Loss.build(form, **kw))", "response": "Adds a loss function to the model."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_loss(self, *args, **kwargs):\n        '''Clear the current loss functions from the network and add a new one.\n\n        All parameters and keyword arguments are passed to :func:`add_loss`\n        after clearing the current losses.\n        '''\n        self.losses = []\n        self.add_loss(*args, **kwargs)", "response": "Clear the current loss functions from the network and add a new one."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntrain our network one batch at a time.", "response": "def itertrain(self, train, valid=None, algo='rmsprop', subalgo='rmsprop',\n                  save_every=0, save_progress=None, **kwargs):\n        '''Train our network, one batch at a time.\n\n        This method yields a series of ``(train, valid)`` monitor pairs. The\n        ``train`` value is a dictionary mapping names to monitor values\n        evaluated on the training dataset. The ``valid`` value is also a\n        dictionary mapping names to values, but these values are evaluated on\n        the validation dataset.\n\n        Because validation might not occur every training iteration, the\n        validation monitors might be repeated for multiple training iterations.\n        It is probably most helpful to think of the validation monitors as being\n        the \"most recent\" values that have been computed.\n\n        After training completes, the network attribute of this class will\n        contain the trained network parameters.\n\n        Parameters\n        ----------\n        train : :class:`Dataset <downhill.dataset.Dataset>` or list\n            A dataset to use when training the network. If this is a\n            ``downhill.Dataset`` instance, it will be used directly as the\n            training datset. If it is a list of numpy arrays or a list of\n            callables, it will be converted to a ``downhill.Dataset`` and then\n            used as the training set.\n        valid : :class:`Dataset <downhill.dataset.Dataset>` or list, optional\n            If this is provided, it will be used as a validation dataset. If not\n            provided, the training set will be used for validation. (This is not\n            recommended!)\n        algo : str, optional\n            An optimization algorithm to use for training our network. If not\n            provided, :class:`RMSProp <downhill.adaptive.RMSProp>` will be used.\n        subalgo : str, optional\n            An optimization algorithm to use for a trainer that requires a\n            \"sub-algorithm,\" sugh as an unsupervised pretrainer. Defaults to\n            :class:`RMSProp <downhill.adaptive.RMSProp>`.\n        save_every : int or float, optional\n            If this is nonzero and ``save_progress`` is not None, then the model\n            being trained will be saved periodically. If this is a float, it is\n            treated as a number of minutes to wait between savings. If it is an\n            int, it is treated as the number of training epochs to wait between\n            savings. Defaults to 0.\n        save_progress : str or file handle, optional\n            If this is not None, and ``save_progress`` is nonzero, then save the\n            model periodically during training. This parameter gives either (a)\n            the full path of a file to save the model, or (b) a file-like object\n            where the model should be saved. If it is a string and the given\n            name contains a \"{}\" format specifier, it will be filled with the\n            integer Unix timestamp at the time the model is saved. Defaults to\n            None, which does not save models.\n\n        Yields\n        ------\n        training : dict\n            A dictionary of monitor values computed using the training dataset,\n            at the conclusion of training. This dictionary will at least contain\n            a 'loss' key that indicates the value of the loss function. Other\n            keys may be available depending on the trainer being used.\n        validation : dict\n            A dictionary of monitor values computed using the validation\n            dataset, at the conclusion of training.\n        '''\n        if 'rng' not in kwargs:\n            kwargs['rng'] = self._rng\n\n        def create_dataset(data, **kwargs):\n            name = kwargs.get('name', 'dataset')\n            s = '{}_batches'.format(name)\n            return downhill.Dataset(\n                data,\n                name=name,\n                batch_size=kwargs.get('batch_size', 32),\n                iteration_size=kwargs.get('iteration_size', kwargs.get(s)),\n                axis=kwargs.get('axis', 0),\n                rng=kwargs['rng'])\n\n        # set up datasets ...\n        if valid is None:\n            valid = train\n        if not isinstance(valid, downhill.Dataset):\n            valid = create_dataset(valid, name='valid', **kwargs)\n        if not isinstance(train, downhill.Dataset):\n            train = create_dataset(train, name='train', **kwargs)\n\n        if 'algorithm' in kwargs:\n            warnings.warn(\n                'please use the \"algo\" keyword arg instead of \"algorithm\"',\n                DeprecationWarning)\n            algo = kwargs.pop('algorithm')\n            if isinstance(algo, (list, tuple)):\n                algo = algo[0]\n\n        # set up trainer ...\n        if isinstance(algo, util.basestring):\n            algo = algo.lower()\n            if algo == 'sample':\n                algo = trainer.SampleTrainer(self)\n            elif algo.startswith('layer') or algo.startswith('sup'):\n                algo = trainer.SupervisedPretrainer(subalgo, self)\n            elif algo.startswith('pre') or algo.startswith('unsup'):\n                algo = trainer.UnsupervisedPretrainer(subalgo, self)\n            else:\n                algo = trainer.DownhillTrainer(algo, self)\n\n        # set up check to save model ...\n        def needs_saving(elapsed, iteration):\n            if save_progress is None:\n                return False\n            if isinstance(save_every, float):\n                return elapsed > 60 * save_every\n            if isinstance(save_every, int):\n                return iteration % save_every == 0\n            return False\n\n        # train it!\n        start = time.time()\n        for i, monitors in enumerate(algo.itertrain(train, valid, **kwargs)):\n            yield monitors\n            now = time.time()\n            if i and needs_saving(now - start, i):\n                filename_or_handle = save_progress\n                if isinstance(filename_or_handle, util.basestring):\n                    filename_or_handle = save_progress.format(int(now))\n                self.save(filename_or_handle)\n                start = now"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef train(self, *args, **kwargs):\n        '''Train the network until the trainer converges.\n\n        All arguments are passed to :func:`itertrain`.\n\n        Returns\n        -------\n        training : dict\n            A dictionary of monitor values computed using the training dataset,\n            at the conclusion of training. This dictionary will at least contain\n            a 'loss' key that indicates the value of the loss function. Other\n            keys may be available depending on the trainer being used.\n        validation : dict\n            A dictionary of monitor values computed using the validation\n            dataset, at the conclusion of training.\n        '''\n        monitors = None\n        for monitors in self.itertrain(*args, **kwargs):\n            pass\n        return monitors", "response": "Train the network until the trainer converges."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _hash(self, regularizers=()):\n        '''Construct a string key for representing a computation graph.\n\n        This key will be unique for a given (a) network topology, (b) set of\n        losses, and (c) set of regularizers.\n\n        Returns\n        -------\n        key : str\n            A hash representing the computation graph for the current network.\n        '''\n        def add(s):\n            h.update(str(s).encode('utf-8'))\n        h = hashlib.md5()\n        for l in self.layers:\n            add('{}{}{}'.format(l.__class__.__name__, l.name, l.output_shape))\n        for l in self.losses:\n            add('{}{}'.format(l.__class__.__name__, l.weight))\n        for r in regularizers:\n            add('{}{}{}'.format(r.__class__.__name__, r.weight, r.pattern))\n        return h.hexdigest()", "response": "Construct a string key for representing a computation graph."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconnecting the layers in this network to form a computation graph.", "response": "def build_graph(self, regularizers=()):\n        '''Connect the layers in this network to form a computation graph.\n\n        Parameters\n        ----------\n        regularizers : list of :class:`theanets.regularizers.Regularizer`\n            A list of the regularizers to apply while building the computation\n            graph.\n\n        Returns\n        -------\n        outputs : list of Theano variables\n            A list of expressions giving the output of each layer in the graph.\n        updates : list of update tuples\n            A list of updates that should be performed by a Theano function that\n            computes something using this graph.\n        '''\n        key = self._hash(regularizers)\n        if key not in self._graphs:\n            util.log('building computation graph')\n            for loss in self.losses:\n                loss.log()\n            for reg in regularizers:\n                reg.log()\n            outputs = {}\n            updates = []\n            for layer in self.layers:\n                out, upd = layer.connect(outputs)\n                for reg in regularizers:\n                    reg.modify_graph(out)\n                outputs.update(out)\n                updates.extend(upd)\n            self._graphs[key] = outputs, updates\n        return self._graphs[key]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef inputs(self):\n        '''A list of Theano variables for feedforward computations.'''\n        return [l.input for l in self.layers if isinstance(l, layers.Input)]", "response": "A list of Theano variables for feedforward computations."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find(self, which, param):\n        '''Get a parameter from a layer in the network.\n\n        Parameters\n        ----------\n        which : int or str\n            The layer that owns the parameter to return.\n\n            If this is an integer, then 0 refers to the input layer, 1 refers\n            to the first hidden layer, 2 to the second, and so on.\n\n            If this is a string, the layer with the corresponding name, if any,\n            will be used.\n\n        param : int or str\n            Name of the parameter to retrieve from the specified layer, or its\n            index in the parameter list of the layer.\n\n        Raises\n        ------\n        KeyError\n            If there is no such layer, or if there is no such parameter in the\n            specified layer.\n\n        Returns\n        -------\n        param : Theano shared variable\n            A shared parameter variable from the indicated layer.\n        '''\n        for i, layer in enumerate(self.layers):\n            if which == i or which == layer.name:\n                return layer.find(param)\n        raise KeyError(which)", "response": "Find a parameter from a layer in the network."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef feed_forward(self, x, **kwargs):\n        '''Compute a forward pass of all layers from the given input.\n\n        All keyword arguments are passed directly to :func:`build_graph`.\n\n        Parameters\n        ----------\n        x : ndarray (num-examples, num-variables)\n            An array containing data to be fed into the network. Multiple\n            examples are arranged as rows in this array, with columns containing\n            the variables for each example.\n\n        Returns\n        -------\n        layers : list of ndarray (num-examples, num-units)\n            The activation values of each layer in the the network when given\n            input `x`. For each of the hidden layers, an array is returned\n            containing one row per input example; the columns of each array\n            correspond to units in the respective layer. The \"output\" of the\n            network is the last element of this list.\n        '''\n        regs = regularizers.from_kwargs(self, **kwargs)\n        key = self._hash(regs)\n        if key not in self._functions:\n            outputs, updates = self.build_graph(regs)\n            labels, exprs = list(outputs.keys()), list(outputs.values())\n            util.log('compiling feed_forward function')\n            self._functions[key] = (labels, theano.function(\n                self.inputs, exprs, updates=updates))\n        labels, f = self._functions[key]\n        return dict(zip(labels, f(x)))", "response": "Compute a forward pass of all layers from the given input."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef predict(self, x, **kwargs):\n        '''Compute a forward pass of the inputs, returning the network output.\n\n        All keyword arguments end up being passed to :func:`build_graph`.\n\n        Parameters\n        ----------\n        x : ndarray (num-examples, num-variables)\n            An array containing data to be fed into the network. Multiple\n            examples are arranged as rows in this array, with columns containing\n            the variables for each example.\n\n        Returns\n        -------\n        y : ndarray (num-examples, num-variables)\n            Returns the values of the network output units when given input `x`.\n            Rows in this array correspond to examples, and columns to output\n            variables.\n        '''\n        return self.feed_forward(x, **kwargs)[self.layers[-1].output_name]", "response": "Compute a forward pass of the inputs returning the network output."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef score(self, x, y, w=None, **kwargs):\n        '''Compute R^2 coefficient of determination for a given labeled input.\n\n        Parameters\n        ----------\n        x : ndarray (num-examples, num-inputs)\n            An array containing data to be fed into the network. Multiple\n            examples are arranged as rows in this array, with columns containing\n            the variables for each example.\n        y : ndarray (num-examples, num-outputs)\n            An array containing expected target data for the network. Multiple\n            examples are arranged as rows in this array, with columns containing\n            the variables for each example.\n\n        Returns\n        -------\n        r2 : float\n            The R^2 correlation between the prediction of this netork and its\n            target output.\n        '''\n        u = y - self.predict(x, **kwargs)\n        v = y - y.mean()\n        if w is None:\n            w = np.ones_like(u)\n        return 1 - (w * u * u).sum() / (w * v * v).sum()", "response": "Compute R^2 coefficient of determination of determination for a given labeled input."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsave the state of this network to a pickle file on disk.", "response": "def save(self, filename_or_handle):\n        '''Save the state of this network to a pickle file on disk.\n\n        Parameters\n        ----------\n        filename_or_handle : str or file handle\n            Save the state of this network to a pickle file. If this parameter\n            is a string, it names the file where the pickle will be saved. If it\n            is a file-like object, this object will be used for writing the\n            pickle. If the filename ends in \".gz\" then the output will\n            automatically be gzipped.\n        '''\n        if isinstance(filename_or_handle, util.basestring):\n            opener = gzip.open if filename_or_handle.lower().endswith('.gz') else open\n            handle = opener(filename_or_handle, 'wb')\n        else:\n            handle = filename_or_handle\n        pickle.dump(self, handle, -1)\n        if isinstance(filename_or_handle, util.basestring):\n            handle.close()\n        util.log('saved model to {}', filename_or_handle)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading a saved network from disk.", "response": "def load(cls, filename_or_handle):\n        '''Load a saved network from disk.\n\n        Parameters\n        ----------\n        filename_or_handle : str or file handle\n            Load the state of this network from a pickle file. If this parameter\n            is a string, it names the file where the pickle will be saved. If it\n            is a file-like object, this object will be used for reading the\n            pickle. If the filename ends in \".gz\" then the output will\n            automatically be gunzipped.\n        '''\n        assert not isinstance(cls, Network), \\\n            'cannot load an instance! say instead: net = Network.load(source)'\n        if isinstance(filename_or_handle, util.basestring):\n            opener = gzip.open if filename_or_handle.lower().endswith('.gz') else open\n            handle = opener(filename_or_handle, 'rb')\n        else:\n            handle = filename_or_handle\n        model = pickle.load(handle)\n        if isinstance(filename_or_handle, util.basestring):\n            handle.close()\n        util.log('loaded model from {}', filename_or_handle)\n        return model"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a variable representing the regularized loss for this network.", "response": "def loss(self, **kwargs):\n        '''Return a variable representing the regularized loss for this network.\n\n        The regularized loss includes both the :ref:`loss computation <losses>`\n        for the network as well as any :ref:`regularizers <regularizers>` that\n        are in place.\n\n        Keyword arguments are passed directly to\n        :func:`theanets.regularizers.from_kwargs`.\n\n        Returns\n        -------\n        loss : Theano expression\n            A Theano expression representing the loss of this network.\n        '''\n        regs = regularizers.from_kwargs(self, **kwargs)\n        outputs, _ = self.build_graph(regs)\n        return sum(l.weight * l(outputs) for l in self.losses) + \\\n            sum(r.weight * r.loss(self.layers, outputs) for r in regs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn expressions that should be computed to monitor training.", "response": "def monitors(self, **kwargs):\n        '''Return expressions that should be computed to monitor training.\n\n        Returns\n        -------\n        monitors : list of (name, expression) pairs\n            A list of named monitor expressions to compute for this network.\n        '''\n        regs = regularizers.from_kwargs(self, **kwargs)\n        outputs, _ = self.build_graph(regs)\n        monitors = [('err', self.losses[0](outputs))]\n\n        def matching(pattern):\n            '''Yield all matching outputs or parameters from the graph.'''\n            for name, expr in util.outputs_matching(outputs, pattern):\n                yield name, expr\n            for name, expr in util.params_matching(self.layers, pattern):\n                yield name, expr\n\n        def parse_levels(levels):\n            '''Yield named monitor callables.'''\n            if isinstance(levels, dict):\n                levels = levels.items()\n            if isinstance(levels, (int, float)):\n                levels = [levels]\n            for level in levels:\n                if isinstance(level, (tuple, list)):\n                    label, call = level\n                    yield ':{}'.format(label), call\n                if isinstance(level, (int, float)):\n                    def call(expr):\n                        return (expr < level).mean()\n                    yield '<{}'.format(level), call\n\n        inputs = kwargs.get('monitors', {})\n        if isinstance(inputs, dict):\n            inputs = inputs.items()\n        for pattern, levels in inputs:\n            for name, expr in matching(pattern):\n                for key, value in parse_levels(levels):\n                    monitors.append(('{}{}'.format(name, key), value(expr)))\n\n        return monitors"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef updates(self, **kwargs):\n        '''Return expressions to run as updates during network training.\n\n        Returns\n        -------\n        updates : list of (parameter, expression) pairs\n            A list of named parameter update expressions for this network.\n        '''\n        regs = regularizers.from_kwargs(self, **kwargs)\n        _, updates = self.build_graph(regs)\n        return updates", "response": "Return expressions to run as updates during training."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nnames of layer with one input.", "response": "def input_name(self):\n        '''Name of layer input (for layers with one input).'''\n        if len(self._input_shapes) != 1:\n            raise util.ConfigurationError(\n                'expected one input for layer \"{}\", got {}'\n                .format(self.name, self._input_shapes))\n        return list(self._input_shapes)[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsizes of layer input.", "response": "def input_size(self):\n        '''Size of layer input (for layers with one input).'''\n        shape = self.input_shape\n        if shape is None:\n            raise util.ConfigurationError(\n                'undefined input size for layer \"{}\"'.format(self.name))\n        return shape[-1]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef output_size(self):\n        '''Number of \"neurons\" in this layer's default output.'''\n        shape = self.output_shape\n        if shape is None:\n            raise util.ConfigurationError(\n                'undefined output size for layer \"{}\"'.format(self.name))\n        return shape[-1]", "response": "Number of neurons in this layer s default output."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates Theano variables representing the outputs of this layer.", "response": "def connect(self, inputs):\n        '''Create Theano variables representing the outputs of this layer.\n\n        Parameters\n        ----------\n        inputs : dict of Theano expressions\n            Symbolic inputs to this layer, given as a dictionary mapping string\n            names to Theano expressions. Each string key should be of the form\n            \"{layer_name}:{output_name}\" and refers to a specific output from\n            a specific layer in the graph.\n\n        Returns\n        -------\n        outputs : dict\n            A dictionary mapping names to Theano expressions for the outputs\n            from this layer.\n        updates : sequence of (parameter, expression) tuples\n            Updates that should be performed by a Theano function that computes\n            something using this layer.\n        '''\n        outputs, updates = self.transform(inputs)\n        # transform the outputs to be a list of ordered pairs if needed.\n        if isinstance(outputs, dict):\n            outputs = sorted(outputs.items())\n        if isinstance(outputs, (TT.TensorVariable, SS.SparseVariable)):\n            outputs = [('out', outputs)]\n        outs = {self.full_name(name): expr for name, expr in outputs}\n        return outs, updates"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nbinds this layer into a computation graph.", "response": "def bind(self, graph, reset=True, initialize=True):\n        '''Bind this layer into a computation graph.\n\n        This method is a wrapper for performing common initialization tasks. It\n        calls :func:`resolve`, :func:`setup`, and :func:`log`.\n\n        Parameters\n        ----------\n        graph : :class:`Network <theanets.graph.Network>`\n            A computation network in which this layer is to be bound.\n        reset : bool, optional\n            If ``True`` (the default), reset the resolved layers for this layer.\n        initialize : bool, optional\n            If ``True`` (the default), initialize the parameters for this layer\n            by calling :func:`setup`.\n\n        Raises\n        ------\n        theanets.util.ConfigurationError :\n            If an input cannot be resolved.\n        '''\n        if reset:\n            for k in self._input_shapes:\n                self._input_shapes[k] = None\n            for k in self._output_shapes:\n                self._output_shapes[k] = None\n        self.resolve_inputs(graph.layers)\n        self.resolve_outputs()\n        self.activate = activations.build(\n            self.kwargs.get('activation', 'relu'), self)\n        if initialize:\n            self.setup()\n        self.log()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef resolve_inputs(self, layers):\n        '''Resolve the names of inputs for this layer into shape tuples.\n\n        Parameters\n        ----------\n        layers : list of :class:`Layer`\n            A list of the layers that are available for resolving inputs.\n\n        Raises\n        ------\n        theanets.util.ConfigurationError :\n            If an input cannot be resolved.\n        '''\n        resolved = {}\n        for name, shape in self._input_shapes.items():\n            if shape is None:\n                name, shape = self._resolve_shape(name, layers)\n            resolved[name] = shape\n        self._input_shapes = resolved", "response": "Resolve the names of inputs for this layer into shape tuples."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef resolve_outputs(self):\n        '''Resolve the names of outputs for this layer into shape tuples.'''\n        input_shape = None\n        for i, shape in enumerate(self._input_shapes.values()):\n            if i == 0:\n                input_shape = shape\n            if len(input_shape) != len(shape) or any(\n                    a is not None and b is not None and a != b\n                    for a, b in zip(input_shape[:-1], shape[:-1])):\n                raise util.ConfigurationError(\n                    'layer \"{}\" incompatible input shapes {}'\n                    .format(self.name, self._input_shapes))\n        size = self.kwargs.get('size')\n        shape = self.kwargs.get('shape')\n        if shape is not None:\n            pass\n        elif size is not None:\n            shape = tuple(input_shape[:-1]) + (size, )\n        else:\n            raise util.ConfigurationError(\n                'layer \"{}\" does not specify a size'.format(self.name))\n        self._output_shapes['out'] = shape", "response": "Resolve the names of outputs for this layer into shape tuples."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef log(self):\n        '''Log some information about this layer.'''\n        inputs = ', '.join('\"{0}\" {1}'.format(*ns) for ns in self._input_shapes.items())\n        util.log('layer {0.__class__.__name__} \"{0.name}\" {0.output_shape} {1} from {2}',\n                 self, getattr(self.activate, 'name', self.activate), inputs)\n        util.log('learnable parameters: {}', self.log_params())", "response": "Log some information about this layer."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef log_params(self):\n        '''Log information about this layer's parameters.'''\n        total = 0\n        for p in self.params:\n            shape = p.get_value().shape\n            util.log('parameter \"{}\" {}', p.name, shape)\n            total += np.prod(shape)\n        return total", "response": "Log information about this layer s parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _resolve_shape(self, name, layers):\n        '''Given a list of layers, find the layer output with the given name.\n\n        Parameters\n        ----------\n        name : str\n            Name of a layer to resolve.\n        layers : list of :class:`theanets.layers.base.Layer`\n            A list of layers to search in.\n\n        Raises\n        ------\n        util.ConfigurationError :\n            If there is no such layer, or if there are more than one.\n\n        Returns\n        -------\n        name : str\n            The fully-scoped name of the desired output.\n        shape : tuple of None and/or int\n            The shape of the named output.\n        '''\n        matches = [l for l in layers if name.split(':')[0] == l.name]\n        if len(matches) != 1:\n            raise util.ConfigurationError(\n                'layer \"{}\" cannot resolve \"{}\" using {}'\n                .format(self.name, name, [l.name for l in layers]))\n        name = name if ':' in name else matches[0].output_name\n        return name, matches[0]._output_shapes[name.split(':')[1]]", "response": "Given a list of layers find the layer output with the given name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef find(self, key):\n        '''Get a shared variable for a parameter by name.\n\n        Parameters\n        ----------\n        key : str or int\n            The name of the parameter to look up, or the index of the parameter\n            in our parameter list. These are both dependent on the\n            implementation of the layer.\n\n        Returns\n        -------\n        param : shared variable\n            A shared variable containing values for the given parameter.\n\n        Raises\n        ------\n        KeyError\n            If a param with the given name does not exist.\n        '''\n        name = self._fmt(str(key))\n        for i, p in enumerate(self._params):\n            if key == i or name == p.name:\n                return p\n        raise KeyError(key)", "response": "Get a shared variable for a parameter by name."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_weights(self, name, nin, nout, mean=0, std=0, sparsity=0, diagonal=0):\n        '''Helper method to create a new weight matrix.\n\n        Parameters\n        ----------\n        name : str\n            Name of the parameter to add.\n        nin : int\n            Size of \"input\" for this weight matrix.\n        nout : int\n            Size of \"output\" for this weight matrix.\n        mean : float, optional\n            Mean value for randomly-initialized weights. Defaults to 0.\n        std : float, optional\n            Standard deviation of initial matrix values. Defaults to\n            :math:`1 / sqrt(n_i + n_o)`.\n        sparsity : float, optional\n            Fraction of weights to be set to zero. Defaults to 0.\n        diagonal : float, optional\n            Initialize weights to a matrix of zeros with this value along the\n            diagonal. Defaults to None, which initializes all weights randomly.\n        '''\n        glorot = 1 / np.sqrt(nin + nout)\n        m = self.kwargs.get(\n            'mean_{}'.format(name), self.kwargs.get('mean', mean))\n        s = self.kwargs.get(\n            'std_{}'.format(name), self.kwargs.get('std', std or glorot))\n        p = self.kwargs.get(\n            'sparsity_{}'.format(name), self.kwargs.get('sparsity', sparsity))\n        d = self.kwargs.get(\n            'diagonal_{}'.format(name), self.kwargs.get('diagonal', diagonal))\n        self._params.append(theano.shared(\n            util.random_matrix(nin, nout, mean=m, std=s, sparsity=p,\n                               diagonal=d, rng=self.rng),\n            name=self._fmt(name)))", "response": "Helper method to create a new weight matrix."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a specification dictionary for this layer.", "response": "def to_spec(self):\n        '''Create a specification dictionary for this layer.\n\n        Returns\n        -------\n        spec : dict\n            A dictionary specifying the configuration of this layer.\n        '''\n        spec = dict(**self.kwargs)\n        spec.update(\n            form=self.__class__.__name__.lower(),\n            name=self.name,\n            activation=self.kwargs.get('activation', 'relu'),\n        )\n        return spec"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the ArgMax from C by returning the ArgMax from C by returning the ArgMax from C by returning the ArgMax from C by returning the ArgMax from C by returning the ArgMax from C by returning the ArgMax from C by returning the ArgMax from C by returning the ArgMax from C by returning the ArgMax from C by returning the ArgMax", "response": "def argmax(self, C):\n        \"\"\"\n        Returns the ArgMax from C by returning the\n        (x_pos, y_pos, theta, scale)  tuple\n\n        >>> C = np.random.randn(10, 10, 5, 4)\n        >>> x_pos, y_pos, theta, scale = mp.argmax(C)\n        >>> C[x_pos][y_pos][theta][scale] = C.max()\n\n        \"\"\"\n        ind = np.absolute(C).argmax()\n        return np.unravel_index(ind, C.shape)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef band(self, sf_0, B_sf, force=False):\n        if sf_0 == 0.:\n            return 1.\n        elif self.pe.use_cache and not force:\n            tag = str(sf_0) + '_' + str(B_sf)\n            try:\n                return self.cache['band'][tag]\n            except:\n                if self.pe.verbose>50: print('doing band cache for tag ', tag)\n                self.cache['band'][tag] = self.band(sf_0, B_sf, force=True)\n                return self.cache['band'][tag]\n        else:\n            # see http://en.wikipedia.org/wiki/Log-normal_distribution\n            env = 1./self.f*np.exp(-.5*(np.log(self.f/sf_0)**2)/B_sf**2)\n        return env", "response": "Returns the radial frequency envelope of a given preferred spatial frequency and bandwidth."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the orientation of the object in the specified time - domain.", "response": "def orientation(self, theta, B_theta, force=False):\n        \"\"\"\n        Returns the orientation envelope:\n        We use a von-Mises distribution on the orientation:\n        - mean orientation is ``theta`` (in radians),\n        - ``B_theta`` is the bandwidth (in radians). It is equal to the standard deviation of the Gaussian\n        envelope which approximate the distribution for low bandwidths. The Half-Width at Half Height is\n        given by approximately np.sqrt(2*B_theta_**2*np.log(2)).\n\n        # selecting one direction,  theta is the mean direction, B_theta the spread\n        # we use a von-mises distribution on the orientation\n        # see http://en.wikipedia.org/wiki/Von_Mises_distribution\n        \"\"\"\n        if B_theta is np.inf: # for large bandwidth, returns a strictly flat envelope\n            enveloppe_orientation = 1.\n        elif self.pe.use_cache and not force:\n            tag = str(theta) + '_' + str(B_theta)\n            try:\n                return self.cache['orientation'][tag]\n            except:\n                if self.pe.verbose>50: print('doing orientation cache for tag ', tag)\n                self.cache['orientation'][tag] = self.orientation(theta, B_theta, force=True)\n                return self.cache['orientation'][tag]\n        else: # non pathological case\n            # As shown in:\n            #  http://www.csse.uwa.edu.au/~pk/research/matlabfns/PhaseCongruency/Docs/convexpl.html\n            # this single bump allows (without the symmetric) to code both symmetric\n            # and anti-symmetric parts in one shot.\n            cos_angle = np.cos(self.f_theta-theta)\n            enveloppe_orientation = np.exp(cos_angle/B_theta**2)\n        return enveloppe_orientation"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef loggabor(self, x_pos, y_pos, sf_0, B_sf, theta, B_theta, preprocess=True):\n\n        env = np.multiply(self.band(sf_0, B_sf), self.orientation(theta, B_theta))\n        if not(x_pos==0.) and not(y_pos==0.): # bypass translation whenever none is needed\n              env = env.astype(np.complex128) * self.trans(x_pos*1., y_pos*1.)\n        if preprocess : env *= self.f_mask # retina processing\n        # normalizing energy:\n        env /= np.sqrt((np.abs(env)**2).mean())\n        # in the case a a single bump (see ``orientation``), we should compensate the fact that the distribution gets complex:\n        env *= np.sqrt(2.)\n        return env", "response": "Returns the envelope of a loggabor with the given parameters"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the image of a LogGabor with the given parameters", "response": "def loggabor_image(self, x_pos, y_pos, theta, sf_0, phase, B_sf, B_theta):\n        \"\"\"\n        Returns the image of a LogGabor\n\n        Note that the convention for coordinates follows that of matrices:\n        the origin is at the top left of the image, and coordinates are first\n        the rows (vertical axis, going down) then the columns (horizontal axis,\n        going right).\n\n        \"\"\"\n\n        FT_lg = self.loggabor(x_pos, y_pos, sf_0=sf_0, B_sf=B_sf, theta=theta, B_theta=B_theta)\n        FT_lg = FT_lg * np.exp(1j * phase)\n        return self.invert(FT_lg, full=False)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_file(self, ifile, codec='ascii'):\n        if ifile.read(12) == b'ooBinaryFile':\n            def bin2str(ifile):\n                textlen = struct.unpack('>h', ifile.read(2))[0]\n                # Single byte characters\n                if textlen >= 0:\n                    return ifile.read(textlen).decode('ascii')\n                # Multi byte characters have initial len -1 and then \\xff bytes\n                elif textlen == -1:\n                    textlen = struct.unpack('>h', ifile.read(2))[0]\n                    data = ifile.read(textlen*2)\n                    # Hack to go from number to unicode in python3 and python2\n                    fun = unichr if 'unichr' in __builtins__ else chr\n                    charlist = (data[i:i+2] for i in range(0, len(data), 2))\n                    return u''.join(\n                        fun(struct.unpack('>h', i)[0]) for i in charlist)\n\n            ifile.read(ord(ifile.read(1)))  # skip oo type\n            self.xmin = struct.unpack('>d', ifile.read(8))[0]\n            self.xmax = struct.unpack('>d', ifile.read(8))[0]\n            ifile.read(1)  # skip <exists>\n            self.tier_num = struct.unpack('>i', ifile.read(4))[0]\n            for i in range(self.tier_num):\n                tier_type = ifile.read(ord(ifile.read(1))).decode('ascii')\n                name = bin2str(ifile)\n                tier = Tier(0, 0, name=name, tier_type=tier_type)\n                self.tiers.append(tier)\n                tier.xmin = struct.unpack('>d', ifile.read(8))[0]\n                tier.xmax = struct.unpack('>d', ifile.read(8))[0]\n                nint = struct.unpack('>i', ifile.read(4))[0]\n                for i in range(nint):\n                    x1 = struct.unpack('>d', ifile.read(8))[0]\n                    if tier.tier_type == 'IntervalTier':\n                        x2 = struct.unpack('>d', ifile.read(8))[0]\n                    text = bin2str(ifile)\n                    if tier.tier_type == 'IntervalTier':\n                        tier.intervals.append((x1, x2, text))\n                    elif tier.tier_type == 'TextTier':\n                        tier.intervals.append((x1, text))\n                    else:\n                        raise Exception('Tiertype does not exist.')\n        else:\n            def nn(ifile, pat):\n                line = next(ifile).decode(codec)\n                return pat.search(line).group(1)\n\n            regfloat = re.compile('([\\d.]+)\\s*$', flags=re.UNICODE)\n            regint = re.compile('([\\d]+)\\s*$', flags=re.UNICODE)\n            regstr = re.compile('\"(.*)\"\\s*$', flags=re.UNICODE)\n            # Skip the Headers and empty line\n            next(ifile), next(ifile), next(ifile)\n            self.xmin = float(nn(ifile, regfloat))\n            self.xmax = float(nn(ifile, regfloat))\n            # Skip <exists>\n            line = next(ifile)\n            short = line.strip() == b'<exists>'\n            self.tier_num = int(nn(ifile, regint))\n            not short and next(ifile)\n            for i in range(self.tier_num):\n                not short and next(ifile)  # skip item[]: and item[\\d]:\n                tier_type = nn(ifile, regstr)\n                name = nn(ifile, regstr)\n                tier = Tier(0, 0, name=name, tier_type=tier_type)\n                self.tiers.append(tier)\n                tier.xmin = float(nn(ifile, regfloat))\n                tier.xmax = float(nn(ifile, regfloat))\n                for i in range(int(nn(ifile, regint))):\n                    not short and next(ifile)  # skip intervals [\\d]\n                    x1 = float(nn(ifile, regfloat))\n                    if tier.tier_type == 'IntervalTier':\n                        x2 = float(nn(ifile, regfloat))\n                        t = nn(ifile, regstr)\n                        tier.intervals.append((x1, x2, t))\n                    elif tier.tier_type == 'TextTier':\n                        t = nn(ifile, regstr)\n                        tier.intervals.append((x1, t))", "response": "Read a single or multi - byte text grid from a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sort_tiers(self, key=lambda x: x.name):\n        self.tiers.sort(key=key)", "response": "Sort the tiers given the key function."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd an interval or text tier to the specified location.", "response": "def add_tier(self, name, tier_type='IntervalTier', number=None):\n        \"\"\"Add an IntervalTier or a TextTier on the specified location.\n\n        :param str name: Name of the tier, duplicate names is allowed.\n        :param str tier_type: Type of the tier.\n        :param int number: Place to insert the tier, when ``None`` the number\n            is generated and the tier will be placed on the bottom.\n        :returns: The created tier.\n        :raises ValueError: If the number is out of bounds.\n        \"\"\"\n        if number is None:\n            number = 1 if not self.tiers else len(self.tiers)+1\n        elif number < 1 or number > len(self.tiers):\n            raise ValueError('Number not in [1..{}]'.format(len(self.tiers)))\n        elif tier_type not in Tier.P_TIERS:\n            raise ValueError('tier_type has to be in {}'.format(self.P_TIERS))\n        self.tiers.insert(number-1,\n                          Tier(self.xmin, self.xmax, name, tier_type))\n        return self.tiers[number-1]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove a tier from the cache.", "response": "def remove_tier(self, name_num):\n        \"\"\"Remove a tier, when multiple tiers exist with that name only the\n        first is removed.\n\n        :param name_num: Name or number of the tier to remove.\n        :type name_num: int or str\n        :raises IndexError: If there is no tier with that number.\n        \"\"\"\n        if isinstance(name_num, int):\n            del(self.tiers[name_num-1])\n        else:\n            self.tiers = [i for i in self.tiers if i.name != name_num]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngive a tier when multiple tiers exist with that name only the first one is returned.", "response": "def get_tier(self, name_num):\n        \"\"\"Gives a tier, when multiple tiers exist with that name only the\n        first is returned.\n\n        :param name_num: Name or number of the tier to return.\n        :type name_num: int or str\n        :returns: The tier.\n        :raises IndexError: If the tier doesn't exist.\n        \"\"\"\n        return self.tiers[name_num - 1] if isinstance(name_num, int) else\\\n            [i for i in self.tiers if i.name == name_num][0]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrite the object to a file.", "response": "def to_file(self, filepath, codec='utf-8', mode='normal'):\n        \"\"\"Write the object to a file.\n\n        :param str filepath: Path of the fil.\n        :param str codec: Text encoding.\n        :param string mode: Flag to for write mode, possible modes:\n            'n'/'normal', 's'/'short' and 'b'/'binary'\n        \"\"\"\n        self.tier_num = len(self.tiers)\n        if mode in ['binary', 'b']:\n            with open(filepath, 'wb') as f:\n                def writebstr(s):\n                    try:\n                        bstr = s.encode('ascii')\n                    except UnicodeError:\n                        f.write(b'\\xff\\xff')\n                        bstr = b''.join(struct.pack('>h', ord(c)) for c in s)\n                    f.write(struct.pack('>h', len(s)))\n                    f.write(bstr)\n\n                f.write(b'ooBinaryFile\\x08TextGrid')\n                f.write(struct.pack('>d', self.xmin))\n                f.write(struct.pack('>d', self.xmax))\n                f.write(b'\\x01')\n                f.write(struct.pack('>i', self.tier_num))\n                for tier in self.tiers:\n                    f.write(chr(len(tier.tier_type)).encode('ascii'))\n                    f.write(tier.tier_type.encode('ascii'))\n                    writebstr(tier.name)\n                    f.write(struct.pack('>d', tier.xmin))\n                    f.write(struct.pack('>d', tier.xmax))\n                    ints = tier.get_all_intervals()\n                    f.write(struct.pack('>i', len(ints)))\n                    itier = tier.tier_type == 'IntervalTier'\n                    for c in ints:\n                        f.write(struct.pack('>d', c[0]))\n                        itier and f.write(struct.pack('>d', c[1]))\n                        writebstr(c[2 if itier else 1])\n        elif mode in ['normal', 'n', 'short', 's']:\n            with codecs.open(filepath, 'w', codec) as f:\n                short = mode[0] == 's'\n\n                def wrt(indent, prefix, value, ff=''):\n                    indent = 0 if short else indent\n                    prefix = '' if short else prefix\n                    if value is not None or not short:\n                        s = u'{{}}{{}}{}\\n'.format(ff)\n                        f.write(s.format(' '*indent, prefix, value))\n\n                f.write(u'File type = \"ooTextFile\"\\n'\n                        u'Object class = \"TextGrid\"\\n\\n')\n                wrt(0, u'xmin = ', self.xmin, '{:f}')\n                wrt(0, u'xmax = ', self.xmax, '{:f}')\n                wrt(0, u'tiers? ', u'<exists>', '{}')\n                wrt(0, u'size = ', self.tier_num, '{:d}')\n                wrt(0, u'item []:', None)\n                for tnum, tier in enumerate(self.tiers, 1):\n                    wrt(4, u'item [{:d}]:'.format(tnum), None)\n                    wrt(8, u'class = ', tier.tier_type, '\"{}\"')\n                    wrt(8, u'name = ', tier.name, '\"{}\"')\n                    wrt(8, u'xmin = ', tier.xmin, '{:f}')\n                    wrt(8, u'xmax = ', tier.xmax, '{:f}')\n                    if tier.tier_type == 'IntervalTier':\n                        ints = tier.get_all_intervals()\n                        wrt(8, u'intervals: size = ', len(ints), '{:d}')\n                        for i, c in enumerate(ints):\n                            wrt(8, 'intervals [{:d}]:'.format(i+1), None)\n                            wrt(12, 'xmin = ', c[0], '{:f}')\n                            wrt(12, 'xmax = ', c[1], '{:f}')\n                            wrt(12, 'text = ', c[2].replace('\"', '\"\"'), '\"{}\"')\n                    elif tier.tier_type == 'TextTier':\n                        wrt(8, u'points: size = ', len(tier.intervals), '{:d}')\n                        for i, c in enumerate(tier.get_intervals()):\n                            wrt(8, 'points [{:d}]:'.format(i+1), None)\n                            wrt(12, 'number = ', c[0], '{:f}')\n                            wrt(12, 'mark = ', c[1].replace('\"', '\"\"'), '\"{}\"')\n        else:\n            raise Exception('Unknown mode')"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts the object to an Eaf object.", "response": "def to_eaf(self, skipempty=True, pointlength=0.1):\n        \"\"\"Convert the object to an pympi.Elan.Eaf object\n\n        :param int pointlength: Length of respective interval from points in\n                                seconds\n        :param bool skipempty: Skip the empty annotations\n        :returns: :class:`pympi.Elan.Eaf` object\n        :raises ImportError: If the Eaf module can't be loaded.\n        :raises ValueError: If the pointlength is not strictly positive.\n        \"\"\"\n        from pympi.Elan import Eaf\n        eaf_out = Eaf()\n        if pointlength <= 0:\n            raise ValueError('Pointlength should be strictly positive')\n        for tier in self.get_tiers():\n            eaf_out.add_tier(tier.name)\n            for ann in tier.get_intervals(True):\n                if tier.tier_type == 'TextTier':\n                    ann = (ann[0], ann[0]+pointlength, ann[1])\n                if ann[2].strip() or not skipempty:\n                    eaf_out.add_annotation(tier.name, int(round(ann[0]*1000)),\n                                           int(round(ann[1]*1000)), ann[2])\n        return eaf_out"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a point to the TextTier.", "response": "def add_point(self, point, value, check=True):\n        \"\"\"Add a point to the TextTier\n\n        :param int point: Time of the point.\n        :param str value: Text of the point.\n        :param bool check: Flag to check for overlap.\n        :raises Exception: If overlap or wrong tiertype.\n        \"\"\"\n        if self.tier_type != 'TextTier':\n            raise Exception('Tiertype must be TextTier.')\n        if check and any(i for i in self.intervals if i[0] == point):\n                raise Exception('No overlap is allowed')\n        self.intervals.append((point, value))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding an interval to the IntervalTier.", "response": "def add_interval(self, begin, end, value, check=True):\n        \"\"\"Add an interval to the IntervalTier.\n\n        :param float begin: Start time of the interval.\n        :param float end: End time of the interval.\n        :param str value: Text of the interval.\n        :param bool check: Flag to check for overlap.\n        :raises Exception: If overlap, begin > end or wrong tiertype.\n        \"\"\"\n        if self.tier_type != 'IntervalTier':\n            raise Exception('Tiertype must be IntervalTier')\n        if check:\n            if any(i for i in self.intervals if begin < i[1] and end > i[0]):\n                raise Exception('No overlap is allowed')\n            if begin > end:\n                raise Exception('Begin must be smaller then end')\n        self.intervals.append((begin, end, value))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nremoves an interval from the list of intervals.", "response": "def remove_interval(self, time):\n        \"\"\"Remove an interval, if no interval is found nothing happens.\n\n        :param int time: Time of the interval.\n        :raises TierTypeException: If the tier is not a IntervalTier.\n        \"\"\"\n        if self.tier_type != 'IntervalTier':\n            raise Exception('Tiertype must be IntervalTier.')\n        self.intervals = [i for i in self.intervals\n                          if not(i[0] <= time and i[1] >= time)]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove a point from the set of points.", "response": "def remove_point(self, time):\n        \"\"\"Remove a point, if no point is found nothing happens.\n\n        :param int time: Time of the point.\n        :raises TierTypeException: If the tier is not a TextTier.\n        \"\"\"\n        if self.tier_type != 'TextTier':\n            raise Exception('Tiertype must be TextTier.')\n        self.intervals = [i for i in self.intervals if i[0] != time]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngiving all the intervals or points sorted.", "response": "def get_intervals(self, sort=False):\n        \"\"\"Give all the intervals or points.\n\n        :param bool sort: Flag for yielding the intervals or points sorted.\n        :yields: All the intervals\n        \"\"\"\n        for i in sorted(self.intervals) if sort else self.intervals:\n            yield i"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the true list of intervals including the empty intervals.", "response": "def get_all_intervals(self):\n        \"\"\"Returns the true list of intervals including the empty intervals.\"\"\"\n        ints = sorted(self.get_intervals(True))\n        if self.tier_type == 'IntervalTier':\n            if not ints:\n                ints.append((self.xmin, self.xmax, ''))\n            else:\n                if ints[0][0] > self.xmin:\n                    ints.insert(0, (self.xmin, ints[0][0], ''))\n                if ints[-1][1] < self.xmax:\n                    ints.append((ints[-1][1], self.xmax, ''))\n                p = ints[-1]\n                for index, i in reversed(list(enumerate(ints[:-1], 1))):\n                    if p[0] - i[1] != 0:\n                        ints.insert(index, (i[1], p[0], ''))\n                    p = i\n        return ints"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading a. cha file and converts it to an ELAN object.", "response": "def eaf_from_chat(file_path, codec='ascii', extension='wav'):\n    \"\"\"Reads a .cha file and converts it to an elan object. The functions tries\n    to mimic the CHAT2ELAN program that comes with the CLAN package as close as\n    possible. This function however converts to the latest ELAN file format\n    since the library is designed for it. All CHAT headers will be added as\n    Properties in the object and the headers that have a similar field in an\n    Eaf file will be added there too. The file description of chat files can be\n    found `here <http://childes.psy.cmu.edu/manuals/CHAT.pdf>`_.\n\n    :param str file_path: The file path of the .cha file.\n    :param str codec: The codec, if the @UTF8 header is present it will choose\n        utf-8, default is ascii. Older CHAT files don't have their encoding\n        embedded in a header so you will probably need to choose some obscure\n        ISO charset then.\n    :param str extension: The extension of the media file.\n    :throws StopIteration: If the file doesn't contain a @End header, thus\n        inferring the file is broken.\n    \"\"\"\n    eafob = Eaf()\n    eafob.add_linguistic_type('parent')\n    eafob.add_linguistic_type(\n        'child', constraints='Symbolic_Association', timealignable=False)\n    participantsdb = {}\n    last_annotation = None\n    with open(file_path, 'r') as chatin:\n        while True:\n            line = chatin.readline().strip().decode(codec)\n            if line == '@UTF8':  # Codec marker\n                codec = 'utf8'\n                continue\n            elif line == '@End':  # End of file marker\n                break\n            elif line.startswith('@') and line != '@Begin':  # Header marker\n                key, value = line.split(':\\t')\n                eafob.add_property('{}:\\t'.format(key), value)\n                if key == '@Languages':\n                    for language in value.split(','):\n                        eafob.add_language(language)\n                elif key == '@Participants':\n                    for participant in value.split(','):\n                        splits = participant.strip().split(' ')\n                        splits = map(lambda x: x.replace('_', ' '), splits)\n                        if len(splits) == 2:\n                            participantsdb[splits[0]] = (None, splits[1])\n                        elif len(splits) == 3:\n                            participantsdb[splits[0]] = (splits[1], splits[2])\n                elif key == '@ID':\n                    ids = map(lambda x: x.replace('_', ''), value.split('|'))\n                    eafob.add_tier(ids[2], part=participantsdb[ids[2]][0],\n                                   language=ids[0])\n                elif key == '@Media':\n                    media = value.split(',')\n                    eafob.add_linked_file(\n                        'file://{}.{}'.format(media[0], extension))\n                elif key == '@Transcriber:':\n                    for tier in eafob.get_tier_names():\n                        eafob.tiers[tier][2]['ANNOTATOR'] = value\n            elif line.startswith('*'):  # Main tier marker\n                while len(line.split('\\x15')) != 3:\n                    line += chatin.readline().decode(codec).strip()\n                for participant in participantsdb.keys():\n                    if line.startswith('*{}:'.format(participant)):\n                        splits = ''.join(line.split(':')[1:]).strip()\n                        utt, time, _ = splits.split('\\x15')\n                        time = map(int, time.split('_'))\n                        last_annotation = (participant, time[0], time[1], utt)\n                        eafob.add_annotation(*last_annotation)\n            elif line.startswith('%'):  # Dependant tier marker\n                splits = line.split(':')\n                name = '{}_{}'.format(last_annotation[0], splits[0][1:])\n                if name not in eafob.get_tier_names():\n                    eafob.add_tier(name, 'child', last_annotation[0])\n                eafob.add_ref_annotation(\n                    name, last_annotation[0], sum(last_annotation[1:3])/2,\n                    ''.join(splits[1:]).strip())\n    return eafob"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing an EAF file and return a new EAF object.", "response": "def parse_eaf(file_path, eaf_obj):\n    \"\"\"Parse an EAF file\n\n    :param str file_path: Path to read from, - for stdin.\n    :param pympi.Elan.Eaf eaf_obj: Existing EAF object to put the data in.\n    :returns: EAF object.\n    \"\"\"\n    if file_path == '-':\n        file_path = sys.stdin\n    # Annotation document\n    try:\n        tree_root = etree.parse(file_path).getroot()\n    except etree.ParseError:\n        raise Exception('Unable to parse eaf, can you open it in ELAN?')\n\n    if tree_root.attrib['VERSION'] not in ['2.8', '2.7']:\n        sys.stdout.write('Parsing unknown version of ELAN spec... '\n                         'This could result in errors...\\n')\n    eaf_obj.adocument.update(tree_root.attrib)\n    del(eaf_obj.adocument['{http://www.w3.org/2001/XMLSchema-instance}noNamesp'\n                          'aceSchemaLocation'])\n    tier_number = 0\n    for elem in tree_root:\n        # Licence\n        if elem.tag == 'LICENSE':\n            eaf_obj.licenses.append((elem.text, elem.attrib['LICENSE_URL']))\n        # Header\n        if elem.tag == 'HEADER':\n            eaf_obj.header.update(elem.attrib)\n            for elem1 in elem:\n                if elem1.tag == 'MEDIA_DESCRIPTOR':\n                    eaf_obj.media_descriptors.append(elem1.attrib)\n                elif elem1.tag == 'LINKED_FILE_DESCRIPTOR':\n                    eaf_obj.linked_file_descriptors.append(elem1.attrib)\n                elif elem1.tag == 'PROPERTY':\n                    eaf_obj.properties.append(\n                        (elem1.attrib['NAME'], elem1.text))\n        # Time order\n        elif elem.tag == 'TIME_ORDER':\n            for elem1 in elem:\n                tsid = elem1.attrib['TIME_SLOT_ID']\n                tsnum = int(''.join(filter(str.isdigit, tsid)))\n                if tsnum and tsnum > eaf_obj.maxts:\n                    eaf_obj.maxts = tsnum\n                ts = elem1.attrib.get('TIME_VALUE', None)\n                eaf_obj.timeslots[tsid] = ts if ts is None else int(ts)\n        # Tier\n        elif elem.tag == 'TIER':\n            tier_id = elem.attrib['TIER_ID']\n            align = {}\n            ref = {}\n            for elem1 in elem:\n                if elem1.tag == 'ANNOTATION':\n                    for elem2 in elem1:\n                        if elem2.tag == 'ALIGNABLE_ANNOTATION':\n                            annot_id = elem2.attrib['ANNOTATION_ID']\n                            annot_num = int(''.join(\n                                filter(str.isdigit, annot_id)))\n                            if annot_num and annot_num > eaf_obj.maxaid:\n                                eaf_obj.maxaid = annot_num\n                            annot_start = elem2.attrib['TIME_SLOT_REF1']\n                            annot_end = elem2.attrib['TIME_SLOT_REF2']\n                            svg_ref = elem2.attrib.get('SVG_REF', None)\n                            align[annot_id] = (annot_start, annot_end,\n                                               '' if not list(elem2)[0].text\n                                               else list(elem2)[0].text,\n                                               svg_ref)\n                            eaf_obj.annotations[annot_id] = tier_id\n                        elif elem2.tag == 'REF_ANNOTATION':\n                            annot_ref = elem2.attrib['ANNOTATION_REF']\n                            previous = elem2.attrib.get('PREVIOUS_ANNOTATION',\n                                                        None)\n                            annot_id = elem2.attrib['ANNOTATION_ID']\n                            annot_num = int(''.join(\n                                filter(str.isdigit, annot_id)))\n                            if annot_num and annot_num > eaf_obj.maxaid:\n                                eaf_obj.maxaid = annot_num\n                            svg_ref = elem2.attrib.get('SVG_REF', None)\n                            ref[annot_id] = (annot_ref,\n                                             '' if not list(elem2)[0].text else\n                                             list(elem2)[0].text,\n                                             previous, svg_ref)\n                            eaf_obj.annotations[annot_id] = tier_id\n            eaf_obj.tiers[tier_id] = (align, ref, elem.attrib, tier_number)\n            tier_number += 1\n        # Linguistic type\n        elif elem.tag == 'LINGUISTIC_TYPE':\n            eaf_obj.linguistic_types[elem.attrib['LINGUISTIC_TYPE_ID']] =\\\n                elem.attrib\n        # Locale\n        elif elem.tag == 'LOCALE':\n            eaf_obj.locales[elem.attrib['LANGUAGE_CODE']] =\\\n                (elem.attrib.get('COUNTRY_CODE', None),\n                 elem.attrib.get('VARIANT', None))\n        # Language\n        elif elem.tag == 'LANGUAGE':\n            eaf_obj.languages[elem.attrib['LANG_ID']] =\\\n                (elem.attrib.get('LANG_DEF', None),\n                 elem.attrib.get('LANG_LABEL', None))\n        # Constraint\n        elif elem.tag == 'CONSTRAINT':\n            eaf_obj.constraints[elem.attrib['STEREOTYPE']] =\\\n                elem.attrib['DESCRIPTION']\n        # Controlled vocabulary\n        elif elem.tag == 'CONTROLLED_VOCABULARY':\n            cv_id = elem.attrib['CV_ID']\n            ext_ref = elem.attrib.get('EXT_REF', None)\n            descriptions = []\n\n            if 'DESCRIPTION' in elem.attrib:\n                eaf_obj.languages['und'] = (\n                    'http://cdb.iso.org/lg/CDB-00130975-001',\n                    'undetermined (und)')\n                descriptions.append(('und', elem.attrib['DESCRIPTION']))\n            entries = {}\n            for elem1 in elem:\n                if elem1.tag == 'DESCRIPTION':\n                    descriptions.append((elem1.attrib['LANG_REF'], elem1.text))\n                elif elem1.tag == 'CV_ENTRY':\n                    cve_value = (elem1.text, 'und',\n                                 elem1.get('DESCRIPTION', None))\n                    entries['cveid{}'.format(len(entries))] = \\\n                        ([cve_value], elem1.attrib.get('EXT_REF', None))\n                elif elem1.tag == 'CV_ENTRY_ML':\n                    cem_ext_ref = elem1.attrib.get('EXT_REF', None)\n                    cve_id = elem1.attrib['CVE_ID']\n                    cve_values = []\n                    for elem2 in elem1:\n                        if elem2.tag == 'CVE_VALUE':\n                            cve_values.append((elem2.text,\n                                               elem2.attrib['LANG_REF'],\n                                               elem2.get('DESCRIPTION', None)))\n                    entries[cve_id] = (cve_values, cem_ext_ref)\n            eaf_obj.controlled_vocabularies[cv_id] =\\\n                (descriptions, entries, ext_ref)\n        # Lexicon ref\n        elif elem.tag == 'LEXICON_REF':\n            eaf_obj.lexicon_refs[elem.attrib['LEX_REF_ID']] = elem.attrib\n        # External ref\n        elif elem.tag == 'EXTERNAL_REF':\n            eaf_obj.external_refs[elem.attrib['EXT_REF_ID']] = (\n                elem.attrib['TYPE'], elem.attrib['VALUE'])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfunction to pretty print the xml.", "response": "def indent(el, level=0):\n    \"\"\"Function to pretty print the xml, meaning adding tabs and newlines.\n\n    :param ElementTree.Element el: Current element.\n    :param int level: Current level.\n    \"\"\"\n    i = '\\n' + level * '\\t'\n    if len(el):\n        if not el.text or not el.text.strip():\n            el.text = i+'\\t'\n        if not el.tail or not el.tail.strip():\n            el.tail = i\n        for elem in el:\n            indent(elem, level+1)\n        if not el.tail or not el.tail.strip():\n            el.tail = i\n    else:\n        if level and (not el.tail or not el.tail.strip()):\n            el.tail = i"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwriting an Eaf object to file.", "response": "def to_eaf(file_path, eaf_obj, pretty=True):\n    \"\"\"Write an Eaf object to file.\n\n    :param str file_path: Filepath to write to, - for stdout.\n    :param pympi.Elan.Eaf eaf_obj: Object to write.\n    :param bool pretty: Flag to set pretty printing.\n    \"\"\"\n    def rm_none(x):\n        try:  # Ugly hack to test if s is a string in py3 and py2\n            basestring\n\n            def isstr(s):\n                return isinstance(s, basestring)\n        except NameError:\n            def isstr(s):\n                return isinstance(s, str)\n        return {k: v if isstr(v) else str(v) for k, v in x.items()\n                if v is not None}\n    # Annotation Document\n    ADOCUMENT = etree.Element('ANNOTATION_DOCUMENT', eaf_obj.adocument)\n    # Licence\n    for m in eaf_obj.licenses:\n        n = etree.SubElement(ADOCUMENT, 'LICENSE', {'LICENSE_URL': m[1]})\n        n.text = m[0]\n    # Header\n    HEADER = etree.SubElement(ADOCUMENT, 'HEADER', eaf_obj.header)\n    # Media descriptiors\n    for m in eaf_obj.media_descriptors:\n        etree.SubElement(HEADER, 'MEDIA_DESCRIPTOR', rm_none(m))\n    # Linked file descriptors\n    for m in eaf_obj.linked_file_descriptors:\n        etree.SubElement(HEADER, 'LINKED_FILE_DESCRIPTOR', rm_none(m))\n    # Properties\n    for k, v in eaf_obj.properties:\n        etree.SubElement(HEADER, 'PROPERTY', {'NAME': k}).text = str(v)\n    # Time order\n    TIME_ORDER = etree.SubElement(ADOCUMENT, 'TIME_ORDER')\n    for t in sorted(eaf_obj.timeslots.items(), key=lambda x: int(x[0][2:])):\n        etree.SubElement(TIME_ORDER, 'TIME_SLOT', rm_none(\n            {'TIME_SLOT_ID': t[0], 'TIME_VALUE': t[1]}))\n    # Tiers\n    for t in sorted(eaf_obj.tiers.items(), key=lambda x: x[1][3]):\n        tier = etree.SubElement(ADOCUMENT, 'TIER', rm_none(t[1][2]))\n        for a in t[1][0].items():\n            ann = etree.SubElement(tier, 'ANNOTATION')\n            alan = etree.SubElement(ann, 'ALIGNABLE_ANNOTATION', rm_none(\n                {'ANNOTATION_ID': a[0], 'TIME_SLOT_REF1': a[1][0],\n                 'TIME_SLOT_REF2': a[1][1], 'SVG_REF': a[1][3]}))\n            etree.SubElement(alan, 'ANNOTATION_VALUE').text = a[1][2]\n        for a in t[1][1].items():\n            ann = etree.SubElement(tier, 'ANNOTATION')\n            rean = etree.SubElement(ann, 'REF_ANNOTATION', rm_none(\n                {'ANNOTATION_ID': a[0], 'ANNOTATION_REF': a[1][0],\n                 'PREVIOUS_ANNOTATION': a[1][2], 'SVG_REF': a[1][3]}))\n            etree.SubElement(rean, 'ANNOTATION_VALUE').text = a[1][1]\n    # Linguistic types\n    for l in eaf_obj.linguistic_types.values():\n        etree.SubElement(ADOCUMENT, 'LINGUISTIC_TYPE', rm_none(l))\n    # Locales\n    for lc, (cc, vr) in eaf_obj.locales.items():\n        etree.SubElement(ADOCUMENT, 'LOCALE', rm_none(\n            {'LANGUAGE_CODE': lc, 'COUNTRY_CODE': cc, 'VARIANT': vr}))\n    # Languages\n    for lid, (ldef, label) in eaf_obj.languages.items():\n        etree.SubElement(ADOCUMENT, 'LANGUAGE', rm_none(\n            {'LANG_ID': lid, 'LANG_DEF': ldef, 'LANG_LABEL': label}))\n    # Constraints\n    for l in eaf_obj.constraints.items():\n        etree.SubElement(ADOCUMENT, 'CONSTRAINT', rm_none(\n            {'STEREOTYPE': l[0], 'DESCRIPTION': l[1]}))\n    # Controlled vocabularies\n    for cvid, (descriptions, cv_entries, ext_ref) in\\\n            eaf_obj.controlled_vocabularies.items():\n        cv = etree.SubElement(ADOCUMENT, 'CONTROLLED_VOCABULARY',\n                              rm_none({'CV_ID': cvid, 'EXT_REF': ext_ref}))\n        for lang_ref, description in descriptions:\n            des = etree.SubElement(cv, 'DESCRIPTION', {'LANG_REF': lang_ref})\n            if description:\n                des.text = description\n        for cveid, (values, ext_ref) in cv_entries.items():\n            cem = etree.SubElement(cv, 'CV_ENTRY_ML', rm_none({\n                'CVE_ID': cveid, 'EXT_REF': ext_ref}))\n            for value, lang_ref, description in values:\n                val = etree.SubElement(cem, 'CVE_VALUE', rm_none({\n                    'LANG_REF': lang_ref, 'DESCRIPTION': description}))\n                val.text = value\n    # Lexicon refs\n    for l in eaf_obj.lexicon_refs.values():\n        etree.SubElement(ADOCUMENT, 'LEXICON_REF', rm_none(l))\n    # Exteral refs\n    for eid, (etype, value) in eaf_obj.external_refs.items():\n        etree.SubElement(ADOCUMENT, 'EXTERNAL_REF', rm_none(\n            {'EXT_REF_ID': eid, 'TYPE': etype, 'VALUE': value}))\n\n    if pretty:\n        indent(ADOCUMENT)\n    if file_path == '-':\n        try:\n            sys.stdout.write(etree.tostring(ADOCUMENT, encoding='unicode'))\n        except LookupError:\n            sys.stdout.write(etree.tostring(ADOCUMENT, encoding='UTF-8'))\n    else:\n        if os.access(file_path, os.F_OK):\n            os.rename(file_path, '{}.bak'.format(file_path))\n        etree.ElementTree(ADOCUMENT).write(\n            file_path, xml_declaration=True, encoding='UTF-8')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_annotation(self, id_tier, start, end, value='', svg_ref=None):\n        if self.tiers[id_tier][1]:\n            raise ValueError('Tier already contains ref annotations...')\n        if start == end:\n            raise ValueError('Annotation length is zero...')\n        if start > end:\n            raise ValueError('Annotation length is negative...')\n        if start < 0:\n            raise ValueError('Start is negative...')\n        start_ts = self.generate_ts_id(start)\n        end_ts = self.generate_ts_id(end)\n        aid = self.generate_annotation_id()\n        self.annotations[aid] = id_tier\n        self.tiers[id_tier][0][aid] = (start_ts, end_ts, value, svg_ref)", "response": "Adds an annotation to the metadata."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds an entry to a controlled vocabulary.", "response": "def add_cv_entry(self, cv_id, cve_id, values, ext_ref=None):\n        \"\"\"Add an entry to a controlled vocabulary.\n\n        :param str cv_id: Name of the controlled vocabulary to add an entry.\n        :param str cve_id: Name of the entry.\n        :param list values: List of values of the form:\n            ``(value, lang_ref, description)`` where description can be\n            ``None``.\n        :param str ext_ref: External reference.\n        :throws KeyError: If there is no controlled vocabulary with that id.\n        :throws ValueError: If a language in one of the entries doesn't exist.\n        \"\"\"\n        for value, lang_ref, description in values:\n            if lang_ref not in self.languages:\n                raise ValueError('Language not present: {}'.format(lang_ref))\n        self.controlled_vocabularies[cv_id][1][cve_id] = (values, ext_ref)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_cv_description(self, cv_id, lang_ref, description=None):\n        if lang_ref not in self.languages:\n            raise ValueError('Language not present: {}'.format(lang_ref))\n        self.controlled_vocabularies[cv_id][0].append((lang_ref, description))", "response": "Adds a description to a controlled vocabulary."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd an external reference.", "response": "def add_external_ref(self, eid, etype, value):\n        \"\"\"Add an external reference.\n\n        :param str eid: Name of the external reference.\n        :param str etype: Type of the external reference, has to be in\n            ``['iso12620', 'ecv', 'cve_id', 'lexen_id', 'resource_url']``.\n        :param str value: Value of the external reference.\n        :throws KeyError: if etype is not in the list of possible types.\n        \"\"\"\n        if etype not in self.ETYPES:\n            raise KeyError('etype not in {}'.format(self.ETYPES))\n        self.external_refs[eid] = (etype, value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a language. :param str lang_id: ID of the language. :param str lang_def: Definition of the language(preferably ISO-639-3). :param str lang_label: Label of the language.", "response": "def add_language(self, lang_id, lang_def=None, lang_label=None):\n        \"\"\"Add a language.\n\n        :param str lang_id: ID of the language.\n        :param str lang_def: Definition of the language(preferably ISO-639-3).\n        :param str lang_label: Label of the language.\n        \"\"\"\n        self.languages[lang_id] = (lang_def, lang_label)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a new lexicon reference.", "response": "def add_lexicon_ref(self, lrid, name, lrtype, url, lexicon_id,\n                        lexicon_name, datcat_id=None, datcat_name=None):\n        \"\"\"Add lexicon reference.\n\n        :param str lrid: Lexicon reference internal ID.\n        :param str name: Lexicon reference display name.\n        :param str lrtype: Lexicon reference service type.\n        :param str url: Lexicon reference service location\n        :param str lexicon_id: Lexicon reference service id.\n        :param str lexicon_name: Lexicon reference service name.\n        :param str datacat_id: Lexicon reference identifier of data category.\n        :param str datacat_name: Lexicon reference name of data category.\n        \"\"\"\n        self.lexicon_refs[lrid] = {\n            'LEX_REF_ID': lrid,\n            'NAME': name,\n            'TYPE': lrtype,\n            'URL': url,\n            'LEXICON_ID': lexicon_id,\n            'LEXICON_NAME': lexicon_name,\n            'DATCAT_ID': datcat_id,\n            'DATCAT_NAME': datcat_name\n            }"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a linguistic type to the list of linguistic types in the resource.", "response": "def add_linguistic_type(self, lingtype, constraints=None,\n                            timealignable=True, graphicreferences=False,\n                            extref=None, param_dict=None):\n        \"\"\"Add a linguistic type.\n\n        :param str lingtype: Name of the linguistic type.\n        :param str constraints: Constraint name.\n        :param bool timealignable: Flag for time alignable.\n        :param bool graphicreferences: Flag for graphic references.\n        :param str extref: External reference.\n        :param dict param_dict: TAG attributes, when this is not ``None`` it\n                                 will ignore all other options. Please only use\n                                 dictionaries coming from the\n                                 :func:`get_parameters_for_linguistic_type`\n        :raises KeyError: If a constraint is not defined\n        \"\"\"\n        if param_dict:\n            self.linguistic_types[lingtype] = param_dict\n        else:\n            if constraints:\n                self.constraints[constraints]\n            self.linguistic_types[lingtype] = {\n                'LINGUISTIC_TYPE_ID': lingtype,\n                'TIME_ALIGNABLE': str(timealignable).lower(),\n                'GRAPHIC_REFERENCES': str(graphicreferences).lower(),\n                'CONSTRAINTS': constraints}\n            if extref is not None:\n                self.linguistic_types[lingtype]['EXT_REF'] = extref"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_linked_file(self, file_path, relpath=None, mimetype=None,\n                        time_origin=None, ex_from=None):\n        \"\"\"Add a linked file.\n\n        :param str file_path: Path of the file.\n        :param str relpath: Relative path of the file.\n        :param str mimetype: Mimetype of the file, if ``None`` it tries to\n            guess it according to the file extension which currently only works\n            for wav, mpg, mpeg and xml.\n        :param int time_origin: Time origin for the media file.\n        :param str ex_from: Extracted from field.\n        :raises KeyError: If mimetype had to be guessed and a non standard\n                          extension or an unknown mimetype.\n        \"\"\"\n        if mimetype is None:\n            mimetype = self.MIMES[file_path.split('.')[-1]]\n        self.media_descriptors.append({\n            'MEDIA_URL': file_path, 'RELATIVE_MEDIA_URL': relpath,\n            'MIME_TYPE': mimetype, 'TIME_ORIGIN': time_origin,\n            'EXTRACTED_FROM': ex_from})", "response": "Adds a linked file to the media_descriptors list."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_locale(self, language_code, country_code=None, variant=None):\n        self.locales[language_code] = (country_code, variant)", "response": "Add a locale to the locale table."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_ref_annotation(self, id_tier, tier2, time, value='',\n                           prev=None, svg=None):\n        \"\"\"Add a reference annotation.\n        .. note:: When a timepoint matches two annotations the new reference\n        annotation will reference to the first annotation. To circumvent this\n        it's always safer to take the middle of the annotation you want to\n        reference to.\n\n        :param str id_tier: Name of the tier.\n        :param str tier2: Tier of the referenced annotation.\n        :param int time: Time of the referenced annotation.\n        :param str value: Value of the annotation.\n        :param str prev: Id of the previous annotation.\n        :param str svg_ref: Svg reference.\n        :raises KeyError: If the tier is non existent.\n        :raises ValueError: If the tier already contains normal annotations or\n            if there is no annotation in the tier on the time to reference to.\n        \"\"\"\n        if self.tiers[id_tier][0]:\n            raise ValueError('This tier already contains normal annotations.')\n        ann = None\n        for aid, (begin, end, _, _) in self.tiers[tier2][0].items():\n            begin = self.timeslots[begin]\n            end = self.timeslots[end]\n            if begin <= time and end >= time:\n                ann = aid\n                break\n        if not ann:\n            raise ValueError('There is no annotation to reference to.')\n        aid = self.generate_annotation_id()\n        self.annotations[aid] = id_tier\n        self.tiers[id_tier][1][aid] = (ann, value, prev, svg)", "response": "Add a reference annotation to the given timepoint."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a secondary linked file.", "response": "def add_secondary_linked_file(self, file_path, relpath=None, mimetype=None,\n                                  time_origin=None, assoc_with=None):\n        \"\"\"Add a secondary linked file.\n\n        :param str file_path: Path of the file.\n        :param str relpath: Relative path of the file.\n        :param str mimetype: Mimetype of the file, if ``None`` it tries to\n            guess it according to the file extension which currently only works\n            for wav, mpg, mpeg and xml.\n        :param int time_origin: Time origin for the media file.\n        :param str assoc_with: Associated with field.\n        :raises KeyError: If mimetype had to be guessed and a non standard\n                          extension or an unknown mimetype.\n        \"\"\"\n        if mimetype is None:\n            mimetype = self.MIMES[file_path.split('.')[-1]]\n        self.linked_file_descriptors.append({\n            'LINK_URL': file_path, 'RELATIVE_LINK_URL': relpath,\n            'MIME_TYPE': mimetype, 'TIME_ORIGIN': time_origin,\n            'ASSOCIATED_WITH': assoc_with})"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_tier(self, tier_id, ling='default-lt', parent=None, locale=None,\n                 part=None, ann=None, language=None, tier_dict=None):\n        \"\"\"Add a tier. When no linguistic type is given and the default\n        linguistic type is unavailable then the assigned linguistic type will\n        be the first in the list.\n\n        :param str tier_id: Name of the tier.\n        :param str ling: Linguistic type, if the type is not available it will\n                         warn and pick the first available type.\n        :param str parent: Parent tier name.\n        :param str locale: Locale, if the locale is not present this option is\n            ignored and the locale will not be set.\n        :param str part: Participant.\n        :param str ann: Annotator.\n        :param str language: Language , if the language is not present this\n            option is ignored and the language will not be set.\n        :param dict tier_dict: TAG attributes, when this is not ``None`` it\n                               will ignore all other options. Please only use\n                               dictionaries coming from the\n                               :func:`get_parameters_for_tier`\n        :raises ValueError: If the tier_id is empty\n        \"\"\"\n        if not tier_id:\n            raise ValueError('Tier id is empty...')\n        if ling not in self.linguistic_types:\n            ling = sorted(self.linguistic_types.keys())[0]\n        if locale and locale not in self.locales:\n            locale = None\n        if language and language not in self.languages:\n            language = None\n        if tier_dict is None:\n            self.tiers[tier_id] = ({}, {}, {\n                'TIER_ID': tier_id,\n                'LINGUISTIC_TYPE_REF': ling,\n                'PARENT_REF': parent,\n                'PARTICIPANT': part,\n                'DEFAULT_LOCALE': locale,\n                'LANG_REF': language,\n                'ANNOTATOR': ann}, len(self.tiers))\n        else:\n            self.tiers[tier_id] = ({}, {}, tier_dict, len(self.tiers))", "response": "Add a tier to the list of available linguistics."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef clean_time_slots(self):\n        ts = ((a[0], a[1]) for t in self.tiers.values() for a in t[0].values())\n        for a in {a for b in ts for a in b} ^ set(self.timeslots):\n            del(self.timeslots[a])", "response": "Clean up all unused timeslots."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef copy_tier(self, eaf_obj, tier_name):\n        if tier_name in eaf_obj.get_tier_names():\n            eaf_obj.remove_tier(tier_name)\n        eaf_obj.add_tier(tier_name,\n                         tier_dict=self.get_parameters_for_tier(tier_name))\n        for ann in self.get_annotation_data_for_tier(tier_name):\n            eaf_obj.insert_annotation(tier_name, ann[0], ann[1], ann[2])", "response": "Copies a tier to another."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_gaps_and_overlaps_tier(self, tier1, tier2, tier_name=None,\n                                      maxlen=-1, fast=False):\n        \"\"\"Create a tier with the gaps and overlaps of the annotations.\n        For types see :func:`get_gaps_and_overlaps`\n\n        :param str tier1: Name of the first tier.\n        :param str tier2: Name of the second tier.\n        :param str tier_name: Name of the new tier, if ``None`` the name will\n                              be generated.\n        :param int maxlen: Maximum length of gaps (skip longer ones), if ``-1``\n                           no maximum will be used.\n        :param bool fast: Flag for using the fast method.\n        :returns: List of gaps and overlaps of the form:\n                  ``[(type, start, end)]``.\n        :raises KeyError: If a tier is non existent.\n        :raises IndexError: If no annotations are available in the tiers.\n        \"\"\"\n        if tier_name is None:\n            tier_name = '{}_{}_ftos'.format(tier1, tier2)\n        self.add_tier(tier_name)\n        ftos = []\n        ftogen = self.get_gaps_and_overlaps2(tier1, tier2, maxlen) if fast\\\n            else self.get_gaps_and_overlaps(tier1, tier2, maxlen)\n        for fto in ftogen:\n            ftos.append(fto)\n            if fto[1]-fto[0] >= 1:\n                self.add_annotation(tier_name, fto[0], fto[1], fto[2])\n        self.clean_time_slots()\n        return ftos", "response": "Create a new tier with the gaps and overlaps of the annotations."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef extract(self, start, end):\n        from copy import deepcopy\n        eaf_out = deepcopy(self)\n        for t in eaf_out.get_tier_names():\n            for ab, ae, value in eaf_out.get_annotation_data_for_tier(t):\n                if ab > end or ae < start:\n                    eaf_out.remove_annotation(t, (start-end)//2, False)\n        eaf_out.clean_time_slots()\n        return eaf_out", "response": "Extracts the selected time frame as a new object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef filter_annotations(self, tier, tier_name=None, filtin=None,\n                           filtex=None, regex=False, safe=False):\n        \"\"\"Filter annotations in a tier using an exclusive and/or inclusive\n        filter.\n\n        :param str tier: Name of the tier.\n        :param str tier_name: Name of the output tier, when ``None`` the name\n            will be generated.\n        :param list filtin: List of strings to be included, if None all\n            annotations all is included.\n        :param list filtex: List of strings to be excluded, if None no strings\n            are excluded.\n        :param bool regex: If this flag is set, the filters are seen as regex\n            matches.\n        :param bool safe: Ignore zero length annotations(when working with\n            possible malformed data).\n        :returns: Name of the created tier.\n        :raises KeyError: If the tier is non existent.\n        \"\"\"\n        if tier_name is None:\n            tier_name = '{}_filter'.format(tier)\n        self.add_tier(tier_name)\n        func = (lambda x, y: re.match(x, y)) if regex else lambda x, y: x == y\n        for begin, end, value in self.get_annotation_data_for_tier(tier):\n            if (filtin and not any(func(f, value) for f in filtin)) or\\\n                    (filtex and any(func(f, value) for f in filtex)):\n                continue\n            if not safe or end > begin:\n                self.add_annotation(tier_name, begin, end, value)\n        self.clean_time_slots()\n        return tier_name", "response": "Filter the annotations in a tier using an exclusive and or inclusive filter."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef generate_annotation_id(self):\n        if not self.maxaid:\n            valid_anns = [int(''.join(filter(str.isdigit, a)))\n                          for a in self.timeslots]\n            self.maxaid = max(valid_anns + [1])+1\n        else:\n            self.maxaid += 1\n        return 'a{:d}'.format(self.maxaid)", "response": "Generate the next annotation id. This function is mainly used\n        internally."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate the next timeslot id, this function is mainly used internally :param int time: Initial time to assign to the timeslot. :raises ValueError: If the time is negative.", "response": "def generate_ts_id(self, time=None):\n        \"\"\"Generate the next timeslot id, this function is mainly used\n        internally\n\n        :param int time: Initial time to assign to the timeslot.\n        :raises ValueError: If the time is negative.\n        \"\"\"\n        if time and time < 0:\n            raise ValueError('Time is negative...')\n        if not self.maxts:\n            valid_ts = [int(''.join(filter(str.isdigit, a)))\n                        for a in self.timeslots]\n            self.maxts = max(valid_ts + [1])+1\n        else:\n            self.maxts += 1\n        ts = 'ts{:d}'.format(self.maxts)\n        self.timeslots[ts] = time\n        return ts"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_annotation_data_at_time(self, id_tier, time):\n        if self.tiers[id_tier][1]:\n            return self.get_ref_annotation_at_time(id_tier, time)\n        anns = self.tiers[id_tier][0]\n        return sorted([(self.timeslots[m[0]], self.timeslots[m[1]], m[2])\n                       for m in anns.values() if\n                       self.timeslots[m[0]] <= time and\n                       self.timeslots[m[1]] >= time])", "response": "Give the annotations at the given time."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngive the annotation before a given time.", "response": "def get_annotation_data_after_time(self, id_tier, time):\n        \"\"\"Give the annotation before a given time. When the tier contains\n        reference annotations this will be returned, check\n        :func:`get_ref_annotation_data_before_time` for the format. If an\n        annotation overlaps with ``time`` that annotation will be returned.\n\n        :param str id_tier: Name of the tier.\n        :param int time: Time to get the annotation before.\n        :raises KeyError: If the tier is non existent.\n        \"\"\"\n        if self.tiers[id_tier][1]:\n            return self.get_ref_annotation_after_time(id_tier, time)\n        befores = self.get_annotation_data_between_times(\n            id_tier, time, self.get_full_time_interval()[1])\n        if befores:\n            return [min(befores, key=lambda x: x[0])]\n        else:\n            return []"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_annotation_data_before_time(self, id_tier, time):\n        if self.tiers[id_tier][1]:\n            return self.get_ref_annotation_before_time(id_tier, time)\n        befores = self.get_annotation_data_between_times(id_tier, 0, time)\n        if befores:\n            return [max(befores, key=lambda x: x[0])]\n        else:\n            return []", "response": "Give the annotation before a given time."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the list of annotations within the times.", "response": "def get_annotation_data_between_times(self, id_tier, start, end):\n        \"\"\"Gives the annotations within the times.\n        When the tier contains reference annotations this will be returned,\n        check :func:`get_ref_annotation_data_between_times` for the format.\n\n        :param str id_tier: Name of the tier.\n        :param int start: Start time of the annotation.\n        :param int end: End time of the annotation.\n        :returns: List of annotations within that time.\n        :raises KeyError: If the tier is non existent.\n        \"\"\"\n        if self.tiers[id_tier][1]:\n            return self.get_ref_annotation_data_between_times(\n                id_tier, start, end)\n        anns = ((self.timeslots[a[0]], self.timeslots[a[1]], a[2])\n                for a in self.tiers[id_tier][0].values())\n        return sorted(a for a in anns if a[1] >= start and a[0] <= end)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_annotation_data_for_tier(self, id_tier):\n        if self.tiers[id_tier][1]:\n            return self.get_ref_annotation_data_for_tier(id_tier)\n        a = self.tiers[id_tier][0]\n        return [(self.timeslots[a[b][0]], self.timeslots[a[b][1]], a[b][2])\n                for b in a]", "response": "Returns a list of annotations for the given tier."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_child_tiers_for(self, id_tier):\n        self.tiers[id_tier]\n        return [m for m in self.tiers if 'PARENT_REF' in self.tiers[m][2] and\n                self.tiers[m][2]['PARENT_REF'] == id_tier]", "response": "Give all child tiers for a tier."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngives the full time interval of the file.", "response": "def get_full_time_interval(self):\n        \"\"\"Give the full time interval of the file. Note that the real interval\n        can be longer because the sound file attached can be longer.\n\n        :returns: Tuple of the form: ``(min_time, max_time)``.\n        \"\"\"\n        return (0, 0) if not self.timeslots else\\\n            (min(self.timeslots.values()), max(self.timeslots.values()))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngives gaps and overlaps.", "response": "def get_gaps_and_overlaps(self, tier1, tier2, maxlen=-1):\n        \"\"\"Give gaps and overlaps. The return types are shown in the table\n        below. The string will be of the format: ``id_tiername_tiername``.\n\n        .. note:: There is also a faster method: :func:`get_gaps_and_overlaps2`\n\n        For example when a gap occurs between tier1 and tier2 and they are\n        called ``speakerA`` and ``speakerB`` the annotation value of that gap\n        will be ``G12_speakerA_speakerB``.\n\n        | The gaps and overlaps are calculated using Heldner and Edlunds\n          method found in:\n        | *Heldner, M., & Edlund, J. (2010). Pauses, gaps and overlaps in\n          conversations. Journal of Phonetics, 38(4), 555\u2013568.\n          doi:10.1016/j.wocn.2010.08.002*\n\n        +-----+---------------------------------------------+\n        | id  | Description                                 |\n        +=====+=============================================+\n        | O12 | Overlap from tier1 to tier2                 |\n        +-----+---------------------------------------------+\n        | O21 | Overlap from tier2 to tier1                 |\n        +-----+---------------------------------------------+\n        | G12 | Between speaker gap from tier1 to tier2     |\n        +-----+---------------------------------------------+\n        | G21 | Between speaker gap from tier2 to tier1     |\n        +-----+---------------------------------------------+\n        | W12 | Within speaker overlap from tier2 in tier1  |\n        +-----+---------------------------------------------+\n        | W21 | Within speaker overlap from tier1 in tier2  |\n        +-----+---------------------------------------------+\n        | P1  | Pause for tier1                             |\n        +-----+---------------------------------------------+\n        | P2  | Pause for tier2                             |\n        +-----+---------------------------------------------+\n\n        :param str tier1: Name of the first tier.\n        :param str tier2: Name of the second tier.\n        :param int maxlen: Maximum length of gaps (skip longer ones), if ``-1``\n                           no maximum will be used.\n        :yields: Tuples of the form ``[(start, end, type)]``.\n        :raises KeyError: If a tier is non existent.\n        :raises IndexError: If no annotations are available in the tiers.\n        \"\"\"\n        spkr1anns = sorted((self.timeslots[a[0]], self.timeslots[a[1]])\n                           for a in self.tiers[tier1][0].values())\n        spkr2anns = sorted((self.timeslots[a[0]], self.timeslots[a[1]])\n                           for a in self.tiers[tier2][0].values())\n        line1 = []\n\n        def isin(x, lst):\n            return False if\\\n                len([i for i in lst if i[0] <= x and i[1] >= x]) == 0 else True\n        minmax = (min(spkr1anns[0][0], spkr2anns[0][0]),\n                  max(spkr1anns[-1][1], spkr2anns[-1][1]))\n        last = (1, minmax[0])\n        for ts in range(*minmax):\n            in1, in2 = isin(ts, spkr1anns), isin(ts, spkr2anns)\n            if in1 and in2:      # Both speaking\n                if last[0] == 'B':\n                    continue\n                ty = 'B'\n            elif in1:            # Only 1 speaking\n                if last[0] == '1':\n                    continue\n                ty = '1'\n            elif in2:            # Only 2 speaking\n                if last[0] == '2':\n                    continue\n                ty = '2'\n            else:                # None speaking\n                if last[0] == 'N':\n                    continue\n                ty = 'N'\n            line1.append((last[0], last[1], ts))\n            last = (ty, ts)\n        line1.append((last[0], last[1], minmax[1]))\n        for i in range(len(line1)):\n            if line1[i][0] == 'N':\n                if i != 0 and i < len(line1) - 1 and\\\n                        line1[i-1][0] != line1[i+1][0]:\n                    t = ('G12', tier1, tier2) if line1[i-1][0] == '1' else\\\n                        ('G21', tier2, tier1)\n                    if maxlen == -1 or abs(line1[i][1]-line1[i][2]) < maxlen:\n                        yield (line1[i][1], line1[i][2]-1, '_'.join(t))\n                else:\n                    t = ('P1', tier1) if line1[i-1][0] == '1' else\\\n                        ('P2', tier2)\n                    if maxlen == -1 or abs(line1[i][1]-line1[i][2]) < maxlen:\n                        yield (line1[i][1], line1[i][2]-1, '_'.join(t))\n            elif line1[i][0] == 'B':\n                if i != 0 and i < len(line1) - 1 and\\\n                        line1[i-1][0] != line1[i+1][0]:\n                    t = ('O12', tier1, tier2) if line1[i-1][0] == '1' else\\\n                        ('O21', tier2, tier1)\n                    yield (line1[i][1], line1[i][2]-1, '_'.join(t))\n                else:\n                    t = ('W12', tier1, tier2) if line1[i-1][0] == '1' else\\\n                        ('W21', tier2, tier1)\n                    yield (line1[i][1], line1[i][2]-1, '_'.join(t))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_gaps_and_overlaps2(self, tier1, tier2, maxlen=-1):\n        ad = sorted(((a, i+1) for i, t in enumerate([tier1, tier2]) for a in\n                     self.get_annotation_data_for_tier(t)), reverse=True)\n        if ad:\n            last = (lambda x: (x[0][0], x[0][1], x[1]))(ad.pop())\n\n            def thr(x, y):\n                return maxlen == -1 or abs(x-y) < maxlen\n            while ad:\n                (begin, end, _), current = ad.pop()\n                if last[2] == current and thr(begin, last[1]):\n                    yield (last[1], begin, 'P{}'.format(current))\n                elif last[0] < begin and last[1] > end:\n                    yield (begin, end, 'W{}{}'.format(last[2], current))\n                    continue\n                elif last[1] > begin:\n                    yield (begin, last[1], 'O{}{}'.format(last[2], current))\n                elif last[1] < begin and thr(begin, last[1]):\n                    yield (last[1], begin, 'G{}{}'.format(last[2], current))\n                last = (begin, end, current)", "response": "A generator function that yields tuples of the first and last gaps and overlapped gaps."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngives the ref annotations at the given time of the form [ begin end value refvalue ]", "response": "def get_ref_annotation_at_time(self, tier, time):\n        \"\"\"Give the ref annotations at the given time of the form\n        ``[(start, end, value, refvalue)]``\n\n        :param str tier: Name of the tier.\n        :param int time: Time of the annotation of the parent.\n        :returns: List of annotations at that time.\n        :raises KeyError: If the tier is non existent.\n        \"\"\"\n        bucket = []\n        for aid, (ref, value, _, _) in self.tiers[tier][1].items():\n            begin, end, rvalue, _ = self.tiers[self.annotations[ref]][0][ref]\n            begin = self.timeslots[begin]\n            end = self.timeslots[end]\n            if begin <= time and end >= time:\n                bucket.append((begin, end, value, rvalue))\n        return bucket"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngive the ref annotation after a time.", "response": "def get_ref_annotation_data_after_time(self, id_tier, time):\n        \"\"\"Give the ref annotation after a time. If an annotation overlaps\n        with `ktime`` that annotation will be returned.\n\n        :param str id_tier: Name of the tier.\n        :param int time: Time to get the annotation after.\n        :returns: Annotation after that time in a list\n        :raises KeyError: If the tier is non existent.\n        \"\"\"\n        befores = self.get_ref_annotation_data_between_times(\n            id_tier, time, self.get_full_time_interval())\n        if befores:\n            return [min(befores, key=lambda x: x[0])]\n        else:\n            return []"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_ref_annotation_data_before_time(self, id_tier, time):\n        befores = self.get_ref_annotation_data_between_times(id_tier, 0, time)\n        if befores:\n            return [max(befores, key=lambda x: x[0])]\n        else:\n            return []", "response": "Give the ref annotation before a time."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngiving the ref annotations between times of the form [ start end value refvalue )", "response": "def get_ref_annotation_data_between_times(self, id_tier, start, end):\n        \"\"\"Give the ref annotations between times of the form\n        ``[(start, end, value, refvalue)]``\n\n        :param str tier: Name of the tier.\n        :param int start: End time of the annotation of the parent.\n        :param int end: Start time of the annotation of the parent.\n        :returns: List of annotations at that time.\n        :raises KeyError: If the tier is non existent.\n        \"\"\"\n        bucket = []\n        for aid, (ref, value, _, _) in self.tiers[id_tier][1].items():\n            begin, end, rvalue, _ = self.tiers[self.annotations[ref]][0][ref]\n            begin = self.timeslots[begin]\n            end = self.timeslots[end]\n            if begin <= end and end >= begin:\n                bucket.append((begin, end, value, rvalue))\n        return bucket"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngive a list of all reference annotations of the form : start end value refvalue", "response": "def get_ref_annotation_data_for_tier(self, id_tier):\n        \"\"\"\"Give a list of all reference annotations of the form:\n        ``[(start, end, value, refvalue)]``\n\n        :param str id_tier: Name of the tier.\n        :raises KeyError: If the tier is non existent.\n        :returns: Reference annotations within that tier.\n        \"\"\"\n        bucket = []\n        for aid, (ref, value, prev, _) in self.tiers[id_tier][1].items():\n            refann = self.get_parent_aligned_annotation(ref)\n            bucket.append((self.timeslots[refann[0]],\n                           self.timeslots[refann[1]], value, refann[2]))\n        return bucket"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngiving the aligment annotation that a reference annotation belongs to directly or indirectly through other reference annotations.", "response": "def get_parent_aligned_annotation(self, ref_id):\n        \"\"\"\" Give the aligment annotation that a reference annotation belongs to directly, or indirectly through other\n        reference annotations.\n        :param str ref_id: Id of a reference annotation.\n        :raises KeyError: If no annotation exists with the id or if it belongs to an alignment annotation.\n        :returns: The alignment annotation at the end of the reference chain.\n        \"\"\"\n        parentTier = self.tiers[self.annotations[ref_id]]\n        while \"PARENT_REF\" in parentTier[2] and len(parentTier[2]) > 0:\n            ref_id = parentTier[1][ref_id][0]\n            parentTier = self.tiers[self.annotations[ref_id]]\n\n        return parentTier[0][ref_id]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_tier_ids_for_linguistic_type(self, ling_type, parent=None):\n        return [t for t in self.tiers if\n                self.tiers[t][2]['LINGUISTIC_TYPE_REF'] == ling_type and\n                (parent is None or self.tiers[t][2]['PARENT_REF'] == parent)]", "response": "Give a list of all tiers matching a linguistic type."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef insert_annotation(self, id_tier, start, end, value='', svg_ref=None):\n        return self.add_annotation(id_tier, start, end, value, svg_ref)", "response": "Insert an annotation into the cache."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef insert_ref_annotation(self, id_tier, tier2, time, value='',\n                              prev=None, svg=None):\n        \"\"\".. deprecated:: 1.2\n\n        Use :func:`add_ref_annotation` instead.\n        \"\"\"\n        return self.add_ref_annotation(id_tier, tier2, time, value, prev, svg)", "response": "Insert a new ref annotation into the cache."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef merge_tiers(self, tiers, tiernew=None, gapt=0, sep='_', safe=False):\n        if tiernew is None:\n            tiernew = u'{}_merged'.format('_'.join(tiers))\n        self.add_tier(tiernew)\n        aa = [(sys.maxsize, sys.maxsize, None)] + sorted((\n            a for t in tiers for a in self.get_annotation_data_for_tier(t)),\n            reverse=True)\n        l = None\n        while aa:\n            begin, end, value = aa.pop()\n            if l is None:\n                l = [begin, end, [value]]\n            elif begin - l[1] >= gapt:\n                if not safe or l[1] > l[0]:\n                    self.add_annotation(tiernew, l[0], l[1], sep.join(l[2]))\n                l = [begin, end, [value]]\n            else:\n                if end > l[1]:\n                    l[1] = end\n                l[2].append(value)\n        return tiernew", "response": "Merge tiers into a new tier and optionally add annotations to the new tier."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove all annotations from a tier", "response": "def remove_all_annotations_from_tier(self, id_tier, clean=True):\n        \"\"\"remove all annotations from a tier\n\n        :param str id_tier: Name of the tier.\n        :raises KeyError: If the tier is non existent.\n        \"\"\"\n        for aid in self.tiers[id_tier][0]:\n            del(self.annotations[aid])\n        for aid in self.tiers[id_tier][1]:\n            del(self.annotations[aid])\n\n        self.tiers[id_tier][0].clear()\n        self.tiers[id_tier][1].clear()\n        if clean:\n            self.clean_time_slots()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove an annotation in a tier.", "response": "def remove_annotation(self, id_tier, time, clean=True):\n        \"\"\"Remove an annotation in a tier, if you need speed the best thing is\n        to clean the timeslots after the last removal. When the tier contains\n        reference annotations :func:`remove_ref_annotation` will be executed\n        instead.\n\n        :param str id_tier: Name of the tier.\n        :param int time: Timepoint within the annotation.\n        :param bool clean: Flag to clean the timeslots afterwards.\n        :raises KeyError: If the tier is non existent.\n        :returns: Number of removed annotations.\n        \"\"\"\n        if self.tiers[id_tier][1]:\n            return self.remove_ref_annotation(id_tier, time, clean)\n        removed = 0\n        for b in [a for a in self.tiers[id_tier][0].items() if\n                  self.timeslots[a[1][0]] <= time and\n                  self.timeslots[a[1][1]] >= time]:\n            del(self.tiers[id_tier][0][b[0]])\n            del(self.annotations[b[0]])\n            removed += 1\n        if clean:\n            self.clean_time_slots()\n        return removed"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef remove_cv_description(self, cv_id, lang_ref):\n        for i, (l, d) in reversed(enumerate(\n                self.controlled_vocabularies[cv_id][1])):\n            if l == lang_ref:\n                del(self.controlled_vocabularies[cv_id][1][i])", "response": "Removes a description from a controlled vocabulary."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove all licenses matching both key and value.", "response": "def remove_license(self, name=None, url=None):\n        \"\"\"Remove all licenses matching both key and value.\n\n        :param str name: Name of the license.\n        :param str url: URL of the license.\n        \"\"\"\n        for k, v in self.licenses[:]:\n            if (name is None or name == k) and (url is None or url == v):\n                del(self.licenses[self.licenses.index((k, v))])"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves all linked files that match all the criteria.", "response": "def remove_linked_files(self, file_path=None, relpath=None, mimetype=None,\n                            time_origin=None, ex_from=None):\n        \"\"\"Remove all linked files that match all the criteria, criterias that\n        are ``None`` are ignored.\n\n        :param str file_path: Path of the file.\n        :param str relpath: Relative filepath.\n        :param str mimetype: Mimetype of the file.\n        :param int time_origin: Time origin.\n        :param str ex_from: Extracted from.\n        \"\"\"\n        for attrib in self.media_descriptors[:]:\n            if file_path is not None and attrib['MEDIA_URL'] != file_path:\n                continue\n            if relpath is not None and attrib['RELATIVE_MEDIA_URL'] != relpath:\n                continue\n            if mimetype is not None and attrib['MIME_TYPE'] != mimetype:\n                continue\n            if time_origin is not None and\\\n                    attrib['TIME_ORIGIN'] != time_origin:\n                continue\n            if ex_from is not None and attrib['EXTRACTED_FROM'] != ex_from:\n                continue\n            del(self.media_descriptors[self.media_descriptors.index(attrib)])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove a property from the resource table.", "response": "def remove_property(self, key=None, value=None):\n        \"\"\"Remove all properties matching both key and value.\n\n        :param str key: Key of the property.\n        :param str value: Value of the property.\n        \"\"\"\n        for k, v in self.properties[:]:\n            if (key is None or key == k) and (value is None or value == v):\n                del(self.properties[self.properties.index((k, v))])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef remove_ref_annotation(self, id_tier, time):\n        removed = 0\n        bucket = []\n        for aid, (ref, value, _, _) in self.tiers[id_tier][1].items():\n            begin, end, rvalue, _ = self.tiers[self.annotations[ref]][0][ref]\n            begin = self.timeslots[begin]\n            end = self.timeslots[end]\n            if begin <= time and end >= time:\n                removed += 1\n                bucket.append(aid)\n        for aid in bucket:\n            del(self.tiers[id_tier][1][aid])\n        return removed", "response": "Removes a reference annotation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove all secondary linked files that match all the criteria.", "response": "def remove_secondary_linked_files(self, file_path=None, relpath=None,\n                                      mimetype=None, time_origin=None,\n                                      assoc_with=None):\n        \"\"\"Remove all secondary linked files that match all the criteria,\n        criterias that are ``None`` are ignored.\n\n        :param str file_path: Path of the file.\n        :param str relpath: Relative filepath.\n        :param str mimetype: Mimetype of the file.\n        :param int time_origin: Time origin.\n        :param str ex_from: Extracted from.\n        \"\"\"\n        for attrib in self.linked_file_descriptors[:]:\n            if file_path is not None and attrib['LINK_URL'] != file_path:\n                continue\n            if relpath is not None and attrib['RELATIVE_LINK_URL'] != relpath:\n                continue\n            if mimetype is not None and attrib['MIME_TYPE'] != mimetype:\n                continue\n            if time_origin is not None and\\\n                    attrib['TIME_ORIGIN'] != time_origin:\n                continue\n            if assoc_with is not None and\\\n                    attrib['ASSOCIATED_WITH'] != assoc_with:\n                continue\n            del(self.linked_file_descriptors[\n                self.linked_file_descriptors.index(attrib)])"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves a tier from the cache.", "response": "def remove_tier(self, id_tier, clean=True):\n        \"\"\"Remove a tier.\n\n        :param str id_tier: Name of the tier.\n        :param bool clean: Flag to also clean the timeslots.\n        :raises KeyError: If tier is non existent.\n        \"\"\"\n        del(self.tiers[id_tier])\n        if clean:\n            self.clean_time_slots()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nremoves multiple tiers from the cache.", "response": "def remove_tiers(self, tiers):\n        \"\"\"Remove multiple tiers, note that this is a lot faster then removing\n        them individually because of the delayed cleaning of timeslots.\n\n        :param list tiers: Names of the tier to remove.\n        :raises KeyError: If a tier is non existent.\n        \"\"\"\n        for a in tiers:\n            self.remove_tier(a, clean=False)\n        self.clean_time_slots()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrename a tier. Note that this renames also the child tiers that have the tier as a parent. :param str id_from: Original name of the tier. :param str id_to: Target name of the tier. :throws KeyError: If the tier doesnt' exist.", "response": "def rename_tier(self, id_from, id_to):\n        \"\"\"Rename a tier. Note that this renames also the child tiers that have\n        the tier as a parent.\n\n        :param str id_from: Original name of the tier.\n        :param str id_to: Target name of the tier.\n        :throws KeyError: If the tier doesnt' exist.\n        \"\"\"\n        childs = self.get_child_tiers_for(id_from)\n        self.tiers[id_to] = self.tiers.pop(id_from)\n        self.tiers[id_to][2]['TIER_ID'] = id_to\n        for child in childs:\n            self.tiers[child][2]['PARENT_REF'] = id_to"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nshifts all annotations in time.", "response": "def shift_annotations(self, time):\n        \"\"\"Shift all annotations in time. Annotations that are in the beginning\n        and a left shift is applied can be squashed or discarded.\n\n        :param int time: Time shift width, negative numbers make a left shift.\n        :returns: Tuple of a list of squashed annotations and a list of removed\n                  annotations in the format: ``(tiername, start, end, value)``.\n        \"\"\"\n        total_re = []\n        total_sq = []\n        for name, tier in self.tiers.items():\n            squashed = []\n            for aid, (begin, end, value, _) in tier[0].items():\n                if self.timeslots[end]+time <= 0:\n                    squashed.append((name, aid))\n                elif self.timeslots[begin]+time < 0:\n                    total_sq.append((name, self.timeslots[begin],\n                                     self.timeslots[end], value))\n                    self.timeslots[begin] = 0\n                else:\n                    self.timeslots[begin] += time\n                    self.timeslots[end] += time\n            for name, aid in squashed:\n                start, end, value, _ = self.tiers[name][0][aid]\n                del(self.tiers[name][0][aid])\n                del(self.annotations[aid])\n                total_re.append(\n                    (name, self.timeslots[start], self.timeslots[end], value))\n        return total_sq, total_re"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_textgrid(self, filtin=[], filtex=[], regex=False):\n        from pympi.Praat import TextGrid\n        _, end = self.get_full_time_interval()\n        tgout = TextGrid(xmax=end/1000.0)\n        func = (lambda x, y: re.match(x, y)) if regex else lambda x, y: x == y\n        for tier in self.tiers:\n            if (filtin and not any(func(f, tier) for f in filtin)) or\\\n                    (filtex and any(func(f, tier) for f in filtex)):\n                continue\n            ctier = tgout.add_tier(tier)\n            for intv in self.get_annotation_data_for_tier(tier):\n                try:\n                    ctier.add_interval(intv[0]/1000.0, intv[1]/1000.0, intv[2])\n                except:\n                    pass\n        return tgout", "response": "Convert the object to a TextGrid object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef main():\n\n    import optparse\n    import sys\n    import codecs\n    import locale\n    import six\n    from .algorithm import get_display\n\n    parser = optparse.OptionParser()\n\n    parser.add_option('-e', '--encoding',\n                      dest='encoding',\n                      default='utf-8',\n                      type='string',\n                      help='Text encoding (default: utf-8)')\n\n    parser.add_option('-u', '--upper-is-rtl',\n                      dest='upper_is_rtl',\n                      default=False,\n                      action='store_true',\n                      help=\"Treat upper case chars as strong 'R' \"\n                      'for debugging (default: False).')\n\n    parser.add_option('-d', '--debug',\n                      dest='debug',\n                      default=False,\n                      action='store_true',\n                      help=\"Output to stderr steps taken with the algorithm\")\n\n    parser.add_option('-b', '--base-dir',\n                      dest='base_dir',\n                      default=None,\n                      type='string',\n                      help=\"Override base direction [L|R]\")\n\n    options, rest = parser.parse_args()\n\n    if options.base_dir and options.base_dir not in 'LR':\n        parser.error('option -b can be L or R')\n\n    # allow unicode in sys.stdout.write\n    if six.PY2:\n        sys.stdout = codecs.getwriter(locale.getpreferredencoding())(sys.stdout)\n\n    if rest:\n        lines = rest\n    else:\n        lines = sys.stdin\n\n    for line in lines:\n        display = get_display(line, options.encoding, options.upper_is_rtl,\n                              options.base_dir, options.debug)\n        # adjust the encoding as unicode, to match the output encoding\n        if not isinstance(display, six.text_type):\n            display = display.decode(options.encoding)\n\n        six.print_(display, end='')", "response": "This function will be used to create the console script"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndisplays debug information for the storage", "response": "def debug_storage(storage, base_info=False, chars=True, runs=False):\n    \"Display debug information for the storage\"\n\n    import codecs\n    import locale\n    import sys\n\n    if six.PY2:\n        stderr = codecs.getwriter(locale.getpreferredencoding())(sys.stderr)\n    else:\n        stderr = sys.stderr\n\n    caller = inspect.stack()[1][3]\n    stderr.write('in %s\\n' % caller)\n\n    if base_info:\n        stderr.write(u'  base level  : %d\\n' % storage['base_level'])\n        stderr.write(u'  base dir    : %s\\n' % storage['base_dir'])\n\n    if runs:\n        stderr.write(u'  runs        : %s\\n' % list(storage['runs']))\n\n    if chars:\n        output = u'  Chars       : '\n        for _ch in storage['chars']:\n            if _ch != '\\n':\n                output += _ch['ch']\n            else:\n                output += 'C'\n        stderr.write(output + u'\\n')\n\n        output = u'  Res. levels : %s\\n' % u''.join(\n            [six.text_type(_ch['level']) for _ch in storage['chars']])\n        stderr.write(output)\n\n        _types = [_ch['type'].ljust(3) for _ch in storage['chars']]\n\n        for i in range(3):\n            if i:\n                output = u'                %s\\n'\n            else:\n                output = u'  Res. types  : %s\\n'\n            stderr.write(output % u''.join([_t[i] for _t in _types]))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_base_level(text, upper_is_rtl=False):\n\n    base_level = None\n\n    prev_surrogate = False\n    # P2\n    for _ch in text:\n        # surrogate in case of ucs2\n        if _IS_UCS2 and (_SURROGATE_MIN <= ord(_ch) <= _SURROGATE_MAX):\n            prev_surrogate = _ch\n            continue\n        elif prev_surrogate:\n            _ch = prev_surrogate + _ch\n            prev_surrogate = False\n\n        # treat upper as RTL ?\n        if upper_is_rtl and _ch.isupper():\n            base_level = 1\n            break\n\n        bidi_type = bidirectional(_ch)\n\n        if bidi_type in ('AL', 'R'):\n            base_level = 1\n            break\n\n        elif bidi_type == 'L':\n            base_level = 0\n            break\n\n    # P3\n    if base_level is None:\n        base_level = 0\n\n    return base_level", "response": "Get the base embedding level of a text. Returns 0 for LTR 1 for RTL."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_embedding_levels(text, storage, upper_is_rtl=False, debug=False):\n\n    prev_surrogate = False\n    base_level = storage['base_level']\n\n    # preset the storage's chars\n    for _ch in text:\n        if _IS_UCS2 and (_SURROGATE_MIN <= ord(_ch) <= _SURROGATE_MAX):\n            prev_surrogate = _ch\n            continue\n        elif prev_surrogate:\n            _ch = prev_surrogate + _ch\n            prev_surrogate = False\n\n        if upper_is_rtl and _ch.isupper():\n            bidi_type = 'R'\n        else:\n            bidi_type = bidirectional(_ch)\n\n        storage['chars'].append({\n            'ch': _ch,\n            'level': base_level,\n            'type': bidi_type,\n            'orig': bidi_type\n        })\n    if debug:\n        debug_storage(storage, base_info=True)", "response": "Get the base embedding level and direction of the text."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef explicit_embed_and_overrides(storage, debug=False):\n    overflow_counter = almost_overflow_counter = 0\n    directional_override = 'N'\n    levels = deque()\n\n    # X1\n    embedding_level = storage['base_level']\n\n    for _ch in storage['chars']:\n        bidi_type = _ch['type']\n\n        level_func, override = X2_X5_MAPPINGS.get(bidi_type, (None, None))\n\n        if level_func:\n            # So this is X2 to X5\n            # if we've past EXPLICIT_LEVEL_LIMIT, note it and do nothing\n\n            if overflow_counter != 0:\n                overflow_counter += 1\n                continue\n\n            new_level = level_func(embedding_level)\n            if new_level < EXPLICIT_LEVEL_LIMIT:\n                levels.append((embedding_level, directional_override))\n                embedding_level, directional_override = new_level, override\n\n            elif embedding_level == EXPLICIT_LEVEL_LIMIT - 2:\n                # The new level is invalid, but a valid level can still be\n                # achieved if this level is 60 and we encounter an RLE or\n                # RLO further on.  So record that we 'almost' overflowed.\n                almost_overflow_counter += 1\n\n            else:\n                overflow_counter += 1\n        else:\n            # X6\n            if bidi_type not in X6_IGNORED:\n                _ch['level'] = embedding_level\n                if directional_override != 'N':\n                    _ch['type'] = directional_override\n\n            # X7\n            elif bidi_type == 'PDF':\n                if overflow_counter:\n                    overflow_counter -= 1\n                elif almost_overflow_counter and \\\n                        embedding_level != EXPLICIT_LEVEL_LIMIT - 1:\n                    almost_overflow_counter -= 1\n                elif levels:\n                    embedding_level, directional_override = levels.pop()\n\n            # X8\n            elif bidi_type == 'B':\n                levels.clear()\n                overflow_counter = almost_overflow_counter = 0\n                embedding_level = _ch['level'] = storage['base_level']\n                directional_override = 'N'\n\n    # Removes the explicit embeds and overrides of types\n    # RLE, LRE, RLO, LRO, PDF, and BN. Adjusts extended chars\n    # next and prev as well\n\n    # Applies X9. See http://unicode.org/reports/tr9/#X9\n    storage['chars'] = [_ch for _ch in storage['chars']\n                        if _ch['type'] not in X9_REMOVED]\n\n    calc_level_runs(storage)\n\n    if debug:\n        debug_storage(storage, runs=True)", "response": "Apply X1 to X9 rules of the unicode algorithm."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef calc_level_runs(storage):\n    # run level depends on the higher of the two levels on either side of\n    # the boundary If the higher level is odd, the type is R; otherwise,\n    # it is L\n\n    storage['runs'].clear()\n    chars = storage['chars']\n\n    # empty string ?\n    if not chars:\n        return\n\n    def calc_level_run(b_l, b_r):\n        return ['L', 'R'][max(b_l, b_r) % 2]\n\n    first_char = chars[0]\n\n    sor = calc_level_run(storage['base_level'], first_char['level'])\n    eor = None\n\n    run_start = run_length = 0\n\n    prev_level, prev_type = first_char['level'], first_char['type']\n\n    for _ch in chars:\n        curr_level, curr_type = _ch['level'], _ch['type']\n\n        if curr_level == prev_level:\n            run_length += 1\n        else:\n            eor = calc_level_run(prev_level, curr_level)\n            storage['runs'].append({'sor': sor, 'eor': eor, 'start': run_start,\n                                    'type': prev_type, 'length': run_length})\n            sor = eor\n            run_start += run_length\n            run_length = 1\n\n        prev_level, prev_type = curr_level, curr_type\n\n    # for the last char/runlevel\n    eor = calc_level_run(curr_level, storage['base_level'])\n    storage['runs'].append({'sor': sor, 'eor': eor, 'start': run_start,\n                            'type': curr_type, 'length': run_length})", "response": "Split the storage to run of char types at the same level."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nresolve weak types of the European numbers and ALs in the given storage.", "response": "def resolve_weak_types(storage, debug=False):\n    \"\"\"Reslove weak type rules W1 - W3.\n\n    See: http://unicode.org/reports/tr9/#Resolving_Weak_Types\n\n    \"\"\"\n\n    for run in storage['runs']:\n        prev_strong = prev_type = run['sor']\n        start, length = run['start'], run['length']\n        chars = storage['chars'][start:start+length]\n        for _ch in chars:\n            # W1. Examine each nonspacing mark (NSM) in the level run, and\n            # change the type of the NSM to the type of the previous character.\n            # If the NSM is at the start of the level run, it will get the type\n            # of sor.\n            bidi_type = _ch['type']\n\n            if bidi_type == 'NSM':\n                _ch['type'] = bidi_type = prev_type\n\n            # W2. Search backward from each instance of a European number until\n            # the first strong type (R, L, AL, or sor) is found. If an AL is\n            # found, change the type of the European number to Arabic number.\n            if bidi_type == 'EN' and prev_strong == 'AL':\n                _ch['type'] = 'AN'\n\n            # update prev_strong if needed\n            if bidi_type in ('R', 'L', 'AL'):\n                prev_strong = bidi_type\n\n            prev_type = _ch['type']\n\n        # W3. Change all ALs to R\n        for _ch in chars:\n            if _ch['type'] == 'AL':\n                _ch['type'] = 'R'\n\n        # W4. A single European separator between two European numbers changes\n        # to a European number. A single common separator between two numbers of\n        # the same type changes to that type.\n        for idx in range(1, len(chars) - 1):\n            bidi_type = chars[idx]['type']\n            prev_type = chars[idx-1]['type']\n            next_type = chars[idx+1]['type']\n\n            if bidi_type == 'ES' and (prev_type == next_type == 'EN'):\n                chars[idx]['type'] = 'EN'\n\n            if bidi_type == 'CS' and prev_type == next_type and \\\n                    prev_type in ('AN', 'EN'):\n                chars[idx]['type'] = prev_type\n\n        # W5. A sequence of European terminators adjacent to European numbers\n        # changes to all European numbers.\n        for idx in range(len(chars)):\n            if chars[idx]['type'] == 'EN':\n                for et_idx in range(idx-1, -1, -1):\n                    if chars[et_idx]['type'] == 'ET':\n                        chars[et_idx]['type'] = 'EN'\n                    else:\n                        break\n                for et_idx in range(idx+1, len(chars)):\n                    if chars[et_idx]['type'] == 'ET':\n                        chars[et_idx]['type'] = 'EN'\n                    else:\n                        break\n\n        # W6. Otherwise, separators and terminators change to Other Neutral.\n        for _ch in chars:\n            if _ch['type'] in ('ET', 'ES', 'CS'):\n                _ch['type'] = 'ON'\n\n        # W7. Search backward from each instance of a European number until the\n        # first strong type (R, L, or sor) is found. If an L is found, then\n        # change the type of the European number to L.\n        prev_strong = run['sor']\n        for _ch in chars:\n            if _ch['type'] == 'EN' and prev_strong == 'L':\n                _ch['type'] = 'L'\n\n            if _ch['type'] in ('L', 'R'):\n                prev_strong = _ch['type']\n\n    if debug:\n        debug_storage(storage, runs=True)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nresolve the neutral types in the given storage.", "response": "def resolve_neutral_types(storage, debug):\n    \"\"\"Resolving neutral types. Implements N1 and N2\n\n    See: http://unicode.org/reports/tr9/#Resolving_Neutral_Types\n\n    \"\"\"\n\n    for run in storage['runs']:\n        start, length = run['start'], run['length']\n        # use sor and eor\n        chars = [{'type': run['sor']}] + storage['chars'][start:start+length] +\\\n                [{'type': run['eor']}]\n        total_chars = len(chars)\n\n        seq_start = None\n        for idx in range(total_chars):\n            _ch = chars[idx]\n            if _ch['type'] in ('B', 'S', 'WS', 'ON'):\n                # N1. A sequence of neutrals takes the direction of the\n                # surrounding strong text if the text on both sides has the same\n                # direction. European and Arabic numbers act as if they were R\n                # in terms of their influence on neutrals. Start-of-level-run\n                # (sor) and end-of-level-run (eor) are used at level run\n                # boundaries.\n                if seq_start is None:\n                    seq_start = idx\n                    prev_bidi_type = chars[idx-1]['type']\n            else:\n                if seq_start is not None:\n                    next_bidi_type = chars[idx]['type']\n\n                    if prev_bidi_type in ('AN', 'EN'):\n                        prev_bidi_type = 'R'\n\n                    if next_bidi_type in ('AN', 'EN'):\n                        next_bidi_type = 'R'\n\n                    for seq_idx in range(seq_start, idx):\n                        if prev_bidi_type == next_bidi_type:\n                            chars[seq_idx]['type'] = prev_bidi_type\n                        else:\n                            # N2. Any remaining neutrals take the embedding\n                            # direction. The embedding direction for the given\n                            # neutral character is derived from its embedding\n                            # level: L if the character is set to an even level,\n                            # and R if the level is odd.\n                            chars[seq_idx]['type'] = \\\n                                _embedding_direction(chars[seq_idx]['level'])\n\n                    seq_start = None\n\n    if debug:\n        debug_storage(storage)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef resolve_implicit_levels(storage, debug):\n    for run in storage['runs']:\n        start, length = run['start'], run['length']\n        chars = storage['chars'][start:start+length]\n\n        for _ch in chars:\n            # only those types are allowed at this stage\n            assert _ch['type'] in ('L', 'R', 'EN', 'AN'),\\\n                    '%s not allowed here' % _ch['type']\n\n            if _embedding_direction(_ch['level']) == 'L':\n                # I1. For all characters with an even (left-to-right) embedding\n                # direction, those of type R go up one level and those of type\n                # AN or EN go up two levels.\n                if _ch['type'] == 'R':\n                    _ch['level'] += 1\n                elif _ch['type'] != 'L':\n                    _ch['level'] += 2\n            else:\n                # I2. For all characters with an odd (right-to-left) embedding\n                # direction, those of type L, EN or AN  go up one level.\n                if _ch['type'] != 'R':\n                    _ch['level'] += 1\n\n    if debug:\n        debug_storage(storage, runs=True)", "response": "Resolves implicit levels in the given storage."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef reverse_contiguous_sequence(chars, line_start, line_end, highest_level,\n                                lowest_odd_level):\n    \"\"\"L2. From the highest level found in the text to the lowest odd\n    level on each line, including intermediate levels not actually\n    present in the text, reverse any contiguous sequence of characters\n    that are at that level or higher.\n\n    \"\"\"\n    for level in range(highest_level, lowest_odd_level-1, -1):\n        _start = _end = None\n\n        for run_idx in range(line_start, line_end+1):\n            run_ch = chars[run_idx]\n\n            if run_ch['level'] >= level:\n                if _start is None:\n                    _start = _end = run_idx\n                else:\n                    _end = run_idx\n            else:\n                if _end:\n                    chars[_start:+_end+1] = \\\n                            reversed(chars[_start:+_end+1])\n                    _start = _end = None\n\n        # anything remaining ?\n        if _start is not None:\n            chars[_start:+_end+1] = \\\n                reversed(chars[_start:+_end+1])", "response": "L2. From the highest level found in the text to the lowest odd\n    level on each line and including intermediate levels not actually necessary."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef reorder_resolved_levels(storage, debug):\n\n    # Applies L1.\n\n    should_reset = True\n    chars = storage['chars']\n\n    for _ch in chars[::-1]:\n        # L1. On each line, reset the embedding level of the following\n        # characters to the paragraph embedding level:\n        if _ch['orig'] in ('B', 'S'):\n            # 1. Segment separators,\n            # 2. Paragraph separators,\n            _ch['level'] = storage['base_level']\n            should_reset = True\n        elif should_reset and _ch['orig'] in ('BN', 'WS'):\n            # 3. Any sequence of whitespace characters preceding a segment\n            # separator or paragraph separator\n            # 4. Any sequence of white space characters at the end of the\n            # line.\n            _ch['level'] = storage['base_level']\n        else:\n            should_reset = False\n\n    max_len = len(chars)\n\n    # L2 should be per line\n    # Calculates highest level and loweset odd level on the fly.\n\n    line_start = line_end = 0\n    highest_level = 0\n    lowest_odd_level = EXPLICIT_LEVEL_LIMIT\n\n    for idx in range(max_len):\n        _ch = chars[idx]\n\n        # calc the levels\n        char_level = _ch['level']\n        if char_level > highest_level:\n            highest_level = char_level\n\n        if char_level % 2 and char_level < lowest_odd_level:\n            lowest_odd_level = char_level\n\n        if _ch['orig'] == 'B' or idx == max_len - 1:\n            line_end = idx\n            # omit line breaks\n            if _ch['orig'] == 'B':\n                line_end -= 1\n\n            reverse_contiguous_sequence(chars, line_start, line_end,\n                                        highest_level, lowest_odd_level)\n\n            # reset for next line run\n            line_start = idx+1\n            highest_level = 0\n            lowest_odd_level = EXPLICIT_LEVEL_LIMIT\n\n    if debug:\n        debug_storage(storage)", "response": "Reorder the resolved levels of the language classes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef apply_mirroring(storage, debug):\n    # L4. A character is depicted by a mirrored glyph if and only if (a) the\n    # resolved directionality of that character is R, and (b) the\n    # Bidi_Mirrored property value of that character is true.\n    for _ch in storage['chars']:\n        unichar = _ch['ch']\n        if mirrored(unichar) and \\\n                _embedding_direction(_ch['level']) == 'R':\n            _ch['ch'] = MIRRORED.get(unichar, unichar)\n\n    if debug:\n        debug_storage(storage)", "response": "Applies mirroring to the base character list."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_display(unicode_or_str, encoding='utf-8', upper_is_rtl=False,\n                base_dir=None, debug=False):\n    \"\"\"Accepts unicode or string. In case it's a string, `encoding`\n    is needed as it works on unicode ones (default:\"utf-8\").\n\n    Set `upper_is_rtl` to True to treat upper case chars as strong 'R'\n    for debugging (default: False).\n\n    Set `base_dir` to 'L' or 'R' to override the calculated base_level.\n\n    Set `debug` to True to display (using sys.stderr) the steps taken with the\n    algorithm.\n\n    Returns the display layout, either as unicode or `encoding` encoded\n    string.\n\n    \"\"\"\n    storage = get_empty_storage()\n\n    # utf-8 ? we need unicode\n    if isinstance(unicode_or_str, six.text_type):\n        text = unicode_or_str\n        decoded = False\n    else:\n        text = unicode_or_str.decode(encoding)\n        decoded = True\n\n    if base_dir is None:\n        base_level = get_base_level(text, upper_is_rtl)\n    else:\n        base_level = PARAGRAPH_LEVELS[base_dir]\n\n    storage['base_level'] = base_level\n    storage['base_dir'] = ('L', 'R')[base_level]\n\n    get_embedding_levels(text, storage, upper_is_rtl, debug)\n    explicit_embed_and_overrides(storage, debug)\n    resolve_weak_types(storage, debug)\n    resolve_neutral_types(storage, debug)\n    resolve_implicit_levels(storage, debug)\n    reorder_resolved_levels(storage, debug)\n    apply_mirroring(storage, debug)\n\n    chars = storage['chars']\n    display = u''.join([_ch['ch'] for _ch in chars])\n\n    if decoded:\n        return display.encode(encoding)\n    else:\n        return display", "response": "Returns the display layout of the given unicode or string."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef process(self, context):\n        import os\n        from maya import cmds\n\n        \"\"\"Inject the current working file\"\"\"\n        current_file = cmds.file(sceneName=True, query=True)\n\n        # Maya returns forward-slashes by default\n        normalised = os.path.normpath(current_file)\n\n        context.set_data('currentFile', value=normalised)\n\n        # For backwards compatibility\n        context.set_data('current_file', value=normalised)", "response": "Inject the current working file"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef convert(lines):\n\n    def parse(line):\n        line = line.replace(\"from PySide2 import\", \"from Qt import\")\n        line = line.replace(\"QtWidgets.QApplication.translate\",\n                            \"Qt.QtCompat.translate\")\n        return line\n\n    parsed = list()\n    for line in lines:\n        line = parse(line)\n        parsed.append(line)\n\n    return parsed", "response": "Convert compiled. ui file from PySide2 to Qt. py\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding an attribute to the object.", "response": "def _add(object, name, value):\n    \"\"\"Append to self, accessible via Qt.QtCompat\"\"\"\n    self.__added__.append(name)\n    setattr(object, name, value)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cli(args):\n    import argparse\n\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--convert\",\n                        help=\"Path to compiled Python module, e.g. my_ui.py\")\n    parser.add_argument(\"--compile\",\n                        help=\"Accept raw .ui file and compile with native \"\n                             \"PySide2 compiler.\")\n    parser.add_argument(\"--stdout\",\n                        help=\"Write to stdout instead of file\",\n                        action=\"store_true\")\n    parser.add_argument(\"--stdin\",\n                        help=\"Read from stdin instead of file\",\n                        action=\"store_true\")\n\n    args = parser.parse_args(args)\n\n    if args.stdout:\n        raise NotImplementedError(\"--stdout\")\n\n    if args.stdin:\n        raise NotImplementedError(\"--stdin\")\n\n    if args.compile:\n        raise NotImplementedError(\"--compile\")\n\n    if args.convert:\n        sys.stdout.write(\"#\\n\"\n                         \"# WARNING: --convert is an ALPHA feature.\\n#\\n\"\n                         \"# See https://github.com/mottosso/Qt.py/pull/132\\n\"\n                         \"# for details.\\n\"\n                         \"#\\n\")\n\n        #\n        # ------> Read\n        #\n        with open(args.convert) as f:\n            lines = convert(f.readlines())\n\n        backup = \"%s_backup%s\" % os.path.splitext(args.convert)\n        sys.stdout.write(\"Creating \\\"%s\\\"..\\n\" % backup)\n        shutil.copy(args.convert, backup)\n\n        #\n        # <------ Write\n        #\n        with open(args.convert, \"w\") as f:\n            f.write(\"\".join(lines))\n\n        sys.stdout.write(\"Successfully converted \\\"%s\\\"\\n\" % args.convert)", "response": "Qt command - line interface for the Sequence System."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _maintain_backwards_compatibility(binding):\n\n    for member in (\"__binding__\",\n                   \"__binding_version__\",\n                   \"__qt_version__\",\n                   \"__added__\",\n                   \"__remapped__\",\n                   \"__modified__\",\n                   \"convert\",\n                   \"load_ui\",\n                   \"translate\"):\n        setattr(binding, member, getattr(self, member))\n        self.__added__.append(member)\n\n    setattr(binding, \"__wrapper_version__\", self.__version__)\n    self.__added__.append(\"__wrapper_version__\")", "response": "Maintain backwards compatibility for the current version of the current version of the current version of the current version of the current version."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntry showing the most desirable GUI", "response": "def show():\n    \"\"\"Try showing the most desirable GUI\n\n    This function cycles through the currently registered\n    graphical user interfaces, if any, and presents it to\n    the user.\n\n    \"\"\"\n\n    parent = next(\n        o for o in QtWidgets.QApplication.instance().topLevelWidgets()\n        if o.objectName() == \"MayaWindow\"\n    )\n\n    gui = _discover_gui()\n\n    if gui is None:\n        _show_no_gui()\n    else:\n        return gui(parent)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _discover_gui():\n\n    # Prefer last registered\n    guis = reversed(pyblish.api.registered_guis())\n\n    for gui in guis:\n        try:\n            gui = __import__(gui).show\n        except (ImportError, AttributeError):\n            continue\n        else:\n            return gui", "response": "Return the most desirable GUI of the currently registered GUIs"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef teardown():\n    if not self._has_been_setup:\n        return\n\n    deregister_plugins()\n    deregister_host()\n\n    if self._has_menu:\n        remove_from_filemenu()\n        self._has_menu = False\n\n    self._has_been_setup = False\n    print(\"pyblish: Integration torn down successfully\")", "response": "Remove integration from file menu and plugins"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds Pyblish to file - menu.", "response": "def add_to_filemenu():\n    \"\"\"Add Pyblish to file-menu\n\n    .. note:: We're going a bit hacky here, probably due to my lack\n        of understanding for `evalDeferred` or `executeDeferred`,\n        so if you can think of a better solution, feel free to edit.\n\n    \"\"\"\n\n    if hasattr(cmds, 'about') and not cmds.about(batch=True):\n        # As Maya builds its menus dynamically upon being accessed,\n        # we force its build here prior to adding our entry using it's\n        # native mel function call.\n        mel.eval(\"evalDeferred buildFileMenu\")\n\n        # Serialise function into string\n        script = inspect.getsource(_add_to_filemenu)\n        script += \"\\n_add_to_filemenu()\"\n\n        # If cmds doesn't have any members, we're most likely in an\n        # uninitialized batch-mode. It it does exists, ensure we\n        # really aren't in batch mode.\n        cmds.evalDeferred(script)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef maintained_selection():\n\n    previous_selection = cmds.ls(selection=True)\n    try:\n        yield\n    finally:\n        if previous_selection:\n            cmds.select(previous_selection,\n                        replace=True,\n                        noExpand=True)\n        else:\n            cmds.select(deselect=True,\n                        noExpand=True)", "response": "Maintain selection during context\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmaintain current time during context", "response": "def maintained_time():\n    \"\"\"Maintain current time during context\n\n    Example:\n        >>> with maintained_time():\n        ...    cmds.playblast()\n        >>> # Time restored\n\n    \"\"\"\n\n    ct = cmds.currentTime(query=True)\n    try:\n        yield\n    finally:\n        cmds.currentTime(ct, edit=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nshow a popup with no GUI.", "response": "def _show_no_gui():\n    \"\"\"Popup with information about how to register a new GUI\n\n    In the event of no GUI being registered or available,\n    this information dialog will appear to guide the user\n    through how to get set up with one.\n\n    \"\"\"\n\n    messagebox = QtWidgets.QMessageBox()\n    messagebox.setIcon(messagebox.Warning)\n    messagebox.setWindowIcon(QtGui.QIcon(os.path.join(\n        os.path.dirname(pyblish.__file__),\n        \"icons\",\n        \"logo-32x32.svg\"))\n    )\n\n    spacer = QtWidgets.QWidget()\n    spacer.setMinimumSize(400, 0)\n    spacer.setSizePolicy(QtWidgets.QSizePolicy.Minimum,\n                         QtWidgets.QSizePolicy.Expanding)\n\n    layout = messagebox.layout()\n    layout.addWidget(spacer, layout.rowCount(), 0, 1, layout.columnCount())\n\n    messagebox.setWindowTitle(\"Uh oh\")\n\n    text = \"No registered GUI found.\\n\\n\"\n\n    if not pyblish.api.registered_guis():\n        text += (\n            \"In order to show you a GUI, one must first be registered. \"\n            \"\\n\"\n            \"Pyblish supports one or more graphical user interfaces \"\n            \"to be registered at once, the next acting as a fallback to \"\n            \"the previous.\"\n            \"\\n\"\n            \"\\n\"\n            \"For example, to use Pyblish Lite, first install it:\"\n            \"\\n\"\n            \"\\n\"\n            \"$ pip install pyblish-lite\"\n            \"\\n\"\n            \"\\n\"\n            \"Then register it, like so:\"\n            \"\\n\"\n            \"\\n\"\n            \">>> import pyblish.api\\n\"\n            \">>> pyblish.api.register_gui(\\\"pyblish_lite\\\")\"\n            \"\\n\"\n            \"\\n\"\n            \"The next time you try running this, Lite will appear.\"\n            \"\\n\"\n            \"See http://api.pyblish.com/register_gui.html for \"\n            \"more information.\"\n        )\n    else:\n        text += (\n            \"None of the registered graphical user interfaces \"\n            \"could be found.\"\n            \"\\n\"\n            \"These interfaces are currently registered:\"\n            \"\\n\"\n            \"%s\" % \"\\n\".join(pyblish.api.registered_guis())\n        )\n\n    messagebox.setText(text)\n    messagebox.setStandardButtons(messagebox.Ok)\n    messagebox.exec_()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_cumulative_data(self):\n\t\tsets = map(itemgetter('data'), self.data)\n\t\tif not sets:\n\t\t\treturn\n\t\tsum = sets.pop(0)\n\t\tyield sum\n\t\twhile sets:\n\t\t\tsum = map(add, sets.pop(0))\n\t\t\tyield sum", "response": "Get the data as it will be charted."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_single_axis_values(self, axis, dataset):\n\t\tdata_index = getattr(self, '%s_data_index' % axis)\n\t\treturn [p[data_index] for p in dataset['data']]", "response": "Get the values for a single axis of the data."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __draw_constant_line(self, value_label_style):\n\t\t\"Draw a constant line on the y-axis with the label\"\n\t\tvalue, label, style = value_label_style\n\t\tstart = self.transform_output_coordinates((0, value))[1]\n\t\tstop = self.graph_width\n\t\tpath = etree.SubElement(self.graph, 'path', {\n\t\t\t'd': 'M 0 %(start)s h%(stop)s' % locals(),\n\t\t\t'class': 'constantLine'})\n\t\tif style:\n\t\t\tpath.set('style', style)\n\t\ttext = etree.SubElement(self.graph, 'text', {\n\t\t\t'x': str(2),\n\t\t\t'y': str(start - 2),\n\t\t\t'class': 'constantLine'})\n\t\ttext.text = label", "response": "Draw a constant line on the y - axis with the label"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncache the parameters necessary to transform x & y coordinates", "response": "def load_transform_parameters(self):\n\t\t\"Cache the parameters necessary to transform x & y coordinates\"\n\t\tx_min, x_max, x_div = self.x_range()\n\t\ty_min, y_max, y_div = self.y_range()\n\t\tx_step = (float(self.graph_width) - self.font_size * 2) / \\\n\t\t\t(x_max - x_min)\n\t\ty_step = (float(self.graph_height) - self.font_size * 2) / \\\n\t\t\t(y_max - y_min)\n\t\tself.__transform_parameters = dict(locals())\n\t\tdel self.__transform_parameters['self']"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef reverse_mapping(mapping):\n\tkeys, values = zip(*mapping.items())\n\treturn dict(zip(values, keys))", "response": "Returns the mapping for every key value pair return the mapping for the\n\tequivalent value key pair\n\t"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef flatten_mapping(mapping):\n\treturn {\n\t\tkey: value\n\t\tfor keys, value in mapping.items()\n\t\tfor key in always_iterable(keys)\n\t}", "response": "For every key that has an __iter__ method, assign the values\n\tto a key for each.\n\n\t>>> flatten_mapping({'ab': 3, ('c','d'): 4}) == {'ab': 3, 'c': 4, 'd': 4}\n\tTrue"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef float_range(start=0, stop=None, step=1):\n\tstart = float(start)\n\twhile start < stop:\n\t\tyield start\n\t\tstart += step", "response": "A generator that yields floats from start to stop."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_data(self, data_descriptor):\n\t\tpairs = itertools.zip_longest(self.data, data_descriptor['data'])\n\t\tself.data = list(itertools.starmap(robust_add, pairs))", "response": "Adds a data set to the graph."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_data(self, conf):\n\t\tself.validate_data(conf)\n\t\tself.process_data(conf)\n\t\tself.data.append(conf)", "response": "Add data to the graph object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprocessing the template with the data and config which has been set and return the resulting SVG. Raises ValueError when no data set has been added to the graph object.", "response": "def burn(self):\n\t\t\"\"\"\n\t\tProcess the template with the data and\n\t\tconfig which has been set and return the resulting SVG.\n\n\t\tRaises ValueError when no data set has\n\t\tbeen added to the graph object.\n\t\t\"\"\"\n\t\tif not self.data:\n\t\t\traise ValueError(\"No data available\")\n\n\t\tif hasattr(self, 'calculations'):\n\t\t\tself.calculations()\n\n\t\tself.start_svg()\n\t\tself.calculate_graph_dimensions()\n\t\tself.foreground = etree.Element(\"g\")\n\t\tself.draw_graph()\n\t\tself.draw_titles()\n\t\tself.draw_legend()\n\t\tself.draw_data()\n\t\tself.graph.append(self.foreground)\n\t\tself.render_inline_styles()\n\n\t\treturn self.render(self.root)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating the margin to the left of the plot area setting border_left.", "response": "def calculate_left_margin(self):\n\t\t\"\"\"\n\t\tCalculates the margin to the left of the plot area, setting\n\t\tborder_left.\n\t\t\"\"\"\n\t\tbl = 7\n\t\t# Check for Y labels\n\t\tif self.rotate_y_labels:\n\t\t\tmax_y_label_height_px = self.y_label_font_size\n\t\telse:\n\t\t\tlabel_lengths = map(len, self.get_y_labels())\n\t\t\tmax_y_label_len = max(label_lengths)\n\t\t\tmax_y_label_height_px = 0.6 * max_y_label_len * self.y_label_font_size\n\t\tif self.show_y_labels:\n\t\t\tbl += max_y_label_height_px\n\t\tif self.stagger_y_labels:\n\t\t\tbl += max_y_label_height_px + 10\n\t\tif self.show_y_title:\n\t\t\tbl += self.y_title_font_size + 5\n\t\tself.border_left = bl"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalculates the margin in pixels to the right of the plot area.", "response": "def calculate_right_margin(self):\n\t\t\"\"\"\n\t\tCalculate the margin in pixels to the right of the plot area,\n\t\tsetting border_right.\n\t\t\"\"\"\n\t\tbr = 7\n\t\tif self.key and self.key_position == 'right':\n\t\t\tmax_key_len = max(map(len, self.keys()))\n\t\t\tbr += max_key_len * self.key_font_size * 0.6\n\t\t\tbr += self.KEY_BOX_SIZE\n\t\t\tbr += 10\t\t# Some padding around the box\n\t\tself.border_right = br"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef calculate_top_margin(self):\n\t\tself.border_top = 5\n\t\tif self.show_graph_title:\n\t\t\tself.border_top += self.title_font_size\n\t\tself.border_top += 5\n\t\tif self.show_graph_subtitle:\n\t\t\tself.border_top += self.subtitle_font_size", "response": "Calculate the margin in pixels above the plot area setting\n\tborder_top."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_popup(self, x, y, label):\n\t\ttxt_width = len(label) * self.font_size * 0.6 + 10\n\t\ttx = x + [5, -5][int(x + txt_width > self.width)]\n\t\tanchor = ['start', 'end'][x + txt_width > self.width]\n\t\tstyle = 'fill: #000; text-anchor: %s;' % anchor\n\t\tid = 'label-%s' % self._w3c_name(label)\n\t\tattrs = {\n\t\t\t'x': str(tx),\n\t\t\t'y': str(y - self.font_size),\n\t\t\t'visibility': 'hidden',\n\t\t\t'style': style,\n\t\t\t'text': label,\n\t\t\t'id': id,\n\t\t}\n\t\tetree.SubElement(self.foreground, 'text', attrs)\n\n\t\t# add the circle element to the foreground\n\t\tvis_tmpl = (\n\t\t\t\"document.getElementById('{id}').setAttribute('visibility', {val})\"\n\t\t)\n\t\tattrs = {\n\t\t\t'cx': str(x),\n\t\t\t'cy': str(y),\n\t\t\t'r': str(10),\n\t\t\t'style': 'opacity: 0;',\n\t\t\t'onmouseover': vis_tmpl.format(val='visible', id=id),\n\t\t\t'onmouseout': vis_tmpl.format(val='hidden', id=id),\n\t\t}\n\t\tetree.SubElement(self.foreground, 'circle', attrs)", "response": "Add pop - up information to a point on the graph."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef calculate_bottom_margin(self):\n\t\tbb = 7\n\t\tif self.key and self.key_position == 'bottom':\n\t\t\tbb += len(self.data) * (self.font_size + 5)\n\t\t\tbb += 10\n\t\tif self.show_x_labels:\n\t\t\tmax_x_label_height_px = self.x_label_font_size\n\t\t\tif self.rotate_x_labels:\n\t\t\t\tlabel_lengths = map(len, self.get_x_labels())\n\t\t\t\tmax_x_label_len = functools.reduce(max, label_lengths)\n\t\t\t\tmax_x_label_height_px *= 0.6 * max_x_label_len\n\t\t\tbb += max_x_label_height_px\n\t\t\tif self.stagger_x_labels:\n\t\t\t\tbb += max_x_label_height_px + 10\n\t\tif self.show_x_title:\n\t\t\tbb += self.x_title_font_size + 5\n\t\tself.border_bottom = bb", "response": "Calculate the bottom margin in pixels below the plot area setting\n\tborder_bottom."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef draw_graph(self):\n\t\ttransform = 'translate (%s %s)' % (self.border_left, self.border_top)\n\t\tself.graph = etree.SubElement(self.root, 'g', transform=transform)\n\n\t\tetree.SubElement(self.graph, 'rect', {\n\t\t\t'x': '0',\n\t\t\t'y': '0',\n\t\t\t'width': str(self.graph_width),\n\t\t\t'height': str(self.graph_height),\n\t\t\t'class': 'graphBackground'\n\t\t})\n\n\t\t# Axis\n\t\tetree.SubElement(self.graph, 'path', {\n\t\t\t'd': 'M 0 0 v%s' % self.graph_height,\n\t\t\t'class': 'axis',\n\t\t\t'id': 'xAxis'\n\t\t})\n\t\tetree.SubElement(self.graph, 'path', {\n\t\t\t'd': 'M 0 %s h%s' % (self.graph_height, self.graph_width),\n\t\t\t'class': 'axis',\n\t\t\t'id': 'yAxis'\n\t\t})\n\n\t\tself.draw_x_labels()\n\t\tself.draw_y_labels()", "response": "This method draws the graph."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef make_datapoint_text(self, x, y, value, style=None):\n\t\tif not self.show_data_values:\n\t\t\t# do nothing\n\t\t\treturn\n\t\t# first lay down the text in a wide white stroke to\n\t\t#  differentiate it from the background\n\t\te = etree.SubElement(self.foreground, 'text', {\n\t\t\t'x': str(x),\n\t\t\t'y': str(y),\n\t\t\t'class': 'dataPointLabel',\n\t\t\t'style': '%(style)s stroke: #fff; stroke-width: 2;' % vars(),\n\t\t})\n\t\te.text = str(value)\n\t\t# then lay down the text in the specified style\n\t\te = etree.SubElement(self.foreground, 'text', {\n\t\t\t'x': str(x),\n\t\t\t'y': str(y),\n\t\t\t'class': 'dataPointLabel'})\n\t\te.text = str(value)\n\t\tif style:\n\t\t\te.set('style', style)", "response": "Add text for a datapoint"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef draw_x_labels(self):\n\t\t\"Draw the X axis labels\"\n\t\tif self.show_x_labels:\n\t\t\tlabels = self.get_x_labels()\n\t\t\tcount = len(labels)\n\n\t\t\tlabels = enumerate(iter(labels))\n\t\t\tstart = int(not self.step_include_first_x_label)\n\t\t\tlabels = itertools.islice(labels, start, None, self.step_x_labels)\n\t\t\tlist(map(self.draw_x_label, labels))\n\t\t\tself.draw_x_guidelines(self.field_width(), count)", "response": "Draw the X axis labels"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef draw_y_labels(self):\n\t\t\"Draw the Y axis labels\"\n\t\tif not self.show_y_labels:\n\t\t\t# do nothing\n\t\t\treturn\n\n\t\tlabels = self.get_y_labels()\n\t\tcount = len(labels)\n\n\t\tlabels = enumerate(iter(labels))\n\t\tstart = int(not self.step_include_first_y_label)\n\t\tlabels = itertools.islice(labels, start, None, self.step_y_labels)\n\t\tlist(map(self.draw_y_label, labels))\n\t\tself.draw_y_guidelines(self.field_height(), count)", "response": "Draw the Y axis labels"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef draw_x_guidelines(self, label_height, count):\n\t\t\"Draw the X-axis guidelines\"\n\t\tif not self.show_x_guidelines:\n\t\t\treturn\n\t\t# skip the first one\n\t\tfor count in range(1, count):\n\t\t\tmove = 'M {start} 0 v{stop}'.format(\n\t\t\t\tstart=label_height * count,\n\t\t\t\tstop=self.graph_height,\n\t\t\t)\n\t\t\tpath = {'d': move, 'class': 'guideLines'}\n\t\t\tetree.SubElement(self.graph, 'path', path)", "response": "Draw the X - axis guidelines"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndraws the Y - axis guidelines", "response": "def draw_y_guidelines(self, label_height, count):\n\t\t\"Draw the Y-axis guidelines\"\n\t\tif not self.show_y_guidelines:\n\t\t\treturn\n\t\tfor count in range(1, count):\n\t\t\tmove = 'M 0 {start} h{stop}'.format(\n\t\t\t\tstart=self.graph_height - label_height * count,\n\t\t\t\tstop=self.graph_width,\n\t\t\t)\n\t\t\tpath = {'d': move, 'class': 'guideLines'}\n\t\t\tetree.SubElement(self.graph, 'path', path)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndrawing the graph title and subtitle", "response": "def draw_titles(self):\n\t\t\"Draws the graph title and subtitle\"\n\t\tif self.show_graph_title:\n\t\t\tself.draw_graph_title()\n\t\tif self.show_graph_subtitle:\n\t\t\tself.draw_graph_subtitle()\n\t\tif self.show_x_title:\n\t\t\tself.draw_x_title()\n\t\tif self.show_y_title:\n\t\t\tself.draw_y_title()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef render_inline_styles(self):\n\t\t\"Hard-code the styles into the SVG XML if style sheets are not used.\"\n\t\tif not self.css_inline:\n\t\t\t# do nothing\n\t\t\treturn\n\n\t\tstyles = self.parse_css()\n\t\tfor node in self.root.xpath('//*[@class]'):\n\t\t\tcl = '.' + node.attrib['class']\n\t\t\tif cl not in styles:\n\t\t\t\tcontinue\n\t\t\tstyle = styles[cl]\n\t\t\tif 'style' in node.attrib:\n\t\t\t\tstyle += node.attrib['style']\n\t\t\tnode.attrib['style'] = style", "response": "Hard - code the styles into the SVG XML if style sheets are not used."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_css(self):\n\t\t# todo: save the prefs for use later\n\t\t# orig_prefs = cssutils.ser.prefs\n\t\tcssutils.ser.prefs.useMinified()\n\t\tpairs = (\n\t\t\t(r.selectorText, r.style.cssText)\n\t\t\tfor r in self.get_stylesheet()\n\t\t\tif not isinstance(r, cssutils.css.CSSComment)\n\t\t)\n\t\treturn dict(pairs)", "response": "Take a. css file and parse it into a dictionary containing class and style pairs."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbasing SVG Document Creation", "response": "def start_svg(self):\n\t\t\"Base SVG Document Creation\"\n\t\tSVG_NAMESPACE = 'http://www.w3.org/2000/svg'\n\t\tSVG = '{%s}' % SVG_NAMESPACE\n\t\tNSMAP = {\n\t\t\tNone: SVG_NAMESPACE,\n\t\t\t'xlink': 'http://www.w3.org/1999/xlink',\n\t\t\t'a3': 'http://ns.adobe.com/AdobeSVGViewerExtensions/3.0/',\n\t\t}\n\t\troot_attrs = self._get_root_attributes()\n\t\tself.root = etree.Element(SVG + \"svg\", attrib=root_attrs, nsmap=NSMAP)\n\t\tif hasattr(self, 'style_sheet_href'):\n\t\t\tpi = etree.ProcessingInstruction(\n\t\t\t\t'xml-stylesheet',\n\t\t\t\t'href=\"%s\" type=\"text/css\"' % self.style_sheet_href\n\t\t\t)\n\t\t\tself.root.addprevious(pi)\n\n\t\tcomment_strings = (\n\t\t\t' Created with SVG.Graph ',\n\t\t\t' SVG.Graph by Jason R. Coombs ',\n\t\t\t' Based on SVG::Graph by Sean E. Russel ',\n\t\t\t' Based on Perl SVG:TT:Graph by Leo Lapworth & Stephan Morgan ',\n\t\t\t' ' + '/' * 66,\n\t\t)\n\t\tlist(map(self.root.append, map(etree.Comment, comment_strings)))\n\n\t\tdefs = etree.SubElement(self.root, 'defs')\n\t\tself.add_defs(defs)\n\n\t\tif not hasattr(self, 'style_sheet_href') and not self.css_inline:\n\t\t\tself.root.append(etree.Comment(\n\t\t\t\t' include default stylesheet if none specified '))\n\t\t\tstyle = etree.SubElement(defs, 'style', type='text/css')\n\t\t\t# TODO: the text was previously escaped in a CDATA declaration... how\n\t\t\t#  to do that with etree?\n\t\t\tstyle.text = self.get_stylesheet().cssText\n\n\t\tself.root.append(etree.Comment('SVG Background'))\n\t\tetree.SubElement(self.root, 'rect', {\n\t\t\t'width': str(self.width),\n\t\t\t'height': str(self.height),\n\t\t\t'x': '0',\n\t\t\t'y': '0',\n\t\t\t'class': 'svgBackground'})"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the stylesheets for this instance", "response": "def get_stylesheet_resources(self):\n\t\t\"Get the stylesheets for this instance\"\n\t\t# allow css to include class variables\n\t\tclass_vars = class_dict(self)\n\t\tloader = functools.partial(\n\t\t\tself.load_resource_stylesheet,\n\t\t\tsubs=class_vars)\n\t\tsheets = list(map(loader, self.stylesheet_names))\n\t\treturn sheets"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef send(self, data, force=False):\n        if self._registered or force:\n            self._sock_file.write('%s\\r\\n' % data)\n            self._sock_file.flush()\n        else:\n            self._out_buffer.append(data)", "response": "\\ Sends data over the wire if the connection is registered."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconnect to the IRC server using the nickname", "response": "def connect(self):\n        \"\"\"\\\n        Connect to the IRC server using the nickname\n        \"\"\"\n        self._sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        if self.use_ssl:\n            self._sock = ssl.wrap_socket(self._sock)\n        try:\n            self._sock.connect((self.server, self.port))\n        except socket.error:\n            self.logger.error('Unable to connect to %s on port %d' % (self.server, self.port), exc_info=1)\n            return False\n\n        self._sock_file = self._sock.makefile()\n        if self.password:\n            self.set_password()\n        self.register_nick()\n        self.register()\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsends a message to a specific user or channel.", "response": "def respond(self, message, channel=None, nick=None):\n        \"\"\"\\\n        Multipurpose method for sending responses to channel or via message to\n        a single user\n        \"\"\"\n        if channel:\n            if not channel.startswith('#'):\n                channel = '#%s' % channel\n            self.send('PRIVMSG %s :%s' % (channel, message))\n        elif nick:\n            self.send('PRIVMSG %s :%s' % (nick, message))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndispatches the patterns of the socket data based on the patterns in the patterns in the patterns list.", "response": "def dispatch_patterns(self):\n        \"\"\"\\\n        Low-level dispatching of socket data based on regex matching, in general\n        handles\n\n        * In event a nickname is taken, registers under a different one\n        * Responds to periodic PING messages from server\n        * Dispatches to registered callbacks when\n            - any user leaves or enters a room currently connected to\n            - a channel message is observed\n            - a private message is received\n        \"\"\"\n        return (\n            (self.nick_re, self.new_nick),\n            (self.nick_change_re, self.handle_nick_change),\n            (self.ping_re, self.handle_ping),\n            (self.part_re, self.handle_part),\n            (self.join_re, self.handle_join),\n            (self.quit_re, self.handle_quit),\n            (self.chanmsg_re, self.handle_channel_message),\n            (self.privmsg_re, self.handle_private_message),\n            (self.registered_re, self.handle_registered),\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef handle_registered(self, server):\n        if not self._registered:\n            self.logger.info('Registered')\n            self._registered = True\n            for data in self._out_buffer:\n                self.send(data)\n            self._out_buffer = []", "response": "Handle a registered connection."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef register_callbacks(self):\n        self.conn.register_callbacks((\n            (re.compile(pattern), callback) \\\n                for pattern, callback in self.command_patterns()\n        ))", "response": "Register callbacks with the connection"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwraps for the conn. respond method.", "response": "def respond(self, message, channel=None, nick=None):\n        \"\"\"\\\n        Wraps the connection object's respond() method\n        \"\"\"\n        self.conn.respond(message, channel, nick)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef register_with_boss(self):\n        gevent.sleep(10) # wait for things to connect, etc\n        \n        while not self.registered.is_set():\n            self.respond('!register {%s}' % platform.node(), nick=self.boss)\n            gevent.sleep(30)", "response": "Register the worker with the boss."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef task_runner(self):\n        while 1:\n            (task_id, command) = self.task_queue.get()\n            \n            for pattern, callback in self.task_patterns:\n                match = re.match(pattern, command)\n                if match:\n                    # execute the callback\n                    ret = callback(**match.groupdict()) or ''\n                    \n                    # clear the stop flag in the event it was set\n                    self.stop_flag.clear()\n                    \n                    # send output of command to channel\n                    for line in ret.splitlines():\n                        self.respond('!task-data %s:%s' % (task_id, line), self.channel)\n                        gevent.sleep(.34)\n            \n            # indicate task is complete\n            self.respond('!task-finished %s' % task_id, self.channel)", "response": "This function is run in a greenlet and will pull the task queue and execute the task callbacks."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef require_boss(self, callback):\n        def inner(nick, message, channel, *args, **kwargs):\n            if nick != self.boss:\n                return\n            \n            return callback(nick, message, channel, *args, **kwargs)\n        return inner", "response": "Decorator to ensure that the command can come from the boss."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef command_patterns(self):\n        return (\n            ('!register-success (?P<cmd_channel>.+)', self.require_boss(self.register_success)),\n            ('!worker-execute (?:\\((?P<workers>.+?)\\) )?(?P<task_id>\\d+):(?P<command>.+)', self.require_boss(self.worker_execute)),\n            ('!worker-ping', self.require_boss(self.worker_ping_handler)),\n            ('!worker-stop', self.require_boss(self.worker_stop)),\n        )", "response": "Return a list of command patterns that can be used to dispatch the command to the worker bot."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef register_success(self, nick, message, channel, cmd_channel):\n        # the boss will tell what channel to join\n        self.channel = cmd_channel\n        self.conn.join(self.channel)\n        \n        # indicate that registered so we'll stop trying\n        self.registered.set()", "response": "This method is called when the bot is successfully registered with the command channel."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nindicate that the worker with given nick is performing this task", "response": "def add(self, nick):\n        \"\"\"\\\n        Indicate that the worker with given nick is performing this task\n        \"\"\"\n        self.data[nick] = ''\n        self.workers.add(nick)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef send_validation_email(self):\n        if self.email_verified:\n            raise ValueError(_('Cannot validate already active user.'))\n\n        site = Site.objects.get_current()\n        self.validation_notification(user=self, site=site).notify()", "response": "Send a validation email to the user s email address."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef send_password_reset(self):\n        site = Site.objects.get_current()\n        self.password_reset_notification(user=self, site=site).notify()", "response": "Send a password reset notification to the user s email address."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef validate_password_strength(value):\n    used_chars = set(value)\n    good_chars = set(ascii_letters + digits + punctuation + ' ')\n    required_sets = (ascii_uppercase, ascii_lowercase, digits)\n\n    if not used_chars.issubset(good_chars):\n        raise ValidationError(too_fancy)\n\n    for required in required_sets:\n        if not used_chars.intersection(required):\n            raise ValidationError(too_simple)", "response": "Validate that the password strength is correct."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nverifies that the user has a valid token.", "response": "def verify_token(self, request, *args, **kwargs):\n        \"\"\"\n        Use `token` to allow one-time access to a view.\n\n        Set the user as a class attribute or raise an `InvalidExpiredToken`.\n\n        Token expiry can be set in `settings` with `VERIFY_ACCOUNT_EXPIRY` and is\n        set in seconds.\n        \"\"\"\n        User = get_user_model()\n\n        try:\n            max_age = settings.VERIFY_ACCOUNT_EXPIRY\n        except AttributeError:\n            max_age = self.DEFAULT_VERIFY_ACCOUNT_EXPIRY\n\n        try:\n            email_data = signing.loads(kwargs['token'], max_age=max_age)\n        except signing.BadSignature:\n            raise self.invalid_exception_class\n\n        email = email_data['email']\n\n        try:\n            self.user = User.objects.get_by_natural_key(email)\n        except User.DoesNotExist:\n            raise self.invalid_exception_class\n\n        if self.user.email_verified:\n            raise self.permission_denied_class"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delete(self, request, *args, **kwargs):\n        user = self.get_object()\n        user.avatar = None\n        user.save()\n        return response.Response(status=HTTP_204_NO_CONTENT)", "response": "Delete the user s avatar."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nallows the given request to be throttled.", "response": "def allow_request(self, request, view):\n        \"\"\"\n        Throttle POST requests only.\n        \"\"\"\n        if request.method != 'POST':\n            return True\n\n        return super(PostRequestThrottleMixin, self).allow_request(request, view)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsingle global client instance", "response": "def client(self):\n        \"\"\"single global client instance\"\"\"\n        cls = self.__class__\n\n        if cls._client is None:\n            kwargs = {}\n            if self.tls_config:\n                kwargs['tls'] = docker.tls.TLSConfig(**self.tls_config)\n            kwargs.update(kwargs_from_env())\n            client = docker.APIClient(version='auto', **kwargs)\n\n            cls._client = client\n        return cls._client"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef tls_client(self):\n        if self.tls_cert and self.tls_key:\n            return (self.tls_cert, self.tls_key)\n        return None", "response": "A tuple consisting of the TLS client certificate and key if they have been provided otherwise None."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the service name inside the Docker Swarm", "response": "def service_name(self):\n        \"\"\"\n        Service name inside the Docker Swarm\n\n        service_suffix should be a numerical value unique for user\n        {service_prefix}-{service_owner}-{service_suffix}\n        \"\"\"\n        if hasattr(self, \"server_name\") and self.server_name:\n            server_name = self.server_name\n        else:\n            server_name = 1\n\n        return \"{}-{}-{}\".format(self.service_prefix,\n                                 self.service_owner,\n                                 server_name\n                                 )"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwraps for calling docker methods", "response": "def _docker(self, method, *args, **kwargs):\n        \"\"\"wrapper for calling docker methods\n\n        to be passed to ThreadPoolExecutor\n        \"\"\"\n        m = getattr(self.client, method)\n        return m(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncall a docker method in a background thread returns a Future", "response": "def docker(self, method, *args, **kwargs):\n        \"\"\"Call a docker method in a background thread\n\n        returns a Future\n        \"\"\"\n        return self.executor.submit(self._docker, method, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef poll(self):\n        service = yield self.get_service()\n        if not service:\n            self.log.warn(\"Docker service not found\")\n            return 0\n\n        task_filter = {'service': service['Spec']['Name']}\n\n        tasks = yield self.docker(\n            'tasks', task_filter\n        )\n\n        running_task = None\n        for task in tasks:\n            task_state = task['Status']['State']\n            self.log.debug(\n                \"Task %s of Docker service %s status: %s\",\n                task['ID'][:7],\n                self.service_id[:7],\n                pformat(task_state),\n            )\n            if task_state == 'running':\n                # there should be at most one running task\n                running_task = task\n\n        if running_task is not None:\n            return None\n        else:\n            return 1", "response": "Check for a task state like docker service ps id"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef start(self):\n\n        # https://github.com/jupyterhub/jupyterhub/blob/master/jupyterhub/user.py#L202\n        # By default jupyterhub calls the spawner passing user_options\n        if self.use_user_options:\n            user_options = self.user_options\n        else:\n            user_options = {}\n\n        self.log.warn(\"user_options: {}\".format(user_options))\n\n        service = yield self.get_service()\n\n        if service is None:\n\n            if 'name' in user_options:\n                self.server_name = user_options['name']\n\n            if hasattr(self, 'container_spec') and self.container_spec is not None:\n                container_spec = dict(**self.container_spec)\n            elif user_options == {}:\n                raise(\"A container_spec is needed in to create a service\")\n\n            container_spec.update(user_options.get('container_spec', {}))\n\n            # iterates over mounts to create\n            # a new mounts list of docker.types.Mount\n            container_spec['mounts'] = []\n            for mount in self.container_spec['mounts']:\n                m = dict(**mount)\n\n                if 'source' in m:\n                    m['source'] = m['source'].format(\n                        username=self.service_owner)\n\n                if 'driver_config' in m:\n                    device = m['driver_config']['options']['device'].format(\n                        username=self.service_owner\n                    )\n                    m['driver_config']['options']['device'] = device\n                    m['driver_config'] = docker.types.DriverConfig(\n                        **m['driver_config'])\n\n                container_spec['mounts'].append(docker.types.Mount(**m))\n\n            # some Envs are required by the single-user-image\n            container_spec['env'] = self.get_env()\n\n            if hasattr(self, 'resource_spec'):\n                resource_spec = self.resource_spec\n            resource_spec.update(user_options.get('resource_spec', {}))\n\n            if hasattr(self, 'networks'):\n                networks = self.networks\n            if user_options.get('networks') is not None:\n                networks = user_options.get('networks')\n\n            if hasattr(self, 'placement'):\n                placement = self.placement\n            if user_options.get('placement') is not None:\n                placement = user_options.get('placement')\n\n            image = container_spec['Image']\n            del container_spec['Image']\n\n            # create the service\n            container_spec = docker.types.ContainerSpec(\n                image, **container_spec)\n            resources = docker.types.Resources(**resource_spec)\n\n            task_spec = {'container_spec': container_spec,\n                         'resources': resources,\n                         'placement': placement\n                         }\n            task_tmpl = docker.types.TaskTemplate(**task_spec)\n\n            resp = yield self.docker('create_service',\n                                     task_tmpl,\n                                     name=self.service_name,\n                                     networks=networks)\n\n            self.service_id = resp['ID']\n\n            self.log.info(\n                \"Created Docker service '%s' (id: %s) from image %s\",\n                self.service_name, self.service_id[:7], image)\n\n        else:\n            self.log.info(\n                \"Found existing Docker service '%s' (id: %s)\",\n                self.service_name, self.service_id[:7])\n            # Handle re-using API token.\n            # Get the API token from the environment variables\n            # of the running service:\n            envs = service['Spec']['TaskTemplate']['ContainerSpec']['Env']\n            for line in envs:\n                if line.startswith('JPY_API_TOKEN='):\n                    self.api_token = line.split('=', 1)[1]\n                    break\n\n        ip = self.service_name\n        port = self.service_port\n\n        # we use service_name instead of ip\n        # https://docs.docker.com/engine/swarm/networking/#use-swarm-mode-service-discovery\n        # service_port is actually equal to 8888\n        return (ip, port)", "response": "Start a single - user server in a docker service."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef stop(self, now=False):\n        self.log.info(\n            \"Stopping and removing Docker service %s (id: %s)\",\n            self.service_name, self.service_id[:7])\n        yield self.docker('remove_service', self.service_id[:7])\n        self.log.info(\n            \"Docker service %s (id: %s) removed\",\n            self.service_name, self.service_id[:7])\n\n        self.clear_state()", "response": "Stop and remove the service from the registry"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks lower - cased email is unique.", "response": "def filter_queryset(self, value, queryset):\n        \"\"\"Check lower-cased email is unique.\"\"\"\n        return super(UniqueEmailValidator, self).filter_queryset(\n            value.lower(),\n            queryset,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update(self, instance, validated_data):\n        if not instance.check_password(validated_data['old_password']):\n            msg = _('Invalid password.')\n            raise serializers.ValidationError({'old_password': msg})\n\n        instance.set_password(validated_data['new_password'])\n        instance.save()\n        return instance", "response": "Check the old password is valid and set the new password."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nupdating the user s password.", "response": "def update(self, instance, validated_data):\n        \"\"\"Set the new password for the user.\"\"\"\n        instance.set_password(validated_data['new_password'])\n        instance.save()\n        return instance"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nvalidating if the given email address exists and requires a verification.", "response": "def validate_email(self, email):\n        \"\"\"\n        Validate if email exists and requires a verification.\n\n        `validate_email` will set a `user` attribute on the instance allowing\n        the view to send an email confirmation.\n        \"\"\"\n        try:\n            self.user = User.objects.get_by_natural_key(email)\n        except User.DoesNotExist:\n            msg = _('A user with this email address does not exist.')\n            raise serializers.ValidationError(msg)\n\n        if self.user.email_verified:\n            msg = _('User email address is already verified.')\n            raise serializers.ValidationError(msg)\n        return email"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef post(self, request):\n        serializer = self.serializer_class(data=request.data)\n        if serializer.is_valid():\n            user = serializer.validated_data['user']\n            signals.user_logged_in.send(type(self), user=user, request=request)\n            token = self.model.objects.create(user=user)\n            token.update_expiry()\n            return response.Response({'token': token.key})\n\n        return response.Response(\n            serializer.errors, status=status.HTTP_400_BAD_REQUEST)", "response": "Create auth token. Differs from DRF that it always creates new token but not re - using them."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete(self, request, *args, **kwargs):\n        # Logic repeated from DRF because one cannot easily reuse it\n        auth = get_authorization_header(request).split()\n\n        if not auth or auth[0].lower() != b'token':\n            return response.Response(status=status.HTTP_400_BAD_REQUEST)\n\n        if len(auth) == 1:\n            msg = 'Invalid token header. No credentials provided.'\n            return response.Response(msg, status=status.HTTP_400_BAD_REQUEST)\n        elif len(auth) > 2:\n            msg = 'Invalid token header. Token string should not contain spaces.'\n            return response.Response(msg, status=status.HTTP_400_BAD_REQUEST)\n\n        try:\n            token = self.model.objects.get(key=auth[1])\n        except self.model.DoesNotExist:\n            pass\n        else:\n            token.delete()\n            signals.user_logged_out.send(\n                type(self),\n                user=token.user,\n                request=request,\n            )\n        return response.Response(status=status.HTTP_204_NO_CONTENT)", "response": "Delete auth token when delete request was issued."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndisallows users other than the user whose email is being reset.", "response": "def initial(self, request, *args, **kwargs):\n        \"\"\"Disallow users other than the user whose email is being reset.\"\"\"\n        email = request.data.get('email')\n        if request.user.is_authenticated() and email != request.user.email:\n            raise PermissionDenied()\n\n        return super(ResendConfirmationEmail, self).initial(\n            request,\n            *args,\n            **kwargs\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef post(self, request, *args, **kwargs):\n        serializer = self.serializer_class(data=request.data)\n\n        if not serializer.is_valid():\n            return response.Response(\n                serializer.errors,\n                status=status.HTTP_400_BAD_REQUEST,\n            )\n\n        serializer.user.send_validation_email()\n        msg = _('Email confirmation sent.')\n        return response.Response(msg, status=status.HTTP_204_NO_CONTENT)", "response": "Validate email and send a request to confirm it."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nvalidate that the email is unique and return it.", "response": "def clean_email(self):\n        \"\"\"\n        Since User.email is unique, this check is redundant,\n        but it sets a nicer error message than the ORM. See #13147.\n        \"\"\"\n        email = self.cleaned_data['email']\n        try:\n            User._default_manager.get(email__iexact=email)\n        except User.DoesNotExist:\n            return email.lower()\n        raise forms.ValidationError(self.error_messages['duplicate_email'])"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_expiry(self, commit=True):\n        self.expires = update_expiry(self.created)\n        if commit:\n            self.save()", "response": "Update token s expiration datetime on every auth action."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef password_reset_email_context(notification):\n    return {\n        'protocol': 'https',\n        'uid': notification.user.generate_uid(),\n        'token': notification.user.generate_token(),\n        'site': notification.site,\n    }", "response": "Generate email context to reset a user password."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef email_handler(notification, email_context):\n    incuna_mail.send(\n        to=notification.user.email,\n        subject=notification.email_subject,\n        template_name=notification.text_email_template,\n        html_template_name=notification.html_email_template,\n        context=email_context(notification),\n        headers=getattr(notification, 'headers', {}),\n    )", "response": "Send a notification by email."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef password_reset_email_handler(notification):\n    base_subject = _('{domain} password reset').format(domain=notification.site.domain)\n    subject = getattr(settings, 'DUM_PASSWORD_RESET_SUBJECT', base_subject)\n    notification.email_subject = subject\n    email_handler(notification, password_reset_email_context)", "response": "Password reset email handler."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef authenticate(self, request):\n        try:\n            key = request.data['token']\n        except KeyError:\n            return\n\n        try:\n            token = AuthToken.objects.get(key=key)\n        except AuthToken.DoesNotExist:\n            return\n\n        return (token.user, token)", "response": "Authenticate a user from a token form field\n\n        Returns a tuple of user and AuthToken instance"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef authenticate_credentials(self, key):\n        user, token = super(TokenAuthentication, self).authenticate_credentials(key)\n\n        if token.expires < timezone.now():\n            msg = _('Token has expired.')\n            raise exceptions.AuthenticationFailed(msg)\n\n        # Update the token's expiration date\n        token.update_expiry()\n\n        return (user, token)", "response": "Custom authentication to check if auth token has expired."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef notebook_show(obj, doc, comm):\n    target = obj.ref['id']\n    load_mime = 'application/vnd.holoviews_load.v0+json'\n    exec_mime = 'application/vnd.holoviews_exec.v0+json'\n\n    # Publish plot HTML\n    bokeh_script, bokeh_div, _ = bokeh.embed.notebook.notebook_content(obj, comm.id)\n    publish_display_data(data={'text/html': encode_utf8(bokeh_div)})\n\n    # Publish comm manager\n    JS = '\\n'.join([PYVIZ_PROXY, JupyterCommManager.js_manager])\n    publish_display_data(data={load_mime: JS, 'application/javascript': JS})\n\n    # Publish bokeh plot JS\n    msg_handler = bokeh_msg_handler.format(plot_id=target)\n    comm_js = comm.js_template.format(plot_id=target, comm_id=comm.id, msg_handler=msg_handler)\n    bokeh_js = '\\n'.join([comm_js, bokeh_script])\n\n    # Note: extension should be altered so text/html is not required\n    publish_display_data(data={exec_mime: '', 'text/html': '',\n                               'application/javascript': bokeh_js},\n                         metadata={exec_mime: {'id': target}})", "response": "Displays bokeh output inside a notebook."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_customjs(self, change, p_name):\n        data_template = \"data = {{p_name: '{p_name}', value: cb_obj['{change}']}};\"\n        fetch_data = data_template.format(change=change, p_name=p_name)\n        self_callback = JS_CALLBACK.format(comm_id=self.comm.id,\n                                           timeout=self.timeout,\n                                           debounce=self.debounce,\n                                           plot_id=self.plot_id)\n        js_callback = CustomJS(code='\\n'.join([fetch_data,\n                                               self_callback]))\n        return js_callback", "response": "Returns a CustomJS callback that can be attached to send the\n        widget state across the notebook comms."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef widget(self, param_name):\n        if param_name not in self._widgets:\n            self._widgets[param_name] = self._make_widget(param_name)\n        return self._widgets[param_name]", "response": "Get widget for param_name"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning name widget boxes for all parameters.", "response": "def widgets(self):\n        \"\"\"Return name,widget boxes for all parameters (i.e., a property sheet)\"\"\"\n\n        params = self.parameterized.params().items()\n        key_fn = lambda x: x[1].precedence if x[1].precedence is not None else self.p.default_precedence\n        sorted_precedence = sorted(params, key=key_fn)\n        outputs = [k for k, p in sorted_precedence if isinstance(p, _View)]\n        filtered = [(k,p) for (k,p) in sorted_precedence\n                    if ((p.precedence is None) or (p.precedence >= self.p.display_threshold))\n                    and k not in outputs]\n        groups = itertools.groupby(filtered, key=key_fn)\n        sorted_groups = [sorted(grp) for (k,grp) in groups]\n        ordered_params = [el[0] for group in sorted_groups for el in group]\n\n        # Format name specially\n        ordered_params.pop(ordered_params.index('name'))\n        widgets = [Div(text='<b>{0}</b>'.format(self.parameterized.name))]\n\n        def format_name(pname):\n            p = self.parameterized.params(pname)\n            # omit name for buttons, which already show the name on the button\n            name = \"\" if issubclass(type(p),param.Action) else pname\n            return Div(text=name)\n\n        if self.p.show_labels:\n            widgets += [self.widget(pname) for pname in ordered_params]\n        else:\n            widgets += [self.widget(pname) for pname in ordered_params]\n\n        if self.p.button and not (self.p.callback is None and self.p.next_n==0):\n            display_button = Button(label=self.p.button_text)\n            def click_cb():\n                # Execute and clear changes since last button press\n                try:\n                    self.execute(self._changed)\n                except Exception as e:\n                    self._changed.clear()\n                    raise e\n                self._changed.clear()\n            display_button.on_click(click_cb)\n            widgets.append(display_button)\n\n        outputs = [self.widget(pname) for pname in outputs]\n        return widgets, outputs"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a TextInput instance with the given arguments and keyword arguments.", "response": "def TextWidget(*args, **kw):\n    \"\"\"Forces a parameter value to be text\"\"\"\n    kw['value'] = str(kw['value'])\n    kw.pop('options', None)\n    return TextInput(*args,**kw)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngiving a list of objects returns a dictionary mapping from string name for the object to the object itself.", "response": "def named_objs(objlist):\n    \"\"\"\n    Given a list of objects, returns a dictionary mapping from\n    string name for the object to the object itself.\n    \"\"\"\n    objs = []\n    for k, obj in objlist:\n        if hasattr(k, '__name__'):\n            k = k.__name__\n        else:\n            k = as_unicode(k)\n        objs.append((k, obj))\n    return objs"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the instance or class owning the supplied method.", "response": "def get_method_owner(meth):\n    \"\"\"\n    Returns the instance owning the supplied instancemethod or\n    the class owning the supplied classmethod.\n    \"\"\"\n    if inspect.ismethod(meth):\n        if sys.version_info < (3,0):\n            return meth.im_class if meth.im_self is None else meth.im_self\n        else:\n            return meth.__self__"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _assign_auth_values(self, http_auth):\n        if not http_auth:\n            pass\n        elif isinstance(http_auth, (tuple, list)):\n            self._auth_user, self._auth_password = http_auth\n        elif isinstance(http_auth, str):\n            self._auth_user, self._auth_password = http_auth.split(':')\n        else:\n            raise ValueError('HTTP Auth Credentials should be str or '\n                             'tuple, not %s' % type(http_auth))", "response": "Assign the username and password of the attributes that are set in the object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ping(self, params=None):\n        try:\n            self.transport.perform_request('HEAD', '/', params=params)\n        except TransportError:\n            raise gen.Return(False)\n        raise gen.Return(True)", "response": "Checks if the cluster is up."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef info(self, params=None):\n        _, data = yield self.transport.perform_request('GET', '/',\n                                                       params=params)\n        raise gen.Return(data)", "response": "Get basic info from the current cluster."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create(self, index, doc_type, body, id=None, params=None):\n        result = yield self.index(index, doc_type, body, id=id, params=params,\n                                  op_type='create')\n        raise gen.Return(result)", "response": "Adds a typed JSON document in a specific index making it searchable."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef index(self, index, doc_type, body, id=None, params=None):\n        _, data = yield self.transport.perform_request(\n            'PUT' if id else 'POST', _make_path(index, doc_type, id),\n            params=params, body=body)\n        raise gen.Return(data)", "response": "Add or update a typed JSON document in a specific index making it searchable."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a boolean indicating whether or not given document exists in the given index.", "response": "def exists(self, index, id, doc_type='_all', params=None):\n        \"\"\"\n        Returns a boolean indicating whether or not given document exists in\n        Elasticsearch. `<http://elasticsearch.org/guide/reference/api/get/>`_\n\n        :arg index: The name of the index\n        :arg id: The document ID\n        :arg doc_type: The type of the document (uses `_all` by default to\n            fetch the first document matching the ID across all types)\n        :arg parent: The ID of the parent document\n        :arg preference: Specify the node or shard the operation should be\n            performed on (default: random)\n        :arg realtime: Specify whether to perform the operation in realtime or\n            search mode\n        :arg refresh: Refresh the shard containing the document before\n            performing the operation\n        :arg routing: Specific routing value\n        \"\"\"\n        try:\n            self.transport.perform_request(\n                'HEAD', _make_path(index, doc_type, id), params=params)\n        except exceptions.NotFoundError:\n            return gen.Return(False)\n        raise gen.Return(True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nretrieving a specified alias.", "response": "def get_alias(self, index=None, name=None, params=None):\n        \"\"\"\n        Retrieve a specified alias.\n        `<http://www.elastic.co/guide/en/elasticsearch/reference/current/indices-aliases.html>`_\n        :arg index: A comma-separated list of index names to filter aliases\n        :arg name: A comma-separated list of alias names to return\n        :arg allow_no_indices: Whether to ignore if a wildcard indices\n            expression resolves into no concrete indices. (This includes `_all`\n            string or when no indices have been specified)\n        :arg expand_wildcards: Whether to expand wildcard expression to\n            concrete indices that are open, closed or both., default 'all',\n            valid choices are: 'open', 'closed', 'none', 'all'\n        :arg ignore_unavailable: Whether specified concrete indices should be\n            ignored when unavailable (missing or closed)\n        :arg local: Return local information, do not retrieve the state from\n            master node (default: false)\n        \"\"\"\n        _, result = yield self.transport.perform_request(\n            'GET', _make_path(index, '_alias', name), params=params)\n        raise gen.Return(result)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nexecutes a search query and get back search hits", "response": "def search(self, index=None, doc_type=None, body=None, params=None):\n        \"\"\"\n        Execute a search query and get back search hits that match the query.\n        `<http://www.elasticsearch.org/guide/reference/api/search/>`_\n\n        :arg index: A comma-separated list of index names to search; use `_all`\n            or empty string to perform the operation on all indices\n        :arg doc_type: A comma-separated list of document types to search;\n            leave empty to perform the operation on all types\n        :arg body: The search definition using the Query DSL\n        :arg _source: True or false to return the _source field or not, or a\n            list of fields to return\n        :arg _source_exclude: A list of fields to exclude from the returned\n            _source field\n        :arg _source_include: A list of fields to extract and return from the\n            _source field\n        :arg analyze_wildcard: Specify whether wildcard and prefix queries\n            should be analyzed (default: false)\n        :arg analyzer: The analyzer to use for the query string\n        :arg default_operator: The default operator for query string query (AND\n            or OR) (default: OR)\n        :arg df: The field to use as default where no field prefix is given in\n            the query string\n        :arg explain: Specify whether to return detailed information about\n            score computation as part of a hit\n        :arg fields: A comma-separated list of fields to return as part of a hit\n        :arg ignore_indices: When performed on multiple indices, allows to\n            ignore `missing` ones (default: none)\n        :arg indices_boost: Comma-separated list of index boosts\n        :arg lenient: Specify whether format-based query failures (such as\n            providing text to a numeric field) should be ignored\n        :arg lowercase_expanded_terms: Specify whether query terms should be\n            lowercased\n        :arg from_: Starting offset (default: 0)\n        :arg preference: Specify the node or shard the operation should be\n            performed on (default: random)\n        :arg q: Query in the Lucene query string syntax\n        :arg routing: A comma-separated list of specific routing values\n        :arg scroll: Specify how long a consistent view of the index should be\n            maintained for scrolled search\n        :arg search_type: Search operation type\n        :arg size: Number of hits to return (default: 10)\n        :arg sort: A comma-separated list of <field>:<direction> pairs\n        :arg source: The URL-encoded request definition using the Query DSL\n            (instead of using request body)\n        :arg stats: Specific 'tag' of the request for logging and statistical\n            purposes\n        :arg suggest_field: Specify which field to use for suggestions\n        :arg suggest_mode: Specify suggest mode (default: missing)\n        :arg suggest_size: How many suggestions to return in response\n        :arg suggest_text: The source text for which the suggestions should be\n            returned\n        :arg timeout: Explicit operation timeout\n        :arg version: Specify whether to return document version as part of a\n            hit\n        \"\"\"\n        # from is a reserved word so it cannot be used, use from_ instead\n        if 'from_' in params:\n            params['from'] = params.pop('from_')\n\n        if doc_type and not index:\n            index = '_all'\n        _, data = yield self.transport.perform_request('GET',\n                                                       _make_path(index,\n                                                                  doc_type,\n                                                                  '_search'),\n                                                       params=params,\n                                                       body=body)\n        raise gen.Return(data)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nscrolling a search request created by specifying the scroll parameter.", "response": "def scroll(self, scroll_id, scroll, params=None):\n        \"\"\"\n        Scroll a search request created by specifying the scroll parameter.\n        `<http://www.elasticsearch.org/guide/reference/api/search/scroll/>`_\n\n        :arg scroll_id: The scroll ID\n        :arg scroll: Specify how long a consistent view of the index should be\n            maintained for scrolled search\n        \"\"\"\n        body = {\n            \"scroll\": scroll,\n            \"scroll_id\": scroll_id\n        }\n\n        if params:\n            if \"scroll\" in params.keys():\n                params.pop(\"scroll\")\n            if \"scroll_id\" in params.keys():\n                params.pop(\"scroll_id\")\n\n        _, data = yield self.transport.perform_request('POST',\n                                                       _make_path('_search',\n                                                                  'scroll'),\n                                                       body=body,\n                                                       params=params)\n        raise gen.Return(data)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef clear_scroll(self, scroll_id, params=None):\n        if not isinstance(scroll_id, list):\n            scroll_id = [scroll_id]\n\n        body = {\n            \"scroll_id\": scroll_id\n        }\n\n        if params and \"scroll_id\" in params.keys():\n            params.pop(\"scroll_id\")\n\n        _, data = yield self.transport.perform_request('DELETE',\n                                                       _make_path('_search',\n                                                                  'scroll'),\n                                                       body=body,\n                                                       params=params)\n        raise gen.Return(data)", "response": "Clear the scroll request created by specifying the scroll ID or a list of scroll IDs."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nretrieving mapping definition of index or type.", "response": "def get_mapping(self, index=None, doc_type=None, params=None):\n        \"\"\"\n        Retrieve mapping definition of index or index/type.\n        `<http://www.elastic.co/guide/en/elasticsearch/reference/current/indices-get-mapping.html>`_\n        :arg index: A comma-separated list of index names\n        :arg doc_type: A comma-separated list of document types\n        :arg allow_no_indices: Whether to ignore if a wildcard indices\n            expression resolves into no concrete indices. (This includes `_all`\n            string or when no indices have been specified)\n        :arg expand_wildcards: Whether to expand wildcard expression to concrete\n            indices that are open, closed or both., default 'open', valid\n            choices are: 'open', 'closed', 'none', 'all'\n        :arg ignore_unavailable: Whether specified concrete indices should be\n            ignored when unavailable (missing or closed)\n        :arg local: Return local information, do not retrieve the state from\n            master node (default: false)\n        \"\"\"\n        _, data = yield self.transport.perform_request('GET',\n                                                       _make_path(index,\n                                                                  '_mapping',\n                                                                  doc_type),\n                                                       params=params)\n        raise gen.Return(data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef suggest(self, index=None, body=None, params=None):\n        _, data = yield self.transport.perform_request('POST',\n                                                       _make_path(index,\n                                                                  '_suggest'),\n                                                       params=params, body=body)\n        raise gen.Return(data)", "response": "The suggest feature suggests similar looking terms based on a provided index and body."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting a number of bytes to a human readable format", "response": "def bytes_to_readable(num):\r\n        \"\"\"Converts bytes to a human readable format\"\"\"\r\n        if num < 512:\r\n            return \"0 Kb\"\r\n        elif num < 1024:\r\n            return \"1 Kb\"\r\n\r\n        for unit in ['', 'Kb', 'Mb', 'Gb', 'Tb', 'Pb', 'Eb', 'Zb']:\r\n            if abs(num) < 1024.0:\r\n                return \"%3.1f%s\" % (num, unit)\r\n            num /= 1024.0\r\n        return \"%.1f%s\" % (num, 'Yb')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntotal CPU load for Synology DSM", "response": "def cpu_total_load(self):\r\n        \"\"\"Total CPU load for Synology DSM\"\"\"\r\n        system_load = self.cpu_system_load\r\n        user_load = self.cpu_user_load\r\n        other_load = self.cpu_other_load\r\n\r\n        if system_load is not None and \\\r\n           user_load is not None and \\\r\n           other_load is not None:\r\n            return system_load + user_load + other_load"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef memory_size(self, human_readable=True):\r\n        if self._data is not None:\r\n            # Memory is actually returned in KB's so multiply before converting\r\n            return_data = int(self._data[\"memory\"][\"memory_size\"]) * 1024\r\n            if human_readable:\r\n                return SynoFormatHelper.bytes_to_readable(\r\n                    return_data)\r\n            else:\r\n                return return_data", "response": "Returns the total memory size of the Synology DSM"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfunction to get specific network", "response": "def _get_network(self, network_id):\r\n        \"\"\"Function to get specific network (eth0, total, etc)\"\"\"\r\n        if self._data is not None:\r\n            for network in self._data[\"network\"]:\r\n                if network[\"device\"] == network_id:\r\n                    return network"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the total upload speed being used", "response": "def network_up(self, human_readable=True):\r\n        \"\"\"Total upload speed being used\"\"\"\r\n        network = self._get_network(\"total\")\r\n        if network is not None:\r\n            return_data = int(network[\"tx\"])\r\n            if human_readable:\r\n                return SynoFormatHelper.bytes_to_readable(\r\n                    return_data)\r\n            else:\r\n                return return_data"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of all available volumes", "response": "def volumes(self):\r\n        \"\"\"Returns all available volumes\"\"\"\r\n        if self._data is not None:\r\n            volumes = []\r\n            for volume in self._data[\"volumes\"]:\r\n                volumes.append(volume[\"id\"])\r\n            return volumes"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_volume(self, volume_id):\r\n        if self._data is not None:\r\n            for volume in self._data[\"volumes\"]:\r\n                if volume[\"id\"] == volume_id:\r\n                    return volume", "response": "Returns a specific volume"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the total size of the given volume", "response": "def volume_size_total(self, volume, human_readable=True):\r\n        \"\"\"Total size of volume\"\"\"\r\n        volume = self._get_volume(volume)\r\n        if volume is not None:\r\n            return_data = int(volume[\"size\"][\"total\"])\r\n            if human_readable:\r\n                return SynoFormatHelper.bytes_to_readable(\r\n                    return_data)\r\n            else:\r\n                return return_data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntotal used size in percentage for volume", "response": "def volume_percentage_used(self, volume):\r\n        \"\"\"Total used size in percentage for volume\"\"\"\r\n        volume = self._get_volume(volume)\r\n        if volume is not None:\r\n            total = int(volume[\"size\"][\"total\"])\r\n            used = int(volume[\"size\"][\"used\"])\r\n\r\n            if used is not None and used > 0 and \\\r\n               total is not None and total > 0:\r\n                return round((float(used) / float(total)) * 100.0, 1)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the average temperature of all disks making up the volume", "response": "def volume_disk_temp_avg(self, volume):\r\n        \"\"\"Average temperature of all disks making up the volume\"\"\"\r\n        volume = self._get_volume(volume)\r\n        if volume is not None:\r\n            vol_disks = volume[\"disks\"]\r\n            if vol_disks is not None:\r\n                total_temp = 0\r\n                total_disks = 0\r\n\r\n                for vol_disk in vol_disks:\r\n                    disk_temp = self.disk_temp(vol_disk)\r\n                    if disk_temp is not None:\r\n                        total_disks += 1\r\n                        total_temp += disk_temp\r\n\r\n                if total_temp > 0 and total_disks > 0:\r\n                    return round(total_temp / total_disks, 0)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the maximum temperature of all disks making up the volume", "response": "def volume_disk_temp_max(self, volume):\r\n        \"\"\"Maximum temperature of all disks making up the volume\"\"\"\r\n        volume = self._get_volume(volume)\r\n        if volume is not None:\r\n            vol_disks = volume[\"disks\"]\r\n            if vol_disks is not None:\r\n                max_temp = 0\r\n\r\n                for vol_disk in vol_disks:\r\n                    disk_temp = self.disk_temp(vol_disk)\r\n                    if disk_temp is not None and disk_temp > max_temp:\r\n                        max_temp = disk_temp\r\n\r\n                return max_temp"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn all available ( internal ) disks", "response": "def disks(self):\r\n        \"\"\"Returns all available (internal) disks\"\"\"\r\n        if self._data is not None:\r\n            disks = []\r\n            for disk in self._data[\"disks\"]:\r\n                disks.append(disk[\"id\"])\r\n            return disks"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_disk(self, disk_id):\r\n        if self._data is not None:\r\n            for disk in self._data[\"disks\"]:\r\n                if disk[\"id\"] == disk_id:\r\n                    return disk", "response": "Returns a specific disk"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbuilds and execute login request", "response": "def _login(self):\r\n        \"\"\"Build and execute login request\"\"\"\r\n        api_path = \"%s/auth.cgi?api=SYNO.API.Auth&version=2\" % (\r\n            self.base_url,\r\n        )\r\n\r\n        login_path = \"method=login&%s\" % (self._encode_credentials())\r\n\r\n        url = \"%s&%s&session=Core&format=cookie\" % (\r\n            api_path,\r\n            login_path)\r\n        result = self._execute_get_url(url, False)\r\n\r\n        # Parse Result if valid\r\n        if result is not None:\r\n            self.access_token = result[\"data\"][\"sid\"]\r\n            self._debuglog(\"Authentication Succesfull, token: \" +\r\n                           str(self.access_token))\r\n            return True\r\n        else:\r\n            self._debuglog(\"Authentication Failed\")\r\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfunctioning to handle GET requests for a given url.", "response": "def _get_url(self, url, retry_on_error=True):\r\n        \"\"\"Function to handle sessions for a GET request\"\"\"\r\n        # Check if we failed to request the url or need to login\r\n        if self.access_token is None or \\\r\n           self._session is None or \\\r\n           self._session_error:\r\n            # Clear Access Token en reset session error\r\n            self.access_token = None\r\n            self._session_error = False\r\n\r\n            # First Reset the session\r\n            if self._session is not None:\r\n                self._session = None\r\n            self._debuglog(\"Creating New Session\")\r\n            self._session = requests.Session()\r\n            \r\n            # disable SSL certificate verification\r\n            if self._use_https:\r\n                self._session.verify = False\r\n\r\n\r\n            # We Created a new Session so login\r\n            if self._login() is False:\r\n                self._session_error = True\r\n                self._debuglog(\"Login Failed, unable to process request\")\r\n                return\r\n\r\n        # Now request the data\r\n        response = self._execute_get_url(url)\r\n        if (self._session_error or response is None) and retry_on_error:\r\n            self._debuglog(\"Error occured, retrying...\")\r\n            self._get_url(url, False)\r\n\r\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nexecute a GET request and return the response", "response": "def _execute_get_url(self, request_url, append_sid=True):\r\n        \"\"\"Function to execute and handle a GET request\"\"\"\r\n        # Prepare Request\r\n        self._debuglog(\"Requesting URL: '\" + request_url + \"'\")\r\n        if append_sid:\r\n            self._debuglog(\"Appending access_token (SID: \" +\r\n                           self.access_token + \") to url\")\r\n            request_url = \"%s&_sid=%s\" % (\r\n                request_url, self.access_token)\r\n\r\n        # Execute Request\r\n        try:\r\n            resp = self._session.get(request_url)\r\n            self._debuglog(\"Request executed: \" + str(resp.status_code))\r\n            if resp.status_code == 200:\r\n                # We got a response\r\n                json_data = json.loads(resp.text)\r\n\r\n                if json_data[\"success\"]:\r\n                    self._debuglog(\"Succesfull returning data\")\r\n                    self._debuglog(str(json_data))\r\n                    return json_data\r\n                else:\r\n                    if json_data[\"error\"][\"code\"] in {105, 106, 107, 119}:\r\n                        self._debuglog(\"Session error: \" +\r\n                                       str(json_data[\"error\"][\"code\"]))\r\n                        self._session_error = True\r\n                    else:\r\n                        self._debuglog(\"Failed: \" + resp.text)\r\n            else:\r\n                # We got a 404 or 401\r\n                return None\r\n        #pylint: disable=bare-except\r\n        except:\r\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupdate the various instanced modules", "response": "def update(self):\r\n        \"\"\"Updates the various instanced modules\"\"\"\r\n        if self._utilisation is not None:\r\n            api = \"SYNO.Core.System.Utilization\"\r\n            url = \"%s/entry.cgi?api=%s&version=1&method=get&_sid=%s\" % (\r\n                self.base_url,\r\n                api,\r\n                self.access_token)\r\n            self._utilisation.update(self._get_url(url))\r\n        if self._storage is not None:\r\n            api = \"SYNO.Storage.CGI.Storage\"\r\n            url = \"%s/entry.cgi?api=%s&version=1&method=load_info&_sid=%s\" % (\r\n                self.base_url,\r\n                api,\r\n                self.access_token)\r\n            self._storage.update(self._get_url(url))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the various Utilisation variables from the API.", "response": "def utilisation(self):\r\n        \"\"\"Getter for various Utilisation variables\"\"\"\r\n        if self._utilisation is None:\r\n            api = \"SYNO.Core.System.Utilization\"\r\n            url = \"%s/entry.cgi?api=%s&version=1&method=get\" % (\r\n                self.base_url,\r\n                api)\r\n            self._utilisation = SynoUtilization(self._get_url(url))\r\n        return self._utilisation"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef storage(self):\r\n        if self._storage is None:\r\n            api = \"SYNO.Storage.CGI.Storage\"\r\n            url = \"%s/entry.cgi?api=%s&version=1&method=load_info\" % (\r\n                self.base_url,\r\n                api)\r\n            self._storage = SynoStorage(self._get_url(url))\r\n        return self._storage", "response": "Gets the SynoStorage object for the given tag."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a context for a specific request.", "response": "def for_request(request, body=None):\n        \"\"\"Creates the context for a specific request.\"\"\"\n        tenant, jwt_data = Tenant.objects.for_request(request, body)\n        webhook_sender_id = jwt_data.get('sub')\n        sender_data = None\n\n        if body and 'item' in body:\n            if 'sender' in body['item']:\n                sender_data = body['item']['sender']\n            elif 'message' in body['item'] and 'from' in body['item']['message']:\n                sender_data = body['item']['message']['from']\n\n        if sender_data is None:\n            if webhook_sender_id is None:\n                raise BadTenantError('Cannot identify sender in tenant')\n            sender_data = {'id': webhook_sender_id}\n\n        return Context(\n            tenant=tenant,\n            sender=HipchatUser(\n                id=sender_data.get('id'),\n                name=sender_data.get('name'),\n                mention_name=sender_data.get('mention_name'),\n            ),\n            signed_request=request.GET.get('signed_request'),\n            context=jwt_data.get('context') or {},\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef tenant_token(self):\n        rv = getattr(self, '_tenant_token', None)\n        if rv is None:\n            rv = self._tenant_token = self.tenant.get_token()\n        return rv", "response": "The cached token of the current tenant."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef build_attrs(self, extra_attrs=None, **kwargs):\n        \"Helper function for building an attribute dictionary.\"\n        self.attrs = self.widget.build_attrs(extra_attrs=None, **kwargs)\n        return self.attrs", "response": "Helper function for building an attribute dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef with_apps(*apps):\n    apps_set = set(settings.INSTALLED_APPS)\n    apps_set.update(apps)\n    return override_settings(INSTALLED_APPS=list(apps_set))", "response": "A class decorator that makes sure the passed apps are present in the INSTALLED_APPS setting."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nclasses decorator that makes sure the passed apps are not present in INSTALLED_APPS.", "response": "def without_apps(*apps):\n    \"\"\"\n    Class decorator that makes sure the passed apps are not present in\n    INSTALLED_APPS.\n    \"\"\"\n    apps_list = [a for a in settings.INSTALLED_APPS if a not in apps]\n    return override_settings(INSTALLED_APPS=apps_list)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_global_settings(self):\n        return dict((key, getattr(global_settings, key)) for key in dir(global_settings)\n                    if key.isupper())", "response": "Return a dictionary of all global_settings values."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nhandle the retrieval of the code", "response": "def do_GET(self):\n\t\t\"\"\"\n\t\tHandle the retrieval of the code\n\t\t\"\"\"\n\t\tparsed_url = urlparse(self.path)\n\n\t\tif parsed_url[2] == \"/\" + SERVER_REDIRECT_PATH:  # 2 = Path\n\t\t\tparsed_query = parse_qs(parsed_url[4])  # 4 = Query\n\n\t\t\tif \"code\" not in parsed_query:\n\t\t\t\tself.send_response(200)\n\t\t\t\tself.send_header(\"Content-Type\", \"text/plain\")\n\t\t\t\tself.end_headers()\n\n\t\t\t\tself.wfile.write(\"No code found, try again!\".encode(\"utf-8\"))\n\t\t\t\treturn\n\n\t\t\tself.server.response_code = parsed_query[\"code\"][0]\n\n\t\t\tself.send_response(200)\n\t\t\tself.send_header(\"Content-Type\", \"text/plain\")\n\t\t\tself.end_headers()\n\n\t\t\tself.wfile.write(\n\t\t\t\t\"Thank you for using OAuth2Util. The authorization was successful, \"\n\t\t\t\t\"you can now close this window.\".encode(\"utf-8\"))\n\t\telif parsed_url[2] == \"/\" + SERVER_LINK_PATH: # 2 = Path\n\t\t\tself.send_response(200)\n\t\t\tself.send_header(\"Content-Type\", \"text/html\")\n\t\t\tself.end_headers()\n\n\t\t\tself.wfile.write(\"<html><body>Hey there!<br/>Click <a href=\\\"{0}\\\">here</a> to claim your prize.</body></html>\"\n\t\t\t\t.format(self.server.authorize_url).encode(\"utf-8\"))\n\t\telse:\n\t\t\tself.send_response(404)\n\t\t\tself.send_header(\"Content-Type\", \"text/plain\")\n\t\t\tself.end_headers()\n\t\t\tself.wfile.write(\"404 not found\".encode(\"utf-8\"))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the app info read from the config file on the Reddit object self. r", "response": "def _set_app_info(self):\n\t\t\"\"\"\n\t\tSet the app info (id & secret) read from the config file on the Reddit object\n\t\t\"\"\"\n\t\tredirect_url = \"http://{0}:{1}/{2}\".format(SERVER_URL, SERVER_PORT,\n\t\t\t\t\t\t\t\t\t\t\t\t   SERVER_REDIRECT_PATH)\n\t\tself.r.set_oauth_app_info(self._get_value(CONFIGKEY_APP_KEY),\n\t\t\t\t\t\t\t\t  self._get_value(CONFIGKEY_APP_SECRET),\n\t\t\t\t\t\t\t\t  redirect_url)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_value(self, key, func=None, split_val=None, as_boolean=False,\n\t\texception_default=None):\n\t\t\"\"\"\n\t\tHelper method to get a value from the config\n\t\t\"\"\"\n\t\ttry:\n\t\t\tif as_boolean:\n\t\t\t\treturn self.config.getboolean(key[0], key[1])\n\t\t\tvalue = self.config.get(key[0], key[1])\n\t\t\tif split_val is not None:\n\t\t\t\tvalue = value.split(split_val)\n\t\t\tif func is not None:\n\t\t\t\treturn func(value)\n\t\t\treturn value\n\t\texcept (KeyError, configparser.NoSectionError, configparser.NoOptionError) as e:\n\t\t\tif exception_default is not None:\n\t\t\t\treturn exception_default\n\t\t\traise KeyError(e)", "response": "Internal method to get a value from the configparser object"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _change_value(self, key, value):\n\t\tif not self.config.has_section(key[0]):\n\t\t\tself.config.add_section(key[0])\n\n\t\tself.config.set(key[0], key[1], str(value))\n\n\t\twith open(self.configfile, \"w\") as f:\n\t\t\tself.config.write(f)", "response": "Change the value of the given key in the given file to the given value."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmigrates the old config file format to the new one", "response": "def _migrate_config(self, oldname=DEFAULT_CONFIG, newname=DEFAULT_CONFIG):\n\t\t\"\"\"\n\t\tMigrates the old config file format to the new one\n\t\t\"\"\"\n\t\tself._log(\"Your OAuth2Util config file is in an old format and needs \"\n\t\t\t\t\"to be changed. I tried as best as I could to migrate it.\", logging.WARNING)\n\n\t\twith open(oldname, \"r\") as old:\n\t\t\twith open(newname, \"w\") as new:\n\t\t\t\tnew.write(\"[app]\\n\")\n\t\t\t\tnew.write(old.read())"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _start_webserver(self, authorize_url=None):\n\t\tserver_address = (SERVER_URL, SERVER_PORT)\n\t\tself.server = HTTPServer(server_address, OAuth2UtilRequestHandler)\n\t\tself.server.response_code = None\n\t\tself.server.authorize_url = authorize_url\n\t\tt = Thread(target=self.server.serve_forever)\n\t\tt.daemon = True\n\t\tt.start()", "response": "Start the webserver that will receive the code\n\t"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwait until the server has accepted or rejected the request.", "response": "def _wait_for_response(self):\n\t\t\"\"\"\n\t\tWait until the user accepted or rejected the request\n\t\t\"\"\"\n\t\twhile not self.server.response_code:\n\t\t\ttime.sleep(2)\n\t\ttime.sleep(5)\n\t\tself.server.shutdown()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_new_access_information(self):\n\t\tif not self.r.has_oauth_app_info:\n\t\t\tself._log('Cannot obtain authorize url from PRAW. Please check your configuration.', logging.ERROR)\n\t\t\traise AttributeError('Reddit Session invalid, please check your designated config file.')\n\t\turl = self.r.get_authorize_url('UsingOAuth2Util',\n\t\t\t\t\t\tself._get_value(CONFIGKEY_SCOPE, set, split_val=','),\n\t\t\t\t\t\tself._get_value(CONFIGKEY_REFRESHABLE, as_boolean=True))\n\n\t\tself._start_webserver(url)\n\t\tif not self._get_value(CONFIGKEY_SERVER_MODE, as_boolean=True):\n\t\t\twebbrowser.open(url)\n\t\telse:\n\t\t\tprint(\"Webserver is waiting for you :D. Please open {0}:{1}/{2} \"\n\t\t\t\t\t\"in your browser\"\n\t\t\t\t.format(SERVER_URL, SERVER_PORT, SERVER_LINK_PATH))\n\t\tself._wait_for_response()\n\n\t\ttry:\n\t\t\taccess_information = self.r.get_access_information(\n\t\t\t\tself.server.response_code)\n\t\texcept praw.errors.OAuthException:\n\t\t\tself._log(\"Can not authenticate, maybe the app infos (e.g. secret) are wrong.\", logging.ERROR)\n\t\t\traise\n\n\t\tself._change_value(CONFIGKEY_TOKEN, access_information[\"access_token\"])\n\t\tself._change_value(CONFIGKEY_REFRESH_TOKEN, access_information[\"refresh_token\"])\n\t\tself._change_value(CONFIGKEY_VALID_UNTIL, time.time() + TOKEN_VALID_DURATION)", "response": "Get new access information from the reddit server."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _check_token_present(self):\n\t\ttry:\n\t\t\tself._get_value(CONFIGKEY_TOKEN)\n\t\t\tself._get_value(CONFIGKEY_REFRESH_TOKEN)\n\t\t\tself._get_value(CONFIGKEY_REFRESHABLE)\n\t\texcept KeyError:\n\t\t\tself._log(\"Request new Token (CTP)\")\n\t\t\tself._get_new_access_information()", "response": "Check whether the tokens are set and request new ones if not"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_access_credentials(self, _retry=0):\n\t\tif _retry >= 5:\n\t\t\traise ConnectionAbortedError('Reddit is not accessible right now, cannot refresh OAuth2 tokens.')\n\n\t\tself._check_token_present()\n\n\t\ttry:\n\t\t\tself.r.set_access_credentials(self._get_value(CONFIGKEY_SCOPE, set, split_val=\",\"),\n\t\t\t\t\t\t\t\t\t\t  self._get_value(CONFIGKEY_TOKEN),\n\t\t\t\t\t\t\t\t\t\t  self._get_value(CONFIGKEY_REFRESH_TOKEN))\n\t\texcept (praw.errors.OAuthInvalidToken, praw.errors.HTTPException) as e:\n\t\t\t# todo check e status code\n\t\t\t# self._log('Retrying in 5s.')\n\t\t\t# time.sleep(5)\n\t\t\t# self.set_access_credentials(_retry=_retry + 1)\n\n\t\t\tself._log(\"Request new Token (SAC)\")\n\t\t\tself._get_new_access_information()", "response": "Set the token on the Reddit Object again"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef refresh(self, force=False, _retry=0):\n\t\tif _retry >= 5:\n\t\t\traise ConnectionAbortedError('Reddit is not accessible right now, cannot refresh OAuth2 tokens.')\n\t\tself._check_token_present()\n\n\t\t# We check whether another instance already refreshed the token\n\t\tif time.time() > self._get_value(CONFIGKEY_VALID_UNTIL, float, exception_default=0) - REFRESH_MARGIN:\n\t\t\tself.config.read(self.configfile)\n\n\t\t\tif time.time() < self._get_value(CONFIGKEY_VALID_UNTIL, float, exception_default=0) - REFRESH_MARGIN:\n\t\t\t\tself._log(\"Found new token\")\n\t\t\t\tself.set_access_credentials()\n\n\t\tif force or time.time() > self._get_value(CONFIGKEY_VALID_UNTIL, float, exception_default=0) - REFRESH_MARGIN:\n\t\t\tself._log(\"Refresh Token\")\n\t\t\ttry:\n\t\t\t\tnew_token = self.r.refresh_access_information(self._get_value(CONFIGKEY_REFRESH_TOKEN))\n\t\t\t\tself._change_value(CONFIGKEY_TOKEN, new_token[\"access_token\"])\n\t\t\t\tself._change_value(CONFIGKEY_VALID_UNTIL, time.time() + TOKEN_VALID_DURATION)\n\t\t\t\tself.set_access_credentials()\n\t\t\texcept (praw.errors.OAuthInvalidToken, praw.errors.HTTPException) as e:\n\t\t\t\t# todo check e status code\n\t\t\t\t# self._log('Retrying in 5s.')\n\t\t\t\t# time.sleep(5)\n\t\t\t\t# self.refresh(_retry=_retry + 1)\n\n\t\t\t\tself._log(\"Request new Token (REF)\")\n\t\t\t\tself._get_new_access_information()", "response": "Refresh the token from Reddit"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate DynamoDB table for run manifests", "response": "def create_manifest_table(dynamodb_client, table_name):\n    \"\"\"Create DynamoDB table for run manifests\n\n    Arguments:\n    dynamodb_client - boto3 DynamoDB client (not service)\n    table_name - string representing existing table name\n    \"\"\"\n    try:\n        dynamodb_client.create_table(\n            AttributeDefinitions=[\n                {\n                    'AttributeName': DYNAMODB_RUNID_ATTRIBUTE,\n                    'AttributeType': 'S'\n                },\n            ],\n            TableName=table_name,\n            KeySchema=[\n                {\n                    'AttributeName': DYNAMODB_RUNID_ATTRIBUTE,\n                    'KeyType': 'HASH'\n                },\n            ],\n            ProvisionedThroughput={\n                'ReadCapacityUnits': 5,\n                'WriteCapacityUnits': 5\n            }\n        )\n        dynamodb_client.get_waiter('table_exists').wait(TableName=table_name)\n    except ClientError as e:\n        # Table already exists\n        if e.response['Error']['Code'] == 'ResourceInUseException':\n            pass\n        else:\n            raise e"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn list of all run ids inside S3 folder.", "response": "def list_runids(s3_client, full_path):\n    \"\"\"Return list of all run ids inside S3 folder. It does not respect\n    S3 pagination (`MaxKeys`) and returns **all** keys from bucket\n    and won't list any prefixes with object archived to AWS Glacier\n\n    Arguments:\n    s3_client - boto3 S3 client (not service)\n    full_path - full valid S3 path to events (such as enriched-archive)\n                example: s3://acme-events-bucket/main-pipeline/enriched-archive\n    \"\"\"\n    listing_finished = False                 # last response was not truncated\n    run_ids_buffer = []\n    last_continuation_token = None\n\n    (bucket, prefix) = split_full_path(full_path)\n\n    while not listing_finished:\n        options = clean_dict({\n            'Bucket': bucket,\n            'Prefix': prefix,\n            'Delimiter': '/',\n            'ContinuationToken': last_continuation_token\n        })\n\n        response = s3_client.list_objects_v2(**options)\n        keys = [extract_run_id(key['Prefix']) for key\n                in response.get('CommonPrefixes', [])]\n        run_ids_buffer.extend([key for key in keys if key is not None])\n        last_continuation_token = response.get('NextContinuationToken', None)\n\n        if not response['IsTruncated']:\n            listing_finished = True\n\n    non_archived_run_ids = [run_id for run_id in run_ids_buffer\n                            if not is_glacier(s3_client, bucket, run_id)]\n    return non_archived_run_ids"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsplitting a full S3 path into a pair of bucket and path.", "response": "def split_full_path(path):\n    \"\"\"Return pair of bucket without protocol and path\n\n    Arguments:\n    path - valid S3 path, such as s3://somebucket/events\n\n    >>> split_full_path('s3://mybucket/path-to-events')\n    ('mybucket', 'path-to-events/')\n    >>> split_full_path('s3://mybucket')\n    ('mybucket', None)\n    >>> split_full_path('s3n://snowplow-bucket/some/prefix/')\n    ('snowplow-bucket', 'some/prefix/')\n    \"\"\"\n    if path.startswith('s3://'):\n        path = path[5:]\n    elif path.startswith('s3n://'):\n        path = path[6:]\n    elif path.startswith('s3a://'):\n        path = path[6:]\n    else:\n        raise ValueError(\"S3 path should start with s3://, s3n:// or \"\n                         \"s3a:// prefix\")\n    parts = path.split('/')\n    bucket = parts[0]\n    path = '/'.join(parts[1:])\n    return bucket, normalize_prefix(path)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if prefix is archived in Glacier", "response": "def is_glacier(s3_client, bucket, prefix):\n    \"\"\"Check if prefix is archived in Glacier, by checking storage class of\n    first object inside that prefix\n\n    Arguments:\n    s3_client - boto3 S3 client (not service)\n    bucket - valid extracted bucket (without protocol and prefix)\n             example: sowplow-events-data\n    prefix - valid S3 prefix (usually, run_id)\n             example: snowplow-archive/enriched/archive/\n    \"\"\"\n    response = s3_client.list_objects_v2(Bucket=bucket,\n                                         Prefix=prefix,\n                                         MaxKeys=3)  # 3 to not fetch _SUCCESS\n\n    for key in response['Contents']:\n        if key.get('StorageClass', 'STANDARD') == 'GLACIER':\n            return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef extract_run_id(key):\n    filename = key.split('/')[-2]  # -1 element is empty string\n    run_id = filename.lstrip('run=')\n    try:\n        datetime.strptime(run_id, '%Y-%m-%d-%H-%M-%S')\n        return key\n    except ValueError:\n        return None", "response": "Extract date part from run id"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove all keys with Nones as values", "response": "def clean_dict(dict):\n    \"\"\"Remove all keys with Nones as values\n\n    >>> clean_dict({'key': None})\n    {}\n    >>> clean_dict({'empty_s': ''})\n    {'empty_s': ''}\n    \"\"\"\n    if sys.version_info[0] < 3:\n        return {k: v for k, v in dict.iteritems() if v is not None}\n    else:\n        return {k: v for k, v in dict.items() if v is not None}"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd run_id into DynamoDB manifest table", "response": "def add_to_manifest(dynamodb_client, table_name, run_id):\n    \"\"\"Add run_id into DynamoDB manifest table\n\n    Arguments:\n    dynamodb_client - boto3 DynamoDB client (not service)\n    table_name - string representing existing table name\n    run_id - string representing run_id to store\n    \"\"\"\n    dynamodb_client.put_item(\n        TableName=table_name,\n        Item={\n            DYNAMODB_RUNID_ATTRIBUTE: {\n                'S': run_id\n            }\n        }\n    )"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if run_id is stored in DynamoDB table.", "response": "def is_in_manifest(dynamodb_client, table_name, run_id):\n    \"\"\"Check if run_id is stored in DynamoDB table.\n    Return True if run_id is stored or False otherwise.\n\n    Arguments:\n    dynamodb_client - boto3 DynamoDB client (not service)\n    table_name - string representing existing table name\n    run_id - string representing run_id to store\n    \"\"\"\n    response = dynamodb_client.get_item(\n        TableName=table_name,\n        Key={\n            DYNAMODB_RUNID_ATTRIBUTE: {\n                'S': run_id\n            }\n        }\n    )\n    return response.get('Item') is not None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nextract the schema information from Iglu URI", "response": "def extract_schema(uri):\n    \"\"\"\n    Extracts Schema information from Iglu URI\n\n    >>> extract_schema(\"iglu:com.acme-corporation_underscore/event_name-dash/jsonschema/1-10-1\")['vendor']\n    'com.acme-corporation_underscore'\n    \"\"\"\n    match = re.match(SCHEMA_URI_REGEX, uri)\n    if match:\n        return {\n            'vendor': match.group(1),\n            'name': match.group(2),\n            'format': match.group(3),\n            'version': match.group(4)\n\n        }\n    else:\n        raise SnowplowEventTransformationException([\n            \"Schema {} does not conform to regular expression {}\".format(uri, SCHEMA_URI)\n        ])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating an Elasticsearch field name from a schema string", "response": "def fix_schema(prefix, schema):\n    \"\"\"\n    Create an Elasticsearch field name from a schema string\n    \"\"\"\n    schema_dict = extract_schema(schema)\n    snake_case_organization = schema_dict['vendor'].replace('.', '_').lower()\n    snake_case_name = re.sub('([^A-Z_])([A-Z])', '\\g<1>_\\g<2>', schema_dict['name']).lower()\n    model = schema_dict['version'].split('-')[0]\n    return \"{}_{}_{}_{}\".format(prefix, snake_case_organization, snake_case_name, model)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_contexts(contexts):\n    my_json = json.loads(contexts)\n    data = my_json['data']\n    distinct_contexts = {}\n    for context in data:\n        schema = fix_schema(\"contexts\", context['schema'])\n        inner_data = context['data']\n        if schema not in distinct_contexts:\n            distinct_contexts[schema] = [inner_data]\n        else:\n            distinct_contexts[schema].append(inner_data)\n    output = []\n    for key in distinct_contexts:\n        output.append((key, distinct_contexts[key]))\n    return output", "response": "Convert a contexts JSON to an Elasticsearch - compatible list of key - value pairs\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_unstruct(unstruct):\n    my_json = json.loads(unstruct)\n    data = my_json['data']\n    schema = data['schema']\n    if 'data' in data:\n        inner_data = data['data']\n    else:\n        raise SnowplowEventTransformationException([\"Could not extract inner data field from unstructured event\"])\n    fixed_schema = fix_schema(\"unstruct_event\", schema)\n    return [(fixed_schema, inner_data)]", "response": "Convert an unstructured event JSON to a list containing one Elasticsearch - compatible key - value pair\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef transform(line, known_fields=ENRICHED_EVENT_FIELD_TYPES, add_geolocation_data=True):\n    return jsonify_good_event(line.split('\\t'), known_fields, add_geolocation_data)", "response": "Convert a Snowplow enriched event TSV into a JSON\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting a Snowplow enriched event into a JSON object.", "response": "def jsonify_good_event(event, known_fields=ENRICHED_EVENT_FIELD_TYPES, add_geolocation_data=True):\n    \"\"\"\n    Convert a Snowplow enriched event in the form of an array of fields into a JSON\n    \"\"\"\n    if len(event) != len(known_fields):\n        raise SnowplowEventTransformationException(\n            [\"Expected {} fields, received {} fields.\".format(len(known_fields), len(event))]\n        )\n    else:\n        output = {}\n        errors = []\n        if add_geolocation_data and event[LATITUDE_INDEX] != '' and event[LONGITUDE_INDEX] != '':\n            output['geo_location'] = event[LATITUDE_INDEX] + ',' + event[LONGITUDE_INDEX]\n        for i in range(len(event)):\n            key = known_fields[i][0]\n            if event[i] != '':\n                try:\n                    kvpairs = known_fields[i][1](key, event[i])\n                    for kvpair in kvpairs:\n                        output[kvpair[0]] = kvpair[1]\n                except SnowplowEventTransformationException as sete:\n                    errors += sete.error_messages\n                except Exception as e:\n                    errors += [\"Unexpected exception parsing field with key {} and value {}: {}\".format(\n                        known_fields[i][0],\n                        event[i],\n                        repr(e)\n                    )]\n        if errors:\n            raise SnowplowEventTransformationException(errors)\n        else:\n            return output"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nextracting the used view from the TemplateResponse context", "response": "def _get_view_data(self, context_data):\n        \"\"\"\n        Extract the used view from the TemplateResponse context (ContextMixin)\n        \"\"\"\n        view = context_data.get('view')\n        if not isinstance(view, View):\n            view = None\n\n        # Denote interesting objects in the template context\n        template_context = []\n        for key, obj in context_data.items():\n            if isinstance(obj, (BaseForm, BaseFormSet, Model)):\n                template_context.append((key, _format_path(obj.__class__)))\n\n        return {\n            'model': _get_view_model(view),\n            'form': _get_form_class(view),\n            'template_context': template_context,\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_used_template(response):\n    if not hasattr(response, 'template_name'):\n        return None, None\n\n    template = response.template_name\n    if template is None:\n        return None, None\n\n    if isinstance(template, (list, tuple)):\n        # See which template name was really used.\n        if len(template) == 1:\n            return template[0], None\n        else:\n            used_name = _get_used_template_name(template)\n            return used_name, template\n    elif isinstance(template, six.string_types):\n        # Single string\n        return template, None\n    else:\n        # Template object.\n        filename = _get_template_filename(template)\n        template_name = '<template object from {0}>'.format(filename) if filename else '<template object>'\n        return template_name, None", "response": "Get the template used in a TemplateResponse."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef print_context(self, context):\n        text = [CONTEXT_TITLE]\n        for i, context_scope in enumerate(context):\n            dump1 = linebreaksbr(pformat_django_context_html(context_scope))\n            dump2 = pformat_dict_summary_html(context_scope)\n\n            # Collapse long objects by default (e.g. request, LANGUAGES and sql_queries)\n            if len(context_scope) <= 3 and dump1.count('<br />') > 20:\n                (dump1, dump2) = (dump2, dump1)\n\n            text.append(CONTEXT_BLOCK.format(\n                style=PRE_STYLE,\n                num=i,\n                dump1=dump1,\n                dump2=dump2\n            ))\n        return u''.join(text)", "response": "Print the entire template context"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprints a set of variables that are available in the context.", "response": "def print_variables(self, context):\n        \"\"\"\n        Print a set of variables\n        \"\"\"\n        text = []\n        for name, expr in self.variables:\n            # Some extended resolving, to handle unknown variables\n            data = ''\n            try:\n                if isinstance(expr.var, Variable):\n                    data = expr.var.resolve(context)\n                else:\n                    data = expr.resolve(context)  # could return TEMPLATE_STRING_IF_INVALID\n            except VariableDoesNotExist as e:\n                # Failed to resolve, display exception inline\n                keys = []\n                for scope in context:\n                    keys += scope.keys()\n                keys = sorted(set(keys))  # Remove duplicates, e.g. csrf_token\n                return ERROR_TYPE_BLOCK.format(style=PRE_ALERT_STYLE, error=escape(u\"Variable '{0}' not found!  Available context variables are:\\n\\n{1}\".format(expr, u', '.join(keys))))\n            else:\n                # Regular format\n                textdata = linebreaksbr(pformat_django_context_html(data))\n\n            # At top level, prefix class name if it's a longer result\n            if isinstance(data, SHORT_NAME_TYPES):\n                text.append(BASIC_TYPE_BLOCK.format(style=PRE_STYLE, name=name, value=textdata))\n            else:\n                text.append(OBJECT_TYPE_BLOCK.format(style=PRE_STYLE, name=name, type=data.__class__.__name__, value=textdata))\n        return u''.join(text)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nhighlight common SQL words in a string.", "response": "def pformat_sql_html(sql):\n    \"\"\"\n    Highlight common SQL words in a string.\n    \"\"\"\n    sql = escape(sql)\n    sql = RE_SQL_NL.sub(u'<br>\\n\\\\1', sql)\n    sql = RE_SQL.sub(u'<strong>\\\\1</strong>', sql)\n    return sql"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndump a variable to a HTML string with sensible output for template context fields.", "response": "def pformat_django_context_html(object):\n    \"\"\"\n    Dump a variable to a HTML string with sensible output for template context fields.\n    It filters out all fields which are not usable in a template context.\n    \"\"\"\n    if isinstance(object, QuerySet):\n        text = ''\n        lineno = 0\n        for item in object.all()[:21]:\n            lineno += 1\n            if lineno >= 21:\n                text += u'   (remaining items truncated...)'\n                break\n            text += u'   {0}\\n'.format(escape(repr(item)))\n        return text\n    elif isinstance(object, Manager):\n        return mark_safe(u'    (use <kbd>.all</kbd> to read it)')\n    elif isinstance(object, six.string_types):\n        return escape(repr(object))\n    elif isinstance(object, Promise):\n        # lazy() object\n        return escape(_format_lazy(object))\n    elif isinstance(object, dict):\n        # This can also be a ContextDict\n        return _format_dict(object)\n    elif isinstance(object, list):\n        return _format_list(object)\n    elif hasattr(object, '__dict__'):\n        return _format_object(object)\n    else:\n        # Use regular pprint as fallback.\n        text = DebugPrettyPrinter(width=200).pformat(object)\n        return _style_text(text)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\napply some HTML highlighting to the contents of the text.", "response": "def _style_text(text):\n    \"\"\"\n    Apply some HTML highlighting to the contents.\n    This can't be done in the\n    \"\"\"\n    # Escape text and apply some formatting.\n    # To have really good highlighting, pprint would have to be re-implemented.\n    text = escape(text)\n    text = text.replace(' &lt;iterator object&gt;', \" <small>&lt;<var>this object can be used in a 'for' loop</var>&gt;</small>\")\n    text = text.replace(' &lt;dynamic item&gt;', ' <small>&lt;<var>this object may have extra field names</var>&gt;</small>')\n    text = text.replace(' &lt;dynamic attribute&gt;', ' <small>&lt;<var>this object may have extra field names</var>&gt;</small>')\n    text = RE_PROXY.sub('\\g<1><small>&lt;<var>proxy object</var>&gt;</small>', text)\n    text = RE_FUNCTION.sub('\\g<1><small>&lt;<var>object method</var>&gt;</small>', text)\n    text = RE_GENERATOR.sub(\"\\g<1><small>&lt;<var>generator, use 'for' to traverse it</var>&gt;</small>\", text)\n    text = RE_OBJECT_ADDRESS.sub('\\g<1><small>&lt;<var>\\g<2> object</var>&gt;</small>', text)\n    text = RE_MANAGER.sub('\\g<1><small>&lt;<var>manager, use <kbd>.all</kbd> to traverse it</var>&gt;</small>', text)\n    text = RE_CLASS_REPR.sub('\\g<1><small>&lt;<var>\\g<2> class</var>&gt;</small>', text)\n\n    # Since Django's WSGIRequest does a pprint like format for it's __repr__, make that styling consistent\n    text = RE_REQUEST_FIELDNAME.sub('\\g<1>:\\n   <strong style=\"color: #222;\">\\g<2></strong>: ', text)\n    text = RE_REQUEST_CLEANUP1.sub('\\g<1>', text)\n    text = RE_REQUEST_CLEANUP2.sub(')', text)\n\n    return mark_safe(text)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nformats the object into a tree structure.", "response": "def _format_object(object):\n    \"\"\"\n    # Instead of just printing <SomeType at 0xfoobar>, expand the fields.\n    \"\"\"\n\n    attrs = iter(object.__dict__.items())\n    if object.__class__:\n        # Add class members too.\n        attrs = chain(attrs, iter(object.__class__.__dict__.items()))\n\n    # Remove private and protected variables\n    # Filter needless exception classes which are added to each model.\n    # Filter unremoved form.Meta (unline model.Meta) which makes no sense either\n    is_model = isinstance(object, Model)\n    is_form = isinstance(object, BaseForm)\n    attrs = dict(\n        (k, v)\n        for k, v in attrs\n            if not k.startswith('_')\n            and not getattr(v, 'alters_data', False)\n            and not (is_model and k in ('DoesNotExist', 'MultipleObjectsReturned'))\n            and not (is_form and k in ('Meta',))\n    )\n\n    # Add members which are not found in __dict__.\n    # This includes values such as auto_id, c, errors in a form.\n    for member in dir(object):\n        try:\n            if member.startswith('_') or not hasattr(object, member):\n                continue\n        except HANDLED_EXCEPTIONS as e:\n            attrs[member] = _format_exception(e)\n            continue\n\n        value = getattr(object, member)\n        if callable(value) or member in attrs or getattr(value, 'alters_data', False):\n            continue\n\n        attrs[member] = value\n\n    # Format property objects\n    for name, value in list(attrs.items()):  # not iteritems(), so can delete.\n        if isinstance(value, property):\n            attrs[name] = _try_call(lambda: getattr(object, name))\n        elif isinstance(value, types.FunctionType):\n            if PY3:\n                spec = inspect.getfullargspec(value)\n            else:\n                spec = inspect.getargspec(value)\n            if len(spec.args) == 1 or len(spec.args) == len(spec.defaults or ()) + 1:\n                if _is_unsafe_name(name):\n                    # The delete and save methods should have an alters_data = True set.\n                    # however, when delete or save methods are overridden, this is often missed.\n                    attrs[name] = LiteralStr('<Skipped for safety reasons (could alter the database)>')\n                else:\n                    # should be simple method(self) signature to be callable in the template\n                    # function may have args (e.g. BoundField.as_textarea) as long as they have defaults.\n                    attrs[name] = _try_call(lambda: value(object))\n            else:\n                del attrs[name]\n        elif hasattr(value, '__get__'):\n            # fetched the descriptor, e.g. django.db.models.fields.related.ForeignRelatedObjectsDescriptor\n            attrs[name] = value = _try_call(lambda: getattr(object, name), return_exceptions=True)\n            if isinstance(value, Manager):\n                attrs[name] = LiteralStr('<{0} manager>'.format(value.__class__.__name__))\n            elif isinstance(value, AttributeError):\n                del attrs[name]  # e.g. Manager isn't accessible via Model instances.\n            elif isinstance(value, HANDLED_EXCEPTIONS):\n                attrs[name] = _format_exception(value)\n\n    # Include representations which are relevant in template context.\n    if getattr(object, '__str__', None) is not object.__str__:\n        attrs['__str__'] = _try_call(lambda: smart_str(object))\n    elif getattr(object, '__unicode__', None) is not object.__unicode__:\n        attrs['__unicode__'] = _try_call(lambda: smart_str(object))\n\n    if hasattr(object, '__getattr__'):\n        attrs['__getattr__'] = LiteralStr('<dynamic attribute>')\n    if hasattr(object, '__getitem__'):\n        attrs['__getitem__'] = LiteralStr('<dynamic item>')\n    if hasattr(object, '__iter__'):\n        attrs['__iter__'] = LiteralStr('<iterator object>')\n    if hasattr(object, '__len__'):\n        attrs['__len__'] = len(object)\n\n    # Add known __getattr__ members which are useful for template designers.\n    if isinstance(object, BaseForm):\n        for field_name in list(object.fields.keys()):\n            attrs[field_name] = object[field_name]\n        del attrs['__getitem__']\n\n    return _format_dict(attrs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _format_lazy(value):\n    args = value._proxy____args\n    kw = value._proxy____kw\n    if not kw and len(args) == 1 and isinstance(args[0], six.string_types):\n        # Found one of the Xgettext_lazy() calls.\n        return LiteralStr(u'ugettext_lazy({0})'.format(repr(value._proxy____args[0])))\n\n    # Prints <django.functional.utils.__proxy__ object at ..>\n    return value", "response": "Format a lazy call to something meaningful."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncall a method on a butonckal object.", "response": "def _try_call(func, extra_exceptions=(), return_exceptions=False):\n    \"\"\"\n    Call a method, but\n    :param func:\n    :type func:\n    :param extra_exceptions:\n    :type extra_exceptions:\n    :return:\n    :rtype:\n    \"\"\"\n    try:\n        return func()\n    except HANDLED_EXCEPTIONS as e:\n        if return_exceptions:\n            return e\n        else:\n            return _format_exception(e)\n    except extra_exceptions as e:\n        if return_exceptions:\n            return e\n        else:\n            return _format_exception(e)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef format(self, object, context, maxlevels, level):\n        try:\n            return PrettyPrinter.format(self, object, context, maxlevels, level)\n        except HANDLED_EXCEPTIONS as e:\n            return _format_exception(e), True, False", "response": "Format an item in the result."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_token(s, pos, brackets_are_chars=True, environments=True, **parse_flags):\n    return LatexWalker(s, **parse_flags).get_token(pos=pos,\n                                                   brackets_are_chars=brackets_are_chars,\n                                                   environments=environments)", "response": "Parse the next token in the stream."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread a latex expression from the given string at the given position.", "response": "def get_latex_expression(s, pos, **parse_flags):\n    \"\"\"\n    Reads a latex expression, e.g. macro argument. This may be a single char, an escape\n    sequence, or a expression placed in braces.\n\n    Returns a tuple `(<LatexNode instance>, pos, len)`. `pos` is the first char of the\n    expression, and `len` is its length.\n\n    .. deprecated:: 1.0\n       Please use :py:meth:`LatexWalker.get_latex_expression()` instead.\n    \"\"\"\n\n    return LatexWalker(s, **parse_flags).get_latex_expression(pos=pos)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_latex_maybe_optional_arg(s, pos, **parse_flags):\n\n    return LatexWalker(s, **parse_flags).get_latex_maybe_optional_arg(pos=pos)", "response": "Attempts to parse an optional argument. Returns a tuple if success otherwise returns None."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_latex_braced_group(s, pos, brace_type='{', **parse_flags):\n\n    return LatexWalker(s, **parse_flags).get_latex_braced_group(pos=pos, brace_type=brace_type)", "response": "Reads a latex expression enclosed in braces {...."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_latex_environment(s, pos, environmentname=None, **parse_flags):\n\n    return LatexWalker(s, **parse_flags).get_latex_environment(pos=pos, environmentname=environmentname)", "response": "Reads a latex expression enclosed in a \\\\ begin { environment... \\\\ end { environment }."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing latex content s and returns a list of nodes.", "response": "def get_latex_nodes(s, pos=0, stop_upon_closing_brace=None, stop_upon_end_environment=None,\n                    stop_upon_closing_mathmode=None, **parse_flags):\n    \"\"\"\n    Parses latex content `s`.\n\n    Returns a tuple `(nodelist, pos, len)` where nodelist is a list of `LatexNode` 's.\n\n    If `stop_upon_closing_brace` is given, then `len` includes the closing brace, but the\n    closing brace is not included in any of the nodes in the `nodelist`.\n\n    .. deprecated:: 1.0\n       Please use :py:meth:`LatexWalker.get_latex_nodes()` instead.\n    \"\"\"\n\n    return LatexWalker(s, **parse_flags).get_latex_nodes(stop_upon_closing_brace=stop_upon_closing_brace,\n                                                         stop_upon_end_environment=stop_upon_end_environment,\n                                                         stop_upon_closing_mathmode=stop_upon_closing_mathmode)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_token(self, pos, brackets_are_chars=True, environments=True, keep_inline_math=None):\n\n        s = self.s # shorthand\n\n        with _PushPropOverride(self, 'keep_inline_math', keep_inline_math):\n\n            space = ''\n            while (pos < len(s) and s[pos].isspace()):\n                space += s[pos]\n                pos += 1\n                if (space.endswith('\\n\\n')):  # two \\n's indicate new paragraph.\n                    # Adding pre-space is overkill here I think.\n                    return LatexToken(tok='char', arg='\\n\\n', pos=pos-2, len=2, pre_space='')\n\n\n            if (pos >= len(s)):\n                raise LatexWalkerEndOfStream()\n\n            if (s[pos] == '\\\\'):\n                # escape sequence\n                i = 2\n                macro = s[pos+1] # next char is necessarily part of macro\n                # following chars part of macro only if all are alphabetical\n                isalphamacro = False\n                if (s[pos+1].isalpha()):\n                    isalphamacro = True\n                    while pos+i<len(s) and s[pos+i].isalpha():\n                        macro += s[pos+i]\n                        i += 1\n                # possibly followed by a star\n                if (pos+i<len(s) and s[pos+i] == '*'):\n                    macro += '*'\n                    i += 1\n\n                # see if we have a begin/end environment\n                if (environments and (macro == 'begin' or macro == 'end')):\n                    # \\begin{environment} or \\end{environment}\n                    envmatch = re.match(r'^\\s*\\{([\\w*]+)\\}', s[pos+i:])\n                    if (envmatch is None):\n                        raise LatexWalkerParseError(\n                            s=s,\n                            pos=pos,\n                            msg=\"Bad \\\\%s macro: expected {environment}\" %(macro)\n                        )\n\n                    return LatexToken(\n                        tok=('begin_environment' if macro == 'begin' else  'end_environment'),\n                        arg=envmatch.group(1),\n                        pos=pos,\n                        len=i+envmatch.end(), # !!envmatch.end() counts from pos+i\n                        pre_space=space\n                        )\n\n                # get the following whitespace, and store it in the macro's post_space\n                post_space = ''\n                if isalphamacro:\n                    # important, LaTeX does not consume space after non-alpha macros, like \\&\n                    while pos+i<len(s) and s[pos+i].isspace():\n                        post_space += s[pos+i]\n                        i += 1\n\n                return LatexToken(tok='macro', arg=macro, pos=pos, len=i,\n                                  pre_space=space, post_space=post_space)\n\n            if (s[pos] == '%'):\n                # latex comment\n                m = re.search(r'(\\n|\\r|\\n\\r)\\s*', s[pos:])\n                mlen = None\n                if m is not None:\n                    arglen = m.start() # relative to pos already\n                    mlen = m.end() # relative to pos already\n                    mspace = m.group()\n                else:\n                    arglen = len(s)-pos# [  ==len(s[pos:])  ]\n                    mlen = arglen\n                    mspace = ''\n                return LatexToken(tok='comment', arg=s[pos+1:pos+arglen], pos=pos, len=mlen,\n                                  pre_space=space, post_space=mspace)\n\n            openbracechars = '{'\n            closebracechars = '}'\n            if not brackets_are_chars:\n                openbracechars += '['\n                closebracechars += ']'\n\n            if s[pos] in openbracechars:\n                return LatexToken(tok='brace_open', arg=s[pos], pos=pos, len=1, pre_space=space)\n\n            if s[pos] in closebracechars:\n                return LatexToken(tok='brace_close', arg=s[pos], pos=pos, len=1, pre_space=space)\n\n            # check if it is an inline math char, if we care about inline math.\n            if (s[pos] == '$' and self.keep_inline_math):\n                # check that we don't have double-$$, which would be a display environment.\n                if not (pos+1 < len(s) and s[pos+1] == '$'):\n                    return LatexToken(tok='mathmode_inline', arg=s[pos], pos=pos, len=1, pre_space=space)\n                # otherwise, proceed to 'char' type.\n\n            return LatexToken(tok='char', arg=s[pos], pos=pos, len=1, pre_space=space)", "response": "Parses the latex content at the given position and returns a LatexToken object."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreads a LaTeX expression at the given position.", "response": "def get_latex_expression(self, pos, strict_braces=None):\n        \"\"\"\n        Parses the latex content given to the constructor (and stored in `self.s`),\n        starting at position `pos`, to parse a single LaTeX expression.\n\n        Reads a latex expression, e.g. macro argument. This may be a single char, an escape\n        sequence, or a expression placed in braces.  This is what TeX calls a \"token\" (and\n        not what we call a token... anyway).\n\n        Returns a tuple `(node, pos, len)`, where `pos` is the position of the\n        first char of the expression and `len` the length of the expression.\n        \"\"\"\n\n        with _PushPropOverride(self, 'strict_braces', strict_braces):\n\n            tok = self.get_token(pos, environments=False, keep_inline_math=False)\n\n            if (tok.tok == 'macro'):\n                if (tok.arg == 'end'):\n                    if not self.tolerant_parsing:\n                        # error, this should be an \\end{environment}, not an argument in itself\n                        raise LatexWalkerParseError(\"Expected expression, got \\end\", self.s, pos)\n                    else:\n                        return (LatexCharsNode(chars=''), tok.pos, 0)\n                return (LatexMacroNode(macroname=tok.arg, nodeoptarg=None, nodeargs=[],\n                                       macro_post_space=tok.post_space),\n                        tok.pos, tok.len)\n            if (tok.tok == 'comment'):\n                return self.get_latex_expression(pos+tok.len)\n            if (tok.tok == 'brace_open'):\n                return self.get_latex_braced_group(tok.pos)\n            if (tok.tok == 'brace_close'):\n                if (self.strict_braces and not self.tolerant_parsing):\n                    raise LatexWalkerParseError(\"Expected expression, got closing brace!\", self.s, pos)\n                return (LatexCharsNode(chars=''), tok.pos, 0)\n            if (tok.tok == 'char'):\n                return (LatexCharsNode(chars=tok.arg), tok.pos, tok.len)\n\n            raise LatexWalkerParseError(\"Unknown token type: %s\" %(tok.tok), self.s, pos)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_latex_maybe_optional_arg(self, pos):\n\n        tok = self.get_token(pos, brackets_are_chars=False, environments=False)\n        if (tok.tok == 'brace_open' and tok.arg == '['):\n            return self.get_latex_braced_group(pos, brace_type='[')\n\n        return None", "response": "Parses the latex content given at the given position and returns the optional argument."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses the latex content given at position pos and returns a tuple of node pos len", "response": "def get_latex_braced_group(self, pos, brace_type='{'):\n        \"\"\"\n        Parses the latex content given to the constructor (and stored in `self.s`),\n        starting at position `pos`, to read a latex group delimited by braces.\n\n        Reads a latex expression enclosed in braces ``{ ... }``. The first token of\n        `s[pos:]` must be an opening brace.\n\n        Returns a tuple `(node, pos, len)`, where `node` is a\n        :py:class:`LatexGroupNode` instance, `pos` is the position of the first\n        char of the expression (which has to be an opening brace), and `len` is\n        the length of the group, including the closing brace (relative to the\n        starting position).\n        \"\"\"\n\n        closing_brace = None\n        if (brace_type == '{'):\n            closing_brace = '}'\n        elif (brace_type == '['):\n            closing_brace = ']'\n        else:\n            raise LatexWalkerParseError(s=self.s, pos=pos, msg=\"Uknown brace type: %s\" %(brace_type))\n        brackets_are_chars = (brace_type != '[')\n\n        firsttok = self.get_token(pos, brackets_are_chars=brackets_are_chars)\n        if (firsttok.tok != 'brace_open'  or  firsttok.arg != brace_type):\n            raise LatexWalkerParseError(\n                s=self.s,\n                pos=pos,\n                msg='get_latex_braced_group: not an opening brace/bracket: %s' %(self.s[pos])\n            )\n\n        #pos = firsttok.pos + firsttok.len\n\n        (nodelist, npos, nlen) = self.get_latex_nodes(firsttok.pos + firsttok.len,\n                                                      stop_upon_closing_brace=closing_brace)\n\n        return (LatexGroupNode(nodelist=nodelist), firsttok.pos, npos + nlen - firsttok.pos)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing the latex content and returns a list of nodes.", "response": "def get_latex_nodes(self, pos=0, stop_upon_closing_brace=None, stop_upon_end_environment=None,\n                        stop_upon_closing_mathmode=None):\n        \"\"\"\n        Parses the latex content given to the constructor (and stored in `self.s`)\n        into a list of nodes.\n\n        Returns a tuple `(nodelist, pos, len)` where nodelist is a list of\n        :py:class:`LatexNode`\\ 's.\n        \n        If `stop_upon_closing_brace` is given and set to a character, then parsing stops\n        once the given closing brace is encountered (but not inside a subgroup).  The\n        brace is given as a character, ']' or '}'.  The returned `len` includes the\n        closing brace, but the closing brace is not included in any of the nodes in the\n        `nodelist`.\n\n        If `stop_upon_end_environment` is provided, then parsing stops once the given\n        environment was closed.  If there is an environment mismatch, then a\n        `LatexWalkerParseError` is raised except in tolerant parsing mode (see\n        py:meth:`parse_flags()`).  Again, the closing environment is included in the\n        length count but not the nodes.\n\n        If `stop_upon_closing_mathmode` is specified, then the parsing stops\n        once the corresponding math mode (assumed already open) is closed.\n        Currently, only inline math modes delimited by ``$`` are supported.\n        I.e., currently, if set, only the value\n        ``stop_upon_closing_mathmode='$'`` is valid.\n        \"\"\"\n\n        nodelist = []\n    \n        brackets_are_chars = True\n        if (stop_upon_closing_brace == ']'):\n            brackets_are_chars = False\n\n        origpos = pos\n\n        class PosPointer:\n            def __init__(self, pos=0, lastchars=''):\n                self.pos = pos\n                self.lastchars = lastchars\n\n        p = PosPointer(pos)\n\n        def do_read(nodelist, p):\n            \"\"\"\n            Read a single token and process it, recursing into brace blocks and environments etc if\n            needed, and appending stuff to nodelist.\n\n            Return True whenever we should stop trying to read more. (e.g. upon reaching the a matched\n            stop_upon_end_environment etc.)\n            \"\"\"\n\n            try:\n                tok = self.get_token(p.pos, brackets_are_chars=brackets_are_chars)\n            except LatexWalkerEndOfStream:\n                if self.tolerant_parsing:\n                    return True\n                raise # re-raise\n\n            p.pos = tok.pos + tok.len\n\n            # if it's a char, just append it to the stream of last characters.\n            if (tok.tok == 'char'):\n                p.lastchars += tok.pre_space + tok.arg\n                return False\n\n            # if it's not a char, push the last `p.lastchars` into the node list before anything else\n            if len(p.lastchars):\n                strnode = LatexCharsNode(chars=p.lastchars+tok.pre_space)\n                nodelist.append(strnode)\n                p.lastchars = ''\n            elif len(tok.pre_space):\n                # If we have pre_space, add a separate chars node that contains\n                # the spaces.  We do this seperately, so that latex2text can\n                # ignore these groups by default to avoid too much space on the\n                # output.  This allows latex2text to implement the\n                # `strict_latex_spaces=True` flag correctly.\n                spacestrnode = LatexCharsNode(chars=tok.pre_space)\n                nodelist.append(spacestrnode)\n\n            # and see what the token is.\n\n            if (tok.tok == 'brace_close'):\n                # we've reached the end of the group. stop the parsing.\n                if (tok.arg != stop_upon_closing_brace):\n                    if (not self.tolerant_parsing):\n                        raise LatexWalkerParseError(\n                            s=self.s,\n                            pos=tok.pos,\n                            msg='Unexpected mismatching closing brace: `%s\\'' %(tok.arg)\n                        )\n                    return False\n                return True\n\n            if (tok.tok == 'end_environment'):\n                # we've reached the end of an environment.\n                if (tok.arg != stop_upon_end_environment):\n                    if (not self.tolerant_parsing):\n                        raise LatexWalkerParseError(\n                            s=self.s,\n                            pos=tok.pos,\n                            msg=('Unexpected mismatching closing environment: `%s\\', '\n                                 'expecting `%s\\'' %(tok.arg, stop_upon_end_environment))\n                        )\n                    return False\n                return True\n\n            if (tok.tok == 'mathmode_inline'):\n                # if we care about keeping math mode inlines verbatim, gulp all of the expression.\n                if stop_upon_closing_mathmode is not None:\n                    if stop_upon_closing_mathmode != '$':\n                        raise LatexWalkerParseError(\n                            s=self.s,\n                            pos=tok.pos,\n                            msg='Unexpected mismatching closing math mode: `$\\''\n                        )\n                    return True\n\n                # we have encountered a new math inline, so gulp all of the math expression\n                (mathinline_nodelist, mpos, mlen) = self.get_latex_nodes(p.pos, stop_upon_closing_mathmode='$')\n                p.pos = mpos + mlen\n\n                nodelist.append(LatexMathNode(displaytype='inline', nodelist=mathinline_nodelist))\n                return\n\n            if (tok.tok == 'comment'):\n                commentnode = LatexCommentNode(comment=tok.arg, comment_post_space=tok.post_space)\n                nodelist.append(commentnode)\n                return\n\n            if (tok.tok == 'brace_open'):\n                # another braced group to read.\n                (groupnode, bpos, blen) = self.get_latex_braced_group(tok.pos)\n                p.pos = bpos + blen\n                nodelist.append(groupnode)\n                return\n\n            if (tok.tok == 'begin_environment'):\n                # an environment to read.\n                (envnode, epos, elen) = self.get_latex_environment(tok.pos, environmentname=tok.arg)\n                p.pos = epos + elen\n                # add node and continue.\n                nodelist.append(envnode)\n                return\n\n            if (tok.tok == 'macro'):\n                # read a macro. see if it has arguments.\n                nodeoptarg = None\n                nodeargs = []\n                macname = tok.arg.rstrip('*') # for lookup in macro_dict\n                if macname in self.macro_dict:\n                    mac = self.macro_dict[macname]\n\n                    def getoptarg(pos):\n                        \"\"\"\n                        Gets a possibly optional argument. returns (argnode, new-pos) where argnode\n                        might be `None` if the argument was not specified.\n                        \"\"\"\n                        optarginfotuple = self.get_latex_maybe_optional_arg(pos)\n                        if optarginfotuple is not None:\n                            (nodeoptarg, optargpos, optarglen) = optarginfotuple\n                            return (nodeoptarg, optargpos+optarglen)\n                        return (None, pos)\n\n                    def getarg(pos):\n                        \"\"\"\n                        Gets a mandatory argument. returns (argnode, new-pos)\n                        \"\"\"\n                        (nodearg, npos, nlen) = self.get_latex_expression(pos, strict_braces=False)\n                        return (nodearg, npos + nlen)\n\n                    if mac.optarg:\n                        (nodeoptarg, p.pos) = getoptarg(p.pos)\n\n                    if isinstance(mac.numargs, _basestring):\n                        # specific argument specification\n                        for arg in mac.numargs:\n                            if arg == '{':\n                                (node, p.pos) = getarg(p.pos)\n                                nodeargs.append(node)\n                            elif arg == '[':\n                                (node, p.pos) = getoptarg(p.pos)\n                                nodeargs.append(node)\n                            else:\n                                raise LatexWalkerError(\n                                    \"Unknown macro argument kind for macro %s: %s\"\n                                    % (mac.macroname, arg)\n                                )\n                    else:\n                        for n in range(mac.numargs):\n                            (nodearg, p.pos) = getarg(p.pos)\n                            nodeargs.append(nodearg)\n\n                nodelist.append(LatexMacroNode(macroname=tok.arg,\n                                               nodeoptarg=nodeoptarg,\n                                               nodeargs=nodeargs,\n                                               macro_post_space=tok.post_space))\n                return None\n\n            raise LatexWalkerParseError(s=self.s, pos=p.pos, msg=\"Unknown token: %r\" %(tok))\n\n\n\n        while True:\n            try:\n                r_endnow = do_read(nodelist, p)\n            except LatexWalkerEndOfStream:\n                if stop_upon_closing_brace or stop_upon_end_environment:\n                    # unexpected eof\n                    if (not self.tolerant_parsing):\n                        raise LatexWalkerError(\"Unexpected end of stream!\")\n                    else:\n                        r_endnow = False\n                else:\n                    r_endnow = True\n\n            if (r_endnow):\n                # add last chars\n                if (p.lastchars):\n                    strnode = LatexCharsNode(chars=p.lastchars)\n                    nodelist.append(strnode)\n                return (nodelist, origpos, p.pos - origpos)\n\n        raise LatexWalkerError(                # lgtm [py/unreachable-statement]\n            \"CONGRATULATIONS !! \"\n            \"You are the first human to telepathically break an infinite loop !!!!!!!\"\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nextracts text from LaTeX content meant for database indexing. content is latex text.", "response": "def latex2text(content, tolerant_parsing=False, keep_inline_math=False, keep_comments=False):\n    \"\"\"\n    Extracts text from `content` meant for database indexing. `content` is\n    some LaTeX code.\n\n    .. deprecated:: 1.0\n       Please use :py:class:`LatexNodes2Text` instead.\n    \"\"\"\n\n    (nodelist, tpos, tlen) = latexwalker.get_latex_nodes(content, keep_inline_math=keep_inline_math,\n                                                         tolerant_parsing=tolerant_parsing)\n\n    return latexnodes2text(nodelist, keep_inline_math=keep_inline_math, keep_comments=keep_comments)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef latexnodes2text(nodelist, keep_inline_math=False, keep_comments=False):\n\n    return LatexNodes2Text(\n        keep_inline_math=keep_inline_math,\n        keep_comments=keep_comments\n    ).nodelist_to_text(nodelist)", "response": "Extracts text from a node list."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_tex_input_directory(self, tex_input_directory, latex_walker_init_args=None, strict_input=True):\n        self.tex_input_directory = tex_input_directory\n        self.latex_walker_init_args = latex_walker_init_args if latex_walker_init_args else {}\n        self.strict_input = strict_input\n        \n        if tex_input_directory:\n            self.macro_dict['input'] = MacroDef('input', lambda n: self._callback_input(n))\n            self.macro_dict['include'] = MacroDef('include', lambda n: self._callback_input(n))\n        else:\n            self.macro_dict['input'] = MacroDef('input', discard=True)\n            self.macro_dict['include'] = MacroDef('include', discard=True)", "response": "Sets the directory where to look for input files."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read_input_file(self, fn):\n        fnfull = os.path.realpath(os.path.join(self.tex_input_directory, fn))\n        if self.strict_input:\n            # make sure that the input file is strictly within dirfull, and didn't escape with\n            # '../..' tricks or via symlinks.\n            dirfull = os.path.realpath(self.tex_input_directory)\n            if not fnfull.startswith(dirfull):\n                logger.warning(\n                    \"Can't access path '%s' leading outside of mandated directory [strict input mode]\",\n                    fn\n                )\n                return ''\n\n        if not os.path.exists(fnfull) and os.path.exists(fnfull + '.tex'):\n            fnfull = fnfull + '.tex'\n        if not os.path.exists(fnfull) and os.path.exists(fnfull + '.latex'):\n            fnfull = fnfull + '.latex'\n        if not os.path.isfile(fnfull):\n            logger.warning(u\"Error, file doesn't exist: '%s'\", fn)\n            return ''\n        \n        logger.debug(\"Reading input file %r\", fnfull)\n\n        try:\n            with open(fnfull) as f:\n                return f.read()\n        except IOError as e:\n            logger.warning(u\"Error, can't access '%s': %s\", fn, e)\n            return ''", "response": "This method reads the input file and returns the contents of the file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse the given latex code and returns its textual representation.", "response": "def latex_to_text(self, latex, **parse_flags):\n        \"\"\"\n        Parses the given `latex` code and returns its textual representation.\n\n        The `parse_flags` are the flags to give on to the\n        :py:class:`pylatexenc.latexwalker.LatexWalker` constructor.\n        \"\"\"\n        return self.nodelist_to_text(latexwalker.LatexWalker(latex, **parse_flags).get_latex_nodes()[0])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef nodelist_to_text(self, nodelist):\n\n        s = self._nodelistcontents_to_text(nodelist)\n\n        # now, perform suitable replacements\n        for pattern, replacement in self.text_replacements:\n            if (hasattr(pattern, 'sub')):\n                s = pattern.sub(replacement, s)\n            else:\n                s = s.replace(pattern, replacement)\n\n        if not self.keep_inline_math:\n            s = s.replace('$', ''); # removing math mode inline signs, just keep their Unicode counterparts..\n\n        return s", "response": "Extracts text from a node list."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nturns the node list to text representations of each node.", "response": "def _nodelistcontents_to_text(self, nodelist):\n        \"\"\"\n        Turn the node list to text representations of each node.  Basically apply\n        `node_to_text()` to each node.  (But not quite actually, since we take\n        some care as to where we add whitespace.)\n        \"\"\"\n        s = ''\n        prev_node = None\n        for node in nodelist:\n            if self._is_bare_macro_node(prev_node) and node.isNodeType(latexwalker.LatexCharsNode):\n                if not self.strict_latex_spaces['between-macro-and-chars']:\n                    # after a macro with absolutely no arguments, include post_space\n                    # in output by default if there are other chars that follow.\n                    # This is for more breathing space (especially in equations(?)),\n                    # and for compatibility with earlier versions of pylatexenc (<=\n                    # 1.3).  This is NOT LaTeX' default behavior (see issue #11), so\n                    # only do this if `strict_latex_spaces=False`.\n                    s += prev_node.macro_post_space\n            s += self.node_to_text(node)\n            prev_node = node\n        return s"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the textual representation of the given node.", "response": "def node_to_text(self, node, prev_node_hint=None):\n        \"\"\"\n        Return the textual representation of the given `node`.\n\n        If `prev_node_hint` is specified, then the current node is formatted\n        suitably as following the node given in `prev_node_hint`.  This might\n        affect how much space we keep/discard, etc.\n        \"\"\"\n        if node is None:\n            return \"\"\n        \n        if node.isNodeType(latexwalker.LatexCharsNode):\n            # Unless in strict latex spaces mode, ignore nodes consisting only\n            # of empty chars, as this tends to produce too much space...  These\n            # have been inserted by LatexWalker() in some occasions to keep\n            # track of all relevant pre_space of tokens, such as between two\n            # braced groups (\"{one} {two}\") or other such situations.\n            if not self.strict_latex_spaces['between-latex-constructs'] and len(node.chars.strip()) == 0:\n                return \"\"\n            return node.chars\n        \n        if node.isNodeType(latexwalker.LatexCommentNode):\n            if self.keep_comments:\n                if self.strict_latex_spaces['after-comment']:\n                    return '%' + node.comment + '\\n'\n                else:\n                    # default spaces, i.e., keep what spaces were already there after the comment\n                    return '%' + node.comment + node.comment_post_space\n            else:\n                if self.strict_latex_spaces['after-comment']:\n                    return \"\"\n                else:\n                    # default spaces, i.e., keep what spaces were already there after the comment\n                    # This can be useful to preserve e.g. indentation of the next line\n                    return node.comment_post_space\n        \n        if node.isNodeType(latexwalker.LatexGroupNode):\n            contents = self._groupnodecontents_to_text(node)\n            if self.keep_braced_groups and len(contents) >= self.keep_braced_groups_minlen:\n                return \"{\" + contents + \"}\"\n            return contents\n\n        def apply_simplify_repl(node, simplify_repl, nodelistargs, what):\n            if callable(simplify_repl):\n                if 'l2tobj' in getfullargspec(simplify_repl)[0]:\n                    # callable accepts an argument named 'l2tobj', provide pointer to self\n                    return simplify_repl(node, l2tobj=self)\n                return simplify_repl(node)\n            if '%' in simplify_repl:\n                try:\n                    return simplify_repl % tuple([self._groupnodecontents_to_text(nn)\n                                                  for nn in nodelistargs])\n                except (TypeError, ValueError):\n                    logger.warning(\n                        \"WARNING: Error in configuration: {} failed its substitution!\".format(what)\n                    )\n                    return simplify_repl # too bad, keep the percent signs as they are...\n            return simplify_repl\n            \n        \n        if node.isNodeType(latexwalker.LatexMacroNode):\n            # get macro behavior definition.\n            macroname = node.macroname.rstrip('*')\n            if macroname in self.macro_dict:\n                mac = self.macro_dict[macroname]\n            else:\n                # no predefined behavior, use default:\n                mac = self.macro_dict['']\n\n            def get_macro_str_repl(node, macroname, mac):\n                if mac.simplify_repl:\n                    return apply_simplify_repl(node, mac.simplify_repl, node.nodeargs,\n                                               what=\"macro '%s'\"%(macroname))\n                if mac.discard:\n                    return \"\"\n                a = node.nodeargs\n                if (node.nodeoptarg):\n                    a.prepend(node.nodeoptarg)\n                return \"\".join([self._groupnodecontents_to_text(n) for n in a])\n\n            macrostr = get_macro_str_repl(node, macroname, mac)\n            return macrostr\n\n        if node.isNodeType(latexwalker.LatexEnvironmentNode):\n            # get environment behavior definition.\n            envname = node.envname.rstrip('*')\n            if (envname in self.env_dict):\n                envdef = self.env_dict[envname]\n            else:\n                # no predefined behavior, use default:\n                envdef = self.env_dict['']\n\n            if envdef.simplify_repl:\n                return apply_simplify_repl(node, envdef.simplify_repl, node.nodelist,\n                                           what=\"environment '%s'\"%(envname))\n            if envdef.discard:\n                return \"\"\n            return self._nodelistcontents_to_text(node.nodelist)\n\n        if node.isNodeType(latexwalker.LatexMathNode):\n            if self.keep_inline_math:\n                # we care about math modes and we should keep this verbatim\n                return latexwalker.math_node_to_latex(node)\n            else:\n                # note, this here only happens if the latexwalker had keep_inline_math=True\n                with _PushEquationContext(self):\n                    return self._nodelistcontents_to_text(node.nodelist)\n\n        logger.warning(\"LatexNodes2Text.node_to_text(): Unknown node: %r\", node)\n\n        # discard anything else.\n        return \"\""}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef utf8tolatex(s, non_ascii_only=False, brackets=True, substitute_bad_chars=False, fail_bad_chars=False):\n\n    s = unicode(s) # make sure s is unicode\n    s = unicodedata.normalize('NFC', s)\n\n    if not s:\n        return \"\"\n\n    result = u\"\"\n    for ch in s:\n        #log.longdebug(\"Encoding char %r\", ch)\n        if (non_ascii_only and ord(ch) < 127):\n            result += ch\n        else:\n            lch = utf82latex.get(ord(ch), None)\n            if (lch is not None):\n                # add brackets if needed, i.e. if we have a substituting macro.\n                # note: in condition, beware, that lch might be of zero length.\n                result += (  '{'+lch+'}' if brackets and lch[0:1] == '\\\\' else\n                             lch  )\n            elif ((ord(ch) >= 32 and ord(ch) <= 127) or\n                  (ch in \"\\n\\r\\t\")):\n                # ordinary printable ascii char, just add it\n                result += ch\n            else:\n                # non-ascii char\n                msg = u\"Character cannot be encoded into LaTeX: U+%04X - `%s'\" % (ord(ch), ch)\n                if fail_bad_chars:\n                    raise ValueError(msg)\n\n                log.warning(msg)\n                if substitute_bad_chars:\n                    result += r'{\\bfseries ?}'\n                else:\n                    # keep unescaped char\n                    result += ch\n\n    return result", "response": "u Encode a UTF - 8 string to a LaTeX snippet."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _unascii(s):\n\n    # make the fast path fast: if there are no matches in the string, the\n    # whole thing is ascii. On python 2, that means we're done. On python 3,\n    # we have to turn it into a bytes, which is quickest with encode('utf-8')\n    m = _U_ESCAPE.search(s)\n    if not m:\n        return s if PY2 else s.encode('utf-8')\n\n    # appending to a string (or a bytes) is slooow, so we accumulate sections\n    # of string result in 'chunks', and join them all together later.\n    # (It doesn't seem to make much difference whether we accumulate\n    # utf8-encoded bytes, or strings which we utf-8 encode after rejoining)\n    #\n    chunks = []\n\n    # 'pos' tracks the index in 's' that we have processed into 'chunks' so\n    # far.\n    pos = 0\n\n    while m:\n        start = m.start()\n        end = m.end()\n\n        g = m.group(1)\n\n        if g is None:\n            # escaped backslash: pass it through along with anything before the\n            # match\n            chunks.append(s[pos:end])\n        else:\n            # \\uNNNN, but we have to watch out for surrogate pairs.\n            #\n            # On python 2, str.encode(\"utf-8\") will decode utf-16 surrogates\n            # before re-encoding, so it's fine for us to pass the surrogates\n            # through. (Indeed we must, to deal with UCS-2 python builds, per\n            # https://github.com/matrix-org/python-canonicaljson/issues/12).\n            #\n            # On python 3, str.encode(\"utf-8\") complains about surrogates, so\n            # we have to unpack them.\n            c = int(g, 16)\n\n            if c < 0x20:\n                # leave as a \\uNNNN escape\n                chunks.append(s[pos:end])\n            else:\n                if PY3:   # pragma nocover\n                    if c & 0xfc00 == 0xd800 and s[end:end + 2] == '\\\\u':\n                        esc2 = s[end + 2:end + 6]\n                        c2 = int(esc2, 16)\n                        if c2 & 0xfc00 == 0xdc00:\n                            c = 0x10000 + (((c - 0xd800) << 10) |\n                                           (c2 - 0xdc00))\n                            end += 6\n\n                chunks.append(s[pos:start])\n                chunks.append(unichr(c))\n\n        pos = end\n        m = _U_ESCAPE.search(s, pos)\n\n    # pass through anything after the last match\n    chunks.append(s[pos:])\n\n    return (''.join(chunks)).encode(\"utf-8\")", "response": "Unpacks any UNNNNNN and encodes the result as UTF - 8 and returns the result as a string."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a dictionary of values.", "response": "def get_organisation_information(self, query_params=None):\n        '''\n        Get information fot this organisation. Returns a dictionary of values.\n        '''\n        return self.fetch_json(\n            uri_path=self.base_uri,\n            query_params=query_params or {}\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of Board s. Returns a list of Board s.", "response": "def get_boards(self, **query_params):\n        '''\n        Get all the boards for this organisation. Returns a list of Board s.\n\n        Returns:\n            list(Board): The boards attached to this organisation\n        '''\n        boards = self.get_boards_json(self.base_uri, query_params=query_params)\n\n        boards_list = []\n        for board_json in boards:\n            boards_list.append(self.create_board(board_json))\n\n        return boards_list"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of Member objects representing the members attached to this organisation. Returns a list of Member objects representing the members attached to this organisation.", "response": "def get_members(self, **query_params):\n        '''\n        Get all members attached to this organisation. Returns a list of\n        Member objects\n\n        Returns:\n            list(Member): The members attached to this organisation\n        '''\n        members = self.get_members_json(self.base_uri,\n                                        query_params=query_params)\n\n        members_list = []\n        for member_json in members:\n            members_list.append(self.create_member(member_json))\n\n        return members_list"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates this organisations information. Returns a new organisation object.", "response": "def update_organisation(self, query_params=None):\n        '''\n        Update this organisations information. Returns a new organisation\n        object.\n        '''\n        organisation_json = self.fetch_json(\n            uri_path=self.base_uri,\n            http_method='PUT',\n            query_params=query_params or {}\n        )\n\n        return self.create_organisation(organisation_json)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving a member from the organisation. Returns the JSON of all members if successful.", "response": "def remove_member(self, member_id):\n        '''\n        Remove a member from the organisation.Returns JSON of all members if\n        successful or raises an Unauthorised exception if not.\n        '''\n        return self.fetch_json(\n            uri_path=self.base_uri + '/members/%s' % member_id,\n            http_method='DELETE'\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a member to the board using the id.", "response": "def add_member_by_id(self, member_id, membership_type='normal'):\n        '''\n        Add a member to the board using the id. Membership type can be\n        normal or admin. Returns JSON of all members if successful or raises an\n        Unauthorised exception if not.\n        '''\n        return self.fetch_json(\n            uri_path=self.base_uri + '/members/%s' % member_id,\n            http_method='PUT',\n            query_params={\n                'type': membership_type\n            }\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a member to the board.", "response": "def add_member(self, email, fullname, membership_type='normal'):\n        '''\n        Add a member to the board. Membership type can be normal or admin.\n        Returns JSON of all members if successful or raises an Unauthorised\n        exception if not.\n        '''\n        return self.fetch_json(\n            uri_path=self.base_uri + '/members',\n            http_method='PUT',\n            query_params={\n                'email': email,\n                'fullName': fullname,\n                'type': membership_type\n            }\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_list_information(self, query_params=None):\n        '''\n        Get information for this list. Returns a dictionary of values.\n        '''\n        return self.fetch_json(\n            uri_path=self.base_uri,\n            query_params=query_params or {}\n        )", "response": "Returns a dictionary of values."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_card(self, query_params=None):\n        '''\n        Create a card for this list. Returns a Card object.\n        '''\n        card_json = self.fetch_json(\n            uri_path=self.base_uri + '/cards',\n            http_method='POST',\n            query_params=query_params or {}\n        )\n\n        return self.create_card(card_json)", "response": "Creates a card for this list. Returns a Card object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a dictionary of values for this Label. Returns a dictionary of values.", "response": "def get_label_information(self, query_params=None):\n        '''\n        Get all information for this Label. Returns a dictionary of values.\n        '''\n        return self.fetch_json(\n            uri_path=self.base_uri,\n            query_params=query_params or {}\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a list of dictionaries containing the values for each item in the item set.", "response": "def get_items(self, query_params=None):\n        '''\n        Get all the items for this label. Returns a list of dictionaries.\n        Each dictionary has the values for an item.\n        '''\n        return self.fetch_json(\n            uri_path=self.base_uri + '/checkItems',\n            query_params=query_params or {}\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _update_label_name(self, name):\n        '''\n        Update the current label's name. Returns a new Label object.\n        '''\n        label_json = self.fetch_json(\n            uri_path=self.base_uri,\n            http_method='PUT',\n            query_params={'name': name}\n        )\n\n        return self.create_label(label_json)", "response": "Updates the current label s name. Returns a new Label object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _update_label_dict(self, query_params={}):\n        '''\n        Update the current label. Returns a new Label object.\n        '''\n        label_json = self.fetch_json(\n            uri_path=self.base_uri,\n            http_method='PUT',\n            query_params=query_params\n        )\n\n        return self.create_label(label_json)", "response": "Updates the current label. Returns a new Label object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_authorisation_url(self, application_name, token_expire='1day'):\n        '''\n        Returns a URL that needs to be opened in a browser to retrieve an\n        access token.\n        '''\n        query_params = {\n            'name': application_name,\n            'expiration': token_expire,\n            'response_type': 'token',\n            'scope': 'read,write'\n        }\n\n        authorisation_url = self.build_uri(\n            path='/authorize',\n            query_params=self.add_authorisation(query_params)\n        )\n\n        print('Please go to the following URL and get the user authorisation '\n              'token:\\n', authorisation_url)\n        return authorisation_url", "response": "Returns a URL that needs to be opened in a browser to retrieve an anonymized access token."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a dictionary of values.", "response": "def get_card_information(self, query_params=None):\n        '''\n        Get information for this card. Returns a dictionary of values.\n        '''\n        return self.fetch_json(\n            uri_path=self.base_uri,\n            query_params=query_params or {}\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a Board object.", "response": "def get_board(self, **query_params):\n        '''\n        Get board information for this card. Returns a Board object.\n\n        Returns:\n            Board: The board this card is attached to\n        '''\n        board_json = self.get_board_json(self.base_uri,\n                                         query_params=query_params)\n        return self.create_board(board_json)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a List object.", "response": "def get_list(self, **query_params):\n        '''\n        Get list information for this card. Returns a List object.\n\n        Returns:\n            List: The list this card is attached to\n        '''\n        list_json = self.get_list_json(self.base_uri,\n                                       query_params=query_params)\n        return self.create_list(list_json)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_checklists(self, **query_params):\n        '''\n        Get the checklists for this card. Returns a list of Checklist objects.\n\n        Returns:\n            list(Checklist): The checklists attached to this card\n        '''\n        checklists = self.get_checklist_json(self.base_uri,\n                                             query_params=query_params)\n\n        checklists_list = []\n        for checklist_json in checklists:\n            checklists_list.append(self.create_checklist(checklist_json))\n\n        return checklists_list", "response": "Returns a list of Checklist objects."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a comment to the current user s card by the current user.", "response": "def add_comment(self, comment_text):\n        '''\n        Adds a comment to this card by the current user.\n        '''\n        return self.fetch_json(\n            uri_path=self.base_uri + '/actions/comments',\n            http_method='POST',\n            query_params={'text': comment_text}\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_attachment(self, filename, open_file):\n        '''\n        Adds an attachment to this card.\n        '''\n        fields = {\n            'api_key': self.client.api_key,\n            'token': self.client.user_auth_token\n        }\n\n        content_type, body = self.encode_multipart_formdata(\n            fields=fields,\n            filename=filename,\n            file_values=open_file\n        )\n\n        return self.fetch_json(\n            uri_path=self.base_uri + '/attachments',\n            http_method='POST',\n            body=body,\n            headers={'Content-Type': content_type},\n        )", "response": "Adds an attachment to this card."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a checklist to this card. Returns a Checklist object.", "response": "def add_checklist(self, query_params=None):\n        '''\n        Add a checklist to this card. Returns a Checklist object.\n        '''\n        checklist_json = self.fetch_json(\n            uri_path=self.base_uri + '/checklists',\n            http_method='POST',\n            query_params=query_params or {}\n        )\n\n        return self.create_checklist(checklist_json)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd a label to this card from a dictionary.", "response": "def _add_label_from_dict(self, query_params=None):\n        '''\n        Add a label to this card, from a dictionary.\n        '''\n        return self.fetch_json(\n            uri_path=self.base_uri + '/labels',\n            http_method='POST',\n            query_params=query_params or {}\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds an existing label to this card.", "response": "def _add_label_from_class(self, label=None):\n        '''\n        Add an existing label to this card.\n        '''\n        return self.fetch_json(\n            uri_path=self.base_uri + '/idLabels',\n            http_method='POST',\n            query_params={'value': label.id}\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_member(self, member_id):\n        '''\n        Add a member to this card. Returns a list of Member objects.\n        '''\n        members = self.fetch_json(\n            uri_path=self.base_uri + '/idMembers',\n            http_method='POST',\n            query_params={'value': member_id}\n        )\n\n        members_list = []\n        for member_json in members:\n            members_list.append(self.create_member(member_json))\n\n        return members_list", "response": "Adds a member to this card. Returns a list of Member objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef encode_multipart_formdata(self, fields, filename, file_values):\n        '''\n        Encodes data to updload a file to Trello.\n        Fields is a dictionary of api_key and token. Filename is the name of\n        the file and file_values is the open(file).read() string.\n        '''\n        boundary = '----------Trello_Boundary_$'\n        crlf = '\\r\\n'\n\n        data = []\n\n        for key in fields:\n            data.append('--' + boundary)\n            data.append('Content-Disposition: form-data; name=\"%s\"' % key)\n            data.append('')\n            data.append(fields[key])\n\n        data.append('--' + boundary)\n        data.append(\n            'Content-Disposition: form-data; name=\"file\"; filename=\"%s\"' %\n            filename)\n        data.append('Content-Type: %s' % self.get_content_type(filename))\n        data.append('')\n        data.append(file_values)\n\n        data.append('--' + boundary + '--')\n        data.append('')\n\n        # Try and avoid the damn unicode errors\n        data = [str(segment) for segment in data]\n\n        body = crlf.join(data)\n        content_type = 'multipart/form-data; boundary=%s' % boundary\n\n        return content_type, body", "response": "Encodes data to updload a file to Trello."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_member_information(self, query_params=None):\n        '''\n        Get Information for a member. Returns a dictionary of values.\n\n        Returns:\n            dict\n        '''\n        return self.fetch_json(\n            uri_path=self.base_uri,\n            query_params=query_params or {}\n        )", "response": "Get Information for a member. Returns a dictionary of values."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets all cards this member is attached to. Return a list of Card objects.", "response": "def get_cards(self, **query_params):\n        '''\n        Get all cards this member is attached to. Return a list of Card\n        objects.\n\n        Returns:\n            list(Card): Return all cards this member is attached to\n        '''\n        cards = self.get_cards_json(self.base_uri, query_params=query_params)\n\n        cards_list = []\n        for card_json in cards:\n            cards_list.append(self.create_card(card_json))\n\n        return cards_list"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_organisations(self, **query_params):\n        '''\n        Get all organisations this member is attached to. Return a list of\n        Organisation objects.\n\n        Returns:\n            list(Organisation): Return all organisations this member is\n            attached to\n        '''\n        organisations = self.get_organisations_json(self.base_uri,\n                                                    query_params=query_params)\n\n        organisations_list = []\n        for organisation_json in organisations:\n            organisations_list.append(\n                self.create_organisation(organisation_json))\n\n        return organisations_list", "response": "Get all organisations this resource is attached to. Return a list of Organisation objects."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a new board.", "response": "def create_new_board(self, query_params=None):\n        '''\n        Create a new board. name is required in query_params. Returns a Board\n        object.\n\n        Returns:\n            Board: Returns the created board\n        '''\n        board_json = self.fetch_json(\n            uri_path='/boards',\n            http_method='POST',\n            query_params=query_params or {}\n        )\n        return self.create_board(board_json)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef singledispatchmethod(method):\n    '''\n    Enable singledispatch for class methods.\n\n    See http://stackoverflow.com/a/24602374/274318\n    '''\n    dispatcher = singledispatch(method)\n    def wrapper(*args, **kw):\n        return dispatcher.dispatch(args[1].__class__)(*args, **kw)\n    wrapper.register = dispatcher.register\n    update_wrapper(wrapper, dispatcher)\n    return wrapper", "response": "Decorator for singledispatching a method."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_checklist_item(self, card_id, checklist_id, checklistitem_json, **kwargs):\n        '''\n        Create a ChecklistItem object from JSON object\n        '''\n        return self.client.create_checklist_item(card_id, checklist_id, checklistitem_json, **kwargs)", "response": "Create a ChecklistItem object from a JSON object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting all information for this board. Returns a dictionary of values.", "response": "def get_board_information(self, query_params=None):\n        '''\n        Get all information for this board. Returns a dictionary of values.\n        '''\n        return self.fetch_json(\n            uri_path='/boards/' + self.id,\n            query_params=query_params or {}\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_lists(self, **query_params):\n        '''\n        Get the lists attached to this board. Returns a list of List objects.\n\n        Returns:\n            list(List): The lists attached to this board\n        '''\n        lists = self.get_lists_json(self.base_uri, query_params=query_params)\n\n        lists_list = []\n        for list_json in lists:\n            lists_list.append(self.create_list(list_json))\n\n        return lists_list", "response": "Returns a list of List objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_labels(self, **query_params):\n        '''\n        Get the labels attached to this board. Returns a label of Label\n        objects.\n\n        Returns:\n            list(Label): The labels attached to this board\n        '''\n        labels = self.get_labels_json(self.base_uri, query_params=query_params)\n\n        labels_list = []\n        for label_json in labels:\n            labels_list.append(self.create_label(label_json))\n\n        return labels_list", "response": "Returns a list of Label objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_card(self, card_id, **query_params):\n        '''\n        Get a Card for a given card id. Returns a Card object.\n\n        Returns:\n            Card: The card with the given card_id\n        '''\n        card_json = self.fetch_json(\n            uri_path=self.base_uri + '/cards/' + card_id\n        )\n\n        return self.create_card(card_json)", "response": "Returns a Card object for a given card id. Returns a Card object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_checklists( self ):\n        checklists = self.getChecklistsJson( self.base_uri )\n\n        checklists_list = []\n        for checklist_json in checklists:\n            checklists_list.append( self.createChecklist( checklist_json ) )\n\n        return checklists_list", "response": "Returns a list of Checklist objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_organisation(self, **query_params):\n        '''\n        Get the Organisation for this board. Returns Organisation object.\n\n        Returns:\n            list(Organisation): The organisation attached to this board\n        '''\n        organisation_json = self.get_organisations_json(\n            self.base_uri, query_params=query_params)\n\n        return self.create_organisation(organisation_json)", "response": "Get the Organisation for this board. Returns the Organisation object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update_board(self, query_params=None):\n        '''\n        Update this board's information. Returns a new board.\n        '''\n        board_json = self.fetch_json(\n            uri_path=self.base_uri,\n            http_method='PUT',\n            query_params=query_params or {}\n        )\n\n        return self.create_board(board_json)", "response": "Updates this board s information. Returns a new board."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_list(self, query_params=None):\n        '''\n        Create a list for a board. Returns a new List object.\n        '''\n        list_json = self.fetch_json(\n            uri_path=self.base_uri + '/lists',\n            http_method='POST',\n            query_params=query_params or {}\n        )\n\n        return self.create_list(list_json)", "response": "Creates a list for a board. Returns a new List object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_label(self, query_params=None):\n        '''\n        Create a label for a board. Returns a new Label object.\n        '''\n        list_json = self.fetch_json(\n            uri_path=self.base_uri + '/labels',\n            http_method='POST',\n            query_params=query_params or {}\n        )\n\n        return self.create_label(list_json)", "response": "Creates a new label for a board. Returns a new Label object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget all information for this Checklist. Returns a dictionary of values.", "response": "def get_checklist_information(self, query_params=None):\n        '''\n        Get all information for this Checklist. Returns a dictionary of values.\n        '''\n        # We don't use trelloobject.TrelloObject.get_checklist_json, because\n        # that is meant to return lists of checklists.\n        return self.fetch_json(\n            uri_path=self.base_uri,\n            query_params=query_params or {}\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_card(self):\n        '''\n        Get card this checklist is on.\n        '''\n        card_id = self.get_checklist_information().get('idCard', None)\n        if card_id:\n            return self.client.get_card(card_id)", "response": "Get the card this checklist is on."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_item_objects(self, query_params=None):\n        card = self.get_card()\n        checklistitems_list = []\n        for checklistitem_json in self.get_items(query_params):\n            checklistitems_list.append(self.create_checklist_item(card.id, self.id, checklistitem_json))\n\n        return checklistitems_list", "response": "Returns a list of ChecklistItem objects."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_checklist(self, name):\n        '''\n        Update the current checklist. Returns a new Checklist object.\n        '''\n        checklist_json = self.fetch_json(\n            uri_path=self.base_uri,\n            http_method='PUT',\n            query_params={'name': name}\n        )\n\n        return self.create_checklist(checklist_json)", "response": "Updates the current checklist. Returns a new Checklist object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd an item to this checklist. Returns a dictionary of values of new item.", "response": "def add_item(self, query_params=None):\n        '''\n        Add an item to this checklist. Returns a dictionary of values of new\n        item.\n        '''\n        return self.fetch_json(\n            uri_path=self.base_uri + '/checkItems',\n            http_method='POST',\n            query_params=query_params or {}\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove an item from this checklist.", "response": "def remove_item(self, item_id):\n        '''\n        Deletes an item from this checklist.\n        '''\n        return self.fetch_json(\n            uri_path=self.base_uri + '/checkItems/' + item_id,\n            http_method='DELETE'\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_name( self, name ):\n        checklistitem_json = self.fetch_json(\n            uri_path = self.base_uri + '/name',\n            http_method = 'PUT',\n            query_params = {'value': name}\n        )\n\n        return self.create_checklist_item(self.idCard, self.idChecklist, checklistitem_json)", "response": "Updates the name of the current checklist item. Returns a new ChecklistItem object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_state(self, state):\n        checklistitem_json = self.fetch_json(\n            uri_path = self.base_uri + '/state',\n            http_method = 'PUT',\n            query_params = {'value': 'complete' if state else 'incomplete'}\n        )\n\n        return self.create_checklist_item(self.idCard, self.idChecklist, checklistitem_json)", "response": "Updates the state of the current checklist item. Returns a new ChecklistItem object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_authorisation(self, query_params):\n        '''\n        Adds the API key and user auth token to the query parameters\n        '''\n        query_params['key'] = self.api_key\n\n        if self.user_auth_token:\n            query_params['token'] = self.user_auth_token\n\n        return query_params", "response": "Adds the API key and user auth token to the query parameters"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks HTTP response for known errors and raise exception if not", "response": "def check_errors(self, uri, response):\n        '''\n        Check HTTP reponse for known errors\n        '''\n        if response.status == 401:\n            raise trolly.Unauthorised(uri, response)\n\n        if response.status != 200:\n            raise trolly.ResourceUnavailable(uri, response)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nbuilding the URI for the API call.", "response": "def build_uri(self, path, query_params):\n        '''\n        Build the URI for the API call.\n        '''\n        url = 'https://api.trello.com/1' + self.clean_path(path)\n        url += '?' + urlencode(query_params)\n\n        return url"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fetch_json(self, uri_path, http_method='GET', query_params=None,\n                   body=None, headers=None):\n        '''\n        Make a call to Trello API and capture JSON response. Raises an error\n        when it fails.\n\n        Returns:\n            dict: Dictionary with the JSON data\n        '''\n        query_params = query_params or {}\n        headers = headers or {}\n\n        query_params = self.add_authorisation(query_params)\n        uri = self.build_uri(uri_path, query_params)\n\n        allowed_methods = (\"POST\", \"PUT\", \"DELETE\")\n        if http_method in allowed_methods and 'Content-Type' not in headers:\n            headers['Content-Type'] = 'application/json'\n\n        headers['Accept'] = 'application/json'\n        response, content = self.client.request(\n            uri=uri,\n            method=http_method,\n            body=body,\n            headers=headers\n        )\n\n        self.check_errors(uri, response)\n\n        return json.loads(content.decode('utf-8'))", "response": "Make a call to Trello API and capture JSON response. Raises an error if it fails."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate an Organisation object from a JSON object.", "response": "def create_organisation(self, organisation_json):\n        '''\n        Create an Organisation object from a JSON object\n\n        Returns:\n            Organisation: The organisation from the given `organisation_json`.\n        '''\n        return trolly.organisation.Organisation(\n            trello_client=self,\n            organisation_id=organisation_json['id'],\n            name=organisation_json['name'],\n            data=organisation_json,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a Board object from a JSON object.", "response": "def create_board(self, board_json):\n        '''\n        Create Board object from a JSON object\n\n        Returns:\n            Board: The board from the given `board_json`.\n        '''\n        return trolly.board.Board(\n            trello_client=self,\n            board_id=board_json['id'],\n            name=board_json['name'],\n            data=board_json,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_label(self, label_json):\n        '''\n        Create Label object from JSON object\n\n        Returns:\n            Label: The label from the given `label_json`.\n        '''\n        return trolly.label.Label(\n            trello_client=self,\n            label_id=label_json['id'],\n            name=label_json['name'],\n            data=label_json,\n        )", "response": "Create a Label object from a JSON object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_list(self, list_json):\n        '''\n        Create List object from JSON object\n\n        Returns:\n            List: The list from the given `list_json`.\n        '''\n        return trolly.list.List(\n            trello_client=self,\n            list_id=list_json['id'],\n            name=list_json['name'],\n            data=list_json,\n        )", "response": "Create a list object from the given JSON object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_card(self, card_json):\n        '''\n        Create a Card object from JSON object\n\n        Returns:\n            Card: The card from the given `card_json`.\n        '''\n        return trolly.card.Card(\n            trello_client=self,\n            card_id=card_json['id'],\n            name=card_json['name'],\n            data=card_json,\n        )", "response": "Create a Card object from the given JSON object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_checklist(self, checklist_json):\n        '''\n        Create a Checklist object from JSON object\n\n        Returns:\n            Checklist: The checklist from the given `checklist_json`.\n        '''\n        return trolly.checklist.Checklist(\n            trello_client=self,\n            checklist_id=checklist_json['id'],\n            name=checklist_json['name'],\n            data=checklist_json,\n        )", "response": "Create a Checklist object from the given JSON object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a ChecklistItem object from a JSON object.", "response": "def create_checklist_item(self, card_id, checklist_id, checklistitem_json):\n        \"\"\"\n        Create a ChecklistItem object from JSON object\n        \"\"\"\n        return trolly.checklist.ChecklistItem(\n            trello_client=self,\n            card_id=card_id,\n            checklist_id=checklist_id,\n            checklistitem_id=checklistitem_json['id'].encode('utf-8'),\n            name=checklistitem_json['name'].encode('utf-8'),\n            state=checklistitem_json['state'].encode('utf-8')\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_member(self, member_json):\n        '''\n        Create a Member object from JSON object\n\n        Returns:\n            Member: The member from the given `member_json`.\n        '''\n        return trolly.member.Member(\n            trello_client=self,\n            member_id=member_json['id'],\n            name=member_json['fullName'],\n            data=member_json,\n        )", "response": "Create a Member object from the given JSON object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_organisation(self, id, name=None):\n        '''\n        Get an organisation\n\n        Returns:\n            Organisation: The organisation with the given `id`\n        '''\n        return self.create_organisation(dict(id=id, name=name))", "response": "Get an organisation with the given id"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting a board with the given id and name.", "response": "def get_board(self, id, name=None):\n        '''\n        Get a board\n\n        Returns:\n            Board: The board with the given `id`\n        '''\n        return self.create_board(dict(id=id, name=name))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_list(self, id, name=None):\n        '''\n        Get a list\n\n        Returns:\n            List: The list with the given `id`\n        '''\n        return self.create_list(dict(id=id, name=name))", "response": "Get a list with the given id and name"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_card(self, id, name=None):\n        '''\n        Get a card\n\n        Returns:\n            Card: The card with the given `id`\n        '''\n        return self.create_card(dict(id=id, name=name))", "response": "Get a card with the given id and optional name."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_checklist(self, id, name=None):\n        '''\n        Get a checklist\n\n        Returns:\n            Checklist: The checklist with the given `id`\n        '''\n        return self.create_checklist(dict(id=id, name=name))", "response": "Get a checklist with the given id and name."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_member(self, id='me', name=None):\n        '''\n        Get a member or your current member if `id` wasn't given.\n\n        Returns:\n            Member: The member with the given `id`, defaults to the\n            logged in member.\n        '''\n        return self.create_member(dict(id=id, fullName=name))", "response": "Get a member or your current member if id is not given."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget root domain from url", "response": "def domain_from_url(url):\n    \"\"\"\n    Get root domain from url.\n    Will prune away query strings, url paths, protocol prefix and sub-domains\n    Exceptions will be raised on invalid urls\n    \"\"\"\n    ext = tldextract.extract(url)\n    if not ext.suffix:\n        raise InvalidURLException()\n    new_url = ext.domain + \".\" + ext.suffix\n    return new_url"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef to_raw_text_markupless(text, keep_whitespace=False, normalize_ascii=True):\n    return sent_tokenize(\n        remove_dates(_remove_urls(text)),\n        keep_whitespace,\n        normalize_ascii\n    )", "response": "Returns a generator that returns a list of words separated by the raw text segments without xml and any markup."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting raw text segments with xml and other non - textual content to a list of words.", "response": "def to_raw_text(text, keep_whitespace=False, normalize_ascii=True):\n    \"\"\"\n    A generator to convert raw text segments, with xml, and other\n    non-textual content to a list of words without any markup.\n    Additionally dates are replaced by `7777` for normalization.\n\n    Arguments\n    ---------\n       text: str, input text to tokenize, strip of markup.\n       keep_whitespace : bool, should the output retain the\n          whitespace of the input (so that char offsets in the\n          output correspond to those in the input).\n\n    Returns\n    -------\n        generator<list<list<str>>>, a generator for sentences, with\n            within each sentence a list of the words separated.\n    \"\"\"\n    out = text\n    out = _remove_urls(text)\n    out = _remove_mvar(out)\n    out = _remove_squiggly_bracket(out)\n    out = _remove_table(out)\n    out = _remove_brackets(out)\n    out = remove_remaining_double_brackets(out)\n    out = remove_markup(out)\n    out = remove_wikipedia_link.sub(anchor_replacer, out)\n    out = remove_bullets_nbsps.sub(empty_space, out)\n    out = remove_dates(out)\n    out = remove_math_sections(out)\n    out = remove_html(out)\n    out = sent_tokenize(out, keep_whitespace, normalize_ascii)\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_raw_text_pairings(text, keep_whitespace=False, normalize_ascii=True):\n    out = text\n    out = _remove_mvar(out)\n    out = _remove_squiggly_bracket(out)\n    out = _remove_table(out)\n    out = remove_markup(out)\n    out = remove_wikipedia_link.sub(anchor_replacer, out)\n    out = remove_bullets_nbsps.sub(empty_space, out)\n    out = remove_math_sections(out)\n    out = remove_html(out)\n    for sentence in sent_tokenize(out, keep_whitespace, normalize_ascii):\n        yield sentence", "response": "This function takes a string and returns a generator that yields sentences with raw text segments."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef detect_sentence_boundaries(tokens):\n    tokenized = group_quoted_tokens(tokens)\n    words = []\n    sentences = []\n    for i in range(len(tokenized)):\n        # this is a parenthetical:\n        end_sentence = False\n        if isinstance(tokenized[i], list):\n            if len(words) == 0:\n                # end if a sentence finishes inside quoted section,\n                # and no sentence was begun beforehand\n                if is_end_symbol(tokenized[i][-2].rstrip()):\n                    end_sentence = True\n            else:\n                # end if a sentence finishes inside quote marks\n                if (tokenized[i][0][0] == '\"' and\n                    is_end_symbol(tokenized[i][-2].rstrip()) and\n                    not tokenized[i][1][0].isupper()):\n                    end_sentence = True\n            words.extend(tokenized[i])\n        else:\n            stripped_tokenized = tokenized[i].rstrip()\n            if is_end_symbol(stripped_tokenized):\n                words.append(tokenized[i])\n                not_last_word = i + 1 != len(tokenized)\n                next_word_lowercase = (\n                    not_last_word and\n                    tokenized[i+1][0].islower()\n                )\n                next_word_continue_punct = (\n                    not_last_word and\n                    tokenized[i+1][0] in CONTINUE_PUNCT_SYMBOLS\n                )\n                end_sentence = not (\n                    not_last_word and\n                    (\n                        next_word_lowercase or\n                        next_word_continue_punct\n                    )\n                )\n            else:\n                words.append(tokenized[i])\n        if end_sentence:\n            sentences.append(words)\n            words = []\n\n    # add final sentence, if it wasn't added yet.\n    if len(words) > 0:\n        sentences.append(words)\n\n    # If the final word ends in a period:\n    if len(sentences) > 0 and sentences[-1][-1]:\n        alpha_word_piece = word_with_alpha_and_period.match(sentences[-1][-1])\n        if alpha_word_piece:\n            sentences[-1][-1] = alpha_word_piece.group(1)\n            sentences[-1].append(alpha_word_piece.group(2))\n    return sentences", "response": "Detects the sentence boundaries of a list of tokens."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntake a string and returns a list of sentences that are sent to the current language.", "response": "def sent_tokenize(text, keep_whitespace=False, normalize_ascii=True):\n    \"\"\"\n    Perform sentence + word tokenization on the input text\n    using regular expressions and english/french specific\n    rules.\n\n    Arguments:\n    ----------\n        text : str, input string to tokenize\n        keep_whitespace : bool, whether to strip out spaces\n            and newlines.\n        normalize_ascii : bool, perform some replacements\n            on rare characters so that they become\n            easier to process in a ascii pipeline\n            (canonicalize dashes, replace \u0153 -> oe, etc..)\n    Returns:\n    --------\n        list<list<str>> : sentences with their content held\n            in a list of strings for each token.\n    \"\"\"\n    sentences = detect_sentence_boundaries(\n        tokenize(\n            text,\n            normalize_ascii\n        )\n    )\n    if not keep_whitespace:\n        sentences = remove_whitespace(sentences)\n    return sentences"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of tags that can be used in a verbatim template tag.", "response": "def verbatim_tags(parser, token, endtagname):\n    \"\"\"\n    Javascript templates (jquery, handlebars.js, mustache.js) use constructs like:\n\n    ::\n\n        {{if condition}} print something{{/if}}\n\n    This, of course, completely screws up Django templates,\n    because Django thinks {{ and }} means something.\n\n    The following code preserves {{ }} tokens.\n\n    This version of verbatim template tag allows you to use tags\n    like url {% url name %}. {% trans \"foo\" %} or {% csrf_token %} within.\n    \"\"\"\n    text_and_nodes = []\n    while 1:\n        token = parser.tokens.pop(0)\n        if token.contents == endtagname:\n            break\n\n        if token.token_type == template.base.TOKEN_VAR:\n            text_and_nodes.append('{{')\n            text_and_nodes.append(token.contents)\n\n        elif token.token_type == template.base.TOKEN_TEXT:\n            text_and_nodes.append(token.contents)\n\n        elif token.token_type == template.base.TOKEN_BLOCK:\n            try:\n                command = token.contents.split()[0]\n            except IndexError:\n                parser.empty_block_tag(token)\n\n            try:\n                compile_func = parser.tags[command]\n            except KeyError:\n                parser.invalid_block_tag(token, command, None)\n            try:\n                node = compile_func(parser, token)\n            except template.TemplateSyntaxError as e:\n                if not parser.compile_function_error(token, e):\n                    raise\n            text_and_nodes.append(node)\n\n        if token.token_type == template.base.TOKEN_VAR:\n            text_and_nodes.append('}}')\n\n    return text_and_nodes"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwriting the password in the file.", "response": "def set_password(self, service, username, password):\n        \"\"\"Write the password in the file.\n        \"\"\"\n        assoc = self._generate_assoc(service, username)\n        # encrypt the password\n        password_encrypted = self.encrypt(password.encode('utf-8'), assoc)\n        # encode with base64 and add line break to untangle config file\n        password_base64 = '\\n' + encodebytes(password_encrypted).decode()\n\n        self._write_config_value(service, username, password_base64)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprotect a string that contains periods or periods as being true periods or periods or periods that are part of shorthand.", "response": "def protect_shorthand(text, split_locations):\n    \"\"\"\n    Annotate locations in a string that contain\n    periods as being true periods or periods\n    that are a part of shorthand (and thus should\n    not be treated as punctuation marks).\n\n    Arguments:\n    ----------\n        text : str\n        split_locations : list<int>, same length as text.\n    \"\"\"\n    word_matches = list(re.finditer(word_with_period, text))\n    total_words = len(word_matches)\n\n    for i, match in enumerate(word_matches):\n        match_start = match.start()\n        match_end = match.end()\n        for char_pos in range(match_start, match_end):\n            if split_locations[char_pos] == SHOULD_SPLIT and match_end - char_pos > 1:\n                match_start = char_pos\n        word = text[match_start:match_end]\n\n        if not word.endswith('.'):\n            # ensure that words contained within other words:\n            # e.g. 'chocolate.Mountains of'  -> 'chocolate. Mountains of'\n            if (not word[0].isdigit() and\n                split_locations[match_start] == UNDECIDED):\n                split_locations[match_start] = SHOULD_SPLIT\n            continue\n        period_pos = match_end - 1\n        # this is not the last word, abbreviation\n        # is not the final period of the sentence,\n        # moreover:\n        word_is_in_abbr = word[:-1].lower() in ABBR\n        is_abbr_like = (\n            word_is_in_abbr or\n            one_letter_long_or_repeating.match(word[:-1]) is not None\n        )\n        is_digit = False if is_abbr_like else word[:-1].isdigit()\n\n        is_last_word = i == (total_words - 1)\n        is_ending = is_last_word and (match_end == len(text) or text[match_end:].isspace())\n        is_not_ending = not is_ending\n        abbreviation_and_not_end = (\n            len(word) > 1 and\n            is_abbr_like and\n            is_not_ending\n        )\n\n        if abbreviation_and_not_end and (\n                (not is_last_word and word_matches[i+1].group(0)[0].islower()) or\n                (not is_last_word and word_matches[i+1].group(0) in PUNCT_SYMBOLS) or\n                word[0].isupper() or\n                word_is_in_abbr or\n                len(word) == 2):\n            # next word is lowercase (e.g. not a new sentence?), or next word\n            # is punctuation or next word is totally uppercase (e.g. 'Mister.\n            # ABAGNALE called to the stand')\n            if split_locations[period_pos] == SHOULD_SPLIT and period_pos + 1 < len(split_locations):\n                split_locations[period_pos + 1] = SHOULD_SPLIT\n            split_locations[period_pos] = SHOULD_NOT_SPLIT\n        elif (is_digit and\n              len(word[:-1]) <= 2 and\n              not is_last_word and\n              word_matches[i+1].group(0).lower() in MONTHS):\n            # a date or weird number with a period:\n            if split_locations[period_pos] == SHOULD_SPLIT and period_pos + 1 < len(split_locations):\n                split_locations[period_pos + 1] = SHOULD_SPLIT\n            split_locations[period_pos] = SHOULD_NOT_SPLIT\n        elif split_locations[period_pos] == UNDECIDED:\n            # split this period into its own segment:\n            split_locations[period_pos] = SHOULD_SPLIT"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating a list of strings that are split by the given locations.", "response": "def split_with_locations(text, locations):\n    \"\"\"\n    Use an integer list to split the string\n    contained in `text`.\n\n    Arguments:\n    ----------\n        text : str, same length as locations.\n        locations : list<int>, contains values\n            'SHOULD_SPLIT', 'UNDECIDED', and\n            'SHOULD_NOT_SPLIT'. Will create\n            strings between each 'SHOULD_SPLIT'\n            locations.\n    Returns:\n    --------\n        Generator<str> : the substrings of text\n            corresponding to the slices given\n            in locations.\n    \"\"\"\n    start = 0\n    for pos, decision in enumerate(locations):\n        if decision == SHOULD_SPLIT:\n            if start != pos:\n                yield text[start:pos]\n            start = pos\n    if start != len(text):\n        yield text[start:]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef mark_regex(regex, text, split_locations):\n    for match in regex.finditer(text):\n        end_match = match.end()\n        if end_match < len(split_locations):\n            split_locations[end_match] = SHOULD_SPLIT", "response": "Regex that adds a SHOULD_SPLIT marker at the end of each matching group of the given regex."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmarking the beginning and end of a given regex as SHOULD_SPLIT.", "response": "def mark_begin_end_regex(regex, text, split_locations):\n    \"\"\"\n    Regex that adds a 'SHOULD_SPLIT' marker at the end\n    location of each matching group of the given regex,\n    and adds a 'SHOULD_SPLIT' at the beginning of the\n    matching group. Each character within the matching\n    group will be marked as 'SHOULD_NOT_SPLIT'.\n\n    Arguments\n    ---------\n        regex : re.Expression\n        text : str, same length as split_locations\n        split_locations : list<int>, split decisions.\n    \"\"\"\n    for match in regex.finditer(text):\n        end_match = match.end()\n        begin_match = match.start()\n\n        for i in range(begin_match+1, end_match):\n            split_locations[i] = SHOULD_NOT_SPLIT\n        if end_match < len(split_locations):\n            if split_locations[end_match] == UNDECIDED:\n                split_locations[end_match] = SHOULD_SPLIT\n        if split_locations[begin_match] == UNDECIDED:\n            split_locations[begin_match] = SHOULD_SPLIT"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef tokenize(text, normalize_ascii=True):\n    # 1. If there's no punctuation, return immediately\n    if no_punctuation.match(text):\n        return [text]\n    # 2. let's standardize the input text to ascii (if desired)\n    # Note: this will no longer respect input-to-output character positions\n    if normalize_ascii:\n        # normalize these greco-roman characters to ascii:\n        text = text.replace(u\"\u0153\", \"oe\").replace(u\"\u00e6\", \"ae\")\n        # normalize dashes:\n        text = repeated_dash_converter.sub(\"-\", text)\n    # 3. let's construct an integer array of the possible split locations:\n    split_locations = [UNDECIDED] * len(text)\n\n    regexes = (\n        pure_whitespace,\n        left_quote_shifter,\n        left_quote_converter,\n        left_single_quote_converter,\n        remaining_quote_converter,\n        # regex can't fix this -> regex ca n't fix this\n        english_nots,\n        # you'll dig this -> you 'll dig this\n        english_contractions,\n        # the rhino's horns -> the rhino 's horns\n        english_specific_appendages,\n        # qu'a tu fais au rhino -> qu ' a tu fais au rhino,\n        french_appendages\n    )\n    # 4. Mark end locations for specific regular expressions:\n    for regex in regexes:\n        mark_regex(regex, text, split_locations)\n\n    begin_end_regexes = (\n        multi_single_quote_finder,\n        right_single_quote_converter,\n        # use dashes as the breakpoint:\n        # the rhino--truck -> the rhino -- truck\n        simple_dash_finder if normalize_ascii else advanced_dash_finder,\n        numerical_expression,\n        url_file_finder,\n        shifted_ellipses,\n        # the #rhino! -> the # rhino ! ;\n        # the rino[sic] -> the rino [ sic\u00a0]\n        shifted_standard_punctuation\n    )\n\n    # 5. Mark begin and end locations for other regular expressions:\n    for regex in begin_end_regexes:\n        mark_begin_end_regex(regex, text, split_locations)\n\n    # 6. Remove splitting on exceptional uses of periods:\n    # I'm with Mr. -> I 'm with Mr. , I'm with Mister. -> I 'm with Mister .\n    protect_shorthand(text, split_locations)\n\n    if normalize_ascii:\n        text = dash_converter.sub(\"-\", text)\n    # 7. Return the split string using the integer list:\n    return list(split_with_locations(text, split_locations))", "response": "Takes a single string and returns a list of substrings."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef main(argv=None):\n    if argv is None:\n        argv = sys.argv[1:]\n\n    cli = CommandLineTool()\n    try:\n        return cli.run(argv)\n    except KeyboardInterrupt:\n        print('Canceled')\n        return 3", "response": "Main command line interface."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate the cipher object to encrypt or decrypt a payload.", "response": "def _create_cipher(self, password, salt, nonce = None):\n        \"\"\"\n        Create the cipher object to encrypt or decrypt a payload.\n        \"\"\"\n        from argon2.low_level import hash_secret_raw, Type\n        from Crypto.Cipher import AES\n\n        aesmode = self._get_mode(self.aesmode)\n        if aesmode is None:     # pragma: no cover\n            raise ValueError('invalid AES mode: %s' % self.aesmode)\n\n        key = hash_secret_raw(\n            secret = password.encode(self.password_encoding),\n            salt = salt,\n            time_cost = self.time_cost,\n            memory_cost = self.memory_cost,\n            parallelism = self.parallelism,\n            hash_len = 16,\n            type = Type.ID)\n\n        return AES.new(key, aesmode, nonce)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_mode(mode = None):\n        from Crypto.Cipher import AES\n\n        AESModeMap = {\n            'CCM': AES.MODE_CCM,\n            'EAX': AES.MODE_EAX,\n            'GCM': AES.MODE_GCM,\n            'OCB': AES.MODE_OCB,\n        }\n\n        if mode is None:\n            return AESModeMap.keys()\n        return AESModeMap.get(mode)", "response": "Return the AES mode or a list of valid AES modes."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef priority(self):\n        try:\n            __import__('argon2.low_level')\n        except ImportError:     # pragma: no cover\n            raise RuntimeError(\"argon2_cffi package required\")\n        try:\n            __import__('Crypto.Cipher.AES')\n        except ImportError:     # pragma: no cover\n            raise RuntimeError(\"PyCryptodome package required\")\n        if not json:            # pragma: no cover\n            raise RuntimeError(\"JSON implementation such as simplejson \"\n                \"required.\")\n        return 2.5", "response": "Returns the priority of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking for a valid encryption scheme and if it is valid raise an AttributeError or ValueError", "response": "def _check_scheme(self, config):\n        \"\"\"\n        check for a valid scheme\n\n        raise AttributeError if missing\n        raise ValueError if not valid\n        \"\"\"\n        try:\n            scheme = config.get(\n                escape_for_ini('keyring-setting'),\n                escape_for_ini('scheme'),\n            )\n        except (configparser.NoSectionError, configparser.NoOptionError):\n            raise AttributeError(\"Encryption scheme missing\")\n\n        # extract AES mode\n        aesmode = scheme[-3:]\n        if aesmode not in self._get_mode():\n            raise ValueError(\"Encryption scheme invalid: %s\" % (aesmode))\n\n        # setup AES mode\n        self.aesmode = aesmode\n\n        # remove pointless crypto module name\n        if scheme.startswith('PyCryptodome '):\n            scheme = scheme[13:]\n\n        # check other scheme properties\n        if scheme != self.scheme:\n            raise ValueError(\"Encryption scheme mismatch \"\n                             \"(exp.: %s, found: %s)\" % (self.scheme, scheme))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nstart the global Twisted logger subsystem with maybe stdout and or a file specified in the config file.", "response": "def startLogging(console=True, filepath=None):\n    '''\n    Starts the global Twisted logger subsystem with maybe\n    stdout and/or a file specified in the config file\n    '''\n    global logLevelFilterPredicate\n   \n    observers = []\n    if console:\n        observers.append( FilteringLogObserver(observer=textFileLogObserver(sys.stdout),  \n            predicates=[logLevelFilterPredicate] ))\n    \n    if filepath is not None and filepath != \"\":\n        observers.append( FilteringLogObserver(observer=textFileLogObserver(open(filepath,'a')), \n            predicates=[logLevelFilterPredicate] ))\n    globalLogBeginner.beginLoggingTo(observers)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset a new log level for a given namespace", "response": "def setLogLevel(namespace=None, levelStr='info'):\n    '''\n    Set a new log level for a given namespace\n    LevelStr is: 'critical', 'error', 'warn', 'info', 'debug'\n    '''\n    level = LogLevel.levelWithName(levelStr)\n    logLevelFilterPredicate.setLogLevelForNamespace(namespace=namespace, level=level)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconnects to MQTT broker and subscribe to the topic.", "response": "def connectToBroker(self, protocol):\n        '''\n        Connect to MQTT broker\n        '''\n        self.protocol                 = protocol\n        self.protocol.onPublish       = self.onPublish\n        self.protocol.onDisconnection = self.onDisconnection\n        self.protocol.setWindowSize(3) \n        try:\n            yield self.protocol.connect(\"TwistedMQTT-subs\", keepalive=60)\n            yield self.subscribe()\n        except Exception as e:\n            log.error(\"Connecting to {broker} raised {excp!s}\", \n               broker=BROKER, excp=e)\n        else:\n            log.info(\"Connected and subscribed to {broker}\", broker=BROKER)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef onPublish(self, topic, payload, qos, dup, retain, msgId):\n        '''\n        Callback Receiving messages from publisher\n        '''\n        log.debug(\"msg={payload}\", payload=payload)", "response": "Callback when a message is published"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef onDisconnection(self, reason):\n        '''\n        get notfied of disconnections\n        and get a deferred for a new protocol object (next retry)\n        '''\n        log.debug(\"<Connection was lost !> <reason={r}>\", r=reason)\n        self.whenConnected().addCallback(self.connectToBroker)", "response": "Called when the broker is disconnected"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef connectToBroker(self, protocol):\n        '''\n        Connect to MQTT broker\n        '''\n        self.protocol                 = protocol\n        self.protocol.onPublish       = self.onPublish\n        self.protocol.onDisconnection = self.onDisconnection\n        self.protocol.setWindowSize(3)\n        self.task = task.LoopingCall(self.publish)\n        self.task.start(5.0, now=False) \n        try:\n            yield self.protocol.connect(\"TwistedMQTT-pubsubs\", keepalive=60)\n            yield self.subscribe()\n        except Exception as e:\n            log.error(\"Connecting to {broker} raised {excp!s}\", \n               broker=BROKER, excp=e)\n        else:\n            log.info(\"Connected and subscribed to {broker}\", broker=BROKER)", "response": "Connect to the MQTT broker and subscribe to the MQTT broker."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nproduce ids for Protocol packets outliving their sessions", "response": "def makeId(self):\n        '''Produce ids for Protocol packets, outliving their sessions'''\n        self.id = (self.id + 1) % 65536\n        self.id = self.id or 1   # avoid id 0\n        return self.id"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsend a CONNECT control packet.", "response": "def connect(self, request):\n        '''\n        Send a CONNECT control packet.\n        '''\n        state = self.__class__.__name__\n        return defer.fail(MQTTStateError(\"Unexpected connect() operation\", state))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nhandle a CONNACK packet from the server.", "response": "def handleCONNACK(self, response):\n        '''\n        Handles CONNACK packet from the server\n        '''\n        state = self.__class__.__name__\n        log.error(\"Unexpected {packet:7} packet received in {log_source}\", packet=\"CONNACK\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef connect(clientId, keepalive=0, willTopic=None,\n                willMessage=None, willQoS=0, willRetain=False, \n                username=None, password=None, cleanStart=True, version=mqtt.v311):\n        '''\n        Abstract\n        ========\n\n        Send a CONNECT control packet.\n\n        Description\n        ===========\n\n        After a Network Connection is established by a Client to a Server, \n        the first Packet sent from the Client to the Server MUST be a CONNECT \n        Packet [MQTT-3.1.0-1].\n\n        A Client can only send the CONNECT Packet once over a \n        Network Connection. The Server MUST process a second CONNECT Packet \n        sent from a Client as a protocol violation and disconnect the Client.\n\n        If the Client does not receive a CONNACK Packet from the Server within\n        a reasonable amount of time, he Client SHOULD close the Network \n        Connection. A \"reasonable\" amount of time depends on the type of \n        application and the communications infrastructure.\n\n        Signature\n        =========\n\n        @param clientId: client ID for the connection (UTF-8 string)\n        @param keepalive: connection keepalive period in seconds.\n        @param willTopic:   last will topic  (UTF-8 string)\n        @param willMessage: last will message  (UTF-8 string)\n        @param willQoS:     last will qos message\n        @param willRetain:  lass will retain flag.\n        @param cleanStart:  session clean flag.\n        @return: a Deferred whose callback will be called with a tuple\n            C{returnCode, sessionFlag)} when the connection completes. \n            The Deferred errback with a C{MQTTError} exception will be called \n            if no connection ack is received from the server within a keepalive\n            period. If no keepalive is used, a max of 10 seconds is used.\n        '''", "response": "Connects a new connection to the server."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nencoding an UTF - 8 string into MQTT format. Returns a bytearray", "response": "def encodeString(string):\n    '''\n    Encode an UTF-8 string into MQTT format. \n    Returns a bytearray\n    '''\n    encoded = bytearray(2)\n    encoded.extend(bytearray(string, encoding='utf-8'))\n    l = len(encoded)-2\n    if(l > 65535):\n        raise StringValueError(l)\n    encoded[0] = l >> 8\n    encoded[1] = l & 0xFF\n    return encoded"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndecoding an MQTT bytearray into a UTF - 8 string", "response": "def decodeString(encoded):\n    '''\n    Decodes an UTF-8 string from an encoded MQTT bytearray.\n    Returns the decoded string and renaining bytearray to be parsed\n    '''\n    length = encoded[0]*256 + encoded[1]\n    return (encoded[2:2+length].decode('utf-8'), encoded[2+length:])"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nencodes a 16 bit unsigned integer into MQTT format.", "response": "def encode16Int(value):\n    '''\n    Encodes a 16 bit unsigned integer into MQTT format.\n    Returns a bytearray\n    '''\n    value      = int(value)\n    encoded    = bytearray(2)\n    encoded[0] = value >> 8\n    encoded[1] = value & 0xFF\n    return encoded"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef encodeLength(value):\n    '''\n    Encodes value into a multibyte sequence defined by MQTT protocol.\n    Used to encode packet length fields.\n    '''\n    encoded = bytearray()\n    while True:\n        digit = value % 128\n        value //= 128\n        if value > 0:\n            digit |= 128\n        encoded.append(digit)\n        if value <= 0:\n            break\n    return encoded", "response": "Encodes a value into a multibyte sequence defined by MQTT protocol."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndecode a variable length value defined in the MQTT protocol.", "response": "def decodeLength(encoded):\n    '''\n    Decodes a variable length value defined in the MQTT protocol.\n    This value typically represents remaining field lengths\n    '''\n    value      = 0\n    multiplier = 1\n    for i in encoded:\n        value += (i & 0x7F) * multiplier\n        multiplier *= 0x80\n        if (i & 0x80) != 0x80:\n            break\n    return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nencodes and store a DISCONNECT control packet.", "response": "def encode(self):\n        '''\n        Encode and store a DISCONNECT control packet.\n        '''\n        header    = bytearray(2)\n        header[0] = 0xE0\n        self.encoded = header\n        return str(header) if PY2 else bytes(header)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nencodes and store a CONNECT control packet.", "response": "def encode(self):\n        '''\n        Encode and store a CONNECT control packet. \n        @raise e: C{ValueError} if any encoded topic string exceeds 65535 bytes.\n        @raise e: C{ValueError} if encoded username string exceeds 65535 bytes.\n        '''\n        header    = bytearray(1)\n        varHeader = bytearray()\n        payload   = bytearray()\n        header[0] = 0x10            # packet code\n        # ---- Variable header encoding section -----\n        \n        varHeader.extend(encodeString(self.version['tag'])) \n        varHeader.append(self.version['level']) # protocol Level\n        flags =  (self.cleanStart << 1)\n        if  self.willTopic is not None and self.willMessage is not None:\n            flags |= 0x04 | (self.willRetain << 5) | (self.willQoS << 3)\n        if self.username is not None:\n            flags |= 0x80\n        if self.password is not None:\n            flags |= 0x40\n        varHeader.append(flags)\n        varHeader.extend(encode16Int(self.keepalive))\n        # ------ Payload encoding section ----\n        payload.extend(encodeString(self.clientId))\n        if self.willTopic is not None and self.willMessage is not None:\n            payload.extend(encodeString(self.willTopic))\n            payload.extend(encodeString(self.willMessage))\n        if self.username is not None:\n             payload.extend(encodeString(self.username))\n        if self.password is not None:\n            payload.extend(encode16Int(len(self.password)))\n            payload.extend(bytearray(self.password, encoding='ascii', errors='ignore'))\n        # ---- Build the packet once all lengths are known ----\n        header.extend(encodeLength(len(varHeader) + len(payload)))\n        header.extend(varHeader)\n        header.extend(payload)\n        self.encoded = header\n        return str(header) if PY2 else bytes(header)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef decode(self, packet):\n        '''\n        Decode a CONNECT control packet. \n        '''\n        self.encoded = packet\n        # Strip the fixed header plus variable length field\n        lenLen = 1\n        while packet[lenLen] & 0x80:\n            lenLen += 1\n        packet_remaining = packet[lenLen+1:]\n        # Variable Header\n        version_str, packet_remaining = decodeString(packet_remaining)\n        version_id = int(packet_remaining[0])\n        if version_id == v31['level']:\n            self.version = v31\n        else:\n            self.version = v311\n        flags = packet_remaining[1]\n        self.cleanStart = (flags & 0x02) != 0\n        willFlag   = (flags & 0x04) != 0\n        willQoS    = (flags >> 3) & 0x03\n        willRetain = (flags & 0x20) != 0\n        userFlag   = (flags & 0x80)  != 0\n        passFlag   = (flags & 0x40)  != 0\n        packet_remaining = packet_remaining[2:]\n        self.keepalive = decode16Int(packet_remaining)\n        # Payload\n        packet_remaining = packet_remaining[2:]\n        self.clientId, packet_remaining = decodeString(packet_remaining)\n        if willFlag:\n            self.willRetain = willRetain\n            self.willQoS    = willQoS\n            self.willTopic,  packet_remaining  = decodeString(packet_remaining)\n            self.willMessage, packet_remaining = decodeString(packet_remaining)\n        if userFlag:\n            self.username, packet_remaining = decodeString(packet_remaining)\n        if passFlag:\n            l = decode16Int(packet_remaining)\n            self.password = packet_remaining[2:2+l]", "response": "Decode a CONNECT control packet."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef encode(self):\n        '''\n        Encode and store a CONNACK control packet. \n        '''\n     \n        header       = bytearray(1)\n        varHeader    = bytearray(2)\n        header[0]    = 0x20 \n        varHeader[0] = self.session\n        varHeader[1] = self.resultCode\n        header.extend(encodeLength(len(varHeader)))\n        header.extend(varHeader)\n        self.encoded = header\n        return str(header) if PY2 else bytes(header)", "response": "Encode and store a CONNACK control packet."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndecoding a CONNACK packet.", "response": "def decode(self, packet):\n        '''\n        Decode a CONNACK control packet. \n        '''\n        self.encoded = packet\n        # Strip the fixed header plus variable length field\n        lenLen = 1\n        while packet[lenLen] & 0x80:\n            lenLen += 1\n        packet_remaining = packet[lenLen+1:]\n        self.session = (packet_remaining[0] & 0x01) == 0x01 \n        self.resultCode  = int(packet_remaining[1])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef decode(self, packet):\n        '''\n        Decode a SUBSCRIBE control packet. \n        '''\n        self.encoded = packet\n        lenLen = 1\n        while packet[lenLen] & 0x80:\n            lenLen += 1\n        packet_remaining = packet[lenLen+1:]\n        self.msgId   = decode16Int(packet_remaining[0:2])\n        self.topics = []\n        packet_remaining = packet_remaining[2:]\n        while len(packet_remaining):\n            topic, packet_remaining = decodeString(packet_remaining)\n            qos =  int (packet_remaining[0]) & 0x03\n            self.topics.append((topic,qos))\n            packet_remaining = packet_remaining[1:]", "response": "Decode a SUBSCRIBE control packet."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nencoding and store a SUBACK control packet.", "response": "def encode(self):\n        '''\n        Encode and store a SUBACK control packet.\n        '''\n        header    = bytearray(1)\n        payload   = bytearray()\n        varHeader = encode16Int(self.msgId)\n        header[0] = 0x90\n        for code in self.granted:\n            payload.append(code[0] | (0x80 if code[1] == True else 0x00))\n        header.extend(encodeLength(len(varHeader) + len(payload)))\n        header.extend(varHeader)\n        header.extend(payload)\n        self.encoded = header\n        return str(header) if PY2 else bytes(header)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nencodes and store an UNSUBCRIBE control packet.", "response": "def encode(self):\n        '''\n        Encode and store an UNSUBCRIBE control packet\n        @raise e: C{ValueError} if any encoded topic string exceeds 65535 bytes\n        '''\n        header    = bytearray(1)\n        payload   = bytearray()\n        varHeader = encode16Int(self.msgId)\n        header[0] = 0xA2    # packet with QoS=1\n        for topic in self.topics:\n            payload.extend(encodeString(topic)) # topic name\n        header.extend(encodeLength(len(varHeader) + len(payload)))\n        header.extend(varHeader)\n        header.extend(payload)\n        self.encoded = header\n        return str(header) if PY2 else bytes(header)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndecoding a UNSUBACK control packet.", "response": "def decode(self, packet):\n        '''\n        Decode a UNSUBACK control packet. \n        '''\n        self.encoded = packet\n        lenLen = 1\n        while packet[lenLen] & 0x80:\n            lenLen += 1\n        packet_remaining = packet[lenLen+1:]\n        self.msgId   = decode16Int(packet_remaining[0:2])\n        self.topics = []\n        packet_remaining = packet_remaining[2:]\n        while len(packet_remaining):\n            l = decode16Int(packet_remaining[0:2])\n            topic = packet_remaining[2:2+l].decode(encoding='utf-8')\n            self.topics.append(topic)\n            packet_remaining = packet_remaining[2+l:]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef encode(self):\n        '''\n        Encode and store an UNSUBACK control packet\n        '''\n        header    = bytearray(1)\n        varHeader = encode16Int(self.msgId)\n        header[0] = 0xB0 \n        header.extend(encodeLength(len(varHeader)))\n        header.extend(varHeader)\n        self.encoded = header\n        return str(header) if PY2 else bytes(header)", "response": "Encode and store an UNSUBACK control packet"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nencode and store a PUBLISH control packet.", "response": "def encode(self):\n        '''\n        Encode and store a PUBLISH control packet.\n        @raise e: C{ValueError} if encoded topic string exceeds 65535 bytes.\n        @raise e: C{ValueError} if encoded packet size exceeds 268435455 bytes.\n        @raise e: C{TypeError} if C{data} is not a string, bytearray, int, boolean or float.\n        '''\n        header    = bytearray(1)\n        varHeader = bytearray()\n        payload   = bytearray()\n\n        if self.qos:\n            header[0] = 0x30 | self.retain | (self.qos << 1) | (self.dup << 3)\n            varHeader.extend(encodeString(self.topic)) # topic name\n            varHeader.extend(encode16Int(self.msgId))  # msgId should not be None\n        else:\n            header[0] = 0x30 | self.retain\n            varHeader.extend(encodeString(self.topic)) # topic name\n        if isinstance(self.payload, bytearray):\n            payload.extend(self.payload)\n        elif isinstance(self.payload, str):\n            payload.extend(bytearray(self.payload, encoding='utf-8'))\n        else:\n            raise PayloadTypeError(type(self.payload))\n        totalLen = len(varHeader) + len(payload)\n        if totalLen > 268435455:\n            raise PayloadValueError(totalLen)\n        header.extend(encodeLength(totalLen))\n        header.extend(varHeader)\n        header.extend(payload)\n        self.encoded = header\n        return str(header) if PY2 else bytes(header)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndecode a PUBLISH control packet.", "response": "def decode(self, packet):\n        '''\n        Decode a PUBLISH control packet. \n        '''\n        self.encoded = packet\n        lenLen = 1\n        while packet[lenLen] & 0x80:\n            lenLen += 1\n        packet_remaining = packet[lenLen+1:]\n        self.dup    = (packet[0] & 0x08) == 0x08\n        self.qos    = (packet[0] & 0x06) >> 1\n        self.retain = (packet[0] & 0x01) == 0x01\n        self.topic, _  = decodeString(packet_remaining)\n        topicLen       = decode16Int(packet_remaining)\n        if self.qos:\n            self.msgId = decode16Int( packet_remaining[topicLen+2:topicLen+4] )\n            self.payload =  packet_remaining[topicLen+4:]\n        else:\n            self.msgId = None\n            self.payload = packet_remaining[topicLen+2:]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef decode(self, packet):\n        '''\n        Decode a PUBREL control packet. \n        '''\n        self.encoded = packet\n        lenLen = 1\n        while packet[lenLen] & 0x80:\n            lenLen += 1\n        packet_remaining = packet[lenLen+1:]\n        self.msgId  = decode16Int(packet_remaining)\n        self.dup = (packet[0] & 0x08) == 0x08", "response": "Decode a PUBREL control packet."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn url for call method.", "response": "def get_url(self, method=None, **kwargs):\n        \"\"\"Return url for call method.\n\n        :param method (optional): `str` method name.\n        :returns: `str` URL.\n        \"\"\"\n        kwargs.setdefault('v', self.__version)\n\n        if self.__token is not None:\n            kwargs.setdefault('access_token', self.__token)\n\n        return 'https://api.vk.com/method/{}?{}'.format(\n            method or self.__method, urlencode(kwargs)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsend request to API.", "response": "def request(self, method, **kwargs):\n        \"\"\"\n        Send request to API.\n\n        :param method: `str` method name.\n        :returns: `dict` response.\n        \"\"\"\n        kwargs.setdefault('v', self.__version)\n\n        if self.__token is not None:\n            kwargs.setdefault('access_token', self.__token)\n\n        return requests.get(self.get_url(method, **kwargs)).json()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef authentication(login, password):\n    session = requests.Session()\n    response = session.get('https://m.vk.com')\n    url = re.search(r'action=\"([^\\\"]+)\"', response.text).group(1)\n    data = {'email': login, 'pass': password}\n    response = session.post(url, data=data)\n    return session", "response": "Authenticate on vk. com."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_from_array(self, blockname, array, Nfile=None, memorylimit=1024 * 1024 * 256):\n        size = len(array)\n\n        # sane value -- 32 million items per physical file\n        sizeperfile = 32 * 1024 * 1024\n\n        if Nfile is None:\n            Nfile = (size + sizeperfile - 1) // sizeperfile\n\n        dtype = numpy.dtype((array.dtype, array.shape[1:]))\n\n        itemsize = dtype.itemsize\n        # we will do some chunking\n\n        # write memorylimit bytes at most (256M bytes)\n        # round to 1024 items\n        itemlimit = memorylimit // dtype.itemsize // 1024 * 1024\n\n        with self.create(blockname, dtype, size, Nfile) as b:\n            for i in range(0, len(array), itemlimit):\n                b.write(i, numpy.array(array[i:i+itemlimit]))\n\n        return self.open(blockname)", "response": "create a new block from array like objects"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrefresh the list of blocks to the disk collectively", "response": "def refresh(self):\n        \"\"\" Refresh the list of blocks to the disk, collectively \"\"\"\n        if self.comm.rank == 0:\n            self._blocks = self.list_blocks()\n        else:\n            self._blocks = None\n        self._blocks = self.comm.bcast(self._blocks)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a new block from array like objects", "response": "def create_from_array(self, blockname, array, Nfile=None, memorylimit=1024 * 1024 * 256):\n        \"\"\" create a block from array like objects\n            The operation is well defined only if array is at most 2d.\n\n            Parameters\n            ----------\n            array : array_like,\n                array shall have a scalar dtype. \n            blockname : string\n                name of the block\n            Nfile : int or None\n                number of physical files. if None, 32M items per file\n                is used.\n            memorylimit : int\n                number of bytes to use for the buffering. relevant only if\n                indexing on array returns a copy (e.g. IO or dask array)\n\n        \"\"\"\n        size = self.comm.allreduce(len(array))\n\n        # sane value -- 32 million items per physical file\n        sizeperfile = 32 * 1024 * 1024\n\n        if Nfile is None:\n            Nfile = (size + sizeperfile - 1) // sizeperfile\n\n        offset = sum(self.comm.allgather(len(array))[:self.comm.rank])\n        dtype = numpy.dtype((array.dtype, array.shape[1:]))\n\n        itemsize = dtype.itemsize\n        # we will do some chunking\n\n        # write memorylimit bytes at most (256M bytes)\n        # round to 1024 items\n        itemlimit = memorylimit // dtype.itemsize // 1024 * 1024\n\n        with self.create(blockname, dtype, size, Nfile) as b:\n            for i in range(0, len(array), itemlimit):\n                b.write(offset + i, numpy.array(array[i:i+itemlimit]))\n\n        return self.open(blockname)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if the value is a string type and attempts to convert it to a boolean otherwise returns the original value.", "response": "def maybebool(value):\n    '''\n    If `value` is a string type, attempts to convert it to a boolean\n    if it looks like it might be one, otherwise returns the value\n    unchanged. The difference between this and\n    :func:`pyramid.settings.asbool` is how non-bools are handled: this\n    returns the original value, whereas `asbool` returns False.\n    '''\n    if isinstance(value, six.string_types) and value.lower() in booly:\n        return asbool(value)  # pragma: no cover\n    return value"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef format_data(self, data, scale=True):\n        if len(self.analytes) == 1:\n            # if single analyte\n            d = nominal_values(data[self.analytes[0]])\n            ds = np.array(list(zip(d, np.zeros(len(d)))))\n        else:\n            # package multiple analytes\n            d = [nominal_values(data[a]) for a in self.analytes]\n            ds = np.vstack(d).T\n\n        # identify all nan values\n        finite = np.isfinite(ds).sum(1) == ds.shape[1]\n        # remember which values are sampled\n        sampled = np.arange(data[self.analytes[0]].size)[finite]\n        # remove all nan values\n        ds = ds[finite]\n\n        if scale:\n            ds = self.scaler.transform(ds)\n\n        return ds, sampled", "response": "Function for converting a dict of data to an array suitable for sklearn."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fitting_data(self, data):\n        ds_fit, _ = self.format_data(data, scale=False)\n\n        # define scaler\n        self.scaler = preprocessing.StandardScaler().fit(ds_fit)\n\n        # scale data and return\n        return self.scaler.transform(ds_fit)", "response": "Function to format data for cluster fitting."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fit_kmeans(self, data, n_clusters, **kwargs):\n        km = cl.KMeans(n_clusters=n_clusters, **kwargs)\n        km.fit(data)\n        return km", "response": "Fit KMeans clustering algorithm to data."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fit_meanshift(self, data, bandwidth=None, bin_seeding=False, **kwargs):\n        if bandwidth is None:\n            bandwidth = cl.estimate_bandwidth(data)\n        ms = cl.MeanShift(bandwidth=bandwidth, bin_seeding=bin_seeding)\n        ms.fit(data)\n        return ms", "response": "Fit MeanShift clustering algorithm to data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfit classifiers from large dataset.", "response": "def fit(self, data, method='kmeans', **kwargs):\n        \"\"\"\n        fit classifiers from large dataset.\n\n        Parameters\n        ----------\n        data : dict\n            A dict of data for clustering. Must contain\n            items with the same name as analytes used for\n            clustering.\n        method : str\n            A string defining the clustering method used. Can be:\n\n            * 'kmeans' : K-Means clustering algorithm\n            * 'meanshift' : Meanshift algorithm\n\n        n_clusters : int\n            *K-Means only*. The numebr of clusters to identify\n        bandwidth : float\n            *Meanshift only.*\n            The bandwidth value used during clustering.\n            If none, determined automatically. Note:\n            the data are scaled before clutering, so\n            this is not in the same units as the data.\n        bin_seeding : bool\n            *Meanshift only.*\n            Whether or not to use 'bin_seeding'. See\n            documentation for `sklearn.cluster.MeanShift`.\n        **kwargs :\n            passed to `sklearn.cluster.MeanShift`.\n\n        Returns\n        -------\n        list\n        \"\"\"\n        self.method = method\n        ds_fit = self.fitting_data(data)\n        mdict = {'kmeans': self.fit_kmeans,\n                 'meanshift': self.fit_meanshift}\n        clust = mdict[method]\n\n        self.classifier = clust(data=ds_fit, **kwargs)\n\n        # sort cluster centers by value of first column, to avoid random variation.\n        c0 = self.classifier.cluster_centers_.T[self.sort_by]\n        self.classifier.cluster_centers_ = self.classifier.cluster_centers_[np.argsort(c0)]\n\n        # recalculate the labels, so it's consistent with cluster centers\n        self.classifier.labels_ = self.classifier.predict(ds_fit)\n        self.classifier.ulabels_ = np.unique(self.classifier.labels_)\n\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef predict(self, data):\n        size = data[self.analytes[0]].size\n        ds, sampled = self.format_data(data)\n\n        # predict clusters\n        cs = self.classifier.predict(ds)\n        # map clusters to original index\n        clusters = self.map_clusters(size, sampled, cs)\n\n        return clusters", "response": "Predict new data with cluster identities."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntranslate cluster identity back to original data size.", "response": "def map_clusters(self, size, sampled, clusters):\n        \"\"\"\n        Translate cluster identity back to original data size.\n\n        Parameters\n        ----------\n        size : int\n            size of original dataset\n        sampled : array-like\n            integer array describing location of finite values\n            in original data.\n        clusters : array-like\n            integer array of cluster identities\n\n        Returns\n        -------\n        list of cluster identities the same length as original\n        data. Where original data are non-finite, returns -2.\n\n        \"\"\"\n        ids = np.zeros(size, dtype=int)\n        ids[:] = -2\n\n        ids[sampled] = clusters\n\n        return ids"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsorting clusters by concentration of a particular analyte.", "response": "def sort_clusters(self, data, cs, sort_by):\n        \"\"\"\n        Sort clusters by the concentration of a particular analyte.\n\n        Parameters\n        ----------\n        data : dict\n            A dataset containing sort_by as a key.\n        cs : array-like\n            An array of clusters, the same length as values of data.\n        sort_by : str\n            analyte to sort the clusters by\n\n        Returns\n        -------\n        array of clusters, sorted by mean value of sort_by analyte.\n        \"\"\"\n        # label the clusters according to their contents\n        sdat = data[sort_by]\n\n        means = []\n        nclusts = np.arange(cs.max() + 1)\n        for c in nclusts:\n            means.append(np.nanmean(sdat[cs == c]))\n\n        # create ranks\n        means = np.array(means)\n        rank = np.zeros(means.size)\n        rank[np.argsort(means)] = np.arange(means.size)\n\n        csn = cs.copy()\n        for c, o in zip(nclusts, rank):\n            csn[cs == c] = o\n\n        return csn"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a datetime oject from a string with optional time format.", "response": "def get_date(datetime, time_format=None):\n    \"\"\"\n    Return a datetime oject from a string, with optional time format.\n\n    Parameters\n    ----------\n    datetime : str\n        Date-time as string in any sensible format.\n    time_format : datetime str (optional)\n        String describing the datetime format. If missing uses\n        dateutil.parser to guess time format.\n    \"\"\"\n    if time_format is None:\n        t = du.parser.parse(datetime)\n    else:\n        t = dt.datetime.strftime(datetime, time_format)\n    return t"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the total number of data points in values of dict.", "response": "def get_total_n_points(d):\n    \"\"\"\n    Returns the total number of data points in values of dict.\n\n    Paramters\n    ---------\n    d : dict\n    \"\"\"\n    n = 0\n    for di in d.values():\n        n += len(di)\n    return n"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_total_time_span(d):\n\n    tmax = 0\n    for di in d.values():\n        if di.uTime.max() > tmax:\n            tmax = di.uTime.max()\n    \n    return tmax", "response": "Returns the total length of analysis."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef unitpicker(a, llim=0.1, denominator=None, focus_stage=None):\n\n    if not isinstance(a, (int, float)):\n        a = nominal_values(a)\n        a = np.percentile(a[~np.isnan(a)], 25)\n\n    if denominator is not None:\n        pd = pretty_element(denominator)\n    else:\n        pd = ''\n\n    if focus_stage == 'calibrated':\n        udict = {0: 'mol/mol ' + pd,\n                 1: 'mmol/mol ' + pd,\n                 2: '$\\mu$mol/mol ' + pd,\n                 3: 'nmol/mol ' + pd,\n                 4: 'pmol/mol ' + pd,\n                 5: 'fmol/mol ' + pd}\n    elif focus_stage == 'ratios':\n        udict = {0: 'counts/count ' + pd,\n                 1: '$10^{-3}$ counts/count ' + pd,\n                 2: '$10^{-6}$ counts/count ' + pd,\n                 3: '$10^{-9}$ counts/count ' + pd,\n                 4: '$10^{-12}$ counts/count ' + pd,\n                 5: '$10^{-15}$ counts/count ' + pd}\n    elif focus_stage in ('rawdata', 'despiked', 'bkgsub'):\n        udict = udict = {0: 'counts',\n                         1: '$10^{-3}$ counts',\n                         2: '$10^{-6}$ counts',\n                         3: '$10^{-9}$ counts',\n                         4: '$10^{-12}$ counts',\n                         5: '$10^{-15}$ counts'}\n    else:\n        udict = {0: '', 1: '', 2: '', 3: '', 4: '', 5: ''}\n\n    a = abs(a)\n    n = 0\n    if a < llim:\n        while a < llim:\n            a *= 1000\n            n += 1\n    return float(1000**n), udict[n]", "response": "Returns a new random number generator that can be used to plot the data in a new random number generator."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a string with the name of the current language element.", "response": "def pretty_element(s):\n    \"\"\"\n    Returns formatted element name.\n\n    Parameters\n    ----------\n    s : str\n        of format [A-Z][a-z]?[0-9]+\n\n    Returns\n    -------\n    str\n        LaTeX formatted string with superscript numbers.\n    \"\"\"\n    el = re.match('.*?([A-z]{1,3}).*?', s).groups()[0]\n    m = re.match('.*?([0-9]{1,3}).*?', s).groups()[0]\n\n    return '$^{' + m + '}$' + el"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting analytes in format 27Al to Al27.", "response": "def analyte_2_namemass(s):\n    \"\"\"\n    Converts analytes in format '27Al' to 'Al27'.\n\n    Parameters\n    ----------\n    s : str\n        of format [A-z]{1,3}[0-9]{1,3}\n\n    Returns\n    -------\n    str\n        Name in format [0-9]{1,3}[A-z]{1,3}\n    \"\"\"\n    el = re.match('.*?([A-z]{1,3}).*?', s).groups()[0]\n    m = re.match('.*?([0-9]{1,3}).*?', s).groups()[0]\n\n    return el + m"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts analytes in format Al27 to 27Al.", "response": "def analyte_2_massname(s):\n    \"\"\"\n    Converts analytes in format 'Al27' to '27Al'.\n\n    Parameters\n    ----------\n    s : str\n        of format [0-9]{1,3}[A-z]{1,3}\n\n    Returns\n    -------\n    str\n        Name in format [A-z]{1,3}[0-9]{1,3}\n    \"\"\"\n    el = re.match('.*?([A-z]{1,3}).*?', s).groups()[0]\n    m = re.match('.*?([0-9]{1,3}).*?', s).groups()[0]\n\n    return m + el"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef collate_data(in_dir, extension='.csv', out_dir=None):\n    if out_dir is None:\n        out_dir = './' + re.search('^\\.(.*)', extension).groups(0)[0]\n\n    if not os.path.isdir(out_dir):\n        os.mkdir(out_dir)\n\n    for p, d, fs in os.walk(in_dir):\n        for f in fs:\n            if extension in f:\n                shutil.copy(p + '/' + f, out_dir + '/' + f)\n    return", "response": "This function collates all csv files in a directory into a single directory."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef bool_2_indices(a):\n    if any(a):\n        lims = []\n        lims.append(np.where(a[:-1] != a[1:])[0])\n\n        if a[0]:\n            lims.append([0])\n        if a[-1]:\n            lims.append([len(a) - 1])\n        lims = np.concatenate(lims)\n        lims.sort()\n\n        return np.reshape(lims, (lims.size // 2, 2))\n    else:\n        return None", "response": "Convert boolean array into a 2D array of start stop pairs."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef enumerate_bool(bool_array, nstart=0):\n    ind = bool_2_indices(bool_array)\n    ns = np.full(bool_array.size, nstart, dtype=int)\n    for n, lims in enumerate(ind):\n        ns[lims[0]:lims[-1] + 1] = nstart + n + 1\n    return ns", "response": "Enumerate contiguous booleans in array."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates boolean array from list of limit tuples.", "response": "def tuples_2_bool(tuples, x):\n    \"\"\"\n    Generate boolean array from list of limit tuples.\n\n    Parameters\n    ----------\n    tuples : array_like\n        [2, n] array of (start, end) values\n    x : array_like\n        x scale the tuples are mapped to\n\n    Returns\n    -------\n    array_like\n        boolean array, True where x is between each pair of tuples.\n    \"\"\"\n    if np.ndim(tuples) == 1:\n        tuples = [tuples]\n\n    out = np.zeros(x.size, dtype=bool)\n    for l, u in tuples:\n        out[(x > l) & (x < u)] = True\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef rolling_window(a, window, pad=None):\n    shape = a.shape[:-1] + (a.shape[-1] - window + 1, window)\n    strides = a.strides + (a.strides[-1], )\n    out = np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)\n    # pad shape\n    if window % 2 == 0:\n        npre = window // 2 - 1\n        npost = window // 2\n    else:\n        npre = npost = window // 2\n    if isinstance(pad, str):\n        if pad == 'ends':\n            prepad = np.full((npre, window), a[0])\n            postpad = np.full((npost, window), a[-1])\n        elif pad == 'mean_ends':\n            prepad = np.full((npre, window), np.mean(a[:(window // 2)]))\n            postpad = np.full((npost, window), np.mean(a[-(window // 2):]))\n        elif pad == 'repeat_ends':\n            prepad = np.full((npre, window), out[0])\n            postpad = np.full((npost, window), out[0])\n        else:\n            raise ValueError(\"If pad is a string, it must be either 'ends', 'mean_ends' or 'repeat_ends'.\")\n\n        return np.concatenate((prepad, out, postpad))\n    elif pad is not None:\n        pre_blankpad = np.empty(((npre, window)))\n        pre_blankpad[:] = pad\n        post_blankpad = np.empty(((npost, window)))\n        post_blankpad[:] = pad\n        return np.concatenate([pre_blankpad, out, post_blankpad])\n    else:\n        return out", "response": "Return a rolling window of a array of data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfunctioning to efficiently calculate the rolling mean of a numpy array using stride_tricks", "response": "def fastsmooth(a, win=11):\n    \"\"\"\n    Returns rolling - window smooth of a.\n\n    Function to efficiently calculate the rolling mean of a numpy\n    array using 'stride_tricks' to split up a 1D array into an ndarray of\n    sub - sections of the original array, of dimensions [len(a) - win, win].\n\n    Parameters\n    ----------\n    a : array_like\n        The 1D array to calculate the rolling gradient of.\n    win : int\n        The width of the rolling window.\n\n    Returns\n    -------\n    array_like\n        Gradient of a, assuming as constant integer x - scale.\n    \"\"\"\n    # check to see if 'window' is odd (even does not work)\n    if win % 2 == 0:\n        win += 1  # add 1 to window if it is even.\n    kernel = np.ones(win) / win\n    npad = int((win - 1) / 2)\n    spad = np.full(npad + 1, np.mean(a[:(npad + 1)]))\n    epad = np.full(npad - 1, np.mean(a[-(npad - 1):]))\n    return np.concatenate([spad, np.convolve(a, kernel, 'valid'), epad])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fastgrad(a, win=11):\n    # check to see if 'window' is odd (even does not work)\n    if win % 2 == 0:\n        win += 1  # subtract 1 from window if it is even.\n    # trick for efficient 'rolling' computation in numpy\n    # shape = a.shape[:-1] + (a.shape[-1] - win + 1, win)\n    # strides = a.strides + (a.strides[-1], )\n    # wins = np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)\n    wins = rolling_window(a, win, 'ends')\n    # apply rolling gradient to data\n    a = map(lambda x: np.polyfit(np.arange(win), x, 1)[0], wins)\n\n    return np.array(list(a))", "response": "Function to efficiently calculate the rolling - window gradient of a 1D array."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncalculate gradients of values in x in a dict of items.", "response": "def calc_grads(x, dat, keys=None, win=5):\n    \"\"\"\n    Calculate gradients of values in dat.\n    \n    Parameters\n    ----------\n    x : array like\n        Independent variable for items in dat.\n    dat : dict\n        {key: dependent_variable} pairs\n    keys : str or array-like\n        Which keys in dict to calculate the gradient of.\n    win : int\n        The side of the rolling window for gradient calculation\n\n    Returns\n    -------\n    dict of gradients\n    \"\"\"\n    if keys is None:\n        keys = dat.keys()\n\n    def grad(xy):\n        if (~np.isnan(xy)).all():\n            try:\n                return np.polyfit(xy[0], xy[1], 1)[0]\n            except ValueError:\n                return np.nan\n        else:\n            return np.nan\n\n    xs = rolling_window(x, win, pad='repeat_ends')\n    grads = Bunch()\n    for k in keys:\n        d = nominal_values(rolling_window(dat[k], win, pad='repeat_ends'))\n\n        grads[k] = np.array(list(map(grad, zip(xs, d))))\n\n    return grads"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfunction to find local minima.", "response": "def findmins(x, y):\n    \"\"\" Function to find local minima.\n\n    Parameters\n    ----------\n    x, y : array_like\n        1D arrays of the independent (x) and dependent (y) variables.\n\n    Returns\n    -------\n    array_like\n        Array of points in x where y has a local minimum.\n    \"\"\"\n    return x[np.r_[False, y[1:] < y[:-1]] & np.r_[y[:-1] < y[1:], False]]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef stack_keys(ddict, keys, extra=None):\n    if isinstance(keys, str):\n        d = [ddict[keys]]\n    else:\n        d = [ddict[k] for k in keys]\n    if extra is not None:\n        d = extra + d\n    return np.vstack(d).T", "response": "Stacks the keys of a dict into a single array of shape len ( keys )."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cluster_meanshift(data, bandwidth=None, bin_seeding=False, **kwargs):\n    if bandwidth is None:\n        bandwidth = cl.estimate_bandwidth(data)\n\n    ms = cl.MeanShift(bandwidth=bandwidth, bin_seeding=bin_seeding, **kwargs)\n    ms.fit(data)\n\n    labels = ms.labels_\n\n    return labels, [np.nan]", "response": "Identify clusters using Meanshift algorithm."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cluster_kmeans(data, n_clusters, **kwargs):\n    km = cl.KMeans(n_clusters, **kwargs)\n    kmf = km.fit(data)\n\n    labels = kmf.labels_\n\n    return labels, [np.nan]", "response": "Identify clusters using K - Means algorithm."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nidentify clusters using DBSCAN algorithm. Parameters ---------- data : array_like array of size [n_samples, n_features]. eps : float The minimum 'distance' points must be apart for them to be in the same cluster. Defaults to 0.3. Note: If the data are normalised (they should be for DBSCAN) this is in terms of total sample variance. Normalised data have a mean of 0 and a variance of 1. min_samples : int The minimum number of samples within distance `eps` required to be considered as an independent cluster. n_clusters : int The number of clusters expected. If specified, `eps` will be incrementally reduced until the expected number of clusters is found. maxiter : int The maximum number of iterations DBSCAN will run. Returns ------- dict boolean array for each identified cluster and core samples.", "response": "def cluster_DBSCAN(data, eps=None, min_samples=None,\n                   n_clusters=None, maxiter=200, **kwargs):\n    \"\"\"\n    Identify clusters using DBSCAN algorithm.\n\n    Parameters\n    ----------\n    data : array_like\n        array of size [n_samples, n_features].\n    eps : float\n        The minimum 'distance' points must be apart for them to be in the\n        same cluster. Defaults to 0.3. Note: If the data are normalised\n        (they should be for DBSCAN) this is in terms of total sample\n        variance.  Normalised data have a mean of 0 and a variance of 1.\n    min_samples : int\n        The minimum number of samples within distance `eps` required\n        to be considered as an independent cluster.\n    n_clusters : int\n        The number of clusters expected. If specified, `eps` will be\n        incrementally reduced until the expected number of clusters is\n        found.\n    maxiter : int\n        The maximum number of iterations DBSCAN will run.\n\n    Returns\n    -------\n    dict\n        boolean array for each identified cluster and core samples.\n    \"\"\"\n    if n_clusters is None:\n        if eps is None:\n            eps = 0.3\n        db = cl.DBSCAN(eps=eps, min_samples=min_samples, **kwargs).fit(data)\n    else:\n        clusters = 0\n        eps_temp = 1 / .95\n        niter = 0\n        while clusters < n_clusters:\n            clusters_last = clusters\n            eps_temp *= 0.95\n            db = cl.DBSCAN(eps=eps_temp, min_samples=min_samples, **kwargs).fit(data)\n            clusters = (len(set(db.labels_)) -\n                        (1 if -1 in db.labels_ else 0))\n            if clusters < clusters_last:\n                eps_temp *= 1 / 0.95\n                db = cl.DBSCAN(eps=eps_temp, min_samples=min_samples, **kwargs).fit(data)\n                clusters = (len(set(db.labels_)) -\n                            (1 if -1 in db.labels_ else 0))\n                warnings.warn(('\\n\\n***Unable to find {:.0f} clusters in '\n                                'data. Found {:.0f} with an eps of {:.2e}'\n                                '').format(n_clusters, clusters, eps_temp))\n                break\n            niter += 1\n            if niter == maxiter:\n                warnings.warn(('\\n\\n***Maximum iterations ({:.0f}) reached'\n                                ', {:.0f} clusters not found.\\nDeacrease '\n                                'min_samples or n_clusters (or increase '\n                                'maxiter).').format(maxiter, n_clusters))\n                break\n\n    labels = db.labels_\n\n    core_samples_mask = np.zeros_like(labels)\n    core_samples_mask[db.core_sample_indices_] = True\n\n    return labels, core_samples_mask"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning list of SRMS defined in the SRM database", "response": "def get_defined_srms(srm_file):\n    \"\"\"\n    Returns list of SRMS defined in the SRM database\n    \"\"\"\n    srms = read_table(srm_file)\n    return np.asanyarray(srms.index.unique())"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read_configuration(config='DEFAULT'):\n    # read configuration file\n    _, conf = read_latoolscfg()\n    # if 'DEFAULT', check which is the default configuration\n    if config == 'DEFAULT':\n        config = conf['DEFAULT']['config']\n\n    # grab the chosen configuration\n    conf = dict(conf[config])\n    # update config name with chosen\n    conf['config'] = config\n    return conf", "response": "Read LAtools configuration file and return parameters as dict.\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read_latoolscfg():\n    config_file = pkgrs.resource_filename('latools', 'latools.cfg')\n    cf = configparser.ConfigParser()\n    cf.read(config_file)\n    return config_file, cf", "response": "Reads the config file returns a ConfigParser object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef print_all():\n    # read configuration file\n    _, conf = read_latoolscfg()\n\n    default = conf['DEFAULT']['config']\n\n    pstr = '\\nCurrently defined LAtools configurations:\\n\\n'\n    for s in conf.sections():\n        if s == default:\n            pstr += s + ' [DEFAULT]\\n'\n        elif s == 'REPRODUCE':\n            pstr += s + ' [DO NOT ALTER]\\n'\n        else:\n            pstr += s + '\\n'\n\n        for k, v in conf[s].items():\n            if k != 'config':\n                if v[:9] == 'resources':\n                    v = pkgrs.resource_filename('latools', v)\n                pstr += '   ' + k + ': ' + v + '\\n'\n        pstr += '\\n'\n\n    print(pstr)\n    return", "response": "Prints all currently defined LAtools configurations."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef copy_SRM_file(destination=None, config='DEFAULT'):\n    # find SRM file from configuration    \n    conf = read_configuration()\n\n    src = pkgrs.resource_filename('latools', conf['srmfile'])\n\n    # work out destination path (if not given)\n    if destination is None:\n        destination = './LAtools_' + conf['config'] + '_SRMTable.csv'\n    \n    if os.path.isdir(destination):\n        destination += 'LAtools_' + conf['config'] + '_SRMTable.csv'\n\n    copyfile(src, destination)\n\n    print(src + ' \\n    copied to:\\n      ' + destination)\n    return", "response": "Copy the default SRM file to the specified location."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a new configuration file and returns it.", "response": "def create(config_name, srmfile=None, dataformat=None, base_on='DEFAULT', make_default=False):\n    \"\"\"\n    Adds a new configuration to latools.cfg.\n\n    Parameters\n    ----------\n    config_name : str\n        The name of the new configuration. This should be descriptive\n        (e.g. UC Davis Foram Group)\n    srmfile : str (optional)\n        The location of the srm file used for calibration.\n    dataformat : str (optional)\n        The location of the dataformat definition to use.\n    base_on : str\n        The name of the existing configuration to base the new one on.\n        If either srm_file or dataformat are not specified, the new\n        config will copy this information from the base_on config.\n    make_default : bool\n        Whether or not to make the new configuration the default\n        for future analyses. Default = False.\n\n    Returns\n    -------\n    None\n    \"\"\"\n\n    base_config = read_configuration(base_on)\n\n    # read config file\n    config_file, cf = read_latoolscfg()\n    \n    # if config doesn't already exist, create it.\n    if config_name not in cf.sections():\n        cf.add_section(config_name)\n    # set parameter values\n    if dataformat is None:\n        dataformat = base_config['dataformat']\n    cf.set(config_name, 'dataformat', dataformat)\n\n    if srmfile is None:\n        srmfile = base_config['srmfile']\n    cf.set(config_name, 'srmfile', srmfile)\n\n    # make the parameter set default, if requested\n    if make_default:\n        cf.set('DEFAULT', 'config', config_name)\n\n    with open(config_file, 'w') as f:\n        cf.write(f)\n\n    return"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef change_default(config):\n    config_file, cf = read_latoolscfg()\n\n    if config not in cf.sections():\n        raise ValueError(\"\\n'{:s}' is not a defined configuration.\".format(config))\n\n    if config == 'REPRODUCE':\n        pstr = ('Are you SURE you want to set REPRODUCE as your default configuration?\\n' + \n                '     ... this is an odd thing to be doing.')\n    else:\n        pstr = ('Are you sure you want to change the default configuration from {:s}'.format(cf['DEFAULT']['config']) + \n                'to {:s}?'.format(config))\n\n    response = input(pstr + '\\n> [N/y]: ')\n\n    if response.lower() == 'y':\n        cf.set('DEFAULT', 'config', config)\n        with open(config_file, 'w') as f:\n            cf.write(f)\n        print('  Default changed!')\n    else:\n        print('  Done nothing.')", "response": "Change the default configuration of the current language."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn boolean arrays where a < threshold and a < threshold.", "response": "def threshold(values, threshold):\n    \"\"\"\n    Return boolean arrays where a >= and < threshold.\n\n    Parameters\n    ----------\n    values : array-like\n        Array of real values.\n    threshold : float\n        Threshold value\n    \n    Returns\n    -------\n    (below, above) : tuple or boolean arrays\n    \"\"\"\n    values = nominal_values(values)\n    return (values < threshold, values >= threshold)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef exclude_downhole(filt, threshold=2):\n    cfilt = filt.copy()\n\n    inds = bool_2_indices(~filt)\n\n    rem = (np.diff(inds) >= threshold)[:, 0]\n\n    if any(rem):\n        if inds[rem].shape[0] > 1:\n            limit = inds[rem][1, 0]\n            cfilt[limit:] = False\n    \n    return cfilt", "response": "Exclude all data after the first excluded portion."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef trim(ind, start=1, end=0):\n\n    return np.roll(ind, start) & np.roll(ind, -end)", "response": "Removes points from the start and end of True regions."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the focus attribute of the object.", "response": "def setfocus(self, focus):\n        \"\"\"\n        Set the 'focus' attribute of the data file.\n\n        The 'focus' attribute of the object points towards data from a\n        particular stage of analysis. It is used to identify the 'working\n        stage' of the data. Processing functions operate on the 'focus'\n        stage, so if steps are done out of sequence, things will break.\n\n        Names of analysis stages:\n\n        * 'rawdata': raw data, loaded from csv file when object\n          is initialised.\n        * 'despiked': despiked data.\n        * 'signal'/'background': isolated signal and background data,\n          padded with np.nan. Created by self.separate, after\n          signal and background regions have been identified by\n          self.autorange.\n        * 'bkgsub': background subtracted data, created by\n          self.bkg_correct\n        * 'ratios': element ratio data, created by self.ratio.\n        * 'calibrated': ratio data calibrated to standards, created by\n          self.calibrate.\n\n        Parameters\n        ----------\n        focus : str\n            The name of the analysis stage desired.\n\n        Returns\n        -------\n        None\n        \"\"\"\n        self.focus = self.data[focus]\n        self.focus_stage = focus\n\n        self.__dict__.update(self.focus)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\napply exponential decay and noise despike to data.", "response": "def despike(self, expdecay_despiker=True, exponent=None,\n                noise_despiker=True, win=3, nlim=12., maxiter=3):\n        \"\"\"\n        Applies expdecay_despiker and noise_despiker to data.\n\n        Parameters\n        ----------\n        expdecay_despiker : bool\n            Whether or not to apply the exponential decay filter.\n        exponent : None or float\n            The exponent for the exponential decay filter. If None,\n            it is determined automatically using `find_expocoef`.\n        noise_despiker : bool\n            Whether or not to apply the standard deviation spike filter.\n        win : int\n            The rolling window over which the spike filter calculates\n            the trace statistics.\n        nlim : float\n            The number of standard deviations above the rolling mean\n            that data are excluded.\n        maxiter : int\n            The max number of times that the fitler is applied.\n\n        Returns\n        -------\n        None\n\n        \"\"\"\n        if not hasattr(self, 'despiked'):\n            self.data['despiked'] = Bunch()\n\n        out = {}\n        for a, v in self.focus.items():\n            if 'time' not in a.lower():\n                sig = v.copy()  # copy data\n                if expdecay_despiker:\n                    if exponent is not None:\n                        sig = proc.expdecay_despike(sig, exponent, self.tstep, maxiter)\n                    else:\n                        warnings.warn('exponent is None - either provide exponent, or run at `analyse`\\nlevel to automatically calculate it.')\n                \n                if noise_despiker:\n                    sig = proc.noise_despike(sig, int(win), nlim, maxiter)\n                out[a] = sig\n\n        self.data['despiked'].update(out)\n        # recalculate total counts\n        self.data['total_counts'] = sum(self.data['despiked'].values())\n        self.setfocus('despiked')\n        return"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef autorange(self, analyte='total_counts', gwin=5, swin=3, win=30,\n                  on_mult=[1., 1.], off_mult=[1., 1.5],\n                  ploterrs=True, transform='log', **kwargs):\n        \"\"\"\n        Automatically separates signal and background data regions.\n\n        Automatically detect signal and background regions in the laser\n        data, based on the behaviour of a single analyte. The analyte used\n        should be abundant and homogenous in the sample.\n\n        **Step 1: Thresholding.**\n        The background signal is determined using a gaussian kernel density\n        estimator (kde) of all the data. Under normal circumstances, this\n        kde should find two distinct data distributions, corresponding to\n        'signal' and 'background'. The minima between these two distributions\n        is taken as a rough threshold to identify signal and background\n        regions. Any point where the trace crosses this thrshold is identified\n        as a 'transition'.\n\n        **Step 2: Transition Removal.**\n        The width of the transition regions between signal and background are\n        then determined, and the transitions are excluded from analysis. The\n        width of the transitions is determined by fitting a gaussian to the\n        smoothed first derivative of the analyte trace, and determining its\n        width at a point where the gaussian intensity is at at `conf` time the\n        gaussian maximum. These gaussians are fit to subsets of the data\n        centered around the transitions regions determined in Step 1, +/- `win`\n        data points. The peak is further isolated by finding the minima and\n        maxima of a second derivative within this window, and the gaussian is\n        fit to the isolated peak.\n\n        Parameters\n        ----------\n        analyte : str\n            The analyte that autorange should consider. For best results,\n            choose an analyte that is present homogeneously in high\n            concentrations.\n        gwin : int\n            The smoothing window used for calculating the first derivative.\n            Must be odd.\n        win : int\n            Determines the width (c +/- win) of the transition data subsets.\n        on_mult and off_mult : tuple, len=2\n            Factors to control the width of the excluded transition regions.\n            A region n times the full - width - half - maximum of the transition\n            gradient will be removed either side of the transition center.\n            `on_mult` and `off_mult` refer to the laser - on and laser - off\n            transitions, respectively. See manual for full explanation.\n            Defaults to (1.5, 1) and (1, 1.5).\n\n\n        Returns\n        -------\n        Outputs added as instance attributes. Returns None.\n        bkg, sig, trn : iterable, bool\n            Boolean arrays identifying background, signal and transision\n            regions\n        bkgrng, sigrng and trnrng : iterable\n            (min, max) pairs identifying the boundaries of contiguous\n            True regions in the boolean arrays.\n        \"\"\"\n        if analyte is None:\n            # sig = self.focus[self.internal_standard]\n            sig = self.data['total_counts']\n        elif analyte == 'total_counts':\n            sig = self.data['total_counts']\n        elif analyte in self.analytes:\n            sig = self.focus[analyte]\n        else:\n            raise ValueError('Invalid analyte.')\n\n        (self.bkg, self.sig,\n         self.trn, failed) = proc.autorange(self.Time, sig, gwin=gwin, swin=swin, win=win,\n                                            on_mult=on_mult, off_mult=off_mult,\n                                            transform=transform)\n\n        self.mkrngs()\n\n        errs_to_plot = False\n        if len(failed) > 0:\n            errs_to_plot = True\n            plotlines = []\n            for f in failed:\n                if f != self.Time[-1]:\n                    plotlines.append(f)\n            # warnings.warn((\"\\n\\nSample {:s}: \".format(self.sample) +\n            #                \"Transition identification at \" +\n            #                \"{:.1f} failed.\".format(f) +\n            #                \"\\n  **This is not necessarily a problem**\"\n            #                \"\\nBut please check the data plots and make sure \" +\n            #                \"everything is OK.\\n\"))\n\n        if ploterrs and errs_to_plot and len(plotlines) > 0:\n            f, ax = self.tplot(ranges=True)\n            for pl in plotlines:\n                ax.axvline(pl, c='r', alpha=0.6, lw=3, ls='dashed')\n            return f, plotlines\n        else:\n            return", "response": "A basic autorange of the log - likelihood of the current sample."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nplot a detailed autorange report for this sample.", "response": "def autorange_plot(self, analyte='total_counts', gwin=7, swin=None, win=20,\n                       on_mult=[1.5, 1.], off_mult=[1., 1.5],\n                       transform='log'):\n        \"\"\"\n        Plot a detailed autorange report for this sample.\n        \"\"\"\n        if analyte is None:\n            # sig = self.focus[self.internal_standard]\n            sig = self.data['total_counts']\n        elif analyte == 'total_counts':\n            sig = self.data['total_counts']\n        elif analyte in self.analytes:\n            sig = self.focus[analyte]\n        else:\n            raise ValueError('Invalid analyte.')\n\n        if transform == 'log':\n            sig = np.log10(sig)\n\n        fig, axs = plot.autorange_plot(t=self.Time, sig=sig, gwin=gwin,\n                                       swin=swin, win=win, on_mult=on_mult,\n                                       off_mult=off_mult)\n\n        return fig, axs"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntransform boolean arrays into list of limit pairs.", "response": "def mkrngs(self):\n        \"\"\"\n        Transform boolean arrays into list of limit pairs.\n\n        Gets Time limits of signal/background boolean arrays and stores them as\n        sigrng and bkgrng arrays. These arrays can be saved by 'save_ranges' in\n        the analyse object.\n        \"\"\"\n        bbool = bool_2_indices(self.bkg)\n        if bbool is not None:\n            self.bkgrng = self.Time[bbool]\n        else:\n            self.bkgrng = [[np.nan, np.nan]]\n        sbool = bool_2_indices(self.sig)\n        if sbool is not None:\n            self.sigrng = self.Time[sbool]\n        else:\n            self.sigrng = [[np.nan, np.nan]]\n        tbool = bool_2_indices(self.trn)\n        if tbool is not None:\n            self.trnrng = self.Time[tbool]\n        else:\n            self.trnrng = [[np.nan, np.nan]]\n\n        self.ns = np.zeros(self.Time.size)\n        n = 1\n        for i in range(len(self.sig) - 1):\n            if self.sig[i]:\n                self.ns[i] = n\n            if self.sig[i] and ~self.sig[i + 1]:\n                n += 1\n        self.n = int(max(self.ns))  # record number of traces\n\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef bkg_subtract(self, analyte, bkg, ind=None, focus_stage='despiked'):\n        if 'bkgsub' not in self.data.keys():\n            self.data['bkgsub'] = Bunch()\n\n        self.data['bkgsub'][analyte] = self.data[focus_stage][analyte] - bkg\n\n        if ind is not None:\n            self.data['bkgsub'][analyte][ind] = np.nan\n\n        return", "response": "Subtracts provided background from signal."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef correct_spectral_interference(self, target_analyte, source_analyte, f):\n\n        if target_analyte not in self.analytes:\n            raise ValueError('target_analyte: {:} not in available analytes ({:})'.format(target_analyte, ', '.join(self.analytes)))\n\n        if source_analyte not in self.analytes:\n            raise ValueError('source_analyte: {:} not in available analytes ({:})'.format(source_analyte, ', '.join(self.analytes)))\n\n        self.data['bkgsub'][target_analyte] -= self.data['bkgsub'][source_analyte] * f", "response": "Correct the spectral interference of two sets of analytes."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndivides all analytes by a specified internal_standard and set the focus to the ratio of the analytes.", "response": "def ratio(self, internal_standard=None):\n        \"\"\"\n        Divide all analytes by a specified internal_standard analyte.\n\n        Parameters\n        ----------\n        internal_standard : str\n            The analyte used as the internal_standard.\n\n        Returns\n        -------\n        None\n        \"\"\"\n        if internal_standard is not None:\n            self.internal_standard = internal_standard\n\n        self.data['ratios'] = Bunch()\n        for a in self.analytes:\n            self.data['ratios'][a] = (self.data['bkgsub'][a] /\n                                      self.data['bkgsub'][self.internal_standard])\n        self.setfocus('ratios')\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\napplies calibration to data.", "response": "def calibrate(self, calib_ps, analytes=None):\n        \"\"\"\n        Apply calibration to data.\n\n        The `calib_dict` must be calculated at the `analyse` level,\n        and passed to this calibrate function.\n\n        Parameters\n        ----------\n        calib_dict : dict\n            A dict of calibration values to apply to each analyte.\n\n        Returns\n        -------\n        None\n        \"\"\"\n        # can have calibration function stored in self and pass *coefs?\n        if analytes is None:\n            analytes = self.analytes\n\n        if 'calibrated' not in self.data.keys():\n            self.data['calibrated'] = Bunch()\n\n        for a in analytes:\n            m = calib_ps[a]['m'].new(self.uTime)\n\n            if 'c' in calib_ps[a]:\n                c = calib_ps[a]['c'].new(self.uTime)\n            else:\n                c = 0\n\n            self.data['calibrated'][a] = self.data['ratios'][a] * m + c\n\n        if self.internal_standard not in analytes:\n            self.data['calibrated'][self.internal_standard] = \\\n                np.empty(len(self.data['ratios'][self.internal_standard]))\n\n        self.setfocus('calibrated')\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalculates sample statistics for the specified analytes and return the samples analytes and arrays of statistics.", "response": "def sample_stats(self, analytes=None, filt=True,\n                     stat_fns={},\n                     eachtrace=True):\n        \"\"\"\n        Calculate sample statistics\n\n        Returns samples, analytes, and arrays of statistics\n        of shape (samples, analytes). Statistics are calculated\n        from the 'focus' data variable, so output depends on how\n        the data have been processed.\n\n        Parameters\n        ----------\n        analytes : array_like\n            List of analytes to calculate the statistic on\n        filt : bool or str\n            The filter to apply to the data when calculating sample statistics.\n                bool: True applies filter specified in filt.switches.\n                str: logical string specifying a partucular filter\n        stat_fns : dict\n            Dict of {name: function} pairs. Functions that take a single\n            array_like input, and return a single statistic. Function should\n            be able to cope with NaN values.\n        eachtrace : bool\n            True: per - ablation statistics\n            False: whole sample statistics\n\n        Returns\n        -------\n        None\n        \"\"\"\n        if analytes is None:\n                analytes = self.analytes\n        elif isinstance(analytes, str):\n            analytes = [analytes]\n\n        self.stats = Bunch()\n        self.stats['analytes'] = analytes\n\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n            for n, f in stat_fns.items():\n                self.stats[n] = []\n                for a in analytes:\n                    ind = self.filt.grab_filt(filt, a)\n                    dat = nominal_values(self.focus[a])\n                    if eachtrace:\n                        sts = []\n                        for t in np.arange(self.n) + 1:\n                            sts.append(f(dat[ind & (self.ns == t)]))\n                        self.stats[n].append(sts)\n                    else:\n                        self.stats[n].append(f(dat[ind]))\n                self.stats[n] = np.array(self.stats[n])\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfunctions for calculating the ablation time for each entry in the set of all the ablation times. Returns ------- dict of times for each entry in the set of ablation times for each entry in the set.", "response": "def ablation_times(self):\n        \"\"\"\n        Function for calculating the ablation time for each\n        ablation.\n\n        Returns\n        -------\n            dict of times for each ablation.\n        \"\"\"\n        ats = {}\n        for n in np.arange(self.n) + 1:\n            t = self.Time[self.ns == n]\n            ats[n - 1] = t.max() - t.min()\n        return ats"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\napply threshold filter. Generates threshold filters for the given analytes above and below the specified threshold. Two filters are created with prefixes '_above' and '_below'. '_above' keeps all the data above the threshold. '_below' keeps all the data below the threshold. i.e. to select data below the threshold value, you should turn the '_above' filter off. Parameters ---------- analyte : TYPE Description of `analyte`. threshold : TYPE Description of `threshold`. Returns ------- None", "response": "def filter_threshold(self, analyte, threshold):\n        \"\"\"\n        Apply threshold filter.\n\n        Generates threshold filters for the given analytes above and below\n        the specified threshold.\n\n        Two filters are created with prefixes '_above' and '_below'.\n            '_above' keeps all the data above the threshold.\n            '_below' keeps all the data below the threshold.\n\n        i.e. to select data below the threshold value, you should turn the\n        '_above' filter off.\n\n        Parameters\n        ----------\n        analyte : TYPE\n            Description of `analyte`.\n        threshold : TYPE\n            Description of `threshold`.\n\n        Returns\n        -------\n        None\n        \"\"\"\n        params = locals()\n        del(params['self'])\n\n        # generate filter\n        below, above = filters.threshold(self.focus[analyte], threshold)\n\n        setn = self.filt.maxset + 1\n\n        self.filt.add(analyte + '_thresh_below',\n                        below,\n                        'Keep below {:.3e} '.format(threshold) + analyte,\n                        params, setn=setn)\n        self.filt.add(analyte + '_thresh_above',\n                        above,\n                        'Keep above {:.3e} '.format(threshold) + analyte,\n                        params, setn=setn)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\napplying gradient threshold filter.", "response": "def filter_gradient_threshold(self, analyte, win, threshold, recalc=True):\n        \"\"\"\n        Apply gradient threshold filter.\n\n        Generates threshold filters for the given analytes above and below\n        the specified threshold.\n\n        Two filters are created with prefixes '_above' and '_below'.\n            '_above' keeps all the data above the threshold.\n            '_below' keeps all the data below the threshold.\n\n        i.e. to select data below the threshold value, you should turn the\n        '_above' filter off.\n\n        Parameters\n        ----------\n        analyte : str\n            Description of `analyte`.\n        threshold : float\n            Description of `threshold`.\n        win : int\n            Window used to calculate gradients (n points)\n        recalc : bool\n            Whether or not to re-calculate the gradients.\n\n        Returns\n        -------\n        None\n        \"\"\"\n        params = locals()\n        del(params['self'])\n\n        # calculate absolute gradient\n        if recalc or not self.grads_calced:\n            self.grads = calc_grads(self.Time, self.focus,\n                                    [analyte], win)\n            self.grads_calced = True\n\n        below, above = filters.threshold(abs(self.grads[analyte]), threshold)\n\n        setn = self.filt.maxset + 1\n\n        self.filt.add(analyte + '_gthresh_below',\n                        below,\n                        'Keep gradient below {:.3e} '.format(threshold) + analyte,\n                        params, setn=setn)\n        self.filt.add(analyte + '_gthresh_above',\n                        above,\n                        'Keep gradient above {:.3e} '.format(threshold) + analyte,\n                        params, setn=setn)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\napplies a n - dimensional clustering filter to the data.", "response": "def filter_clustering(self, analytes, filt=False, normalise=True,\n                          method='meanshift', include_time=False,\n                          sort=None, min_data=10, **kwargs):\n        \"\"\"\n        Applies an n - dimensional clustering filter to the data.\n\n        Available Clustering Algorithms\n\n        * 'meanshift': The `sklearn.cluster.MeanShift` algorithm.\n          Automatically determines number of clusters\n          in data based on the `bandwidth` of expected\n          variation.\n        * 'kmeans': The `sklearn.cluster.KMeans` algorithm. Determines\n          the characteristics of a known number of clusters\n          within the data. Must provide `n_clusters` to specify\n          the expected number of clusters.\n        * 'DBSCAN': The `sklearn.cluster.DBSCAN` algorithm. Automatically\n          determines the number and characteristics of clusters\n          within the data based on the 'connectivity' of the\n          data (i.e. how far apart each data point is in a\n          multi - dimensional parameter space). Requires you to\n          set `eps`, the minimum distance point must be from\n          another point to be considered in the same cluster,\n          and `min_samples`, the minimum number of points that\n          must be within the minimum distance for it to be\n          considered a cluster. It may also be run in automatic\n          mode by specifying `n_clusters` alongside\n          `min_samples`, where eps is decreased until the\n          desired number of clusters is obtained.\n        \n        For more information on these algorithms, refer to the\n        documentation.\n\n        Parameters\n        ----------\n        analytes : str\n            The analyte(s) that the filter applies to.\n        filt : bool\n            Whether or not to apply existing filters to the data before\n            calculating this filter.\n        normalise : bool\n            Whether or not to normalise the data to zero mean and unit\n            variance. Reccomended if clustering based on more than 1 analyte.\n            Uses `sklearn.preprocessing.scale`.\n        method : str\n            Which clustering algorithm to use (see above).\n        include_time : bool\n            Whether or not to include the Time variable in the clustering\n            analysis. Useful if you're looking for spatially continuous\n            clusters in your data, i.e. this will identify each spot in your\n            analysis as an individual cluster.\n        sort : bool, str or array-like\n            Whether or not to label the resulting clusters according to their\n            contents. If used, the cluster with the lowest values will be\n            labelled from 0, in order of increasing cluster mean value.analytes.\n            The sorting rules depend on the value of 'sort', which can be the name\n            of a single analyte (str), a list of several analyte names (array-like)\n            or True (bool), to specify all analytes used to calcualte the cluster.\n        min_data : int\n            The minimum number of data points that should be considered by\n            the filter. Default = 10.\n        **kwargs\n            Parameters passed to the clustering algorithm specified by\n            `method`.\n\n        Meanshift Parameters\n        --------------------\n        bandwidth : str or float\n            The bandwith (float) or bandwidth method ('scott' or 'silverman')\n            used to estimate the data bandwidth.\n        bin_seeding : bool\n            Modifies the behaviour of the meanshift algorithm. Refer to\n            sklearn.cluster.meanshift documentation.\n\n        K - Means Parameters\n        ------------------\n        n_clusters : int\n            The number of clusters expected in the data.\n\n        DBSCAN Parameters\n        -----------------\n        eps : float\n            The minimum 'distance' points must be apart for them to be in the\n            same cluster. Defaults to 0.3. Note: If the data are normalised\n            (they should be for DBSCAN) this is in terms of total sample\n            variance. Normalised data have a mean of 0 and a variance of 1.\n        min_samples : int\n            The minimum number of samples within distance `eps` required\n            to be considered as an independent cluster.\n        n_clusters : int\n            The number of clusters expected. If specified, `eps` will be\n            incrementally reduced until the expected number of clusters is\n            found.\n        maxiter : int\n            The maximum number of iterations DBSCAN will run.\n\n        Returns\n        -------\n        None\n        \"\"\"\n        params = locals()\n        del(params['self'])\n\n        # convert string to list, if single analyte\n        if isinstance(analytes, str):\n            analytes = [analytes]\n\n        setn = self.filt.maxset + 1\n\n        # generate filter\n        vals = np.vstack(nominal_values(list(self.focus.values())))\n        if filt is not None:\n            ind = (self.filt.grab_filt(filt, analytes) &\n                   np.apply_along_axis(all, 0, ~np.isnan(vals)))\n        else:\n            ind = np.apply_along_axis(all, 0, ~np.isnan(vals))\n\n        if sum(ind) > min_data:\n\n            # get indices for data passed to clustering\n            sampled = np.arange(self.Time.size)[ind]\n\n            # generate data for clustering\n            if include_time:\n                extra = self.Time\n            else:\n                extra = None\n            # get data as array\n            ds = stack_keys(self.focus, analytes, extra)\n            # apply filter, and get nominal values\n            ds = nominal_values(ds[ind, :])\n\n            if normalise | (len(analytes) > 1):\n                ds = preprocessing.scale(ds)\n\n            method_key = {'kmeans': clustering.cluster_kmeans,\n                        #   'DBSCAN': clustering.cluster_DBSCAN,\n                          'meanshift': clustering.cluster_meanshift}\n\n            cfun = method_key[method]\n\n            labels, core_samples_mask = cfun(ds, **kwargs)\n            # return labels, and if DBSCAN core_sample_mask\n\n            labels_unique = np.unique(labels)\n\n            # label the clusters according to their contents\n            if (sort is not None) & (sort is not False):\n\n                if isinstance(sort, str):\n                    sort = [sort]\n\n                sanalytes = analytes\n\n                # make boolean filter to select analytes\n                if sort is True:\n                    sortk = np.array([True] * len(sanalytes))\n                else:\n                    sortk = np.array([s in sort for s in sanalytes])\n\n                # create per-point mean based on selected analytes.\n                sd = np.apply_along_axis(sum, 1, ds[:, sortk])\n                # calculate per-cluster means\n                avs = [np.nanmean(sd[labels == lab]) for lab in labels_unique]\n                # re-order the cluster labels based on their means\n                order = [x[0] for x in sorted(enumerate(avs), key=lambda x:x[1])]\n                sdict = dict(zip(order, labels_unique))\n            else:\n                sdict = dict(zip(labels_unique, labels_unique))\n\n            filts = {}\n            for ind, lab in sdict.items():\n                filts[lab] = labels == ind\n\n            # only applies to DBSCAN results.\n            if not all(np.isnan(core_samples_mask)):\n                filts['core'] = core_samples_mask\n\n            resized = {}\n            for k, v in filts.items():\n                resized[k] = np.zeros(self.Time.size, dtype=bool)\n                resized[k][sampled] = v\n\n            namebase = '-'.join(analytes) + '_cluster-' + method\n            info = '-'.join(analytes) + ' cluster filter.'\n\n            if method == 'DBSCAN':\n                for k, v in resized.items():\n                    if isinstance(k, str):\n                        name = namebase + '_core'\n                    elif k < 0:\n                        name = namebase + '_noise'\n                    else:\n                        name = namebase + '_{:.0f}'.format(k)\n                    self.filt.add(name, v, info=info, params=params, setn=setn)\n            else:\n                for k, v in resized.items():\n                    name = namebase + '_{:.0f}'.format(k)\n                    self.filt.add(name, v, info=info, params=params, setn=setn)\n        else:\n            # if there are no data\n            name = '-'.join(analytes) + '_cluster-' + method + '_0'\n            info = '-'.join(analytes) + ' cluster filter failed.'\n\n            self.filt.add(name, np.zeros(self.Time.size, dtype=bool),\n                          info=info, params=params, setn=setn)\n\n        return"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncalculate the local correlation between two analytes.", "response": "def calc_correlation(self, x_analyte, y_analyte, window=15, filt=True, recalc=True):\n        \"\"\"\n        Calculate local correlation between two analytes.\n\n        Parameters\n        ----------\n        x_analyte, y_analyte : str\n            The names of the x and y analytes to correlate.\n        window : int, None\n            The rolling window used when calculating the correlation.\n        filt : bool\n            Whether or not to apply existing filters to the data before\n            calculating this filter.\n        recalc : bool\n            If True, the correlation is re-calculated, even if it is already present.\n\n        Returns\n        -------\n        None\n        \"\"\"\n        label = '{:}_{:}_{:.0f}'.format(x_analyte, y_analyte, window)\n\n        if label in self.correlations and not recalc:\n            return\n\n        # make window odd\n        if window % 2 != 1:\n            window += 1\n        \n        # get filter\n        ind = self.filt.grab_filt(filt, [x_analyte, y_analyte])\n\n        x = nominal_values(self.focus[x_analyte])\n        x[~ind] = np.nan\n        xr = rolling_window(x, window, pad=np.nan)\n\n        y = nominal_values(self.focus[y_analyte])\n        y[~ind] = np.nan\n        yr = rolling_window(y, window, pad=np.nan)\n\n        r, p = zip(*map(nan_pearsonr, xr, yr))\n\n        r = np.array(r)\n        p = np.array(p)\n\n        # save correlation info\n        \n        self.correlations[label] = r, p\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef filter_correlation(self, x_analyte, y_analyte, window=15,\n                           r_threshold=0.9, p_threshold=0.05, filt=True, recalc=False):\n        \"\"\"\n        Calculate correlation filter.\n\n        Parameters\n        ----------\n        x_analyte, y_analyte : str\n            The names of the x and y analytes to correlate.\n        window : int, None\n            The rolling window used when calculating the correlation.\n        r_threshold : float\n            The correlation index above which to exclude data.\n            Note: the absolute pearson R value is considered, so\n            negative correlations below -`r_threshold` will also\n            be excluded.\n        p_threshold : float\n            The significant level below which data are excluded.\n        filt : bool\n            Whether or not to apply existing filters to the data before\n            calculating this filter.\n        recalc : bool\n            If True, the correlation is re-calculated, even if it is already present.\n\n        Returns\n        -------\n        None\n        \"\"\"\n        # make window odd\n        if window % 2 != 1:\n            window += 1\n\n        params = locals()\n        del(params['self'])\n\n        setn = self.filt.maxset + 1\n\n        label = '{:}_{:}_{:.0f}'.format(x_analyte, y_analyte, window)\n        \n        self.calc_correlation(x_analyte, y_analyte, window, filt, recalc)\n        r, p = self.correlations[label]\n\n        cfilt = (abs(r) > r_threshold) & (p < p_threshold)\n        cfilt = ~cfilt\n\n        name = x_analyte + '_' + y_analyte + '_corr'\n\n        self.filt.add(name=name,\n                      filt=cfilt,\n                      info=(x_analyte + ' vs. ' + y_analyte +\n                            ' correlation filter.'),\n                      params=params, setn=setn)\n        self.filt.off(filt=name)\n        self.filt.on(analyte=y_analyte, filt=name)\n\n        return", "response": "Calculate and apply a correlation filter to the set of analytes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nplot the local correlation between two analytes.", "response": "def correlation_plot(self, x_analyte, y_analyte, window=15, filt=True, recalc=False):\n        \"\"\"\n        Plot the local correlation between two analytes.\n\n        Parameters\n        ----------\n        x_analyte, y_analyte : str\n            The names of the x and y analytes to correlate.\n        window : int, None\n            The rolling window used when calculating the correlation.\n        filt : bool\n            Whether or not to apply existing filters to the data before\n            calculating this filter.\n        recalc : bool\n            If True, the correlation is re-calculated, even if it is already present.\n\n        Returns\n        -------\n        fig, axs : figure and axes objects\n        \"\"\"\n        label = '{:}_{:}_{:.0f}'.format(x_analyte, y_analyte, window)\n\n        self.calc_correlation(x_analyte, y_analyte, window, filt, recalc)\n        r, p = self.correlations[label]\n\n        fig, axs = plt.subplots(3, 1, figsize=[7, 5], sharex=True)\n        \n        # plot analytes\n        ax = axs[0]\n            \n        ax.plot(self.Time, nominal_values(self.focus[x_analyte]), color=self.cmap[x_analyte], label=x_analyte)\n        ax.plot(self.Time, nominal_values(self.focus[y_analyte]), color=self.cmap[y_analyte], label=y_analyte)\n        \n        ax.set_yscale('log')\n        ax.legend()\n        ax.set_ylabel('Signals')\n        \n        # plot r\n        ax = axs[1]\n        ax.plot(self.Time, r)\n        ax.set_ylabel('Pearson R')\n        \n        # plot p\n        ax = axs[2]\n        ax.plot(self.Time, p)\n        ax.set_ylabel('pignificance Level (p)')\n        \n        fig.tight_layout()\n        \n        return fig, axs"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef filter_new(self, name, filt_str):\n        filt = self.filt.grab_filt(filt=filt_str)\n        self.filt.add(name, filt, info=filt_str)\n        return", "response": "Make new filter from combination of other filters."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves points from the start and end of the filter regions.", "response": "def filter_trim(self, start=1, end=1, filt=True):\n        \"\"\"\n        Remove points from the start and end of filter regions.\n        \n        Parameters\n        ----------\n        start, end : int\n            The number of points to remove from the start and end of\n            the specified filter.\n        filt : valid filter string or bool\n            Which filter to trim. If True, applies to currently active\n            filters.\n        \"\"\"\n        params = locals()\n        del(params['self'])\n            \n        f = self.filt.grab_filt(filt)\n        nf = filters.trim(f, start, end)\n        \n        self.filt.add('trimmed_filter',\n                    nf,\n                    'Trimmed Filter ({:.0f} start, {:.0f} end)'.format(start, end),\n                    params, setn=self.filt.maxset + 1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef filter_exclude_downhole(self, threshold, filt=True):\n        f = self.filt.grab_filt(filt)\n\n        if self.n == 1:\n            nfilt = filters.exclude_downhole(f, threshold)\n\n        else:\n            nfilt = []\n            for i in range(self.n):\n                nf = self.ns == i + 1\n                nfilt.append(filters.exclude_downhole(f & nf, threshold))\n            nfilt = np.apply_along_axis(any, 0, nfilt)\n\n        self.filt.add(name='downhole_excl_{:.0f}'.format(threshold),\n                      filt=nfilt,\n                      info='Exclude data downhole of {:.0f} consecutive filtered points.'.format(threshold),\n                      params=(threshold, filt))", "response": "Exclude all data points down -hole of the specified threshold."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef signal_optimiser(self, analytes, min_points=5,\n                         threshold_mode='kde_first_max',\n                         threshold_mult=1., x_bias=0,\n                         weights=None, filt=True, mode='minimise'):\n        \"\"\"\n        Optimise data selection based on specified analytes.\n\n        Identifies the longest possible contiguous data region in\n        the signal where the relative standard deviation (std) and \n        concentration of all analytes is minimised.\n\n        Optimisation is performed via a grid search of all possible\n        contiguous data regions. For each region, the mean std and\n        mean scaled analyte concentration ('amplitude') are calculated. \n        \n        The size and position of the optimal data region are identified \n        using threshold std and amplitude values. Thresholds are derived\n        from all calculated stds and amplitudes using the method specified\n        by `threshold_mode`. For example, using the 'kde_max' method, a\n        probability density function (PDF) is calculated for std and\n        amplitude values, and the threshold is set as the maximum of the\n        PDF. These thresholds are then used to identify the size and position\n        of the longest contiguous region where the std is below the threshold, \n        and the amplitude is either below the threshold.\n\n        All possible regions of the data that have at least\n        `min_points` are considered.\n\n        For a graphical demonstration of the action of signal_optimiser, \n        use `optimisation_plot`. \n\n        Parameters\n        ----------\n        d : latools.D object\n            An latools data object.\n        analytes : str or array-like\n            Which analytes to consider.\n        min_points : int\n            The minimum number of contiguous points to\n            consider.\n        threshold_mode : str\n            The method used to calculate the optimisation\n            thresholds. Can be 'mean', 'median', 'kde_max'\n            or 'bayes_mvs', or a custom function. If a\n            function, must take a 1D array, and return a\n            single, real number.\n        weights : array-like of length len(analytes)\n            An array of numbers specifying the importance of\n            each analyte considered. Larger number makes the\n            analyte have a greater effect on the optimisation.\n            Default is None.\n        \"\"\"\n        params = locals()\n        del(params['self'])\n        setn = self.filt.maxset + 1\n\n        if isinstance(analytes, str):\n            analytes = [analytes]\n        \n        # get filter\n        if filt is not False:\n            ind = (self.filt.grab_filt(filt, analytes))\n        else:\n            ind = np.full(self.Time.shape, True)\n        \n        errmsg = []\n        ofilt = []\n        self.opt = {}\n        for i in range(self.n):\n            nind = ind & (self.ns == i + 1)\n\n            self.opt[i + 1], err = signal_optimiser(self, analytes=analytes,\n                                                    min_points=min_points, \n                                                    threshold_mode=threshold_mode,\n                                                    threshold_mult=threshold_mult,\n                                                    weights=weights,\n                                                    ind=nind, x_bias=x_bias,\n                                                    mode=mode)\n\n            if err == '':\n                ofilt.append(self.opt[i + 1].filt)\n            else:\n                errmsg.append(self.sample + '_{:.0f}: '.format(i + 1) + err)\n\n        if len(ofilt) > 0:\n            ofilt = np.apply_along_axis(any, 0, ofilt)\n\n            name = 'optimise_' + '_'.join(analytes)\n            self.filt.add(name=name,\n                        filt=ofilt,\n                        info=\"Optimisation filter to minimise \" + ', '.join(analytes),\n                        params=params, setn=setn)            \n        \n        if len(errmsg) > 0:\n            return '\\n'.join(errmsg)\n        else:\n            return ''", "response": "This method is used to optimize the data selection based on the specified analytes."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nplots analytes as a function of Time.", "response": "def tplot(self, analytes=None, figsize=[10, 4], scale='log', filt=None,\n              ranges=False, stats=False, stat='nanmean', err='nanstd',\n              focus_stage=None, err_envelope=False, ax=None):\n        \"\"\"\n        Plot analytes as a function of Time.\n\n        Parameters\n        ----------\n        analytes : array_like\n            list of strings containing names of analytes to plot.\n            None = all analytes.\n        figsize : tuple\n            size of final figure.\n        scale : str or None\n           'log' = plot data on log scale\n        filt : bool, str or dict\n            False: plot unfiltered data.\n            True: plot filtered data over unfiltered data.\n            str: apply filter key to all analytes\n            dict: apply key to each analyte in dict. Must contain all\n            analytes plotted. Can use self.filt.keydict.\n        ranges : bool\n            show signal/background regions.\n        stats : bool\n            plot average and error of each trace, as specified by `stat` and\n            `err`.\n        stat : str\n            average statistic to plot.\n        err : str\n            error statistic to plot.\n\n        Returns\n        -------\n        figure, axis\n        \"\"\"\n\n        return plot.tplot(self=self, analytes=analytes, figsize=figsize, scale=scale, filt=filt,\n                          ranges=ranges, stats=stats, stat=stat, err=err,\n                          focus_stage=focus_stage, err_envelope=err_envelope, ax=ax)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nplotting analytes gradients as a function of Time.", "response": "def gplot(self, analytes=None, win=5, figsize=[10, 4],\n              ranges=False, focus_stage=None, ax=None):\n        \"\"\"\n        Plot analytes gradients as a function of Time.\n\n        Parameters\n        ----------\n        analytes : array_like\n            list of strings containing names of analytes to plot.\n            None = all analytes.\n        win : int\n            The window over which to calculate the rolling gradient.\n        figsize : tuple\n            size of final figure.\n        ranges : bool\n            show signal/background regions.\n\n        Returns\n        -------\n        figure, axis\n        \"\"\"\n\n        return plot.gplot(self=self, analytes=analytes, win=win, figsize=figsize,\n                          ranges=ranges, focus_stage=focus_stage, ax=ax)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef crossplot(self, analytes=None, bins=25, lognorm=True, filt=True, colourful=True, figsize=(12, 12)):\n        if analytes is None:\n            analytes = self.analytes\n        if self.focus_stage in ['ratio', 'calibrated']:\n            analytes = [a for a in analytes if self.internal_standard not in a]\n\n        if figsize[0] < 1.5 * len(analytes):\n            figsize = [1.5 * len(analytes)] * 2\n\n        numvars = len(analytes)\n        fig, axes = plt.subplots(nrows=numvars, ncols=numvars,\n                                 figsize=(12, 12))\n        fig.subplots_adjust(hspace=0.05, wspace=0.05)\n\n        for ax in axes.flat:\n            ax.xaxis.set_visible(False)\n            ax.yaxis.set_visible(False)\n\n            if ax.is_first_col():\n                ax.yaxis.set_ticks_position('left')\n            if ax.is_last_col():\n                ax.yaxis.set_ticks_position('right')\n            if ax.is_first_row():\n                ax.xaxis.set_ticks_position('top')\n            if ax.is_last_row():\n                ax.xaxis.set_ticks_position('bottom')\n\n        # set up colour scales\n        if colourful:\n            cmlist = ['Blues', 'BuGn', 'BuPu', 'GnBu',\n                      'Greens', 'Greys', 'Oranges', 'OrRd',\n                      'PuBu', 'PuBuGn', 'PuRd', 'Purples',\n                      'RdPu', 'Reds', 'YlGn', 'YlGnBu', 'YlOrBr', 'YlOrRd']\n        else:\n            cmlist = ['Greys']\n\n        while len(cmlist) < len(analytes):\n            cmlist *= 2\n\n        udict = {}\n        for i, j in zip(*np.triu_indices_from(axes, k=1)):\n            for x, y in [(i, j), (j, i)]:\n                # set unit multipliers\n                mx, ux = unitpicker(np.nanmean(self.focus[analytes[x]]),\n                                    denominator=self.internal_standard,\n                                    focus_stage=self.focus_stage)\n                my, uy = unitpicker(np.nanmean(self.focus[analytes[y]]),\n                                    denominator=self.internal_standard,\n                                    focus_stage=self.focus_stage)\n                udict[analytes[x]] = (x, ux)\n\n                # get filter\n                xd = nominal_values(self.focus[analytes[x]])\n                yd = nominal_values(self.focus[analytes[y]])\n\n                ind = (self.filt.grab_filt(filt, analytes[x]) &\n                       self.filt.grab_filt(filt, analytes[y]) &\n                       ~np.isnan(xd) &\n                       ~np.isnan(yd))\n\n                # make plot\n                pi = xd[ind] * mx\n                pj = yd[ind] * my\n\n                # determine normalisation shceme\n                if lognorm:\n                    norm = mpl.colors.LogNorm()\n                else:\n                    norm = None\n\n                # draw plots\n                axes[i, j].hist2d(pj, pi, bins,\n                                  norm=norm,\n                                  cmap=plt.get_cmap(cmlist[i]))\n                axes[j, i].hist2d(pi, pj, bins,\n                                  norm=norm,\n                                  cmap=plt.get_cmap(cmlist[j]))\n\n                axes[x, y].set_ylim([pi.min(), pi.max()])\n                axes[x, y].set_xlim([pj.min(), pj.max()])\n        # diagonal labels\n        for a, (i, u) in udict.items():\n            axes[i, i].annotate(a + '\\n' + u, (0.5, 0.5),\n                                xycoords='axes fraction',\n                                ha='center', va='center')\n        # switch on alternating axes\n        for i, j in zip(range(numvars), itertools.cycle((-1, 0))):\n            axes[j, i].xaxis.set_visible(True)\n            for label in axes[j, i].get_xticklabels():\n                label.set_rotation(90)\n            axes[i, j].yaxis.set_visible(True)\n\n        axes[0, 0].set_title(self.sample, weight='bold', x=0.05, ha='left')\n\n        return fig, axes", "response": "Plot analytes against each other."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nplots the results of a group of filters in a crossplot.", "response": "def crossplot_filters(self, filter_string, analytes=None):\n        \"\"\"\n        Plot the results of a group of filters in a crossplot.\n\n        Parameters\n        ----------\n        filter_string : str\n            A string that identifies a group of filters.\n            e.g. 'test' would plot all filters with 'test' in the\n            name.\n        analytes : optional, array_like or str\n            The analyte(s) to plot. Defaults to all analytes.\n\n        Returns\n        -------\n        fig, axes objects\n        \"\"\"\n\n        if analytes is None:\n            analytes = [a for a in self.analytes if 'Ca' not in a]\n\n        # isolate relevant filters\n        filts = self.filt.components.keys()\n        cfilts = [f for f in filts if filter_string in f]\n        flab = re.compile('.*_(.*)$')  # regex to get cluster number\n\n        # set up axes\n        numvars = len(analytes)\n        fig, axes = plt.subplots(nrows=numvars, ncols=numvars,\n                                 figsize=(12, 12))\n        fig.subplots_adjust(hspace=0.05, wspace=0.05)\n\n        for ax in axes.flat:\n            ax.xaxis.set_visible(False)\n            ax.yaxis.set_visible(False)\n\n            if ax.is_first_col():\n                ax.yaxis.set_ticks_position('left')\n            if ax.is_last_col():\n                ax.yaxis.set_ticks_position('right')\n            if ax.is_first_row():\n                ax.xaxis.set_ticks_position('top')\n            if ax.is_last_row():\n                ax.xaxis.set_ticks_position('bottom')\n\n        # isolate nominal_values for all analytes\n        focus = {k: nominal_values(v) for k, v in self.focus.items()}\n        # determine units for all analytes\n        udict = {a: unitpicker(np.nanmean(focus[a]),\n                               denominator=self.internal_standard,\n                               focus_stage=self.focus_stage) for a in analytes}\n        # determine ranges for all analytes\n        rdict = {a: (np.nanmin(focus[a] * udict[a][0]),\n                     np.nanmax(focus[a] * udict[a][0])) for a in analytes}\n\n        for f in cfilts:\n            ind = self.filt.grab_filt(f)\n            focus = {k: nominal_values(v[ind]) for k, v in self.focus.items()}\n            lab = flab.match(f).groups()[0]\n            axes[0, 0].scatter([], [], s=10, label=lab)\n\n            for i, j in zip(*np.triu_indices_from(axes, k=1)):\n                # get analytes\n                ai = analytes[i]\n                aj = analytes[j]\n\n                # remove nan, apply multipliers\n                pi = focus[ai][~np.isnan(focus[ai])] * udict[ai][0]\n                pj = focus[aj][~np.isnan(focus[aj])] * udict[aj][0]\n\n                # make plot\n                axes[i, j].scatter(pj, pi, alpha=0.4, s=10, lw=0)\n                axes[j, i].scatter(pi, pj, alpha=0.4, s=10, lw=0)\n\n                axes[i, j].set_ylim(*rdict[ai])\n                axes[i, j].set_xlim(*rdict[aj])\n\n                axes[j, i].set_ylim(*rdict[aj])\n                axes[j, i].set_xlim(*rdict[ai])\n\n        # diagonal labels\n        for a, n in zip(analytes, np.arange(len(analytes))):\n            axes[n, n].annotate(a + '\\n' + udict[a][1], (0.5, 0.5),\n                                xycoords='axes fraction',\n                                ha='center', va='center')\n            axes[n, n].set_xlim(*rdict[a])\n            axes[n, n].set_ylim(*rdict[a])\n\n        axes[0, 0].legend(loc='upper left', title=filter_string, fontsize=8)\n\n        # switch on alternating axes\n        for i, j in zip(range(numvars), itertools.cycle((-1, 0))):\n            axes[j, i].xaxis.set_visible(True)\n            for label in axes[j, i].get_xticklabels():\n                label.set_rotation(90)\n            axes[i, j].yaxis.set_visible(True)\n\n        return fig, axes"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nvisualises effect of data filters.", "response": "def filter_report(self, filt=None, analytes=None, savedir=None, nbin=5):\n        \"\"\"\n        Visualise effect of data filters.\n\n        Parameters\n        ----------\n        filt : str\n            Exact or partial name of filter to plot. Supports\n            partial matching. i.e. if 'cluster' is specified, all\n            filters with 'cluster' in the name will be plotted.\n            Defaults to all filters.\n        analyte : str\n            Name of analyte to plot.\n        save : str\n            file path to save the plot\n\n        Returns\n        -------\n        (fig, axes)\n        \"\"\"\n        return plot.filter_report(self, filt, analytes, savedir, nbin)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a dictionary of the parameters used to process data.", "response": "def get_params(self):\n        \"\"\"\n        Returns paramters used to process data.\n\n        Returns\n        -------\n        dict\n            dict of analysis parameters\n        \"\"\"\n        outputs = ['sample',\n                   'ratio_params',\n                   'despike_params',\n                   'autorange_params',\n                   'bkgcorrect_params']\n\n        out = {}\n        for o in outputs:\n            out[o] = getattr(self, o)\n\n        out['filter_params'] = self.filt.params\n        out['filter_sequence'] = self.filt.sequence\n        out['filter_used'] = self.filt.make_keydict()\n\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nplots analytes as a function of Time.", "response": "def tplot(self, analytes=None, figsize=[10, 4], scale='log', filt=None,\n              ranges=False, stats=False, stat='nanmean', err='nanstd',\n              focus_stage=None, err_envelope=False, ax=None):\n        \"\"\"\n        Plot analytes as a function of Time.\n\n        Parameters\n        ----------\n        analytes : array_like\n            list of strings containing names of analytes to plot.\n            None = all analytes.\n        figsize : tuple\n            size of final figure.\n        scale : str or None\n           'log' = plot data on log scale\n        filt : bool, str or dict\n            False: plot unfiltered data.\n            True: plot filtered data over unfiltered data.\n            str: apply filter key to all analytes\n            dict: apply key to each analyte in dict. Must contain all\n            analytes plotted. Can use self.filt.keydict.\n        ranges : bool\n            show signal/background regions.\n        stats : bool\n            plot average and error of each trace, as specified by `stat` and\n            `err`.\n        stat : str\n            average statistic to plot.\n        err : str\n            error statistic to plot.\n\n        Returns\n        -------\n        figure, axis\n        \"\"\"\n        if type(analytes) is str:\n            analytes = [analytes]\n        if analytes is None:\n            analytes = self.analytes\n\n        if focus_stage is None:\n            focus_stage = self.focus_stage\n        \n        # exclude internal standard from analytes\n        if focus_stage in ['ratios', 'calibrated']:\n            analytes = [a for a in analytes if a != self.internal_standard]\n\n        if ax is None:\n            fig = plt.figure(figsize=figsize)\n            ax = fig.add_axes([.1, .12, .77, .8])\n            ret = True\n        else:\n            fig = ax.figure\n            ret = False\n\n        for a in analytes:\n            x = self.Time\n            y, yerr = unpack_uncertainties(self.data[focus_stage][a])\n\n            if scale is 'log':\n                ax.set_yscale('log')\n                y[y == 0] = np.nan\n\n            if filt:\n                ind = self.filt.grab_filt(filt, a)\n                xf = x.copy()\n                yf = y.copy()\n                yerrf = yerr.copy()\n                if any(~ind):\n                    xf[~ind] = np.nan\n                    yf[~ind] = np.nan\n                    yerrf[~ind] = np.nan\n                if any(~ind):\n                    ax.plot(x, y, color=self.cmap[a], alpha=.2, lw=0.6)\n                ax.plot(xf, yf, color=self.cmap[a], label=a)\n                if err_envelope:\n                    ax.fill_between(xf, yf - yerrf, yf + yerrf, color=self.cmap[a],\n                                    alpha=0.2, zorder=-1)\n            else:\n                ax.plot(x, y, color=self.cmap[a], label=a)\n                if err_envelope:\n                    ax.fill_between(x, y - yerr, y + yerr, color=self.cmap[a],\n                                    alpha=0.2, zorder=-1)\n\n            # Plot averages and error envelopes\n            if stats and hasattr(self, 'stats'):\n                warnings.warn('\\nStatistic plotting is broken.\\nCheck progress here: https://github.com/oscarbranson/latools/issues/18')\n                pass\n                # sts = self.stats[sig][0].size\n                # if sts > 1:\n                #     for n in np.arange(self.n):\n                #         n_ind = ind & (self.ns == n + 1)\n                #         if sum(n_ind) > 2:\n                #             x = [self.Time[n_ind][0], self.Time[n_ind][-1]]\n                #             y = [self.stats[sig][self.stats['analytes'] == a][0][n]] * 2\n\n                #             yp = ([self.stats[sig][self.stats['analytes'] == a][0][n] +\n                #                   self.stats[err][self.stats['analytes'] == a][0][n]] * 2)\n                #             yn = ([self.stats[sig][self.stats['analytes'] == a][0][n] -\n                #                   self.stats[err][self.stats['analytes'] == a][0][n]] * 2)\n\n                #             ax.plot(x, y, color=self.cmap[a], lw=2)\n                #             ax.fill_between(x + x[::-1], yp + yn,\n                #                             color=self.cmap[a], alpha=0.4,\n                #                             linewidth=0)\n                # else:\n                #     x = [self.Time[0], self.Time[-1]]\n                #     y = [self.stats[sig][self.stats['analytes'] == a][0]] * 2\n                #     yp = ([self.stats[sig][self.stats['analytes'] == a][0] +\n                #           self.stats[err][self.stats['analytes'] == a][0]] * 2)\n                #     yn = ([self.stats[sig][self.stats['analytes'] == a][0] -\n                #           self.stats[err][self.stats['analytes'] == a][0]] * 2)\n\n                #     ax.plot(x, y, color=self.cmap[a], lw=2)\n                #     ax.fill_between(x + x[::-1], yp + yn, color=self.cmap[a],\n                #                     alpha=0.4, linewidth=0)\n\n        if ranges:\n            for lims in self.bkgrng:\n                ax.axvspan(*lims, color='k', alpha=0.1, zorder=-1)\n            for lims in self.sigrng:\n                ax.axvspan(*lims, color='r', alpha=0.1, zorder=-1)\n\n        ax.text(0.01, 0.99, self.sample + ' : ' + focus_stage,\n                transform=ax.transAxes,\n                ha='left', va='top')\n\n        ax.set_xlabel('Time (s)')\n        ax.set_xlim(np.nanmin(x), np.nanmax(x))\n\n        # y label\n        ud = {'rawdata': 'counts',\n              'despiked': 'counts',\n              'bkgsub': 'background corrected counts',\n              'ratios': 'counts/{:s} count',\n              'calibrated': 'mol/mol {:s}'}\n        if focus_stage in ['ratios', 'calibrated']:\n            ud[focus_stage] = ud[focus_stage].format(self.internal_standard)\n        ax.set_ylabel(ud[focus_stage])\n\n        # if interactive:\n        #     ax.legend()\n        #     plugins.connect(fig, plugins.MousePosition(fontsize=14))\n        #     display.clear_output(wait=True)\n        #     display.display(fig)\n        #     input('Press [Return] when finished.')\n        # else:\n        ax.legend(bbox_to_anchor=(1.15, 1))\n\n        if ret:\n            return fig, ax"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nplot the rolling gradient of the analytes.", "response": "def gplot(self, analytes=None, win=25, figsize=[10, 4],\n              ranges=False, focus_stage=None, ax=None, recalc=True):\n        \"\"\"\n        Plot analytes gradients as a function of Time.\n\n        Parameters\n        ----------\n        analytes : array_like\n            list of strings containing names of analytes to plot.\n            None = all analytes.\n        win : int\n            The window over which to calculate the rolling gradient.\n        figsize : tuple\n            size of final figure.\n        ranges : bool\n            show signal/background regions.\n\n        Returns\n        -------\n        figure, axis\n        \"\"\"\n\n        if type(analytes) is str:\n            analytes = [analytes]\n        if analytes is None:\n            analytes = self.analytes\n\n        if focus_stage is None:\n            focus_stage = self.focus_stage\n\n        if ax is None:\n            fig = plt.figure(figsize=figsize)\n            ax = fig.add_axes([.1, .12, .77, .8])\n            ret = True\n        else:\n            fig = ax.figure\n            ret = False\n\n        x = self.Time\n        if recalc or not self.grads_calced:\n            self.grads = calc_grads(x, self.data[focus_stage], analytes, win)\n            self.grads_calce = True\n\n        for a in analytes:\n            ax.plot(x, self.grads[a], color=self.cmap[a], label=a)\n\n        if ranges:\n            for lims in self.bkgrng:\n                ax.axvspan(*lims, color='k', alpha=0.1, zorder=-1)\n            for lims in self.sigrng:\n                ax.axvspan(*lims, color='r', alpha=0.1, zorder=-1)\n\n        ax.text(0.01, 0.99, self.sample + ' : ' + self.focus_stage + ' : gradient',\n                transform=ax.transAxes,\n                ha='left', va='top')\n\n        ax.set_xlabel('Time (s)')\n        ax.set_xlim(np.nanmin(x), np.nanmax(x))\n\n        # y label\n        ud = {'rawdata': 'counts/s',\n              'despiked': 'counts/s',\n              'bkgsub': 'background corrected counts/s',\n              'ratios': 'counts/{:s} count/s',\n              'calibrated': 'mol/mol {:s}/s'}\n        if focus_stage in ['ratios', 'calibrated']:\n            ud[focus_stage] = ud[focus_stage].format(self.internal_standard)\n        ax.set_ylabel(ud[focus_stage])\n        # y tick format\n\n        def yfmt(x, p):\n            return '{:.0e}'.format(x)\n        ax.yaxis.set_major_formatter(mpl.ticker.FuncFormatter(yfmt))\n\n        ax.legend(bbox_to_anchor=(1.15, 1))\n\n        ax.axhline(0, color='k', lw=1, ls='dashed', alpha=0.5)\n\n        if ret:\n            return fig, ax"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nplotting analytes against each other.", "response": "def crossplot(dat, keys=None, lognorm=True, bins=25, figsize=(12, 12),\n              colourful=True, focus_stage=None, denominator=None,\n              mode='hist2d', cmap=None, **kwargs):\n    \"\"\"\n    Plot analytes against each other.\n\n    The number of plots is n**2 - n, where n = len(keys).\n\n    Parameters\n    ----------\n    dat : dict\n        A dictionary of key: data pairs, where data is the same\n        length in each entry.\n    keys : optional, array_like or str\n        The keys of dat to plot. Defaults to all keys.\n    lognorm : bool\n        Whether or not to log normalise the colour scale\n        of the 2D histogram.\n    bins : int\n        The number of bins in the 2D histogram.\n    figsize : tuple\n    colourful : bool\n\n    Returns\n    -------\n    (fig, axes)\n    \"\"\"\n    if keys is None:\n        keys = list(dat.keys())\n\n    numvar = len(keys)\n    if figsize[0] < 1.5 * numvar:\n        figsize = [1.5 * numvar] * 2\n    \n    fig, axes = plt.subplots(nrows=numvar, ncols=numvar,\n                             figsize=(12, 12))\n    fig.subplots_adjust(hspace=0.05, wspace=0.05)\n\n    for ax in axes.flat:\n        ax.xaxis.set_visible(False)\n        ax.yaxis.set_visible(False)\n\n        if ax.is_first_col():\n            ax.yaxis.set_ticks_position('left')\n        if ax.is_last_col():\n            ax.yaxis.set_ticks_position('right')\n        if ax.is_first_row():\n            ax.xaxis.set_ticks_position('top')\n        if ax.is_last_row():\n            ax.xaxis.set_ticks_position('bottom')\n\n    # set up colour scales\n    if colourful:\n        cmlist = ['Blues', 'BuGn', 'BuPu', 'GnBu',\n                  'Greens', 'Greys', 'Oranges', 'OrRd',\n                  'PuBu', 'PuBuGn', 'PuRd', 'Purples',\n                  'RdPu', 'Reds', 'YlGn', 'YlGnBu', 'YlOrBr', 'YlOrRd']\n    else:\n        cmlist = ['Greys']\n\n    if cmap is None and mode == 'scatter':\n        cmap = {k: 'k' for k in dat.keys()}\n\n    while len(cmlist) < len(keys):\n        cmlist *= 2\n\n    # isolate nominal_values for all keys\n    focus = {k: nominal_values(dat[k]) for k in keys}\n    # determine units for all keys\n    udict = {a: unitpicker(np.nanmean(focus[a]),\n                           focus_stage=focus_stage,\n                           denominator=denominator) for a in keys}\n    # determine ranges for all analytes\n    rdict = {a: (np.nanmin(focus[a] * udict[a][0]),\n                 np.nanmax(focus[a] * udict[a][0])) for a in keys}\n\n    for i, j in tqdm(zip(*np.triu_indices_from(axes, k=1)), desc='Drawing Plots',\n                     total=sum(range(len(keys)))):\n        # get analytes\n        ai = keys[i]\n        aj = keys[j]\n\n        # remove nan, apply multipliers\n        pi = focus[ai] * udict[ai][0]\n        pj = focus[aj] * udict[aj][0]\n\n        # determine normalisation shceme\n        if lognorm:\n            norm = mpl.colors.LogNorm()\n        else:\n            norm = None\n\n        # draw plots\n        if mode == 'hist2d':\n            # remove nan\n            pi = pi[~np.isnan(pi)]\n            pj = pj[~np.isnan(pj)]\n\n            axes[i, j].hist2d(pj, pi, bins,\n                              norm=norm,\n                              cmap=plt.get_cmap(cmlist[i]))\n            axes[j, i].hist2d(pi, pj, bins,\n                              norm=norm,\n                              cmap=plt.get_cmap(cmlist[j]))\n        elif mode == 'scatter':\n            axes[i, j].scatter(pj, pi, s=10,\n                               color=cmap[ai], lw=0.5, edgecolor='k',\n                               alpha=0.4)\n            axes[j, i].scatter(pi, pj, s=10,\n                               color=cmap[aj], lw=0.5, edgecolor='k',\n                               alpha=0.4)\n        else:\n            raise ValueError(\"invalid mode. Must be 'hist2d' or 'scatter'.\")\n\n        axes[i, j].set_ylim(*rdict[ai])\n        axes[i, j].set_xlim(*rdict[aj])\n\n        axes[j, i].set_ylim(*rdict[aj])\n        axes[j, i].set_xlim(*rdict[ai])\n\n    # diagonal labels\n    for a, n in zip(keys, np.arange(len(keys))):\n        axes[n, n].annotate(a + '\\n' + udict[a][1], (0.5, 0.5),\n                            xycoords='axes fraction',\n                            ha='center', va='center', fontsize=8)\n        axes[n, n].set_xlim(*rdict[a])\n        axes[n, n].set_ylim(*rdict[a])\n    # switch on alternating axes\n    for i, j in zip(range(numvar), itertools.cycle((-1, 0))):\n        axes[j, i].xaxis.set_visible(True)\n        for label in axes[j, i].get_xticklabels():\n            label.set_rotation(90)\n        axes[i, j].yaxis.set_visible(True)\n\n    return fig, axes"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nplotting histograms of all items in dat.", "response": "def histograms(dat, keys=None, bins=25, logy=False, cmap=None, ncol=4):\n    \"\"\"\n    Plot histograms of all items in dat.\n\n    Parameters\n    ----------\n    dat : dict\n        Data in {key: array} pairs.\n    keys : arra-like\n        The keys in dat that you want to plot. If None,\n        all are plotted.\n    bins : int\n        The number of bins in each histogram (default = 25)\n    logy : bool\n        If true, y axis is a log scale.\n    cmap : dict\n        The colours that the different items should be. If None,\n        all are grey.\n\n    Returns\n    -------\n    fig, axes\n    \"\"\"\n    if keys is None:\n        keys = dat.keys()\n\n    ncol = int(ncol)\n    nrow = calc_nrow(len(keys), ncol)\n\n    fig, axs = plt.subplots(nrow, 4, figsize=[ncol * 2, nrow * 2])\n\n    pn = 0\n    for k, ax in zip(keys, axs.flat):\n        tmp = nominal_values(dat[k])\n        x = tmp[~np.isnan(tmp)]\n\n        if cmap is not None:\n            c = cmap[k]\n        else:\n            c = (0, 0, 0, 0.5)\n        ax.hist(x, bins=bins, color=c)\n\n        if logy:\n            ax.set_yscale('log')\n            ylab = '$log_{10}(n)$'\n        else:\n            ylab = 'n'\n\n        ax.set_ylim(1, ax.get_ylim()[1])\n\n        if ax.is_first_col():\n            ax.set_ylabel(ylab)\n\n        ax.set_yticklabels([])\n\n        ax.text(.95, .95, k, ha='right', va='top', transform=ax.transAxes)\n\n        pn += 1\n\n    for ax in axs.flat[pn:]:\n        ax.set_visible(False)\n    fig.tight_layout()\n\n    return fig, axs"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef autorange_plot(t, sig, gwin=7, swin=None, win=30,\n                   on_mult=(1.5, 1.), off_mult=(1., 1.5),\n                   nbin=10, thresh=None):\n    \"\"\"\n    Function for visualising the autorange mechanism.\n\n    Parameters\n    ----------\n    t : array-like\n        Independent variable (usually time).\n    sig : array-like\n        Dependent signal, with distinctive 'on' and 'off' regions.\n    gwin : int\n        The window used for calculating first derivative.\n        Defaults to 7.\n    swin : int\n        The window ised for signal smoothing. If None, gwin // 2.\n    win : int\n        The width (c +/- win) of the transition data subsets.\n        Defaults to 20.\n    on_mult and off_mult : tuple, len=2\n        Control the width of the excluded transition regions, which is defined\n        relative to the peak full-width-half-maximum (FWHM) of the transition\n        gradient. The region n * FHWM below the transition, and m * FWHM above\n        the tranision will be excluded, where (n, m) are specified in `on_mult`\n        and `off_mult`.\n        `on_mult` and `off_mult` apply to the off-on and on-off transitions,\n        respectively.\n        Defaults to (1.5, 1) and (1, 1.5).\n    nbin : ind\n        Used to calculate the number of bins in the data histogram.\n        bins = len(sig) // nbin\n\n    Returns\n    -------\n    fig, axes\n    \"\"\"\n    if swin is None:\n        swin = gwin // 2\n\n    sigs = fastsmooth(sig, swin)\n\n    # perform autorange calculations\n    \n    # bins = 50\n    bins = sig.size // nbin\n    kde_x = np.linspace(sig.min(), sig.max(), bins)\n\n    kde = gaussian_kde(sigs)\n    yd = kde.pdf(kde_x)\n    mins = findmins(kde_x, yd)  # find minima in kde\n\n    if thresh is not None:\n        mins = [thresh]\n    if len(mins) > 0:\n        bkg = sigs < (mins[0])  # set background as lowest distribution\n    else:\n        bkg = np.ones(sig.size, dtype=bool)\n    # bkg[0] = True  # the first value must always be background\n\n    # assign rough background and signal regions based on kde minima\n    fbkg = bkg\n    fsig = ~bkg\n\n    g = abs(fastgrad(sigs, gwin))  # calculate gradient of signal\n    # 2. determine the approximate index of each transition\n    zeros = bool_2_indices(fsig)\n\n    if zeros is not None:\n        zeros = zeros.flatten()\n        lohi = []\n        pgs = []\n        excl = []\n        tps = []\n        failed = []\n\n        for z in zeros:  # for each approximate transition\n            # isolate the data around the transition\n            if z - win < 0:\n                lo = gwin // 2\n                hi = int(z + win)\n            elif z + win > (len(sig) - gwin // 2):\n                lo = int(z - win)\n                hi = len(sig) - gwin // 2\n            else:\n                lo = int(z - win)\n                hi = int(z + win)\n\n            xs = t[lo:hi]\n            ys = g[lo:hi]\n\n            lohi.append([lo, hi])\n\n            # determine type of transition (on/off)\n            mid = (hi + lo) // 2\n            tp = sigs[mid + 3] > sigs[mid - 3]  # True if 'on' transition.\n            tps.append(tp)\n\n            c = t[z]  # center of transition\n            width = (t[1] - t[0]) * 2  # initial width guess\n            try:\n                pg, _ = curve_fit(gauss, xs, ys,\n                                  p0=(np.nanmax(ys),\n                                      c,\n                                      width),\n                                  sigma=(xs - c)**2 + .01)\n                pgs.append(pg)\n                fwhm = abs(2 * pg[-1] * np.sqrt(2 * np.log(2)))\n                # apply on_mult or off_mult, as appropriate.\n                if tp:\n                    lim = np.array([-fwhm, fwhm]) * on_mult + pg[1]\n                else:\n                    lim = np.array([-fwhm, fwhm]) * off_mult + pg[1]\n                excl.append(lim)\n\n                fbkg[(t > lim[0]) & (t < lim[1])] = False\n                fsig[(t > lim[0]) & (t < lim[1])] = False\n                failed.append(False)\n            except RuntimeError:\n                failed.append(True)\n                lohi.append([np.nan, np.nan])\n                pgs.append([np.nan, np.nan, np.nan])\n                excl.append([np.nan, np.nan])\n                tps.append(tp)\n                pass\n    else:\n        zeros = []\n\n    # make plot\n    nrows = 2 + len(zeros) // 2 + len(zeros) % 2\n\n    fig, axs = plt.subplots(nrows, 2, figsize=(6, 4 + 1.5 * nrows))\n\n    # Trace\n    ax1, ax2, ax3, ax4 = axs.flat[:4]\n    ax4.set_visible(False)\n\n    # widen ax1 & 3\n    for ax in [ax1, ax3]:\n        p = ax.axes.get_position()\n        p2 = [p.x0, p.y0, p.width * 1.75, p.height]\n        ax.axes.set_position(p2)\n\n    # move ax3 up\n    p = ax3.axes.get_position()\n    p2 = [p.x0, p.y0 + 0.15 * p.height, p.width, p.height]\n    ax3.axes.set_position(p2)\n\n    # truncate ax2\n    p = ax2.axes.get_position()\n    p2 = [p.x0 + p.width * 0.6, p.y0, p.width * 0.4, p.height]\n    ax2.axes.set_position(p2)\n\n    # plot traces and gradient\n    ax1.plot(t, sig, color='k', lw=1)\n    ax1.set_xticklabels([])\n    ax1.set_ylabel('Signal')\n    ax3.plot(t, g, color='k', lw=1)\n    ax3.set_xlabel('Time (s)')\n    ax3.set_ylabel('Gradient')\n\n    # plot kde\n    ax2.fill_betweenx(kde_x, yd, color=(0, 0, 0, 0.2))\n    ax2.plot(yd, kde_x, color='k')\n    ax2.set_ylim(ax1.get_ylim())\n    ax2.set_yticklabels([])\n    ax2.set_xlabel('Data\\nDensity')\n\n    # limit\n    for ax in [ax1, ax2]:\n        ax.axhline(mins[0], color='k', ls='dashed', alpha=0.4)\n\n    if len(zeros) > 0:\n        # zeros\n        for z in zeros:\n            ax1.axvline(t[z], color='r', alpha=0.5)\n            ax3.axvline(t[z], color='r', alpha=0.5)\n\n        # plot individual transitions\n        n = 1\n        for (lo, hi), lim, tp, pg, fail, ax in zip(lohi, excl, tps, pgs, failed, axs.flat[4:]):\n            # plot region on gradient axis\n            ax3.axvspan(t[lo], t[hi], color='r', alpha=0.1, zorder=-2)\n\n            # plot individual transitions\n            x = t[lo:hi]\n            y = g[lo:hi]\n            ys = sig[lo:hi]\n            ax.scatter(x, y, color='k', marker='x', zorder=-1, s=10)\n            ax.set_yticklabels([])\n            ax.set_ylim(rangecalc(y))\n\n            tax = ax.twinx()\n            tax.plot(x, ys, color='k', alpha=0.3, zorder=-5)\n            tax.set_yticklabels([])\n            tax.set_ylim(rangecalc(ys))\n\n            # plot fitted gaussian\n            xn = np.linspace(x.min(), x.max(), 100)\n            ax.plot(xn, gauss(xn, *pg), color='r', alpha=0.5)\n\n            # plot center and excluded region\n            ax.axvline(pg[1], color='b', alpha=0.5)\n            ax.axvspan(*lim, color='b', alpha=0.1, zorder=-2)\n\n            ax1.axvspan(*lim, color='b', alpha=0.1, zorder=-2)\n            if tp:\n                ax.text(.05, .95, '{} (on)'.format(n), ha='left',\n                        va='top', transform=ax.transAxes)\n            else:\n                ax.text(.95, .95, '{} (off)'.format(n), ha='right',\n                        va='top', transform=ax.transAxes)\n\n            if ax.is_last_row():\n                ax.set_xlabel('Time (s)')\n            if ax.is_first_col():\n                ax.set_ylabel('Gradient (x)')\n            if ax.is_last_col():\n                tax.set_ylabel('Signal (line)')\n\n            if fail:\n                ax.axes.set_facecolor((1, 0, 0, 0.2))\n                ax.text(.5, .5, 'FAIL', ha='center', va='center',\n                        fontsize=16, color=(1, 0, 0, 0.5), transform=ax.transAxes)\n\n            n += 1\n\n        # should never be, but just in case...\n        if len(zeros) % 2 == 1:\n            axs.flat[-1].set_visible = False\n\n    return fig, axs", "response": "Function for visualising the autorange mechanism."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nplotting the calibration lines between measured and known SRM values.", "response": "def calibration_plot(self, analytes=None, datarange=True, loglog=False, ncol=3, srm_group=None, save=True):\n    \"\"\"\n    Plot the calibration lines between measured and known SRM values.\n\n    Parameters\n    ----------\n    analytes : optional, array_like or str\n        The analyte(s) to plot. Defaults to all analytes.\n    datarange : boolean\n        Whether or not to show the distribution of the measured data\n        alongside the calibration curve.\n    loglog : boolean\n        Whether or not to plot the data on a log - log scale. This is\n        useful if you have two low standards very close together,\n        and want to check whether your data are between them, or\n        below them.\n\n    Returns\n    -------\n    (fig, axes)\n    \"\"\"\n\n    if isinstance(analytes, str):\n        analytes = [analytes]\n\n    if analytes is None:\n        analytes = [a for a in self.analytes if self.internal_standard not in a]\n\n    if srm_group is not None:\n        srm_groups = {int(g): t for g, t in self.stdtab.loc[:, ['group', 'gTime']].values}\n        try:\n            gTime = srm_groups[srm_group]\n        except KeyError:\n            text = ('Invalid SRM group selection. Valid options are:\\n' +\n                    ' Key:  Time Centre\\n' + \n                    '\\n'.join(['   {:}:  {:.1f}s'.format(k, v) for k, v in srm_groups.items()]))\n            print(text)\n    else:\n        gTime = None\n\n    ncol = int(ncol)\n    n = len(analytes)\n    nrow = calc_nrow(n + 1, ncol)\n\n    axes = []\n\n    if not datarange:\n        fig = plt.figure(figsize=[4.1 * ncol, 3 * nrow])\n    else:\n        fig = plt.figure(figsize=[4.7 * ncol, 3 * nrow])\n        self.get_focus()\n\n    gs = mpl.gridspec.GridSpec(nrows=int(nrow), ncols=int(ncol),\n                            hspace=0.35, wspace=0.3)\n\n    mdict = self.srm_mdict\n\n    for g, a in zip(gs, analytes):\n        if not datarange:\n            ax = fig.add_axes(g.get_position(fig))\n            axes.append((ax,))\n        else:\n            f = 0.8\n            p0 = g.get_position(fig)\n            p1 = [p0.x0, p0.y0, p0.width * f, p0.height]\n            p2 = [p0.x0 + p0.width * f, p0.y0, p0.width * (1 - f), p0.height]\n            ax = fig.add_axes(p1)\n            axh = fig.add_axes(p2)\n            axes.append((ax, axh))\n        \n        if gTime is None:\n            sub = idx[a]\n        else:\n            sub = idx[a, :, :, gTime]\n        x = self.srmtabs.loc[sub, 'meas_mean'].values\n        xe = self.srmtabs.loc[sub, 'meas_err'].values\n        y = self.srmtabs.loc[sub, 'srm_mean'].values\n        ye = self.srmtabs.loc[sub, 'srm_err'].values\n        srm = self.srmtabs.loc[sub].index.get_level_values('SRM')\n        \n        # plot calibration data\n        for s, m in mdict.items():\n            ind = srm == s\n            ax.errorbar(x[ind], y[ind], xerr=xe[ind], yerr=ye[ind],\n                        color=self.cmaps[a], alpha=0.6,\n                        lw=0, elinewidth=1, marker=m, #'o',\n                        capsize=0, markersize=5, label='_')\n\n        # work out axis scaling\n        if not loglog:\n            xmax = np.nanmax(x + xe)\n            ymax = np.nanmax(y + ye)\n            if any(x - xe < 0):\n                xmin = np.nanmin(x - xe)\n                xpad = (xmax - xmin) * 0.05\n                xlim = [xmin - xpad, xmax + xpad]\n            else:\n                xlim = [0, xmax * 1.05]\n\n            if any(y - ye < 0):\n                ymin = np.nanmin(y - ye)\n                ypad = (ymax - ymin) * 0.05\n                ylim = [ymin - ypad, ymax + ypad]\n            else:\n                ylim = [0, ymax * 1.05]\n\n        else:\n            xd = self.srmtabs.loc[a, 'meas_mean'][self.srmtabs.loc[a, 'meas_mean'] > 0].values\n            yd = self.srmtabs.loc[a, 'srm_mean'][self.srmtabs.loc[a, 'srm_mean'] > 0].values\n\n            xlim = [10**np.floor(np.log10(np.nanmin(xd))),\n                    10**np.ceil(np.log10(np.nanmax(xd)))]\n            ylim = [10**np.floor(np.log10(np.nanmin(yd))),\n                    10**np.ceil(np.log10(np.nanmax(yd)))]\n\n            # scale sanity checks\n            if xlim[0] == xlim[1]:\n                xlim[0] = ylim[0]\n            if ylim[0] == ylim[1]:\n                ylim[0] = xlim[0]\n\n            ax.set_xscale('log')\n            ax.set_yscale('log')\n\n        ax.set_xlim(xlim)\n        ax.set_ylim(ylim)\n\n        # visual warning if any values < 0\n        if xlim[0] < 0:\n            ax.axvspan(xlim[0], 0, color=(1,0.8,0.8), zorder=-1)\n        if ylim[0] < 0:\n            ax.axhspan(ylim[0], 0, color=(1,0.8,0.8), zorder=-1)\n        if any(x < 0) or any(y < 0):\n            ax.text(.5, .5, 'WARNING: Values below zero.', color='r', weight='bold',\n                    ha='center', va='center', rotation=40, transform=ax.transAxes, alpha=0.6)\n\n        # calculate line and R2\n        if loglog:\n            x = np.logspace(*np.log10(xlim), 100)\n        else:\n            x = np.array(xlim)\n        \n        if gTime is None:\n            coefs = self.calib_params.loc[:, a]\n        else:\n            coefs = self.calib_params.loc[gTime, a]\n        \n        m = np.nanmean(coefs['m'])\n        m_nom = nominal_values(m)\n        # calculate case-specific paramers\n        if 'c' in coefs:\n            c = np.nanmean(coefs['c'])\n            c_nom = nominal_values(c)\n            # calculate R2\n            ym = self.srmtabs.loc[a, 'meas_mean'] * m_nom + c_nom\n            R2 = R2calc(self.srmtabs.loc[a, 'srm_mean'], ym, force_zero=False)\n            # generate line and label\n            line = x * m_nom + c_nom\n            label = 'y = {:.2e} x'.format(m)\n            if c > 0:\n                label += '\\n+ {:.2e}'.format(c)\n            else:\n                label += '\\n {:.2e}'.format(c)\n        else:\n            # calculate R2\n            ym = self.srmtabs.loc[a, 'meas_mean'] * m_nom\n            R2 = R2calc(self.srmtabs.loc[a, 'srm_mean'], ym, force_zero=True)\n            # generate line and label\n            line = x * m_nom\n            label = 'y = {:.2e} x'.format(m)\n\n        # plot line of best fit\n        ax.plot(x, line, color=(0, 0, 0, 0.5), ls='dashed')\n\n        # add R2 to label\n        if round(R2, 3) == 1:\n            label = '$R^2$: >0.999\\n' + label\n        else:\n            label = '$R^2$: {:.3f}\\n'.format(R2) + label\n\n        ax.text(.05, .95, pretty_element(a), transform=ax.transAxes,\n                weight='bold', va='top', ha='left', size=12)\n        ax.set_xlabel('counts/counts ' + self.internal_standard)\n        ax.set_ylabel('mol/mol ' + self.internal_standard)\n        # write calibration equation on graph happens after data distribution\n\n        # plot data distribution historgram alongside calibration plot\n        if datarange:\n            # isolate data\n            meas = nominal_values(self.focus[a])\n            meas = meas[~np.isnan(meas)]\n\n            # check and set y scale\n            if np.nanmin(meas) < ylim[0]:\n                if loglog:\n                    mmeas = meas[meas > 0]\n                    ylim[0] = 10**np.floor(np.log10(np.nanmin(mmeas)))\n                else:\n                    ylim[0] = 0\n                ax.set_ylim(ylim)\n\n            m95 = np.percentile(meas[~np.isnan(meas)], 95) * 1.05\n            if m95 > ylim[1]:\n                if loglog:\n                    ylim[1] = 10**np.ceil(np.log10(m95))\n                else:\n                    ylim[1] = m95\n\n            # hist\n            if loglog:\n                bins = np.logspace(*np.log10(ylim), 30)\n            else:\n                bins = np.linspace(*ylim, 30)\n\n            axh.hist(meas, bins=bins, orientation='horizontal',\n                        color=self.cmaps[a], lw=0.5, alpha=0.5)\n\n            if loglog:\n                axh.set_yscale('log')\n            axh.set_ylim(ylim)  # ylim of histogram axis\n            ax.set_ylim(ylim)  # ylim of calibration axis\n            axh.set_xticks([])\n            axh.set_yticklabels([])\n\n        # write calibration equation on graph\n        cmax = np.nanmax(y)\n        if cmax / ylim[1] > 0.5:\n            ax.text(0.98, 0.04, label, transform=ax.transAxes,\n                    va='bottom', ha='right')\n        else:\n            ax.text(0.02, 0.75, label, transform=ax.transAxes,\n                    va='top', ha='left')\n\n    if srm_group is None:\n        title = 'All SRMs'\n    else:\n        title = 'SRM Group {:} (centre at {:.1f}s)'.format(srm_group, gTime)\n    axes[0][0].set_title(title, loc='left', weight='bold', fontsize=12)\n            \n    # SRM legend\n    ax = fig.add_axes(gs[-1].get_position(fig))\n    for lab, m in mdict.items():\n        ax.scatter([],[],marker=m, label=lab, color=(0,0,0,0.6))\n    ax.legend()\n    ax.axis('off')\n\n    if save:\n        fig.savefig(self.report_dir + '/calibration.pdf')\n\n    return fig, axes"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef filter_report(Data, filt=None, analytes=None, savedir=None, nbin=5):\n    if filt is None or filt == 'all':\n        sets = Data.filt.sets\n    else:\n        sets = {k: v for k, v in Data.filt.sets.items() if any(filt in f for f in v)}\n\n    regex = re.compile('^([0-9]+)_([A-Za-z0-9-]+)_'\n                    '([A-Za-z0-9-]+)[_$]?'\n                    '([a-z0-9]+)?')\n\n    cm = plt.cm.get_cmap('Spectral')\n    ngrps = len(sets)\n\n    if analytes is None:\n        analytes = Data.analytes\n    elif isinstance(analytes, str):\n        analytes = [analytes]\n\n    axes = []\n    for analyte in analytes:\n        if analyte != Data.internal_standard:\n            fig = plt.figure()\n\n            for i in sorted(sets.keys()):\n                filts = sets[i]\n                nfilts = np.array([re.match(regex, f).groups() for f in filts])\n                fgnames = np.array(['_'.join(a) for a in nfilts[:, 1:3]])\n                fgrp = np.unique(fgnames)[0]\n\n                fig.set_size_inches(10, 3.5 * ngrps)\n                h = .8 / ngrps\n\n                y = nominal_values(Data.focus[analyte])\n                yh = y[~np.isnan(y)]\n\n                m, u = unitpicker(np.nanmax(y),\n                                denominator=Data.internal_standard,\n                                focus_stage=Data.focus_stage)\n\n                axs = tax, hax = (fig.add_axes([.1, .9 - (i + 1) * h, .6, h * .98]),\n                                fig.add_axes([.7, .9 - (i + 1) * h, .2, h * .98]))\n                axes.append(axs)\n\n                # get variables\n                fg = sets[i]\n                cs = cm(np.linspace(0, 1, len(fg)))\n                fn = ['_'.join(x) for x in nfilts[:, (0, 3)]]\n                an = nfilts[:, 0]\n                bins = np.linspace(np.nanmin(y), np.nanmax(y), len(yh) // nbin) * m\n\n                if 'DBSCAN' in fgrp:\n                    # determine data filters\n                    core_ind = Data.filt.components[[f for f in fg\n                                                    if 'core' in f][0]]\n                    other = np.array([('noise' not in f) & ('core' not in f)\n                                    for f in fg])\n                    tfg = fg[other]\n                    tfn = fn[other]\n                    tcs = cm(np.linspace(0, 1, len(tfg)))\n\n                    # plot all data\n                    hax.hist(m * yh, bins, alpha=0.2, orientation='horizontal',\n                            color='k', lw=0)\n                    # legend markers for core/member\n                    tax.scatter([], [], s=20, label='core', color='w', lw=0.5, edgecolor='k')\n                    tax.scatter([], [], s=7.5, label='member', color='w', lw=0.5, edgecolor='k')\n                    # plot noise\n                    try:\n                        noise_ind = Data.filt.components[[f for f in fg\n                                                        if 'noise' in f][0]]\n                        tax.scatter(Data.Time[noise_ind], m * y[noise_ind],\n                                    lw=1, color='k', s=10, marker='x',\n                                    label='noise', alpha=0.6)\n                    except:\n                        pass\n\n                    # plot filtered data\n                    for f, c, lab in zip(tfg, tcs, tfn):\n                        ind = Data.filt.components[f]\n                        tax.scatter(Data.Time[~core_ind & ind],\n                                    m * y[~core_ind & ind], lw=.5, color=c, s=5, edgecolor='k')\n                        tax.scatter(Data.Time[core_ind & ind],\n                                    m * y[core_ind & ind], lw=.5, color=c, s=15, edgecolor='k',\n                                    label=lab)\n                        hax.hist(m * y[ind][~np.isnan(y[ind])], bins, color=c, lw=0.1,\n                                orientation='horizontal', alpha=0.6)\n\n                else:\n                    # plot all data\n                    tax.scatter(Data.Time, m * y, color='k', alpha=0.2, lw=0.1,\n                                s=20, label='excl')\n                    hax.hist(m * yh, bins, alpha=0.2, orientation='horizontal',\n                             color='k', lw=0)\n\n                    # plot filtered data\n                    for f, c, lab in zip(fg, cs, fn):\n                        ind = Data.filt.components[f]\n                        tax.scatter(Data.Time[ind], m * y[ind],\n                                    edgecolor=(0,0,0,0), color=c, s=15, label=lab)\n                        hax.hist(m * y[ind][~np.isnan(y[ind])], bins, color=c, lw=0.1,\n                                orientation='horizontal', alpha=0.6)\n\n                if 'thresh' in fgrp and analyte in fgrp:\n                    tax.axhline(Data.filt.params[fg[0]]['threshold'] * m,\n                                ls='dashed', zorder=-2, alpha=0.5, color='k')\n                    hax.axhline(Data.filt.params[fg[0]]['threshold'] * m,\n                                ls='dashed', zorder=-2, alpha=0.5, color='k')\n\n                # formatting\n                for ax in axs:\n                    mn = np.nanmin(y) * m\n                    mx = np.nanmax(y) * m\n                    rn = mx - mn\n                    ax.set_ylim(mn - .05 * rn, mx + 0.05 * rn)\n\n                # legend\n                hn, la = tax.get_legend_handles_labels()\n                hax.legend(hn, la, loc='upper right', scatterpoints=1)\n\n                tax.text(.02, .98, Data.sample + ': ' + fgrp, size=12,\n                        weight='bold', ha='left', va='top',\n                        transform=tax.transAxes)\n                tax.set_ylabel(pretty_element(analyte) + ' (' + u + ')')\n                tax.set_xticks(tax.get_xticks()[:-1])\n                hax.set_yticklabels([])\n\n                if i < ngrps - 1:\n                    tax.set_xticklabels([])\n                    hax.set_xticklabels([])\n                else:\n                    tax.set_xlabel('Time (s)')\n                    hax.set_xlabel('n')\n\n        if isinstance(savedir, str):\n            fig.savefig(savedir + '/' + Data.sample + '_' +\n                        analyte + '.pdf')\n            plt.close(fig)\n\n    return fig, axes", "response": "Visualise effect of data filters."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncalculate the reproducibility of LA - ICPMS based on unique pairs of repeat analyses.", "response": "def pairwise_reproducibility(df, plot=False):\n    \"\"\"\n    Calculate the reproducibility of LA-ICPMS based on unique pairs of repeat analyses.\n    \n    Pairwise differences are fit with a half-Cauchy distribution, and the median and \n    95% confidence limits are returned for each analyte.\n    \n    Parameters\n    ----------\n    df : pandas.DataFrame\n        A dataset\n    \n    plot : bool\n        Whether or not to plot the resulting error distributions.\n    \n    Returns\n    -------\n    pdiffs : pandas.DataFrame\n        Unique pairwise differences for all analytes.\n    rep_dists : dict of scipy.stats.halfcauchy\n        Half-Cauchy distribution objects fitted to the\n        differences.\n    rep_stats : dict of tuples\n        The 50% and 95% quantiles of the half-cauchy\n        distribution.\n    (fig, axs) : matplotlib objects\n        The figure. If not made, returnes (None, None) placeholder\n    \n    \"\"\"\n    \n    ans = df.columns.values\n    pdifs = []\n    \n    # calculate differences between unique pairs\n    for ind, d in df.groupby(level=0):\n        d.index = d.index.droplevel(0)\n\n        difs = []\n        for i, r in d.iterrows():\n            t = d.loc[i+1:, :]\n            difs.append(t[ans] - r[ans])\n\n        pdifs.append(pd.concat(difs))\n    pdifs = pd.concat(pdifs).abs()\n\n    # calculate stats\n    rep_stats = {}\n    rep_dists = {}\n    errfn = stats.halfcauchy\n    \n    for a in ans:\n        d = pdifs.loc[:, a].dropna().values\n        hdist = errfn.fit(d, floc=0)\n        rep_dists[a] = errfn(*hdist)\n        rep_stats[a] = rep_dists[a].ppf((0.5, 0.95))\n    \n    # make plot\n    if not plot:\n        return pdifs, rep_dists, rep_stats, (None, None)\n    \n    fig, axs = plt.subplots(1, len(ans), figsize=[len(ans) * 2, 2])\n    for a, ax in zip(ans, axs):\n        d = pdifs.loc[:, a].dropna().values\n        hist, edges, _ = ax.hist(d, 30)\n        ax.plot(edges, rep_dists[a].pdf(edges) * (sum(hist) * np.mean(np.diff(edges))))\n        ax.set_title(a, loc='left')\n\n    return pdifs, rep_dists, rep_stats, (fig, axs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncomputing comparison stats for a set of elements in a set of objects.", "response": "def comparison_stats(df, els=['Mg', 'Sr', 'Ba', 'Al', 'Mn']):\n    \"\"\"\n    Compute comparison stats for test and LAtools data.\n    \n    Population-level similarity assessed by a Kolmogorov-Smirnov test.\n    \n    Individual similarity assessed by a pairwise Wilcoxon signed rank test.\n    \n    Trends in residuals assessed by regression analysis, where significance of\n    the slope and intercept is determined by t-tests (both relative to zero).\n    \n    Parameters\n    ----------\n    df : pandas.DataFrame\n        A dataframe containing reference ('X/Ca_r'), test user \n        ('X/Ca_t') and LAtools ('X123') data.\n    els : list\n        list of elements (names only) to plot.\n    \n    Returns\n    -------\n    pandas.DataFrame\n    \n    \"\"\"\n    \n    # get corresponding analyte and ratio names\n    As = []\n    Rs = []\n    analytes = [c for c in df.columns if ('_r' not in c) and ('_t' not in c)]\n    ratios = [c for c in df.columns if ('_r' in c)]\n\n    for e in els:\n        if e == 'Sr':\n            As.append('Sr88')\n        elif e == 'Mg':\n            As.append('Mg24')\n        else:\n            As.append([a for a in analytes if e in a][0])\n        Rs.append([r for r in ratios if e in r][0][:-2])\n        \n    yt_stats = []\n    yl_stats = []\n    \n    for i, (e, a) in enumerate(zip(Rs, As)):\n        if a == 'Ba138':\n            m = 1e3\n            u = '$\\mu$mol/mol'\n        else:\n            m = 1\n            u = 'mmol/mol'\n        \n        x = df.loc[:, e + '_r'].values * m\n        yt = df.loc[:, e + '_t'].values * m\n        yl = df.loc[:, a].values * m\n        \n        yt_stats.append(summary_stats(x, yt, e))\n        yl_stats.append(summary_stats(x, yl, e))\n    \n    yt_stats = pd.concat(yt_stats).T\n    yl_stats = pd.concat(yl_stats).T\n    \n    return pd.concat([yt_stats, yl_stats], keys=['Test User', 'LAtools']).T"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncomputes summary statistics for paired x y data.", "response": "def summary_stats(x, y, nm=None):\n    \"\"\"\n    Compute summary statistics for paired x, y data.\n\n    Tests\n    -----\n\n    Parameters\n    ----------\n    x, y : array-like\n        Data to compare\n    nm : str (optional)\n        Index value of created dataframe.\n\n    Returns\n    -------\n    pandas dataframe of statistics.\n    \"\"\"\n    # create datafrane for results\n    if isinstance(nm, str):\n        nm = [nm]\n    # cols = pd.MultiIndex.from_arrays([['', 'Pairwise', 'Pairwise', cat, cat, cat, cat],\n    #                                   ['N', 'W', 'p', 'Median', 'IQR', 'W', 'p']])\n#     cols = ['Median', 'IQR', 'CI95', 'L95', 'LQ', 'UQ', 'U95', 'N',\n#             'Wilcoxon_stat', 'Wilcoxon_p',\n#             'KS_stat', 'KS_p',\n#             'LR_slope', 'LR_intercept', 'LR_slope_tvalue', 'LR_intercept_tvalue', 'LR_slope_p', 'LR_intercept_p', 'LR_R2adj']\n#     out = pd.DataFrame(index=nm, columns=cols)\n    \n    cols = pd.MultiIndex.from_tuples([('Residual Summary', 'N'),\n                                      ('Residual Summary', 'Median'),\n                                      ('Residual Summary', 'LQ'),\n                                      ('Residual Summary', 'IQR'),\n                                      ('Residual Summary', 'UQ'),\n                                      ('Residual Regression', 'Slope'),\n                                      ('Residual Regression', 'Slope t'),\n                                      ('Residual Regression', 'Slope p'),\n                                      ('Residual Regression', 'Intercept'),\n                                      ('Residual Regression', 'Intercept t'),\n                                      ('Residual Regression', 'Intercept p'),\n                                      ('Residual Regression', 'R2'),\n                                      ('Kolmogorov-Smirnov', 'KS'),\n                                      ('Kolmogorov-Smirnov', 'p')])\n    \n    out = pd.DataFrame(index=nm, columns=cols)\n    \n\n    # remove nan values\n    ind = ~(np.isnan(x) | np.isnan(y))\n    x = x[ind]\n    y = y[ind]\n\n    # calculate residuals\n    r = y - x\n\n    # summary statistics\n    cat = 'Residual Summary'\n    out.loc[:, (cat, 'N')] = len(x)\n    out.loc[:, (cat, 'Median')] = np.median(r)\n    out.loc[:, [(cat, 'LQ'), (cat, 'UQ')]] = np.percentile(r, [25, 75])\n    out.loc[:, (cat, 'IQR')] = out.loc[:, (cat, 'UQ')] - out.loc[:, (cat, 'LQ')]\n\n    # non-paired test for same distribution\n    cat = 'Kolmogorov-Smirnov'\n    ks = stats.ks_2samp(x, y)\n    out.loc[:, (cat, 'KS')] = ks.statistic\n    out.loc[:, (cat, 'p')] = ks.pvalue\n\n    # regression analysis of residuals - slope should be 0, intercept should be 0\n    cat = 'Residual Regression'\n    X = sm.add_constant(x)\n    reg = sm.OLS(r, X, missing='drop')\n    fit = reg.fit()\n    \n    out.loc[:, [(cat, 'Intercept'), (cat, 'Slope')]] = fit.params\n    out.loc[:, [(cat, 'Intercept t'), (cat, 'Slope t')]] = fit.tvalues\n    out.loc[:, (cat, 'R2')] = fit.rsquared\n    out.loc[:, [(cat, 'Intercept p'), (cat, 'Slope p')]] = fit.pvalues\n\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndownloading the data from the LAtools reference repository.", "response": "def load_reference_data(name=None):\n    \"\"\"\n    Fetch LAtools reference data from online repository.\n\n    Parameters\n    ----------\n    name : str<\n        Which data to download. Can be one of 'culture_reference',\n        'culture_test', 'downcore_reference', 'downcore_test', 'iolite_reference'\n        or 'zircon_reference'.\n        If None, all are downloaded and returned as a dict.\n\n    Returns\n    -------\n    pandas.DataFrame or dict.\n    \"\"\"\n    base_url = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vQJfCeuqrtFFMAeSpA9rguzLAo9OVuw50AHhAULuqjMJzbd3h46PK1KjF69YiJAeNAAjjMDkJK7wMpG/pub?gid={:}&single=true&output=csv'\n    gids = {'culture_reference': '0',\n            'culture_test': '1170065442',\n            'downcore_reference': '190752797',\n            'downcore_test': '721359794',\n            'iolite_reference': '483581945',\n            'zircon_reference': '1355554964'}\n\n    if name is None:\n        out = {}\n        for nm, gid in gids.items():\n            url = base_url.format(gid)\n            tmp = pd.read_csv(url, header=[0], index_col=[0, 1])\n            tmp.index.names = ['sample', 'rep']\n            tmp.columns.names = ['analyte']\n            tmp.sort_index(1, inplace=True)\n            out[nm] = tmp\n    else:\n        gid = gids[name]\n        url = base_url.format(gid)\n        out = pd.read_csv(url, index_col=[0, 1])\n        out.columns.names = ['analyte']\n        out.sort_index(1, inplace=True)\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef lookup(self, TC: type, G: type) -> Optional[TypeClass]:\n        ''' Find an instance of the type class `TC` for type `G`.\n        Iterates `G`'s parent classes, looking up instances for each,\n        checking whether the instance is a subclass of the target type\n        class `TC`.\n        '''\n        if isinstance(G, str):\n            raise ImplicitNotFound(TC, G, f'{G} is a string annotation')\n        if not isinstance(G, (type, TypeVar, _GenericAlias)):\n            raise ImplicitNotFound(TC, G, f'{G} is neither type, _GenericAlias nor TypeVar: {type(G)}')\n        match = lambda a: self._lookup_type(TC, a)\n        def attach_type(tc: TypeClass) -> TypeClass:\n            setattr(tc, 'tpe', G)\n            return tc\n        scrutinee = (\n            (\n                unbounded_typevar(TC, G)\n                if G.__bound__ is None else\n                G.__bound__\n            )\n            if isinstance(G, TypeVar) else\n            G\n        )\n        safe_mro = lambda t: getattr(t, '__mro__', (t,))\n        target = scrutinee.__origin__ if isinstance(scrutinee, _GenericAlias) else scrutinee\n        mro = safe_mro(target)\n        return next((attach_type(a) for a in map(match, mro) if a is not None), None)", "response": "Find an instance of the type class TC for type G."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalculating the rangecalc of a single series.", "response": "def rangecalc(x, y=None, pad=0.05):\n    \"\"\"\n    Calculate padded range limits for axes.\n    \"\"\"        \n    mn = np.nanmin([np.nanmin(x), np.nanmin(y)])\n    mx = np.nanmax([np.nanmax(x), np.nanmax(y)])\n    rn = mx - mn\n    \n    return (mn - pad * rn, mx + pad * rn)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating the rangecalcx limits for axes.", "response": "def rangecalcx(x, pad=0.05):\n    \"\"\"\n    Calculate padded range limits for axes.\n    \"\"\"        \n    mn = np.nanmin(x)\n    mx = np.nanmax(x)\n    rn = mx - mn\n\n    return (mn - pad * rn, mx + pad * rn)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef bland_altman(x, y, interval=None, indep_conf=None, ax=None, c=None, **kwargs):\n    ret = False\n    \n    if ax is None:\n        fig, ax = plt.subplots(1, 1)\n        ret = True\n        \n    # NaN screening\n    ind = ~(np.isnan(x) | np.isnan(y))\n    x = x[ind]\n    y = y[ind]\n    \n    xy_mean = (x + y) / 2\n    xy_resid = (y - x)\n\n    ax.scatter(xy_mean, xy_resid, lw=0.5, edgecolor='k', alpha=0.6, c=c, s=15, **kwargs)\n\n    # markup\n    ax.axhline(0, ls='dashed', c='k', alpha=0.6, zorder=-1)\n    \n    ax.axhline(np.median(xy_resid), ls='dashed', c=c, alpha=0.8)\n    \n    if interval is not None:\n        perc = 100 - interval * 100\n        ints = [perc / 2, 100 - perc / 2]\n        lims = np.percentile(xy_resid, ints)\n        ax.axhspan(*lims, color=c, alpha=0.1, zorder=-3)\n    \n    if indep_conf is not None:\n        ax.axhspan(-indep_conf, indep_conf, color=(0,0,0,0.1), zorder=-2)\n\n    # labels\n    ax.set_ylabel('y - x')\n    ax.set_xlabel('mean (x, y)')\n    \n    if ret:\n        return fig, ax", "response": "Plots a Bland - Altman plot of x and y data."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the components of the autorange algorithm.", "response": "def autorange_components(t, sig, transform='log', gwin=7, swin=None,\n                         win=30, on_mult=(1.5, 1.), off_mult=(1., 1.5),\n                         thresh=None):\n    \"\"\"\n    Returns the components underlying the autorange algorithm.\n\n    Returns\n    -------\n    t : array-like\n        Time axis (independent variable)\n    sig : array-like\n        Raw signal (dependent variable)\n    sigs : array-like\n        Smoothed signal (swin)\n    tsig : array-like\n        Transformed raw signal (transform)\n    tsigs : array-like\n        Transformed smoothed signal (transform, swin)\n    kde_x : array-like\n        kernel density estimate of smoothed signal.\n    yd : array-like\n        bins of kernel density estimator.\n    g : array-like\n        gradient of smoothed signal (swin, gwin)\n    trans : dict\n        per-transition data.\n    thresh : float\n        threshold identified from kernel density plot\n    \"\"\"\n    failed = []\n    # smooth signal\n    if swin is not None:\n        sigs = fastsmooth(sig, swin)\n    else:\n        sigs = sig\n\n    # transform signal\n    if transform == 'log':\n        tsigs = np.log10(sigs)\n        tsig = np.log10(sig)\n    else:\n        tsigs = sigs\n        tsig = sig\n\n    if thresh is None:\n        bins = 50\n        kde_x = np.linspace(tsigs.min(), tsigs.max(), bins)\n\n        kde = gaussian_kde(tsigs)\n        yd = kde.pdf(kde_x)\n        mins = findmins(kde_x, yd)  # find minima in kde\n\n        if len(mins) > 0:\n            bkg = tsigs < (mins[0])  # set background as lowest distribution\n            thresh = mins[0]\n        else:\n            bkg = np.ones(tsigs.size, dtype=bool)\n    else:\n        bkg = tsigs < thresh\n\n    # assign rough background and signal regions based on kde minima\n    fbkg = bkg\n    fsig = ~bkg\n\n    # remove transitions by fitting a gaussian to the gradients of\n    # each transition\n\n    # 1. determine the approximate index of each transition\n    zeros = bool_2_indices(fsig)\n\n    # 2. calculate the absolute gradient of the target trace.\n    g = abs(fastgrad(sigs, gwin))  # gradient of untransformed data.\n\n    if zeros is not None:\n        zeros = zeros.flatten()\n        trans = dict(zeros=zeros.flatten(),\n                     lohi=[],\n                     pgs=[],\n                     excl=[],\n                     tps=[],\n                     failed=[],\n                     xs=[],\n                     ys=[])\n\n        for z in zeros:  # for each approximate transition\n            # isolate the data around the transition\n            if z - win < 0:\n                lo = gwin // 2\n                hi = int(z + win)\n            elif z + win > (len(sig) - gwin // 2):\n                lo = int(z - win)\n                hi = len(sig) - gwin // 2\n            else:\n                lo = int(z - win)\n                hi = int(z + win)\n\n            xs = t[lo:hi]\n            ys = g[lo:hi]\n\n            trans['xs'].append(xs)\n            trans['ys'].append(ys)\n\n            trans['lohi'].append([lo, hi])\n\n            # determine type of transition (on/off)\n            mid = (hi + lo) // 2\n            tp = sigs[mid + 3] > sigs[mid - 3]  # True if 'on' transition.\n            trans['tps'].append(tp)\n\n            c = t[z]  # center of transition\n            width = (t[1] - t[0]) * 2  # initial width guess\n            try:\n                pg, _ = curve_fit(gauss, xs, ys,\n                                  p0=(np.nanmax(ys),\n                                      c,\n                                      width),\n                                  sigma=(xs - c)**2 + .01)\n                trans['pgs'].append(pg)\n                fwhm = abs(2 * pg[-1] * np.sqrt(2 * np.log(2)))\n                # apply on_mult or off_mult, as appropriate.\n                if tp:\n                    lim = np.array([-fwhm, fwhm]) * on_mult + pg[1]\n                else:\n                    lim = np.array([-fwhm, fwhm]) * off_mult + pg[1]\n                trans['excl'].append(lim)\n\n                fbkg[(t > lim[0]) & (t < lim[1])] = False\n                fsig[(t > lim[0]) & (t < lim[1])] = False\n                failed.append(False)\n            except RuntimeError:\n                failed.append(True)\n                trans['lohi'].append([np.nan, np.nan])\n                trans['pgs'].append([np.nan, np.nan, np.nan])\n                trans['excl'].append([np.nan, np.nan])\n                trans['tps'].append(tp)\n                pass\n    else:\n        zeros = []\n    \n    return t, sig, sigs, tsig, tsigs, kde_x, yd, g, trans, thresh"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef elements(all_isotopes=True):\n    el = pd.read_pickle(pkgrs.resource_filename('latools', 'resources/elements.pkl'))\n    if all_isotopes:\n        return el.set_index('element')\n    else:\n        def wmean(g):\n            return (g.atomic_weight * g.percent).sum() / 100\n        iel = el.groupby('element').apply(wmean)\n        iel.name = 'atomic_weight'\n        return iel", "response": "Load a DataFrame of all elements and isotopes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalculating the molecular weight of a molecule.", "response": "def calc_M(molecule):\n    \"\"\"\n    Returns molecular weight of molecule.\n\n    Where molecule is in standard chemical notation,\n    e.g. 'CO2', 'HCO3' or B(OH)4\n\n    Returns\n    -------\n    molecular_weight : float\n    \"\"\"\n\n    # load periodic table\n    els = elements()\n\n    # define regexs\n    parens = re.compile('\\(([A-z0-9]+)\\)([0-9]+)?')\n    stoich = re.compile('([A-Z][a-z]?)([0-9]+)?')\n\n    ps = parens.findall(molecule)  # find subgroups in parentheses\n    rem = parens.sub('', molecule)  # get remainder\n\n    m = 0\n    # deal with sub-groups\n    if len(ps) > 0:\n        for sub, ns in ps:\n            ms = 0\n            for e, n in stoich.findall(sub):\n                me = (els.loc[e, 'atomic_weight'] *\n                      els.loc[e, 'percent'] / 100).sum()\n                if n == '':\n                    n = 1\n                else:\n                    n = int(n)\n                ms += me * n\n            if ns == '':\n                ns = 1\n            else:\n                ns = int(ns)\n            m += ms * ns\n    # deal with remainder\n    for e, n in stoich.findall(rem):\n        me = (els.loc[e, 'atomic_weight'] *\n              els.loc[e, 'percent'] / 100).sum()\n        if n == '':\n            n = 1\n        else:\n            n = int(n)\n        m += me * n\n    return m"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating single escape sequence mapping.", "response": "def gen_keywords(*args: Union[ANSIColors, ANSIStyles], **kwargs: Union[ANSIColors, ANSIStyles]) -> tuple:\n    '''generate single escape sequence mapping.'''\n    fields: tuple = tuple()\n    values: tuple = tuple()\n    for tpl in args:\n        fields += tpl._fields\n        values += tpl\n    for prefix, tpl in kwargs.items():\n        fields += tuple(map(lambda x: '_'.join([prefix, x]), tpl._fields))\n        values += tpl\n    return namedtuple('ANSISequences', fields)(*values)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nhandle Resets in input stack. Breaks the input stack if a Reset operator is encountered.", "response": "def zero_break(stack: tuple) -> tuple:\n    '''Handle Resets in input stack.\n    Breaks the input stack if a Reset operator (zero) is encountered.\n    '''\n    reducer = lambda x, y: tuple() if y == 0 else x + (y,)\n    return reduce(reducer, stack, tuple())"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsquashes and reduce the input stack.", "response": "def annihilate(predicate: tuple, stack: tuple) -> tuple:\n    '''Squash and reduce the input stack.\n    Removes the elements of input that match predicate and only keeps the last\n    match at the end of the stack.\n    '''\n    extra = tuple(filter(lambda x: x not in predicate, stack))\n    head = reduce(lambda x, y: y if y in predicate else x, stack, None)\n    return extra + (head,) if head else extra"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove duplicates from the stack in first - seen order.", "response": "def dedup(stack: tuple) -> tuple:\n    '''Remove duplicates from the stack in first-seen order.'''\n    # Initializes with an accumulator and then reduces the stack with first match\n    # deduplication.\n    reducer = lambda x, y: x if y in x else x + (y,)\n    return reduce(reducer, stack, tuple())"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef gauss_weighted_stats(x, yarray, x_new, fwhm):\n    sigma = fwhm / (2 * np.sqrt(2 * np.log(2)))\n\n    # create empty mask array\n    mask = np.zeros((x.size, yarray.shape[1], x_new.size))\n    # fill mask\n    for i, xni in enumerate(x_new):\n        mask[:, :, i] = gauss(x[:, np.newaxis], 1, xni, sigma)\n    # normalise mask\n    nmask = mask / mask.sum(0)  # sum of each gaussian = 1\n\n    # calculate moving average\n    av = (nmask * yarray[:, :, np.newaxis]).sum(0)  # apply mask to data\n    # sum along xn axis to get means\n\n    # calculate moving sd\n    diff = np.power(av - yarray[:, :, np.newaxis], 2)\n    std = np.sqrt((diff * nmask).sum(0))\n    # sqrt of weighted average of data-mean\n\n    # calculate moving se\n    se = std / np.sqrt(mask.sum(0))\n    # max amplitude of weights is 1, so sum of weights scales\n    # a fn of how many points are nearby. Use this as 'n' in\n    # SE calculation.\n\n    return av, std, se", "response": "Calculate the weighted average SD and SE of a gaussian weigted moving mean."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the gaussian function.", "response": "def gauss(x, *p):\n    \"\"\" Gaussian function.\n\n    Parameters\n    ----------\n    x : array_like\n        Independent variable.\n    *p : parameters unpacked to A, mu, sigma\n        A = amplitude, mu = centre, sigma = width\n\n    Return\n    ------\n    array_like\n        gaussian descriped by *p.\n    \"\"\"\n    A, mu, sigma = p\n    return A * np.exp(-0.5 * (-mu + x)**2 / sigma**2)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalculates the standard error of a sequence.", "response": "def stderr(a):\n    \"\"\"\n    Calculate the standard error of a.\n    \"\"\"\n    return np.nanstd(a) / np.sqrt(sum(np.isfinite(a)))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncalculate the Huber ( H15 ) Robust mean of x.", "response": "def H15_mean(x):\n    \"\"\"\n    Calculate the Huber (H15) Robust mean of x.\n\n    For details, see:\n        http://www.cscjp.co.jp/fera/document/ANALYSTVol114Decpgs1693-97_1989.pdf\n        http://www.rsc.org/images/robust-statistics-technical-brief-6_tcm18-214850.pdf\n    \"\"\"\n    mu = np.nanmean(x)\n    sd = np.nanstd(x) * 1.134\n    sig = 1.5\n\n    hi = x > mu + sig * sd\n    lo = x < mu - sig * sd\n\n    if any(hi | lo):\n        x[hi] = mu + sig * sd\n        x[lo] = mu - sig * sd\n        return H15_mean(x)\n    else:\n        return mu"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef H15_se(x):\n    sd = H15_std(x)\n    return sd / np.sqrt(sum(np.isfinite(x)))", "response": "Calculates the Huber ( H15 ) Robust standard deviation of x"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef reproduce(past_analysis, plotting=False, data_folder=None,\n              srm_table=None, custom_stat_functions=None):\n    \"\"\"\n    Reproduce a previous analysis exported with :func:`latools.analyse.minimal_export`\n\n    For normal use, supplying `log_file` and specifying a plotting option should be\n    enough to reproduce an analysis. All requisites (raw data, SRM table and any\n    custom stat functions) will then be imported from the minimal_export folder.\n\n    You may also specify your own raw_data, srm_table and custom_stat_functions,\n    if you wish.\n\n    Parameters\n    ----------\n    log_file : str\n        The path to the log file produced by :func:`~latools.analyse.minimal_export`.\n    plotting : bool\n        Whether or not to output plots.\n    data_folder : str\n        Optional. Specify a different data folder. Data folder\n        should normally be in the same folder as the log file.\n    srm_table : str\n        Optional. Specify a different SRM table. SRM table\n        should normally be in the same folder as the log file.\n    custom_stat_functions : str\n        Optional. Specify a python file containing custom\n        stat functions for use by reproduce. Any custom\n        stat functions should normally be included in the\n        same folder as the log file.\n    \"\"\"\n    if '.zip' in past_analysis:\n        dirpath = utils.extract_zipdir(past_analysis)\n        logpath = os.path.join(dirpath, 'analysis.lalog')\n    elif os.path.isdir(past_analysis):\n        if os.path.exists(os.path.join(past_analysis, 'analysis.lalog')):\n            logpath = os.path.join(past_analysis, 'analysis.lalog')\n    elif 'analysis.lalog' in past_analysis:\n        logpath = past_analysis\n    else:\n        raise ValueError(('\\n\\n{} is not a valid input.\\n\\n' + \n                          'Must be one of:\\n' +\n                          '  - A .zip file exported by latools\\n' + \n                          '  - An analysis.lalog file\\n' +\n                          '  - A directory containing an analysis.lalog files\\n'))\n\n    runargs, paths = logging.read_logfile(logpath)\n\n    # parse custom stat functions\n    csfs = Bunch()\n    if custom_stat_functions is None and 'custom_stat_functions' in paths.keys():\n        # load custom functions as a dict\n        with open(paths['custom_stat_functions'], 'r') as f:\n            csf = f.read()\n\n        fname = re.compile('def (.*)\\(.*')\n\n        for c in csf.split('\\n\\n\\n\\n'):\n            if fname.match(c):\n                csfs[fname.match(c).groups()[0]] = c\n\n    # create analysis object\n    rep = analyse(*runargs[0][-1]['args'], **runargs[0][-1]['kwargs'])\n\n    # rest of commands\n    for fname, arg in runargs:\n        if fname != '__init__':\n            if 'plot' in fname.lower() and plotting:\n                getattr(rep, fname)(*arg['args'], **arg['kwargs'])\n            elif 'sample_stats' in fname.lower():\n                rep.sample_stats(*arg['args'], csf_dict=csfs, **arg['kwargs'])\n            else:\n                getattr(rep, fname)(*arg['args'], **arg['kwargs'])\n\n    return rep", "response": "Reproduces a previous analysis."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndetermine exponential decay coefficient for despike filter. Fits an exponential decay function to the washout phase of standards to determine the washout time of your laser cell. The exponential coefficient reported is `nsd_below` standard deviations below the fitted exponent, to ensure that no real data is removed. Total counts are used in fitting, rather than a specific analyte. Parameters ---------- nsd_below : float The number of standard deviations to subtract from the fitted coefficient when calculating the filter exponent. plot : bool or str If True, creates a plot of the fit, if str the plot is to the location specified in str. trimlim : float A threshold limit used in determining the start of the exponential decay region of the washout. Defaults to half the increase in signal over background. If the data in the plot don't fall on an exponential decay line, change this number. Normally you'll need to increase it. Returns ------- None", "response": "def find_expcoef(self, nsd_below=0., plot=False,\n                     trimlim=None, autorange_kwargs={}):\n        \"\"\"\n        Determines exponential decay coefficient for despike filter.\n\n        Fits an exponential decay function to the washout phase of standards\n        to determine the washout time of your laser cell. The exponential\n        coefficient reported is `nsd_below` standard deviations below the\n        fitted exponent, to ensure that no real data is removed.\n\n        Total counts are used in fitting, rather than a specific analyte.\n\n        Parameters\n        ----------\n        nsd_below : float\n            The number of standard deviations to subtract from the fitted\n            coefficient when calculating the filter exponent.\n        plot : bool or str\n            If True, creates a plot of the fit, if str the plot is to the\n            location specified in str.\n        trimlim : float\n            A threshold limit used in determining the start of the\n            exponential decay region of the washout. Defaults to half\n            the increase in signal over background. If the data in\n            the plot don't fall on an exponential decay line, change\n            this number. Normally you'll need to increase it.\n\n        Returns\n        -------\n        None\n        \"\"\"\n        print('Calculating exponential decay coefficient\\nfrom SRM washouts...')\n\n        def findtrim(tr, lim=None):\n            trr = np.roll(tr, -1)\n            trr[-1] = 0\n            if lim is None:\n                lim = 0.5 * np.nanmax(tr - trr)\n            ind = (tr - trr) >= lim\n            return np.arange(len(ind))[ind ^ np.roll(ind, -1)][0]\n\n        if not hasattr(self.stds[0], 'trnrng'):\n            for s in self.stds:\n                s.autorange(**autorange_kwargs, ploterrs=False)\n\n        trans = []\n        times = []\n        for v in self.stds:\n            for trnrng in v.trnrng[-1::-2]:\n                tr = minmax_scale(v.data['total_counts'][(v.Time > trnrng[0]) & (v.Time < trnrng[1])])\n                sm = np.apply_along_axis(np.nanmean, 1,\n                                         rolling_window(tr, 3, pad=0))\n                sm[0] = sm[1]\n                trim = findtrim(sm, trimlim) + 2\n                trans.append(minmax_scale(tr[trim:]))\n                times.append(np.arange(tr[trim:].size) *\n                             np.diff(v.Time[1:3]))\n\n        times = np.concatenate(times)\n        times = np.round(times, 2)\n        trans = np.concatenate(trans)\n\n        ti = []\n        tr = []\n        for t in np.unique(times):\n            ti.append(t)\n            tr.append(np.nanmin(trans[times == t]))\n\n        def expfit(x, e):\n            \"\"\"\n            Exponential decay function.\n            \"\"\"\n            return np.exp(e * x)\n\n        ep, ecov = curve_fit(expfit, ti, tr, p0=(-1.))\n\n        eeR2 = R2calc(trans, expfit(times, ep))\n\n        if plot:\n            fig, ax = plt.subplots(1, 1, figsize=[6, 4])\n\n            ax.scatter(times, trans, alpha=0.2, color='k', marker='x', zorder=-2)\n            ax.scatter(ti, tr, alpha=1, color='k', marker='o')\n            fitx = np.linspace(0, max(ti))\n            ax.plot(fitx, expfit(fitx, ep), color='r', label='Fit')\n            ax.plot(fitx, expfit(fitx, ep - nsd_below * np.diag(ecov)**.5, ),\n                    color='b', label='Used')\n            ax.text(0.95, 0.75,\n                    ('y = $e^{%.2f \\pm %.2f * x}$\\n$R^2$= %.2f \\nCoefficient: '\n                     '%.2f') % (ep,\n                                np.diag(ecov)**.5,\n                                eeR2,\n                                ep - nsd_below * np.diag(ecov)**.5),\n                    transform=ax.transAxes, ha='right', va='top', size=12)\n            ax.set_xlim(0, ax.get_xlim()[-1])\n            ax.set_xlabel('Time (s)')\n            ax.set_ylim(-0.05, 1.05)\n            ax.set_ylabel('Proportion of Signal')\n            plt.legend()\n            if isinstance(plot, str):\n                fig.savefig(plot)\n\n        self.expdecay_coef = ep - nsd_below * np.diag(ecov)**.5\n\n        print('  {:0.2f}'.format(self.expdecay_coef[0]))\n\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_background(self, n_min=10, n_max=None, focus_stage='despiked', bkg_filter=False, f_win=5, f_n_lim=3):\n        allbkgs = {'uTime': [],\n                   'ns': []}\n                \n        if focus_stage == 'despiked':\n            if 'despiked' not in self.stages_complete:\n                focus_stage = 'rawdata'\n\n        for a in self.analytes:\n            allbkgs[a] = []\n\n        n0 = 0\n        for s in self.data.values():\n            if sum(s.bkg) > 0:\n                allbkgs['uTime'].append(s.uTime[s.bkg])\n                allbkgs['ns'].append(enumerate_bool(s.bkg, n0)[s.bkg])\n                n0 = allbkgs['ns'][-1][-1]\n                for a in self.analytes:\n                    allbkgs[a].append(s.data[focus_stage][a][s.bkg])\n\n        allbkgs.update((k, np.concatenate(v)) for k, v in allbkgs.items())\n        bkgs = pd.DataFrame(allbkgs)  # using pandas here because it's much more efficient than loops.\n\n        self.bkg = Bunch()\n        # extract background data from whole dataset\n        if n_max is None:\n            self.bkg['raw'] = bkgs.groupby('ns').filter(lambda x: len(x) > n_min)\n        else:\n            self.bkg['raw'] = bkgs.groupby('ns').filter(lambda x: (len(x) > n_min) & (len(x) < n_max))\n        # calculate per - background region stats\n        self.bkg['summary'] = self.bkg['raw'].groupby('ns').aggregate([np.mean, np.std, stderr])\n        # sort summary by uTime\n        self.bkg['summary'].sort_values(('uTime', 'mean'), inplace=True)\n        # self.bkg['summary'].index = np.arange(self.bkg['summary'].shape[0])\n        # self.bkg['summary'].index.name = 'ns'\n\n        if bkg_filter:\n            # calculate rolling mean and std from summary\n            t = self.bkg['summary'].loc[:, idx[:, 'mean']]\n            r = t.rolling(f_win).aggregate([np.nanmean, np.nanstd])\n            # calculate upper threshold\n            upper = r.loc[:, idx[:, :, 'nanmean']] + f_n_lim * r.loc[:, idx[:, :, 'nanstd']].values\n            # calculate which are over upper threshold\n            over = r.loc[:, idx[:, :, 'nanmean']] > np.roll(upper.values, 1, 0)\n            # identify them\n            ns_drop = over.loc[over.apply(any, 1), :].index.values\n            # drop them from summary\n            self.bkg['summary'].drop(ns_drop, inplace=True)\n            # remove them from raw\n            ind = np.ones(self.bkg['raw'].shape[0], dtype=bool)\n            for ns in ns_drop:\n                ind = ind & (self.bkg['raw'].loc[:, 'ns'] != ns)\n            self.bkg['raw'] = self.bkg['raw'].loc[ind, :]\n        return", "response": "Extract all background data from all samples on universal time scale."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef bkg_calc_weightedmean(self, analytes=None, weight_fwhm=None,\n                              n_min=20, n_max=None, cstep=None,\n                              bkg_filter=False, f_win=7, f_n_lim=3, focus_stage='despiked'):\n        \"\"\"\n        Background calculation using a gaussian weighted mean.\n\n        Parameters\n        ----------\n        analytes : str or iterable\n            Which analyte or analytes to calculate.\n        weight_fwhm : float\n            The full-width-at-half-maximum of the gaussian used\n            to calculate the weighted average.\n        n_min : int\n            Background regions with fewer than n_min points\n            will not be included in the fit.\n        cstep : float or None\n            The interval between calculated background points.\n        filter : bool\n            If true, apply a rolling filter to the isolated background regions\n            to exclude regions with anomalously high values. If True, two parameters\n            alter the filter's behaviour:\n        f_win : int\n            The size of the rolling window\n        f_n_lim : float\n            The number of standard deviations above the rolling mean\n            to set the threshold.\n        focus_stage : str\n            Which stage of analysis to apply processing to. \n            Defaults to 'despiked' if present, or 'rawdata' if not. \n            Can be one of:\n            * 'rawdata': raw data, loaded from csv file.\n            * 'despiked': despiked data.\n            * 'signal'/'background': isolated signal and background data.\n              Created by self.separate, after signal and background\n              regions have been identified by self.autorange.\n            * 'bkgsub': background subtracted data, created by \n              self.bkg_correct\n            * 'ratios': element ratio data, created by self.ratio.\n            * 'calibrated': ratio data calibrated to standards, created by self.calibrate.\n        \"\"\"\n        if analytes is None:\n            analytes = self.analytes\n            self.bkg = Bunch()\n        elif isinstance(analytes, str):\n            analytes = [analytes]\n        \n        if weight_fwhm is None:\n            weight_fwhm = 600  # 10 minute default window\n\n        self.get_background(n_min=n_min, n_max=n_max,\n                            bkg_filter=bkg_filter,\n                            f_win=f_win, f_n_lim=f_n_lim, focus_stage=focus_stage)\n\n        # Gaussian - weighted average\n        if 'calc' not in self.bkg.keys():\n            # create time points to calculate background\n            if cstep is None:\n                cstep = weight_fwhm / 20\n            elif cstep > weight_fwhm:\n                warnings.warn(\"\\ncstep should be less than weight_fwhm. Your backgrounds\\n\" +\n                              \"might not behave as expected.\\n\")\n            bkg_t = np.linspace(0,\n                                self.max_time,\n                                self.max_time // cstep)\n            self.bkg['calc'] = Bunch()\n            self.bkg['calc']['uTime'] = bkg_t\n\n        # TODO : calculation then dict assignment is clumsy...\n        mean, std, stderr = gauss_weighted_stats(self.bkg['raw'].uTime,\n                                                 self.bkg['raw'].loc[:, analytes].values,\n                                                 self.bkg['calc']['uTime'],\n                                                 fwhm=weight_fwhm)\n\n        for i, a in enumerate(analytes):\n            self.bkg['calc'][a] = {'mean': mean[i],\n                                    'std': std[i],\n                                    'stderr': stderr[i]}", "response": "This function calculates the weighted mean of the background regions."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nbackgrounds calculation using a 1D interpolation. scipy.interpolate.interp1D is used for interpolation. Parameters ---------- analytes : str or iterable Which analyte or analytes to calculate. kind : str or int Integer specifying the order of the spline interpolation used, or string specifying a type of interpolation. Passed to `scipy.interpolate.interp1D` n_min : int Background regions with fewer than n_min points will not be included in the fit. cstep : float or None The interval between calculated background points. filter : bool If true, apply a rolling filter to the isolated background regions to exclude regions with anomalously high values. If True, two parameters alter the filter's behaviour: f_win : int The size of the rolling window f_n_lim : float The number of standard deviations above the rolling mean to set the threshold. focus_stage : str Which stage of analysis to apply processing to. Defaults to 'despiked' if present, or 'rawdata' if not. Can be one of: * 'rawdata': raw data, loaded from csv file. * 'despiked': despiked data. * 'signal'/'background': isolated signal and background data. Created by self.separate, after signal and background regions have been identified by self.autorange. * 'bkgsub': background subtracted data, created by self.bkg_correct * 'ratios': element ratio data, created by self.ratio. * 'calibrated': ratio data calibrated to standards, created by self.calibrate.", "response": "def bkg_calc_interp1d(self, analytes=None, kind=1, n_min=10, n_max=None, cstep=None,\n                          bkg_filter=False, f_win=7, f_n_lim=3, focus_stage='despiked'):\n        \"\"\"\n        Background calculation using a 1D interpolation.\n\n        scipy.interpolate.interp1D is used for interpolation.\n\n        Parameters\n        ----------\n        analytes : str or iterable\n            Which analyte or analytes to calculate.\n        kind : str or int\n            Integer specifying the order of the spline interpolation\n            used, or string specifying a type of interpolation.\n            Passed to `scipy.interpolate.interp1D`\n        n_min : int\n            Background regions with fewer than n_min points\n            will not be included in the fit.\n        cstep : float or None\n            The interval between calculated background points.\n        filter : bool\n            If true, apply a rolling filter to the isolated background regions\n            to exclude regions with anomalously high values. If True, two parameters\n            alter the filter's behaviour:\n        f_win : int\n            The size of the rolling window\n        f_n_lim : float\n            The number of standard deviations above the rolling mean\n            to set the threshold.\n        focus_stage : str\n            Which stage of analysis to apply processing to. \n            Defaults to 'despiked' if present, or 'rawdata' if not. \n            Can be one of:\n            * 'rawdata': raw data, loaded from csv file.\n            * 'despiked': despiked data.\n            * 'signal'/'background': isolated signal and background data.\n              Created by self.separate, after signal and background\n              regions have been identified by self.autorange.\n            * 'bkgsub': background subtracted data, created by \n              self.bkg_correct\n            * 'ratios': element ratio data, created by self.ratio.\n            * 'calibrated': ratio data calibrated to standards, created by self.calibrate.            \n        \"\"\"\n        if analytes is None:\n            analytes = self.analytes\n            self.bkg = Bunch()\n        elif isinstance(analytes, str):\n            analytes = [analytes]\n\n        self.get_background(n_min=n_min, n_max=n_max,\n                            bkg_filter=bkg_filter,\n                            f_win=f_win, f_n_lim=f_n_lim, focus_stage=focus_stage)\n\n        def pad(a, lo=None, hi=None):\n            if lo is None:\n                lo = [a[0]]\n            if hi is None:\n                hi = [a[-1]]\n            return np.concatenate((lo, a, hi))\n\n        if 'calc' not in self.bkg.keys():\n            # create time points to calculate background\n            # if cstep is None:\n                # cstep = self.bkg['raw']['uTime'].ptp() / 100\n            # bkg_t = np.arange(self.bkg['summary']['uTime']['mean'].min(),\n            #                   self.bkg['summary']['uTime']['mean'].max(),\n            #                   cstep)\n\n            bkg_t = pad(self.bkg['summary'].loc[:, ('uTime', 'mean')], [0], [self.max_time])\n\n            self.bkg['calc'] = Bunch()\n            self.bkg['calc']['uTime'] = bkg_t\n\n        d = self.bkg['summary']\n        with self.pbar.set(total=len(analytes), desc='Calculating Analyte Backgrounds') as prog:\n            for a in analytes:\n                self.bkg['calc'][a] = {'mean': pad(d.loc[:, (a, 'mean')].values),\n                                    'std': pad(d.loc[:, (a, 'std')].values),\n                                    'stderr': pad(d.loc[:, (a, 'stderr')].values)}\n                prog.update()\n\n        self.bkg['calc']\n\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef bkg_subtract(self, analytes=None, errtype='stderr', focus_stage='despiked'):\n        if analytes is None:\n            analytes = self.analytes\n        elif isinstance(analytes, str):\n            analytes = [analytes]\n\n        if focus_stage == 'despiked':\n            if 'despiked' not in self.stages_complete:\n                focus_stage = 'rawdata'\n\n        # make uncertainty-aware background interpolators\n        bkg_interps = {}\n        for a in analytes:\n            bkg_interps[a] = un_interp1d(x=self.bkg['calc']['uTime'],\n                                         y=un.uarray(self.bkg['calc'][a]['mean'],\n                                                     self.bkg['calc'][a][errtype]))\n        self.bkg_interps = bkg_interps\n\n        # apply background corrections\n        with self.pbar.set(total=len(self.data), desc='Background Subtraction') as prog:\n            for d in self.data.values():\n                # [d.bkg_subtract(a, bkg_interps[a].new(d.uTime), None, focus_stage=focus_stage) for a in analytes]\n                [d.bkg_subtract(a, bkg_interps[a].new(d.uTime), ~d.sig, focus_stage=focus_stage) for a in analytes]\n                d.setfocus('bkgsub')\n\n                prog.update()\n\n        self.stages_complete.update(['bkgsub'])\n        self.focus_stage = 'bkgsub'\n        return", "response": "Subtracts background from data."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncorrect the spectral interference of two sets of peaks.", "response": "def correct_spectral_interference(self, target_analyte, source_analyte, f):\n        \"\"\"\n        Correct spectral interference.\n\n        Subtract interference counts from target_analyte, based on the\n        intensity of a source_analayte and a known fractional contribution (f).\n\n        Correction takes the form:\n        target_analyte -= source_analyte * f\n\n        Only operates on background-corrected data ('bkgsub'). To undo a correction,\n        rerun `self.bkg_subtract()`.\n\n        Example\n        -------\n        To correct 44Ca+ for an 88Sr++ interference, where both 43.5 and 44 Da\n        peaks are known:\n        f = abundance(88Sr) / (abundance(87Sr) \n\n        counts(44Ca) = counts(44 Da) - counts(43.5 Da) * f\n\n\n        Parameters\n        ----------\n        target_analyte : str\n            The name of the analyte to modify.\n        source_analyte : str\n            The name of the analyte to base the correction on.\n        f : float\n            The fraction of the intensity of the source_analyte to\n            subtract from the target_analyte. Correction is:\n            target_analyte - source_analyte * f\n\n        Returns\n        -------\n        None\n        \"\"\"\n\n        if target_analyte not in self.analytes:\n            raise ValueError('target_analyte: {:} not in available analytes ({:})'.format(target_analyte, ', '.join(self.analytes)))\n\n        if source_analyte not in self.analytes:\n            raise ValueError('source_analyte: {:} not in available analytes ({:})'.format(source_analyte, ', '.join(self.analytes)))\n\n        with self.pbar.set(total=len(self.data), desc='Interference Correction') as prog:\n            for d in self.data.values():\n                d.correct_spectral_interference(target_analyte, source_analyte, f)\n\n                prog.update()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef bkg_plot(self, analytes=None, figsize=None, yscale='log',\n                 ylim=None, err='stderr', save=True):\n        \"\"\"\n        Plot the calculated background.\n\n        Parameters\n        ----------\n        analytes : str or iterable\n            Which analyte(s) to plot.\n        figsize : tuple\n            The (width, height) of the figure, in inches.\n            If None, calculated based on number of samples.\n        yscale : str\n            'log' (default) or 'linear'.\n        ylim : tuple\n            Manually specify the y scale.\n        err : str\n            What type of error to plot. Default is stderr.\n        save : bool\n            If True, figure is saved.\n\n        Returns\n        -------\n        fig, ax : matplotlib.figure, matplotlib.axes\n        \"\"\"\n        if not hasattr(self, 'bkg'):\n            raise ValueError(\"\\nPlease calculate a background before attempting to\\n\" +\n                             \"plot it... either:\\n\" +\n                             \"   bkg_calc_interp1d\\n\" +\n                             \"   bkg_calc_weightedmean\\n\")\n\n        if analytes is None:\n            analytes = self.analytes\n        elif isinstance(analytes, str):\n            analytes = [analytes]\n\n        if figsize is None:\n            if len(self.samples) > 50:\n                figsize = (len(self.samples) * 0.15, 5)\n            else:\n                figsize = (7.5, 5)\n\n        fig = plt.figure(figsize=figsize)\n\n        ax = fig.add_axes([.07, .1, .84, .8])\n        \n        with self.pbar.set(total=len(analytes), desc='Plotting backgrounds') as prog:\n            for a in analytes:\n                # draw data points\n                ax.scatter(self.bkg['raw'].uTime, self.bkg['raw'].loc[:, a],\n                        alpha=0.5, s=3, c=self.cmaps[a],\n                        lw=0.5)\n                \n                # draw STD boxes\n                for i, r in self.bkg['summary'].iterrows():\n                    x = (r.loc['uTime', 'mean'] - r.loc['uTime', 'std'] * 2,\n                        r.loc['uTime', 'mean'] + r.loc['uTime', 'std'] * 2)\n                    yl = [r.loc[a, 'mean'] - r.loc[a, err]] * 2\n                    yu = [r.loc[a, 'mean'] + r.loc[a, err]] * 2\n\n                    ax.fill_between(x, yl, yu, alpha=0.8, lw=0.5, color=self.cmaps[a], zorder=1)\n                prog.update()\n\n        if yscale == 'log':\n            ax.set_yscale('log')\n        if ylim is not None:\n            ax.set_ylim(ylim)\n        else:\n            ax.set_ylim(ax.get_ylim() * np.array([1, 10]))  # x10 to make sample names readable.\n\n        for a in analytes:\n            # draw confidence intervals of calculated\n            x = self.bkg['calc']['uTime']\n            y = self.bkg['calc'][a]['mean']\n            yl = self.bkg['calc'][a]['mean'] - self.bkg['calc'][a][err]\n            yu = self.bkg['calc'][a]['mean'] + self.bkg['calc'][a][err]\n\n            # trim values below zero if log scale=    \n            if yscale == 'log':\n                yl[yl < ax.get_ylim()[0]] = ax.get_ylim()[0]\n\n            ax.plot(x, y,\n                    c=self.cmaps[a], zorder=2, label=a)\n            ax.fill_between(x, yl, yu,\n                            color=self.cmaps[a], alpha=0.3, zorder=-1)\n\n        ax.set_xlabel('Time (s)')\n        ax.set_ylabel('Background Counts')\n\n        ax.set_title('Points = raw data; Bars = {:s}; Lines = Calculated Background; Envelope = Background {:s}'.format(err, err),\n                     fontsize=10)\n\n        ha, la = ax.get_legend_handles_labels()\n\n        ax.legend(labels=la[:len(analytes)], handles=ha[:len(analytes)], bbox_to_anchor=(1, 1))\n\n        # scale x axis to range \u00b1 2.5%\n        xlim = rangecalc(self.bkg['raw']['uTime'], 0.025)\n        ax.set_xlim(xlim)\n\n        # add sample labels\n        for s, d in self.data.items():\n            ax.axvline(d.uTime[0], alpha=0.2, color='k', zorder=-1)\n            ax.text(d.uTime[0], ax.get_ylim()[1], s, rotation=90,\n                    va='top', ha='left', zorder=-1, fontsize=7)\n\n        if save:\n            fig.savefig(self.report_dir + '/background.png', dpi=200)\n\n        return fig, ax", "response": "Plots the calculated background for the specified analytes."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ratio(self, internal_standard=None):\n        if 'bkgsub' not in self.stages_complete:\n            raise RuntimeError('Cannot calculate ratios before background subtraction.')\n\n        if internal_standard is not None:\n            self.internal_standard = internal_standard\n            self.minimal_analytes.update([internal_standard])\n\n        with self.pbar.set(total=len(self.data), desc='Ratio Calculation') as prog:\n            for s in self.data.values():\n                s.ratio(internal_standard=self.internal_standard)\n                prog.update()\n\n        self.stages_complete.update(['ratios'])\n        self.focus_stage = 'ratios'\n        return", "response": "Calculates the ratio of all analytes to a single analyte."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef srm_id_auto(self, srms_used=['NIST610', 'NIST612', 'NIST614'], n_min=10, reload_srm_database=False):\n        if isinstance(srms_used, str):\n            srms_used = [srms_used]\n            \n        # get mean and standard deviations of measured standards\n        self.srm_compile_measured(n_min)\n        stdtab = self.stdtab.copy()\n\n        # load corresponding SRM database\n        self.srm_load_database(srms_used, reload_srm_database)\n\n        # create blank srm table\n        srm_tab = self.srmdat.loc[:, ['mol_ratio', 'element']].reset_index().pivot(index='SRM', columns='element', values='mol_ratio')\n\n        # Auto - ID STDs\n        # 1. identify elements in measured SRMS with biggest range of values\n        meas_tab = stdtab.loc[:, (slice(None), 'mean')]  # isolate means of standards\n        meas_tab.columns = meas_tab.columns.droplevel(1)  # drop 'mean' column names\n        meas_tab.columns = [re.findall('[A-Za-z]+', a)[0] for a in meas_tab.columns]  # rename to element names\n        meas_tab = meas_tab.T.groupby(level=0).first().T  # remove duplicate columns\n\n        ranges = nominal_values(meas_tab.apply(lambda a: np.ptp(a) / np.nanmean(a), 0))  # calculate relative ranges of all elements\n        # (used as weights later)\n\n        # 2. Work out which standard is which\n        # normalise all elements between 0-1\n        def normalise(a):\n            a = nominal_values(a)\n            if np.nanmin(a) < np.nanmax(a):\n                return (a - np.nanmin(a)) / np.nanmax(a - np.nanmin(a))\n            else:\n                return np.ones(a.shape)\n\n        nmeas = meas_tab.apply(normalise, 0)\n        nmeas.dropna(1, inplace=True)  # remove elements with NaN values\n        # nmeas.replace(np.nan, 1, inplace=True)\n        nsrm_tab = srm_tab.apply(normalise, 0)\n        nsrm_tab.dropna(1, inplace=True)\n        # nsrm_tab.replace(np.nan, 1, inplace=True)\n\n        for uT, r in nmeas.iterrows():  # for each standard...\n            idx = np.nansum(((nsrm_tab - r) * ranges)**2, 1)\n            idx = abs((nsrm_tab - r) * ranges).sum(1)\n            # calculate the absolute difference between the normalised elemental\n            # values for each measured SRM and the SRM table. Each element is\n            # multiplied by the relative range seen in that element (i.e. range / mean\n            # measuerd value), so that elements with a large difference are given\n            # more importance in identifying the SRM.   \n            # This produces a table, where wach row contains the difference between\n            # a known vs. measured SRM. The measured SRM is identified as the SRM that\n            # has the smallest weighted sum value.\n            stdtab.loc[uT, 'SRM'] = srm_tab.index[idx == min(idx)].values[0]\n\n        # calculate mean time for each SRM\n        # reset index and sort\n        stdtab.reset_index(inplace=True)\n        stdtab.sort_index(1, inplace=True)\n        # isolate STD and uTime\n        uT = stdtab.loc[:, ['gTime', 'STD']].set_index('STD')\n        uT.sort_index(inplace=True)\n        uTm = uT.groupby(level=0).mean()  # mean uTime for each SRM\n        # replace uTime values with means\n        stdtab.set_index(['STD'], inplace=True)\n        stdtab.loc[:, 'gTime'] = uTm\n        # reset index\n        stdtab.reset_index(inplace=True)\n        stdtab.set_index(['STD', 'SRM', 'gTime'], inplace=True)\n\n        # combine to make SRM reference tables\n        srmtabs = Bunch()\n        for a in self.analytes:\n            el = re.findall('[A-Za-z]+', a)[0]\n\n            sub = stdtab.loc[:, a]\n\n            srmsub = self.srmdat.loc[self.srmdat.element == el, ['mol_ratio', 'mol_ratio_err']]\n\n            srmtab = sub.join(srmsub)\n            srmtab.columns = ['meas_err', 'meas_mean', 'srm_mean', 'srm_err']\n\n            srmtabs[a] = srmtab\n\n        self.srmtabs = pd.concat(srmtabs).apply(nominal_values).sort_index()\n        self.srmtabs.dropna(subset=['srm_mean'], inplace=True)\n        # replace any nan error values with zeros - nans cause problems later.\n        self.srmtabs.loc[:, ['meas_err', 'srm_err']] = self.srmtabs.loc[:, ['meas_err', 'srm_err']].replace(np.nan, 0)\n\n        # remove internal standard from calibration elements\n        self.srmtabs.drop(self.internal_standard, inplace=True)\n\n        self.srms_ided = True\n        return", "response": "Function for automarically identifying the SRMs in the current SRM table."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef calibrate(self, analytes=None, drift_correct=True,\n                  srms_used=['NIST610', 'NIST612', 'NIST614'],\n                  zero_intercept=True, n_min=10, reload_srm_database=False):\n        \"\"\"\n        Calibrates the data to measured SRM values.\n\n        Assumes that y intercept is zero.\n\n        Parameters\n        ----------  \n        analytes : str or iterable\n            Which analytes you'd like to calibrate. Defaults to all.\n        drift_correct : bool\n            Whether to pool all SRM measurements into a single calibration,\n            or vary the calibration through the run, interpolating\n            coefficients between measured SRMs.\n        srms_used : str or iterable\n            Which SRMs have been measured. Must match names given in\n            SRM data file *exactly*.\n        n_min : int\n            The minimum number of data points an SRM measurement\n            must have to be included.\n\n        Returns\n        -------\n        None\n        \"\"\"\n        if analytes is None:\n            analytes = self.analytes[self.analytes != self.internal_standard]\n        elif isinstance(analytes, str):\n            analytes = [analytes]\n\n        if not hasattr(self, 'srmtabs'):\n            self.srm_id_auto(srms_used=srms_used, n_min=n_min, reload_srm_database=reload_srm_database)\n\n        # make container for calibration params\n        if not hasattr(self, 'calib_params'):\n            gTime = self.stdtab.gTime.unique()\n            self.calib_params = pd.DataFrame(columns=pd.MultiIndex.from_product([analytes, ['m']]),\n                                            index=gTime)\n\n        calib_analytes = self.srmtabs.index.get_level_values(0).unique()\n\n        if zero_intercept:\n            fn  = lambda x, m: x * m\n        else:\n            fn = lambda x, m, c: x * m + c\n\n        for a in calib_analytes:\n            if zero_intercept:\n                if (a, 'c') in self.calib_params:\n                    self.calib_params.drop((a, 'c'), 1, inplace=True)\n            if drift_correct:\n                for g in self.stdtab.gTime.unique():\n                    ind = idx[a, :, :, g]\n                    if self.srmtabs.loc[ind].size == 0:\n                        continue\n                    # try:\n                    meas = self.srmtabs.loc[ind, 'meas_mean']\n                    srm = self.srmtabs.loc[ind, 'srm_mean']\n                    # TODO: replace curve_fit with Sambridge's 2D likelihood function for better uncertainty incorporation.\n                    merr = self.srmtabs.loc[ind, 'meas_err']\n                    serr = self.srmtabs.loc[ind, 'srm_err']\n                    sigma = np.sqrt(merr**2 + serr**2)\n\n                    if len(meas) > 1:\n                        # multiple SRMs - do a regression\n                        p, cov = curve_fit(fn, meas, srm, sigma=sigma)\n                        pe = unc.correlated_values(p, cov)                \n                        self.calib_params.loc[g, (a, 'm')] = pe[0]\n                        if not zero_intercept:\n                            self.calib_params.loc[g, (a, 'c')] = pe[1]\n                    else:\n                        # deal with case where there's only one datum\n                        self.calib_params.loc[g, (a, 'm')] = (un.uarray(srm, serr) / \n                                                              un.uarray(meas, merr))[0]\n                        if not zero_intercept:\n                            self.calib_params.loc[g, (a, 'c')] = 0\n\n                    # This should be obsolete, because no-longer sourcing locator from calib_params index.\n                    # except KeyError:\n                    #     # If the calibration is being recalculated, calib_params\n                    #     # will have t=0 and t=max(uTime) values that are outside\n                    #     # the srmtabs index.\n                    #     # If this happens, drop them, and re-fill them at the end.\n                    #     self.calib_params.drop(g, inplace=True)\n            else:\n                ind = idx[a, :, :, :]\n                meas = self.srmtabs.loc[ind, 'meas_mean']\n                srm = self.srmtabs.loc[ind, 'srm_mean']\n                merr = self.srmtabs.loc[ind, 'meas_err']\n                serr = self.srmtabs.loc[ind, 'srm_err']\n                sigma = np.sqrt(merr**2 + serr**2)\n                \n                if len(meas) > 1:\n                    p, cov = curve_fit(fn, meas, srm, sigma=sigma)\n                    pe = unc.correlated_values(p, cov)                \n                    self.calib_params.loc[:, (a, 'm')] = pe[0]\n                    if not zero_intercept:\n                        self.calib_params.loc[:, (a, 'c')] = pe[1]\n                else:\n                    self.calib_params.loc[:, (a, 'm')] = (un.uarray(srm, serr) / \n                                                          un.uarray(meas, merr))[0]\n                    if not zero_intercept:\n                        self.calib_params.loc[:, (a, 'c')] = 0\n\n        # if fill:\n        # fill in uTime=0 and uTime = max cases for interpolation\n        if self.calib_params.index.min() == 0:\n            self.calib_params.drop(0, inplace=True)\n            self.calib_params.drop(self.calib_params.index.max(), inplace=True)\n        self.calib_params.loc[0, :] = self.calib_params.loc[self.calib_params.index.min(), :]\n        maxuT = np.max([d.uTime.max() for d in self.data.values()])  # calculate max uTime\n        self.calib_params.loc[maxuT, :] = self.calib_params.loc[self.calib_params.index.max(), :]\n        # sort indices for slice access\n        self.calib_params.sort_index(1, inplace=True)\n        self.calib_params.sort_index(0, inplace=True)\n\n        # calculcate interpolators for applying calibrations\n        self.calib_ps = Bunch()\n        for a in analytes:\n            # TODO: revisit un_interp1d to see whether it plays well with correlated values. \n            # Possible re-write to deal with covariance matrices?\n            self.calib_ps[a] = {'m': un_interp1d(self.calib_params.index.values,\n                                                self.calib_params.loc[:, (a, 'm')].values)}\n            if not zero_intercept:\n                self.calib_ps[a]['c'] = un_interp1d(self.calib_params.index.values,\n                                                    self.calib_params.loc[:, (a, 'c')].values)\n\n        with self.pbar.set(total=len(self.data), desc='Applying Calibrations') as prog:\n            for d in self.data.values():\n                d.calibrate(self.calib_ps, analytes)\n                prog.update()\n\n        # record SRMs used for plotting\n        markers = 'osDsv<>PX'  # for future implementation of SRM-specific markers.\n        if not hasattr(self, 'srms_used'):\n            self.srms_used = set(srms_used)\n        else:\n            self.srms_used.update(srms_used)\n        self.srm_mdict = {k: markers[i] for i, k in enumerate(self.srms_used)}\n\n        self.stages_complete.update(['calibrated'])\n        self.focus_stage = 'calibrated'\n\n        return", "response": "Calibrates the data to measured SRM values."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef make_subset(self, samples=None, name=None):\n        # Check if a subset containing the same samples already exists.\n        for k, v in self.subsets.items():\n            if set(v) == set(samples) and k != 'not_in_set':\n                return k\n\n        if isinstance(samples, str):\n            samples = [samples]\n\n        not_exists = [s for s in samples if s not in self.subsets['All_Analyses']]\n        if len(not_exists) > 0:\n            raise ValueError(', '.join(not_exists) + ' not in the list of sample names.\\nPlease check your sample names.\\nNote: Sample names are stored in the .samples attribute of your analysis.')\n\n        if name is None:\n            name = max([-1] + [x for x in self.subsets.keys() if isinstance(x, int)]) + 1\n\n        self._subset_names.append(name)\n\n        if samples is not None:\n            self.subsets[name] = samples\n            for s in samples:\n                try:\n                    self.subsets['not_in_set'].remove(s)\n                except ValueError:\n                    pass\n\n        self._has_subsets = True\n\n        # for subset in np.unique(list(self.subsets.values())):\n        #     self.subsets[subset] = sorted([k for k, v in self.subsets.items() if str(v) == subset])\n\n        return name", "response": "Creates a subset of samples which can be treated independently."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef zeroscreen(self, focus_stage=None):\n        if focus_stage is None:\n            focus_stage = self.focus_stage\n\n        for s in self.data.values():\n            ind = np.ones(len(s.Time), dtype=bool)\n            for v in s.data[focus_stage].values():\n                ind = ind & (nominal_values(v) > 0)\n\n            for k in s.data[focus_stage].keys():\n                s.data[focus_stage][k][~ind] = unc.ufloat(np.nan, np.nan)\n\n        self.set_focus(focus_stage)\n\n        return", "response": "Remove all points containing data below zero which are impossible!"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\napply a threshold filter to the data.", "response": "def filter_threshold(self, analyte, threshold,\n                         samples=None, subset=None):\n        \"\"\"\n        Applies a threshold filter to the data.\n\n        Generates two filters above and below the threshold value for a\n        given analyte.\n\n        Parameters\n        ----------\n        analyte : str\n            The analyte that the filter applies to.\n        threshold : float\n            The threshold value.\n        filt : bool\n            Whether or not to apply existing filters to the data before\n            calculating this filter.\n        samples : array_like or None\n            Which samples to apply this filter to. If None, applies to all\n            samples.\n        subset : str or number\n            The subset of samples (defined by make_subset) you want to apply\n            the filter to.\n\n        Returns\n        -------\n        None\n        \"\"\"\n        if samples is not None:\n            subset = self.make_subset(samples)\n\n        samples = self._get_samples(subset)\n\n        self.minimal_analytes.update([analyte])\n\n        with self.pbar.set(total=len(samples), desc='Threshold Filter') as prog:\n            for s in samples:\n                self.data[s].filter_threshold(analyte, threshold)\n                prog.update()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\napplies a threshold filter to the data.", "response": "def filter_threshold_percentile(self, analyte, percentiles, level='population', filt=False,\n                                    samples=None, subset=None):\n        \"\"\"\n        Applies a threshold filter to the data.\n\n        Generates two filters above and below the threshold value for a\n        given analyte.\n\n        Parameters\n        ----------\n        analyte : str\n            The analyte that the filter applies to.\n        percentiles : float or iterable of len=2\n            The percentile values.\n        level : str\n            Whether to calculate percentiles from the entire dataset\n            ('population') or for each individual sample ('individual')\n        filt : bool\n            Whether or not to apply existing filters to the data before\n            calculating this filter.\n        samples : array_like or None\n            Which samples to apply this filter to. If None, applies to all\n            samples.\n        subset : str or number\n            The subset of samples (defined by make_subset) you want to apply\n            the filter to.\n\n        Returns\n        -------\n        None\n        \"\"\"\n        params = locals()\n        del(params['self'])\n\n        if samples is not None:\n            subset = self.make_subset(samples)\n\n        samples = self._get_samples(subset)\n\n        self.minimal_analytes.update([analyte])\n\n        if isinstance(percentiles, (int, float)):\n            percentiles = [percentiles]\n\n        if level == 'population':\n            # Get all samples\n            self.get_focus(filt=filt, subset=subset, nominal=True)\n            dat = self.focus[analyte][~np.isnan(self.focus[analyte])]\n\n            # calculate filter limits\n            lims = np.percentile(dat, percentiles)\n\n        # Calculate filter for individual samples\n        with self.pbar.set(total=len(samples), desc='Percentile theshold filter') as prog:\n            for s in samples:\n                d = self.data[s]\n                setn = d.filt.maxset + 1\n                g = d.focus[analyte]\n\n                if level == 'individual':\n                    gt = nominal_values(g)\n                    lims = np.percentile(gt[~np.isnan(gt)], percentiles)\n\n                if len(lims) == 1:\n                    above = g >= lims[0]\n                    below = g < lims[0]\n\n                    d.filt.add(analyte + '_{:.1f}-pcnt_below'.format(percentiles[0]),\n                            below,\n                            'Values below {:.1f}th {:} percentile ({:.2e})'.format(percentiles[0], analyte, lims[0]),\n                            params, setn=setn)\n                    d.filt.add(analyte + '_{:.1f}-pcnt_above'.format(percentiles[0]),\n                            above,\n                            'Values above {:.1f}th {:} percentile ({:.2e})'.format(percentiles[0], analyte, lims[0]),\n                            params, setn=setn)\n\n                elif len(lims) == 2:\n                    inside = (g >= min(lims)) & (g <= max(lims))\n                    outside = (g < min(lims)) | (g > max(lims))\n\n                    lpc = '-'.join(['{:.1f}'.format(p) for p in percentiles])\n                    d.filt.add(analyte + '_' + lpc + '-pcnt_inside',\n                            inside,\n                            'Values between ' + lpc + ' ' + analyte + 'percentiles',\n                            params, setn=setn)\n                    d.filt.add(analyte + '_' + lpc + '-pcnt_outside',\n                            outside,\n                            'Values outside ' + lpc + ' ' + analyte + 'percentiles',\n                            params, setn=setn)\n                prog.update()\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalculating a gradient threshold filter for the specified analyte and percentile values.", "response": "def filter_gradient_threshold_percentile(self, analyte, percentiles, level='population', win=15, filt=False,\n                                             samples=None, subset=None):\n        \"\"\"\n        Calculate a gradient threshold filter to the data.\n\n        Generates two filters above and below the threshold value for a\n        given analyte.\n\n        Parameters\n        ----------\n        analyte : str\n            The analyte that the filter applies to.\n        win : int\n            The window over which to calculate the moving gradient\n        percentiles : float or iterable of len=2\n            The percentile values.\n        filt : bool\n            Whether or not to apply existing filters to the data before\n            calculating this filter.\n        samples : array_like or None\n            Which samples to apply this filter to. If None, applies to all\n            samples.\n        subset : str or number\n            The subset of samples (defined by make_subset) you want to apply\n            the filter to.\n\n        Returns\n        -------\n        None\n        \"\"\"\n        params = locals()\n        del(params['self'])\n\n        if samples is not None:\n            subset = self.make_subset(samples)\n\n        samples = self._get_samples(subset)\n\n        self.minimal_analytes.update([analyte])\n\n        # Calculate gradients of all samples\n        self.get_gradients(analytes=[analyte], win=win, filt=filt, subset=subset)\n        grad = self.gradients[analyte][~np.isnan(self.gradients[analyte])]\n\n        if isinstance(percentiles, (int, float)):\n            percentiles = [percentiles]\n\n        if level == 'population':\n            # calculate filter limits\n            lims = np.percentile(grad, percentiles)\n\n        # Calculate filter for individual samples\n        with self.pbar.set(total=len(samples), desc='Percentile Threshold Filter') as prog:\n            for s in samples:\n                d = self.data[s]\n                setn = d.filt.maxset + 1\n                g = calc_grads(d.Time, d.focus, [analyte], win)[analyte]\n\n                if level == 'individual':\n                    gt = nominal_values(g)\n                    lims = np.percentile(gt[~np.isnan(gt)], percentiles)\n\n                if len(lims) == 1:\n                    above = g >= lims[0]\n                    below = g < lims[0]\n\n                    d.filt.add(analyte + '_{:.1f}-grd-pcnt_below'.format(percentiles[0]),\n                            below,\n                            'Gradients below {:.1f}th {:} percentile ({:.2e})'.format(percentiles[0], analyte, lims[0]),\n                            params, setn=setn)\n                    d.filt.add(analyte + '_{:.1f}-grd-pcnt_above'.format(percentiles[0]),\n                            above,\n                            'Gradients above {:.1f}th {:} percentile ({:.2e})'.format(percentiles[0], analyte, lims[0]),\n                            params, setn=setn)\n\n                elif len(lims) == 2:\n                    inside = (g >= min(lims)) & (g <= max(lims))\n                    outside = (g < min(lims)) | (g > max(lims))\n\n                    lpc = '-'.join(['{:.1f}'.format(p) for p in percentiles])\n                    d.filt.add(analyte + '_' + lpc + '-grd-pcnt_inside',\n                            inside,\n                            'Gradients between ' + lpc + ' ' + analyte + 'percentiles',\n                            params, setn=setn)\n                    d.filt.add(analyte + '_' + lpc + '-grd-pcnt_outside',\n                            outside,\n                            'Gradients outside ' + lpc + ' ' + analyte + 'percentiles',\n                            params, setn=setn)\n                prog.update()\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\napplying a n - dimensional clustering filter to the data.", "response": "def filter_clustering(self, analytes, filt=False, normalise=True,\n                          method='kmeans', include_time=False, samples=None,\n                          sort=True, subset=None, level='sample', min_data=10, **kwargs):\n        \"\"\"\n        Applies an n - dimensional clustering filter to the data.\n     \n        Parameters\n        ----------\n        analytes : str\n            The analyte(s) that the filter applies to.\n        filt : bool\n            Whether or not to apply existing filters to the data before\n            calculating this filter.\n        normalise : bool\n            Whether or not to normalise the data to zero mean and unit\n            variance. Reccomended if clustering based on more than 1 analyte.\n            Uses `sklearn.preprocessing.scale`.\n        method : str\n            Which clustering algorithm to use:\n            \n            * 'meanshift': The `sklearn.cluster.MeanShift` algorithm.\n              Automatically determines number of clusters\n              in data based on the `bandwidth` of expected\n              variation.\n            * 'kmeans': The `sklearn.cluster.KMeans` algorithm. Determines\n              the characteristics of a known number of clusters\n              within the data. Must provide `n_clusters` to specify\n              the expected number of clusters.\n        level : str\n            Whether to conduct the clustering analysis at the 'sample' or \n            'population' level.\n        include_time : bool\n            Whether or not to include the Time variable in the clustering\n            analysis. Useful if you're looking for spatially continuous\n            clusters in your data, i.e. this will identify each spot in your\n            analysis as an individual cluster.\n        samples : optional, array_like or None\n            Which samples to apply this filter to. If None, applies to all\n            samples.\n        sort : bool\n            Whether or not you want the cluster labels to\n            be sorted by the mean magnitude of the signals\n            they are based on (0 = lowest)\n        min_data : int\n            The minimum number of data points that should be considered by\n            the filter. Default = 10.\n        **kwargs\n            Parameters passed to the clustering algorithm specified by\n            `method`.\n        Meanshift Parameters\n            bandwidth : str or float\n                The bandwith (float) or bandwidth method ('scott' or 'silverman')\n                used to estimate the data bandwidth.\n            bin_seeding : bool\n                Modifies the behaviour of the meanshift algorithm. Refer to\n                sklearn.cluster.meanshift documentation.\n        K-Means Parameters\n            n_clusters : int\n                The number of clusters expected in the data.\n\n        Returns\n        -------\n        None\n        \"\"\"\n        if samples is not None:\n            subset = self.make_subset(samples)\n\n        samples = self._get_samples(subset)\n\n        if isinstance(analytes, str):\n            analytes = [analytes]\n\n        self.minimal_analytes.update(analytes)\n\n        if level == 'sample':\n            with self.pbar.set(total=len(samples), desc='Clustering Filter') as prog:\n                for s in samples:\n                    self.data[s].filter_clustering(analytes=analytes, filt=filt,\n                                                normalise=normalise,\n                                                method=method,\n                                                include_time=include_time,\n                                                min_data=min_data,\n                                                sort=sort,\n                                                **kwargs)\n                    prog.update()\n        \n        if level == 'population':\n            if isinstance(sort, bool):\n                sort_by = 0\n            else:\n                sort_by = sort\n            \n            name = '_'.join(analytes) + '_{}'.format(method)\n\n            self.fit_classifier(name=name, analytes=analytes, method=method,\n                                subset=subset, filt=filt, sort_by=sort_by, **kwargs)\n\n            self.apply_classifier(name=name, subset=subset)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfits a clustering classifier on the data.", "response": "def fit_classifier(self, name, analytes, method, samples=None,\n                       subset=None, filt=True, sort_by=0, **kwargs):\n        \"\"\"\n        Create a clustering classifier based on all samples, or a subset.\n\n        Parameters\n        ----------\n        name : str\n            The name of the classifier.\n        analytes : str or iterable\n            Which analytes the clustering algorithm should consider.\n        method : str\n            Which clustering algorithm to use. Can be:\n\n            'meanshift'\n                The `sklearn.cluster.MeanShift` algorithm.\n                Automatically determines number of clusters\n                in data based on the `bandwidth` of expected\n                variation.\n            'kmeans'\n                The `sklearn.cluster.KMeans` algorithm. Determines\n                the characteristics of a known number of clusters\n                within the data. Must provide `n_clusters` to specify\n                the expected number of clusters.\n        samples : iterable\n            list of samples to consider. Overrides 'subset'.\n        subset : str\n            The subset of samples used to fit the classifier. Ignored if\n            'samples' is specified.\n        sort_by : int\n            Which analyte the resulting clusters should be sorted\n            by - defaults to 0, which is the first analyte.\n        **kwargs :\n            method-specific keyword parameters - see below.\n        Meanshift Parameters\n            bandwidth : str or float\n                The bandwith (float) or bandwidth method ('scott' or 'silverman')\n                used to estimate the data bandwidth.\n            bin_seeding : bool\n                Modifies the behaviour of the meanshift algorithm. Refer to\n                sklearn.cluster.meanshift documentation.\n        K - Means Parameters\n            n_clusters : int\n                The number of clusters expected in the data.\n\n        Returns\n        -------\n        name : str\n        \"\"\"\n        # isolate data\n        if samples is not None:\n            subset = self.make_subset(samples)\n\n        self.get_focus(subset=subset, filt=filt)\n\n        # create classifer\n        c = classifier(analytes,\n                       sort_by)\n        # fit classifier\n        c.fit(data=self.focus,\n              method=method,\n              **kwargs)\n\n        self.classifiers[name] = c\n\n        return name"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\napply a clustering classifier based on all samples or a subset of samples.", "response": "def apply_classifier(self, name, samples=None, subset=None):\n        \"\"\"\n        Apply a clustering classifier based on all samples, or a subset.\n\n        Parameters\n        ----------\n        name : str\n            The name of the classifier to apply.\n        subset : str\n            The subset of samples to apply the classifier to.\n        Returns\n        -------\n        name : str\n        \"\"\"\n        if samples is not None:\n            subset = self.make_subset(samples)\n\n        samples = self._get_samples(subset)\n\n        c = self.classifiers[name]\n        labs = c.classifier.ulabels_\n\n        with self.pbar.set(total=len(samples), desc='Applying ' + name + ' classifier') as prog:\n            for s in samples:\n                d = self.data[s]\n                try:\n                    f = c.predict(d.focus)\n                except ValueError:\n                    # in case there's no data\n                    f = np.array([-2] * len(d.Time))\n                for l in labs:\n                    ind = f == l\n                    d.filt.add(name=name + '_{:.0f}'.format(l),\n                            filt=ind,\n                            info=name + ' ' + c.method + ' classifier',\n                            params=(c.analytes, c.method))\n                prog.update()\n\n        return name"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\napplies a correlation filter to the data.", "response": "def filter_correlation(self, x_analyte, y_analyte, window=None,\n                           r_threshold=0.9, p_threshold=0.05, filt=True,\n                           samples=None, subset=None):\n        \"\"\"\n        Applies a correlation filter to the data.\n\n        Calculates a rolling correlation between every `window` points of\n        two analytes, and excludes data where their Pearson's R value is\n        above `r_threshold` and statistically significant.\n\n        Data will be excluded where their absolute R value is greater than\n        `r_threshold` AND the p - value associated with the correlation is\n        less than `p_threshold`. i.e. only correlations that are statistically\n        significant are considered.\n\n        Parameters\n        ----------\n        x_analyte, y_analyte : str\n            The names of the x and y analytes to correlate.\n        window : int, None\n            The rolling window used when calculating the correlation.\n        r_threshold : float\n            The correlation index above which to exclude data.\n            Note: the absolute pearson R value is considered, so\n            negative correlations below -`r_threshold` will also\n            be excluded.\n        p_threshold : float\n            The significant level below which data are excluded.\n        filt : bool\n            Whether or not to apply existing filters to the data before\n            calculating this filter.\n\n        Returns\n        -------\n        None\n        \"\"\"\n        if samples is not None:\n            subset = self.make_subset(samples)\n\n        samples = self._get_samples(subset)\n\n        self.minimal_analytes.update([x_analyte, y_analyte])\n\n        with self.pbar.set(total=len(samples), desc='Correlation Filter') as prog:\n            for s in samples:\n                self.data[s].filter_correlation(x_analyte, y_analyte,\n                                                window=window,\n                                                r_threshold=r_threshold,\n                                                p_threshold=p_threshold,\n                                                filt=filt)\n                prog.update()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef correlation_plots(self, x_analyte, y_analyte, window=15, filt=True, recalc=False, samples=None, subset=None, outdir=None):\n        if outdir is None:\n            outdir = self.report_dir + '/correlations/'\n        if not os.path.isdir(outdir):\n            os.mkdir(outdir)\n        \n        if subset is not None:\n            samples = self._get_samples(subset)\n        elif samples is None:\n            samples = self.subsets['All_Analyses']\n        elif isinstance(samples, str):\n            samples = [samples]\n\n        with self.pbar.set(total=len(samples), desc='Drawing Plots') as prog:\n            for s in samples:\n                f, a = self.data[s].correlation_plot(x_analyte=x_analyte, y_analyte=y_analyte,\n                                                     window=window, filt=filt, recalc=recalc)\n                f.savefig('{}/{}_{}-{}.pdf'.format(outdir, s, x_analyte, y_analyte))\n                plt.close(f)\n                prog.update()\n        return", "response": "Plots the local correlation between two analytes."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nturning data filters on for particular analytes and samples.", "response": "def filter_on(self, filt=None, analyte=None, samples=None, subset=None, show_status=False):\n        \"\"\"\n        Turns data filters on for particular analytes and samples.\n\n        Parameters\n        ----------\n        filt : optional, str or array_like\n            Name, partial name or list of names of filters. Supports\n            partial matching. i.e. if 'cluster' is specified, all\n            filters with 'cluster' in the name are activated.\n            Defaults to all filters.\n        analyte : optional, str or array_like\n            Name or list of names of analytes. Defaults to all analytes.\n        samples : optional, array_like or None\n            Which samples to apply this filter to. If None, applies to all\n            samples.\n\n        Returns\n        -------\n        None\n        \"\"\"\n        if samples is not None:\n            subset = self.make_subset(samples)\n\n        samples = self._get_samples(subset)\n\n        for s in samples:\n            try:\n                self.data[s].filt.on(analyte, filt)\n            except:\n                warnings.warn(\"filt.on failure in sample \" + s)\n\n        if show_status:\n            self.filter_status(subset=subset)\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nturn data filters off for particular analytes and samples.", "response": "def filter_off(self, filt=None, analyte=None, samples=None, subset=None, show_status=False):\n        \"\"\"\n        Turns data filters off for particular analytes and samples.\n\n        Parameters\n        ----------\n        filt : optional, str or array_like\n            Name, partial name or list of names of filters. Supports\n            partial matching. i.e. if 'cluster' is specified, all\n            filters with 'cluster' in the name are activated.\n            Defaults to all filters.\n        analyte : optional, str or array_like\n            Name or list of names of analytes. Defaults to all analytes.\n        samples : optional, array_like or None\n            Which samples to apply this filter to. If None, applies to all\n            samples.\n\n        Returns\n        -------\n        None\n        \"\"\"\n        if samples is not None:\n            subset = self.make_subset(samples)\n\n        samples = self._get_samples(subset)\n\n        for s in samples:\n            try:\n                self.data[s].filt.off(analyte, filt)\n            except:\n                warnings.warn(\"filt.off failure in sample \" + s)\n\n        if show_status:\n            self.filter_status(subset=subset)\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nprinting the current status of filters for the specified samples and optionally a subset.", "response": "def filter_status(self, sample=None, subset=None, stds=False):\n        \"\"\"\n        Prints the current status of filters for specified samples.\n\n        Parameters\n        ----------\n        sample : str\n            Which sample to print.\n        subset : str\n            Specify a subset\n        stds : bool\n            Whether or not to include standards.\n        \"\"\"\n        s = ''\n        if sample is None and subset is None:\n            if not self._has_subsets:\n                s += 'Subset: All Samples\\n\\n'\n                s += self.data[self.subsets['All_Samples'][0]].filt.__repr__()\n            else:\n                for n in sorted(str(sn) for sn in self._subset_names):\n                    if n in self.subsets:\n                        pass\n                    elif int(n) in self.subsets:\n                        n = int(n)\n                        pass\n                    s += 'Subset: ' + str(n) + '\\n'\n                    s += 'Samples: ' + ', '.join(self.subsets[n]) + '\\n\\n'\n                    s += self.data[self.subsets[n][0]].filt.__repr__()\n                if len(self.subsets['not_in_set']) > 0:\n                    s += '\\nNot in Subset:\\n'\n                    s += 'Samples: ' + ', '.join(self.subsets['not_in_set']) + '\\n\\n'\n                    s += self.data[self.subsets['not_in_set'][0]].filt.__repr__()\n            print(s)\n            return\n\n        elif sample is not None:\n            s += 'Sample: ' + sample + '\\n'\n            s += self.data[sample].filt.__repr__()\n            print(s)\n            return\n\n        elif subset is not None:\n            if isinstance(subset, (str, int, float)):\n                subset = [subset]\n            for n in subset:\n                s += 'Subset: ' + str(n) + '\\n'\n                s += 'Samples: ' + ', '.join(self.subsets[n]) + '\\n\\n'\n                s += self.data[self.subsets[n][0]].filt.__repr__()\n            print(s)\n            return"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef filter_clear(self, samples=None, subset=None):\n        if samples is not None:\n            subset = self.make_subset(samples)\n\n        samples = self._get_samples(subset)\n\n        for s in samples:\n            self.data[s].filt.clear()", "response": "Clears all data filters."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef filter_defragment(self, threshold, mode='include', filt=True, samples=None, subset=None):\n        if samples is not None:\n            subset = self.make_subset(samples)\n\n        samples = self._get_samples(subset)\n\n        for s in samples:\n            f = self.data[s].filt.grab_filt(filt)\n            self.data[s].filt.add(name='defrag_{:s}_{:.0f}'.format(mode, threshold),\n                                  filt=filters.defrag(f, threshold, mode),\n                                  info='Defrag {:s} filter with threshold {:.0f}'.format(mode, threshold),\n                                  params=(threshold, mode, filt, samples, subset))", "response": "Filter the data for which a specific number of points is less than threshold."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef filter_exclude_downhole(self, threshold, filt=True, samples=None, subset=None):\n        if samples is not None:\n            subset = self.make_subset(samples)\n\n        samples = self._get_samples(subset)\n\n        for s in samples:\n            self.data[s].filter_exclude_downhole(threshold, filt)", "response": "Exclude all points down -hole after the first excluded data point."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef filter_trim(self, start=1, end=1, filt=True, samples=None, subset=None):\n        if samples is not None:\n            subset = self.make_subset(samples)\n\n        samples = self._get_samples(subset)\n\n        for s in samples:\n            self.data[s].filter_trim(start, end, filt)", "response": "Removes points from the start and end of the filter regions."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef filter_nremoved(self, filt=True, quiet=False):\n        rminfo = {}\n        for n in self.subsets['All_Samples']:\n            s = self.data[n]\n            rminfo[n] = s.filt_nremoved(filt)\n        if not quiet:\n            maxL = max([len(s) for s in rminfo.keys()])\n            print('{string:{number}s}'.format(string='Sample ', number=maxL + 3) +\n                  '{total:4s}'.format(total='tot') +\n                  '{removed:4s}'.format(removed='flt') +\n                  '{percent:4s}'.format(percent='%rm'))\n            for k, (ntot, nfilt, pcrm) in rminfo.items():\n                print('{string:{number}s}'.format(string=k, number=maxL + 3) +\n                      '{total:4.0f}'.format(total=ntot) +\n                      '{removed:4.0f}'.format(removed=nfilt) +\n                      '{percent:4.0f}'.format(percent=pcrm))\n\n        return rminfo", "response": "Report how many data are removed by the active filters."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef optimise_signal(self, analytes, min_points=5,\n                        threshold_mode='kde_first_max', \n                        threshold_mult=1., x_bias=0, filt=True,\n                        weights=None, mode='minimise',\n                        samples=None, subset=None):\n        \"\"\"\n        Optimise data selection based on specified analytes.\n\n        Identifies the longest possible contiguous data region in\n        the signal where the relative standard deviation (std) and \n        concentration of all analytes is minimised.\n\n        Optimisation is performed via a grid search of all possible\n        contiguous data regions. For each region, the mean std and\n        mean scaled analyte concentration ('amplitude') are calculated. \n        \n        The size and position of the optimal data region are identified \n        using threshold std and amplitude values. Thresholds are derived\n        from all calculated stds and amplitudes using the method specified\n        by `threshold_mode`. For example, using the 'kde_max' method, a\n        probability density function (PDF) is calculated for std and\n        amplitude values, and the threshold is set as the maximum of the\n        PDF. These thresholds are then used to identify the size and position\n        of the longest contiguous region where the std is below the threshold, \n        and the amplitude is either below the threshold.\n\n        All possible regions of the data that have at least\n        `min_points` are considered.\n\n        For a graphical demonstration of the action of signal_optimiser, \n        use `optimisation_plot`. \n\n        Parameters\n        ----------\n        d : latools.D object\n            An latools data object.\n        analytes : str or array-like\n            Which analytes to consider.\n        min_points : int\n            The minimum number of contiguous points to\n            consider.\n        threshold_mode : str\n            The method used to calculate the optimisation\n            thresholds. Can be 'mean', 'median', 'kde_max'\n            or 'bayes_mvs', or a custom function. If a\n            function, must take a 1D array, and return a\n            single, real number.\n        weights : array-like of length len(analytes)\n            An array of numbers specifying the importance of\n            each analyte considered. Larger number makes the\n            analyte have a greater effect on the optimisation.\n            Default is None.\n        \"\"\"\n        if samples is not None:\n            subset = self.make_subset(samples)\n        samples = self._get_samples(subset)\n\n        if isinstance(analytes, str):\n            analytes = [analytes]\n\n        self.minimal_analytes.update(analytes)\n\n        errs = []\n\n        with self.pbar.set(total=len(samples), desc='Optimising Data selection') as prog:\n            for s in samples:\n                e = self.data[s].signal_optimiser(analytes=analytes, min_points=min_points,\n                                                  threshold_mode=threshold_mode, threshold_mult=threshold_mult,\n                                                  x_bias=x_bias, weights=weights, filt=filt, mode=mode)\n                if e != '':\n                    errs.append(e)\n                prog.update()\n        \n        if len(errs) > 0:\n            print('\\nA Few Problems:\\n' + '\\n'.join(errs) + '\\n\\n  *** Check Optimisation Plots ***')", "response": "This method optimises the signal based on the specified analytes."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nplot the result of signal_optimise.", "response": "def optimisation_plots(self, overlay_alpha=0.5, samples=None, subset=None, **kwargs):\n        \"\"\"\n        Plot the result of signal_optimise.\n\n        `signal_optimiser` must be run first, and the output\n        stored in the `opt` attribute of the latools.D object.\n\n        Parameters\n        ----------\n        d : latools.D object\n            A latools data object.\n        overlay_alpha : float\n            The opacity of the threshold overlays. Between 0 and 1.\n        **kwargs\n            Passed to `tplot`\n        \"\"\"\n        if samples is not None:\n            subset = self.make_subset(samples)\n        samples = self._get_samples(subset)\n\n        outdir=self.report_dir + '/optimisation_plots/'\n        if not os.path.isdir(outdir):\n            os.mkdir(outdir)\n        \n        with self.pbar.set(total=len(samples), desc='Drawing Plots') as prog:\n            for s in samples:\n                figs = self.data[s].optimisation_plot(overlay_alpha, **kwargs)\n                \n                n = 1\n                for f, _ in figs:\n                    if f is not None:\n                        f.savefig(outdir + '/' + s + '_optim_{:.0f}.pdf'.format(n))\n                        plt.close(f)\n                    n += 1\n                prog.update()\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_focus(self, focus_stage=None, samples=None, subset=None):\n        if samples is not None:\n            subset = self.make_subset(samples)\n        \n        if subset is None:\n            subset = 'All_Analyses'\n\n        samples = self._get_samples(subset)\n\n        if focus_stage is None:\n            focus_stage = self.focus_stage\n        else:\n            self.focus_stage = focus_stage\n\n        for s in samples:\n            self.data[s].setfocus(focus_stage)", "response": "Set the focus attribute of the data file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncollect all data from all analytes into a single array.", "response": "def get_focus(self, filt=False, samples=None, subset=None, nominal=False):\n        \"\"\"\n        Collect all data from all samples into a single array.\n        Data from standards is not collected.\n\n        Parameters\n        ----------\n        filt : str, dict or bool\n            Either logical filter expression contained in a str,\n            a dict of expressions specifying the filter string to\n            use for each analyte or a boolean. Passed to `grab_filt`.\n        samples : str or list\n            which samples to get\n        subset : str or int\n            which subset to get\n\n        Returns\n        -------\n        None\n        \"\"\"\n\n        if samples is not None:\n            subset = self.make_subset(samples)\n        \n        samples = self._get_samples(subset)\n\n        # t = 0\n        focus = {'uTime': []}\n        focus.update({a: [] for a in self.analytes})\n\n        for sa in samples:\n            s = self.data[sa]\n            focus['uTime'].append(s.uTime)\n            ind = s.filt.grab_filt(filt)\n            for a in self.analytes:\n                tmp = s.focus[a].copy()\n                tmp[~ind] = np.nan\n                focus[a].append(tmp)\n\n        if nominal:\n            self.focus.update({k: nominal_values(np.concatenate(v)) for k, v, in focus.items()})\n        else:\n            self.focus.update({k: np.concatenate(v) for k, v, in focus.items()})\n\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_gradients(self, analytes=None, win=15, filt=False, samples=None, subset=None, recalc=True):\n        if analytes is None:\n            analytes = self.analytes\n\n        if samples is not None:\n            subset = self.make_subset(samples)\n\n        samples = self._get_samples(subset)\n\n        # check if gradients already calculated\n        if all([self.data[s].grads_calced for s in samples]) and hasattr(self, 'gradients'):\n            if not recalc:\n                print(\"Using existing gradients. Set recalc=True to re-calculate.\")\n                return\n\n        if not hasattr(self, 'gradients'):\n            self.gradients = Bunch()\n\n        # t = 0\n        focus = {'uTime': []}\n        focus.update({a: [] for a in analytes})\n\n        with self.pbar.set(total=len(samples), desc='Calculating Gradients') as prog:\n            for sa in samples:\n                s = self.data[sa]\n                focus['uTime'].append(s.uTime)\n                ind = s.filt.grab_filt(filt)\n                grads = calc_grads(s.uTime, s.focus, keys=analytes, win=win)\n                for a in analytes:\n                    tmp = grads[a]\n                    tmp[~ind] = np.nan\n                    focus[a].append(tmp)\n                    s.grads = tmp\n                s.grads_calced = True\n                prog.update()\n\n        self.gradients.update({k: np.concatenate(v) for k, v, in focus.items()})\n\n        return", "response": "Calculates all gradients for all analytes in the specified set of samples and returns a list of arrays."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nplot a histogram of the gradients in all samples.", "response": "def gradient_histogram(self, analytes=None, win=15, filt=False, bins=None, samples=None, subset=None, recalc=True, ncol=4):\n        \"\"\"\n        Plot a histogram of the gradients in all samples.\n\n        Parameters\n        ----------\n        filt : str, dict or bool\n            Either logical filter expression contained in a str,\n            a dict of expressions specifying the filter string to\n            use for each analyte or a boolean. Passed to `grab_filt`.\n        bins : None or array-like\n            The bins to use in the histogram\n        samples : str or list\n            which samples to get\n        subset : str or int\n            which subset to get\n        recalc : bool\n            Whether to re-calculate the gradients, or use existing gradients.\n\n        Returns\n        -------\n        fig, ax\n        \"\"\"\n        if analytes is None:\n            analytes = [a for a in self.analytes if self.internal_standard not in a]\n        if not hasattr(self, 'gradients'):\n            self.gradients = Bunch()\n\n        ncol = int(ncol)\n        n = len(analytes)\n        nrow = plot.calc_nrow(n, ncol)\n\n        if samples is not None:\n            subset = self.make_subset(samples)\n\n        samples = self._get_samples(subset)\n\n        self.get_gradients(analytes=analytes, win=win, filt=filt, subset=subset, recalc=recalc)\n\n        fig, axs = plt.subplots(nrow, ncol, figsize=[3. * ncol, 2.5 * nrow])\n\n        if not isinstance(axs, np.ndarray):\n            axs = [axs]\n\n        i = 0\n        for a, ax in zip(analytes, axs.flatten()):\n            d = nominal_values(self.gradients[a])\n            d = d[~np.isnan(d)]\n\n            m, u = unitpicker(d, focus_stage=self.focus_stage, denominator=self.internal_standard)\n\n            if bins is None:\n                ibins = np.linspace(*np.percentile(d * m, [1, 99]), 50)\n            else:\n                ibins = bins\n\n            ax.hist(d * m, bins=ibins, color=self.cmaps[a])\n            ax.axvline(0, ls='dashed', lw=1, c=(0,0,0,0.7))\n\n            ax.set_title(a, loc='left')\n            if ax.is_first_col():\n                ax.set_ylabel('N')\n            ax.set_xlabel(u + '/s')\n\n            i += 1\n\n        if i < ncol * nrow:\n            for ax in axs.flatten()[i:]:\n                ax.set_visible(False)\n        \n        fig.tight_layout()\n\n        return fig, axs"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nplots the two analytes against each other.", "response": "def crossplot(self, analytes=None, lognorm=True,\n                  bins=25, filt=False, samples=None,\n                  subset=None, figsize=(12, 12), save=False,\n                  colourful=True, mode='hist2d', **kwargs):\n        \"\"\"\n        Plot analytes against each other.\n\n        Parameters\n        ----------\n        analytes : optional, array_like or str\n            The analyte(s) to plot. Defaults to all analytes.\n        lognorm : bool\n            Whether or not to log normalise the colour scale\n            of the 2D histogram.\n        bins : int\n            The number of bins in the 2D histogram.\n        filt : str, dict or bool\n            Either logical filter expression contained in a str,\n            a dict of expressions specifying the filter string to\n            use for each analyte or a boolean. Passed to `grab_filt`.\n        figsize : tuple\n            Figure size (width, height) in inches.\n        save : bool or str\n            If True, plot is saves as 'crossplot.png', if str plot is\n            saves as str.\n        colourful : bool\n            Whether or not the plot should be colourful :).\n        mode : str\n            'hist2d' (default) or 'scatter'\n\n        Returns\n        -------\n        (fig, axes)\n        \"\"\"\n        if analytes is None:\n            analytes = self.analytes\n        if self.focus_stage in ['ratio', 'calibrated']:\n            analytes = [a for a in analytes if self.internal_standard not in a]\n\n        # sort analytes\n        try:\n            analytes = sorted(analytes, key=lambda x: float(re.findall('[0-9.-]+', x)[0]))\n        except IndexError:\n            analytes = sorted(analytes)\n\n        self.get_focus(filt=filt, samples=samples, subset=subset)\n\n        fig, axes = plot.crossplot(dat=self.focus, keys=analytes, lognorm=lognorm,\n                                   bins=bins, figsize=figsize, colourful=colourful,\n                                   focus_stage=self.focus_stage, cmap=self.cmaps,\n                                   denominator=self.internal_standard, mode=mode)\n\n        if save or isinstance(save, str):\n            if isinstance(save, str):\n                fig.savefig(self.report_dir + '/' + save, dpi=200)            \n            else:\n                fig.savefig(self.report_dir + '/crossplot.png', dpi=200)\n\n        return fig, axes"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nplot the gradients of the analytes against each other.", "response": "def gradient_crossplot(self, analytes=None, win=15, lognorm=True,\n                           bins=25, filt=False, samples=None,\n                           subset=None, figsize=(12, 12), save=False,\n                           colourful=True, mode='hist2d', recalc=True, **kwargs):\n        \"\"\"\n        Plot analyte gradients against each other.\n\n        Parameters\n        ----------\n        analytes : optional, array_like or str\n            The analyte(s) to plot. Defaults to all analytes.\n        lognorm : bool\n            Whether or not to log normalise the colour scale\n            of the 2D histogram.\n        bins : int\n            The number of bins in the 2D histogram.\n        filt : str, dict or bool\n            Either logical filter expression contained in a str,\n            a dict of expressions specifying the filter string to\n            use for each analyte or a boolean. Passed to `grab_filt`.\n        figsize : tuple\n            Figure size (width, height) in inches.\n        save : bool or str\n            If True, plot is saves as 'crossplot.png', if str plot is\n            saves as str.\n        colourful : bool\n            Whether or not the plot should be colourful :).\n        mode : str\n            'hist2d' (default) or 'scatter'\n        recalc : bool\n            Whether to re-calculate the gradients, or use existing gradients.\n\n        Returns\n        -------\n        (fig, axes)\n        \"\"\"\n\n        if analytes is None:\n            analytes = self.analytes\n        if self.focus_stage in ['ratio', 'calibrated']:\n            analytes = [a for a in analytes if self.internal_standard not in a]\n\n        # sort analytes\n        try:\n            analytes = sorted(analytes, key=lambda x: float(re.findall('[0-9.-]+', x)[0]))\n        except IndexError:\n            analytes = sorted(analytes)\n\n        samples = self._get_samples(subset)\n\n        # calculate gradients\n        self.get_gradients(analytes=analytes, win=win, filt=filt, subset=subset, recalc=recalc)\n\n        # self.get_focus(filt=filt, samples=samples, subset=subset)\n        # grads = calc_grads(self.focus.uTime, self.focus, analytes, win)\n\n        fig, axes = plot.crossplot(dat=self.gradients, keys=analytes, lognorm=lognorm,\n                                   bins=bins, figsize=figsize, colourful=colourful,\n                                   focus_stage=self.focus_stage, cmap=self.cmaps,\n                                   denominator=self.internal_standard, mode=mode)\n\n        if save:\n            fig.savefig(self.report_dir + '/g_crossplot.png', dpi=200)\n\n        return fig, axes"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef histograms(self, analytes=None, bins=25, logy=False,\n                   filt=False, colourful=True):\n        \"\"\"\n        Plot histograms of analytes.\n\n        Parameters\n        ----------\n        analytes : optional, array_like or str\n            The analyte(s) to plot. Defaults to all analytes.\n        bins : int\n            The number of bins in each histogram (default = 25)\n        logy : bool\n            If true, y axis is a log scale.\n        filt : str, dict or bool\n            Either logical filter expression contained in a str,\n            a dict of expressions specifying the filter string to\n            use for each analyte or a boolean. Passed to `grab_filt`.\n        colourful : bool\n            If True, histograms are colourful :)\n\n        Returns\n        -------\n        (fig, axes)\n        \"\"\"\n        if analytes is None:\n            analytes = self.analytes\n        if self.focus_stage in ['ratio', 'calibrated']:\n            analytes = [a for a in analytes if self.internal_standard not in a]\n        if colourful:\n            cmap = self.cmaps\n        else:\n            cmap = None\n\n        self.get_focus(filt=filt)\n        fig, axes = plot.histograms(self.focus, keys=analytes,\n                                    bins=bins, logy=logy, cmap=cmap)\n\n        return fig, axes", "response": "Plot histograms of analytes."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef filter_effect(self, analytes=None, stats=['mean', 'std'], filt=True):\n        if analytes is None:\n            analytes = self.analytes\n        if isinstance(analytes, str):\n            analytes = [analytes]\n        \n        # calculate filtered and unfiltered stats\n        self.sample_stats(['La139', 'Ti49'], stats=stats, filt=False)\n        suf = self.stats.copy()\n        self.sample_stats(['La139', 'Ti49'], stats=stats, filt=filt)\n        sf = self.stats.copy()\n        \n        # create dataframe for results\n        cols = []\n        for s in self.stats_calced:\n            cols += ['unfiltered_{:}'.format(s), 'filtered_{:}'.format(s)] \n\n        comp = pd.DataFrame(index=self.samples,\n                            columns=pd.MultiIndex.from_arrays([cols, [None] * len(cols)]))\n\n        # collate stats\n        for k, v in suf.items():\n            vf = sf[k]\n            for i, a in enumerate(v['analytes']):\n                for s in self.stats_calced:\n                    comp.loc[k, ('unfiltered_{:}'.format(s), a)] = v[s][i,0]\n                    comp.loc[k, ('filtered_{:}'.format(s), a)] = vf[s][i,0]\n        comp.dropna(0, 'all', inplace=True)\n        comp.dropna(1, 'all', inplace=True)\n        comp.sort_index(1, inplace=True)\n\n        # calculate filtered/unfiltered ratios\n        rats = []\n        for s in self.stats_calced:\n            rat = comp.loc[:, 'filtered_{:}'.format(s)] / comp.loc[:, 'unfiltered_{:}'.format(s)]\n            rat.columns = pd.MultiIndex.from_product([['{:}_ratio'.format(s)], rat.columns])\n            rats.append(rat)\n        \n        # join it all up\n        comp = comp.join(pd.concat(rats, 1))\n        comp.sort_index(1, inplace=True)\n        \n        return comp.loc[:, (pd.IndexSlice[:], pd.IndexSlice[analytes])]", "response": "Filter the effect of the active filter."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nplots analytes and samples as function of time.", "response": "def trace_plots(self, analytes=None, samples=None, ranges=False,\n                    focus=None, outdir=None, filt=None, scale='log',\n                    figsize=[10, 4], stats=False, stat='nanmean',\n                    err='nanstd', subset='All_Analyses'):\n        \"\"\"\n        Plot analytes as a function of time.\n\n        Parameters\n        ----------\n        analytes : optional, array_like or str\n            The analyte(s) to plot. Defaults to all analytes.\n        samples: optional, array_like or str\n            The sample(s) to plot. Defaults to all samples.\n        ranges : bool\n            Whether or not to show the signal/backgroudn regions\n            identified by 'autorange'.\n        focus : str\n            The focus 'stage' of the analysis to plot. Can be\n            'rawdata', 'despiked':, 'signal', 'background',\n            'bkgsub', 'ratios' or 'calibrated'.\n        outdir : str\n            Path to a directory where you'd like the plots to be\n            saved. Defaults to 'reports/[focus]' in your data directory.\n        filt : str, dict or bool\n            Either logical filter expression contained in a str,\n            a dict of expressions specifying the filter string to\n            use for each analyte or a boolean. Passed to `grab_filt`.\n        scale : str\n            If 'log', plots the data on a log scale.\n        figsize : array_like\n            Array of length 2 specifying figure [width, height] in\n            inches.\n        stats : bool\n            Whether or not to overlay the mean and standard deviations\n            for each trace.\n        stat, err: str\n            The names of the statistic and error components to plot.\n            Deafaults to 'nanmean' and 'nanstd'.\n\n\n        Returns\n        -------\n        None\n        \"\"\"\n        if focus is None:\n            focus = self.focus_stage\n        if outdir is None:\n            outdir = self.report_dir + '/' + focus\n        if not os.path.isdir(outdir):\n            os.mkdir(outdir)\n\n        # if samples is not None:\n        #     subset = self.make_subset(samples)\n\n        if subset is not None:\n            samples = self._get_samples(subset)\n        elif samples is None:\n            samples = self.subsets['All_Analyses']\n        elif isinstance(samples, str):\n            samples = [samples]\n        \n        with self.pbar.set(total=len(samples), desc='Drawing Plots') as prog:\n            for s in samples:\n                f, a = self.data[s].tplot(analytes=analytes, figsize=figsize,\n                                        scale=scale, filt=filt,\n                                        ranges=ranges, stats=stats,\n                                        stat=stat, err=err, focus_stage=focus)\n                # ax = fig.axes[0]\n                # for l, u in s.sigrng:\n                #     ax.axvspan(l, u, color='r', alpha=0.1)\n                # for l, u in s.bkgrng:\n                #     ax.axvspan(l, u, color='k', alpha=0.1)\n                f.savefig(outdir + '/' + s + '_traces.pdf')\n                # TODO: on older(?) computers raises\n                # 'OSError: [Errno 24] Too many open files'\n                plt.close(f)\n                prog.update()\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nplotting the gradients of the analytes in the specified directory.", "response": "def gradient_plots(self, analytes=None, win=15, samples=None, ranges=False,\n                       focus=None, outdir=None,\n                       figsize=[10, 4], subset='All_Analyses'):\n        \"\"\"\n        Plot analyte gradients as a function of time.\n\n        Parameters\n        ----------\n        analytes : optional, array_like or str\n            The analyte(s) to plot. Defaults to all analytes.\n        samples: optional, array_like or str\n            The sample(s) to plot. Defaults to all samples.\n        ranges : bool\n            Whether or not to show the signal/backgroudn regions\n            identified by 'autorange'.\n        focus : str\n            The focus 'stage' of the analysis to plot. Can be\n            'rawdata', 'despiked':, 'signal', 'background',\n            'bkgsub', 'ratios' or 'calibrated'.\n        outdir : str\n            Path to a directory where you'd like the plots to be\n            saved. Defaults to 'reports/[focus]' in your data directory.\n        filt : str, dict or bool\n            Either logical filter expression contained in a str,\n            a dict of expressions specifying the filter string to\n            use for each analyte or a boolean. Passed to `grab_filt`.\n        scale : str\n            If 'log', plots the data on a log scale.\n        figsize : array_like\n            Array of length 2 specifying figure [width, height] in\n            inches.\n        stats : bool\n            Whether or not to overlay the mean and standard deviations\n            for each trace.\n        stat, err: str\n            The names of the statistic and error components to plot.\n            Deafaults to 'nanmean' and 'nanstd'.\n\n\n        Returns\n        -------\n        None\n        \"\"\"\n        if focus is None:\n            focus = self.focus_stage\n        if outdir is None:\n            outdir = self.report_dir + '/' + focus + '_gradient'\n        if not os.path.isdir(outdir):\n            os.mkdir(outdir)\n\n        # if samples is not None:\n        #     subset = self.make_subset(samples)\n\n        if subset is not None:\n            samples = self._get_samples(subset)\n        elif samples is None:\n            samples = self.subsets['All_Analyses']\n        elif isinstance(samples, str):\n            samples = [samples]\n\n        with self.pbar.set(total=len(samples), desc='Drawing Plots') as prog:\n            for s in samples:\n                f, a = self.data[s].gplot(analytes=analytes, win=win, figsize=figsize,\n                                        ranges=ranges, focus_stage=focus)\n                # ax = fig.axes[0]\n                # for l, u in s.sigrng:\n                #     ax.axvspan(l, u, color='r', alpha=0.1)\n                # for l, u in s.bkgrng:\n                #     ax.axvspan(l, u, color='k', alpha=0.1)\n                f.savefig(outdir + '/' + s + '_gradients.pdf')\n                # TODO: on older(?) computers raises\n                # 'OSError: [Errno 24] Too many open files'\n                plt.close(f)\n                prog.update()\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nplot filter reports for all analytes in the name.", "response": "def filter_reports(self, analytes, filt_str='all', nbin=5, samples=None,\n                       outdir=None, subset='All_Samples'):\n        \"\"\"\n        Plot filter reports for all filters that contain ``filt_str``\n        in the name.\n        \"\"\"\n        if outdir is None:\n            outdir = self.report_dir + '/filters/' + filt_str\n            if not os.path.isdir(self.report_dir + '/filters'):\n                os.mkdir(self.report_dir + '/filters')\n        if not os.path.isdir(outdir):\n            os.mkdir(outdir)\n\n        if samples is not None:\n            subset = self.make_subset(samples)\n\n        samples = self._get_samples(subset)\n\n        with self.pbar.set(total=len(samples), desc='Drawing Plots') as prog:\n            for s in samples:\n                _ = self.data[s].filter_report(filt=filt_str,\n                                            analytes=analytes,\n                                            savedir=outdir,\n                                            nbin=nbin)\n                prog.update()\n            # plt.close(fig)\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating sample statistics for the specified analytes.", "response": "def sample_stats(self, analytes=None, filt=True,\n                     stats=['mean', 'std'],\n                     eachtrace=True, csf_dict={}):\n        \"\"\"\n        Calculate sample statistics.\n\n        Returns samples, analytes, and arrays of statistics\n        of shape (samples, analytes). Statistics are calculated\n        from the 'focus' data variable, so output depends on how\n        the data have been processed.\n\n        Included stat functions:\n\n        * :func:`~latools.stat_fns.mean`: arithmetic mean\n        * :func:`~latools.stat_fns.std`: arithmetic standard deviation\n        * :func:`~latools.stat_fns.se`: arithmetic standard error\n        * :func:`~latools.stat_fns.H15_mean`: Huber mean (outlier removal)\n        * :func:`~latools.stat_fns.H15_std`: Huber standard deviation (outlier removal)\n        * :func:`~latools.stat_fns.H15_se`: Huber standard error (outlier removal)\n\n        Parameters\n        ----------\n        analytes : optional, array_like or str\n            The analyte(s) to calculate statistics for. Defaults to\n            all analytes.\n        filt : str, dict or bool\n            Either logical filter expression contained in a str,\n            a dict of expressions specifying the filter string to\n            use for each analyte or a boolean. Passed to `grab_filt`.\n        stats : array_like\n            take a single array_like input, and return a single statistic. \n            list of functions or names (see above) or functions that\n            Function should be able to cope with NaN values.\n        eachtrace : bool\n            Whether to calculate the statistics for each analysis\n            spot individually, or to produce per - sample means.\n            Default is True.\n\n        Returns\n        -------\n        None\n            Adds dict to analyse object containing samples, analytes and\n            functions and data.\n        \"\"\"\n        if analytes is None:\n            analytes = self.analytes\n        elif isinstance(analytes, str):\n            analytes = [analytes]\n\n        self.stats = Bunch()\n\n        self.stats_calced = []\n        stat_fns = Bunch()\n\n        stat_dict = {'mean': np.nanmean,\n                     'std': np.nanstd,\n                     'nanmean': np.nanmean,\n                     'nanstd': np.nanstd,\n                     'se': stderr,\n                     'H15_mean': H15_mean,\n                     'H15_std': H15_std,\n                     'H15_se': H15_se}\n\n        for s in stats:\n            if isinstance(s, str):\n                if s in stat_dict.keys():\n                    self.stats_calced.append(s)\n                    stat_fns[s] = stat_dict[s]\n                if s in csf_dict.keys():\n                    self.stats_calced.append(s)\n                    exec(csf_dict[s])\n                    stat_fns[s] = eval(s)\n            elif callable(s):\n                self.stats_calced.append(s.__name__)\n                stat_fns[s.__name__] = s\n                if not hasattr(self, 'custom_stat_functions'):\n                    self.custom_stat_functions = ''\n                self.custom_stat_functions += inspect.getsource(s) + '\\n\\n\\n\\n'\n\n        # calculate stats for each sample\n        with self.pbar.set(total=len(self.samples), desc='Calculating Stats') as prog:\n            for s in self.samples:\n                if self.srm_identifier not in s:\n                    self.data[s].sample_stats(analytes, filt=filt,\n                                            stat_fns=stat_fns,\n                                            eachtrace=eachtrace)\n\n                    self.stats[s] = self.data[s].stats\n                prog.update()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef statplot(self, analytes=None, samples=None, figsize=None,\n                 stat='mean', err='std', subset=None):\n        \"\"\"\n        Function for visualising per-ablation and per-sample means.\n\n        Parameters\n        ----------\n        analytes : str or iterable\n            Which analyte(s) to plot\n        samples : str or iterable\n            Which sample(s) to plot\n        figsize : tuple\n            Figure (width, height) in inches\n        stat : str\n            Which statistic to plot. Must match\n            the name of the functions used in \n            'sample_stats'.\n        err : str\n            Which uncertainty to plot.\n        subset : str\n            Which subset of samples to plot.\n        \"\"\"\n        if not hasattr(self, 'stats'):\n            self.sample_stats()\n\n        if analytes is None:\n                analytes = self.analytes\n        elif isinstance(analytes, str):\n            analytes = [analytes]\n\n        if samples is not None:\n            subset = self.make_subset(samples)\n\n        samples = self._get_samples(subset)\n\n        analytes = [a for a in analytes if a !=\n                    self.internal_standard]\n\n        if figsize is None:\n            figsize = (1.5 * len(self.stats), 3 * len(analytes))\n\n        fig, axs = plt.subplots(len(analytes), 1, figsize=figsize)\n\n        for ax, an in zip(axs, analytes):\n            i = 0\n            stab = self.getstats()\n            m, u = unitpicker(np.percentile(stab.loc[:, an].dropna(), 25), 0.1,\n                              focus_stage='calibrated',\n                              denominator=self.internal_standard)\n            for s in samples:\n                if self.srm_identifier not in s:\n                    d = self.stats[s]\n                    if d[stat].ndim == 2:\n                        n = d[stat].shape[-1]\n                        x = np.linspace(i - .1 * n / 2, i + .1 * n / 2, n)\n                    else:\n                        x = [i]\n                    a_ind = d['analytes'] == an\n\n                    # plot individual ablations with error bars\n                    ax.errorbar(x, d[stat][a_ind][0] * m,\n                                yerr=d[err][a_ind][0] * m,\n                                marker='o', color=self.cmaps[an],\n                                lw=0, elinewidth=1)\n\n                    ax.set_ylabel('%s / %s (%s )' % (pretty_element(an),\n                                                     pretty_element(self.internal_standard),\n                                                     u))\n\n                    # plot whole - sample mean\n                    if len(x) > 1:\n                        # mean calculation with error propagation?\n                        # umean = un.uarray(d[stat][a_ind][0] * m, d[err][a_ind][0] * m).mean()\n                        # std = un.std_devs(umean)\n                        # mean = un.nominal_values(umean)\n                        mean = np.nanmean(d[stat][a_ind][0] * m)\n                        std = np.nanstd(d[stat][a_ind][0] * m)\n                        ax.plot(x, [mean] * len(x), c=self.cmaps[an], lw=2)\n                        ax.fill_between(x, [mean + std] * len(x),\n                                        [mean - std] * len(x),\n                                        lw=0, alpha=0.2, color=self.cmaps[an])\n\n                    # highlight each sample\n                    if i % 2 == 1:\n                        ax.axvspan(i - .5, i + .5, color=(0, 0, 0, 0.05), lw=0)\n\n                    i += 1\n\n            ax.set_xticks(np.arange(0, len(self.stats)))\n            ax.set_xlim(-0.5, len(self.stats) - .5)\n\n            ax.set_xticklabels(samples)\n\n        return fig, ax", "response": "Function for visualising per - abation and per - sample means."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getstats(self, save=True, filename=None, samples=None, subset=None, ablation_time=False):\n        slst = []\n\n        if samples is not None:\n            subset = self.make_subset(samples)\n\n        samples = self._get_samples(subset)\n\n        for s in self.stats_calced:\n            for nm in [n for n in samples if self.srm_identifier\n                       not in n]:\n                if self.stats[nm][s].ndim == 2:\n                    # make multi - index\n                    reps = np.arange(self.stats[nm][s].shape[-1])\n                    ss = np.array([s] * reps.size)\n                    nms = np.array([nm] * reps.size)\n                    # make sub - dataframe\n                    stdf = pd.DataFrame(self.stats[nm][s].T,\n                                        columns=self.stats[nm]['analytes'],\n                                        index=[ss, nms, reps])\n                    stdf.index.set_names(['statistic', 'sample', 'rep'],\n                                         inplace=True)\n                else:\n                    stdf = pd.DataFrame(self.stats[nm][s],\n                                        index=self.stats[nm]['analytes'],\n                                        columns=[[s], [nm]]).T\n\n                    stdf.index.set_names(['statistic', 'sample'],\n                                         inplace=True)\n                slst.append(stdf)\n        out = pd.concat(slst)\n\n        if ablation_time:\n            ats = self.ablation_times(samples=samples, subset=subset)\n            ats['statistic'] = 'nanmean'\n            ats.set_index('statistic', append=True, inplace=True)\n            ats = ats.reorder_levels(['statistic', 'sample', 'rep'])\n\n            out = out.join(ats)\n\n        out.drop(self.internal_standard, 1, inplace=True)\n\n        if save:\n            if filename is None:\n                filename = 'stat_export.csv'\n            out.to_csv(self.export_dir + '/' + filename)\n\n        self.stats_df = out\n\n        return out", "response": "Return pandas dataframe of all sample statistics."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nexport traces from all analytes to a single file.", "response": "def _minimal_export_traces(self, outdir=None, analytes=None,\n                               samples=None, subset='All_Analyses'):\n        \"\"\"\n        Used for exporting minimal dataset. DON'T USE.\n        \"\"\"\n        if analytes is None:\n            analytes = self.analytes\n        elif isinstance(analytes, str):\n            analytes = [analytes]\n\n        if samples is not None:\n            subset = self.make_subset(samples)\n\n        samples = self._get_samples(subset)\n\n        focus_stage = 'rawdata'\n        # ud = 'counts'\n\n        if not os.path.isdir(outdir):\n            os.mkdir(outdir)\n\n        for s in samples:\n            d = self.data[s].data[focus_stage]\n            out = Bunch()\n\n            for a in analytes:\n                out[a] = d[a]\n\n            out = pd.DataFrame(out, index=self.data[s].Time)\n            out.index.name = 'Time'\n\n            d = dateutil.parser.parse(self.data[s].meta['date'])\n            header = ['# Minimal Reproduction Dataset Exported from LATOOLS on %s' %\n                      (time.strftime('%Y:%m:%d %H:%M:%S')),\n                      \"# Analysis described in '../analysis.lalog'\",\n                      '# Run latools.reproduce to import analysis.',\n                      '#',\n                      '# Sample: %s' % (s),\n                      '# Analysis Time: ' + d.strftime('%Y-%m-%d %H:%M:%S')]\n\n            header = '\\n'.join(header) + '\\n'\n\n            csv = out.to_csv()\n\n            with open('%s/%s.csv' % (outdir, s), 'w') as f:\n                f.write(header)\n                f.write(csv)\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfunctioning to export raw data from the main - dir - name_export directory.", "response": "def export_traces(self, outdir=None, focus_stage=None, analytes=None,\n                      samples=None, subset='All_Analyses', filt=False, zip_archive=False):\n        \"\"\"\n        Function to export raw data.\n\n        Parameters\n        ----------\n        outdir : str\n            directory to save toe traces. Defaults to 'main-dir-name_export'.\n        focus_stage : str\n            The name of the analysis stage to export.\n\n            * 'rawdata': raw data, loaded from csv file.\n            * 'despiked': despiked data.\n            * 'signal'/'background': isolated signal and background data.\n              Created by self.separate, after signal and background\n              regions have been identified by self.autorange.\n            * 'bkgsub': background subtracted data, created by \n              self.bkg_correct\n            * 'ratios': element ratio data, created by self.ratio.\n            * 'calibrated': ratio data calibrated to standards, created by self.calibrate.\n\n            Defaults to the most recent stage of analysis.\n        analytes : str or array - like\n            Either a single analyte, or list of analytes to export.\n            Defaults to all analytes.\n        samples : str or array - like\n            Either a single sample name, or list of samples to export.\n            Defaults to all samples.\n        filt : str, dict or bool\n            Either logical filter expression contained in a str,\n            a dict of expressions specifying the filter string to\n            use for each analyte or a boolean. Passed to `grab_filt`.\n        \"\"\"\n        if analytes is None:\n            analytes = self.analytes\n        elif isinstance(analytes, str):\n            analytes = [analytes]\n\n        if samples is not None:\n            subset = self.make_subset(samples)\n\n        samples = self._get_samples(subset)\n\n        if focus_stage is None:\n            focus_stage = self.focus_stage\n\n        if focus_stage in ['ratios', 'calibrated']:\n            analytes = [a for a in analytes if a != self.internal_standard]\n\n        if outdir is None:\n            outdir = os.path.join(self.export_dir, 'trace_export')\n\n        ud = {'rawdata': 'counts',\n              'despiked': 'counts',\n              'bkgsub': 'background corrected counts',\n              'ratios': 'counts/count {:s}',\n              'calibrated': 'mol/mol {:s}'}\n        if focus_stage in ['ratios', 'calibrated']:\n            ud[focus_stage] = ud[focus_stage].format(self.internal_standard)\n\n        if not os.path.isdir(outdir):\n            os.mkdir(outdir)\n\n        for s in samples:\n            d = self.data[s].data[focus_stage]\n            ind = self.data[s].filt.grab_filt(filt)\n            out = Bunch()\n\n            for a in analytes:\n                out[a] = nominal_values(d[a][ind])\n                if focus_stage not in ['rawdata', 'despiked']:\n                    out[a + '_std'] = std_devs(d[a][ind])\n                    out[a + '_std'][out[a + '_std'] == 0] = np.nan\n\n            out = pd.DataFrame(out, index=self.data[s].Time[ind])\n            out.index.name = 'Time'\n\n            header = ['# Sample: %s' % (s),\n                      '# Data Exported from LATOOLS on %s' %\n                      (time.strftime('%Y:%m:%d %H:%M:%S')),\n                      '# Processed using %s configuration' % (self.config['config']),\n                      '# Analysis Stage: %s' % (focus_stage),\n                      '# Unit: %s' % ud[focus_stage]]\n\n            header = '\\n'.join(header) + '\\n'\n\n            csv = out.to_csv()\n\n            with open('%s/%s_%s.csv' % (outdir, s, focus_stage), 'w') as f:\n                f.write(header)\n                f.write(csv)\n        \n        if zip_archive:\n            utils.zipdir(outdir, delete=True)\n\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef save_log(self, directory=None, logname=None, header=None):\n        if directory is None:\n            directory = self.export_dir\n        if not os.path.isdir(directory):\n            directory = os.path.dirname(directory)\n\n        if logname is None:\n            logname = 'analysis.lalog'\n\n        if header is None:\n            header = self._log_header()\n\n        loc = logging.write_logfile(self.log, header, \n                                    os.path.join(directory, logname))\n        \n        return loc", "response": "Save the log file in specified location."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nexporting a minimal reproduction dataset and a minimal reproduction dataset.", "response": "def minimal_export(self, target_analytes=None, path=None):\n        \"\"\"\n        Exports a analysis parameters, standard info and a minimal dataset,\n        which can be imported by another user.\n\n        Parameters\n        ----------\n        target_analytes : str or iterable\n            Which analytes to include in the export. If specified, the export\n            will contain these analytes, and all other analytes used during\n            data processing (e.g. during filtering). If not specified, \n            all analytes are exported.\n        path : str\n            Where to save the minimal export. \n            If it ends with .zip, a zip file is created.\n            If it's a folder, all data are exported to a folder.\n        \"\"\"\n        if target_analytes is None:\n            target_analytes = self.analytes\n        if isinstance(target_analytes, str):\n            target_analytes = [target_analytes]\n\n        self.minimal_analytes.update(target_analytes)\n        zip_archive = False\n\n        # set up data path\n        if path is None:\n            path = self.export_dir + '/minimal_export.zip'\n        if path.endswith('.zip'):\n            path = path.replace('.zip', '')\n            zip_archive = True\n        if not os.path.isdir(path):\n            os.mkdir(path)\n\n        # export data\n        self._minimal_export_traces(path + '/data', analytes=self.minimal_analytes)\n\n         # define analysis_log header\n        log_header = ['# Minimal Reproduction Dataset Exported from LATOOLS on %s' %\n                      (time.strftime('%Y:%m:%d %H:%M:%S')),\n                      'data_folder :: ./data/']\n                      \n        if hasattr(self, 'srmdat'):\n            log_header.append('srm_table :: ./srm.table')\n\n            # export srm table\n            els = np.unique([re.sub('[0-9]', '', a) for a in self.minimal_analytes])\n            srmdat = []\n            for e in els:\n                srmdat.append(self.srmdat.loc[self.srmdat.element == e, :])\n            srmdat = pd.concat(srmdat)\n\n            with open(path + '/srm.table', 'w') as f:\n                f.write(srmdat.to_csv())\n\n        # save custom functions (of defined)\n        if hasattr(self, 'custom_stat_functions'):\n            with open(path + '/custom_stat_fns.py', 'w') as f:\n                f.write(self.custom_stat_functions)\n            log_header.append('custom_stat_functions :: ./custom_stat_fns.py')\n\n        log_header.append('# Analysis Log Start: \\n')\n\n        # format sample_stats correctly\n        lss = [(i, l) for i, l in enumerate(self.log) if 'sample_stats' in l]\n        rep = re.compile(\"(.*'stats': )(\\[.*?\\])(.*)\")\n        for i, l in lss:\n            self.log[i] = rep.sub(r'\\1' + str(self.stats_calced) + r'\\3', l)\n\n        # save log\n        self.save_log(path, 'analysis.lalog', header=log_header)\n\n        if zip_archive:\n            utils.zipdir(directory=path, delete=True)\n        \n        return"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef by_regex(file, outdir=None, split_pattern=None, global_header_rows=0, fname_pattern=None, trim_tail_lines=0, trim_head_lines=0):\n    # create output sirectory\n    if outdir is None:\n        outdir = os.path.join(os.path.dirname(file), 'split')\n    if not os.path.exists(outdir):\n        os.mkdir(outdir)\n    \n    # read input file\n    with open(file, 'r') as f:\n        lines = f.readlines()\n    \n    # get file extension\n    extension = os.path.splitext(file)[-1]\n    \n    # grab global header rows\n    global_header = lines[:global_header_rows]\n\n    # find indices of lines containing split_pattern\n    starts = []\n    for i, line in enumerate(lines):\n        if re.search(split_pattern, line):\n            starts.append(i)    \n    starts.append(len(lines))  # get length of lines\n\n    # split lines into segments based on positions of regex\n    splits = {}\n    for i in range(len(starts) - 1):\n        m = re.search(fname_pattern, lines[starts[i]])\n        if m:\n            fname = m.groups()[0].strip()\n        else:\n            fname = 'no_name_{:}'.format(i)\n\n        splits[fname] = global_header + lines[starts[i]:starts[i+1]][trim_head_lines:trim_tail_lines]\n    \n    # write files\n    print('Writing files to: {:}'.format(outdir))\n    for k, v in splits.items():\n        fname = (k + extension).replace(' ', '_')\n        with open(os.path.join(outdir, fname), 'w') as f:\n            f.writelines(v)\n        print('  {:}'.format(fname))\n    \n    print('Done.')\n\n    return outdir", "response": "Splits one long analysis file into multiple smaller ones."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef long_file(data_file, dataformat, sample_list, savedir=None, srm_id=None, **autorange_args):\n    if isinstance(sample_list, str):\n        if os.path.exists(sample_list):\n            sample_list = np.genfromtxt(sample_list, dtype=str)\n        else:\n            raise ValueError('File {} not found.')\n    elif not isinstance(sample_list, (list, np.ndarray)):\n        raise ValueError('sample_list should be an array_like or a file.')\n        \n    if srm_id is not None:\n        srm_replace = []\n        for s in sample_list:\n            if srm_id in s:\n                s = srm_id\n            srm_replace.append(s)\n        sample_list = srm_replace\n                \n    _, _, dat, meta = read_data(data_file, dataformat=dataformat, name_mode='file')\n    \n    if 'date' in meta:\n        d = dateutil.parser.parse(meta['date'])\n    else:\n        d = datetime.datetime.now()\n    # autorange\n    bkg, sig, trn, _ = autorange(dat['Time'], dat['total_counts'], **autorange_args)\n    \n    ns = np.zeros(sig.size)\n    ns[sig] = np.cumsum((sig ^ np.roll(sig, 1)) & sig)[sig]\n    \n    n = int(max(ns))\n    \n    if len(sample_list) != n:\n        warn('Length of sample list does not match number of ablations in file.\\n' + \n             'We will continue, but please make sure the assignments are correct.')\n    \n    # calculate split boundaries\n    bounds = []\n    lower = 0\n    sn = 0\n    next_sample = ''\n    for ni in range(n-1):\n        sample = sample_list[sn]\n        next_sample = sample_list[sn + 1]\n                \n        if sample != next_sample:\n            current_end = np.argwhere(dat['Time'] == dat['Time'][ns == ni + 1].max())[0]\n            next_start = np.argwhere(dat['Time'] == dat['Time'][ns == ni + 2].min())[0]\n            upper = (current_end + next_start) // 2\n\n            bounds.append((sample, (int(lower), int(upper))))\n\n            lower = upper + 1\n\n        sn += 1\n\n    bounds.append((sample_list[-1], (int(upper) + 1, len(ns))))\n\n    # split up data\n    sections = {}\n    seen = {}\n    for s, (lo, hi) in bounds:\n        if s not in seen:\n            seen[s] = 0\n        else:\n            seen[s] += 1\n            s += '_{}'.format(seen[s])\n        sections[s] = {'oTime': dat['Time'][lo:hi]}\n        sections[s]['Time'] = sections[s]['oTime'] - np.nanmin(sections[s]['oTime'])\n        sections[s]['rawdata'] = {}\n        for k, v in dat['rawdata'].items():\n            sections[s]['rawdata'][k] = v[lo:hi]\n        sections[s]['starttime'] = d + datetime.timedelta(seconds=np.nanmin(sections[s]['oTime']))\n    \n    # save output\n    if savedir is None:\n        savedir = os.path.join(os.path.dirname(os.path.abspath(data_file)), os.path.splitext(os.path.basename(data_file))[0] + '_split')\n    if not os.path.isdir(savedir):\n        os.makedirs(savedir)\n    \n    header = ['# Long data file split by latools on {}'.format(datetime.datetime.now().strftime('%Y:%m:%d %H:%M:%S'))]\n    if 'date' not in meta:\n        header.append('# Warning: No date specified in file - Analysis Times are date file was split. ')\n    else:\n        header.append('# ')\n        header.append('# ')\n        header.append('# ')\n    \n    flist = [savedir]\n    for s, dat in sections.items():\n        iheader = header.copy()\n        iheader.append('# Sample: {}'.format(s))\n        iheader.append('# Analysis Time: {}'.format(dat['starttime'].strftime('%Y-%m-%d %H:%M:%S')))\n    \n        iheader = '\\n'.join(iheader) + '\\n'\n        \n        out = pd.DataFrame({analyte_2_namemass(k): v for k, v in dat['rawdata'].items()}, index=dat['Time'])\n        out.index.name = 'Time'\n        csv = out.to_csv()\n        \n        with open('{}/{}.csv'.format(savedir, s), 'w') as f:\n            f.write(iheader)\n            f.write(csv)\n        flist.append('   {}.csv'.format(s))\n    \n    print(\"File split into {} sections.\\n Saved to: {}\\n\\n Import using the 'REPRODUCE' configuration.\".format(n, '\\n'.join(flist)))\n    return None", "response": "Read a file and return a list of all possible long ablations."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fold_map(self, fa: F[A], z: B, f: Callable[[A], B], g: Callable[[Z, B], Z]=operator.add) -> Z:\n        ''' map `f` over the traversable, then fold over the result\n        using the supplied initial element `z` and operation `g`,\n        defaulting to addition for the latter.\n        '''\n        mapped = Functor.fatal(type(fa)).map(fa, f)\n        return self.fold_left(mapped)(z)(g)", "response": "fold over the traversable then fold over the result\n        using the supplied initial element z and operation g."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pca_calc(nc, d):\n    \n    # check for and remove nans\n    ind = ~np.apply_along_axis(any, 1, np.isnan(d))\n\n    if any(~ind):\n        pcs = np.full((d.shape[0], nc), np.nan)\n        d = d[ind, :]\n\n    pca = PCA(nc).fit(d)\n    \n    if any(~ind):\n        pcs[ind, :] = pca.transform(d)\n    else:\n        pcs = pca.transform(d)\n    \n    return pca, pcs", "response": "Calculates the pca of d."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pca_plot(pca, dt, xlabs=None, mode='scatter', lognorm=True):\n    \n    nc = pca.n_components\n    f = np.arange(pca.n_features_)\n    cs = list(itertools.combinations(range(nc), 2))\n    \n    ind = ~np.apply_along_axis(any, 1, np.isnan(dt))\n\n    cylim = (pca.components_.min(), pca.components_.max())\n    yd = cylim[1] - cylim[0]\n    \n    # Make figure\n    fig, axs = plt.subplots(nc, nc, figsize=[3 * nc, nc * 3], tight_layout=True)\n            \n    for x, y in zip(*np.triu_indices(nc)):\n        if x == y:\n            tax = axs[x, y]\n            tax.bar(f, pca.components_[x], 0.8)\n            tax.set_xticks([])\n            tax.axhline(0, zorder=-1, c=(0,0,0,0.6))\n\n            # labels            \n            tax.set_ylim(cylim[0] - 0.2 * yd,\n                         cylim[1] + 0.2 * yd)\n\n            for xi, yi, lab in zip(f, pca.components_[x], xlabs):\n                if yi > 0:\n                    yo = yd * 0.03\n                    va = 'bottom'\n                else:\n                    yo = yd * -0.02\n                    va = 'top'\n\n                tax.text(xi, yi + yo, lab, ha='center', va=va, rotation=90, fontsize=8)\n\n        else:\n            xv = dt[ind, x]\n            yv = dt[ind, y]\n\n            if mode == 'scatter':\n                axs[x, y].scatter(xv, yv, alpha=0.2)\n                axs[y, x].scatter(yv, xv, alpha=0.2)\n            if mode == 'hist2d':\n                if lognorm:\n                    norm = mpl.colors.LogNorm()\n                else:\n                    norm = None\n                axs[x, y].hist2d(xv, yv, 50, cmap=plt.cm.Blues, norm=norm)\n                axs[y, x].hist2d(yv, xv, 50, cmap=plt.cm.Blues, norm=norm)\n\n        if x == 0:\n            axs[y, x].set_ylabel('PC{:.0f}'.format(y + 1))\n        if y == nc - 1:\n            axs[y, x].set_xlabel('PC{:.0f}'.format(x + 1))\n        \n    return fig, axs, xv, yv", "response": "Plots a fitted PCA and all components."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef calc_windows(fn, s, min_points):\n    max_points = np.sum(~np.isnan(s))\n    n_points = max_points - min_points\n\n    out = np.full((n_points, s.size), np.nan)\n\n    # skip nans, for speed\n    ind = ~np.isnan(s)\n    s = s[ind]\n\n    for i, w in enumerate(range(min_points, s.size)):\n        r = rolling_window(s, w, pad=np.nan)\n        out[i, ind] = np.apply_along_axis(fn, 1, r)\n\n    return out", "response": "Calculate the number of windows in a set of contiguous regions."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalculating the mean and std of a window.", "response": "def calc_window_mean_std(s, min_points, ind=None):\n    \"\"\"\n    Apply fn to all contiguous regions in s that have at least min_points.\n    \"\"\"\n    max_points = np.sum(~np.isnan(s))\n    n_points = max_points - min_points\n\n    mean = np.full((n_points, s.size), np.nan)\n    std = np.full((n_points, s.size), np.nan)\n\n    # skip nans, for speed\n    if ind is None:\n        ind = ~np.isnan(s)\n    else:\n        ind = ind & ~np.isnan(s)\n    s = s[ind]\n\n    for i, w in enumerate(range(min_points, s.size)):\n        r = rolling_window(s, w, pad=np.nan)\n        mean[i, ind] = r.sum(1) / w\n        std[i, ind] = (((r - mean[i, ind][:, np.newaxis])**2).sum(1) / (w - 1))**0.5\n        # mean[i, ind] = np.apply_along_axis(np.nanmean, 1, r)\n        # std[i, ind] = np.apply_along_axis(np.nanstd, 1, r)\n\n    return mean, std"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef bayes_scale(s):\n    if sum(~np.isnan(s)) > 1:\n        bm, bv, bs = bayes_mvs(s[~np.isnan(s)])\n        return (s - bm.statistic) / bs.statistic\n    else:\n        return np.full(s.shape, np.nan)", "response": "Scale a sequence of data points using bayes_kvm statistics."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncomputing the median scaling of a sequence of log entries.", "response": "def median_scaler(s):\n    \"\"\"\n    Remove median, divide by IQR.\n    \"\"\"\n    if sum(~np.isnan(s)) > 2:\n        ss = s[~np.isnan(s)]\n        median = np.median(ss)\n        IQR = np.diff(np.percentile(ss, [25, 75]))\n        return (s - median) / IQR\n    else:\n        return np.full(s.shape, np.nan)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef signal_optimiser(d, analytes, min_points=5,\n                     threshold_mode='kde_first_max',\n                     threshold_mult=1., x_bias=0,\n                     weights=None, ind=None, mode='minimise'):\n    \"\"\"\n    Optimise data selection based on specified analytes.\n\n    Identifies the longest possible contiguous data region in\n    the signal where the relative standard deviation (std) and \n    concentration of all analytes is minimised.\n\n    Optimisation is performed via a grid search of all possible\n    contiguous data regions. For each region, the mean std and\n    mean scaled analyte concentration ('amplitude') are calculated. \n    \n    The size and position of the optimal data region are identified \n    using threshold std and amplitude values. Thresholds are derived\n    from all calculated stds and amplitudes using the method specified\n    by `threshold_mode`. For example, using the 'kde_max' method, a\n    probability density function (PDF) is calculated for std and\n    amplitude values, and the threshold is set as the maximum of the\n    PDF. These thresholds are then used to identify the size and position\n    of the longest contiguous region where the std is below the threshold, \n    and the amplitude is either below the threshold.\n\n    All possible regions of the data that have at least\n    `min_points` are considered.\n\n    For a graphical demonstration of the action of signal_optimiser, \n    use `optimisation_plot`. \n\n    Parameters\n    ----------\n    d : latools.D object\n        An latools data object.\n    analytes : str or array-like\n        Which analytes to consider.\n    min_points : int\n        The minimum number of contiguous points to\n        consider.\n    threshold_mode : str\n        The method used to calculate the optimisation\n        thresholds. Can be 'mean', 'median', 'kde_max'\n        or 'bayes_mvs', or a custom function. If a\n        function, must take a 1D array, and return a\n        single, real number.\n    threshood_mult : float or tuple\n        A multiplier applied to the calculated threshold\n        before use. If a tuple, the first value is applied\n        to the mean threshold, and the second is applied to\n        the standard deviation threshold. Reduce this to make\n        data selection more stringent.\n    x_bias : float\n        If non-zero, a bias is applied to the calculated statistics\n        to prefer the beginning (if > 0) or end (if < 0) of the\n        signal. Should be between zero and 1.\n    weights : array-like of length len(analytes)\n        An array of numbers specifying the importance of\n        each analyte considered. Larger number makes the\n        analyte have a greater effect on the optimisation.\n        Default is None.\n    ind : boolean array\n        A boolean array the same length as the data. Where\n        false, data will not be included.\n    mode : str\n        Whether to 'minimise' or 'maximise' the concentration\n        of the elements.\n\n    Returns\n    -------\n    dict, str : optimisation result, error message\n    \"\"\"\n    errmsg = ''\n\n    if isinstance(analytes, str):\n        analytes = [analytes]\n    \n    if ind is None:\n        ind = np.full(len(d.Time), True)\n\n    # initial catch\n    if not any(ind) or (np.diff(bool_2_indices(ind)).max() < min_points):\n        errmsg = 'Optmisation failed. No contiguous data regions longer than {:.0f} points.'.format(min_points)\n        return Bunch({'means': np.nan,\n                      'stds': np.nan,\n                      'mean_threshold': np.nan,\n                      'std_threshold': np.nan,\n                      'lims': np.nan,\n                      'filt': ind,\n                      'threshold_mode': threshold_mode,\n                      'min_points': min_points,\n                      'analytes': analytes,\n                      'opt_centre': np.nan,\n                      'opt_n_points': np.nan,\n                      'weights': weights,\n                      'optimisation_success': False,\n                      'errmsg': errmsg}), errmsg\n\n    msmeans, msstds = calculate_optimisation_stats(d, analytes, min_points, weights, ind, x_bias)\n    \n    # second catch\n    if all(np.isnan(msmeans).flat) or all(np.isnan(msmeans).flat):\n        errmsg = 'Optmisation failed. No contiguous data regions longer than {:.0f} points.'.format(min_points)\n        return Bunch({'means': np.nan,\n                      'stds': np.nan,\n                      'mean_threshold': np.nan,\n                      'std_threshold': np.nan,\n                      'lims': np.nan,\n                      'filt': ind,\n                      'threshold_mode': threshold_mode,\n                      'min_points': min_points,\n                      'analytes': analytes,\n                      'opt_centre': np.nan,\n                      'opt_n_points': np.nan,\n                      'weights': weights,\n                      'optimisation_success': False,\n                      'errmsg': errmsg}), errmsg\n\n    # define thresholds\n    valid = ['kde_first_max', 'kde_max', 'median', 'bayes_mvs', 'mean']\n    n_under = 0\n    i = np.argwhere(np.array(valid) == threshold_mode)[0, 0]\n    o_threshold_mode = threshold_mode\n    while (n_under <= 0) & (i < len(valid)):\n        if threshold_mode == 'median':\n            # median - OK, but best?\n            std_threshold = np.nanmedian(msstds)\n            mean_threshold = np.nanmedian(msmeans)\n        elif threshold_mode == 'mean':\n            # mean\n            std_threshold = np.nanmean(msstds)\n            mean_threshold = np.nanmean(msmeans)\n        elif threshold_mode == 'kde_max':\n            # maximum of gaussian kernel density estimator\n            mkd = gaussian_kde(msmeans[~np.isnan(msmeans)].flat)\n            xm = np.linspace(*np.percentile(msmeans.flatten()[~np.isnan(msmeans.flatten())], (1, 99)), 100)\n            mdf = mkd.pdf(xm)\n            mean_threshold = xm[np.argmax(mdf)]\n\n            rkd = gaussian_kde(msstds[~np.isnan(msstds)])\n            xr = np.linspace(*np.percentile(msstds.flatten()[~np.isnan(msstds.flatten())], (1, 99)), 100)\n            rdf = rkd.pdf(xr)\n            std_threshold = xr[np.argmax(rdf)]\n        elif threshold_mode == 'kde_first_max':\n            # first local maximum of gaussian kernel density estimator\n            mkd = gaussian_kde(msmeans[~np.isnan(msmeans)].flat)\n            xm = np.linspace(*np.percentile(msmeans.flatten()[~np.isnan(msmeans.flatten())], (1, 99)), 100)\n            mdf = mkd.pdf(xm)\n            inds = np.argwhere(np.r_[False, mdf[1:] > mdf[:-1]] & \n                            np.r_[mdf[:-1] > mdf[1:], False] & \n                            (mdf > 0.25 * mdf.max()))\n            mean_threshold = xm[np.min(inds)]\n\n            rkd = gaussian_kde(msstds[~np.isnan(msstds)])\n            xr = np.linspace(*np.percentile(msstds.flatten()[~np.isnan(msstds.flatten())], (1, 99)), 100)\n            rdf = rkd.pdf(xr)\n            inds = np.argwhere(np.r_[False, rdf[1:] > rdf[:-1]] & \n                            np.r_[rdf[:-1] > rdf[1:], False] & \n                            (rdf > 0.25 * rdf.max()))\n            std_threshold = xr[np.min(inds)]\n        elif threshold_mode == 'bayes_mvs':\n            # bayesian mvs.\n            bm, _, bs = bayes_mvs(msstds[~np.isnan(msstds)])\n            std_threshold = bm.statistic\n\n            bm, _, bs = bayes_mvs(msmeans[~np.isnan(msmeans)])\n            mean_threshold = bm.statistic\n        elif callable(threshold_mode):\n            std_threshold = threshold_mode(msstds[~np.isnan(msstds)].flatten())\n            mean_threshold = threshold_mode(msmeans[~np.isnan(msmeans)].flatten())\n        else:\n            try:\n                mean_threshold, std_threshold = threshold_mode\n            except:\n                raise ValueError('\\nthreshold_mode must be one of:\\n   ' + ', '.join(valid) + ',\\na custom function, or a \\n(mean_threshold, std_threshold) tuple.')\n\n        # apply threshold_mult\n        if isinstance(threshold_mult, (int, float)):\n            std_threshold *= threshold_mult\n            mean_threshold *= threshold_mult\n        elif len(threshold_mult) == 2:\n            mean_threshold *= threshold_mult[0]\n            std_threshold *= threshold_mult[1]\n        else:\n            raise ValueError('\\nthreshold_mult must be a float, int or tuple of length 2.')\n\n        rind = (msstds < std_threshold)\n\n        if mode == 'minimise':\n            mind = (msmeans < mean_threshold)\n        else:\n            mind = (msmeans > mean_threshold)\n\n        ind = rind & mind\n\n        n_under = ind.sum()\n        if n_under == 0:\n            i += 1\n            if i <= len(valid) - 1:\n                threshold_mode = valid[i]\n            else:\n                errmsg = 'Optimisation failed. No of the threshold_mode would work. Try reducting min_points.'\n                return Bunch({'means': np.nan,\n                              'stds': np.nan,\n                              'mean_threshold': np.nan,\n                              'std_threshold': np.nan,\n                              'lims': np.nan,\n                              'filt': ind,\n                              'threshold_mode': threshold_mode,\n                              'min_points': min_points,\n                              'analytes': analytes,\n                              'opt_centre': np.nan,\n                              'opt_n_points': np.nan,\n                              'weights': weights,\n                              'optimisation_success': False,\n                              'errmsg': errmsg}), errmsg\n    \n    if i > 0:\n        errmsg = \"optimisation failed using threshold_mode='{:}', falling back to '{:}'\".format(o_threshold_mode, threshold_mode)\n\n    # identify max number of points within thresholds\n    passing = np.argwhere(ind)\n    opt_n_points = passing[:, 0].max()\n    opt_centre = passing[passing[:, 0] == opt_n_points, 1].min()\n\n    opt_n_points += min_points\n\n    # centres, npoints = np.meshgrid(np.arange(msmeans.shape[1]),\n    #                                np.arange(min_points, min_points + msmeans.shape[0]))\n    # opt_n_points = npoints[ind].max()\n    # plus/minus one point to allow some freedom to shift selection window.\n    # cind = ind & (npoints == opt_n_points)\n    # opt_centre = centres[cind].min()\n\n    if opt_n_points % 2 == 0:\n        lims = (opt_centre - opt_n_points // 2,\n                opt_centre + opt_n_points // 2)\n    else:\n        lims = (opt_centre - opt_n_points // 2,\n                opt_centre + opt_n_points // 2 + 1)\n\n    filt = np.zeros(d.Time.shape, dtype=bool)\n    filt[lims[0]:lims[1]] = True\n\n    return Bunch({'means': msmeans,\n                  'stds': msstds,\n                  'mean_threshold': mean_threshold,\n                  'std_threshold': std_threshold,\n                  'lims': lims,\n                  'filt': filt,\n                  'threshold_mode': threshold_mode,\n                  'min_points': min_points,\n                  'analytes': analytes,\n                  'opt_centre': opt_centre,\n                  'opt_n_points': opt_n_points,\n                  'weights': weights,\n                  'optimisation_success': True,\n                  'errmsg': errmsg}), errmsg", "response": "This function is used to optimize the signal of the specified analytes."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nplots the result of signal_optimise.", "response": "def optimisation_plot(d, overlay_alpha=0.5, **kwargs):\n    \"\"\"\n    Plot the result of signal_optimise.\n\n    `signal_optimiser` must be run first, and the output\n    stored in the `opt` attribute of the latools.D object.\n\n    Parameters\n    ----------\n    d : latools.D object\n        A latools data object.\n    overlay_alpha : float\n        The opacity of the threshold overlays. Between 0 and 1.\n    **kwargs\n        Passed to `tplot`\n    \"\"\"\n    if not hasattr(d, 'opt'):\n        raise ValueError('Please run `signal_optimiser` before trying to plot its results.')\n    \n    out = []\n    for n, opt in d.opt.items():\n        if not opt['optimisation_success']:\n            out.append((None, None))\n        \n        else:\n            # unpack variables\n            means = opt['means']\n            stds = opt['stds']\n            min_points = opt['min_points']\n            mean_threshold = opt['mean_threshold']\n            std_threshold = opt['std_threshold']\n            opt_centre = opt['opt_centre']\n            opt_n_points = opt['opt_n_points']\n            \n            centres, npoints = np.meshgrid(np.arange(means.shape[1]), np.arange(min_points, min_points + means.shape[0]))\n            rind = (stds < std_threshold)\n            mind = (means < mean_threshold)\n\n            # color scale and histogram limits\n            mlim = np.percentile(means.flatten()[~np.isnan(means.flatten())], (0, 99))\n            rlim = np.percentile(stds.flatten()[~np.isnan(stds.flatten())], (0, 99))\n\n            cmr = plt.cm.Blues\n            cmr.set_bad((0,0,0,0.3))\n\n            cmm = plt.cm.Reds\n            cmm.set_bad((0,0,0,0.3))\n            \n            # create figure\n            fig = plt.figure(figsize=[7,7])\n\n            ma = fig.add_subplot(3, 2, 1)\n            ra = fig.add_subplot(3, 2, 2)\n\n            # work out image limits\n            nonan = np.argwhere(~np.isnan(means))\n            xdif = np.ptp(nonan[:, 1])\n            ydif = np.ptp(nonan[:, 0])\n            extent = (nonan[:, 1].min() - np.ceil(0.1 * xdif),  # x min\n                    nonan[:, 1].max() + np.ceil(0.1 * xdif),  # x max\n                    nonan[:, 0].min() + min_points,  # y min\n                    nonan[:, 0].max() + np.ceil(0.1 * ydif) + min_points)  # y max\n\n            mm = ma.imshow(means, origin='bottomleft', cmap=cmm, vmin=mlim[0], vmax=mlim[1],\n                        extent=(centres.min(), centres.max(), npoints.min(), npoints.max()))\n\n            ma.set_ylabel('N points')\n            ma.set_xlabel('Center')\n            fig.colorbar(mm, ax=ma, label='Amplitude')\n\n            mr = ra.imshow(stds, origin='bottomleft', cmap=cmr, vmin=rlim[0], vmax=rlim[1],\n                        extent=(centres.min(), centres.max(), npoints.min(), npoints.max()))\n\n            ra.set_xlabel('Center')\n            fig.colorbar(mr, ax=ra, label='std')\n\n            # view limits\n            ra.imshow(~rind, origin='bottomleft', cmap=plt.cm.Greys, alpha=overlay_alpha,\n                    extent=(centres.min(), centres.max(), npoints.min(), npoints.max()))\n            ma.imshow(~mind, origin='bottomleft', cmap=plt.cm.Greys, alpha=overlay_alpha,\n                    extent=(centres.min(), centres.max(), npoints.min(), npoints.max()))\n\n            for ax in [ma, ra]:\n                ax.scatter(opt_centre, opt_n_points, c=(1,1,1,0.7), edgecolor='k',marker='o')\n                ax.set_xlim(extent[:2])\n                ax.set_ylim(extent[-2:])\n\n            # draw histograms\n            mah = fig.add_subplot(3, 2, 3)\n            rah = fig.add_subplot(3, 2, 4)\n\n            mah.set_xlim(mlim)\n            mbin = np.linspace(*mah.get_xlim(), 50)\n            mah.hist(means.flatten()[~np.isnan(means.flatten())], mbin)\n            mah.axvspan(mean_threshold, mah.get_xlim()[1], color=(0,0,0,overlay_alpha))\n\n            mah.axvline(mean_threshold, c='r')\n            mah.set_xlabel('Scaled Mean Analyte Conc')\n            mah.set_ylabel('N')\n\n            rah.set_xlim(rlim)\n            rbin = np.linspace(*rah.get_xlim(), 50)\n            rah.hist(stds.flatten()[~np.isnan(stds.flatten())], rbin)\n            rah.axvspan(std_threshold, rah.get_xlim()[1], color=(0,0,0,0.4))\n            rah.axvline(std_threshold, c='r')\n            rah.set_xlabel('std')\n            \n            tax = fig.add_subplot(3,1,3)\n            tplot(d, opt.analytes, ax=tax, **kwargs)\n            tax.axvspan(*d.Time[[opt.lims[0], opt.lims[1]]], alpha=0.2)\n            \n            tax.set_xlim(d.Time[d.ns == n].min() - 3, d.Time[d.ns == n].max() + 3)\n\n            fig.tight_layout()\n\n            out.append((fig, (ma, ra, mah, rah, tax)))\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef noise_despike(sig, win=3, nlim=24., maxiter=4):\n    if win % 2 != 1:\n        win += 1  # win must be odd\n\n    kernel = np.ones(win) / win  # make convolution kernel\n    over = np.ones(len(sig), dtype=bool)  # initialize bool array\n    # pad edges to avoid edge-effects\n    npad = int((win - 1) / 2)\n    over[:npad] = False\n    over[-npad:] = False\n    # set up monitoring\n    nloops = 0\n    # do the despiking\n    while any(over) and (nloops < maxiter):\n        rmean = np.convolve(sig, kernel, 'valid')  # mean by convolution\n        rstd = rmean**0.5  # std = sqrt(signal), because count statistics\n        # identify where signal > mean + std * nlim (OR signa < mean - std *\n        # nlim)\n        # | (sig[npad:-npad] < rmean - nlim * rstd)\n        over[npad:-npad] = (sig[npad:-npad] > rmean + nlim * rstd)\n        # if any are over, replace them with mean of neighbours\n        if any(over):\n            # replace with values either side\n            # sig[over] = sig[np.roll(over, -1) | np.roll(over, 1)].reshape((sum(over), 2)).mean(1)\n            # replace with mean\n            sig[npad:-npad][over[npad:-npad]] = rmean[over[npad:-npad]]\n            nloops += 1\n        # repeat until no more removed.\n    return sig", "response": "This function is used to remove anomalous values from a signal."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\napplying exponential decay filter to remove physically impossible data based on instrumental washout. The filter is re-applied until no more points are removed, or maxiter is reached. Parameters ---------- exponent : float Exponent used in filter tstep : float The time increment between data points. maxiter : int The maximum number of times the filter should be applied. Returns ------- None", "response": "def expdecay_despike(sig, expdecay_coef, tstep, maxiter=3):\n    \"\"\"\n    Apply exponential decay filter to remove physically impossible data based on instrumental washout.\n\n    The filter is re-applied until no more points are removed, or maxiter is reached.\n\n    Parameters\n    ----------\n    exponent : float\n        Exponent used in filter\n    tstep : float\n        The time increment between data points.\n    maxiter : int\n        The maximum number of times the filter should be applied.\n\n    Returns\n    -------\n    None\n    \"\"\"\n    # determine rms noise of data\n    noise = np.std(sig[:5])  # initially, calculated based on first 5 points\n    # expand the selection up to 50 points, unless it dramatically increases \n    # the std (i.e. catches the 'laser on' region)\n    for i in [10, 20, 30, 50]:\n        inoise = np.std(sig[:i])\n        if inoise < 1.5 * noise:\n            noise = inoise\n    rms_noise3 = 3 * noise\n\n    i = 0\n    f = True\n    while (i < maxiter) and f:\n        # calculate low and high possibles values based on exponential decay\n        siglo = np.roll(sig * np.exp(tstep * expdecay_coef), 1)\n        sighi = np.roll(sig * np.exp(-tstep * expdecay_coef), -1)\n\n        # identify points that are outside these limits, beyond what might be explained\n        # by noise in the data\n        loind = (sig < siglo - rms_noise3) & (sig < np.roll(sig, -1) - rms_noise3)\n        hiind = (sig > sighi + rms_noise3) & (sig > np.roll(sig, 1) + rms_noise3)\n\n        # replace all such values with their preceding\n        sig[loind] = sig[np.roll(loind, -1)]\n        sig[hiind] = sig[np.roll(hiind, -1)]\n\n        f = any(np.concatenate([loind, hiind]))\n        i += 1\n\n    return sig"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _flat_map(self, f: Callable):\n        ''' **f** must return the same stack type as **self.value** has.\n        Iterates over the effects, sequences the inner instance\n        successively to the top and joins with the outer instance.\n        Example:\n        List(Right(Just(1))) => List(Right(Just(List(Right(Just(5))))))\n        => List(List(Right(Just(Right(Just(5))))))\n        => List(Right(Just(Right(Just(5)))))\n        => List(Right(Right(Just(Just(5)))))\n        => List(Right(Just(Just(5))))\n        => List(Right(Just(5)))\n        Note: IO works only as outermost effect, as it cannot sequence\n        '''\n        index = List.range(self.depth + 1)\n        g = index.fold_left(f)(lambda z, i: lambda a: a.map(z))\n        nested = g(self.value)\n        def sequence_level(z, depth, tpe):\n            nesting = lambda z, i: lambda a: a.map(z).sequence(tpe)\n            lifter = List.range(depth).fold_left(I)(nesting)\n            return z // lifter\n        def sequence_type(z, data):\n            return lambda a: sequence_level(a, *data).map(z)\n        h = self.all_effects.reversed.with_index.fold_left(I)(sequence_type)\n        return h(nested)", "response": "Map a function over the effects and return the same stack type as self. value."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add(self, name, filt, info='', params=(), setn=None):\n\n        iname = '{:.0f}_'.format(self.n) + name\n        self.index[self.n] = iname\n\n        if setn is None:\n            setn = self.maxset + 1\n        self.maxset = setn\n\n        if setn not in self.sets.keys():\n            self.sets[setn] = [iname]\n        else:\n            self.sets[setn].append(iname)\n\n        # self.keys is not added to?\n        self.components[iname] = filt\n        self.info[iname] = info\n        self.params[iname] = params\n        for a in self.analytes:\n            self.switches[a][iname] = False\n        self.n += 1\n        return", "response": "Add a new entry to the set."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves the filter from the set that name belongs to the current set.", "response": "def remove(self, name=None, setn=None):\n        \"\"\"\n        Remove filter.\n\n        Parameters\n        ----------\n        name : str\n            name of the filter to remove\n        setn : int or True\n            int: number of set to remove\n            True: remove all filters in set that 'name' belongs to\n\n        Returns\n        -------\n        None\n        \"\"\"\n        if isinstance(name, int):\n            name = self.index[name]\n\n        if setn is not None:\n            name = self.sets[setn]\n            del self.sets[setn]\n        elif isinstance(name, (int, str)):\n            name = [name]\n\n        if setn is True:\n            for n in name:\n                for k, v in self.sets.items():\n                    if n in v:\n                        name.append([m for m in v if m != n])\n\n        for n in name:\n            for k, v in self.sets.items():\n                if n in v:\n                    self.sets[k] = [m for m in v if n != m]\n            del self.components[n]\n            del self.info[n]\n            del self.params[n]\n            del self.keys[n]\n            for a in self.analytes:\n                del self.switches[a][n]\n            return"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef clear(self):\n        self.components = {}\n        self.info = {}\n        self.params = {}\n        self.switches = {}\n        self.keys = {}\n        self.index = {}\n        self.sets = {}\n        self.maxset = -1\n        self.n = 0\n        for a in self.analytes:\n            self.switches[a] = {}\n        return", "response": "Clear all the related data."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nturn on specified filter", "response": "def on(self, analyte=None, filt=None):\n        \"\"\"\n        Turn on specified filter(s) for specified analyte(s).\n\n        Parameters\n        ----------\n        analyte : optional, str or array_like\n            Name or list of names of analytes.\n            Defaults to all analytes.\n        filt : optional. int, str or array_like\n            Name/number or iterable names/numbers of filters.\n\n        Returns\n        -------\n        None\n        \"\"\"\n        if isinstance(analyte, str):\n            analyte = [analyte]\n        if isinstance(filt, (int, float)):\n            filt = [filt]\n        elif isinstance(filt, str):\n            filt = self.fuzzmatch(filt, multi=True)\n\n        if analyte is None:\n            analyte = self.analytes\n        if filt is None:\n            filt = list(self.index.values())\n\n        for a in analyte:\n            for f in filt:\n                if isinstance(f, (int, float)):\n                    f = self.index[int(f)]\n\n                try:\n                    self.switches[a][f] = True\n                except KeyError:\n                    f = self.fuzzmatch(f, multi=False)\n                    self.switches[a][f] = True\n\n                # for k in self.switches[a].keys():\n                #     if f in k:\n                #         self.switches[a][k] = True\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmaking a new filter for the specified analyte.", "response": "def make(self, analyte):\n        \"\"\"\n        Make filter for specified analyte(s).\n\n        Filter specified in filt.switches.\n\n        Parameters\n        ----------\n        analyte : str or array_like\n            Name or list of names of analytes.\n\n        Returns\n        -------\n        array_like\n            boolean filter\n        \"\"\"\n        if analyte is None:\n            analyte = self.analytes\n        elif isinstance(analyte, str):\n            analyte = [analyte]\n\n        out = []\n        for f in self.components.keys():\n            for a in analyte:\n                if self.switches[a][f]:\n                    out.append(f)\n        key = ' & '.join(sorted(out))\n        for a in analyte:\n            self.keys[a] = key\n        return self.make_fromkey(key)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nidentify a filter by fuzzy string matching.", "response": "def fuzzmatch(self, fuzzkey, multi=False):\n        \"\"\"\n        Identify a filter by fuzzy string matching.\n\n        Partial ('fuzzy') matching performed by `fuzzywuzzy.fuzzy.ratio`\n\n        Parameters\n        ----------\n        fuzzkey : str\n            A string that partially matches one filter name more than the others.\n\n        Returns\n        -------\n        The name of the most closely matched filter. : str\n        \"\"\"\n\n        keys, ratios = np.array([(f, seqm(None, fuzzkey, f).ratio()) for f in self.components.keys()]).T\n        mratio = max(ratios)\n\n        if multi:\n            return keys[ratios == mratio]\n        else:\n            if sum(ratios == mratio) == 1:\n                return keys[ratios == mratio][0]\n            else:\n                raise ValueError(\"\\nThe filter key provided ('{:}') matches two or more filter names equally well:\\n\".format(fuzzkey) + ', '.join(keys[ratios == mratio]) + \"\\nPlease be more specific!\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmake a filter from a logical expression.", "response": "def make_fromkey(self, key):\n        \"\"\"\n        Make filter from logical expression.\n\n        Takes a logical expression as an input, and returns a filter. Used for advanced\n        filtering, where combinations of nested and/or filters are desired. Filter names must\n        exactly match the names listed by print(filt).\n\n        Example: ``key = '(Filter_1 | Filter_2) & Filter_3'``\n        is equivalent to:\n        ``(Filter_1 OR Filter_2) AND Filter_3``\n        statements in parentheses are evaluated first.\n\n        Parameters\n        ----------\n        key : str\n            logical expression describing filter construction.\n\n        Returns\n        -------\n        array_like\n            boolean filter\n\n        \"\"\"\n        if key != '':\n            def make_runable(match):\n                return \"self.components['\" + self.fuzzmatch(match.group(0)) + \"']\"\n\n            runable = re.sub('[^\\(\\)|& ]+', make_runable, key)\n            return eval(runable)\n        else:\n            return ~np.zeros(self.size, dtype=bool)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef make_keydict(self, analyte=None):\n        if analyte is None:\n            analyte = self.analytes\n        elif isinstance(analyte, str):\n            analyte = [analyte]\n\n        out = {}\n        for a in analyte:\n            key = []\n            for f in self.components.keys():\n                if self.switches[a][f]:\n                    key.append(f)\n            out[a] = ' & '.join(sorted(key))\n        self.keydict = out\n        return out", "response": "Make a dictionary containing the logical filter expressions describing the filter ( s ) for the specified analytes."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngrabbing a specific filter from the cache.", "response": "def grab_filt(self, filt, analyte=None):\n        \"\"\"\n        Flexible access to specific filter using any key format.\n\n        Parameters\n        ----------\n        f : str, dict or bool\n            either logical filter expression, dict of expressions,\n            or a boolean\n        analyte : str\n            name of analyte the filter is for.\n\n        Returns\n        -------\n        array_like\n            boolean filter\n        \"\"\"\n        if isinstance(filt, str):\n            if filt in self.components:\n                if analyte is None:\n                    return self.components[filt]\n                else:\n                    if self.switches[analyte][filt]:\n                        return self.components[filt]\n            else:\n                try:\n                    ind = self.make_fromkey(filt)\n                except KeyError:\n                    print((\"\\n\\n***Filter key invalid. Please consult \"\n                           \"manual and try again.\"))\n        elif isinstance(filt, dict):\n            try:\n                ind = self.make_fromkey(filt[analyte])\n            except ValueError:\n                print((\"\\n\\n***Filter key invalid. Please consult manual \"\n                       \"and try again.\\nOR\\nAnalyte missing from filter \"\n                       \"key dict.\"))\n        elif filt:\n            ind = self.make(analyte)\n        else:\n            ind = ~np.zeros(self.size, dtype=bool)\n        return ind"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nextracts filter components for specific analyte.", "response": "def get_components(self, key, analyte=None):\n        \"\"\"\n        Extract filter components for specific analyte(s).\n\n        Parameters\n        ----------\n        key : str\n            string present in one or more filter names.\n            e.g. 'Al27' will return all filters with\n            'Al27' in their names.\n        analyte : str\n            name of analyte the filter is for\n\n        Returns\n        -------\n        boolean filter : array-like\n        \"\"\"\n        out = {}\n        for k, v in self.components.items():\n            if key in k:\n                if analyte is None:\n                    out[k] = v\n                elif self.switches[analyte][k]:\n                    out[k] = v\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting info for all filters.", "response": "def get_info(self):\n        \"\"\"\n        Get info for all filters.\n        \"\"\"\n        out = ''\n        for k in sorted(self.components.keys()):\n            out += '{:s}: {:s}'.format(k, self.info[k]) + '\\n'\n        return(out)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload the data from a file in a dataformat dict.", "response": "def read_data(data_file, dataformat, name_mode):\n    \"\"\"\n    Load data_file described by a dataformat dict.\n\n    Parameters\n    ----------\n    data_file : str\n        Path to data file, including extension.\n    dataformat : dict\n        A dataformat dict, see example below.\n    name_mode : str\n        How to identyfy sample names. If 'file_names' uses the\n        input name of the file, stripped of the extension. If\n        'metadata_names' uses the 'name' attribute of the 'meta'\n        sub-dictionary in dataformat. If any other str, uses this\n        str as the sample name.\n\n    Example\n    -------\n    >>>\n    {'genfromtext_args': {'delimiter': ',',\n                          'skip_header': 4},  # passed directly to np.genfromtxt\n     'column_id': {'name_row': 3,  # which row contains the column names\n                   'delimiter': ',',  # delimeter between column names\n                   'timecolumn': 0,  # which column contains the 'time' variable\n                   'pattern': '([A-z]{1,2}[0-9]{1,3})'},  # a regex pattern which captures the column names\n     'meta_regex': {  # a dict of (line_no: ([descriptors], [regexs])) pairs\n                    0: (['path'], '(.*)'),\n                    2: (['date', 'method'],  # MUST include date\n                     '([A-Z][a-z]+ [0-9]+ [0-9]{4}[ ]+[0-9:]+ [amp]+).* ([A-z0-9]+\\.m)')\n                   }\n    }\n\n    Returns\n    -------\n    sample, analytes, data, meta : tuple\n    \"\"\"\n    with open(data_file) as f:\n        lines = f.readlines()\n\n    if 'meta_regex' in dataformat.keys():\n        meta = Bunch()\n        for k, v in dataformat['meta_regex'].items():\n            try:\n                out = re.search(v[-1], lines[int(k)]).groups()\n            except:\n                raise ValueError('Failed reading metadata when applying:\\n  regex: {}\\nto\\n  line: {}'.format(v[-1], lines[int(k)]))\n            for i in np.arange(len(v[0])):\n                meta[v[0][i]] = out[i]\n    else:\n        meta = {}\n\n    # sample name\n    if name_mode == 'file_names':\n        sample = os.path.basename(data_file).split('.')[0]\n    elif name_mode == 'metadata_names':\n        sample = meta['name']\n    else:\n        sample = name_mode\n\n    # column and analyte names\n    columns = np.array(lines[dataformat['column_id']['name_row']].strip().split(\n        dataformat['column_id']['delimiter']))\n    if 'pattern' in dataformat['column_id'].keys():\n        pr = re.compile(dataformat['column_id']['pattern'])\n        analytes = [pr.match(c).groups()[0] for c in columns if pr.match(c)]\n\n    # do any required pre-formatting\n    if 'preformat_replace' in dataformat.keys():\n        with open(data_file) as f:\n            fbuffer = f.read()\n        for k, v in dataformat['preformat_replace'].items():\n            fbuffer = re.sub(k, v, fbuffer)\n        # dead data\n        read_data = np.genfromtxt(BytesIO(fbuffer.encode()),\n                                  **dataformat['genfromtext_args']).T\n    else:\n        # read data\n        read_data = np.genfromtxt(data_file,\n                                  **dataformat['genfromtext_args']).T\n\n    # data dict\n    dind = np.zeros(read_data.shape[0], dtype=bool)\n    for a in analytes:\n        dind[columns == a] = True\n\n    data = Bunch()\n    data['Time'] = read_data[dataformat['column_id']['timecolumn']]\n\n    # deal with time units\n    if 'time_unit' in dataformat['column_id']:\n        if isinstance(dataformat['column_id']['time_unit'], (float, int)):\n            time_mult = dataformat['column_id']['time_unit']\n        elif isinstance(dataformat['column_id']['time_unit'], str):\n            unit_multipliers = {'ms': 1/1000,\n                                'min': 60/1,\n                                's': 1}\n            try:\n                time_mult = unit_multipliers[dataformat['column_id']['time_unit']]\n            except:\n                raise ValueError(\"In dataformat: time_unit must be a number, 'ms', 'min' or 's'\")\n        data['Time'] *= time_mult\n        \n    # convert raw data into counts\n    # TODO: Is this correct? Should actually be per-analyte dwell?\n    # if 'unit' in dataformat:\n    #     if dataformat['unit'] == 'cps':\n    #         tstep = data['Time'][1] - data['Time'][0]\n    #         read_data[dind] *= tstep\n    #     else:\n    #         pass\n    data['rawdata'] = Bunch(zip(analytes, read_data[dind]))\n    data['total_counts'] = np.nansum(read_data[dind], 0)\n\n    return sample, analytes, data, meta"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfunction for plotting test user and Latools data comparison.", "response": "def residual_plots(df, rep_stats=None, els=['Mg', 'Sr', 'Al', 'Mn', 'Fe', 'Cu', 'Zn', 'B']):\n    \"\"\"\n    Function for plotting Test User and LAtools data comparison.\n\n    Parameters\n    ----------\n    df : pandas.DataFrame\n        A dataframe containing reference ('X/Ca_r'), test user \n        ('X/Ca_t') and LAtools ('X123') data.\n    rep_stats : dict\n        Reproducibility stats of the reference data produced by\n        `pairwise_reproducibility`\n    els : list\n        list of elements (names only) to plot.\n    \"\"\"\n    \n    # get corresponding analyte and ratio names\n    As = []\n    Rs = []\n    analytes = [c for c in df.columns if ('/' not in c)]\n    ratios = [c for c in df.columns if ('/' in c)]\n\n    for e in els:\n        if e == 'Sr':\n            As.append('88Sr')\n        elif e == 'Mg':\n            As.append('24Mg')\n        else:\n            As.append([a for a in analytes if e in a][0])\n        Rs.append([r for r in ratios if e in r][0])\n    \n    fig, axs = plt.subplots(len(els), 2, figsize=(5, len(els) * 2))\n    \n    for i, (e, a) in enumerate(zip(Rs, As)):\n        lax, hax = axs[i]\n        \n        x = df.loc[:, e].values\n        yl = df.loc[:, a].values\n        \n        c = element_colour(fmt_el(a))\n        u = 'mmol/mol'\n        \n        # calculate residuals\n        rl = yl - x\n        \n        # plot residuals\n        lax.scatter(x, rl, c=c, s=15, lw=0.5, edgecolor='k', alpha=0.5)\n        \n        # plot PDFs\n        rl = rl[~np.isnan(rl)]\n        lims = np.percentile(rl, [99, 1])\n        lims += lims.ptp() * np.array((-1.25, 1.25))\n        bins = np.linspace(*lims, 100)\n        kdl = stats.gaussian_kde(rl, .4)\n        hax.fill_betweenx(bins, kdl(bins), facecolor=c, alpha=0.7, edgecolor='k', lw=0.5, label='LAtools')\n        hax.set_xlim([0, hax.get_xlim()[-1]])\n                \n        # axis labels, annotations and limits\n        lax.set_ylabel(e + ' ('+ u + ')')\n        lax.text(.02,.02,fmt_RSS(rl), fontsize=8,\n                 ha='left', va='bottom', transform=lax.transAxes)\n\n        xlim = np.percentile(x[~np.isnan(x)], [0, 98])\n        lax.set_xlim(xlim)\n        \n        for ax in axs[i]:\n            ax.set_ylim(lims)\n            # zero line and 2SD precision\n            ax.axhline(0, c='k', ls='dashed', alpha=0.6)\n            if rep_stats is not None:\n                ax.axhspan(-rep_stats[e][0] * 2, rep_stats[e][0] * 2, color=(0,0,0,0.2), zorder=-1)\n            \n            if not ax.is_first_col():\n                ax.set_yticklabels([])\n                \n            if ax.is_last_row():\n                hax.set_xlabel('Density')\n                lax.set_xlabel('Iolite User')\n\n            if ax.is_first_row():\n                lax.set_title('LAtools', loc='left')\n            \n    fig.tight_layout()\n\n    return fig, axs"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompute comparison stats for a set of elements in a set of reference sets.", "response": "def comparison_stats(df, els=None):\n    \"\"\"\n    Compute comparison stats for test and LAtools data.\n    \n    Population-level similarity assessed by a Kolmogorov-Smirnov test.\n    \n    Individual similarity assessed by a pairwise Wilcoxon signed rank test.\n    \n    Trends in residuals assessed by regression analysis, where significance of\n    the slope and intercept is determined by t-tests (both relative to zero).\n    \n    Parameters\n    ----------\n    df : pandas.DataFrame\n        A dataframe containing reference ('X/Ca_r'), test user \n        ('X/Ca_t') and LAtools ('X123') data.\n    els : list\n        list of elements (names only) to plot.\n    \n    Returns\n    -------\n    pandas.DataFrame\n    \n    \"\"\"\n    if els is None:\n        els = ['Li', 'Mg', 'Al', 'P', 'Ti', 'Y', 'La', 'Ce', 'Pr', 'Nd', 'Sm',\n               'Eu', 'Gd', 'Tb', 'Dy', 'Ho', 'Er', 'Tm', 'Yb', 'Lu', 'Hf', 'Pb', 'Th',\n               'U']\n        \n    yl_stats = []\n    \n    for i, e in enumerate(els):\n        x = df.loc[:, e + '_rd'].values\n        yl = df.loc[:, e + '_la'].values\n        \n        yl_stats.append(summary_stats(x, yl, e))\n    \n    yl_stats = pd.concat(yl_stats).T\n    \n    return yl_stats.T"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfunctions for logging method calls and parameters", "response": "def _log(func):\n    \"\"\"\n    Function for logging method calls and parameters\n    \"\"\"\n    @wraps(func)\n    def wrapper(self, *args, **kwargs):\n        a = func(self, *args, **kwargs)\n        self.log.append(func.__name__ + ' :: args={} kwargs={}'.format(args, kwargs))\n        return a\n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef write_logfile(log, header, file_name):\n    path, ext = os.path.splitext(file_name)\n    if ext == '':\n        ext = '.lalog'\n    \n    with open(path + ext, 'w') as f:\n        f.write('\\n'.join(header))\n        f.write('\\n'.join(log))\n    \n    return path + ext", "response": "Writes and analysis log to a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads an analysis. log file and returns a tuple containing the arguments required to run each step in the order they were generated.", "response": "def read_logfile(log_file):\n    \"\"\"\n    Reads an latools analysis.log file, and returns dicts of arguments.\n\n    Parameters\n    ----------\n    log_file : str\n        Path to an analysis.log file produced by latools.\n    \n    Returns\n    -------\n    runargs, paths : tuple\n        Two dictionaries. runargs contains all the arguments required to run each step\n        of analysis in the form (function_name, {'args': (), 'kwargs': {}}). paths contains\n        the locations of the data directory and the SRM database used for analysis.\n    \"\"\"\n    dirname = os.path.dirname(log_file) + '/'\n    \n    with open(log_file, 'r') as f:\n        rlog = f.readlines()\n\n    hashind = [i for i, n in enumerate(rlog) if '#' in n]\n\n    pathread = re.compile('(.*) :: (.*)\\n')\n    paths = (pathread.match(l).groups() for l in rlog[hashind[0] + 1:hashind[-1]] if pathread.match(l))\n    paths = {k: os.path.join(dirname, v) for k, v in paths}\n    # paths = {k: os.path.abspath(v) for k, v in paths}\n\n    logread = re.compile('([a-z_]+) :: args=(\\(.*\\)) kwargs=(\\{.*\\})')\n    runargs = []\n    for line in rlog[hashind[1] + 1:]:\n        fname, args, kwargs = (logread.match(line).groups())\n        runargs.append((fname ,{'args': eval(args), 'kwargs': eval(kwargs)}))\n        \n        if fname == '__init__':\n            runargs[-1][-1]['kwargs']['config'] = 'REPRODUCE'\n            runargs[-1][-1]['kwargs']['dataformat'] = None\n            runargs[-1][-1]['kwargs']['data_folder'] = paths['data_folder']\n            if 'srm_table' in paths:\n                runargs[-1][-1]['kwargs']['srm_file'] = paths['srm_table']\n\n    return runargs, paths"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncompresses the target directory and saves it to.. / name. zip.", "response": "def zipdir(directory, name=None, delete=False):\n    \"\"\"\n    Compresses the target directory, and saves it to ../name.zip\n\n    Parameters\n    ----------\n    directory : str\n        Path to the directory you want to compress.\n        Compressed file will be saved at directory/../name.zip\n    name : str (default=None)\n        The name of the resulting zip file. If not specified, the\n        name of the directory to be compressed is used.\n    delete : bool\n        If True, the uncompressed directory is deleted after the zip file\n        has been created. Defaults to False.\n\n    Returns\n    -------\n    None\n    \"\"\"\n    if not os.path.isdir(directory) or not os.path.exists(directory):\n        raise ValueError('Please provide a valid directory.')\n    if name is None:\n        name = directory.split('/')[-1]\n    \n    savepath = os.path.join(directory, os.path.pardir)\n    \n    # create zipfile\n    with zipfile.ZipFile(os.path.join(savepath, name + '.zip'), 'w', zipfile.ZIP_DEFLATED) as zipf:\n        for root, dirs, files in os.walk(directory):\n            for f in files:\n                zipf.write(os.path.join(root, f), os.path.join(root.replace(directory, ''), f))\n    if delete:\n        shutil.rmtree(directory)\n\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef extract_zipdir(zip_file):\n    if not os.path.exists(zip_file):\n        raise ValueError('{} does not exist'.format(zip_file))\n    directory = os.path.dirname(zip_file)\n    filename = os.path.basename(zip_file)\n    dirpath = os.path.join(directory, filename.replace('.zip', ''))\n\n    with zipfile.ZipFile(zip_file, 'r', zipfile.ZIP_DEFLATED) as zipf:\n        zipf.extractall(dirpath)\n\n    return dirpath", "response": "Extract contents of zip file into subfolder in parent directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef autologin(function, timeout=TIMEOUT):\n    @wraps(function)\n    async def wrapper(self, *args, **kwargs):\n        \"\"\"Wrap a function with timeout.\"\"\"\n        try:\n            async with async_timeout.timeout(timeout):\n                return await function(self, *args, **kwargs)\n        except (asyncio.TimeoutError, ClientError, Error):\n            pass\n\n        _LOGGER.debug(\"autologin\")\n        try:\n            async with async_timeout.timeout(timeout):\n                await self.login()\n                return await function(self, *args, **kwargs)\n        except (asyncio.TimeoutError, ClientError, Error):\n            raise Error(str(function))\n\n    return wrapper", "response": "Decorator that will try to login and redo an action before failing."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def get_information():\n    jar = aiohttp.CookieJar(unsafe=True)\n    websession = aiohttp.ClientSession(cookie_jar=jar)\n\n    modem = eternalegypt.Modem(hostname=sys.argv[1], websession=websession)\n    await modem.login(password=sys.argv[2])\n\n    result = await modem.information()\n    for sms in result.sms:\n        pprint.pprint(sms)\n\n    await modem.logout()\n    await websession.close()", "response": "Example of printing the inbox."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def get_information():\n    jar = aiohttp.CookieJar(unsafe=True)\n    websession = aiohttp.ClientSession(cookie_jar=jar)\n\n    try:\n        modem = eternalegypt.Modem(hostname=sys.argv[1], websession=websession)\n        await modem.login(password=sys.argv[2])\n\n        result = await modem.information()\n        print(\"upstream: {}\".format(result.upstream))\n        print(\"serial_number: {}\".format(result.serial_number))\n        print(\"wire_connected: {}\".format(result.wire_connected))\n        print(\"mobile_connected: {}\".format(result.mobile_connected))\n        print(\"connection_text: {}\".format(result.connection_text))\n        print(\"connection_type: {}\".format(result.connection_type))\n        print(\"current_nw_service_type: {}\".format(result.current_nw_service_type))\n        print(\"current_ps_service_type: {}\".format(result.current_ps_service_type))\n        print(\"register_network_display: {}\".format(result.register_network_display))\n        print(\"roaming: {}\".format(result.roaming))\n        print(\"radio_quality: {}\".format(result.radio_quality))\n        print(\"rx_level: {}\".format(result.rx_level))\n        print(\"tx_level: {}\".format(result.tx_level))\n        print(\"current_band: {}\".format(result.current_band))\n        print(\"cell_id: {}\".format(result.cell_id))\n\n        await modem.logout()\n    except eternalegypt.Error:\n        print(\"Could not login\")\n\n    await websession.close()", "response": "Example of printing the current upstream."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def set_failover_mode(mode):\n    jar = aiohttp.CookieJar(unsafe=True)\n    websession = aiohttp.ClientSession(cookie_jar=jar)\n\n    try:\n        modem = eternalegypt.Modem(hostname=sys.argv[1], websession=websession)\n        await modem.login(password=sys.argv[2])\n\n        await modem.set_failover_mode(mode)\n\n        await modem.logout()\n    except eternalegypt.Error:\n        print(\"Could not login\")\n\n    await websession.close()", "response": "Example of printing the current upstream."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing a file - like object or string.", "response": "def parse(file_or_string):\n    \"\"\"Parse a file-like object or string.\n\n    Args:\n        file_or_string (file, str): File-like object or string.\n\n    Returns:\n        ParseResults: instance of pyparsing parse results.\n    \"\"\"\n    from mysqlparse.grammar.sql_file import sql_file_syntax\n\n    if hasattr(file_or_string, 'read') and hasattr(file_or_string.read, '__call__'):\n        return sql_file_syntax.parseString(file_or_string.read())\n    elif isinstance(file_or_string, six.string_types):\n        return sql_file_syntax.parseString(file_or_string)\n    else:\n        raise TypeError(\"Expected file-like or string object, but got '{type_name}' instead.\".format(\n            type_name=type(file_or_string).__name__,\n        ))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the link to the Jupyter notebook viewer for the given notebook url", "response": "def nbviewer_link(url):\n    \"\"\"Return the link to the Jupyter nbviewer for the given notebook url\"\"\"\n    if six.PY2:\n        from urlparse import urlparse as urlsplit\n    else:\n        from urllib.parse import urlsplit\n    info = urlsplit(url)\n    domain = info.netloc\n    url_type = 'github' if domain == 'github.com' else 'url'\n    return 'https://nbviewer.jupyter.org/%s%s' % (url_type, info.path)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef thumbnail_div(self):\n        return self.THUMBNAIL_TEMPLATE.format(\n            snippet=self.get_description()[1], thumbnail=self.thumb_file,\n            ref_name=self.reference)", "response": "The string for creating the thumbnail of this example"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef code_div(self):\n        code_example = self.code_example\n        if code_example is None:\n            return None\n        return self.CODE_TEMPLATE.format(\n            snippet=self.get_description()[1], code=code_example,\n            ref_name=self.reference)", "response": "The string for creating a code example for the gallery"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef other_supplementary_files(self):\n        if self._other_supplementary_files is not None:\n            return self._other_supplementary_files\n        return getattr(self.nb.metadata, 'other_supplementary_files', None)", "response": "The supplementary files of this notebook"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef url(self):\n        if self._url is not None:\n            url = self._url\n        else:\n            url = getattr(self.nb.metadata, 'url', None)\n        if url is not None:\n            return nbviewer_link(url)", "response": "The url on jupyter nbviewer for this notebook or None if unknown"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the output file with the specified ending", "response": "def get_out_file(self, ending='rst'):\n        \"\"\"get the output file with the specified `ending`\"\"\"\n        return os.path.splitext(self.outfile)[0] + os.path.extsep + ending"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef process_notebook(self, disable_warnings=True):\n        infile = self.infile\n        outfile = self.outfile\n        in_dir = os.path.dirname(infile) + os.path.sep\n        odir = os.path.dirname(outfile) + os.path.sep\n        create_dirs(os.path.join(odir, 'images'))\n        ep = nbconvert.preprocessors.ExecutePreprocessor(\n            timeout=300)\n        cp = nbconvert.preprocessors.ClearOutputPreprocessor(\n            timeout=300)\n\n        self.nb = nb = nbformat.read(infile, nbformat.current_nbformat)\n        # disable warnings in the rst file\n        if disable_warnings:\n            for i, cell in enumerate(nb.cells):\n                if cell['cell_type'] == 'code':\n                    cell = cell.copy()\n                    break\n            cell = cell.copy()\n            cell.source = \"\"\"\nimport logging\nlogging.captureWarnings(True)\nlogging.getLogger('py.warnings').setLevel(logging.ERROR)\n\"\"\"\n            nb.cells.insert(i, cell)\n        # write and process rst_file\n        if self.preprocess:\n            t = dt.datetime.now()\n            logger.info('Processing %s', self.infile)\n            try:\n                ep.preprocess(nb, {'metadata': {'path': in_dir}})\n            except nbconvert.preprocessors.execute.CellExecutionError:\n                logger.critical(\n                    'Error while processing %s!', self.infile, exc_info=True)\n            else:\n                logger.info('Done. Seconds needed: %i',\n                            (dt.datetime.now() - t).seconds)\n            if disable_warnings:\n                nb.cells.pop(i)\n\n        self.py_file = self.get_out_file('py')\n\n        if self.remove_tags:\n            tp = nbconvert.preprocessors.TagRemovePreprocessor(timeout=300)\n            for key, val in self.tag_options.items():\n                setattr(tp, key, set(val))\n            nb4rst = deepcopy(nb)\n            tp.preprocess(nb4rst, {'metadata': {'path': in_dir}})\n        else:\n            nb4rst = nb\n\n        self.create_rst(nb4rst, in_dir, odir)\n\n        if self.clear:\n            cp.preprocess(nb, {'metadata': {'path': in_dir}})\n        # write notebook file\n        nbformat.write(nb, outfile)\n        self.create_py(nb)", "response": "This method processes the notebook and creates all the pictures and files and returns the object that represents the new notebook and the new rst file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_rst(self, nb, in_dir, odir):\n        raw_rst, resources = nbconvert.export_by_name('rst', nb)\n        # remove ipython magics\n        rst_content = ''\n        i0 = 0\n        m = None\n        # HACK: we insert the bokeh style sheets here as well, since for some\n        # themes (e.g. the sphinx_rtd_theme) it is not sufficient to include\n        # the style sheets only via app.add_stylesheet\n        bokeh_str = ''\n        if 'bokeh' in raw_rst and self.insert_bokeh:\n            bokeh_str += self.BOKEH_TEMPLATE.format(\n                version=self.insert_bokeh)\n        if 'bokeh' in raw_rst and self.insert_bokeh_widgets:\n            bokeh_str += self.BOKEH_WIDGETS_TEMPLATE.format(\n                version=self.insert_bokeh_widgets)\n        for m in code_blocks.finditer(raw_rst):\n            lines = m.group().splitlines(True)\n            header, content = lines[0], ''.join(lines[1:])\n            no_magics = magic_patt.sub('\\g<1>', content)\n            # if the code cell only contained magic commands, we skip it\n            if no_magics.strip():\n                rst_content += (\n                    raw_rst[i0:m.start()] + bokeh_str + header + no_magics)\n                bokeh_str = ''\n                i0 = m.end()\n            else:\n                rst_content += raw_rst[i0:m.start()]\n                i0 = m.end()\n        if m is not None:\n            rst_content += bokeh_str + raw_rst[m.end():]\n        else:\n            rst_content = raw_rst\n        rst_content = '.. _%s:\\n\\n' % self.reference + \\\n            rst_content\n        url = self.url\n        if url is not None:\n            rst_content += self.CODE_DOWNLOAD_NBVIEWER.format(\n                pyfile=os.path.basename(self.py_file),\n                nbfile=os.path.basename(self.outfile),\n                url=url)\n        else:\n            rst_content += self.CODE_DOWNLOAD.format(\n                pyfile=os.path.basename(self.py_file),\n                nbfile=os.path.basename(self.outfile))\n        supplementary_files = self.supplementary_files\n        other_supplementary_files = self.other_supplementary_files\n        if supplementary_files or other_supplementary_files:\n            for f in (supplementary_files or []) + (\n                    other_supplementary_files or []):\n                if not os.path.exists(os.path.join(odir, f)):\n                    copyfile(os.path.join(in_dir, f), os.path.join(odir, f))\n        if supplementary_files:\n            rst_content += self.data_download(supplementary_files)\n\n        rst_file = self.get_out_file()\n        outputs = sorted(resources['outputs'], key=rst_content.find)\n        base = os.path.join('images', os.path.splitext(\n            os.path.basename(self.infile))[0] + '_%i.png')\n        out_map = {os.path.basename(original): base % i\n                   for i, original in enumerate(outputs)}\n        for original, final in six.iteritems(out_map):\n            rst_content = rst_content.replace(original, final)\n        with open(rst_file, 'w') \\\n                as f:\n            f.write(rst_content.rstrip() + '\\n')\n        pictures = []\n        for original in outputs:\n            fname = os.path.join(odir, out_map[os.path.basename(original)])\n            pictures.append(fname)\n            if six.PY3:\n                f = open(fname, 'w+b')\n            else:\n                f = open(fname, 'w')\n            f.write(resources['outputs'][original])\n            f.close()\n        self.pictures = pictures", "response": "Create the rst file from the notebook node."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates the python script from the notebook node", "response": "def create_py(self, nb, force=False):\n        \"\"\"Create the python script from the notebook node\"\"\"\n        # Although we would love to simply use ``nbconvert.export_python(nb)``\n        # this causes troubles in other cells processed by the ipython\n        # directive. Instead of getting something like ``Out [5]:``, we get\n        # some weird like '[0;31mOut[\u001b[1;31m5\u001b[0;31m]: \u001b[0m' which look like\n        # color information if we allow the call of nbconvert.export_python\n        if list(map(int, re.findall('\\d+', nbconvert.__version__))) >= [4, 2]:\n            py_file = os.path.basename(self.py_file)\n        else:\n            py_file = self.py_file\n        try:\n            level = logger.logger.level\n        except AttributeError:\n            level = logger.level\n        spr.call(['jupyter', 'nbconvert', '--to=python',\n                  '--output=' + py_file, '--log-level=%s' % level,\n                  self.outfile])\n        with open(self.py_file) as f:\n            py_content = f.read()\n        # comment out ipython magics\n        py_content = re.sub('^\\s*get_ipython\\(\\).magic.*', '# \\g<0>',\n                            py_content, flags=re.MULTILINE)\n        with open(self.py_file, 'w') as f:\n            f.write(py_content)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef data_download(self, files):\n        if len(files) > 1:\n            return self.DATA_DOWNLOAD % (\n                ('\\n\\n' + ' '*8) + ('\\n' + ' '*8).join(\n                    '* :download:`%s`' % f for f in files))\n        return self.DATA_DOWNLOAD % ':download:`%s`' % files[0]", "response": "Create the rst string to download supplementary data"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_thumb(self):\n        thumbnail_figure = self.copy_thumbnail_figure()\n        if thumbnail_figure is not None:\n            if isinstance(thumbnail_figure, six.string_types):\n                pic = thumbnail_figure\n            else:\n                pic = self.pictures[thumbnail_figure]\n            self.save_thumbnail(pic)\n        else:\n            for pic in self.pictures[::-1]:\n                if pic.endswith('png'):\n                    self.save_thumbnail(pic)\n                    return", "response": "Create the thumbnail for html output"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting summary and description of this notebook", "response": "def get_description(self):\n        \"\"\"Get summary and description of this notebook\"\"\"\n        def split_header(s, get_header=True):\n            s = s.lstrip().rstrip()\n            parts = s.splitlines()\n            if parts[0].startswith('#'):\n                if get_header:\n                    header = re.sub('#+\\s*', '', parts.pop(0))\n                    if not parts:\n                        return header, ''\n                else:\n                    header = ''\n                rest = '\\n'.join(parts).lstrip().split('\\n\\n')\n                desc = rest[0].replace('\\n', ' ')\n                return header, desc\n            else:\n                if get_header:\n                    if parts[0].startswith(('=', '-')):\n                        parts = parts[1:]\n                    header = parts.pop(0)\n                    if parts and parts[0].startswith(('=', '-')):\n                        parts.pop(0)\n                    if not parts:\n                        return header, ''\n                else:\n                    header = ''\n                rest = '\\n'.join(parts).lstrip().split('\\n\\n')\n                desc = rest[0].replace('\\n', ' ')\n                return header, desc\n\n        first_cell = self.nb['cells'][0]\n\n        if not first_cell['cell_type'] == 'markdown':\n            return '', ''\n        header, desc = split_header(first_cell['source'])\n        if not desc and len(self.nb['cells']) > 1:\n            second_cell = self.nb['cells'][1]\n            if second_cell['cell_type'] == 'markdown':\n                _, desc = split_header(second_cell['source'], False)\n        return header, desc"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef scale_image(self, in_fname, out_fname, max_width, max_height):\n        # local import to avoid testing dependency on PIL:\n        try:\n            from PIL import Image\n        except ImportError:\n            import Image\n        img = Image.open(in_fname)\n        width_in, height_in = img.size\n        scale_w = max_width / float(width_in)\n        scale_h = max_height / float(height_in)\n\n        if height_in * scale_w <= max_height:\n            scale = scale_w\n        else:\n            scale = scale_h\n\n        if scale >= 1.0 and in_fname == out_fname:\n            return\n\n        width_sc = int(round(scale * width_in))\n        height_sc = int(round(scale * height_in))\n\n        # resize the image\n        img.thumbnail((width_sc, height_sc), Image.ANTIALIAS)\n\n        # insert centered\n        thumb = Image.new('RGB', (max_width, max_height), (255, 255, 255))\n        pos_insert = (\n            (max_width - width_sc) // 2, (max_height - height_sc) // 2)\n        thumb.paste(img, pos_insert)\n\n        thumb.save(out_fname)", "response": "Scales an image with the same aspect ratio centered in an analyzed image with a given max_width and max_height."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef save_thumbnail(self, image_path):\n        thumb_dir = os.path.join(os.path.dirname(image_path), 'thumb')\n        create_dirs(thumb_dir)\n\n        thumb_file = os.path.join(thumb_dir,\n                                  '%s_thumb.png' % self.reference)\n        if os.path.exists(image_path):\n            logger.info('Scaling %s to thumbnail %s', image_path, thumb_file)\n            self.scale_image(image_path, thumb_file, 400, 280)\n        self.thumb_file = thumb_file", "response": "Save the thumbnail image"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef process_directories(self):\n        for i, (base_dir, target_dir, paths) in enumerate(zip(\n                self.in_dir, self.out_dir, map(os.walk, self.in_dir))):\n            self._in_dir_count = i\n            self.recursive_processing(base_dir, target_dir, paths)", "response": "Create the rst files from the input directories in the the\n                attribute."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef recursive_processing(self, base_dir, target_dir, it):\n        try:\n            file_dir, dirs, files = next(it)\n        except StopIteration:\n            return '', []\n        readme_files = {'README.md', 'README.rst', 'README.txt'}\n        if readme_files.intersection(files):\n            foutdir = file_dir.replace(base_dir, target_dir)\n            create_dirs(foutdir)\n            this_nbps = [\n                NotebookProcessor(\n                    infile=f,\n                    outfile=os.path.join(foutdir, os.path.basename(f)),\n                    disable_warnings=self.disable_warnings,\n                    preprocess=(\n                        (self.preprocess is True or f in self.preprocess) and\n                        not (self.dont_preprocess is True or\n                             f in self.dont_preprocess)),\n                    clear=((self.clear is True or f in self.clear) and not\n                           (self.dont_clear is True or f in self.dont_clear)),\n                    code_example=self.code_examples.get(f),\n                    supplementary_files=self.supplementary_files.get(f),\n                    other_supplementary_files=self.osf.get(f),\n                    thumbnail_figure=self.thumbnail_figures.get(f),\n                    url=self.get_url(f.replace(base_dir, '')),\n                    **self._nbp_kws)\n                for f in map(lambda f: os.path.join(file_dir, f),\n                             filter(self.pattern.match, files))]\n            readme_file = next(iter(readme_files.intersection(files)))\n        else:\n            return '', []\n        labels = OrderedDict()\n        this_label = 'gallery_' + foutdir.replace(os.path.sep, '_')\n        if this_label.endswith('_'):\n            this_label = this_label[:-1]\n        for d in dirs:\n            label, nbps = self.recursive_processing(\n                base_dir, target_dir, it)\n            if label:\n                labels[label] = nbps\n        s = \".. _%s:\\n\\n\" % this_label\n        with open(os.path.join(file_dir, readme_file)) as f:\n            s += f.read().rstrip() + '\\n\\n'\n\n        s += \"\\n\\n.. toctree::\\n\\n\"\n        s += ''.join('    %s\\n' % os.path.splitext(os.path.basename(\n            nbp.get_out_file()))[0] for nbp in this_nbps)\n        for d in dirs:\n            findex = os.path.join(d, 'index.rst')\n            if os.path.exists(os.path.join(foutdir, findex)):\n                s += '    %s\\n' % os.path.splitext(findex)[0]\n\n        s += '\\n'\n\n        for nbp in this_nbps:\n            code_div = nbp.code_div\n            if code_div is not None:\n                s += code_div + '\\n'\n            else:\n                s += nbp.thumbnail_div + '\\n'\n        s += \"\\n.. raw:: html\\n\\n    <div style='clear:both'></div>\\n\"\n        for label, nbps in labels.items():\n            s += '\\n.. only:: html\\n\\n    .. rubric:: :ref:`%s`\\n\\n' % (\n                label)\n            for nbp in nbps:\n                code_div = nbp.code_div\n                if code_div is not None:\n                    s += code_div + '\\n'\n                else:\n                    s += nbp.thumbnail_div + '\\n'\n            s += \"\\n.. raw:: html\\n\\n    <div style='clear:both'></div>\\n\"\n\n        s += '\\n'\n\n        with open(os.path.join(foutdir, 'index.rst'), 'w') as f:\n            f.write(s)\n        return this_label, list(chain(this_nbps, *labels.values()))", "response": "Method to recursivly process the notebooks in the base_dir and target_dir."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nclassing method to create a new instance of the classGallery from the current Sphinx application configuration.", "response": "def from_sphinx(cls, app):\n        \"\"\"Class method to create a :class:`Gallery` instance from the\n        configuration of a sphinx application\"\"\"\n        app.config.html_static_path.append(os.path.join(\n            os.path.dirname(__file__), '_static'))\n        config = app.config.example_gallery_config\n\n        insert_bokeh = config.get('insert_bokeh')\n        if insert_bokeh:\n            if not isstring(insert_bokeh):\n                import bokeh\n                insert_bokeh = bokeh.__version__\n            app.add_stylesheet(\n                NotebookProcessor.BOKEH_STYLE_SHEET.format(\n                    version=insert_bokeh))\n            app.add_javascript(\n                NotebookProcessor.BOKEH_JS.format(version=insert_bokeh))\n\n        insert_bokeh_widgets = config.get('insert_bokeh_widgets')\n        if insert_bokeh_widgets:\n            if not isstring(insert_bokeh_widgets):\n                import bokeh\n                insert_bokeh_widgets = bokeh.__version__\n            app.add_stylesheet(\n                NotebookProcessor.BOKEH_WIDGETS_STYLE_SHEET.format(\n                    version=insert_bokeh_widgets))\n            app.add_javascript(\n                NotebookProcessor.BOKEH_WIDGETS_JS.format(\n                    version=insert_bokeh_widgets))\n\n        if not app.config.process_examples:\n            return\n        cls(**app.config.example_gallery_config).process_directories()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_url(self, nbfile):\n        urls = self.urls\n        if isinstance(urls, dict):\n            return urls.get(nbfile)\n        elif isstring(urls):\n            if not urls.endswith('/'):\n                urls += '/'\n            return urls + nbfile", "response": "Return the url corresponding to the given notebook file."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nexecutes the sync sql command", "response": "def handle(self, *args, **options):\n        \"\"\" command execution \"\"\"\n        assume_yes = options.get('assume_yes', False)\n        default_language = options.get('default_language', None)\n\n        # set manual transaction management\n        transaction.commit_unless_managed()\n        transaction.enter_transaction_management()\n        transaction.managed(True)\n\n        self.cursor = connection.cursor()\n        self.introspection = connection.introspection\n\n        self.default_lang = default_language or mandatory_language()\n\n        all_models = get_models()\n        found_db_change_fields = False\n        for model in all_models:\n            if hasattr(model._meta, 'translatable_fields'):\n                model_full_name = '%s.%s' % (model._meta.app_label, model._meta.module_name)\n                translatable_fields = get_all_translatable_fields(model, column_in_current_table=True)\n                db_table = model._meta.db_table\n                for field_name in translatable_fields:\n                    db_table_fields = self.get_table_fields(db_table)\n                    db_change_langs = list(set(list(self.get_db_change_languages(field_name, db_table_fields)) + [self.default_lang]))\n                    if db_change_langs:\n                        sql_sentences = self.get_sync_sql(field_name, db_change_langs, model, db_table_fields)\n                        if sql_sentences:\n                            found_db_change_fields = True\n                            print_db_change_langs(db_change_langs, field_name, model_full_name)\n                            execute_sql = ask_for_confirmation(sql_sentences, model_full_name, assume_yes)\n                            if execute_sql:\n                                print ('Executing SQL...')\n                                for sentence in sql_sentences:\n                                    self.cursor.execute(sentence)\n                                    # commit\n                                    transaction.commit()\n                                print ('Done')\n                            else:\n                                print ('SQL not executed')\n\n        if transaction.is_dirty():\n            transaction.commit()\n        transaction.leave_transaction_management()\n\n        if not found_db_change_fields:\n            print ('\\nNo new translatable fields detected')\n        if default_language:\n            variable = 'TRANSMETA_DEFAULT_LANGUAGE'\n            has_transmeta_default_language = getattr(settings, variable, False)\n            if not has_transmeta_default_language:\n                variable = 'LANGUAGE_CODE'\n            if getattr(settings, variable) != default_language:\n                print (('\\n\\nYou should change in your settings '\n                       'the %s variable to \"%s\"' % (variable, default_language)))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_db_change_languages(self, field_name, db_table_fields):\n        for lang_code, lang_name in get_languages():\n            if get_real_fieldname(field_name, lang_code) not in db_table_fields:\n                yield lang_code\n        for db_table_field in db_table_fields:\n            pattern = re.compile('^%s_(?P<lang>\\w{2})$' % field_name)\n            m = pattern.match(db_table_field)\n            if not m:\n                continue\n            lang = m.group('lang')\n            yield lang", "response": "get only db changes fields"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn SQL needed for sync schema for a new translatable field", "response": "def get_sync_sql(self, field_name, db_change_langs, model, db_table_fields):\n        \"\"\" returns SQL needed for sync schema for a new translatable field \"\"\"\n        qn = connection.ops.quote_name\n        style = no_style()\n        sql_output = []\n        db_table = model._meta.db_table\n        was_translatable_before = self.was_translatable_before(field_name, db_table_fields)\n        default_f = self.get_default_field(field_name, model)\n        default_f_required = default_f and self.get_field_required_in_db(db_table,\n                                                    default_f.name,\n                                                    value_not_implemented=False)\n        for lang in db_change_langs:\n            new_field = get_real_fieldname(field_name, lang)\n            try:\n                f = model._meta.get_field(new_field)\n                col_type = self.get_type_of_db_field(field_name, model)\n                field_column = f.column\n            except FieldDoesNotExist:  # columns in db, removed the settings.LANGUGES\n                field_column = new_field\n                col_type = self.get_type_of_db_field(field_name, model)\n            field_sql = [style.SQL_FIELD(qn(field_column)), style.SQL_COLTYPE(col_type)]\n\n            alter_colum_set = 'ALTER COLUMN %s SET' % qn(field_column)\n            if default_f:\n                alter_colum_drop = 'ALTER COLUMN %s DROP' % qn(field_column)\n            not_null = style.SQL_KEYWORD('NOT NULL')\n\n            if 'mysql' in backend.__name__:\n                alter_colum_set = 'MODIFY %s %s' % (qn(field_column), col_type)\n                not_null = style.SQL_KEYWORD('NULL')\n                if default_f:\n                    alter_colum_drop = 'MODIFY %s %s' % (qn(field_column), col_type)\n\n            # column creation\n            if not new_field in db_table_fields:\n                sql_output.append(\"ALTER TABLE %s ADD COLUMN %s\" % (qn(db_table), ' '.join(field_sql)))\n\n            if lang == self.default_lang and not was_translatable_before:\n                # data copy from old field (only for default language)\n                sql_output.append(\"UPDATE %s SET %s = %s\" % (qn(db_table), \\\n                                    qn(field_column), qn(field_name)))\n                if not f.null:\n                    # changing to NOT NULL after having data copied\n                    sql_output.append(\"ALTER TABLE %s %s %s\" % \\\n                                    (qn(db_table), alter_colum_set, \\\n                                    style.SQL_KEYWORD('NOT NULL')))\n            elif default_f and not default_f.null:\n                if lang == self.default_lang:\n                    f_required = self.get_field_required_in_db(db_table,\n                                                           field_column,\n                                                           value_not_implemented=False)\n                    if default_f.name == new_field and default_f_required:\n                        continue\n                    if not f_required:\n                        # data copy from old field (only for default language)\n                        sql_output.append((\"UPDATE %(db_table)s SET %(f_colum)s = '%(value_default)s' \"\n                                    \"WHERE %(f_colum)s is %(null)s or %(f_colum)s = '' \" %  \n                                        {'db_table': qn(db_table),\n                                        'f_colum': qn(field_column),\n                                        'value_default': self.get_value_default(),\n                                        'null': style.SQL_KEYWORD('NULL'),\n                                        }))\n                        # changing to NOT NULL after having data copied\n                        sql_output.append(\"ALTER TABLE %s %s %s\" % \\\n                                        (qn(db_table), alter_colum_set, \\\n                                        style.SQL_KEYWORD('NOT NULL')))\n                else:\n                    f_required = self.get_field_required_in_db(db_table,\n                                                           field_column,\n                                                           value_not_implemented=True)\n                    if f_required:\n                        sql_output.append((\"ALTER TABLE %s %s %s\" % \n                                        (qn(db_table), alter_colum_drop, not_null)))\n\n        if not was_translatable_before:\n            # we drop field only if field was no translatable before\n            sql_output.append(\"ALTER TABLE %s DROP COLUMN %s\" % (qn(db_table), qn(field_name)))\n        return sql_output"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_all_translatable_fields(model, model_trans_fields=None, column_in_current_table=False):\n    if model_trans_fields is None:\n        model_trans_fields = set()\n    model_trans_fields.update(set(getattr(model._meta, 'translatable_fields', [])))\n    for parent in model.__bases__:\n        if getattr(parent, '_meta', None) and (not column_in_current_table or parent._meta.abstract):\n            get_all_translatable_fields(parent, model_trans_fields, column_in_current_table)\n    return tuple(model_trans_fields)", "response": "Returns all translatable fields in a model including all superclasses"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef default_value(field):\n    '''\n    When accessing to the name of the field itself, the value\n    in the current language will be returned. Unless it's set,\n    the value in the default language will be returned.\n    '''\n\n    def default_value_func(self):\n        attname = lambda x: get_real_fieldname(field, x)\n\n        if getattr(self, attname(get_language()), None):\n            result = getattr(self, attname(get_language()))\n        elif getattr(self, attname(get_language()[:2]), None):\n            result = getattr(self, attname(get_language()[:2]))\n        else:\n            default_language = fallback_language()\n            if getattr(self, attname(default_language), None):\n                result = getattr(self, attname(default_language), None)\n            else:\n                result = getattr(self, attname(settings.LANGUAGE_CODE), None)\n        return result\n\n    return default_value_func", "response": "Returns a function that returns the default value of the object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef process(thumbnail_file, size, **kwargs):\n    from . import conf\n\n    size_dict = conf.SIZES[size]\n    for processor in size_dict['POST_PROCESSORS']:\n        processor['processor'](thumbnail_file, **processor['kwargs'])\n\n    return thumbnail_file", "response": "Process a thumbnail file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef import_attribute(name):\n    if hasattr(name, '__call__'):\n        return name\n    module_name, attribute = name.rsplit('.', 1)\n    module = importlib.import_module(module_name)\n    return getattr(module, attribute)", "response": "Imports an attribute from a dotted path name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing the processors defined in the processor_definition.", "response": "def parse_processors(processor_definition):\n    \"\"\"\n    Returns a dictionary that contains the imported processors and\n    kwargs. For example, passing in:\n\n    processors = [\n        {'processor': 'thumbnails.processors.resize', 'width': 10, 'height': 10},\n        {'processor': 'thumbnails.processors.crop', 'width': 10, 'height': 10},\n    ]\n\n    Would return:\n\n    [\n        {'processor': resize_function, kwargs: {'width': 10, 'height': 10}}\n        {'processor': crop_function, kwargs: {'width': 10, 'height': 10}}\n    ]\n    \"\"\"\n    parsed_processors = []\n    for processor in processor_definition:\n        processor_function = import_attribute(processor['PATH'])\n        kwargs = deepcopy(processor)\n        kwargs.pop('PATH')\n        parsed_processors.append({\n            'processor': processor_function,\n            'kwargs': kwargs\n        })\n\n    return parsed_processors"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprocesses an image through its defined processors and return a ContentFile object", "response": "def process(file, size):\n    \"\"\"\n    Process an image through its defined processors\n    params :file: filename or file-like object\n    params :size: string for size defined in settings\n    return a ContentFile\n    \"\"\"\n    from . import conf\n    # open image in piccaso\n    raw_image = images.from_file(file)\n\n    # run through all processors, if defined\n    size_dict = conf.SIZES[size]\n    for processor in size_dict['PROCESSORS']:\n        raw_image = processor['processor'](raw_image, **processor['kwargs'])\n\n    # write to Content File\n    image_io = io.BytesIO()\n    raw_image.save(file=image_io)\n    image_file = ContentFile(image_io.getvalue())\n    #print dir(image_file)\n\n    return image_file"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pre_save(self, model_instance, add):\n        file = getattr(model_instance, self.attname)\n\n        if file and not file._committed:\n            image_file = file\n            if self.resize_source_to:\n                file.seek(0)\n                image_file = processors.process(file, self.resize_source_to)\n                image_file = post_processors.process(image_file, self.resize_source_to)\n            filename = str(shortuuid.uuid()) + os.path.splitext(file.name)[1]\n            file.save(filename, image_file, save=False)\n        return file", "response": "Process the source image through the defined processors and save it."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef all(self):\n        if self._thumbnails is not None:\n            return self._thumbnails\n        self._refresh_cache()\n        return self._thumbnails", "response": "Return all thumbnails in a dict format."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a Thumbnail instance of the specified size.", "response": "def get(self, size, create=True):\n        \"\"\"\n        Returns a Thumbnail instance.\n        First check whether thumbnail is already cached. If it doesn't:\n        1. Try to fetch the thumbnail\n        2. Create thumbnail if it's not present\n        3. Cache the thumbnail for future use\n        \"\"\"\n        if self._thumbnails is None:\n            self._refresh_cache()\n\n        thumbnail = self._thumbnails.get(size)\n\n        if thumbnail is None:\n            thumbnail = images.get(self.source_image.name, size,\n                                   self.metadata_backend, self.storage)\n\n            if thumbnail is None:\n                thumbnail = self.create(size)\n\n            self._thumbnails[size] = thumbnail\n\n        return thumbnail"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create(self, size):\n        thumbnail = images.create(self.source_image.name, size,\n                                  self.metadata_backend, self.storage)\n        return thumbnail", "response": "Creates and returns a thumbnail of a given size."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndelete a thumbnail of a given size", "response": "def delete(self, size):\n        \"\"\"\n        Deletes a thumbnail of a given size\n        \"\"\"\n        images.delete(self.source_image.name, size,\n                      self.metadata_backend, self.storage)\n        del(self._thumbnails[size])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create(source_name, size, metadata_backend=None, storage_backend=None):\n\n    if storage_backend is None:\n        storage_backend = backends.storage.get_backend()\n    if metadata_backend is None:\n        metadata_backend = backends.metadata.get_backend()\n\n    thumbnail_file = processors.process(storage_backend.open(source_name), size)\n    thumbnail_file = post_processors.process(thumbnail_file, size)\n    name = get_thumbnail_name(source_name, size)\n    name = storage_backend.save(name, thumbnail_file)\n\n    metadata = metadata_backend.add_thumbnail(source_name, size, name)\n    return Thumbnail(metadata=metadata, storage=storage_backend)", "response": "Creates a thumbnail file and its relevant metadata."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a Thumbnail instance for the given source name and size.", "response": "def get(source_name, size, metadata_backend=None, storage_backend=None):\n    \"\"\"\n    Returns a Thumbnail instance, or None if thumbnail does not yet exist.\n    \"\"\"\n    if storage_backend is None:\n        storage_backend = backends.storage.get_backend()\n    if metadata_backend is None:\n        metadata_backend = backends.metadata.get_backend()\n\n    metadata = metadata_backend.get_thumbnail(source_name, size)\n    if metadata is None:\n        return None\n    else:\n        return Thumbnail(metadata=metadata, storage=storage_backend)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete(source_name, size, metadata_backend=None, storage_backend=None):\n    if storage_backend is None:\n        storage_backend = backends.storage.get_backend()\n    if metadata_backend is None:\n        metadata_backend = backends.metadata.get_backend()\n    storage_backend.delete(get_thumbnail_name(source_name, size))\n    metadata_backend.delete_thumbnail(source_name, size)", "response": "Deletes a thumbnail file and its relevant metadata."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsimulating an incoming message and return a IncomingMessage object.", "response": "def received(self, src, body):\n        \"\"\" Simulate an incoming message\n\n            :type src: str\n            :param src: Message source\n            :type boby: str | unicode\n            :param body: Message body\n            :rtype: IncomingMessage\n        \"\"\"\n        # Create the message\n        self._msgid += 1\n        message = IncomingMessage(src, body, self._msgid)\n\n        # Log traffic\n        self._traffic.append(message)\n\n        # Handle it\n        self._receive_message(message)\n\n        # Finish\n        return message"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef subscribe(self, number, callback):\n        self._subscribers[digits_only(number)] = callback\n        return self", "response": "Register a virtual subscriber which receives messages to the matching number."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef states(self):\n        ret = set()\n        if self.accepted:\n            ret.add('accepted')\n        if self.delivered:\n            ret.add('delivered')\n        if self.expired:\n            ret.add('expired')\n        if self.error:\n            ret.add('error')\n        return ret", "response": "Returns a set of states."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nregister a provider on the gateway", "response": "def add_provider(self, name, Provider, **config):\n        \"\"\" Register a provider on the gateway\n\n            The first provider defined becomes the default one: used in case the routing function has no better idea.\n\n            :type name: str\n            :param name: Provider name that will be used to uniquely identify it\n            :type Provider: type\n            :param Provider: Provider class that inherits from `smsframework.IProvider`\n            :param config: Provider configuration. Please refer to the Provider documentation.\n            :rtype: IProvider\n            :returns: The created provider\n        \"\"\"\n        assert issubclass(Provider, IProvider), 'Provider does not implement IProvider'\n        assert isinstance(name, str), 'Provider name must be a string'\n\n        # Configure\n        provider = Provider(self, name, **config)\n\n        # Register\n        assert name not in self._providers, 'Provider is already registered'\n        self._providers[name] = provider\n\n        # If first - set default\n        if self.default_provider is None:\n            self.default_provider = name\n\n        # Finish\n        return provider"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsend a message object to the specified provider.", "response": "def send(self, message):\n        \"\"\" Send a message object\n\n            :type message: data.OutgoingMessage\n            :param message: The message to send\n            :rtype: data.OutgoingMessage\n            :returns: The sent message with populated fields\n            :raises AssertionError: wrong provider name encountered (returned by the router, or provided to OutgoingMessage)\n            :raises MessageSendError: generic errors\n            :raises AuthError: provider authentication failed\n            :raises LimitsError: sending limits exceeded\n            :raises CreditError: not enough money on the account\n        \"\"\"\n        # Which provider to use?\n        provider_name = self._default_provider  # default\n        if message.provider is not None:\n            assert message.provider in self._providers, \\\n                'Unknown provider specified in OutgoingMessage.provideer: {}'.format(provider_name)\n            provider = self.get_provider(message.provider)\n        else:\n            # Apply routing\n            if message.routing_values is not None: # Use the default provider when no routing values are given\n                # Routing values are present\n                provider_name = self.router(message, *message.routing_values) or self._default_provider\n                assert provider_name in self._providers, \\\n                    'Routing function returned an unknown provider name: {}'.format(provider_name)\n            provider = self.get_provider(provider_name)\n\n        # Set message provider name\n        message.provider = provider.name\n\n        # Send the message using the provider\n        message = provider.send(message)\n\n        # Emit the send event\n        self.onSend(message)\n\n        # Finish\n        return message"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a Flask Blueprint that handles incoming messages & status reports for the named provider", "response": "def receiver_blueprint_for(self, name):\n        \"\"\" Get a Flask blueprint for the named provider that handles incoming messages & status reports\n\n            Note: this requires Flask microframework.\n\n            :rtype: flask.blueprints.Blueprint\n            :returns: Flask Blueprint, fully functional\n            :raises KeyError: provider not found\n            :raises NotImplementedError: Provider does not implement a receiver\n        \"\"\"\n        # Get the provider & blueprint\n        provider = self.get_provider(name)\n        bp = provider.make_receiver_blueprint()\n\n        # Register a Flask handler that initializes `g.provider`\n        # This is the only way for the blueprint to get the current IProvider instance\n        from flask.globals import g  # local import as the user is not required to use receivers at all\n\n        @bp.before_request\n        def init_g():\n            g.provider = provider\n\n        # Finish\n        return bp"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a dict of Flask blueprints for every provider that supports it", "response": "def receiver_blueprints(self):\n        \"\"\" Get Flask blueprints for every provider that supports it\n\n            Note: this requires Flask microframework.\n\n            :rtype: dict\n            :returns: A dict { provider-name: Blueprint }\n        \"\"\"\n        blueprints = {}\n        for name in self._providers:\n            try:\n                blueprints[name] = self.receiver_blueprint_for(name)\n            except NotImplementedError:\n                pass  # Ignore providers that does not support receivers\n        return blueprints"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nregister all blueprints on the provided Flask application under the provided prefix.", "response": "def receiver_blueprints_register(self, app, prefix='/'):\n        \"\"\" Register all provider receivers on the provided Flask application under '/{prefix}/provider-name'\n\n            Note: this requires Flask microframework.\n\n            :type app: flask.Flask\n            :param app: Flask app to register the blueprints on\n            :type prefix: str\n            :param prefix: URL prefix to hide the receivers under.\n                You likely want some random stuff here so no stranger can simulate incoming messages.\n            :rtype: flask.Flask\n        \"\"\"\n        # Register\n        for name, bp in self.receiver_blueprints().items():\n            app.register_blueprint(\n                bp,\n                url_prefix='{prefix}{name}'.format(\n                    prefix='/'+prefix.strip('/')+'/' if prefix else '/',\n                    name=name\n                )\n            )\n\n        # Finish\n        return app"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _receive_message(self, message):\n        # Populate fields\n        message.provider = self.name\n\n        # Fire the event hook\n        self.gateway.onReceive(message)\n\n        # Finish\n        return message", "response": "Callback for receiving a message from the service"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef im():\n    req = jsonex_loads(request.get_data())\n    message = g.provider._receive_message(req['message'])\n    return {'message': message}", "response": "Incoming message handler: forwarded by ForwardServerProvider"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef jsonex_loads(s):\n    return json.loads(s.decode('utf-8'), cls=JsonExDecoder, classes=classes, exceptions=exceptions)", "response": "Unserialize with JsonEx\n    :rtype: dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nviews wrapper for JsonEx responses. Catches exceptions as well", "response": "def jsonex_api(f):\n    \"\"\" View wrapper for JsonEx responses. Catches exceptions as well \"\"\"\n    @wraps(f)\n    def wrapper(*args, **kwargs):\n        # Call, catch exceptions\n        try:\n            code, res = 200, f(*args, **kwargs)\n        except HTTPException as e:\n            code, res = e.code, {'error': e}\n        except Exception as e:\n            code, res = 500, {'error': e}\n            logger.exception('Method error')\n\n        # Response\n        response = make_response(jsonex_dumps(res), code)\n        response.headers['Content-Type'] = 'application/json'\n        return response\n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses authentication data from the URL and put it in the headers dict. With caching behavior is returned.", "response": "def _parse_authentication(url):\n    \"\"\" Parse authentication data from the URL and put it in the `headers` dict. With caching behavior\n    :param url: URL\n    :type url: str\n    :return: (URL without authentication info, headers dict)\n    :rtype: str, dict\n    \"\"\"\n    u = url\n    h = {}  # New headers\n\n    # Cache?\n    if url in _parse_authentication._memoize:\n        u, h = _parse_authentication._memoize[url]\n    else:\n        # Parse\n        p = urlsplit(url, 'http')\n        if p.username and p.password:\n            # Prepare header\n            h['Authorization'] = b'Basic ' + base64.b64encode(p.username.encode() + b':' + p.password.encode())\n            # Remove authentication info since urllib2.Request() does not understand it\n            u = urlunsplit((p.scheme, p.netloc.split('@', 1)[1], p.path, p.query, p.fragment))\n        # Cache\n        _parse_authentication._memoize[url] = (u, h)\n\n    # Finish\n    return u, h"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef jsonex_request(url, data, headers=None):\n    # Authentication?\n    url, headers = _parse_authentication(url)\n    headers['Content-Type'] = 'application/json'\n\n    # Request\n    try:\n        req = Request(url, headers=headers)\n        response = urlopen(req, jsonex_dumps(data))\n        res_str = response.read()\n        res = jsonex_loads(res_str)\n    except HTTPError as e:\n        if 'Content-Type' in e.headers and e.headers['Content-Type'] == 'application/json':\n            res = jsonex_loads(e.read())\n        else:\n            raise exc.ServerError('Server at \"{}\" failed: {}'.format(url, e))\n    except URLError as e:\n        raise exc.ConnectionError('Connection to \"{}\" failed: {}'.format(url, e))\n\n    # Errors?\n    if 'error' in res:  # Exception object\n        raise res['error']  # Error raised by the remote side\n\n    return res", "response": "Make a request with JsonEx"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsend a message to the server by forwarding it to the server", "response": "def send(self, message):\n        \"\"\" Send a message by forwarding it to the server\n        :param message: Message\n        :type message: smsframework.data.OutgoingMessage\n        :rtype: smsframework.data.OutgoingMessage\n        :raise Exception: any exception reported by the other side\n        :raise urllib2.URLError: Connection error\n        \"\"\"\n        res = jsonex_request(self.server_url + '/im'.lstrip('/'), {'message': message})\n        msg = res['message']  # OutgoingMessage object\n\n        # Replace properties in the original object (so it's the same object, like with other providers)\n        for k, v in msg.__dict__.items():\n            setattr(message, k, v)\n        return message"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _forward_object_to_client(self, client, obj):\n        url, name = ('/im', 'message') if isinstance(obj, IncomingMessage) else ('/status', 'status')\n        res = jsonex_request(client.rstrip('/') + '/' + url.lstrip('/'), {name: obj})\n        return res[name]", "response": "Forward an object to the client"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef forward(self, obj):\n        assert isinstance(obj, (IncomingMessage, MessageStatus)), 'Tried to forward an object of an unsupported type: {}'.format(obj)\n        clients = self.choose_clients(obj)\n\n        if Parallel:\n            pll = Parallel(self._forward_object_to_client)\n            for client in clients:\n                pll(client, obj)\n            results, errors = pll.join()\n            if errors:\n                raise errors[0]\n        else:\n            for client in clients:\n                self._forward_object_to_client(client, obj)", "response": "Forward an object to all the clients."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef stats(self):\n        d = dict()\n        d['framing'] = self.api.delimiter.stats()\n        d['protocol'] = self.api.stats()\n\n        return d", "response": "Returns a dictionnary that contains critical information about the transport and protocol behavior."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the balance of the given erc20 token", "response": "def get_balance(self, address: str, erc20_address: str) -> int:\n        \"\"\"\n        Get balance of address for `erc20_address`\n        :param address: owner address\n        :param erc20_address: erc20 token address\n        :return: balance\n        \"\"\"\n        return get_erc20_contract(self.w3, erc20_address).functions.balanceOf(address).call()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets erc20 information (`name`, `symbol` and `decimals`) :param erc20_address: :return: Erc20_Info", "response": "def get_info(self, erc20_address: str) -> Erc20_Info:\n        \"\"\"\n        Get erc20 information (`name`, `symbol` and `decimals`)\n        :param erc20_address:\n        :return: Erc20_Info\n        \"\"\"\n        # We use the `example erc20` as the `erc20 interface` doesn't have `name`, `symbol` nor `decimals`\n        erc20 = get_example_erc20_contract(self.w3, erc20_address)\n        name = erc20.functions.name().call()\n        symbol = erc20.functions.symbol().call()\n        decimals = erc20.functions.decimals().call()\n        return Erc20_Info(name, symbol, decimals)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the events for erc20 transfers.", "response": "def get_transfer_history(self, from_block: int, to_block: Optional[int] = None,\n                             from_address: Optional[str] = None, to_address: Optional[str] = None,\n                             token_address: Optional[str] = None) -> List[Dict[str, any]]:\n        \"\"\"\n        Get events for erc20 transfers. At least one of `from_address`, `to_address` or `token_address` must be\n        defined\n        An example of event:\n        {\n            \"args\": {\n                \"from\": \"0x1Ce67Ea59377A163D47DFFc9BaAB99423BE6EcF1\",\n                \"to\": \"0xaE9E15896fd32E59C7d89ce7a95a9352D6ebD70E\",\n                \"value\": 15000000000000000\n            },\n            \"event\": \"Transfer\",\n            \"logIndex\": 42,\n            \"transactionIndex\": 60,\n            \"transactionHash\": \"0x71d6d83fef3347bad848e83dfa0ab28296e2953de946ee152ea81c6dfb42d2b3\",\n            \"address\": \"0xfecA834E7da9D437645b474450688DA9327112a5\",\n            \"blockHash\": \"0x054de9a496fc7d10303068cbc7ee3e25181a3b26640497859a5e49f0342e7db2\",\n            \"blockNumber\": 7265022\n        }\n        :param from_block: Block to start querying from\n        :param to_block: Block to stop querying from\n        :param from_address: Address sending the erc20 transfer\n        :param to_address: Address receiving the erc20 transfer\n        :param token_address: Address of the token\n        :return: List of events\n        :throws: ReadTimeout\n        \"\"\"\n        assert from_address or to_address or token_address, 'At least one parameter must be provided'\n\n        erc20 = get_erc20_contract(self.w3)\n\n        argument_filters = {}\n        if from_address:\n            argument_filters['from'] = from_address\n        if to_address:\n            argument_filters['to'] = to_address\n\n        return erc20.events.Transfer.createFilter(fromBlock=from_block,\n                                                  toBlock=to_block,\n                                                  address=token_address,\n                                                  argument_filters=argument_filters).get_all_entries()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef send_tokens(self, to: str, amount: int, erc20_address: str, private_key: str) -> bytes:\n        erc20 = get_erc20_contract(self.w3, erc20_address)\n        account = Account.privateKeyToAccount(private_key)\n        tx = erc20.functions.transfer(to, amount).buildTransaction({'from': account.address})\n        return self.ethereum_client.send_unsigned_transaction(tx, private_key=private_key)", "response": "Send a number of tokens to the given address."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef trace_filter(self, from_block: int = 1, to_block: Optional[int] = None,\n                     from_address: Optional[List[str]] = None, to_address: Optional[List[str]] = None,\n                     after: Optional[int] = None, count: Optional[int] = None) -> List[Dict[str, any]]:\n        \"\"\"\n        :param from_block: Quantity or Tag - (optional) From this block. `0` is not working, it needs to be `>= 1`\n        :param to_block: Quantity or Tag - (optional) To this block.\n        :param from_address: Array - (optional) Sent from these addresses.\n        :param to_address: Address - (optional) Sent to these addresses.\n        :param after: Quantity - (optional) The offset trace number\n        :param count: Quantity - (optional) Integer number of traces to display in a batch.\n        :return:\n          [\n            {\n              \"action\": {\n                \"callType\": \"call\",\n                \"from\": \"0x32be343b94f860124dc4fee278fdcbd38c102d88\",\n                \"gas\": \"0x4c40d\",\n                \"input\": \"0x\",\n                \"to\": \"0x8bbb73bcb5d553b5a556358d27625323fd781d37\",\n                \"value\": \"0x3f0650ec47fd240000\"\n              },\n              \"blockHash\": \"0x86df301bcdd8248d982dbf039f09faf792684e1aeee99d5b58b77d620008b80f\",\n              \"blockNumber\": 3068183,\n              \"result\": {\n                \"gasUsed\": \"0x0\",\n                \"output\": \"0x\"\n              },\n              \"subtraces\": 0,\n              \"traceAddress\": [],\n              \"transactionHash\": \"0x3321a7708b1083130bd78da0d62ead9f6683033231617c9d268e2c7e3fa6c104\",\n              \"transactionPosition\": 3,\n              \"type\": \"call\"\n            },\n          {\n            \"action\": {\n              \"from\": \"0x3b169a0fb55ea0b6bafe54c272b1fe4983742bf7\",\n              \"gas\": \"0x49b0b\",\n              \"init\": \"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\",\n              \"value\": \"0x0\"\n            },\n            \"blockHash\": \"0x03f9f64dfeb7807b5df608e6957dd4d521fd71685aac5533451d27f0abe03660\",\n            \"blockNumber\": 3793534,\n            \"result\": {\n              \"address\": \"0x61a7cc907c47c133d5ff5b685407201951fcbd08\",\n              \"code\": \"0x60806040526004361061004c576000357c0100000000000000000000000000000000000000000000000000000000900463ffffffff1680634555d5c91461008b5780635c60da1b146100b6575b73ffffffffffffffffffffffffffffffffffffffff600054163660008037600080366000845af43d6000803e6000811415610086573d6000fd5b3d6000f35b34801561009757600080fd5b506100a061010d565b6040518082815260200191505060405180910390f35b3480156100c257600080fd5b506100cb610116565b604051808273ffffffffffffffffffffffffffffffffffffffff1673ffffffffffffffffffffffffffffffffffffffff16815260200191505060405180910390f35b60006002905090565b60008060009054906101000a900473ffffffffffffffffffffffffffffffffffffffff169050905600a165627a7a7230582007fffd557dfc8c4d2fdf56ba6381a6ce5b65b6260e1492d87f26c6d4f1d041080029\",\n              \"gasUsed\": \"0x4683f\"\n            },\n            \"subtraces\": 2,\n            \"traceAddress\": [],\n            \"transactionHash\": \"0x6c7e8f8778d33d81b29c4bd7526ee50a4cea340d69eed6c89ada4e6fab731789\",\n            \"transactionPosition\": 1,\n            \"type\": \"create\"\n          },\n          ...\n        ]\n        \"\"\"\n        assert from_address or to_address, 'You must provide at least `from_address` or `to_address`'\n        parameters = {}\n        if from_block:\n            parameters['fromBlock'] = '0x%x' % from_block\n        if to_block:\n            parameters['toBlock'] = '0x%x' % to_block\n        if from_address:\n            parameters['fromAddress'] = from_address\n        if to_address:\n            parameters['toAddress'] = to_address\n        if after:\n            parameters['after'] = after\n        if count:\n            parameters['count'] = count\n\n        try:\n            return self._decode_traces(self.slow_w3.parity.traceFilter(parameters))\n        except ParityTraceDecodeException as exc:\n            logger.warning('Problem decoding trace: %s - Retrying', exc)\n            return self._decode_traces(self.slow_w3.parity.traceFilter(parameters))", "response": "This function returns a list of traces that can be used to filter the log messages for the current block."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a new web3 provider for slow queries. Default HTTPProvider timeouts after 10 seconds.", "response": "def get_slow_provider(self, timeout: int):\n        \"\"\"\n        Get web3 provider for slow queries. Default `HTTPProvider` timeouts after 10 seconds\n        :param provider: Configured Web3 provider\n        :param timeout: Timeout to configure for internal requests (default is 10)\n        :return: A new web3 provider with the `slow_provider_timeout`\n        \"\"\"\n        if isinstance(self.w3_provider, AutoProvider):\n            return HTTPProvider(endpoint_uri='http://localhost:8545',\n                                request_kwargs={'timeout': timeout})\n        elif isinstance(self.w3_provider, HTTPProvider):\n            return HTTPProvider(endpoint_uri=self.w3_provider.endpoint_uri,\n                                request_kwargs={'timeout': timeout})\n        else:\n            return self.w3_provider"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef send_unsigned_transaction(self, tx: Dict[str, any], private_key: Optional[str] = None,\n                                  public_key: Optional[str] = None, retry: bool = False,\n                                  block_identifier: Optional[str] = None) -> bytes:\n        \"\"\"\n        Send a tx using an unlocked public key in the node or a private key. Both `public_key` and\n        `private_key` cannot be `None`\n        :param tx:\n        :param private_key:\n        :param public_key:\n        :param retry: Retry if a problem with nonce is found\n        :param block_identifier:\n        :return: tx hash\n        \"\"\"\n        if private_key:\n            address = self.private_key_to_address(private_key)\n        elif public_key:\n            address = public_key\n        else:\n            logger.error('No ethereum account provided. Need a public_key or private_key')\n            raise ValueError(\"Ethereum account was not configured or unlocked in the node\")\n\n        if tx.get('nonce') is None:\n            tx['nonce'] = self.get_nonce_for_account(address, block_identifier=block_identifier)\n\n        number_errors = 5\n        while number_errors >= 0:\n            try:\n                if private_key:\n                    signed_tx = self.w3.eth.account.signTransaction(tx, private_key=private_key)\n                    logger.debug('Sending %d wei from %s to %s', tx['value'], address, tx['to'])\n                    try:\n                        return self.send_raw_transaction(signed_tx.rawTransaction)\n                    except TransactionAlreadyImported as e:\n                        # Sometimes Parity 2.2.11 fails with Transaction already imported, even if it's not, but it's\n                        # processed\n                        tx_hash = signed_tx.hash\n                        logger.error('Transaction with tx-hash=%s already imported: %s' % (tx_hash.hex(), str(e)))\n                        return tx_hash\n                elif public_key:\n                    tx['from'] = address\n                    return self.send_transaction(tx)\n            except ReplacementTransactionUnderpriced as e:\n                if not retry or not number_errors:\n                    raise e\n                logger.error('address=%s Tx with nonce=%d was already sent, retrying with nonce + 1',\n                             address, tx['nonce'])\n                tx['nonce'] += 1\n            except InvalidNonce as e:\n                if not retry or not number_errors:\n                    raise e\n                logger.error('address=%s Tx with invalid nonce=%d, retrying recovering nonce again',\n                             address, tx['nonce'])\n                tx['nonce'] = self.get_nonce_for_account(address, block_identifier=block_identifier)\n                number_errors -= 1", "response": "Send an unsigned transaction to the node."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef send_eth_to(self, private_key: str, to: str, gas_price: int, value: int, gas: int=22000,\n                    retry: bool = False, block_identifier=None, max_eth_to_send: int = 0) -> bytes:\n        \"\"\"\n        Send ether using configured account\n        :param to: to\n        :param gas_price: gas_price\n        :param value: value(wei)\n        :param gas: gas, defaults to 22000\n        :param retry: Retry if a problem is found\n        :param block_identifier: None default, 'pending' not confirmed txs\n        :return: tx_hash\n        \"\"\"\n\n        assert check_checksum(to)\n        if max_eth_to_send and value > self.w3.toWei(max_eth_to_send, 'ether'):\n            raise EtherLimitExceeded('%d is bigger than %f' % (value, max_eth_to_send))\n\n        tx = {\n            'to': to,\n            'value': value,\n            'gas': gas,\n            'gasPrice': gas_price,\n        }\n\n        return self.send_unsigned_transaction(tx, private_key=private_key, retry=retry,\n                                              block_identifier=block_identifier)", "response": "Send an unsigned Ethernet transaction to the specified address."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if a transaction has the required number of confirmations.", "response": "def check_tx_with_confirmations(self, tx_hash: str, confirmations: int) -> bool:\n        \"\"\"\n        Check tx hash and make sure it has the confirmations required\n        :param w3: Web3 instance\n        :param tx_hash: Hash of the tx\n        :param confirmations: Minimum number of confirmations required\n        :return: True if tx was mined with the number of confirmations required, False otherwise\n        \"\"\"\n        tx_receipt = self.w3.eth.getTransactionReceipt(tx_hash)\n        if not tx_receipt or tx_receipt['blockNumber'] is None:\n            # If tx_receipt exists but blockNumber is None, tx is still pending (just Parity)\n            return False\n        else:\n            return (self.w3.eth.blockNumber - tx_receipt['blockNumber']) >= confirmations"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_signing_address(hash: Union[bytes, str], v: int, r: int, s: int) -> str:\n        encoded_64_address = ecrecover_to_pub(hash, v, r, s)\n        address_bytes = sha3(encoded_64_address)[-20:]\n        return checksum_encode(address_bytes)", "response": "Returns the signing address for the given hash value r and s."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate an address for a contract created using CREATE2.", "response": "def generate_address_2(from_: Union[str, bytes], salt: Union[str, bytes], init_code: [str, bytes]) -> str:\n    \"\"\"\n    Generates an address for a contract created using CREATE2.\n    :param from_: The address which is creating this new address (need to be 20 bytes)\n    :param salt: A salt (32 bytes)\n    :param init_code: A init code of the contract being created\n    :return: Address of the new contract\n    \"\"\"\n\n    from_ = HexBytes(from_)\n    salt = HexBytes(salt)\n    init_code = HexBytes(init_code)\n\n    assert len(from_) == 20, \"Address %s is not valid. Must be 20 bytes\" % from_\n    assert len(salt) == 32, \"Salt %s is not valid. Must be 32 bytes\" % salt\n    assert len(init_code) > 0, \"Init code %s is not valid\" % init_code\n\n    init_code_hash = Web3.sha3(init_code)\n    contract_address = Web3.sha3(HexBytes('ff') + from_ + salt + init_code_hash)\n    return Web3.toChecksumAddress(contract_address[12:])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_safe_contract(w3: Web3, address=None):\n    return w3.eth.contract(address,\n                           abi=GNOSIS_SAFE_INTERFACE['abi'],\n                           bytecode=GNOSIS_SAFE_INTERFACE['bytecode'])", "response": "Get Gnosis Safe Master contract."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_old_safe_contract(w3: Web3, address=None):\n    return w3.eth.contract(address,\n                           abi=OLD_GNOSIS_SAFE_INTERFACE['abi'],\n                           bytecode=OLD_GNOSIS_SAFE_INTERFACE['bytecode'])", "response": "Get the old safe contract."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget Paying Proxy Contract.", "response": "def get_paying_proxy_contract(w3: Web3, address=None):\n    \"\"\"\n    Get Paying Proxy Contract. This should be used just for contract creation/changing master_copy\n    If you want to call Safe methods you should use `get_safe_contract` with the Proxy address,\n    so you can access every method of the Safe\n    :param w3: Web3 instance\n    :param address: address of the proxy contract\n    :return: Paying Proxy Contract\n    \"\"\"\n    return w3.eth.contract(address,\n                           abi=PAYING_PROXY_INTERFACE['abi'],\n                           bytecode=PAYING_PROXY_INTERFACE['bytecode'])"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets ERC20 interface :param w3: Web3 instance :param address: address of the proxy contract :return: ERC 20 contract", "response": "def get_erc20_contract(w3: Web3, address=None):\n    \"\"\"\n    Get ERC20 interface\n    :param w3: Web3 instance\n    :param address: address of the proxy contract\n    :return: ERC 20 contract\n    \"\"\"\n    return w3.eth.contract(address,\n                           abi=ERC20_INTERFACE['abi'],\n                           bytecode=ERC20_INTERFACE['bytecode'])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef signature_split(signatures: bytes, pos: int) -> Tuple[int, int, int]:\n    signature_pos = 65 * pos\n    v = signatures[64 + signature_pos]\n    r = int.from_bytes(signatures[signature_pos:32 + signature_pos], 'big')\n    s = int.from_bytes(signatures[32 + signature_pos:64 + signature_pos], 'big')\n\n    return v, r, s", "response": "split the signature into v r s"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert signature to bytes", "response": "def signature_to_bytes(vrs: Tuple[int, int, int]) -> bytes:\n    \"\"\"\n    Convert signature to bytes\n    :param vrs: tuple of v, r, s\n    :return: signature in form of {bytes32 r}{bytes32 s}{uint8 v}\n    \"\"\"\n\n    byte_order = 'big'\n    v, r, s = vrs\n\n    return (r.to_bytes(32, byteorder=byte_order) +\n            s.to_bytes(32, byteorder=byte_order) +\n            v.to_bytes(1, byteorder=byte_order))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert a list of tuples to 65 bytes per signature", "response": "def signatures_to_bytes(signatures: List[Tuple[int, int, int]]) -> bytes:\n    \"\"\"\n    Convert signatures to bytes\n    :param signatures: list of tuples(v, r, s)\n    :return: 65 bytes per signature\n    \"\"\"\n    return b''.join([signature_to_bytes(vrs) for vrs in signatures])"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfinds v and r valid values for a given s", "response": "def find_valid_random_signature(s: int) -> Tuple[int, int]:\n        \"\"\"\n        Find v and r valid values for a given s\n        :param s: random value\n        :return: v, r\n        \"\"\"\n        for _ in range(10000):\n            r = int(os.urandom(31).hex(), 16)\n            v = (r % 2) + 27\n            if r < secpk1n:\n                tx = Transaction(0, 1, 21000, b'', 0, b'', v=v, r=r, s=s)\n                try:\n                    tx.sender\n                    return v, r\n                except (InvalidTransaction, ValueError):\n                    logger.debug('Cannot find signature with v=%d r=%d s=%d', v, r, s)\n\n        raise ValueError('Valid signature not found with s=%d', s)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbuilding a ContractConstructor object for the proxy contract creation.", "response": "def _build_proxy_contract_creation_constructor(self,\n                                                   master_copy: str,\n                                                   initializer: bytes,\n                                                   funder: str,\n                                                   payment_token: str,\n                                                   payment: int) -> ContractConstructor:\n        \"\"\"\n        :param master_copy: Master Copy of Gnosis Safe already deployed\n        :param initializer: Data initializer to send to GnosisSafe setup method\n        :param funder: Address that should get the payment (if payment set)\n        :param payment_token: Address if a token is used. If not set, 0x0 will be ether\n        :param payment: Payment\n        :return: Transaction dictionary\n        \"\"\"\n        if not funder or funder == NULL_ADDRESS:\n            funder = NULL_ADDRESS\n            payment = 0\n\n        return get_paying_proxy_contract(self.w3).constructor(\n            master_copy,\n            initializer,\n            funder,\n            payment_token,\n            payment)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nbuild a proxy contract creation transaction.", "response": "def _build_proxy_contract_creation_tx(self,\n                                          master_copy: str,\n                                          initializer: bytes,\n                                          funder: str,\n                                          payment_token: str,\n                                          payment: int,\n                                          gas: int,\n                                          gas_price: int,\n                                          nonce: int=0):\n        \"\"\"\n        :param master_copy: Master Copy of Gnosis Safe already deployed\n        :param initializer: Data initializer to send to GnosisSafe setup method\n        :param funder: Address that should get the payment (if payment set)\n        :param payment_token: Address if a token is used. If not set, 0x0 will be ether\n        :param payment: Payment\n        :return: Transaction dictionary\n        \"\"\"\n        return self._build_proxy_contract_creation_constructor(\n            master_copy,\n            initializer,\n            funder,\n            payment_token,\n            payment\n        ).buildTransaction({\n            'gas': gas,\n            'gasPrice': gas_price,\n            'nonce': nonce,\n        })"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbuilds a valid contract creation tx using a random signature.", "response": "def _build_contract_creation_tx_with_valid_signature(self, tx_dict: Dict[str, None], s: int) -> Transaction:\n        \"\"\"\n        Use pyethereum `Transaction` to generate valid tx using a random signature\n        :param tx_dict: Web3 tx dictionary\n        :param s: Signature s value\n        :return: PyEthereum creation tx for the proxy contract\n        \"\"\"\n        zero_address = HexBytes('0x' + '0' * 40)\n        f_address = HexBytes('0x' + 'f' * 40)\n        nonce = tx_dict['nonce']\n        gas_price = tx_dict['gasPrice']\n        gas = tx_dict['gas']\n        to = tx_dict.get('to', b'')  # Contract creation should always have `to` empty\n        value = tx_dict['value']\n        data = tx_dict['data']\n        for _ in range(100):\n            try:\n                v, r = self.find_valid_random_signature(s)\n                contract_creation_tx = Transaction(nonce, gas_price, gas, to, value, HexBytes(data), v=v, r=r, s=s)\n                sender_address = contract_creation_tx.sender\n                contract_address = contract_creation_tx.creates\n                if sender_address in (zero_address, f_address) or contract_address in (zero_address, f_address):\n                    raise InvalidTransaction\n                return contract_creation_tx\n            except InvalidTransaction:\n                pass\n        raise ValueError('Valid signature not found with s=%d', s)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _estimate_gas(self,\n                      master_copy: str,\n                      initializer: bytes,\n                      funder: str,\n                      payment_token: str) -> int:\n        \"\"\"\n        Gas estimation done using web3 and calling the node\n        Payment cannot be estimated, as no ether is in the address. So we add some gas later.\n        :param master_copy: Master Copy of Gnosis Safe already deployed\n        :param initializer: Data initializer to send to GnosisSafe setup method\n        :param funder: Address that should get the payment (if payment set)\n        :param payment_token: Address if a token is used. If not set, 0x0 will be ether\n        :return: Total gas estimation\n        \"\"\"\n\n        # Estimate the contract deployment. We cannot estimate the refunding, as the safe address has not any fund\n        gas: int = self._build_proxy_contract_creation_constructor(\n            master_copy,\n            initializer,\n            funder,\n            payment_token,\n            0).estimateGas()\n\n        # We estimate the refund as a new tx\n        if payment_token == NULL_ADDRESS:\n            # Same cost to send 1 ether than 1000\n            gas += self.w3.eth.estimateGas({'to': funder, 'value': 1})\n        else:\n            # Top should be around 52000 when storage is needed (funder no previous owner of token),\n            # we use value 1 as we are simulating an internal call, and in that calls you don't pay for the data.\n            # If it was a new tx sending 5000 tokens would be more expensive than sending 1 because of data costs\n            try:\n                gas += get_erc20_contract(self.w3,\n                                          payment_token).functions.transfer(funder, 1).estimateGas({'from':\n                                                                                                    payment_token})\n            except ValueError as exc:\n                raise InvalidERC20Token from exc\n\n        return gas", "response": "Estimates the amount of gas needed for the refund as a new tx"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsign a web3 transaction", "response": "def _sign_web3_transaction(tx: Dict[str, any], v: int, r: int, s: int) -> (bytes, HexBytes):\n        \"\"\"\n        Signed transaction that compatible with `w3.eth.sendRawTransaction`\n        Is not used because `pyEthereum` implementation of Transaction was found to be more\n        robust regarding invalid signatures\n        \"\"\"\n        unsigned_transaction = serializable_unsigned_transaction_from_dict(tx)\n        rlp_encoded_transaction = encode_transaction(unsigned_transaction, vrs=(v, r, s))\n\n        # To get the address signing, just do ecrecover_to_pub(unsigned_transaction.hash(), v, r, s)\n        return rlp_encoded_transaction, unsigned_transaction.hash()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if proxy is valid", "response": "def check_proxy_code(self, address) -> bool:\n        \"\"\"\n        Check if proxy is valid\n        :param address: address of the proxy\n        :return: True if proxy is valid, False otherwise\n        \"\"\"\n        deployed_proxy_code = self.w3.eth.getCode(address)\n        proxy_code_fns = (get_paying_proxy_deployed_bytecode,\n                          get_proxy_factory_contract(self.w3,\n                                                     self.proxy_factory_address).functions.proxyRuntimeCode().call)\n        for proxy_code_fn in proxy_code_fns:\n            if deployed_proxy_code == proxy_code_fn():\n                return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if a safe has enough funds to pay for a tx_gas", "response": "def check_funds_for_tx_gas(self, safe_address: str, safe_tx_gas: int, data_gas: int, gas_price: int,\n                               gas_token: str) -> bool:\n        \"\"\"\n        Check safe has enough funds to pay for a tx\n        :param safe_address: Address of the safe\n        :param safe_tx_gas: Start gas\n        :param data_gas: Data gas\n        :param gas_price: Gas Price\n        :param gas_token: Gas Token, to use token instead of ether for the gas\n        :return: True if enough funds, False, otherwise\n        \"\"\"\n        if gas_token == NULL_ADDRESS:\n            balance = self.ethereum_client.get_balance(safe_address)\n        else:\n            balance = self.ethereum_client.erc20.get_balance(safe_address, gas_token)\n        return balance >= (safe_tx_gas + data_gas) * gas_price"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef deploy_paying_proxy_contract(self, initializer=b'', deployer_account=None, deployer_private_key=None) -> str:\n        assert deployer_account or deployer_private_key\n        deployer_address = deployer_account or self.ethereum_client.private_key_to_address(deployer_private_key)\n\n        safe_proxy_contract = get_paying_proxy_contract(self.w3)\n        tx = safe_proxy_contract.constructor(self.master_copy_address, initializer,\n                                             NULL_ADDRESS,\n                                             NULL_ADDRESS, 0).buildTransaction({'from': deployer_address})\n\n        tx_hash = self.ethereum_client.send_unsigned_transaction(tx, private_key=deployer_private_key,\n                                                                  public_key=deployer_account)\n        tx_receipt = self.ethereum_client.get_transaction_receipt(tx_hash, timeout=60)\n        assert tx_receipt.status\n        return tx_receipt.contractAddress", "response": "Deploy a proxy contract. Takes deployer_account or the deployer private key of the node."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndeploys proxy contract using the Proxy Factory Contract.", "response": "def deploy_proxy_contract(self, initializer=b'', deployer_account=None, deployer_private_key=None) -> str:\n        \"\"\"\n        Deploy proxy contract using the `Proxy Factory Contract`.\n        Takes deployer_account (if unlocked in the node) or the deployer private key\n        :param initializer: Initializer\n        :param deployer_account: Unlocked ethereum account\n        :param deployer_private_key: Private key of an ethereum account\n        :return: deployed contract address\n        \"\"\"\n        assert deployer_account or deployer_private_key\n        deployer_address = deployer_account or self.ethereum_client.private_key_to_address(deployer_private_key)\n\n        proxy_factory_contract = get_proxy_factory_contract(self.w3, self.proxy_factory_address)\n        create_proxy_fn = proxy_factory_contract.functions.createProxy(self.master_copy_address, initializer)\n        contract_address = create_proxy_fn.call()\n        tx = create_proxy_fn.buildTransaction({'from': deployer_address})\n\n        tx_hash = self.ethereum_client.send_unsigned_transaction(tx, private_key=deployer_private_key,\n                                                                  public_key=deployer_account)\n        tx_receipt = self.ethereum_client.get_transaction_receipt(tx_hash, timeout=120)\n        assert tx_receipt.status\n        return contract_address"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndeploys proxy contract using create2 with the proxy factory contract.", "response": "def deploy_proxy_contract_with_nonce(self, salt_nonce: int, initializer: bytes, gas: int, gas_price: int,\n                                         deployer_private_key=None) -> Tuple[bytes, Dict[str, any], str]:\n        \"\"\"\n        Deploy proxy contract using `create2` withthe `Proxy Factory Contract`.\n        Takes `deployer_account` (if unlocked in the node) or the `deployer_private_key`\n        :param salt_nonce: Uint256 for `create2` salt\n        :param initializer: Data for safe creation\n        :param gas: Gas\n        :param gas_price: Gas Price\n        :param deployer_private_key: Private key of an ethereum account\n        :return: Tuple(tx-hash, tx, deployed contract address)\n        \"\"\"\n        assert deployer_private_key\n\n        proxy_factory_contract = get_proxy_factory_contract(self.w3, self.proxy_factory_address)\n        create_proxy_fn = proxy_factory_contract.functions.createProxyWithNonce(self.master_copy_address, initializer,\n                                                                                salt_nonce)\n        contract_address = create_proxy_fn.call()\n\n        deployer_account = Account.privateKeyToAccount(deployer_private_key)\n        nonce = self.ethereum_client.get_nonce_for_account(deployer_account.address, 'pending')\n        # Auto estimation of gas does not work. We use a little more gas just in case\n        tx = create_proxy_fn.buildTransaction({'from': deployer_account.address, 'gasPrice': gas_price,\n                                               'nonce': nonce, 'gas': gas + 50000})\n        signed_tx = deployer_account.signTransaction(tx)\n        tx_hash = self.ethereum_client.send_raw_transaction(signed_tx.rawTransaction)\n        return tx_hash, tx, contract_address"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndeploying proxy factory contract. Takes deployer_account or the deployer private key of the node. Returns the address of the deployed proxy factory contract.", "response": "def deploy_proxy_factory_contract(self, deployer_account=None, deployer_private_key=None) -> str:\n        \"\"\"\n        Deploy proxy factory contract. Takes deployer_account (if unlocked in the node) or the deployer private key\n        :param deployer_account: Unlocked ethereum account\n        :param deployer_private_key: Private key of an ethereum account\n        :return: deployed contract address\n        \"\"\"\n        assert deployer_account or deployer_private_key\n        deployer_address = deployer_account or self.ethereum_client.private_key_to_address(deployer_private_key)\n\n        proxy_factory_contract = get_proxy_factory_contract(self.w3)\n        tx = proxy_factory_contract.constructor().buildTransaction({'from': deployer_address})\n\n        tx_hash = self.ethereum_client.send_unsigned_transaction(tx, private_key=deployer_private_key,\n                                                                  public_key=deployer_account)\n\n        tx_receipt = self.ethereum_client.get_transaction_receipt(tx_hash, timeout=120)\n        assert tx_receipt.status\n        contract_address = tx_receipt.contractAddress\n        logger.info(\"Deployed and initialized Proxy Factory Contract=%s by %s\", contract_address, deployer_address)\n        return contract_address"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nestimates the gas of the transaction using the safe method.", "response": "def estimate_tx_gas_with_safe(self, safe_address: str, to: str, value: int, data: bytes, operation: int,\n                                  block_identifier='pending') -> int:\n        \"\"\"\n        Estimate tx gas using safe `requiredTxGas` method\n        :return: int: Estimated gas\n        :raises: CannotEstimateGas: If gas cannot be estimated\n        :raises: ValueError: Cannot decode received data\n        \"\"\"\n\n        data = data or b''\n\n        def parse_revert_data(result: bytes) -> int:\n            # 4 bytes - error method id\n            # 32 bytes - position\n            # 32 bytes - length\n            # Last 32 bytes - value of revert (if everything went right)\n            gas_estimation_offset = 4 + 32 + 32\n            estimated_gas = result[gas_estimation_offset:]\n\n            # Estimated gas must be 32 bytes\n            if len(estimated_gas) != 32:\n                logger.warning('Safe=%s Problem estimating gas, returned value is %s for tx=%s',\n                               safe_address, result.hex(), tx)\n                raise CannotEstimateGas('Received %s for tx=%s' % (result.hex(), tx))\n\n            return int(estimated_gas.hex(), 16)\n\n        # Add 10k, else we will fail in case of nested calls\n        try:\n            tx = self.get_contract(safe_address).functions.requiredTxGas(\n                to,\n                value,\n                data,\n                operation\n            ).buildTransaction({\n                'from': safe_address,\n                'gas': int(1e7),\n                'gasPrice': 0,\n            })\n            # If we build the tx web3 will not try to decode it for us\n            # Ganache 6.3.0 and Geth are working like this\n            result: HexBytes = self.w3.eth.call(tx, block_identifier=block_identifier)\n            return parse_revert_data(result)\n        except ValueError as exc:  # Parity\n            \"\"\"\n            Parity throws a ValueError, e.g.\n            {'code': -32015,\n             'message': 'VM execution error.',\n             'data': 'Reverted 0x08c379a00000000000000000000000000000000000000000000000000000000000000020000000000000000\n                      000000000000000000000000000000000000000000000002c4d6574686f642063616e206f6e6c792062652063616c6c656\n                      42066726f6d207468697320636f6e74726163740000000000000000000000000000000000000000'}\n            \"\"\"\n            error_dict = exc.args[0]\n            data = error_dict.get('data')\n            if not data:\n                raise exc\n            elif isinstance(data, str) and 'Reverted ' in data:\n                # Parity\n                result = HexBytes(data.replace('Reverted ', ''))\n                return parse_revert_data(result)\n\n            key = list(data.keys())[0]\n            result = data[key]['return']\n            if result == '0x0':\n                raise exc\n            else:\n                # Ganache-Cli with no `--noVMErrorsOnRPCResponse` flag enabled\n                logger.warning('You should use `--noVMErrorsOnRPCResponse` flag with Ganache-cli')\n                estimated_gas_hex = result[138:]\n                assert len(estimated_gas_hex) == 64\n                estimated_gas = int(estimated_gas_hex, 16)\n                return estimated_gas"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef estimate_tx_gas_with_web3(self, safe_address: str, to: str, value: int, data: bytes) -> int:\n        return self.ethereum_client.estimate_gas(safe_address, to, value, data, block_identifier='pending')", "response": "Estimate tx gas using web3"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef estimate_tx_gas(self, safe_address: str, to: str, value: int, data: bytes, operation: int) -> int:\n        # Costs to route through the proxy and nested calls\n        proxy_gas = 1000\n        # https://github.com/ethereum/solidity/blob/dfe3193c7382c80f1814247a162663a97c3f5e67/libsolidity/codegen/ExpressionCompiler.cpp#L1764\n        # This was `false` before solc 0.4.21 -> `m_context.evmVersion().canOverchargeGasForCall()`\n        # So gas needed by caller will be around 35k\n        old_call_gas = 35000\n        safe_gas_estimation = (self.estimate_tx_gas_with_safe(safe_address, to, value, data, operation)\n                               + proxy_gas + old_call_gas)\n        # We cannot estimate DELEGATECALL (different storage)\n        if SafeOperation(operation) == SafeOperation.CALL:\n            try:\n                web3_gas_estimation = (self.estimate_tx_gas_with_web3(safe_address, to, value, data)\n                                       + proxy_gas + old_call_gas)\n            except ValueError:\n                web3_gas_estimation = 0\n            return max(safe_gas_estimation, web3_gas_estimation)\n\n        else:\n            return safe_gas_estimation", "response": "Estimate the amount of gas needed by a safe call or web3 call."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef estimate_tx_operational_gas(self, safe_address: str, data_bytes_length: int):\n        threshold = self.retrieve_threshold(safe_address)\n        return 15000 + data_bytes_length // 32 * 100 + 5000 * threshold", "response": "Estimate the gas for the verification of the signatures and other safe related tasks\n        before and after executing a transaction."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsend a multisig tx to the user account.", "response": "def send_multisig_tx(self,\n                         safe_address: str,\n                         to: str,\n                         value: int,\n                         data: bytes,\n                         operation: int,\n                         safe_tx_gas: int,\n                         data_gas: int,\n                         gas_price: int,\n                         gas_token: str,\n                         refund_receiver: str,\n                         signatures: bytes,\n                         tx_sender_private_key: str,\n                         tx_gas=None,\n                         tx_gas_price=None,\n                         block_identifier='pending') -> Tuple[bytes, Dict[str, any]]:\n        \"\"\"\n        Send multisig tx to the Safe\n        :param tx_gas: Gas for the external tx. If not, `(safe_tx_gas + data_gas) * 2` will be used\n        :param tx_gas_price: Gas price of the external tx. If not, `gas_price` will be used\n        :return: Tuple(tx_hash, tx)\n        :raises: InvalidMultisigTx: If user tx cannot go through the Safe\n        \"\"\"\n\n        safe_tx = self.build_multisig_tx(safe_address,\n                                         to,\n                                         value,\n                                         data,\n                                         operation,\n                                         safe_tx_gas,\n                                         data_gas,\n                                         gas_price,\n                                         gas_token,\n                                         refund_receiver,\n                                         signatures)\n\n        tx_sender_address = Account.privateKeyToAccount(tx_sender_private_key).address\n        safe_tx.call(tx_sender_address=tx_sender_address)\n\n        return safe_tx.execute(tx_sender_private_key=tx_sender_private_key,\n                               tx_gas=tx_gas,\n                               tx_gas_price=tx_gas_price,\n                               block_identifier=block_identifier)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef build(self, owners: List[str], threshold: int, salt_nonce: int,\n              gas_price: int, payment_receiver: Optional[str] = None,\n              payment_token: Optional[str] = None,\n              payment_token_eth_value: float = 1.0, fixed_creation_cost: Optional[int] = None):\n        \"\"\"\n        Prepare Safe creation\n        :param owners: Owners of the Safe\n        :param threshold: Minimum number of users required to operate the Safe\n        :param salt_nonce: Web3 instance\n        :param gas_price: Gas Price\n        :param payment_receiver: Address to refund when the Safe is created. Address(0) if no need to refund\n        :param payment_token: Payment token instead of paying the funder with ether. If None Ether will be used\n        :param payment_token_eth_value: Value of payment token per 1 Ether\n        :param fixed_creation_cost: Fixed creation cost of Safe (Wei)\n        \"\"\"\n\n        assert 0 < threshold <= len(owners)\n        payment_receiver = payment_receiver or NULL_ADDRESS\n        payment_token = payment_token or NULL_ADDRESS\n        assert Web3.isChecksumAddress(payment_receiver)\n        assert Web3.isChecksumAddress(payment_token)\n\n        # Get bytes for `setup(address[] calldata _owners, uint256 _threshold, address to, bytes calldata data,\n        # address paymentToken, uint256 payment, address payable paymentReceiver)`\n        # This initializer will be passed to the ProxyFactory to be called right after proxy is deployed\n        # We use `payment=0` as safe has no ether yet and estimation will fail\n        safe_setup_data: bytes = self._get_initial_setup_safe_data(owners, threshold, payment_token=payment_token,\n                                                                   payment_receiver=payment_receiver)\n\n        magic_gas: int = self._calculate_gas(owners, safe_setup_data, payment_token)\n        estimated_gas: int = self._estimate_gas(safe_setup_data,\n                                                salt_nonce, payment_token, payment_receiver)\n        logger.debug('Magic gas %d - Estimated gas %d' % (magic_gas, estimated_gas))\n        gas = max(magic_gas, estimated_gas)\n\n        # Payment will be safe deploy cost\n        payment = self._calculate_refund_payment(gas,\n                                                 gas_price,\n                                                 fixed_creation_cost,\n                                                 payment_token_eth_value)\n\n        # Now we have a estimate for `payment` so we get initialization data again\n        safe_setup_data: bytes = self._get_initial_setup_safe_data(owners, threshold, payment_token=payment_token,\n                                                                   payment=payment, payment_receiver=payment_receiver)\n\n        safe_address = self.calculate_create2_address(safe_setup_data, salt_nonce)\n        assert int(safe_address, 16), 'Calculated Safe address cannot be the NULL ADDRESS'\n\n        return SafeCreate2Tx(salt_nonce, owners, threshold, self.master_copy_address, self.proxy_factory_address,\n                             payment_receiver, payment_token, payment, gas, gas_price, payment_token_eth_value,\n                             fixed_creation_cost, safe_address, safe_setup_data)", "response": "Prepare Safe creation for the given list of owners."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalculating the gas needed for the deployment.", "response": "def _calculate_gas(owners: List[str], safe_setup_data: bytes, payment_token: str) -> int:\n        \"\"\"\n        Calculate gas manually, based on tests of previosly deployed safes\n        :param owners: Safe owners\n        :param safe_setup_data: Data for proxy setup\n        :param payment_token: If payment token, we will need more gas to transfer and maybe storage if first time\n        :return: total gas needed for deployment\n        \"\"\"\n        base_gas = 205000  # Transaction base gas\n\n        # If we already have the token, we don't have to pay for storage, so it will be just 5K instead of 20K.\n        # The other 1K is for overhead of making the call\n        if payment_token != NULL_ADDRESS:\n            payment_token_gas = 55000\n        else:\n            payment_token_gas = 0\n\n        data_gas = 68 * len(safe_setup_data)  # Data gas\n        gas_per_owner = 20000  # Magic number calculated by testing and averaging owners\n        return base_gas + data_gas + payment_token_gas + len(owners) * gas_per_owner"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _estimate_gas(self, initializer: bytes, salt_nonce: int,\n                      payment_token: str, payment_receiver: str) -> int:\n        \"\"\"\n        Gas estimation done using web3 and calling the node\n        Payment cannot be estimated, as no ether is in the address. So we add some gas later.\n        :param initializer: Data initializer to send to GnosisSafe setup method\n        :param salt_nonce: Nonce that will be used to generate the salt to calculate\n        the address of the new proxy contract.\n        :return: Total gas estimation\n        \"\"\"\n\n        # Estimate the contract deployment. We cannot estimate the refunding, as the safe address has not any fund\n        gas: int = self.proxy_factory_contract.functions.createProxyWithNonce(self.master_copy_address,\n                                                                              initializer, salt_nonce).estimateGas()\n\n        # It's not very relevant if is 1 or 9999\n        payment: int = 1\n\n        # We estimate the refund as a new tx\n        if payment_token == NULL_ADDRESS:\n            # Same cost to send 1 ether than 1000\n            gas += self.w3.eth.estimateGas({'to': payment_receiver, 'value': payment})\n        else:\n            # Top should be around 52000 when storage is needed (funder no previous owner of token),\n            # we use value 1 as we are simulating an internal call, and in that calls you don't pay for the data.\n            # If it was a new tx sending 5000 tokens would be more expensive than sending 1 because of data costs\n            gas += 55000\n            # try:\n            #     gas += get_erc20_contract(self.w3,\n            #                               payment_token).functions.transfer(payment_receiver,\n            #                                                                 payment).estimateGas({'from':\n            #                                                                                      payment_token})\n            # except ValueError as exc:\n            #     raise InvalidERC20Token from exc\n\n        return gas", "response": "Estimates the amount of gas needed to send a new proxy contract."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef w3_tx(self):\n        safe_contract = get_safe_contract(self.w3, address=self.safe_address)\n        return safe_contract.functions.execTransaction(\n            self.to,\n            self.value,\n            self.data,\n            self.operation,\n            self.safe_tx_gas,\n            self.data_gas,\n            self.gas_price,\n            self.gas_token,\n            self.refund_receiver,\n            self.signatures)", "response": "Execute a Web3 transaction."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef call(self, tx_sender_address: Optional[str] = None, tx_gas: Optional[int] = None,\n             block_identifier='pending') -> int:\n        \"\"\"\n        :param tx_sender_address:\n        :param tx_gas: Force a gas limit\n        :param block_identifier:\n        :return: `1` if everything ok\n        \"\"\"\n        parameters = {}\n        if tx_sender_address:\n            parameters['from'] = tx_sender_address\n        if tx_gas:\n            parameters['gas'] = tx_gas\n        try:\n            success = self.w3_tx.call(parameters, block_identifier=block_identifier)\n\n            if not success:\n                raise InvalidInternalTx('Success bit is %d, should be equal to 1' % success)\n            return success\n        except BadFunctionCallOutput as exc:  # Geth\n            return self._parse_vm_exception(str(exc))\n        except ValueError as exc:  # Parity\n            \"\"\"\n            Parity throws a ValueError, e.g.\n            {'code': -32015,\n             'message': 'VM execution error.',\n             'data': 'Reverted 0x08c379a0000000000000000000000000000000000000000000000000000000000000020000000000000000\n                      000000000000000000000000000000000000000000000001b496e76616c6964207369676e6174757265732070726f7669\n                      6465640000000000'\n            }\n            \"\"\"\n            error_dict = exc.args[0]\n            data = error_dict.get('data')\n            if not data:\n                raise exc\n            elif isinstance(data, str) and 'Reverted ' in data:\n                # Parity\n                result = HexBytes(data.replace('Reverted ', ''))\n                return self._parse_vm_exception(str(result))", "response": "Calls the W3C method."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsends a multisig tx to the ETHereum client.", "response": "def execute(self,\n                tx_sender_private_key: str,\n                tx_gas: Optional[int] = None,\n                tx_gas_price: Optional[int] = None,\n                tx_nonce: Optional[int] = None,\n                block_identifier='pending') -> Tuple[bytes, Dict[str, any]]:\n        \"\"\"\n        Send multisig tx to the Safe\n        :param tx_sender_private_key: Sender private key\n        :param tx_gas: Gas for the external tx. If not, `(safe_tx_gas + data_gas) * 2` will be used\n        :param tx_gas_price: Gas price of the external tx. If not, `gas_price` will be used\n        :param tx_nonce: Force nonce for `tx_sender`\n        :param block_identifier: `latest` or `pending`\n        :return: Tuple(tx_hash, tx)\n        :raises: InvalidMultisigTx: If user tx cannot go through the Safe\n        \"\"\"\n\n        tx_gas_price = tx_gas_price or self.gas_price  # Use wrapped tx gas_price if not provided\n        tx_gas = tx_gas or (self.safe_tx_gas + self.data_gas) * 2\n        tx_sender_address = Account.privateKeyToAccount(tx_sender_private_key).address\n\n        tx_parameters = {\n            'from': tx_sender_address,\n            'gas': tx_gas,\n            'gasPrice': tx_gas_price,\n        }\n        if tx_nonce is not None:\n            tx_parameters['nonce'] = tx_nonce\n\n        self.tx = self.w3_tx.buildTransaction(tx_parameters)\n        self.tx_hash = self.ethereum_client.send_unsigned_transaction(self.tx,\n                                                                      private_key=tx_sender_private_key,\n                                                                      retry=True,\n                                                                      block_identifier=block_identifier)\n        return self.tx_hash, self.tx"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrite towrite to the write queue and waits for all data to be written.", "response": "async def write(self, towrite: bytes, await_blocking=False):\n        \"\"\"\n        Appends towrite to the write queue\n\n        >>> await test.write(b\"HELLO\")\n        # Returns without wait time\n        >>> await test.write(b\"HELLO\", await_blocking = True)\n        # Returns when the bufer is flushed\n\n        :param towrite:      Write buffer\n        :param await_blocking:  wait for everything to be written\n        \"\"\"\n\n        await self._write(towrite)\n\n        # Wait for the output buffer to be flushed if requested\n        if await_blocking:\n            return await self.flush()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread a given number of bytes from the cache.", "response": "async def read(self, num_bytes=0) -> bytes:\n        \"\"\"\n        Reads a given number of bytes\n\n        :param bytecount: How many bytes to read, leave it at default\n                          to read everything that is available\n        :returns: incoming bytes\n        \"\"\"\n        if num_bytes < 1:\n            num_bytes = self.in_waiting or 1\n\n        return await self._read(num_bytes)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading a given number of bytes from the serial port.", "response": "async def _read(self, num_bytes) -> bytes:\n        \"\"\"\n        Reads a given number of bytes\n\n        :param num_bytes: How many bytes to read\n        :returns: incoming bytes\n        \"\"\"\n        while True:\n\n            if self.in_waiting < num_bytes:\n                await asyncio.sleep(self._asyncio_sleep_time)\n\n            else:\n                # Try to read bytes\n                inbytes = self._serial_instance.read(num_bytes)\n\n                # Just for safety, should never happen\n                if not inbytes:\n                    await asyncio.sleep(self._asyncio_sleep_time)\n                else:\n                    return inbytes"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def readline(self) -> bytes:\n        while True:\n            line = self._serial_instance.readline()\n            if not line:\n                await asyncio.sleep(self._asyncio_sleep_time)\n            else:\n                return line", "response": "Reads one line from the serial port."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nverifies and sends a message.", "response": "def send(self, message):\n        \"\"\"Verifies and sends message.\n\n        :param message: Message instance.\n        :param envelope_from: Email address to be used in MAIL FROM command.\n        \"\"\"\n        assert message.send_to, \"No recipients have been added\"\n\n        if message.has_bad_headers(self.mail.default_sender):\n            raise BadHeaderError\n\n        if message.date is None:\n            message.date = time.time()\n\n        sender = message.sender or self.mail.default_sender\n        if self.host:\n            self.host.sendmail(sanitize_address(sender) if sender is not None else None,\n                               message.send_to,\n                               message.as_string(self.mail.default_sender),\n                               message.mail_options,\n                               message.rcpt_options)\n\n        email_dispatched.send(message, mail=self.mail)\n\n        self.num_emails += 1\n\n        if self.num_emails == self.mail.max_emails:\n            self.num_emails = 0\n            if self.host:\n                self.host.quit()\n                self.host = self.configure_host()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _mimetext(self, text, subtype='plain'):\n        charset = self.charset or 'utf-8'\n        return MIMEText(text, _subtype=subtype, _charset=charset)", "response": "Create a MIMEText object with the given text."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates the email as a string.", "response": "def as_string(self, default_from=None):\n        \"\"\"Creates the email\"\"\"\n\n        encoding = self.charset or 'utf-8'\n\n        attachments = self.attachments or []\n\n        if len(attachments) == 0 and not self.html:\n            # No html content and zero attachments means plain text\n            msg = self._mimetext(self.body)\n        elif len(attachments) > 0 and not self.html:\n            # No html and at least one attachment means multipart\n            msg = MIMEMultipart()\n            msg.attach(self._mimetext(self.body))\n        else:\n            # Anything else\n            msg = MIMEMultipart()\n            alternative = MIMEMultipart('alternative')\n            alternative.attach(self._mimetext(self.body, 'plain'))\n            alternative.attach(self._mimetext(self.html, 'html'))\n            msg.attach(alternative)\n\n        if self.charset:\n            msg['Subject'] = Header(self.subject, encoding)\n        else:\n            msg['Subject'] = self.subject\n\n        sender = self.sender or default_from\n        if sender is not None:\n            msg['From'] = sanitize_address(sender, encoding)\n        msg['To'] = ', '.join(list(set(sanitize_addresses(self.recipients, encoding))))\n\n        msg['Date'] = formatdate(self.date, localtime=True)\n        # see RFC 5322 section 3.6.4.\n        msg['Message-ID'] = self.msgId\n\n        if self.cc:\n            msg['Cc'] = ', '.join(list(set(sanitize_addresses(self.cc, encoding))))\n\n        if self.reply_to:\n            msg['Reply-To'] = sanitize_address(self.reply_to, encoding)\n\n        if self.extra_headers:\n            for k, v in self.extra_headers.items():\n                msg[k] = v\n\n        for attachment in attachments:\n            f = MIMEBase(*attachment.content_type.split('/'))\n            f.set_payload(attachment.data)\n            encode_base64(f)\n\n            try:\n                attachment.filename and attachment.filename.encode('ascii')\n            except UnicodeEncodeError:\n                filename = attachment.filename\n                if not PY3:\n                    filename = filename.encode('utf8')\n                f.add_header('Content-Disposition', attachment.disposition,\n                            filename=('UTF8', '', filename))\n            else:\n                f.add_header('Content-Disposition', '%s;filename=%s' %\n                             (attachment.disposition, attachment.filename))\n\n            for key, value in attachment.headers:\n                f.add_header(key, value)\n\n            msg.attach(f)\n\n        return msg.as_string()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef has_bad_headers(self, default_from=None):\n\n        sender = self.sender or default_from\n        reply_to = self.reply_to or ''\n        for val in [self.subject, sender, reply_to] + self.recipients:\n            for c in '\\r\\n':\n                if c in val:\n                    return True\n        return False", "response": "Checks if the message contains bad headers i. e. newlines in subject sender or recipients."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef attach(self,\n               filename=None,\n               content_type=None,\n               data=None,\n               disposition=None,\n               headers=None):\n        \"\"\"Adds an attachment to the message.\n\n        :param filename: filename of attachment\n        :param content_type: file mimetype\n        :param data: the raw file data\n        :param disposition: content-disposition (if any)\n        \"\"\"\n        self.attachments.append(\n            Attachment(filename, content_type, data, disposition, headers))", "response": "Adds an attachment to the message."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrecord all messages. Use in unit tests for example:: with mail.record_messages() as outbox: response = app.test_client.get(\"/email-sending-view/\") assert len(outbox) == 1 assert outbox[0].subject == \"testing\" You must have blinker installed in order to use this feature. :versionadded: 0.4", "response": "def record_messages(self):\n        \"\"\"Records all messages. Use in unit tests for example::\n\n            with mail.record_messages() as outbox:\n                response = app.test_client.get(\"/email-sending-view/\")\n                assert len(outbox) == 1\n                assert outbox[0].subject == \"testing\"\n\n        You must have blinker installed in order to use this feature.\n        :versionadded: 0.4\n        \"\"\"\n\n        if not email_dispatched:\n            raise RuntimeError(\"blinker must be installed\")\n\n        outbox = []\n\n        def _record(message, mail):\n            outbox.append(message)\n\n        email_dispatched.connect(_record)\n\n        try:\n            yield outbox\n        finally:\n            email_dispatched.disconnect(_record)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nregister Services that can be accessed by this DAL.", "response": "def register_services(self, **services):\n        \"\"\"\n        Register Services that can be accessed by this DAL. Upon\n        registration, the service is set up.\n\n        :param **services: Keyword arguments where the key is the name\n          to register the Service as and the value is the Service.\n        \"\"\"\n        for key, service in services.items():\n            if key in self._services:\n                raise AlreadyExistsException('A Service for {} is already registered.'.format(key))\n\n            self._init_service(key, service)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nregisters a list of middleware to be executed in order of execution.", "response": "def register_context_middleware(self, *middleware):\n        \"\"\"\n        :param middleware: Middleware in order of execution\n        \"\"\"\n        for m in middleware:\n            if not is_generator(m):\n                raise Exception('Middleware {} must be a Python generator callable.'.format(m))\n\n        self._middleware.extend(middleware)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading a configuration module and return a Config object", "response": "def from_module(module_name):\n    \"\"\"\n    Load a configuration module and return a Config\n    \"\"\"\n    d = importlib.import_module(module_name)\n    config = {}\n    for key in dir(d):\n        if key.isupper():\n            config[key] = getattr(d, key)\n    return Config(config)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef register_resources(self, **resources):\n        for key, resource in resources.items():\n            if key in self._resources:\n                raise AlreadyExistsException('A Service for {} is already registered.'.format(key))\n\n            self._init_resource(key, resource)", "response": "Register resources with the ResourceManager."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the value for the given key. Raises an exception if the key is empty.", "response": "def require(self, key):\n        \"\"\"\n        Raises an exception if value for ``key`` is empty.\n        \"\"\"\n        value = self.get(key)\n        if not value:\n            raise ValueError('\"{}\" is empty.'.format(key))\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nhook to setup this service with a specific DataManager. Will recursively setup sub-services.", "response": "def setup(self, data_manager):\n        \"\"\"\n        Hook to setup this service with a specific DataManager.\n\n        Will recursively setup sub-services.\n        \"\"\"\n        self._data_manager = data_manager\n        if self._data_manager:\n            self._dal = self._data_manager.get_dal()\n        else:\n            self._dal = None\n\n        for key, service in self._services.items():\n            service.setup(self._data_manager)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the group index with respect to wavelength.", "response": "def ng(self, wavelength):\n        '''\n        The group index with respect to wavelength.\n\n        Args:\n            wavelength (float, list, None): The wavelength(s) the group\n                index will be evaluated at.\n\n        Returns:\n            float, list: The group index at the target wavelength(s).\n        '''\n        return self.n(wavelength) - (wavelength*1.e-9)*self.nDer1(wavelength)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef gvd(self, wavelength):\n        '''\n        The group velocity dispersion (GVD) with respect to wavelength.\n\n        Args:\n            wavelength (float, list, None): The wavelength(s) the GVD will\n                be evaluated at.\n\n        Returns:\n            float, list: The GVD at the target wavelength(s).\n        '''\n        g = (wavelength*1.e-9)**3./(2.*spc.pi*spc.c**2.) * self.nDer2(wavelength)\n        return g", "response": "Returns the group velocity dispersion of the entry in the system at the target wavelength."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninitializing the object with the username and password.", "response": "def initialize(self):\n        # pylint: disable=attribute-defined-outside-init\n        \"\"\"Login on backend with username and password\n\n        :return: None\n        \"\"\"\n        try:\n            logger.info(\"Authenticating...\")\n            self.backend = Backend(self.backend_url)\n            self.backend.login(self.username, self.password)\n        except BackendException as exp:  # pragma: no cover, should never happen\n            logger.exception(\"Exception: %s\", exp)\n            logger.error(\"Response: %s\", exp.response)\n\n        if self.backend.token is None:\n            print(\"Access denied!\")\n            print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n            print(\"Exiting with error code: 1\")\n            exit(1)\n\n        logger.info(\"Authenticated.\")\n\n        # Logged-in user and default realm\n        users = self.backend.get_all('user', {'where': json.dumps({'name': self.username})})\n        self.logged_in_user = users['_items'][0]\n        self.default_realm = self.logged_in_user['_realm']\n\n        # Main realm\n        self.realm_all = None\n        realms = self.backend.get_all('realm')\n        for r in realms['_items']:\n            if r['name'] == 'All' and r['_level'] == 0:\n                self.realm_all = r['_id']\n                logger.info(\"Found realm 'All': %s\", self.realm_all)\n            if r['_id'] == self.default_realm:\n                logger.info(\"Found logged-in user realm: %s\", r['name'])\n\n        # Default timeperiods\n        self.tp_always = None\n        self.tp_never = None\n        timeperiods = self.backend.get_all('timeperiod')\n        for tp in timeperiods['_items']:\n            if tp['name'] == '24x7':\n                self.tp_always = tp['_id']\n                logger.info(\"Found TP '24x7': %s\", self.tp_always)\n            if tp['name'].lower() == 'none' or tp['name'].lower() == 'never':\n                self.tp_never = tp['_id']\n                logger.info(\"Found TP 'Never': %s\", self.tp_never)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef file_dump(self, data, filename):  # pylint: disable=no-self-use\n        dump = json.dumps(data, indent=4,\n                          separators=(',', ': '), sort_keys=True)\n        path = os.path.join(self.folder or os.getcwd(), filename)\n        try:\n            dfile = open(path, \"wt\")\n            dfile.write(dump)\n            dfile.close()\n            return path\n        except (OSError, IndexError) as exp:  # pragma: no cover, should never happen\n            logger.exception(\"Error when writing the list dump file %s : %s\", path, str(exp))\n        return None", "response": "Dump the data to a JSON formatted file."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a specific resource list.", "response": "def get_resource_list(self, resource_name, name=''):\n        # pylint: disable=too-many-locals, too-many-nested-blocks\n        \"\"\"Get a specific resource list\n\n        If name is not None, it may be a request to get the list of the services of an host.\n        \"\"\"\n        try:\n            logger.info(\"Trying to get %s list\", resource_name)\n\n            params = {}\n            if resource_name in ['host', 'service', 'user']:\n                params = {'where': json.dumps({'_is_template': self.model})}\n\n            if resource_name == 'service' and name and '/' in name:\n                splitted_name = name.split('/')\n\n                # Get host from name\n                response2 = self.backend.get(\n                    'host', params={'where': json.dumps({'name': splitted_name[0],\n                                                         '_is_template': self.model})})\n                if response2['_items']:\n                    host = response2['_items'][0]\n                    logger.info(\"Got host '%s' for the service '%s'\",\n                                splitted_name[0], splitted_name[1])\n                else:\n                    logger.warning(\"Not found host '%s'!\", splitted_name[0])\n                    return False\n\n                params = {'where': json.dumps({'host': host['_id']})}\n\n            if self.embedded and resource_name in self.embedded_resources:\n                params.update({'embedded': json.dumps(self.embedded_resources[resource_name])})\n\n            rsp = self.backend.get_all(resource_name, params=params)\n            if rsp['_items'] and rsp['_status'] == 'OK':\n                response = rsp['_items']\n\n                logger.info(\"-> found %ss\", resource_name)\n\n                # Exists in the backend, we got the element\n                if not self.dry_run:\n                    logger.info(\"-> dumping %ss list\", resource_name)\n                    for item in response:\n                        # Filter fields prefixed with an _ (internal backend fields)\n                        for field in list(item):\n                            if field in ['_created', '_updated', '_etag', '_links', '_status']:\n                                item.pop(field)\n                                continue\n\n                            # Filter fields prefixed with an _ in embedded items\n                            if self.embedded and resource_name in self.embedded_resources and \\\n                                    field in self.embedded_resources[resource_name]:\n                                # Embedded items may be a list or a simple dictionary,\n                                # always make it a list\n                                embedded_items = item[field]\n                                if not isinstance(item[field], list):\n                                    embedded_items = [item[field]]\n                                # Filter fields in each embedded item\n                                for embedded_item in embedded_items:\n                                    if not embedded_item:\n                                        continue\n                                    for embedded_field in list(embedded_item):\n                                        if embedded_field.startswith('_'):\n                                            embedded_item.pop(embedded_field)\n\n                    filename = self.file_dump(response, 'alignak-%s-list-%ss.json'\n                                              % ('model' if self.model else 'object',\n                                                 resource_name))\n                    if filename:\n                        logger.info(\"-> dumped %ss list to %s\", resource_name, filename)\n                else:\n                    logger.info(\"Dry-run mode: should have dumped an %s list\", resource_name)\n\n                return True\n            else:\n                logger.warning(\"-> %s list is empty\", resource_name)\n                if not self.dry_run:\n                    logger.info(\"-> dumping %ss list\", resource_name)\n                    filename = self.file_dump([], 'alignak-%s-list-%ss.json'\n                                              % ('model' if self.model else 'object',\n                                                 resource_name))\n                    if filename:\n                        logger.info(\"-> dumped %ss list to %s\", resource_name, filename)\n\n                return True\n\n        except BackendException as exp:  # pragma: no cover, should never happen\n            logger.exception(\"Exception: %s\", exp)\n            logger.error(\"Response: %s\", exp.response)\n            print(\"Get error for '%s' list\" % (resource_name))\n            print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n            print(\"Exiting with error code: 5\")\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a specific resource by name", "response": "def get_resource(self, resource_name, name):\n        # pylint: disable=too-many-locals, too-many-nested-blocks\n        \"\"\"Get a specific resource by name\"\"\"\n        try:\n            logger.info(\"Trying to get %s: '%s'\", resource_name, name)\n\n            services_list = False\n            if resource_name == 'host' and '/' in name:\n                splitted_name = name.split('/')\n                services_list = True\n                name = splitted_name[0]\n\n            params = {'where': json.dumps({'name': name})}\n\n            if resource_name in ['host', 'service', 'user']:\n                params = {'where': json.dumps({'name': name, '_is_template': self.model})}\n\n            if resource_name == 'service' and '/' in name:\n                splitted_name = name.split('/')\n                # new_name = splitted_name[0] + '_' + splitted_name[1]\n                # name = splitted_name[1]\n\n                # Get host from name\n                response2 = self.backend.get(\n                    'host', params={'where': json.dumps({'name': splitted_name[0]})})\n                if response2['_items']:\n                    host = response2['_items'][0]\n                    logger.info(\"Got host '%s' for the service '%s'\",\n                                splitted_name[0], splitted_name[1])\n                else:\n                    logger.warning(\"Not found host '%s'!\", splitted_name[0])\n                    return False\n\n                params = {'where': json.dumps({'name': splitted_name[1],\n                                               'host': host['_id'],\n                                               '_is_template': self.model})}\n\n            if self.embedded and resource_name in self.embedded_resources:\n                params.update({'embedded': json.dumps(self.embedded_resources[resource_name])})\n\n            response = self.backend.get(resource_name, params=params)\n            if response['_items']:\n                response = response['_items'][0]\n\n                logger.info(\"-> found %s '%s': %s\", resource_name, name, response['_id'])\n\n                if services_list:\n                    # Get services for the host\n                    params = {'where': json.dumps({'host': response['_id']})}\n                    if self.embedded and 'service' in self.embedded_resources:\n                        params.update(\n                            {'embedded': json.dumps(self.embedded_resources['service'])})\n\n                    response2 = self.backend.get('service', params=params)\n                    if response2['_items']:\n                        response['_services'] = response2['_items']\n                        logger.info(\"Got %d services for host '%s'\",\n                                    len(response2['_items']), splitted_name[0])\n                    else:\n                        logger.warning(\"Not found host '%s'!\", splitted_name[0])\n                        return False\n\n                # Exists in the backend, we got the element\n                if not self.dry_run:\n                    logger.info(\"-> dumping %s: %s\", resource_name, name)\n                    # Filter fields prefixed with an _ (internal backend fields)\n                    for field in list(response):\n                        if field in ['_created', '_updated', '_etag', '_links', '_status']:\n                            response.pop(field)\n                            continue\n\n                        # Filter fields prefixed with an _ in embedded items\n                        if self.embedded and resource_name in self.embedded_resources and \\\n                                field in self.embedded_resources[resource_name]:\n                            logger.info(\"-> embedded %s\", field)\n                            # Embedded items may be a list or a simple dictionary,\n                            # always make it a list\n                            embedded_items = response[field]\n                            if not isinstance(response[field], list):\n                                embedded_items = [response[field]]\n                            # Filter fields in each embedded item\n                            for embedded_item in embedded_items:\n                                if not embedded_item:\n                                    continue\n                                for embedded_field in list(embedded_item):\n                                    if embedded_field.startswith('_'):\n                                        embedded_item.pop(embedded_field)\n\n                    dump = json.dumps(response, indent=4,\n                                      separators=(',', ': '), sort_keys=True)\n                    if not self.quiet:\n                        print(dump)\n\n                    if resource_name == 'service' and '/' in name:\n                        name = splitted_name[0] + '_' + splitted_name[1]\n                    filename = self.file_dump(response,\n                                              'alignak-object-dump-%s-%s.json'\n                                              % (resource_name, name))\n                    if filename:\n                        logger.info(\"-> dumped %s '%s' to %s\", resource_name, name, filename)\n\n                    logger.info(\"-> dumped %s: %s\", resource_name, name)\n                else:\n                    if resource_name == 'service' and '/' in name:\n                        name = splitted_name[0] + '_' + splitted_name[1]\n                    logger.info(\"Dry-run mode: should have dumped an %s '%s'\",\n                                resource_name, name)\n\n                return True\n            else:\n                logger.warning(\"-> %s '%s' not found\", resource_name, name)\n                return False\n\n        except BackendException as exp:  # pragma: no cover, should never happen\n            logger.exception(\"Exception: %s\", exp)\n            logger.error(\"Response: %s\", exp.response)\n            print(\"Get error for  '%s' : %s\" % (resource_name, name))\n            print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n            print(\"Exiting with error code: 5\")\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndeletes a specific resource by name", "response": "def delete_resource(self, resource_name, name):\n        \"\"\"Delete a specific resource by name\"\"\"\n        try:\n            logger.info(\"Trying to get %s: '%s'\", resource_name, name)\n\n            if name is None:\n                # No name is defined, delete all the resources...\n                if not self.dry_run:\n                    headers = {\n                        'Content-Type': 'application/json'\n                    }\n                    logger.info(\"-> deleting all %s\", resource_name)\n                    self.backend.delete(resource_name, headers)\n                    logger.info(\"-> deleted all %s\", resource_name)\n                else:\n                    response = {'_id': '_fake', '_etag': '_fake'}\n                    logger.info(\"Dry-run mode: should have deleted all %s\", resource_name)\n            else:\n                params = {'where': json.dumps({'name': name})}\n                if resource_name in ['host', 'service', 'user']:\n                    params = {'where': json.dumps({'name': name, '_is_template': self.model})}\n                if resource_name == 'service' and '/' in name:\n                    splitted_name = name.split('/')\n                    name = splitted_name[0] + '_' + splitted_name[1]\n\n                    # Get host from name\n                    response2 = self.backend.get(\n                        'host', params={'where': json.dumps({'name': splitted_name[0]})})\n                    if response2['_items']:\n                        host = response2['_items'][0]\n                        logger.info(\"Got host '%s' for the service '%s'\",\n                                    splitted_name[0], splitted_name[1])\n                    else:\n                        logger.warning(\"Not found host '%s'!\", splitted_name[0])\n                        return False\n\n                    if splitted_name[1] == '*':\n                        params = {'where': json.dumps({'host': host['_id']})}\n                    else:\n                        params = {'where': json.dumps({'name': splitted_name[1],\n                                                       'host': host['_id']})}\n\n                response = self.backend.get_all(resource_name, params=params)\n                if response['_items']:\n                    logger.info(\"-> found %d matching %s\", len(response['_items']), resource_name)\n                    for item in response['_items']:\n                        logger.info(\"-> found %s '%s': %s\", resource_name, name, item['name'])\n\n                        # Exists in the backend, we must delete the element...\n                        if not self.dry_run:\n                            headers = {\n                                'Content-Type': 'application/json',\n                                'If-Match': item['_etag']\n                            }\n                            logger.info(\"-> deleting %s: %s\", resource_name, item['name'])\n                            self.backend.delete(resource_name + '/' + item['_id'], headers)\n                            logger.info(\"-> deleted %s: %s\", resource_name, item['name'])\n                        else:\n                            response = {'_id': '_fake', '_etag': '_fake'}\n                            logger.info(\"Dry-run mode: should have deleted an %s '%s'\",\n                                        resource_name, name)\n                        logger.info(\"-> deleted: '%s': %s\",\n                                    resource_name, item['_id'])\n                else:\n                    logger.warning(\"-> %s item '%s' not found\", resource_name, name)\n                    return False\n        except BackendException as exp:  # pragma: no cover, should never happen\n            logger.exception(\"Exception: %s\", exp)\n            logger.error(\"Response: %s\", exp.response)\n            print(\"Deletion error for  '%s' : %s\" % (resource_name, name))\n            print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n            print(\"Exiting with error code: 5\")\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates or update a specific resource in the backend.", "response": "def create_update_resource(self, resource_name, name, update=False):\n        # pylint: disable=too-many-return-statements, too-many-locals\n        # pylint: disable=too-many-nested-blocks\n        \"\"\"Create or update a specific resource\n\n        :param resource_name: backend resource endpoint (eg. host, user, ...)\n        :param name: name of the resource to create/update\n        :param update: True to update an existing resource, else will try to create\n        :return:\n        \"\"\"\n        if self.data is None:\n            self.data = {}\n\n        # If some data are provided, try to get them\n        json_data = None\n        if self.data:\n            try:\n                # Data may be provided on the command line or from a file\n                if self.data == 'stdin':\n                    input_file = sys.stdin\n                else:\n                    path = os.path.join(self.folder or os.getcwd(), self.data)\n                    input_file = open(path)\n\n                json_data = json.load(input_file)\n                logger.info(\"Got provided data: %s\", json_data)\n                if input_file is not sys.stdin:\n                    input_file.close()\n            except IOError:\n                logger.error(\"Error reading data file: %s\", path)\n                return False\n            except ValueError:\n                logger.error(\"Error malformed data file: %s\", path)\n                return False\n\n        if name is None and json_data is None:\n            logger.error(\"-> can not add/update a %s without a name and/or data!\", resource_name)\n            return False\n\n        # Manage provided templates\n        used_templates = []\n        if self.templates is not None:\n            logger.info(\"Searching the %s template(s): %s\",\n                        resource_name, self.templates)\n            for template in self.templates:\n                response = self.backend.get(\n                    resource_name, params={'where': json.dumps({'name': template,\n                                                                '_is_template': True})})\n                if response['_items']:\n                    used_templates.append(response['_items'][0]['_id'])\n\n                    logger.info(\"-> found %s template '%s': %s\",\n                                resource_name, template, response['_items'][0]['_id'])\n                else:\n                    logger.error(\"-> %s required template not found '%s'\", resource_name, template)\n                    return False\n\n        try:\n            if json_data is None:\n                json_data = {'name': name}\n\n            if not isinstance(json_data, list):\n                json_data = [json_data]\n\n            logger.info(\"Got %d %ss\", len(json_data), resource_name)\n            count = 0\n            for json_item in json_data:\n                logger.info(\"-> json item: %s\", json_item)\n                if resource_name not in ['history', 'userrestrictrole', 'logcheckresult'] \\\n                        and name is None and ('name' not in json_item or not json_item['name']):\n                    logger.warning(\"-> unnamed '%s'!\", resource_name)\n                    continue\n\n                # Manage resource name\n                item_name = name\n                if 'name' in json_item:\n                    item_name = json_item['name']\n\n                # Got the item name\n                params = {'name': item_name}\n\n                if resource_name == 'service' and 'host' in json_item:\n                    # Get host from name\n                    host_search = {'name': json_item['host']}\n                    if '_is_template' in json_item:\n                        host_search.update({'_is_template': json_item['_is_template']})\n                    logger.info(\"Host search: %s\", host_search)\n                    resp_host = self.backend.get(\n                        'host', params={'where': json.dumps(host_search)})\n                    if resp_host['_items']:\n                        host = resp_host['_items'][0]\n                        logger.info(\"Got host '%s' for the service '%s'\", host['name'], item_name)\n                    else:\n                        logger.warning(\"Host not found: '%s' for the service: %s!\",\n                                       json_item['host'], item_name)\n                        continue\n\n                    params = {'name': item_name, 'host': host['_id']}\n\n                if resource_name == 'service' and '/' in item_name:\n                    splitted_name = item_name.split('/')\n\n                    # Get host from name\n                    host_search = {'name': splitted_name[0]}\n                    if '_is_template' in json_item:\n                        host_search.update({'_is_template': json_item['_is_template']})\n                    resp_host = self.backend.get(\n                        'host', params={'where': json.dumps(host_search)})\n                    if resp_host['_items']:\n                        host = resp_host['_items'][0]\n                        logger.info(\"Got host '%s' for the service '%s'\",\n                                    splitted_name[0], splitted_name[1])\n                    else:\n                        logger.warning(\"Host not found: '%s' for the service: %s!\",\n                                       splitted_name[0], item_name)\n                        continue\n\n                    item_name = splitted_name[1]\n                    params = {'name': item_name, 'host': host['_id']}\n\n                if '_is_template' in json_item:\n                    params.update({'_is_template': json_item['_is_template']})\n\n                params = {'where': json.dumps(params)}\n\n                if name:\n                    logger.info(\"Trying to get %s: '%s', params: %s\",\n                                resource_name, item_name, params)\n                    response = self.backend.get(resource_name, params=params)\n                    if response['_items']:\n                        found_item = response['_items'][0]\n                        found_id = found_item['_id']\n                        found_etag = found_item['_etag']\n                        logger.info(\"-> found %s '%s': %s\", resource_name, item_name, found_id)\n\n                        if not update:\n                            logger.warning(\"-> '%s' %s cannot be created because it already \"\n                                           \"exists!\", resource_name, item_name)\n                            continue\n                    else:\n                        if update:\n                            logger.warning(\"-> '%s' %s cannot be updated because it does not \"\n                                           \"exist!\", resource_name, item_name)\n                            continue\n\n                # Item data updated with provided information if some\n\n                # Data to update\n                item_data = {}\n                if self.include_read_data:\n                    # Include read data if required\n                    item_data = found_item\n\n                # Json provided data update existing data\n                item_data.update(json_item)\n                # Name is also updated (eg. for a service...)\n                item_data['name'] = item_name\n                # Template information if templating is required\n                if used_templates:\n                    item_data.update({'_templates': used_templates,\n                                      '_templates_with_services': True})\n\n                for field in item_data.copy():\n                    logger.debug(\"Field: %s = %s\", field, item_data[field])\n                    # Filter Eve extra fields\n                    if field in ['_created', '_updated', '_etag', '_links', '_status']:\n                        item_data.pop(field)\n                        continue\n                    # Filter specific backend inner computed fields\n                    # pylint: disable=fixme\n                    # todo: list to be completed!\n                    if field in ['_overall_state_id']:\n                        item_data.pop(field)\n                        continue\n\n                    # Manage potential object link fields\n                    if field not in ['realm', '_realm', '_templates',\n                                     'command', 'host', 'service',\n                                     'escalation_period', 'maintenance_period',\n                                     'snapshot_period', 'check_period', 'dependency_period',\n                                     'notification_period', 'host_notification_period',\n                                     'escalation_period', 'service_notification_period',\n                                     'host_notification_commands', 'service_notification_commands',\n                                     'service_dependencies', 'users', 'usergroups',\n                                     'check_command', 'event_handler', 'grafana', 'statsd']:\n                        continue\n\n                    field_values = item_data[field]\n                    if not isinstance(item_data[field], list):\n                        field_values = [item_data[field]]\n\n                    found = None\n                    for value in field_values:\n                        logger.debug(\" - %s, single value: %s\", field, value)\n                        try:\n                            int(value, 16)\n                            logger.debug(\" - %s, uuid value: %s\", field, value)\n\n                            if not isinstance(item_data[field], list):\n                                found = value\n                            else:\n                                if found is None:\n                                    found = []\n                                found.append(value)\n                        except TypeError:\n                            pass\n                        except ValueError:\n                            # Not an integer, consider an item name\n                            field_params = {'where': json.dumps({'name': value})}\n                            logger.debug(\" - %s, params: %s\", field, field_params)\n                            if field in ['escalation_period', 'maintenance_period',\n                                         'snapshot_period', 'check_period',\n                                         'dependency_period', 'notification_period',\n                                         'host_notification_period',\n                                         'service_notification_period']:\n                                response2 = self.backend.get('timeperiod', params=field_params)\n                            elif field in ['_realm']:\n                                response2 = self.backend.get('realm', params=field_params)\n                            elif field in ['service_dependencies']:\n                                response2 = self.backend.get('service', params=field_params)\n                            elif field in ['users']:\n                                response2 = self.backend.get('user', params=field_params)\n                            elif field in ['usergroups']:\n                                response2 = self.backend.get('usergroup', params=field_params)\n                            elif field in ['check_command', 'event_handler',\n                                           'service_notification_commands',\n                                           'host_notification_commands']:\n                                response2 = self.backend.get('command', params=field_params)\n                            elif field in ['_templates']:\n                                field_params = {'where': json.dumps({'name': value,\n                                                                     '_is_template': True})}\n                                response2 = self.backend.get(resource_name, params=field_params)\n                            else:\n                                response2 = self.backend.get(field, params=field_params)\n\n                            if response2['_items']:\n                                response2 = response2['_items'][0]\n                                logger.info(\"Replaced %s = %s with found item _id\",\n                                            field, value)\n                                if not isinstance(item_data[field], list):\n                                    found = response2['_id']\n                                else:\n                                    if found is None:\n                                        found = []\n                                    found.append(response2['_id'])\n\n                    if found is None:\n                        logger.warning(\"Not found %s = %s, removing field!\", field, field_values)\n                        item_data.pop(field)\n                    else:\n                        item_data[field] = found\n\n                if resource_name not in ['realm'] and '_realm' not in item_data:\n                    logger.info(\"add default realm to the data\")\n                    item_data.update({'_realm': self.default_realm})\n\n                if resource_name in ['realm'] and '_realm' not in item_data:\n                    logger.info(\"add parent realm to the data\")\n                    item_data.update({'_parent': self.default_realm})\n\n                if '_id' in item_data:\n                    item_data.pop('_id')\n\n                if not update:\n                    # Trying to create a new element\n                    if not item_data['name']:\n                        item_data.pop('name')\n                    logger.info(\"-> trying to create the %s: %s.\", resource_name, item_name)\n                    logger.debug(\"-> with: %s.\", item_data)\n                    if not self.dry_run:\n                        try:\n                            response = self.backend.post(resource_name, item_data, headers=None)\n                        except BackendException as exp:\n                            self.item = item_name\n                            logger.error(\"Exception: %s\", exp)\n                            # logger.error(\"Response: %s\", exp.response)\n                            continue\n                    else:\n                        response = {'_status': 'OK', '_id': '_fake', '_etag': '_fake'}\n                else:\n                    if not name:\n                        logger.warning(\"-> can not update '%s' with no name!\", resource_name)\n                        continue\n\n                    # Trying to update an element\n                    logger.info(\"-> trying to update the %s: %s.\", resource_name, item_name)\n                    logger.debug(\"-> with: %s.\", item_data)\n                    if not self.dry_run:\n                        try:\n                            headers = {'Content-Type': 'application/json', 'If-Match': found_etag}\n                            response = self.backend.patch(resource_name + '/' + found_id,\n                                                          item_data, headers=headers,\n                                                          inception=True)\n                        except BackendException as exp:\n                            self.item = item_name\n                            logger.exception(\"Exception: %s\", exp)\n                            # logger.error(\"Response: %s\", exp.response)\n                            continue\n                    else:\n                        response = {'_status': 'OK', '_id': '_fake', '_etag': '_fake'}\n\n                if response['_status'] == 'ERR':\n                    logger.warning(\"Response: %s\", response)\n                    return False\n\n                if not update:\n                    # Created a new element\n                    if not self.dry_run:\n                        logger.info(\"-> created: '%s': %s\", resource_name, response['_id'])\n                    else:\n                        logger.info(\"Dry-run mode: should have created an %s '%s'\",\n                                    resource_name, name)\n                else:\n                    # Updated an element\n                    if not self.dry_run:\n                        logger.info(\"-> updated: '%s': %s\", resource_name, response['_id'])\n                    else:\n                        logger.info(\"Dry-run mode: should have updated an %s '%s'\",\n                                    resource_name, name)\n                count = count + 1\n\n        except BackendException as exp:  # pragma: no cover, should never happen\n            logger.exception(\"Exception: %s\", exp)\n            logger.error(\"Response: %s\", exp.response)\n            print(\"Creation/update error for  '%s' : %s\" % (resource_name, name))\n            print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n            print(\"Exiting with error code: 5\")\n            return False\n\n        if count == len(json_data):\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the response from the requested endpoint with the requested method.", "response": "def get_response(self, method, endpoint, headers=None, json=None, params=None, data=None):\n        # pylint: disable=too-many-arguments\n        \"\"\"\n        Returns the response from the requested endpoint with the requested method\n        :param method: str. one of the methods accepted by Requests ('POST', 'GET', ...)\n        :param endpoint: str. the relative endpoint to access\n        :param params: (optional) Dictionary or bytes to be sent in the query string\n        for the :class:`Request`.\n        :param data: (optional) Dictionary, bytes, or file-like object to send in the body\n        of the :class:`Request`.\n        :param json: (optional) json to send in the body of the :class:`Request`.\n        :param headers: (optional) Dictionary of HTTP Headers to send with the :class:`Request`.\n        :return: Requests.response\n        \"\"\"\n        logger.debug(\"Parameters for get_response:\")\n        logger.debug(\"\\t - endpoint: %s\", endpoint)\n        logger.debug(\"\\t - method: %s\", method)\n        logger.debug(\"\\t - headers: %s\", headers)\n        logger.debug(\"\\t - json: %s\", json)\n        logger.debug(\"\\t - params: %s\", params)\n        logger.debug(\"\\t - data: %s\", data)\n\n        url = self.get_url(endpoint)\n\n        # First stage. Errors are connection errors (timeout, no session, ...)\n        try:\n            response = self.session.request(method=method, url=url, headers=headers, json=json,\n                                            params=params, data=data, proxies=self.proxies,\n                                            timeout=self.timeout)\n            logger.debug(\"response headers: %s\", response.headers)\n            logger.debug(\"response content: %s\", response.content)\n        except RequestException as e:\n            response = {\"_status\": \"ERR\",\n                        \"_error\": {\"message\": e, \"code\": BACKEND_ERROR},\n                        \"_issues\": {\"message\": e, \"code\": BACKEND_ERROR}}\n            raise BackendException(code=BACKEND_ERROR,\n                                   message=e,\n                                   response=response)\n        else:\n            return response"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef decode(response):\n\n        # Second stage. Errors are backend errors (bad login, bad url, ...)\n        try:\n            response.raise_for_status()\n        except requests.HTTPError as e:\n            raise BackendException(code=response.status_code,\n                                   message=e,\n                                   response=response)\n        else:\n            resp_json = response.json()\n            # Catch errors not sent in a HTTP error\n            error = resp_json.get('_error', None)\n            if error:\n                raise BackendException(code=error['code'],\n                                       message=error['message'],\n                                       response=response)\n            return resp_json", "response": "Decodes the response and returns the JSON dict or raises BackendException\n           "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting token in authentification for next requests", "response": "def set_token(self, token):\n        \"\"\"\n        Set token in authentification for next requests\n        :param token: str. token to set in auth. If None, reinit auth\n        \"\"\"\n        if token:\n            auth = HTTPBasicAuth(token, '')\n            self._token = token\n            self.authenticated = True  # TODO: Remove this parameter\n            self.session.auth = auth\n            logger.debug(\"Using session token: %s\", token)\n        else:\n            self._token = None\n            self.authenticated = False\n            self.session.auth = None\n            logger.debug(\"Session token/auth reinitialised\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef login(self, username, password, generate='enabled', proxies=None):\n        logger.debug(\"login for: %s with generate: %s\", username, generate)\n\n        if not username or not password:\n            raise BackendException(BACKEND_ERROR, \"Missing mandatory parameters\")\n\n        if proxies:\n            for key in proxies.keys():\n                try:\n                    assert key in PROXY_PROTOCOLS\n                except AssertionError:\n                    raise BackendException(BACKEND_ERROR, \"Wrong proxy protocol \", key)\n        self.proxies = proxies\n\n        endpoint = 'login'\n        json = {u'username': username, u'password': password}\n        if generate == 'force':\n            json['action'] = 'generate'\n            logger.debug(\"Asking for generating new token\")\n\n        response = self.get_response(method='POST', endpoint=endpoint, json=json)\n        if response.status_code == 401:\n            logger.error(\"Backend refused login with params %s\", json)\n            self.set_token(token=None)\n            return False\n\n        resp = self.decode(response=response)\n\n        if 'token' in resp:\n            self.set_token(token=resp['token'])\n            return True\n        if generate == 'force':  # pragma: no cover - need specific backend tests\n            self.set_token(token=None)\n            raise BackendException(BACKEND_ERROR, \"Token not provided\")\n        if generate == 'disabled':  # pragma: no cover - need specific backend tests\n            logger.error(\"Token disabled ... to be implemented!\")\n            return False\n        if generate == 'enabled':  # pragma: no cover - need specific backend tests\n            logger.warning(\"Token enabled, but none provided, require new token generation\")\n            return self.login(username, password, 'force')\n\n        return False", "response": "Log into the backend and get the token"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_domains(self):\n\n        resp = self.get('')\n        if \"_links\" in resp:\n            _links = resp[\"_links\"]\n            if \"child\" in _links:\n                return _links[\"child\"]\n\n        return {}", "response": "Get all the domains available in the alignak backend."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting all items in the specified endpoint of alignak backend.", "response": "def get_all(self, endpoint, params=None):\n        # pylint: disable=too-many-locals\n        \"\"\"\n        Get all items in the specified endpoint of alignak backend\n\n        If an error occurs, a BackendException is raised.\n\n        If the max_results parameter is not specified in parameters, it is set to\n        BACKEND_PAGINATION_LIMIT (backend maximum value) to limit requests number.\n\n        This method builds a response that always contains: _items and _status::\n\n            {\n                u'_items': [\n                    ...\n                ],\n                u'_status': u'OK'\n            }\n\n        :param endpoint: endpoint (API URL) relative from root endpoint\n        :type endpoint: str\n        :param params: list of parameters for the backend API\n        :type params: dict\n        :return: dict of properties\n        :rtype: dict\n        \"\"\"\n        # Set max results at maximum value supported by the backend to limit requests number\n        if not params:\n            params = {'max_results': BACKEND_PAGINATION_LIMIT}\n        elif params and 'max_results' not in params:\n            params['max_results'] = BACKEND_PAGINATION_LIMIT\n\n        # Get first page\n        last_page = False\n        items = []\n        if self.processes == 1:\n            while not last_page:\n                # Get elements ...\n                resp = self.get(endpoint=endpoint, params=params)\n                # Response contains:\n                # _items:\n                # ...\n                # _links:\n                #  self, parent, prev, last, next\n                # _meta:\n                # - max_results, total, page\n\n                if 'next' in resp['_links']:\n                    # Go to next page ...\n                    params['page'] = int(resp['_meta']['page']) + 1\n                    params['max_results'] = int(resp['_meta']['max_results'])\n                else:\n                    last_page = True\n                items.extend(resp['_items'])\n        else:\n            def get_pages(endpoint, params, pages, out_q):\n                \"\"\"\n                Function to get pages loaded by multiprocesses\n\n                :param endpoint: endpoint to get data\n                :type endpoint: string\n                :param params: parameters for get request\n                :type params: dict\n                :param pages: range of pages to get\n                :type pages: list\n                :param out_q: Queue object\n                :type out_q: multiprocessing.Queue\n                :return: None\n                \"\"\"\n                multi_items = []\n                for page in pages:\n                    params['page'] = page\n                    resp = self.get(endpoint, params)\n                    multi_items.extend(resp['_items'])\n                out_q.put(multi_items)\n\n            # Get first page\n            resp = self.get(endpoint, params)\n            number_pages = int(math.ceil(\n                float(resp['_meta']['total']) / float(resp['_meta']['max_results'])))\n\n            out_q = multiprocessing.Queue()\n            chunksize = int(math.ceil(number_pages / float(self.processes)))\n            procs = []\n            for i in range(self.processes):\n                begin = i * chunksize\n                end = begin + chunksize\n                if end > number_pages:\n                    end = number_pages\n                begin += 1\n                end += 1\n                p = multiprocessing.Process(target=get_pages,\n                                            args=(endpoint, params, range(begin, end), out_q))\n                procs.append(p)\n                p.start()\n\n            # Collect all results into a single result dict. We know how many dicts\n            # with results to expect.\n            for i in range(self.processes):\n                items.extend(out_q.get())\n\n            # Wait for all worker processes to finish\n            for p in procs:\n                p.join()\n\n        return {\n            '_items': items,\n            '_status': 'OK'\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning True if path1 and path2 refer to the same file.", "response": "def samefile(path1, path2):\n    \"\"\"\n    Returns True if path1 and path2 refer to the same file.\n    \"\"\"\n    # Check if both are on the same volume and have the same file ID\n    info1 = fs.getfileinfo(path1)\n    info2 = fs.getfileinfo(path2)\n    return (info1.dwVolumeSerialNumber == info2.dwVolumeSerialNumber and\n            info1.nFileIndexHigh == info2.nFileIndexHigh and\n            info1.nFileIndexLow == info2.nFileIndexLow)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngive a path return a new REPARSE_DATA_BUFFER and the length of the buffer.", "response": "def new_junction_reparse_buffer(path=None):    \n    \"\"\"\n    Given a path, return a pair containing a new REPARSE_DATA_BUFFER and the\n    length of the buffer (not necessarily the same as sizeof due to packing\n    issues).\n    If no path is provided, the maximum length is assumed.\n    \"\"\"\n\n    if path is None:\n        # The maximum reparse point data buffer length is 16384 bytes. We are a\n        # bit conservative here and set a length of 16000 bytes (8000\n        # characters) + a few more for the header.\n        substnamebufferchars = 8000\n    else:\n        # 1 more character for the null terminator. Python 2.x calculates\n        # len(surrogate pair) = 2, so multiplying this by 2 is the right thing\n        # to do.\n        substnamebufferchars = len(path) + 1\n\n    # It is amazing how ugly MSDN's version of REPARSE_DATA_BUFFER is:\n    # <http://msdn.microsoft.com/en-us/library/windows/hardware/ff552012>. It\n    # is a variable-length struct with two strings in the wchar[] buffer at\n    # the end. Both are supposed to be null-terminated, and the individual\n    # lengths do not include that of the null character, but the total\n    # ReparseDataLength does.\n    #\n    # In our case, only the SubstituteName part of the mount point/junction-\n    # specific part is relevant. So we set PrintNameLength to 0, but we still\n    # need to allow for one null character, so PrintNameBuffer has length 1.\n    class REPARSE_DATA_BUFFER(ctypes.Structure):\n        _fields_ = [(\"ReparseTag\", ctypes.c_ulong),\n                    (\"ReparseDataLength\", ctypes.c_ushort),\n                    (\"Reserved\", ctypes.c_ushort),\n                    (\"SubstituteNameOffset\", ctypes.c_ushort),\n                    (\"SubstituteNameLength\", ctypes.c_ushort),\n                    (\"PrintNameOffset\", ctypes.c_ushort),\n                    (\"PrintNameLength\", ctypes.c_ushort),\n                    (\"SubstituteNameBuffer\", ctypes.c_wchar * substnamebufferchars),\n                    (\"PrintNameBuffer\", ctypes.c_wchar * 1)]\n\n    numpathbytes = (substnamebufferchars - 1) * sizeof(ctypes.c_wchar)\n    # We can't really use sizeof on the struct because of packing issues.\n    # Instead, calculate the size manually\n    buffersize = (numpathbytes + (sizeof(ctypes.c_wchar) * 2) + \n        (sizeof(ctypes.c_ushort) * 4))\n    if path is None:\n        buffer = REPARSE_DATA_BUFFER()\n        buffer.ReparseTag = IO_REPARSE_TAG_MOUNT_POINT\n    else:\n        buffer = REPARSE_DATA_BUFFER(\n            IO_REPARSE_TAG_MOUNT_POINT,\n            buffersize,\n            0,\n            # print name offset, length\n            0, numpathbytes,\n            # substitute name offset, length\n            numpathbytes + 2, 0,\n            # print name\n            path,\n            # substitute name\n            \"\")\n\n    return (buffer, buffersize + REPARSE_DATA_BUFFER.SubstituteNameOffset.offset)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create(source, link_name):\n    success = False\n    if not os.path.isdir(source):\n        raise Exception(\"%s is not a directory\" % source)\n    if os.path.exists(link_name):\n        raise Exception(\"%s: junction link name already exists\" % link_name)\n\n    link_name = os.path.abspath(link_name)\n    os.mkdir(link_name)\n\n    # Get a handle to the directory\n    hlink = CreateFile(link_name, fs.GENERIC_WRITE,\n        fs.FILE_SHARE_READ | fs.FILE_SHARE_WRITE, None, fs.OPEN_EXISTING,\n        fs.FILE_FLAG_OPEN_REPARSE_POINT | fs.FILE_FLAG_BACKUP_SEMANTICS,\n        None)\n    try:\n        if hlink == fs.INVALID_HANDLE_VALUE:\n            raise WinError()\n\n        srcvolpath = unparsed_convert(source)\n        (junctioninfo, infolen) = new_junction_reparse_buffer(srcvolpath)\n\n        dummy = DWORD(0)\n        res = DeviceIoControl(\n            hlink,\n            FSCTL_SET_REPARSE_POINT,\n            byref(junctioninfo),\n            infolen,\n            None,\n            0,\n            byref(dummy),\n            None)\n\n        if res == 0:\n            raise WinError()\n        success = True\n    finally:\n        if hlink != fs.INVALID_HANDLE_VALUE:\n            CloseHandle(hlink)\n        if not success:\n            os.rmdir(link_name)", "response": "Create a new junction at link_name pointing to source."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getvolumeinfo(path):\n\n    # Add 1 for a trailing backslash if necessary, and 1 for the terminating\n    # null character.\n    volpath = ctypes.create_unicode_buffer(len(path) + 2)\n    rv = GetVolumePathName(path, volpath, len(volpath))\n    if rv == 0:\n        raise WinError()\n\n    fsnamebuf = ctypes.create_unicode_buffer(MAX_PATH + 1)\n    fsflags = DWORD(0)\n    rv = GetVolumeInformation(volpath, None, 0, None, None, byref(fsflags),\n                              fsnamebuf, len(fsnamebuf))\n    if rv == 0:\n        raise WinError()\n\n    return (fsnamebuf.value, fsflags.value)", "response": "Get the information for the given path."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninitializing the logger for the current command line", "response": "def initialize_logger(args):\n    \"\"\"Sets command name and formatting for subsequent calls to logger\"\"\"\n\n    global log_filename\n    log_filename = os.path.join(os.getcwd(), \"jacquard.log\")\n    if args.log_file:\n        _validate_log_file(args.log_file)\n        log_filename = args.log_file\n\n    logging.basicConfig(format=_FILE_LOG_FORMAT,\n                        level=\"DEBUG\",\n                        datefmt=_DATE_FORMAT,\n                        filename=log_filename)\n\n    global _verbose\n    if args.verbose:\n        _verbose = args.verbose\n\n    start_time = datetime.now().strftime(_DATE_FORMAT)\n    global _logging_dict\n    _logging_dict = {'user': getpass.getuser(),\n                     'host': socket.gethostname(),\n                     'start_time': start_time,\n                     'tool': args.subparser_name}"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef error(self, message):\n        '''Suppress default exit behavior'''\n        message = self._remessage_invalid_subparser(message)\n        raise utils.UsageError(message)", "response": "Suppress default exit behavior"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef claim(self, file_readers):\n        unclaimed_readers = []\n        vcf_readers = []\n        for file_reader in file_readers:\n            if self._is_mutect_vcf(file_reader):\n                vcf_reader = vcf.VcfReader(file_reader)\n                vcf_readers.append(_MutectVcfReader(vcf_reader))\n            else:\n                unclaimed_readers.append(file_reader)\n        return (unclaimed_readers, vcf_readers)", "response": "Recognizes and claims MuTect VCFs form the set of all input VCFs."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a standardized column header.", "response": "def _get_new_column_header(self, vcf_reader):\n        \"\"\"Returns a standardized column header.\n\n        MuTect sample headers include the name of input alignment, which is\n        nice, but doesn't match up with the sample names reported in Strelka\n        or VarScan. To fix this, we replace with NORMAL and TUMOR using the\n        MuTect metadata command line to replace them correctly.\"\"\"\n        mutect_dict = self._build_mutect_dict(vcf_reader.metaheaders)\n\n        new_header_list = []\n        required_keys = set([self._NORMAL_SAMPLE_KEY, self._TUMOR_SAMPLE_KEY])\n        mutect_keys = set(mutect_dict.keys())\n\n        if not required_keys.issubset(mutect_keys):\n            raise utils.JQException(\"Unable to determine normal \"\n                                    \"and tumor sample ordering \"\n                                    \"based on MuTect metaheader.\")\n\n        for field_name in vcf_reader.column_header.split(\"\\t\"):\n            if field_name == mutect_dict[self._NORMAL_SAMPLE_KEY]:\n                field_name = \"NORMAL\"\n            elif field_name == mutect_dict[self._TUMOR_SAMPLE_KEY]:\n                field_name = \"TUMOR\"\n            new_header_list.append(field_name)\n\n        return \"\\t\".join(new_header_list)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nbuilds a file path from *paths* and return the contents.", "response": "def read(*paths):\n    \"\"\"Build a file path from *paths* and return the contents.\"\"\"\n    with open(os.path.join(*paths), 'r') as filename:\n        return filename.read()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nrecognizes and claims VarScan VCFs form the set of all input VCFs.", "response": "def claim(self, file_readers):\n        \"\"\"Recognizes and claims VarScan VCFs form the set of all input VCFs.\n\n        Each defined caller has a chance to evaluate and claim all the incoming\n        files as something that it can process. Since VarScan can claim\n        high-confidence files as well, this process is significantly more\n        complex than for other callers.\n\n        Args:\n            file_readers: the collection of currently unclaimed files\n\n        Returns:\n            A tuple of unclaimed readers and VarScanVcfReaders.\n        \"\"\"\n\n        (prefix_to_readers,\n         filter_files,\n         unclaimed_set) = self._find_varscan_files(file_readers)\n\n        prefix_by_patients = self._split_prefix_by_patient(prefix_to_readers)\n        self._validate_vcf_readers(prefix_by_patients)\n        vcf_hc_pairs = self._pair_files(prefix_to_readers, filter_files)\n        self._validate_vcf_hc_pairs(vcf_hc_pairs)\n        vcf_readers = self._create_vcf_readers(vcf_hc_pairs)\n\n        return list(unclaimed_set), vcf_readers"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nextracts ( float ) value of dependent tag or None.", "response": "def _get_dependent_value(tag_values, dependent_tag_id):\n        '''Extract (float) value of dependent tag or None if absent.'''\n        try:\n            values = tag_values[dependent_tag_id].split(\",\")\n            return max([float(value) for value in values])\n        except KeyError:\n            return None\n        except ValueError:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nderive mean and stdev.", "response": "def _init_population_stats(self, vcf_reader, dependent_tag_id):\n        '''Derive mean and stdev.\n\n        Adapted from online variance algorithm from Knuth, The Art of Computer \n        Programming, volume 2\n\n        Returns: mean and stdev when len(values) > 1, otherwise (None, None)\n            Values rounded to _MAX_PRECISION to ameliorate discrepancies between\n            python versions.'''\n        #pylint: disable=invalid-name\n        n = 0\n        mean = 0\n        M2 = 0\n        try:\n            vcf_reader.open()\n            for vcf_record in vcf_reader.vcf_records():\n                for tag_values in vcf_record.sample_tag_values.values():\n                    value = self._get_dependent_value(tag_values,\n                                                      dependent_tag_id)\n                    if value is not None:\n                        n += 1\n                        delta = value - mean\n                        mean += delta / n\n                        M2 += delta * (value - mean)\n        finally:\n            vcf_reader.close()\n\n        mean = round(mean, self._MAX_PRECISION)\n\n        stdev = 0\n        if n == 0:\n            mean = None\n            stdev = None\n        elif n >= 2:\n            variance = M2/n\n            stdev = round(math.sqrt(variance), self._MAX_PRECISION)\n\n        return mean, stdev"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef claim(self, unclaimed_file_readers):\n        claimed_vcf_readers = []\n        for caller in self._callers:\n            (unclaimed_file_readers,\n             translated_vcf_readers) = caller.claim(unclaimed_file_readers)\n            claimed_vcf_readers.extend(translated_vcf_readers)\n\n        return unclaimed_file_readers, claimed_vcf_readers", "response": "Allows each caller to claim incoming files as they are recognized."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef vcf_records(self, format_tags=None, qualified=False):\n        if qualified:\n            sample_names = self.qualified_sample_names\n        else:\n            sample_names = self.sample_names\n\n        for line in self._file_reader.read_lines():\n            if line.startswith(\"#\"):\n                continue\n            vcf_record = vcf.VcfRecord.parse_record(line, sample_names)\n            if format_tags:\n                vcf_record = self.modify_format_tag(vcf_record, format_tags)\n            yield vcf_record", "response": "Generates parsed VcfRecords objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfollows a file at the given path.", "response": "def follow_path(file_path, buffering=-1, encoding=None, errors='strict'):\n    \"\"\"\n    Similar to follow, but also looks up if inode of file is changed\n    e.g. if it was re-created.\n\n    Returned generator yields strings encoded by using encoding.\n    If encoding is not specified, it defaults to locale.getpreferredencoding()\n\n    >>> import io\n    >>> import os\n    >>> f = io.open('test_follow_path.txt', 'w+')\n    >>> generator = follow_path('test_follow_path.txt')\n    >>> _ = f.write('Line 1\\\\n')\n    >>> f.flush()\n    >>> print(next(generator))\n    Line 1\n    >>> _ = f.write('Line 2\\\\n')\n    >>> f.flush()\n    >>> print(next(generator))\n    Line 2\n    >>> _ = f.truncate(0)\n    >>> _ = f.seek(0)\n    >>> _ = f.write('Line 3\\\\n')\n    >>> f.flush()\n    >>> print(next(generator))\n    Line 3\n    >>> f.close()\n    >>> os.remove('test_follow_path.txt')\n    >>> f = io.open('test_follow_path.txt', 'w+')\n    >>> _ = f.write('Line 4\\\\n')\n    >>> f.flush()\n    >>> print(next(generator))\n    Line 4\n    >>> print(next(generator))\n    None\n    >>> f.close()\n    >>> os.remove('test_follow_path.txt')\n    \"\"\"\n    if encoding is None:\n        encoding = locale.getpreferredencoding()\n\n    class FollowPathGenerator(object):\n        def __init__(self):\n            if os.path.isfile(file_path):\n                self.following_file = io.open(file_path, 'rb', buffering)\n                self.follow_generator = Tailer(self.following_file, end=True).follow()\n                self.follow_from_end_on_open = False\n            else:\n                self.following_file = None\n                self.follow_generator = None\n                self.follow_from_end_on_open = True\n\n        def next(self):\n            while True:\n                if self.follow_generator:\n                    line = next(self.follow_generator)\n                else:\n                    line = None\n\n                if line is None:\n                    if self.follow_generator:\n                        try:\n                            is_file_changed = not os.path.isfile(file_path) or os.stat(file_path).st_ino != os.fstat(self.following_file.fileno()).st_ino\n                        except OSError:\n                            # File could be deleted between isfile and stat invocations, which will make the latter to fail.\n                            is_file_changed = True\n\n                        if is_file_changed:\n                            # File was deleted or re-created.\n                            self.following_file.close()\n                            self.following_file = None\n                            self.follow_generator = None\n\n                    if not self.follow_generator and os.path.isfile(file_path):\n                        # New file is available. Open it.\n                        try:\n                            self.following_file = io.open(file_path, 'rb', buffering)\n                            self.follow_generator = Tailer(self.following_file, end=self.follow_from_end_on_open).follow()\n                            self.follow_from_end_on_open = False  # something could be written before we noticed change of file\n                        except (IOError, OSError) as e:\n                            LOG.info(\"Unable to tail file: %s\", e)\n                            if self.following_file:\n                                self.following_file.close()\n\n                            self.following_file= None\n                            self.follow_generator = None\n                            line = None\n                        else:\n                            line = next(self.follow_generator)\n\n                return line.decode(encoding, errors) if line is not None else line\n\n        def __iter__(self):\n            return self\n\n        def __next__(self):\n            return self.next()\n\n    return FollowPathGenerator()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef splitlines(self, data):\n        return re.split(b'|'.join(self.LINE_TERMINATORS), data)", "response": "Split data into lines where lines are separated by LINE_TERMINATORS."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef read(self, read_size=-1):\n        read_str = self.file.read(read_size)\n        return len(read_str), read_str", "response": "Reads given number of bytes from file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the first line terminator that starts with data or None.", "response": "def prefix_line_terminator(self, data):\n        \"\"\"\n        Return line terminator data begins with or None.\n        \"\"\"\n        for t in self.LINE_TERMINATORS:\n            if data.startswith(t):\n                return t\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef suffix_line_terminator(self, data):\n        for t in self.LINE_TERMINATORS:\n            if data.endswith(t):\n                return t\n\n        return None", "response": "Return the suffix of the data with a line terminator or None if the data does not end with one of the line terminators."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nseeks to the next line in the file.", "response": "def seek_next_line(self):\n        \"\"\"\n        Seek next line relative to the current file position.\n\n        :return: Position of the line or -1 if next line was not found.\n        \"\"\"\n        where = self.file.tell()\n        offset = 0\n\n        while True:\n            data_len, data = self.read(self.read_size)\n            data_where = 0\n\n            if not data_len:\n                break\n\n            # Consider the following example: Foo\\r | \\nBar where \" | \" denotes current position,\n            # 'Foo\\r' is the read part and '\\nBar' is the remaining part.\n            # We should completely consume terminator \"\\r\\n\" by reading one extra byte.\n            if b'\\r\\n' in self.LINE_TERMINATORS and data[-1] == b'\\r'[0]:\n                terminator_where = self.file.tell()\n                terminator_len, terminator_data = self.read(1)\n\n                if terminator_len and terminator_data[0] == b'\\n'[0]:\n                    data_len += 1\n                    data += b'\\n'\n                else:\n                    self.file.seek(terminator_where)\n\n            while data_where < data_len:\n                terminator = self.prefix_line_terminator(data[data_where:])\n                if terminator:\n                    self.file.seek(where + offset + data_where + len(terminator))\n                    return self.file.tell()\n                else:\n                    data_where += 1\n\n            offset += data_len\n            self.file.seek(where + offset)\n\n        return -1"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef seek_previous_line(self):\n        where = self.file.tell()\n        offset = 0\n\n        while True:\n            if offset == where:\n                break\n\n            read_size = self.read_size if self.read_size <= where else where\n            self.file.seek(where - offset - read_size, SEEK_SET)\n            data_len, data = self.read(read_size)\n\n            # Consider the following example: Foo\\r | \\nBar where \" | \" denotes current position,\n            # '\\nBar' is the read part and 'Foo\\r' is the remaining part.\n            # We should completely consume terminator \"\\r\\n\" by reading one extra byte.\n            if b'\\r\\n' in self.LINE_TERMINATORS and data[0] == b'\\n'[0]:\n                terminator_where = self.file.tell()\n                if terminator_where > data_len + 1:\n                    self.file.seek(where - offset - data_len - 1, SEEK_SET)\n                    terminator_len, terminator_data = self.read(1)\n\n                    if terminator_data[0] == b'\\r'[0]:\n                        data_len += 1\n                        data = b'\\r' + data\n\n                    self.file.seek(terminator_where)\n\n            data_where = data_len\n\n            while data_where > 0:\n                terminator = self.suffix_line_terminator(data[:data_where])\n                if terminator and offset == 0 and data_where == data_len:\n                    # The last character is a line terminator that finishes current line. Ignore it.\n                    data_where -= len(terminator)\n                elif terminator:\n                    self.file.seek(where - offset - (data_len - data_where))\n                    return self.file.tell()\n                else:\n                    data_where -= 1\n\n            offset += data_len\n\n        if where == 0:\n            # Nothing more to read.\n            return -1\n        else:\n            # Very first line.\n            self.file.seek(0)\n            return 0", "response": "Seek to the previous line in the file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef tail(self, lines=10):\n        self.file.seek(0, SEEK_END)\n\n        for i in range(lines):\n            if self.seek_previous_line() == -1:\n                break\n\n        data = self.file.read()\n\n        for t in self.LINE_TERMINATORS:\n            if data.endswith(t):\n                # Only terminators _between_ lines should be preserved.\n                # Otherwise terminator of the last line will be treated as separtaing line and empty line.\n                data = data[:-len(t)]\n                break\n\n        if data:\n            return self.splitlines(data)\n        else:\n            return []", "response": "Return the last lines of the file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef head(self, lines=10):\n        self.file.seek(0)\n\n        for i in range(lines):\n            if self.seek_next_line() == -1:\n                break\n    \n        end_pos = self.file.tell()\n        \n        self.file.seek(0)\n        data = self.file.read(end_pos)\n\n        for t in self.LINE_TERMINATORS:\n            if data.endswith(t):\n                # Only terminators _between_ lines should be preserved.\n                # Otherwise terminator of the last line will be treated as separtaing line and empty line.\n                data = data[:-len(t)]\n                break\n\n        if data:\n            return self.splitlines(data)\n        else:\n            return []", "response": "Return the first lines of the file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef follow(self):\n        trailing = True       \n        \n        while True:\n            where = self.file.tell()\n\n            if where > os.fstat(self.file.fileno()).st_size:\n                # File was truncated.\n                where = 0\n                self.file.seek(where)\n\n            line = self.file.readline()\n\n            if line:    \n                if trailing and line in self.LINE_TERMINATORS:\n                    # This is just the line terminator added to the end of the file\n                    # before a new line, ignore.\n                    trailing = False\n                    continue\n\n                terminator = self.suffix_line_terminator(line)\n                if terminator:\n                    line = line[:-len(terminator)]\n\n                trailing = False\n                yield line\n            else:\n                trailing = True\n                self.file.seek(where)\n                yield None", "response": "Iterator that returns lines as data is added to the file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrecognize and claims Strelka VCFs form the set of all input VCFs.", "response": "def claim(self, file_readers):\n        \"\"\"Recognizes and claims Strelka VCFs form the set of all input VCFs.\n\n        Each defined caller has a chance to evaluate and claim all the incoming\n        files as something that it can process.\n\n        Args:\n            file_readers: the collection of currently unclaimed files\n\n        Returns:\n            A tuple of unclaimed readers and StrelkaVcfReaders.\n        \"\"\"\n        (prefix_to_reader,\n         unclaimed_readers) = self._find_strelka_files(file_readers)\n        prefix_by_patients = self._split_prefix_by_patient(prefix_to_reader)\n        self._validate_vcf_readers(prefix_by_patients)\n        vcf_readers = self._create_vcf_readers(prefix_to_reader)\n\n        return (unclaimed_readers, vcf_readers)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef vcf_records(self, qualified=False):\n        if qualified:\n            sample_names = self.qualified_sample_names\n        else:\n            sample_names = self.sample_names\n\n        for line in self._file_reader.read_lines():\n            if line.startswith(\"#\"):\n                continue\n            yield VcfRecord.parse_record(line, sample_names)", "response": "Generates parsed VcfRecords objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_record(cls, vcf_line, sample_names):\n        vcf_fields = vcf_line.rstrip(\"\\r\\n\").split(\"\\t\")\n        chrom, pos, rid, ref, alt, qual, rfilter, info \\\n                = vcf_fields[0:8]\n        sample_fields = []\n        sample_tag_values = {}\n        if len(vcf_fields) > 9:\n            rformat = vcf_fields[8]\n            sample_fields = vcf_fields[9:]\n            sample_tag_values = VcfRecord._sample_tag_values(sample_names,\n                                                             rformat,\n                                                             sample_fields)\n        return VcfRecord(chrom, pos, ref, alt,\n                         rid, qual, rfilter, info,\n                         sample_tag_values)", "response": "Alternative constructor that parses a VCF record from a string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _sample_tag_values(cls, sample_names, rformat, sample_fields):\n        sample_tag_values = OrderedDict()\n        tag_names = VcfRecord._format_list(rformat)\n        for i, sample_field in enumerate(sample_fields):\n            tag_values = sample_field.split(\":\") if sample_field else \".\"\n            sample_tag_values[sample_names[i]] = OrderedDict(zip(tag_names,\n                                                                 tag_values))\n        return sample_tag_values", "response": "Create a sample dict of tag - value dicts for a single variant record."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning set of format tags.", "response": "def format_tags(self):\n        \"\"\"Returns set of format tags.\"\"\"\n        tags = VcfRecord._EMPTY_SET\n        if self.sample_tag_values:\n            first_sample = list(self.sample_tag_values.keys())[0]\n            tags = set(self.sample_tag_values[first_sample].keys())\n        return tags"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_info_field(self, field):\n        if field in self.info_dict:\n            msg = \"New info field [{}] already exists.\".format(field)\n            raise KeyError(msg)\n\n        if \"=\" in field:\n            key, value = field.split(\"=\")\n            self.info_dict[key] = value\n        else:\n            self.info_dict[field] = field\n\n        self._join_info_fields()", "response": "Adds new info field to the internal dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _join_info_fields(self):\n        if self.info_dict:\n            info_fields = []\n            if len(self.info_dict) > 1:\n                self.info_dict.pop(\".\", None)\n            for field, value in self.info_dict.items():\n                if field == value:\n                    info_fields.append(value)\n                else:\n                    info_fields.append(\"=\".join([field, value]))\n            self.info = \";\".join(info_fields)\n        else:\n            self.info = \".\"", "response": "Updates info attribute from info dict."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _format_field(self):\n        format_field = \".\"\n        if self.sample_tag_values:\n            first_sample = list(self.sample_tag_values.keys())[0]\n            tag_names = self.sample_tag_values[first_sample].keys()\n            if tag_names:\n                format_field = \":\".join(tag_names)\n        return format_field", "response": "Returns string representation of format field."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _sample_field(self, sample):\n        tag_values = self.sample_tag_values[sample].values()\n        if tag_values:\n            return \":\".join(tag_values)\n        else:\n            return \".\"", "response": "Returns the string representation of sample - format values."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns tab - delimited newline terminated string of VcfRecord.", "response": "def text(self):\n        \"Returns tab-delimited, newline terminated string of VcfRecord.\"\n        stringifier = [self.chrom, self.pos, self.vcf_id, self.ref, self.alt,\n                       self.qual, self.filter, self.info,\n                       self._format_field()]\n\n        for sample in self.sample_tag_values:\n            stringifier.append(self._sample_field(sample))\n\n        return \"\\t\".join(stringifier) + \"\\n\""}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nappend a new format tag - value for all samples.", "response": "def add_sample_tag_value(self, tag_name, new_sample_values):\n        \"\"\"Appends a new format tag-value for all samples.\n\n        Args:\n            tag_name: string tag name; must not already exist\n            new_sample\n\n        Raises:\n            KeyError: if tag_name to be added already exists\n        \"\"\"\n        if tag_name in self.format_tags:\n            msg = \"New format value [{}] already exists.\".format(tag_name)\n            raise KeyError(msg)\n\n        if not self._samples_match(new_sample_values):\n            raise KeyError(\"Sample name values must match \"\n                           \"existing sample names\")\n        for sample in self.sample_tag_values.keys():\n            value = str(new_sample_values[sample])\n            self.sample_tag_values[sample][tag_name] = value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreplace null or blank filter or adds new_filter to existing list.", "response": "def add_or_replace_filter(self, new_filter):\n        \"\"\"Replaces null or blank filter or adds filter to existing list.\"\"\"\n        if self.filter.lower() in self._FILTERS_TO_REPLACE:\n            self.filter = new_filter\n        elif new_filter not in self.filter.split(\";\"):\n            self.filter = \";\".join([self.filter,\n                                    new_filter])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef available_categories(cls, user, products=AllProducts):\n        ''' Returns the categories available to the user. Specify `products` if\n        you want to restrict to just the categories that hold the specified\n        products, otherwise it'll do all. '''\n\n        # STOPGAP -- this needs to be elsewhere tbqh\n        from .product import ProductController\n\n        if products is AllProducts:\n            products = inventory.Product.objects.all().select_related(\n                \"category\",\n            )\n\n        available = ProductController.available_products(\n            user,\n            products=products,\n        )\n\n        return sorted(set(i.category for i in available), key=attrgetter(\"order\"))", "response": "Returns the available categories to the user. Specify products to restrict to just the categories that hold the specified\n        products."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nproduces an appropriate _ProductsForm subclass for the given category and products.", "response": "def ProductsForm(category, products):\n    ''' Produces an appropriate _ProductsForm subclass for the given render\n    type. '''\n\n    # Each Category.RENDER_TYPE value has a subclass here.\n    cat = inventory.Category\n    RENDER_TYPES = {\n        cat.RENDER_TYPE_QUANTITY: _QuantityBoxProductsForm,\n        cat.RENDER_TYPE_RADIO: _RadioButtonProductsForm,\n        cat.RENDER_TYPE_ITEM_QUANTITY: _ItemQuantityProductsForm,\n        cat.RENDER_TYPE_CHECKBOX: _CheckboxProductsForm,\n    }\n\n    # Produce a subclass of _ProductsForm which we can alter the base_fields on\n    class ProductsForm(RENDER_TYPES[category.render_type]):\n        pass\n\n    products = list(products)\n    products.sort(key=lambda prod: prod.order)\n\n    ProductsForm.set_fields(category, products)\n\n    if category.render_type == inventory.Category.RENDER_TYPE_ITEM_QUANTITY:\n        ProductsForm = forms.formset_factory(\n            ProductsForm,\n            formset=_ItemQuantityProductsFormSet,\n        )\n\n    return ProductsForm"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef staff_products_form_factory(user):\n    ''' Creates a StaffProductsForm that restricts the available products to\n    those that are available to a user. '''\n\n    products = inventory.Product.objects.all()\n    products = ProductController.available_products(user, products=products)\n\n    product_ids = [product.id for product in products]\n    product_set = inventory.Product.objects.filter(id__in=product_ids)\n\n    class StaffProductsForm(forms.Form):\n        ''' Form for allowing staff to add an item to a user's cart. '''\n\n        product = forms.ModelChoiceField(\n            widget=forms.Select,\n            queryset=product_set,\n        )\n\n        quantity = forms.IntegerField(\n            min_value=0,\n        )\n\n    return StaffProductsForm", "response": "Creates a StaffProductsForm that restricts the available products to\n    those that are available to a user."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_product_error(self, product, error):\n        ''' Adds an error to the given product's field '''\n\n        ''' if product in field_names:\n            field = field_names[product]\n        elif isinstance(product, inventory.Product):\n            return\n        else:\n            field = None '''\n\n        self.add_error(self.field_name(product), error)", "response": "Adds an error to the given product s field."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef initial_data(cls, product_quantities):\n        ''' Prepares initial data for an instance of this form.\n        product_quantities is a sequence of (product,quantity) tuples '''\n\n        f = [\n            {\n                _ItemQuantityProductsForm.CHOICE_FIELD: product.id,\n                _ItemQuantityProductsForm.QUANTITY_FIELD: quantity,\n            }\n            for product, quantity in product_quantities\n            if quantity > 0\n        ]\n        return f", "response": "Prepares initial data for an instance of this form."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef product_quantities(self):\n        ''' Yields a sequence of (product, quantity) tuples from the\n        cleaned form data. '''\n\n        products = set()\n        # Track everything so that we can yield some zeroes\n        all_products = set()\n\n        for form in self:\n            if form.empty_permitted and not form.cleaned_data:\n                # This is the magical empty form at the end of the list.\n                continue\n\n            for product, quantity in form.product_quantities():\n                all_products.add(product)\n                if quantity == 0:\n                    continue\n                if product in products:\n                    form.add_error(\n                        _ItemQuantityProductsForm.CHOICE_FIELD,\n                        \"You may only choose each product type once.\",\n                    )\n                    form.add_error(\n                        _ItemQuantityProductsForm.QUANTITY_FIELD,\n                        \"You may only choose each product type once.\",\n                    )\n                products.add(product)\n                yield product, quantity\n\n        for product in (all_products - products):\n            yield product, 0", "response": "Yields a sequence of tuples from the the\nEffectiveProductForm cleaned form data."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a form for specifying fields from a model to display.", "response": "def model_fields_form_factory(model):\n    ''' Creates a form for specifying fields from a model to display. '''\n\n    fields = model._meta.get_fields()\n\n    choices = []\n    for field in fields:\n        if hasattr(field, \"verbose_name\"):\n            choices.append((field.name, field.verbose_name))\n\n    class ModelFieldsForm(forms.Form):\n        fields = forms.MultipleChoiceField(\n            choices=choices,\n            required=False,\n        )\n\n    return ModelFieldsForm"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list of product - and - quantity pairs for all items in the cart that have purchased.", "response": "def _items(self, cart_status, category=None):\n        ''' Aggregates the items that this user has purchased.\n\n        Arguments:\n            cart_status (int or Iterable(int)): etc\n            category (Optional[models.inventory.Category]): the category\n                of items to restrict to.\n\n        Returns:\n            [ProductAndQuantity, ...]: A list of product-quantity pairs,\n                aggregating like products from across multiple invoices.\n\n        '''\n\n        if not isinstance(cart_status, Iterable):\n            cart_status = [cart_status]\n\n        status_query = (\n            Q(productitem__cart__status=status) for status in cart_status\n        )\n\n        in_cart = Q(productitem__cart__user=self.user)\n        in_cart = in_cart & reduce(operator.__or__, status_query)\n\n        quantities_in_cart = When(\n            in_cart,\n            then=\"productitem__quantity\",\n        )\n\n        quantities_or_zero = Case(\n            quantities_in_cart,\n            default=Value(0),\n        )\n\n        products = inventory.Product.objects\n\n        if category:\n            products = products.filter(category=category)\n\n        products = products.select_related(\"category\")\n        products = products.annotate(quantity=Sum(quantities_or_zero))\n        products = products.filter(quantity__gt=0)\n\n        out = []\n        for prod in products:\n            out.append(ProductAndQuantity(prod, prod.quantity))\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef items_pending_or_purchased(self):\n        ''' Returns the items that this user has purchased or has pending. '''\n        status = [commerce.Cart.STATUS_PAID, commerce.Cart.STATUS_ACTIVE]\n        return self._items(status)", "response": "Returns the items that this user has purchased or has pending."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef items_purchased(self, category=None):\n        ''' Aggregates the items that this user has purchased.\n\n        Arguments:\n            category (Optional[models.inventory.Category]): the category\n                of items to restrict to.\n\n        Returns:\n            [ProductAndQuantity, ...]: A list of product-quantity pairs,\n                aggregating like products from across multiple invoices.\n\n        '''\n        return self._items(commerce.Cart.STATUS_PAID, category=category)", "response": "Returns a list of items that this user has purchased."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef send_email(self, to, kind, **kwargs):\n        ''' Sends an e-mail to the given address.\n\n        to: The address\n        kind: the ID for an e-mail kind; it should point to a subdirectory of\n            self.template_prefix containing subject.txt and message.html, which\n            are django templates for the subject and HTML message respectively.\n\n        context: a context for rendering the e-mail.\n\n        '''\n\n        return __send_email__(self.template_prefix, to, kind, **kwargs)", "response": "Sends an e - mail to the given address."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nstarts processing an OSM changeset stream and yield one tuple at a time to the caller.", "response": "def iter_changeset_stream(start_sqn=None, base_url='https://planet.openstreetmap.org/replication/changesets', expected_interval=60, parse_timestamps=True, state_dir=None):\n    \"\"\"Start processing an OSM changeset stream and yield one (action, primitive) tuple\n    at a time to the caller.\"\"\"\n\n    # This is a lot like the other osm_stream except there's no\n    # state file for each of the diffs, so just push ahead until\n    # we run into a 404.\n\n    # If the user specifies a state_dir, read the state from the statefile there\n    if state_dir:\n        if not os.path.exists(state_dir):\n            raise Exception('Specified state_dir \"%s\" doesn\\'t exist.' % state_dir)\n\n        if os.path.exists('%s/state.yaml' % state_dir):\n            with open('%s/state.yaml' % state_dir) as f:\n                state = readState(f, ': ')\n                start_sqn = state['sequence']\n\n    # If no start_sqn, assume to start from the most recent changeset file\n    if not start_sqn:\n        u = urllib2.urlopen('%s/state.yaml' % base_url)\n        state = readState(u, ': ')\n        sequenceNumber = int(state['sequence'])\n    else:\n        sequenceNumber = int(start_sqn)\n\n    interval_fudge = 0.0\n    while True:\n        sqnStr = str(sequenceNumber).zfill(9)\n        url = '%s/%s/%s/%s.osm.gz' % (base_url, sqnStr[0:3], sqnStr[3:6], sqnStr[6:9])\n\n        delay = 1.0\n        while True:\n            try:\n                content = urllib2.urlopen(url)\n                content = StringIO.StringIO(content.read())\n                gzipper = gzip.GzipFile(fileobj=content)\n                interval_fudge -= (interval_fudge / 2.0)\n                break\n            except urllib2.HTTPError as e:\n                if e.code == 404:\n                    time.sleep(delay)\n                    delay = min(delay * 2, 13)\n                    interval_fudge += delay\n\n        obj = None\n        for event, elem in etree.iterparse(gzipper, events=('start', 'end')):\n            if event == 'start':\n                if elem.tag == 'changeset':\n                    obj = model.Changeset(\n                        int(elem.attrib['id']),\n                        isoToDatetime(elem.attrib.get('created_at')) if parse_timestamps else elem.attrib.get('created_at'),\n                        isoToDatetime(elem.attrib.get('closed_at')) if parse_timestamps else elem.attrib.get('closed_at'),\n                        maybeBool(elem.attrib['open']),\n                        maybeFloat(elem.get('min_lat')),\n                        maybeFloat(elem.get('max_lat')),\n                        maybeFloat(elem.get('min_lon')),\n                        maybeFloat(elem.get('max_lon')),\n                        elem.attrib.get('user'),\n                        maybeInt(elem.attrib.get('uid')),\n                        []\n                    )\n                elif elem.tag == 'tag':\n                    obj.tags.append(\n                        model.Tag(\n                            elem.attrib['k'],\n                            elem.attrib['v']\n                        )\n                    )\n            elif event == 'end':\n                if elem.tag == 'changeset':\n                    yield obj\n                    obj = None\n\n        yield model.Finished(sequenceNumber, None)\n\n        sequenceNumber += 1\n\n        if state_dir:\n            with open('%s/state.yaml' % state_dir, 'w') as f:\n                f.write('sequence: %d' % sequenceNumber)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstarts processing an OSM diff stream and yield one changeset at a time to the caller.", "response": "def iter_osm_stream(start_sqn=None, base_url='https://planet.openstreetmap.org/replication/minute', expected_interval=60, parse_timestamps=True, state_dir=None):\n    \"\"\"Start processing an OSM diff stream and yield one changeset at a time to\n    the caller.\"\"\"\n\n    # If the user specifies a state_dir, read the state from the statefile there\n    if state_dir:\n        if not os.path.exists(state_dir):\n            raise Exception('Specified state_dir \"%s\" doesn\\'t exist.' % state_dir)\n\n        if os.path.exists('%s/state.txt' % state_dir):\n            with open('%s/state.txt' % state_dir) as f:\n                state = readState(f)\n                start_sqn = state['sequenceNumber']\n\n    # If no start_sqn, assume to start from the most recent diff\n    if not start_sqn:\n        u = urllib2.urlopen('%s/state.txt' % base_url)\n        state = readState(u)\n    else:\n        sqnStr = str(start_sqn).zfill(9)\n        u = urllib2.urlopen('%s/%s/%s/%s.state.txt' % (base_url, sqnStr[0:3], sqnStr[3:6], sqnStr[6:9]))\n        state = readState(u)\n\n    interval_fudge = 0.0\n\n    while True:\n        sqnStr = state['sequenceNumber'].zfill(9)\n        url = '%s/%s/%s/%s.osc.gz' % (base_url, sqnStr[0:3], sqnStr[3:6], sqnStr[6:9])\n        content = urllib2.urlopen(url)\n        content = StringIO.StringIO(content.read())\n        gzipper = gzip.GzipFile(fileobj=content)\n\n        for a in iter_osm_change_file(gzipper, parse_timestamps):\n            yield a\n\n        # After parsing the OSC, check to see how much time is remaining\n        stateTs = datetime.datetime.strptime(state['timestamp'], \"%Y-%m-%dT%H:%M:%SZ\")\n        yield (None, model.Finished(state['sequenceNumber'], stateTs))\n\n        nextTs = stateTs + datetime.timedelta(seconds=expected_interval + interval_fudge)\n        if datetime.datetime.utcnow() < nextTs:\n            timeToSleep = (nextTs - datetime.datetime.utcnow()).total_seconds()\n        else:\n            timeToSleep = 0.0\n        time.sleep(timeToSleep)\n\n        # Then try to fetch the next state file\n        sqnStr = str(int(state['sequenceNumber']) + 1).zfill(9)\n        url = '%s/%s/%s/%s.state.txt' % (base_url, sqnStr[0:3], sqnStr[3:6], sqnStr[6:9])\n        delay = 1.0\n        while True:\n            try:\n                u = urllib2.urlopen(url)\n                interval_fudge -= (interval_fudge / 2.0)\n                break\n            except urllib2.HTTPError as e:\n                if e.code == 404:\n                    time.sleep(delay)\n                    delay = min(delay * 2, 13)\n                    interval_fudge += delay\n\n        if state_dir:\n            with open('%s/state.txt' % state_dir, 'w') as f:\n                f.write(u.read())\n            with open('%s/state.txt' % state_dir, 'r') as f:\n                state = readState(f)\n        else:\n            state = readState(u)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_osm_file(f, parse_timestamps=True):\n\n    nodes = []\n    ways = []\n    relations = []\n\n    for p in iter_osm_file(f, parse_timestamps):\n\n        if type(p) == model.Node:\n            nodes.append(p)\n        elif type(p) == model.Way:\n            ways.append(p)\n        elif type(p) == model.Relation:\n            relations.append(p)\n\n    return (nodes, ways, relations)", "response": "Parse an OSM XML file into memory and return an object with\n    the nodes ways and relations it contains."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nyielding all OSM Note objects in the feed.", "response": "def iter_osm_notes(feed_limit=25, interval=60, parse_timestamps=True):\n    \"\"\" Parses the global OSM Notes feed and yields as much Note information as possible. \"\"\"\n\n    last_seen_guid = None\n    while True:\n        u = urllib2.urlopen('https://www.openstreetmap.org/api/0.6/notes/feed?limit=%d' % feed_limit)\n\n        tree = etree.parse(u)\n\n        new_notes = []\n        for note_item in tree.xpath('/rss/channel/item'):\n            title = note_item.xpath('title')[0].text\n\n            if title.startswith('new note ('):\n                action = 'create'\n            elif title.startswith('new comment ('):\n                action = 'comment'\n            elif title.startswith('closed note ('):\n                action = 'close'\n\n            # Note that (at least for now) the link and guid are the same in the feed.\n            guid = note_item.xpath('link')[0].text\n\n            if last_seen_guid == guid:\n                break\n            elif last_seen_guid == None:\n                # The first time through we want the first item to be the \"last seen\"\n                # because the RSS feed is newest-to-oldest\n                last_seen_guid = guid\n            else:\n                note_id = int(guid.split('/')[-1].split('#c')[0])\n                new_notes.append((action, get_note(note_id, parse_timestamps)))\n\n        # We yield the reversed list because we want to yield in change order\n        # (i.e. \"oldest to most current\")\n        for note in reversed(new_notes):\n            yield note\n\n        yield model.Finished(None, None)\n\n        time.sleep(interval)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns true if the condition passes the filter", "response": "def passes_filter(self, user):\n        ''' Returns true if the condition passes the filter '''\n\n        cls = type(self.condition)\n        qs = cls.objects.filter(pk=self.condition.id)\n        return self.condition in self.pre_filter(qs, user)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the number of items covered by this flag condition the user can add to the current cart.", "response": "def user_quantity_remaining(self, user, filtered=False):\n        ''' Returns the number of items covered by this flag condition the\n        user can add to the current cart. This default implementation returns\n        a big number if is_met() is true, otherwise 0.\n\n        Either this method, or is_met() must be overridden in subclasses.\n        '''\n\n        return _BIG_QUANTITY if self.is_met(user, filtered) else 0"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning True if this flag condition is met otherwise returns False.", "response": "def is_met(self, user, filtered=False):\n        ''' Returns True if this flag condition is met, otherwise returns\n        False. It determines if the condition is met by calling pre_filter\n        with a queryset containing only self.condition. '''\n\n        if filtered:\n            return True  # Why query again?\n\n        return self.passes_filter(user)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef user_quantity_remaining(self, user, filtered=True):\n        ''' returns 0 if the date range is violated, otherwise, it will return\n        the quantity remaining under the stock limit.\n\n        The filter for this condition must add an annotation called \"remainder\"\n        in order for this to work.\n        '''\n\n        if filtered:\n            if hasattr(self.condition, \"remainder\"):\n                return self.condition.remainder\n\n        # Mark self.condition with a remainder\n        qs = type(self.condition).objects.filter(pk=self.condition.id)\n        qs = self.pre_filter(qs, user)\n\n        if len(qs) > 0:\n            return qs[0].remainder\n        else:\n            return 0", "response": "returns 0 if the date range is violated otherwise it will return\n        the quantity remaining under the stock limit."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning all of the items from queryset where the user has a product from a category from a category invoking that item s condition in one of their carts.", "response": "def pre_filter(self, queryset, user):\n        ''' Returns all of the items from queryset where the user has a\n        product from a category invoking that item's condition in one of their\n        carts. '''\n\n        in_user_carts = Q(\n            enabling_category__product__productitem__cart__user=user\n        )\n        released = commerce.Cart.STATUS_RELEASED\n        in_released_carts = Q(\n            enabling_category__product__productitem__cart__status=released\n        )\n        queryset = queryset.filter(in_user_carts)\n        queryset = queryset.exclude(in_released_carts)\n\n        return queryset"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pre_filter(self, queryset, user):\n        ''' Returns all of the items from queryset where the user has a\n        product invoking that item's condition in one of their carts. '''\n\n        in_user_carts = Q(enabling_products__productitem__cart__user=user)\n        released = commerce.Cart.STATUS_RELEASED\n        paid = commerce.Cart.STATUS_PAID\n        active = commerce.Cart.STATUS_ACTIVE\n        in_released_carts = Q(\n            enabling_products__productitem__cart__status=released\n        )\n        not_in_paid_or_active_carts = ~(\n            Q(enabling_products__productitem__cart__status=paid) |\n            Q(enabling_products__productitem__cart__status=active)\n        )\n\n        queryset = queryset.filter(in_user_carts)\n        queryset = queryset.exclude(\n            in_released_carts & not_in_paid_or_active_carts\n        )\n\n        return queryset", "response": "Returns all of the items from queryset where the user has a\n        product invoking that item s condition in one of their carts."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pre_filter(self, queryset, user):\n        ''' Returns all of the items from queryset where the date falls into\n        any specified range, but not yet where the stock limit is not yet\n        reached.'''\n\n        now = timezone.now()\n\n        # Keep items with no start time, or start time not yet met.\n        queryset = queryset.filter(Q(start_time=None) | Q(start_time__lte=now))\n        queryset = queryset.filter(Q(end_time=None) | Q(end_time__gte=now))\n\n        # Filter out items that have been reserved beyond the limits\n        quantity_or_zero = self._calculate_quantities(user)\n\n        remainder = Case(\n            When(limit=None, then=Value(_BIG_QUANTITY)),\n            default=F(\"limit\") - Sum(quantity_or_zero),\n        )\n\n        queryset = queryset.annotate(remainder=remainder)\n        queryset = queryset.filter(remainder__gt=0)\n\n        return queryset", "response": "Returns all of the items from queryset where the date falls into any specified range but not yet where the stock limit is not yet\n        reached."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfiltering out items which are enabled by a user being a presenter or copresenter of a non - cancelled proposal.", "response": "def pre_filter(self, queryset, user):\n        ''' Returns all of the items from queryset which are enabled by a user\n        being a presenter or copresenter of a non-cancelled proposal. '''\n\n        # Filter out cancelled proposals\n        queryset = queryset.filter(\n            proposal_kind__proposalbase__presentation__cancelled=False\n        )\n\n        u = user\n        # User is a presenter\n        user_is_presenter = Q(\n            is_presenter=True,\n            proposal_kind__proposalbase__presentation__speaker__user=u,\n        )\n        # User is a copresenter\n        user_is_copresenter = Q(\n            is_copresenter=True,\n            proposal_kind__proposalbase__presentation__additional_speakers__user=u,  # NOQA\n        )\n\n        return queryset.filter(user_is_presenter | user_is_copresenter)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns all items from conditions which are enabled by a Django Auth Group user being member of Django Auth Group.", "response": "def pre_filter(self, conditions, user):\n        ''' Returns all of the items from conditions which are enabled by a\n        user being member of a Django Auth Group. '''\n\n        return conditions.filter(group__in=user.groups.all())"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the user s current cart or creates a new one if there isn t one.", "response": "def for_user(cls, user):\n        ''' Returns the user's current cart, or creates a new cart\n        if there isn't one ready yet. '''\n\n        try:\n            existing = commerce.Cart.objects.get(\n                user=user,\n                status=commerce.Cart.STATUS_ACTIVE,\n            )\n        except ObjectDoesNotExist:\n            existing = commerce.Cart.objects.create(\n                user=user,\n                time_last_updated=timezone.now(),\n                reservation_duration=datetime.timedelta(),\n            )\n        return cls(existing)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _autoextend_reservation(self):\n        ''' Updates the cart's time last updated value, which is used to\n        determine whether the cart has reserved the items and discounts it\n        holds. '''\n\n        time = timezone.now()\n\n        # Calculate the residual of the _old_ reservation duration\n        # if it's greater than what's in the cart now, keep it.\n        time_elapsed_since_updated = (time - self.cart.time_last_updated)\n        residual = self.cart.reservation_duration - time_elapsed_since_updated\n\n        reservations = [datetime.timedelta(0), residual]\n\n        # If we have vouchers, we're entitled to an hour at minimum.\n        if len(self.cart.vouchers.all()) >= 1:\n            reservations.append(inventory.Voucher.RESERVATION_DURATION)\n\n        # Else, it's the maximum of the included products\n        items = commerce.ProductItem.objects.filter(cart=self.cart)\n        agg = items.aggregate(Max(\"product__reservation_duration\"))\n        product_max = agg[\"product__reservation_duration__max\"]\n\n        if product_max is not None:\n            reservations.append(product_max)\n\n        self.cart.time_last_updated = time\n        self.cart.reservation_duration = max(reservations)", "response": "Updates the cart s time last updated value which is used to determine whether the cart has reserved the items and discounts it\n        holds."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _end_batch(self):\n        ''' Performs operations that occur occur at the end of a batch of\n        product changes/voucher applications etc.\n\n        You need to call this after you've finished modifying the user's cart.\n        This is normally done by wrapping a block of code using\n        ``operations_batch``.\n\n        '''\n\n        self.cart.refresh_from_db()\n\n        self._recalculate_discounts()\n\n        self._autoextend_reservation()\n        self.cart.revision += 1\n        self.cart.save()", "response": "Ends the batch of operations."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef extend_reservation(self, timedelta):\n        ''' Extends the reservation on this cart by the given timedelta.\n        This can only be done if the current state of the cart is valid (i.e\n        all items and discounts in the cart are still available.)\n\n        Arguments:\n            timedelta (timedelta): The amount of time to extend the cart by.\n                The resulting reservation_duration will be now() + timedelta,\n                unless the requested extension is *LESS* than the current\n                reservation deadline.\n\n        '''\n\n        self.validate_cart()\n        cart = self.cart\n        cart.refresh_from_db()\n\n        elapsed = (timezone.now() - cart.time_last_updated)\n\n        if cart.reservation_duration - elapsed > timedelta:\n            return\n\n        cart.time_last_updated = timezone.now()\n        cart.reservation_duration = timedelta\n        cart.save()", "response": "Extends the reservation on this cart by the given timedelta."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the quantities on each of the products on each of the theCOOKIES products specified. Raises an exception if a limit is violated.", "response": "def set_quantities(self, product_quantities):\n        ''' Sets the quantities on each of the products on each of the\n        products specified. Raises an exception (ValidationError) if a limit\n        is violated. `product_quantities` is an iterable of (product, quantity)\n        pairs. '''\n\n        items_in_cart = commerce.ProductItem.objects.filter(cart=self.cart)\n        items_in_cart = items_in_cart.select_related(\n            \"product\",\n            \"product__category\",\n        )\n\n        product_quantities = list(product_quantities)\n\n        # n.b need to add have the existing items first so that the new\n        # items override the old ones.\n        all_product_quantities = dict(itertools.chain(\n            ((i.product, i.quantity) for i in items_in_cart.all()),\n            product_quantities,\n        )).items()\n\n        # Validate that the limits we're adding are OK\n        products = set(product for product, q in product_quantities)\n        try:\n            self._test_limits(all_product_quantities)\n        except CartValidationError as ve:\n            # Only raise errors for products that we're explicitly\n            # Manipulating here.\n            for ve_field in ve.error_list:\n                product, message = ve_field.message\n                if product in products:\n                    raise ve\n\n        new_items = []\n        products = []\n        for product, quantity in product_quantities:\n            products.append(product)\n\n            if quantity == 0:\n                continue\n\n            item = commerce.ProductItem(\n                cart=self.cart,\n                product=product,\n                quantity=quantity,\n            )\n            new_items.append(item)\n\n        to_delete = (\n            Q(quantity=0) |\n            Q(product__in=products)\n        )\n\n        items_in_cart.filter(to_delete).delete()\n        commerce.ProductItem.objects.bulk_create(new_items)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef apply_voucher(self, voucher_code):\n        ''' Applies the voucher with the given code to this cart. '''\n\n        # Try and find the voucher\n        voucher = inventory.Voucher.objects.get(code=voucher_code.upper())\n\n        # Re-applying vouchers should be idempotent\n        if voucher in self.cart.vouchers.all():\n            return\n\n        self._test_voucher(voucher)\n\n        # If successful...\n        self.cart.vouchers.add(voucher)", "response": "Applies the voucher with the given code to this cart."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nvalidate the status of the current cart and returns True if the status of the current cart is valid False otherwise.", "response": "def validate_cart(self):\n        ''' Determines whether the status of the current cart is valid;\n        this is normally called before generating or paying an invoice '''\n\n        cart = self.cart\n        user = self.cart.user\n        errors = []\n\n        try:\n            self._test_vouchers(self.cart.vouchers.all())\n        except ValidationError as ve:\n            errors.append(ve)\n\n        items = commerce.ProductItem.objects.filter(cart=cart)\n        items = items.select_related(\"product\", \"product__category\")\n\n        product_quantities = list((i.product, i.quantity) for i in items)\n        try:\n            self._test_limits(product_quantities)\n        except ValidationError as ve:\n            self._append_errors(errors, ve)\n\n        try:\n            self._test_required_categories()\n        except ValidationError as ve:\n            self._append_errors(errors, ve)\n\n        # Validate the discounts\n        # TODO: refactor in terms of available_discounts\n        # why aren't we doing that here?!\n\n        #     def available_discounts(cls, user, categories, products):\n\n        products = [i.product for i in items]\n        discounts_with_quantity = DiscountController.available_discounts(\n            user,\n            [],\n            products,\n        )\n        discounts = set(i.discount.id for i in discounts_with_quantity)\n\n        discount_items = commerce.DiscountItem.objects.filter(cart=cart)\n        for discount_item in discount_items:\n            discount = discount_item.discount\n\n            if discount.id not in discounts:\n                errors.append(\n                    ValidationError(\"Discounts are no longer available\")\n                )\n\n        if errors:\n            raise ValidationError(errors)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _recalculate_discounts(self):\n        ''' Calculates all of the discounts available for this product.'''\n\n        # Delete the existing entries.\n        commerce.DiscountItem.objects.filter(cart=self.cart).delete()\n\n        # Order the products such that the most expensive ones are\n        # processed first.\n        product_items = self.cart.productitem_set.all().select_related(\n            \"product\", \"product__category\"\n        ).order_by(\"-product__price\")\n\n        products = [i.product for i in product_items]\n        discounts = DiscountController.available_discounts(\n            self.cart.user,\n            [],\n            products,\n        )\n\n        # The highest-value discounts will apply to the highest-value\n        # products first, because of the order_by clause\n        for item in product_items:\n            self._add_discount(item.product, item.quantity, discounts)", "response": "Calculates all of the discounts available for this product."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _add_discount(self, product, quantity, discounts):\n        ''' Applies the best discounts on the given product, from the given\n        discounts.'''\n\n        def matches(discount):\n            ''' Returns True if and only if the given discount apples to\n            our product. '''\n            if isinstance(discount.clause, conditions.DiscountForCategory):\n                return discount.clause.category == product.category\n            else:\n                return discount.clause.product == product\n\n        def value(discount):\n            ''' Returns the value of this discount clause\n            as applied to this product '''\n            if discount.clause.percentage is not None:\n                return discount.clause.percentage * product.price\n            else:\n                return discount.clause.price\n\n        discounts = [i for i in discounts if matches(i)]\n        discounts.sort(key=value)\n\n        for candidate in reversed(discounts):\n            if quantity == 0:\n                break\n            elif candidate.quantity == 0:\n                # This discount clause has been exhausted by this cart\n                continue\n\n            # Get a provisional instance for this DiscountItem\n            # with the quantity set to as much as we have in the cart\n            discount_item = commerce.DiscountItem.objects.create(\n                product=product,\n                cart=self.cart,\n                discount=candidate.discount,\n                quantity=quantity,\n            )\n\n            # Truncate the quantity for this DiscountItem if we exceed quantity\n            ours = discount_item.quantity\n            allowed = candidate.quantity\n            if ours > allowed:\n                discount_item.quantity = allowed\n                discount_item.save()\n                # Update the remaining quantity.\n                quantity = ours - allowed\n            else:\n                quantity = 0\n\n            candidate.quantity -= discount_item.quantity", "response": "Adds a discount clause to the given product from the given discounts."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef rows(self, content_type):\n        ''' Returns the data rows for the table. '''\n\n        for row in self._data:\n            yield [\n                self.cell_text(content_type, i, cell)\n                for i, cell in enumerate(row)\n            ]", "response": "Returns the data rows for the table."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_form(self, request):\n\n        ''' Creates an instance of self.form_type using request.GET '''\n\n        # Create a form instance\n        if self.form_type is not None:\n            form = self.form_type(request.GET)\n\n            # Pre-validate it\n            form.is_valid()\n        else:\n            form = None\n\n        return form", "response": "Creates an instance of self. form_type using request. GET"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrap the reports in a _ReportTemplateWrapper for the given content_type.", "response": "def wrap_reports(cls, reports, content_type):\n        ''' Wraps the reports in a _ReportTemplateWrapper for the given\n        content_type -- this allows data to be returned as HTML links, for\n        instance. '''\n\n        reports = [\n            _ReportTemplateWrapper(content_type, report)\n            for report in reports\n        ]\n\n        return reports"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef render(self, data):\n        ''' Renders the reports based on data.content_type's value.\n\n        Arguments:\n            data (ReportViewRequestData): The report data. data.content_type\n                is used to determine how the reports are rendered.\n\n        Returns:\n            HTTPResponse: The rendered version of the report.\n\n        '''\n        renderers = {\n            \"text/csv\": self._render_as_csv,\n            \"text/html\": self._render_as_html,\n            None: self._render_as_html,\n        }\n        render = renderers[data.content_type]\n        return render(data)", "response": "Renders the reports based on data. content_type."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef reports_list(request):\n    ''' Lists all of the reports currently available. '''\n\n    reports = []\n\n    for report in get_all_reports():\n        reports.append({\n            \"name\": report.__name__,\n            \"url\": reverse(report),\n            \"description\": report.__doc__,\n        })\n\n    reports.sort(key=lambda report: report[\"name\"])\n\n    ctx = {\n        \"reports\": reports,\n    }\n\n    return render(request, \"registrasion/reports_list.html\", ctx)", "response": "Lists all of the reports currently available."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef items_sold():\n    ''' Summarises the items sold and discounts granted for a given set of\n    products, or products from categories. '''\n\n    data = None\n    headings = None\n\n    line_items = commerce.LineItem.objects.filter(\n        invoice__status=commerce.Invoice.STATUS_PAID,\n    ).select_related(\"invoice\")\n\n    line_items = line_items.order_by(\n        # sqlite requires an order_by for .values() to work\n        \"-price\", \"description\",\n    ).values(\n        \"price\", \"description\",\n    ).annotate(\n        total_quantity=Sum(\"quantity\"),\n    )\n\n    headings = [\"Description\", \"Quantity\", \"Price\", \"Total\"]\n\n    data = []\n    total_income = 0\n    for line in line_items:\n        cost = line[\"total_quantity\"] * line[\"price\"]\n        data.append([\n            line[\"description\"], line[\"total_quantity\"],\n            line[\"price\"], cost,\n        ])\n        total_income += cost\n\n    data.append([\n        \"(TOTAL)\", \"--\", \"--\", total_income,\n    ])\n\n    return ListReport(\"Items sold\", headings, data)", "response": "Summarises the items sold and discounts granted for a given set of\n    products or products from categories."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsummarises paid items and payments.", "response": "def sales_payment_summary():\n    ''' Summarises paid items and payments. '''\n\n    def value_or_zero(aggregate, key):\n        return aggregate[key] or 0\n\n    def sum_amount(payment_set):\n        a = payment_set.values(\"amount\").aggregate(total=Sum(\"amount\"))\n        return value_or_zero(a, \"total\")\n\n    headings = [\"Category\", \"Total\"]\n    data = []\n\n    # Summarise all sales made (= income.)\n    sales = commerce.LineItem.objects.filter(\n        invoice__status=commerce.Invoice.STATUS_PAID,\n    ).values(\n        \"price\", \"quantity\"\n    ).aggregate(\n        total=Sum(F(\"price\") * F(\"quantity\"), output_field=CURRENCY()),\n    )\n    sales = value_or_zero(sales, \"total\")\n\n    all_payments = sum_amount(commerce.PaymentBase.objects.all())\n\n    # Manual payments\n    # Credit notes generated (total)\n    # Payments made by credit note\n    # Claimed credit notes\n\n    all_credit_notes = 0 - sum_amount(commerce.CreditNote.objects.all())\n    unclaimed_credit_notes = 0 - sum_amount(commerce.CreditNote.unclaimed())\n    claimed_credit_notes = sum_amount(\n        commerce.CreditNoteApplication.objects.all()\n    )\n    refunded_credit_notes = 0 - sum_amount(commerce.CreditNote.refunded())\n\n    data.append([\"Items on paid invoices\", sales])\n    data.append([\"All payments\", all_payments])\n    data.append([\"Sales - Payments \", sales - all_payments])\n    data.append([\"All credit notes\", all_credit_notes])\n    data.append([\"Credit notes paid on invoices\", claimed_credit_notes])\n    data.append([\"Credit notes refunded\", refunded_credit_notes])\n    data.append([\"Unclaimed credit notes\", unclaimed_credit_notes])\n    data.append([\n        \"Credit notes - (claimed credit notes + unclaimed credit notes)\",\n        all_credit_notes - claimed_credit_notes -\n        refunded_credit_notes - unclaimed_credit_notes\n        ])\n\n    return ListReport(\"Sales and Payments Summary\", headings, data)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nshowing the history of payments into the system", "response": "def payments():\n    ''' Shows the history of payments into the system '''\n\n    payments = commerce.PaymentBase.objects.all()\n    return QuerysetReport(\n        \"Payments\",\n        [\"invoice__id\", \"id\", \"reference\", \"amount\"],\n        payments,\n        link_view=views.invoice,\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef credit_note_refunds():\n    ''' Shows all of the credit notes that have been generated. '''\n    notes_refunded = commerce.CreditNote.refunded()\n    return QuerysetReport(\n        \"Credit note refunds\",\n        [\"id\", \"creditnoterefund__reference\", \"amount\"],\n        notes_refunded,\n        link_view=views.credit_note,\n    )", "response": "Displays all of the credit notes that have been generated."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef product_status(request, form):\n    ''' Summarises the inventory status of the given items, grouping by\n    invoice status. '''\n\n    products = form.cleaned_data[\"product\"]\n    categories = form.cleaned_data[\"category\"]\n\n    items = commerce.ProductItem.objects.filter(\n        Q(product__in=products) | Q(product__category__in=categories),\n    ).select_related(\"cart\", \"product\")\n\n    items = group_by_cart_status(\n        items,\n        [\"product__category__order\", \"product__order\"],\n        [\"product\", \"product__category__name\", \"product__name\"],\n    )\n\n    headings = [\n        \"Product\", \"Paid\", \"Reserved\", \"Unreserved\", \"Refunded\",\n    ]\n    data = []\n\n    for item in items:\n        data.append([\n            \"%s - %s\" % (\n                item[\"product__category__name\"], item[\"product__name\"]\n            ),\n            item[\"total_paid\"],\n            item[\"total_reserved\"],\n            item[\"total_unreserved\"],\n            item[\"total_refunded\"],\n        ])\n\n    return ListReport(\"Inventory\", headings, data)", "response": "Summarises the inventory status of the given items grouping by product status."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef discount_status(request, form):\n    ''' Summarises the usage of a given discount. '''\n\n    discounts = form.cleaned_data[\"discount\"]\n\n    items = commerce.DiscountItem.objects.filter(\n        Q(discount__in=discounts),\n    ).select_related(\"cart\", \"product\", \"product__category\")\n\n    items = group_by_cart_status(\n        items,\n        [\"discount\"],\n        [\"discount\", \"discount__description\"],\n    )\n\n    headings = [\n        \"Discount\", \"Paid\", \"Reserved\", \"Unreserved\", \"Refunded\",\n    ]\n    data = []\n\n    for item in items:\n        data.append([\n            item[\"discount__description\"],\n            item[\"total_paid\"],\n            item[\"total_reserved\"],\n            item[\"total_unreserved\"],\n            item[\"total_refunded\"],\n        ])\n\n    return ListReport(\"Usage by item\", headings, data)", "response": "Summarises the usage of a given discount."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nshow each product line item from invoices including their date and purchashing customer.", "response": "def product_line_items(request, form):\n    ''' Shows each product line item from invoices, including their date and\n    purchashing customer. '''\n\n    products = form.cleaned_data[\"product\"]\n    categories = form.cleaned_data[\"category\"]\n\n    invoices = commerce.Invoice.objects.filter(\n        (\n            Q(lineitem__product__in=products) |\n            Q(lineitem__product__category__in=categories)\n        ),\n        status=commerce.Invoice.STATUS_PAID,\n    ).select_related(\n        \"cart\",\n        \"user\",\n        \"user__attendee\",\n        \"user__attendee__attendeeprofilebase\"\n    ).order_by(\"issue_time\")\n\n    headings = [\n        'Invoice', 'Invoice Date', 'Attendee', 'Qty', 'Product', 'Status'\n    ]\n\n    data = []\n    for invoice in invoices:\n        for item in invoice.cart.productitem_set.all():\n            if item.product in products or item.product.category in categories:\n                output = []\n                output.append(invoice.id)\n                output.append(invoice.issue_time.strftime('%Y-%m-%d %H:%M:%S'))\n                output.append(\n                    invoice.user.attendee.attendeeprofilebase.attendee_name()\n                )\n                output.append(item.quantity)\n                output.append(item.product)\n                cart = invoice.cart\n                if cart.status == commerce.Cart.STATUS_PAID:\n                    output.append('PAID')\n                elif cart.status == commerce.Cart.STATUS_ACTIVE:\n                    output.append('UNPAID')\n                elif cart.status == commerce.Cart.STATUS_RELEASED:\n                    output.append('REFUNDED')\n                data.append(output)\n\n    return ListReport(\"Line Items\", headings, data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef paid_invoices_by_date(request, form):\n    ''' Shows the number of paid invoices containing given products or\n    categories per day. '''\n\n    products = form.cleaned_data[\"product\"]\n    categories = form.cleaned_data[\"category\"]\n\n    invoices = commerce.Invoice.objects.filter(\n        (\n            Q(lineitem__product__in=products) |\n            Q(lineitem__product__category__in=categories)\n        ),\n        status=commerce.Invoice.STATUS_PAID,\n    )\n\n    # Invoices with payments will be paid at the time of their latest payment\n    payments = commerce.PaymentBase.objects.all()\n    payments = payments.filter(\n        invoice__in=invoices,\n    )\n    payments = payments.order_by(\"invoice\")\n    invoice_max_time = payments.values(\"invoice\").annotate(\n        max_time=Max(\"time\")\n    )\n\n    # Zero-value invoices will have no payments, so they're paid at issue time\n    zero_value_invoices = invoices.filter(value=0)\n\n    times = itertools.chain(\n        (line[\"max_time\"] for line in invoice_max_time),\n        (invoice.issue_time for invoice in zero_value_invoices),\n    )\n\n    by_date = collections.defaultdict(int)\n    for time in times:\n        date = datetime.datetime(\n            year=time.year, month=time.month, day=time.day\n        )\n        by_date[date] += 1\n\n    data = [(date_, count) for date_, count in sorted(by_date.items())]\n    data = [(date_.strftime(\"%Y-%m-%d\"), count) for date_, count in data]\n\n    return ListReport(\n        \"Paid Invoices By Date\",\n        [\"date\", \"count\"],\n        data,\n    )", "response": "Displays the number of paid invoices containing given products or categories per day."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef credit_notes(request, form):\n    ''' Shows all of the credit notes in the system. '''\n\n    notes = commerce.CreditNote.objects.all().select_related(\n        \"creditnoterefund\",\n        \"creditnoteapplication\",\n        \"invoice\",\n        \"invoice__user__attendee__attendeeprofilebase\",\n    )\n\n    return QuerysetReport(\n        \"Credit Notes\",\n        [\"id\",\n         \"invoice__user__attendee__attendeeprofilebase__invoice_recipient\",\n         \"status\", \"value\"],\n        notes,\n        headings=[\"id\", \"Owner\", \"Status\", \"Value\"],\n        link_view=views.credit_note,\n    )", "response": "Displays all credit notes in the system."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nshowing all of the invoices in the system.", "response": "def invoices(request, form):\n    ''' Shows all of the invoices in the system. '''\n\n    invoices = commerce.Invoice.objects.all().order_by(\"status\", \"id\")\n\n    return QuerysetReport(\n        \"Invoices\",\n        [\"id\", \"recipient\", \"value\", \"get_status_display\"],\n        invoices,\n        headings=[\"id\", \"Recipient\", \"Value\", \"Status\"],\n        link_view=views.invoice,\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of all manifested attendees if no user_id is specified else displays the attendee manifest.", "response": "def attendee(request, form, user_id=None):\n    ''' Returns a list of all manifested attendees if no attendee is specified,\n    else displays the attendee manifest. '''\n\n    if user_id is None and form.cleaned_data[\"user\"] is not None:\n        user_id = form.cleaned_data[\"user\"]\n\n    if user_id is None:\n        return attendee_list(request)\n\n    attendee = people.Attendee.objects.get(user__id=user_id)\n    name = attendee.attendeeprofilebase.attendee_name()\n\n    reports = []\n\n    profile_data = []\n    try:\n        profile = people.AttendeeProfileBase.objects.get_subclass(\n            attendee=attendee\n        )\n        fields = profile._meta.get_fields()\n    except people.AttendeeProfileBase.DoesNotExist:\n        fields = []\n\n    exclude = set([\"attendeeprofilebase_ptr\", \"id\"])\n    for field in fields:\n        if field.name in exclude:\n            # Not actually important\n            continue\n        if not hasattr(field, \"verbose_name\"):\n            continue  # Not a publicly visible field\n        value = getattr(profile, field.name)\n\n        if isinstance(field, models.ManyToManyField):\n            value = \", \".join(str(i) for i in value.all())\n\n        profile_data.append((field.verbose_name, value))\n\n    cart = CartController.for_user(attendee.user)\n    reservation = cart.cart.reservation_duration + cart.cart.time_last_updated\n    profile_data.append((\"Current cart reserved until\", reservation))\n\n    reports.append(ListReport(\"Profile\", [\"\", \"\"], profile_data))\n\n    links = []\n    links.append((\n        reverse(views.badge, args=[user_id]),\n        \"View badge\",\n    ))\n    links.append((\n        reverse(views.amend_registration, args=[user_id]),\n        \"Amend current cart\",\n    ))\n    links.append((\n        reverse(views.extend_reservation, args=[user_id]),\n        \"Extend reservation\",\n    ))\n\n    reports.append(Links(\"Actions for \" + name, links))\n\n    # Paid and pending  products\n    ic = ItemController(attendee.user)\n    reports.append(ListReport(\n        \"Paid Products\",\n        [\"Product\", \"Quantity\"],\n        [(pq.product, pq.quantity) for pq in ic.items_purchased()],\n    ))\n    reports.append(ListReport(\n        \"Unpaid Products\",\n        [\"Product\", \"Quantity\"],\n        [(pq.product, pq.quantity) for pq in ic.items_pending()],\n    ))\n\n    # Invoices\n    invoices = commerce.Invoice.objects.filter(\n        user=attendee.user,\n    )\n    reports.append(QuerysetReport(\n        \"Invoices\",\n        [\"id\", \"get_status_display\", \"value\"],\n        invoices,\n        headings=[\"Invoice ID\", \"Status\", \"Value\"],\n        link_view=views.invoice,\n    ))\n\n    # Credit Notes\n    credit_notes = commerce.CreditNote.objects.filter(\n        invoice__user=attendee.user,\n    ).select_related(\"invoice\", \"creditnoteapplication\", \"creditnoterefund\")\n\n    reports.append(QuerysetReport(\n        \"Credit Notes\",\n        [\"id\", \"status\", \"value\"],\n        credit_notes,\n        link_view=views.credit_note,\n    ))\n\n    # All payments\n    payments = commerce.PaymentBase.objects.filter(\n        invoice__user=attendee.user,\n    ).select_related(\"invoice\")\n\n    reports.append(QuerysetReport(\n        \"Payments\",\n        [\"invoice__id\", \"id\", \"reference\", \"amount\"],\n        payments,\n        link_view=views.invoice,\n    ))\n\n    return reports"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef attendee_list(request):\n    ''' Returns a list of all attendees. '''\n\n    attendees = people.Attendee.objects.select_related(\n        \"attendeeprofilebase\",\n        \"user\",\n    )\n\n    profiles = AttendeeProfile.objects.filter(\n        attendee__in=attendees\n    ).select_related(\n        \"attendee\", \"attendee__user\",\n    )\n    profiles_by_attendee = dict((i.attendee, i) for i in profiles)\n\n    attendees = attendees.annotate(\n        has_registered=Count(\n            Q(user__invoice__status=commerce.Invoice.STATUS_PAID)\n        ),\n    )\n\n    headings = [\n        \"User ID\", \"Name\", \"Email\", \"Has registered\",\n    ]\n\n    data = []\n\n    for a in attendees:\n        data.append([\n            a.user.id,\n            (profiles_by_attendee[a].attendee_name()\n                if a in profiles_by_attendee else \"\"),\n            a.user.email,\n            a.has_registered > 0,\n        ])\n\n    # Sort by whether they've registered, then ID.\n    data.sort(key=lambda a: (-a[3], a[0]))\n\n    return AttendeeListReport(\"Attendees\", headings, data, link_view=attendee)", "response": "Returns a list of all attendees."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlist attendees for a given product category selection along with profile data.", "response": "def attendee_data(request, form, user_id=None):\n    ''' Lists attendees for a given product/category selection along with\n    profile data.'''\n\n    status_display = {\n        commerce.Cart.STATUS_ACTIVE: \"Unpaid\",\n        commerce.Cart.STATUS_PAID: \"Paid\",\n        commerce.Cart.STATUS_RELEASED: \"Refunded\",\n    }\n\n    output = []\n\n    by_category = (\n        form.cleaned_data[\"group_by\"] == forms.GroupByForm.GROUP_BY_CATEGORY)\n\n    products = form.cleaned_data[\"product\"]\n    categories = form.cleaned_data[\"category\"]\n    fields = form.cleaned_data[\"fields\"]\n    name_field = AttendeeProfile.name_field()\n\n    items = commerce.ProductItem.objects.filter(\n        Q(product__in=products) | Q(product__category__in=categories),\n    ).exclude(\n        cart__status=commerce.Cart.STATUS_RELEASED\n    ).select_related(\n        \"cart\", \"cart__user\", \"product\", \"product__category\",\n    ).order_by(\"cart__status\")\n\n    # Add invoice nag link\n    links = []\n    invoice_mailout = reverse(views.invoice_mailout, args=[])\n    invoice_mailout += \"?\" + request.META[\"QUERY_STRING\"]\n    links += [\n        (invoice_mailout + \"&status=1\", \"Send invoice reminders\",),\n        (invoice_mailout + \"&status=2\", \"Send mail for paid invoices\",),\n    ]\n\n    if items.count() > 0:\n        output.append(Links(\"Actions\", links))\n\n    # Make sure we select all of the related fields\n    related_fields = set(\n        field for field in fields\n        if isinstance(AttendeeProfile._meta.get_field(field), RelatedField)\n    )\n\n    # Get all of the relevant attendee profiles in one hit.\n    profiles = AttendeeProfile.objects.filter(\n        attendee__user__cart__productitem__in=items\n    ).select_related(\"attendee__user\").prefetch_related(*related_fields)\n    by_user = {}\n    for profile in profiles:\n        by_user[profile.attendee.user] = profile\n\n    cart = \"attendee__user__cart\"\n    cart_status = cart + \"__status\"  # noqa\n    product = cart + \"__productitem__product\"\n    product_name = product + \"__name\"\n    category = product + \"__category\"\n    category_name = category + \"__name\"\n\n    if by_category:\n        grouping_fields = (category, category_name)\n        order_by = (category, )\n        first_column = \"Category\"\n        group_name = lambda i: \"%s\" % (i[category_name], )  # noqa\n    else:\n        grouping_fields = (product, product_name, category_name)\n        order_by = (category, )\n        first_column = \"Product\"\n        group_name = lambda i: \"%s - %s\" % (i[category_name], i[product_name])  # noqa\n\n    # Group the responses per-field.\n    for field in fields:\n        concrete_field = AttendeeProfile._meta.get_field(field)\n        field_verbose = concrete_field.verbose_name\n\n        # Render the correct values for related fields\n        if field in related_fields:\n            # Get all of the IDs that will appear\n            all_ids = profiles.order_by(field).values(field)\n            all_ids = [i[field] for i in all_ids if i[field] is not None]\n            # Get all of the concrete objects for those IDs\n            model = concrete_field.related_model\n            all_objects = model.objects.filter(id__in=all_ids)\n            all_objects_by_id = dict((i.id, i) for i in all_objects)\n\n            # Define a function to render those IDs.\n            def display_field(value):\n                if value in all_objects_by_id:\n                    return all_objects_by_id[value]\n                else:\n                    return None\n        else:\n            def display_field(value):\n                return value\n\n        status_count = lambda status: Case(When(  # noqa\n                attendee__user__cart__status=status,\n                then=Value(1),\n            ),\n            default=Value(0),\n            output_field=models.fields.IntegerField(),\n        )\n        paid_count = status_count(commerce.Cart.STATUS_PAID)\n        unpaid_count = status_count(commerce.Cart.STATUS_ACTIVE)\n\n        groups = profiles.order_by(\n            *(order_by + (field, ))\n        ).values(\n            *(grouping_fields + (field, ))\n        ).annotate(\n            paid_count=Sum(paid_count),\n            unpaid_count=Sum(unpaid_count),\n        )\n        output.append(ListReport(\n            \"Grouped by %s\" % field_verbose,\n            [first_column, field_verbose, \"paid\", \"unpaid\"],\n            [\n                (\n                    group_name(group),\n                    display_field(group[field]),\n                    group[\"paid_count\"] or 0,\n                    group[\"unpaid_count\"] or 0,\n                )\n                for group in groups\n            ],\n        ))\n\n    # DO the report for individual attendees\n\n    field_names = [\n        AttendeeProfile._meta.get_field(field).verbose_name for field in fields\n    ]\n\n    def display_field(profile, field):\n        field_type = AttendeeProfile._meta.get_field(field)\n        attr = getattr(profile, field)\n\n        if isinstance(field_type, models.ManyToManyField):\n            return [str(i) for i in attr.all()] or \"\"\n        else:\n            return attr\n\n    headings = [\"User ID\", \"Name\", \"Email\", \"Product\", \"Item Status\"]\n    headings.extend(field_names)\n    data = []\n    for item in items:\n        profile = by_user[item.cart.user]\n        line = [\n            item.cart.user.id,\n            getattr(profile, name_field),\n            profile.attendee.user.email,\n            item.product,\n            status_display[item.cart.status],\n        ] + [\n            display_field(profile, field) for field in fields\n        ]\n        data.append(line)\n\n    output.append(AttendeeListReport(\n        \"Attendees by item with profile data\", headings, data,\n        link_view=attendee\n    ))\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nshow registration status for speakers with a given proposal kind.", "response": "def speaker_registrations(request, form):\n    ''' Shows registration status for speakers with a given proposal kind. '''\n\n    kinds = form.cleaned_data[\"kind\"]\n\n    presentations = schedule_models.Presentation.objects.filter(\n        proposal_base__kind__in=kinds,\n    ).exclude(\n        cancelled=True,\n    )\n\n    users = User.objects.filter(\n        Q(speaker_profile__presentations__in=presentations) |\n        Q(speaker_profile__copresentations__in=presentations)\n    )\n\n    paid_carts = commerce.Cart.objects.filter(status=commerce.Cart.STATUS_PAID)\n\n    paid_carts = Case(\n        When(cart__in=paid_carts, then=Value(1)),\n        default=Value(0),\n        output_field=models.IntegerField(),\n    )\n    users = users.annotate(paid_carts=Sum(paid_carts))\n    users = users.order_by(\"paid_carts\")\n\n    return QuerysetReport(\n        \"Speaker Registration Status\",\n        [\"id\", \"speaker_profile__name\", \"email\", \"paid_carts\"],\n        users,\n        link_view=attendee,\n    )\n\n    return []"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef manifest(request, form):\n    '''\n    Produces the registration manifest for people with the given product\n    type.\n    '''\n\n    products = form.cleaned_data[\"product\"]\n    categories = form.cleaned_data[\"category\"]\n\n    line_items = (\n        Q(lineitem__product__in=products) |\n        Q(lineitem__product__category__in=categories)\n    )\n\n    invoices = commerce.Invoice.objects.filter(\n        line_items,\n        status=commerce.Invoice.STATUS_PAID,\n    ).select_related(\n        \"cart\",\n        \"user\",\n        \"user__attendee\",\n        \"user__attendee__attendeeprofilebase\"\n    )\n\n    users = set(i.user for i in invoices)\n\n    carts = commerce.Cart.objects.filter(\n        user__in=users\n    )\n\n    items = commerce.ProductItem.objects.filter(\n        cart__in=carts\n    ).select_related(\n        \"product\",\n        \"product__category\",\n        \"cart\",\n        \"cart__user\",\n        \"cart__user__attendee\",\n        \"cart__user__attendee__attendeeprofilebase\"\n    ).order_by(\"product__category__order\", \"product__order\")\n\n    users = {}\n\n    for item in items:\n        cart = item.cart\n        if cart.user not in users:\n            users[cart.user] = {\"unpaid\": [], \"paid\": [], \"refunded\": []}\n        items = users[cart.user]\n        if cart.status == commerce.Cart.STATUS_ACTIVE:\n            items[\"unpaid\"].append(item)\n        elif cart.status == commerce.Cart.STATUS_PAID:\n            items[\"paid\"].append(item)\n        elif cart.status == commerce.Cart.STATUS_RELEASED:\n            items[\"refunded\"].append(item)\n\n    users_by_name = list(users.keys())\n    users_by_name.sort(key=(\n        lambda i: i.attendee.attendeeprofilebase.attendee_name().lower()\n    ))\n\n    headings = [\"User ID\", \"Name\", \"Paid\", \"Unpaid\", \"Refunded\"]\n\n    def format_items(item_list):\n        strings = [\n            '%d x %s' % (item.quantity, str(item.product))\n            for item in item_list\n        ]\n        return \", \\n\".join(strings)\n\n    output = []\n    for user in users_by_name:\n        items = users[user]\n        output.append([\n            user.id,\n            user.attendee.attendeeprofilebase.attendee_name(),\n            format_items(items[\"paid\"]),\n            format_items(items[\"unpaid\"]),\n            format_items(items[\"refunded\"]),\n        ])\n\n    return ListReport(\"Manifest\", headings, output)", "response": "Generates the registration manifest for people with the given product\n    type."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef missing_categories(context):\n    ''' Adds the categories that the user does not currently have. '''\n    user = user_for_context(context)\n    categories_available = set(CategoryController.available_categories(user))\n    items = ItemController(user).items_pending_or_purchased()\n\n    categories_held = set()\n\n    for product, quantity in items:\n        categories_held.add(product.category)\n\n    return categories_available - categories_held", "response": "Adds the categories that the user does not currently have."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef available_credit(context):\n    ''' Calculates the sum of unclaimed credit from this user's credit notes.\n\n    Returns:\n        Decimal: the sum of the values of unclaimed credit notes for the\n            current user.\n\n    '''\n\n    notes = commerce.CreditNote.unclaimed().filter(\n        invoice__user=user_for_context(context),\n    )\n    ret = notes.values(\"amount\").aggregate(Sum(\"amount\"))[\"amount__sum\"] or 0\n    return 0 - ret", "response": "Calculates the sum of unclaimed credit from this user s credit notes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the total number of items purchased for this user.", "response": "def total_items_purchased(context, category=None):\n    ''' Returns the number of items purchased for this user (sum of quantities).\n\n    The user will be either `context.user`, and `context.request.user` if\n    the former is not defined.\n    '''\n\n    return sum(i.quantity for i in items_purchased(context, category))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning True if the current user s sold out and unregistered products.", "response": "def sold_out_and_unregistered(context):\n    ''' If the current user is unregistered, returns True if there are no\n    products in the TICKET_PRODUCT_CATEGORY that are available to that user.\n\n    If there *are* products available, the return False.\n\n    If the current user *is* registered, then return None (it's not a\n    pertinent question for people who already have a ticket).\n\n    '''\n\n    user = user_for_context(context)\n    if hasattr(user, \"attendee\") and user.attendee.completed_registration:\n        # This user has completed registration, and so we don't need to answer\n        # whether they have sold out yet.\n\n        # TODO: what if a user has got to the review phase?\n        # currently that user will hit the review page, click \"Check out and\n        # pay\", and that will fail. Probably good enough for now.\n\n        return None\n\n    ticket_category = settings.TICKET_PRODUCT_CATEGORY\n    categories = available_categories(context)\n\n    return ticket_category not in [cat.id for cat in categories]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef include_if_exists(parser, token):\n    try:\n        tag_name, template_name = token.split_contents()\n    except ValueError:\n        raise template.TemplateSyntaxError, \\\n            \"%r tag requires a single argument\" % token.contents.split()[0]\n\n    return IncludeNode(template_name)", "response": "Include the current page if it exists."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngoes through the registration process in order, making sure user sees all valid categories. The user must be logged in to see this view. Parameter: page_number: 1) Profile form (and e-mail address?) 2) Ticket type 3) Remaining products 4) Mark registration as complete Returns: render: Renders ``registrasion/guided_registration.html``, with the following data:: { \"current_step\": int(), # The current step in the # registration \"sections\": sections, # A list of # GuidedRegistrationSections \"title\": str(), # The title of the page \"total_steps\": int(), # The total number of steps }", "response": "def guided_registration(request, page_number=None):\n    ''' Goes through the registration process in order, making sure user sees\n    all valid categories.\n\n    The user must be logged in to see this view.\n\n    Parameter:\n        page_number:\n            1) Profile form (and e-mail address?)\n            2) Ticket type\n            3) Remaining products\n            4) Mark registration as complete\n\n    Returns:\n        render: Renders ``registrasion/guided_registration.html``,\n            with the following data::\n\n                {\n                    \"current_step\": int(),  # The current step in the\n                                            # registration\n                    \"sections\": sections,   # A list of\n                                            # GuidedRegistrationSections\n                    \"title\": str(),         # The title of the page\n                    \"total_steps\": int(),   # The total number of steps\n                }\n\n    '''\n\n    PAGE_PROFILE = 1\n    PAGE_TICKET = 2\n    PAGE_PRODUCTS = 3\n    PAGE_PRODUCTS_MAX = 4\n    TOTAL_PAGES = 4\n\n    ticket_category = inventory.Category.objects.get(\n        id=settings.TICKET_PRODUCT_CATEGORY\n    )\n    cart = CartController.for_user(request.user)\n\n    attendee = people.Attendee.get_instance(request.user)\n\n    # This guided registration process is only for people who have\n    # not completed registration (and has confusing behaviour if you go\n    # back to it.)\n    if attendee.completed_registration:\n        return redirect(review)\n\n    # Calculate the current maximum page number for this user.\n    has_profile = hasattr(attendee, \"attendeeprofilebase\")\n    if not has_profile:\n        # If there's no profile, they have to go to the profile page.\n        max_page = PAGE_PROFILE\n        redirect_page = PAGE_PROFILE\n    else:\n        # We have a profile.\n        # Do they have a ticket?\n        products = inventory.Product.objects.filter(\n            productitem__cart=cart.cart\n        )\n        products = products.filter(category=ticket_category)\n\n        if products.count() == 0:\n            # If no ticket, they can only see the profile or ticket page.\n            max_page = PAGE_TICKET\n            redirect_page = PAGE_TICKET\n        else:\n            # If there's a ticket, they should *see* the general products page#\n            # but be able to go to the overflow page if needs be.\n            max_page = PAGE_PRODUCTS_MAX\n            redirect_page = PAGE_PRODUCTS\n\n    if page_number is None or int(page_number) > max_page:\n        return redirect(\"guided_registration\", redirect_page)\n\n    page_number = int(page_number)\n\n    next_step = redirect(\"guided_registration\", page_number + 1)\n\n    with BatchController.batch(request.user):\n\n        # This view doesn't work if the conference has sold out.\n        available = ProductController.available_products(\n            request.user, category=ticket_category\n        )\n        if not available:\n            messages.error(request, \"There are no more tickets available.\")\n            return redirect(\"dashboard\")\n\n        sections = []\n\n        # Build up the list of sections\n        if page_number == PAGE_PROFILE:\n            # Profile bit\n            title = \"Attendee information\"\n            sections = _guided_registration_profile_and_voucher(request)\n        elif page_number == PAGE_TICKET:\n            # Select ticket\n            title = \"Select ticket type\"\n            sections = _guided_registration_products(\n                request, GUIDED_MODE_TICKETS_ONLY\n            )\n        elif page_number == PAGE_PRODUCTS:\n            # Select additional items\n            title = \"Additional items\"\n            sections = _guided_registration_products(\n                request, GUIDED_MODE_ALL_ADDITIONAL\n            )\n        elif page_number == PAGE_PRODUCTS_MAX:\n            # Items enabled by things on page 3 -- only shows things\n            # that have not been marked as complete.\n            title = \"More additional items\"\n            sections = _guided_registration_products(\n                request, GUIDED_MODE_EXCLUDE_COMPLETE\n            )\n\n        if not sections:\n            # We've filled in every category\n            attendee.completed_registration = True\n            attendee.save()\n            return redirect(\"review\")\n\n        if sections and request.method == \"POST\":\n            for section in sections:\n                if section.form.errors:\n                    break\n            else:\n                # We've successfully processed everything\n                return next_step\n\n    data = {\n        \"current_step\": page_number,\n        \"sections\": sections,\n        \"title\": title,\n        \"total_steps\": TOTAL_PAGES,\n    }\n    return render(request, \"registrasion/guided_registration.html\", data)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nview for editing an attendee s profile.", "response": "def edit_profile(request):\n    ''' View for editing an attendee's profile\n\n    The user must be logged in to edit their profile.\n\n    Returns:\n        redirect or render:\n            In the case of a ``POST`` request, it'll redirect to ``dashboard``,\n            or otherwise, it will render ``registrasion/profile_form.html``\n            with data::\n\n                {\n                    \"form\": form,  # Instance of ATTENDEE_PROFILE_FORM.\n                }\n\n    '''\n\n    form, handled = _handle_profile(request, \"profile\")\n\n    if handled and not form.errors:\n        messages.success(\n            request,\n            \"Your attendee profile was updated.\",\n        )\n        return redirect(\"dashboard\")\n\n    data = {\n        \"form\": form,\n    }\n    return render(request, \"registrasion/profile_form.html\", data)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _handle_profile(request, prefix):\n    ''' Returns a profile form instance, and a boolean which is true if the\n    form was handled. '''\n    attendee = people.Attendee.get_instance(request.user)\n\n    try:\n        profile = attendee.attendeeprofilebase\n        profile = people.AttendeeProfileBase.objects.get_subclass(\n            pk=profile.id,\n        )\n    except ObjectDoesNotExist:\n        profile = None\n\n    # Load a pre-entered name from the speaker's profile,\n    # if they have one.\n    try:\n        speaker_profile = request.user.speaker_profile\n        speaker_name = speaker_profile.name\n    except ObjectDoesNotExist:\n        speaker_name = None\n\n    name_field = ProfileForm.Meta.model.name_field()\n    initial = {}\n    if profile is None and name_field is not None:\n        initial[name_field] = speaker_name\n\n    form = ProfileForm(\n        request.POST or None,\n        initial=initial,\n        instance=profile,\n        prefix=prefix\n    )\n\n    handled = True if request.POST else False\n\n    if request.POST and form.is_valid():\n        form.instance.attendee = attendee\n        form.save()\n\n    return form, handled", "response": "Returns a profile form instance and a boolean which is true if the profile form was handled."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef product_category(request, category_id):\n    ''' Form for selecting products from an individual product category.\n\n    Arguments:\n        category_id (castable to int): The id of the category to display.\n\n    Returns:\n        redirect or render:\n            If the form has been sucessfully submitted, redirect to\n            ``dashboard``. Otherwise, render\n            ``registrasion/product_category.html`` with data::\n\n                {\n                    \"category\": category,         # An inventory.Category for\n                                                  # category_id\n                    \"discounts\": discounts,       # A list of\n                                                  # DiscountAndQuantity\n                    \"form\": products_form,        # A form for selecting\n                                                  # products\n                    \"voucher_form\": voucher_form, # A form for entering a\n                                                  # voucher code\n                }\n\n    '''\n\n    PRODUCTS_FORM_PREFIX = \"products\"\n    VOUCHERS_FORM_PREFIX = \"vouchers\"\n\n    # Handle the voucher form *before* listing products.\n    # Products can change as vouchers are entered.\n    v = _handle_voucher(request, VOUCHERS_FORM_PREFIX)\n    voucher_form, voucher_handled = v\n\n    category_id = int(category_id)  # Routing is [0-9]+\n    category = inventory.Category.objects.get(pk=category_id)\n\n    with BatchController.batch(request.user):\n        products = ProductController.available_products(\n            request.user,\n            category=category,\n        )\n\n        if not products:\n            messages.warning(\n                request,\n                (\n                    \"There are no products available from category: \" +\n                    category.name\n                ),\n            )\n            return redirect(\"dashboard\")\n\n        p = _handle_products(request, category, products, PRODUCTS_FORM_PREFIX)\n        products_form, discounts, products_handled = p\n\n    if request.POST and not voucher_handled and not products_form.errors:\n        # Only return to the dashboard if we didn't add a voucher code\n        # and if there's no errors in the products form\n        if products_form.has_changed():\n            messages.success(\n                request,\n                \"Your reservations have been updated.\",\n            )\n        return redirect(review)\n\n    data = {\n        \"category\": category,\n        \"discounts\": discounts,\n        \"form\": products_form,\n        \"voucher_form\": voucher_form,\n    }\n\n    return render(request, \"registrasion/product_category.html\", data)", "response": "Handles the products and vouchers from an individual product category."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef voucher_code(request):\n    ''' A view *just* for entering a voucher form. '''\n\n    VOUCHERS_FORM_PREFIX = \"vouchers\"\n\n    # Handle the voucher form *before* listing products.\n    # Products can change as vouchers are entered.\n    v = _handle_voucher(request, VOUCHERS_FORM_PREFIX)\n    voucher_form, voucher_handled = v\n\n    if voucher_handled:\n        messages.success(request, \"Your voucher code was accepted.\")\n        return redirect(\"dashboard\")\n\n    data = {\n        \"voucher_form\": voucher_form,\n    }\n\n    return render(request, \"registrasion/voucher_code.html\", data)", "response": "A view just for entering a voucher form."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nhandle a products list form in the given request. Returns the products form instance the discounts applicable to this form and whether the contents were handled.", "response": "def _handle_products(request, category, products, prefix):\n    ''' Handles a products list form in the given request. Returns the\n    form instance, the discounts applicable to this form, and whether the\n    contents were handled. '''\n\n    current_cart = CartController.for_user(request.user)\n\n    ProductsForm = forms.ProductsForm(category, products)\n\n    # Create initial data for each of products in category\n    items = commerce.ProductItem.objects.filter(\n        product__in=products,\n        cart=current_cart.cart,\n    ).select_related(\"product\")\n    quantities = []\n    seen = set()\n\n    for item in items:\n        quantities.append((item.product, item.quantity))\n        seen.add(item.product)\n\n    zeros = set(products) - seen\n    for product in zeros:\n        quantities.append((product, 0))\n\n    products_form = ProductsForm(\n        request.POST or None,\n        product_quantities=quantities,\n        prefix=prefix,\n    )\n\n    if request.method == \"POST\" and products_form.is_valid():\n        if products_form.has_changed():\n            _set_quantities_from_products_form(products_form, current_cart)\n\n        # If category is required, the user must have at least one\n        # in an active+valid cart\n        if category.required:\n            carts = commerce.Cart.objects.filter(user=request.user)\n            items = commerce.ProductItem.objects.filter(\n                product__category=category,\n                cart=carts,\n            )\n            if len(items) == 0:\n                products_form.add_error(\n                    None,\n                    \"You must have at least one item from this category\",\n                )\n    handled = False if products_form.errors else True\n\n    # Making this a function to lazily evaluate when it's displayed\n    # in templates.\n\n    discounts = util.lazy(\n        DiscountController.available_discounts,\n        request.user,\n        [],\n        products,\n    )\n\n    return products_form, discounts, handled"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nhandles a voucher form in the given request. Returns the voucher form instance and whether the voucher code was handled.", "response": "def _handle_voucher(request, prefix):\n    ''' Handles a voucher form in the given request. Returns the voucher\n    form instance, and whether the voucher code was handled. '''\n\n    voucher_form = forms.VoucherForm(request.POST or None, prefix=prefix)\n    current_cart = CartController.for_user(request.user)\n\n    if (voucher_form.is_valid() and\n            voucher_form.cleaned_data[\"voucher\"].strip()):\n\n        voucher = voucher_form.cleaned_data[\"voucher\"]\n        voucher = inventory.Voucher.normalise_code(voucher)\n\n        if len(current_cart.cart.vouchers.filter(code=voucher)) > 0:\n            # This voucher has already been applied to this cart.\n            # Do not apply code\n            handled = False\n        else:\n            try:\n                current_cart.apply_voucher(voucher)\n            except Exception as e:\n                voucher_form.add_error(\"voucher\", e)\n            handled = True\n    else:\n        handled = False\n\n    return (voucher_form, handled)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nruns the checkout process for the current cart.", "response": "def checkout(request, user_id=None):\n    ''' Runs the checkout process for the current cart.\n\n    If the query string contains ``fix_errors=true``, Registrasion will attempt\n    to fix errors preventing the system from checking out, including by\n    cancelling expired discounts and vouchers, and removing any unavailable\n    products.\n\n    Arguments:\n        user_id (castable to int):\n            If the requesting user is staff, then the user ID can be used to\n            run checkout for another user.\n    Returns:\n        render or redirect:\n            If the invoice is generated successfully, or there's already a\n            valid invoice for the current cart, redirect to ``invoice``.\n            If there are errors when generating the invoice, render\n            ``registrasion/checkout_errors.html`` with the following data::\n\n                {\n                    \"error_list\", [str, ...]  # The errors to display.\n                }\n\n    '''\n\n    if user_id is not None:\n        if request.user.is_staff:\n            user = User.objects.get(id=int(user_id))\n        else:\n            raise Http404()\n    else:\n        user = request.user\n\n    current_cart = CartController.for_user(user)\n\n    if \"fix_errors\" in request.GET and request.GET[\"fix_errors\"] == \"true\":\n        current_cart.fix_simple_errors()\n\n    try:\n        current_invoice = InvoiceController.for_cart(current_cart.cart)\n    except ValidationError as ve:\n        return _checkout_errors(request, ve)\n\n    return redirect(\"invoice\", current_invoice.invoice.id)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef invoice_access(request, access_code):\n    ''' Redirects to an invoice for the attendee that matches the given access\n    code, if any.\n\n    If the attendee has multiple invoices, we use the following tie-break:\n\n    - If there's an unpaid invoice, show that, otherwise\n    - If there's a paid invoice, show the most recent one, otherwise\n    - Show the most recent invoid of all\n\n    Arguments:\n\n        access_code (castable to int): The access code for the user whose\n            invoice you want to see.\n\n    Returns:\n        redirect:\n            Redirect to the selected invoice for that user.\n\n    Raises:\n        Http404: If the user has no invoices.\n    '''\n\n    invoices = commerce.Invoice.objects.filter(\n        user__attendee__access_code=access_code,\n    ).order_by(\"-issue_time\")\n\n    if not invoices:\n        raise Http404()\n\n    unpaid = invoices.filter(status=commerce.Invoice.STATUS_UNPAID)\n    paid = invoices.filter(status=commerce.Invoice.STATUS_PAID)\n\n    if unpaid:\n        invoice = unpaid[0]  # (should only be 1 unpaid invoice?)\n    elif paid:\n        invoice = paid[0]  # Most recent paid invoice\n    else:\n        invoice = invoices[0]  # Most recent of any invoices\n\n    return redirect(\"invoice\", invoice.id, access_code)", "response": "Redirects to an invoice for the user whose invoice is available for the given access code."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndisplays an invoice. This view is not authenticated, but it will only allow access to either: the user the invoice belongs to; staff; or a request made with the correct access code. Arguments: invoice_id (castable to int): The invoice_id for the invoice you want to view. access_code (Optional[str]): The access code for the user who owns this invoice. Returns: render: Renders ``registrasion/invoice.html``, with the following data:: { \"invoice\": models.commerce.Invoice(), } Raises: Http404: if the current user cannot view this invoice and the correct access_code is not provided.", "response": "def invoice(request, invoice_id, access_code=None):\n    ''' Displays an invoice.\n\n    This view is not authenticated, but it will only allow access to either:\n    the user the invoice belongs to; staff; or a request made with the correct\n    access code.\n\n    Arguments:\n\n        invoice_id (castable to int): The invoice_id for the invoice you want\n            to view.\n\n        access_code (Optional[str]): The access code for the user who owns\n            this invoice.\n\n    Returns:\n        render:\n            Renders ``registrasion/invoice.html``, with the following\n            data::\n\n                {\n                    \"invoice\": models.commerce.Invoice(),\n                }\n\n    Raises:\n        Http404: if the current user cannot view this invoice and the correct\n            access_code is not provided.\n\n    '''\n\n    current_invoice = InvoiceController.for_id_or_404(invoice_id)\n\n    if not current_invoice.can_view(\n            user=request.user,\n            access_code=access_code,\n            ):\n        raise Http404()\n\n    data = {\n        \"invoice\": current_invoice.invoice,\n    }\n\n    return render(request, \"registrasion/invoice.html\", data)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nallow staff to make manual payments or refunds on an invoice.", "response": "def manual_payment(request, invoice_id):\n    ''' Allows staff to make manual payments or refunds on an invoice.\n\n    This form requires a login, and the logged in user needs to be staff.\n\n    Arguments:\n        invoice_id (castable to int): The invoice ID to be paid\n\n    Returns:\n        render:\n            Renders ``registrasion/manual_payment.html`` with the following\n            data::\n\n                {\n                    \"invoice\": models.commerce.Invoice(),\n                    \"form\": form,   # A form that saves a ``ManualPayment``\n                                    # object.\n                }\n\n    '''\n\n    FORM_PREFIX = \"manual_payment\"\n\n    current_invoice = InvoiceController.for_id_or_404(invoice_id)\n\n    form = forms.ManualPaymentForm(\n        request.POST or None,\n        prefix=FORM_PREFIX,\n    )\n\n    if request.POST and form.is_valid():\n        form.instance.invoice = current_invoice.invoice\n        form.instance.entered_by = request.user\n        form.save()\n        current_invoice.update_status()\n        form = forms.ManualPaymentForm(prefix=FORM_PREFIX)\n\n    data = {\n        \"invoice\": current_invoice.invoice,\n        \"form\": form,\n    }\n\n    return render(request, \"registrasion/manual_payment.html\", data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef refund(request, invoice_id):\n    ''' Marks an invoice as refunded and requests a credit note for the\n    full amount paid against the invoice.\n\n    This view requires a login, and the logged in user must be staff.\n\n    Arguments:\n        invoice_id (castable to int): The ID of the invoice to refund.\n\n    Returns:\n        redirect:\n            Redirects to ``invoice``.\n\n    '''\n\n    current_invoice = InvoiceController.for_id_or_404(invoice_id)\n\n    try:\n        current_invoice.refund()\n        messages.success(request, \"This invoice has been refunded.\")\n    except ValidationError as ve:\n        messages.error(request, ve)\n\n    return redirect(\"invoice\", invoice_id)", "response": "Mark an invoice as refunded and requests a credit note for the invoice."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef credit_note(request, note_id, access_code=None):\n    ''' Displays a credit note.\n\n    If ``request`` is a ``POST`` request, forms for applying or refunding\n    a credit note will be processed.\n\n    This view requires a login, and the logged in user must be staff.\n\n    Arguments:\n        note_id (castable to int): The ID of the credit note to view.\n\n    Returns:\n        render or redirect:\n            If the \"apply to invoice\" form is correctly processed, redirect to\n            that invoice, otherwise, render ``registration/credit_note.html``\n            with the following data::\n\n                {\n                    \"credit_note\": models.commerce.CreditNote(),\n                    \"apply_form\": form,  # A form for applying credit note\n                                         # to an invoice.\n                    \"refund_form\": form, # A form for applying a *manual*\n                                         # refund of the credit note.\n                    \"cancellation_fee_form\" : form, # A form for generating an\n                                                    # invoice with a\n                                                    # cancellation fee\n                }\n\n    '''\n\n    note_id = int(note_id)\n    current_note = CreditNoteController.for_id_or_404(note_id)\n\n    apply_form = forms.ApplyCreditNoteForm(\n        current_note.credit_note.invoice.user,\n        request.POST or None,\n        prefix=\"apply_note\"\n    )\n\n    refund_form = forms.ManualCreditNoteRefundForm(\n        request.POST or None,\n        prefix=\"refund_note\"\n    )\n\n    cancellation_fee_form = forms.CancellationFeeForm(\n        request.POST or None,\n        prefix=\"cancellation_fee\"\n    )\n\n    if request.POST and apply_form.is_valid():\n        inv_id = apply_form.cleaned_data[\"invoice\"]\n        invoice = commerce.Invoice.objects.get(pk=inv_id)\n        current_note.apply_to_invoice(invoice)\n        messages.success(\n            request,\n            \"Applied credit note %d to invoice.\" % note_id,\n        )\n        return redirect(\"invoice\", invoice.id)\n\n    elif request.POST and refund_form.is_valid():\n        refund_form.instance.entered_by = request.user\n        refund_form.instance.parent = current_note.credit_note\n        refund_form.save()\n        messages.success(\n            request,\n            \"Applied manual refund to credit note.\"\n        )\n        refund_form = forms.ManualCreditNoteRefundForm(\n            prefix=\"refund_note\",\n        )\n\n    elif request.POST and cancellation_fee_form.is_valid():\n        percentage = cancellation_fee_form.cleaned_data[\"percentage\"]\n        invoice = current_note.cancellation_fee(percentage)\n        messages.success(\n            request,\n            \"Generated cancellation fee for credit note %d.\" % note_id,\n        )\n        return redirect(\"invoice\", invoice.invoice.id)\n\n    data = {\n        \"credit_note\": current_note.credit_note,\n        \"apply_form\": apply_form,\n        \"refund_form\": refund_form,\n        \"cancellation_fee_form\": cancellation_fee_form,\n    }\n\n    return render(request, \"registrasion/credit_note.html\", data)", "response": "Displays a credit note."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nallows staff to amend a user s current registration cart and etc etc.", "response": "def amend_registration(request, user_id):\n    ''' Allows staff to amend a user's current registration cart, and etc etc.\n    '''\n\n    user = User.objects.get(id=int(user_id))\n    current_cart = CartController.for_user(user)\n\n    items = commerce.ProductItem.objects.filter(\n        cart=current_cart.cart,\n    ).select_related(\"product\")\n    initial = [{\"product\": i.product, \"quantity\": i.quantity} for i in items]\n\n    StaffProductsFormSet = forms.staff_products_formset_factory(user)\n    formset = StaffProductsFormSet(\n        request.POST or None,\n        initial=initial,\n        prefix=\"products\",\n    )\n\n    for item, form in zip(items, formset):\n        queryset = inventory.Product.objects.filter(id=item.product.id)\n        form.fields[\"product\"].queryset = queryset\n\n    voucher_form = forms.VoucherForm(\n        request.POST or None,\n        prefix=\"voucher\",\n    )\n\n    if request.POST and formset.is_valid():\n\n        pq = [\n            (f.cleaned_data[\"product\"], f.cleaned_data[\"quantity\"])\n            for f in formset\n            if \"product\" in f.cleaned_data and\n            f.cleaned_data[\"product\"] is not None\n        ]\n\n        try:\n            current_cart.set_quantities(pq)\n            return redirect(amend_registration, user_id)\n        except ValidationError as ve:\n            for ve_field in ve.error_list:\n                product, message = ve_field.message\n                for form in formset:\n                    if \"product\" not in form.cleaned_data:\n                        # This is the empty form.\n                        continue\n                    if form.cleaned_data[\"product\"] == product:\n                        form.add_error(\"quantity\", message)\n\n    if request.POST and voucher_form.has_changed() and voucher_form.is_valid():\n        try:\n            current_cart.apply_voucher(voucher_form.cleaned_data[\"voucher\"])\n            return redirect(amend_registration, user_id)\n        except ValidationError as ve:\n            voucher_form.add_error(None, ve)\n\n    ic = ItemController(user)\n    data = {\n        \"user\": user,\n        \"paid\": ic.items_purchased(),\n        \"cancelled\": ic.items_released(),\n        \"form\": formset,\n        \"voucher_form\": voucher_form,\n    }\n\n    return render(request, \"registrasion/amend_registration.html\", data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef extend_reservation(request, user_id, days=7):\n    ''' Allows staff to extend the reservation on a given user's cart.\n    '''\n\n    user = User.objects.get(id=int(user_id))\n    cart = CartController.for_user(user)\n    cart.extend_reservation(datetime.timedelta(days=days))\n\n    return redirect(request.META[\"HTTP_REFERER\"])", "response": "Allows staff to extend the reservation on a given user s cart."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef invoice_mailout(request):\n    ''' Allows staff to send emails to users based on their invoice status. '''\n\n    category = request.GET.getlist(\"category\", [])\n    product = request.GET.getlist(\"product\", [])\n    status = request.GET.get(\"status\")\n\n    form = forms.InvoiceEmailForm(\n        request.POST or None,\n        category=category,\n        product=product,\n        status=status,\n    )\n\n    emails = []\n\n    if form.is_valid():\n        emails = []\n        for invoice in form.cleaned_data[\"invoice\"]:\n            # datatuple = (subject, message, from_email, recipient_list)\n            from_email = form.cleaned_data[\"from_email\"]\n            subject = form.cleaned_data[\"subject\"]\n            body = Template(form.cleaned_data[\"body\"]).render(\n                Context({\n                    \"invoice\": invoice,\n                    \"user\": invoice.user,\n                })\n            )\n            recipient_list = [invoice.user.email]\n            emails.append(Email(subject, body, from_email, recipient_list))\n\n        if form.cleaned_data[\"action\"] == forms.InvoiceEmailForm.ACTION_SEND:\n            # Send e-mails *ONLY* if we're sending.\n            send_mass_mail(emails)\n            messages.info(request, \"The e-mails have been sent.\")\n\n    data = {\n        \"form\": form,\n        \"emails\": emails,\n    }\n\n    return render(request, \"registrasion/invoice_mailout.html\", data)", "response": "Allows staff to send emails to users based on their invoice status."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrender a single user s badge.", "response": "def badge(request, user_id):\n    ''' Renders a single user's badge (SVG). '''\n\n    user_id = int(user_id)\n    user = User.objects.get(pk=user_id)\n\n    rendered = render_badge(user)\n    response = HttpResponse(rendered)\n\n    response[\"Content-Type\"] = \"image/svg+xml\"\n    response[\"Content-Disposition\"] = 'inline; filename=\"badge.svg\"'\n    return response"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef badges(request):\n    ''' Either displays a form containing a list of users with badges to\n    render, or returns a .zip file containing their badges. '''\n\n    category = request.GET.getlist(\"category\", [])\n    product = request.GET.getlist(\"product\", [])\n    status = request.GET.get(\"status\")\n\n    form = forms.InvoicesWithProductAndStatusForm(\n        request.POST or None,\n        category=category,\n        product=product,\n        status=status,\n    )\n\n    if form.is_valid():\n        response = HttpResponse()\n        response[\"Content-Type\"] = \"application.zip\"\n        response[\"Content-Disposition\"] = 'attachment; filename=\"badges.zip\"'\n\n        z = zipfile.ZipFile(response, \"w\")\n\n        for invoice in form.cleaned_data[\"invoice\"]:\n            user = invoice.user\n            badge = render_badge(user)\n            z.writestr(\"badge_%d.svg\" % user.id, badge.encode(\"utf-8\"))\n\n        return response\n\n    data = {\n        \"form\": form,\n    }\n\n    return render(request, \"registrasion/badges.html\", data)", "response": "Returns a. zip file containing the badges to\n    render."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef render_badge(user):\n    ''' Renders a single user's badge. '''\n\n    data = {\n        \"user\": user,\n    }\n\n    t = loader.get_template('registrasion/badge.svg')\n    return t.render(data)", "response": "Renders a single user s badge."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning all discounts available to this user for the given categories and products. The discounts also list the available quantity for this user.", "response": "def available_discounts(cls, user, categories, products):\n        ''' Returns all discounts available to this user for the given\n        categories and products. The discounts also list the available quantity\n        for this user, not including products that are pending purchase. '''\n\n        filtered_clauses = cls._filtered_clauses(user)\n\n        # clauses that match provided categories\n        categories = set(categories)\n        # clauses that match provided products\n        products = set(products)\n        # clauses that match categories for provided products\n        product_categories = set(product.category for product in products)\n        # (Not relevant: clauses that match products in provided categories)\n        all_categories = categories | product_categories\n\n        filtered_clauses = (\n            clause for clause in filtered_clauses\n            if hasattr(clause, 'product') and clause.product in products or\n            hasattr(clause, 'category') and clause.category in all_categories\n        )\n\n        discounts = []\n\n        # Markers so that we don't need to evaluate given conditions\n        # more than once\n        accepted_discounts = set()\n        failed_discounts = set()\n\n        for clause in filtered_clauses:\n            discount = clause.discount\n            cond = ConditionController.for_condition(discount)\n\n            past_use_count = clause.past_use_count\n            if past_use_count >= clause.quantity:\n                # This clause has exceeded its use count\n                pass\n            elif discount not in failed_discounts:\n                # This clause is still available\n                is_accepted = discount in accepted_discounts\n                if is_accepted or cond.is_met(user, filtered=True):\n                    # This clause is valid for this user\n                    discounts.append(DiscountAndQuantity(\n                        discount=discount,\n                        clause=clause,\n                        quantity=clause.quantity - past_use_count,\n                    ))\n                    accepted_discounts.add(discount)\n                else:\n                    # This clause is not valid for this user\n                    failed_discounts.add(discount)\n        return discounts"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _annotate_with_past_uses(cls, queryset, user):\n        ''' Annotates the queryset with a usage count for that discount claus\n        by the given user. '''\n\n        if queryset.model == conditions.DiscountForCategory:\n            matches = (\n                Q(category=F('discount__discountitem__product__category'))\n            )\n        elif queryset.model == conditions.DiscountForProduct:\n            matches = (\n                Q(product=F('discount__discountitem__product'))\n            )\n\n        in_carts = (\n            Q(discount__discountitem__cart__user=user) &\n            Q(discount__discountitem__cart__status=commerce.Cart.STATUS_PAID)\n        )\n\n        past_use_quantity = When(\n            in_carts & matches,\n            then=\"discount__discountitem__quantity\",\n        )\n\n        past_use_quantity_or_zero = Case(\n            past_use_quantity,\n            default=Value(0),\n        )\n\n        queryset = queryset.annotate(\n            past_use_count=Sum(past_use_quantity_or_zero)\n        )\n        return queryset", "response": "Annotates the queryset with a usage count for that discount claus\n        by the given user."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef available_products(cls, user, category=None, products=None):\n        ''' Returns a list of all of the products that are available per\n        flag conditions from the given categories. '''\n        if category is None and products is None:\n            raise ValueError(\"You must provide products or a category\")\n\n        if category is not None:\n            all_products = inventory.Product.objects.filter(category=category)\n            all_products = all_products.select_related(\"category\")\n        else:\n            all_products = []\n\n        if products is not None:\n            all_products = set(itertools.chain(all_products, products))\n\n        category_remainders = CategoryController.user_remainders(user)\n        product_remainders = ProductController.user_remainders(user)\n\n        passed_limits = set(\n            product\n            for product in all_products\n            if category_remainders[product.category.id] > 0\n            if product_remainders[product.id] > 0\n        )\n\n        failed_and_messages = FlagController.test_flags(\n            user, products=passed_limits\n        )\n        failed_conditions = set(i[0] for i in failed_and_messages)\n\n        out = list(passed_limits - failed_conditions)\n        out.sort(key=lambda product: product.order)\n\n        return out", "response": "Returns a list of all of the products that are available per\n        flag conditions from the given categories."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef generate_from_invoice(cls, invoice, value):\n        ''' Generates a credit note of the specified value and pays it against\n        the given invoice. You need to call InvoiceController.update_status()\n        to set the status correctly, if appropriate. '''\n\n        credit_note = commerce.CreditNote.objects.create(\n            invoice=invoice,\n            amount=0-value,  # Credit notes start off as a payment against inv.\n            reference=\"ONE MOMENT\",\n        )\n        credit_note.reference = \"Generated credit note %d\" % credit_note.id\n        credit_note.save()\n\n        return cls(credit_note)", "response": "Generates a credit note of the specified value and pays it against the invoice."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\napplying the total value of this credit note to the invoice.", "response": "def apply_to_invoice(self, invoice):\n        ''' Applies the total value of this credit note to the specified\n        invoice. If this credit note overpays the invoice, a new credit note\n        containing the residual value will be created.\n\n        Raises ValidationError if the given invoice is not allowed to be\n        paid.\n        '''\n\n        # Local import to fix import cycles. Can we do better?\n        from .invoice import InvoiceController\n        inv = InvoiceController(invoice)\n        inv.validate_allowed_to_pay()\n\n        # Apply payment to invoice\n        commerce.CreditNoteApplication.objects.create(\n            parent=self.credit_note,\n            invoice=invoice,\n            amount=self.credit_note.value,\n            reference=\"Applied credit note #%d\" % self.credit_note.id,\n        )\n\n        inv.update_status()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates an invoice with a cancellation fee and applies the credit to the invoice.", "response": "def cancellation_fee(self, percentage):\n        ''' Generates an invoice with a cancellation fee, and applies\n        credit to the invoice.\n\n        percentage (Decimal): The percentage of the credit note to turn into\n        a cancellation fee. Must be 0 <= percentage <= 100.\n        '''\n\n        # Local import to fix import cycles. Can we do better?\n        from .invoice import InvoiceController\n\n        assert(percentage >= 0 and percentage <= 100)\n\n        cancellation_fee = self.credit_note.value * percentage / 100\n        due = datetime.timedelta(days=1)\n        item = [(\"Cancellation fee\", cancellation_fee)]\n        invoice = InvoiceController.manual_invoice(\n            self.credit_note.invoice.user, due, item\n        )\n\n        if not invoice.is_paid:\n            self.apply_to_invoice(invoice)\n\n        return InvoiceController(invoice)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef generate_access_code():\n    ''' Generates an access code for users' payments as well as their\n    fulfilment code for check-in.\n    The access code will 4 characters long, which allows for 1,500,625\n    unique codes, which really should be enough for anyone. '''\n\n    length = 6\n    # all upper-case letters + digits 1-9 (no 0 vs O confusion)\n    chars = string.uppercase + string.digits[1:]\n    # 6 chars => 35 ** 6 = 1838265625 (should be enough for anyone)\n    return get_random_string(length=length, allowed_chars=chars)", "response": "Generates an access code for users and payments as well as their\n    fulfilment code for check - in."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef lazy(function, *args, **kwargs):\n    ''' Produces a callable so that functions can be lazily evaluated in\n    templates.\n\n    Arguments:\n\n        function (callable): The function to call at evaluation time.\n\n        args: Positional arguments, passed directly to ``function``.\n\n        kwargs: Keyword arguments, passed directly to ``function``.\n\n    Return:\n\n        callable: A callable that will evaluate a call to ``function`` with\n            the specified arguments.\n\n    '''\n\n    NOT_EVALUATED = object()\n    retval = [NOT_EVALUATED]\n\n    def evaluate():\n        if retval[0] is NOT_EVALUATED:\n            retval[0] = function(*args, **kwargs)\n        return retval[0]\n\n    return evaluate", "response": "Returns a callable that can be lazily evaluated in\n            templates."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_object_from_name(name):\n    ''' Returns the named object.\n\n    Arguments:\n        name (str): A string of form `package.subpackage.etc.module.property`.\n            This function will import `package.subpackage.etc.module` and\n            return `property` from that module.\n\n    '''\n\n    dot = name.rindex(\".\")\n    mod_name, property_name = name[:dot], name[dot + 1:]\n    __import__(mod_name)\n    return getattr(sys.modules[mod_name], property_name)", "response": "Returns the named object."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns an invoice object for a given cart at its current revision.", "response": "def for_cart(cls, cart):\n        ''' Returns an invoice object for a given cart at its current revision.\n        If such an invoice does not exist, the cart is validated, and if valid,\n        an invoice is generated.'''\n\n        cart.refresh_from_db()\n        try:\n            invoice = commerce.Invoice.objects.exclude(\n                status=commerce.Invoice.STATUS_VOID,\n            ).get(\n                cart=cart,\n                cart_revision=cart.revision,\n            )\n        except ObjectDoesNotExist:\n            cart_controller = CartController(cart)\n            cart_controller.validate_cart()  # Raises ValidationError on fail.\n\n            cls.update_old_invoices(cart)\n            invoice = cls._generate_from_cart(cart)\n\n        return cls(invoice)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef manual_invoice(cls, user, due_delta, description_price_pairs):\n        ''' Generates an invoice for arbitrary items, not held in a user's\n        cart.\n\n        Arguments:\n            user (User): The user the invoice is being generated for.\n            due_delta (datetime.timedelta): The length until the invoice is\n                due.\n            description_price_pairs ([(str, long or Decimal), ...]): A list of\n                pairs. Each pair consists of the description for each line item\n                and the price for that line item. The price will be cast to\n                Decimal.\n\n        Returns:\n            an Invoice.\n        '''\n\n        line_items = []\n        for description, price in description_price_pairs:\n            line_item = commerce.LineItem(\n                description=description,\n                quantity=1,\n                price=Decimal(price),\n                product=None,\n            )\n            line_items.append(line_item)\n\n        min_due_time = timezone.now() + due_delta\n        return cls._generate(user, None, min_due_time, line_items)", "response": "Generates an invoice for arbitrary items not held in a user s cart."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate an invoice for the given cart.", "response": "def _generate_from_cart(cls, cart):\n        ''' Generates an invoice for the given cart. '''\n\n        cart.refresh_from_db()\n\n        # Generate the line items from the cart.\n\n        product_items = commerce.ProductItem.objects.filter(cart=cart)\n        product_items = product_items.select_related(\n            \"product\",\n            \"product__category\",\n        )\n        product_items = product_items.order_by(\n            \"product__category__order\", \"product__order\"\n        )\n\n        if len(product_items) == 0:\n            raise ValidationError(\"Your cart is empty.\")\n\n        discount_items = commerce.DiscountItem.objects.filter(cart=cart)\n        discount_items = discount_items.select_related(\n            \"discount\",\n            \"product\",\n            \"product__category\",\n        )\n\n        def format_product(product):\n            return \"%s - %s\" % (product.category.name, product.name)\n\n        def format_discount(discount, product):\n            description = discount.description\n            return \"%s (%s)\" % (description, format_product(product))\n\n        line_items = []\n\n        for item in product_items:\n            product = item.product\n            line_item = commerce.LineItem(\n                description=format_product(product),\n                quantity=item.quantity,\n                price=product.price,\n                product=product,\n            )\n            line_items.append(line_item)\n        for item in discount_items:\n            line_item = commerce.LineItem(\n                description=format_discount(item.discount, item.product),\n                quantity=item.quantity,\n                price=cls.resolve_discount_value(item) * -1,\n                product=item.product,\n            )\n            line_items.append(line_item)\n\n        # Generate the invoice\n\n        min_due_time = cart.reservation_duration + cart.time_last_updated\n\n        return cls._generate(cart.user, cart, min_due_time, line_items)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\napply the user s credit notes to the given invoice on creation.", "response": "def _apply_credit_notes(cls, invoice):\n        ''' Applies the user's credit notes to the given invoice on creation.\n        '''\n\n        # We only automatically apply credit notes if this is the *only*\n        # unpaid invoice for this user.\n        invoices = commerce.Invoice.objects.filter(\n            user=invoice.user,\n            status=commerce.Invoice.STATUS_UNPAID,\n        )\n        if invoices.count() > 1:\n            return\n\n        notes = commerce.CreditNote.unclaimed().filter(\n            invoice__user=invoice.user\n        )\n        for note in notes:\n            try:\n                CreditNoteController(note).apply_to_invoice(invoice)\n            except ValidationError:\n                # ValidationError will get raised once we're overpaying.\n                break\n\n        invoice.refresh_from_db()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns true if the accessing user is allowed to view this invoice and the given access code.", "response": "def can_view(self, user=None, access_code=None):\n        ''' Returns true if the accessing user is allowed to view this invoice,\n        or if the given access code matches this invoice's user's access code.\n        '''\n\n        if user == self.invoice.user:\n            return True\n\n        if user.is_staff:\n            return True\n\n        if self.invoice.user.attendee.access_code == access_code:\n            return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _refresh(self):\n        ''' Refreshes the underlying invoice and cart objects. '''\n        self.invoice.refresh_from_db()\n        if self.invoice.cart:\n            self.invoice.cart.refresh_from_db()", "response": "Refreshes the underlying invoice and cart objects."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npassing cleanly if we re allowed to pay otherwise raise a ValidationError.", "response": "def validate_allowed_to_pay(self):\n        ''' Passes cleanly if we're allowed to pay, otherwise raise\n        a ValidationError. '''\n\n        self._refresh()\n\n        if not self.invoice.is_unpaid:\n            raise ValidationError(\"You can only pay for unpaid invoices.\")\n\n        if not self.invoice.cart:\n            return\n\n        if not self._invoice_matches_cart():\n            raise ValidationError(\"The registration has been amended since \"\n                                  \"generating this invoice.\")\n\n        CartController(self.invoice.cart).validate_cart()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_status(self):\n        ''' Updates the status of this invoice based upon the total\n        payments.'''\n\n        old_status = self.invoice.status\n        total_paid = self.invoice.total_payments()\n        num_payments = commerce.PaymentBase.objects.filter(\n            invoice=self.invoice,\n        ).count()\n        remainder = self.invoice.value - total_paid\n\n        if old_status == commerce.Invoice.STATUS_UNPAID:\n            # Invoice had an amount owing\n            if remainder <= 0:\n                # Invoice no longer has amount owing\n                self._mark_paid()\n\n            elif total_paid == 0 and num_payments > 0:\n                # Invoice has multiple payments totalling zero\n                self._mark_void()\n        elif old_status == commerce.Invoice.STATUS_PAID:\n            if remainder > 0:\n                # Invoice went from having a remainder of zero or less\n                # to having a positive remainder -- must be a refund\n                self._mark_refunded()\n        elif old_status == commerce.Invoice.STATUS_REFUNDED:\n            # Should not ever change from here\n            pass\n        elif old_status == commerce.Invoice.STATUS_VOID:\n            # Should not ever change from here\n            pass\n\n        # Generate credit notes from residual payments\n        residual = 0\n        if self.invoice.is_paid:\n            if remainder < 0:\n                residual = 0 - remainder\n        elif self.invoice.is_void or self.invoice.is_refunded:\n            residual = total_paid\n\n        if residual != 0:\n            CreditNoteController.generate_from_invoice(self.invoice, residual)\n\n        self.email_on_invoice_change(\n            self.invoice,\n            old_status,\n            self.invoice.status,\n        )", "response": "Updates the status of this invoice based upon the total_payments payments."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _mark_paid(self):\n        ''' Marks the invoice as paid, and updates the attached cart if\n        necessary. '''\n        cart = self.invoice.cart\n        if cart:\n            cart.status = commerce.Cart.STATUS_PAID\n            cart.save()\n        self.invoice.status = commerce.Invoice.STATUS_PAID\n        self.invoice.save()", "response": "Mark the invoice as paid and updates the cart if necessary."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmarking the invoice as refunded and updates the attached cart if necessary.", "response": "def _mark_refunded(self):\n        ''' Marks the invoice as refunded, and updates the attached cart if\n        necessary. '''\n        self._release_cart()\n        self.invoice.status = commerce.Invoice.STATUS_REFUNDED\n        self.invoice.save()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmark the invoice as void and updates the attached cart if necessary.", "response": "def _mark_void(self):\n        ''' Marks the invoice as refunded, and updates the attached cart if\n        necessary. '''\n        self.invoice.status = commerce.Invoice.STATUS_VOID\n        self.invoice.save()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _invoice_matches_cart(self):\n        ''' Returns true if there is no cart, or if the revision of this\n        invoice matches the current revision of the cart. '''\n\n        self._refresh()\n\n        cart = self.invoice.cart\n        if not cart:\n            return True\n\n        return cart.revision == self.invoice.cart_revision", "response": "Returns true if the invoice is in the cart and the current revision of the cart."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nvoids this invoice if the invoice is no longer valid because the cart revision has changed.", "response": "def update_validity(self):\n        ''' Voids this invoice if the attached cart is no longer valid because\n        the cart revision has changed, or the reservations have expired. '''\n\n        is_valid = self._invoice_matches_cart()\n        cart = self.invoice.cart\n        if self.invoice.is_unpaid and is_valid and cart:\n            try:\n                CartController(cart).validate_cart()\n            except ValidationError:\n                is_valid = False\n\n        if not is_valid:\n            if self.invoice.total_payments() > 0:\n                # Free up the payments made to this invoice\n                self.refund()\n            else:\n                self.void()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef void(self):\n        ''' Voids the invoice if it is valid to do so. '''\n        if self.invoice.total_payments() > 0:\n            raise ValidationError(\"Invoices with payments must be refunded.\")\n        elif self.invoice.is_refunded:\n            raise ValidationError(\"Refunded invoices may not be voided.\")\n        if self.invoice.is_paid:\n            self._release_cart()\n\n        self._mark_void()", "response": "Voids the invoice if it is valid to do so."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef refund(self):\n        ''' Refunds the invoice by generating a CreditNote for the value of\n        all of the payments against the cart.\n\n        The invoice is marked as refunded, and the underlying cart is marked\n        as released.\n\n        '''\n\n        if self.invoice.is_void:\n            raise ValidationError(\"Void invoices cannot be refunded\")\n\n        # Raises a credit note fot the value of the invoice.\n        amount = self.invoice.total_payments()\n\n        if amount == 0:\n            self.void()\n            return\n\n        CreditNoteController.generate_from_invoice(self.invoice, amount)\n        self.update_status()", "response": "Refund the invoice by generating a CreditNote for the value of\n        all of the payments against the cart."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef email(cls, invoice, kind):\n        ''' Sends out an e-mail notifying the user about something to do\n        with that invoice. '''\n\n        context = {\n            \"invoice\": invoice,\n        }\n\n        send_email([invoice.user.email], kind, context=context)", "response": "Sends an e - mail to the user about something to do\n            with that invoice."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef email_on_invoice_change(cls, invoice, old_status, new_status):\n        ''' Sends out all of the necessary notifications that the status of the\n        invoice has changed to:\n\n        - Invoice is now paid\n        - Invoice is now refunded\n\n        '''\n\n        # The statuses that we don't care about.\n        silent_status = [\n            commerce.Invoice.STATUS_VOID,\n            commerce.Invoice.STATUS_UNPAID,\n        ]\n\n        if old_status == new_status:\n            return\n        if False and new_status in silent_status:\n            pass\n\n        cls.email(invoice, \"invoice_updated\")", "response": "Sends out an email to the user that the invoice has changed."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update(self, data):\n        fields = [\n            'id',\n            'status',\n            'type',\n            'persistence',\n            'date_start',\n            'date_finish',\n            'date_created',\n            'date_modified',\n            'checksum',\n            'processor_name',\n            'input',\n            'input_schema',\n            'output',\n            'output_schema',\n            'static',\n            'static_schema',\n            'var',\n            'var_template',\n        ]\n\n        self.annotation = {}\n        for f in fields:\n            setattr(self, f, data[f])\n\n        self.name = data['static']['name'] if 'name' in data['static'] else ''\n\n        self.annotation.update(self._flatten_field(data['input'], data['input_schema'], 'input'))\n        self.annotation.update(self._flatten_field(data['output'], data['output_schema'], 'output'))\n        self.annotation.update(self._flatten_field(data['static'], data['static_schema'], 'static'))\n        self.annotation.update(self._flatten_field(data['var'], data['var_template'], 'var'))", "response": "Update the object with new data."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreduces dicts of dicts to dot separated keys.", "response": "def _flatten_field(self, field, schema, path):\n        \"\"\"Reduce dicts of dicts to dot separated keys.\"\"\"\n        flat = {}\n        for field_schema, fields, path in iterate_schema(field, schema, path):\n            name = field_schema['name']\n            typ = field_schema['type']\n            label = field_schema['label']\n            value = fields[name] if name in fields else None\n            flat[path] = {'name': name, 'value': value, 'type': typ, 'label': label}\n\n        return flat"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprints annotation key - value pairs to standard output.", "response": "def print_annotation(self):\n        \"\"\"Print annotation \"key: value\" pairs to standard output.\"\"\"\n        for path, ann in self.annotation.items():\n            print(\"{}: {}\".format(path, ann['value']))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef print_downloads(self):\n        for path, ann in self.annotation.items():\n            if path.startswith('output') and ann['type'] == 'basic:file:':\n                print(\"{}: {}\".format(path, ann['value']['file']))", "response": "Print file fields to standard output."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndownloads a file. :param field: file field to download :type field: string :rtype: a file handle", "response": "def download(self, field):\n        \"\"\"Download a file.\n\n        :param field: file field to download\n        :type field: string\n        :rtype: a file handle\n\n        \"\"\"\n        if not field.startswith('output'):\n            raise ValueError(\"Only processor results (output.* fields) can be downloaded\")\n\n        if field not in self.annotation:\n            raise ValueError(\"Download field {} does not exist\".format(field))\n\n        ann = self.annotation[field]\n        if ann['type'] != 'basic:file:':\n            raise ValueError(\"Only basic:file: field can be downloaded\")\n\n        return next(self.gencloud.download([self.id], field))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_arguments(cls, parser):\n\n        parser.add_argument(\n            '-t', '--title',\n            action='store',\n            nargs='?',\n            const='',\n            dest='title',\n            help=\"[issue] task/issue title.\",\n            )\n\n        parser.add_argument(\n            '-b', '--body',\n            action='store',\n            nargs='?',\n            const='',\n            dest='body',\n            help=\"[issue] task/issue body.\",\n            )\n\n        pass", "response": "Add arguments to the parser for collection in app. args.\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of GenProject objects.", "response": "def projects(self):\n        \"\"\"Return a list :obj:`GenProject` projects.\n\n        :rtype: list of :obj:`GenProject` projects\n\n        \"\"\"\n        if not ('projects' in self.cache and self.cache['projects']):\n            self.cache['projects'] = {c['id']: GenProject(c, self) for c in self.api.case.get()['objects']}\n\n        return self.cache['projects']"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef project_data(self, project):\n        projobjects = self.cache['project_objects']\n        objects = self.cache['objects']\n        project_id = str(project)\n\n        if not re.match('^[0-9a-fA-F]{24}$', project_id):\n            # project_id is a slug\n            projects = self.api.case.get(url_slug=project_id)['objects']\n            if len(projects) != 1:\n                raise ValueError(msg='Attribute project not a slug or ObjectId: {}'.format(project_id))\n\n            project_id = str(projects[0]['id'])\n\n        if project_id not in projobjects:\n            projobjects[project_id] = []\n            data = self.api.data.get(case_ids__contains=project_id)['objects']\n            for d in data:\n                _id = d['id']\n                if _id in objects:\n                    # Update existing object\n                    objects[_id].update(d)\n                else:\n                    # Insert new object\n                    objects[_id] = GenData(d, self)\n\n                projobjects[project_id].append(objects[_id])\n\n            # Hydrate reference fields\n            for d in projobjects[project_id]:\n                while True:\n                    ref_annotation = {}\n                    remove_annotation = []\n                    for path, ann in d.annotation.items():\n                        if ann['type'].startswith('data:'):\n                            # Referenced data object found\n                            # Copy annotation\n                            if ann['value'] in self.cache['objects']:\n                                annotation = self.cache['objects'][ann['value']].annotation\n                                ref_annotation.update({path + '.' + k: v for k, v in annotation.items()})\n\n                            remove_annotation.append(path)\n                    if ref_annotation:\n                        d.annotation.update(ref_annotation)\n                        for path in remove_annotation:\n                            del d.annotation[path]\n                    else:\n                        break\n\n        return projobjects[project_id]", "response": "Return a list of Data objects for a given project."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef data(self, **query):\n        objects = self.cache['objects']\n        data = self.api.data.get(**query)['objects']\n        data_objects = []\n\n        for d in data:\n            _id = d['id']\n            if _id in objects:\n                # Update existing object\n                objects[_id].update(d)\n            else:\n                # Insert new object\n                objects[_id] = GenData(d, self)\n\n            data_objects.append(objects[_id])\n\n        # Hydrate reference fields\n        for d in data_objects:\n            count += 1\n            while True:\n                ref_annotation = {}\n                remove_annotation = []\n                for path, ann in d.annotation.items():\n                    if ann['type'].startswith('data:'):\n                        # Referenced data object found\n                        # Copy annotation\n                        _id = ann['value']\n                        if _id not in objects:\n                            try:\n                                d_tmp = self.api.data(_id).get()\n                            except slumber.exceptions.HttpClientError as ex:\n                                if ex.response.status_code == 404:\n                                    continue\n                                else:\n                                    raise ex\n\n                            objects[_id] = GenData(d_tmp, self)\n\n                        annotation = objects[_id].annotation\n                        ref_annotation.update({path + '.' + k: v for k, v in annotation.items()})\n                        remove_annotation.append(path)\n                if ref_annotation:\n                    d.annotation.update(ref_annotation)\n                    for path in remove_annotation:\n                        del d.annotation[path]\n                else:\n                    break\n\n        return data_objects", "response": "Query for Data object annotation."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef processors(self, processor_name=None):\n        if processor_name:\n            return self.api.processor.get(name=processor_name)['objects']\n        else:\n            return self.api.processor.get()['objects']", "response": "Return a list of Processor objects."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef print_processor_inputs(self, processor_name):\n        p = self.processors(processor_name=processor_name)\n\n        if len(p) == 1:\n            p = p[0]\n        else:\n            Exception('Invalid processor name')\n\n        for field_schema, _, _ in iterate_schema({}, p['input_schema'], 'input'):\n            name = field_schema['name']\n            typ = field_schema['type']\n            # value = fields[name] if name in fields else None\n            print(\"{} -> {}\".format(name, typ))", "response": "Print input fields and types of a specific processor."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef rundata(self, strjson):\n\n        d = json.loads(strjson)\n        return self.api.data.post(d)", "response": "POST JSON data object to server"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create(self, data, resource='data'):\n        if isinstance(data, dict):\n            data = json.dumps(data)\n\n        if not isinstance(data, str):\n            raise ValueError(mgs='data must be dict, str or unicode')\n\n        resource = resource.lower()\n        if resource not in ('data', 'project', 'processor', 'trigger', 'template'):\n            raise ValueError(mgs='resource must be data, project, processor, trigger or template')\n\n        if resource == 'project':\n            resource = 'case'\n\n        url = urlparse.urljoin(self.url, '/api/v1/{}/'.format(resource))\n        return requests.post(url,\n                             data=data,\n                             auth=self.auth,\n                             headers={\n                                 'cache-control': 'no-cache',\n                                 'content-type': 'application/json',\n                                 'accept': 'application/json, text/plain, */*',\n                                 'referer': self.url,\n                             })", "response": "Create an object of resource"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupload files and data objects.", "response": "def upload(self, project_id, processor_name, **fields):\n        \"\"\"Upload files and data objects.\n\n        :param project_id: ObjectId of Genesis project\n        :type project_id: string\n        :param processor_name: Processor object name\n        :type processor_name: string\n        :param fields: Processor field-value pairs\n        :type fields: args\n        :rtype: HTTP Response object\n\n        \"\"\"\n        p = self.processors(processor_name=processor_name)\n\n        if len(p) == 1:\n            p = p[0]\n        else:\n            Exception('Invalid processor name {}'.format(processor_name))\n\n        for field_name, field_val in fields.items():\n            if field_name not in p['input_schema']:\n                Exception(\"Field {} not in processor {} inputs\".format(field_name, p['name']))\n\n            if find_field(p['input_schema'], field_name)['type'].startswith('basic:file:'):\n                if not os.path.isfile(field_val):\n                    Exception(\"File {} not found\".format(field_val))\n\n        inputs = {}\n\n        for field_name, field_val in fields.items():\n            if find_field(p['input_schema'], field_name)['type'].startswith('basic:file:'):\n\n                file_temp = self._upload_file(field_val)\n\n                if not file_temp:\n                    Exception(\"Upload failed for {}\".format(field_val))\n\n                inputs[field_name] = {\n                    'file': field_val,\n                    'file_temp': file_temp\n                }\n            else:\n                inputs[field_name] = field_val\n\n        d = {\n            'status': 'uploading',\n            'case_ids': [project_id],\n            'processor_name': processor_name,\n            'input': inputs,\n        }\n\n        return self.create(d)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nuploading a single file on the platform.", "response": "def _upload_file(self, fn):\n        \"\"\"Upload a single file on the platform.\n\n        File is uploaded in chunks of 1,024 bytes.\n\n        :param fn: File path\n        :type fn: string\n\n        \"\"\"\n        size = os.path.getsize(fn)\n        counter = 0\n        base_name = os.path.basename(fn)\n        session_id = str(uuid.uuid4())\n\n        with open(fn, 'rb') as f:\n            while True:\n                response = None\n                chunk = f.read(CHUNK_SIZE)\n                if not chunk:\n                    break\n\n                for i in range(5):\n                    content_range = 'bytes {}-{}/{}'.format(counter * CHUNK_SIZE,\n                                                            counter * CHUNK_SIZE + len(chunk) - 1, size)\n                    if i > 0 and response is not None:\n                        print(\"Chunk upload failed (error {}): repeating {}\"\n                              .format(response.status_code, content_range))\n\n                    response = requests.post(urlparse.urljoin(self.url, 'upload/'),\n                                             auth=self.auth,\n                                             data=chunk,\n                                             headers={\n                                                 'Content-Disposition': 'attachment; filename=\"{}\"'.format(base_name),\n                                                 'Content-Length': size,\n                                                 'Content-Range': content_range,\n                                                 'Content-Type': 'application/octet-stream',\n                                                 'Session-Id': session_id})\n\n                    if response.status_code in [200, 201]:\n                        break\n                else:\n                    # Upload of a chunk failed (5 retries)\n                    return None\n\n                progress = 100. * (counter * CHUNK_SIZE + len(chunk)) / size\n                sys.stdout.write(\"\\r{:.0f} % Uploading {}\".format(progress, fn))\n                sys.stdout.flush()\n                counter += 1\n        print()\n        return session_id"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndownloading files of data objects.", "response": "def download(self, data_objects, field):\n        \"\"\"Download files of data objects.\n\n        :param data_objects: Data object ids\n        :type data_objects: list of UUID strings\n        :param field: Download field name\n        :type field: string\n        :rtype: generator of requests.Response objects\n\n        \"\"\"\n        if not field.startswith('output'):\n            raise ValueError(\"Only processor results (output.* fields) can be downloaded\")\n\n        for o in data_objects:\n            o = str(o)\n            if re.match('^[0-9a-fA-F]{24}$', o) is None:\n                raise ValueError(\"Invalid object id {}\".format(o))\n\n            if o not in self.cache['objects']:\n                self.cache['objects'][o] = GenData(self.api.data(o).get(), self)\n\n            if field not in self.cache['objects'][o].annotation:\n                raise ValueError(\"Download field {} does not exist\".format(field))\n\n            ann = self.cache['objects'][o].annotation[field]\n            if ann['type'] != 'basic:file:':\n                raise ValueError(\"Only basic:file: field can be downloaded\")\n\n        for o in data_objects:\n            ann = self.cache['objects'][o].annotation[field]\n            url = urlparse.urljoin(self.url, 'data/{}/{}'.format(o, ann['value']['file']))\n            yield requests.get(url, stream=True, auth=self.auth)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_subclasses(c):\n    subclasses = c.__subclasses__()\n    for d in list(subclasses):\n        subclasses.extend(get_subclasses(d))\n    return subclasses", "response": "Gets the subclasses of a class."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd arguments to the parser for the command line.", "response": "def add_arguments(cls, parser):\n        \"\"\"Add arguments to the parser for collection in app.args.\n\n        Args:\n            parser:\n                `argparse.ArgumentParser`. Parser.\n                Arguments added here are server on\n                self.args.\n        \"\"\"\n\n        parser.add_argument(\n            '-as-api', '--asana-api',\n            action='store',\n            nargs='?',\n            const='',\n            dest='asana_api',\n            help=\"[setting] asana api key.\",\n            )\n\n        parser.add_argument(\n            '-gh-api', '--github-api',\n            action='store',\n            nargs='?',\n            const='',\n            dest='github_api',\n            help=\"[setting] github api token.\",\n            )\n\n        parser.add_argument(\n            '--first-issue',\n            type=int,\n            action='store',\n            nargs='?',\n            const='',\n            help=\"[setting] only sync issues [FIRST_ISSUE] and above\"\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_repo_and_project(self):\n        app = self.app\n\n        # Get repo\n        repo = app.data.apply('github-repo', app.args.github_repo,\n            app.prompt_repo,\n            on_load=app.github.get_repo,\n            on_save=lambda r: r.id\n            )\n\n        assert repo, \"repository not found.\"\n\n        # Get project\n        project = app.data.apply('asana-project', app.args.asana_project,\n            app.prompt_project,\n            on_load=app.asana.projects.find_by_id,\n            on_save=lambda p: p['id']\n            )\n\n        assert project, \"project not found.\"\n\n        # Set first issue\n        first_issue = app.data.apply('first-issue', app.args.first_issue,\n            \"set the first issue to sync with [1 for new repos]\",\n            on_save=int)\n\n        assert first_issue\n        assert first_issue >= 0, \"issue must be positive\"\n\n        app.sync_data()\n\n        return repo, project", "response": "Returns repository and project."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_variant_phenotypes_with_suggested_changes(variant_id_list):\n    '''for each variant, yields evidence and associated phenotypes, both current and suggested'''\n    variants = civic.get_variants_by_ids(variant_id_list)\n    evidence = list()\n    for variant in variants:\n        evidence.extend(variant.evidence)\n    for e in evidence:\n        suggested_changes_url = f'https://civicdb.org/api/evidence_items/{e.id}/suggested_changes'\n        resp = requests.get(suggested_changes_url)\n        resp.raise_for_status()\n        suggested_changes = dict()\n        for suggested_change in resp.json():\n            pheno_changes = suggested_change['suggested_changes'].get('phenotype_ids', None)\n            if pheno_changes is None:\n                continue\n            a, b = pheno_changes\n            added = set(b) - set(a)\n            deleted = set(a) - set(b)\n            rid = suggested_change['id']\n            suggested_changes[rid] = {'added': added, 'deleted': deleted}\n        yield e, {'suggested_changes': suggested_changes, 'current': set([x.id for x in e.phenotypes])}", "response": "yields all the variants with suggested changes"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_variant_phenotypes_with_suggested_changes_merged(variant_id_list):\n    '''for each variant, yields evidence and merged phenotype from applying suggested changes to current'''\n    for evidence, phenotype_status in get_variant_phenotypes_with_suggested_changes(variant_id_list):\n        final = phenotype_status['current']\n        for rid in sorted(phenotype_status['suggested_changes']):\n            changes = phenotype_status['suggested_changes'][rid]\n            final = final - changes['deleted']\n            final = final | changes['added']\n        if final:\n            yield evidence, final", "response": "yields all the variants with suggested changes merged"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef search_variants_by_coordinates(coordinate_query, search_mode='any'):\n    get_all_variants()\n    ct = COORDINATE_TABLE\n    start_idx = COORDINATE_TABLE_START\n    stop_idx = COORDINATE_TABLE_STOP\n    chr_idx = COORDINATE_TABLE_CHR\n    start = int(coordinate_query.start)\n    stop = int(coordinate_query.stop)\n    chromosome = str(coordinate_query.chr)\n    # overlapping = (start <= ct.stop) & (stop >= ct.start)\n    left_idx = chr_idx.searchsorted(chromosome)\n    right_idx = chr_idx.searchsorted(chromosome, side='right')\n    chr_ct_idx = chr_idx[left_idx:right_idx].index\n    right_idx = start_idx.searchsorted(stop, side='right')\n    start_ct_idx = start_idx[:right_idx].index\n    left_idx = stop_idx.searchsorted(start)\n    stop_ct_idx = stop_idx[left_idx:].index\n    match_idx = chr_ct_idx & start_ct_idx & stop_ct_idx\n    m_df = ct.loc[match_idx, ]\n    if search_mode == 'any':\n        var_digests = m_df.v_hash.to_list()\n        return [CACHE[v] for v in var_digests]\n    elif search_mode == 'include_smaller':\n        match_idx = (start <= m_df.start) & (stop >= m_df.stop)\n    elif search_mode == 'include_larger':\n        match_idx = (start >= m_df.start) & (stop <= m_df.stop)\n    elif search_mode == 'exact':\n        match_idx = (start == m_df.stop) & (stop == m_df.start)\n        if coordinate_query.alt:\n            match_idx = match_idx & (coordinate_query.alt == m_df.alt)\n    else:\n        raise ValueError(\"unexpected search mode\")\n    var_digests = m_df.loc[match_idx,].v_hash.to_list()\n    return [CACHE[v] for v in var_digests]", "response": "Search the cache for variants matching the provided coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupdate record and returns True if record is complete else False.", "response": "def update(self, allow_partial=True, force=False, **kwargs):\n        \"\"\"Updates record and returns True if record is complete after update, else False.\"\"\"\n        if kwargs:\n            self.__init__(partial=allow_partial, force=force, **kwargs)\n            return not self._partial\n\n        if not force and CACHE.get(hash(self)):\n            cached = CACHE[hash(self)]\n            for field in self._SIMPLE_FIELDS | self._COMPLEX_FIELDS:\n                v = getattr(cached, field)\n                setattr(self, field, v)\n            self._partial = False\n            logging.info(f'Loading {str(self)} from cache')\n            return True\n        resp_dict = element_lookup_by_id(self.type, self.id)\n        self.__init__(partial=False, **resp_dict)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a unique list of seq", "response": "def uniqify(cls, seq):\n        \"\"\"Returns a unique list of seq\"\"\"\n        seen = set()\n        seen_add = seen.add\n        return [ x for x in seq if x not in seen and not seen_add(x)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconnects to Github and Asana and authenticates via OAuth.", "response": "def authenticate(self):\n        \"\"\"Connects to Github and Asana and authenticates via OAuth.\"\"\"\n        if self.oauth:\n            return False\n\n        # Save asana.\n        self.settings.apply('api-asana', self.args.asana_api,\n            \"enter asana api key\")\n\n        # Save github.com\n        self.settings.apply('api-github', self.args.github_api,\n            \"enter github.com token\")\n\n        logging.debug(\"authenticating asana api.\")\n        self.asana = Client.basic_auth(self.settings['api-asana'])\n        self.asana_errors = asana_errors\n        self.asana_me = self.asana.users.me()\n        logging.debug(\"authenticating github api\")\n        self.github = Github(self.settings['api-github'])\n        self.github_user = self.github.get_user()\n\n        self.oauth = True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _list_select(cls, lst, prompt, offset=0):\n\n        inp = raw_input(\"select %s: \" % prompt)\n        assert inp, \"value required.\"\n\n        try:\n            return lst[int(inp)+offset]\n        except ValueError:\n            return inp\n        except IndexError:\n            assert False, \"bad value.\"", "response": "Given a list of values and names accepts the index value or name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef save_issue_data_task(self, issue, task_id, namespace='open'):\n\n        issue_data = self.get_saved_issue_data(issue, namespace)\n\n        if not issue_data.has_key('tasks'):\n            issue_data['tasks'] = [task_id]\n        elif task_id not in issue_data['tasks']:\n            issue_data['tasks'].append(task_id)", "response": "Saves a task to local data."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_saved_issue_data(self, issue, namespace='open'):\n\n        if isinstance(issue, int):\n            issue_number = str(issue)\n        elif isinstance(issue, basestring):\n            issue_number = issue\n        else:\n            issue_number = issue.number\n\n        issue_data_key = self._issue_data_key(namespace)\n        issue_data = self.data.get(issue_data_key,\n            {})\n\n        _data = issue_data.get(str(issue_number), {})\n        issue_data[str(issue_number)] = _data\n        return _data", "response": "Returns the issue data from local data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmove an issue_data from one namespace to another.", "response": "def move_saved_issue_data(self, issue, ns, other_ns):\n        \"\"\"Moves an issue_data from one namespace to another.\"\"\"\n\n        if isinstance(issue, int):\n            issue_number = str(issue)\n        elif isinstance(issue, basestring):\n            issue_number = issue\n        else:\n            issue_number = issue.number\n\n        issue_data_key = self._issue_data_key(ns)\n        other_issue_data_key = self._issue_data_key(other_ns)\n        issue_data = self.data.get(issue_data_key,\n            {})\n        other_issue_data = self.data.get(other_issue_data_key,\n            {})\n\n        _id = issue_data.pop(issue_number, None)\n        if _id:\n            other_issue_data[issue_number] = _id\n\n        self.data[other_issue_data_key] = other_issue_data\n        self.data[issue_data_key] = issue_data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the task data from local data.", "response": "def get_saved_task_data(self, task):\n        \"\"\"Returns task data from local data.\n\n        Args:\n            task:\n                `int`. Asana task number.\n        \"\"\"\n\n        if isinstance(task, int):\n            task_number = str(task)\n        elif isinstance(task, basestring):\n            task_number = task\n        else:\n            task_number = task['id']\n\n        task_data_key = self._task_data_key()\n        task_data = self.data.get(task_data_key, {})\n\n        _data = task_data.get(str(task_number), {})\n        task_data[str(task_number)] = _data\n        return _data"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_asana_task(self, asana_task_id):\n\n        try:\n            return self.asana.tasks.find_by_id(asana_task_id)\n        except asana_errors.NotFoundError:\n            return None\n        except asana_errors.ForbiddenError:\n            return None", "response": "Retrieves a task from the asana."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef save(self):\n\n        with open(self.filename, 'wb') as file:\n            self.prune()\n            self.data['version'] = self.version\n            json.dump(self.data,\n                file,\n                sort_keys=True, indent=2)", "response": "Save data to a file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\napply a setting value to a key. Returns without prompting if the value is not None.", "response": "def apply(self, key, value, prompt=None,\n        on_load=lambda a: a, on_save=lambda a: a):\n        \"\"\"Applies a setting value to a key, if the value is not `None`.\n\n        Returns without prompting if either of the following:\n            * `value` is not `None`\n            * already present in the dictionary\n\n        Args:\n            prompt:\n                May either be a string to prompt via `raw_input` or a\n                method (callable) that returns the value.\n\n            on_load:\n                lambda. Value is passed through here after loaded.\n\n            on_save:\n                lambda. Value is saved as this value.\n        \"\"\"\n\n        # Reset value if flag exists without value\n        if value == '':\n            value = None\n            if key and self.data.has_key(key): del self.data[key]\n\n        # If value is explicitly set from args.\n        if value is not None:\n            value = on_load(value)\n            if key: self.data[key] = on_save(value)\n            return value\n\n        elif not key or not self.has_key(key):\n            if callable(prompt):\n                value = prompt()\n            elif prompt is not None:\n                value = raw_input(prompt + \": \")\n\n            if value is None:\n                if self.data.has_key(key): del self.data[key]\n                return None\n\n            self.data[key] = on_save(value)\n            return value\n\n        return on_load(self.data[key])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding arguments to the parser for the command line.", "response": "def add_arguments(cls, parser):\n        \"\"\"Add arguments to the parser for collection in app.args.\n\n        Args:\n            parser:\n                `argparse.ArgumentParser`. Parser.\n                Arguments added here are server on\n                self.args.\n        \"\"\"\n\n        parser.add_argument(\n            '-i', '--issue',\n            action='store',\n            nargs='?',\n            const='',\n            dest='issue',\n            help=\"[pr] issue #\",\n            )\n\n        parser.add_argument(\n            '-br', '--branch',\n            action='store',\n            nargs='?',\n            const='',\n            dest='branch',\n            help=\"[pr] branch\",\n            )\n\n        parser.add_argument(\n            '-tbr', '--target-branch',\n            action='store',\n            nargs='?',\n            const='',\n            default='master',\n            dest='target_branch',\n            help=\"[pr] name of branch to pull changes into\\n(defaults to: master)\",\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef transport_task(func):\n\n    def wrapped_func(*args, **kwargs):\n        tries = 0\n        while True:\n            try:\n                try:\n                    return func(*args, **kwargs)\n\n                except (asana_errors.InvalidRequestError,\n                        asana_errors.NotFoundError), exc:\n                    logging.warn(\"warning: invalid request: %r\", exc)\n\n                except asana_errors.ForbiddenError, exc:\n                    logging.warn(\"forbidden error: %r\", exc)\n\n                except asana_errors.NotFoundError, exc:\n                    logging.warn(\"not found error: %r\", exc)\n\n                return None\n            except asana_errors.RetryableAsanaError, retry_exc:\n                tries += 1\n                logging.warn(\"retry exception %r on try %d\", retry_exc, tries)\n\n                if tries >= 3:\n                    raise\n            except Exception, exc:\n                logging.exception(\"Exception in transport.\")\n                return\n\n    return wrapped_func", "response": "Decorator for retrying tasks with special cases."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwait until the queue is empty.", "response": "def flush(callback=None):\n    \"\"\"Waits until queue is empty.\"\"\"\n\n    while True:\n        if shutdown_event.is_set():\n            return\n\n        if callable(callback):\n            callback()\n\n        try:\n            item = queue.get(timeout=1)\n            queue.put(item)  # put it back, we're just peeking.\n        except Queue.Empty:\n            return"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef task_create(asana_workspace_id, name, notes, assignee, projects,\n                completed, **kwargs):\n    \"\"\"Creates a task\"\"\"\n    put(\"task_create\",\n        asana_workspace_id=asana_workspace_id,\n        name=name,\n        notes=notes,\n        assignee=assignee,\n        projects=projects,\n        completed=completed,\n        **kwargs)", "response": "Creates a task in the cluster."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns formatting for the tasks section of asana.", "response": "def format_task_numbers_with_links(tasks):\n    \"\"\"Returns formatting for the tasks section of asana.\"\"\"\n\n    project_id = data.get('asana-project', None)\n\n    def _task_format(task_id):\n        if project_id:\n            asana_url = tool.ToolApp.make_asana_url(project_id, task_id)\n            return \"[#%d](%s)\" % (task_id, asana_url)\n        else:\n            return \"#%d\" % task_id\n\n    return \"\\n\".join([_task_format(tid) for tid in tasks])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a missing task in the specified workspace.", "response": "def create_missing_task(self,\n                            asana_workspace_id,\n                            name,\n                            assignee,\n                            projects,\n                            completed,\n                            issue_number,\n                            issue_html_url,\n                            issue_state,\n                            issue_body,\n                            tasks,\n                            labels,\n                            label_tag_map):\n\n        \"\"\"Creates a missing task.\"\"\"\n\n        task = self.asana.tasks.create_in_workspace(\n            asana_workspace_id,\n            {\n                'name': name,\n                'notes': issue_body,\n                'assignee': assignee,\n                'projects': projects,\n                'completed': completed,\n            })\n\n        # Announce task git issue\n        task_id = task['id']\n\n        put(\"create_story\",\n            task_id=task_id,\n            text=\"Git Issue #%d: \\n\"\n                  \"%s\" % (\n                    issue_number,\n                    issue_html_url,\n                    )\n            )\n\n        put(\"apply_tasks_to_issue\",\n            tasks=[task_id],\n            issue_number=issue_number,\n            issue_body=issue_body,\n            )\n\n        # Save task to drive\n        put_setting(\"save_issue_data_task\",\n                    issue=issue_number,\n                    task_id=task_id,\n                    namespace=issue_state)\n\n        tasks.append(task_id)\n\n        # Sync tags/labels\n        put(\"sync_tags\",\n            tasks=tasks,\n            labels=labels,\n            label_tag_map=label_tag_map)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef apply_tasks_to_issue(self, tasks, issue_number, issue_body):\n        issue_body = issue_body\n        task_numbers = format_task_numbers_with_links(tasks)\n        if task_numbers:\n            new_body = ASANA_SECTION_RE.sub('', issue_body)\n            new_body = new_body + \"\\n## Asana Tasks:\\n\\n%s\" % task_numbers\n            put(\"issue_edit\",\n                issue_number=issue_number,\n                body=new_body)\n            return new_body\n\n        return issue_body", "response": "Applies the tasks to an issue."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef data_types(self):\n        data = self.gencloud.project_data(self.id)\n        return sorted(set(d.type for d in data))", "response": "Return a list of data types for this project."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef data(self, **query):\n        data = self.gencloud.project_data(self.id)\n        query['case_ids__contains'] = self.id\n        ids = set(d['id'] for d in self.gencloud.api.dataid.get(**query)['objects'])\n        return [d for d in data if d.id in ids]", "response": "Query for Data object annotation."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsends string to module level log", "response": "def ekm_log(logstr, priority=3):\n    \"\"\" Send string to module level log\n\n    Args:\n        logstr (str): string to print.\n        priority (int): priority, supports 3 (default) and 4 (special).\n    \"\"\"\n    if priority <= ekmmeters_log_level:\n        dt = datetime.datetime\n        stamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M.%f\")\n        ekmmeters_log_func(\"[EKM Meter Debug Message: \" + stamp + \"] -> \" + logstr)\n    pass"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef initPort(self):\n        try:\n            self.m_ser = serial.Serial(port=self.m_ttyport,\n                                       baudrate=self.m_baudrate,\n                                       timeout=0,\n                                       parity=serial.PARITY_EVEN,\n                                       stopbits=serial.STOPBITS_ONE,\n                                       bytesize=serial.SEVENBITS,\n                                       rtscts=False)\n            ekm_log(\"Pyserial version = \" + serial.VERSION)\n            ekm_log(\"Port = \" + self.m_ttyport)\n            ekm_log(\"Rate = \" + str(self.m_baudrate))\n            time.sleep(self.m_init_wait)\n            return True\n        except:\n            ekm_log(traceback.format_exc(sys.exc_info()))\n\n        return False", "response": "Initializes the serial port."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwriting a block of data to the serial port.", "response": "def write(self, output):\n        \"\"\"Passthrough for pyserial Serial.write().\n\n        Args:\n            output (str): Block to write to port\n        \"\"\"\n        view_str = output.encode('ascii', 'ignore')\n        if (len(view_str) > 0):\n            self.m_ser.write(view_str)\n            self.m_ser.flush()\n            self.m_ser.reset_input_buffer()\n            time.sleep(self.m_force_wait)\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the maximum number of wait time until the polling loop is done.", "response": "def setPollingValues(self, max_waits, wait_sleep):\n        \"\"\" Optional polling loop control\n\n        Args:\n            max_waits (int):   waits\n            wait_sleep (int):  ms per wait\n        \"\"\"\n        self.m_max_waits = max_waits\n        self.m_wait_sleep = wait_sleep"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\npoll for finished block or first byte ACK.", "response": "def getResponse(self, context=\"\"):\n        \"\"\" Poll for finished block or first byte ACK.\n        Args:\n            context (str): internal serial call context.\n\n        Returns:\n            string: Response, implict cast from byte array.\n        \"\"\"\n        waits = 0  # allowed interval counter\n        response_str = \"\"  # returned bytes in string default\n        try:\n            waits = 0  # allowed interval counter\n            while (waits < self.m_max_waits):\n                bytes_to_read = self.m_ser.inWaiting()\n                if bytes_to_read > 0:\n                    next_chunk = str(self.m_ser.read(bytes_to_read)).encode('ascii', 'ignore')\n                    response_str += next_chunk\n                    if (len(response_str) == 255):\n                        time.sleep(self.m_force_wait)\n                        return response_str\n                    if (len(response_str) == 1) and (response_str.encode('hex') == '06'):\n                        time.sleep(self.m_force_wait)\n                        return response_str\n                else:  # hang out -- half shortest expected interval (50 ms)\n                    waits += 1\n                    time.sleep(self.m_force_wait)\n            response_str = \"\"\n\n        except:\n            ekm_log(traceback.format_exc(sys.exc_info()))\n\n        return response_str"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef combineAB(self):\n        v4definition_meter = V4Meter()\n        v4definition_meter.makeAB()\n        defv4 = v4definition_meter.getReadBuffer()\n\n        v3definition_meter = V3Meter()\n        v3definition_meter.makeReturnFormat()\n        defv3 = v3definition_meter.getReadBuffer()\n\n        for fld in defv3:\n            if fld not in self.m_all_fields:\n                compare_fld = fld.upper()\n                if not \"RESERVED\" in compare_fld and not \"CRC\" in compare_fld:\n                    self.m_all_fields[fld] = defv3[fld]\n\n        for fld in defv4:\n            if fld not in self.m_all_fields:\n                compare_fld = fld.upper()\n                if not \"RESERVED\" in compare_fld and not \"CRC\" in compare_fld:\n                    self.m_all_fields[fld] = defv4[fld]\n        pass", "response": "Use the serial block definitions in V3 and V4 to create one field list."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntranslate FieldType to Portable SQL Type.", "response": "def mapTypeToSql(fld_type=FieldType.NoType, fld_len=0):\n        \"\"\" Translate FieldType to portable SQL Type.  Override if needful.\n        Args:\n            fld_type (int): :class:`~ekmmeters.FieldType` in serial block.\n            fld_len (int): Binary length in serial block\n\n        Returns:\n            string: Portable SQL type and length where appropriate.\n        \"\"\"\n        if fld_type == FieldType.Float:\n            return \"FLOAT\"\n        elif fld_type == FieldType.String:\n            return \"VARCHAR(\" + str(fld_len) + \")\"\n        elif fld_type == FieldType.Int:\n            return \"INT\"\n        elif fld_type == FieldType.Hex:\n            return \"VARCHAR(\" + str(fld_len * 2) + \")\"\n        elif fld_type == FieldType.PowerFactor:\n            return \"VARCHAR(\" + str(fld_len) + \")\"\n        else:\n            ekm_log(\"Type \" + str(type) + \" not handled by mapTypeToSql, returned VARCHAR(255)\")\n            return \"VARCHAR(255)\""}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn query portion below CREATE.", "response": "def fillCreate(self, qry_str):\n        \"\"\" Return query portion below CREATE.\n        Args:\n            qry_str (str): String as built.\n\n        Returns:\n            string: Passed string with fields appended.\n        \"\"\"\n        count = 0\n        for fld in self.m_all_fields:\n            fld_type = self.m_all_fields[fld][MeterData.TypeValue]\n            fld_len = self.m_all_fields[fld][MeterData.SizeValue]\n            qry_spec = self.mapTypeToSql(fld_type, fld_len)\n            if count > 0:\n                qry_str += \", \\n\"\n            qry_str = qry_str + '   ' + fld + ' ' + qry_spec\n            count += 1\n\n        qry_str += (\",\\n\\t\" + Field.Time_Stamp + \" BIGINT,\\n\\t\" +\n                    \"Raw_A VARCHAR(512),\\n\\t\" +\n                    \"Raw_B VARCHAR(512)\\n)\")\n\n        return qry_str"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sqlInsert(def_buf, raw_a, raw_b):\n        count = 0\n        qry_str = \"INSERT INTO  Meter_Reads ( \\n\\t\"\n        for fld in def_buf:\n            if count > 0:\n                qry_str += \", \\n\\t\"\n            qry_str = qry_str + fld\n            count += 1\n        qry_str += (\",\\n\\t\" + Field.Time_Stamp + \", \\n\\t\" +\n                    \"Raw_A,\\n\\t\" +\n                    \"Raw_B\\n) \\n\" +\n                    \"VALUES( \\n\\t\")\n        count = 0\n        for fld in def_buf:\n            if count > 0:\n                qry_str += \", \\n\\t\"\n            fld_type = def_buf[fld][MeterData.TypeValue]\n            fld_str_content = def_buf[fld][MeterData.StringValue]\n            delim = \"\"\n            if (fld_type == FieldType.Hex) or \\\n                    (fld_type == FieldType.String) or \\\n                    (fld_type == FieldType.PowerFactor):\n                delim = \"'\"\n            qry_str = qry_str + delim + fld_str_content + delim\n            count += 1\n        time_val = int(time.time() * 1000)\n        qry_str = (qry_str + \",\\n\\t\" + str(time_val) + \",\\n\\t'\" +\n                   binascii.b2a_hex(raw_a) + \"'\" + \",\\n\\t'\" +\n                   binascii.b2a_hex(raw_b) + \"'\\n);\")\n        ekm_log(qry_str, 4)\n        return qry_str", "response": "Reasonably portable SQL INSERT for passed read buffer."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncall overridden dbExec with built insert statement.", "response": "def dbInsert(self, def_buf, raw_a, raw_b):\n        \"\"\" Call overridden dbExec() with built insert statement.\n        Args:\n            def_buf (SerialBlock): Block of read buffer fields to write.\n            raw_a (str): Hex string of raw A read.\n            raw_b (str): Hex string of raw B read or empty.\n        \"\"\"\n        self.dbExec(self.sqlInsert(def_buf, raw_a, raw_b))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dbExec(self, query_str):\n        try:\n            connection = sqlite3.connect(self.m_connection_string)\n            cursor = connection.cursor()\n            cursor.execute(query_str)\n            connection.commit()\n            cursor.close()\n            connection.close()\n            return True\n        except:\n            ekm_log(traceback.format_exc(sys.exc_info()))\n            return False\n        pass", "response": "Run a query on the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef raw_dict_factory(cursor, row):\n        d = {}\n        for idx, col in enumerate(cursor.description):\n            val = row[idx]\n            name = col[0]\n            if name == Field.Time_Stamp or name == Field.Meter_Address:\n                d[name] = str(val)\n                continue\n            if name == \"Raw_A\" or name == \"Raw_B\":\n                d[name] = str(val)\n                continue\n        return d", "response": "Sqlite callback accepting the cursor and the original row as a tuple."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef renderJsonReadsSince(self, timestamp, meter):\n        result = \"\"\n        try:\n            connection = sqlite3.connect(self.m_connection_string)\n            connection.row_factory = self.dict_factory\n            select_cursor = connection.cursor()\n            select_cursor.execute(\"select * from Meter_Reads where \" + Field.Time_Stamp +\n                                  \" > \" + str(timestamp) + \" and \" + Field.Meter_Address +\n                                  \"= '\" + meter + \"';\")\n            reads = select_cursor.fetchall()\n            result = json.dumps(reads, indent=4)\n\n        except:\n            ekm_log(traceback.format_exc(sys.exc_info()))\n        return result", "response": "Simple since Time_Stamp query returned as JSON records."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets context string for serial command. Private setter. Args: context_str (str): Command specific string.", "response": "def setContext(self, context_str):\n        \"\"\" Set context string for serial command.  Private setter.\n\n        Args:\n            context_str (str): Command specific string.\n        \"\"\"\n        if (len(self.m_context) == 0) and (len(context_str) >= 7):\n            if context_str[0:7] != \"request\":\n                ekm_log(\"Context: \" + context_str)\n        self.m_context = context_str"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalculates the 16 bit CRC for the current EKM Omnimeters.", "response": "def calc_crc16(buf):\n        \"\"\" Drop in pure python replacement for ekmcrc.c extension.\n\n        Args:\n            buf (bytes): String or byte array (implicit Python 2.7 cast)\n\n        Returns:\n            str: 16 bit CRC per EKM Omnimeters formatted as hex string.\n        \"\"\"\n        crc_table = [0x0000, 0xc0c1, 0xc181, 0x0140, 0xc301, 0x03c0, 0x0280, 0xc241,\n                     0xc601, 0x06c0, 0x0780, 0xc741, 0x0500, 0xc5c1, 0xc481, 0x0440,\n                     0xcc01, 0x0cc0, 0x0d80, 0xcd41, 0x0f00, 0xcfc1, 0xce81, 0x0e40,\n                     0x0a00, 0xcac1, 0xcb81, 0x0b40, 0xc901, 0x09c0, 0x0880, 0xc841,\n                     0xd801, 0x18c0, 0x1980, 0xd941, 0x1b00, 0xdbc1, 0xda81, 0x1a40,\n                     0x1e00, 0xdec1, 0xdf81, 0x1f40, 0xdd01, 0x1dc0, 0x1c80, 0xdc41,\n                     0x1400, 0xd4c1, 0xd581, 0x1540, 0xd701, 0x17c0, 0x1680, 0xd641,\n                     0xd201, 0x12c0, 0x1380, 0xd341, 0x1100, 0xd1c1, 0xd081, 0x1040,\n                     0xf001, 0x30c0, 0x3180, 0xf141, 0x3300, 0xf3c1, 0xf281, 0x3240,\n                     0x3600, 0xf6c1, 0xf781, 0x3740, 0xf501, 0x35c0, 0x3480, 0xf441,\n                     0x3c00, 0xfcc1, 0xfd81, 0x3d40, 0xff01, 0x3fc0, 0x3e80, 0xfe41,\n                     0xfa01, 0x3ac0, 0x3b80, 0xfb41, 0x3900, 0xf9c1, 0xf881, 0x3840,\n                     0x2800, 0xe8c1, 0xe981, 0x2940, 0xeb01, 0x2bc0, 0x2a80, 0xea41,\n                     0xee01, 0x2ec0, 0x2f80, 0xef41, 0x2d00, 0xedc1, 0xec81, 0x2c40,\n                     0xe401, 0x24c0, 0x2580, 0xe541, 0x2700, 0xe7c1, 0xe681, 0x2640,\n                     0x2200, 0xe2c1, 0xe381, 0x2340, 0xe101, 0x21c0, 0x2080, 0xe041,\n                     0xa001, 0x60c0, 0x6180, 0xa141, 0x6300, 0xa3c1, 0xa281, 0x6240,\n                     0x6600, 0xa6c1, 0xa781, 0x6740, 0xa501, 0x65c0, 0x6480, 0xa441,\n                     0x6c00, 0xacc1, 0xad81, 0x6d40, 0xaf01, 0x6fc0, 0x6e80, 0xae41,\n                     0xaa01, 0x6ac0, 0x6b80, 0xab41, 0x6900, 0xa9c1, 0xa881, 0x6840,\n                     0x7800, 0xb8c1, 0xb981, 0x7940, 0xbb01, 0x7bc0, 0x7a80, 0xba41,\n                     0xbe01, 0x7ec0, 0x7f80, 0xbf41, 0x7d00, 0xbdc1, 0xbc81, 0x7c40,\n                     0xb401, 0x74c0, 0x7580, 0xb541, 0x7700, 0xb7c1, 0xb681, 0x7640,\n                     0x7200, 0xb2c1, 0xb381, 0x7340, 0xb101, 0x71c0, 0x7080, 0xb041,\n                     0x5000, 0x90c1, 0x9181, 0x5140, 0x9301, 0x53c0, 0x5280, 0x9241,\n                     0x9601, 0x56c0, 0x5780, 0x9741, 0x5500, 0x95c1, 0x9481, 0x5440,\n                     0x9c01, 0x5cc0, 0x5d80, 0x9d41, 0x5f00, 0x9fc1, 0x9e81, 0x5e40,\n                     0x5a00, 0x9ac1, 0x9b81, 0x5b40, 0x9901, 0x59c0, 0x5880, 0x9841,\n                     0x8801, 0x48c0, 0x4980, 0x8941, 0x4b00, 0x8bc1, 0x8a81, 0x4a40,\n                     0x4e00, 0x8ec1, 0x8f81, 0x4f40, 0x8d01, 0x4dc0, 0x4c80, 0x8c41,\n                     0x4400, 0x84c1, 0x8581, 0x4540, 0x8701, 0x47c0, 0x4680, 0x8641,\n                     0x8201, 0x42c0, 0x4380, 0x8341, 0x4100, 0x81c1, 0x8081, 0x4040]\n\n        crc = 0xffff\n        for c in buf:\n            index = (crc ^ ord(c)) & 0xff\n            crct = crc_table[index]\n            crc = (crc >> 8) ^ crct\n        crc = (crc << 8) | (crc >> 8)\n        crc &= 0x7F7F\n\n        return \"%04x\" % crc"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef setMeterPassword(self, new_pwd, pwd=\"00000000\"):\n        result = False\n        self.setContext(\"setMeterPassword\")\n        try:\n            if len(new_pwd) != 8 or len(pwd) != 8:\n                self.writeCmdMsg(\"Passwords must be exactly eight characters.\")\n                self.setContext(\"\")\n                return result\n\n            if not self.request(False):\n                self.writeCmdMsg(\"Pre command read failed: check serial line.\")\n            else:\n                if not self.serialCmdPwdAuth(pwd):\n                    self.writeCmdMsg(\"Password failure\")\n                else:\n                    req_pwd = binascii.hexlify(new_pwd.zfill(8))\n                    req_str = \"015731023030323028\" + req_pwd + \"2903\"\n                    req_str += self.calc_crc16(req_str[2:].decode(\"hex\"))\n                    self.m_serial_port.write(req_str.decode(\"hex\"))\n                    if self.m_serial_port.getResponse(self.getContext()).encode(\"hex\") == \"06\":\n                        self.writeCmdMsg(\"Success(setMeterPassword): 06 returned.\")\n                        result = True\n            self.serialPostEnd()\n        except:\n            ekm_log(traceback.format_exc(sys.exc_info()))\n\n        self.setContext(\"\")\n        return result", "response": "This method is used to set the meter password."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef unpackStruct(self, data, def_buf):\n        struct_str = \"=\"\n        for fld in def_buf:\n            if not def_buf[fld][MeterData.CalculatedFlag]:\n                struct_str = struct_str + str(def_buf[fld][MeterData.SizeValue]) + \"s\"\n        if len(data) == 255:\n            contents = struct.unpack(struct_str, str(data))\n        else:\n            self.writeCmdMsg(\"Length error.  Len() size = \" + str(len(data)))\n            contents = ()\n        return contents", "response": "Wrapper for struct. unpack with field lengths."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert data from raw tuple into scaled and conveted values.", "response": "def convertData(self, contents, def_buf, kwh_scale=ScaleKWH.EmptyScale):\n        \"\"\" Move data from raw tuple into scaled and conveted values.\n\n        Args:\n            contents (tuple): Breakout of passed block from unpackStruct().\n            def_buf (): Read buffer destination.\n            kwh_scale (int):  :class:`~ekmmeters.ScaleKWH` as int, from Field.kWhScale`\n\n        Returns:\n            bool: True on completion.\n        \"\"\"\n        log_str = \"\"\n        count = 0\n        \n        # getting scale does not require a full read.  It does require that the\n        # reads have the scale value in the first block read.  This requirement\n        # is filled by default in V3 and V4 requests\n        if kwh_scale == ScaleKWH.EmptyScale:\n            scale_offset = int(def_buf.keys().index(Field.kWh_Scale))\n            self.m_kwh_precision = kwh_scale = int(contents[scale_offset])\n\n        for fld in def_buf:\n\n            if def_buf[fld][MeterData.CalculatedFlag]:\n                count += 1\n                continue\n\n            if len(contents) == 0:\n                count += 1\n                continue\n\n            try:  # scrub up messes on a field by field basis\n                raw_data = contents[count]\n                fld_type = def_buf[fld][MeterData.TypeValue]\n                fld_scale = def_buf[fld][MeterData.ScaleValue]\n\n                if fld_type == FieldType.Float:\n                    float_data = float(str(raw_data))\n                    divisor = 1\n                    if fld_scale == ScaleType.KWH:\n                        divisor = 1\n                        if kwh_scale == ScaleKWH.Scale10:\n                            divisor = 10\n                        elif kwh_scale == ScaleKWH.Scale100:\n                            divisor = 100\n                        elif (kwh_scale != ScaleKWH.NoScale) and (kwh_scale != ScaleKWH.EmptyScale):\n                            ekm_log(\"Unrecognized kwh scale.\")\n                    elif fld_scale == ScaleType.Div10:\n                        divisor = 10\n                    elif fld_scale == ScaleType.Div100:\n                        divisor = 100\n                    elif fld_scale != ScaleType.No:\n                        ekm_log(\"Unrecognized float scale.\")\n                    float_data /= divisor\n                    float_data_str = str(float_data)\n                    def_buf[fld][MeterData.StringValue] = float_data_str\n                    def_buf[fld][MeterData.NativeValue] = float_data\n\n                elif fld_type == FieldType.Hex:\n                    hex_data = raw_data.encode('hex')\n                    def_buf[fld][MeterData.StringValue] = hex_data\n                    def_buf[fld][MeterData.NativeValue] = hex_data\n\n                elif fld_type == FieldType.Int:\n                    integer_data = int(raw_data)\n                    integer_data_str = str(integer_data)\n                    if len(integer_data_str) == 0:\n                        integer_data_str = str(0)\n                    def_buf[fld][MeterData.StringValue] = integer_data_str\n                    def_buf[fld][MeterData.NativeValue] = integer_data\n\n                elif fld_type == FieldType.String:\n                    string_data = str(raw_data)\n                    def_buf[fld][MeterData.StringValue] = string_data\n                    def_buf[fld][MeterData.NativeValue] = string_data\n\n                elif fld_type == FieldType.PowerFactor:\n                    def_buf[fld][MeterData.StringValue] = str(raw_data)\n                    def_buf[fld][MeterData.NativeValue] = str(raw_data)\n\n                else:\n                    ekm_log(\"Unrecognized field type\")\n\n                log_str = log_str + '\"' + fld + '\":  \"' + def_buf[fld][MeterData.StringValue] + '\"\\n'\n\n            except:\n                ekm_log(\"Exception on Field:\" + str(fld))\n                ekm_log(traceback.format_exc(sys.exc_info()))\n                self.writeCmdMsg(\"Exception on Field:\" + str(fld))\n\n            count += 1\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntranslate the passed serial block into string only JSON.", "response": "def jsonRender(self, def_buf):\n        \"\"\" Translate the passed serial block into string only JSON.\n\n        Args:\n            def_buf (SerialBlock): Any :class:`~ekmmeters.SerialBlock` object.\n\n        Returns:\n            str: JSON rendering of meter record.\n        \"\"\"\n        try:\n            ret_dict = SerialBlock()\n            ret_dict[Field.Meter_Address] = self.getMeterAddress()\n            for fld in def_buf:\n                compare_fld = fld.upper()\n                if not \"RESERVED\" in compare_fld and not \"CRC\" in compare_fld:\n                    ret_dict[str(fld)] = def_buf[fld][MeterData.StringValue]\n        except:\n            ekm_log(traceback.format_exc(sys.exc_info()))\n            return \"\"\n        return json.dumps(ret_dict, indent=4)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef crcMeterRead(self, raw_read, def_buf):\n        try:\n            if len(raw_read) == 0:\n                ekm_log(\"(\" + self.m_context + \") Empty return read.\")\n                return False\n            sent_crc = self.calc_crc16(raw_read[1:-2])\n            logstr = \"(\" + self.m_context + \")CRC sent = \" + str(def_buf[\"crc16\"][MeterData.StringValue])\n            logstr += \" CRC calc = \" + sent_crc\n            ekm_log(logstr)\n            if int(def_buf[\"crc16\"][MeterData.StringValue], 16) == int(sent_crc, 16):\n                return True\n\n        # A cross simple test lines on a USB serial adapter, these occur every\n        # 1000 to 2000 reads, and they show up here as a bad unpack or\n        # a bad crc type call.  In either case, we suppress them a log will\n        # become quite large.  ekmcrc errors come through as type errors.\n        # Failures of int type conversion in 16 bit conversion occur as value\n        # errors.\n        except struct.error:\n            ekm_log(str(sys.exc_info()))\n            for frame in traceback.extract_tb(sys.exc_info()[2]):\n                fname, lineno, fn, text = frame\n                ekm_log(\"Error in %s on line %d\" % (fname, lineno))\n            return False\n\n        except TypeError:\n            ekm_log(str(sys.exc_info()))\n            for frame in traceback.extract_tb(sys.exc_info()[2]):\n                fname, lineno, fn, text = frame\n                ekm_log(\"Error in %s on line %d\" % (fname, lineno))\n            return False\n\n        except ValueError:\n            ekm_log(str(sys.exc_info()))\n            for frame in traceback.extract_tb(sys.exc_info()[2]):\n                fname, lineno, fn, text = frame\n                ekm_log(\"Error in %s on line %d\" % (fname, lineno))\n            return False\n\n        return False", "response": "Internal function to calculate the CRC of a USB serial read."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef splitEkmDate(dateint):\n        date_str = str(dateint)\n        dt = namedtuple('EkmDate', ['yy', 'mm', 'dd', 'weekday', 'hh', 'minutes', 'ss'])\n\n        if len(date_str) != 14:\n            dt.yy = dt.mm = dt.dd = dt.weekday = dt.hh = dt.minutes = dt.ss = 0\n            return dt\n\n        dt.yy = int(date_str[0:2])\n        dt.mm = int(date_str[2:4])\n        dt.dd = int(date_str[4:6])\n        dt.weekday = int(date_str[6:8])\n        dt.hh = int(date_str[8:10])\n        dt.minutes = int(date_str[10:12])\n        dt.ss = int(date_str[12:14])\n        return dt", "response": "Break out a date from Omnimeter read."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove an observer from the meter update chain.", "response": "def unregisterObserver(self, observer):\n        \"\"\" Remove an observer from the meter update() chain.\n\n        Args:\n            observer (MeterObserver): Subclassed MeterObserver.\n        \"\"\"\n        if observer in self.m_observers:\n            self.m_observers.remove(observer)\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef initSchd_1_to_4(self):\n        self.m_schd_1_to_4[\"reserved_40\"] = [6, FieldType.Hex, ScaleType.No, \"\", 0, False, False]\n        self.m_schd_1_to_4[\"Schedule_1_Period_1_Hour\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_1_to_4[\"Schedule_1_Period_1_Min\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_1_to_4[\"Schedule_1_Period_1_Tariff\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_1_to_4[\"Schedule_1_Period_2_Hour\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_1_to_4[\"Schedule_1_Period_2_Min\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_1_to_4[\"Schedule_1_Period_2_Tariff\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_1_to_4[\"Schedule_1_Period_3_Hour\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_1_to_4[\"Schedule_1_Period_3_Min\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_1_to_4[\"Schedule_1_Period_3_Tariff\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_1_to_4[\"Schedule_1_Period_4_Hour\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_1_to_4[\"Schedule_1_Period_4_Min\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_1_to_4[\"Schedule_1_Period_4_Tariff\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_1_to_4[\"reserved_41\"] = [24, FieldType.Hex, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_1_to_4[\"Schedule_2_Period_1_Hour\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_1_to_4[\"Schedule_2_Period_1_Min\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_1_to_4[\"Schedule_2_Period_1_Tariff\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_1_to_4[\"Schedule_2_Period_2_Hour\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_1_to_4[\"Schedule_2_Period_2_Min\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_1_to_4[\"Schedule_2_Period_2_Tariff\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_1_to_4[\"Schedule_2_Period_3_Hour\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_1_to_4[\"Schedule_2_Period_3_Min\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_1_to_4[\"Schedule_2_Period_3_Tariff\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_1_to_4[\"Schedule_2_Period_4_Hour\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_1_to_4[\"Schedule_2_Period_4_Min\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_1_to_4[\"Schedule_2_Period_4_Tariff\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_1_to_4[\"reserved_42\"] = [24, FieldType.Hex, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_1_to_4[\"Schedule_3_Period_1_Hour\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_1_to_4[\"Schedule_3_Period_1_Min\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_1_to_4[\"Schedule_3_Period_1_Tariff\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_1_to_4[\"Schedule_3_Period_2_Hour\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_1_to_4[\"Schedule_3_Period_2_Min\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_1_to_4[\"Schedule_3_Period_2_Tariff\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_1_to_4[\"Schedule_3_Period_3_Hour\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_1_to_4[\"Schedule_3_Period_3_Min\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_1_to_4[\"Schedule_3_Period_3_Tariff\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_1_to_4[\"Schedule_3_Period_4_Hour\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_1_to_4[\"Schedule_3_Period_4_Min\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_1_to_4[\"Schedule_3_Period_4_Tariff\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_1_to_4[\"reserved_43\"] = [24, FieldType.Hex, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_1_to_4[\"Schedule_4_Period_1_Hour\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_1_to_4[\"Schedule_4_Period_1_Min\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_1_to_4[\"Schedule_4_Period_1_Tariff\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_1_to_4[\"Schedule_4_Period_2_Hour\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_1_to_4[\"Schedule_4_Period_2_Min\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_1_to_4[\"Schedule_4_Period_2_Tariff\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_1_to_4[\"Schedule_4_Period_3_Hour\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_1_to_4[\"Schedule_4_Period_3_Min\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_1_to_4[\"Schedule_4_Period_3_Tariff\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_1_to_4[\"Schedule_4_Period_4_Hour\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_1_to_4[\"Schedule_4_Period_4_Min\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_1_to_4[\"Schedule_4_Period_4_Tariff\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_1_to_4[\"reserved_44\"] = [79, FieldType.Hex, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_1_to_4[\"crc16\"] = [2, FieldType.Hex, ScaleType.No, \"\", 0, False, False]\n        pass", "response": "Initialize Schd 1 to 4 schedule."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninitializing second and last tariff schedule.", "response": "def initSchd_5_to_6(self):\n        \"\"\" Initialize second(and last) tariff schedule :class:`~ekmmeters.SerialBlock`. \"\"\"\n        self.m_schd_5_to_6[\"reserved_30\"] = [6, FieldType.Hex, ScaleType.No, \"\", 0, False, False]\n        self.m_schd_5_to_6[\"Schedule_5_Period_1_Hour\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_5_to_6[\"Schedule_5_Period_1_Min\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_5_to_6[\"Schedule_5_Period_1_Tariff\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_5_to_6[\"Schedule_5_Period_2_Hour\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_5_to_6[\"Schedule_5_Period_2_Min\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_5_to_6[\"Schedule_5_Period_2_Tariff\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_5_to_6[\"Schedule_5_Period_3_Hour\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_5_to_6[\"Schedule_5_Period_3_Min\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_5_to_6[\"Schedule_5_Period_3_Tariff\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_5_to_6[\"Schedule_5_Period_4_Hour\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_5_to_6[\"Schedule_5_Period_4_Min\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_5_to_6[\"Schedule_5_Period_4_Tariff\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_5_to_6[\"reserved_31\"] = [24, FieldType.Hex, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_5_to_6[\"Schedule_6_Period_1_Hour\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_5_to_6[\"Schedule_6_Period_1_Min\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_5_to_6[\"Schedule_6_Period_1_Tariff\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_5_to_6[\"Schedule_6_Period_2_Hour\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_5_to_6[\"Schedule_6_Period_2_Min\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_5_to_6[\"Schedule_6_Period_2_Tariff\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_5_to_6[\"Schedule_6_Period_3_Hour\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_5_to_6[\"Schedule_6_Period_3_Min\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_5_to_6[\"Schedule_6_Period_3_Tariff\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_5_to_6[\"Schedule_6_Period_4_Hour\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_5_to_6[\"Schedule_6_Period_4_Min\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_5_to_6[\"Schedule_6_Period_4_Tariff\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_5_to_6[\"reserved_32\"] = [24, FieldType.Hex, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_5_to_6[\"reserved_33\"] = [24, FieldType.Hex, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_5_to_6[\"reserved_34\"] = [24, FieldType.Hex, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_5_to_6[\"reserved_35\"] = [24, FieldType.Hex, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_5_to_6[\"reserved_36\"] = [79, FieldType.Hex, ScaleType.No, \"\", 0, False, True]\n        self.m_schd_5_to_6[\"crc16\"] = [2, FieldType.Hex, ScaleType.No, \"\", 0, False, False]\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getSchedulesBuffer(self, period_group):\n        empty_return = SerialBlock()\n        if period_group == ReadSchedules.Schedules_1_To_4:\n            return self.m_schd_1_to_4\n        elif period_group == ReadSchedules.Schedules_5_To_6:\n            return self.m_schd_5_to_6\n        else:\n            return empty_return", "response": "Returns the requested tariff schedules for the given period group."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef initHldyDates(self):\n        self.m_hldy[\"reserved_20\"] = [6, FieldType.Hex, ScaleType.No, \"\", 0, False, False]\n        self.m_hldy[\"Holiday_1_Mon\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_hldy[\"Holiday_1_Day\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_hldy[\"Holiday_2_Mon\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_hldy[\"Holiday_2_Day\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_hldy[\"Holiday_3_Mon\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_hldy[\"Holiday_3_Day\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_hldy[\"Holiday_4_Mon\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_hldy[\"Holiday_4_Day\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_hldy[\"Holiday_5_Mon\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_hldy[\"Holiday_5_Day\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_hldy[\"Holiday_6_Mon\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_hldy[\"Holiday_6_Day\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_hldy[\"Holiday_7_Mon\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_hldy[\"Holiday_7_Day\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_hldy[\"Holiday_8_Mon\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_hldy[\"Holiday_8_Day\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_hldy[\"Holiday_9_Mon\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_hldy[\"Holiday_9_Day\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_hldy[\"Holiday_10_Mon\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_hldy[\"Holiday_10_Day\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_hldy[\"Holiday_11_Mon\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_hldy[\"Holiday_11_Day\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_hldy[\"Holiday_12_Mon\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_hldy[\"Holiday_12_Day\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_hldy[\"Holiday_13_Mon\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_hldy[\"Holiday_13_Day\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_hldy[\"Holiday_14_Mon\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_hldy[\"Holiday_14_Day\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_hldy[\"Holiday_15_Mon\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_hldy[\"Holiday_15_Day\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_hldy[\"Holiday_16_Mon\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_hldy[\"Holiday_16_Day\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_hldy[\"Holiday_17_Mon\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_hldy[\"Holiday_17_Day\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_hldy[\"Holiday_18_Mon\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_hldy[\"Holiday_18_Day\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_hldy[\"Holiday_19_Mon\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_hldy[\"Holiday_19_Day\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_hldy[\"Holiday_20_Mon\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_hldy[\"Holiday_20_Day\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_hldy[\"Weekend_Schd\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_hldy[\"Holiday_Schd\"] = [2, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_hldy[\"reserved_21\"] = [163, FieldType.Hex, ScaleType.No, \"\", 0, False, False]\n        self.m_hldy[\"crc16\"] = [2, FieldType.Hex, ScaleType.No, \"\", 0, False, False]\n        pass", "response": "Initialize holidays and dates."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ninitializes the month names for the meter", "response": "def initMons(self):\n        \"\"\" Initialize first month tariff :class:`~ekmmeters.SerialBlock` for meter \"\"\"\n        self.m_mons[\"reserved_echo_cmd\"] = [6, FieldType.Hex, ScaleType.No, \"\", 0, False, False]\n        self.m_mons[\"Month_1_Tot\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_mons[\"Month_1_Tariff_1\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_mons[\"Month_1_Tariff_2\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_mons[\"Month_1_Tariff_3\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_mons[\"Month_1_Tariff_4\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_mons[\"Month_2_Tot\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_mons[\"Month_2_Tariff_1\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_mons[\"Month_2_Tariff_2\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_mons[\"Month_2_Tariff_3\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_mons[\"Month_2_Tariff_4\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_mons[\"Month_3_Tot\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_mons[\"Month_3_Tariff_1\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_mons[\"Month_3_Tariff_2\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_mons[\"Month_3_Tariff_3\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_mons[\"Month_3_Tariff_4\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_mons[\"Month_4_Tot\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_mons[\"Month_4_Tariff_1\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_mons[\"Month_4_Tariff_2\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_mons[\"Month_4_Tariff_3\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_mons[\"Month_4_Tariff_4\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_mons[\"Month_5_Tot\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_mons[\"Month_5_Tariff_1\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_mons[\"Month_5_Tariff_2\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_mons[\"Month_5_Tariff_3\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_mons[\"Month_5_Tariff_4\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_mons[\"Month_6_Tot\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_mons[\"Month_6_Tariff_1\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_mons[\"Month_6_Tariff_2\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_mons[\"Month_6_Tariff_3\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_mons[\"Month_6_Tariff_4\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_mons[\"reserved_1\"] = [7, FieldType.Hex, ScaleType.No, \"\", 0, False, False]\n        self.m_mons[\"crc16\"] = [2, FieldType.Hex, ScaleType.No, \"\", 0, False, False]\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ninitializing the RevMons field for the given manufacture.", "response": "def initRevMons(self):\n        \"\"\" Initialize second (and last) month tarifff :class:`~ekmmeters.SerialBlock` for meter. \"\"\"\n        self.m_rev_mons[\"reserved_echo_cmd\"] = [6, FieldType.Hex, ScaleType.No, \"\", 0, False, False]\n        self.m_rev_mons[\"Month_1_Tot\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_rev_mons[\"Month_1_Tariff_1\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_rev_mons[\"Month_1_Tariff_2\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_rev_mons[\"Month_1_Tariff_3\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_rev_mons[\"Month_1_Tariff_4\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_rev_mons[\"Month_2_Tot\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_rev_mons[\"Month_2_Tariff_1\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_rev_mons[\"Month_2_Tariff_2\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_rev_mons[\"Month_2_Tariff_3\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_rev_mons[\"Month_2_Tariff_4\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_rev_mons[\"Month_3_Tot\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_rev_mons[\"Month_3_Tariff_1\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_rev_mons[\"Month_3_Tariff_2\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_rev_mons[\"Month_3_Tariff_3\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_rev_mons[\"Month_3_Tariff_4\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_rev_mons[\"Month_4_Tot\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_rev_mons[\"Month_4_Tariff_1\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_rev_mons[\"Month_4_Tariff_2\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_rev_mons[\"Month_4_Tariff_3\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_rev_mons[\"Month_4_Tariff_4\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_rev_mons[\"Month_5_Tot\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_rev_mons[\"Month_5_Tariff_1\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_rev_mons[\"Month_5_Tariff_2\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_rev_mons[\"Month_5_Tariff_3\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_rev_mons[\"Month_5_Tariff_4\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_rev_mons[\"Month_6_Tot\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_rev_mons[\"Month_6_Tariff_1\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_rev_mons[\"Month_6_Tariff_2\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_rev_mons[\"Month_6_Tariff_3\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_rev_mons[\"Month_6_Tariff_4\"] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_rev_mons[\"reserved_1\"] = [7, FieldType.Hex, ScaleType.No, \"\", 0, False, False]\n        self.m_rev_mons[\"crc16\"] = [2, FieldType.Hex, ScaleType.No, \"\", 0, False, False]\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the months tariffs buffer for the given direction", "response": "def getMonthsBuffer(self, direction):\n        \"\"\" Get the months tariff SerialBlock for meter.\n\n        Args:\n            direction (int): A :class:`~ekmmeters.ReadMonths` value.\n\n        Returns:\n            SerialBlock: Requested months tariffs buffer.\n\n        \"\"\"\n        if direction == ReadMonths.kWhReverse:\n            return self.m_rev_mons\n\n        # default direction == ReadMonths.kWh\n        return self.m_mons"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef setTime(self, yy, mm, dd, hh, minutes, ss, password=\"00000000\"):\n        result = False\n        self.setContext(\"setTime\")\n        try:\n            if mm < 1 or mm > 12:\n                self.writeCmdMsg(\"Month must be between 1 and 12\")\n                self.setContext(\"\")\n                return result\n\n            if dd < 1 or dd > 31:\n                self.writeCmdMsg(\"Day must be between 1 and 31\")\n                self.setContext(\"\")\n                return result\n\n            if hh < 0 or hh > 23:\n                self.writeCmdMsg(\"Hour must be between 0 and 23, inclusive\")\n                self.setContext(\"\")\n                return result\n\n            if minutes < 0 or minutes > 59:\n                self.writeCmdMsg(\"Minutes must be between 0 and 59, inclusive\")\n                self.setContext(\"\")\n                return result\n\n            if ss < 0 or ss > 59:\n                self.writeCmdMsg(\"Seconds must be between 0 and 59, inclusive\")\n                self.setContext(\"\")\n                return result\n\n            if len(password) != 8:\n                self.writeCmdMsg(\"Invalid password length.\")\n                self.setContext(\"\")\n                return result\n\n            if not self.request(False):\n                self.writeCmdMsg(\"Bad read CRC on setting\")\n            else:\n                if not self.serialCmdPwdAuth(password):\n                    self.writeCmdMsg(\"Password failure\")\n                else:\n                    dt_buf = datetime.datetime(int(yy), int(mm), int(dd), int(hh), int(minutes), int(ss))\n                    ekm_log(\"Writing Date and Time \" + dt_buf.strftime(\"%Y-%m-%d %H:%M\"))\n                    dayofweek = dt_buf.date().isoweekday()\n                    ekm_log(\"Calculated weekday \" + str(dayofweek))\n\n                    req_str = \"015731023030363028\"\n                    req_str += binascii.hexlify(str(yy)[-2:])\n                    req_str += binascii.hexlify(str(mm).zfill(2))\n                    req_str += binascii.hexlify(str(dd).zfill(2))\n                    req_str += binascii.hexlify(str(dayofweek).zfill(2))\n                    req_str += binascii.hexlify(str(hh).zfill(2))\n                    req_str += binascii.hexlify(str(minutes).zfill(2))\n                    req_str += binascii.hexlify(str(ss).zfill(2))\n                    req_str += \"2903\"\n                    req_str += self.calc_crc16(req_str[2:].decode(\"hex\"))\n                    self.m_serial_port.write(req_str.decode(\"hex\"))\n                    if self.m_serial_port.getResponse(self.getContext()).encode(\"hex\") == \"06\":\n                        self.writeCmdMsg(\"Success(setTime): 06 returned.\")\n                        result = True\n            self.serialPostEnd()\n        except:\n            ekm_log(traceback.format_exc(sys.exc_info()))\n\n        self.setContext(\"\")\n        return result", "response": "This method is used to set the time of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef setCTRatio(self, new_ct, password=\"00000000\"):\n        ret = False\n        self.setContext(\"setCTRatio\")\n        try:\n            self.clearCmdMsg()\n            if ((new_ct != CTRatio.Amps_100) and (new_ct != CTRatio.Amps_200) and\n                    (new_ct != CTRatio.Amps_400) and (new_ct != CTRatio.Amps_600) and\n                    (new_ct != CTRatio.Amps_800) and (new_ct != CTRatio.Amps_1000) and\n                    (new_ct != CTRatio.Amps_1200) and (new_ct != CTRatio.Amps_1500) and\n                    (new_ct != CTRatio.Amps_2000) and (new_ct != CTRatio.Amps_3000) and\n                    (new_ct != CTRatio.Amps_4000) and (new_ct != CTRatio.Amps_5000)):\n                self.writeCmdMsg(\"Legal CT Ratios: 100, 200, 400, 600, \" +\n                                 \"800, 1000, 1200, 1500, 2000, 3000, 4000 and 5000\")\n                self.setContext(\"\")\n                return ret\n\n            if len(password) != 8:\n                self.writeCmdMsg(\"Invalid password length.\")\n                self.setContext(\"\")\n                return ret\n\n            if not self.request(False):\n                self.writeCmdMsg(\"Bad read CRC on setting\")\n            else:\n                if not self.serialCmdPwdAuth(password):\n                    self.writeCmdMsg(\"Password failure\")\n                else:\n                    req_str = \"015731023030443028\" + binascii.hexlify(str(new_ct).zfill(4)) + \"2903\"\n                    req_str += self.calc_crc16(req_str[2:].decode(\"hex\"))\n                    self.m_serial_port.write(req_str.decode(\"hex\"))\n                    if self.m_serial_port.getResponse(self.getContext()).encode(\"hex\") == \"06\":\n                        self.writeCmdMsg(\"Success(setCTRatio): 06 returned.\")\n                        ret = True\n            self.serialPostEnd()\n\n        except:\n            ekm_log(traceback.format_exc(sys.exc_info()))\n\n        self.setContext(\"\")\n        return ret", "response": "This method is used to set the CT ratio for attached inductive pickup."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef assignSchedule(self, schedule, period, hour, minute, tariff):\n        if ((schedule not in range(Extents.Schedules)) or\n                (period not in range(Extents.Tariffs)) or\n                (hour < 0) or (hour > 23) or (minute < 0) or\n                (minute > 59) or (tariff < 0)):\n            ekm_log(\"Out of bounds in Schedule_\" + str(schedule + 1))\n            return False\n\n        period += 1\n        idx_min = \"Min_\" + str(period)\n        idx_hour = \"Hour_\" + str(period)\n        idx_rate = \"Tariff_\" + str(period)\n        if idx_min not in self.m_schedule_params:\n            ekm_log(\"Incorrect index: \" + idx_min)\n            return False\n        if idx_hour not in self.m_schedule_params:\n            ekm_log(\"Incorrect index: \" + idx_hour)\n            return False\n        if idx_rate not in self.m_schedule_params:\n            ekm_log(\"Incorrect index: \" + idx_rate)\n            return False\n\n        self.m_schedule_params[idx_rate] = tariff\n        self.m_schedule_params[idx_hour] = hour\n        self.m_schedule_params[idx_min] = minute\n        self.m_schedule_params['Schedule'] = schedule\n        return True", "response": "Assign one schedule tariff period to meter bufffer."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef assignSeasonSchedule(self, season, month, day, schedule):\n        season += 1\n        schedule += 1\n        if ((season < 1) or (season > Extents.Seasons) or (schedule < 1) or\n                (schedule > Extents.Schedules) or (month > 12) or (month < 0) or\n                (day < 0) or (day > 31)):\n            ekm_log(\"Out of bounds: month \" + str(month) + \" day \" + str(day) +\n                    \" schedule \" + str(schedule) + \" season \" + str(season))\n            return False\n\n        idx_mon = \"Season_\" + str(season) + \"_Start_Day\"\n        idx_day = \"Season_\" + str(season) + \"_Start_Month\"\n        idx_schedule = \"Season_\" + str(season) + \"_Schedule\"\n        if idx_mon not in self.m_seasons_sched_params:\n            ekm_log(\"Incorrect index: \" + idx_mon)\n            return False\n        if idx_day not in self.m_seasons_sched_params:\n            ekm_log(\"Incorrect index: \" + idx_day)\n            return False\n        if idx_schedule not in self.m_seasons_sched_params:\n            ekm_log(\"Incorrect index: \" + idx_schedule)\n            return False\n\n        self.m_seasons_sched_params[idx_mon] = month\n        self.m_seasons_sched_params[idx_day] = day\n        self.m_seasons_sched_params[idx_schedule] = schedule\n        return True", "response": "Define a single season and assign a schedule to the current season."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef setSeasonSchedules(self, cmd_dict=None, password=\"00000000\"):\n        result = False\n        self.setContext(\"setSeasonSchedules\")\n\n        if not cmd_dict:\n            cmd_dict = self.m_seasons_sched_params\n\n        try:\n            if not self.request(False):\n                self.writeCmdMsg(\"Bad read CRC on setting\")\n            else:\n                if not self.serialCmdPwdAuth(password):\n                    self.writeCmdMsg(\"Password failure\")\n                else:\n                    req_table = \"\"\n                    req_table += binascii.hexlify(str(cmd_dict[\"Season_1_Start_Month\"]).zfill(2))\n                    req_table += binascii.hexlify(str(cmd_dict[\"Season_1_Start_Day\"]).zfill(2))\n                    req_table += binascii.hexlify(str(cmd_dict[\"Season_1_Schedule\"]).zfill(2))\n                    req_table += binascii.hexlify(str(cmd_dict[\"Season_2_Start_Month\"]).zfill(2))\n                    req_table += binascii.hexlify(str(cmd_dict[\"Season_2_Start_Day\"]).zfill(2))\n                    req_table += binascii.hexlify(str(cmd_dict[\"Season_2_Schedule\"]).zfill(2))\n                    req_table += binascii.hexlify(str(cmd_dict[\"Season_3_Start_Month\"]).zfill(2))\n                    req_table += binascii.hexlify(str(cmd_dict[\"Season_3_Start_Day\"]).zfill(2))\n                    req_table += binascii.hexlify(str(cmd_dict[\"Season_3_Schedule\"]).zfill(2))\n                    req_table += binascii.hexlify(str(cmd_dict[\"Season_4_Start_Month\"]).zfill(2))\n                    req_table += binascii.hexlify(str(cmd_dict[\"Season_4_Start_Day\"]).zfill(2))\n                    req_table += binascii.hexlify(str(cmd_dict[\"Season_4_Schedule\"]).zfill(2))\n                    req_table += binascii.hexlify(str(0).zfill(24))\n                    req_str = \"015731023030383028\" + req_table + \"2903\"\n                    req_str += self.calc_crc16(req_str[2:].decode(\"hex\"))\n                    self.m_serial_port.write(req_str.decode(\"hex\"))\n                    if self.m_serial_port.getResponse(self.getContext()).encode(\"hex\") == \"06\":\n                        self.writeCmdMsg(\"Success(setSeasonSchedules): 06 returned.\")\n                        result = True\n            self.serialPostEnd()\n        except:\n            ekm_log(traceback.format_exc(sys.exc_info()))\n\n        self.setContext(\"\")\n        return result", "response": "This function is used to set the seasons table."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef assignHolidayDate(self, holiday, month, day):\n        holiday += 1\n        if (month > 12) or (month < 0) or (day > 31) or (day < 0) or (holiday < 1) or (holiday > Extents.Holidays):\n            ekm_log(\"Out of bounds: month \" + str(month) + \" day \" + str(day) + \" holiday \" + str(holiday))\n            return False\n\n        day_str = \"Holiday_\" + str(holiday) + \"_Day\"\n        mon_str = \"Holiday_\" + str(holiday) + \"_Month\"\n        if day_str not in self.m_holiday_date_params:\n            ekm_log(\"Incorrect index: \" + day_str)\n            return False\n        if mon_str not in self.m_holiday_date_params:\n            ekm_log(\"Incorrect index: \" + mon_str)\n            return False\n        self.m_holiday_date_params[day_str] = day\n        self.m_holiday_date_params[mon_str] = month\n        return True", "response": "Assign a singe holiday day and month to the object buffer."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading the current state of the current Schdian and returns the state of the Schdian.", "response": "def readSchedules(self, tableset):\n        \"\"\" Serial call to read schedule tariffs buffer\n\n        Args:\n            tableset (int): :class:`~ekmmeters.ReadSchedules` buffer to return.\n\n        Returns:\n            bool: True on completion and ACK.\n        \"\"\"\n        self.setContext(\"readSchedules\")\n        try:\n            req_table = binascii.hexlify(str(tableset).zfill(1))\n            req_str = \"01523102303037\" + req_table + \"282903\"\n\n            self.request(False)\n            req_crc = self.calc_crc16(req_str[2:].decode(\"hex\"))\n            req_str += req_crc\n            self.m_serial_port.write(req_str.decode(\"hex\"))\n            raw_ret = self.m_serial_port.getResponse(self.getContext())\n            self.serialPostEnd()\n            return_crc = self.calc_crc16(raw_ret[1:-2])\n\n            if tableset == ReadSchedules.Schedules_1_To_4:\n                unpacked_read = self.unpackStruct(raw_ret, self.m_schd_1_to_4)\n                self.convertData(unpacked_read, self.m_schd_1_to_4, self.m_kwh_precision)\n                if str(return_crc) == str(self.m_schd_1_to_4[\"crc16\"][MeterData.StringValue]):\n                    ekm_log(\"Schedules 1 to 4 CRC success (06 return\")\n                    self.setContext(\"\")\n                    return True\n\n            elif tableset == ReadSchedules.Schedules_5_To_6:\n                unpacked_read = self.unpackStruct(raw_ret, self.m_schd_5_to_6)\n                self.convertData(unpacked_read, self.m_schd_5_to_6, self.m_kwh_precision)\n                if str(return_crc) == str(self.m_schd_5_to_6[\"crc16\"][MeterData.StringValue]):\n                    ekm_log(\"Schedules 5 to 8 CRC success (06 return)\")\n                    self.setContext(\"\")\n                    return True\n        except:\n            ekm_log(traceback.format_exc(sys.exc_info()))\n\n        self.setContext(\"\")\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef extractSchedule(self, schedule, period):\n        ret = namedtuple(\"ret\", [\"Hour\", \"Min\", \"Tariff\", \"Period\", \"Schedule\"])\n        work_table = self.m_schd_1_to_4\n        if Schedules.Schedule_5 <= schedule <= Schedules.Schedule_6:\n            work_table = self.m_schd_5_to_6\n        period += 1\n        schedule += 1\n        ret.Period = str(period)\n        ret.Schedule = str(schedule)\n        if (schedule < 1) or (schedule > Extents.Schedules) or (period < 0) or (period > Extents.Periods):\n            ekm_log(\"Out of bounds: tariff \" + str(period) + \" for schedule \" + str(schedule))\n            ret.Hour = ret.Min = ret.Tariff = str(0)\n            return ret\n\n        idxhr = \"Schedule_\" + str(schedule) + \"_Period_\" + str(period) + \"_Hour\"\n        idxmin = \"Schedule_\" + str(schedule) + \"_Period_\" + str(period) + \"_Min\"\n        idxrate = \"Schedule_\" + str(schedule) + \"_Period_\" + str(period) + \"_Tariff\"\n\n        if idxhr not in work_table:\n            ekm_log(\"Incorrect index: \" + idxhr)\n            ret.Hour = ret.Min = ret.Tariff = str(0)\n            return ret\n\n        if idxmin not in work_table:\n            ekm_log(\"Incorrect index: \" + idxmin)\n            ret.Hour = ret.Min = ret.Tariff = str(0)\n            return ret\n\n        if idxrate not in work_table:\n            ekm_log(\"Incorrect index: \" + idxrate)\n            ret.Hour = ret.Min = ret.Tariff = str(0)\n            return ret\n\n        ret.Hour = work_table[idxhr][MeterData.StringValue]\n        ret.Min = work_table[idxmin][MeterData.StringValue].zfill(2)\n        ret.Tariff = work_table[idxrate][MeterData.StringValue]\n        return ret", "response": "Read a single schedule tariff from meter object buffer."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads a month tariffs block into meter object buffer.", "response": "def readMonthTariffs(self, months_type):\n        \"\"\" Serial call to read month tariffs block into meter object buffer.\n\n        Args:\n            months_type (int): A :class:`~ekmmeters.ReadMonths` value.\n\n        Returns:\n            bool: True on completion.\n        \"\"\"\n        self.setContext(\"readMonthTariffs\")\n        try:\n\n            req_type = binascii.hexlify(str(months_type).zfill(1))\n            req_str = \"01523102303031\" + req_type + \"282903\"\n            work_table = self.m_mons\n            if months_type == ReadMonths.kWhReverse:\n                work_table = self.m_rev_mons\n\n            self.request(False)\n            req_crc = self.calc_crc16(req_str[2:].decode(\"hex\"))\n            req_str += req_crc\n            self.m_serial_port.write(req_str.decode(\"hex\"))\n            raw_ret = self.m_serial_port.getResponse(self.getContext())\n            self.serialPostEnd()\n            unpacked_read = self.unpackStruct(raw_ret, work_table)\n            self.convertData(unpacked_read, work_table, self.m_kwh_precision)\n            return_crc = self.calc_crc16(raw_ret[1:-2])\n            if str(return_crc) == str(work_table[\"crc16\"][MeterData.StringValue]):\n                ekm_log(\"Months CRC success, type = \" + str(req_type))\n                self.setContext(\"\")\n                return True\n        except:\n            ekm_log(traceback.format_exc(sys.exc_info()))\n\n        self.setContext(\"\")\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nextracts the tariff for a single month from the meter object buffer. Args: month (int): A :class:`~ekmmeters.Months` value or range(Extents.Months). Returns: tuple: The eight tariff period totals for month. The return tuple breaks out as follows: ================= ====================================== kWh_Tariff_1 kWh for tariff period 1 over month. kWh_Tariff_2 kWh for tariff period 2 over month kWh_Tariff_3 kWh for tariff period 3 over month kWh_Tariff_4 kWh for tariff period 4 over month kWh_Tot Total kWh over requested month Rev_kWh_Tariff_1 Rev kWh for tariff period 1 over month Rev_kWh_Tariff_3 Rev kWh for tariff period 2 over month Rev_kWh_Tariff_3 Rev kWh for tariff period 3 over month Rev_kWh_Tariff_4 Rev kWh for tariff period 4 over month Rev_kWh_Tot Total Rev kWh over requested month ================= ======================================", "response": "def extractMonthTariff(self, month):\n        \"\"\" Extract the tariff for a single month from the meter object buffer.\n\n        Args:\n            month (int):  A :class:`~ekmmeters.Months` value or range(Extents.Months).\n\n        Returns:\n            tuple: The eight tariff period totals for month. The return tuple breaks out as follows:\n\n            ================= ======================================\n            kWh_Tariff_1      kWh for tariff period 1 over month.\n            kWh_Tariff_2      kWh for tariff period 2 over month\n            kWh_Tariff_3      kWh for tariff period 3 over month\n            kWh_Tariff_4      kWh for tariff period 4 over month\n            kWh_Tot           Total kWh over requested month\n            Rev_kWh_Tariff_1  Rev kWh for tariff period 1 over month\n            Rev_kWh_Tariff_3  Rev kWh for tariff period 2 over month\n            Rev_kWh_Tariff_3  Rev kWh for tariff period 3 over month\n            Rev_kWh_Tariff_4  Rev kWh for tariff period 4 over month\n            Rev_kWh_Tot       Total Rev kWh over requested month\n            ================= ======================================\n\n        \"\"\"\n        ret = namedtuple(\"ret\", [\"Month\", Field.kWh_Tariff_1, Field.kWh_Tariff_2, Field.kWh_Tariff_3,\n                         Field.kWh_Tariff_4, Field.kWh_Tot, Field.Rev_kWh_Tariff_1,\n                         Field.Rev_kWh_Tariff_2, Field.Rev_kWh_Tariff_3,\n                         Field.Rev_kWh_Tariff_4, Field.Rev_kWh_Tot])\n        month += 1\n        ret.Month = str(month)\n        if (month < 1) or (month > Extents.Months):\n            ret.kWh_Tariff_1 = ret.kWh_Tariff_2 = ret.kWh_Tariff_3 = ret.kWh_Tariff_4 = str(0)\n            ret.Rev_kWh_Tariff_1 = ret.Rev_kWh_Tariff_2 = ret.Rev_kWh_Tariff_3 = ret.Rev_kWh_Tariff_4 = str(0)\n            ret.kWh_Tot = ret.Rev_kWh_Tot = str(0)\n            ekm_log(\"Out of range(Extents.Months) month = \" + str(month))\n            return ret\n\n        base_str = \"Month_\" + str(month) + \"_\"\n        ret.kWh_Tariff_1 = self.m_mons[base_str + \"Tariff_1\"][MeterData.StringValue]\n        ret.kWh_Tariff_2 = self.m_mons[base_str + \"Tariff_2\"][MeterData.StringValue]\n        ret.kWh_Tariff_3 = self.m_mons[base_str + \"Tariff_3\"][MeterData.StringValue]\n        ret.kWh_Tariff_4 = self.m_mons[base_str + \"Tariff_4\"][MeterData.StringValue]\n        ret.kWh_Tot = self.m_mons[base_str + \"Tot\"][MeterData.StringValue]\n        ret.Rev_kWh_Tariff_1 = self.m_rev_mons[base_str + \"Tariff_1\"][MeterData.StringValue]\n        ret.Rev_kWh_Tariff_2 = self.m_rev_mons[base_str + \"Tariff_2\"][MeterData.StringValue]\n        ret.Rev_kWh_Tariff_3 = self.m_rev_mons[base_str + \"Tariff_3\"][MeterData.StringValue]\n        ret.Rev_kWh_Tariff_4 = self.m_rev_mons[base_str + \"Tariff_4\"][MeterData.StringValue]\n        ret.Rev_kWh_Tot = self.m_rev_mons[base_str + \"Tot\"][MeterData.StringValue]\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef readHolidayDates(self):\n        self.setContext(\"readHolidayDates\")\n        try:\n            req_str = \"0152310230304230282903\"\n            self.request(False)\n            req_crc = self.calc_crc16(req_str[2:].decode(\"hex\"))\n            req_str += req_crc\n            self.m_serial_port.write(req_str.decode(\"hex\"))\n            raw_ret = self.m_serial_port.getResponse(self.getContext())\n            self.serialPostEnd()\n            unpacked_read = self.unpackStruct(raw_ret, self.m_hldy)\n            self.convertData(unpacked_read, self.m_hldy, self.m_kwh_precision)\n            return_crc = self.calc_crc16(raw_ret[1:-2])\n            if str(return_crc) == str(self.m_hldy[\"crc16\"][MeterData.StringValue]):\n                ekm_log(\"Holidays and Schedules CRC success\")\n                self.setContext(\"\")\n                return True\n        except:\n            ekm_log(traceback.format_exc(sys.exc_info()))\n\n        self.setContext(\"\")\n        return False", "response": "Reads the holiday dates into the meter object buffer."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nread a single holiday date from the meter buffer.", "response": "def extractHolidayDate(self, setting_holiday):\n        \"\"\" Read a single holiday date from meter buffer.\n\n        Args:\n            setting_holiday (int):  Holiday from 0-19 or in range(Extents.Holidays)\n\n        Returns:\n            tuple: Holiday tuple, elements are strings.\n\n            =============== ======================\n            Holiday         Holiday 0-19 as string\n            Day             Day 1-31 as string\n            Month           Monty 1-12 as string\n            =============== ======================\n\n        \"\"\"\n        ret = namedtuple(\"result\", [\"Holiday\", \"Month\", \"Day\"])\n        setting_holiday += 1\n        ret.Holiday = str(setting_holiday)\n\n        if (setting_holiday < 1) or (setting_holiday > Extents.Holidays):\n            ekm_log(\"Out of bounds:  holiday \" + str(setting_holiday))\n            ret.Holiday = ret.Month = ret.Day = str(0)\n            return ret\n\n        idxday = \"Holiday_\" + str(setting_holiday) + \"_Day\"\n        idxmon = \"Holiday_\" + str(setting_holiday) + \"_Mon\"\n        if idxmon not in self.m_hldy:\n            ret.Holiday = ret.Month = ret.Day = str(0)\n            return ret\n        if idxday not in self.m_hldy:\n            ret.Holiday = ret.Month = ret.Day = str(0)\n            return ret\n        ret.Day = self.m_hldy[idxday][MeterData.StringValue]\n        ret.Month = self.m_hldy[idxmon][MeterData.StringValue]\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nextracts holiday and weekend schedules from meter object buffer.", "response": "def extractHolidayWeekendSchedules(self):\n        \"\"\" extract holiday and weekend :class:`~ekmmeters.Schedule` from meter object buffer.\n\n        Returns:\n            tuple: Holiday and weekend :class:`~ekmmeters.Schedule` values, as strings.\n\n            ======= ======================================\n            Holiday :class:`~ekmmeters.Schedule` as string\n            Weekend :class:`~ekmmeters.Schedule` as string\n            ======= ======================================\n\n        \"\"\"\n        result = namedtuple(\"result\", [\"Weekend\", \"Holiday\"])\n        result.Weekend = self.m_hldy[\"Weekend_Schd\"][MeterData.StringValue]\n        result.Holiday = self.m_hldy[\"Holiday_Schd\"][MeterData.StringValue]\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef readSettings(self):\n        success = (self.readHolidayDates() and\n                   self.readMonthTariffs(ReadMonths.kWh) and\n                   self.readMonthTariffs(ReadMonths.kWhReverse) and\n                   self.readSchedules(ReadSchedules.Schedules_1_To_4) and\n                   self.readSchedules(ReadSchedules.Schedules_5_To_6))\n        return success", "response": "Recommended call to read all meter settings at once."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef serialCmdPwdAuth(self, password_str):\n        result = False\n        try:\n            req_start = \"0150310228\" + binascii.hexlify(password_str) + \"2903\"\n            req_crc = self.calc_crc16(req_start[2:].decode(\"hex\"))\n            req_str = req_start + req_crc\n            self.m_serial_port.write(req_str.decode(\"hex\"))\n            if self.m_serial_port.getResponse(self.getContext()).encode(\"hex\") == \"06\":\n                ekm_log(\"Password accepted (\" + self.getContext() + \")\")\n                result = True\n            else:\n                ekm_log(\"Password call failure no 06(\" + self.getContext() + \")\")\n        except:\n            ekm_log(\"Password call failure by exception(\" + self.getContext() + \")\")\n\n            ekm_log(traceback.format_exc(sys.exc_info()))\n\n        return result", "response": "This method is used to set the password of a specific user in a specific serial command."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef initWorkFormat(self):\n        self.m_blk_a[\"reserved_10\"] = [1, FieldType.Hex, ScaleType.No, \"\", 0, False, False]\n        self.m_blk_a[Field.Model] = [2, FieldType.Hex, ScaleType.No, \"\", 0, False, True]\n        self.m_blk_a[Field.Firmware] = [1, FieldType.Hex, ScaleType.No, \"\", 0, False, True]\n        self.m_blk_a[Field.Meter_Address] = [12, FieldType.String, ScaleType.No, \"\", 0, False, True]\n        self.m_blk_a[Field.kWh_Tot] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_blk_a[Field.kWh_Tariff_1] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_blk_a[Field.kWh_Tariff_2] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_blk_a[Field.kWh_Tariff_3] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_blk_a[Field.kWh_Tariff_4] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_blk_a[Field.Rev_kWh_Tot] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_blk_a[Field.Rev_kWh_Tariff_1] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_blk_a[Field.Rev_kWh_Tariff_2] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_blk_a[Field.Rev_kWh_Tariff_3] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_blk_a[Field.Rev_kWh_Tariff_4] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_blk_a[Field.RMS_Volts_Ln_1] = [4, FieldType.Float, ScaleType.Div10, \"\", 0, False, False]\n        self.m_blk_a[Field.RMS_Volts_Ln_2] = [4, FieldType.Float, ScaleType.Div10, \"\", 0, False, False]\n        self.m_blk_a[Field.RMS_Volts_Ln_3] = [4, FieldType.Float, ScaleType.Div10, \"\", 0, False, False]\n        self.m_blk_a[Field.Amps_Ln_1] = [5, FieldType.Float, ScaleType.Div10, \"\", 0, False, False]\n        self.m_blk_a[Field.Amps_Ln_2] = [5, FieldType.Float, ScaleType.Div10, \"\", 0, False, False]\n        self.m_blk_a[Field.Amps_Ln_3] = [5, FieldType.Float, ScaleType.Div10, \"\", 0, False, False]\n        self.m_blk_a[Field.RMS_Watts_Ln_1] = [7, FieldType.Int, ScaleType.No, \"\", 0, False, False]\n        self.m_blk_a[Field.RMS_Watts_Ln_2] = [7, FieldType.Int, ScaleType.No, \"\", 0, False, False]\n        self.m_blk_a[Field.RMS_Watts_Ln_3] = [7, FieldType.Int, ScaleType.No, \"\", 0, False, False]\n        self.m_blk_a[Field.RMS_Watts_Tot] = [7, FieldType.Int, ScaleType.No, \"\", 0, False, False]\n        self.m_blk_a[Field.Cos_Theta_Ln_1] = [4, FieldType.PowerFactor, ScaleType.No, \"\", 0, False, False]\n        self.m_blk_a[Field.Cos_Theta_Ln_2] = [4, FieldType.PowerFactor, ScaleType.No, \"\", 0, False, False]\n        self.m_blk_a[Field.Cos_Theta_Ln_3] = [4, FieldType.PowerFactor, ScaleType.No, \"\", 0, False, False]\n        self.m_blk_a[Field.Max_Demand] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, True]\n        self.m_blk_a[Field.Max_Demand_Period] = [1, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_blk_a[Field.Meter_Time] = [14, FieldType.String, ScaleType.No, \"\", 0, False, False]\n        self.m_blk_a[Field.CT_Ratio] = [4, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_blk_a[Field.Pulse_Cnt_1] = [8, FieldType.Int, ScaleType.No, \"\", 0, False, False]\n        self.m_blk_a[Field.Pulse_Cnt_2] = [8, FieldType.Int, ScaleType.No, \"\", 0, False, False]\n        self.m_blk_a[Field.Pulse_Cnt_3] = [8, FieldType.Int, ScaleType.No, \"\", 0, False, False]\n        self.m_blk_a[Field.Pulse_Ratio_1] = [4, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_blk_a[Field.Pulse_Ratio_2] = [4, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_blk_a[Field.Pulse_Ratio_3] = [4, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_blk_a[Field.State_Inputs] = [3, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_blk_a[\"reserved_11\"] = [19, FieldType.Hex, ScaleType.No, \"\", 0, False, False]\n        self.m_blk_a[Field.Status_A] = [1, FieldType.Hex, ScaleType.No, \"\", 0, False, False]\n        self.m_blk_a[\"reserved_12\"] = [4, FieldType.Hex, ScaleType.No, \"\", 0, False, False]\n        self.m_blk_a[\"crc16\"] = [2, FieldType.Hex, ScaleType.No, \"\", 0, False, False]\n        self.m_blk_a[Field.Power_Factor_Ln_1] = [4, FieldType.Int, ScaleType.No, \"0\", 0, True, False]\n        self.m_blk_a[Field.Power_Factor_Ln_2] = [4, FieldType.Int, ScaleType.No, \"0\", 0, True, False]\n        self.m_blk_a[Field.Power_Factor_Ln_3] = [4, FieldType.Int, ScaleType.No, \"0\", 0, True, False]", "response": "Initialize the work format of the current thread."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef request(self, send_terminator = False):\n        self.m_a_crc = False\n        start_context = self.getContext()\n        self.setContext(\"request[v3A]\")\n        try:\n            self.m_serial_port.write(\"2f3f\".decode(\"hex\") +\n                                     self.m_meter_address +\n                                     \"210d0a\".decode(\"hex\"))\n            self.m_raw_read_a = self.m_serial_port.getResponse(self.getContext())\n            unpacked_read_a = self.unpackStruct(self.m_raw_read_a, self.m_blk_a)\n            self.convertData(unpacked_read_a, self.m_blk_a, 1)\n            self.m_a_crc = self.crcMeterRead(self.m_raw_read_a, self.m_blk_a)\n            if send_terminator:\n                self.serialPostEnd()\n            self.calculateFields()\n            self.makeReturnFormat()\n        except:\n            ekm_log(traceback.format_exc(sys.exc_info()))\n\n        self.setContext(start_context)\n        return self.m_a_crc", "response": "This method is used to send a request to the most recent read."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef makeReturnFormat(self):\n        for fld in self.m_blk_a:\n            compare_fld = fld.upper()\n            if not \"RESERVED\" in compare_fld and not \"CRC\" in compare_fld:\n                self.m_req[fld] = self.m_blk_a[fld]\n        pass", "response": "Make the format of the return data."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninserting to meter DB.", "response": "def insert(self, meter_db):\n        \"\"\" Insert to :class:`~ekmmeters.MeterDB`  subclass.\n\n        Please note MeterDB subclassing is only for simplest-case.\n\n        Args:\n            meter_db (MeterDB): Instance of subclass of MeterDB.\n        \"\"\"\n        if meter_db:\n            meter_db.dbInsert(self.m_req, self.m_raw_read_a, self.m_raw_read_b)\n        else:\n            ekm_log(\"Attempt to insert when no MeterDB assigned.\")\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfires update method in all attached observers in order of attachment.", "response": "def updateObservers(self):\n        \"\"\" Fire update method in all attached observers in order of attachment. \"\"\"\n        for observer in self.m_observers:\n            try:\n                observer.update(self.m_req)\n            except:\n                ekm_log(traceback.format_exc(sys.exc_info()))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getField(self, fld_name):\n        result = \"\"\n        if fld_name in self.m_req:\n            result = self.m_req[fld_name][MeterData.StringValue]\n        else:\n            ekm_log(\"Requested nonexistent field: \" + fld_name)\n\n        return result", "response": "Return the value of a given field in the current object."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ninitializes A read field.", "response": "def initFormatA(self):\n        \"\"\" Initialize A read :class:`~ekmmeters.SerialBlock`.\"\"\"\n        self.m_blk_a[\"reserved_1\"] = [1, FieldType.Hex, ScaleType.No, \"\", 0, False, False]\n        self.m_blk_a[Field.Model] = [2, FieldType.Hex, ScaleType.No, \"\", 0, False, True]\n        self.m_blk_a[Field.Firmware] = [1, FieldType.Hex, ScaleType.No, \"\", 0, False, True]\n        self.m_blk_a[Field.Meter_Address] = [12, FieldType.String, ScaleType.No, \"\", 0, False, True]\n        self.m_blk_a[Field.kWh_Tot] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_blk_a[Field.Reactive_Energy_Tot] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_blk_a[Field.Rev_kWh_Tot] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_blk_a[Field.kWh_Ln_1] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_blk_a[Field.kWh_Ln_2] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_blk_a[Field.kWh_Ln_3] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_blk_a[Field.Rev_kWh_Ln_1] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_blk_a[Field.Rev_kWh_Ln_2] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_blk_a[Field.Rev_kWh_Ln_3] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_blk_a[Field.Resettable_kWh_Tot] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_blk_a[Field.Resettable_Rev_kWh_Tot] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_blk_a[Field.RMS_Volts_Ln_1] = [4, FieldType.Float, ScaleType.Div10, \"\", 0, False, False]\n        self.m_blk_a[Field.RMS_Volts_Ln_2] = [4, FieldType.Float, ScaleType.Div10, \"\", 0, False, False]\n        self.m_blk_a[Field.RMS_Volts_Ln_3] = [4, FieldType.Float, ScaleType.Div10, \"\", 0, False, False]\n        self.m_blk_a[Field.Amps_Ln_1] = [5, FieldType.Float, ScaleType.Div10, \"\", 0, False, False]\n        self.m_blk_a[Field.Amps_Ln_2] = [5, FieldType.Float, ScaleType.Div10, \"\", 0, False, False]\n        self.m_blk_a[Field.Amps_Ln_3] = [5, FieldType.Float, ScaleType.Div10, \"\", 0, False, False]\n        self.m_blk_a[Field.RMS_Watts_Ln_1] = [7, FieldType.Int, ScaleType.No, \"\", 0, False, False]\n        self.m_blk_a[Field.RMS_Watts_Ln_2] = [7, FieldType.Int, ScaleType.No, \"\", 0, False, False]\n        self.m_blk_a[Field.RMS_Watts_Ln_3] = [7, FieldType.Int, ScaleType.No, \"\", 0, False, False]\n        self.m_blk_a[Field.RMS_Watts_Tot] = [7, FieldType.Int, ScaleType.No, \"\", 0, False, False]\n        self.m_blk_a[Field.Cos_Theta_Ln_1] = [4, FieldType.PowerFactor, ScaleType.No, \"\", 0, False, False]\n        self.m_blk_a[Field.Cos_Theta_Ln_2] = [4, FieldType.PowerFactor, ScaleType.No, \"\", 0, False, False]\n        self.m_blk_a[Field.Cos_Theta_Ln_3] = [4, FieldType.PowerFactor, ScaleType.No, \"\", 0, False, False]\n        self.m_blk_a[Field.Reactive_Pwr_Ln_1] = [7, FieldType.Int, ScaleType.No, \"\", 0, False, False]\n        self.m_blk_a[Field.Reactive_Pwr_Ln_2] = [7, FieldType.Int, ScaleType.No, \"\", 0, False, False]\n        self.m_blk_a[Field.Reactive_Pwr_Ln_3] = [7, FieldType.Int, ScaleType.No, \"\", 0, False, False]\n        self.m_blk_a[Field.Reactive_Pwr_Tot] = [7, FieldType.Int, ScaleType.No, \"\", 0, False, False]\n        self.m_blk_a[Field.Line_Freq] = [4, FieldType.Float, ScaleType.Div100, \"\", 0, False, False]\n        self.m_blk_a[Field.Pulse_Cnt_1] = [8, FieldType.Int, ScaleType.No, \"\", 0, False, False]\n        self.m_blk_a[Field.Pulse_Cnt_2] = [8, FieldType.Int, ScaleType.No, \"\", 0, False, False]\n        self.m_blk_a[Field.Pulse_Cnt_3] = [8, FieldType.Int, ScaleType.No, \"\", 0, False, False]\n        self.m_blk_a[Field.State_Inputs] = [1, FieldType.Int, ScaleType.No, \"\", 0, False, False]\n        self.m_blk_a[Field.State_Watts_Dir] = [1, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_blk_a[Field.State_Out] = [1, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_blk_a[Field.kWh_Scale] = [1, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_blk_a[\"reserved_2\"] = [2, FieldType.Hex, ScaleType.No, \"\", 0, False, False]\n        self.m_blk_a[Field.Meter_Time] = [14, FieldType.String, ScaleType.No, \"\", 0, False, False]\n        self.m_blk_a[\"reserved_3\"] = [2, FieldType.Hex, ScaleType.No, \"\", 0, False, False]\n        self.m_blk_a[\"reserved_4\"] = [4, FieldType.Hex, ScaleType.No, \"\", 0, False, False]\n        self.m_blk_a[\"crc16\"] = [2, FieldType.Hex, ScaleType.No, \"\", 0, False, False]\n        self.m_blk_a[Field.Power_Factor_Ln_1] = [4, FieldType.Int, ScaleType.No, \"0\", 0, True, False]\n        self.m_blk_a[Field.Power_Factor_Ln_2] = [4, FieldType.Int, ScaleType.No, \"0\", 0, True, False]\n        self.m_blk_a[Field.Power_Factor_Ln_3] = [4, FieldType.Int, ScaleType.No, \"0\", 0, True, False]\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninitialize the format B field.", "response": "def initFormatB(self):\n        \"\"\" Initialize B read :class:`~ekmmeters.SerialBlock`.\"\"\"\n        self.m_blk_b[\"reserved_5\"] = [1, FieldType.Hex, ScaleType.No, \"\", 0, False, False]\n        self.m_blk_b[Field.Model] = [2, FieldType.Hex, ScaleType.No, \"\", 0, False, True]\n        self.m_blk_b[Field.Firmware] = [1, FieldType.Hex, ScaleType.No, \"\", 0, False, True]\n        self.m_blk_b[Field.Meter_Address] = [12, FieldType.String, ScaleType.No, \"\", 0, False, True]\n        self.m_blk_b[Field.kWh_Tariff_1] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_blk_b[Field.kWh_Tariff_2] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_blk_b[Field.kWh_Tariff_3] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_blk_b[Field.kWh_Tariff_4] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_blk_b[Field.Rev_kWh_Tariff_1] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_blk_b[Field.Rev_kWh_Tariff_2] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_blk_b[Field.Rev_kWh_Tariff_3] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_blk_b[Field.Rev_kWh_Tariff_4] = [8, FieldType.Float, ScaleType.KWH, \"\", 0, False, False]\n        self.m_blk_b[Field.RMS_Volts_Ln_1] = [4, FieldType.Float, ScaleType.Div10, \"\", 0, False, False]\n        self.m_blk_b[Field.RMS_Volts_Ln_2] = [4, FieldType.Float, ScaleType.Div10, \"\", 0, False, False]\n        self.m_blk_b[Field.RMS_Volts_Ln_3] = [4, FieldType.Float, ScaleType.Div10, \"\", 0, False, False]\n        self.m_blk_b[Field.Amps_Ln_1] = [5, FieldType.Float, ScaleType.Div10, \"\", 0, False, False]\n        self.m_blk_b[Field.Amps_Ln_2] = [5, FieldType.Float, ScaleType.Div10, \"\", 0, False, False]\n        self.m_blk_b[Field.Amps_Ln_3] = [5, FieldType.Float, ScaleType.Div10, \"\", 0, False, False]\n        self.m_blk_b[Field.RMS_Watts_Ln_1] = [7, FieldType.Int, ScaleType.No, \"\", 0, False, False]\n        self.m_blk_b[Field.RMS_Watts_Ln_2] = [7, FieldType.Int, ScaleType.No, \"\", 0, False, False]\n        self.m_blk_b[Field.RMS_Watts_Ln_3] = [7, FieldType.Int, ScaleType.No, \"\", 0, False, False]\n        self.m_blk_b[Field.RMS_Watts_Tot] = [7, FieldType.Int, ScaleType.No, \"\", 0, False, False]\n        self.m_blk_b[Field.Cos_Theta_Ln_1] = [4, FieldType.PowerFactor, ScaleType.No, \"\", 0, False, False]\n        self.m_blk_b[Field.Cos_Theta_Ln_2] = [4, FieldType.PowerFactor, ScaleType.No, \"\", 0, False, False]\n        self.m_blk_b[Field.Cos_Theta_Ln_3] = [4, FieldType.PowerFactor, ScaleType.No, \"\", 0, False, False]\n        self.m_blk_b[Field.RMS_Watts_Max_Demand] = [8, FieldType.Float, ScaleType.Div10, \"\", 0, False, False]\n        self.m_blk_b[Field.Max_Demand_Period] = [1, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_blk_b[Field.Pulse_Ratio_1] = [4, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_blk_b[Field.Pulse_Ratio_2] = [4, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_blk_b[Field.Pulse_Ratio_3] = [4, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_blk_b[Field.CT_Ratio] = [4, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_blk_b[Field.Max_Demand_Interval_Reset] = [1, FieldType.Int, ScaleType.No, \"\", 0, False, False]\n        self.m_blk_b[Field.Pulse_Output_Ratio] = [4, FieldType.Int, ScaleType.No, \"\", 0, False, True]\n        self.m_blk_b[\"reserved_7\"] = [53, FieldType.Hex, ScaleType.No, \"\", 0, False, False]\n        self.m_blk_b[Field.Status_A] = [1, FieldType.Hex, ScaleType.No, \"\", 0, False, True]\n        self.m_blk_b[Field.Status_B] = [1, FieldType.Hex, ScaleType.No, \"\", 0, False, True]\n        self.m_blk_b[Field.Status_C] = [1, FieldType.Hex, ScaleType.No, \"\", 0, False, True]\n        self.m_blk_b[Field.Meter_Time] = [14, FieldType.String, ScaleType.No, \"\", 0, False, False]\n        self.m_blk_b[\"reserved_8\"] = [2, FieldType.Hex, ScaleType.No, \"\", 0, False, False]\n        self.m_blk_b[\"reserved_9\"] = [4, FieldType.Hex, ScaleType.No, \"\", 0, False, False]\n        self.m_blk_b[\"crc16\"] = [2, FieldType.Hex, ScaleType.No, \"\", 0, False, False]\n        self.m_blk_b[Field.Net_Calc_Watts_Ln_1] = [7, FieldType.Int, ScaleType.No, \"0\", 0, True, False]\n        self.m_blk_b[Field.Net_Calc_Watts_Ln_2] = [7, FieldType.Int, ScaleType.No, \"0\", 0, True, False]\n        self.m_blk_b[Field.Net_Calc_Watts_Ln_3] = [7, FieldType.Int, ScaleType.No, \"0\", 0, True, False]\n        self.m_blk_b[Field.Net_Calc_Watts_Tot] = [7, FieldType.Int, ScaleType.No, \"0\", 0, True, False]\n        self.m_blk_b[Field.Power_Factor_Ln_1] = [4, FieldType.Int, ScaleType.No, \"0\", 0, True, False]\n        self.m_blk_b[Field.Power_Factor_Ln_2] = [4, FieldType.Int, ScaleType.No, \"0\", 0, True, False]\n        self.m_blk_b[Field.Power_Factor_Ln_3] = [4, FieldType.Int, ScaleType.No, \"0\", 0, True, False]\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninitializing the lookup table for the given class", "response": "def initLcdLookup(self):\n        \"\"\" Initialize lookup table for string input of LCD fields \"\"\"\n        self.m_lcd_lookup[\"kWh_Tot\"] = LCDItems.kWh_Tot\n        self.m_lcd_lookup[\"Rev_kWh_Tot\"] = LCDItems.Rev_kWh_Tot\n        self.m_lcd_lookup[\"RMS_Volts_Ln_1\"] = LCDItems.RMS_Volts_Ln_1\n        self.m_lcd_lookup[\"RMS_Volts_Ln_2\"] = LCDItems.RMS_Volts_Ln_2\n        self.m_lcd_lookup[\"RMS_Volts_Ln_3\"] = LCDItems.RMS_Volts_Ln_3\n        self.m_lcd_lookup[\"Amps_Ln_1\"] = LCDItems.Amps_Ln_1\n        self.m_lcd_lookup[\"Amps_Ln_2\"] = LCDItems.Amps_Ln_2\n        self.m_lcd_lookup[\"Amps_Ln_3\"] = LCDItems.Amps_Ln_3\n        self.m_lcd_lookup[\"RMS_Watts_Ln_1\"] = LCDItems.RMS_Watts_Ln_1\n        self.m_lcd_lookup[\"RMS_Watts_Ln_2\"] = LCDItems.RMS_Watts_Ln_2\n        self.m_lcd_lookup[\"RMS_Watts_Ln_3\"] = LCDItems.RMS_Watts_Ln_3\n        self.m_lcd_lookup[\"RMS_Watts_Tot\"] = LCDItems.RMS_Watts_Tot\n        self.m_lcd_lookup[\"Power_Factor_Ln_1\"] = LCDItems.Power_Factor_Ln_1\n        self.m_lcd_lookup[\"Power_Factor_Ln_2\"] = LCDItems.Power_Factor_Ln_2\n        self.m_lcd_lookup[\"Power_Factor_Ln_3\"] = LCDItems.Power_Factor_Ln_3\n        self.m_lcd_lookup[\"kWh_Tariff_1\"] = LCDItems.kWh_Tariff_1\n        self.m_lcd_lookup[\"kWh_Tariff_2\"] = LCDItems.kWh_Tariff_2\n        self.m_lcd_lookup[\"kWh_Tariff_3\"] = LCDItems.kWh_Tariff_3\n        self.m_lcd_lookup[\"kWh_Tariff_4\"] = LCDItems.kWh_Tariff_4\n        self.m_lcd_lookup[\"Rev_kWh_Tariff_1\"] = LCDItems.Rev_kWh_Tariff_1\n        self.m_lcd_lookup[\"Rev_kWh_Tariff_2\"] = LCDItems.Rev_kWh_Tariff_2\n        self.m_lcd_lookup[\"Rev_kWh_Tariff_3\"] = LCDItems.Rev_kWh_Tariff_3\n        self.m_lcd_lookup[\"Rev_kWh_Tariff_4\"] = LCDItems.Rev_kWh_Tariff_4\n        self.m_lcd_lookup[\"Reactive_Pwr_Ln_1\"] = LCDItems.Reactive_Pwr_Ln_1\n        self.m_lcd_lookup[\"Reactive_Pwr_Ln_2\"] = LCDItems.Reactive_Pwr_Ln_2\n        self.m_lcd_lookup[\"Reactive_Pwr_Ln_3\"] = LCDItems.Reactive_Pwr_Ln_3\n        self.m_lcd_lookup[\"Reactive_Pwr_Tot\"] = LCDItems.Reactive_Pwr_Tot\n        self.m_lcd_lookup[\"Line_Freq\"] = LCDItems.Line_Freq\n        self.m_lcd_lookup[\"Pulse_Cnt_1\"] = LCDItems.Pulse_Cnt_1\n        self.m_lcd_lookup[\"Pulse_Cnt_2\"] = LCDItems.Pulse_Cnt_2\n        self.m_lcd_lookup[\"Pulse_Cnt_3\"] = LCDItems.Pulse_Cnt_3\n        self.m_lcd_lookup[\"kWh_Ln_1\"] = LCDItems.kWh_Ln_1\n        self.m_lcd_lookup[\"Rev_kWh_Ln_1\"] = LCDItems.Rev_kWh_Ln_1\n        self.m_lcd_lookup[\"kWh_Ln_2\"] = LCDItems.kWh_Ln_2\n        self.m_lcd_lookup[\"Rev_kWh_Ln_2\"] = LCDItems.Rev_kWh_Ln_2\n        self.m_lcd_lookup[\"kWh_Ln_3\"] = LCDItems.kWh_Ln_3\n        self.m_lcd_lookup[\"Rev_kWh_Ln_3\"] = LCDItems.Rev_kWh_Ln_3\n        self.m_lcd_lookup[\"Reactive_Energy_Tot\"] = LCDItems.Reactive_Energy_Tot\n        self.m_lcd_lookup[\"Max_Demand_Rst\"] = LCDItems.Max_Demand_Rst\n        self.m_lcd_lookup[\"Rev_kWh_Rst\"] = LCDItems.Rev_kWh_Rst\n        self.m_lcd_lookup[\"State_Inputs\"] = LCDItems.State_Inputs\n        self.m_lcd_lookup[\"Max_Demand\"] = LCDItems.Max_Demand"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef request(self, send_terminator = False):\n        try:\n            retA = self.requestA()\n            retB = self.requestB()\n            if retA and retB:\n                self.makeAB()\n                self.calculateFields()\n                self.updateObservers()\n                return True\n        except:\n            ekm_log(traceback.format_exc(sys.exc_info()))\n\n        return False", "response": "Request A and B for a V4 meter."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nissuing an A read on V4 meter.", "response": "def requestA(self):\n        \"\"\"Issue an A read on V4 meter.\n\n        Returns:\n            bool: True if CRC match at end of call.\n        \"\"\"\n        work_context = self.getContext()\n        self.setContext(\"request[v4A]\")\n        self.m_serial_port.write(\"2f3f\".decode(\"hex\") + self.m_meter_address + \"3030210d0a\".decode(\"hex\"))\n        self.m_raw_read_a = self.m_serial_port.getResponse(self.getContext())\n        unpacked_read_a = self.unpackStruct(self.m_raw_read_a, self.m_blk_a)\n        self.convertData(unpacked_read_a, self.m_blk_a)\n        self.m_kwh_precision = int(self.m_blk_a[Field.kWh_Scale][MeterData.NativeValue])\n        self.m_a_crc = self.crcMeterRead(self.m_raw_read_a, self.m_blk_a)\n        self.setContext(work_context)\n        return self.m_a_crc"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nissuing a B read on the V4 meter.", "response": "def requestB(self):\n        \"\"\" Issue a B read on V4 meter.\n\n        Returns:\n            bool: True if CRC match at end of call.\n        \"\"\"\n        work_context = self.getContext()\n        self.setContext(\"request[v4B]\")\n        self.m_serial_port.write(\"2f3f\".decode(\"hex\") + self.m_meter_address + \"3031210d0a\".decode(\"hex\"))\n        self.m_raw_read_b = self.m_serial_port.getResponse(self.getContext())\n        unpacked_read_b = self.unpackStruct(self.m_raw_read_b, self.m_blk_b)\n        self.convertData(unpacked_read_b, self.m_blk_b, self.m_kwh_precision)\n        self.m_b_crc = self.crcMeterRead(self.m_raw_read_b, self.m_blk_b)\n        self.setContext(work_context)\n        return self.m_b_crc"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef makeAB(self):\n        for fld in self.m_blk_a:\n            compare_fld = fld.upper()\n            if not \"RESERVED\" in compare_fld and not \"CRC\" in compare_fld:\n                self.m_req[fld] = self.m_blk_a[fld]\n        for fld in self.m_blk_b:\n            compare_fld = fld.upper()\n            if not \"RESERVED\" in compare_fld and not \"CRC\" in compare_fld:\n                self.m_req[fld] = self.m_blk_b[fld]\n        pass", "response": "Munge A and B reads into single serial block with only unique fields."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwrites calculated fields for read buffer.", "response": "def calculateFields(self):\n        \"\"\"Write calculated fields for read buffer.\"\"\"\n        pf1 = self.m_blk_b[Field.Cos_Theta_Ln_1][MeterData.StringValue]\n        pf2 = self.m_blk_b[Field.Cos_Theta_Ln_2][MeterData.StringValue]\n        pf3 = self.m_blk_b[Field.Cos_Theta_Ln_3][MeterData.StringValue]\n\n        pf1_int = self.calcPF(pf1)\n        pf2_int = self.calcPF(pf2)\n        pf3_int = self.calcPF(pf3)\n\n        self.m_blk_b[Field.Power_Factor_Ln_1][MeterData.StringValue] = str(pf1_int)\n        self.m_blk_b[Field.Power_Factor_Ln_2][MeterData.StringValue] = str(pf2_int)\n        self.m_blk_b[Field.Power_Factor_Ln_3][MeterData.StringValue] = str(pf3_int)\n\n        self.m_blk_b[Field.Power_Factor_Ln_1][MeterData.NativeValue] = pf1_int\n        self.m_blk_b[Field.Power_Factor_Ln_2][MeterData.NativeValue] = pf2_int\n        self.m_blk_b[Field.Power_Factor_Ln_3][MeterData.NativeValue] = pf2_int\n\n        rms_watts_1 = self.m_blk_b[Field.RMS_Watts_Ln_1][MeterData.NativeValue]\n        rms_watts_2 = self.m_blk_b[Field.RMS_Watts_Ln_2][MeterData.NativeValue]\n        rms_watts_3 = self.m_blk_b[Field.RMS_Watts_Ln_3][MeterData.NativeValue]\n\n        sign_rms_watts_1 = 1\n        sign_rms_watts_2 = 1\n        sign_rms_watts_3 = 1\n\n        direction_byte = self.m_blk_a[Field.State_Watts_Dir][MeterData.NativeValue]\n\n        if direction_byte == DirectionFlag.ForwardForwardForward:\n            # all good\n            pass\n        if direction_byte == DirectionFlag.ForwardForwardReverse:\n            sign_rms_watts_3 = -1\n            pass\n        if direction_byte == DirectionFlag.ForwardReverseForward:\n            sign_rms_watts_2 = -1\n            pass\n        if direction_byte == DirectionFlag.ReverseForwardForward:\n            sign_rms_watts_1 = -1\n            pass\n        if direction_byte == DirectionFlag.ForwardReverseReverse:\n            sign_rms_watts_2 = -1\n            sign_rms_watts_3 = -1\n            pass\n        if direction_byte == DirectionFlag.ReverseForwardReverse:\n            sign_rms_watts_1 = -1\n            sign_rms_watts_3 = -1\n            pass\n        if direction_byte == DirectionFlag.ReverseReverseForward:\n            sign_rms_watts_1 = -1\n            sign_rms_watts_2 = -1\n            pass\n        if direction_byte == DirectionFlag.ReverseReverseReverse:\n            sign_rms_watts_1 = -1\n            sign_rms_watts_2 = -1\n            sign_rms_watts_3 = -1\n            pass\n\n        net_watts_1 = rms_watts_1 * sign_rms_watts_1\n        net_watts_2 = rms_watts_2 * sign_rms_watts_2\n        net_watts_3 = rms_watts_3 * sign_rms_watts_3\n        net_watts_tot = net_watts_1 + net_watts_2 + net_watts_3\n\n        self.m_blk_b[Field.Net_Calc_Watts_Ln_1][MeterData.NativeValue] = net_watts_1\n        self.m_blk_b[Field.Net_Calc_Watts_Ln_2][MeterData.NativeValue] = net_watts_2\n        self.m_blk_b[Field.Net_Calc_Watts_Ln_3][MeterData.NativeValue] = net_watts_3\n        self.m_blk_b[Field.Net_Calc_Watts_Tot][MeterData.NativeValue] = net_watts_tot\n\n        self.m_blk_b[Field.Net_Calc_Watts_Ln_1][MeterData.StringValue] = str(net_watts_1)\n        self.m_blk_b[Field.Net_Calc_Watts_Ln_2][MeterData.StringValue] = str(net_watts_2)\n        self.m_blk_b[Field.Net_Calc_Watts_Ln_3][MeterData.StringValue] = str(net_watts_3)\n        self.m_blk_b[Field.Net_Calc_Watts_Tot][MeterData.StringValue] = str(net_watts_tot)\n\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsingling call wrapper for LCD set.", "response": "def setLCDCmd(self, display_list, password=\"00000000\"):\n        \"\"\" Single call wrapper for LCD set.\"\n\n        Wraps :func:`~ekmmeters.V4Meter.setLcd` and associated init and add methods.\n\n        Args:\n            display_list (list): List composed of :class:`~ekmmeters.LCDItems`\n            password (str): Optional password.\n\n        Returns:\n            bool: Passthrough from :func:`~ekmmeters.V4Meter.setLcd`\n        \"\"\"\n        result = False\n        try:\n            self.initLcd()\n            item_cnt = len(display_list)\n            if (item_cnt > 45) or (item_cnt <= 0):\n                ekm_log(\"LCD item list must have between 1 and 40 items\")\n                return False\n\n            for display_item in display_list:\n                self.addLcdItem(int(display_item))\n            result = self.setLCD(password)\n        except:\n            ekm_log(traceback.format_exc(sys.exc_info()))\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef setRelay(self, seconds, relay, status, password=\"00000000\"):\n        result = False\n        self.setContext(\"setRelay\")\n        try:\n            self.clearCmdMsg()\n\n            if len(password) != 8:\n                self.writeCmdMsg(\"Invalid password length.\")\n                self.setContext(\"\")\n                return result\n\n            if seconds < 0 or seconds > 9999:\n                self.writeCmdMsg(\"Relay duration must be between 0 and 9999.\")\n                self.setContext(\"\")\n                return result\n\n            if not self.requestA():\n                self.writeCmdMsg(\"Bad read CRC on setting\")\n            else:\n                if not self.serialCmdPwdAuth(password):\n                    self.writeCmdMsg(\"Password failure\")\n                else:\n                    req_str = \"\"\n                    req_str = (\"01573102303038\" +\n                               binascii.hexlify(str(relay)).zfill(2) +\n                               \"28\" +\n                               binascii.hexlify(str(status)).zfill(2) +\n                               binascii.hexlify(str(seconds).zfill(4)) + \"2903\")\n                    req_str += self.calc_crc16(req_str[2:].decode(\"hex\"))\n                    self.m_serial_port.write(req_str.decode(\"hex\"))\n                    if self.m_serial_port.getResponse(self.getContext()).encode(\"hex\") == \"06\":\n                        self.writeCmdMsg(\"Success: 06 returned.\")\n                        result = True\n            self.serialPostEnd()\n        except:\n            ekm_log(traceback.format_exc(sys.exc_info()))\n\n        self.setContext(\"\")\n        return result", "response": "This method is used to set the amount of time to hold forever."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsends termination string to implicit current meter.", "response": "def serialPostEnd(self):\n        \"\"\" Send termination string to implicit current meter.\"\"\"\n        ekm_log(\"Termination string sent (\" + self.m_context + \")\")\n\n        try:\n            self.m_serial_port.write(\"0142300375\".decode(\"hex\"))\n        except:\n            ekm_log(traceback.format_exc(sys.exc_info()))\n\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef setPulseInputRatio(self, line_in, new_cnst, password=\"00000000\"):\n        result = False\n        self.setContext(\"setPulseInputRatio\")\n\n        try:\n            if not self.requestA():\n                self.writeCmdMsg(\"Bad read CRC on setting\")\n            else:\n                if not self.serialCmdPwdAuth(password):\n                    self.writeCmdMsg(\"Password failure\")\n                else:\n                    req_const = binascii.hexlify(str(new_cnst).zfill(4))\n                    line_const = binascii.hexlify(str(line_in - 1))\n                    req_str = \"01573102303041\" + line_const + \"28\" + req_const + \"2903\"\n                    req_str += self.calc_crc16(req_str[2:].decode(\"hex\"))\n                    self.m_serial_port.write(req_str.decode(\"hex\"))\n                    if self.m_serial_port.getResponse(self.getContext()).encode(\"hex\") == \"06\":\n                        self.writeCmdMsg(\"Success: 06 returned.\")\n                        result = True\n\n            self.serialPostEnd()\n        except:\n            ekm_log(traceback.format_exc(sys.exc_info()))\n\n        self.setContext(\"\")\n        return result", "response": "This method is used to set the pulse input ratio on a line."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef iterate_fields(fields, schema):\n    schema_dict = {val['name']: val for val in schema}\n    for field_id, properties in fields.iteritems():\n        if 'group' in schema_dict[field_id]:\n            for _field_schema, _fields in iterate_fields(properties, schema_dict[field_id]['group']):\n                yield (_field_schema, _fields)\n        else:\n            yield (schema_dict[field_id], fields)", "response": "Recursively iterate over all DictField sub - fields."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef iterate_schema(fields, schema, path=None):\n    for field_schema in schema:\n        name = field_schema['name']\n        if 'group' in field_schema:\n            for rvals in iterate_schema(fields[name] if name in fields else {},\n                                        field_schema['group'],\n                                        None if path is None else '{}.{}'.format(path, name)):\n                yield rvals\n        else:\n            if path is None:\n                yield (field_schema, fields)\n            else:\n                yield (field_schema, fields, '{}.{}'.format(path, name))", "response": "Recursively iterate over all schema sub - fields."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_arguments(cls, parser):\n\n        parser.add_argument(\n            '-c', '--create-missing-tasks',\n            action='store_true',\n            dest='create_missing_tasks',\n            help=\"[sync] create asana tasks for issues without tasks\"\n            )\n\n        parser.add_argument(\n            '-l', '--sync-labels',\n            action='store_true',\n            dest='sync_labels',\n            help=\"[sync] sync labels and milestones for each issue\"\n            )", "response": "Add arguments to the parser for the base class."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef apply_tasks_to_issue(self, issue, tasks, issue_body=None):\n        issue_body = issue_body or issue.body\n        task_numbers = transport.format_task_numbers_with_links(tasks)\n        if task_numbers:\n            new_body = transport.ASANA_SECTION_RE.sub('', issue_body)\n            new_body = new_body + \"\\n## Asana Tasks:\\n\\n%s\" % task_numbers\n            transport.issue_edit(issue,\n                                 body=new_body)\n            return new_body\n\n        return issue_body", "response": "Applies the tasks to an issue."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sync_labels(self, repo):\n\n        logging.info(\"syncing new github.com labels to tags\")\n\n        # create label tag map\n        ltm = self.app.data.get(\"label-tag-map\", {})\n\n        # loop over labels, if they don't have tags, make them\n        for label in repo.get_labels():\n            tag_id = ltm.get(label.name, None)\n            if tag_id is None:\n\n                tag = self.app.asana.tags.create(name=label.name,\n                                      workspace=self.asana_ws_id,\n                                      notes=\"gh: %s\" % label.url\n                                      )\n\n                logging.info(\"\\t%s => tag %d\", label.name, tag['id'])\n                ltm[label.name] = tag['id']\n\n        # loop over milestones, if they don't have tags, make them\n        for ms in repo.get_milestones(state=\"all\"):\n            tag_id = ltm.get(_ms_label(ms.id), None)\n            if tag_id is None:\n\n                tag = self.app.asana.tags.create(name=ms.title,\n                                      workspace=self.asana_ws_id,\n                                      notes=\"gh: %s\" % ms.url\n                                      )\n\n                logging.info(\"\\t%s => tag %d\", ms.title, tag['id'])\n                ltm[_ms_label(ms.id)] = tag['id']\n\n        self.app.data['label-tag-map'] = ltm\n        return ltm", "response": "Creates a local map of github labels to asana tags."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning output for the combined time and result summary statistics.", "response": "def statistics(self, elapsed, result):\n        \"\"\"\n        Return output for the combined time and result summary statistics.\n\n        \"\"\"\n\n        return \"\\n\".join((self.timing(elapsed), self.result_summary(result)))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncolor some text in the given ANSI color.", "response": "def color(self, color, text):\n        \"\"\"\n        Color some text in the given ANSI color.\n\n        \"\"\"\n\n        return \"{escape}{text}{reset}\".format(\n            escape=self.ANSI[color], text=text, reset=self.ANSI[\"reset\"],\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef show(self, text):\n\n        self.stream.write(text)\n        self.stream.flush()", "response": "Write the text to the stream and flush immediately."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a summary of the results.", "response": "def result_summary(self, result):\n        \"\"\"\n        Return a summary of the results.\n\n        \"\"\"\n\n        return \"{} examples, {} errors, {} failures\\n\".format(\n            result.testsRun, len(result.errors), len(result.failures),\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse(argv=None):\n\n    if argv is None:\n        argv = sys.argv[1:]\n\n    # Evade http://bugs.python.org/issue9253\n    if not argv or argv[0] not in {\"run\", \"transform\"}:\n        argv = [\"run\"] + argv\n\n    arguments = _clean(_parser.parse_args(argv))\n    return arguments", "response": "Parse some arguments using the parser."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef setup(config):\n\n    formatter = config.Formatter()\n\n    if config.verbose:\n        formatter = result.Verbose(formatter)\n    if config.color:\n        formatter = result.Colored(formatter)\n\n    current_result = result.ExampleResult(formatter)\n\n    ivoire.current_result = ivoire._manager.result = current_result", "response": "Setup the environment for an example run."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef transform(config):\n\n    if transform_possible:\n        ExampleLoader.register()\n\n        args, sys.argv[1:] = sys.argv[1:], config.args\n        try:\n            return runpy.run_path(config.runner, run_name=\"__main__\")\n        finally:\n            sys.argv[1:] = args", "response": "Run in transform mode."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nvisit the with node and transform it to a TestThing", "response": "def visit_With(self, node):\n        \"\"\"\n        with describe(thing) as it:\n            ...\n\n             |\n             v\n\n        class TestThing(TestCase):\n            ...\n\n        \"\"\"\n\n        withitem, = node.items\n        context = withitem.context_expr\n\n        if context.func.id == \"describe\":\n            describes = context.args[0].id\n            example_group_name = withitem.optional_vars.id\n            return self.transform_describe(node, describes, example_group_name)\n        else:\n            return node"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntransform a describe node into a TestCase.", "response": "def transform_describe(self, node, describes, context_variable):\n        \"\"\"\n        Transform a describe node into a ``TestCase``.\n\n        ``node`` is the node object.\n        ``describes`` is the name of the object being described.\n        ``context_variable`` is the name bound in the context manager (usually\n        \"it\").\n\n        \"\"\"\n\n        body = self.transform_describe_body(node.body, context_variable)\n        return ast.ClassDef(\n            name=\"Test\" + describes.title(),\n            bases=[ast.Name(id=\"TestCase\", ctx=ast.Load())],\n            keywords=[],\n            starargs=None,\n            kwargs=None,\n            body=list(body),\n            decorator_list=[],\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntransform the body of an example group.", "response": "def transform_describe_body(self, body, group_var):\n        \"\"\"\n        Transform the body of an ``ExampleGroup``.\n\n        ``body`` is the body.\n        ``group_var`` is the name bound to the example group in the context\n        manager (usually \"it\").\n\n        \"\"\"\n\n        for node in body:\n            withitem, = node.items\n            context_expr = withitem.context_expr\n\n            name = context_expr.args[0].s\n            context_var = withitem.optional_vars.id\n\n            yield self.transform_example(node, name, context_var, group_var)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef transform_example(self, node, name, context_variable, group_variable):\n\n        test_name = \"_\".join([\"test\", group_variable] + name.split())\n        body = self.transform_example_body(node.body, context_variable)\n\n        return ast.FunctionDef(\n            name=test_name,\n            args=self.takes_only_self(),\n            body=list(body),\n            decorator_list=[],\n        )", "response": "Transform an example node into a test method."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntransform the body of an example into the body of a method.", "response": "def transform_example_body(self, body, context_variable):\n        \"\"\"\n        Transform the body of an ``Example`` into the body of a method.\n\n        Replaces instances of ``context_variable`` to refer to ``self``.\n\n        ``body`` is the body.\n        ``context_variable`` is the name bound in the surrounding context\n        manager to the example (usually \"test\").\n\n        \"\"\"\n\n        for node in body:\n            for child in ast.walk(node):\n                if isinstance(child, ast.Name):\n                    if child.id == context_variable:\n                        child.id = \"self\"\n            yield node"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning an argument list node that takes only self.", "response": "def takes_only_self(self):\n        \"\"\"\n        Return an argument list node that takes only ``self``.\n\n        \"\"\"\n\n        return ast.arguments(\n            args=[ast.arg(arg=\"self\")],\n            defaults=[],\n            kw_defaults=[],\n            kwonlyargs=[],\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nregister the path hook.", "response": "def register(cls):\n        \"\"\"\n        Register the path hook.\n\n        \"\"\"\n\n        cls._finder = FileFinder.path_hook((cls, [cls.suffix]))\n        sys.path_hooks.append(cls._finder)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntransform the source code then return the code object.", "response": "def source_to_code(self, source_bytes, source_path):\n        \"\"\"\n        Transform the source code, then return the code object.\n\n        \"\"\"\n\n        node = ast.parse(source_bytes)\n        transformed = ExampleTransformer().transform(node)\n        return compile(transformed, source_path, \"exec\", dont_inherit=True)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef apply_argument_parser(argumentsParser, options=None):\n    if options is not None:\n        args = argumentsParser.parse_args(options)\n    else:\n        args = argumentsParser.parse_args()\n    return args", "response": "Apply the argument parser."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading a single spec from either a file path or a fully qualified name.", "response": "def load_by_name(name):\n    \"\"\"\n    Load a spec from either a file path or a fully qualified name.\n\n    \"\"\"\n\n    if os.path.exists(name):\n        load_from_path(name)\n    else:\n        __import__(name)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef load_from_path(path):\n\n    if os.path.isdir(path):\n        paths = discover(path)\n    else:\n        paths = [path]\n\n    for path in paths:\n        name = os.path.basename(os.path.splitext(path)[0])\n        imp.load_source(name, path)", "response": "Load a single spec from a given path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef discover(path, filter_specs=filter_specs):\n\n    for dirpath, _, filenames in os.walk(path):\n        for spec in filter_specs(filenames):\n            yield os.path.join(dirpath, spec)", "response": "Discover all of the specs inside path."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconstructs a function that checks a directory for process configuration files and calls the appropriate receiver WorkItem methods.", "response": "def checker(location, receiver):\n    \"\"\"Construct a function that checks a directory for process configuration\n\n    The function checks for additions or removals\n    of JSON process configuration files and calls the appropriate receiver\n    methods.\n\n    :param location: string, the directory to monitor\n    :param receiver: IEventReceiver\n    :returns: a function with no parameters\n    \"\"\"\n    path = filepath.FilePath(location)\n    files = set()\n    filesContents = {}\n\n    def _check(path):\n        currentFiles = set(fname for fname in os.listdir(location)\n                           if not fname.endswith('.new'))\n        removed = files - currentFiles\n        added = currentFiles - files\n        for fname in added:\n            contents = path.child(fname).getContent()\n            filesContents[fname] = contents\n            receiver.add(fname, contents)\n        for fname in removed:\n            receiver.remove(fname)\n        same = currentFiles & files\n        for fname in same:\n            newContents = path.child(fname).getContent()\n            oldContents = filesContents[fname]\n            if newContents == oldContents:\n                continue\n            receiver.remove(fname)\n            filesContents[fname] = newContents\n            receiver.add(fname, newContents)\n        files.clear()\n        files.update(currentFiles)\n    return functools.partial(_check, path)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef messages(location, receiver):\n    path = filepath.FilePath(location)\n\n    def _check(path):\n        messageFiles = path.globChildren('*')\n        for message in messageFiles:\n            if message.basename().endswith('.new'):\n                continue\n            receiver.message(message.getContent())\n            message.remove()\n    return functools.partial(_check, path)", "response": "Construct a function that checks a directory for new messages and a receiver."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add(places, name, cmd, args, env=None, uid=None, gid=None, extras=None,\n        env_inherit=None):\n    \"\"\"Add a process.\n\n    :param places: a Places instance\n    :param name: string, the logical name of the process\n    :param cmd: string, executable\n    :param args: list of strings, command-line arguments\n    :param env: dictionary mapping strings to strings\n         (will be environment in subprocess)\n    :param uid: integer, uid to run the new process as\n    :param gid: integer, gid to run the new process as\n    :param extras: a dictionary with additional parameters\n    :param env_inherit: a list of environment variables to inherit\n    :returns: None\n    \"\"\"\n    args = [cmd]+args\n    config = filepath.FilePath(places.config)\n    fle = config.child(name)\n    details = dict(args=args)\n    if env is not None:\n        newEnv = {}\n        for thing in env:\n            name, value = thing.split('=', 1)\n            newEnv[name] = value\n        details['env'] = newEnv\n    if uid is not None:\n        details['uid'] = uid\n    if gid is not None:\n        details['gid'] = gid\n    if env_inherit is not None:\n        details['env_inherit'] = env_inherit\n    if extras is not None:\n        details.update(extras)\n    content = _dumps(details)\n    fle.setContent(content)", "response": "Add a process to the specified process."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef remove(places, name):\n    config = filepath.FilePath(places.config)\n    fle = config.child(name)\n    fle.remove()", "response": "Removes a process\n    from the config file"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrestart a process :params places: a Places instance :params name: string, the logical name of the process :returns: None", "response": "def restart(places, name):\n    \"\"\"Restart a process\n\n    :params places: a Places instance\n    :params name: string, the logical name of the process\n    :returns: None\n    \"\"\"\n    content = _dumps(dict(type='RESTART', name=name))\n    _addMessage(places, content)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef call(results):\n    results = vars(results)\n    places = Places(config=results.pop('config'),\n                    messages=results.pop('messages'))\n    func = results.pop('func')\n    func(places, **results)", "response": "Call results. func on the attributes of results\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a service which monitors processes based on the contents of the config directory and messages.", "response": "def get(config, messages, freq, pidDir=None, reactor=None):\n    \"\"\"Return a service which monitors processes based on directory contents\n\n    Construct and return a service that, when started, will run processes\n    based on the contents of the 'config' directory, restarting them\n    if file contents change and stopping them if the file is removed.\n\n    It also listens for restart and restart-all messages on the 'messages'\n    directory.\n\n    :param config: string, location of configuration directory\n    :param messages: string, location of messages directory\n    :param freq: number, frequency to check for new messages and configuration\n                 updates\n    :param pidDir: {twisted.python.filepath.FilePath} or None,\n                   location to keep pid files\n    :param reactor: something implementing the interfaces\n                       {twisted.internet.interfaces.IReactorTime} and\n                       {twisted.internet.interfaces.IReactorProcess} and\n    :returns: service, {twisted.application.interfaces.IService}\n    \"\"\"\n    ret = taservice.MultiService()\n    args = ()\n    if reactor is not None:\n        args = reactor,\n    procmon = procmonlib.ProcessMonitor(*args)\n    if pidDir is not None:\n        protocols = TransportDirectoryDict(pidDir)\n        procmon.protocols = protocols\n    procmon.setName('procmon')\n    receiver = process_events.Receiver(procmon)\n    confcheck = directory_monitor.checker(config, receiver)\n    confserv = internet.TimerService(freq, confcheck)\n    confserv.setServiceParent(ret)\n    messagecheck = directory_monitor.messages(messages, receiver)\n    messageserv = internet.TimerService(freq, messagecheck)\n    messageserv.setServiceParent(ret)\n    procmon.setServiceParent(ret)\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef makeService(opt):\n    ret = get(config=opt['config'], messages=opt['messages'],\n              pidDir=opt['pid'], freq=opt['frequency'])\n    pm = ret.getServiceNamed(\"procmon\")\n    pm.threshold = opt[\"threshold\"]\n    pm.killTime = opt[\"killtime\"]\n    pm.minRestartDelay = opt[\"minrestartdelay\"]\n    pm.maxRestartDelay = opt[\"maxrestartdelay\"]\n    return ret", "response": "Return a service based on parsed command - line options\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef refresh_session(self, node_id=None):\n        if not node_id:\n            node_id = self.conn.id\n\n        self.conn.client.hset(self.nodelist_key, node_id, int(time.time() * 1000.))", "response": "Refreshes the session for a particular node in the nodelist"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find_expired_nodes(self, node_ids=None):\n        if node_ids:\n            nodes = zip(node_ids, [int(t) for t in self.conn.client.hmget(self.nodelist_key, node_ids)])\n        else:\n            nodes = self.get_all_nodes().items()\n\n        expiration_delta = self.conn.PROCESS_TTL * 1000.\n        now = int(time.time() * 1000.)\n        return [node_id for (node_id, last_updated) in nodes if (now - last_updated) > expiration_delta]", "response": "Finds nodes that have expired since the process_ttl of the current session."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove all expired nodes from the nodelist.", "response": "def remove_expired_nodes(self, node_ids=None):\n        \"\"\"\n        Removes all expired nodes from the nodelist.  If a set of node_ids is\n        passed in, those ids are checked to ensure they haven't been refreshed\n        prior to a lock being acquired.\n\n        Should only be run with a lock.\n\n        :param list node_ids: optional, a list of node_ids to remove.  They\n            will be verified to ensure they haven't been refreshed.\n\n        \"\"\"\n        nodes = self.find_expired_nodes(node_ids)\n        if nodes:\n            self.conn.client.hdel(self.nodelist_key, *nodes)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef remove_node(self, node_id=None):\n        if not node_id:\n            node_id = self.conn.id\n\n        self.conn.client.hdel(self.nodelist_key, node_id)", "response": "Removes a particular node from the nodelist."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nretrieve the last updated time for a particular node.", "response": "def get_last_updated(self, node_id=None):\n        \"\"\"\n        Returns the time a particular node has been last refreshed.\n\n        :param string node_id: optional, the connection id of the node to retrieve\n\n        :rtype: int\n        :returns: Returns a unix timestamp if it exists, otherwise None\n        \"\"\"\n        if not node_id:\n            node_id = self.conn.id\n\n        dt = self.conn.client.hget(self.nodelist_key, node_id)\n        return int(dt) if dt else None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning all nodes in the hash with the time they were last refreshed as a dictionary.", "response": "def get_all_nodes(self):\n        \"\"\"\n        Returns all nodes in the hash with the time they were last refreshed\n        as a dictionary.\n\n        :rtype: dict(string, int)\n        :returns: A dictionary of strings and corresponding timestamps\n\n        \"\"\"\n        nodes = self.conn.client.hgetall(self.nodelist_key)\n        return {node_id: int(dt) for (node_id, dt) in nodes.items()}"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef refresh_session(self):\n        expired_nodes = self.nodelist.find_expired_nodes()\n        if expired_nodes:\n            self.nodelist.remove_expired_nodes(expired_nodes)\n        self.nodelist.refresh_session()", "response": "Refresh the session for this node. Specifically ; lock on the reflist and update the time of the node."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef increment_times_modified(self):\n        rc = self.conn.client.incr(self.times_modified_key)\n        self.conn.client.pexpire(self.times_modified_key,\n                                 phonon.s_to_ms(TTL))", "response": "Increments the number of times this resource has been modified by all\n        processes."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_times_modified(self):\n        times_modified = self.conn.client.get(self.times_modified_key)\n        if times_modified is None:\n            return 0\n        return int(times_modified)", "response": "Returns the number of times increment_times_modified has been called for this resource by all processes."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef count(self):\n        references = self.conn.client.get(self.refcount_key)\n        if references is None:\n            return 0\n        return int(references)", "response": "Returns the number of elements in the reference list."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dereference(self, callback=None, args=None, kwargs=None):\n        if args is None:\n            args = tuple()\n        if kwargs is None:\n            kwargs = {}\n\n        client = self.conn.client\n\n        should_execute = False\n        if self.force_expiry:\n            should_execute = True\n\n        if not should_execute:\n            self.nodelist.remove_node(self.conn.id)\n            self.nodelist.remove_expired_nodes()\n\n            updated_refcount = client.incr(self.refcount_key, -1)\n            should_execute = (updated_refcount <= 0)  # When we force expiry this will be -1\n\n        try:\n            if callable(callback) and should_execute:\n                callback(*args, **kwargs)\n        finally:\n            if should_execute:\n                client.delete(self.resource_key,\n                              self.nodelist.nodelist_key,\n                              self.times_modified_key,\n                              self.refcount_key)\n\n            self.conn.remove_from_registry(self.resource_key)\n        return should_execute", "response": "This method is used to remove the value stored in the backend for this resource from the resource list."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delimit(values, delimiter=', '):\n    \"Returns a list of tokens interleaved with the delimiter.\"\n    toks = []\n\n    if not values:\n        return toks\n\n    if not isinstance(delimiter, (list, tuple)):\n        delimiter = [delimiter]\n\n    last = len(values) - 1\n\n    for i, value in enumerate(values):\n        toks.append(value)\n\n        if i < last:\n            toks.extend(delimiter)\n\n    return toks", "response": "Returns a list of tokens interleaved with the delimiter."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking which processes need to be restarted", "response": "def check(path, start, now):\n    \"\"\"check which processes need to be restarted\n\n    :params path: a twisted.python.filepath.FilePath with configurations\n    :params start: when the checker started running\n    :params now: current time\n    :returns: list of strings\n    \"\"\"\n    return [child.basename() for child in path.children()\n            if _isbad(child, start, now)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parseConfig(opt):\n    places = ctllib.Places(config=opt['config'], messages=opt['messages'])\n    restarter = functools.partial(ctllib.restart, places)\n    path = filepath.FilePath(opt['config'])\n    return restarter, path", "response": "Parse configuration of a single node."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmaking a service that at opt['freq'] checks for stale processes in opt [ config and sends restart messages through opt [ messages ]", "response": "def makeService(opt):\n    \"\"\"Make a service\n\n    :params opt: dictionary-like object with 'freq', 'config' and 'messages'\n    :returns: twisted.application.internet.TimerService that at opt['freq']\n              checks for stale processes in opt['config'], and sends\n              restart messages through opt['messages']\n    \"\"\"\n    restarter, path = parseConfig(opt)\n    now = time.time()\n    checker = functools.partial(check, path, now)\n    beatcheck = tainternet.TimerService(opt['freq'], run, restarter,\n                                        checker, time.time)\n    beatcheck.setName('beatcheck')\n    return heart.wrapHeart(beatcheck)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef expected_error(self, expected: str) -> str:\n\n        if self.finished:\n            return 'Expected {} but found end of source'.format(expected)\n        else:\n            return 'Expected {} but found {} at index {}'.format(expected, self.next_token(), self.position)", "response": "Generate a basic error message to include the current state of the current state."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef recursion_error(self, repeated_parser: str):\n\n        if self.finished:\n            return 'Infinite recursion detected in {}; empty string was matched and will be matched forever at ' \\\n                   'end of source'.format(repeated_parser)\n        else:\n            return 'Infinite recursion detected in {}; empty string was matched and will be matched forever at ' \\\n                   'index {} before {}'.format(repeated_parser, self.position, self.next_token())", "response": "Generate an error message to indicate that infinite recursion was encountered."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate an error message to include the current state of the current state.", "response": "def expected_error(self, expected: str) -> str:\n        \"\"\"Generate a basic error to include the current state.\n\n        A parser can supply only a representation of what it is expecting to\n        this method and the reader will provide the context, including the line\n        and character positions.\n\n        Args:\n            expected: A representation of what the parser is currently expecting\n\n        Returns:\n            A full error message\n        \"\"\"\n\n        if self.finished:\n            return super().expected_error(expected)\n        else:\n            line_index, character_index, line, pointer = self.current_line()\n\n            return 'Expected {} but found {}\\nLine {}, character {}\\n\\n{}{}'.format(\n                expected, repr(self.next_token()), line_index, character_index, line, pointer)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates an error message to indicate that infinite recursion was encountered.", "response": "def recursion_error(self, repeated_parser: str):\n        \"\"\"Generate an error to indicate that infinite recursion was encountered.\n\n        A parser can supply a representation of itself to this method and the\n        reader will supply the context, including the location where the\n        parser stalled.\n\n        Args:\n            repeated_parser: A representation of the repeated parser\n\n        Returns:\n            A full error message\n        \"\"\"\n        if self.finished:\n            return super().recursion_error(repeated_parser)\n        else:\n            line_index, character_index, line, pointer = self.current_line()\n\n            return 'Infinite recursion detected in {}; empty string was matched and will be matched forever\\n' \\\n                   'Line {}, character {}\\n\\n{}{}'.format(repeated_parser, line_index, character_index, line, pointer)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmerging the failure message from another status into this one.", "response": "def merge(self, status: 'Status[Input, Output]') -> 'Status[Input, Output]':\n        \"\"\"Merge the failure message from another status into this one.\n\n        Whichever status represents parsing that has gone the farthest is\n        retained. If both statuses have gone the same distance, then the\n        expected values from both are retained.\n\n        Args:\n            status: The status to merge into this one.\n\n        Returns:\n            This ``Status`` which may have ``farthest`` and ``expected``\n            updated accordingly.\n        \"\"\"\n        if status is None or status.farthest is None:\n            # No new message; simply return unchanged\n            pass\n        elif self.farthest is None:\n            # No current message to compare to; use the message from status\n            self.farthest = status.farthest\n            self.expected = status.expected\n        elif status.farthest.position < self.farthest.position:\n            # New message is not farther; keep current message\n            pass\n        elif status.farthest.position > self.farthest.position:\n            # New message is farther than current message; replace with new message\n            self.farthest = status.farthest\n            self.expected = status.expected\n        else:\n            # New message and current message are equally far; merge messages\n            self.expected = status.expected + self.expected\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef exists(value):\n    \"Query to test if a value exists.\"\n    if not isinstance(value, Token):\n        raise TypeError('value must be a token')\n\n    if not hasattr(value, 'identifier'):\n        raise TypeError('value must support an identifier')\n\n    if not value.identifier:\n        value = value.__class__(**value.__dict__)\n        value.identifier = 'v'\n\n    ident = Identifier(value.identifier)\n\n    return Query([\n        OptionalMatch(value),\n        Return(Predicate(ident, 'IS NOT NULL')),\n        Limit(1),\n    ])", "response": "Query to test if a value exists."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(value):\n    \"Query to get the value.\"\n    if not isinstance(value, Token):\n        raise TypeError('value must be a token')\n\n    if not hasattr(value, 'identifier'):\n        raise TypeError('value must support an identifier')\n\n    if not value.identifier:\n        value = value.__class__(**value.__dict__)\n        value.identifier = 'v'\n\n    ident = Identifier(value.identifier)\n\n    return Query([\n        Match(value),\n        Return(ident)\n    ])", "response": "Query to get the value."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nproduces a function that always returns a supplied value.", "response": "def constant(x: A) -> Callable[..., A]:\n    \"\"\"Produce a function that always returns a supplied value.\n\n    Args:\n        x: Any object.\n\n    Returns:\n        A function that accepts any number of positional and keyword arguments, discards them, and returns ``x``.\n    \"\"\"\n\n    def constanted(*args, **kwargs):\n        return x\n\n    return constanted"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert a function taking multiple arguments into a function taking a single iterable argument.", "response": "def splat(f: Callable[..., A]) -> Callable[[Iterable], A]:\n    \"\"\"Convert a function taking multiple arguments into a function taking a single iterable argument.\n\n    Args:\n        f: Any function\n\n    Returns:\n        A function that accepts a single iterable argument. Each element of this iterable argument is passed as an\n        argument to ``f``.\n\n    Example:\n        $ def f(a, b, c):\n        $     return a + b + c\n        $\n        $ f(1, 2, 3)  # 6\n        $ g = splat(f)\n        $ g([1, 2, 3])  # 6\n    \"\"\"\n\n    def splatted(args):\n        return f(*args)\n\n    return splatted"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert a function taking a single iterable argument into a function taking multiple arguments.", "response": "def unsplat(f: Callable[[Iterable], A]) -> Callable[..., A]:\n    \"\"\"Convert a function taking a single iterable argument into a function taking multiple arguments.\n\n    Args:\n        f: Any function taking a single iterable argument\n\n    Returns:\n        A function that accepts multiple arguments. Each argument of this function is passed as an element of an\n        iterable to ``f``.\n\n    Example:\n        $ def f(a):\n        $     return a[0] + a[1] + a[2]\n        $\n        $ f([1, 2, 3])  # 6\n        $ g = unsplat(f)\n        $ g(1, 2, 3)  # 6\n    \"\"\"\n\n    def unsplatted(*args):\n        return f(args)\n\n    return unsplatted"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef runProcess(args, timeout, grace, reactor):\n    deferred = defer.Deferred()\n    protocol = ProcessProtocol(deferred)\n    process = reactor.spawnProcess(protocol, args[0], args, env=os.environ)\n\n    def _logEnded(err):\n        err.trap(tierror.ProcessDone, tierror.ProcessTerminated)\n        print(err.value)\n    deferred.addErrback(_logEnded)\n\n    def _cancelTermination(dummy):\n        for termination in terminations:\n            if termination.active():\n                termination.cancel()\n    deferred.addCallback(_cancelTermination)\n    terminations = []\n    terminations.append(reactor.callLater(timeout, process.signalProcess,\n                                          \"TERM\"))\n    terminations.append(reactor.callLater(timeout+grace,\n                                          process.signalProcess, \"KILL\"))\n    return deferred", "response": "Runs a process and returns a deferred that fires when it is done"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef makeService(opts):\n    ser = tainternet.TimerService(opts['frequency'], runProcess, opts['args'],\n                                  opts['timeout'], opts['grace'], tireactor)\n    ret = service.MultiService()\n    ser.setName('scheduler')\n    ser.setServiceParent(ret)\n    heart.maybeAddHeart(ret)\n    return ret", "response": "Make scheduler service\n\n    :params opts: dict-like object.\n       keys: frequency, args, timeout, grace"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef completely_parse_reader(parser: Parser[Input, Output], reader: Reader[Input]) -> Result[Output]:\n    result = (parser << eof).consume(reader)\n\n    if isinstance(result, Continue):\n        return Success(result.value)\n    else:\n        used = set()\n        unique_expected = []\n        for expected_lambda in result.expected:\n            expected = expected_lambda()\n            if expected not in used:\n                used.add(expected)\n                unique_expected.append(expected)\n\n        return Failure(result.farthest.expected_error(' or '.join(unique_expected)))", "response": "Consume reader and return Success if the input is completely consumed."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmatch a literal string.", "response": "def lit(literal: Sequence[Input], *literals: Sequence[Sequence[Input]]) -> Parser:\n    \"\"\"Match a literal sequence.\n\n    In the `TextParsers`` context, this matches the literal string\n    provided. In the ``GeneralParsers`` context, this matches a sequence of\n    input.\n\n    If multiple literals are provided, they are treated as alternatives. e.g.\n    ``lit('+', '-')`` is the same as ``lit('+') | lit('-')``.\n\n    Args:\n        literal: A literal to match\n        *literals: Alternative literals to match\n\n    Returns:\n        A ``LiteralParser`` in the ``GeneralContext``, a ``LiteralStringParser``\n        in the ``TextParsers`` context, and an ``AlternativeParser`` if multiple\n        arguments are provided.\n    \"\"\"\n    if len(literals) > 0:\n        return AlternativeParser(options.handle_literal(literal), *map(options.handle_literal, literals))\n    else:\n        return options.handle_literal(literal)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmatching a parser one or more times repeatedly.", "response": "def rep1(parser: Union[Parser, Sequence[Input]]) -> RepeatedOnceParser:\n    \"\"\"Match a parser one or more times repeatedly.\n\n    This matches ``parser`` multiple times in a row. If it matches as least\n    once, it returns a list of values from each time ``parser`` matched. If it\n    does not match ``parser`` at all, it fails.\n\n    Args:\n        parser: Parser or literal\n    \"\"\"\n    if isinstance(parser, str):\n        parser = lit(parser)\n    return RepeatedOnceParser(parser)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef rep(parser: Union[Parser, Sequence[Input]]) -> RepeatedParser:\n    if isinstance(parser, str):\n        parser = lit(parser)\n    return RepeatedParser(parser)", "response": "Match a parser zero or more times repeatedly."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmatches a parser one or more times separated by another parser.", "response": "def rep1sep(parser: Union[Parser, Sequence[Input]], separator: Union[Parser, Sequence[Input]]) \\\n        -> RepeatedOnceSeparatedParser:\n    \"\"\"Match a parser one or more times separated by another parser.\n\n    This matches repeated sequences of ``parser`` separated by ``separator``.\n    If there is at least one match, a list containing the values of the\n    ``parser`` matches is returned. The values from ``separator`` are discarded.\n    If it does not match ``parser`` at all, it fails.\n\n    Args:\n        parser: Parser or literal\n        separator: Parser or literal\n    \"\"\"\n    if isinstance(parser, str):\n        parser = lit(parser)\n    if isinstance(separator, str):\n        separator = lit(separator)\n    return RepeatedOnceSeparatedParser(parser, separator)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmatches a parser zero or more times separated by another parser.", "response": "def repsep(parser: Union[Parser, Sequence[Input]], separator: Union[Parser, Sequence[Input]]) \\\n        -> RepeatedSeparatedParser:\n    \"\"\"Match a parser zero or more times separated by another parser.\n\n    This matches repeated sequences of ``parser`` separated by ``separator``. A\n    list is returned containing the value from each match of ``parser``. The\n    values from ``separator`` are discarded. If there are no matches, an empty\n    list is returned.\n\n    Args:\n        parser: Parser or literal\n        separator: Parser or literal\n    \"\"\"\n    if isinstance(parser, str):\n        parser = lit(parser)\n    if isinstance(separator, str):\n        separator = lit(separator)\n    return RepeatedSeparatedParser(parser, separator)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck all processes in a tree", "response": "def check(settings, states, location):\n    \"\"\"Check all processes\"\"\"\n    children = {child.basename(): child for child in location.children()}\n    last = set(states)\n    current = set(children)\n    gone = last - current\n    added = current - last\n    for name in gone:\n        states[name].close()\n        del states[name]\n    for name in added:\n        states[name] = State(location=children[name], settings=settings)\n    return [name for name, state in six.iteritems(states) if state.check()]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef makeService(opt):\n    restarter, path = beatcheck.parseConfig(opt)\n    pool = client.HTTPConnectionPool(reactor)\n    agent = client.Agent(reactor=reactor, pool=pool)\n    settings = Settings(reactor=reactor, agent=agent)\n    states = {}\n    checker = functools.partial(check, settings, states, path)\n    httpcheck = tainternet.TimerService(opt['freq'], run, restarter, checker)\n    httpcheck.setName('httpcheck')\n    return heart.wrapHeart(httpcheck)", "response": "Make a service that at opt [ freq ]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nclose the instance and cancel all calls.", "response": "def close(self):\n        \"\"\"Discard data and cancel all calls.\n\n        Instance cannot be reused after closing.\n        \"\"\"\n        if self.closed:\n            raise ValueError(\"Cannot close a closed state\")\n        if self.call is not None:\n            self.call.cancel()\n        self.closed = True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check(self):\n        if self.closed:\n            raise ValueError(\"Cannot check a closed state\")\n        self._maybeReset()\n        if self.url is None:\n            return False\n        return self._maybeCheck()", "response": "Check the state of HTTP"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmakes a service :returns: an IService", "response": "def makeService():\n    \"\"\"Make a service\n\n    :returns: an IService\n    \"\"\"\n    configJSON = os.environ.get('NCOLONY_CONFIG')\n    if configJSON is None:\n        return None\n    config = json.loads(configJSON)\n    params = config.get('ncolony.beatcheck')\n    if params is None:\n        return None\n    myFilePath = filepath.FilePath(params['status'])\n    if myFilePath.isdir():\n        name = os.environ['NCOLONY_NAME']\n        myFilePath = myFilePath.child(name)\n    heart = Heart(myFilePath)\n    ret = tainternet.TimerService(params['period']/3, heart.beat)\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding a heart to a service collection if it is not None.", "response": "def maybeAddHeart(master):\n    \"\"\"Add a heart to a service collection\n\n    Add a heart to a service.IServiceCollector if\n    the heart is not None.\n\n    :params master: a service.IServiceCollector\n    \"\"\"\n    heartSer = makeService()\n    if heartSer is None:\n        return\n    heartSer.setName('heart')\n    heartSer.setServiceParent(master)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef wrapHeart(service):\n    master = taservice.MultiService()\n    service.setServiceParent(master)\n    maybeAddHeart(master)\n    return master", "response": "Wrap a service in a MultiService with a heart"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfreezing and shrink the graph based on a checkpoint and the output node names.", "response": "def freeze_from_checkpoint(input_checkpoint, output_file_path, output_node_names):\n    \"\"\"Freeze and shrink the graph based on a checkpoint and the output node names.\"\"\"\n    check_input_checkpoint(input_checkpoint)\n\n    output_node_names = output_node_names_string_as_list(output_node_names)\n\n    with tf.Session() as sess:\n        restore_from_checkpoint(sess, input_checkpoint)\n        freeze_graph.freeze_graph_with_def_protos(input_graph_def=sess.graph_def, input_saver_def=None,\n                                                  input_checkpoint=input_checkpoint,\n                                                  output_node_names=','.join(output_node_names),\n                                                  restore_op_name='save/restore_all',\n                                                  filename_tensor_name='save/Const:0', output_graph=output_file_path,\n                                                  clear_devices=True, initializer_nodes='')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef freeze(sess, output_file_path, output_node_names):\n    with TemporaryDirectory() as temp_dir_name:\n        checkpoint_path = os.path.join(temp_dir_name, 'model.ckpt')\n        tf.train.Saver().save(sess, checkpoint_path)\n\n        freeze_from_checkpoint(checkpoint_path, output_file_path, output_node_names)", "response": "Freeze and shrink the graph based on a session and the output node names."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsave a small version of the graph based on a session and the output node names.", "response": "def save_graph_only(sess, output_file_path, output_node_names, as_text=False):\n    \"\"\"Save a small version of the graph based on a session and the output node names.\"\"\"\n    for node in sess.graph_def.node:\n        node.device = ''\n    graph_def = graph_util.extract_sub_graph(sess.graph_def, output_node_names)\n    output_dir, output_filename = os.path.split(output_file_path)\n    graph_io.write_graph(graph_def, output_dir, output_filename, as_text=as_text)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsave a small version of the graph based on a checkpoint and the output node names.", "response": "def save_graph_only_from_checkpoint(input_checkpoint, output_file_path, output_node_names, as_text=False):\n    \"\"\"Save a small version of the graph based on a checkpoint and the output node names.\"\"\"\n    check_input_checkpoint(input_checkpoint)\n\n    output_node_names = output_node_names_string_as_list(output_node_names)\n\n    with tf.Session() as sess:\n        restore_from_checkpoint(sess, input_checkpoint)\n        save_graph_only(sess, output_file_path, output_node_names, as_text=as_text)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef save_weights(sess, output_path, conv_var_names=None, conv_transpose_var_names=None):\n    if not conv_var_names:\n        conv_var_names = []\n\n    if not conv_transpose_var_names:\n        conv_transpose_var_names = []\n\n    for var in tf.trainable_variables():\n        filename = '{}-{}'.format(output_path, var.name.replace(':', '-').replace('/', '-'))\n\n        if var.name in conv_var_names:\n            var = tf.transpose(var, perm=[3, 0, 1, 2])\n        elif var.name in conv_transpose_var_names:\n            var = tf.transpose(var, perm=[3, 1, 0, 2])\n\n        value = sess.run(var)\n\n        # noinspection PyTypeChecker\n        with open(filename, 'w') as file_:\n            value.tofile(file_)", "response": "Save the weights of the trainable variables each one in a different file in output_path."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsave the weights of the trainable variables given a checkpoint.", "response": "def save_weights_from_checkpoint(input_checkpoint, output_path, conv_var_names=None, conv_transpose_var_names=None):\n    \"\"\"Save the weights of the trainable variables given a checkpoint, each one in a different file in output_path.\"\"\"\n    check_input_checkpoint(input_checkpoint)\n\n    with tf.Session() as sess:\n        restore_from_checkpoint(sess, input_checkpoint)\n        save_weights(sess, output_path, conv_var_names=conv_var_names,\n                     conv_transpose_var_names=conv_transpose_var_names)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef restore_from_checkpoint(sess, input_checkpoint):\n    saver = tf.train.import_meta_graph('{}.meta'.format(input_checkpoint))\n    saver.restore(sess, input_checkpoint)\n    return saver", "response": "Return a TensorFlow saver from a checkpoint containing the metagraph."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse(cls, parser, token):\n        tag_name, args, kwargs = parse_token_kwargs(\n            parser, token,\n            allowed_kwargs=cls.allowed_kwargs,\n            compile_args=cls.compile_args,\n            compile_kwargs=cls.compile_kwargs\n        )\n        cls.validate_args(tag_name, *args, **kwargs)\n        if cls.end_tag_name:\n            kwargs['nodelist'] = parser.parse((cls.end_tag_name,))\n            parser.delete_first_token()\n\n        return cls(tag_name, *args, **kwargs)", "response": "Parse the tag and instantiate the class."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef render(self, context):\n        # Resolve token kwargs\n        tag_args = [expr.resolve(context) for expr in self.args] if self.compile_args else self.args\n        tag_kwargs = dict([(name, expr.resolve(context)) for name, expr in six.iteritems(self.kwargs)]) if self.compile_kwargs else self.kwargs\n\n        return self.render_tag(context, *tag_args, **tag_kwargs)", "response": "Returns the HTML code for the current tag."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef render_tag(self, context, *tag_args, **tag_kwargs):\n        raise NotImplementedError(\"{0}.render_tag() is not implemented!\".format(self.__class__.__name__))", "response": "Render the tag with all arguments resolved to their actual values."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef validate_args(cls, tag_name, *args, **kwargs):\n        if cls.min_args is not None and len(args) < cls.min_args:\n            if cls.min_args == 1:\n                raise TemplateSyntaxError(\"'{0}' tag requires at least {1} argument\".format(tag_name, cls.min_args))\n            else:\n                raise TemplateSyntaxError(\"'{0}' tag requires at least {1} arguments\".format(tag_name, cls.min_args))\n\n        if cls.max_args is not None and len(args) > cls.max_args:\n            if cls.max_args == 0:\n                if cls.allowed_kwargs:\n                    raise TemplateSyntaxError(\"'{0}' tag only allows keywords arguments, for example {1}=\\\"...\\\".\".format(tag_name, cls.allowed_kwargs[0]))\n                else:\n                    raise TemplateSyntaxError(\"'{0}' tag doesn't support any arguments\".format(tag_name))\n            elif cls.max_args == 1:\n                raise TemplateSyntaxError(\"'{0}' tag only allows {1} argument.\".format(tag_name, cls.max_args))\n            else:\n                raise TemplateSyntaxError(\"'{0}' tag only allows {1} arguments.\".format(tag_name, cls.max_args))", "response": "Validate the syntax of the template tag."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the context data for the included template.", "response": "def get_context_data(self, parent_context, *tag_args, **tag_kwargs):\n        \"\"\"\n        Return the context data for the included template.\n        \"\"\"\n        raise NotImplementedError(\"{0}.get_context_data() is not implemented.\".format(self.__class__.__name__))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_context(self, parent_context, data):\n        if django.VERSION >= (1, 8):\n            new_context = parent_context.new(data)\n        else:\n            settings = {\n                'autoescape': parent_context.autoescape,\n                'current_app': parent_context.current_app,\n                'use_l10n': parent_context.use_l10n,\n                'use_tz': parent_context.use_tz,\n            }\n            new_context = Context(data, **settings)\n\n        # Pass CSRF token for same reasons as @register.inclusion_tag does.\n        csrf_token = parent_context.get('csrf_token', None)\n        if csrf_token is not None:\n            new_context['csrf_token'] = csrf_token\n\n        return new_context", "response": "Wrap the data in a Context object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrender of the tag. It either assigns the value as variable, or renders it.", "response": "def render_tag(self, context, *tag_args, **tag_kwargs):\n        \"\"\"\n        Rendering of the tag. It either assigns the value as variable, or renders it.\n        \"\"\"\n        if self.as_var:\n            # Assign the value in the parent context\n            context[self.as_var] = self.get_value(context, *tag_args, **tag_kwargs)\n\n        return u''"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse the as var syntax.", "response": "def parse(cls, parser, token):\n        \"\"\"\n        Parse the \"as var\" syntax.\n        \"\"\"\n        bits, as_var = parse_as_var(parser, token)\n        tag_name, args, kwargs = parse_token_kwargs(parser, bits, ('template',) + cls.allowed_kwargs, compile_args=cls.compile_args, compile_kwargs=cls.compile_kwargs)\n\n        # Pass through standard chain\n        cls.validate_args(tag_name, *args)\n        return cls(tag_name, as_var, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef render_tag(self, context, *tag_args, **tag_kwargs):\n        # Be very explicit about which base functionality is used:\n        # Using super() for mixin support will not work nicely anyway here.\n        if self.as_var:\n            # Assign the value in the parent context\n            return BaseAssignmentNode.render_tag(self, context, *tag_args, **tag_kwargs)\n        else:\n            # Render the output using the BaseInclusionNode features\n            return BaseInclusionNode.render_tag(self, context, *tag_args, **tag_kwargs)", "response": "Rendering of the tag. It either assigns the value as variable, or renders it."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_context_data(self, parent_context, *tag_args, **tag_kwargs):\n        if 'template' not in self.allowed_kwargs:\n            # The overwritten get_value() doesn't have to take care of our customly inserted tag parameters,\n            # It can safely assume passing **tag_kwargs to another function.\n            tag_kwargs.pop('template', None)\n\n        return {\n            self.context_value_name: self.get_value(parent_context, *tag_args, **tag_kwargs)\n        }", "response": "Return the context data for the inclusion tag."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a TensorFlow Session from a Caffe model.", "response": "def caffe_to_tensorflow_session(caffe_def_path, caffemodel_path, inputs, graph_name='Graph',\n                                conversion_out_dir_path=None, use_padding_same=False):\n    \"\"\"Create a TensorFlow Session from a Caffe model.\"\"\"\n    try:\n        # noinspection PyUnresolvedReferences\n        from caffeflow import convert\n    except ImportError:\n        raise Exception(\"caffeflow package needs to be installed to freeze Caffe models. Check out the README file.\")\n\n    with (dummy_context_mgr(conversion_out_dir_path) or util.TemporaryDirectory()) as dir_path:\n        params_values_output_path = os.path.join(dir_path, 'params_values.npy')\n        network_output_path = os.path.join(dir_path, 'network.py')\n\n        convert.convert(caffe_def_path, caffemodel_path, params_values_output_path, network_output_path, False,\n                        use_padding_same=use_padding_same)\n\n        network_module = imp.load_source('module.name', network_output_path)\n        network_class = getattr(network_module, graph_name)\n        network = network_class(inputs)\n\n        sess = tf.Session()\n\n        network.load(params_values_output_path, sess)\n\n        return sess"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfreezes and shrink the graph based on a Caffe model.", "response": "def freeze(caffe_def_path, caffemodel_path, inputs, output_file_path, output_node_names, graph_name='Graph',\n           conversion_out_dir_path=None, checkpoint_out_path=None, use_padding_same=False):\n    \"\"\"Freeze and shrink the graph based on a Caffe model, the input tensors and the output node names.\"\"\"\n    with caffe_to_tensorflow_session(caffe_def_path, caffemodel_path, inputs, graph_name=graph_name,\n                                     conversion_out_dir_path=conversion_out_dir_path,\n                                     use_padding_same=use_padding_same) as sess:\n        saver = tf.train.Saver()\n\n        with (dummy_context_mgr(checkpoint_out_path) or util.TemporaryDirectory()) as temp_dir_path:\n            checkpoint_path = checkpoint_out_path or os.path.join(temp_dir_path, 'pose.ckpt')\n            saver.save(sess, checkpoint_path)\n\n            output_node_names = util.output_node_names_string_as_list(output_node_names)\n\n            tf_freeze.freeze_from_checkpoint(checkpoint_path, output_file_path, output_node_names)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef save_graph_only(caffe_def_path, caffemodel_path, inputs, output_file_path, output_node_names, graph_name='Graph',\n                    use_padding_same=False):\n    \"\"\"Save a small version of the graph based on a Caffe model, the input tensors and the output node names.\"\"\"\n    with caffe_to_tensorflow_session(caffe_def_path, caffemodel_path, inputs, graph_name=graph_name,\n                                     use_padding_same=use_padding_same) as sess:\n        tf_freeze.save_graph_only(sess, output_file_path, output_node_names)", "response": "Save a small version of the graph based on a Caffe model and the input tensors and the output node names."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsave the weights of the trainable variables each one in a different file in output_path.", "response": "def save_weights(caffe_def_path, caffemodel_path, inputs, output_path, graph_name='Graph', conv_var_names=None,\n                 conv_transpose_var_names=None, use_padding_same=False):\n    \"\"\"Save the weights of the trainable variables, each one in a different file in output_path.\"\"\"\n    with caffe_to_tensorflow_session(caffe_def_path, caffemodel_path, inputs, graph_name=graph_name,\n                                     use_padding_same=use_padding_same) as sess:\n        tf_freeze.save_weights(sess, output_path, conv_var_names=conv_var_names,\n                               conv_transpose_var_names=conv_transpose_var_names)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef make_rows(num_columns, seq):\n\t# calculate the minimum number of rows necessary to fit the list in\n\t# num_columns Columns\n\tnum_rows, partial = divmod(len(seq), num_columns)\n\tif partial:\n\t\tnum_rows += 1\n\t# break the seq into num_columns of length num_rows\n\ttry:\n\t\tresult = more_itertools.grouper(seq, num_rows)\n\texcept TypeError:\n\t\t# more_itertools before 6.x\n\t\tresult = more_itertools.grouper(num_rows, seq)\n\t# result is now a list of columns... transpose it to return a list\n\t# of rows\n\treturn zip(*result)", "response": "make_rows is a generator that yields a list of rows of num_columns columns."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngive a sequence of elements return two elements that are in the order that they were saved.", "response": "def bisect(seq, func=bool):\n\t\"\"\"\n\tSplit a sequence into two sequences:  the first is elements that\n\treturn False for func(element) and the second for True for\n\tfunc(element).\n\tBy default, func is ``bool``, so uses the truth value of the object.\n\n\t>>> is_odd = lambda n: n%2\n\t>>> even, odd = bisect(range(5), is_odd)\n\t>>> list(odd)\n\t[1, 3]\n\t>>> list(even)\n\t[0, 2, 4]\n\n\t>>> other, zeros = bisect(reversed(range(5)))\n\t>>> list(zeros)\n\t[0]\n\t>>> list(other)\n\t[4, 3, 2, 1]\n\n\t\"\"\"\n\tqueues = GroupbySaved(seq, func)\n\treturn queues.get_first_n_queues(2)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef grouper_nofill_str(n, iterable):\n\tres = more_itertools.chunked(iterable, n)\n\tif isinstance(iterable, six.string_types):\n\t\tres = (''.join(item) for item in res)\n\treturn res", "response": "Take a sequence and break it up into chunks of the specified size."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef flatten(subject, test=None):\n\twarnings.warn(\n\t\t\"Use more_itertools.collapse instead\",\n\t\tDeprecationWarning,\n\t\tstacklevel=2)\n\treturn list(more_itertools.collapse(subject, base_type=(bytes,)))", "response": "Flatten a sequence of bytes into a single list."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef every_other(iterable):\n\titems = iter(iterable)\n\twhile True:\n\t\ttry:\n\t\t\tyield next(items)\n\t\t\tnext(items)\n\t\texcept StopIteration:\n\t\t\treturn", "response": "Yield every other item from the iterable"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef remove_duplicates(iterable, key=None):\n\treturn itertools.chain.from_iterable(six.moves.map(\n\t\tevery_other, six.moves.map(\n\t\t\toperator.itemgetter(1),\n\t\t\titertools.groupby(iterable, key)\n\t\t)))", "response": "Given an iterable with items that may come in as sequential duplicates remove those duplicates."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef peek(iterable):\n\tpeeker, original = itertools.tee(iterable)\n\treturn next(peeker), original", "response": "getNext - Returns the next value from an iterable but also return an iterable\n\t that will subsequently return that value and the rest of the iterable."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef takewhile_peek(predicate, iterable):\n\twhile True:\n\t\ttry:\n\t\t\tif not predicate(iterable.peek()):\n\t\t\t\tbreak\n\t\t\tyield next(iterable)\n\t\texcept StopIteration:\n\t\t\tbreak", "response": "Like takewhile but takes a peekable iterable and doesn t consume the non - matching item."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlikes pairwise except returns n - tuples of adjacent items.", "response": "def nwise(iter, n):\n\t\"\"\"\n\tLike pairwise, except returns n-tuples of adjacent items.\n\ts -> (s0,s1,...,sn), (s1,s2,...,s(n+1)), ...\n\t\"\"\"\n\titerset = [iter]\n\twhile len(iterset) < n:\n\t\titerset[-1:] = itertools.tee(iterset[-1])\n\t\tnext(iterset[-1], None)\n\treturn six.moves.zip(*iterset)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef window(iter, pre_size=1, post_size=1):\n\tpre_iter, iter = itertools.tee(iter)\n\tpre_iter = itertools.chain((None,) * pre_size, pre_iter)\n\tpre_iter = nwise(pre_iter, pre_size)\n\tpost_iter, iter = itertools.tee(iter)\n\tpost_iter = itertools.chain(post_iter, (None,) * post_size)\n\tpost_iter = nwise(post_iter, post_size)\n\tnext(post_iter, None)\n\treturn six.moves.zip(pre_iter, iter, post_iter)", "response": "Given an iterable return a new iterable which yields triples of\n\t pre and post."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef partition_items(count, bin_size):\n\tnum_bins = int(math.ceil(count / float(bin_size)))\n\tbins = [0] * num_bins\n\tfor i in range(count):\n\t\tbins[i % num_bins] += 1\n\treturn bins", "response": "This function will take the total number of items and determine the number of bins that can be added to each bin."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef balanced_rows(n, iterable, fillvalue=None):\n\titerable, iterable_copy = itertools.tee(iterable)\n\tcount = len(tuple(iterable_copy))\n\tfor allocation in partition_items(count, n):\n\t\trow = itertools.islice(iterable, allocation)\n\t\tif allocation < n:\n\t\t\trow = itertools.chain(row, [fillvalue])\n\t\tyield tuple(row)", "response": "Yield n rows from iterable."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef always_iterable(item):\n\tbase_types = six.text_type, bytes, collections.abc.Mapping\n\treturn more_itertools.always_iterable(item, base_type=base_types)", "response": "Returns an always iterable."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nyield the callables that are not supplied and suppresses any exceptions supplied.", "response": "def suppress_exceptions(callables, *exceptions):\n\t\"\"\"\n\tCall each callable in callables, suppressing any exceptions supplied. If\n\tno exception classes are supplied, all Exceptions will be suppressed.\n\n\t>>> import functools\n\t>>> c1 = functools.partial(int, 'a')\n\t>>> c2 = functools.partial(int, '10')\n\t>>> list(suppress_exceptions((c1, c2)))\n\t[10]\n\t>>> list(suppress_exceptions((c1, c2), KeyError))\n\tTraceback (most recent call last):\n\t...\n\tValueError: invalid literal for int() with base 10: 'a'\n\t\"\"\"\n\tif not exceptions:\n\t\texceptions = Exception,\n\tfor callable in callables:\n\t\ttry:\n\t\t\tyield callable()\n\t\texcept exceptions:\n\t\t\tpass"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef duplicates(*iterables, **kwargs):\n\tkey = kwargs.pop('key', lambda x: x)\n\tassert not kwargs\n\tzipped = more_itertools.collate(*iterables, key=key)\n\tgrouped = itertools.groupby(zipped, key=key)\n\tgroups = (\n\t\ttuple(g)\n\t\tfor k, g in grouped\n\t)\n\n\tdef has_dupes(group):\n\t\treturn len(group) > 1\n\treturn filter(has_dupes, groups)", "response": "Yield duplicate items from any number of sorted iterables of items\n\t"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef assert_ordered(iterable, key=lambda x: x, comp=operator.le):\n\terr_tmpl = (\n\t\t\"{pair[0]} > {pair[1]}\" if comp is operator.le else\n\t\t\"{pair[0]} < {pair[1]}\" if comp is operator.ge else\n\t\t\"not {comp} {pair}\"\n\t)\n\tfor pair in more_itertools.pairwise(iterable):\n\t\tkeyed = tuple(map(key, pair))\n\t\tassert comp(*keyed), err_tmpl.format(**locals())\n\t\tyield pair[0]\n\tyield pair[1]", "response": "assert that all items in the iterable are in order based on comp"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef collate_revs(old, new, key=lambda x: x, merge=lambda old, new: new):\n\tmissing = object()\n\n\tdef maybe_merge(*items):\n\t\t\"\"\"\n\t\tMerge any non-null items\n\t\t\"\"\"\n\t\tdef not_missing(ob):\n\t\t\treturn ob is not missing\n\n\t\treturn functools.reduce(merge, filter(not_missing, items))\n\n\tnew_items = collections.OrderedDict(\n\t\t(key(el), el)\n\t\tfor el in new\n\t)\n\told_items = collections.OrderedDict(\n\t\t(key(el), el)\n\t\tfor el in old\n\t)\n\n\t# use the old_items as a reference\n\tfor old_key, old_item in _mutable_iter(old_items):\n\t\tif old_key not in new_items:\n\t\t\tyield old_item\n\t\t\tcontinue\n\n\t\t# yield all new items that appear before the matching key\n\t\tbefore, match_new, new_items = _swap_on_miss(\n\t\t\tpartition_dict(new_items, old_key))\n\t\tfor new_key, new_item in before.items():\n\t\t\t# ensure any new keys are merged with previous items if\n\t\t\t# they exist\n\t\t\tyield maybe_merge(new_item, old_items.pop(new_key, missing))\n\t\tyield merge(old_item, match_new)\n\n\t# finally, yield whatever is leftover\n\t# yield from new_items.values()\n\tfor item in new_items.values():\n\t\tyield item", "response": "This function collates two revision sets old and new into a single set of items yielded in stable order."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _mutable_iter(dict):\n\twhile dict:\n\t\tprev_key = next(iter(dict))\n\t\tyield prev_key, dict.pop(prev_key)", "response": "Iterate over items in the dict yielding the first one and the rest of the items."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nswap the partition_dict result before and after.", "response": "def _swap_on_miss(partition_result):\n\t\"\"\"\n\tGiven a partition_dict result, if the partition missed, swap\n\tthe before and after.\n\t\"\"\"\n\tbefore, item, after = partition_result\n\treturn (before, item, after) if item else (after, item, before)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\npartitions a dictionary of items and a key in that dict.", "response": "def partition_dict(items, key):\n\t\"\"\"\n\tGiven an ordered dictionary of items and a key in that dict,\n\treturn an ordered dict of items before, the keyed item, and\n\tan ordered dict of items after.\n\n\t>>> od = collections.OrderedDict(zip(range(5), 'abcde'))\n\t>>> before, item, after = partition_dict(od, 3)\n\t>>> before\n\tOrderedDict([(0, 'a'), (1, 'b'), (2, 'c')])\n\t>>> item\n\t'd'\n\t>>> after\n\tOrderedDict([(4, 'e')])\n\n\tLike string.partition, if the key is not found in the items,\n\tthe before will contain all items, item will be None, and\n\tafter will be an empty iterable.\n\n\t>>> before, item, after = partition_dict(od, -1)\n\t>>> before\n\tOrderedDict([(0, 'a'), ..., (4, 'e')])\n\t>>> item\n\t>>> list(after)\n\t[]\n\t\"\"\"\n\tdef unmatched(pair):\n\t\ttest_key, item, = pair\n\t\treturn test_key != key\n\n\titems_iter = iter(items.items())\n\titem = items.get(key)\n\tleft = collections.OrderedDict(itertools.takewhile(unmatched, items_iter))\n\tright = collections.OrderedDict(items_iter)\n\treturn left, item, right"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the first n queues in the sequence.", "response": "def get_first_n_queues(self, n):\n\t\t\"\"\"\n\t\tRun through the sequence until n queues are created and return\n\t\tthem. If fewer are created, return those plus empty iterables to\n\t\tcompensate.\n\t\t\"\"\"\n\t\ttry:\n\t\t\twhile len(self.queues) < n:\n\t\t\t\tself.__fetch__()\n\t\texcept StopIteration:\n\t\t\tpass\n\t\tvalues = list(self.queues.values())\n\t\tmissing = n - len(values)\n\t\tvalues.extend(iter([]) for n in range(missing))\n\t\treturn values"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nresets the iterator to the start and resets the saved values.", "response": "def reset(self):\n\t\t\"\"\"\n\t\tResets the iterator to the start.\n\n\t\tAny remaining values in the current iteration are discarded.\n\t\t\"\"\"\n\t\tself.__iterator, self.__saved = itertools.tee(self.__saved)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_as_var(parser, token):\n    if isinstance(token, Token):\n        bits = token.split_contents()\n    else:\n        bits = token\n\n    as_var = None\n    if len(bits) > 2 and bits[-2] == 'as':\n        bits = bits[:]\n        as_var = bits.pop()\n        bits.pop()  # as keyword\n\n    return bits, as_var", "response": "Parses the remainder of the token to find a as varname statement."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_token_kwargs(parser, token, allowed_kwargs=None, compile_args=True, compile_kwargs=True):\n    if isinstance(token, Token):\n        bits = token.split_contents()\n    else:\n        bits = token\n\n    expect_kwarg = False\n    args = []\n    kwargs = {}\n    prev_bit = None\n\n    tag_name = bits[0]\n\n    for bit in bits[1::]:\n        kwarg_match = kwarg_re.match(bit)\n        if kwarg_match:\n            # Keyword argument\n            expect_kwarg = True\n            (name, expr) = bit.split('=', 2)\n            kwargs[name] = parser.compile_filter(expr) if compile_kwargs else expr\n        else:\n            # Still at positioned arguments.\n            if expect_kwarg:\n                raise TemplateSyntaxError(\"{0} tag may not have a non-keyword argument ({1}) after a keyword argument ({2}).\".format(bits[0], bit, prev_bit))\n            args.append(parser.compile_filter(bit) if compile_args else bit)\n\n        prev_bit = bit\n\n    # Validate the allowed arguments, to make things easier for template developers\n    if allowed_kwargs is not None and kwargs:\n        if not allowed_kwargs:\n            raise TemplateSyntaxError(\"The option %s=... cannot be used in '%s'.\\nNo keyword arguments are allowed.\")\n\n        for name in kwargs:\n            if name not in allowed_kwargs:\n                raise TemplateSyntaxError(\"The option %s=... cannot be used in '%s'.\\nPossible options are: %s.\" % (name, bits[0], \", \".join(allowed_kwargs)))\n\n    return tag_name, args, kwargs", "response": "Parses the keyword arguments of a tag."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nserializes a tuple into a BIP32 format", "response": "def bip32_serialize(rawtuple):\n    \"\"\"\n    Derived from code from pybitcointools (https://github.com/vbuterin/pybitcointools)\n    by Vitalik Buterin\n    \"\"\"\n    vbytes, depth, fingerprint, i, chaincode, key = rawtuple\n    i = encode(i, 256, 4)\n    chaincode = encode(hash_to_int(chaincode), 256, 32)\n    keydata = b'\\x00'  +key[:-1] if vbytes in PRIVATE else key\n    bindata = vbytes + from_int_to_byte(depth % 256) + fingerprint + i + chaincode + keydata\n    return changebase(bindata + bin_dbl_sha256(bindata)[:4], 256, 58)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nderiving from code from pybitcointools (https://github.com/vbuterin/pybitcointools) by Vitalik Buterin", "response": "def bip32_deserialize(data):\n    \"\"\"\n    Derived from code from pybitcointools (https://github.com/vbuterin/pybitcointools)\n    by Vitalik Buterin\n    \"\"\"\n    dbin = changebase(data, 58, 256)\n    if bin_dbl_sha256(dbin[:-4])[:4] != dbin[-4:]:\n        raise Exception(\"Invalid checksum\")\n    vbytes = dbin[0:4]\n    depth = from_byte_to_int(dbin[4])\n    fingerprint = dbin[5:9]\n    i = decode(dbin[9:13], 256)\n    chaincode = dbin[13:45]\n    key = dbin[46:78]+b'\\x01' if vbytes in PRIVATE else dbin[45:78]\n    return (vbytes, depth, fingerprint, i, chaincode, key)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fetch_table_names(self, include_system_table=False):\n\n        result = self.__cur.execute(\"SELECT name FROM sqlite_master WHERE TYPE='table'\")\n        if result is None:\n            return []\n\n        table_names = [record[0] for record in result.fetchall()]\n\n        if include_system_table:\n            return table_names\n\n        return [table for table in table_names if table not in SQLITE_SYSTEM_TABLES]", "response": "Returns a list of table names in the database."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfetch sqlite_master table information as a list of dictionaries.", "response": "def fetch_sqlite_master(self):\n        \"\"\"\n        Get sqlite_master table information as a list of dictionaries.\n\n        :return: sqlite_master table information.\n        :rtype: list\n\n        :Sample Code:\n            .. code:: python\n\n                from sqliteschema import SQLiteSchemaExtractor\n\n                print(json.dumps(SQLiteSchemaExtractor(\"sample.sqlite\").fetch_sqlite_master(), indent=4))\n\n        :Output:\n            .. code-block:: json\n\n                [\n                    {\n                        \"tbl_name\": \"sample_table\",\n                        \"sql\": \"CREATE TABLE 'sample_table' ('a' INTEGER, 'b' REAL, 'c' TEXT, 'd' REAL, 'e' TEXT)\",\n                        \"type\": \"table\",\n                        \"name\": \"sample_table\",\n                        \"rootpage\": 2\n                    },\n                    {\n                        \"tbl_name\": \"sample_table\",\n                        \"sql\": \"CREATE INDEX sample_table_a_index ON sample_table('a')\",\n                        \"type\": \"index\",\n                        \"name\": \"sample_table_a_index\",\n                        \"rootpage\": 3\n                    }\n                ]\n        \"\"\"\n\n        sqlite_master_record_list = []\n        result = self.__cur.execute(\n            \"SELECT {:s} FROM sqlite_master\".format(\", \".join(self._SQLITE_MASTER_ATTR_NAME_LIST))\n        )\n\n        for record in result.fetchall():\n            sqlite_master_record_list.append(\n                dict(\n                    [\n                        [attr_name, item]\n                        for attr_name, item in zip(self._SQLITE_MASTER_ATTR_NAME_LIST, record)\n                    ]\n                )\n            )\n\n        return sqlite_master_record_list"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nyields each node of object graph in postorder.", "response": "def object_iter(obj, parent=None, parent_key=None, idx=None,\n                siblings=None):\n    \"\"\"Yields each node of object graph in postorder.\"\"\"\n\n    obj_node = Node(value=obj, parent=parent, parent_key=parent_key,\n                siblings=siblings, idx=idx)\n\n    if isinstance(obj, list):\n        _siblings = len(obj)\n        for i, elem in enumerate(obj):\n            for node in object_iter(elem, obj_node, None, i + 1, _siblings):\n                yield node\n    elif isinstance(obj, collections.Mapping):\n        for key in obj:\n            for node in object_iter(obj[key], obj_node, key):\n                yield node\n    yield obj_node"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef select(selector, obj):\n\n    parser = Parser(obj)\n    try:\n        return parser.parse(selector)\n    except SelectorSyntaxError as e:\n        log.exception(e)\n        return False", "response": "Appy selector to obj and return matching nodes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse(self, selector):\n        log.debug(self.obj)\n        tokens = lex(selector)\n\n        if self.peek(tokens, 'operator') == '*':\n            self.match(tokens, 'operator')\n            results = list(object_iter(self.obj))\n        else:\n            results = self.selector_production(tokens)\n\n        results = [node.value for node in results]\n        # single results should be returned as a primitive\n        if len(results) == 1:\n            return results[0]\n        elif not len(results):\n            return None\n        return results", "response": "Accept a list of tokens. Returns matched nodes of self. obj."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef selector_production(self, tokens):\n\n        validators = []\n        # the following productions should return predicate functions.\n\n        if self.peek(tokens, 'type'):\n            type_ = self.match(tokens, 'type')\n            validators.append(self.type_production(type_))\n\n        if self.peek(tokens, 'identifier'):\n            key = self.match(tokens, 'identifier')\n            validators.append(self.key_production(key))\n\n        if self.peek(tokens, 'pclass'):\n            pclass = self.match(tokens, 'pclass')\n            validators.append(self.pclass_production(pclass))\n\n        if self.peek(tokens, 'nth_func'):\n            nth_func = self.match(tokens, 'nth_func')\n            validators.append(self.nth_child_production(nth_func, tokens))\n\n        if self.peek(tokens, 'pclass_func'):\n            pclass_func = self.match(tokens, 'pclass_func')\n            validators.append(self.pclass_func_production(pclass_func, tokens))\n\n        if not len(validators):\n            raise SelectorSyntaxError('no selector recognized.')\n\n        # apply validators from a selector expression to self.obj\n        results = self._match_nodes(validators, self.obj)\n\n        if self.peek(tokens, 'operator'):\n            operator = self.match(tokens, 'operator')\n            rvals = self.selector_production(tokens)\n            if operator == ',':\n                results.extend(rvals)\n            elif operator == '>':\n                results = self.parents(results, rvals)\n            elif operator == '~':\n                results = self.siblings(results, rvals)\n            elif operator == ' ':\n                results = self.ancestors(results, rvals)\n            else:\n                raise SelectorSyntaxError(\"unrecognized operator '%s'\"\n                                          % operator)\n        else:\n            if len(tokens):\n                rvals = self.selector_production(tokens)\n                results = self.ancestors(results, rvals)\n\n        return results", "response": "Production for a full selector."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parents(self, lhs, rhs):\n\n        return [node for node in rhs if node.parent in lhs]", "response": "Find nodes in rhs which have parents in lhs."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn nodes from rhs which have ancestors in lhs.", "response": "def ancestors(self, lhs, rhs):\n        \"\"\"Return nodes from rhs which have ancestors in lhs.\"\"\"\n\n        def _search(node):\n            if node in lhs:\n                return True\n            if not node.parent:\n                return False\n            return _search(node.parent)\n\n        return [node for node in rhs if _search(node)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfinds nodes in lhs having common parents in rhs.", "response": "def siblings(self, lhs, rhs):\n        \"\"\"Find nodes in rhs having common parents in lhs.\"\"\"\n        parents = [node.parent for node in lhs]\n\n        return [node for node in rhs if node.parent in parents]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing nth - child production.", "response": "def nth_child_production(self, lexeme, tokens):\n        \"\"\"Parse args and pass them to pclass_func_validator.\"\"\"\n\n        args = self.match(tokens, 'expr')\n\n        pat = self.nth_child_pat.match(args)\n\n        if pat.group(5):\n            a = 2\n            b = 1 if pat.group(5) == 'odd' else 0\n        elif pat.group(6):\n            a = 0\n            b = int(pat.group(6))\n        else:\n            sign = pat.group(1) if pat.group(1) else '+'\n            coef = pat.group(2) if pat.group(2) else '1'\n            a = eval(sign + coef)\n            b = eval(pat.group(3) + pat.group(4)) if pat.group(3) else 0\n\n        reverse = False\n        if lexeme == 'nth-last-child':\n            reverse = True\n\n        def validate(node):\n            \"\"\"This crazy function taken from jsonselect.js:444.\"\"\"\n\n            if not node.siblings:\n                return False\n\n            idx = node.idx - 1\n            tot = node.siblings\n\n            if reverse:\n                idx = tot - idx\n            else:\n                idx += 1\n\n            if a == 0:\n                m = b == idx\n            else:\n                mod = (idx - b) % a\n                m = not mod and (idx * a + b) >= 0\n            return m\n\n        return validate"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _match_nodes(self, validators, obj):\n\n        results = []\n        for node in object_iter(obj):\n            if all([validate(node) for validate in validators]):\n                results.append(node)\n        return results", "response": "Apply each validator in validators to each node in obj.\n\n        Return each node in obj which matches all validators."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ping(dst, count, inter=0.2, maxwait=1000, size=64):\n    def _then(result, p):\n        p.stopListening()\n        return result\n\n    d = defer.Deferred()\n    p = ICMPPort(0, ICMPPing(d, dst, count, inter, maxwait, size), \"\", 8192, reactor)\n    p.startListening()\n\n    return d.addCallback(_then, p)", "response": "Sends ICMP echo requests to destination dst count times."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmakes an HTTP request and return the body", "response": "def getBody(self, url, method='GET', headers={}, data=None, socket=None):\n        \"\"\"Make an HTTP request and return the body\n        \"\"\"\n\n        if not 'User-Agent' in headers:\n            headers['User-Agent'] = ['Tensor HTTP checker']\n\n        return self.request(url, method, headers, data, socket)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nexpire any items in the cache older than age seconds", "response": "def expire(self, age):\n        \"\"\"Expire any items in the cache older than `age` seconds\"\"\"\n        now = time.time()\n        cache = self._acquire_cache()\n        \n        expired = [k for k, v in cache.items() if (now - v[0]) > age]\n\n        for k in expired:\n            if k in cache:\n                del cache[k]\n            if k in self.store:\n                del self.store[k]\n\n        self._write_cache(cache)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset a key k to value v", "response": "def set(self, k, v):\n        \"\"\"Set a key `k` to value `v`\"\"\"\n        self.store[k] = (time.time(), v)\n        self._persist()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn key contents and modify time", "response": "def get(self, k):\n        \"\"\"Returns key contents, and modify time\"\"\"\n        if self._changed():\n            self._read()\n\n        if k in self.store:\n            return tuple(self.store[k])\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef contains(self, k):\n        if self._changed():\n            self._read()\n        return k in self.store.keys()", "response": "Return True if key k exists"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nverifying the chain integrity.", "response": "def chain_check(cls, timestamp: int) -> bool:\n        \"\"\"\n        Given a record timestamp, verify the chain integrity.\n\n        :param timestamp: UNIX time / POSIX time / Epoch time\n        :return: 'True' if the timestamp fits the chain. 'False' otherwise.\n        \"\"\"\n\n        # Creation is messy.\n        # You want genius, you get madness; two sides of the same coin.\n        # ... I'm sure this can be cleaned up. However, let's test it first.\n\n        record = cls.get_record(timestamp)\n\n        if isinstance(record, NistBeaconValue) is False:\n            # Don't you dare try to play me\n            return False\n\n        prev_record = cls.get_previous(record.timestamp)\n        next_record = cls.get_next(record.timestamp)\n\n        if prev_record is None and next_record is None:\n            # Uh, how did you manage to do this?\n            # I'm not even mad, that's amazing.\n            return False\n\n        if (\n                isinstance(prev_record, NistBeaconValue) and\n                isinstance(next_record, NistBeaconValue)\n        ):\n            # Majority case, somewhere in the middle of the chain\n            # True if:\n            #   - All three records have proper signatures\n            #   - The requested record's previous output equals previous\n            #   - The next possible record's previous output equals the record\n            return (\n                record.valid_signature and\n                prev_record.valid_signature and\n                next_record.valid_signature and\n                record.previous_output_value == prev_record.output_value and\n                next_record.previous_output_value == record.output_value\n            )\n\n        if (\n                prev_record is None and\n                isinstance(next_record, NistBeaconValue)\n        ):\n            # Edge case, this was potentially the first record of all time\n            return (\n                record.valid_signature and\n                next_record.valid_signature and\n                cls._INIT_RECORD == record and\n                next_record.previous_output_value == record.output_value\n            )\n\n        if (\n                isinstance(prev_record, NistBeaconValue) and\n                next_record is None\n        ):\n            # Edge case, this was potentially the latest and greatest\n            return (\n                record.valid_signature and\n                prev_record.valid_signature and\n                record.previous_output_value == prev_record.output_value\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_first_record(\n            cls,\n            download: bool=True\n    ) -> NistBeaconValue:\n        \"\"\"\n        Get the first (oldest) record available. Since the first record\n        IS a known value in the system we can load it from constants.\n\n        :param download: 'True' will always reach out to NIST to get the\n                         first record. 'False' returns a local copy.\n        :return: The first beacon value. 'None' otherwise.\n        \"\"\"\n\n        if download:\n            return NistBeacon.get_record(cls._INIT_RECORD.timestamp)\n        else:\n            return NistBeaconValue.from_json(cls._INIT_RECORD.json)", "response": "Get the first record available."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert a string of JSON which represents a NIST randomness beacon value into a Nist RandomnessBeaconValue object.", "response": "def from_json(cls, input_json: str) -> 'NistBeaconValue':\n        \"\"\"\n        Convert a string of JSON which represents a NIST randomness beacon\n        value into a 'NistBeaconValue' object.\n\n        :param input_json: JSON to build a 'Nist RandomnessBeaconValue' from\n        :return: A 'NistBeaconValue' object, 'None' otherwise\n        \"\"\"\n\n        try:\n            data_dict = json.loads(input_json)\n        except ValueError:\n            return None\n\n        # Our required values are \"must haves\". This makes it simple\n        # to verify we loaded everything out of JSON correctly.\n        required_values = {\n            cls._KEY_FREQUENCY: None,\n            cls._KEY_OUTPUT_VALUE: None,\n            cls._KEY_PREVIOUS_OUTPUT_VALUE: None,\n            cls._KEY_SEED_VALUE: None,\n            cls._KEY_SIGNATURE_VALUE: None,\n            cls._KEY_STATUS_CODE: None,\n            cls._KEY_TIMESTAMP: None,\n            cls._KEY_VERSION: None,\n        }\n\n        for key in required_values:\n            if key in data_dict:\n                required_values[key] = data_dict[key]\n\n        # Confirm that the required values are set, and not 'None'\n        if None in required_values.values():\n            return None\n\n        # We have all the required values, return a node object\n        return cls(\n            version=required_values[cls._KEY_VERSION],\n            frequency=int(required_values[cls._KEY_FREQUENCY]),\n            timestamp=int(required_values[cls._KEY_TIMESTAMP]),\n            seed_value=required_values[cls._KEY_SEED_VALUE],\n            previous_output_value=required_values[\n                cls._KEY_PREVIOUS_OUTPUT_VALUE\n            ],\n            signature_value=required_values[cls._KEY_SIGNATURE_VALUE],\n            output_value=required_values[cls._KEY_OUTPUT_VALUE],\n            status_code=required_values[cls._KEY_STATUS_CODE],\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef from_xml(cls, input_xml: str) -> 'NistBeaconValue':\n\n        invalid_result = None\n\n        understood_namespaces = {\n            'nist-0.1': 'http://beacon.nist.gov/record/0.1/',\n        }\n\n        # Our required values are \"must haves\". This makes it simple\n        # to verify we loaded everything out of XML correctly.\n        required_values = {\n            cls._KEY_FREQUENCY: None,\n            cls._KEY_OUTPUT_VALUE: None,\n            cls._KEY_PREVIOUS_OUTPUT_VALUE: None,\n            cls._KEY_SEED_VALUE: None,\n            cls._KEY_SIGNATURE_VALUE: None,\n            cls._KEY_STATUS_CODE: None,\n            cls._KEY_TIMESTAMP: None,\n            cls._KEY_VERSION: None,\n        }\n\n        # First attempt to load the xml, return 'None' on ParseError\n        try:\n            tree = ElementTree.ElementTree(ElementTree.fromstring(input_xml))\n        except ElementTree.ParseError:\n            return invalid_result\n\n        # Using the required values, let's load the xml values in\n        for key in required_values:\n            discovered_element = tree.find(\n                \"{0}:{1}\".format('nist-0.1', key),\n                namespaces=understood_namespaces,\n            )\n\n            if not isinstance(discovered_element, ElementTree.Element):\n                continue\n\n            # Bad pylint message - https://github.com/PyCQA/pylint/issues/476\n            # pylint: disable=no-member\n            required_values[key] = discovered_element.text\n\n        # Confirm that the required values are set, and not 'None'\n        if None in required_values.values():\n            return invalid_result\n\n        # We have all the required values, return a node object\n        return cls(\n            version=required_values[cls._KEY_VERSION],\n            frequency=int(required_values[cls._KEY_FREQUENCY]),\n            timestamp=int(required_values[cls._KEY_TIMESTAMP]),\n            seed_value=required_values[cls._KEY_SEED_VALUE],\n            previous_output_value=required_values[\n                cls._KEY_PREVIOUS_OUTPUT_VALUE\n            ],\n            signature_value=required_values[cls._KEY_SIGNATURE_VALUE],\n            output_value=required_values[cls._KEY_OUTPUT_VALUE],\n            status_code=required_values[cls._KEY_STATUS_CODE],\n        )", "response": "Convert a string of XML which represents a NIST Randomness Beacon value\n            into a NistBeaconValue object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a minified version of the javascript content", "response": "def rendered_content(self):\n        \"\"\"Returns a 'minified' version of the javascript content\"\"\"\n        template = self.resolve_template(self.template_name)\n        if django.VERSION[1] < 8:\n            if template.name.endswith('.min'):\n                return super(MinifiedJsTemplateResponse, self).rendered_content\n        else:\n            if template.template.name.endswith('.min'):\n                return super(MinifiedJsTemplateResponse, self).rendered_content\n        # if no minified template exists, minify the response\n        content = super(MinifiedJsTemplateResponse, self).rendered_content\n        content = jsmin.jsmin(content)\n        return content"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_fn(self, fn, max_lines=None):\n        stat = os.stat(self.logfile)\n\n        if (stat.st_ino == self.lastInode) and (stat.st_size == self.lastSize):\n            # Nothing new\n            return []\n\n        # Handle rollover and rotations vaguely\n        if (stat.st_ino != self.lastInode) or (stat.st_size < self.lastSize):\n            self.lastSize = 0\n\n        fi = open(self.logfile, 'rt')\n        fi.seek(self.lastSize)\n\n        self.lastInode = stat.st_ino\n\n        lines = 0\n\n        for i in fi:\n            lines += 1\n            if max_lines and (lines > max_lines):\n                self.storeLast()\n                fi.close()\n                return \n\n            if '\\n' in i:\n                self.lastSize += len(i)\n                if self.parser:\n                    line = self.parser(i.strip('\\n'))\n                else:\n                    line = i.strip('\\n')\n\n                fn(line)\n\n        self.storeLast()\n\n        fi.close()", "response": "Passes each parsed log line to fn"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a big list of all log lines since the last run", "response": "def get(self, max_lines=None):\n        \"\"\"Returns a big list of all log lines since the last run\n        \"\"\"\n        rows = []\n\n        self.get_fn(lambda row: rows.append(row), max_lines=max_lines)\n\n        return rows"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_token(self, obj_id, extra_data):\n        return self.dumps(\n            dict(\n                id=obj_id,\n                data=extra_data,\n                rnd=binascii.hexlify(os.urandom(4)).decode('utf-8')\n            )\n        )", "response": "Create a token referencing the object id with extra data."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef validate_token(self, token, expected_data=None):\n        try:\n            # Load token and remove random data.\n            data = self.load_token(token)\n\n            # Compare expected data with data in token.\n            if expected_data:\n                for k in expected_data:\n                    if expected_data[k] != data[\"data\"].get(k):\n                        return None\n            return data\n        except BadData:\n            return None", "response": "Validate secret link token."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads data in a token.", "response": "def load_token(self, token, force=False):\n        \"\"\"Load data in a token.\n\n        :param token: Token to load.\n        :param force: Load token data even if signature expired.\n                      Default: False.\n        \"\"\"\n        try:\n            data = self.loads(token)\n        except SignatureExpired as e:\n            if not force:\n                raise\n            data = e.payload\n\n        del data[\"rnd\"]\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_token(self, obj_id, extra_data):\n        return self.engine.encrypt(\n            super(EncryptedTokenMixIn, self).create_token(obj_id, extra_data)\n        )", "response": "Create a token referencing the object id with extra data."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads data in a token.", "response": "def load_token(self, token, force=False):\n        \"\"\"Load data in a token.\n\n        :param token: Token to load.\n        :param force: Load token data even if signature expired.\n                      Default: False.\n        \"\"\"\n        return super(EncryptedTokenMixIn, self).load_token(\n            self.engine.decrypt(token), force=force\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate the secret link token.", "response": "def create_token(cls, obj_id, data, expires_at=None):\n        \"\"\"Create the secret link token.\"\"\"\n        if expires_at:\n            s = TimedSecretLinkSerializer(expires_at=expires_at)\n        else:\n            s = SecretLinkSerializer()\n\n        return s.create_token(obj_id, data)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef validate_token(cls, token, expected_data=None):\n        for algorithm in SUPPORTED_DIGEST_ALGORITHMS:\n            s = SecretLinkSerializer(algorithm_name=algorithm)\n            st = TimedSecretLinkSerializer(algorithm_name=algorithm)\n\n            try:\n                for serializer in (s, st):\n                    data = serializer.validate_token(\n                        token, expected_data=expected_data)\n                    if data:\n                        return data\n            except SignatureExpired:  # move to next algorithm\n                raise\n            except BadData:\n                continue", "response": "Validate a secret link token."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nvalidates a secret link token.", "response": "def load_token(cls, token, force=False):\n        \"\"\"Validate a secret link token (non-expiring + expiring).\"\"\"\n        for algorithm in SUPPORTED_DIGEST_ALGORITHMS:\n            s = SecretLinkSerializer(algorithm_name=algorithm)\n            st = TimedSecretLinkSerializer(algorithm_name=algorithm)\n            for serializer in (s, st):\n                try:\n                    data = serializer.load_token(token, force=force)\n                    if data:\n                        return data\n                except SignatureExpired:\n                    raise  # signature was parsed and is expired\n                except BadData:\n                    continue"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef Counter32(a, b, delta):\n    if b < a:\n        c = 4294967295 - a\n        return (c + b) / float(delta)\n\n    return (b - a) / float(delta)", "response": "32bit counter aggregator with wrapping\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef Counter(a, b, delta):\n    if b < a:\n        return None \n\n    return (b - a) / float(delta)", "response": "Calculate the ratio of two items in a counter."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset up sources from the given config", "response": "def setupSources(self, config):\n        \"\"\"Sets up source objects from the given config\"\"\"\n        sources = config.get('sources', [])\n\n        for source in sources:\n            src = self.createSource(source)\n            self.setupTriggers(source, src)\n\n            self.sources.append(src)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _parse_format(self, format):\n        format = format.strip()\n        format = re.sub('[ \\t]+',' ',format)\n        \n        subpatterns = []\n\n        findquotes = re.compile(r'^\\\\\"')\n        findreferreragent = re.compile('Referer|User-Agent')\n        findpercent = re.compile('^%.*t$')\n        lstripquotes = re.compile(r'^\\\\\"')\n        rstripquotes = re.compile(r'\\\\\"$')\n        header = re.compile(r'.*%\\{([^\\}]+)\\}i')\n        \n        for element in format.split(' '):\n\n            hasquotes = 0\n            if findquotes.search(element): hasquotes = 1\n\n            if hasquotes:\n                element = lstripquotes.sub('', element)\n                element = rstripquotes.sub('', element)\n            \n            head = header.match(element)\n            if head:\n                self._names.append(head.groups()[0].lower())\n                self._types.append(str)\n            else:\n                self._names.append(self.alias(element))\n                self._types.append(self.types.get(element, [None, str])[1])\n            \n            subpattern = '(\\S*)'\n            \n            if hasquotes:\n                if element == '%r' or findreferreragent.search(element):\n                    subpattern = r'\\\"([^\"\\\\]*(?:\\\\.[^\"\\\\]*)*)\\\"'\n                else:\n                    subpattern = r'\\\"([^\\\"]*)\\\"'\n                \n            elif findpercent.search(element):\n                subpattern = r'(\\[[^\\]]+\\])'\n                \n            elif element == '%U':\n                subpattern = '(.+?)'\n            \n            subpatterns.append(subpattern)\n        \n        self._pattern = '^' + ' '.join(subpatterns) + '$'\n        try:\n            self._regex = re.compile(self._pattern)\n        except Exception as e:\n            raise ApacheLogParserError(e)", "response": "Converts the input format to a regular expression and returns the fields that are extracted from the internal state."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing a single line from the log file and returns a dictionary of the contents of it s contents. Raises an exception if it couldn t parse the line.", "response": "def parse(self, line):\n        \"\"\"\n        Parses a single line from the log file and returns\n        a dictionary of it's contents.\n\n        Raises and exception if it couldn't parse the line\n        \"\"\"\n        line = line.strip()\n        match = self._regex.match(line)\n        \n        if match:\n            data = {}\n            for i, e in enumerate(match.groups()):\n                if e == \"-\":\n                    k, v = self._names[i], None\n                else:\n                    k, v = self._names[i], self._types[i](e)\n                data[k] = v\n            return data\n        \n        raise ApacheLogParserError(\"Unable to parse: %s\" % line)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef validate_expires_at(form, field):\n    if form.accept.data:\n        if not field.data or datetime.utcnow().date() >= field.data:\n            raise validators.StopValidation(_(\n                \"Please provide a future date.\"\n            ))\n        if not field.data or \\\n                datetime.utcnow().date() + timedelta(days=365) < field.data:\n            raise validators.StopValidation(_(\n                \"Please provide a date no more than 1 year into the future.\"\n            ))", "response": "Validate that the date is in the future."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef validate_accept(form, field):\n        if field.data and form.reject.data:\n            raise validators.ValidationError(\n                _(\"Both reject and accept cannot be set at the same time.\")\n            )", "response": "Validate that reject and accept are not set at the same time."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef validate_reject(form, field):\n        if field.data and form.accept.data:\n            raise validators.ValidationError(\n                _(\"Both reject and accept cannot be set at the same time.\")\n            )", "response": "Validate that reject and accept are not set at the same time."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nverify token and save in session if it s valid.", "response": "def verify_token():\n    \"\"\"Verify token and save in session if it's valid.\"\"\"\n    try:\n        from .models import SecretLink\n        token = request.args['token']\n        # if the token is valid\n        if token and SecretLink.validate_token(token, {}):\n            # then save in session the token\n            session['accessrequests-secret-token'] = token\n    except KeyError:\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef name(self):\n        if (\n            self.device_type and\n            self.device_type.code in (DeviceType.MOBILE, DeviceType.TABLET)\n        ):\n            return self.device\n        else:\n            return self.browser", "response": "Return a basic meaningful name based on device type and browser type."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndoes not warn on external images.", "response": "def _warn_node(self, msg, *args, **kwargs):\n    \"\"\"Do not warn on external images.\"\"\"\n    if not msg.startswith('nonlocal image URI found:'):\n        _warn_node_old(self, msg, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconnect receivers to signals.", "response": "def connect_receivers():\n    \"\"\"Connect receivers to signals.\"\"\"\n    request_created.connect(send_email_validation)\n    request_confirmed.connect(send_confirmed_notifications)\n    request_rejected.connect(send_reject_notification)\n    # Order is important:\n    request_accepted.connect(create_secret_link)\n    request_accepted.connect(send_accept_notification)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_secret_link(request, message=None, expires_at=None):\n    pid, record = get_record(request.recid)\n    if not record:\n        raise RecordNotFound(request.recid)\n\n    description = render_template(\n        \"zenodo_accessrequests/link_description.tpl\",\n        request=request,\n        record=record,\n        pid=pid,\n        expires_at=expires_at,\n        message=message,\n    )\n\n    request.create_secret_link(\n        record[\"title\"],\n        description=description,\n        expires_at=expires_at\n    )", "response": "Receiver for request - accepted signal."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef send_confirmed_notifications(request):\n    pid, record = get_record(request.recid)\n    if record is None:\n        current_app.logger.error(\"Cannot retrieve record %s. Emails not sent\"\n                                 % request.recid)\n        return\n    title = _(\"Access request: %(record)s\", record=record[\"title\"])\n\n    _send_notification(\n        request.receiver.email,\n        title,\n        \"zenodo_accessrequests/emails/new_request.tpl\",\n        request=request,\n        record=record,\n        pid=pid,\n    )\n\n    _send_notification(\n        request.sender_email,\n        title,\n        \"zenodo_accessrequests/emails/confirmation.tpl\",\n        request=request,\n        record=record,\n        pid=pid,\n    )", "response": "Receiver for request - confirmed signal to send email notification."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef send_reject_notification(request, message=None):\n    pid, record = get_record(request.recid)\n    _send_notification(\n        request.sender_email,\n        _(\"Access request rejected\"),\n        \"zenodo_accessrequests/emails/rejected.tpl\",\n        request=request,\n        record=record,\n        pid=pid,\n        message=message,\n    )", "response": "Receiver for request - rejected signal to send email notification."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrender a template and send as email.", "response": "def _send_notification(to, subject, template, **ctx):\n    \"\"\"Render a template and send as email.\"\"\"\n    msg = Message(\n        subject,\n        sender=current_app.config.get('SUPPORT_EMAIL'),\n        recipients=[to]\n    )\n    msg.body = render_template(template, **ctx)\n\n    send_email.delay(msg.__dict__)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new secret link.", "response": "def create(cls, title, owner, extra_data, description=\"\", expires_at=None):\n        \"\"\"Create a new secret link.\"\"\"\n        if isinstance(expires_at, date):\n            expires_at = datetime.combine(expires_at, datetime.min.time())\n\n        with db.session.begin_nested():\n            obj = cls(\n                owner=owner,\n                title=title,\n                description=description,\n                expires_at=expires_at,\n                token='',\n            )\n            db.session.add(obj)\n\n        with db.session.begin_nested():\n            # Create token (dependent on obj.id and recid)\n            obj.token = SecretLinkFactory.create_token(\n                obj.id, extra_data, expires_at=expires_at\n            ).decode('utf8')\n\n        link_created.send(obj)\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nvalidate a secret link token.", "response": "def validate_token(cls, token, expected_data):\n        \"\"\"Validate a secret link token.\n\n        Only queries the database if token is valid to determine that the token\n        has not been revoked.\n        \"\"\"\n        data = SecretLinkFactory.validate_token(\n            token, expected_data=expected_data\n        )\n\n        if data:\n            link = cls.query.get(data['id'])\n            if link and link.is_valid():\n                return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading extra data stored in token.", "response": "def extra_data(self):\n        \"\"\"Load token data stored in token (ignores expiry date of tokens).\"\"\"\n        if self.token:\n            return SecretLinkFactory.load_token(self.token, force=True)[\"data\"]\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets absolute url for the given endpoint.", "response": "def get_absolute_url(self, endpoint):\n        \"\"\"Get absolute for secret link (using https scheme).\n\n        The endpoint is passed to ``url_for`` with ``token`` and ``extra_data``\n        as keyword arguments. E.g.::\n\n            >>> link.extra_data\n            dict(recid=1)\n            >>> link.get_absolute_url('record.metadata')\n\n        translates into::\n\n            >>> url_for('record.metadata', token=\"...\", recid=1, )\n        \"\"\"\n        copy = deepcopy(self.extra_data)\n        if 'recid' in copy:\n            copy['pid_value'] = copy.pop('recid')\n        return url_for(\n            endpoint, token=self.token,\n            _external=True, **(copy or {})\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create(cls, recid=None, receiver=None, sender_full_name=None,\n               sender_email=None, justification=None, sender=None):\n        \"\"\"Create a new access request.\n\n        :param recid: Record id (required).\n        :param receiver: User object of receiver (required).\n        :param sender_full_name: Full name of sender (required).\n        :param sender_email: Email address of sender (required).\n        :param justification: Justification message (required).\n        :param sender: User object of sender (optional).\n        \"\"\"\n        sender_user_id = None if sender is None else sender.id\n\n        assert recid\n        assert receiver\n        assert sender_full_name\n        assert sender_email\n        assert justification\n\n        # Determine status\n        status = RequestStatus.EMAIL_VALIDATION\n        if sender and sender.confirmed_at:\n            status = RequestStatus.PENDING\n\n        with db.session.begin_nested():\n            # Create object\n            obj = cls(\n                status=status,\n                recid=recid,\n                receiver_user_id=receiver.id,\n                sender_user_id=sender_user_id,\n                sender_full_name=sender_full_name,\n                sender_email=sender_email,\n                justification=justification\n            )\n\n            db.session.add(obj)\n\n        # Send signal\n        if obj.status == RequestStatus.EMAIL_VALIDATION:\n            request_created.send(obj)\n        else:\n            request_confirmed.send(obj)\n        return obj", "response": "Create a new access request."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting an access request for a specific receiver.", "response": "def get_by_receiver(cls, request_id, user):\n        \"\"\"Get access request for a specific receiver.\"\"\"\n        return cls.query.filter_by(\n            id=request_id,\n            receiver_user_id=user.id\n        ).first()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconfirms that the senders email is valid.", "response": "def confirm_email(self):\n        \"\"\"Confirm that senders email is valid.\"\"\"\n        with db.session.begin_nested():\n            if self.status != RequestStatus.EMAIL_VALIDATION:\n                raise InvalidRequestStateError(RequestStatus.EMAIL_VALIDATION)\n\n            self.status = RequestStatus.PENDING\n        request_confirmed.send(self)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef reject(self, message=None):\n        with db.session.begin_nested():\n            if self.status != RequestStatus.PENDING:\n                raise InvalidRequestStateError(RequestStatus.PENDING)\n            self.status = RequestStatus.REJECTED\n        request_rejected.send(self, message=message)", "response": "Reject the current request."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a secret link from request.", "response": "def create_secret_link(self, title, description=None, expires_at=None):\n        \"\"\"Create a secret link from request.\"\"\"\n        self.link = SecretLink.create(\n            title,\n            self.receiver,\n            extra_data=dict(recid=self.recid),\n            description=description,\n            expires_at=expires_at,\n        )\n        return self.link"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncomputing the SHA512 hash for a given NistBeaconValue object.", "response": "def get_hash(\n            cls,\n            version: str,\n            frequency: int,\n            timestamp: int,\n            seed_value: str,\n            prev_output: str,\n            status_code: str,\n    ) -> SHA512Hash:\n        \"\"\"\n        Given required properties from a NistBeaconValue,\n        compute the SHA512Hash object.\n\n        :param version: NistBeaconValue.version\n        :param frequency: NistBeaconValue.frequency\n        :param timestamp: NistBeaconValue.timestamp\n        :param seed_value: NistBeaconValue.seed_value\n        :param prev_output: NistBeaconValue.previous_output_value\n        :param status_code: NistBeaconValue.status_code\n\n        :return: SHA512 Hash for NistBeaconValue signature verification\n        \"\"\"\n        return SHA512.new(\n            version.encode() +\n            struct.pack(\n                '>1I1Q64s64s1I',\n                frequency,\n                timestamp,\n                binascii.a2b_hex(seed_value),\n                binascii.a2b_hex(prev_output),\n                int(status_code),\n            )\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nverifies a given NIST record.", "response": "def verify(\n            cls,\n            timestamp: int,\n            message_hash: SHA512Hash,\n            signature: bytes,\n    ) -> bool:\n        \"\"\"\n        Verify a given NIST message hash and signature for a beacon value.\n\n        :param timestamp: The timestamp of the record being verified.\n        :param message_hash:\n            The hash that was carried out over the message.\n            This is an object belonging to the `Crypto.Hash` module.\n        :param signature: The signature that needs to be validated.\n        :return: True if verification is correct. False otherwise.\n        \"\"\"\n\n        # Determine verifier type to use based on timestamp.\n        if timestamp < 1496176860:\n            verifier = cls._VERIFIER_20130905\n        elif timestamp < 1502202360:\n            verifier = None\n        else:\n            verifier = cls._VERIFIER_20170808\n\n        # If a verifier exists to handle this problem, use it directly.\n        # Else, we cannot verify the record and must mark it invalid.\n        if verifier:\n            result = verifier.verify(\n                message_hash,\n                signature,\n            )\n        else:\n            result = False\n\n        # Convert 1 to 'True', 'False' otherwise\n        if isinstance(result, int):\n            result = True if result == 1 else False\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntemplate filter to check if a record is embargoed.", "response": "def is_embargoed(record):\n    \"\"\"Template filter to check if a record is embargoed.\"\"\"\n    return record.get('access_right') == 'embargoed' and \\\n        record.get('embargo_date') and \\\n        record.get('embargo_date') > datetime.utcnow().date()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate an access request.", "response": "def access_request(pid, record, template, **kwargs):\n    \"\"\"Create an access request.\"\"\"\n    recid = int(pid.pid_value)\n    datastore = LocalProxy(\n        lambda: current_app.extensions['security'].datastore)\n\n    # Record must be in restricted access mode.\n    if record.get('access_right') != 'restricted' or \\\n       not record.get('access_conditions'):\n        abort(404)\n\n    # Record must have an owner and owner must still exists.\n    owners = record.get('owners', [])\n    record_owners = [datastore.find_user(id=owner_id) for owner_id in owners]\n    if not record_owners:\n        abort(404)\n\n    sender = None\n    initialdata = dict()\n\n    # Prepare initial form data\n    if current_user.is_authenticated:\n        sender = current_user\n        initialdata['email'] = current_user.email\n        if current_user.profile:\n            initialdata['full_name'] = current_user.profile.full_name\n\n    # Normal form validation\n    form = AccessRequestForm(formdata=request.form, **initialdata)\n\n    if form.validate_on_submit():\n        accreq = AccessRequest.create(\n            recid=recid,\n            receiver=record_owners[0],\n            sender_full_name=form.data['full_name'],\n            sender_email=form.data['email'],\n            justification=form.data['justification'],\n            sender=sender\n        )\n        db.session.commit()\n\n        if accreq.status == RequestStatus.EMAIL_VALIDATION:\n            flash(_(\n                \"Email confirmation needed: We have sent you an email to \"\n                \"verify your address. Please check the email and follow the \"\n                \"instructions to complete the access request.\"),\n                category='info')\n        else:\n            flash(_(\"Access request submitted.\"), category='info')\n        return redirect(url_for('invenio_records_ui.recid', pid_value=recid))\n\n    return render_template(\n        template,\n        pid=pid,\n        record=record,\n        form=form,\n        owners=record_owners,\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a generic endpoint that doesn t finish", "response": "def _get_endpoint(self):\n        \"\"\" Creates a generic endpoint connection that doesn't finish\n        \"\"\"\n        return SSHCommandClientEndpoint.newConnection(\n            reactor, b'/bin/cat', self.username, self.hostname,\n            port=self.port, keys=self.keys, password=self.password,\n            knownHosts = self.knownHosts)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef reverse(self, col):\n        if col in self.options:\n            if self.is_selected(col):\n                return col if not self.asc else '-{0}'.format(col)\n            else:\n                return col\n        return None", "response": "Get reverse direction of ordering."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dir(self, col, asc='asc', desc='desc'):\n        if col == self._selected and self.asc is not None:\n            return asc if self.asc else desc\n        else:\n            return None", "response": "Get direction of ordering."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef selected(self):\n        if self._selected:\n            return self._selected if self.asc else \\\n                \"-{0}\".format(self._selected)\n        return None", "response": "Get column which is being order by."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting query with correct ordering.", "response": "def items(self):\n        \"\"\"Get query with correct ordering.\"\"\"\n        if self.asc is not None:\n            if self._selected and self.asc:\n                return self.query.order_by(self._selected)\n            elif self._selected and not self.asc:\n                return self.query.order_by(desc(self._selected))\n        return self.query"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the version of the magic_line in the file referenced in this object.", "response": "def get_version(self) -> str:\n        \"\"\"\n        Open the file referenced in this object, and scrape the version.\n\n        :return:\n            The version as a string, an empty string if there is no match\n            to the magic_line, or any file exception messages encountered.\n        \"\"\"\n\n        try:\n            f = open(self.file_path, 'r')\n            lines = f.readlines()\n            f.close()\n        except Exception as e:\n            return str(e)\n\n        result = ''\n\n        for line in lines:\n            if self.magic_line in line:\n                start = len(self.magic_line)\n                end = len(line) - self.strip_end_chars\n                result = line[start:end]\n                break\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_version(self, new_version: str):\n\n        try:\n            f = open(self.file_path, 'r')\n            lines = f.readlines()\n            f.close()\n        except Exception as e:\n            print(str(e))\n            return\n\n        for idx, line in enumerate(lines):\n            if self.magic_line in line:\n                start = len(self.magic_line)\n                end = len(line) - self.strip_end_chars\n\n                start_str = line[0:start]\n                end_str = line[end:]\n                lines[idx] = start_str + new_version + end_str\n\n        try:\n            f = open(self.file_path, 'w')\n            f.writelines(lines)\n            f.close()\n        except Exception as e:\n            print(str(e))\n            return", "response": "Set the version for this given file."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads test data fixture.", "response": "def records():\n    \"\"\"Load test data fixture.\"\"\"\n    import uuid\n    from invenio_records.api import Record\n    from invenio_pidstore.models import PersistentIdentifier, PIDStatus\n\n    create_test_user()\n\n    indexer = RecordIndexer()\n\n    # Record 1 - Live record\n    with db.session.begin_nested():\n        rec_uuid = uuid.uuid4()\n        pid1 = PersistentIdentifier.create(\n            'recid', '1', object_type='rec', object_uuid=rec_uuid,\n            status=PIDStatus.REGISTERED)\n        Record.create({\n            'title': 'Registered',\n            'description': 'This is an awesome description',\n            'control_number': '1',\n            'access_right': 'restricted',\n            'access_conditions': 'fuu',\n            'owners': [1, 2],\n            'recid': 1\n        }, id_=rec_uuid)\n        indexer.index_by_id(pid1.object_uuid)\n\n    db.session.commit()\n\n    sleep(3)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninitializing SSH client options and initialize internal variables.", "response": "def _init_ssh(self):\n        \"\"\" Configure SSH client options\n        \"\"\"\n\n        self.ssh_host = self.config.get('ssh_host', self.hostname)\n\n        self.known_hosts = self.config.get('ssh_knownhosts_file',\n            self.tensor.config.get('ssh_knownhosts_file', None))\n\n        self.ssh_keyfile = self.config.get('ssh_keyfile',\n            self.tensor.config.get('ssh_keyfile', None))\n\n        self.ssh_key = self.config.get('ssh_key',\n            self.tensor.config.get('ssh_key', None))\n\n        # Not sure why you'd bother but maybe you've got a weird policy\n        self.ssh_keypass = self.config.get('ssh_keypass',\n            self.tensor.config.get('ssh_keypass', None))\n\n        self.ssh_user = self.config.get('ssh_username',\n            self.tensor.config.get('ssh_username', None))\n\n        self.ssh_password = self.config.get('ssh_password',\n            self.tensor.config.get('ssh_password', None))\n\n        self.ssh_port = self.config.get('ssh_port',\n            self.tensor.config.get('ssh_port', 22))\n\n        # Verify config to see if we're good to go\n\n        if not (self.ssh_key or self.ssh_keyfile or self.ssh_password):\n            raise Exception(\"To use SSH you must specify *one* of ssh_key,\"\n                            \" ssh_keyfile or ssh_password for this source\"\n                            \" check or globally\")\n\n        if not self.ssh_user:\n            raise Exception(\"ssh_username must be set\")\n\n        self.ssh_keydb = []\n\n        cHash = hashlib.sha1(':'.join((\n                        self.ssh_host, self.ssh_user, str(self.ssh_port),\n                        str(self.ssh_password), str(self.ssh_key),\n                        str(self.ssh_keyfile)\n                    )).encode()).hexdigest()\n\n        if cHash in self.tensor.hostConnectorCache:\n            self.ssh_client = self.tensor.hostConnectorCache.get(cHash)\n            self.ssh_connector = False\n        else:\n            self.ssh_connector = True\n            self.ssh_client = ssh.SSHClient(self.ssh_host, self.ssh_user,\n                    self.ssh_port, password=self.ssh_password,\n                    knownhosts=self.known_hosts)\n\n            if self.ssh_keyfile:\n                self.ssh_client.addKeyFile(self.ssh_keyfile, self.ssh_keypass)\n\n            if self.ssh_key:\n                self.ssh_client.addKeyString(self.ssh_key, self.ssh_keypass)\n\n            self.tensor.hostConnectorCache[cHash] = self.ssh_client"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nstart the timer for this source", "response": "def startTimer(self):\n        \"\"\"Starts the timer for this source\"\"\"\n        self.td = self.t.start(self.inter)\n\n        if self.use_ssh and self.ssh_connector:\n            self.ssh_client.connect()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef tick(self):\n\n        if self.sync:\n            if self.running:\n                defer.returnValue(None)\n\n        self.running = True\n\n        try:\n            event = yield self._get()\n            if event:\n                self.queueBack(event)\n\n        except Exception as e:\n            log.msg(\"[%s] Unhandled error: %s\" % (self.service, e))\n\n        self.running = False", "response": "Called for every timer tick. Calls self. _get and passes that result back to the queueBack method."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef createEvent(self, state, description, metric, prefix=None,\n            hostname=None, aggregation=None, evtime=None):\n        \"\"\"Creates an Event object from the Source configuration\"\"\"\n        if prefix:\n            service_name = self.service + \".\" + prefix\n        else:\n            service_name = self.service\n\n        return Event(state, service_name, description, metric, self.ttl,\n            hostname=hostname or self.hostname, aggregation=aggregation,\n            evtime=evtime, tags=self.tags, attributes=self.attributes\n        )", "response": "Creates an Event object from the Source configuration"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate an Event object from the Source configuration", "response": "def createLog(self, type, data, evtime=None, hostname=None):\n        \"\"\"Creates an Event object from the Source configuration\"\"\"\n\n        return Event(None, type, data, 0, self.ttl,\n            hostname=hostname or self.hostname, evtime=evtime, tags=self.tags, type='log'\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef index():\n    query = request.args.get('query', '')\n    order = request.args.get('sort', '-created')\n    try:\n        page = int(request.args.get('page', 1))\n        per_page = int(request.args.get('per_page', 20))\n    except (TypeError, ValueError):\n        abort(404)\n\n    # Delete form\n    form = DeleteForm(request.form)\n    if form.validate_on_submit():\n        link = SecretLink.query_by_owner(current_user).filter_by(\n            id=form.link.data).first()\n        if link.revoke():\n            flash(_(\"Shared link revoked.\"), category='success')\n        db.session.commit()\n\n    # Links\n    links = SecretLink.query_by_owner(current_user).filter(\n        SecretLink.revoked_at.is_(None)\n    )\n\n    # Querying\n    if query:\n        lquery = \"%{0}%\".format(query)\n        links = links.filter(\n            SecretLink.title.like(lquery) | SecretLink.description.like(lquery)\n        )\n\n    # Ordering\n    ordering = QueryOrdering(links, ['title', 'created', 'expires_at'], order)\n    links = ordering.items()\n\n    # Pending access requests\n    requests = AccessRequest.query_by_receiver(current_user).filter_by(\n        status=RequestStatus.PENDING).order_by('created')\n\n    return render_template(\n        \"zenodo_accessrequests/settings/index.html\",\n        links_pagination=links.paginate(page, per_page=per_page),\n        requests=requests,\n        query=query,\n        order=ordering,\n        get_record=get_record,\n        form=DeleteForm(),\n    )", "response": "List pending access requests and shared links."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef accessrequest(request_id):\n    r = AccessRequest.get_by_receiver(request_id, current_user)\n    if not r or r.status != RequestStatus.PENDING:\n        abort(404)\n\n    form = ApprovalForm(request.form)\n\n    if form.validate_on_submit():\n        if form.accept.data:\n            r.accept(message=form.data['message'],\n                     expires_at=form.expires_at.data)\n            db.session.commit()\n            flash(_(\"Request accepted.\"))\n            return redirect(url_for(\".index\"))\n        elif form.reject.data:\n            r.reject(message=form.data['message'])\n            db.session.commit()\n            flash(_(\"Request rejected.\"))\n            return redirect(url_for(\".index\"))\n\n    pid, record = get_record(r.recid)\n    return render_template(\n        \"zenodo_accessrequests/settings/request.html\",\n        accessrequest=r,\n        record=record,\n        form=form,\n    )", "response": "Accept or reject access request."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a TCP connection to Riemann with automatic reconnection", "response": "def createClient(self):\n        \"\"\"Create a TCP connection to Riemann with automatic reconnection\n        \"\"\"\n\n        server = self.config.get('server', 'localhost')\n        port = self.config.get('port', 5555)\n        failover = self.config.get('failover', False)\n\n        self.factory = riemann.RiemannClientFactory(server, failover=failover)\n\n        if failover:\n            initial = random.choice(server)\n        else:\n            initial = server\n\n        log.msg('Connecting to Riemann on %s:%s' % (initial, port))\n        \n        if self.tls:\n            if SSL:\n                self.connector = reactor.connectSSL(initial, port, self.factory,\n                    ClientTLSContext(self.key, self.cert))\n            else:\n                log.msg('[FATAL] SSL support not available!' \\\n                    ' Please install PyOpenSSL. Exiting now')\n                reactor.stop()\n        else:\n            self.connector = reactor.connectTCP(initial, port, self.factory)\n\n        d = defer.Deferred()\n\n        def cb():\n            # Wait until we have a useful proto object\n            if hasattr(self.factory, 'proto') and self.factory.proto:\n                self.t.start(self.inter)\n                d.callback(None)\n            else:\n                reactor.callLater(0.01, cb)\n\n        cb()\n\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef tick(self):\n        if self.factory.proto:\n            # Check backpressure\n            if (self.pressure < 0) or (self.factory.proto.pressure <= self.pressure):\n                self.emptyQueue()\n        elif self.expire:\n            # Check queue age and expire stale events\n            for i, e in enumerate(self.events):\n                if (time.time() - e.time) > e.ttl:\n                    self.events.pop(i)", "response": "Check if there are any stale events in the queue and remove them from the internal list"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove all or self. queueDepth items from the queue.", "response": "def emptyQueue(self):\n        \"\"\"Remove all or self.queueDepth events from the queue\n        \"\"\"\n        if self.events:\n            if self.queueDepth and (len(self.events) > self.queueDepth):\n                # Remove maximum of self.queueDepth items from queue\n                events = self.events[:self.queueDepth]\n                self.events = self.events[self.queueDepth:]\n            else:\n                events = self.events\n                self.events = []\n\n            if self.allow_nan:\n                self.factory.proto.sendEvents(events)\n            else:\n                self.factory.proto.sendEvents([e for e in events if e.metric is not None])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef eventsReceived(self, events):\n        # Make sure queue isn't oversized\n        if (self.maxsize < 1) or (len(self.events) < self.maxsize):\n            self.events.extend(events)", "response": "Receives a list of events and transmits them to Riemann\n       "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef createClient(self):\n        server = self.config.get('server', '127.0.0.1')\n        port = self.config.get('port', 5555)\n\n        def connect(ip):\n            self.protocol = riemann.RiemannUDP(ip, port)\n            self.endpoint = reactor.listenUDP(0, self.protocol)\n\n        d = reactor.resolve(server)\n        d.addCallback(connect)\n        return d", "response": "Create a UDP connection to Riemann"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting up HTTP connector and starts queue timer", "response": "def createClient(self):\n        \"\"\"Sets up HTTP connector and starts queue timer\n        \"\"\"\n\n        server = self.config.get('server', 'localhost')\n        port = int(self.config.get('port', 9200))\n\n        self.client = elasticsearch.ElasticSearch(self.url, self.user,\n            self.password, self.index)\n\n        self.t.start(self.inter)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef tick(self):\n        if self.events:\n            if self.queueDepth and (len(self.events) > self.queueDepth):\n                # Remove maximum of self.queueDepth items from queue\n                events = self.events[:self.queueDepth]\n                self.events = self.events[self.queueDepth:]\n            else:\n                events = self.events\n                self.events = []\n\n            try:\n                result = yield self.sendEvents(events)\n                if result.get('errors', False):\n                    log.msg(repr(result))\n                    self.events.extend(events)\n\n            except Exception as e:\n                log.msg('Could not connect to elasticsearch ' + str(e))\n                self.events.extend(events)", "response": "This is the main entry point for the event loop."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadapting an Riemann protobuf event Event object to a Riemann protobuf event Event", "response": "def encodeEvent(self, event):\n        \"\"\"Adapts an Event object to a Riemann protobuf event Event\"\"\"\n        pbevent = proto_pb2.Event(\n            time=int(event.time),\n            state=event.state,\n            service=event.service,\n            host=event.hostname,\n            description=event.description,\n            tags=event.tags,\n            ttl=event.ttl,\n        )\n\n        if event.metric is not None:\n            # I have no idea what I'm doing\n            if isinstance(event.metric, int):\n                pbevent.metric_sint64 = event.metric\n                pbevent.metric_f = float(event.metric)\n            else:\n                pbevent.metric_d = float(event.metric)\n                pbevent.metric_f = float(event.metric)\n        if event.attributes is not None:\n            for key, value in event.attributes.items():\n                attribute = pbevent.attributes.add()\n                attribute.key, attribute.value = key, value\n\n        return pbevent"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nencode a list of Tensor events with protobuf", "response": "def encodeMessage(self, events):\n        \"\"\"Encode a list of Tensor events with protobuf\"\"\"\n\n        message = proto_pb2.Msg(\n            events=[self.encodeEvent(e) for e in events if e._type=='riemann']\n        )\n\n        return message.SerializeToString()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndecoding a protobuf message into a list of Tensor events", "response": "def decodeMessage(self, data):\n        \"\"\"Decode a protobuf message into a list of Tensor events\"\"\"\n        message = proto_pb2.Msg()\n        message.ParseFromString(data)\n\n        return message"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sendEvents(self, events):\n        self.pressure += 1\n        self.sendString(self.encodeMessage(events))", "response": "Send a Tensor Event to Riemann"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates preview for URL.", "response": "def generate(ctx, url, *args, **kwargs):\n    \"\"\"\n    Generate preview for URL.\n    \"\"\"\n    file_previews = ctx.obj['file_previews']\n\n    options = {}\n    metadata = kwargs['metadata']\n    width = kwargs['width']\n    height = kwargs['height']\n    output_format = kwargs['format']\n\n    if metadata:\n        options['metadata'] = metadata.split(',')\n\n    if width:\n        options.setdefault('size', {})\n        options['size']['width'] = width\n\n    if height:\n        options.setdefault('size', {})\n        options['size']['height'] = height\n\n    if output_format:\n        options['format'] = output_format\n\n    results = file_previews.generate(url, **options)\n\n    click.echo(results)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef retrieve(ctx, preview_id, *args, **kwargs):\n    file_previews = ctx.obj['file_previews']\n    results = file_previews.retrieve(preview_id)\n\n    click.echo(results)", "response": "Retrieve preview results for preview_id."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrefresh the access token for the remote access application.", "response": "def _refresh_access_token(self):\n        \"\"\"\n        If the client application has a refresh token, it can use it to send a request for a new access token. \n        \n        To ask for a new access token, the client application should send a POST request to https://login.instance_name/services/oauth2/token with the following query parameters:\n        \n            grant_type:     Value must be refresh_token for this flow.\n            refresh_token:  The refresh token the client application already received. \n            client_id:      Consumer key from the remote access application definition.\n            client_secret:  Consumer secret from the remote access application definition.\n            format:         Expected return format. This parameter is optional. The default is json. Values are:\n        \n                * urlencoded\n                * json\n                * xml\n        \n        e.g.\n        \n            $ curl -i --form grant_type=refresh_token \\\n                --form refresh_token=<refresh_token> \\\n                --form client_id=<client_id> \\\n                --form client_secret=<client_secret> \\\n                --form format=json \\\n                https://na1.salesforce.com/services/oauth2/token\n        \"\"\"\n\n        resource = \"https://na1.salesforce.com/services/oauth2/token\"\n        fields = dict(grant_type=\"refresh_token\", refresh_token=self.refresh_token,\n                      client_id=self.auth.client_id, client_secret=self.auth.client_secret,\n                      format=\"json\")\n        status, data = self._handle_response(\"POST\", resource, fields=fields, \n                                             refresh_access_token=False)\n        \n        if \"access_token\" in data:\n            # Update access token\n            self.access_token = data[\"access_token\"]\n            \n            # Notify others via callback\n            if callable(self.access_token_refreshed_callback):\n                self.access_token_refreshed_callback(self.access_token)\n            \n            # Return True, indicating access_token refresehed\n            return True\n\n        # Return False, indicating access_token not refreshed\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsend a dict of message to the r_q queue and throw explicit errors for pickle problems", "response": "def r_q_send(self, msg_dict):\n        \"\"\"Send message dicts through r_q, and throw explicit errors for \n        pickle problems\"\"\"\n\n        # Check whether msg_dict can be pickled...\n        no_pickle_keys = self.invalid_dict_pickle_keys(msg_dict)\n\n        if no_pickle_keys == []:\n            self.r_q.put(msg_dict)\n\n        else:\n            ## Explicit pickle error handling\n            hash_func = md5()\n            hash_func.update(str(msg_dict))\n            dict_hash = str(hash_func.hexdigest())[-7:]  # Last 7 digits of hash\n            linesep = os.linesep\n            sys.stderr.write(\n                \"{0} {1}r_q_send({2}) Can't pickle this dict:{3} '''{7}{4}   {5}{7}{6}''' {7}\".format(\n                    datetime.now(),\n                    Style.BRIGHT,\n                    dict_hash,\n                    Style.RESET_ALL,\n                    Fore.MAGENTA,\n                    msg_dict,\n                    Style.RESET_ALL,\n                    linesep,\n                )\n            )\n\n            ## Verbose list of the offending key(s) / object attrs\n            ## Send all output to stderr...\n            err_frag1 = (\n                Style.BRIGHT\n                + \"    r_q_send({0}) Offending dict keys:\".format(dict_hash)\n                + Style.RESET_ALL\n            )\n            err_frag2 = Fore.YELLOW + \" {0}\".format(no_pickle_keys) + Style.RESET_ALL\n            err_frag3 = \"{0}\".format(linesep)\n            sys.stderr.write(err_frag1 + err_frag2 + err_frag3)\n            for key in sorted(no_pickle_keys):\n                sys.stderr.write(\n                    \"      msg_dict['{0}']: {1}'{2}'{3}{4}\".format(\n                        key,\n                        Fore.MAGENTA,\n                        repr(msg_dict.get(key)),\n                        Style.RESET_ALL,\n                        linesep,\n                    )\n                )\n                if isinstance(msg_dict.get(key), object):\n                    thisobj = msg_dict.get(key)\n                    no_pickle_attrs = self.invalid_obj_pickle_attrs(thisobj)\n                    err_frag1 = (\n                        Style.BRIGHT\n                        + \"      r_q_send({0}) Offending attrs:\".format(dict_hash)\n                        + Style.RESET_ALL\n                    )\n                    err_frag2 = (\n                        Fore.YELLOW + \" {0}\".format(no_pickle_attrs) + Style.RESET_ALL\n                    )\n                    err_frag3 = \"{0}\".format(linesep)\n                    sys.stderr.write(err_frag1 + err_frag2 + err_frag3)\n                    for attr in no_pickle_attrs:\n                        sys.stderr.write(\n                            \"        msg_dict['{0}'].{1}: {2}'{3}'{4}{5}\".format(\n                                key,\n                                attr,\n                                Fore.RED,\n                                repr(getattr(thisobj, attr)),\n                                Style.RESET_ALL,\n                                linesep,\n                            )\n                        )\n\n            sys.stderr.write(\n                \"    {0}r_q_send({1}) keys (no problems):{2}{3}\".format(\n                    Style.BRIGHT, dict_hash, Style.RESET_ALL, linesep\n                )\n            )\n            for key in sorted(set(msg_dict.keys()).difference(no_pickle_keys)):\n                sys.stderr.write(\n                    \"      msg_dict['{0}']: {1}{2}{3}{4}\".format(\n                        key,\n                        Fore.GREEN,\n                        repr(msg_dict.get(key)),\n                        Style.RESET_ALL,\n                        linesep,\n                    )\n                )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nlooping through messages and execute tasks", "response": "def message_loop(self, t_q, r_q):\n        \"\"\"Loop through messages and execute tasks\"\"\"\n        t_msg = {}\n        while t_msg.get(\"state\", \"\") != \"__DIE__\":\n            try:\n                t_msg = t_q.get(True, self.cycle_sleep)  # Poll blocking\n                self.task = t_msg.get(\"task\", \"\")  # __DIE__ has no task\n                if self.task != \"\":\n\n                    self.task.task_start = time.time()  # Start the timer\n                    # Send ACK to the controller who requested work on this task\n                    self.r_q_send(\n                        {\"w_id\": self.w_id, \"task\": self.task, \"state\": \"__ACK__\"}\n                    )\n\n                    # Update the sleep time with latest recommendations\n                    self.cycle_sleep = self.task.worker_loop_delay\n\n                    # Assign the result of task.run() to task.result\n                    self.task.result = self.task.run()\n                    self.task.task_stop = time.time()  # Seconds since epoch\n\n                    self.r_q_send(\n                        {\"w_id\": self.w_id, \"task\": self.task, \"state\": \"__FINISHED__\"}\n                    )  # Ack work finished\n\n                    self.task = None\n            except Empty:\n                pass\n            except Full:\n                time.sleep(0.1)\n            ## Disable extraneous error handling...\n            except:\n                if self.task is not None:\n                    self.task.task_stop = time.time()  # Seconds since epoch\n                # Handle all other errors here...\n                tb_str = \"\".join(tb.format_exception(*(sys.exc_info())))\n                self.r_q_send(\n                    {\n                        \"w_id\": self.w_id,\n                        \"task\": self.task,\n                        \"error\": tb_str,\n                        \"state\": \"__ERROR__\",\n                    }\n                )\n\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef log_time(self):\n        if self.hot_loop and self.time_delta >= self.log_interval:\n            return True\n        return False", "response": "Return True if it s time to log"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef log_message(self):\n        time_delta = deepcopy(self.time_delta)\n        total_work_time = self.worker_count * time_delta\n        time_worked = sum(self.exec_times)\n        pct_busy = time_worked / total_work_time * 100.0\n\n        min_task_time = min(self.exec_times)\n        avg_task_time = sum(self.exec_times) / len(self.exec_times)\n        max_task_time = max(self.exec_times)\n\n        min_queue_time = min(self.queue_times)\n        avg_queue_time = sum(self.queue_times) / len(self.queue_times)\n        max_queue_time = max(self.queue_times)\n\n        time_delta = self.time_delta\n        total_tasks = len(self.exec_times)\n        avg_task_rate = total_tasks / time_delta\n\n        self.reset()\n\n        task_msg = \"\"\"Ran {0} tasks, {1} tasks/s; {2} workers {3}% busy\"\"\".format(\n            total_tasks, round(avg_task_rate, 1), self.worker_count, round(pct_busy, 1)\n        )\n        task_mam = \"\"\"     Task run times: {0}/{1}/{2} (min/avg/max)\"\"\".format(\n            round(min_task_time, 3), round(avg_task_time, 3), round(max_task_time, 3)\n        )\n        queue_mam = \"\"\"     Time in queue: {0}/{1}/{2} (min/avg/max)\"\"\".format(\n            round(min_queue_time, 6), round(avg_queue_time, 6), round(max_queue_time, 6)\n        )\n\n        return \"\"\"{0}\\n{1}\\n{2}\"\"\".format(task_msg, task_mam, queue_mam)", "response": "Build a log message and reset the stats"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_monoprice(port_url):\n\n    lock = RLock()\n\n    def synchronized(func):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            with lock:\n                return func(*args, **kwargs)\n        return wrapper\n\n    class MonopriceSync(Monoprice):\n        def __init__(self, port_url):\n            self._port = serial.serial_for_url(port_url, do_not_open=True)\n            self._port.baudrate = 9600\n            self._port.stopbits = serial.STOPBITS_ONE\n            self._port.bytesize = serial.EIGHTBITS\n            self._port.parity = serial.PARITY_NONE\n            self._port.timeout = TIMEOUT\n            self._port.write_timeout = TIMEOUT\n            self._port.open()\n\n        def _process_request(self, request: bytes, skip=0):\n            \"\"\"\n            :param request: request that is sent to the monoprice\n            :param skip: number of bytes to skip for end of transmission decoding\n            :return: ascii string returned by monoprice\n            \"\"\"\n            _LOGGER.debug('Sending \"%s\"', request)\n            # clear\n            self._port.reset_output_buffer()\n            self._port.reset_input_buffer()\n            # send\n            self._port.write(request)\n            self._port.flush()\n            # receive\n            result = bytearray()\n            while True:\n                c = self._port.read(1)\n                if not c:\n                    raise serial.SerialTimeoutException(\n                        'Connection timed out! Last received bytes {}'.format([hex(a) for a in result]))\n                result += c\n                if len(result) > skip and result[-LEN_EOL:] == EOL:\n                    break\n            ret = bytes(result)\n            _LOGGER.debug('Received \"%s\"', ret)\n            return ret.decode('ascii')\n\n        @synchronized\n        def zone_status(self, zone: int):\n            # Ignore first 6 bytes as they will contain 3 byte command and 3 bytes of EOL\n            return ZoneStatus.from_string(self._process_request(_format_zone_status_request(zone), skip=6))\n\n        @synchronized\n        def set_power(self, zone: int, power: bool):\n            self._process_request(_format_set_power(zone, power))\n\n        @synchronized\n        def set_mute(self, zone: int, mute: bool):\n            self._process_request(_format_set_mute(zone, mute))\n\n        @synchronized\n        def set_volume(self, zone: int, volume: int):\n            self._process_request(_format_set_volume(zone, volume))\n\n        @synchronized\n        def set_treble(self, zone: int, treble: int):\n            self._process_request(_format_set_treble(zone, treble))\n\n        @synchronized\n        def set_bass(self, zone: int, bass: int):\n            self._process_request(_format_set_bass(zone, bass))\n\n        @synchronized\n        def set_balance(self, zone: int, balance: int):\n            self._process_request(_format_set_balance(zone, balance))\n\n        @synchronized\n        def set_source(self, zone: int, source: int):\n            self._process_request(_format_set_source(zone, source))\n\n        @synchronized\n        def restore_zone(self, status: ZoneStatus):\n            self.set_power(status.zone, status.power)\n            self.set_mute(status.zone, status.mute)\n            self.set_volume(status.zone, status.volume)\n            self.set_treble(status.zone, status.treble)\n            self.set_bass(status.zone, status.bass)\n            self.set_balance(status.zone, status.balance)\n            self.set_source(status.zone, status.source)\n\n    return MonopriceSync(port_url)", "response": "Return a Monoprice object for the given port_url."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_async_monoprice(port_url, loop):\n\n    lock = asyncio.Lock()\n\n    def locked_coro(coro):\n        @asyncio.coroutine\n        @wraps(coro)\n        def wrapper(*args, **kwargs):\n            with (yield from lock):\n                return (yield from coro(*args, **kwargs))\n        return wrapper\n\n    class MonopriceAsync(Monoprice):\n        def __init__(self, monoprice_protocol):\n            self._protocol = monoprice_protocol\n\n        @locked_coro\n        @asyncio.coroutine\n        def zone_status(self, zone: int):\n            # Ignore first 6 bytes as they will contain 3 byte command and 3 bytes of EOL\n            string = yield from self._protocol.send(_format_zone_status_request(zone), skip=6)\n            return ZoneStatus.from_string(string)\n\n        @locked_coro\n        @asyncio.coroutine\n        def set_power(self, zone: int, power: bool):\n            yield from self._protocol.send(_format_set_power(zone, power))\n\n        @locked_coro\n        @asyncio.coroutine\n        def set_mute(self, zone: int, mute: bool):\n            yield from self._protocol.send(_format_set_mute(zone, mute))\n\n        @locked_coro\n        @asyncio.coroutine\n        def set_volume(self, zone: int, volume: int):\n            yield from self._protocol.send(_format_set_volume(zone, volume))\n\n        @locked_coro\n        @asyncio.coroutine\n        def set_treble(self, zone: int, treble: int):\n            yield from self._protocol.send(_format_set_treble(zone, treble))\n\n        @locked_coro\n        @asyncio.coroutine\n        def set_bass(self, zone: int, bass: int):\n            yield from self._protocol.send(_format_set_bass(zone, bass))\n\n        @locked_coro\n        @asyncio.coroutine\n        def set_balance(self, zone: int, balance: int):\n            yield from self._protocol.send(_format_set_balance(zone, balance))\n\n        @locked_coro\n        @asyncio.coroutine\n        def set_source(self, zone: int, source: int):\n            yield from self._protocol.send(_format_set_source(zone, source))\n\n        @locked_coro\n        @asyncio.coroutine\n        def restore_zone(self, status: ZoneStatus):\n            yield from self._protocol.send(_format_set_power(status.zone, status.power))\n            yield from self._protocol.send(_format_set_mute(status.zone, status.mute))\n            yield from self._protocol.send(_format_set_volume(status.zone, status.volume))\n            yield from self._protocol.send(_format_set_treble(status.zone, status.treble))\n            yield from self._protocol.send(_format_set_bass(status.zone, status.bass))\n            yield from self._protocol.send(_format_set_balance(status.zone, status.balance))\n            yield from self._protocol.send(_format_set_source(status.zone, status.source))\n\n    class MonopriceProtocol(asyncio.Protocol):\n        def __init__(self, loop):\n            super().__init__()\n            self._loop = loop\n            self._lock = asyncio.Lock()\n            self._transport = None\n            self._connected = asyncio.Event(loop=loop)\n            self.q = asyncio.Queue(loop=loop)\n\n        def connection_made(self, transport):\n            self._transport = transport\n            self._connected.set()\n            _LOGGER.debug('port opened %s', self._transport)\n\n        def data_received(self, data):\n            asyncio.ensure_future(self.q.put(data), loop=self._loop)\n\n        @asyncio.coroutine\n        def send(self, request: bytes, skip=0):\n            yield from self._connected.wait()\n            result = bytearray()\n            # Only one transaction at a time\n            with (yield from self._lock):\n                self._transport.serial.reset_output_buffer()\n                self._transport.serial.reset_input_buffer()\n                while not self.q.empty():\n                    self.q.get_nowait()\n                self._transport.write(request)\n                try:\n                    while True:\n                        result += yield from asyncio.wait_for(self.q.get(), TIMEOUT, loop=self._loop)\n                        if len(result) > skip and result[-LEN_EOL:] == EOL:\n                            ret = bytes(result)\n                            _LOGGER.debug('Received \"%s\"', ret)\n                            return ret.decode('ascii')\n                except asyncio.TimeoutError:\n                    _LOGGER.error(\"Timeout during receiving response for command '%s', received='%s'\", request, result)\n                    raise\n\n    _, protocol = yield from create_serial_connection(loop, functools.partial(MonopriceProtocol, loop),\n                                                      port_url, baudrate=9600)\n    return MonopriceAsync(protocol)", "response": "Return asynchronous version of Monoprice interface."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a new instance of the class based on the given state.", "response": "def from_reply(cls, state):\n        \"\"\"\n        Comptaibility layer for old :class:`SASLInterface`\n        implementations.\n\n        Accepts the follwing set of :class:`SASLState` or strings and\n        maps the strings to :class:`SASLState` elements as follows:\n\n          ``\"challenge\"``\n            :member:`SASLState.CHALLENGE`\n\n           ``\"failue\"``\n             :member:`SASLState.FAILURE`\n\n           ``\"success\"``\n             :member:`SASLState.SUCCESS`\n        \"\"\"\n        if state in (SASLState.FAILURE, SASLState.SUCCESS,\n                     SASLState.CHALLENGE):\n            return state\n\n        if state in (\"failure\", \"success\", \"challenge\"):\n            return SASLState(state)\n        else:\n            raise RuntimeError(\"invalid SASL state\", state)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninitiating the SASL handshake and advertise the use of the given mechanism.", "response": "def initiate(self, mechanism, payload=None):\n        \"\"\"\n        Initiate the SASL handshake and advertise the use of the given\n        `mechanism`. If `payload` is not :data:`None`, it will be base64\n        encoded and sent as initial client response along with the ``<auth />``\n        element.\n\n        Return the next state of the state machine as tuple (see\n        :class:`SASLStateMachine` for details).\n        \"\"\"\n\n        if self._state != SASLState.INITIAL:\n            raise RuntimeError(\"initiate has already been called\")\n\n        try:\n            next_state, payload = yield from self.interface.initiate(\n                mechanism,\n                payload=payload)\n        except SASLFailure:\n            self._state = SASLState.FAILURE\n            raise\n\n        next_state = SASLState.from_reply(next_state)\n        self._state = next_state\n        return next_state, payload"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsend a response to the previously received challenge with the given payload.", "response": "def response(self, payload):\n        \"\"\"\n        Send a response to the previously received challenge, with the given\n        `payload`. The payload is encoded using base64 and transmitted to the\n        server.\n\n        Return the next state of the state machine as tuple (see\n        :class:`SASLStateMachine` for details).\n        \"\"\"\n        if self._state == SASLState.SUCCESS_SIMULATE_CHALLENGE:\n            if payload != b\"\":\n                # XXX: either our mechanism is buggy or the server\n                # sent SASLState.SUCCESS before all challenge-response\n                # messages defined by the mechanism were sent\n                self._state = SASLState.FAILURE\n                raise SASLFailure(\n                    None,\n                    \"protocol violation: mechanism did not\"\n                    \" respond with an empty response to a\"\n                    \" challenge with final data \u2013 this suggests\"\n                    \" a protocol-violating early success from the server.\"\n                )\n            self._state = SASLState.SUCCESS\n            return SASLState.SUCCESS, None\n\n        if self._state != SASLState.CHALLENGE:\n            raise RuntimeError(\n                \"no challenge has been made or negotiation failed\")\n\n        try:\n            next_state, payload = yield from self.interface.respond(payload)\n        except SASLFailure:\n            self._state = SASLState.FAILURE\n            raise\n\n        next_state = SASLState.from_reply(next_state)\n\n        # unfold the (SASLState.SUCCESS, payload) to a sequence of\n        # (SASLState.CHALLENGE, payload), (SASLState.SUCCESS, None) for the SASLMethod\n        # to allow uniform treatment of both cases\n        if next_state == SASLState.SUCCESS and payload is not None:\n            self._state = SASLState.SUCCESS_SIMULATE_CHALLENGE\n            return SASLState.CHALLENGE, payload\n\n        self._state = next_state\n        return next_state, payload"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nabort an initiated SASL authentication process. The expected result is success.", "response": "def abort(self):\n        \"\"\"\n        Abort an initiated SASL authentication process. The expected result\n        state is ``failure``.\n        \"\"\"\n        if self._state == SASLState.INITIAL:\n            raise RuntimeError(\"SASL authentication hasn't started yet\")\n\n        if self._state == SASLState.SUCCESS_SIMULATE_CHALLENGE:\n            raise RuntimeError(\"SASL message exchange already over\")\n\n        try:\n            return (yield from self.interface.abort())\n        finally:\n            self._state = SASLState.FAILURE"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _saslprep_do_mapping(chars):\n    i = 0\n    while i < len(chars):\n        c = chars[i]\n        if stringprep.in_table_c12(c):\n            chars[i] = \"\\u0020\"\n        elif stringprep.in_table_b1(c):\n            del chars[i]\n            continue\n        i += 1", "response": "Perform the SASLprep mapping step of SASLprep. Operates in - place on a\n    list of unicode characters provided in chars."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nimplementing the trace profile specified in RFC 4505.", "response": "def trace(string):\n    \"\"\"\n    Implement the ``trace`` profile specified in :rfc:`4505`.\n    \"\"\"\n\n    check_prohibited_output(\n        string,\n        (\n            stringprep.in_table_c21,\n            stringprep.in_table_c22,\n            stringprep.in_table_c3,\n            stringprep.in_table_c4,\n            stringprep.in_table_c5,\n            stringprep.in_table_c6,\n            stringprep.in_table_c8,\n            stringprep.in_table_c9,\n        )\n    )\n    check_bidi(string)\n    return string"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef xor_bytes(a, b):\n    assert len(a) == len(b)\n    return bytes(map(operator.xor, a, b))", "response": "Calculate the byte wise exclusive of two : class : bytes objects a and b."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the AdminFooterNode that renders the footer information based on the authenticated user s permissions.", "response": "def admin_footer(parser, token):\n    \"\"\"\n    Template tag that renders the footer information based on the\n    authenticated user's permissions.\n    \"\"\"\n    # split_contents() doesn't know how to split quoted strings.\n    tag_name = token.split_contents()\n\n    if len(tag_name) > 1:\n        raise base.TemplateSyntaxError(\n            '{} tag does not accept any argument(s): {}'.format(\n            token.contents.split()[0],\n            ', '.join(token.contents.split()[1:])\n    ))\n\n    return AdminFooterNode()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef build_payment_parameters(amount: Money, client_ref: str) -> PaymentParameters:\n    merchant_id = web_merchant_id\n    amount, currency = money_to_amount_and_currency(amount)\n    refno = client_ref\n    sign = sign_web(merchant_id, amount, currency, refno)\n\n    parameters = PaymentParameters(\n        merchant_id=merchant_id,\n        amount=amount,\n        currency=currency,\n        refno=refno,\n        sign=sign,\n        use_alias=False,\n    )\n\n    logger.info('build-payment-parameters', parameters=parameters)\n\n    return parameters", "response": "Builds the payment parameters needed to present the user with a datatrans payment form."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbuilding the parameters needed to register a credit card.", "response": "def build_register_credit_card_parameters(client_ref: str) -> PaymentParameters:\n    \"\"\"\n    Builds the parameters needed to present the user with a datatrans form to register a credit card.\n    Contrary to a payment form, datatrans will not show an amount.\n\n    :param client_ref: A unique reference for this alias capture.\n    :return: The parameters needed to display the datatrans form\n    \"\"\"\n\n    amount = 0\n    currency = 'CHF'  # Datatrans requires this value to be filled, so we use this arbitrary currency.\n    merchant_id = web_merchant_id\n    refno = client_ref\n    sign = sign_web(merchant_id, amount, currency, refno)\n\n    parameters = PaymentParameters(\n        merchant_id=merchant_id,\n        amount=amount,\n        currency=currency,\n        refno=refno,\n        sign=sign,\n        use_alias=True,\n    )\n\n    logger.info('building-payment-parameters', parameters=parameters)\n\n    return parameters"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntaking money and currency and alias_registration_id and creates a Payment object with the alias_registration_id.", "response": "def pay_with_alias(amount: Money, alias_registration_id: str, client_ref: str) -> Payment:\n    \"\"\"\n    Charges money using datatrans, given a previously registered credit card alias.\n\n    :param amount: The amount and currency we want to charge\n    :param alias_registration_id: The alias registration to use\n    :param client_ref: A unique reference for this charge\n    :return: a Payment (either successful or not)\n    \"\"\"\n    if amount.amount <= 0:\n        raise ValueError('Pay with alias takes a strictly positive amount')\n\n    alias_registration = AliasRegistration.objects.get(pk=alias_registration_id)\n\n    logger.info('paying-with-alias', amount=amount, client_ref=client_ref,\n                alias_registration=alias_registration)\n\n    request_xml = build_pay_with_alias_request_xml(amount, client_ref, alias_registration)\n\n    logger.info('sending-pay-with-alias-request', url=datatrans_authorize_url, data=request_xml)\n\n    response = requests.post(\n        url=datatrans_authorize_url,\n        headers={'Content-Type': 'application/xml'},\n        data=request_xml)\n\n    logger.info('processing-pay-with-alias-response', response=response.content)\n\n    charge_response = parse_pay_with_alias_response_xml(response.content)\n    charge_response.save()\n    charge_response.send_signal()\n\n    return charge_response"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_notification_xml(xml: str) -> Union[AliasRegistration, Payment]:\n    body = fromstring(xml).find('body')\n    transaction = body.find('transaction')\n    _user_parameters = transaction.find('userParameters')\n\n    def get_named_parameter(name):\n        return _user_parameters.find(\"parameter[@name='\" + name + \"']\")\n\n    def success():\n        return transaction.get('status') == 'success'\n\n    def parse_success():\n        # From the spec: sign2 is only returned in the success case\n        computed_signature = sign_web(body.get('merchantId'), transaction.find('amount').text,\n                                      transaction.find('currency').text,\n                                      transaction.find('uppTransactionId').text)\n\n        sign2 = get_named_parameter('sign2').text\n        if computed_signature != sign2:\n            raise ValueError('sign2 did not match computed signature')\n\n        success = transaction.find('success')\n        d = dict(\n            response_code=success.find('responseCode').text,\n            response_message=success.find('responseMessage').text,\n            authorization_code=success.find('authorizationCode').text,\n            acquirer_authorization_code=success.find('acqAuthorizationCode').text,\n        )\n        return {k: v for k, v in d.items() if v is not None}\n\n    def parse_error():\n        error = transaction.find('error')\n        d = dict(\n            error_code=error.find('errorCode').text,\n            error_message=error.find('errorMessage').text,\n            error_detail=error.find('errorDetail').text)\n\n        acquirer_error_code = get_named_parameter('acqErrorCode')\n        if acquirer_error_code is not None:\n            d['acquirer_error_code'] = acquirer_error_code.text\n\n        return {k: v for k, v in d.items() if v is not None}\n\n    def parse_common_attributes():\n        d = dict(\n            transaction_id=transaction.find('uppTransactionId').text,\n            merchant_id=body.get('merchantId'),\n            client_ref=transaction.get('refno'),\n            amount=parse_money(transaction))\n\n        payment_method = transaction.find('pmethod')\n        if payment_method is not None:\n            d['payment_method'] = payment_method.text\n\n        request_type = transaction.find('reqtype')\n        if request_type is not None:\n            d['request_type'] = request_type.text\n\n        credit_card_country = get_named_parameter('returnCustomerCountry')\n        if credit_card_country is not None:\n            d['credit_card_country'] = credit_card_country.text\n\n        expiry_month = get_named_parameter('expm')\n        if expiry_month is not None:\n            d['expiry_month'] = int(expiry_month.text)\n\n        expiry_year = get_named_parameter('expy')\n        if expiry_year is not None:\n            d['expiry_year'] = int(expiry_year.text)\n\n        return d\n\n    # End of inner helper functions, we're back inside parse_notification_xml\n\n    use_alias_parameter = get_named_parameter('useAlias')\n    if use_alias_parameter is not None and use_alias_parameter.text == 'true':\n        # It's an alias registration\n\n        d = dict(parse_common_attributes())\n\n        masked_card_number = get_named_parameter('maskedCC')\n        if masked_card_number is not None:\n            d['masked_card_number'] = masked_card_number.text\n\n        card_alias = get_named_parameter('aliasCC')\n        if card_alias is not None:\n            d['card_alias'] = card_alias.text\n\n        if success():\n            d['success'] = True\n            d.update(parse_success())\n        else:\n            d['success'] = False\n            d.update(parse_error())\n\n        return AliasRegistration(**d)\n    else:\n        # It's a payment or a charge\n        if success():\n            d = dict(success=True)\n            cardno = get_named_parameter('cardno')\n            if cardno is not None:\n                d['masked_card_number'] = cardno.text\n            d.update(parse_common_attributes())\n            d.update(parse_success())\n            return Payment(**d)\n        else:\n            d = dict(success=False)\n            d.update(parse_common_attributes())\n            d.update(parse_error())\n            return Payment(**d)", "response": "Parses the notification XML from the server."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning short application version. For example 1. 0. 0.", "response": "def short_version(version=None):\n    \"\"\"\n    Return short application version. For example: `1.0.0`.\n    \"\"\"\n    v = version or __version__\n    return '.'.join([str(x) for x in v[:3]])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn full version nr inc. rc beta etc tags.", "response": "def get_version(version=None):\n    \"\"\"\n    Return full version nr, inc. rc, beta etc tags.\n\n    For example: `2.0.0a1`\n    :rtype: str\n    \"\"\"\n    v = version or __version__\n    if len(v) == 4:\n        return '{0}{1}'.format(short_version(v), v[3])\n\n    return short_version(v)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrefund a previously authorized and settled payment.", "response": "def refund(amount: Money, payment_id: str) -> Refund:\n    \"\"\"\n    Refunds (partially or completely) a previously authorized and settled payment.\n    :param amount: The amount and currency we want to refund. Must be positive, in the same currency\n    as the original payment, and not exceed the amount of the original payment.\n    :param payment_id: The id of the payment to refund.\n    :return: a Refund (either successful or not).\n    \"\"\"\n    if amount.amount <= 0:\n        raise ValueError('Refund takes a strictly positive amount')\n    payment = Payment.objects.get(pk=payment_id)\n    if not payment.success:\n        raise ValueError('Only successful payments can be refunded')\n    if payment.amount.currency != amount.currency:\n        raise ValueError('Refund currency must be identical to original payment currency')\n    if amount.amount > payment.amount.amount:\n        raise ValueError('Refund amount exceeds original payment amount')\n\n    logger.info('refunding-payment', amount=str(amount),\n                payment=dict(amount=str(payment.amount), transaction_id=payment.transaction_id,\n                             masked_card_number=payment.masked_card_number))\n\n    client_ref = '{}-r'.format(payment.client_ref)\n\n    request_xml = build_refund_request_xml(amount=amount,\n                                           original_transaction_id=payment.transaction_id,\n                                           client_ref=client_ref,\n                                           merchant_id=payment.merchant_id)\n\n    logger.info('sending-refund-request', url=datatrans_processor_url, data=request_xml)\n\n    response = requests.post(\n        url=datatrans_processor_url,\n        headers={'Content-Type': 'application/xml'},\n        data=request_xml)\n\n    logger.info('processing-refund-response', response=response.content)\n\n    refund_response = parse_refund_response_xml(response.content)\n    refund_response.save()\n    refund_response.send_signal()\n\n    return refund_response"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _postConstruction(self):\n        '''Perform post-construction operations.'''\n        self.setWindowTitle('Filesystem Browser')\n        self._filesystemWidget.sortByColumn(0, QtCore.Qt.AscendingOrder)\n\n        # TODO: Remove once bookmarks widget implemented.\n        self._bookmarksWidget.hide()\n\n        self._acceptButton.setDefault(True)\n        self._acceptButton.setDisabled(True)\n\n        self._acceptButton.clicked.connect(self.accept)\n        self._cancelButton.clicked.connect(self.reject)\n\n        self._configureShortcuts()\n\n        self.setLocation(self._root)\n\n        self._filesystemWidget.horizontalHeader().setResizeMode(\n            QtGui.QHeaderView.ResizeToContents\n        )\n        self._filesystemWidget.horizontalHeader().setResizeMode(\n            0, QtGui.QHeaderView.Stretch\n        )\n\n        self._upButton.clicked.connect(self._onNavigateUpButtonClicked)\n        self._locationWidget.currentIndexChanged.connect(\n            self._onNavigate\n        )\n\n        self._filesystemWidget.activated.connect(self._onActivateItem)\n        selectionModel = self._filesystemWidget.selectionModel()\n        selectionModel.currentRowChanged.connect(self._onSelectItem)", "response": "Perform post - construction operations."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding keyboard shortcuts to navigate the filesystem.", "response": "def _configureShortcuts(self):\n        '''Add keyboard shortcuts to navigate the filesystem.'''\n        self._upShortcut = QtGui.QShortcut(\n            QtGui.QKeySequence('Backspace'), self\n        )\n        self._upShortcut.setAutoRepeat(False)\n        self._upShortcut.activated.connect(self._onNavigateUpButtonClicked)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _onActivateItem(self, index):\n        '''Handle activation of item in listing.'''\n        item = self._filesystemWidget.model().item(index)\n        if not isinstance(item, riffle.model.File):\n            self._acceptButton.setDisabled(True)\n            self.setLocation(item.path, interactive=True)", "response": "Handle activation of item in listing."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nhandles selection of item in listing.", "response": "def _onSelectItem(self, selection, previousSelection):\n        '''Handle selection of item in listing.'''\n        self._acceptButton.setEnabled(True)\n        del self._selected[:]\n        item = self._filesystemWidget.model().item(selection)\n        self._selected.append(item.path)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _onNavigate(self, index):\n        '''Handle selection of path segment.'''\n        if index > 0:\n            self.setLocation(\n                self._locationWidget.itemData(index), interactive=True\n            )", "response": "Handle selection of path segment."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _segmentPath(self, path):\n        '''Return list of valid *path* segments.'''\n        parts = []\n        model = self._filesystemWidget.model()\n\n        # Separate root path from remainder.\n        remainder = path\n\n        while True:\n            if remainder == model.root.path:\n                break\n\n            if remainder:\n                parts.append(remainder)\n\n            head, tail = os.path.split(remainder)\n            if head == remainder:\n                break\n\n            remainder = head\n\n        parts.append(model.root.path)\n        return parts", "response": "Return list of valid path segments."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef setLocation(self, path, interactive=False):\n        '''Set current location to *path*.\n\n        *path* must be the same as root or under the root.\n\n        .. note::\n\n            Comparisons are case-sensitive. If you set the root as 'D:/' then\n            location can be set as 'D:/folder' *not* 'd:/folder'.\n\n        If *interactive* is True, catch any exception occurring and display an\n        appropriate warning dialog to the user. Otherwise allow exceptions to\n        bubble up as normal.\n\n        '''\n        try:\n            self._setLocation(path)\n        except Exception as error:\n            if not interactive:\n                raise\n            else:\n                warning_dialog = QtGui.QMessageBox(\n                    QtGui.QMessageBox.Warning,\n                    'Location is not available',\n                    '{0} is not accessible.'.format(path),\n                    QtGui.QMessageBox.Ok,\n                    self\n                )\n                warning_dialog.setDetailedText(str(error))\n                warning_dialog.exec_()", "response": "Set current location to path."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _setLocation(self, path):\n        '''Set current location to *path*.\n\n        *path* must be the same as root or under the root.\n\n        .. note::\n\n            Comparisons are case-sensitive. If you set the root as 'D:/' then\n            location can be set as 'D:/folder' *not* 'd:/folder'.\n\n        '''\n        model = self._filesystemWidget.model()\n\n        if not path.startswith(model.root.path):\n            raise ValueError('Location must be root or under root.')\n\n        # Ensure children for each segment in path are loaded.\n        segments = self._segmentPath(path)\n        for segment in reversed(segments):\n            pathIndex = model.pathIndex(segment)\n            model.fetchMore(pathIndex)\n\n        self._filesystemWidget.setRootIndex(model.pathIndex(path))\n        self._locationWidget.clear()\n\n        # Add history entry for each segment.\n        for segment in segments:\n            index = model.pathIndex(segment)\n            if not index.isValid():\n                # Root item.\n                icon = model.iconFactory.icon(\n                    riffle.icon_factory.IconType.Computer\n                )\n                self._locationWidget.addItem(\n                    icon, model.root.path or model.root.name, model.root.path\n                )\n            else:\n                icon = model.icon(index)\n                self._locationWidget.addItem(icon, segment, segment)\n\n        if self._locationWidget.count() > 1:\n            self._upButton.setEnabled(True)\n            self._upShortcut.setEnabled(True)\n        else:\n            self._upButton.setEnabled(False)\n            self._upShortcut.setEnabled(False)", "response": "Set current location to path."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef finalize_options(self):\n        '''Finalize options to be used.'''\n        self.resource_source_path = os.path.join(RESOURCE_PATH, 'resource.qrc')\n        self.resource_target_path = RESOURCE_TARGET_PATH", "response": "Finalize options to be used."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ItemFactory(path):\n    '''Return appropriate :py:class:`Item` instance for *path*.\n\n    If *path* is null then return Computer root.\n\n    '''\n    if not path:\n        return Computer()\n\n    elif os.path.isfile(path):\n        return File(path)\n\n    elif os.path.ismount(path):\n        return Mount(path)\n\n    elif os.path.isdir(path):\n        return Directory(path)\n\n    else:\n        raise ValueError('Could not determine correct type for path: {0}'\n                         .format(path))", "response": "Return appropriate : py : class : Item instance for path."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds *item* as child of this item.", "response": "def addChild(self, item):\n        '''Add *item* as child of this item.'''\n        if item.parent and item.parent != self:\n            item.parent.removeChild(item)\n\n        self.children.append(item)\n        item.parent = self"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfetch and return new children.", "response": "def fetchChildren(self):\n        '''Fetch and return new children.\n\n        Will only fetch children whilst canFetchMore is True.\n\n        .. note::\n\n            It is the caller's responsibility to add each fetched child to this\n            parent if desired using :py:meth:`Item.addChild`.\n\n        '''\n        if not self.canFetchMore():\n            return []\n\n        children = self._fetchChildren()\n        self._fetched = True\n\n        return children"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfetch and return new child items.", "response": "def _fetchChildren(self):\n        '''Fetch and return new child items.'''\n        children = []\n        for entry in QDir.drives():\n            path = os.path.normpath(entry.canonicalFilePath())\n            children.append(Mount(path))\n\n        return children"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfetch and return new child items.", "response": "def _fetchChildren(self):\n        '''Fetch and return new child items.'''\n        children = []\n\n        # List paths under this directory.\n        paths = []\n        for name in os.listdir(self.path):\n            paths.append(os.path.normpath(os.path.join(self.path, name)))\n\n        # Handle collections.\n        collections, remainder = clique.assemble(\n            paths, [clique.PATTERNS['frames']]\n        )\n\n        for path in remainder:\n            try:\n                child = ItemFactory(path)\n            except ValueError:\n                pass\n            else:\n                children.append(child)\n\n        for collection in collections:\n            children.append(Collection(collection))\n\n        return children"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfetching and return new child items.", "response": "def _fetchChildren(self):\n        '''Fetch and return new child items.'''\n        children = []\n        for path in self._collection:\n            try:\n                child = ItemFactory(path)\n            except ValueError:\n                pass\n            else:\n                children.append(child)\n\n        return children"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning number of children parent index has.", "response": "def rowCount(self, parent):\n        '''Return number of children *parent* index has.'''\n        if parent.column() > 0:\n            return 0\n\n        if parent.isValid():\n            item = parent.internalPointer()\n        else:\n            item = self.root\n\n        return len(item.children)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef index(self, row, column, parent):\n        '''Return index for *row* and *column* under *parent*.'''\n        if not self.hasIndex(row, column, parent):\n            return QModelIndex()\n\n        if not parent.isValid():\n            item = self.root\n        else:\n            item = parent.internalPointer()\n\n        try:\n            child = item.children[row]\n        except IndexError:\n            return QModelIndex()\n        else:\n            return self.createIndex(row, column, child)", "response": "Return index for row and column under parent."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pathIndex(self, path):\n        '''Return index of item with *path*.'''\n        if path == self.root.path:\n            return QModelIndex()\n\n        if not path.startswith(self.root.path):\n            return QModelIndex()\n\n        parts = []\n        while True:\n            if path == self.root.path:\n                break\n\n            head, tail = os.path.split(path)\n            if head == path:\n                if path:\n                    parts.append(path)\n                break\n\n            parts.append(tail)\n            path = head\n\n        parts.reverse()\n        if parts:\n            item = self.root\n            count = 0\n\n            for count, part in enumerate(parts):\n                matched = False\n\n                for child in item.children:\n                    if child.name == part:\n                        item = child\n                        matched = True\n                        break\n\n                if not matched:\n                    break\n\n            if count + 1 == len(parts):\n                return self.createIndex(item.row, 0, item)\n\n        return QModelIndex()", "response": "Return index of item with path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parent(self, index):\n        '''Return parent of *index*.'''\n        if not index.isValid():\n            return QModelIndex()\n\n        item = index.internalPointer()\n        if not item:\n            return QModelIndex()\n\n        parent = item.parent\n        if not parent or parent == self.root:\n            return QModelIndex()\n\n        return self.createIndex(parent.row, 0, parent)", "response": "Return parent of index."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn data for index according to role.", "response": "def data(self, index, role):\n        '''Return data for *index* according to *role*.'''\n        if not index.isValid():\n            return None\n\n        column = index.column()\n        item = index.internalPointer()\n\n        if role == self.ITEM_ROLE:\n            return item\n\n        elif role == Qt.DisplayRole:\n\n            if column == 0:\n                return item.name\n            elif column == 1:\n                if item.size:\n                    return item.size\n            elif column == 2:\n                return item.type\n            elif column == 3:\n                if item.modified is not None:\n                    return item.modified.strftime('%c')\n\n        elif role == Qt.DecorationRole:\n            if column == 0:\n                return self.iconFactory.icon(item)\n\n        elif role == Qt.TextAlignmentRole:\n            if column == 1:\n                return Qt.AlignRight\n            else:\n                return Qt.AlignLeft\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn label for section according to orientation and role.", "response": "def headerData(self, section, orientation, role):\n        '''Return label for *section* according to *orientation* and *role*.'''\n        if orientation == Qt.Horizontal:\n            if section < len(self.columns):\n                column = self.columns[section]\n                if role == Qt.DisplayRole:\n                    return column\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef hasChildren(self, index):\n        '''Return if *index* has children.\n\n        Optimised to avoid loading children at this stage.\n\n        '''\n        if not index.isValid():\n            item = self.root\n        else:\n            item = index.internalPointer()\n            if not item:\n                return False\n\n        return item.mayHaveChildren()", "response": "Return if * index* has children. Optimised to avoid loading children at this stage."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn if more data available for index.", "response": "def canFetchMore(self, index):\n        '''Return if more data available for *index*.'''\n        if not index.isValid():\n            item = self.root\n        else:\n            item = index.internalPointer()\n\n        return item.canFetchMore()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fetchMore(self, index):\n        '''Fetch additional data under *index*.'''\n        if not index.isValid():\n            item = self.root\n        else:\n            item = index.internalPointer()\n\n        if item.canFetchMore():\n            startIndex = len(item.children)\n            additionalChildren = item.fetchChildren()\n            endIndex = startIndex + len(additionalChildren) - 1\n            if endIndex >= startIndex:\n                self.beginInsertRows(index, startIndex, endIndex)\n                for newChild in additionalChildren:\n                    item.addChild(newChild)\n                self.endInsertRows()", "response": "Fetch additional data under index."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns ordering of left vs right.", "response": "def lessThan(self, left, right):\n        '''Return ordering of *left* vs *right*.'''\n        sourceModel = self.sourceModel()\n        if sourceModel:\n            leftItem = sourceModel.item(left)\n            rightItem = sourceModel.item(right)\n\n            if (isinstance(leftItem, Directory)\n                and not isinstance(rightItem, Directory)):\n                return self.sortOrder() == Qt.AscendingOrder\n\n            elif (not isinstance(leftItem, Directory)\n                and isinstance(rightItem, Directory)):\n                return self.sortOrder() == Qt.DescendingOrder\n\n        return super(FilesystemSortProxy, self).lessThan(left, right)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pathIndex(self, path):\n        '''Return index of item with *path*.'''\n        sourceModel = self.sourceModel()\n        if not sourceModel:\n            return QModelIndex()\n\n        return self.mapFromSource(sourceModel.pathIndex(path))", "response": "Return index of item with path * path *."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef item(self, index):\n        '''Return item at *index*.'''\n        sourceModel = self.sourceModel()\n\n        if not sourceModel:\n            return None\n\n        return sourceModel.item(self.mapToSource(index))", "response": "Return item at index."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns icon for index.", "response": "def icon(self, index):\n        '''Return icon for index.'''\n        sourceModel = self.sourceModel()\n        if not sourceModel:\n            return None\n\n        return sourceModel.icon(self.mapToSource(index))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning if *index* has children.", "response": "def hasChildren(self, index):\n        '''Return if *index* has children.'''\n        sourceModel = self.sourceModel()\n\n        if not sourceModel:\n            return False\n\n        return sourceModel.hasChildren(self.mapToSource(index))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn if more data available for index.", "response": "def canFetchMore(self, index):\n        '''Return if more data available for *index*.'''\n        sourceModel = self.sourceModel()\n\n        if not sourceModel:\n            return False\n\n        return sourceModel.canFetchMore(self.mapToSource(index))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fetchMore(self, index):\n        '''Fetch additional data under *index*.'''\n        sourceModel = self.sourceModel()\n\n        if not sourceModel:\n            return False\n\n        return sourceModel.fetchMore(self.mapToSource(index))", "response": "Fetch additional data under index."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn appropriate icon for *specification*.", "response": "def icon(self, specification):\n        '''Return appropriate icon for *specification*.\n\n        *specification* should be either:\n\n            * An instance of :py:class:`riffle.model.Item`\n            * One of the defined icon types (:py:class:`IconType`)\n\n        '''\n        if isinstance(specification, riffle.model.Item):\n            specification = self.type(specification)\n\n        icon = None\n\n        if specification == IconType.Computer:\n            icon = QtGui.QIcon(':riffle/icon/computer')\n\n        elif specification == IconType.Mount:\n            icon = QtGui.QIcon(':riffle/icon/drive')\n\n        elif specification == IconType.Directory:\n            icon = QtGui.QIcon(':riffle/icon/folder')\n\n        elif specification == IconType.File:\n            icon = QtGui.QIcon(':riffle/icon/file')\n\n        elif specification == IconType.Collection:\n            icon = QtGui.QIcon(':riffle/icon/collection')\n\n        return icon"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning appropriate icon type for item.", "response": "def type(self, item):\n        '''Return appropriate icon type for *item*.'''\n        iconType = IconType.Unknown\n\n        if isinstance(item, riffle.model.Computer):\n            iconType = IconType.Computer\n\n        elif isinstance(item, riffle.model.Mount):\n            iconType = IconType.Mount\n\n        elif isinstance(item, riffle.model.Directory):\n            iconType = IconType.Directory\n\n        elif isinstance(item, riffle.model.File):\n            iconType = IconType.File\n\n        elif isinstance(item, riffle.model.Collection):\n            iconType = IconType.Collection\n\n        return iconType"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncall an external command in a separate process and return the PID of the child process.", "response": "def call(args, stdout=None, stderr=None, stdin=None, daemonize=False,\n         preexec_fn=None, shell=False, cwd=None, env=None):\n    \"\"\"\n    Run an external command in a separate process and detach it from the current process. Excepting\n    `stdout`, `stderr`, and `stdin` all file descriptors are closed after forking. If `daemonize`\n    is True then the parent process exits. All stdio is redirected to `os.devnull` unless\n    specified. The `preexec_fn`, `shell`, `cwd`, and `env` parameters are the same as their `Popen`\n    counterparts. Return the PID of the child process if not daemonized.\n    \"\"\"\n    stream = lambda s, m: s is None and os.open(os.devnull, m) or s\n    stdout = stream(stdout, os.O_WRONLY)\n    stderr = stream(stderr, os.O_WRONLY)\n    stdin = stream(stdin, os.O_RDONLY)\n\n    shared_pid = Value('i', 0)\n    pid = os.fork()\n    if pid > 0:\n        os.waitpid(pid, 0)\n        child_pid = shared_pid.value\n        del shared_pid\n        if daemonize:\n            sys.exit(0)\n        return child_pid\n    else:\n        os.setsid()\n        proc = subprocess.Popen(args, stdout=stdout, stderr=stderr, stdin=stdin, close_fds=True,\n                                preexec_fn=preexec_fn, shell=shell, cwd=cwd, env=env)\n        shared_pid.value = proc.pid\n        os._exit(0)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_max_fd(self):\n        limits = resource.getrlimit(resource.RLIMIT_NOFILE)\n        result = limits[1]\n        if result == resource.RLIM_INFINITY:\n            result = maxfd\n        return result", "response": "Return the maximum file descriptor value."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nclose a file descriptor if it is open.", "response": "def _close_fd(self, fd):\n        \"\"\"Close a file descriptor if it is open.\"\"\"\n        try:\n            os.close(fd)\n        except OSError, exc:\n            if exc.errno != errno.EBADF:\n                msg = \"Failed to close file descriptor {}: {}\".format(fd, exc)\n                raise Error(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncloses open file descriptors.", "response": "def _close_open_fds(self):\n        \"\"\"Close open file descriptors.\"\"\"\n        maxfd = self._get_max_fd()\n        for fd in reversed(range(maxfd)):\n            if fd not in self.exclude_fds:\n                self._close_fd(fd)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _redirect(self, stream, target):\n        if target is None:\n            target_fd = os.open(os.devnull, os.O_RDWR)\n        else:\n            target_fd = target.fileno()\n        os.dup2(target_fd, stream.fileno())", "response": "Redirect a system stream to the provided target."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\napplies a given HTML attributes to each field widget of a given form.", "response": "def set_form_widgets_attrs(form, attrs):\n    \"\"\"Applies a given HTML attributes to each field widget of a given form.\n\n    Example:\n\n        set_form_widgets_attrs(my_form, {'class': 'clickable'})\n\n    \"\"\"\n    for _, field in form.fields.items():\n        attrs_ = dict(attrs)\n        for name, val in attrs.items():\n            if hasattr(val, '__call__'):\n                attrs_[name] = val(field)\n        field.widget.attrs = field.widget.build_attrs(attrs_)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a certain model as defined in a string formatted app_name. model_name.", "response": "def get_model_class_from_string(model_path):\n    \"\"\"Returns a certain model as defined in a string formatted `<app_name>.<model_name>`.\n\n    Example:\n\n        model = get_model_class_from_string('myapp.MyModel')\n\n    \"\"\"\n    try:\n        app_name, model_name = model_path.split('.')\n    except ValueError:\n        raise ImproperlyConfigured('`%s` must have the following format: `app_name.model_name`.' % model_path)\n\n    if apps_get_model is None:\n        model = get_model(app_name, model_name)\n    else:\n        try:\n            model = apps_get_model(app_name, model_name)\n        except (LookupError, ValueError):\n            model = None\n\n    if model is None:\n        raise ImproperlyConfigured('`%s` refers to a model `%s` that has not been installed.' % (model_path, model_name))\n\n    return model"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_site_url(request=None):\n    env = partial(environ.get)\n    settings_ = partial(getattr, settings)\n\n    domain = None\n    scheme = None\n    url = None\n\n    for src in (env, settings_):\n        if url is None:\n            url = src('SITE_URL', None)\n\n        if domain is None:\n            domain = src('SITE_DOMAIN', None)\n\n        if scheme is None:\n            scheme = src('SITE_PROTO', src('SITE_SCHEME', None))\n\n    if domain is None and url is not None:\n        scheme, domain = url.split('://')[:2]\n\n    if domain is None:\n        site = get_current_site(request or DomainGetter(domain))\n        domain = site.domain\n\n    if scheme is None and request:\n        scheme = request.scheme\n\n    if domain is None:\n        domain = 'undefined-domain.local'\n\n    if scheme is None:\n        scheme = 'http'\n\n    domain = domain.rstrip('/')\n\n    return '%s://%s' % (scheme, domain)", "response": "Tries to deduce a site URL from environment and settings."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nimport a module from a given app by its name.", "response": "def import_app_module(app_name, module_name):\n    \"\"\"Returns a module from a given app by its name.\n\n    :param str app_name:\n    :param str module_name:\n    :rtype: module or None\n\n    \"\"\"\n    name_split = app_name.split('.')\n    if name_split[-1][0].isupper():  # Seems that we have app config class path here.\n        app_name = '.'.join(name_split[:-2])\n\n    module = import_module(app_name)\n\n    try:\n        sub_module = import_module('%s.%s' % (app_name, module_name))\n        return sub_module\n\n    except:\n\n        # The same bubbling strategy as in autodiscover_modules().\n        if module_has_submodule(module, module_name):  # Module is in a package.\n            raise\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef import_project_modules(module_name):\n    from django.conf import settings\n\n    submodules = []\n    for app in settings.INSTALLED_APPS:\n        module = import_app_module(app, module_name)\n        if module is not None:\n            submodules.append(module)\n\n    return submodules", "response": "Imports modules from registered apps using given module name\n    and returns them as a list."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef repositories(self):\n        for repo_path in self.path.glob('*.repo'):\n            for id, repository in self._get_repo_file(repo_path).repositories:\n                yield id, repository", "response": "Return a list of all repository objects in the repo folder specified\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_repo_file(self, repo_path):\n        if repo_path not in self._repo_files:\n            self._repo_files[repo_path] = RepoFile(repo_path)\n        return self._repo_files[repo_path]", "response": "Lazy load RepoFile objects on demand."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef from_url(url):\n        package_data = HTTPClient().http_request(url=url, decode=None)\n        return Package(raw_data=package_data)", "response": "Given a URL return a package object"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dependencies(self):\n        cpio = self.rpm.gzip_file.read()\n        content = cpio.read()\n        return []", "response": "Read the contents of the rpm itself"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn Gravatar image URL for a given UserModel.", "response": "def gravatar_get_url(obj, size=65, default='identicon'):\n    \"\"\"Returns Gravatar image URL for a given string or UserModel.\n\n    Example:\n\n        {% load gravatar %}\n        {% gravatar_get_url user_model %}\n\n    :param UserModel, str obj:\n    :param int size:\n    :param str default:\n    :return:\n    \"\"\"\n    return get_gravatar_url(obj, size=size, default=default)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef gravatar_get_img(obj, size=65, default='identicon'):\n    url = get_gravatar_url(obj, size=size, default=default)\n    if url:\n        return safe('<img src=\"%s\" class=\"gravatar\">' % url)\n    return ''", "response": "Returns Gravatar image HTML tag for a given UserModel."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses an xml_path with the inherited xml parser", "response": "def parse(cls, xml_path):\n        \"\"\"\n        Parses an xml_path with the inherited xml parser\n        :param xml_path:\n        :return:\n        \"\"\"\n        parser = etree.XMLParser(target=cls.xml_parse())\n        return etree.parse(xml_path, parser)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload the repo database from the remote source and then parse it.", "response": "def load(self):\n        \"\"\"\n        Load the repo database from the remote source, and then parse it.\n        :return:\n        \"\"\"\n        data = self.http_request(self.location())\n        self._parse(data)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef register_task(self, task_def):\n        '''\n        Register a task for a python dict\n        :param task_def: dict defining gbdx task\n        '''\n        r = self.session.post(\n            self.task_url,\n            data=task_def,\n            headers={'Content-Type': 'application/json', 'Accept': 'application/json'}\n        )\n\n        task_dict = json.loads(task_def)\n\n        if r.status_code == 200:\n            return r.status_code, 'Task %s registered' % task_dict['name']\n        else:\n            return r.status_code, 'Task %s was not registered: %s' % (task_dict['name'], r.text)", "response": "Register a task for a python dict\n           "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delete_task(self, task_name):\n        '''\n        Delete a task from the platforms regoistry\n        :param task_name: name of the task to delete\n        '''\n        response = self.session.delete('%s/%s' % (self.task_url, task_name))\n\n        if response.status_code == 200:\n            return response.status_code, 'Task %s deleted' % task_name\n        elif response.status_code == 400:\n            return response.status_code, None  # Task isn't registered.\n        else:\n            return response.status_code, 'Task %s was not deleted: %s' % (task_name, response.text)", "response": "Delete a task from the platforms regoistry\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_input_string_port(self, port_name, default=None):\n        if self.__string_input_ports:\n            return self.__string_input_ports.get(port_name, default)\n        return default", "response": "Get input string port value"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the value of a string output port.", "response": "def set_output_string_port(self, port_name, value):\n        \"\"\"\n        Set output string port value\n        :param port_name:\n        :param value:\n        :return: :rtype:\n        \"\"\"\n        if not self.__string_output_ports:\n            self.__string_output_ports = {}\n\n        self.__string_output_ports[port_name] = value"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef list_files(self, extensions=None):\n        if self.type.lower() != 'directory':\n            raise ValueError(\"Port type is not == directory\")\n\n        filesystem_location = self.path\n\n        for root, dirs, files in os.walk(filesystem_location):\n            if extensions is None:\n                return [os.path.join(root, f) for f in files]\n            elif not isinstance(extensions, list):\n                extensions = [extensions]\n\n            subset_files = []\n\n            for f in files:\n                for extension in extensions:\n                    if f.lower().endswith(extension.lower()):\n                        subset_files.append(os.path.join(root, f))\n                        break\n            return subset_files", "response": "List the files in the ports by file type or all."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if the path is correct and exists and is not a file.", "response": "def is_valid_filesys(path):\n        \"\"\"Checks if the path is correct and exists, must be abs-> a dir -> and not a file.\"\"\"\n        if os.path.isabs(path) and os.path.isdir(path) and \\\n                not os.path.isfile(path):\n            return True\n        else:\n            raise LocalPortValidationError(\n                'Port value %s is not a valid filesystem location' % path\n            )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_valid_s3_url(url):\n        # Skip if the url start with source: (gbdxtools syntax)\n        if url.startswith('source:'):\n            return True\n\n        scheme, netloc, path, _, _, _ = urlparse(url)\n\n        port_except = RemotePortValidationError(\n            'Port value %s is not a valid s3 location' % url\n        )\n\n        if len(scheme) < 2:\n            raise port_except\n\n        if 's3' in scheme or 's3' in netloc or 's3' in path:\n            return True\n        else:\n            raise port_except", "response": "Checks if the url contains S3. Not an accurate validation of the url"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef invoke(self):\n        for key in self.FUNCTION_KEYS.keys():\n            if self._arguments[key] is True:\n                self.FUNCTION_KEYS[key]()", "response": "Execute the command from the arguments."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nregistering the anonymous task or overwrite it.", "response": "def _register_anonymous_task(self):\n        \"\"\"\n        Register the anonymouse task or overwrite it.\n        :return: success or fail message.\n        \"\"\"\n        is_overwrite = self._arguments.get('--overwrite')\n        task_name = \"CloudHarness_Anonymous_Task\"\n\n        task_srv = TaskService()\n\n        if is_overwrite:\n            # Delete the task first\n            code, message = task_srv.delete_task(task_name)\n            # ignore status if deleted, or not registered\n            if code not in [200, 400]:\n                raise TaskRegistryError(message)\n\n        task_def_file = os.path.join(\n            os.path.dirname(os.path.dirname(os.path.abspath(__file__))),\n            'gbdx_task_template', 'task_definition.json'\n        )\n\n        with open(task_def_file, 'r') as f:\n            code, message = task_srv.register_task(f.read())\n            if code == 200:\n                print(message)\n            elif code == 409:\n                print('Task already exists')\n            else:\n                raise TaskRegistryError(message)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _run_app(self):\n        is_remote_run = self._arguments.get('--remote')\n        filename = self._arguments.get('<file_name>')\n        upload_ports = self._arguments.get('--upload')\n        download_ports = self._arguments.get('--download')\n        is_verbose = self._arguments.get('--verbose')\n        # A dry run means, allow port sot be pushed up, but don't allow execution and monitoring.\n        is_dry_run = self._arguments.get('--dry-run')\n\n        if download_ports:  # TODO temporary until implemented.\n            raise NotImplementedError(\"Downloading of output ports is not implemented yet.\")\n\n        # Check if the filename passed is actually a class object (gbdxtools functionality)\n        if not isinstance(filename, str) and issubclass(filename, TaskTemplate):\n            template_class = filename\n            template_file = inspect.getfile(template_class)\n            config_file = self._write_config_file(template_file)\n\n        else:\n            template_file = self._get_template_abs_path(filename)\n\n            if not os.path.isfile(template_file):\n                raise ValueError('The location %s does not exist' % template_file)\n\n            config_file = self._write_config_file(template_file)\n\n            template_class = self._get_class(template_file)\n\n        with template_class() as template:\n            if is_remote_run:  # Means the user is running with --remote, push to S3 and submit workflow.\n\n                task = template.task\n\n                # Set the source bundle directory to where the template_file is.\n                task.source_bundle.value = os.path.join(os.path.dirname(template_file), 'tmp_%s' % str(uuid.uuid4()))\n\n                task.run_name = '{task_name}_src'.format(task_name=task.name)\n\n                src_bundle_dir = task.source_bundle.value\n\n                # Create source bundle to be executed on the GBDX platform\n                self._archive_source(os.path.dirname(src_bundle_dir), src_bundle_dir)\n\n                port_service = PortService(task)\n\n                if upload_ports:\n                    # Push all port data to S3\n                    port_service.upload_input_ports()\n                else:\n                    # Only push source bundle port\n                    port_service.upload_input_ports(port_list=[self.SOURCE_BUNDLE_PORT])\n\n                # Delete source bundle directory and config after upload.\n                shutil.rmtree(src_bundle_dir)\n                os.remove(config_file)\n\n                # Get the new task object with uploaded port locations.\n                task = port_service.task\n\n                # Validate task\n                task.is_valid(remote=True)\n\n                workflow = Workflow(task)\n\n                if is_verbose:\n                    temp_wf = workflow.json\n                    printer(temp_wf)\n\n                if is_dry_run:\n                    return task\n\n                try:\n                    workflow.execute()\n                    printer(workflow.id)\n                except Exception as e:\n                    printer(e.message)\n                    template.reason = \"Execution Failed: %s\" % e.message\n                    return\n\n                # Monitor events of workflow\n                is_done = workflow.monitor_run()\n\n                if not is_done:\n                    template.reason = \"Execution Failed during Run\"\n\n                if download_ports:\n                    # TODO port_service.download_output_port()\n                    pass\n\n            else:\n                # For local and Docker container execution.\n\n                # Check that all output locations exist.\n                template.check_and_create_outputs()\n\n                # Validate task\n                template.task.is_valid()\n\n                if is_verbose:\n                    printer(template.task.json())\n                    all_ports = template.task.ports[0] + template.task.ports[1]\n                    printer([port.__str__() for port in all_ports])\n\n                if is_dry_run:\n                    template.reason = \"Execution Skipped\"\n                    return\n\n                # Run Task Locally\n                try:\n                    template.invoke()\n                except Exception as e:\n                    template.reason = \"Failed Exception: %s\" % e\n\n                if template.reason is None or template.reason == '':\n                    template.reason = \"Execution Completed\"", "response": "Method for running a custom application."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwriting a config file to the source bundle location to identify the entry point.", "response": "def _write_config_file(template_file):\n        \"\"\"\n        Write a config file to the source bundle location to identify the entry point.\n        :param template_file: path to the task template subclass (executable)\n        \"\"\"\n        config_filename = '.cloud_harness_config.json'\n        config_path = os.path.dirname(template_file)\n\n        filename = os.path.split(template_file)[1]\n\n        if filename.endswith('.pyc'):\n            filename = filename[:-1]\n\n        config_file = os.path.join(config_path, config_filename)\n\n        with open(config_file, 'w') as f:\n            f.write(json.dumps({'task_filename': filename}))\n\n        return config_file"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_class(template_file):\n        with warnings.catch_warnings():\n            # suppress warning from importing\n            warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n            template_module = imp.load_source('module.name', template_file)\n\n        # Find the subclass of TaskTemplate\n        for name, data in inspect.getmembers(template_module, inspect.isclass):\n            if issubclass(data, TaskTemplate) and data.__name__ != TaskTemplate.__name__:\n                return data", "response": "Imports the file and inspect for subclass of TaskTemplate.\n           "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a valid absolute path. filename can be relative or absolute.", "response": "def _get_template_abs_path(filename):\n        \"\"\"\n        Return a valid absolute path. filename can be relative or absolute.\n        \"\"\"\n        if os.path.isabs(filename) and os.path.isfile(filename):\n            return filename\n        else:\n            return os.path.join(os.getcwd(), filename)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef upload(self, source_files, s3_folder=None):\n\n        if s3_folder is None:\n            folder = self.prefix\n        else:\n            folder = '%s/%s' % (self.prefix, s3_folder)\n\n        if isinstance(source_files, list):\n            for file_tuple in source_files:\n                self.__upload_file(file_tuple, folder)\n        elif isinstance(source_files, tuple):\n            self.__upload_file(source_files, folder)\n        else:\n            raise ValueError(\"Source Files must be a tuple or list of tuples: (filename, keyname)\")", "response": "Upload a list of files to a users account location"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndownloads all files from a users account location", "response": "def download(self, local_port_path, key_names):  # pragma: no cover\n        \"\"\"\n        download all files from a users account location\n        :param local_port_path: the local path where the data is to download to\n        :param key_name: can start with self.prefix or taken as relative to prefix.\n\n        Example:\n            local_port_path = /home/user/myworkflow/input_images/ (sync all data in this folder)\n            s3_folder = myworkflow/input_images/ (location on s3 that will be synced to local path)\n        \"\"\"\n\n        if not os.path.isdir(local_port_path):\n            raise ValueError(\"Download path does not exist: %s\" % local_port_path)\n\n        if not isinstance(key_names, list):\n            key_names = [key_names]\n\n        for key_name in key_names:\n            is_folder = key_name.endswith('/')\n\n            # strip leading and trailing slashes\n            key_name = key_name.lstrip('/').rstrip('/')\n            key_parts = key_name.split('/')\n\n            # Key names from the list function will include the account prefix\n            # and any folder namespace.\n            if key_parts[0] == self.prefix:\n                path = os.path.join(local_port_path, *key_parts[1:])\n                if not is_folder:\n                    folder_path = os.path.join(local_port_path, *key_parts[1:-1])\n                get_key_name = key_name\n            else:\n                path = os.path.join(local_port_path, *key_parts)\n                if not is_folder:\n                    folder_path = os.path.join(local_port_path, *key_parts[:-1])\n                get_key_name = '%s/%s' % (self.prefix, key_name)\n\n            if is_folder and not os.path.isdir(path):\n                # A directory that doesn't exist\n                os.makedirs(path)\n            else:\n                if not os.path.isdir(folder_path):\n                    os.makedirs(folder_path)\n                # Assume it is a file\n                self.__download_file(path, get_key_name)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a list of keys for the accounts", "response": "def list(self, s3_folder='', full_key_data=False):\n        \"\"\"Get a list of keys for the accounts\"\"\"\n        if not s3_folder.startswith('/'):\n            s3_folder = '/' + s3_folder\n\n        s3_prefix = self.prefix + s3_folder\n\n        bucket_data = self.client.list_objects(Bucket=self.bucket, Prefix=s3_prefix)\n\n        if full_key_data:\n            return bucket_data['Contents']\n        else:\n            return [k['Key'] for k in bucket_data['Contents']]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _build_worklfow_json(self):\n        wf_json = {'tasks': [], 'name': 'cloud-harness_%s' % str(uuid.uuid4())}\n\n        task_def = json.loads(self.task_template.json())\n\n        d = {\n            \"name\": task_def['name'],\n            \"outputs\": [],\n            \"inputs\": [],\n            \"taskType\": task_def['taskType']\n        }\n\n        # Add input ports\n        for port in self.task_template.input_ports:\n            port_value = port.value\n\n            if port_value is False:\n                port_value = 'false'\n            if port_value is True:\n                port_value = 'true'\n\n            d['inputs'].append({\n                \"name\": port._name,\n                \"value\": port_value\n            })\n\n        # Add output ports\n        for port in self.task_template.output_ports:\n            d['outputs'].append({\n                \"name\": port._name\n            })\n\n        # Add task to workflow\n        wf_json['tasks'].append(d)\n\n        # Add port to be saved\n        for port in self.task_template.output_ports:\n            # Add save data locations\n            if hasattr(port, 'stageToS3') and port.stageToS3:\n                save_location = '{customer_storage}/{run_name}/{port}'.format(\n                    customer_storage=self.storage.location,\n                    run_name=self.task_template.run_name,\n                    port=port.name\n                )\n                new_task = dict(**self.STAGE_TO_S3)\n                new_task['inputs'] = [\n                    {'name': 'data', 'source': '%s:%s' % (task_def['name'], port._name)},\n                    {'name': 'destination', 'value': save_location}\n                ]\n                wf_json['tasks'].append(new_task)\n\n        return wf_json", "response": "Build a JSON representation of the cloud_harness task."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef execute(self, override_wf_json=None):\n        r = self.gbdx.post(\n            self.URL,\n            json=self.json if override_wf_json is None else override_wf_json\n        )\n\n        try:\n            r.raise_for_status()\n        except:\n            print(\"GBDX API Status Code: %s\" % r.status_code)\n            print(\"GBDX API Response: %s\" % r.text)\n            self.id = None\n            return\n\n        self.id = r.json()['id']\n        self._refresh_status()", "response": "Execute the cloud_harness task."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef monitor_run(self):  # pragma: no cover\n\n        spinner = itertools.cycle(['-', '/', '|', '\\\\'])\n\n        while not self.complete:\n            for i in xrange(300):\n                sys.stdout.write(spinner.next())\n                sys.stdout.flush()\n                sys.stdout.write('\\b')\n                time.sleep(0.03)\n\n        if self.succeeded:\n            sys.stdout.write(\"\\nWorkflow completed successfully\\n\")\n            return True\n        else:\n            sys.stdout.write(\"\\nWorkflow failed: %s\\n\" % self.status)\n            return False", "response": "Monitor the workflows events and display spinner while running."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinalizing the task template.", "response": "def finalize(self, success_or_fail, message=''):\n        \"\"\"\n        :param success_or_fail: string that is 'success' or 'fail'\n        :param message:\n        \"\"\"\n        if not self.__remote_run:\n            return json.dumps({'status': success_or_fail, 'reason': message}, indent=4)\n        else:\n            super(TaskTemplate, self).finalize(success_or_fail, message)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef check_and_create_outputs(self):\n        if self.task is None:\n            raise TaskTemplateError('A task must be initialized before running a TaskTemplate subclass.')\n\n        for output_port in self.task.output_ports:\n            # Make the dir\n            if output_port.type == 'directory':\n                try:\n                    is_file = os.path.isabs(output_port.value) and not os.path.isfile(output_port.value)\n                    is_remote = output_port.is_valid_s3_url(output_port.value)\n                except LocalPortValidationError:\n                    is_file = False\n                    is_remote = None\n                except RemotePortValidationError:\n                    is_remote = False\n\n                self.logit.debug('Create Outputs: %s -> is_filesys %s, is_valid_s3_url %s' %\n                                 (output_port.name, is_file, is_remote))\n\n                if is_file and not is_remote:\n                    try:\n                        os.makedirs(output_port.value)\n                    except OSError as e:\n                        self.logit.exception(e)\n                        if 'File exists' not in e.strerror:\n                            raise e", "response": "Check that the task outputs exist and create the directories if they don t."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nuploads the input ports to the account storage.", "response": "def upload_input_ports(self, port_list=None, exclude_list=None):\n        \"\"\"\n        Takes the workflow value for each port and does the following:\n            * If local filesystem -> Uploads locally files to s3.\n                S3 location will be as follows:\n                    gbd-customer-data/<acct_id>/<workflow_name>/<task_name>/<port_name>/\n            * If S3 url -> do nothing.\n        :returns the update workflow with S3 urls.\n        \"\"\"\n\n        input_ports = self._task.input_ports\n\n        for port in input_ports:\n\n            # If port list is not None, then only allow port names in the list\n            if port_list and port.name not in port_list:\n                continue\n\n            # Exclude ports as provided\n            if exclude_list and port.name in exclude_list:\n                continue\n\n            # port_value = port.get('value', None)\n\n            # Check if the port value is a valid file system location\n            if not port.value or not os.path.isabs(port.value) or not os.path.isdir(port.value):\n                continue\n\n            # The prefix for each key that is uploaded, not including the the acct id.\n            prefix = '{run_name}/{port}'.format(\n                run_name=self._task.run_name,\n                # task=self._task.name,\n                port=port.name\n            )\n\n            port_files = self._get_port_files(port.value, prefix)\n\n            # Update the port value with an S3 url\n            port.value = '%s/%s' % (self.s3_root, prefix)\n\n            if len(port_files) == 0:\n                printer('Port %s is empty, push to S3 skipped' % port.name)\n            else:\n                self.storage.upload(port_files)\n                printer('Port %s pushed to account storage, %s files' % (port.name, len(port_files)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfinds files for the local_path and return tuples of filename and keynames", "response": "def _get_port_files(local_path, prefix):\n        \"\"\"\n        Find files for the local_path and return tuples of filename and keynames\n        :param local_path: the local path to search for files\n        :param prefix: the S3 prefix for each key name on S3\n        \"\"\"\n        source_files = []\n\n        for root, dirs, files in os.walk(local_path, topdown=False):\n\n            for name in files:\n                fname = os.path.join(root, name)\n\n                key_name = '%s/%s' % (prefix, fname[len(local_path) + 1:])\n\n                source_files.append((fname, key_name))\n\n        return source_files"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmoves an active project to the archive.", "response": "def archive(folder, dry_run=False):\n    \"Move an active project to the archive.\"\n    # error handling on archive_dir already done in main()\n\n    for f in folder:\n        if not os.path.exists(f):\n            bail('folder does not exist: ' + f)\n\n    _archive_safe(folder, PROJ_ARCHIVE, dry_run=dry_run)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _mkdir(p):\n    \"The equivalent of 'mkdir -p' in shell.\"\n    isdir = os.path.isdir\n\n    stack = [os.path.abspath(p)]\n    while not isdir(stack[-1]):\n        parent_dir = os.path.dirname(stack[-1])\n        stack.append(parent_dir)\n\n    while stack:\n        p = stack.pop()\n        if not isdir(p):\n            os.mkdir(p)", "response": "The equivalent of mkdir - p in shell."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list(pattern=()):\n    \"List the contents of the archive directory.\"\n    # strategy: pick the intersection of all the patterns the user provides\n    globs = ['*{0}*'.format(p) for p in pattern] + ['*']\n\n    matches = []\n    offset = len(PROJ_ARCHIVE) + 1\n    for suffix in globs:\n        glob_pattern = os.path.join(PROJ_ARCHIVE, '*', '*', suffix)\n        matches.append(set(\n            f[offset:] for f in glob.glob(glob_pattern)\n        ))\n\n    matches = reduce(lambda x, y: x.intersection(y),\n                     matches)\n\n    for m in sorted(matches):\n        print(m)", "response": "List the contents of the archive directory."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrestore a project from the archive.", "response": "def restore(folder):\n    \"Restore a project from the archive.\"\n    if os.path.isdir(folder):\n        bail('a folder of the same name already exists!')\n\n    pattern = os.path.join(PROJ_ARCHIVE, '*', '*', folder)\n    matches = glob.glob(pattern)\n    if not matches:\n        bail('no project matches: ' + folder)\n\n    if len(matches) > 1:\n        print('Warning: multiple matches, picking the most recent',\n              file=sys.stderr)\n\n    source = sorted(matches)[-1]\n    print(source, '-->', folder)\n    shutil.move(source, '.')"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a new storage service client.", "response": "def new(cls, access_token, environment='prod'):\n        '''Create new storage service client.\n\n            Arguments:\n                environment(str): The service environment to be used for the client.\n                    'prod' or 'dev'.\n                access_token(str): The access token used to authenticate with the\n                    service\n\n            Returns:\n                A storage_service.Client instance\n        '''\n\n        api_client = ApiClient.new(access_token, environment)\n        return cls(api_client)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef list(self, path):\n        '''List the entities found directly under the given path.\n\n        Args:\n            path (str): The path of the entity to be listed. Must start with a '/'.\n\n        Returns:\n            The list of entity names directly under the given path:\n\n                u'/12345/folder_1'\n\n        Raises:\n            StorageArgumentException: Invalid arguments\n            StorageForbiddenException: Server response code 403\n            StorageNotFoundException: Server response code 404\n            StorageException: other 400-600 error codes\n        '''\n\n        self.__validate_storage_path(path)\n        entity = self.api_client.get_entity_by_query(path=path)\n        if entity['entity_type'] not in self.__BROWSABLE_TYPES:\n            raise StorageArgumentException('The entity type \"{0}\" cannot be'\n                                           'listed'.format(entity['entity_type']))\n        entity_uuid = entity['uuid']\n        file_names = []\n\n        # get files\n        more_pages = True\n        page_number = 1\n        while more_pages:\n            response = self.api_client.list_folder_content(\n                entity_uuid, page=page_number, ordering='name')\n            more_pages = response['next'] is not None\n            page_number += 1\n            for child in response['results']:\n                pattern = '/{name}' if child['entity_type'] == 'folder' else '{name}'\n                file_names.append(pattern.format(name=child['name']))\n\n        return file_names", "response": "List the entities found directly under the given path."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef download_file(self, path, target_path):\n        '''Download a file from storage service to local disk.\n\n        Existing files on the target path will be overwritten.\n        The download is not recursive, as it only works on files.\n\n        Args:\n            path (str): The path of the entity to be downloaded. Must start with a '/'.\n\n        Returns:\n            None\n\n        Raises:\n            StorageArgumentException: Invalid arguments\n            StorageForbiddenException: Server response code 403\n            StorageNotFoundException: Server response code 404\n            StorageException: other 400-600 error codes\n        '''\n\n        self.__validate_storage_path(path)\n        entity = self.api_client.get_entity_by_query(path=path)\n        if entity['entity_type'] != 'file':\n            raise StorageArgumentException('Only file entities can be downloaded')\n\n        signed_url = self.api_client.get_signed_url(entity['uuid'])\n        response = self.api_client.download_signed_url(signed_url)\n\n        with open(target_path, \"wb\") as output:\n            for chunk in response.iter_content(chunk_size=1024):\n                output.write(chunk)", "response": "Download a file from storage service to local disk."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking if a certain path exists in the storage service.", "response": "def exists(self, path):\n        '''Check if a certain path exists in the storage service.\n\n        Args:\n            path (str): The path to be checked\n\n        Returns:\n            True if the path exists, False otherwise\n\n        Raises:\n            StorageArgumentException: Invalid arguments\n            StorageForbiddenException: Server response code 403\n            StorageNotFoundException: Server response code 404\n            StorageException: other 400-600 error codes\n        '''\n\n        self.__validate_storage_path(path)\n        try:\n            metadata = self.api_client.get_entity_by_query(path=path)\n        except StorageNotFoundException:\n            return False\n\n        return metadata and 'uuid' in metadata"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the parent entity of the given path.", "response": "def get_parent(self, path):\n        '''Get the parent entity of the entity pointed by the given path.\n\n        Args:\n            path (str): The path of the entity whose parent is needed\n\n        Returns:\n            A JSON object of the parent entity if found.\n\n        Raises:\n            StorageArgumentException: Invalid arguments\n            StorageForbiddenException: Server response code 403\n            StorageNotFoundException: Server response code 404\n            StorageException: other 400-600 error codes\n        '''\n\n        self.__validate_storage_path(path, projects_allowed=False)\n        path_steps = [step for step in path.split('/') if step]\n        del path_steps[-1]\n        parent_path = '/{0}'.format('/'.join(path_steps))\n        return self.api_client.get_entity_by_query(path=parent_path)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a folder in the storage service pointed by the given path.", "response": "def mkdir(self, path):\n        '''Create a folder in the storage service pointed by the given path.\n\n        Args:\n            path (str): The path of the folder to be created\n\n        Returns:\n            None\n\n        Raises:\n            StorageArgumentException: Invalid arguments\n            StorageForbiddenException: Server response code 403\n            StorageNotFoundException: Server response code 404\n            StorageException: other 400-600 error codes\n        '''\n\n        self.__validate_storage_path(path, projects_allowed=False)\n        parent_metadata = self.get_parent(path)\n        self.api_client.create_folder(path.split('/')[-1], parent_metadata['uuid'])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupload a local file to a storage service destination folder.", "response": "def upload_file(self, local_file, dest_path, mimetype):\n        '''Upload local file content to a storage service destination folder.\n\n            Args:\n                local_file(str)\n                dest_path(str):\n                    absolute Storage service path '/project' prefix is essential\n                    suffix should be the name the file will have on in the destination folder\n                    i.e.: /project/folder/.../file_name\n                mimetype(str): set the contentType attribute\n\n            Returns:\n                The uuid of created file entity as string\n\n            Raises:\n                StorageArgumentException: Invalid arguments\n                StorageForbiddenException: Server response code 403\n                StorageNotFoundException: Server response code 404\n                StorageException: other 400-600 error codes\n        '''\n\n        self.__validate_storage_path(dest_path)\n        # get the paths of the target dir and the target file name\n        if dest_path.endswith('/'):\n            raise StorageArgumentException('Must specify target file name in dest_path argument')\n        if local_file.endswith(os.path.sep):\n            raise StorageArgumentException('Must specify source file name in local_file'\n                                           ' argument, directory upload not supported')\n\n        # create the file container\n        new_file = self.api_client.create_file(\n            name=dest_path.split('/').pop(),\n            content_type=mimetype,\n            parent=self.get_parent(dest_path)['uuid']\n        )\n\n        etag = self.api_client.upload_file_content(new_file['uuid'], source=local_file)\n        new_file['etag'] = etag\n\n        return new_file"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delete(self, path):\n        ''' Delete an entity from the storage service using its path.\n\n            Args:\n                path(str): The path of the entity to be delete\n\n            Returns:\n                The uuid of created file entity as string\n\n            Raises:\n                StorageArgumentException: Invalid arguments\n                StorageForbiddenException: Server response code 403\n                StorageNotFoundException: Server response code 404\n                StorageException: other 400-600 error codes\n        '''\n\n        self.__validate_storage_path(path, projects_allowed=False)\n\n        entity = self.api_client.get_entity_by_query(path=path)\n\n        if entity['entity_type'] in self.__BROWSABLE_TYPES:\n            # At this point it can only be a folder\n            contents = self.api_client.list_folder_content(entity['uuid'])\n            if contents['count'] > 0:\n                raise StorageArgumentException(\n                    'This method cannot delete non-empty folder. Please empty the folder first.')\n\n            self.api_client.delete_folder(entity['uuid'])\n        elif entity['entity_type'] == 'file':\n            self.api_client.delete_file(entity['uuid'])", "response": "Delete an entity from the storage service using its path."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef __validate_storage_path(cls, path, projects_allowed=True):\n        '''Validate a string as a valid storage path'''\n\n        if not path or not isinstance(path, str) or path[0] != '/' or path == '/':\n            raise StorageArgumentException(\n                'The path must be a string, start with a slash (/), and be longer'\n                ' than 1 character.')\n        if not projects_allowed and len([elem for elem in path.split('/') if elem]) == 1:\n            raise StorageArgumentException(\n                'This method does not accept projects in the path.')", "response": "Validate a string as a valid storage path."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_valid(self, remote=False):\n\n        if len(self.input_ports) < 1:\n            return False\n\n        if remote:\n            # Ignore output ports as value will overriden.\n            ports = [\n                port for port in self.input_ports if port.type == 'directory'\n                ]\n            for port in ports:\n                # Will raise exception if the port is invalid.\n                port.is_valid_s3_url(port.value)\n        else:\n            all_ports = self.ports[0] + self.ports[1]\n            ports = [\n                port for port in all_ports if port.type == 'directory' and port.name != 'source_bundle'\n                ]\n            for port in ports:\n                # Will raise exception if the port is invalid.\n                port.is_valid_filesys(port.value)\n\n        return True", "response": "Check if the cloud - harness code is valid."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nestimates the local density of the data - set data.", "response": "def get_local_densities(data, kernel_mult = 2.0, metric = 'manhattan'):\n    \"\"\"For each sample point of the data-set 'data', estimate a local density in feature\n        space by counting the number of neighboring data-points within a particular\n        region centered around that sample point.\n    \n    Parameters\n    ----------\n    data : array of shape (n_samples, n_features)\n        The data-set, a fraction of whose sample points will be extracted\n        by density sampling.\n    \n    kernel_mult : float, optional (default = 2.0)\n        The kernel multiplier, which determine (in terms of the median of the distribution\n        of distances among nearest neighbors) the extent of the regions centered\n        around each sample point to consider for the computation of the local density\n        associated to that particular sample point.\n    \n    metric : string, optional (default = 'manhattan')\n        The distance metric used to determine the nearest-neighbor to each data-point.\n        The DistanceMetric class defined in scikit-learn's library lists all available\n        metrics.\n    \n    Returns\n    -------\n    local_densities : array of shape (n_samples,)\n        The i-th entry of this vector corresponds to the local density of the i-th sample\n        point in the order of the rows of 'data'.  \n    \"\"\"\n    \n    data = np.atleast_2d(data)\n    \n    assert isinstance(kernel_mult, numbers.Real) and kernel_mult > 0\n    \n    kernel_width = kernel_mult * median_min_distance(data, metric)\n    \n    N_samples = data.shape[0]\n\n    if 8.0 * get_chunk_size(N_samples, 1) > N_samples:\n        A = radius_neighbors_graph(data, kernel_width, mode = 'connectivity', metric = metric, include_self = True)\n\n        rows, _ = A.nonzero()\n        with NamedTemporaryFile('w', delete = True, dir = './') as file_name:\n            fp = np.memmap(file_name, dtype = int, mode = 'w+', shape = rows.shape)\n            fp[:] = rows[:]\n            _, counts = np.unique(fp, return_counts = True)\n\n        local_densities = np.zeros(N_samples, dtype = int)\n        for i in xrange(N_samples):\n            local_densities[i] = counts[i]\n    else:\n        local_densities = np.zeros(N_samples, dtype = int)\n\n        chunks_size = get_chunk_size(N_samples, 2)\n        for i in xrange(0, N_samples, chunks_size):\n            chunk = data[i:min(i + chunks_size, N_samples)]\n\n            D = pairwise_distances(chunk, data, metric, n_jobs = 1)\n\n            D = (D <= kernel_width)\n\n            local_densities[i + np.arange(min(chunks_size, N_samples - i))] = D.sum(axis = 1)\n        \n    return local_densities"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef new(cls, access_token, environment='prod'):\n        '''Creates a new cross-service client.'''\n\n        return cls(\n            storage_client=StorageClient.new(access_token, environment=environment))", "response": "Creates a new cross - service client."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a new storage service REST client.", "response": "def new(cls, access_token, environment='prod'):\n        '''Create a new storage service REST client.\n\n            Arguments:\n                environment: The service environment to be used for the client\n                access_token: The access token used to authenticate with the\n                    service\n\n            Returns:\n                A storage_service.api.ApiClient instance\n\n            Example:\n                >>> storage_client = ApiClient.new(my_access_token)\n\n        '''\n        request = RequestBuilder \\\n            .request(environment) \\\n            .to_service(cls.SERVICE_NAME, cls.SERVICE_VERSION) \\\n            .throw(\n                StorageForbiddenException,\n                lambda resp: 'You are forbidden to do this.'\n                if resp.status_code == 403 else None\n            ) \\\n            .throw(\n                StorageNotFoundException,\n                lambda resp: 'The entity is not found'\n                if resp.status_code == 404 else None\n            ) \\\n            .throw(\n                StorageException,\n                lambda resp: 'Server response: {0} - {1}'.format(resp.status_code, resp.text)\n                if not resp.ok else None\n            )\n\n        authenticated_request = request.with_token(access_token)\n\n        return cls(request, authenticated_request)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nremoves empty ( None ) valued keywords and self from function parameters", "response": "def _prep_params(params):\n        '''Remove empty (None) valued keywords and self from function parameters'''\n\n        return {k: v for (k, v) in params.items() if v is not None and k != 'self'}"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting generic entity details.", "response": "def get_entity_details(self, entity_id):\n        '''Get generic entity by UUID.\n\n        Args:\n            entity_id (str): The UUID of the requested entity.\n\n        Returns:\n            A dictionary describing the entity::\n\n                {\n                     u'collab_id': 2271,\n                     u'created_by': u'303447',\n                     u'created_on': u'2017-03-10T12:50:06.077891Z',\n                     u'description': u'',\n                     u'entity_type': u'project',\n                     u'modified_by': u'303447',\n                     u'modified_on': u'2017-03-10T12:50:06.077946Z',\n                     u'name': u'2271',\n                     u'uuid': u'3abd8742-d069-44cf-a66b-2370df74a682'\n                 }\n\n        Raises:\n            StorageArgumentException: Invalid arguments\n            StorageForbiddenException: Server response code 403\n            StorageNotFoundException: Server response code 404\n            StorageException: other 400-600 error codes\n        '''\n        if not is_valid_uuid(entity_id):\n            raise StorageArgumentException(\n                'Invalid UUID for entity_id: {0}'.format(entity_id))\n        return self._authenticated_request \\\n            .to_endpoint('entity/{}/'.format(entity_id)) \\\n            .return_body() \\\n            .get()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nretrieves the details of an entity by the given query.", "response": "def get_entity_by_query(self, uuid=None, path=None, metadata=None):\n        '''Retrieve entity by query param which can be either uuid/path/metadata.\n\n        Args:\n            uuid (str): The UUID of the requested entity.\n            path (str): The path of the requested entity.\n            metadata (dict): A dictionary of one metadata {key: value} of the\n                requested entitity.\n\n        Returns:\n            The details of the entity, if found::\n\n                {\n                    u'content_type': u'plain/text',\n                    u'created_by': u'303447',\n                    u'created_on': u'2017-03-13T10:52:23.275087Z',\n                    u'description': u'',\n                    u'entity_type': u'file',\n                    u'modified_by': u'303447',\n                    u'modified_on': u'2017-03-13T10:52:23.275126Z',\n                    u'name': u'myfile',\n                    u'parent': u'3abd8742-d069-44cf-a66b-2370df74a682',\n                    u'uuid': u'e2c25c1b-f6a9-4cf6-b8d2-271e628a9a56'\n                }\n\n        Raises:\n            StorageArgumentException: Invalid arguments\n            StorageForbiddenException: Server response code 403\n            StorageNotFoundException: Server response code 404\n            StorageException: other 400-600 error codes\n        '''\n        if not (uuid or path or metadata):\n            raise StorageArgumentException('No parameter given for the query.')\n        if uuid and not is_valid_uuid(uuid):\n            raise StorageArgumentException(\n                'Invalid UUID for uuid: {0}'.format(uuid))\n        params = locals().copy()\n        if metadata:\n            if not isinstance(metadata, dict):\n                raise StorageArgumentException('The metadata needs to be provided'\n                                               ' as a dictionary.')\n            key, value = next(iter(metadata.items()))\n            params[key] = value\n            del params['metadata']\n        params = self._prep_params(params)\n\n        return self._authenticated_request \\\n            .to_endpoint('entity/') \\\n            .with_params(params) \\\n            .return_body() \\\n            .get()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_metadata(self, entity_type, entity_id, metadata):\n        '''Set metadata for an entity.\n\n        Args:\n            entity_type (str): Type of the entity. Admitted values: ['project',\n                'folder', 'file'].\n            entity_id (str): The UUID of the entity to be modified.\n            metadata (dict): A dictionary of key/value pairs to be written as\n                metadata.\n\n        Warning:\n            It will replace all existing metadata with the provided dictionary.\n\n        Returns:\n            A dictionary of the updated metadata::\n\n                {\n                    u'bar': u'200',\n                    u'foo': u'100'\n                }\n\n        Raises:\n            StorageArgumentException: Invalid arguments\n            StorageForbiddenException: Server response code 403\n            StorageNotFoundException: Server response code 404\n            StorageException: other 400-600 error codes\n        '''\n        if not is_valid_uuid(entity_id):\n            raise StorageArgumentException(\n                'Invalid UUID for entity_id: {0}'.format(entity_id))\n        if not isinstance(metadata, dict):\n            raise StorageArgumentException('The metadata was not provided as a '\n                                           'dictionary')\n\n        return self._authenticated_request \\\n            .to_endpoint('{}/{}/metadata/'.format(entity_type, entity_id)) \\\n            .with_json_body(metadata) \\\n            .return_body() \\\n            .post()", "response": "Set the metadata for an entity."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_metadata(self, entity_type, entity_id):\n        '''Get metadata of an entity.\n\n        Args:\n            entity_type (str): Type of the entity. Admitted values: ['project',\n                'folder', 'file'].\n            entity_id (str): The UUID of the entity to be modified.\n\n        Returns:\n            A dictionary of the metadata::\n\n                {\n                    u'bar': u'200',\n                    u'foo': u'100'\n                }\n\n        Raises:\n            StorageArgumentException: Invalid arguments\n            StorageForbiddenException: Server response code 403\n            StorageNotFoundException: Server response code 404\n            StorageException: other 400-600 error codes\n        '''\n        if not is_valid_uuid(entity_id):\n            raise StorageArgumentException(\n                'Invalid UUID for entity_id: {0}'.format(entity_id))\n\n        return self._authenticated_request \\\n            .to_endpoint('{}/{}/metadata/'.format(entity_type, entity_id)) \\\n            .return_body() \\\n            .get()", "response": "Get the metadata of an entity."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate the metadata of an entity.", "response": "def update_metadata(self, entity_type, entity_id, metadata):\n        '''Update the metadata of an entity.\n\n        Existing non-modified metadata will not be affected.\n\n        Args:\n            entity_type (str): Type of the entity. Admitted values: 'project',\n                'folder', 'file'.\n            entity_id (str): The UUID of the entity to be modified.\n            metadata (dict): A dictionary of key/value pairs to be written as\n                metadata.\n\n        Returns:\n            A dictionary of the updated object metadata::\n\n                {\n                    u'bar': u'200',\n                    u'foo': u'100'\n                }\n\n        Raises:\n            StorageArgumentException: Invalid arguments\n            StorageForbiddenException: Server response code 403\n            StorageNotFoundException: Server response code 404\n            StorageException: other 400-600 error codes\n        '''\n        if not is_valid_uuid(entity_id):\n            raise StorageArgumentException(\n                'Invalid UUID for entity_id: {0}'.format(entity_id))\n        if not isinstance(metadata, dict):\n            raise StorageArgumentException('The metadata was not provided as a '\n                                           'dictionary')\n\n        return self._authenticated_request \\\n            .to_endpoint('{}/{}/metadata/'.format(entity_type, entity_id)) \\\n            .with_json_body(metadata) \\\n            .return_body() \\\n            .put()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delete_metadata(self, entity_type, entity_id, metadata_keys):\n        '''Delete the selected metadata entries of an entity.\n\n        Only deletes selected metadata keys, for a complete wipe, use set_metadata.\n\n        Args:\n            entity_type (str): Type of the entity. Admitted values: ['project',\n                'folder', 'file'].\n            entity_id (srt): The UUID of the entity to be modified.\n            metadata_keys (lst): A list of metada keys to be deleted.\n\n        Returns:\n            A dictionary of the updated object metadata::\n\n                {\n                    u'bar': u'200',\n                    u'foo': u'100'\n                }\n\n        Raises:\n            StorageArgumentException: Invalid arguments\n            StorageForbiddenException: Server response code 403\n            StorageNotFoundException: Server response code 404\n            StorageException: other 400-600 error codes\n        '''\n        if not is_valid_uuid(entity_id):\n            raise StorageArgumentException(\n                'Invalid UUID for entity_id: {0}'.format(entity_id))\n        if not isinstance(metadata_keys, list):\n            raise StorageArgumentException('The metadata was not provided as a '\n                                           'dictionary')\n\n        return self._authenticated_request \\\n            .to_endpoint('{}/{}/metadata/'.format(entity_type, entity_id)) \\\n            .with_json_body({'keys': metadata_keys}) \\\n            .return_body() \\\n            .delete()", "response": "Delete the selected metadata entries of an entity."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef list_projects(self, hpc=None, access=None, name=None, collab_id=None,\n                      page_size=DEFAULT_PAGE_SIZE, page=None, ordering=None):\n        '''List all the projects the user have access to.\n\n            This function does not retrieve all results, pages have\n            to be manually retrieved by the caller.\n\n        Args:\n            hpc (bool): If 'true', the result will contain only the HPC projects\n                (Unicore projects).\n            access (str): If provided, the result will contain only projects\n                where the user has the provided acccess.\n                Admitted values: ['read', 'write'].\n            name (str): Filter on the project name.\n            collab_id (int): Filter on the collab id.\n            page_size (int): Number of elements per page.\n            page (int): Number of the page\n            ordering (str): Indicate on which fields to sort the result.\n                Prepend '-' to invert order. Multiple values can be provided.\n                Ordering is supported on: ['name', 'created_on', 'modified_on'].\n                Example: ordering='name,created_on'\n\n        Returns:\n            A dictionary of the results::\n\n            {\n                u'count': 256,\n                u'next': u'http://link.to.next/page',\n                u'previous': None,\n                u'results': [{u'collab_id': 2079,\n                    u'created_by': u'258666',\n                    u'created_on': u'2017-02-23T15:09:27.626973Z',\n                    u'description': u'',\n                    u'entity_type': u'project',\n                    u'modified_by': u'258666',\n                    u'modified_on': u'2017-02-23T15:09:27.627025Z',\n                    u'name': u'2079',\n                    u'uuid': u'64a6ad2e-acd1-44a3-a4cd-6bd96e3da2b0'}]\n            }\n\n\n        Raises:\n            StorageForbiddenException: Server response code 403\n            StorageNotFoundException: Server response code 404\n            StorageException: other 400-600 error codes\n        '''\n        return self._authenticated_request \\\n            .to_endpoint('project/') \\\n            .with_params(self._prep_params(locals())) \\\n            .return_body() \\\n            .get()", "response": "This function returns a dictionary of all the projects the user has access to."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_project_details(self, project_id):\n        '''Get information on a given project\n\n        Args:\n            project_id (str): The UUID of the requested project.\n\n        Returns:\n            A dictionary describing the project::\n\n            {\n                u'collab_id': 2271,\n                u'created_by': u'303447',\n                u'created_on': u'2017-03-10T12:50:06.077891Z',\n                u'description': u'',\n                u'entity_type': u'project',\n                u'modified_by': u'303447',\n                u'modified_on': u'2017-03-10T12:50:06.077946Z',\n                u'name': u'2271',\n                u'uuid': u'3abd8742-d069-44cf-a66b-2370df74a682'\n            }\n\n        Raises:\n            StorageForbiddenException: Server response code 403\n            StorageNotFoundException: Server response code 404\n            StorageException: other 400-600 error codes\n        '''\n        if not is_valid_uuid(project_id):\n            raise StorageArgumentException(\n                'Invalid UUID for project_id: {0}'.format(project_id))\n\n        return self._authenticated_request \\\n            .to_endpoint('project/{}/'.format(project_id)) \\\n            .return_body() \\\n            .get()", "response": "Get information on a given project."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a new project.", "response": "def create_project(self, collab_id):\n        '''Create a new project.\n\n        Args:\n            collab_id (int): The id of the collab the project should be created in.\n\n        Returns:\n            A dictionary of details of the created project::\n\n                {\n                    u'collab_id': 12998,\n                    u'created_by': u'303447',\n                    u'created_on': u'2017-03-21T14:06:32.293902Z',\n                    u'description': u'',\n                    u'entity_type': u'project',\n                    u'modified_by': u'303447',\n                    u'modified_on': u'2017-03-21T14:06:32.293967Z',\n                    u'name': u'12998',\n                    u'uuid': u'2516442e-1e26-4de1-8ed8-94523224cc40'\n                }\n\n        Raises:\n            StorageForbiddenException: Server response code 403\n            StorageNotFoundException: Server response code 404\n            StorageException: other 400-600 error codes\n        '''\n        return self._authenticated_request \\\n            .to_endpoint('project/') \\\n            .with_json_body(self._prep_params(locals())) \\\n            .return_body() \\\n            .post()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndeleting a project. It will recursively delete all the content.", "response": "def delete_project(self, project):\n        '''Delete a project. It will recursively delete all the content.\n\n        Args:\n            project (str): The UUID of the project to be deleted.\n\n        Returns:\n            None\n\n        Raises:\n            StorageArgumentException: Invalid arguments\n            StorageForbiddenException: 403\n            StorageNotFoundException: 404\n            HTTPError: other non-20x error codes\n        '''\n        if not is_valid_uuid(project):\n            raise StorageArgumentException(\n                'Invalid UUID for project: {0}'.format(project))\n        self._authenticated_request \\\n            .to_endpoint('project/{}/'.format(project)) \\\n            .delete()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new folder.", "response": "def create_folder(self, name, parent):\n        '''Create a new folder.\n\n        Args:\n            name (srt): The name of the folder.\n            parent (str): The UUID of the parent entity. The parent must be a\n                project or a folder.\n\n        Returns:\n            A dictionary of details of the created folder::\n\n                {\n                    u'created_by': u'303447',\n                    u'created_on': u'2017-03-21T14:06:32.293902Z',\n                    u'description': u'',\n                    u'entity_type': u'folder',\n                    u'modified_by': u'303447',\n                    u'modified_on': u'2017-03-21T14:06:32.293967Z',\n                    u'name': u'myfolder',\n                    u'parent': u'3abd8742-d069-44cf-a66b-2370df74a682',\n                    u'uuid': u'2516442e-1e26-4de1-8ed8-94523224cc40'\n                }\n\n        Raises:\n            StorageArgumentException: Invalid arguments\n            StorageForbiddenException: Server response code 403\n            StorageNotFoundException: Server response code 404\n            StorageException: other 400-600 error codes\n        '''\n        if not is_valid_uuid(parent):\n            raise StorageArgumentException(\n                'Invalid UUID for parent: {0}'.format(parent))\n\n        return self._authenticated_request \\\n            .to_endpoint('folder/') \\\n            .with_json_body(self._prep_params(locals())) \\\n            .return_body() \\\n            .post()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets information on a given folder.", "response": "def get_folder_details(self, folder):\n        '''Get information on a given folder.\n\n        Args:\n            folder (str): The UUID of the requested folder.\n\n        Returns:\n            A dictionary of the folder details if found::\n\n                {\n                    u'created_by': u'303447',\n                    u'created_on': u'2017-03-21T14:06:32.293902Z',\n                    u'description': u'',\n                    u'entity_type': u'folder',\n                    u'modified_by': u'303447',\n                    u'modified_on': u'2017-03-21T14:06:32.293967Z',\n                    u'name': u'myfolder',\n                    u'parent': u'3abd8742-d069-44cf-a66b-2370df74a682',\n                    u'uuid': u'2516442e-1e26-4de1-8ed8-94523224cc40'\n                }\n\n        Raises:\n            StorageArgumentException: Invalid arguments\n            StorageForbiddenException: Server response code 403\n            StorageNotFoundException: Server response code 404\n            StorageException: other 400-600 error codes\n        '''\n        if not is_valid_uuid(folder):\n            raise StorageArgumentException(\n                'Invalid UUID for folder: {0}'.format(folder))\n        return self._authenticated_request \\\n            .to_endpoint('folder/{}/'.format(folder)) \\\n            .return_body() \\\n            .get()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlists files and folders (not recursively) contained in the folder. This function does not retrieve all results, pages have to be manually retrieved by the caller. Args: folder (str): The UUID of the requested folder. name (str): Optional filter on entity name. entity_type (str): Optional filter on entity type. Admitted values: ['file', 'folder']. content_type (str): Optional filter on entity content type (only files are returned). page_size (int): Number of elements per page. page (int): Number of the page. ordering (str): Indicate on which fields to sort the result. Prepend '-' to invert order. Multiple values can be provided. Ordering is supported on: ['name', 'created_on', 'modified_on']. Example: 'ordering=name,created_on' Returns: A dictionary of the results:: { u'count': 1, u'next': None, u'previous': None, u'results': [{u'content_type': u'plain/text', u'created_by': u'303447', u'created_on': u'2017-03-13T10:17:01.688472Z', u'description': u'', u'entity_type': u'file', u'modified_by': u'303447', u'modified_on': u'2017-03-13T10:17:01.688632Z', u'name': u'file_1', u'parent': u'eac11058-4ae0-4ea9-ada8-d3ea23887509', u'uuid': u'0e17eaac-cb00-4336-b9d7-657026844281'}] } Raises: StorageArgumentException: Invalid arguments StorageForbiddenException: Server response code 403 StorageNotFoundException: Server response code 404 StorageException: other 400-600 error codes", "response": "def list_folder_content(self, folder, name=None, entity_type=None,\n                            content_type=None, page_size=DEFAULT_PAGE_SIZE,\n                            page=None, ordering=None):\n        '''List files and folders (not recursively) contained in the folder.\n\n        This function does not retrieve all results, pages have\n        to be manually retrieved by the caller.\n\n        Args:\n            folder (str): The UUID of the requested folder.\n            name (str): Optional filter on entity name.\n            entity_type (str): Optional filter on entity type.\n                Admitted values: ['file', 'folder'].\n            content_type (str): Optional filter on entity content type (only\n                files are returned).\n            page_size (int): Number of elements per page.\n            page (int): Number of the page.\n            ordering (str): Indicate on which fields to sort the result. Prepend\n                '-' to invert order. Multiple values can be provided.\n                Ordering is supported on: ['name', 'created_on', 'modified_on'].\n                Example: 'ordering=name,created_on'\n\n        Returns:\n            A dictionary of the results::\n\n                {\n                u'count': 1,\n                u'next': None,\n                u'previous': None,\n                u'results': [{u'content_type': u'plain/text',\n                    u'created_by': u'303447',\n                    u'created_on': u'2017-03-13T10:17:01.688472Z',\n                    u'description': u'',\n                    u'entity_type': u'file',\n                    u'modified_by': u'303447',\n                    u'modified_on': u'2017-03-13T10:17:01.688632Z',\n                    u'name': u'file_1',\n                    u'parent': u'eac11058-4ae0-4ea9-ada8-d3ea23887509',\n                    u'uuid': u'0e17eaac-cb00-4336-b9d7-657026844281'}]\n                }\n\n        Raises:\n            StorageArgumentException: Invalid arguments\n            StorageForbiddenException: Server response code 403\n            StorageNotFoundException: Server response code 404\n            StorageException: other 400-600 error codes\n        '''\n        if not is_valid_uuid(folder):\n            raise StorageArgumentException(\n                'Invalid UUID for folder: {0}'.format(folder))\n        params = self._prep_params(locals())\n        del params['folder']  # not a query parameter\n        return self._authenticated_request \\\n            .to_endpoint('folder/{}/children/'.format(folder)) \\\n            .with_params(params) \\\n            .return_body() \\\n            .get()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delete_folder(self, folder):\n        '''Delete a folder. It will recursively delete all the content.\n\n        Args:\n            folder_id (str): The UUID of the folder to be deleted.\n\n        Returns:\n            None\n\n        Raises:\n            StorageArgumentException: Invalid arguments\n            StorageForbiddenException: 403\n            StorageNotFoundException: 404\n            HTTPError: other non-20x error codes\n        '''\n        if not is_valid_uuid(folder):\n            raise StorageArgumentException(\n                'Invalid UUID for folder: {0}'.format(folder))\n        self._authenticated_request \\\n            .to_endpoint('folder/{}/'.format(folder)) \\\n            .delete()", "response": "Delete a folder. It will recursively delete all the content."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nuploading a file content to the server.", "response": "def upload_file_content(self, file_id, etag=None, source=None, content=None):\n        '''Upload a file content. The file entity must already exist.\n\n        If an ETag is provided the file stored on the server is verified\n        against it. If it does not match, StorageException is raised.\n        This means the client needs to update its knowledge of the resource\n        before attempting to update again. This can be used for optimistic\n        concurrency control.\n\n        Args:\n            file_id (str): The UUID of the file whose content is written.\n            etag (str): The etag to match the contents against.\n            source (str): The path of the local file whose content to be uploaded.\n            content (str): A string of the content to be uploaded.\n\n        Note:\n            ETags should be enclosed in double quotes::\n\n                my_etag = '\"71e1ed9ee52e565a56aec66bc648a32c\"'\n\n        Returns:\n            The ETag of the file upload::\n\n                '\"71e1ed9ee52e565a56aec66bc648a32c\"'\n\n        Raises:\n            IOError: The source cannot be opened.\n            StorageArgumentException: Invalid arguments\n            StorageForbiddenException: Server response code 403\n            StorageNotFoundException: Server response code 404\n            StorageException: other 400-600 error codes\n        '''\n        if not is_valid_uuid(file_id):\n            raise StorageArgumentException(\n                'Invalid UUID for file_id: {0}'.format(file_id))\n\n        if not (source or content) or (source and content):\n            raise StorageArgumentException('Either one of source file or content '\n                                           'has to be provided.')\n\n        resp = self._authenticated_request \\\n            .to_endpoint('file/{}/content/upload/'.format(file_id)) \\\n            .with_body(content or open(source, 'rb')) \\\n            .with_headers({'If-Match': etag} if etag else {}) \\\n            .post()\n\n        if 'ETag' not in resp.headers:\n            raise StorageException('No ETag received from the service after the upload')\n\n        return resp.headers['ETag']"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncopying file content from source file to target file.", "response": "def copy_file_content(self, file_id, source_file):\n        '''Copy file content from source file to target file.\n\n        Args:\n            file_id (str): The UUID of the file whose content is written.\n            source_file (str): The UUID of the file whose content is copied.\n\n        Returns:\n            None\n\n        Raises:\n        StorageArgumentException: Invalid arguments\n        StorageForbiddenException: Server response code 403\n        StorageNotFoundException: Server response code 404\n        StorageException: other 400-600 error codes\n        '''\n        if not is_valid_uuid(file_id):\n            raise StorageArgumentException(\n                'Invalid UUID for file_id: {0}'.format(file_id))\n\n        if not is_valid_uuid(source_file):\n            raise StorageArgumentException(\n                'Invalid UUID for source_file: {0}'.format(source_file))\n\n        self._authenticated_request \\\n            .to_endpoint('file/{}/content/'.format(file_id)) \\\n            .with_headers({'X-Copy-From': source_file}) \\\n            .put()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndownload file content. Args: file_id (str): The UUID of the file whose content is requested etag (str): If the content is not changed since the provided ETag, the content won't be downloaded. If the content is changed, it will be downloaded and returned with its new ETag. Note: ETags should be enclosed in double quotes:: my_etag = '\"71e1ed9ee52e565a56aec66bc648a32c\"' Returns: A tuple of ETag and content (etag, content) if the content was retrieved. If an etag was provided, and content didn't change returns (None, None):: ('\"71e1ed9ee52e565a56aec66bc648a32c\"', 'Hello world!') Raises: StorageArgumentException: Invalid arguments StorageForbiddenException: Server response code 403 StorageNotFoundException: Server response code 404 StorageException: other 400-600 error codes", "response": "def download_file_content(self, file_id, etag=None):\n        '''Download file content.\n\n        Args:\n            file_id (str): The UUID of the file whose content is requested\n            etag (str): If the content is not changed since the provided ETag,\n                the content won't be downloaded. If the content is changed, it\n                will be downloaded and returned with its new ETag.\n\n        Note:\n            ETags should be enclosed in double quotes::\n\n                my_etag = '\"71e1ed9ee52e565a56aec66bc648a32c\"'\n\n\n        Returns:\n            A tuple of ETag and content (etag, content) if the content was\n            retrieved. If an etag was provided, and content didn't change\n            returns (None, None)::\n\n                ('\"71e1ed9ee52e565a56aec66bc648a32c\"', 'Hello world!')\n\n        Raises:\n            StorageArgumentException: Invalid arguments\n            StorageForbiddenException: Server response code 403\n            StorageNotFoundException: Server response code 404\n            StorageException: other 400-600 error codes\n        '''\n        if not is_valid_uuid(file_id):\n            raise StorageArgumentException(\n                'Invalid UUID for file_id: {0}'.format(file_id))\n\n        headers = {'Accept': '*/*'}\n        if etag:\n            headers['If-None-Match'] = etag\n\n        resp = self._authenticated_request \\\n            .to_endpoint('file/{}/content/'.format(file_id)) \\\n            .with_headers(headers) \\\n            .get()\n\n        if resp.status_code == 304:\n            return (None, None)\n\n        if 'ETag' not in resp.headers:\n            raise StorageException('No ETag received from the service with the download')\n\n        return (resp.headers['ETag'], resp.content)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_signed_url(self, file_id):\n        '''Get a signed unauthenticated URL.\n\n        It can be used to download the file content without the need for a\n        token. The signed URL expires after 5 seconds.\n\n        Args:\n            file_id (str): The UUID of the file to get the link for.\n\n        Returns:\n            The signed url as a string\n\n        Raises:\n            StorageArgumentException: Invalid arguments\n            StorageForbiddenException: Server response code 403\n            StorageNotFoundException: Server response code 404\n            StorageException: other 400-600 error codes\n        '''\n        if not is_valid_uuid(file_id):\n            raise StorageArgumentException(\n                'Invalid UUID for file_id: {0}'.format(file_id))\n\n        return self._authenticated_request \\\n            .to_endpoint('file/{}/content/secure_link/'.format(file_id)) \\\n            .return_body() \\\n            .get()['signed_url']", "response": "Get a signed unauthenticated URL."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndeleting a file. Args: file_id (str): The UUID of the file to delete. Returns: None Raises: StorageArgumentException: Invalid arguments StorageForbiddenException: Server response code 403 StorageNotFoundException: Server response code 404 StorageException: other 400-600 error codes", "response": "def delete_file(self, file_id):\n        '''Delete a file.\n\n        Args:\n            file_id (str): The UUID of the file to delete.\n\n        Returns:\n            None\n\n        Raises:\n            StorageArgumentException: Invalid arguments\n            StorageForbiddenException: Server response code 403\n            StorageNotFoundException: Server response code 404\n            StorageException: other 400-600 error codes\n        '''\n        if not is_valid_uuid(file_id):\n            raise StorageArgumentException(\n                'Invalid UUID for file_id: {0}'.format(file_id))\n\n        self._authenticated_request \\\n            .to_endpoint('file/{}/'.format(file_id)) \\\n            .delete()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the service name and version the request should target", "response": "def to_service(self, service, version):\n        '''Sets the service name and version the request should target\n\n        Args:\n            service (str): The name of the service as displayed in the services.json file\n            version (str): The version of the service as displayed in the services.json file\n\n        Returns:\n            The request builder instance in order to chain calls\n        '''\n        service_url = self._service_locator.get_service_url(service, version)\n        return self.__copy_and_set('service_url', self.__strip_trailing_slashes(service_url))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds headers to the request object", "response": "def with_headers(self, headers):\n        '''Adds headers to the request\n\n        Args:\n            headers (dict): The headers to add the request headers\n\n        Returns:\n            The request builder instance in order to chain calls\n        '''\n        copy = headers.copy()\n        copy.update(self._headers)\n        return self.__copy_and_set('headers', copy)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a new instance with the given parameters added to the request params .", "response": "def with_params(self, params):\n        '''Adds parameters to the request params\n\n        Args:\n            params (dict): The parameters to add to the request params\n\n        Returns:\n            The request builder instance in order to chain calls\n        '''\n        copy = params.copy()\n        copy.update(self._params)\n        return self.__copy_and_set('params', copy)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef throw(self, exception_class, should_throw):\n        '''Defines if the an exception should be thrown after the request is sent\n\n        Args:\n            exception_class (class): The class of the exception to instantiate\n            should_throw (function): The predicate that should indicate if the exception\n                should be thrown. This function will be called with the response as a parameter\n\n        Returns:\n            The request builder instance in order to chain calls\n        '''\n        return self.__copy_and_set('throws', self._throws + [(exception_class, should_throw)])", "response": "Defines if the an exception should be thrown after the request is sent\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run_command(cmd):\n    try:\n        process = subprocess.Popen(\n            cmd,\n            stdin=subprocess.PIPE,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.STDOUT,\n        )\n        outdata, _ = process.communicate()\n        return outdata\n    except subprocess.CalledProcessError as e:\n        return e", "response": "Runs the command and returns the output of the process."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef extract_source(bundle_path, source_path):\n    with tarfile.open(bundle_path, 'r:gz') as tf:\n        tf.extractall(path=source_path)\n    logger.debug(\"Archive Files: %s\" % os.listdir(os.path.dirname(bundle_path)))", "response": "Extract the source bundle"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprint the data to stdout.", "response": "def printer(data):\n    \"\"\"\n    response is json or straight text.\n    :param data:\n    :return:\n    \"\"\"\n    data = str(data) # Get rid of unicode\n    if not isinstance(data, str):\n        output = json.dumps(\n            data,\n            sort_keys=True,\n            indent=4,\n            separators=(',', ': ')\n        )\n    elif hasattr(data, 'json'):\n        output = data.json()\n    else:\n        output = data\n\n    sys.stdout.write(output)\n    sys.stdout.write('\\n')\n    sys.stdout.flush()\n    return"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_list_display(self, request):\n        list_display = []\n        for field_name in self.list_display:\n            try:\n                db_field = self.model._meta.get_field(field_name)\n                if isinstance(db_field, BooleanField):\n                    field_name = boolean_switch_field(db_field)\n            except FieldDoesNotExist:\n                pass\n            list_display.append(field_name)\n        return list_display", "response": "Returns a sequence of the fields to be displayed on the changelist."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a function to the job that maps the given list of samples to the given list of samples.", "response": "def map_job(job, func, inputs, *args):\n    \"\"\"\n    Spawns a tree of jobs to avoid overloading the number of jobs spawned by a single parent.\n    This function is appropriate to use when batching samples greater than 1,000.\n\n    :param JobFunctionWrappingJob job: passed automatically by Toil\n    :param function func: Function to spawn dynamically, passes one sample as first argument\n    :param list inputs: Array of samples to be batched\n    :param list args: any arguments to be passed to the function\n    \"\"\"\n    # num_partitions isn't exposed as an argument in order to be transparent to the user.\n    # The value for num_partitions is a tested value\n    num_partitions = 100\n    partition_size = len(inputs) / num_partitions\n    if partition_size > 1:\n        for partition in partitions(inputs, partition_size):\n            job.addChildJobFn(map_job, func, partition, *args)\n    else:\n        for sample in inputs:\n            job.addChildJobFn(func, sample, *args)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef gatk_genotype_gvcfs(job,\n                        gvcfs,\n                        ref, fai, ref_dict,\n                        annotations=None,\n                        emit_threshold=10.0, call_threshold=30.0,\n                        unsafe_mode=False):\n    \"\"\"\n    Runs GenotypeGVCFs on one or more gVCFs generated by HaplotypeCaller.\n\n    :param JobFunctionWrappingJob job: passed automatically by Toil\n    :param dict gvcfs: Dictionary of GVCF FileStoreIDs {sample identifier: FileStoreID}\n    :param str ref: FileStoreID for the reference genome fasta file\n    :param str fai: FileStoreID for the reference genome index file\n    :param str ref_dict: FileStoreID for the reference genome sequence dictionary\n    :param list[str] annotations: Optional list of GATK variant annotations. Default: None.\n    :param float emit_threshold: Minimum phred-scale confidence threshold for\n                                 a variant to be emitted. GATK default: 10.0\n    :param float call_threshold: Minimum phred-scale confidence threshold for\n                                 a variant to be called. GATK default: 30.0\n    :param bool unsafe_mode: If True, runs gatk UNSAFE mode: \"-U ALLOW_SEQ_DICT_INCOMPATIBILITY\"\n    :return: VCF FileStoreID\n    :rtype: str\n    \"\"\"\n    inputs = {'genome.fa': ref,\n              'genome.fa.fai': fai,\n              'genome.dict': ref_dict}\n    inputs.update(gvcfs)\n\n    work_dir = job.fileStore.getLocalTempDir()\n    for name, file_store_id in inputs.iteritems():\n        job.fileStore.readGlobalFile(file_store_id, os.path.join(work_dir, name))\n\n    command = ['-T', 'GenotypeGVCFs',\n               '-R', '/data/genome.fa',\n               '--out', 'genotyped.vcf',\n               '-stand_emit_conf', str(emit_threshold),\n               '-stand_call_conf', str(call_threshold)]\n\n    if annotations:\n        for annotation in annotations:\n            command.extend(['-A', annotation])\n\n    # Include all GVCFs for joint genotyping\n    for uuid in gvcfs.keys():\n        command.extend(['--variant', os.path.join('/data', uuid)])\n\n    if unsafe_mode:\n        command.extend(['-U', 'ALLOW_SEQ_DICT_INCOMPATIBILITY'])\n\n    job.fileStore.logToMaster('Running GATK GenotypeGVCFs\\n'\n                              'Emit threshold: {emit_threshold}\\n'\n                              'Call threshold: {call_threshold}\\n\\n'\n                              'Annotations:\\n{annotations}\\n\\n'\n                              'Samples:\\n{samples}\\n'.format(emit_threshold=emit_threshold,\n                                                             call_threshold=call_threshold,\n                                                             annotations='\\n'.join(annotations) if annotations else '',\n                                                             samples='\\n'.join(gvcfs.keys())))\n\n    docker_parameters = ['--rm', 'log-driver', 'none',\n                         '-e', 'JAVA_OPTS=-Djava.io.tmpdir=/data/ -Xmx{}'.format(job.memory)]\n    dockerCall(job=job, workDir=work_dir,\n               parameters=command,\n               tool='quay.io/ucsc_cgl/gatk:3.5--dba6dae49156168a909c43330350c6161dc7ecc2',\n               dockerParameters=docker_parameters)\n\n    return job.fileStore.writeGlobalFile(os.path.join(work_dir, 'genotyped.vcf'))", "response": "Runs GenotypeGVCFs on one or more GVCFs generated by HaplotypeCaller."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nuses Oncotator to add cancer relevant variant annotations to a VCF file.", "response": "def run_oncotator(job, vcf_id, oncotator_db):\n    \"\"\"\n    Uses Oncotator to add cancer relevant variant annotations to a VCF file. Oncotator can accept\n    other genome builds, but the output VCF is based on hg19.\n\n    :param JobFunctionWrappingJob job: passed automatically by Toil\n    :param str vcf_id: FileStoreID for VCF file\n    :param str oncotator_db: FileStoreID for Oncotator database\n    :return: Annotated VCF FileStoreID\n    :rtype: str\n    \"\"\"\n    job.fileStore.logToMaster('Running Oncotator')\n\n    inputs = {'input.vcf': vcf_id,\n              'oncotator_db': oncotator_db}\n\n    work_dir = job.fileStore.getLocalTempDir()\n    for name, file_store_id in inputs.iteritems():\n        inputs[name] = job.fileStore.readGlobalFile(file_store_id, os.path.join(work_dir, name))\n\n    # The Oncotator database may be tar/gzipped\n    if tarfile.is_tarfile(inputs['oncotator_db']):\n        tar = tarfile.open(inputs['oncotator_db'])\n        tar.extractall(path=work_dir)\n        # Get the extracted database directory name\n        inputs['oncotator_db'] = tar.getmembers()[0].name\n        tar.close()\n\n    command = ['-i', 'VCF',\n               '-o', 'VCF',\n               '--db-dir', inputs['oncotator_db'],\n               'input.vcf',\n               'annotated.vcf',\n               'hg19']  # Oncotator annotations are based on hg19\n\n    docker_parameters = ['--rm', 'log-driver', 'none',\n                         '-e', 'JAVA_OPTS=-Djava.io.tmpdir=/data/ -Xmx{}'.format(job.memory)]\n    dockerCall(job=job, workDir=work_dir,\n               parameters=command,\n               tool='jpfeil/oncotator:1.9--8fffc356981862d50cfacd711b753700b886b605',\n               dockerParameters=docker_parameters)\n\n    return job.fileStore.writeGlobalFile(os.path.join(work_dir, 'annotated.vcf'))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sort(self, f=lambda d: d[\"t\"]):\n        list.sort(self, key=f)\n        return self", "response": "Sort the list by timestamp by default"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning just the timestamp portion of the datapoints as a list.", "response": "def t(self):\n        \"\"\"Returns just the timestamp portion of the datapoints as a list.\n        The timestamps are in python datetime's date format.\"\"\"\n        return list(map(lambda x: datetime.datetime.fromtimestamp(x[\"t\"]), self.raw()))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwriting the data to the given file.", "response": "def writeJSON(self, filename):\n        \"\"\"Writes the data to the given file::\n\n            DatapointArray([{\"t\": unix timestamp, \"d\": data}]).writeJSON(\"myfile.json\")\n\n        The data can later be loaded using loadJSON.\n        \"\"\"\n        with open(filename, \"w\") as f:\n            json.dump(self, f)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef loadJSON(self, filename):\n        with open(filename, \"r\") as f:\n            self.merge(json.load(f))\n        return self", "response": "Adds the data from a JSON file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef loadExport(self, folder):\n        self.loadJSON(os.path.join(folder, \"data.json\"))\n        return self", "response": "Adds the data from a ConnectorDB export to the current object"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nshifting all timestamps in the datapoint array by the given number of seconds.", "response": "def tshift(self, t):\n        \"\"\"Shifts all timestamps in the datapoint array by the given number of seconds.\n        It is the same as the 'tshift' pipescript transform.\n\n        Warning: The shift is performed in-place! This means that it modifies the underlying array::\n\n            d = DatapointArray([{\"t\":56,\"d\":1}])\n            d.tshift(20)\n            print(d) # [{\"t\":76,\"d\":1}]\n        \"\"\"\n        raw = self.raw()\n        for i in range(len(raw)):\n            raw[i][\"t\"] += t\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the sum of the data portions of all datapoints within", "response": "def sum(self):\n        \"\"\"Gets the sum of the data portions of all datapoints within\"\"\"\n        raw = self.raw()\n        s = 0\n        for i in range(len(raw)):\n            s += raw[i][\"d\"]\n        return s"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nstart the event loop to collect data from the serial device.", "response": "def rfxcom(device):\n    \"\"\"Start the event loop to collect data from the serial device.\"\"\"\n\n    # If the device isn't passed in, look for it in the config.\n    if device is None:\n        device = app.config.get('DEVICE')\n\n    # If the device is *still* none, error.\n    if device is None:\n        print(\"The serial device needs to be passed in as --device or \"\n              \"set in the config as DEVICE.\")\n        return\n\n    rfxcom_collect(device)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a new user.", "response": "def create_user(username):\n    \"Create a new user.\"\n    password = prompt_pass(\"Enter password\")\n    user = User(username=username, password=password)\n    db.session.add(user)\n    db.session.commit()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_iri(iri):\n    # First decode the IRI if needed (python 2)\n    if sys.version_info[0] < 3:\n        if not isinstance(iri, unicode):\n            logger.debug(\"Converting IRI to unicode\")\n            iri = iri.decode('utf-8')\n\n    try:\n        # If we can safely parse the URI, then we don't\n        # need to do anything special here\n        rfc3987.parse(iri, rule='IRI')\n        logger.debug(\"This is already a valid IRI, doing nothing...\")\n        return iri\n    except:\n        # The URI is not valid, so we'll have to fix it.\n        logger.debug(\"The IRI is not valid, proceeding to quote...\")\n        # First see whether we can actually parse it *as if* it is a URI\n\n        parts = urlparse.urlsplit(iri)\n        if not parts.scheme or not parts.netloc:\n            # If there is no scheme (e.g. http) nor a net location (e.g.\n            # example.com) then we cannot do anything\n            logger.error(\"The argument you provided does not comply with \"\n                         \"RFC 3987 and is not parseable as a IRI\"\n                         \"(there is no scheme or no net location part)\")\n            logger.error(iri)\n            raise Exception(\"The argument you provided does not comply with\"\n                            \"RFC 3987 and is not parseable as a IRI\"\n                            \"(there is no scheme or no net location part)\")\n\n        logger.debug(\"The IRI contains all necessary parts (scheme + net location)\")\n        quoted_parts = {}\n        # We'll now convert the path, query and fragment parts of the URI\n\n        # Get the 'anti-pattern' for the valid characters (see rfc3987 package)\n        # This is roughly the ipchar pattern plus the '/' as we don't need to match\n        # the entire path, but merely the individual characters\n        no_invalid_characters = rfc3987.get_compiled_pattern(\"(?!%(iunreserved)s|%(pct_encoded)s|%(sub_delims)s|:|@|/)(.)\")\n\n        # Replace the invalid characters with an underscore (no need to roundtrip)\n        quoted_parts['path'] = no_invalid_characters.sub(u'_', parts.path)\n        if parts.fragment:\n            quoted_parts['fragment'] = no_invalid_characters.sub(u'_', parts.fragment)\n        if parts.query:\n            quoted_parts['query'] = urllib.quote(parts.query.encode('utf-8'),safe=\"&=\")\n        # Leave these untouched\n        quoted_parts['scheme'] = parts.scheme\n        quoted_parts['authority'] = parts.netloc\n\n        # Extra check to make sure we now have a valid IRI\n        quoted_iri = rfc3987.compose(**quoted_parts)\n        try:\n            rfc3987.parse(quoted_iri)\n        except:\n            # Unable to generate a valid quoted iri, using the straightforward\n            # urllib percent quoting (but this is ugly!)\n            logger.warning('Could not safely quote as IRI, falling back to '\n                           'percent encoding')\n            quoted_iri = urllib.quote(iri.encode('utf-8'))\n\n        return quoted_iri", "response": "Converts an IRI into a string in a way that is resilient to unicode and incorrect\n    arguments"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def parse_vn_results(soup):\n    soup = soup.find_all('td', class_='tc1')\n    vns = []\n    for item in soup[1:]:\n        vns.append({'name': item.string, 'id': item.a.get('href')[1:]})\n    return vns", "response": "Parse Visual Novel search results."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse the releases search results page.", "response": "async def parse_release_results(soup):\n    \"\"\"\n    Parse Releases search pages.\n\n    :param soup: The BS4 class object\n    :return: A list of dictionaries containing a release dictionary. This is the same as the one returned in get_novel.\n             It contains a Date released, Platform, Ages group and Name.\n    \"\"\"\n    soup = list(soup.find_all('table', class_='stripe')[0].children)[1:]\n    releases = []\n    for item in soup:\n        child = list(item.children)\n        temp_rel = {'date': None, 'ages': None, 'platform': None, 'name': None}\n        temp_rel['date'] = child[0].string\n        temp_rel['ages'] = child[1].string\n        temp_rel['platform'] = child[2].abbr.get('title')\n        temp_rel['name'] = child[3].a.string\n        releases.append(temp_rel)\n        del temp_rel\n    return releases"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def parse_prod_staff_results(soup):\n    soup = soup.find_all('li')\n    producers = []\n    for item in soup:\n        producers.append({'nationality': item.abbr.get('title'), 'name': item.a.string})\n    return producers", "response": "Parse a page of producer or staff results and return a list of dictionaries containing a name and nationality."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def parse_character_results(soup):\n    soup = list(soup.find_all('table', class_='stripe')[0].children)[1:]\n    characters = []\n    for item in soup:\n        temp_c = {'gender': None, 'name': None, 'games': {}}\n        temp_c['gender'] = item.abbr.get('title')\n        temp_c['name'] = list(item.children)[1].a.string\n        temp_c['games'] = []\n        for game in list(list(list(item.children)[1].children)[1].children):\n            if isinstance(game, NavigableString):\n                continue\n            temp_c['games'].append({'name': game.string, 'id': game.get('href').split('/')[1]})\n        characters.append(temp_c)\n        del temp_c\n    return characters", "response": "Parse a page of character results."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing a page of tag or trait results. Same format.", "response": "async def parse_tag_results(soup):\n    \"\"\"\n    Parse a page of tag or trait results. Same format.\n\n    :param soup: BS4 Class Object\n    :return: A list of tags, Nothing else really useful there\n    \"\"\"\n    soup = soup.find_all('td', class_='tc3')\n    tags = []\n    for item in soup:\n        tags.append(item.a.string)\n    return tags"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses a page of user results and return a list of dictionaries containing a name and join date", "response": "async def parse_user_results(soup):\n    \"\"\"\n    Parse a page of user results\n\n    :param soup: Bs4 Class object\n    :return: A list of dictionaries containing a name and join date\n    \"\"\"\n    soup = list(soup.find_all('table', class_='stripe')[0].children)[1:]\n    users = []\n    for item in soup:\n        t_u = {'name': None, 'joined': None}\n        t_u['name'] = list(item.children)[0].a.string\n        t_u['joined'] = list(item.children)[1].string\n        users.append(t_u)\n        del t_u\n    return users"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef tarball_files(tar_name, file_paths, output_dir='.', prefix=''):\n    with tarfile.open(os.path.join(output_dir, tar_name), 'w:gz') as f_out:\n        for file_path in file_paths:\n            if not file_path.startswith('/'):\n                raise ValueError('Path provided is relative not absolute.')\n            arcname = prefix + os.path.basename(file_path)\n            f_out.add(file_path, arcname=arcname)", "response": "Creates a tarball from a list of files."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __forall_files(file_paths, output_dir, op):\n    for file_path in file_paths:\n        if not file_path.startswith('/'):\n            raise ValueError('Path provided (%s) is relative not absolute.' % file_path)\n        dest = os.path.join(output_dir, os.path.basename(file_path))\n        op(file_path, dest)", "response": "Applies a function to a set of files and an output directory."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef copy_file_job(job, name, file_id, output_dir):\n    work_dir = job.fileStore.getLocalTempDir()\n    fpath = job.fileStore.readGlobalFile(file_id, os.path.join(work_dir, name))\n    copy_files([fpath], output_dir)", "response": "Job version of copy_files for one file\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncombines the contents of separate tarballs into one.", "response": "def consolidate_tarballs_job(job, fname_to_id):\n    \"\"\"\n    Combine the contents of separate tarballs into one.\n    Subdirs within the tarball will be named the keys in **fname_to_id\n\n    :param JobFunctionWrappingJob job: passed automatically by Toil\n    :param dict[str,str] fname_to_id: Dictionary of the form: file-name-prefix=FileStoreID\n    :return: The file store ID of the generated tarball\n    :rtype: str\n    \"\"\"\n    work_dir = job.fileStore.getLocalTempDir()\n    # Retrieve output file paths to consolidate\n    tar_paths = []\n    for fname, file_store_id in fname_to_id.iteritems():\n        p = job.fileStore.readGlobalFile(file_store_id, os.path.join(work_dir, fname + '.tar.gz'))\n        tar_paths.append((p, fname))\n    # I/O\n    # output_name is arbitrary as this job function returns a FileStoreId\n    output_name = 'foo.tar.gz'\n    out_tar = os.path.join(work_dir, output_name)\n    # Consolidate separate tarballs into one\n    with tarfile.open(os.path.join(work_dir, out_tar), 'w:gz') as f_out:\n        for tar, fname in tar_paths:\n            with tarfile.open(tar, 'r') as f_in:\n                for tarinfo in f_in:\n                    with closing(f_in.extractfile(tarinfo)) as f_in_file:\n                        tarinfo.name = os.path.join(output_name, fname, os.path.basename(tarinfo.name))\n                        f_out.addfile(tarinfo, fileobj=f_in_file)\n    return job.fileStore.writeGlobalFile(out_tar)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmakes a Spark Submit style job submission line. :param masterIP: The Spark leader IP address. :param default_parameters: Application specific Spark configuration parameters. :param memory: The memory to allocate to each Spark driver and executor. :param arguments: Arguments to pass to the submitted job. :param override_parameters: Parameters passed by the user, that override our defaults. :type masterIP: MasterAddress :type default_parameters: list of string :type arguments: list of string :type memory: int or None :type override_parameters: list of string or None", "response": "def _make_parameters(master_ip, default_parameters, memory, arguments, override_parameters):\n    \"\"\"\n    Makes a Spark Submit style job submission line.\n\n    :param masterIP: The Spark leader IP address.\n    :param default_parameters: Application specific Spark configuration parameters.\n    :param memory: The memory to allocate to each Spark driver and executor.\n    :param arguments: Arguments to pass to the submitted job.\n    :param override_parameters: Parameters passed by the user, that override our defaults.\n    \n    :type masterIP: MasterAddress\n    :type default_parameters: list of string\n    :type arguments: list of string\n    :type memory: int or None\n    :type override_parameters: list of string or None\n    \"\"\"\n\n    # python doesn't support logical xor?\n    # anywho, exactly one of memory or override_parameters must be defined\n    require((override_parameters is not None or memory is not None) and\n            (override_parameters is None or memory is None),\n            \"Either the memory setting must be defined or you must provide Spark configuration parameters.\")\n    \n    # if the user hasn't provided overrides, set our defaults\n    parameters = []\n    if memory is not None:\n        parameters = [\"--master\", \"spark://%s:%s\" % (master_ip, SPARK_MASTER_PORT),\n                      \"--conf\", \"spark.driver.memory=%sg\" % memory,\n                      \"--conf\", \"spark.executor.memory=%sg\" % memory,\n                      \"--conf\", (\"spark.hadoop.fs.default.name=hdfs://%s:%s\" % (master_ip, HDFS_MASTER_PORT))]\n    else:\n        parameters.extend(override_parameters)\n\n    # add the tool specific spark parameters\n    parameters.extend(default_parameters)\n\n    # spark submit expects a '--' to split the spark conf arguments from tool arguments\n    parameters.append('--')\n\n    # now add the tool arguments and return\n    parameters.extend(arguments)\n\n    return parameters"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef call_conductor(job, master_ip, src, dst, memory=None, override_parameters=None):\n\n    arguments = [\"-C\", src, dst]\n\n    docker_parameters = ['--log-driver', 'none', master_ip.docker_parameters([\"--net=host\"])]\n    dockerCall(job=job,\n                tool=\"quay.io/ucsc_cgl/conductor\",\n                parameters=_make_parameters(master_ip,\n                                            [], # no conductor specific spark configuration\n                                            memory,\n                                            arguments,\n                                            override_parameters),\n               dockerParameters=docker_parameters)", "response": "This function is called by the Spark driver to copy files between S3 and HDFS and vice versa."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ninvoke the ADAM container. Find ADAM at https://github.com/bigdatagenomics/adam. :param toil.Job.job job: The Toil Job calling this function :param masterIP: The Spark leader IP address. :param arguments: Arguments to pass to ADAM. :param memory: Gigabytes of memory to provision for Spark driver/worker. :param override_parameters: Parameters passed by the user, that override our defaults. :param native_adam_path: Path to ADAM executable. If not provided, Docker is used. :param run_local: If true, runs Spark with the --master local[*] setting, which uses all cores on the local machine. The master_ip will be disregarded. :type masterIP: MasterAddress :type arguments: list of string :type memory: int or None :type override_parameters: list of string or None :type native_adam_path: string or None :type run_local: boolean", "response": "def call_adam(job, master_ip, arguments,\n              memory=None,\n              override_parameters=None,\n              run_local=False,\n              native_adam_path=None):\n    \"\"\"\n    Invokes the ADAM container. Find ADAM at https://github.com/bigdatagenomics/adam.\n\n    :param toil.Job.job job: The Toil Job calling this function\n    :param masterIP: The Spark leader IP address.\n    :param arguments: Arguments to pass to ADAM.\n    :param memory: Gigabytes of memory to provision for Spark driver/worker.\n    :param override_parameters: Parameters passed by the user, that override our defaults.\n    :param native_adam_path: Path to ADAM executable. If not provided, Docker is used.\n    :param run_local: If true, runs Spark with the --master local[*] setting, which uses\n      all cores on the local machine. The master_ip will be disregarded.\n\n    :type masterIP: MasterAddress\n    :type arguments: list of string\n    :type memory: int or None\n    :type override_parameters: list of string or None\n    :type native_adam_path: string or None\n    :type run_local: boolean\n    \"\"\"\n    if run_local:\n        master = [\"--master\", \"local[*]\"]\n    else:\n        master = [\"--master\",\n                  (\"spark://%s:%s\" % (master_ip, SPARK_MASTER_PORT)),\n                  \"--conf\", (\"spark.hadoop.fs.default.name=hdfs://%s:%s\" % (master_ip, HDFS_MASTER_PORT)),]\n\n    default_params = (master + [\n            # set max result size to unlimited, see #177\n            \"--conf\", \"spark.driver.maxResultSize=0\",\n            # these memory tuning parameters were derived in the course of running the\n            # experiments for the ADAM sigmod paper:\n            #\n            # Nothaft, Frank Austin, et al. \"Rethinking data-intensive science using scalable\n            # analytics systems.\" Proceedings of the 2015 ACM SIGMOD International Conference\n            # on Management of Data. ACM, 2015.\n            #\n            # the memory tunings reduce the amount of memory dedicated to caching, which we don't\n            # take advantage of, and the network timeout flag reduces the number of job failures\n            # caused by heavy gc load\n            \"--conf\", \"spark.storage.memoryFraction=0.3\",\n            \"--conf\", \"spark.storage.unrollFraction=0.1\",\n            \"--conf\", \"spark.network.timeout=300s\"])\n\n    # are we running adam via docker, or do we have a native path?\n    if native_adam_path is None:\n        docker_parameters = ['--log-driver', 'none', master_ip.docker_parameters([\"--net=host\"])]\n        dockerCall(job=job,\n                    tool=\"quay.io/ucsc_cgl/adam:962-ehf--6e7085f8cac4b9a927dc9fb06b48007957256b80\",\n                    dockerParameters=docker_parameters,\n                    parameters=_make_parameters(master_ip,\n                                                default_params,\n                                                memory,\n                                                arguments,\n                                                override_parameters))\n    else:\n        check_call([os.path.join(native_adam_path, \"bin/adam-submit\")] +\n                   default_params +\n                   arguments)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef docker_parameters(self, docker_parameters=None):\n        if self != self.actual:\n            add_host_option = '--add-host=spark-master:' + self.actual\n            if docker_parameters is None:\n                docker_parameters = [add_host_option]\n            else:\n                docker_parameters.append(add_host_option)\n        return docker_parameters", "response": "Augment a list of docker run arguments with those needed to map the Spark master address to the actual Spark master address."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreloads the metadata of the object from the server.", "response": "def refresh(self):\r\n        \"\"\"Refresh reloads data from the server. It raises an error if it fails to get the object's metadata\"\"\"\r\n        self.metadata = self.db.read(self.path).json()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nattempts to set the given properties of the object.", "response": "def set(self, property_dict):\r\n        \"\"\"Attempts to set the given properties of the object.\r\n        An example of this is setting the nickname of the object::\r\n\r\n            cdb.set({\"nickname\": \"My new nickname\"})\r\n\r\n        note that there is a convenience property `cdb.nickname` that allows you to get/set the nickname directly.\r\n        \"\"\"\r\n        self.metadata = self.db.update(self.path, property_dict).json()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalls MuTect to perform variant analysis :param JobFunctionWrappingJob job: passed automatically by Toil :param str normal_bam: Normal BAM FileStoreID :param str normal_bai: Normal BAM index FileStoreID :param str tumor_bam: Tumor BAM FileStoreID :param str tumor_bai: Tumor BAM Index FileStoreID :param str ref: Reference genome FileStoreID :param str ref_dict: Reference dictionary FileStoreID :param str fai: Reference index FileStoreID :param str cosmic: Cosmic VCF FileStoreID :param str dbsnp: DBSNP VCF FileStoreID :return: MuTect output (tarball) FileStoreID :rtype: str", "response": "def run_mutect(job, normal_bam, normal_bai, tumor_bam, tumor_bai, ref, ref_dict, fai, cosmic, dbsnp):\n    \"\"\"\n    Calls MuTect to perform variant analysis\n\n    :param JobFunctionWrappingJob job: passed automatically by Toil\n    :param str normal_bam: Normal BAM FileStoreID\n    :param str normal_bai: Normal BAM index FileStoreID\n    :param str tumor_bam: Tumor BAM FileStoreID\n    :param str tumor_bai: Tumor BAM Index FileStoreID\n    :param str ref: Reference genome FileStoreID\n    :param str ref_dict: Reference dictionary FileStoreID\n    :param str fai: Reference index FileStoreID\n    :param str cosmic: Cosmic VCF FileStoreID\n    :param str dbsnp: DBSNP VCF FileStoreID\n    :return: MuTect output (tarball) FileStoreID\n    :rtype: str\n    \"\"\"\n    work_dir = job.fileStore.getLocalTempDir()\n    file_ids = [normal_bam, normal_bai, tumor_bam, tumor_bai, ref, fai, ref_dict, cosmic, dbsnp]\n    file_names = ['normal.bam', 'normal.bai', 'tumor.bam', 'tumor.bai', 'ref.fasta',\n                  'ref.fasta.fai', 'ref.dict', 'cosmic.vcf', 'dbsnp.vcf']\n    for file_store_id, name in zip(file_ids, file_names):\n        job.fileStore.readGlobalFile(file_store_id, os.path.join(work_dir, name))\n    # Call: MuTect\n    parameters = ['--analysis_type', 'MuTect',\n                  '--reference_sequence', 'ref.fasta',\n                  '--cosmic', '/data/cosmic.vcf',\n                  '--dbsnp', '/data/dbsnp.vcf',\n                  '--input_file:normal', '/data/normal.bam',\n                  '--input_file:tumor', '/data/tumor.bam',\n                  '--tumor_lod', str(10),  # Taken from MC3 pipeline\n                  '--initial_tumor_lod', str(4.0),  # Taken from MC3 pipeline\n                  '--out', 'mutect.out',\n                  '--coverage_file', 'mutect.cov',\n                  '--vcf', 'mutect.vcf']\n    dockerCall(job=job, workDir=work_dir, parameters=parameters,\n               tool='quay.io/ucsc_cgl/mutect:1.1.7--e8bf09459cf0aecb9f55ee689c2b2d194754cbd3')\n    # Write output to file store\n    output_file_names = ['mutect.vcf', 'mutect.cov', 'mutect.out']\n    output_file_paths = [os.path.join(work_dir, x) for x in output_file_names]\n    tarball_files('mutect.tar.gz', file_paths=output_file_paths, output_dir=work_dir)\n    return job.fileStore.writeGlobalFile(os.path.join(work_dir, 'mutect.tar.gz'))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run_pindel(job, normal_bam, normal_bai, tumor_bam, tumor_bai, ref, fai):\n    work_dir = job.fileStore.getLocalTempDir()\n    file_ids = [normal_bam, normal_bai, tumor_bam, tumor_bai, ref, fai]\n    file_names = ['normal.bam', 'normal.bai', 'tumor.bam', 'tumor.bai', 'ref.fasta', 'ref.fasta.fai']\n    for file_store_id, name in zip(file_ids, file_names):\n        job.fileStore.readGlobalFile(file_store_id, os.path.join(work_dir, name))\n    # Create Pindel config\n    with open(os.path.join(work_dir, 'pindel-config.txt'), 'w') as f:\n        for bam in ['normal', 'tumor']:\n            f.write('/data/{} {} {}\\n'.format(bam + '.bam', get_mean_insert_size(work_dir, bam + '.bam'), bam))\n    # Call: Pindel\n    parameters = ['-f', '/data/ref.fasta',\n                  '-i', '/data/pindel-config.txt',\n                  '--number_of_threads', str(job.cores),\n                  '--minimum_support_for_event', '3',\n                  '--report_long_insertions', 'true',\n                  '--report_breakpoints', 'true',\n                  '-o', 'pindel']\n    dockerCall(job=job, tool='quay.io/ucsc_cgl/pindel:0.2.5b6--4e8d1b31d4028f464b3409c6558fb9dfcad73f88',\n               workDir=work_dir, parameters=parameters)\n    # Collect output files and write to file store\n    output_files = glob(os.path.join(work_dir, 'pindel*'))\n    tarball_files('pindel.tar.gz', file_paths=output_files, output_dir=work_dir)\n    return job.fileStore.writeGlobalFile(os.path.join(work_dir, 'pindel.tar.gz'))", "response": "This function calls Pindel to compute indels and deletions of the given file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating the device. Attempts to create private devices by default, but if public is set to true, creates public devices. You can also set other default properties by passing in the relevant information. For example, setting a device with the given nickname and description:: dev.create(nickname=\"mydevice\", description=\"This is an example\") Furthermore, ConnectorDB supports creation of a device's streams immediately, which can considerably speed up device setup:: dev.create(streams={ \"stream1\": {\"schema\": '{\\\"type\\\":\\\"number\\\"}'} }) Note that the schema must be encoded as a string when creating in this format.", "response": "def create(self, public=False, **kwargs):\n        \"\"\"Creates the device. Attempts to create private devices by default,\n        but if public is set to true, creates public devices.\n\n        You can also set other default properties by passing in the relevant information.\n        For example, setting a device with the given nickname and description::\n\n            dev.create(nickname=\"mydevice\", description=\"This is an example\")\n\n        Furthermore, ConnectorDB supports creation of a device's streams immediately,\n        which can considerably speed up device setup::\n\n            dev.create(streams={\n                \"stream1\": {\"schema\": '{\\\"type\\\":\\\"number\\\"}'}\n            })\n\n        Note that the schema must be encoded as a string when creating in this format.\n        \"\"\"\n        kwargs[\"public\"] = public\n        self.metadata = self.db.create(self.path, kwargs).json()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef streams(self):\n        result = self.db.read(self.path, {\"q\": \"ls\"})\n\n        if result is None or result.json() is None:\n            return []\n        streams = []\n        for s in result.json():\n            strm = self[s[\"name\"]]\n            strm.metadata = s\n            streams.append(strm)\n        return streams", "response": "Returns the list of streams that belong to the device"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef export(self, directory):\n        if os.path.exists(directory):\n            raise FileExistsError(\n                \"The device export directory already exists\")\n\n        os.mkdir(directory)\n\n        # Write the device's info\n        with open(os.path.join(directory, \"device.json\"), \"w\") as f:\n            json.dump(self.data, f)\n\n        # Now export the streams one by one\n        for s in self.streams():\n            s.export(os.path.join(directory, s.name))", "response": "Exports the device to the given directory."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nimport a stream from the given directory. You can import the stream by using stream. export.", "response": "def import_stream(self, directory):\n        \"\"\"Imports a stream from the given directory. You export the Stream\n        by using stream.export()\"\"\"\n\n        # read the stream's info\n        with open(os.path.join(directory, \"stream.json\"), \"r\") as f:\n            sdata = json.load(f)\n\n        s = self[sdata[\"name\"]]\n        if s.exists():\n            raise ValueError(\"The stream \" + s.name + \" already exists\")\n\n        # Create the stream empty first, so we can insert all the data without\n        # worrying about schema violations or downlinks\n        s.create()\n\n        # Now, in order to insert data into this stream, we must be logged in as\n        # the owning device\n        ddb = DatabaseConnection(self.apikey, url=self.db.baseurl)\n        d = Device(ddb, self.path)\n\n        # Set up the owning device\n        sown = d[s.name]\n\n        # read the stream's info\n        sown.insert_array(DatapointArray().loadExport(directory))\n\n        # Now we MIGHT be able to recover the downlink data,\n        # only if we are not logged in as the device that the stream is being inserted into\n        # So we check. When downlink is true, data is inserted into the\n        # downlink stream\n        if (sdata[\"downlink\"] and self.db.path != self.path):\n            s.downlink = True\n            with open(os.path.join(directory, \"downlink.json\"), \"r\") as f:\n                s.insert_array(json.load(f))\n\n        # And finally, update the device\n        del sdata[\"name\"]\n        s.set(sdata)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def search_vndb(self, stype, term):\n        fstype = \"\"\n        if stype not in ['v', 'r', 'p', 's', 'c', 'g', 'i', 'u']:\n            raise VNDBBadStype(stype)\n        else:\n            if stype in ['v', 'p', 's', 'c', 'u']:\n                fstype = '/{}/all'.format(stype)\n            elif stype in ['g', 'i']:\n                fstype = '/{}/list'.format(stype)\n            elif stype == 'r':\n                fstype = '/r'\n        async with self.session.get(self.base_url + \"{}\".format(fstype), params={\"q\": term}, headers=self.headers) as response:\n            if response.status == 404:\n                raise aiohttp.HttpBadRequest(\"VN Not Found\")\n            elif 'q=' not in response.url:\n                raise VNDBOneResult(term, response.url.rsplit('/', 1)[1])\n            text = await response.text()\n            if 'No Results' in text:\n                raise VNDBNoResults(term)\n            soup = BeautifulSoup(text, 'lxml')\n            resp = await self.parse_search(stype, soup)\n            if resp == []:\n                raise VNDBNoResults(term)\n            return resp", "response": "Search vndb. org for a term and return matching results."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def get_novel(self, term, hide_nsfw=False):\n        if not term.isdigit() and not term.startswith('v'):\n            try:\n                vnid = await self.search_vndb('v', term)\n                vnid = vnid[0]['id']\n            except VNDBOneResult as e:\n                vnid = e.vnid\n        else:\n            vnid = str(term)\n            if not vnid.startswith('v'):\n                vnid = 'v' + vnid\n        async with self.session.get(self.base_url + \"/{}\".format(vnid), headers=self.headers) as response:\n            if response.status == 404:\n                raise aiohttp.HttpBadRequest(\"VNDB reported that there is no data for ID {}\".format(vnid))\n            text = await response.text()\n            soup = BeautifulSoup(text, 'lxml')\n            data = {'titles': {'english': [], 'alt': [], 'aliases': []}, 'img': None, 'length': None, 'developers': [], 'publishers': [], 'tags': {}, 'releases': {}, 'id': vnid}\n            data['titles']['english'] = soup.find_all('div', class_='mainbox')[0].h1.string\n            try:\n                data['titles']['alt'] = soup.find_all('h2', class_='alttitle')[0].string\n            except IndexError:\n                data['titles']['alt'] = None\n            try:\n                imgdiv = soup.find_all('div', class_='vnimg')[0]\n                if not (hide_nsfw and 'class' in imgdiv.p.attrs):\n                    data['img'] = 'https:' + imgdiv.img.get('src')\n            except AttributeError:\n                pass\n            for item in soup.find_all('tr'):\n                if 'class' in item.attrs or len(list(item.children)) == 1:\n                    continue\n                if item.td.string == 'Aliases':\n                    tlist = []\n                    for alias in list(item.children)[1:]:\n                        tlist.append(alias.string)\n                    data['titles']['aliases'] = tlist\n                elif item.td.string == 'Length':\n                    data['length'] = list(item.children)[1].string\n                elif item.td.string == 'Developer':\n                    tl = []\n                    for item in list(list(item.children)[1].children):\n                        if isinstance(item, NavigableString):\n                            continue\n                        if 'href' in item.attrs:\n                            tl.append(item.string)\n                    data['developers'] = tl\n                    del tl\n                elif item.td.string == 'Publishers':\n                    tl = []\n                    for item in list(list(item.children)[1].children):\n                        if isinstance(item, NavigableString):\n                            continue\n                        if 'href' in item.attrs:\n                            tl.append(item.string)\n                    data['publishers'] = tl\n            conttags = []\n            techtags = []\n            erotags = []\n            test = soup.find('div', attrs={'id': 'vntags'})\n            if test:\n                for item in list(test.children):\n                    if isinstance(item, NavigableString):\n                        continue\n                    if 'class' not in item.attrs:\n                        continue\n                    if 'cont' in \" \".join(item.get('class')):\n                        conttags.append(item.a.string)\n                    if 'tech' in \" \".join(item.get('class')):\n                        techtags.append(item.a.string)\n                    if 'ero' in \" \".join(item.get('class')):\n                        erotags.append(item.a.string)\n            data['tags']['content'] = conttags if len(conttags) else None\n            data['tags']['technology'] = techtags if len(techtags) else None\n            data['tags']['erotic'] = erotags if len(erotags) else None\n            del conttags\n            del techtags\n            del erotags\n            releases = []\n            cur_lang = None\n            for item in list(soup.find('div', class_='mainbox releases').table.children):\n                if isinstance(item, NavigableString):\n                    continue\n                if 'class' in item.attrs:\n                    if cur_lang is None:\n                        cur_lang = item.td.abbr.get('title')\n                    else:\n                        data['releases'][cur_lang] = releases\n                        releases = []\n                        cur_lang = item.td.abbr.get('title')\n                else:\n                    temp_rel = {'date': 0, 'ages': 0, 'platform': 0, 'name': 0, 'id': 0}\n                    children = list(item.children)\n                    temp_rel['date'] = children[0].string\n                    temp_rel['ages'] = children[1].string\n                    temp_rel['platform'] = children[2].abbr.get('title')\n                    temp_rel['name'] = children[3].a.string\n                    temp_rel['id'] = children[3].a.get('href')[1:]\n                    del children\n                    releases.append(temp_rel)\n                    del temp_rel\n            if len(releases) > 0 and cur_lang is not None:\n                data['releases'][cur_lang] = releases\n            del releases\n            del cur_lang\n            desc = \"\"\n            for item in list(soup.find_all('td', class_='vndesc')[0].children)[1].contents:\n                if not isinstance(item, NavigableString):\n                    continue\n                if item.startswith('['):\n                    continue\n                if item.endswith(']'):\n                    continue\n                desc += item.string + \"\\n\"\n            data['description'] = desc\n            return data", "response": "Get the novel information for a specific term."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def parse_search(self, stype, soup):\n        if stype == 'v':\n            return await parse_vn_results(soup)\n        elif stype == 'r':\n            return await parse_release_results(soup)\n        elif stype == 'p':\n            return await parse_prod_staff_results(soup)\n        elif stype == 's':\n            return await parse_prod_staff_results(soup)\n        elif stype == 'c':\n            return await parse_character_results(soup)\n        elif stype == 'g':\n            return await parse_tag_results(soup)\n        elif stype == 'i':\n            return await parse_tag_results(soup)\n        elif stype == 'u':\n            return await parse_user_results(soup)", "response": "This method is our dispatcher for parsing the search results."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a stream to the current instance of the archive.", "response": "def addStream(self, stream, interpolator=\"closest\", t1=None, t2=None, dt=None, limit=None, i1=None, i2=None, transform=None,colname=None):\n        \"\"\"Adds the given stream to the query construction. Additionally, you can choose the interpolator to use for this stream, as well as a special name\n        for the column in the returned dataset. If no column name is given, the full stream path will be used.\n\n        addStream also supports Merge queries. You can insert a merge query instead of a stream, but be sure to name the column::\n\n            d = Dataset(cdb, t1=time.time()-1000,t2=time.time(),dt=10.)\n            d.addStream(\"temperature\",\"average\")\n            d.addStream(\"steps\",\"sum\")\n\n            m = Merge(cdb)\n            m.addStream(\"mystream\")\n            m.addStream(\"mystream2\")\n            d.addStream(m,colname=\"mycolumn\")\n\n            result = d.run()\n        \"\"\"\n\n        streamquery = query_maker(t1, t2, limit, i1, i2, transform)\n        param_stream(self.cdb, streamquery, stream)\n\n        streamquery[\"interpolator\"] = interpolator\n\n        if colname is None:\n            # What do we call this column?\n            if isinstance(stream, six.string_types):\n                colname = stream\n            elif isinstance(stream, Stream):\n                colname = stream.path\n            else:\n                raise Exception(\n                    \"Could not find a name for the column! use the 'colname' parameter.\")\n\n        if colname in self.query[\"dataset\"] or colname is \"x\":\n            raise Exception(\n                \"The column name either exists, or is labeled 'x'. Use the colname parameter to change the column name.\")\n\n        self.query[\"dataset\"][colname] = streamquery"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninvalidating the device s current api key and generates a new one.", "response": "def reset_apikey(self):\n        \"\"\"invalidates the device's current api key, and generates a new one. Resets current auth to use the new apikey,\n        since the change would have future queries fail if they use the old api key.\"\"\"\n        apikey = Device.reset_apikey(self)\n        self.db.setauth(apikey)\n        return apikey"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a dictionary of information about the database", "response": "def info(self):\n        \"\"\"returns a dictionary of information about the database, including the database version, the transforms\n        and the interpolators supported::\n\n            >>>cdb = connectordb.ConnectorDB(apikey)\n            >>>cdb.info()\n            {\n                \"version\": \"0.3.0\",\n                \"transforms\": {\n                    \"sum\": {\"description\": \"Returns the sum of all the datapoints that go through the transform\"}\n                    ...\n                },\n                \"interpolators\": {\n                    \"closest\": {\"description\": \"Uses the datapoint closest to the interpolation timestamp\"}\n                    ...\n                }\n            }\n\n        \"\"\"\n        return {\n            \"version\": self.db.get(\"meta/version\").text,\n            \"transforms\": self.db.get(\"meta/transforms\").json(),\n            \"interpolators\": self.db.get(\"meta/interpolators\").json()\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef users(self):\n        result = self.db.read(\"\", {\"q\": \"ls\"})\n\n        if result is None or result.json() is None:\n            return []\n        users = []\n        for u in result.json():\n            usr = self(u[\"name\"])\n            usr.metadata = u\n            users.append(usr)\n        return users", "response": "Returns the list of users in the database"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef import_users(self, directory):\n        exportInfoFile = os.path.join(directory, \"connectordb.json\")\n        with open(exportInfoFile) as f:\n            exportInfo = json.load(f)\n        if exportInfo[\"Version\"] != 1:\n            raise ValueError(\"Not able to read this import version\")\n\n        # Now we list all the user directories\n        for name in os.listdir(directory):\n            udir = os.path.join(directory, name)\n            if os.path.isdir(udir):\n                # Let's read in the user\n                with open(os.path.join(udir, \"user.json\")) as f:\n                    usrdata = json.load(f)\n\n                u = self(usrdata[\"name\"])\n                if u.exists():\n                    raise ValueError(\"The user \" + name + \" already exists\")\n\n                del usrdata[\"name\"]\n                u.create(password=name, **usrdata)\n\n                # Now read all of the user's devices\n                for dname in os.listdir(udir):\n                    ddir = os.path.join(udir, dname)\n                    if os.path.isdir(ddir):\n                        u.import_device(ddir)", "response": "Imports version 1 of ConnectorDB export."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef run_bwa_index(job, ref_id):\n    job.fileStore.logToMaster('Created BWA index files')\n    work_dir = job.fileStore.getLocalTempDir()\n    job.fileStore.readGlobalFile(ref_id, os.path.join(work_dir, 'ref.fa'))\n    command = ['index', '/data/ref.fa']\n    dockerCall(job=job, workDir=work_dir, parameters=command,\n               tool='quay.io/ucsc_cgl/bwa:0.7.12--256539928ea162949d8a65ca5c79a72ef557ce7c')\n    ids = {}\n    for output in ['ref.fa.amb', 'ref.fa.ann', 'ref.fa.bwt', 'ref.fa.pac', 'ref.fa.sa']:\n        ids[output.split('.')[-1]] = (job.fileStore.writeGlobalFile(os.path.join(work_dir, output)))\n    return ids['amb'], ids['ann'], ids['bwt'], ids['pac'], ids['sa']", "response": "Use BWA to create reference index files"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef connectordb(self):\n        if self.__cdb is None:\n            logging.debug(\"Logger: Connecting to \" + self.serverurl)\n            self.__cdb = ConnectorDB(self.apikey, url=self.serverurl)\n        return self.__cdb", "response": "Returns the ConnectorDB object that the logger uses. Raises an error if the Logger isn t able to connect."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a stream to the logger.", "response": "def addStream(self, streamname, schema=None, **kwargs):\n        \"\"\"Adds the given stream to the logger. Requires an active connection to the ConnectorDB database.\n\n        If a schema is not specified, loads the stream from the database. If a schema is specified, and the stream\n        does not exist, creates the stream. You can also add stream properties such as description or nickname to be added\n        during creation.\"\"\"\n\n        stream = self.connectordb[streamname]\n\n        if not stream.exists():\n            if schema is not None:\n                stream.create(schema, **kwargs)\n            else:\n                raise Exception(\n                    \"The stream '%s' was not found\" % (streamname, ))\n\n        self.addStream_force(streamname, stream.schema)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ninserting the datapoint into the logger for the given stream name.", "response": "def insert(self, streamname, value):\n        \"\"\"Insert the datapoint into the logger for the given stream name. The logger caches the datapoint\n        and eventually synchronizes it with ConnectorDB\"\"\"\n        if streamname not in self.streams:\n            raise Exception(\"The stream '%s' was not found\" % (streamname, ))\n\n        # Validate the schema\n        validate(value, self.streams[streamname])\n\n        # Insert the datapoint - it fits the schema\n        value = json.dumps(value)\n        logging.debug(\"Logger: %s <= %s\" % (streamname, value))\n        c = self.database.cursor()\n        c.execute(\"INSERT INTO cache VALUES (?,?,?);\",\n                  (streamname, time.time(), value))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninserts data into the cache.", "response": "def insert_many(self, data_dict):\n        \"\"\" Inserts data into the cache, if the data is a dict of the form {streamname: [{\"t\": timestamp,\"d\":data,...]}\"\"\"\n        c = self.database.cursor()\n        c.execute(\"BEGIN TRANSACTION;\")\n        try:\n            for streamname in data_dict:\n                if streamname not in self.streams:\n                    raise Exception(\n                        \"The stream '%s' was not found\" % (streamname, ))\n                for dp in data_dict[streamname]:\n                    validate(dp[\"d\"], self.streams[streamname])\n                    c.execute(\"INSERT INTO cache VALUES (?,?,?);\",\n                              (streamname, dp[\"t\"], dp[\"d\"]))\n        except:\n            c.execute(\"ROLLBACK;\")\n            raise\n        c.exectute(\"COMMIT;\")"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sync(self):\n        logging.debug(\"Logger: Syncing...\")\n        failed = False\n        try:\n            # Get the connectordb object\n            cdb = self.connectordb\n\n            # Ping the database - most connection errors will happen here\n            cdb.ping()\n\n            with self.synclock:\n                c = self.database.cursor()\n                for stream in self.streams:\n                    s = cdb[stream]\n\n                    c.execute(\n                        \"SELECT * FROM cache WHERE stream=? ORDER BY timestamp ASC;\",\n                        (stream, ))\n                    datapointArray = []\n                    for dp in c.fetchall():\n                        datapointArray.append(\n                            {\"t\": dp[1],\n                             \"d\": json.loads(dp[2])})\n\n                    # First, check if the data already inserted has newer timestamps,\n                    # and in that case, assume that there was an error, and remove the datapoints\n                    # with an older timestamp, so that we don't have an error when syncing\n                    if len(s) > 0:\n                        newtime = s[-1][\"t\"]\n                        while (len(datapointArray) > 0 and datapointArray[0][\"t\"] < newtime):\n                            logging.debug(\"Datapoint exists with older timestamp. Removing the datapoint.\")\n                            datapointArray = datapointArray[1:]\n\n                    if len(datapointArray) > 0:\n                        logging.debug(\"%s: syncing %i datapoints\" %\n                                      (stream, len(datapointArray)))\n\n                        while (len(datapointArray) > DATAPOINT_INSERT_LIMIT):\n                            # We insert datapoints in chunks of a couple\n                            # thousand so that they fit in the insert size\n                            # limit of ConnectorDB\n                            s.insert_array(\n                                datapointArray[:DATAPOINT_INSERT_LIMIT])\n\n                            # Clear the written datapoints\n                            datapointArray = datapointArray[\n                                DATAPOINT_INSERT_LIMIT:]\n\n                            # If there was no error inserting, delete the\n                            # datapoints from the cache\n                            c.execute(\n                                \"DELETE FROM cache WHERE stream=? AND timestamp <?\",\n                                (stream, datapointArray[0][\"t\"]))\n\n                        s.insert_array(datapointArray)\n\n                        # If there was no error inserting, delete the\n                        # datapoints from the cache\n                        c.execute(\n                            \"DELETE FROM cache WHERE stream=? AND timestamp <=?\",\n                            (stream, datapointArray[-1][\"t\"]))\n                self.lastsynctime = time.time()\n\n                if self.onsync is not None:\n                    self.onsync()\n        except Exception as e:\n            # Handle the sync failure callback\n            falied = True\n            reraise = self.syncraise\n            if self.onsyncfail is not None:\n                reraise = self.onsyncfail(e)\n            if reraise:\n                raise", "response": "Syncs the datapoints with the ConnectorDB server."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef start(self):\n\n        with self.synclock:\n            if self.syncthread is not None:\n                logging.warn(\n                    \"Logger: Start called on a syncer that is already running\")\n                return\n\n        self.sync()  # Attempt a sync right away\n        self.__setsync()", "response": "Start the background synchronization service."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef stop(self):\n        with self.synclock:\n            if self.syncthread is not None:\n                self.syncthread.cancel()\n                self.syncthread = None", "response": "Stops the background synchronization thread"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nbuilds a file path from the given paths and return the contents.", "response": "def read(*paths):\n    \"\"\"Build a file path from *paths* and return the contents.\"\"\"\n    filename = os.path.join(*paths)\n    with codecs.open(filename, mode='r', encoding='utf-8') as handle:\n        return handle.read()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndownload a URL to a directory.", "response": "def download_url(job, url, work_dir='.', name=None, s3_key_path=None, cghub_key_path=None):\n    \"\"\"\n    Downloads URL, can pass in file://, http://, s3://, or ftp://, gnos://cghub/analysisID, or gnos:///analysisID\n    If downloading S3 URLs, the S3AM binary must be on the PATH\n\n    :param toil.job.Job job: Toil job that is calling this function\n    :param str url: URL to download from\n    :param str work_dir: Directory to download file to\n    :param str name: Name of output file, if None, basename of URL is used\n    :param str s3_key_path: Path to 32-byte encryption key if url points to S3 file that uses SSE-C\n    :param str cghub_key_path: Path to cghub key used to download from CGHub.\n    :return: Path to the downloaded file\n    :rtype: str\n    \"\"\"\n    file_path = os.path.join(work_dir, name) if name else os.path.join(work_dir, os.path.basename(url))\n    if cghub_key_path:\n        _download_with_genetorrent(job, url, file_path, cghub_key_path)\n    elif urlparse(url).scheme == 's3':\n        _s3am_with_retry(job, num_cores=1, file_path=file_path, s3_url=url, mode='download', s3_key_path=s3_key_path)\n    elif urlparse(url).scheme == 'file':\n        shutil.copy(urlparse(url).path, file_path)\n    else:\n        subprocess.check_call(['curl', '-fs', '--retry', '5', '--create-dir', url, '-o', file_path])\n    assert os.path.exists(file_path)\n    return file_path"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\njob version of download_url", "response": "def download_url_job(job, url, name=None, s3_key_path=None, cghub_key_path=None):\n    \"\"\"Job version of `download_url`\"\"\"\n    work_dir = job.fileStore.getLocalTempDir()\n    fpath = download_url(job=job, url=url, work_dir=work_dir, name=name,\n                         s3_key_path=s3_key_path, cghub_key_path=cghub_key_path)\n    return job.fileStore.writeGlobalFile(fpath)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef s3am_upload(job, fpath, s3_dir, num_cores=1, s3_key_path=None):\n    require(s3_dir.startswith('s3://'), 'Format of s3_dir (s3://) is incorrect: %s', s3_dir)\n    s3_dir = os.path.join(s3_dir, os.path.basename(fpath))\n    _s3am_with_retry(job=job, num_cores=num_cores, file_path=fpath,\n                     s3_url=s3_dir, mode='upload', s3_key_path=s3_key_path)", "response": "Uploads a file to S3 via S3AM"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef s3am_upload_job(job, file_id, file_name, s3_dir, s3_key_path=None):\n    work_dir = job.fileStore.getLocalTempDir()\n    fpath = job.fileStore.readGlobalFile(file_id, os.path.join(work_dir, file_name))\n    s3am_upload(job=job, fpath=fpath, s3_dir=s3_dir, num_cores=job.cores, s3_key_path=s3_key_path)", "response": "Job version of s3am_upload"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nruns s3am with retries", "response": "def _s3am_with_retry(job, num_cores, file_path, s3_url, mode='upload', s3_key_path=None):\n    \"\"\"\n    Run s3am with 3 retries\n\n    :param toil.job.Job job: Toil job that is calling this function\n    :param int num_cores: Number of cores to pass to upload/download slots\n    :param str file_path: Full path to the file\n    :param str s3_url: S3 URL\n    :param str mode: Mode to run s3am in. Either \"upload\" or \"download\"\n    :param str s3_key_path: Path to the SSE-C key if using encryption\n    \"\"\"\n    container_key_file = None\n    # try to find suitable credentials\n    base_boto = '.boto'\n    base_aws = '.aws/credentials'\n    docker_home_dir = '/root'\n    # map existing credential paths to their mount point within the container\n    credentials_to_mount = {os.path.join(os.path.expanduser(\"~\"), path): os.path.join(docker_home_dir, path)\n                            for path in [base_aws, base_boto]\n                            if os.path.exists(os.path.join(os.path.expanduser(\"~\"), path))}\n    require(os.path.isabs(file_path), \"'file_path' parameter must be an absolute path\")\n    dir_path, file_name = file_path.rsplit('/', 1)\n    # Mirror user specified paths to simplify debugging\n    container_dir_path = '/data' + dir_path\n    container_file = os.path.join(container_dir_path, file_name)\n    mounts = {dir_path: container_dir_path}\n    if s3_key_path:\n        require(os.path.isabs(s3_key_path), \"'s3_key_path' parameter must be an absolute path\")\n        key_dir_path, key_name = s3_key_path.rsplit('/', 1)\n        container_key_dir_path = '/data' + key_dir_path\n        container_key_file = os.path.join(container_key_dir_path, key_name)\n        # if the key directory is identical to the file directory this assignment is idempotent\n        mounts[key_dir_path] = container_key_dir_path\n    for k, v in credentials_to_mount.iteritems():\n        mounts[k] = v\n    arguments = []\n    url_arguments = []\n    if mode == 'upload':\n        arguments.extend(['upload', '--force', '--upload-slots=%s' % num_cores, '--exists=overwrite'])\n        url_arguments.extend(['file://' + container_file, s3_url])\n    elif mode == 'download':\n        arguments.extend(['download', '--file-exists=overwrite', '--download-exists=discard'])\n        url_arguments.extend([s3_url, 'file://' + container_file])\n    else:\n        raise ValueError('Improper mode specified. mode must be equal to \"upload\" or \"download\".')\n    if s3_key_path:\n        arguments.extend(['--sse-key-is-master', '--sse-key-file', container_key_file])\n    arguments.extend(['--part-size=50M', '--download-slots=%s' % num_cores])\n    # finally, add the url path arguments after all the tool parameters are set\n    arguments.extend(url_arguments)\n    # Pass credential-related environment variables into container\n    env = {}\n    if 'AWS_PROFILE' in os.environ:\n        env['AWS_PROFILE'] = os.environ['AWS_PROFILE']\n    # Create parameters to pass to Docker\n    docker_parameters = ['--rm', '--log-driver', 'none']\n    if mounts:\n        for k, v in mounts.iteritems():\n            docker_parameters.extend(['-v', k + ':' + v])\n    if env:\n        for e, v in env.iteritems():\n            docker_parameters.extend(['-e', '{}={}'.format(e, v)])\n    # Run s3am with retries\n    retry_count = 3\n    for i in xrange(retry_count):\n        try:\n            dockerCall(job=job, tool='quay.io/ucsc_cgl/s3am:2.0--fed932897e7fd40f4ec878362e5dd6afe15caaf0',\n                       parameters=arguments, dockerParameters=docker_parameters)\n        except subprocess.CalledProcessError:\n            _log.debug('S3AM %s failed', mode, exc_info=True)\n        else:\n            _log.debug('S3AM %s succeeded', mode)\n            return\n    raise RuntimeError(\"S3AM failed to %s after %i retries with arguments %s. Enable 'debug' \"\n                       \"level logging to see more information about the failed attempts.\" %\n                       (mode, retry_count, arguments))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef labels(ontology, output, ols_base):\n    for label in get_labels(ontology=ontology, ols_base=ols_base):\n        click.echo(label, file=output)", "response": "Output the names to the given file"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\noutput the parent - child relations to the given file", "response": "def tree(ontology, output, ols_base):\n    \"\"\"Output the parent-child relations to the given file\"\"\"\n    for parent, child in get_hierarchy(ontology=ontology, ols_base=ols_base):\n        click.echo('{}\\t{}'.format(parent, child), file=output)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_mean_insert_size(work_dir, bam_name):\n    cmd = \"docker run --log-driver=none --rm -v {}:/data quay.io/ucsc_cgl/samtools \" \\\n          \"view -f66 {}\".format(work_dir, os.path.join(work_dir, bam_name))\n    process = subprocess.Popen(args=cmd, shell=True, stdout=subprocess.PIPE)\n    b_sum = 0.0\n    b_count = 0.0\n    while True:\n        line = process.stdout.readline()\n        if not line:\n            break\n        tmp = line.split(\"\\t\")\n        if abs(long(tmp[8])) < 10000:\n            b_sum += abs(long(tmp[8]))\n            b_count += 1\n    process.wait()\n    try:\n        mean = b_sum / b_count\n    except ZeroDivisionError:\n        mean = 150\n    print \"Using insert size: %d\" % mean\n    return int(mean)", "response": "Function taken from MC3 Pipeline"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef partitions(l, partition_size):\n    for i in xrange(0, len(l), partition_size):\n        yield l[i:i + partition_size]", "response": "Yields a list of partitions of size partition_size from l."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a string that represents the container ID of the current Docker container.", "response": "def current_docker_container_id():\n    \"\"\"\n    Returns a string that represents the container ID of the current Docker container. If this\n    function is invoked outside of a container a NotInsideContainerError is raised.\n\n    >>> import subprocess\n    >>> import sys\n    >>> a = subprocess.check_output(['docker', 'run', '-v',\n    ...                              sys.modules[__name__].__file__ + ':/foo.py',\n    ...                              'python:2.7.12','python', '-c',\n    ...                              'from foo import current_docker_container_id;\\\\\n    ...                               print current_docker_container_id()'])\n    int call will fail if a is not a valid hex string\n    >>> int(a, 16) > 0\n    True\n    \"\"\"\n    try:\n        with open('/proc/1/cgroup', 'r') as readable:\n            raw = readable.read()\n        ids = set(re.compile('[0-9a-f]{12,}').findall(raw))\n        assert len(ids) == 1\n        return ids.pop()\n    except:\n        logging.exception('Failed to obtain current container ID')\n        raise NotInsideContainerError()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef run_star(job, r1_id, r2_id, star_index_url, wiggle=False, sort=True):\n    work_dir = job.fileStore.getLocalTempDir()\n    download_url(job, url=star_index_url, name='starIndex.tar.gz', work_dir=work_dir)\n    subprocess.check_call(['tar', '-xvf', os.path.join(work_dir, 'starIndex.tar.gz'), '-C', work_dir])\n    os.remove(os.path.join(work_dir, 'starIndex.tar.gz'))\n    # Determine tarball structure - star index contains are either in a subdir or in the tarball itself\n    star_index = os.path.join('/data', os.listdir(work_dir)[0]) if len(os.listdir(work_dir)) == 1 else '/data'\n    # Parameter handling for paired / single-end data\n    parameters = ['--runThreadN', str(job.cores),\n                  '--genomeDir', star_index,\n                  '--outFileNamePrefix', 'rna',\n                  '--outSAMunmapped', 'Within',\n                  '--quantMode', 'TranscriptomeSAM',\n                  '--outSAMattributes', 'NH', 'HI', 'AS', 'NM', 'MD',\n                  '--outFilterType', 'BySJout',\n                  '--outFilterMultimapNmax', '20',\n                  '--outFilterMismatchNmax', '999',\n                  '--outFilterMismatchNoverReadLmax', '0.04',\n                  '--alignIntronMin', '20',\n                  '--alignIntronMax', '1000000',\n                  '--alignMatesGapMax', '1000000',\n                  '--alignSJoverhangMin', '8',\n                  '--alignSJDBoverhangMin', '1',\n                  '--sjdbScore', '1',\n                  '--limitBAMsortRAM', '49268954168']\n    # Modify paramaters based on function arguments\n    if sort:\n        parameters.extend(['--outSAMtype', 'BAM', 'SortedByCoordinate'])\n        aligned_bam = 'rnaAligned.sortedByCoord.out.bam'\n    else:\n        parameters.extend(['--outSAMtype', 'BAM', 'Unsorted'])\n        aligned_bam = 'rnaAligned.out.bam'\n    if wiggle:\n        parameters.extend(['--outWigType', 'bedGraph',\n                           '--outWigStrand', 'Unstranded',\n                           '--outWigReferencesPrefix', 'chr'])\n    if r1_id and r2_id:\n        job.fileStore.readGlobalFile(r1_id, os.path.join(work_dir, 'R1.fastq'))\n        job.fileStore.readGlobalFile(r2_id, os.path.join(work_dir, 'R2.fastq'))\n        parameters.extend(['--readFilesIn', '/data/R1.fastq', '/data/R2.fastq'])\n    else:\n        job.fileStore.readGlobalFile(r1_id, os.path.join(work_dir, 'R1.fastq'))\n        parameters.extend(['--readFilesIn', '/data/R1.fastq'])\n    # Call: STAR Mapping\n    dockerCall(job=job, tool='quay.io/ucsc_cgl/star:2.4.2a--bcbd5122b69ff6ac4ef61958e47bde94001cfe80',\n               workDir=work_dir, parameters=parameters)\n    # Check output bam isnt size zero if sorted\n    aligned_bam_path = os.path.join(work_dir, aligned_bam)\n    if sort:\n        assert(os.stat(aligned_bam_path).st_size > 0, 'Aligned bam failed to sort. Ensure sufficient memory is free.')\n    # Write to fileStore\n    aligned_id = job.fileStore.writeGlobalFile(aligned_bam_path)\n    transcriptome_id = job.fileStore.writeGlobalFile(os.path.join(work_dir, 'rnaAligned.toTranscriptome.out.bam'))\n    log_id = job.fileStore.writeGlobalFile(os.path.join(work_dir, 'rnaLog.final.out'))\n    sj_id = job.fileStore.writeGlobalFile(os.path.join(work_dir, 'rnaSJ.out.tab'))\n    if wiggle:\n        wiggle_id = job.fileStore.writeGlobalFile(os.path.join(work_dir, 'rnaSignal.UniqueMultiple.str1.out.bg'))\n        return transcriptome_id, aligned_id, wiggle_id, log_id, sj_id\n    else:\n        return transcriptome_id, aligned_id, log_id, sj_id", "response": "This function runs a star on the RSEM file and returns the FileStoreID of the resulting RSEM file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrunning BWA-Kit to align single or paired-end fastq files or realign SAM/BAM files. :param JobFunctionWrappingJob job: Passed by Toil automatically :param Namespace config: A configuration object that holds strings as attributes. The attributes must be accessible via the dot operator. The config must have: config.r1 FileStoreID for FASTQ file, or None if realigning SAM/BAM config.r2 FileStoreID for paired FASTQ file, or None if single-ended config.bam FileStoreID for BAM file to be realigned, or None if aligning fastq config.sam FileStoreID for SAM file to be realigned, or None if aligning fastq config.ref FileStoreID for the reference genome config.fai FileStoreID for the reference index file config.amb FileStoreID for the reference amb file config.ann FileStoreID for the reference ann file config.bwt FileStoreID for the reference bwt file config.pac FileStoreID for the reference pac file config.sa FileStoreID for the reference sa file config.alt FileStoreID for the reference alt (or None) config.rg_line The read group value to use (or None -- see below) config.library Read group attribute: library config.platform Read group attribute: platform config.program_unit Read group attribute: program unit config.uuid Read group attribute: sample ID If specifying config.rg_line, use the following format: BAM read group header line (@RG), as defined on page 3 of the SAM spec. Tabs should be escaped, e.g., @RG\\\\tID:foo\\\\tLB:bar... for the read group \"foo\" from sequencing library \"bar\". Multiple @RG lines can be defined, but should be split by an escaped newline \\\\n, e.g., @RG\\\\tID:foo\\\\t:LB:bar\\\\n@RG\\\\tID:santa\\\\tLB:cruz. :param bool sort: If True, sorts the BAM :param bool trim: If True, performs adapter trimming :param bool mark_secondary: If True, mark shorter split reads as secondary :return: FileStoreID of BAM :rtype: str", "response": "def run_bwakit(job, config, sort=True, trim=False, mark_secondary=False):\n    \"\"\"\n    Runs BWA-Kit to align single or paired-end fastq files or realign SAM/BAM files.\n\n    :param JobFunctionWrappingJob job: Passed by Toil automatically\n    :param Namespace config: A configuration object that holds strings as attributes.\n        The attributes must be accessible via the dot operator.\n        The config must have:\n        config.r1               FileStoreID for FASTQ file, or None if realigning SAM/BAM\n        config.r2               FileStoreID for paired FASTQ file, or None if single-ended\n        config.bam              FileStoreID for BAM file to be realigned, or None if aligning fastq\n        config.sam              FileStoreID for SAM file to be realigned, or None if aligning fastq\n        config.ref              FileStoreID for the reference genome\n        config.fai              FileStoreID for the reference index file\n        config.amb              FileStoreID for the reference amb file\n        config.ann              FileStoreID for the reference ann file\n        config.bwt              FileStoreID for the reference bwt file\n        config.pac              FileStoreID for the reference pac file\n        config.sa               FileStoreID for the reference sa file\n        config.alt              FileStoreID for the reference alt (or None)\n        config.rg_line          The read group value to use (or None -- see below)\n        config.library          Read group attribute: library\n        config.platform         Read group attribute: platform\n        config.program_unit     Read group attribute: program unit\n        config.uuid             Read group attribute: sample ID\n\n        If specifying config.rg_line, use the following format:\n            BAM read group header line (@RG), as defined on page 3 of the SAM spec.\n            Tabs should be escaped, e.g., @RG\\\\tID:foo\\\\tLB:bar...\n            for the read group \"foo\" from sequencing library \"bar\".\n            Multiple @RG lines can be defined, but should be split by an escaped newline \\\\n,\n            e.g., @RG\\\\tID:foo\\\\t:LB:bar\\\\n@RG\\\\tID:santa\\\\tLB:cruz.\n\n    :param bool sort: If True, sorts the BAM\n    :param bool trim: If True, performs adapter trimming\n    :param bool mark_secondary: If True, mark shorter split reads as secondary\n    :return: FileStoreID of BAM\n    :rtype: str\n    \"\"\"\n    work_dir = job.fileStore.getLocalTempDir()\n    rg = None\n    inputs = {'ref.fa': config.ref,\n              'ref.fa.fai': config.fai,\n              'ref.fa.amb': config.amb,\n              'ref.fa.ann': config.ann,\n              'ref.fa.bwt': config.bwt,\n              'ref.fa.pac': config.pac,\n              'ref.fa.sa': config.sa}\n    samples = []\n    realignment = False\n    # If a fastq pair was provided\n    if getattr(config, 'r1', None):\n        inputs['input.1.fq.gz'] = config.r1\n        samples.append('input.1.fq.gz')\n    if getattr(config, 'r2', None):\n        inputs['input.2.fq.gz'] = config.r2\n        samples.append('input.2.fq.gz')\n    if getattr(config, 'bam', None):\n        inputs['input.bam'] = config.bam\n        samples.append('input.bam')\n        realignment = True\n    if getattr(config, 'sam', None):\n        inputs['input.sam'] = config.sam\n        samples.append('input.sam')\n        realignment = True\n    # If an alt file was provided\n    if getattr(config, 'alt', None):\n        inputs['ref.fa.alt'] = config.alt\n    for name, fileStoreID in inputs.iteritems():\n        job.fileStore.readGlobalFile(fileStoreID, os.path.join(work_dir, name))\n    # If a read group line was provided\n    if getattr(config, 'rg_line', None):\n        rg = config.rg_line\n    # Otherwise, generate a read group line to place in the BAM.\n    elif all(getattr(config, elem, None) for elem in ['library', 'platform', 'program_unit', 'uuid']):\n        rg = \"@RG\\\\tID:{0}\".format(config.uuid)  # '\\' character is escaped so bwakit gets passed '\\t' properly\n        rg_attributes = [config.library, config.platform, config.program_unit, config.uuid]\n        for tag, info in zip(['LB', 'PL', 'PU', 'SM'], rg_attributes):\n            rg += '\\\\t{0}:{1}'.format(tag, info)\n    # If realigning, then bwakit can use pre-existing read group data\n    elif realignment:\n        rg = None\n\n    # BWA Options\n    opt_args = []\n    if sort:\n        opt_args.append('-s')\n    if trim:\n        opt_args.append('-a')\n    if mark_secondary:\n        opt_args.append('-M')\n    # Call: bwakit\n    parameters = ['-t', str(job.cores)] + opt_args + ['-o', '/data/aligned', '/data/ref.fa']\n    if rg is not None:\n        parameters = ['-R', rg] + parameters\n    for sample in samples:\n        parameters.append('/data/{}'.format(sample))\n\n    dockerCall(job=job, tool='quay.io/ucsc_cgl/bwakit:0.7.12--c85ccff267d5021b75bb1c9ccf5f4b79f91835cc',\n               parameters=parameters, workDir=work_dir)\n\n    # Either write file to local output directory or upload to S3 cloud storage\n    job.fileStore.logToMaster('Aligned sample: {}'.format(config.uuid))\n    return job.fileStore.writeGlobalFile(os.path.join(work_dir, 'aligned.aln.bam'))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntakes the optional arguments and constructs a json query for a stream s datapoints using it", "response": "def query_maker(t1=None, t2=None, limit=None, i1=None, i2=None, transform=None, downlink=False):\n    \"\"\"query_maker takes the optional arguments and constructs a json query for a stream's\n    datapoints using it::\n        #{\"t1\": 5, \"transform\": \"if $ > 5\"}\n        print query_maker(t1=5,transform=\"if $ > 5\")\n    \"\"\"\n    params = {}\n    if t1 is not None:\n        params[\"t1\"] = t1\n    if t2 is not None:\n        params[\"t2\"] = t2\n    if limit is not None:\n        params[\"limit\"] = limit\n    if i1 is not None or i2 is not None:\n        if len(params) > 0:\n            raise AssertionError(\n                \"Stream cannot be accessed both by index and by timestamp at the same time.\")\n        if i1 is not None:\n            params[\"i1\"] = i1\n        if i2 is not None:\n            params[\"i2\"] = i2\n\n    # If no range is given, query whole stream\n    if len(params) == 0:\n        params[\"i1\"] = 0\n        params[\"i2\"] = 0\n\n    if transform is not None:\n        params[\"transform\"] = transform\n    if downlink:\n        params[\"downlink\"] = True\n\n    return params"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create(self, schema=\"{}\", **kwargs):\n        if isinstance(schema, basestring):\n            strschema = schema\n            schema = json.loads(schema)\n        else:\n            strschema = json.dumps(schema)\n        Draft4Validator.check_schema(schema)\n        kwargs[\"schema\"] = strschema\n        self.metadata = self.db.create(self.path, kwargs).json()", "response": "Creates a new stream given an optional JSON schema encoded as a python dict."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngiving an array of datapoints, inserts them to the stream. This is different from insert(), because it requires an array of valid datapoints, whereas insert only requires the data portion of the datapoint, and fills out the rest:: s = cdb[\"mystream\"] s.create({\"type\": \"number\"}) s.insert_array([{\"d\": 4, \"t\": time.time()},{\"d\": 5, \"t\": time.time()}], restamp=False) The optional `restamp` parameter specifies whether or not the database should rewrite the timestamps of datapoints which have a timestamp that is less than one that already exists in the database. That is, if restamp is False, and a datapoint has a timestamp less than a datapoint that already exists in the database, then the insert will fail. If restamp is True, then all datapoints with timestamps below the datapoints already in the database will have their timestamps overwritten to the same timestamp as the most recent datapoint hat already exists in the database, and the insert will succeed.", "response": "def insert_array(self, datapoint_array, restamp=False):\n        \"\"\"given an array of datapoints, inserts them to the stream. This is different from insert(),\n        because it requires an array of valid datapoints, whereas insert only requires the data portion\n        of the datapoint, and fills out the rest::\n\n            s = cdb[\"mystream\"]\n            s.create({\"type\": \"number\"})\n\n            s.insert_array([{\"d\": 4, \"t\": time.time()},{\"d\": 5, \"t\": time.time()}], restamp=False)\n\n        The optional `restamp` parameter specifies whether or not the database should rewrite the timestamps\n        of datapoints which have a timestamp that is less than one that already exists in the database.\n\n        That is, if restamp is False, and a datapoint has a timestamp less than a datapoint that already\n        exists in the database, then the insert will fail. If restamp is True, then all datapoints\n        with timestamps below the datapoints already in the database will have their timestamps overwritten\n        to the same timestamp as the most recent datapoint hat already exists in the database, and the insert will\n        succeed.\n        \"\"\"\n\n        # To be safe, we split into chunks\n        while (len(datapoint_array) > DATAPOINT_INSERT_LIMIT):\n            # We insert datapoints in chunks of a couple thousand so that they\n            # fit in the insert size limit of ConnectorDB\n            a = datapoint_array[:DATAPOINT_INSERT_LIMIT]\n\n            if restamp:\n                self.db.update(self.path + \"/data\", a)\n            else:\n                self.db.create(self.path + \"/data\", a)\n\n            # Clear the written datapoints\n            datapoint_array = datapoint_array[DATAPOINT_INSERT_LIMIT:]\n\n        if restamp:\n            self.db.update(self.path + \"/data\", datapoint_array)\n        else:\n            self.db.create(self.path + \"/data\", datapoint_array)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef insert(self, data):\n        self.insert_array([{\"d\": data, \"t\": time.time()}], restamp=True)", "response": "inserts one datapoint with the given data and appends it to the end of the stream"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef subscribe(self, callback, transform=\"\", downlink=False):\n        streampath = self.path\n        if downlink:\n            streampath += \"/downlink\"\n\n        return self.db.subscribe(streampath, callback, transform)", "response": "Subscribes to the stream running the callback function each time datapoints are inserted into\n        the given stream."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef export(self, directory):\n        if os.path.exists(directory):\n            raise FileExistsError(\n                \"The stream export directory already exists\")\n\n        os.mkdir(directory)\n\n        # Write the stream's info\n        with open(os.path.join(directory, \"stream.json\"), \"w\") as f:\n            json.dump(self.data, f)\n\n        # Now write the stream's data\n        # We sort it first, since older versions of ConnectorDB had a bug\n        # where sometimes datapoints would be returned out of order.\n        self[:].sort().writeJSON(os.path.join(directory, \"data.json\"))\n\n        # And if the stream is a downlink, write the downlink data\n        if self.downlink:\n            self(i1=0, i2=0, downlink=True).sort().writeJSON(os.path.join(directory, \"downlink.json\"))", "response": "Exports the data to the given directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef schema(self, schema):\n        if isinstance(schema, basestring):\n            strschema = schema\n            schema = json.loads(schema)\n        else:\n            strschema = json.dumps(schema)\n        Draft4Validator.check_schema(schema)\n        self.set({\"schema\": strschema})", "response": "sets the stream s schema."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the device which owns the given stream", "response": "def device(self):\n        \"\"\"returns the device which owns the given stream\"\"\"\n        splitted_path = self.path.split(\"/\")\n\n        return Device(self.db,\n                      splitted_path[0] + \"/\" + splitted_path[1])"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_labels(ontology, ols_base=None):\n    client = OlsClient(ols_base=ols_base)\n    return client.iter_labels(ontology)", "response": "Returns an iterator over the labels of terms in the ontology"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the metadata for a given ontology", "response": "def get_metadata(ontology, ols_base=None):\n    \"\"\"Gets the metadata for a given ontology\n\n    :param str ontology: The name of the ontology\n    :param str ols_base: An optional, custom OLS base url\n    :return: The dictionary representing the JSON from the OLS\n    :rtype: dict\n    \"\"\"\n    client = OlsClient(ols_base=ols_base)\n    return client.get_ontology(ontology)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_hierarchy(ontology, ols_base=None):\n    client = OlsClient(ols_base=ols_base)\n    return client.iter_hierarchy(ontology)", "response": "Returns an iterator over the parent - child relationships in an ontology."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef run(cls, name, desc):\n        wrapper = cls(name, desc)\n        mount_path = wrapper._get_mount_path()\n        # prepare parser\n        arg_parser = wrapper._create_argument_parser()\n        wrapper._extend_argument_parser(arg_parser)\n        # prepare config file\n        empty_config = wrapper.__get_empty_config()\n        config_yaml = ruamel.yaml.load(empty_config)\n        wrapper.__populate_parser_from_config(arg_parser, config_yaml)\n        args = arg_parser.parse_args()\n        for k,v in vars(args).items():\n            k = k.replace('_', '-')\n            if k in config_yaml:\n                config_yaml[k] = v\n        config_path = wrapper._get_config_path()\n        with open(config_path, 'w') as writable:\n            ruamel.yaml.dump(config_yaml, stream=writable)\n        # prepare workdir\n        workdir_path = os.path.join(mount_path, 'Toil-' + wrapper._name)\n        if os.path.exists(workdir_path):\n            if args.restart:\n                 log.info('Reusing temporary directory: %s', workdir_path)\n            else:\n                raise UserError('Temporary directory {} already exists. Run with --restart '\n                                'option or remove directory.'.format(workdir_path))\n        else:\n            os.makedirs(workdir_path)\n            log.info('Temporary directory created: %s', workdir_path)\n\n        command = wrapper._create_pipeline_command(args, workdir_path, config_path)\n        wrapper._extend_pipeline_command(command, args)\n        # run command\n        try:\n            subprocess.check_call(command)\n        except subprocess.CalledProcessError as e:\n            print(e, file=sys.stderr)\n        finally:\n            stat = os.stat(mount_path)\n            log.info('Pipeline terminated, changing ownership of output files in %s from root to '\n                     'uid %s and gid %s.', mount_path, stat.st_uid, stat.st_gid)\n            chown_command = ['chown', '-R', '%s:%s' % (stat.st_uid, stat.st_gid), mount_path]\n            subprocess.check_call(chown_command)\n            if args.no_clean:\n                log.info('Flag \"--no-clean\" was used, therefore %s was not deleted.', workdir_path)\n            else:\n                log.info('Cleaning up temporary directory: %s', workdir_path)\n                shutil.rmtree(workdir_path)", "response": "Prepares and runs the pipeline. Note this method must be invoked both from inside a\n        Docker container and while the docker daemon is reachable.\n\n        :param str name: The name of the command to start the workflow.\n        :param str desc: The description of the workflow."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __populate_parser_from_config(self, arg_parser, config_data, prefix=''):\n        for k,v in config_data.items():\n            k = prefix + '.' + k if prefix else k\n            if isinstance(v, dict):\n                self.__populate_parser_from_config(arg_parser, v, prefix=k)\n            else:\n                self._add_option(arg_parser, name=k, default=v)", "response": "Populates an ArgumentParser object with the arguments from the config_data dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __get_empty_config(self):\n        self._generate_config()\n        path = self._get_config_path()\n        with open(path, 'r') as readable:\n            contents = readable.read()\n        os.remove(path)\n        return contents", "response": "Returns the empty config file contents as a string."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the path of the mount point of the current container.", "response": "def _get_mount_path(self):\n        \"\"\"\n        Returns the path of the mount point of the current container. If this method is invoked\n        outside of a Docker container a NotInsideContainerError is raised. Likewise if the docker\n        daemon is unreachable from inside the container a UserError is raised. This method is\n        idempotent.\n        \"\"\"\n        if self._mount_path is None:\n            name = current_docker_container_id()\n            if dockerd_is_reachable():\n                # Get name of mounted volume\n                blob = json.loads(subprocess.check_output(['docker', 'inspect', name]))\n                mounts = blob[0]['Mounts']\n                # Ensure docker.sock is mounted correctly\n                sock_mnt = [x['Source'] == x['Destination']\n                            for x in mounts if 'docker.sock' in x['Source']]\n                require(len(sock_mnt) == 1,\n                        'Missing socket mount. Requires the following: '\n                         'docker run -v /var/run/docker.sock:/var/run/docker.sock')\n                # Ensure formatting of command for 2 mount points\n                if len(mounts) == 2:\n                    require(all(x['Source'] == x['Destination'] for x in mounts),\n                            'Docker Src/Dst mount points, invoked with the -v argument, '\n                            'must be the same if only using one mount point aside from the docker '\n                            'socket.')\n                    work_mount = [x['Source'] for x in mounts if 'docker.sock' not in x['Source']]\n                else:\n                    # Ensure only one mirror mount exists aside from docker.sock\n                    mirror_mounts = [x['Source'] for x in mounts if x['Source'] == x['Destination']]\n                    work_mount = [x for x in mirror_mounts if 'docker.sock' not in x]\n                    require(len(work_mount) == 1, 'Wrong number of mirror mounts provided, see '\n                                                  'documentation.')\n                self._mount_path = work_mount[0]\n                log.info('The work mount is: %s', self._mount_path)\n            else:\n                raise UserError('Docker daemon is not reachable, ensure Docker is being run with: '\n                                 '\"-v /var/run/docker.sock:/var/run/docker.sock\" as an argument.')\n        return self._mount_path"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _add_option(self, arg_parser, name, *args, **kwargs):\n        arg_parser.add_argument('--' + name, *args, **kwargs)", "response": "Adds an argument to the given arg_parser with the given name."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate and returns an argument parser object prepopulated with no clean cores and arguments.", "response": "def _create_argument_parser(self):\n        \"\"\"\n        Creates and returns an ArgumentParser object prepopulated with 'no clean', 'cores' and\n        'restart' arguments.\n        \"\"\"\n        parser = argparse.ArgumentParser(description=self._desc,\n                                         formatter_class=argparse.RawTextHelpFormatter)\n        parser.add_argument('--no-clean', action='store_true',\n                            help='If this flag is used, temporary work directory is not cleaned.')\n        parser.add_argument('--restart', action='store_true',\n                            help='If this flag is used, a previously uncleaned workflow in the same'\n                                 ' directory will be resumed')\n        parser.add_argument('--cores', type=int, default=None,\n                            help='Will set a cap on number of cores to use, default is all '\n                                 'available cores.')\n        return parser"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate and returns a list that represents a command for running the pipeline.", "response": "def _create_pipeline_command(self, args, workdir_path, config_path):\n        \"\"\"\n        Creates and returns a list that represents a command for running the pipeline.\n        \"\"\"\n        return ([self._name, 'run', os.path.join(workdir_path, 'jobStore'),\n                 '--config', config_path,\n                 '--workDir', workdir_path, '--retryCount', '1']\n                 + (['--restart'] if args.restart else []))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the authentication header for use in the session.", "response": "def setauth(self, user_or_apikey=None, user_password=None):\n        \"\"\" setauth sets the authentication header for use in the session.\n        It is for use when apikey is updated or something of the sort, such that\n        there is a seamless experience. \"\"\"\n        auth = None\n        if user_or_apikey is not None:\n            # ConnectorDB allows login using both basic auth or an apikey url param.\n            # The python client uses basic auth for all logins\n            if user_password is None:\n                # Login by api key - the basic auth login uses \"\" user and\n                # apikey as password\n                user_password = user_or_apikey\n                user_or_apikey = \"\"\n            auth = HTTPBasicAuth(user_or_apikey, user_password)\n            self.r.auth = auth\n\n        # Set the websocket's authentication\n        self.ws.setauth(auth)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef handleresult(self, r):\n        if r.status_code >= 400 and r.status_code < 500:\n            msg = r.json()\n            raise AuthenticationError(str(msg[\"code\"]) + \": \" + msg[\"msg\"] +\n                                      \" (\" + msg[\"ref\"] + \")\")\n        elif r.status_code > 300:\n            err = None\n            try:\n                msg = r.json()\n                err = ServerError(str(msg[\"code\"]) + \": \" + msg[\"msg\"] + \" (\" +\n                                  msg[\"ref\"] + \")\")\n            except:\n                raise ServerError(\n                    \"Server returned error, but did not give a valid error message\")\n            raise err\n        return r", "response": "Handles HTTP error codes for the given request."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nattempting to ping the server using current credentials and responds with the path of the currently authenticated device", "response": "def ping(self):\n        \"\"\"Attempts to ping the server using current credentials, and responds with the path of the currently\n        authenticated device\"\"\"\n        return self.handleresult(self.r.get(self.url,\n                                            params={\"q\": \"this\"})).text"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrun the given query on the connection", "response": "def query(self, query_type, query=None):\n        \"\"\"Run the given query on the connection (POST request to /query)\"\"\"\n        return self.handleresult(self.r.post(urljoin(self.url + \"query/\",\n                                                     query_type),\n                                             data=json.dumps(query))).json()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create(self, path, data=None):\n        return self.handleresult(self.r.post(urljoin(self.url + CRUD_PATH,\n                                                     path),\n                                             data=json.dumps(data)))", "response": "Send a POST request to the given path using the given data which will be converted\n        to json"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading the result at the given path from the CRUD API using the optional params dictionary Integrity as url parameters.", "response": "def read(self, path, params=None):\n        \"\"\"Read the result at the given path (GET) from the CRUD API, using the optional params dictionary\n        as url parameters.\"\"\"\n        return self.handleresult(self.r.get(urljoin(self.url + CRUD_PATH,\n                                                    path),\n                                            params=params))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsends an update request to the given path of the CRUD API with the given data dict", "response": "def update(self, path, data=None):\n        \"\"\"Send an update request to the given path of the CRUD API, with the given data dict, which will be converted\n        into json\"\"\"\n        return self.handleresult(self.r.put(urljoin(self.url + CRUD_PATH,\n                                                    path),\n                                            data=json.dumps(data)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsends a delete request to the given path of the CRUD API. This deletes the object. Or tries to find the object.", "response": "def delete(self, path):\n        \"\"\"Send a delete request to the given path of the CRUD API. This deletes the object. Or at least tries to.\"\"\"\n        return self.handleresult(self.r.delete(urljoin(self.url + CRUD_PATH,\n                                                       path)))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef subscribe(self, stream, callback, transform=\"\"):\n        return self.ws.subscribe(stream, callback, transform)", "response": "Subscribe to the given stream with the callback"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create(self, email, password, role=\"user\", public=True, **kwargs):\n        kwargs[\"email\"] = email\n        kwargs[\"password\"] = password\n        kwargs[\"role\"] = role\n        kwargs[\"public\"] = public\n        self.metadata = self.db.create(\n            self.path, kwargs).json()", "response": "Creates the given user using the passed in email and password."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef devices(self):\n        result = self.db.read(self.path, {\"q\": \"ls\"})\n\n        if result is None or result.json() is None:\n            return []\n        devices = []\n        for d in result.json():\n            dev = self[d[\"name\"]]\n            dev.metadata = d\n            devices.append(dev)\n        return devices", "response": "Returns the list of devices that belong to the user"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef streams(self, public=False, downlink=False, visible=True):\n        result = self.db.read(self.path, {\"q\": \"streams\",\n                                          \"public\": str(public).lower(),\n                                          \"downlink\": str(downlink).lower(),\n                                          \"visible\": str(visible).lower()})\n\n        if result is None or result.json() is None:\n            return []\n        streams = []\n        for d in result.json():\n            s = self[d[\"device\"]][d[\"name\"]]\n            s.metadata = d\n            streams.append(s)\n        return streams", "response": "Returns the list of streams that belong to the user."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef export(self, directory):\n\n        exportInfoFile = os.path.join(directory, \"connectordb.json\")\n        if os.path.exists(directory):\n            # Ensure that there is an export there already, and it is version 1\n            if not os.path.exists(exportInfoFile):\n                raise FileExistsError(\n                    \"The export directory already exsits, and is not a ConnectorDB export.\")\n            with open(exportInfoFile) as f:\n                exportInfo = json.load(f)\n            if exportInfo[\"Version\"] != 1:\n                raise ValueError(\n                    \"Could not export to directory: incompatible export versions.\")\n        else:\n            # The folder doesn't exist. Make it.\n            os.mkdir(directory)\n\n            with open(exportInfoFile, \"w\") as f:\n                json.dump(\n                    {\"Version\": 1, \"ConnectorDB\": self.db.get(\"meta/version\").text}, f)\n\n        # Now we create the user directory\n        udir = os.path.join(directory, self.name)\n        os.mkdir(udir)\n\n        # Write the user's info\n        with open(os.path.join(udir, \"user.json\"), \"w\") as f:\n            json.dump(self.data, f)\n\n        # Now export the devices one by one\n        for d in self.devices():\n            d.export(os.path.join(udir, d.name))", "response": "Exports the user into the given directory."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nimport a device from the given directory.", "response": "def import_device(self, directory):\n        \"\"\"Imports a device from the given directory. You export the device\n        by using device.export()\n\n        There are two special cases: user and meta devices.\n        If the device name is meta, import_device will not do anything.\n        If the device name is \"user\", import_device will overwrite the user device\n        even if it exists already.\n        \"\"\"\n\n        # read the device's info\n        with open(os.path.join(directory, \"device.json\"), \"r\") as f:\n            ddata = json.load(f)\n\n        d = self[ddata[\"name\"]]\n\n        dname = ddata[\"name\"]\n        del ddata[\"name\"]\n\n        if dname == \"meta\":\n            return\n        elif dname == \"user\":\n            d.set(ddata)\n        elif d.exists():\n            raise ValueError(\"The device \" + d.name + \" already exists\")\n        else:\n            d.create(**ddata)\n\n        # Now import all of the streams\n        for name in os.listdir(directory):\n            sdir = os.path.join(directory, name)\n            if os.path.isdir(sdir):\n                d.import_stream(sdir)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run_cutadapt(job, r1_id, r2_id, fwd_3pr_adapter, rev_3pr_adapter):\n    work_dir = job.fileStore.getLocalTempDir()\n    if r2_id:\n        require(rev_3pr_adapter, \"Paired end data requires a reverse 3' adapter sequence.\")\n    # Retrieve files\n    parameters = ['-a', fwd_3pr_adapter,\n                  '-m', '35']\n    if r1_id and r2_id:\n        job.fileStore.readGlobalFile(r1_id, os.path.join(work_dir, 'R1.fastq'))\n        job.fileStore.readGlobalFile(r2_id, os.path.join(work_dir, 'R2.fastq'))\n        parameters.extend(['-A', rev_3pr_adapter,\n                           '-o', '/data/R1_cutadapt.fastq',\n                           '-p', '/data/R2_cutadapt.fastq',\n                           '/data/R1.fastq', '/data/R2.fastq'])\n    else:\n        job.fileStore.readGlobalFile(r1_id, os.path.join(work_dir, 'R1.fastq'))\n        parameters.extend(['-o', '/data/R1_cutadapt.fastq', '/data/R1.fastq'])\n    # Call: CutAdapt\n    dockerCall(job=job, tool='quay.io/ucsc_cgl/cutadapt:1.9--6bd44edd2b8f8f17e25c5a268fedaab65fa851d2',\n               workDir=work_dir, parameters=parameters)\n    # Write to fileStore\n    if r1_id and r2_id:\n        r1_cut_id = job.fileStore.writeGlobalFile(os.path.join(work_dir, 'R1_cutadapt.fastq'))\n        r2_cut_id = job.fileStore.writeGlobalFile(os.path.join(work_dir, 'R2_cutadapt.fastq'))\n    else:\n        r1_cut_id = job.fileStore.writeGlobalFile(os.path.join(work_dir, 'R1_cutadapt.fastq'))\n        r2_cut_id = None\n    return r1_cut_id, r2_cut_id", "response": "This function runs the cutadapt command."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef run_samtools_faidx(job, ref_id):\n    job.fileStore.logToMaster('Created reference index')\n    work_dir = job.fileStore.getLocalTempDir()\n    job.fileStore.readGlobalFile(ref_id, os.path.join(work_dir, 'ref.fasta'))\n    command = ['faidx', 'ref.fasta']\n    dockerCall(job=job, workDir=work_dir, parameters=command,\n               tool='quay.io/ucsc_cgl/samtools:0.1.19--dd5ac549b95eb3e5d166a5e310417ef13651994e')\n    return job.fileStore.writeGlobalFile(os.path.join(work_dir, 'ref.fasta.fai'))", "response": "Use SAMtools to create reference index file"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nruns SAMtools index to create a BAM index file", "response": "def run_samtools_index(job, bam):\n    \"\"\"\n    Runs SAMtools index to create a BAM index file\n\n    :param JobFunctionWrappingJob job: passed automatically by Toil\n    :param str bam: FileStoreID of the BAM file\n    :return: FileStoreID for BAM index file\n    :rtype: str\n    \"\"\"\n    work_dir = job.fileStore.getLocalTempDir()\n    job.fileStore.readGlobalFile(bam, os.path.join(work_dir, 'sample.bam'))\n    # Call: index the bam\n    parameters = ['index', '/data/sample.bam']\n    dockerCall(job=job, workDir=work_dir, parameters=parameters,\n               tool='quay.io/ucsc_cgl/samtools:0.1.19--dd5ac549b95eb3e5d166a5e310417ef13651994e')\n    # Write to fileStore\n    return job.fileStore.writeGlobalFile(os.path.join(work_dir, 'sample.bam.bai'))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nruns Sambamba mkdup on the input BAM file and returns FileStoreID for the resulting BAM file.", "response": "def run_sambamba_markdup(job, bam):\n    \"\"\"\n    Marks reads as PCR duplicates using Sambamba\n\n    :param JobFunctionWrappingJob job: passed automatically by Toil\n    :param str bam: FileStoreID for BAM file\n    :return: FileStoreID for sorted BAM file\n    :rtype: str\n    \"\"\"\n    work_dir = job.fileStore.getLocalTempDir()\n    job.fileStore.readGlobalFile(bam, os.path.join(work_dir, 'input.bam'))\n    command = ['/usr/local/bin/sambamba',\n               'markdup',\n               '-t', str(int(job.cores)),\n               '/data/input.bam',\n               '/data/output.bam']\n\n    start_time = time.time()\n    dockerCall(job=job, workDir=work_dir,\n               parameters=command,\n               tool='quay.io/biocontainers/sambamba:0.6.6--0')\n    end_time = time.time()\n    _log_runtime(job, start_time, end_time, \"sambamba mkdup\")\n    return job.fileStore.writeGlobalFile(os.path.join(work_dir, 'output.bam'))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nruns SAMBLASTER on the input file and writes the output to the output file.", "response": "def run_samblaster(job, sam):\n    \"\"\"\n    Marks reads as PCR duplicates using SAMBLASTER\n\n    :param JobFunctionWrappingJob job: passed automatically by Toil\n    :param str sam: FileStoreID for SAM file\n    :return: FileStoreID for deduped SAM file\n    :rtype: str\n    \"\"\"\n    work_dir = job.fileStore.getLocalTempDir()\n    job.fileStore.readGlobalFile(sam, os.path.join(work_dir, 'input.sam'))\n    command = ['/usr/local/bin/samblaster',\n               '-i', '/data/input.sam',\n               '-o', '/data/output.sam',\n               '--ignoreUnmated']\n\n    start_time = time.time()\n    dockerCall(job=job, workDir=work_dir,\n               parameters=command,\n               tool='quay.io/biocontainers/samblaster:0.1.24--0')\n    end_time = time.time()\n    _log_runtime(job, start_time, end_time, \"SAMBLASTER\")\n    return job.fileStore.writeGlobalFile(os.path.join(work_dir, 'output.sam'))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nruns Picard MarkDuplicates on a BAM file.", "response": "def picard_mark_duplicates(job, bam, bai, validation_stringency='LENIENT'):\n    \"\"\"\n    Runs Picard MarkDuplicates on a BAM file. Requires that the BAM file be coordinate sorted.\n\n    :param JobFunctionWrappingJob job: passed automatically by Toil\n    :param str bam: FileStoreID for BAM file\n    :param str bai: FileStoreID for BAM index file\n    :param str validation_stringency: BAM file validation stringency, default is LENIENT\n    :return: FileStoreIDs for BAM and BAI files\n    :rtype: tuple\n    \"\"\"\n    work_dir = job.fileStore.getLocalTempDir()\n\n    # Retrieve file path\n    job.fileStore.readGlobalFile(bam, os.path.join(work_dir, 'sorted.bam'))\n    job.fileStore.readGlobalFile(bai, os.path.join(work_dir, 'sorted.bai'))\n\n    # Call: picardtools\n    command = ['MarkDuplicates',\n               'INPUT=sorted.bam',\n               'OUTPUT=mkdups.bam',\n               'METRICS_FILE=metrics.txt',\n               'ASSUME_SORTED=true',\n               'CREATE_INDEX=true',\n               'VALIDATION_STRINGENCY=%s' % validation_stringency.upper()]\n\n    # picard-tools container doesn't have JAVA_OPTS variable\n    # Set TMPDIR to /data to prevent writing temporary files to /tmp\n    docker_parameters = ['--rm',\n                         '--log-driver', 'none',\n                         '-e', 'JAVA_OPTIONS=-Djava.io.tmpdir=/data/ -Xmx{}'.format(job.memory),\n                         '-v', '{}:/data'.format(work_dir)]\n\n    start_time = time.time()\n    dockerCall(job=job, workDir=work_dir,\n               parameters=command,\n               tool='quay.io/ucsc_cgl/picardtools:1.95--dd5ac549b95eb3e5d166a5e310417ef13651994e',\n               dockerParameters=docker_parameters)\n    end_time = time.time()\n    _log_runtime(job, start_time, end_time, \"Picard MarkDuplicates\")\n\n    bam = job.fileStore.writeGlobalFile(os.path.join(work_dir, 'mkdups.bam'))\n    bai = job.fileStore.writeGlobalFile(os.path.join(work_dir, 'mkdups.bai'))\n    return bam, bai"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrun Picard SortSam on the input BAM file.", "response": "def run_picard_sort(job, bam, sort_by_name=False):\n    \"\"\"\n    Sorts BAM file using Picard SortSam\n\n    :param JobFunctionWrappingJob job: passed automatically by Toil\n    :param str bam: FileStoreID for BAM file\n    :param boolean sort_by_name: If true, sorts by read name instead of coordinate.\n    :return: FileStoreID for sorted BAM file\n    :rtype: str\n    \"\"\"\n    work_dir = job.fileStore.getLocalTempDir()\n    job.fileStore.readGlobalFile(bam, os.path.join(work_dir, 'input.bam'))\n    command = ['SortSam',\n               'O=/data/output.bam',\n               'I=/data/input.bam']\n\n    # picard-tools container doesn't have JAVA_OPTS variable\n    # Set TMPDIR to /data to prevent writing temporary files to /tmp\n    docker_parameters = ['--rm',\n                         '--log-driver', 'none',\n                         '-e', 'JAVA_OPTIONS=-Djava.io.tmpdir=/data/ -Xmx{}'.format(job.memory),\n                         '-v', '{}:/data'.format(work_dir)]\n\n    if sort_by_name:\n        command.append('SO=queryname')\n    else:\n        command.append('SO=coordinate')\n\n    start_time = time.time()\n    dockerCall(job=job, workDir=work_dir,\n               parameters=command,\n               tool='quay.io/ucsc_cgl/picardtools:1.95--dd5ac549b95eb3e5d166a5e310417ef13651994e',\n               dockerParameters=docker_parameters)\n    end_time = time.time()\n    _log_runtime(job, start_time, end_time, \"Picard SortSam\")\n    return job.fileStore.writeGlobalFile(os.path.join(work_dir, 'output.bam'))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run_gatk_preprocessing(job, bam, bai, ref, ref_dict, fai, g1k, mills, dbsnp, realign=False, unsafe=False):\n    # The MarkDuplicates disk requirement depends on the input BAM and BAI files and the output\n    # BAM and BAI files. The output BAM file is approximately the same size as the input BAM file.\n    mdups_disk = PromisedRequirement(lambda bam_, bai_: 2 * (bam_.size + bai_.size), bam, bai)\n    mdups = job.wrapJobFn(picard_mark_duplicates,\n                          bam,\n                          bai,\n                          cores=job.cores,\n                          disk=mdups_disk,\n                          memory=job.memory)\n\n    # Store input for BQSR\n    bqsr_input_bam = mdups.rv(0)\n    bqsr_input_bai = mdups.rv(1)\n\n    # Get genome reference file sizes for calculating disk requirements\n    genome_ref_size = ref.size + ref_dict.size + fai.size\n\n    if realign:\n        # Get INDEL resource file sizes and genome reference file sizes\n        indel_ref_size = mills.size + g1k.size + genome_ref_size\n\n        # The RealignerTargetCreator disk requirement depends on the input BAM/BAI files, the genome reference files,\n        # and the output intervals file. The intervals file size is less than the reference file size, so estimate the\n        # interval file size as the reference file size.\n        realigner_target_disk = PromisedRequirement(lambda bam_, bai_, ref_size:\n                                                    bam_.size + bai_.size + 2 * ref_size,\n                                                    mdups.rv(0),\n                                                    mdups.rv(1),\n                                                    indel_ref_size)\n\n        realigner_target = job.wrapJobFn(run_realigner_target_creator,\n                                         mdups.rv(0),\n                                         mdups.rv(1),\n                                         ref, ref_dict, fai,\n                                         g1k, mills,\n                                         unsafe=unsafe,\n                                         cores=1,  # RealignerTargetCreator is single threaded\n                                         disk=realigner_target_disk,\n                                         memory=job.memory)\n\n        # The INDEL realignment disk requirement depends on the input BAM and BAI files, the intervals\n        # file, the variant resource files, and the output BAM and BAI files. Here, we assume the\n        # output BAM and BAI files are approximately the same size as the input BAM and BAI files.\n        indel_realign_disk = PromisedRequirement(lambda bam_, bai_, intervals, ref_size:\n                                                 2 * (bam_.size + bai_.size) + intervals.size + ref_size,\n                                                 mdups.rv(0),\n                                                 mdups.rv(1),\n                                                 realigner_target.rv(),\n                                                 indel_ref_size)\n\n        indel_realign = job.wrapJobFn(run_indel_realignment,\n                                      realigner_target.rv(),\n                                      mdups.rv(0),\n                                      mdups.rv(1),\n                                      ref, ref_dict, fai,\n                                      g1k, mills,\n                                      unsafe=unsafe,\n                                      cores=1,  # IndelRealigner is single threaded\n                                      disk=indel_realign_disk,\n                                      memory=job.memory)\n\n        mdups.addChild(realigner_target)\n        realigner_target.addChild(indel_realign)\n\n        # Update input for BQSR using the realigned BAM files\n        bqsr_input_bam = indel_realign.rv(0)\n        bqsr_input_bai = indel_realign.rv(1)\n\n\n    # Get size of BQSR databases and genome reference files\n    bqsr_ref_size = dbsnp.size + mills.size + genome_ref_size\n\n    # The BQSR disk requirement depends on the input BAM and BAI files, the reference files, and the output\n    # recalibration table file. The recalibration table file size is less than the reference file sizes, so use\n    # the reference file sizes to estimate the recalibration table file size.\n    base_recal_disk = PromisedRequirement(lambda bam_, bai_, ref_size:\n                                          bam_.size + bai_.size + 2 * ref_size,\n                                          bqsr_input_bam,\n                                          bqsr_input_bai,\n                                          bqsr_ref_size)\n\n    base_recal = job.wrapJobFn(run_base_recalibration,\n                               bqsr_input_bam,\n                               bqsr_input_bai,\n                               ref, ref_dict, fai,\n                               dbsnp, mills,\n                               unsafe=unsafe,\n                               cores=job.cores,\n                               disk=base_recal_disk,\n                               memory=job.memory)\n\n    # The PrintReads disk requirement depends on the input BAM and BAI files, the recalibration table file, the\n    # genome reference files, and the output BAM and BAI files. The output BAM and BAI files are approximately the\n    # same size as the input BAM and BAI files.\n    recalibrate_reads_disk = PromisedRequirement(lambda bam_, bai_, recal, ref_size:\n                                                 2 * (bam_.size + bai_.size) + recal.size + ref_size,\n                                                 bqsr_input_bam,\n                                                 bqsr_input_bai,\n                                                 base_recal.rv(),\n                                                 genome_ref_size)\n\n    recalibrate_reads = job.wrapJobFn(apply_bqsr_recalibration,\n                                      base_recal.rv(),\n                                      bqsr_input_bam,\n                                      bqsr_input_bai,\n                                      ref, ref_dict, fai,\n                                      unsafe=unsafe,\n                                      cores=job.cores,\n                                      disk=recalibrate_reads_disk,\n                                      memory=job.memory)\n\n    job.addChild(mdups)\n    mdups.addFollowOn(base_recal)\n    base_recal.addChild(recalibrate_reads)\n    return recalibrate_reads.rv(0), recalibrate_reads.rv(1)", "response": "Runs GATK preprocessing pipeline."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates recalibration table for Base Quality Score Recalibration :param JobFunctionWrappingJob job: passed automatically by Toil :param str bam: FileStoreID for BAM file :param str bai: FileStoreID for BAM index file :param str ref: FileStoreID for reference genome fasta file :param str ref_dict: FileStoreID for reference genome sequence dictionary file :param str fai: FileStoreID for reference genome fasta index file :param str dbsnp: FileStoreID for dbSNP VCF file :param str mills: FileStoreID for Mills VCF file :param bool unsafe: If True, runs GATK in UNSAFE mode: \"-U ALLOW_SEQ_DICT_INCOMPATIBILITY\" :return: FileStoreID for the recalibration table file :rtype: str", "response": "def run_base_recalibration(job, bam, bai, ref, ref_dict, fai, dbsnp, mills, unsafe=False):\n    \"\"\"\n    Creates recalibration table for Base Quality Score Recalibration\n\n    :param JobFunctionWrappingJob job: passed automatically by Toil\n    :param str bam: FileStoreID for BAM file\n    :param str bai: FileStoreID for BAM index file\n    :param str ref: FileStoreID for reference genome fasta file\n    :param str ref_dict: FileStoreID for reference genome sequence dictionary file\n    :param str fai: FileStoreID for reference genome fasta index file\n    :param str dbsnp: FileStoreID for dbSNP VCF file\n    :param str mills: FileStoreID for Mills VCF file\n    :param bool unsafe: If True, runs GATK in UNSAFE mode: \"-U ALLOW_SEQ_DICT_INCOMPATIBILITY\"\n    :return: FileStoreID for the recalibration table file\n    :rtype: str\n    \"\"\"\n    inputs = {'ref.fasta': ref,\n              'ref.fasta.fai': fai,\n              'ref.dict': ref_dict,\n              'input.bam': bam,\n              'input.bai': bai,\n              'dbsnp.vcf': dbsnp,\n              'mills.vcf': mills}\n\n    work_dir = job.fileStore.getLocalTempDir()\n    for name, file_store_id in inputs.iteritems():\n        job.fileStore.readGlobalFile(file_store_id, os.path.join(work_dir, name))\n\n    # Call: GATK -- BaseRecalibrator\n    parameters = ['-T', 'BaseRecalibrator',\n                  '-nct', str(int(job.cores)),\n                  '-R', '/data/ref.fasta',\n                  '-I', '/data/input.bam',\n                  # Recommended known sites:\n                  # https://software.broadinstitute.org/gatk/guide/article?id=1247\n                  '-knownSites', '/data/dbsnp.vcf',\n                  '-knownSites', '/data/mills.vcf',\n                  '-o', '/data/recal_data.table']\n\n    if unsafe:\n        parameters.extend(['-U', 'ALLOW_SEQ_DICT_INCOMPATIBILITY'])\n\n    # Set TMPDIR to /data to prevent writing temporary files to /tmp\n    docker_parameters = ['--rm',\n                         '--log-driver', 'none',\n                         '-e', 'JAVA_OPTS=-Djava.io.tmpdir=/data/ -Xmx{}'.format(job.memory),\n                         '-v', '{}:/data'.format(work_dir)]\n    start_time = time.time()\n    dockerCall(job=job, tool='quay.io/ucsc_cgl/gatk:3.5--dba6dae49156168a909c43330350c6161dc7ecc2',\n               workDir=work_dir,\n               parameters=parameters,\n               dockerParameters=docker_parameters)\n    end_time = time.time()\n    _log_runtime(job, start_time, end_time, \"GATK3 BaseRecalibrator\")\n\n    return job.fileStore.writeGlobalFile(os.path.join(work_dir, 'recal_data.table'))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrunning Kallisto RNA quantification via Kallisto", "response": "def run_kallisto(job, r1_id, r2_id, kallisto_index_url):\n    \"\"\"\n    RNA quantification via Kallisto\n\n    :param JobFunctionWrappingJob job: passed automatically by Toil\n    :param str r1_id: FileStoreID of fastq (pair 1)\n    :param str r2_id: FileStoreID of fastq (pair 2 if applicable, otherwise pass None for single-end)\n    :param str kallisto_index_url: FileStoreID for Kallisto index file\n    :return: FileStoreID from Kallisto output\n    :rtype: str\n    \"\"\"\n    work_dir = job.fileStore.getLocalTempDir()\n    download_url(job, url=kallisto_index_url, name='kallisto_hg38.idx', work_dir=work_dir)\n    # Retrieve files\n    parameters = ['quant',\n                  '-i', '/data/kallisto_hg38.idx',\n                  '-t', str(job.cores),\n                  '-o', '/data/',\n                  '-b', '100',\n                  '--fusion']\n    if r1_id and r2_id:\n        job.fileStore.readGlobalFile(r1_id, os.path.join(work_dir, 'R1.fastq'))\n        job.fileStore.readGlobalFile(r2_id, os.path.join(work_dir, 'R2.fastq'))\n        parameters.extend(['/data/R1.fastq', '/data/R2.fastq'])\n    else:\n        job.fileStore.readGlobalFile(r1_id, os.path.join(work_dir, 'R1.fastq'))\n        parameters.extend(['--single', '-l', '200', '-s', '15', '/data/R1.fastq'])\n\n    # Call: Kallisto\n    dockerCall(job=job, tool='quay.io/ucsc_cgl/kallisto:0.42.4--35ac87df5b21a8e8e8d159f26864ac1e1db8cf86',\n               workDir=work_dir, parameters=parameters)\n\n    # Tar output files together and store in fileStore\n    output_files = [os.path.join(work_dir, x) for x in ['run_info.json', 'abundance.tsv', 'abundance.h5', 'fusion.txt']]\n    tarball_files(tar_name='kallisto.tar.gz', file_paths=output_files, output_dir=work_dir)\n    return job.fileStore.writeGlobalFile(os.path.join(work_dir, 'kallisto.tar.gz'))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrun RSEM with RNA quantification with RSEM.", "response": "def run_rsem(job, bam_id, rsem_ref_url, paired=True):\n    \"\"\"\n    RNA quantification with RSEM\n\n    :param JobFunctionWrappingJob job: Passed automatically by Toil\n    :param str bam_id: FileStoreID of transcriptome bam for quantification\n    :param str rsem_ref_url: URL of RSEM reference (tarball)\n    :param bool paired: If True, uses parameters for paired end data\n    :return: FileStoreIDs for RSEM's gene and isoform output\n    :rtype: str\n    \"\"\"\n    work_dir = job.fileStore.getLocalTempDir()\n    download_url(job, url=rsem_ref_url, name='rsem_ref.tar.gz', work_dir=work_dir)\n    subprocess.check_call(['tar', '-xvf', os.path.join(work_dir, 'rsem_ref.tar.gz'), '-C', work_dir])\n    os.remove(os.path.join(work_dir, 'rsem_ref.tar.gz'))\n    # Determine tarball structure - based on it, ascertain folder name and rsem reference prefix\n    rsem_files = []\n    for root, directories, files in os.walk(work_dir):\n        rsem_files.extend([os.path.join(root, x) for x in files])\n    # \"grp\" is a required RSEM extension that should exist in the RSEM reference\n    ref_prefix = [os.path.basename(os.path.splitext(x)[0]) for x in rsem_files if 'grp' in x][0]\n    ref_folder = os.path.join('/data', os.listdir(work_dir)[0]) if len(os.listdir(work_dir)) == 1 else '/data'\n    # I/O\n    job.fileStore.readGlobalFile(bam_id, os.path.join(work_dir, 'transcriptome.bam'))\n    output_prefix = 'rsem'\n    # Call: RSEM\n    parameters = ['--quiet',\n                  '--no-qualities',\n                  '-p', str(job.cores),\n                  '--forward-prob', '0.5',\n                  '--seed-length', '25',\n                  '--fragment-length-mean', '-1.0',\n                  '--bam', '/data/transcriptome.bam',\n                  os.path.join(ref_folder, ref_prefix),\n                  output_prefix]\n    if paired:\n        parameters = ['--paired-end'] + parameters\n    dockerCall(job=job, tool='quay.io/ucsc_cgl/rsem:1.2.25--d4275175cc8df36967db460b06337a14f40d2f21',\n               parameters=parameters, workDir=work_dir)\n    # Write to FileStore\n    gene_id = job.fileStore.writeGlobalFile(os.path.join(work_dir, output_prefix + '.genes.results'))\n    isoform_id = job.fileStore.writeGlobalFile(os.path.join(work_dir, output_prefix + '.isoforms.results'))\n    return gene_id, isoform_id"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef run_rsem_postprocess(job, rsem_gene_id, rsem_isoform_id):\n    work_dir = job.fileStore.getLocalTempDir()\n    # I/O\n    genes = job.fileStore.readGlobalFile(rsem_gene_id, os.path.join(work_dir, 'rsem_genes.results'))\n    iso = job.fileStore.readGlobalFile(rsem_isoform_id, os.path.join(work_dir, 'rsem_isoforms.results'))\n    # Perform HUGO gene / isoform name mapping\n    command = ['-g', 'rsem_genes.results', '-i', 'rsem_isoforms.results']\n    dockerCall(job=job, tool='quay.io/ucsc_cgl/gencode_hugo_mapping:1.0--cb4865d02f9199462e66410f515c4dabbd061e4d',\n               parameters=command, workDir=work_dir)\n    hugo_files = [os.path.join(work_dir, x) for x in ['rsem_genes.hugo.results', 'rsem_isoforms.hugo.results']]\n    # Create tarballs for outputs\n    tarball_files('rsem.tar.gz', file_paths=[os.path.join(work_dir, x) for x in [genes, iso]], output_dir=work_dir)\n    tarball_files('rsem_hugo.tar.gz', file_paths=[os.path.join(work_dir, x) for x in hugo_files], output_dir=work_dir)\n    rsem_id = job.fileStore.writeGlobalFile(os.path.join(work_dir, 'rsem.tar.gz'))\n    hugo_id = job.fileStore.writeGlobalFile(os.path.join(work_dir, 'rsem_hugo.tar.gz'))\n    return rsem_id, hugo_id", "response": "Runs RSEMs post - processing on both gene and isoform."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef switch(request, url):\n    app_label, model_name, object_id, field = url.split('/')\n    try:\n        # django >= 1.7\n        from django.apps import apps\n        model = apps.get_model(app_label, model_name)\n    except ImportError:\n        # django < 1.7\n        from django.db.models import get_model\n        model = get_model(app_label, model_name)\n\n    object = get_object_or_404(model, pk=object_id)\n    perm_str = '%s.change_%s' % (app_label, model.__name__)\n    # check only model\n    if not request.user.has_perm(perm_str.lower()):\n        raise PermissionDenied\n\n    setattr(object, field, getattr(object, field) == 0)\n    object.save()\n\n    if request.is_ajax():\n        return JsonResponse({'object_id': object.pk, 'field': field, 'value': getattr(object, field)})\n    else:\n        msg = _(u'flag %(field)s was changed for %(object)s') % {'field': field, 'object': object}\n        messages.success(request, msg)\n        return HttpResponseRedirect(request.META.get('HTTP_REFERER', '/'))", "response": "Switches the value of the object in the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fit(\n        self,\n        df,\n        similarity_type=\"jaccard\",\n        time_decay_coefficient=30,\n        time_now=None,\n        timedecay_formula=False,\n        threshold=1,\n    ):\n        \"\"\"Main fit method for SAR. Expects the dataframes to have row_id, col_id columns which are indexes,\n        i.e. contain the sequential integer index of the original alphanumeric user and item IDs.\n        Dataframe also contains rating and timestamp as floats; timestamp is in seconds since Epoch by default.\n\n        Arguments:\n            df (pySpark.DataFrame): input dataframe which contains the index of users and items. \"\"\"\n\n        # threshold - items below this number get set to zero in coocurrence counts\n        assert threshold > 0\n\n        df.createOrReplaceTempView(\"{prefix}df_train_input\".format(**self.header))\n\n        if timedecay_formula:\n            # WARNING: previously we would take the last value in training dataframe and set it\n            # as a matrix U element\n            # for each user-item pair. Now with time decay, we compute a sum over ratings given\n            # by a user in the case\n            # when T=np.inf, so user gets a cumulative sum of ratings for a particular item and\n            # not the last rating.\n            # Time Decay\n            # do a group by on user item pairs and apply the formula for time decay there\n            # Time T parameter is in days and input time is in seconds\n            # so we do dt/60/(T*24*60)=dt/(T*24*3600)\n            # the folling is the query which we want to run\n\n            query = self.f(\n            \"\"\"\n            SELECT\n                 {col_user}, {col_item}, \n                 SUM({col_rating} * EXP(-log(2) * (latest_timestamp - CAST({col_timestamp} AS long)) / ({time_decay_coefficient} * 3600 * 24))) as {col_rating}\n            FROM {prefix}df_train_input,\n                 (SELECT CAST(MAX({col_timestamp}) AS long) latest_timestamp FROM {prefix}df_train_input)\n            GROUP BY {col_user}, {col_item} \n            CLUSTER BY {col_user} \n            \"\"\",\n                time_now=time_now,\n                time_decay_coefficient=time_decay_coefficient,\n            )\n\n            # replace with timedecayed version\n            df = self.spark.sql(query)\n        else:\n            # since SQL is case insensitive, this check needs to be performed similar\n            if self.header['col_timestamp'].lower() in [s.name.lower() for s in df.schema]:\n                # we need to de-duplicate items by using the latest item\n                query = self.f(\n                \"\"\"\n                SELECT {col_user}, {col_item}, {col_rating}\n                FROM\n                (\n                SELECT\n                    {col_user}, {col_item}, {col_rating}, \n                    ROW_NUMBER() OVER (PARTITION BY {col_user}, {col_item} ORDER BY {col_timestamp} DESC) latest\n                FROM {prefix}df_train_input\n                )\n                WHERE latest = 1\n                \"\"\"\n                )\n                \n                df = self.spark.sql(query)\n\n        df.createOrReplaceTempView(self.f(\"{prefix}df_train\"))\n\n        log.info(\"sarplus.fit 1/2: compute item cooccurences...\")\n\n        # compute cooccurrence above minimum threshold\n        query = self.f(\n            \"\"\"\n        SELECT A.{col_item} i1, B.{col_item} i2, COUNT(*) value\n        FROM   {prefix}df_train A INNER JOIN {prefix}df_train B\n               ON A.{col_user} = B.{col_user} AND A.{col_item} <= b.{col_item}  \n        GROUP  BY A.{col_item}, B.{col_item}\n        HAVING COUNT(*) >= {threshold}\n        CLUSTER BY i1, i2\n        \"\"\",\n            threshold=threshold,\n        )\n\n        item_cooccurrence = self.spark.sql(query)\n        item_cooccurrence.write.mode(\"overwrite\").saveAsTable(\n            self.f(\"{prefix}item_cooccurrence\")\n        )\n\n        # compute the diagonal used later for Jaccard and Lift\n        if similarity_type == SIM_LIFT or similarity_type == SIM_JACCARD:\n            item_marginal = self.spark.sql(\n                self.f(\n                    \"SELECT i1 i, value AS margin FROM {prefix}item_cooccurrence WHERE i1 = i2\"\n                )\n            )\n            item_marginal.createOrReplaceTempView(self.f(\"{prefix}item_marginal\"))\n\n        if similarity_type == SIM_COOCCUR:\n            self.item_similarity = item_cooccurrence\n        elif similarity_type == SIM_JACCARD:\n            query = self.f(\n            \"\"\"\n            SELECT i1, i2, value / (M1.margin + M2.margin - value) AS value\n            FROM {prefix}item_cooccurrence A \n                INNER JOIN {prefix}item_marginal M1 ON A.i1 = M1.i \n                INNER JOIN {prefix}item_marginal M2 ON A.i2 = M2.i\n            CLUSTER BY i1, i2\n            \"\"\"\n            )\n            self.item_similarity = self.spark.sql(query)\n        elif similarity_type == SIM_LIFT:\n            query = self.f(\n            \"\"\"\n            SELECT i1, i2, value / (M1.margin * M2.margin) AS value\n            FROM {prefix}item_cooccurrence A \n                INNER JOIN {prefix}item_marginal M1 ON A.i1 = M1.i \n                INNER JOIN {prefix}item_marginal M2 ON A.i2 = M2.i\n            CLUSTER BY i1, i2\n            \"\"\"\n            )\n            self.item_similarity = self.spark.sql(query)\n        else:\n            raise ValueError(\"Unknown similarity type: {0}\".format(similarity_type))\n\n\n        # store upper triangular\n        log.info(\"sarplus.fit 2/2: compute similiarity metric %s...\" % similarity_type)\n        self.item_similarity.write.mode(\"overwrite\").saveAsTable(\n            self.f(\"{prefix}item_similarity_upper\")\n        )\n\n        # expand upper triangular to full matrix\n\n        query = self.f(\n        \"\"\"\n        SELECT i1, i2, value\n        FROM\n        (\n          (SELECT i1, i2, value FROM {prefix}item_similarity_upper)\n          UNION ALL\n          (SELECT i2 i1, i1 i2, value FROM {prefix}item_similarity_upper WHERE i1 <> i2)\n        )\n        CLUSTER BY i1\n        \"\"\"\n        )\n\n        self.item_similarity = self.spark.sql(query)\n        self.item_similarity.write.mode(\"overwrite\").saveAsTable(\n            self.f(\"{prefix}item_similarity\")\n        )\n\n        # free space\n        self.spark.sql(self.f(\"DROP TABLE {prefix}item_cooccurrence\"))\n        self.spark.sql(self.f(\"DROP TABLE {prefix}item_similarity_upper\"))\n\n        self.item_similarity = self.spark.table(self.f(\"{prefix}item_similarity\"))", "response": "Fits the model to obtain the user - item pair and ratings for the user and item pair."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting all users in the test set that have seen in the past.", "response": "def get_user_affinity(self, test):\n        \"\"\"Prepare test set for C++ SAR prediction code.\n        Find all items the test users have seen in the past.\n\n        Arguments:\n            test (pySpark.DataFrame): input dataframe which contains test users.\n        \"\"\"\n        test.createOrReplaceTempView(self.f(\"{prefix}df_test\"))\n\n        query = self.f(\n            \"SELECT DISTINCT {col_user} FROM {prefix}df_test CLUSTER BY {col_user}\"\n        )\n\n        df_test_users = self.spark.sql(query)\n        df_test_users.write.mode(\"overwrite\").saveAsTable(\n            self.f(\"{prefix}df_test_users\")\n        )\n\n        query = self.f(\n        \"\"\"\n          SELECT a.{col_user}, a.{col_item}, CAST(a.{col_rating} AS double) {col_rating}\n          FROM {prefix}df_train a INNER JOIN {prefix}df_test_users b ON a.{col_user} = b.{col_user} \n          DISTRIBUTE BY {col_user}\n          SORT BY {col_user}, {col_item}          \n        \"\"\"\n        )\n\n        return self.spark.sql(query)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrecommending top K items for all users which are in the test set.", "response": "def recommend_k_items_slow(self, test, top_k=10, remove_seen=True):\n        \"\"\"Recommend top K items for all users which are in the test set.\n\n        Args:\n            test: test Spark dataframe\n            top_k: top n items to return\n            remove_seen: remove items test users have already seen in the past from the recommended set.\n        \"\"\"\n\n        # TODO: remove seen\n        if remove_seen:\n            raise ValueError(\"Not implemented\")\n\n        self.get_user_affinity(test)\\\n            .write.mode(\"overwrite\")\\\n            .saveAsTable(self.f(\"{prefix}user_affinity\"))\n\n        # user_affinity * item_similarity\n        # filter top-k\n        query = self.f(\n            \"\"\"\n        SELECT {col_user}, {col_item}, score\n        FROM\n        (\n          SELECT df.{col_user},\n                 S.i2 {col_item},\n                 SUM(df.{col_rating} * S.value) AS score,\n                 row_number() OVER(PARTITION BY {col_user} ORDER BY SUM(df.{col_rating} * S.value) DESC) rank\n          FROM   \n            {prefix}user_affinity df, \n            {prefix}item_similarity S\n          WHERE df.{col_item} = S.i1\n          GROUP BY df.{col_user}, S.i2\n        )\n        WHERE rank <= {top_k} \n        \"\"\",\n            top_k=top_k,\n        )\n\n        return self.spark.sql(query)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsend the given command thru the websocket", "response": "def send(self, cmd):\n        \"\"\"Send the given command thru the websocket\"\"\"\n        with self.ws_sendlock:\n            self.ws.send(json.dumps(cmd))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsubscribe to a stream and optionally a transform", "response": "def subscribe(self, stream, callback, transform=\"\"):\n        \"\"\"Given a stream, a callback and an optional transform, sets up the subscription\"\"\"\n        if self.status == \"disconnected\" or self.status == \"disconnecting\" or self.status == \"connecting\":\n            self.connect()\n        if self.status is not \"connected\":\n            return False\n        logging.debug(\"Subscribing to %s\", stream)\n\n        self.send({\"cmd\": \"subscribe\", \"arg\": stream, \"transform\": transform})\n        with self.subscription_lock:\n            self.subscriptions[stream + \":\" + transform] = callback\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef unsubscribe(self, stream, transform=\"\"):\n        if self.status is not \"connected\":\n            return False\n        logging.debug(\"Unsubscribing from %s\", stream)\n        self.send(\n            {\"cmd\": \"unsubscribe\",\n             \"arg\": stream,\n             \"transform\": transform})\n\n        self.subscription_lock.acquire()\n        del self.subscriptions[stream + \":\" + transform]\n        if len(self.subscriptions) is 0:\n            self.subscription_lock.release()\n            self.disconnect()\n        else:\n            self.subscription_lock.release()", "response": "Unsubscribe from the given stream."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nattempt to connect to the websocket - and returns either True or False depending on if the connection was successful or not", "response": "def connect(self):\n        \"\"\"Attempt to connect to the websocket - and returns either True or False depending on if\n        the connection was successful or not\"\"\"\n\n        # Wait for the lock to be available (ie, the websocket is not being used (yet))\n        self.ws_openlock.acquire()\n        self.ws_openlock.release()\n\n        if self.status == \"connected\":\n            return True  # Already connected\n        if self.status == \"disconnecting\":\n            # If currently disconnecting, wait a moment, and retry connect\n            time.sleep(0.1)\n            return self.connect()\n        if self.status == \"disconnected\" or self.status == \"reconnecting\":\n            self.ws = websocket.WebSocketApp(self.ws_url,\n                                             header=self.headers,\n                                             on_message=self.__on_message,\n                                             on_ping=self.__on_ping,\n                                             on_open=self.__on_open,\n                                             on_close=self.__on_close,\n                                             on_error=self.__on_error)\n            self.ws_thread = threading.Thread(target=self.ws.run_forever)\n            self.ws_thread.daemon = True\n\n            self.status = \"connecting\"\n            self.ws_openlock.acquire()\n            self.ws_thread.start()\n\n        self.ws_openlock.acquire()\n        self.ws_openlock.release()\n\n        return self.status == \"connected\""}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef __reconnect(self):\n        self.status = \"reconnecting\"\n\n        # Reset the disconnect time after 15 minutes\n        if self.disconnected_time - self.connected_time > 15 * 60:\n            self.reconnect_time = self.reconnect_time_starting_seconds\n        else:\n            self.reconnect_time *= self.reconnect_time_backoff_multiplier\n\n        if self.reconnect_time > self.reconnect_time_max_seconds:\n            self.reconnect_time = self.reconnect_time_max_seconds\n\n        # We want to add some randomness to the reconnect rate - necessary so that we don't pound the server\n        # if it goes down\n        self.reconnect_time *= 1 + random.uniform(-0.2, 0.2)\n\n        if self.reconnect_time < self.reconnect_time_starting_seconds:\n            self.reconnect_time = self.reconnect_time_starting_seconds\n\n        logging.warn(\"ConnectorDB:WS: Attempting to reconnect in %fs\",\n                     self.reconnect_time)\n\n        self.reconnector = threading.Timer(self.reconnect_time,\n                                           self.__reconnect_fnc)\n        self.reconnector.daemon = True\n        self.reconnector.start()", "response": "This method is called when a connection is lost - it attempts to reconnect to the server"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __resubscribe(self):\n        with self.subscription_lock:\n            for sub in self.subscriptions:\n                logging.debug(\"Resubscribing to %s\", sub)\n                stream_transform = sub.split(\":\", 1)\n                self.send({\n                    \"cmd\": \"subscribe\",\n                    \"arg\": stream_transform[0],\n                    \"transform\": stream_transform[1]\n                })", "response": "Send subscribe command for all existing subscriptions. This allows to resume a connection that was closed."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __on_open(self, ws):\n        logging.debug(\"ConnectorDB: Websocket opened\")\n\n        # Connection success - decrease the wait time for next connection\n        self.reconnect_time /= self.reconnect_time_backoff_multiplier\n\n        self.status = \"connected\"\n\n        self.lastpingtime = time.time()\n        self.__ensure_ping()\n\n        self.connected_time = time.time()\n\n        # Release the lock that connect called\n        self.ws_openlock.release()", "response": "Called when the websocket is opened"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __on_close(self, ws):\n        if self.status == \"disconnected\":\n            return  # This can be double-called on disconnect\n        logging.debug(\"ConnectorDB:WS: Websocket closed\")\n\n        # Turn off the ping timer\n        if self.pingtimer is not None:\n            self.pingtimer.cancel()\n\n        self.disconnected_time = time.time()\n        if self.status == \"disconnecting\":\n            self.status = \"disconnected\"\n        elif self.status == \"connected\":\n            self.__reconnect()", "response": "Called when the websocket is closed"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalls when an error occurs in the websocket connection", "response": "def __on_error(self, ws, err):\n        \"\"\"Called when there is an error in the websocket\"\"\"\n        logging.debug(\"ConnectorDB:WS: Connection Error\")\n\n        if self.status == \"connecting\":\n            self.status = \"errored\"\n            self.ws_openlock.release()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __on_ping(self, ws, data):\n        logging.debug(\"ConnectorDB:WS: ping\")\n        self.lastpingtime = time.time()", "response": "This function is called when a websocket ping is received."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __ensure_ping(self):\n\n        logging.debug(\"ConnectorDB:WS: pingcheck\")\n        if (time.time() - self.lastpingtime > self.connection_ping_timeout):\n            logging.warn(\"ConnectorDB:WS: Websocket ping timed out!\")\n            if self.ws is not None:\n                self.ws.close()\n                self.__on_close(self.ws)\n        else:\n            # reset the ping timer\n            self.pingtimer = threading.Timer(self.connection_ping_timeout,\n                                             self.__ensure_ping)\n            self.pingtimer.daemon = True\n            self.pingtimer.start()", "response": "Ensure that the connection is still alive."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nisolates a particular variant type from a VCF file using GATK SelectVariants :param JobFunctionWrappingJob job: passed automatically by Toil :param str mode: variant type (i.e. SNP or INDEL) :param str vcf_id: FileStoreID for input VCF file :param str ref_fasta: FileStoreID for reference genome fasta :param str ref_fai: FileStoreID for reference genome index file :param str ref_dict: FileStoreID for reference genome sequence dictionary file :return: FileStoreID for filtered VCF :rtype: str", "response": "def gatk_select_variants(job, mode, vcf_id, ref_fasta, ref_fai, ref_dict):\n    \"\"\"\n    Isolates a particular variant type from a VCF file using GATK SelectVariants\n\n    :param JobFunctionWrappingJob job: passed automatically by Toil\n    :param str mode: variant type (i.e. SNP or INDEL)\n    :param str vcf_id: FileStoreID for input VCF file\n    :param str ref_fasta: FileStoreID for reference genome fasta\n    :param str ref_fai: FileStoreID for reference genome index file\n    :param str ref_dict: FileStoreID for reference genome sequence dictionary file\n    :return: FileStoreID for filtered VCF\n    :rtype: str\n    \"\"\"\n    job.fileStore.logToMaster('Running GATK SelectVariants to select %ss' % mode)\n\n    inputs = {'genome.fa': ref_fasta,\n              'genome.fa.fai': ref_fai,\n              'genome.dict': ref_dict,\n              'input.vcf': vcf_id}\n\n    work_dir = job.fileStore.getLocalTempDir()\n    for name, file_store_id in inputs.iteritems():\n        job.fileStore.readGlobalFile(file_store_id, os.path.join(work_dir, name))\n\n    command = ['-T', 'SelectVariants',\n               '-R', 'genome.fa',\n               '-V', 'input.vcf',\n               '-o', 'output.vcf',\n               '-selectType', mode]\n\n    docker_parameters = ['--rm', 'log-driver', 'none',\n                         '-e', 'JAVA_OPTS=-Djava.io.tmpdir=/data/ -Xmx{}'.format(job.memory)]\n    dockerCall(job=job, workDir=work_dir,\n               parameters=command,\n               tool='quay.io/ucsc_cgl/gatk:3.5--dba6dae49156168a909c43330350c6161dc7ecc2',\n               dockerParameters=docker_parameters)\n\n    return job.fileStore.writeGlobalFile(os.path.join(work_dir, 'output.vcf'))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef gatk_variant_filtration(job, vcf_id, filter_name, filter_expression, ref_fasta, ref_fai, ref_dict):\n    inputs = {'genome.fa': ref_fasta,\n              'genome.fa.fai': ref_fai,\n              'genome.dict': ref_dict,\n              'input.vcf': vcf_id}\n\n    work_dir = job.fileStore.getLocalTempDir()\n    for name, file_store_id in inputs.iteritems():\n        job.fileStore.readGlobalFile(file_store_id, os.path.join(work_dir, name))\n\n    command = ['-T', 'VariantFiltration',\n               '-R', 'genome.fa',\n               '-V', 'input.vcf',\n               '--filterName', filter_name,   # Documents filter name in header\n               '--filterExpression', filter_expression,\n               '-o', 'filtered_variants.vcf']\n\n    job.fileStore.logToMaster('Running GATK VariantFiltration using {name}: '\n                              '{expression}'.format(name=filter_name, expression=filter_expression))\n\n    docker_parameters = ['--rm', 'log-driver', 'none',\n                         '-e', 'JAVA_OPTS=-Djava.io.tmpdir=/data/ -Xmx{}'.format(job.memory)]\n    dockerCall(job=job, workDir=work_dir,\n               parameters=command,\n               tool='quay.io/ucsc_cgl/gatk:3.5--dba6dae49156168a909c43330350c6161dc7ecc2',\n               dockerParameters=docker_parameters)\n\n    # Remove extra quotation marks around filter expression.\n    malformed_header = os.path.join(work_dir, 'filtered_variants.vcf')\n    fixed_header = os.path.join(work_dir, 'fixed_header.vcf')\n    filter_regex = re.escape('\"%s\"' % filter_expression)\n    with open(malformed_header, 'r') as f, open(fixed_header, 'w') as g:\n        for line in f:\n            g.write(re.sub(filter_regex, filter_expression, line))\n\n    return job.fileStore.writeGlobalFile(fixed_header)", "response": "This function filters a VCF file using GATK VariantFiltration."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef gatk_variant_recalibrator(job,\n                              mode,\n                              vcf,\n                              ref_fasta, ref_fai, ref_dict,\n                              annotations,\n                              hapmap=None, omni=None, phase=None, dbsnp=None, mills=None,\n                              max_gaussians=4,\n                              unsafe_mode=False):\n    \"\"\"\n    Runs either SNP or INDEL variant quality score recalibration using GATK VariantRecalibrator. Because the VQSR method\n    models SNPs and INDELs differently, VQSR must be run separately for these variant types.\n\n    :param JobFunctionWrappingJob job: passed automatically by Toil\n    :param str mode: Determines variant recalibration mode (SNP or INDEL)\n    :param str vcf: FileStoreID for input VCF file\n    :param str ref_fasta: FileStoreID for reference genome fasta\n    :param str ref_fai: FileStoreID for reference genome index file\n    :param str ref_dict: FileStoreID for reference genome sequence dictionary file\n    :param list[str] annotations: List of GATK variant annotations to filter on\n    :param str hapmap: FileStoreID for HapMap resource file, required for SNP VQSR\n    :param str omni: FileStoreID for Omni resource file, required for SNP VQSR\n    :param str phase: FileStoreID for 1000G resource file, required for SNP VQSR\n    :param str dbsnp: FilesStoreID for dbSNP resource file, required for SNP and INDEL VQSR\n    :param str mills: FileStoreID for Mills resource file, required for INDEL VQSR\n    :param int max_gaussians: Number of Gaussians used during training, default is 4\n    :param bool unsafe_mode: If True, runs gatk UNSAFE mode: \"-U ALLOW_SEQ_DICT_INCOMPATIBILITY\"\n    :return: FileStoreID for the variant recalibration table, tranche file, and plots file\n    :rtype: tuple\n    \"\"\"\n    mode = mode.upper()\n\n    inputs = {'genome.fa': ref_fasta,\n              'genome.fa.fai': ref_fai,\n              'genome.dict': ref_dict,\n              'input.vcf': vcf}\n\n    # Refer to GATK documentation for description of recommended parameters:\n    # https://software.broadinstitute.org/gatk/documentation/article?id=1259\n    # https://software.broadinstitute.org/gatk/documentation/article?id=2805\n\n    # This base command includes parameters for both INDEL and SNP VQSR.\n    command = ['-T', 'VariantRecalibrator',\n               '-R', 'genome.fa',\n               '-input', 'input.vcf',\n               '-tranche', '100.0',\n               '-tranche', '99.9',\n               '-tranche', '99.0',\n               '-tranche', '90.0',\n               '--maxGaussians', str(max_gaussians),\n               '-recalFile', 'output.recal',\n               '-tranchesFile', 'output.tranches',\n               '-rscriptFile', 'output.plots.R']\n\n    # Parameters and resource files for SNP VQSR.\n    if mode == 'SNP':\n        command.extend(\n            ['-resource:hapmap,known=false,training=true,truth=true,prior=15.0', 'hapmap.vcf',\n             '-resource:omni,known=false,training=true,truth=true,prior=12.0', 'omni.vcf',\n             '-resource:dbsnp,known=true,training=false,truth=false,prior=2.0', 'dbsnp.vcf',\n             '-resource:1000G,known=false,training=true,truth=false,prior=10.0', '1000G.vcf',\n             '-mode', 'SNP'])\n\n        inputs['hapmap.vcf'] = hapmap\n        inputs['omni.vcf'] = omni\n        inputs['dbsnp.vcf'] = dbsnp\n        inputs['1000G.vcf'] = phase\n\n    # Parameters and resource files for INDEL VQSR\n    elif mode == 'INDEL':\n        command.extend(\n            ['-resource:mills,known=false,training=true,truth=true,prior=12.0', 'mills.vcf',\n             '-resource:dbsnp,known=true,training=false,truth=false,prior=2.0', 'dbsnp.vcf',\n             '-mode', 'INDEL'])\n\n        inputs['mills.vcf'] = mills\n        inputs['dbsnp.vcf'] = dbsnp\n\n    else:\n        raise ValueError('Variant filter modes can be SNP or INDEL, got %s' % mode)\n\n    for annotation in annotations:\n        command.extend(['-an', annotation])\n\n    if unsafe_mode:\n        command.extend(['-U', 'ALLOW_SEQ_DICT_INCOMPATIBILITY'])\n\n    # Delay reading in files until function is configured\n    work_dir = job.fileStore.getLocalTempDir()\n    for name, file_store_id in inputs.iteritems():\n        job.fileStore.readGlobalFile(file_store_id, os.path.join(work_dir, name))\n\n    job.fileStore.logToMaster('Running GATK VariantRecalibrator on {mode}s using the following annotations:\\n'\n                              '{annotations}'.format(mode=mode, annotations='\\n'.join(annotations)))\n\n    docker_parameters = ['--rm', 'log-driver', 'none',\n                         '-e', 'JAVA_OPTS=-Djava.io.tmpdir=/data/ -Xmx{}'.format(job.memory)]\n    dockerCall(job=job, workDir=work_dir,\n               parameters=command,\n               tool='quay.io/ucsc_cgl/gatk:3.5--dba6dae49156168a909c43330350c6161dc7ecc2',\n               dockerParameters=docker_parameters)\n\n    recal_id = job.fileStore.writeGlobalFile(os.path.join(work_dir, 'output.recal'))\n    tranches_id = job.fileStore.writeGlobalFile(os.path.join(work_dir, 'output.tranches'))\n    plots_id = job.fileStore.writeGlobalFile(os.path.join(work_dir, 'output.plots.R'))\n    return recal_id, tranches_id, plots_id", "response": "This function runs either SNP or INDEL variant recalibration using GATK VariantRecalibrator."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef gatk_apply_variant_recalibration(job,\n                                     mode,\n                                     vcf,\n                                     recal_table, tranches,\n                                     ref_fasta, ref_fai, ref_dict,\n                                     ts_filter_level=99.0,\n                                     unsafe_mode=False):\n    \"\"\"\n    Applies variant quality score recalibration to VCF file using GATK ApplyRecalibration\n\n    :param JobFunctionWrappingJob job: passed automatically by Toil\n    :param str mode: Determines variant recalibration mode (SNP or INDEL)\n    :param str vcf: FileStoreID for input VCF file\n    :param str recal_table: FileStoreID for recalibration table file\n    :param str tranches: FileStoreID for tranches file\n    :param str ref_fasta: FileStoreID for reference genome fasta\n    :param str ref_fai: FileStoreID for reference genome index file\n    :param str ref_dict: FileStoreID for reference genome sequence dictionary file\n    :param float ts_filter_level: Sensitivity expressed as a percentage, default is 99.0\n    :param bool unsafe_mode: If True, runs gatk UNSAFE mode: \"-U ALLOW_SEQ_DICT_INCOMPATIBILITY\"\n    :return: FileStoreID for recalibrated VCF file\n    :rtype: str\n    \"\"\"\n    inputs = {'genome.fa': ref_fasta,\n              'genome.fa.fai': ref_fai,\n              'genome.dict': ref_dict,\n              'input.vcf': vcf,\n              'recal': recal_table,\n              'tranches': tranches}\n\n    work_dir = job.fileStore.getLocalTempDir()\n    for name, file_store_id in inputs.iteritems():\n        job.fileStore.readGlobalFile(file_store_id, os.path.join(work_dir, name))\n\n    mode = mode.upper()\n\n    # GATK recommended parameters:\n    # https://software.broadinstitute.org/gatk/documentation/article?id=2805\n    command = ['-T', 'ApplyRecalibration',\n               '-mode', mode,\n               '-R', 'genome.fa',\n               '-input', 'input.vcf',\n               '-o', 'vqsr.vcf',\n               '-ts_filter_level', str(ts_filter_level),\n               '-recalFile', 'recal',\n               '-tranchesFile', 'tranches']\n\n    if unsafe_mode:\n        command.extend(['-U', 'ALLOW_SEQ_DICT_INCOMPATIBILITY'])\n\n    job.fileStore.logToMaster('Running GATK ApplyRecalibration on {mode}s '\n                              'with a sensitivity of {sensitivity}%'.format(mode=mode,\n                                                                            sensitivity=ts_filter_level))\n    docker_parameters = ['--rm', 'log-driver', 'none',\n                         '-e', 'JAVA_OPTS=-Djava.io.tmpdir=/data/ -Xmx{}'.format(job.memory)]\n    dockerCall(job=job, workDir=work_dir,\n               parameters=command,\n               tool='quay.io/ucsc_cgl/gatk:3.5--dba6dae49156168a909c43330350c6161dc7ecc2',\n               dockerParameters=docker_parameters)\n\n    return job.fileStore.writeGlobalFile(os.path.join(work_dir, 'vqsr.vcf'))", "response": "Applies the recalibration to the VCF file using GATK ApplyRecalibration\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef gatk_combine_variants(job, vcfs, ref_fasta, ref_fai, ref_dict, merge_option='UNIQUIFY'):\n    job.fileStore.logToMaster('Running GATK CombineVariants')\n\n    inputs = {'genome.fa': ref_fasta,\n              'genome.fa.fai': ref_fai,\n              'genome.dict': ref_dict}\n    inputs.update(vcfs)\n\n    work_dir = job.fileStore.getLocalTempDir()\n    for name, file_store_id in inputs.iteritems():\n        job.fileStore.readGlobalFile(file_store_id, os.path.join(work_dir, name))\n\n    command = ['-T', 'CombineVariants',\n               '-R', '/data/genome.fa',\n               '-o', '/data/merged.vcf',\n               '--genotypemergeoption', merge_option]\n\n    for uuid, vcf_id in vcfs.iteritems():\n        command.extend(['--variant', os.path.join('/data', uuid)])\n\n    docker_parameters = ['--rm', 'log-driver', 'none',\n                         '-e', 'JAVA_OPTS=-Djava.io.tmpdir=/data/ -Xmx{}'.format(job.memory)]\n    dockerCall(job=job, workDir=work_dir,\n               parameters=command,\n               tool='quay.io/ucsc_cgl/gatk:3.5--dba6dae49156168a909c43330350c6161dc7ecc2',\n               dockerParameters=docker_parameters)\n\n    return job.fileStore.writeGlobalFile(os.path.join(work_dir, 'merged.vcf'))", "response": "This function will combine the VCF files of a single site into a single variant record."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef bam_quickcheck(bam_path):\n    directory, bam_name = os.path.split(bam_path)\n    exit_code = subprocess.call(['docker', 'run', '-v', directory + ':/data',\n                                 'quay.io/ucsc_cgl/samtools:1.3--256539928ea162949d8a65ca5c79a72ef557ce7c',\n                                 'quickcheck', '-vv', '/data/' + bam_name])\n    if exit_code != 0:\n        return False\n    return True", "response": "Perform a quick check on a BAM file via samtools quickcheck."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load_handlers(handler_mapping):\n\n    handlers = {}\n\n    for packet_type, handler in handler_mapping.items():\n\n        if packet_type == '*':\n            Packet = packet_type\n        elif isinstance(packet_type, str):\n            Packet = importer(packet_type)\n        else:\n            Packet = packet_type\n\n        if isinstance(handler, str):\n            Handler = importer(handler)\n        else:\n            Handler = handler\n\n        if Packet in handlers:\n            raise HandlerConfigError(\n                \"Handler already provided for packet %s\" % Packet)\n\n        handlers[Packet] = Handler\n\n    return handlers", "response": "Load the handlers for a single object."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the configuration for this project from the default JSON file or writes one if it doesn t exist", "response": "def get_config():\n    \"\"\"Gets the configuration for this project from the default JSON file, or writes one if it doesn't exist\n\n    :rtype: dict\n    \"\"\"\n    if not os.path.exists(CONFIG_PATH):\n        write_config({})\n\n    with open(CONFIG_PATH) as f:\n        return json.load(f)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_ontology(self, ontology):\n        url = self.ontology_metadata_fmt.format(ontology=ontology)\n        response = requests.get(url)\n        return response.json()", "response": "Gets the metadata for a given ontology"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the data for a given term", "response": "def get_term(self, ontology, iri):\n        \"\"\"Gets the data for a given term\n\n        :param str ontology: The name of the ontology\n        :param str iri: The IRI of a term\n        :rtype: dict\n        \"\"\"\n        url = self.ontology_term_fmt.format(ontology, iri)\n        response = requests.get(url)\n\n        return response.json()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsearch the OLS with the given term name", "response": "def search(self, name, query_fields=None):\n        \"\"\"Searches the OLS with the given term\n\n        :param str name:\n        :param list[str] query_fields: Fields to query\n        :return: dict\n        \"\"\"\n        params = {'q': name}\n        if query_fields is not None:\n            params['queryFields'] = '{{{}}}'.format(','.join(query_fields))\n        response = requests.get(self.ontology_search, params=params)\n\n        return response.json()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsuggest terms from an optional list of ontologies", "response": "def suggest(self, name, ontology=None):\n        \"\"\"Suggest terms from an optional list of ontologies\n\n        :param str name:\n        :param list[str] ontology:\n        :rtype: dict\n\n        .. seealso:: https://www.ebi.ac.uk/ols/docs/api#_suggest_term\n        \"\"\"\n        params = {'q': name}\n        if ontology:\n            params['ontology'] = ','.join(ontology)\n        response = requests.get(self.ontology_suggest, params=params)\n\n        return response.json()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _iter_terms_helper(url, size=None, sleep=None):\n        if size is None:\n            size = 500\n        elif size > 500:\n            raise ValueError('Maximum size is 500. Given: {}'.format(size))\n\n        t = time.time()\n        response = requests.get(url, params={'size': size}).json()\n        links = response['_links']\n\n        for response_term in _iterate_response_terms(response):\n            yield response_term\n\n        t = time.time() - t\n\n        log.info(\n            'Page %s/%s done in %.2f seconds',\n            response['page']['number'] + 1,\n            response['page']['totalPages'],\n            t\n        )\n\n        log.info('Estimated time until done: %.2f minutes', t * response['page']['totalPages'] / 60)\n\n        while 'next' in links:\n            if sleep:\n                time.sleep(sleep)\n\n            t = time.time()\n            response = requests.get(links['next']['href'], params={'size': size}).json()\n            links = response['_links']\n\n            for response_term in _iterate_response_terms(response):\n                yield response_term\n\n            log.info(\n                'Page %s/%s done in %.2f seconds',\n                response['page']['number'],\n                response['page']['totalPages'],\n                time.time() - t\n            )", "response": "Iterates over all terms lazily with paging"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef iter_terms(self, ontology, size=None, sleep=None):\n        url = self.ontology_terms_fmt.format(ontology=ontology)\n        for term in self._iter_terms_helper(url, size=size, sleep=sleep):\n            yield term", "response": "Iterates over all terms in the ontology."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef iter_descendants(self, ontology, iri, size=None, sleep=None):\n        url = self.ontology_term_descendants_fmt.format(ontology=ontology, iri=iri)\n        log.info('getting %s', url)\n        for term in self._iter_terms_helper(url, size=size, sleep=sleep):\n            yield term", "response": "Iterates over the descendants of a given term."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\niterates over the labels for the descendants of a given termata.", "response": "def iter_descendants_labels(self, ontology, iri, size=None, sleep=None):\n        \"\"\"Iterates over the labels for the descendants of a given term\n\n        :param str ontology: The name of the ontology\n        :param str iri: The IRI of a term\n        :param int size: The size of each page. Defaults to 500, which is the maximum allowed by the EBI.\n        :param int sleep: The amount of time to sleep between pages. Defaults to 0 seconds.\n        :rtype: iter[str]\n        \"\"\"\n        for label in _help_iterate_labels(self.iter_descendants(ontology, iri, size=size, sleep=sleep)):\n            yield label"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\niterate over the labels of terms in the ontology. Automatically wraps the pager returned by the OLS.", "response": "def iter_labels(self, ontology, size=None, sleep=None):\n        \"\"\"Iterates over the labels of terms in the ontology. Automatically wraps the pager returned by the OLS.\n\n        :param str ontology: The name of the ontology\n        :param int size: The size of each page. Defaults to 500, which is the maximum allowed by the EBI.\n        :param int sleep: The amount of time to sleep between pages. Defaults to 0 seconds.\n        :rtype: iter[str]\n        \"\"\"\n        for label in _help_iterate_labels(self.iter_terms(ontology=ontology, size=size, sleep=sleep)):\n            yield label"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef iter_hierarchy(self, ontology, size=None, sleep=None):\n        for term in self.iter_terms(ontology=ontology, size=size, sleep=sleep):\n            try:\n                hierarchy_children_link = term['_links'][HIERARCHICAL_CHILDREN]['href']\n            except KeyError:  # there's no children for this one\n                continue\n\n            response = requests.get(hierarchy_children_link).json()\n\n            for child_term in response['_embedded']['terms']:\n                yield term['label'], child_term['label']", "response": "Iterates over parent - child relations of the given ontology."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrun Fastqc on the input reads and return the ID of the output file.", "response": "def run_fastqc(job, r1_id, r2_id):\n    \"\"\"\n    Run Fastqc on the input reads\n\n    :param JobFunctionWrappingJob job: passed automatically by Toil\n    :param str r1_id: FileStoreID of fastq read 1\n    :param str r2_id: FileStoreID of fastq read 2\n    :return: FileStoreID of fastQC output (tarball)\n    :rtype: str\n    \"\"\"\n    work_dir = job.fileStore.getLocalTempDir()\n    job.fileStore.readGlobalFile(r1_id, os.path.join(work_dir, 'R1.fastq'))\n    parameters = ['/data/R1.fastq']\n    output_names = ['R1_fastqc.html', 'R1_fastqc.zip']\n    if r2_id:\n        job.fileStore.readGlobalFile(r2_id, os.path.join(work_dir, 'R2.fastq'))\n        parameters.extend(['-t', '2', '/data/R2.fastq'])\n        output_names.extend(['R2_fastqc.html', 'R2_fastqc.zip'])\n    dockerCall(job=job, tool='quay.io/ucsc_cgl/fastqc:0.11.5--be13567d00cd4c586edf8ae47d991815c8c72a49',\n               workDir=work_dir, parameters=parameters)\n    output_files = [os.path.join(work_dir, x) for x in output_names]\n    tarball_files(tar_name='fastqc.tar.gz', file_paths=output_files, output_dir=work_dir)\n    return job.fileStore.writeGlobalFile(os.path.join(work_dir, 'fastqc.tar.gz'))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef addStream(self, stream, t1=None, t2=None, limit=None, i1=None, i2=None, transform=None):\r\n        params = query_maker(t1, t2, limit, i1, i2, transform)\r\n\r\n        params[\"stream\"] = get_stream(self.cdb, stream)\r\n\r\n        # Now add the stream to the query parameters\r\n        self.query.append(params)", "response": "Adds the given stream to the query construction. The function supports both stream\r\n        names and Stream objects. The function supports both stream\r\n        names and Stream objects."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_app(config=None):\n\n    # Initialise the app\n    from home.config import TEMPLATE_FOLDER, STATIC_FOLDER\n    app = Flask(__name__, static_folder=STATIC_FOLDER,\n                template_folder=TEMPLATE_FOLDER)\n\n    app.config['SECRET_KEY'] = 'ssh, its a secret.'\n\n    # Load the default config, the specified config file and then any\n    # overwrites that are manually passed in.\n    app.config.from_object('home.config')\n\n    if 'HOME_SETTINGS' in environ:\n        app.config.from_envvar('HOME_SETTINGS')\n\n    app.config.from_object(config)\n\n    # Register the web front end and the API.\n    from home.dash.web import web\n    from home.dash.api import api\n    app.register_blueprint(web)\n    app.register_blueprint(api, url_prefix='/api')\n\n    login_manager.init_app(app)\n    login_manager.login_view = 'Dashboard Web.login'\n\n    from home.dash.models import User\n\n    @login_manager.user_loader\n    def load_user(user_id):\n        return User.query.get(int(user_id))\n\n    # Initialise the migrations app, we want to store all migrations within\n    # the project directory for easier packaging.\n    Migrate(app, db, directory=app.config['MIGRATE_DIRECTORY'])\n\n    admin = Admin(app)\n\n    from home.dash.admin import setup_admin\n    setup_admin(admin)\n\n    # Wire up the database to the app so it gets the config.\n    db.init_app(app)\n\n    return app", "response": "Create an app that can be used to run the application."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef spawn_spark_cluster(job,\n                        numWorkers,\n                        cores=None,\n                        memory=None,\n                        disk=None,\n                        overrideLeaderIP=None):\n    '''\n    :param numWorkers: The number of worker nodes to have in the cluster. \\\n    Must be greater than or equal to 1.\n    :param cores: Optional parameter to set the number of cores per node. \\\n    If not provided, we use the number of cores on the node that launches \\\n    the service.\n    :param memory: Optional parameter to set the memory requested per node.\n    :param disk: Optional parameter to set the disk requested per node.\n    :type leaderMemory: int or string convertable by bd2k.util.humanize.human2bytes to an int\n    :type numWorkers: int\n    :type cores: int\n    :type memory: int or string convertable by bd2k.util.humanize.human2bytes to an int\n    :type disk: int or string convertable by bd2k.util.humanize.human2bytes to an int\n    '''\n\n    if numWorkers < 1:\n        raise ValueError(\"Must have more than one worker. %d given.\" % numWorkers)\n\n    leaderService = SparkService(cores=cores,\n                                 memory=memory,\n                                 disk=disk,\n                                 overrideLeaderIP=overrideLeaderIP)\n    leaderIP = job.addService(leaderService)\n    for i in range(numWorkers):\n        job.addService(WorkerService(leaderIP,\n                                     cores=cores,\n                                     disk=disk,\n                                     memory=memory),\n                       parentService=leaderService)\n\n    return leaderIP", "response": "Spawns a Spark cluster."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef start(self, job):\n\n        if self.hostname is None:\n            self.hostname = subprocess.check_output([\"hostname\", \"-f\",])[:-1]\n\n        _log.info(\"Started Spark master container.\")\n        self.sparkContainerID = dockerCheckOutput(job=job,\n                                                  defer=STOP,\n                                                  workDir=os.getcwd(),\n                                                  tool=\"quay.io/ucsc_cgl/apache-spark-master:1.5.2\",\n                                                  dockerParameters=[\"--net=host\",\n                                                                    \"-d\",\n                                                                    \"-v\", \"/mnt/ephemeral/:/ephemeral/:rw\",\n                                                                    \"-e\", \"SPARK_MASTER_IP=\" + self.hostname,\n                                                                    \"-e\", \"SPARK_LOCAL_DIRS=/ephemeral/spark/local\",\n                                                                    \"-e\", \"SPARK_WORKER_DIR=/ephemeral/spark/work\"],\n                                                  parameters=[self.hostname])[:-1]\n        _log.info(\"Started HDFS Datanode.\")\n        self.hdfsContainerID = dockerCheckOutput(job=job,\n                                           defer=STOP,\n                                           workDir=os.getcwd(),\n                                           tool=\"quay.io/ucsc_cgl/apache-hadoop-master:2.6.2\",\n                                           dockerParameters=[\"--net=host\",\n                                                              \"-d\"],\n                                           parameters=[self.hostname])[:-1]\n\n        return self.hostname", "response": "Start Spark master containers and HDFS master containers."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nstarts the HDFS and HDFS worker containers.", "response": "def start(self, job):\n        \"\"\"\n        Start spark and hdfs worker containers\n\n        :param job: The underlying job.\n        \"\"\"\n\n        # start spark and our datanode\n        self.sparkContainerID = dockerCheckOutput(job=job,\n                                                  defer=STOP,\n                                                  workDir=os.getcwd(),\n                                                  tool=\"quay.io/ucsc_cgl/apache-spark-worker:1.5.2\",\n                                                  dockerParameters=[\"--net=host\",\n                                                                    \"-d\",\n                                                                    \"-v\", \"/mnt/ephemeral/:/ephemeral/:rw\",\n                                                                    \"-e\",\n                                                                    \"\\\"SPARK_MASTER_IP=\" + self.masterIP + \":\" + _SPARK_MASTER_PORT + \"\\\"\",\n                                                                    \"-e\", \"SPARK_LOCAL_DIRS=/ephemeral/spark/local\",\n                                                                    \"-e\", \"SPARK_WORKER_DIR=/ephemeral/spark/work\"],\n                                                  parameters=[self.masterIP + \":\" + _SPARK_MASTER_PORT])[:-1]\n        self.__start_datanode(job)\n        \n        # fake do/while to check if HDFS is up\n        hdfs_down = True\n        retries = 0\n        while hdfs_down and (retries < 5):\n\n            _log.info(\"Sleeping 30 seconds before checking HDFS startup.\")\n            time.sleep(30)\n            clusterID = \"\"\n            try:\n                clusterID = subprocess.check_output([\"docker\",\n                                                     \"exec\",\n                                                     self.hdfsContainerID,\n                                                     \"grep\",\n                                                     \"clusterID\",\n                                                     \"-R\",\n                                                     \"/opt/apache-hadoop/logs\"])\n            except:\n                # grep returns a non-zero exit code if the pattern is not found\n                # we expect to not find the pattern, so a non-zero code is OK\n                pass\n\n            if \"Incompatible\" in clusterID:\n                _log.warning(\"Hadoop Datanode failed to start with: %s\", clusterID)\n                _log.warning(\"Retrying container startup, retry #%d.\", retries)\n                retries += 1\n\n                _log.warning(\"Removing ephemeral hdfs directory.\")\n                subprocess.check_call([\"docker\",\n                                       \"exec\",\n                                       self.hdfsContainerID,\n                                       \"rm\",\n                                       \"-rf\",\n                                       \"/ephemeral/hdfs\"])\n\n                _log.warning(\"Killing container %s.\", self.hdfsContainerID)\n                subprocess.check_call([\"docker\",\n                                       \"kill\",\n                                       self.hdfsContainerID])\n\n                # todo: this is copied code. clean up!\n                _log.info(\"Restarting datanode.\")\n                self.__start_datanode(job)\n\n            else:\n                _log.info(\"HDFS datanode started up OK!\")\n                hdfs_down = False\n\n        if retries >= 5:\n            raise RuntimeError(\"Failed %d times trying to start HDFS datanode.\" % retries)\n\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __start_datanode(self, job):\n        self.hdfsContainerID = dockerCheckOutput(job=job,\n                                                 defer=STOP,\n                                                 workDir=os.getcwd(),\n                                                 tool=\"quay.io/ucsc_cgl/apache-hadoop-worker:2.6.2\",\n                                                 dockerParameters=[\"--net=host\",\n                                                                    \"-d\",\n                                                                    \"-v\", \"/mnt/ephemeral/:/ephemeral/:rw\"],\n                                                 parameters=[self.masterIP])[:-1]", "response": "Starts the Hadoop datanode."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef stop(self, fileStore):\n\n        subprocess.call([\"docker\", \"exec\", self.sparkContainerID, \"rm\", \"-r\", \"/ephemeral/spark\"])\n        subprocess.call([\"docker\", \"stop\", self.sparkContainerID])\n        subprocess.call([\"docker\", \"rm\", self.sparkContainerID])\n        _log.info(\"Stopped Spark worker.\")\n\n        subprocess.call([\"docker\", \"exec\", self.hdfsContainerID, \"rm\", \"-r\", \"/ephemeral/hdfs\"])\n        subprocess.call([\"docker\", \"stop\", self.hdfsContainerID])\n        subprocess.call([\"docker\", \"rm\", self.hdfsContainerID])\n        _log.info(\"Stopped HDFS datanode.\")\n\n        return", "response": "Stop Spark and HDFS worker containers"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef check(self):\n\n        status = _checkContainerStatus(self.sparkContainerID,\n                                       self.hdfsContainerID,\n                                       sparkNoun='worker',\n                                       hdfsNoun='datanode')\n        \n        return status", "response": "Checks to see if Spark worker and HDFS datanode are still running."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_mint_tree(tokens_stream):\n    '''\n    This function is wrapper to normal parsers (tag_parser, block_parser, etc.).\n    Returns mint tree.\n    '''\n    smart_stack = RecursiveStack()\n    block_parser.parse(tokens_stream, smart_stack)\n    return MintTemplate(body=smart_stack.stack)", "response": "This function is wrapper to normal parsers ( tag_parser block_parser etc."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlook up a zone ID for a string.", "response": "def lookup_zone(conn, zone):\n  \"\"\"Look up a zone ID for a zone string.\n\n  Args: conn: boto.route53.Route53Connection\n        zone: string eg. foursquare.com\n  Returns: zone ID eg. ZE2DYFZDWGSL4.\n  Raises: ZoneNotFoundError if zone not found.\"\"\"\n  all_zones = conn.get_all_hosted_zones()\n  for resp in all_zones['ListHostedZonesResponse']['HostedZones']:\n    if resp['Name'].rstrip('.') == zone.rstrip('.'):\n      return resp['Id'].replace('/hostedzone/', '')\n  raise ZoneNotFoundError('zone %s not found in response' % zone)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fetch_config(zone, conn):\n  more_to_fetch = True\n  cfg_chunks = []\n  next_name = None\n  next_type = None\n  next_identifier = None\n  while more_to_fetch == True:\n    more_to_fetch = False\n    getstr = '/%s/hostedzone/%s/rrset' % (R53_API_VERSION, zone)\n    if next_name is not None:\n      getstr += '?name=%s&type=%s' % (next_name, next_type)\n      if next_identifier is not None:\n        getstr += '&identifier=%s' % next_identifier\n    log.debug('requesting %s' % getstr)\n    resp = conn.make_request('GET', getstr)\n    etree = lxml.etree.parse(resp)\n    cfg_chunks.append(etree)\n    root = etree.getroot()\n    truncated = root.find('{%s}IsTruncated' % R53_XMLNS)\n    if truncated is not None and truncated.text == 'true':\n      more_to_fetch = True\n      next_name = root.find('{%s}NextRecordName' % R53_XMLNS).text\n      next_type = root.find('{%s}NextRecordType' % R53_XMLNS).text\n      try:\n        next_identifier = root.find('{%s}NextRecordIdentifier' % R53_XMLNS).text\n      except AttributeError:  # may not have next_identifier\n        next_identifier = None\n  return cfg_chunks", "response": "Fetch all pieces of a Route 53 config from Amazon."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmerge a set of fetched Route 53 config Etrees into a canonical form.", "response": "def merge_config(cfg_chunks):\n  \"\"\"Merge a set of fetched Route 53 config Etrees into a canonical form.\n\n  Args: cfg_chunks: [ lxml.etree.ETree ]\n  Returns: lxml.etree.Element\"\"\"\n  root = lxml.etree.XML('<ResourceRecordSets xmlns=\"%s\"></ResourceRecordSets>' % R53_XMLNS, parser=XML_PARSER)\n  for chunk in cfg_chunks:\n    for rrset in chunk.iterfind('.//{%s}ResourceRecordSet' % R53_XMLNS):\n      root.append(rrset)\n  return root"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef normalize_rrs(rrsets):\n  for rrset in rrsets:\n    if rrset.tag == '{%s}ResourceRecordSet' % R53_XMLNS:\n      for rrs in rrset:\n        # preformat wildcard records\n        if rrs.tag == '{%s}Name' % R53_XMLNS:\n          if rrs.text.startswith('*.'):\n            old_text = rrs.text\n            new_text = '\\\\052.%s' % old_text[2:]\n            print 'Found wildcard record, rewriting to %s' % new_text\n            rrs.text = rrs.text.replace(old_text, new_text)\n        # sort ResourceRecord elements by Value\n        if rrs.tag == '{%s}ResourceRecords' % R53_XMLNS:\n          # 0th value of ResourceRecord is always the Value element\n          sorted_rrs = sorted(rrs, key=lambda x: x[0].text)\n          rrs[:] = sorted_rrs\n  return rrsets", "response": "Normalizes the order of every ResourceRecord in a ResourceRecords\n element so that the DNS line protocol does not have spurious changes."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nvalidating a changeset is compatible with Amazon s API spec.", "response": "def validate_changeset(changeset):\n  \"\"\"Validate a changeset is compatible with Amazon's API spec.\n\n  Args: changeset: lxml.etree.Element (<ChangeResourceRecordSetsRequest>)\n  Returns: [ errors ] list of error strings or [].\"\"\"\n  errors = []\n  changes = changeset.findall('.//{%s}Change' % R53_XMLNS)\n  num_changes = len(changes)\n  if num_changes == 0:\n    errors.append('changeset must have at least one <Change> element')\n  if num_changes > 100:\n    errors.append('changeset has %d <Change> elements: max is 100' % num_changes)\n  rrs = changeset.findall('.//{%s}ResourceRecord' % R53_XMLNS)\n  num_rrs = len(rrs)\n  if num_rrs > 1000:\n    errors.append('changeset has %d ResourceRecord elements: max is 1000' % num_rrs)\n  values = changeset.findall('.//{%s}Value' % R53_XMLNS)\n  num_chars = 0\n  for value in values:\n    num_chars += len(value.text)\n  if num_chars > 10000:\n    errors.append('changeset has %d chars in <Value> text: max is 10000' % num_chars)\n  return errors"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef minimize_best_n(Members):\n    '''\n    Orders population members from lowest fitness to highest fitness\n\n    Args:\n        Members (list): list of PyGenetics Member objects\n\n    Returns:\n        lsit: ordered lsit of Members, from highest fitness to lowest fitness\n    '''\n\n    return(list(reversed(sorted(\n        Members, key=lambda Member: Member.fitness_score\n    ))))", "response": "Returns the list of members in order of highest fitness to lowest fitness"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fitness(self):\n        '''Population fitness == average member fitness score'''\n\n        if len(self.__members) != 0:\n            if self.__num_processes > 1:\n                members = [m.get() for m in self.__members]\n            else:\n                members = self.__members\n            return sum(m.fitness_score for m in members) / len(members)\n        else:\n            return None", "response": "Population fitness == average member fitness score"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ave_cost_fn_val(self):\n        '''Returns average cost function return value for all members'''\n\n        if len(self.__members) != 0:\n            if self.__num_processes > 1:\n                members = [m.get() for m in self.__members]\n            else:\n                members = self.__members\n            return sum(m.cost_fn_val for m in members) / len(members)\n        else:\n            return None", "response": "Returns average cost function return value for all members"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef med_cost_fn_val(self):\n        '''Returns median cost function return value for all members'''\n\n        if len(self.__members) != 0:\n            if self.__num_processes > 1:\n                members = [m.get() for m in self.__members]\n            else:\n                members = self.__members\n            return median([m.cost_fn_val for m in members])\n        else:\n            return None", "response": "Returns median cost function return value for all members"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef members(self):\n        '''Returns Member objects of population'''\n\n        if self.__num_processes > 1:\n            return [m.get() for m in self.__members]\n        else:\n            return self.__members", "response": "Returns Member objects of population"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_parameter(self, name, min_val, max_val):\n        '''Adds a paramber to the Population\n\n        Args:\n            name (str): name of the parameter\n            min_val (int or float): minimum value for the parameter\n            max_val (int or float): maximum value for the parameter\n        '''\n\n        self.__parameters.append(Parameter(name, min_val, max_val))", "response": "Adds a parameter to the Population\n            object"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating self. __pop_size Members with randomly initialized values for each parameter added with add_parameter and evaluates their fitness", "response": "def generate_population(self):\n        '''Generates self.__pop_size Members with randomly initialized values\n        for each parameter added with add_parameter(), evaluates their fitness\n        '''\n\n        if self.__num_processes > 1:\n            process_pool = Pool(processes=self.__num_processes)\n        self.__members = []\n\n        for _ in range(self.__pop_size):\n            feed_dict = {}\n            for param in self.__parameters:\n                feed_dict[param.name] = self.__random_param_val(\n                    param.min_val,\n                    param.max_val,\n                    param.dtype\n                )\n            if self.__num_processes > 1:\n                self.__members.append(process_pool.apply_async(\n                    self._start_process,\n                    [self.__cost_fn, feed_dict, self.__cost_fn_args])\n                )\n            else:\n                self.__members.append(\n                    Member(\n                        feed_dict,\n                        self.__cost_fn(feed_dict, self.__cost_fn_args)\n                    )\n                )\n\n        if self.__num_processes > 1:\n            process_pool.close()\n            process_pool.join()\n\n        self.__determine_best_member()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngenerate the next generation from a previously evaluated generation", "response": "def next_generation(self, mut_rate=0, max_mut_amt=0, log_base=10):\n        '''Generates the next population from a previously evaluated generation\n\n        Args:\n            mut_rate (float): mutation rate for new members (0.0 - 1.0)\n            max_mut_amt (float): how much the member is allowed to mutate\n                (0.0 - 1.0, proportion change of mutated parameter)\n            log_base (int): the higher this number, the more likely the first\n                Members (chosen with supplied selection function) are chosen\n                as parents for the next generation\n        '''\n\n        if self.__num_processes > 1:\n            process_pool = Pool(processes=self.__num_processes)\n            members = [m.get() for m in self.__members]\n        else:\n            members = self.__members\n\n        if len(members) == 0:\n            raise Exception(\n                'Generation 0 not found: use generate_population() first'\n            )\n\n        selected_members = self.__select_fn(members)\n        reproduction_probs = list(reversed(logspace(0.0, 1.0,\n                                  num=len(selected_members), base=log_base)))\n        reproduction_probs = reproduction_probs / sum(reproduction_probs)\n\n        self.__members = []\n\n        for _ in range(self.__pop_size):\n            parent_1 = nrandom.choice(selected_members, p=reproduction_probs)\n            parent_2 = nrandom.choice(selected_members, p=reproduction_probs)\n\n            feed_dict = {}\n            for param in self.__parameters:\n                which_parent = uniform(0, 1)\n                if which_parent < 0.5:\n                    feed_dict[param.name] = parent_1.parameters[param.name]\n                else:\n                    feed_dict[param.name] = parent_2.parameters[param.name]\n                feed_dict[param.name] = self.__mutate_parameter(\n                    feed_dict[param.name], param, mut_rate, max_mut_amt\n                )\n\n            if self.__num_processes > 1:\n                self.__members.append(process_pool.apply_async(\n                    self._start_process,\n                    [self.__cost_fn, feed_dict, self.__cost_fn_args])\n                )\n            else:\n                self.__members.append(\n                    Member(\n                        feed_dict,\n                        self.__cost_fn(feed_dict, self.__cost_fn_args)\n                    )\n                )\n\n        if self.__num_processes > 1:\n            process_pool.close()\n            process_pool.join()\n\n        self.__determine_best_member()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates the given defaults with values from the config files and the environ variables.", "response": "def update_defaults(self, defaults):\n        \"\"\"Updates the given defaults with values from the config files and\n        the environ. Does a little special handling for certain types of\n        options (lists).\"\"\"\n        # Then go and look for the other sources of configuration:\n        config = {}\n        # 1. config files\n        for section in ('global', self.name):\n            config.update(\n                self.normalize_keys(self.get_config_section(section))\n            )\n        # 2. environmental variables\n        if not self.isolated:\n            config.update(self.normalize_keys(self.get_environ_vars()))\n        # Then set the options with those values\n        for key, val in config.items():\n            option = self.get_option(key)\n            if option is not None:\n                # ignore empty values\n                if not val:\n                    continue\n                if option.action in ('store_true', 'store_false', 'count'):\n                    val = strtobool(val)\n                if option.action == 'append':\n                    val = val.split()\n                    val = [self.check_default(option, key, v) for v in val]\n                else:\n                    val = self.check_default(option, key, val)\n\n                defaults[option.dest] = val\n        return defaults"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef normalize_keys(self, items):\n        normalized = {}\n        for key, val in items:\n            key = key.replace('_', '-')\n            if not key.startswith('--'):\n                key = '--%s' % key  # only prefer long opts\n            normalized[key] = val\n        return normalized", "response": "Return a config dictionary with normalized keys regardless of the keys were specified in environment variables or in config\n        files."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_environ_vars(self):\n        for key, val in os.environ.items():\n            if _environ_prefix_re.search(key):\n                yield (_environ_prefix_re.sub(\"\", key).lower(), val)", "response": "Returns a generator with all environmental vars with prefix PIP_"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef throws_exception(callable, *exceptions):\n\twith context.ExceptionTrap():\n\t\twith context.ExceptionTrap(*exceptions) as exc:\n\t\t\tcallable()\n\treturn bool(exc)", "response": "Returns True if the callable throws the specified exception."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntransform the hits into a list of packages.", "response": "def transform_hits(hits):\n    \"\"\"\n    The list from pypi is really a list of versions. We want a list of\n    packages with the list of versions stored inline. This converts the\n    list from pypi into one we can use.\n    \"\"\"\n    packages = {}\n    for hit in hits:\n        name = hit['name']\n        summary = hit['summary']\n        version = hit['version']\n        score = hit['_pypi_ordering']\n        if score is None:\n            score = 0\n\n        if name not in packages.keys():\n            packages[name] = {\n                'name': name,\n                'summary': summary,\n                'versions': [version],\n                'score': score,\n            }\n        else:\n            packages[name]['versions'].append(version)\n\n            # if this is the highest version, replace summary and score\n            if version == highest_version(packages[name]['versions']):\n                packages[name]['summary'] = summary\n                packages[name]['score'] = score\n\n    # each record has a unique name now, so we will convert the dict into a\n    # list sorted by score\n    package_list = sorted(\n        packages.values(),\n        key=lambda x: x['score'],\n        reverse=True,\n    )\n    return package_list"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _transform_result(typ, result):\n    if issubclass(typ, bytes):\n        return tostring(result, encoding='utf-8')\n    elif issubclass(typ, unicode):\n        return tostring(result, encoding='unicode')\n    else:\n        return result", "response": "Convert the result back into the input type."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses a string of HTML and returns a list of fragments.", "response": "def fragments_fromstring(html, no_leading_text=False, base_url=None,\n                         parser=None, **kw):\n    \"\"\"\n    Parses several HTML elements, returning a list of elements.\n\n    The first item in the list may be a string (though leading\n    whitespace is removed).  If no_leading_text is true, then it will\n    be an error if there is leading text, and it will always be a list\n    of only elements.\n\n    base_url will set the document's base_url attribute (and the tree's docinfo.URL)\n    \"\"\"\n    if parser is None:\n        parser = html_parser\n    # FIXME: check what happens when you give html with a body, head, etc.\n    if isinstance(html, bytes):\n        if not _looks_like_full_html_bytes(html):\n            # can't use %-formatting in early Py3 versions\n            html = ('<html><body>'.encode('ascii') + html +\n                    '</body></html>'.encode('ascii'))\n    else:\n        if not _looks_like_full_html_unicode(html):\n            html = '<html><body>%s</body></html>' % html\n    doc = document_fromstring(html, parser=parser, base_url=base_url, **kw)\n    assert _nons(doc.tag) == 'html'\n    bodies = [e for e in doc if _nons(e.tag) == 'body']\n    assert len(bodies) == 1, (\"too many bodies: %r in %r\" % (bodies, html))\n    body = bodies[0]\n    elements = []\n    if no_leading_text and body.text and body.text.strip():\n        raise etree.ParserError(\n            \"There is leading text: %r\" % body.text)\n    if body.text and body.text.strip():\n        elements.append(body.text)\n    elements.extend(body)\n    # FIXME: removing the reference to the parent artificial document\n    # would be nice\n    return elements"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fragment_fromstring(html, create_parent=False, base_url=None,\n                        parser=None, **kw):\n    \"\"\"\n    Parses a single HTML element; it is an error if there is more than\n    one element, or if anything but whitespace precedes or follows the\n    element.\n\n    If ``create_parent`` is true (or is a tag name) then a parent node\n    will be created to encapsulate the HTML in a single element.  In this\n    case, leading or trailing text is also allowed, as are multiple elements\n    as result of the parsing.\n\n    Passing a ``base_url`` will set the document's ``base_url`` attribute\n    (and the tree's docinfo.URL).\n    \"\"\"\n    if parser is None:\n        parser = html_parser\n\n    accept_leading_text = bool(create_parent)\n\n    elements = fragments_fromstring(\n        html, parser=parser, no_leading_text=not accept_leading_text,\n        base_url=base_url, **kw)\n\n    if create_parent:\n        if not isinstance(create_parent, basestring):\n            create_parent = 'div'\n        new_root = Element(create_parent)\n        if elements:\n            if isinstance(elements[0], basestring):\n                new_root.text = elements[0]\n                del elements[0]\n            new_root.extend(elements)\n        return new_root\n\n    if not elements:\n        raise etree.ParserError('No elements found')\n    if len(elements) > 1:\n        raise etree.ParserError(\n            \"Multiple elements found (%s)\"\n            % ', '.join([_element_name(e) for e in elements]))\n    el = elements[0]\n    if el.tail and el.tail.strip():\n        raise etree.ParserError(\n            \"Element followed by text: %r\" % el.tail)\n    el.tail = None\n    return el", "response": "Parses a string and returns a new node containing the fragment."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fromstring(html, base_url=None, parser=None, **kw):\n    if parser is None:\n        parser = html_parser\n    if isinstance(html, bytes):\n        is_full_html = _looks_like_full_html_bytes(html)\n    else:\n        is_full_html = _looks_like_full_html_unicode(html)\n    doc = document_fromstring(html, parser=parser, base_url=base_url, **kw)\n    if is_full_html:\n        return doc\n    # otherwise, lets parse it out...\n    bodies = doc.findall('body')\n    if not bodies:\n        bodies = doc.findall('{%s}body' % XHTML_NAMESPACE)\n    if bodies:\n        body = bodies[0]\n        if len(bodies) > 1:\n            # Somehow there are multiple bodies, which is bad, but just\n            # smash them into one body\n            for other_body in bodies[1:]:\n                if other_body.text:\n                    if len(body):\n                        body[-1].tail = (body[-1].tail or '') + other_body.text\n                    else:\n                        body.text = (body.text or '') + other_body.text\n                body.extend(other_body)\n                # We'll ignore tail\n                # I guess we are ignoring attributes too\n                other_body.drop_tree()\n    else:\n        body = None\n    heads = doc.findall('head')\n    if not heads:\n        heads = doc.findall('{%s}head' % XHTML_NAMESPACE)\n    if heads:\n        # Well, we have some sort of structure, so lets keep it all\n        head = heads[0]\n        if len(heads) > 1:\n            for other_head in heads[1:]:\n                head.extend(other_head)\n                # We don't care about text or tail in a head\n                other_head.drop_tree()\n        return doc\n    if body is None:\n        return doc\n    if (len(body) == 1 and (not body.text or not body.text.strip())\n        and (not body[-1].tail or not body[-1].tail.strip())):\n        # The body has just one element, so it was probably a single\n        # element passed in\n        return body[0]\n    # Now we have a body which represents a bunch of tags which have the\n    # content that was passed in.  We will create a fake container, which\n    # is the body tag, except <body> implies too much structure.\n    if _contains_block_level_tag(body):\n        body.tag = 'div'\n    else:\n        body.tag = 'span'\n    return body", "response": "Parses the given html string and returns a single element or document."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses a filename URL or file - like object into an HTML document .", "response": "def parse(filename_or_url, parser=None, base_url=None, **kw):\n    \"\"\"\n    Parse a filename, URL, or file-like object into an HTML document\n    tree.  Note: this returns a tree, not an element.  Use\n    ``parse(...).getroot()`` to get the document root.\n\n    You can override the base URL with the ``base_url`` keyword.  This\n    is most useful when parsing from a file-like object.\n    \"\"\"\n    if parser is None:\n        parser = html_parser\n    return etree.parse(filename_or_url, parser, base_url=base_url, **kw)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef submit_form(form, extra_values=None, open_http=None):\n    values = form.form_values()\n    if extra_values:\n        if hasattr(extra_values, 'items'):\n            extra_values = extra_values.items()\n        values.extend(extra_values)\n    if open_http is None:\n        open_http = open_http_urllib\n    if form.action:\n        url = form.action\n    else:\n        url = form.base_url\n    return open_http(form.method, url, values)", "response": "Submit a form to the server."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef html_to_xhtml(html):\n    try:\n        html = html.getroot()\n    except AttributeError:\n        pass\n    prefix = \"{%s}\" % XHTML_NAMESPACE\n    for el in html.iter(etree.Element):\n        tag = el.tag\n        if tag[0] != '{':\n            el.tag = prefix + tag", "response": "Convert all tags in an HTML tree to XHTML by moving them to the XHTML namespace."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts all tags in an XHTML tree to HTML by removing their XHTML namespace.", "response": "def xhtml_to_html(xhtml):\n    \"\"\"Convert all tags in an XHTML tree to HTML by removing their\n    XHTML namespace.\n    \"\"\"\n    try:\n        xhtml = xhtml.getroot()\n    except AttributeError:\n        pass\n    prefix = \"{%s}\" % XHTML_NAMESPACE\n    prefix_len = len(prefix)\n    for el in xhtml.iter(prefix + \"*\"):\n        el.tag = el.tag[prefix_len:]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns an HTML string representation of the document.", "response": "def tostring(doc, pretty_print=False, include_meta_content_type=False,\n             encoding=None, method=\"html\", with_tail=True, doctype=None):\n    \"\"\"Return an HTML string representation of the document.\n\n    Note: if include_meta_content_type is true this will create a\n    ``<meta http-equiv=\"Content-Type\" ...>`` tag in the head;\n    regardless of the value of include_meta_content_type any existing\n    ``<meta http-equiv=\"Content-Type\" ...>`` tag will be removed\n\n    The ``encoding`` argument controls the output encoding (defauts to\n    ASCII, with &#...; character references for any characters outside\n    of ASCII).  Note that you can pass the name ``'unicode'`` as\n    ``encoding`` argument to serialise to a Unicode string.\n\n    The ``method`` argument defines the output method.  It defaults to\n    'html', but can also be 'xml' for xhtml output, or 'text' to\n    serialise to plain text without markup.\n\n    To leave out the tail text of the top-level element that is being\n    serialised, pass ``with_tail=False``.\n\n    The ``doctype`` option allows passing in a plain string that will\n    be serialised before the XML tree.  Note that passing in non\n    well-formed content here will make the XML output non well-formed.\n    Also, an existing doctype in the document tree will not be removed\n    when serialising an ElementTree instance.\n\n    Example::\n\n        >>> from lxml import html\n        >>> root = html.fragment_fromstring('<p>Hello<br>world!</p>')\n\n        >>> html.tostring(root)\n        b'<p>Hello<br>world!</p>'\n        >>> html.tostring(root, method='html')\n        b'<p>Hello<br>world!</p>'\n\n        >>> html.tostring(root, method='xml')\n        b'<p>Hello<br/>world!</p>'\n\n        >>> html.tostring(root, method='text')\n        b'Helloworld!'\n\n        >>> html.tostring(root, method='text', encoding='unicode')\n        u'Helloworld!'\n\n        >>> root = html.fragment_fromstring('<div><p>Hello<br>world!</p>TAIL</div>')\n        >>> html.tostring(root[0], method='text', encoding='unicode')\n        u'Helloworld!TAIL'\n\n        >>> html.tostring(root[0], method='text', encoding='unicode', with_tail=False)\n        u'Helloworld!'\n\n        >>> doc = html.document_fromstring('<p>Hello<br>world!</p>')\n        >>> html.tostring(doc, method='html', encoding='unicode')\n        u'<html><body><p>Hello<br>world!</p></body></html>'\n\n        >>> print(html.tostring(doc, method='html', encoding='unicode',\n        ...          doctype='<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01//EN\"'\n        ...                  ' \"http://www.w3.org/TR/html4/strict.dtd\">'))\n        <!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01//EN\" \"http://www.w3.org/TR/html4/strict.dtd\">\n        <html><body><p>Hello<br>world!</p></body></html>\n    \"\"\"\n    html = etree.tostring(doc, method=method, pretty_print=pretty_print,\n                          encoding=encoding, with_tail=with_tail,\n                          doctype=doctype)\n    if method == 'html' and not include_meta_content_type:\n        if isinstance(html, str):\n            html = __str_replace_meta_content_type('', html)\n        else:\n            html = __bytes_replace_meta_content_type(bytes(), html)\n    return html"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nopens the HTML document in a web browser.", "response": "def open_in_browser(doc, encoding=None):\n    \"\"\"\n    Open the HTML document in a web browser, saving it to a temporary\n    file to open it.  Note that this does not delete the file after\n    use.  This is mainly meant for debugging.\n    \"\"\"\n    import os\n    import webbrowser\n    import tempfile\n    if not isinstance(doc, etree._ElementTree):\n        doc = etree.ElementTree(doc)\n    handle, fn = tempfile.mkstemp(suffix='.html')\n    f = os.fdopen(handle, 'wb')\n    try:\n        doc.write(f, method=\"html\", encoding=encoding or doc.docinfo.encoding or \"UTF-8\")\n    finally:\n        # we leak the file itself here, but we should at least close it\n        f.close()\n    url = 'file://' + fn.replace(os.path.sep, '/')\n    print(url)\n    webbrowser.open(url)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _label__get(self):\n        id = self.get('id')\n        if not id:\n            return None\n        result = _label_xpath(self, id=id)\n        if not result:\n            return None\n        else:\n            return result[0]", "response": "Get or set any label element associated with this element."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef drop_tree(self):\n        parent = self.getparent()\n        assert parent is not None\n        if self.tail:\n            previous = self.getprevious()\n            if previous is None:\n                parent.text = (parent.text or '') + self.tail\n            else:\n                previous.tail = (previous.tail or '') + self.tail\n        parent.remove(self)", "response": "Removes this element from the tree including its children and its children and the tail text."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nremoves the tag but not its children or text.", "response": "def drop_tag(self):\n        \"\"\"\n        Remove the tag, but not its children or text.  The children and text\n        are merged into the parent.\n\n        Example::\n\n            >>> h = fragment_fromstring('<div>Hello <b>World!</b></div>')\n            >>> h.find('.//b').drop_tag()\n            >>> print(tostring(h, encoding='unicode'))\n            <div>Hello World!</div>\n        \"\"\"\n        parent = self.getparent()\n        assert parent is not None\n        previous = self.getprevious()\n        if self.text and isinstance(self.tag, basestring):\n            # not a Comment, etc.\n            if previous is None:\n                parent.text = (parent.text or '') + self.text\n            else:\n                previous.tail = (previous.tail or '') + self.text\n        if self.tail:\n            if len(self):\n                last = self[-1]\n                last.tail = (last.tail or '') + self.tail\n            elif previous is None:\n                parent.text = (parent.text or '') + self.tail\n            else:\n                previous.tail = (previous.tail or '') + self.tail\n        index = parent.index(self)\n        parent[index:index+1] = self[:]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef find_rel_links(self, rel):\n        rel = rel.lower()\n        return [el for el in _rel_links_xpath(self)\n                if el.get('rel').lower() == rel]", "response": "Find any links like <a rel = rel......</a > ; returns a list of elements."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the first element in a document with the given id.", "response": "def get_element_by_id(self, id, *default):\n        \"\"\"\n        Get the first element in a document with the given id.  If none is\n        found, return the default argument if provided or raise KeyError\n        otherwise.\n\n        Note that there can be more than one element with the same id,\n        and this isn't uncommon in HTML documents found in the wild.\n        Browsers return only the first match, and this function does\n        the same.\n        \"\"\"\n        try:\n            # FIXME: should this check for multiple matches?\n            # browsers just return the first one\n            return _id_xpath(self, id=id)[0]\n        except IndexError:\n            if default:\n                return default[0]\n            else:\n                raise KeyError(id)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrunning the CSS expression on this element and its children and return a list of the results.", "response": "def cssselect(self, expr, translator='html'):\n        \"\"\"\n        Run the CSS expression on this element and its children,\n        returning a list of the results.\n\n        Equivalent to lxml.cssselect.CSSSelect(expr, translator='html')(self)\n        -- note that pre-compiling the expression can provide a substantial\n        speedup.\n        \"\"\"\n        # Do the import here to make the dependency optional.\n        from lxml.cssselect import CSSSelector\n        return CSSSelector(expr, translator=translator)(self)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmakes all links in the document absolute given the base_url.", "response": "def make_links_absolute(self, base_url=None, resolve_base_href=True,\n                            handle_failures=None):\n        \"\"\"\n        Make all links in the document absolute, given the\n        ``base_url`` for the document (the full URL where the document\n        came from), or if no ``base_url`` is given, then the ``.base_url``\n        of the document.\n\n        If ``resolve_base_href`` is true, then any ``<base href>``\n        tags in the document are used *and* removed from the document.\n        If it is false then any such tag is ignored.\n\n        If ``handle_failures`` is None (default), a failure to process\n        a URL will abort the processing.  If set to 'ignore', errors\n        are ignored.  If set to 'discard', failing URLs will be removed.\n        \"\"\"\n        if base_url is None:\n            base_url = self.base_url\n            if base_url is None:\n                raise TypeError(\n                    \"No base_url given, and the document has no base_url\")\n        if resolve_base_href:\n            self.resolve_base_href()\n\n        if handle_failures == 'ignore':\n            def link_repl(href):\n                try:\n                    return urljoin(base_url, href)\n                except ValueError:\n                    return href\n        elif handle_failures == 'discard':\n            def link_repl(href):\n                try:\n                    return urljoin(base_url, href)\n                except ValueError:\n                    return None\n        elif handle_failures is None:\n            def link_repl(href):\n                return urljoin(base_url, href)\n        else:\n            raise ValueError(\n                \"unexpected value for handle_failures: %r\" % handle_failures)\n\n        self.rewrite_links(link_repl)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nresolving the base href of the current page.", "response": "def resolve_base_href(self, handle_failures=None):\n        \"\"\"\n        Find any ``<base href>`` tag in the document, and apply its\n        values to all links found in the document.  Also remove the\n        tag once it has been applied.\n\n        If ``handle_failures`` is None (default), a failure to process\n        a URL will abort the processing.  If set to 'ignore', errors\n        are ignored.  If set to 'discard', failing URLs will be removed.\n        \"\"\"\n        base_href = None\n        basetags = self.xpath('//base[@href]|//x:base[@href]',\n                              namespaces={'x': XHTML_NAMESPACE})\n        for b in basetags:\n            base_href = b.get('href')\n            b.drop_tree()\n        if not base_href:\n            return\n        self.make_links_absolute(base_href, resolve_base_href=False,\n                                 handle_failures=handle_failures)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\niterate over the links in the document.", "response": "def iterlinks(self):\n        \"\"\"\n        Yield (element, attribute, link, pos), where attribute may be None\n        (indicating the link is in the text).  ``pos`` is the position\n        where the link occurs; often 0, but sometimes something else in\n        the case of links in stylesheets or style tags.\n\n        Note: <base href> is *not* taken into account in any way.  The\n        link you get is exactly the link in the document.\n\n        Note: multiple links inside of a single text string or\n        attribute value are returned in reversed order.  This makes it\n        possible to replace or delete them from the text string value\n        based on their reported text positions.  Otherwise, a\n        modification at one text position can change the positions of\n        links reported later on.\n        \"\"\"\n        link_attrs = defs.link_attrs\n        for el in self.iter(etree.Element):\n            attribs = el.attrib\n            tag = _nons(el.tag)\n            if tag == 'object':\n                codebase = None\n                ## <object> tags have attributes that are relative to\n                ## codebase\n                if 'codebase' in attribs:\n                    codebase = el.get('codebase')\n                    yield (el, 'codebase', codebase, 0)\n                for attrib in ('classid', 'data'):\n                    if attrib in attribs:\n                        value = el.get(attrib)\n                        if codebase is not None:\n                            value = urljoin(codebase, value)\n                        yield (el, attrib, value, 0)\n                if 'archive' in attribs:\n                    for match in _archive_re.finditer(el.get('archive')):\n                        value = match.group(0)\n                        if codebase is not None:\n                            value = urljoin(codebase, value)\n                        yield (el, 'archive', value, match.start())\n            else:\n                for attrib in link_attrs:\n                    if attrib in attribs:\n                        yield (el, attrib, attribs[attrib], 0)\n            if tag == 'meta':\n                http_equiv = attribs.get('http-equiv', '').lower()\n                if http_equiv == 'refresh':\n                    content = attribs.get('content', '')\n                    match = _parse_meta_refresh_url(content)\n                    url = (match.group('url') if match else content).strip()\n                    # unexpected content means the redirect won't work, but we might\n                    # as well be permissive and return the entire string.\n                    if url:\n                        url, pos = _unquote_match(\n                            url, match.start('url') if match else content.find(url))\n                        yield (el, 'content', url, pos)\n            elif tag == 'param':\n                valuetype = el.get('valuetype') or ''\n                if valuetype.lower() == 'ref':\n                    ## FIXME: while it's fine we *find* this link,\n                    ## according to the spec we aren't supposed to\n                    ## actually change the value, including resolving\n                    ## it.  It can also still be a link, even if it\n                    ## doesn't have a valuetype=\"ref\" (which seems to be the norm)\n                    ## http://www.w3.org/TR/html401/struct/objects.html#adef-valuetype\n                    yield (el, 'value', el.get('value'), 0)\n            elif tag == 'style' and el.text:\n                urls = [\n                    # (start_pos, url)\n                    _unquote_match(match.group(1), match.start(1))[::-1]\n                    for match in _iter_css_urls(el.text)\n                    ] + [\n                    (match.start(1), match.group(1))\n                    for match in _iter_css_imports(el.text)\n                    ]\n                if urls:\n                    # sort by start pos to bring both match sets back into order\n                    # and reverse the list to report correct positions despite\n                    # modifications\n                    urls.sort(reverse=True)\n                    for start, url in urls:\n                        yield (el, None, url, start)\n            if 'style' in attribs:\n                urls = list(_iter_css_urls(attribs['style']))\n                if urls:\n                    # return in reversed order to simplify in-place modifications\n                    for match in urls[::-1]:\n                        url, start = _unquote_match(match.group(1), match.start(1))\n                        yield (el, 'style', url, start)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef rewrite_links(self, link_repl_func, resolve_base_href=True,\n                      base_href=None):\n        \"\"\"\n        Rewrite all the links in the document.  For each link\n        ``link_repl_func(link)`` will be called, and the return value\n        will replace the old link.\n\n        Note that links may not be absolute (unless you first called\n        ``make_links_absolute()``), and may be internal (e.g.,\n        ``'#anchor'``).  They can also be values like\n        ``'mailto:email'`` or ``'javascript:expr'``.\n\n        If you give ``base_href`` then all links passed to\n        ``link_repl_func()`` will take that into account.\n\n        If the ``link_repl_func`` returns None, the attribute or\n        tag text will be removed completely.\n        \"\"\"\n        if base_href is not None:\n            # FIXME: this can be done in one pass with a wrapper\n            # around link_repl_func\n            self.make_links_absolute(\n                base_href, resolve_base_href=resolve_base_href)\n        elif resolve_base_href:\n            self.resolve_base_href()\n\n        for el, attrib, link, pos in self.iterlinks():\n            new_link = link_repl_func(link.strip())\n            if new_link == link:\n                continue\n            if new_link is None:\n                # Remove the attribute or element content\n                if attrib is None:\n                    el.text = ''\n                else:\n                    del el.attrib[attrib]\n                continue\n\n            if attrib is None:\n                new = el.text[:pos] + new_link + el.text[pos+len(link):]\n                el.text = new\n            else:\n                cur = el.get(attrib)\n                if not pos and len(cur) == len(link):\n                    new = new_link  # most common case\n                else:\n                    new = cur[:pos] + new_link + cur[pos+len(link):]\n                el.set(attrib, new)", "response": "Rewrite all the links in the document."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef form_values(self):\n        results = []\n        for el in self.inputs:\n            name = el.name\n            if not name:\n                continue\n            tag = _nons(el.tag)\n            if tag == 'textarea':\n                results.append((name, el.value))\n            elif tag == 'select':\n                value = el.value\n                if el.multiple:\n                    for v in value:\n                        results.append((name, v))\n                elif value is not None:\n                    results.append((name, el.value))\n            else:\n                assert tag == 'input', (\n                    \"Unexpected tag: %r\" % el)\n                if el.checkable and not el.checked:\n                    continue\n                if el.type in ('submit', 'image', 'reset'):\n                    continue\n                value = el.value\n                if value is not None:\n                    results.append((name, el.value))\n        return results", "response": "Return a list of tuples of the field names and values for the form."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the form s action attribute.", "response": "def _action__get(self):\n        \"\"\"\n        Get/set the form's ``action`` attribute.\n        \"\"\"\n        base_url = self.base_url\n        action = self.get('action')\n        if base_url and action is not None:\n            return urljoin(base_url, action)\n        else:\n            return action"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _value__get(self):\n        content = self.text or ''\n        if self.tag.startswith(\"{%s}\" % XHTML_NAMESPACE):\n            serialisation_method = 'xml'\n        else:\n            serialisation_method = 'html'\n        for el in self:\n            # it's rare that we actually get here, so let's not use ''.join()\n            content += etree.tostring(\n                el, method=serialisation_method, encoding='unicode')\n        return content", "response": "Get the value of this element."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _value__get(self):\n        if self.multiple:\n            return MultipleSelectOptions(self)\n        for el in _options_xpath(self):\n            if el.get('selected') is not None:\n                value = el.get('value')\n                if value is None:\n                    value = el.text or ''\n                if value:\n                    value = value.strip()\n                return value\n        return None", "response": "Get the value of this select option."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef value_options(self):\n        options = []\n        for el in _options_xpath(self):\n            value = el.get('value')\n            if value is None:\n                value = el.text or ''\n            if value:\n                value = value.strip()\n            options.append(value)\n        return options", "response": "Return a list of all the possible values this select can have."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the value of this element using the value attribute.", "response": "def _value__get(self):\n        \"\"\"\n        Get/set the value of this element, using the ``value`` attribute.\n\n        Also, if this is a checkbox and it has no value, this defaults\n        to ``'on'``.  If it is a checkbox or radio that is not\n        checked, this returns None.\n        \"\"\"\n        if self.checkable:\n            if self.checked:\n                return self.get('value') or 'on'\n            else:\n                return None\n        return self.get('value')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _for_element__get(self):\n        id = self.get('for')\n        if not id:\n            return None\n        return self.body.get_element_by_id(id)", "response": "Get the element this label points to. Return None if the element can t be found."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef classpath(v):\n    if isinstance(v, type):\n        ret = strclass(v)\n    else:\n        ret = strclass(v.__class__)\n    return ret", "response": "returns the full class path of a class or instance"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef loghandler_members():\n    Members = namedtuple(\"Members\", [\"name\", \"handler\", \"member_name\", \"member\"])\n    log_manager = logging.Logger.manager\n    loggers = []\n    ignore = set([modname()])\n    if log_manager.root:\n        loggers = list(log_manager.loggerDict.items())\n        loggers.append((\"root\", log_manager.root))\n\n    for logger_name, logger in loggers:\n        if logger_name in ignore: continue\n\n        for handler in getattr(logger, \"handlers\", []):\n            members = inspect.getmembers(handler)\n            for member_name, member in members:\n                yield Members(logger_name, handler, member_name, member)", "response": "iterate through the attributes of every logger s handler\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_counts():\n    counts = {}\n    ks = [\n        ('PYT_TEST_CLASS_COUNT', \"classes\"),\n        ('PYT_TEST_COUNT', \"tests\"),\n        ('PYT_TEST_MODULE_COUNT', \"modules\"),\n    ]\n\n    for ek, cn in ks:\n        counts[cn] = int(os.environ.get(ek, 0))\n\n    return counts", "response": "return test counts that are set via pyt environment variables when pyt \n    runs the test\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning True if only a single class is being run or some tests within a single class", "response": "def is_single_class():\n    \"\"\"Returns True if only a single class is being run or some tests within a single class\"\"\"\n    ret = False\n    counts = get_counts()\n    if counts[\"classes\"] < 1 and counts[\"modules\"] < 1:\n        ret = counts[\"tests\"] > 0\n    else:\n        ret = counts[\"classes\"] <= 1 and counts[\"modules\"] <= 1\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns True if only a module is being run", "response": "def is_single_module():\n    \"\"\"Returns True if only a module is being run\"\"\"\n    ret = False\n    counts = get_counts()\n    if counts[\"modules\"] == 1:\n        ret = True\n\n    elif counts[\"modules\"] < 1:\n        ret = is_single_class()\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nvalidate the id of the current resource.", "response": "def validate_id(request):\n    \"\"\"Validate request id.\"\"\"\n\n    if 'id' in request:\n        correct_id = isinstance(\n            request['id'],\n            (string_types, int, None),\n        )\n        error = 'Incorrect identifier'\n        assert correct_id, error"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef filesys_decode(path):\n\n    fs_enc = sys.getfilesystemencoding()\n    if isinstance(path, decoded_string):\n        return path\n\n    for enc in (fs_enc, \"utf-8\"):\n        try:\n            return path.decode(enc)\n        except UnicodeDecodeError:\n            continue", "response": "Ensure that the given path is decoded"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef codecName(encoding):\n    if isinstance(encoding, bytes):\n        try:\n            encoding = encoding.decode(\"ascii\")\n        except UnicodeDecodeError:\n            return None\n    if encoding:\n        canonicalName = ascii_punctuation_re.sub(\"\", encoding).lower()\n        return encodings.get(canonicalName, None)\n    else:\n        return None", "response": "Return the python codec name corresponding to an encoding or None if the encoding is not a valid encoding."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nattempts to detect at the beginning of the stream. If it can t detect at the beginning of the stream return the name of the encoding otherwise return None", "response": "def detectBOM(self):\n        \"\"\"Attempts to detect at BOM at the start of the stream. If\n        an encoding can be determined from the BOM return the name of the\n        encoding otherwise return None\"\"\"\n        bomDict = {\n            codecs.BOM_UTF8: 'utf-8',\n            codecs.BOM_UTF16_LE: 'utf-16-le', codecs.BOM_UTF16_BE: 'utf-16-be',\n            codecs.BOM_UTF32_LE: 'utf-32-le', codecs.BOM_UTF32_BE: 'utf-32-be'\n        }\n\n        # Go to beginning of file and read in 4 bytes\n        string = self.rawStream.read(4)\n        assert isinstance(string, bytes)\n\n        # Try detecting the BOM using bytes from the string\n        encoding = bomDict.get(string[:3])         # UTF-8\n        seek = 3\n        if not encoding:\n            # Need to detect UTF-32 before UTF-16\n            encoding = bomDict.get(string)         # UTF-32\n            seek = 4\n            if not encoding:\n                encoding = bomDict.get(string[:2])  # UTF-16\n                seek = 2\n\n        # Set the read position past the BOM if one was found, otherwise\n        # set it to the start of the stream\n        self.rawStream.seek(encoding and seek or 0)\n\n        return encoding"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nselects the new remote addr from the given list of ips in X - Forwarded - For.", "response": "def get_remote_addr(self, forwarded_for):\n        \"\"\"Selects the new remote addr from the given list of ips in\n        X-Forwarded-For.  By default it picks the one that the `num_proxies`\n        proxy server provides.  Before 0.9 it would always pick the first.\n\n        .. versionadded:: 0.8\n        \"\"\"\n        if len(forwarded_for) >= self.num_proxies:\n            return forwarded_for[-1 * self.num_proxies]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsubstituting symbols in CLDR number pattern.", "response": "def sub_symbols(pattern, code, symbol):\n    \"\"\"Substitutes symbols in CLDR number pattern.\"\"\"\n    return pattern.replace('\u00a4\u00a4', code).replace('\u00a4', symbol)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef amount_converter(obj):\n    if isinstance(obj, Decimal):\n        return obj\n    elif isinstance(obj, (str, int, float)):\n        return Decimal(str(obj))\n    else:\n        raise ValueError('do not know how to convert: {}'.format(type(obj)))", "response": "Converts amount value from several types into Decimal."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing a string of HTML data into an Element tree using the BeautifulSoup parser.", "response": "def fromstring(data, beautifulsoup=None, makeelement=None, **bsargs):\n    \"\"\"Parse a string of HTML data into an Element tree using the\n    BeautifulSoup parser.\n\n    Returns the root ``<html>`` Element of the tree.\n\n    You can pass a different BeautifulSoup parser through the\n    `beautifulsoup` keyword, and a diffent Element factory function\n    through the `makeelement` keyword.  By default, the standard\n    ``BeautifulSoup`` class and the default factory of `lxml.html` are\n    used.\n    \"\"\"\n    return _parse(data, beautifulsoup, makeelement, **bsargs)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse(file, beautifulsoup=None, makeelement=None, **bsargs):\n    if not hasattr(file, 'read'):\n        file = open(file)\n    root = _parse(file, beautifulsoup, makeelement, **bsargs)\n    return etree.ElementTree(root)", "response": "Parse a file into an ElemenTree using the BeautifulSoup parser."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef convert_tree(beautiful_soup_tree, makeelement=None):\n    if makeelement is None:\n        makeelement = html.html_parser.makeelement\n    root = _convert_tree(beautiful_soup_tree, makeelement)\n    children = root.getchildren()\n    for child in children:\n        root.remove(child)\n    return children", "response": "Convert a BeautifulSoup tree to a list of Element trees."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_current_traceback(ignore_system_exceptions=False,\n                          show_hidden_frames=False, skip=0):\n    \"\"\"Get the current exception info as `Traceback` object.  Per default\n    calling this method will reraise system exceptions such as generator exit,\n    system exit or others.  This behavior can be disabled by passing `False`\n    to the function as first parameter.\n    \"\"\"\n    exc_type, exc_value, tb = sys.exc_info()\n    if ignore_system_exceptions and exc_type in system_exceptions:\n        raise\n    for x in range_type(skip):\n        if tb.tb_next is None:\n            break\n        tb = tb.tb_next\n    tb = Traceback(exc_type, exc_value, tb)\n    if not show_hidden_frames:\n        tb.filter_hidden_frames()\n    return tb", "response": "Get the current traceback as Traceback object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nstringing representation of the exception.", "response": "def exception(self):\n        \"\"\"String representation of the exception.\"\"\"\n        buf = traceback.format_exception_only(self.exc_type, self.exc_value)\n        rv = ''.join(buf).strip()\n        return rv.decode('utf-8', 'replace') if PY2 else rv"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef render_summary(self, include_title=True):\n        title = ''\n        frames = []\n        classes = ['traceback']\n        if not self.frames:\n            classes.append('noframe-traceback')\n\n        if include_title:\n            if self.is_syntax_error:\n                title = u'Syntax Error'\n            else:\n                title = u'Traceback <em>(most recent call last)</em>:'\n\n        for frame in self.frames:\n            frames.append(u'<li%s>%s' % (\n                frame.info and u' title=\"%s\"' % escape(frame.info) or u'',\n                frame.render()\n            ))\n\n        if self.is_syntax_error:\n            description_wrapper = u'<pre class=syntaxerror>%s</pre>'\n        else:\n            description_wrapper = u'<blockquote>%s</blockquote>'\n\n        return SUMMARY_HTML % {\n            'classes':      u' '.join(classes),\n            'title':        title and u'<h3>%s</h3>' % title or u'',\n            'frames':       u'\\n'.join(frames),\n            'description':  description_wrapper % escape(self.exception)\n        }", "response": "Render the traceback for the interactive console."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef generate_plaintext_traceback(self):\n        yield u'Traceback (most recent call last):'\n        for frame in self.frames:\n            yield u'  File \"%s\", line %s, in %s' % (\n                frame.filename,\n                frame.lineno,\n                frame.function_name\n            )\n            yield u'    ' + frame.current_line.strip()\n        yield self.exception", "response": "Like the plaintext attribute but returns a generator"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef egg_info_matches(\n        egg_info, search_name, link,\n        _egg_info_re=re.compile(r'([a-z0-9_.]+)-([a-z0-9_.!+-]+)', re.I)):\n    \"\"\"Pull the version part out of a string.\n\n    :param egg_info: The string to parse. E.g. foo-2.1\n    :param search_name: The name of the package this belongs to. None to\n        infer the name. Note that this cannot unambiguously parse strings\n        like foo-2-2 which might be foo, 2-2 or foo-2, 2.\n    :param link: The link the string came from, for logging on failure.\n    \"\"\"\n    match = _egg_info_re.search(egg_info)\n    if not match:\n        logger.debug('Could not parse version from link: %s', link)\n        return None\n    if search_name is None:\n        full_match = match.group(0)\n        return full_match[full_match.index('-'):]\n    name = match.group(0).lower()\n    # To match the \"safe\" name that pkg_resources creates:\n    name = name.replace('_', '-')\n    # project name and version must be separated by a dash\n    look_for = search_name.lower() + \"-\"\n    if name.startswith(look_for):\n        return match.group(0)[len(look_for):]\n    else:\n        return None", "response": "Return the version part of a string that matches the egg_info."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsort locations into files and urls and return a pair of lists.", "response": "def _sort_locations(locations, expand_dir=False):\n        \"\"\"\n        Sort locations into \"files\" (archives) and \"urls\", and return\n        a pair of lists (files,urls)\n        \"\"\"\n        files = []\n        urls = []\n\n        # puts the url for the given file path into the appropriate list\n        def sort_path(path):\n            url = path_to_url(path)\n            if mimetypes.guess_type(url, strict=False)[0] == 'text/html':\n                urls.append(url)\n            else:\n                files.append(url)\n\n        for url in locations:\n\n            is_local_path = os.path.exists(url)\n            is_file_url = url.startswith('file:')\n\n            if is_local_path or is_file_url:\n                if is_local_path:\n                    path = url\n                else:\n                    path = url_to_path(url)\n                if os.path.isdir(path):\n                    if expand_dir:\n                        path = os.path.realpath(path)\n                        for item in os.listdir(path):\n                            sort_path(os.path.join(path, item))\n                    elif is_file_url:\n                        urls.append(url)\n                elif os.path.isfile(path):\n                    sort_path(path)\n            else:\n                urls.append(url)\n\n        return files, urls"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _candidate_sort_key(self, candidate):\n        support_num = len(supported_tags)\n        if candidate.location == INSTALLED_VERSION:\n            pri = 1\n        elif candidate.location.is_wheel:\n            # can raise InvalidWheelFilename\n            wheel = Wheel(candidate.location.filename)\n            if not wheel.supported():\n                raise UnsupportedWheel(\n                    \"%s is not a supported wheel for this platform. It \"\n                    \"can't be sorted.\" % wheel.filename\n                )\n            pri = -(wheel.support_index_min())\n        else:  # sdist\n            pri = -(support_num)\n        return (candidate.version, pri)", "response": "Function used to generate a sort key for a candidate link entry."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _sort_versions(self, applicable_versions):\n        return sorted(\n            applicable_versions,\n            key=self._candidate_sort_key,\n            reverse=True\n        )", "response": "Sort the list of available version entries according to the current ordering."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the locations found via self. index_urls", "response": "def _get_index_urls_locations(self, project_name):\n        \"\"\"Returns the locations found via self.index_urls\n\n        Checks the url_name on the main (first in the list) index and\n        use this url_name to produce all locations\n        \"\"\"\n\n        def mkurl_pypi_url(url):\n            loc = posixpath.join(url, project_url_name)\n            # For maximum compatibility with easy_install, ensure the path\n            # ends in a trailing slash.  Although this isn't in the spec\n            # (and PyPI can handle it without the slash) some other index\n            # implementations might break if they relied on easy_install's\n            # behavior.\n            if not loc.endswith('/'):\n                loc = loc + '/'\n            return loc\n\n        project_url_name = urllib_parse.quote(project_name.lower())\n\n        if self.index_urls:\n            # Check that we have the url_name correctly spelled:\n\n            # Only check main index if index URL is given\n            main_index_url = Link(\n                mkurl_pypi_url(self.index_urls[0]),\n                trusted=True,\n            )\n\n            page = self._get_page(main_index_url)\n            if page is None and PyPI.netloc not in str(main_index_url):\n                warnings.warn(\n                    \"Failed to find %r at %s. It is suggested to upgrade \"\n                    \"your index to support normalized names as the name in \"\n                    \"/simple/{name}.\" % (project_name, main_index_url),\n                    RemovedInPip8Warning,\n                )\n\n                project_url_name = self._find_url_name(\n                    Link(self.index_urls[0], trusted=True),\n                    project_url_name,\n                ) or project_url_name\n\n        if project_url_name is not None:\n            return [mkurl_pypi_url(url) for url in self.index_urls]\n        return []"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _find_all_versions(self, project_name):\n        index_locations = self._get_index_urls_locations(project_name)\n        index_file_loc, index_url_loc = self._sort_locations(index_locations)\n        fl_file_loc, fl_url_loc = self._sort_locations(\n            self.find_links, expand_dir=True)\n        dep_file_loc, dep_url_loc = self._sort_locations(self.dependency_links)\n\n        file_locations = (\n            Link(url) for url in itertools.chain(\n                index_file_loc, fl_file_loc, dep_file_loc)\n        )\n\n        # We trust every url that the user has given us whether it was given\n        #   via --index-url or --find-links\n        # We explicitly do not trust links that came from dependency_links\n        # We want to filter out any thing which does not have a secure origin.\n        url_locations = [\n            link for link in itertools.chain(\n                (Link(url, trusted=True) for url in index_url_loc),\n                (Link(url, trusted=True) for url in fl_url_loc),\n                (Link(url) for url in dep_url_loc),\n            )\n            if self._validate_secure_origin(logger, link)\n        ]\n\n        logger.debug('%d location(s) to search for versions of %s:',\n                     len(url_locations), project_name)\n\n        for location in url_locations:\n            logger.debug('* %s', location)\n\n        canonical_name = pkg_resources.safe_name(project_name).lower()\n        formats = fmt_ctl_formats(self.format_control, canonical_name)\n        search = Search(project_name.lower(), canonical_name, formats)\n        find_links_versions = self._package_versions(\n            # We trust every directly linked archive in find_links\n            (Link(url, '-f', trusted=True) for url in self.find_links),\n            search\n        )\n\n        page_versions = []\n        for page in self._get_pages(url_locations, project_name):\n            logger.debug('Analyzing links from page %s', page.url)\n            with indent_log():\n                page_versions.extend(\n                    self._package_versions(page.links, search)\n                )\n\n        dependency_versions = self._package_versions(\n            (Link(url) for url in self.dependency_links), search\n        )\n        if dependency_versions:\n            logger.debug(\n                'dependency_links found: %s',\n                ', '.join([\n                    version.location.url for version in dependency_versions\n                ])\n            )\n\n        file_versions = self._package_versions(file_locations, search)\n        if file_versions:\n            file_versions.sort(reverse=True)\n            logger.debug(\n                'Local files found: %s',\n                ', '.join([\n                    url_to_path(candidate.location.url)\n                    for candidate in file_versions\n                ])\n            )\n\n        # This is an intentional priority ordering\n        return (\n            file_versions + find_links_versions + page_versions +\n            dependency_versions\n        )", "response": "Find all available versions for a given project_name"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntries to find an InstallationCandidate for req and returns None if no InstallationCandidate is found.", "response": "def find_requirement(self, req, upgrade):\n        \"\"\"Try to find an InstallationCandidate for req\n\n        Expects req, an InstallRequirement and upgrade, a boolean\n        Returns an InstallationCandidate or None\n        May raise DistributionNotFound or BestVersionAlreadyInstalled\n        \"\"\"\n        all_versions = self._find_all_versions(req.name)\n        # Filter out anything which doesn't match our specifier\n\n        _versions = set(\n            req.specifier.filter(\n                [x.version for x in all_versions],\n                prereleases=(\n                    self.allow_all_prereleases\n                    if self.allow_all_prereleases else None\n                ),\n            )\n        )\n        applicable_versions = [\n            x for x in all_versions if x.version in _versions\n        ]\n\n        if req.satisfied_by is not None:\n            # Finally add our existing versions to the front of our versions.\n            applicable_versions.insert(\n                0,\n                InstallationCandidate(\n                    req.name,\n                    req.satisfied_by.version,\n                    INSTALLED_VERSION,\n                )\n            )\n            existing_applicable = True\n        else:\n            existing_applicable = False\n\n        applicable_versions = self._sort_versions(applicable_versions)\n\n        if not upgrade and existing_applicable:\n            if applicable_versions[0].location is INSTALLED_VERSION:\n                logger.debug(\n                    'Existing installed version (%s) is most up-to-date and '\n                    'satisfies requirement',\n                    req.satisfied_by.version,\n                )\n            else:\n                logger.debug(\n                    'Existing installed version (%s) satisfies requirement '\n                    '(most up-to-date version is %s)',\n                    req.satisfied_by.version,\n                    applicable_versions[0][2],\n                )\n            return None\n\n        if not applicable_versions:\n            logger.critical(\n                'Could not find a version that satisfies the requirement %s '\n                '(from versions: %s)',\n                req,\n                ', '.join(\n                    sorted(\n                        set(str(i.version) for i in all_versions),\n                        key=parse_version,\n                    )\n                )\n            )\n\n            if self.need_warn_external:\n                logger.warning(\n                    \"Some externally hosted files were ignored as access to \"\n                    \"them may be unreliable (use --allow-external %s to \"\n                    \"allow).\",\n                    req.name,\n                )\n\n            if self.need_warn_unverified:\n                logger.warning(\n                    \"Some insecure and unverifiable files were ignored\"\n                    \" (use --allow-unverified %s to allow).\",\n                    req.name,\n                )\n\n            raise DistributionNotFound(\n                'No matching distribution found for %s' % req\n            )\n\n        if applicable_versions[0].location is INSTALLED_VERSION:\n            # We have an existing version, and its the best version\n            logger.debug(\n                'Installed version (%s) is most up-to-date (past versions: '\n                '%s)',\n                req.satisfied_by.version,\n                ', '.join(str(i.version) for i in applicable_versions[1:]) or\n                \"none\",\n            )\n            raise BestVersionAlreadyInstalled\n\n        if len(applicable_versions) > 1:\n            logger.debug(\n                'Using version %s (newest of versions: %s)',\n                applicable_versions[0].version,\n                ', '.join(str(i.version) for i in applicable_versions)\n            )\n\n        selected_version = applicable_versions[0].location\n\n        if (selected_version.verifiable is not None and not\n                selected_version.verifiable):\n            logger.warning(\n                \"%s is potentially insecure and unverifiable.\", req.name,\n            )\n\n        return selected_version"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_pages(self, locations, project_name):\n        all_locations = list(locations)\n        seen = set()\n        normalized = normalize_name(project_name)\n\n        while all_locations:\n            location = all_locations.pop(0)\n            if location in seen:\n                continue\n            seen.add(location)\n\n            page = self._get_page(location)\n            if page is None:\n                continue\n\n            yield page\n\n            for link in page.rel_links():\n\n                if (normalized not in self.allow_external and not\n                        self.allow_all_external):\n                    self.need_warn_external = True\n                    logger.debug(\n                        \"Not searching %s for files because external \"\n                        \"urls are disallowed.\",\n                        link,\n                    )\n                    continue\n\n                if (link.trusted is not None and not\n                        link.trusted and\n                        normalized not in self.allow_unverified):\n                    logger.debug(\n                        \"Not searching %s for urls, it is an \"\n                        \"untrusted link and cannot produce safe or \"\n                        \"verifiable files.\",\n                        link,\n                    )\n                    self.need_warn_unverified = True\n                    continue\n\n                all_locations.append(link)", "response": "Yields page_url for all locations and adds download and homepage links."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn elements of links in order non - egg links first egg links second egg links first egg links second egg links second.", "response": "def _sort_links(self, links):\n        \"\"\"\n        Returns elements of links in order, non-egg links first, egg links\n        second, while eliminating duplicates\n        \"\"\"\n        eggs, no_eggs = [], []\n        seen = set()\n        for link in links:\n            if link not in seen:\n                seen.add(link)\n                if link.egg_fragment:\n                    eggs.append(link)\n                else:\n                    no_eggs.append(link)\n        return no_eggs + eggs"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning an InstallationCandidate or None if the link is not a file or a wheel.", "response": "def _link_package_versions(self, link, search):\n        \"\"\"Return an InstallationCandidate or None\"\"\"\n        platform = get_platform()\n\n        version = None\n        if link.egg_fragment:\n            egg_info = link.egg_fragment\n            ext = link.ext\n        else:\n            egg_info, ext = link.splitext()\n            if not ext:\n                self._log_skipped_link(link, 'not a file')\n                return\n            if ext not in SUPPORTED_EXTENSIONS:\n                self._log_skipped_link(\n                    link, 'unsupported archive format: %s' % ext)\n                return\n            if \"binary\" not in search.formats and ext == wheel_ext:\n                self._log_skipped_link(\n                    link, 'No binaries permitted for %s' % search.supplied)\n                return\n            if \"macosx10\" in link.path and ext == '.zip':\n                self._log_skipped_link(link, 'macosx10 one')\n                return\n            if ext == wheel_ext:\n                try:\n                    wheel = Wheel(link.filename)\n                except InvalidWheelFilename:\n                    self._log_skipped_link(link, 'invalid wheel filename')\n                    return\n                if (pkg_resources.safe_name(wheel.name).lower() !=\n                        search.canonical):\n                    self._log_skipped_link(\n                        link, 'wrong project name (not %s)' % search.supplied)\n                    return\n                if not wheel.supported():\n                    self._log_skipped_link(\n                        link, 'it is not compatible with this Python')\n                    return\n                # This is a dirty hack to prevent installing Binary Wheels from\n                # PyPI unless it is a Windows or Mac Binary Wheel. This is\n                # paired with a change to PyPI disabling uploads for the\n                # same. Once we have a mechanism for enabling support for\n                # binary wheels on linux that deals with the inherent problems\n                # of binary distribution this can be removed.\n                comes_from = getattr(link, \"comes_from\", None)\n                if (\n                        (\n                            not platform.startswith('win') and not\n                            platform.startswith('macosx') and not\n                            platform == 'cli'\n                        ) and\n                        comes_from is not None and\n                        urllib_parse.urlparse(\n                            comes_from.url\n                        ).netloc.endswith(PyPI.netloc)):\n                    if not wheel.supported(tags=supported_tags_noarch):\n                        self._log_skipped_link(\n                            link,\n                            \"it is a pypi-hosted binary \"\n                            \"Wheel on an unsupported platform\",\n                        )\n                        return\n                version = wheel.version\n\n        # This should be up by the search.ok_binary check, but see issue 2700.\n        if \"source\" not in search.formats and ext != wheel_ext:\n            self._log_skipped_link(\n                link, 'No sources permitted for %s' % search.supplied)\n            return\n\n        if not version:\n            version = egg_info_matches(egg_info, search.supplied, link)\n        if version is None:\n            self._log_skipped_link(\n                link, 'wrong project name (not %s)' % search.supplied)\n            return\n\n        if (link.internal is not None and not\n                link.internal and not\n                normalize_name(search.supplied).lower()\n                in self.allow_external and not\n                self.allow_all_external):\n            # We have a link that we are sure is external, so we should skip\n            #   it unless we are allowing externals\n            self._log_skipped_link(link, 'it is externally hosted')\n            self.need_warn_external = True\n            return\n\n        if (link.verifiable is not None and not\n                link.verifiable and not\n                (normalize_name(search.supplied).lower()\n                    in self.allow_unverified)):\n            # We have a link that we are sure we cannot verify its integrity,\n            #   so we should skip it unless we are allowing unsafe installs\n            #   for this requirement.\n            self._log_skipped_link(\n                link, 'it is an insecure and unverifiable file')\n            self.need_warn_unverified = True\n            return\n\n        match = self._py_version_re.search(version)\n        if match:\n            version = version[:match.start()]\n            py_version = match.group(1)\n            if py_version != sys.version[:3]:\n                self._log_skipped_link(\n                    link, 'Python version is incorrect')\n                return\n        logger.debug('Found link %s, version: %s', link, version)\n\n        return InstallationCandidate(search.supplied, version, link)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the Content - Type of the given url using a HEAD request.", "response": "def _get_content_type(url, session):\n        \"\"\"Get the Content-Type of the given url, using a HEAD request\"\"\"\n        scheme, netloc, path, query, fragment = urllib_parse.urlsplit(url)\n        if scheme not in ('http', 'https'):\n            # FIXME: some warning or something?\n            # assertion error?\n            return ''\n\n        resp = session.head(url, allow_redirects=True)\n        resp.raise_for_status()\n\n        return resp.headers.get(\"Content-Type\", \"\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef links(self):\n        for anchor in self.parsed.findall(\".//a\"):\n            if anchor.get(\"href\"):\n                href = anchor.get(\"href\")\n                url = self.clean_link(\n                    urllib_parse.urljoin(self.base_url, href)\n                )\n\n                # Determine if this link is internal. If that distinction\n                #   doesn't make sense in this context, then we don't make\n                #   any distinction.\n                internal = None\n                if self.api_version and self.api_version >= 2:\n                    # Only api_versions >= 2 have a distinction between\n                    #   external and internal links\n                    internal = bool(\n                        anchor.get(\"rel\") and\n                        \"internal\" in anchor.get(\"rel\").split()\n                    )\n\n                yield Link(url, self, internal=internal)", "response": "Yields all links in the page"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef verifiable(self):\n        trusted = self.trusted or getattr(self.comes_from, \"trusted\", None)\n        if trusted is not None and trusted:\n            # This link came from a trusted source. It *may* be verifiable but\n            #   first we need to see if this page is operating under the new\n            #   API version.\n            try:\n                api_version = getattr(self.comes_from, \"api_version\", None)\n                api_version = int(api_version)\n            except (ValueError, TypeError):\n                api_version = None\n\n            if api_version is None or api_version <= 1:\n                # This link is either trusted, or it came from a trusted,\n                #   however it is not operating under the API version 2 so\n                #   we can't make any claims about if it's safe or not\n                return\n\n            if self.hash:\n                # This link came from a trusted source and it has a hash, so we\n                #   can consider it safe.\n                return True\n            else:\n                # This link came from a trusted source, using the new API\n                #   version, and it does not have a hash. It is NOT verifiable\n                return False\n        elif trusted is not None:\n            # This link came from an untrusted source and we cannot trust it\n            return False", "response": "Returns True if this link can be verified after download False if it cannot determine."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_artifact(self):\n        from pip.vcs import vcs\n\n        if self.scheme in vcs.all_schemes:\n            return False\n\n        return True", "response": "Determines if this is an artifact or not."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates list of tuples containing source directory build directory and filenames.", "response": "def _get_data_files(self):\n        \"\"\"Generate list of '(package,src_dir,build_dir,filenames)' tuples\"\"\"\n        self.analyze_manifest()\n        data = []\n        for package in self.packages or ():\n            # Locate package source directory\n            src_dir = self.get_package_dir(package)\n\n            # Compute package build directory\n            build_dir = os.path.join(*([self.build_lib] + package.split('.')))\n\n            # Length of path to strip from found files\n            plen = len(src_dir) + 1\n\n            # Strip directory from globbed filenames\n            filenames = [\n                file[plen:] for file in self.find_data_files(package, src_dir)\n            ]\n            data.append((package, src_dir, build_dir, filenames))\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_data_files(self, package, src_dir):\n        globs = (self.package_data.get('', [])\n                 + self.package_data.get(package, []))\n        files = self.manifest_files.get(package, [])[:]\n        for pattern in globs:\n            # Each pattern has to be converted to a platform-specific path\n            files.extend(glob(os.path.join(src_dir, convert_path(pattern))))\n        return self.exclude_data_files(package, src_dir, files)", "response": "Return filenames for package s data files in src_dir"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking namespace packages __init__ for declare_namespace", "response": "def check_package(self, package, package_dir):\n        \"\"\"Check namespace packages' __init__ for declare_namespace\"\"\"\n        try:\n            return self.packages_checked[package]\n        except KeyError:\n            pass\n\n        init_py = orig.build_py.check_package(self, package, package_dir)\n        self.packages_checked[package] = init_py\n\n        if not init_py or not self.distribution.namespace_packages:\n            return init_py\n\n        for pkg in self.distribution.namespace_packages:\n            if pkg == package or pkg.startswith(package + '.'):\n                break\n        else:\n            return init_py\n\n        f = open(init_py, 'rbU')\n        if 'declare_namespace'.encode() not in f.read():\n            from distutils.errors import DistutilsError\n\n            raise DistutilsError(\n                \"Namespace package problem: %s is a namespace package, but \"\n                \"its\\n__init__.py does not call declare_namespace()! Please \"\n                'fix it.\\n(See the setuptools manual under '\n                '\"Namespace Packages\" for details.)\\n\"' % (package,)\n            )\n        f.close()\n        return init_py"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef exclude_data_files(self, package, src_dir, files):\n        globs = (self.exclude_package_data.get('', [])\n                 + self.exclude_package_data.get(package, []))\n        bad = []\n        for pattern in globs:\n            bad.extend(\n                fnmatch.filter(\n                    files, os.path.join(src_dir, convert_path(pattern))\n                )\n            )\n        bad = dict.fromkeys(bad)\n        seen = {}\n        return [\n            f for f in files if f not in bad\n            and f not in seen and seen.setdefault(f, 1)  # ditch dupes\n        ]", "response": "Filter filenames for package s data files in src_dir"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses a requirements file and yield InstallRequirement instances.", "response": "def parse_requirements(filename, finder=None, comes_from=None, options=None,\n                       session=None, wheel_cache=None):\n    \"\"\"\n    Parse a requirements file and yield InstallRequirement instances.\n\n    :param filename:    Path or url of requirements file.\n    :param finder:      Instance of pip.index.PackageFinder.\n    :param comes_from:  Origin description of requirements.\n    :param options:     Global options.\n    :param session:     Instance of pip.download.PipSession.\n    :param wheel_cache: Instance of pip.wheel.WheelCache\n    \"\"\"\n    if session is None:\n        raise TypeError(\n            \"parse_requirements() missing 1 required keyword argument: \"\n            \"'session'\"\n        )\n\n    _, content = get_file_content(\n        filename, comes_from=comes_from, session=session\n    )\n\n    lines = content.splitlines()\n    lines = ignore_comments(lines)\n    lines = join_lines(lines)\n    lines = skip_regex(lines, options)\n\n    for line_number, line in enumerate(lines, 1):\n        req_iter = process_line(line, filename, line_number, finder,\n                                comes_from, options, session, wheel_cache)\n        for req in req_iter:\n            yield req"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef process_line(line, filename, line_number, finder=None, comes_from=None,\n                 options=None, session=None, wheel_cache=None):\n    \"\"\"Process a single requirements line; This can result in creating/yielding\n    requirements, or updating the finder.\n\n    For lines that contain requirements, the only options that have an effect\n    are from SUPPORTED_OPTIONS_REQ, and they are scoped to the\n    requirement. Other options from SUPPORTED_OPTIONS may be present, but are\n    ignored.\n\n    For lines that do not contain requirements, the only options that have an\n    effect are from SUPPORTED_OPTIONS. Options from SUPPORTED_OPTIONS_REQ may\n    be present, but are ignored. These lines may contain multiple options\n    (although our docs imply only one is supported), and all our parsed and\n    affect the finder.\n\n    \"\"\"\n\n    parser = build_parser()\n    defaults = parser.get_default_values()\n    defaults.index_url = None\n    if finder:\n        # `finder.format_control` will be updated during parsing\n        defaults.format_control = finder.format_control\n    args_str, options_str = break_args_options(line)\n    opts, _ = parser.parse_args(shlex.split(options_str), defaults)\n\n    # yield a line requirement\n    if args_str:\n        comes_from = '-r %s (line %s)' % (filename, line_number)\n        isolated = options.isolated_mode if options else False\n        if options:\n            cmdoptions.check_install_build_global(options, opts)\n        # get the options that apply to requirements\n        req_options = {}\n        for dest in SUPPORTED_OPTIONS_REQ_DEST:\n            if dest in opts.__dict__ and opts.__dict__[dest]:\n                req_options[dest] = opts.__dict__[dest]\n        yield InstallRequirement.from_line(\n            args_str, comes_from, isolated=isolated, options=req_options,\n            wheel_cache=wheel_cache\n        )\n\n    # yield an editable requirement\n    elif opts.editables:\n        comes_from = '-r %s (line %s)' % (filename, line_number)\n        isolated = options.isolated_mode if options else False\n        default_vcs = options.default_vcs if options else None\n        yield InstallRequirement.from_editable(\n            opts.editables[0], comes_from=comes_from,\n            default_vcs=default_vcs, isolated=isolated,\n            wheel_cache=wheel_cache\n        )\n\n    # parse a nested requirements file\n    elif opts.requirements:\n        req_path = opts.requirements[0]\n        # original file is over http\n        if SCHEME_RE.search(filename):\n            # do a url join so relative paths work\n            req_path = urllib_parse.urljoin(filename, req_path)\n        # original file and nested file are paths\n        elif not SCHEME_RE.search(req_path):\n            # do a join so relative paths work\n            req_dir = os.path.dirname(filename)\n            req_path = os.path.join(os.path.dirname(filename), req_path)\n        # TODO: Why not use `comes_from='-r {} (line {})'` here as well?\n        parser = parse_requirements(\n            req_path, finder, comes_from, options, session,\n            wheel_cache=wheel_cache\n        )\n        for req in parser:\n            yield req\n\n    # set finder options\n    elif finder:\n        if opts.index_url:\n            finder.index_urls = [opts.index_url]\n        if opts.use_wheel is False:\n            finder.use_wheel = False\n            pip.index.fmt_ctl_no_use_wheel(finder.format_control)\n        if opts.no_index is True:\n            finder.index_urls = []\n        if opts.allow_all_external:\n            finder.allow_all_external = opts.allow_all_external\n        if opts.extra_index_urls:\n            finder.index_urls.extend(opts.extra_index_urls)\n        if opts.allow_external:\n            finder.allow_external |= set(\n                [normalize_name(v).lower() for v in opts.allow_external])\n        if opts.allow_unverified:\n            # Remove after 7.0\n            finder.allow_unverified |= set(\n                [normalize_name(v).lower() for v in opts.allow_unverified])\n        if opts.find_links:\n            # FIXME: it would be nice to keep track of the source\n            # of the find_links: support a find-links local path\n            # relative to a requirements file.\n            value = opts.find_links[0]\n            req_dir = os.path.dirname(os.path.abspath(filename))\n            relative_to_reqs_file = os.path.join(req_dir, value)\n            if os.path.exists(relative_to_reqs_file):\n                value = relative_to_reqs_file\n            finder.find_links.append(value)", "response": "Process a single line of requirements and yield a list of InstallRequirement objects."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef join_lines(iterator):\n    lines = []\n    for line in iterator:\n        if not line.endswith('\\\\'):\n            if lines:\n                lines.append(line)\n                yield ''.join(lines)\n                lines = []\n            else:\n                yield line\n        else:\n            lines.append(line.strip('\\\\'))", "response": "Yields a list of lines from an iterator that is a single line."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nstrip and filters empty or commented lines.", "response": "def ignore_comments(iterator):\n    \"\"\"\n    Strips and filters empty or commented lines.\n    \"\"\"\n    for line in iterator:\n        line = COMMENT_RE.sub('', line)\n        line = line.strip()\n        if line:\n            yield line"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nexcluding lines that match the skip_requirements_regex option", "response": "def skip_regex(lines, options):\n    \"\"\"\n    Optionally exclude lines that match '--skip-requirements-regex'\n    \"\"\"\n    skip_regex = options.skip_requirements_regex if options else None\n    if skip_regex:\n        lines = filterfalse(re.compile(skip_regex).search, lines)\n    return lines"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncompiles a marker as a function accepting an environment dict.", "response": "def compile(marker):\n    \"\"\"Return compiled marker as a function accepting an environment dict.\"\"\"\n    try:\n        return _cache[marker]\n    except KeyError:\n        pass\n    if not marker.strip():\n        def marker_fn(environment=None, override=None):\n            \"\"\"\"\"\"\n            return True\n    else:\n        compiled_marker = compile_marker(parse_marker(marker))\n        def marker_fn(environment=None, override=None):\n            \"\"\"override updates environment\"\"\"\n            if override is None:\n                override = {}\n            if environment is None:\n                environment = default_environment()\n            environment.update(override)\n            return eval(compiled_marker, environment)\n    marker_fn.__doc__ = marker\n    _cache[marker] = marker_fn\n    return _cache[marker]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nensure statement only contains allowed nodes.", "response": "def visit(self, node):\n        \"\"\"Ensure statement only contains allowed nodes.\"\"\"\n        if not isinstance(node, self.ALLOWED):\n            raise SyntaxError('Not allowed in environment markers.\\n%s\\n%s' %\n                               (self.statement,\n                               (' ' * node.col_offset) + '^'))\n        return ast.NodeTransformer.visit(self, node)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef visit_Attribute(self, node):\n        new_node = ast.Name(\"%s.%s\" % (node.value.id, node.attr), node.ctx)\n        return ast.copy_location(new_node, node)", "response": "Flatten one level of attribute access."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncoercing a value to a float or int.", "response": "def coerce(value):\n\t\"\"\"\n\tcoerce takes a value and attempts to convert it to a float,\n\tor int.\n\n\tIf none of the conversions are successful, the original value is\n\treturned.\n\n\t>>> coerce('3')\n\t3\n\n\t>>> coerce('3.0')\n\t3.0\n\n\t>>> coerce('foo')\n\t'foo'\n\n\t>>> coerce({})\n\t{}\n\n\t>>> coerce('{}')\n\t'{}'\n\t\"\"\"\n\twith contextlib2.suppress(Exception):\n\t\tloaded = json.loads(value)\n\t\tassert isinstance(loaded, numbers.Number)\n\t\treturn loaded\n\treturn value"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef copy_current_request_context(f):\n    top = _request_ctx_stack.top\n    if top is None:\n        raise RuntimeError('This decorator can only be used at local scopes '\n            'when a request context is on the stack.  For instance within '\n            'view functions.')\n    reqctx = top.copy()\n    def wrapper(*args, **kwargs):\n        with reqctx:\n            return f(*args, **kwargs)\n    return update_wrapper(wrapper, f)", "response": "A decorator that returns a function that copies the current request context."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef push(self):\n        self._refcnt += 1\n        _app_ctx_stack.push(self)\n        appcontext_pushed.send(self.app)", "response": "Binds the app context to the current context."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npopping the app context.", "response": "def pop(self, exc=None):\n        \"\"\"Pops the app context.\"\"\"\n        self._refcnt -= 1\n        if self._refcnt <= 0:\n            if exc is None:\n                exc = sys.exc_info()[1]\n            self.app.do_teardown_appcontext(exc)\n        rv = _app_ctx_stack.pop()\n        assert rv is self, 'Popped wrong app context.  (%r instead of %r)' \\\n            % (rv, self)\n        appcontext_popped.send(self.app)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef copy(self):\n        return self.__class__(self.app,\n            environ=self.request.environ,\n            request=self.request\n        )", "response": "Creates a copy of this request context with the same request object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nhook into the matching of the request.", "response": "def match_request(self):\n        \"\"\"Can be overridden by a subclass to hook into the matching\n        of the request.\n        \"\"\"\n        try:\n            url_rule, self.request.view_args = \\\n                self.url_adapter.match(return_rule=True)\n            self.request.url_rule = url_rule\n        except HTTPException as e:\n            self.request.routing_exception = e"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nbinds the request context to the current context.", "response": "def push(self):\n        \"\"\"Binds the request context to the current context.\"\"\"\n        # If an exception occurs in debug mode or if context preservation is\n        # activated under exception situations exactly one context stays\n        # on the stack.  The rationale is that you want to access that\n        # information under debug situations.  However if someone forgets to\n        # pop that context again we want to make sure that on the next push\n        # it's invalidated, otherwise we run at risk that something leaks\n        # memory.  This is usually only a problem in testsuite since this\n        # functionality is not active in production environments.\n        top = _request_ctx_stack.top\n        if top is not None and top.preserved:\n            top.pop(top._preserved_exc)\n\n        # Before we push the request context we have to ensure that there\n        # is an application context.\n        app_ctx = _app_ctx_stack.top\n        if app_ctx is None or app_ctx.app != self.app:\n            app_ctx = self.app.app_context()\n            app_ctx.push()\n            self._implicit_app_ctx_stack.append(app_ctx)\n        else:\n            self._implicit_app_ctx_stack.append(None)\n\n        _request_ctx_stack.push(self)\n\n        # Open the session at the moment that the request context is\n        # available. This allows a custom open_session method to use the\n        # request context (e.g. code that access database information\n        # stored on `g` instead of the appcontext).\n        self.session = self.app.open_session(self.request)\n        if self.session is None:\n            self.session = self.app.make_null_session()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\npop the request context and unbinds it by doing that.", "response": "def pop(self, exc=None):\n        \"\"\"Pops the request context and unbinds it by doing that.  This will\n        also trigger the execution of functions registered by the\n        :meth:`~flask.Flask.teardown_request` decorator.\n\n        .. versionchanged:: 0.9\n           Added the `exc` argument.\n        \"\"\"\n        app_ctx = self._implicit_app_ctx_stack.pop()\n\n        clear_request = False\n        if not self._implicit_app_ctx_stack:\n            self.preserved = False\n            self._preserved_exc = None\n            if exc is None:\n                exc = sys.exc_info()[1]\n            self.app.do_teardown_request(exc)\n\n            # If this interpreter supports clearing the exception information\n            # we do that now.  This will only go into effect on Python 2.x,\n            # on 3.x it disappears automatically at the end of the exception\n            # stack.\n            if hasattr(sys, 'exc_clear'):\n                sys.exc_clear()\n\n            request_close = getattr(self.request, 'close', None)\n            if request_close is not None:\n                request_close()\n            clear_request = True\n\n        rv = _request_ctx_stack.pop()\n        assert rv is self, 'Popped wrong request context.  (%r instead of %r)' \\\n            % (rv, self)\n\n        # get rid of circular dependencies at the end of the request\n        # so that we don't require the GC to be active.\n        if clear_request:\n            rv.request.environ['werkzeug.request'] = None\n\n        # Get rid of the app as well if necessary.\n        if app_ctx is not None:\n            app_ctx.pop(exc)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef backup_dir(dir, ext='.bak'):\n    n = 1\n    extension = ext\n    while os.path.exists(dir + extension):\n        n += 1\n        extension = ext + str(n)\n    return dir + extension", "response": "Figure out the name of a directory to back up the given dir."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning True if all the paths have the same leading path name.", "response": "def has_leading_dir(paths):\n    \"\"\"Returns true if all the paths have the same leading path name\n    (i.e., everything is in one subdirectory in an archive)\"\"\"\n    common_prefix = None\n    for path in paths:\n        prefix, rest = split_leading_dir(path)\n        if not prefix:\n            return False\n        elif common_prefix is None:\n            common_prefix = prefix\n        elif prefix != common_prefix:\n            return False\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmakes a filename relative where the filename path and it is relative to rel_to >>>", "response": "def make_path_relative(path, rel_to):\n    \"\"\"\n    Make a filename relative, where the filename path, and it is\n    relative to rel_to\n\n        >>> make_path_relative('/usr/share/something/a-file.pth',\n        ...                    '/usr/share/another-place/src/Directory')\n        '../../../something/a-file.pth'\n        >>> make_path_relative('/usr/share/something/a-file.pth',\n        ...                    '/home/user/src/Directory')\n        '../../../usr/share/something/a-file.pth'\n        >>> make_path_relative('/usr/share/a-file.pth', '/usr/share/')\n        'a-file.pth'\n    \"\"\"\n    path_filename = os.path.basename(path)\n    path = os.path.dirname(path)\n    path = os.path.normpath(os.path.abspath(path))\n    rel_to = os.path.normpath(os.path.abspath(rel_to))\n    path_parts = path.strip(os.path.sep).split(os.path.sep)\n    rel_to_parts = rel_to.strip(os.path.sep).split(os.path.sep)\n    while path_parts and rel_to_parts and path_parts[0] == rel_to_parts[0]:\n        path_parts.pop(0)\n        rel_to_parts.pop(0)\n    full_parts = ['..'] * len(rel_to_parts) + path_parts + [path_filename]\n    if full_parts == ['']:\n        return '.' + os.path.sep\n    return os.path.sep.join(full_parts)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn True if given Distribution is installed in user site.", "response": "def dist_in_usersite(dist):\n    \"\"\"\n    Return True if given Distribution is installed in user site.\n    \"\"\"\n    norm_path = normalize_path(dist_location(dist))\n    return norm_path.startswith(normalize_path(user_site))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbeing distribution an editable install?", "response": "def dist_is_editable(dist):\n    \"\"\"Is distribution an editable install?\"\"\"\n    # TODO: factor out determining editableness out of FrozenRequirement\n    from pip import FrozenRequirement\n    req = FrozenRequirement.from_dist(dist, [])\n    return req.editable"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef untar_file(filename, location):\n    ensure_dir(location)\n    if filename.lower().endswith('.gz') or filename.lower().endswith('.tgz'):\n        mode = 'r:gz'\n    elif filename.lower().endswith(BZ2_EXTENSIONS):\n        mode = 'r:bz2'\n    elif filename.lower().endswith('.tar'):\n        mode = 'r'\n    else:\n        logger.warning(\n            'Cannot determine compression type for file %s', filename,\n        )\n        mode = 'r:*'\n    tar = tarfile.open(filename, mode)\n    try:\n        # note: python<=2.5 doesn't seem to know about pax headers, filter them\n        leading = has_leading_dir([\n            member.name for member in tar.getmembers()\n            if member.name != 'pax_global_header'\n        ])\n        for member in tar.getmembers():\n            fn = member.name\n            if fn == 'pax_global_header':\n                continue\n            if leading:\n                fn = split_leading_dir(fn)[1]\n            path = os.path.join(location, fn)\n            if member.isdir():\n                ensure_dir(path)\n            elif member.issym():\n                try:\n                    tar._extract_member(member, path)\n                except Exception as exc:\n                    # Some corrupt tar files seem to produce this\n                    # (specifically bad symlinks)\n                    logger.warning(\n                        'In the tar file %s the member %s is invalid: %s',\n                        filename, member.name, exc,\n                    )\n                    continue\n            else:\n                try:\n                    fp = tar.extractfile(member)\n                except (KeyError, AttributeError) as exc:\n                    # Some corrupt tar files seem to produce this\n                    # (specifically bad symlinks)\n                    logger.warning(\n                        'In the tar file %s the member %s is invalid: %s',\n                        filename, member.name, exc,\n                    )\n                    continue\n                ensure_dir(os.path.dirname(path))\n                destfp = open(path, 'wb')\n                try:\n                    shutil.copyfileobj(fp, destfp)\n                finally:\n                    destfp.close()\n                fp.close()\n                # member have any execute permissions for user/group/world?\n                if member.mode & 0o111:\n                    # make dest file have execute for user/group/world\n                    # no-op on windows per python docs\n                    os.chmod(path, (0o777 - current_umask() | 0o111))\n    finally:\n        tar.close()", "response": "Untar a file into a new location."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nregister a function that is called when the blueprint is registered on the application.", "response": "def record(self, func):\n        \"\"\"Registers a function that is called when the blueprint is\n        registered on the application.  This function is called with the\n        state as argument as returned by the :meth:`make_setup_state`\n        method.\n        \"\"\"\n        if self._got_registered_once and self.warn_on_modifications:\n            from warnings import warn\n            warn(Warning('The blueprint was already registered once '\n                         'but is getting modified now.  These changes '\n                         'will not show up.'))\n        self.deferred_functions.append(func)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a new BlueprintSetupState object that is later passed to the register callback functions.", "response": "def make_setup_state(self, app, options, first_registration=False):\n        \"\"\"Creates an instance of :meth:`~flask.blueprints.BlueprintSetupState`\n        object that is later passed to the register callback functions.\n        Subclasses can override this to return a subclass of the setup state.\n        \"\"\"\n        return BlueprintSetupState(self, app, options, first_registration)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlikes :meth:`Flask.endpoint` but for a blueprint. This does not prefix the endpoint with the blueprint name, this has to be done explicitly by the user of this method. If the endpoint is prefixed with a `.` it will be registered to the current blueprint, otherwise it's an application independent endpoint.", "response": "def endpoint(self, endpoint):\n        \"\"\"Like :meth:`Flask.endpoint` but for a blueprint.  This does not\n        prefix the endpoint with the blueprint name, this has to be done\n        explicitly by the user of this method.  If the endpoint is prefixed\n        with a `.` it will be registered to the current blueprint, otherwise\n        it's an application independent endpoint.\n        \"\"\"\n        def decorator(f):\n            def register_endpoint(state):\n                state.app.view_functions[endpoint] = f\n            self.record_once(register_endpoint)\n            return f\n        return decorator"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nregistering a custom template filter available application wide.", "response": "def app_template_filter(self, name=None):\n        \"\"\"Register a custom template filter, available application wide.  Like\n        :meth:`Flask.template_filter` but for a blueprint.\n\n        :param name: the optional name of the filter, otherwise the\n                     function name will be used.\n        \"\"\"\n        def decorator(f):\n            self.add_app_template_filter(f, name=name)\n            return f\n        return decorator"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nregisters a custom template filter available application wide.", "response": "def add_app_template_filter(self, f, name=None):\n        \"\"\"Register a custom template filter, available application wide.  Like\n        :meth:`Flask.add_template_filter` but for a blueprint.  Works exactly\n        like the :meth:`app_template_filter` decorator.\n\n        :param name: the optional name of the filter, otherwise the\n                     function name will be used.\n        \"\"\"\n        def register_template(state):\n            state.app.jinja_env.filters[name or f.__name__] = f\n        self.record_once(register_template)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nregister a custom template global, available application wide. Like :meth:`Flask.template_global` but for a blueprint. .. versionadded:: 0.10 :param name: the optional name of the global, otherwise the function name will be used.", "response": "def app_template_global(self, name=None):\n        \"\"\"Register a custom template global, available application wide.  Like\n        :meth:`Flask.template_global` but for a blueprint.\n\n        .. versionadded:: 0.10\n\n        :param name: the optional name of the global, otherwise the\n                     function name will be used.\n        \"\"\"\n        def decorator(f):\n            self.add_app_template_global(f, name=name)\n            return f\n        return decorator"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_app_template_global(self, f, name=None):\n        def register_template(state):\n            state.app.jinja_env.globals[name or f.__name__] = f\n        self.record_once(register_template)", "response": "Register a custom template global available application wide."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nliking :meth:`Flask.before_request` but for a blueprint. This function is only executed before each request that is handled by a function of that blueprint.", "response": "def before_request(self, f):\n        \"\"\"Like :meth:`Flask.before_request` but for a blueprint.  This function\n        is only executed before each request that is handled by a function of\n        that blueprint.\n        \"\"\"\n        self.record_once(lambda s: s.app.before_request_funcs\n            .setdefault(self.name, []).append(f))\n        return f"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlikes Flask. before_request but adds a function to be executed before each request.", "response": "def before_app_request(self, f):\n        \"\"\"Like :meth:`Flask.before_request`.  Such a function is executed\n        before each request, even if outside of a blueprint.\n        \"\"\"\n        self.record_once(lambda s: s.app.before_request_funcs\n            .setdefault(None, []).append(f))\n        return f"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nlike Flask. before_first_request. This is meant to be used by the Flask app.", "response": "def before_app_first_request(self, f):\n        \"\"\"Like :meth:`Flask.before_first_request`.  Such a function is\n        executed before the first request to the application.\n        \"\"\"\n        self.record_once(lambda s: s.app.before_first_request_funcs.append(f))\n        return f"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlikes :meth:`Flask.after_request` but for a blueprint. This function is only executed after each request that is handled by a function of that blueprint.", "response": "def after_request(self, f):\n        \"\"\"Like :meth:`Flask.after_request` but for a blueprint.  This function\n        is only executed after each request that is handled by a function of\n        that blueprint.\n        \"\"\"\n        self.record_once(lambda s: s.app.after_request_funcs\n            .setdefault(self.name, []).append(f))\n        return f"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nliking Flask. after_request but for a blueprint.", "response": "def after_app_request(self, f):\n        \"\"\"Like :meth:`Flask.after_request` but for a blueprint.  Such a function\n        is executed after each request, even if outside of the blueprint.\n        \"\"\"\n        self.record_once(lambda s: s.app.after_request_funcs\n            .setdefault(None, []).append(f))\n        return f"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlikes :meth:`Flask.teardown_request` but for a blueprint. This function is only executed when tearing down requests handled by a function of that blueprint. Teardown request functions are executed when the request context is popped, even when no actual request was performed.", "response": "def teardown_request(self, f):\n        \"\"\"Like :meth:`Flask.teardown_request` but for a blueprint.  This\n        function is only executed when tearing down requests handled by a\n        function of that blueprint.  Teardown request functions are executed\n        when the request context is popped, even when no actual request was\n        performed.\n        \"\"\"\n        self.record_once(lambda s: s.app.teardown_request_funcs\n            .setdefault(self.name, []).append(f))\n        return f"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nliking Flask. teardown_request but for a blueprint.", "response": "def teardown_app_request(self, f):\n        \"\"\"Like :meth:`Flask.teardown_request` but for a blueprint.  Such a\n        function is executed when tearing down each request, even if outside of\n        the blueprint.\n        \"\"\"\n        self.record_once(lambda s: s.app.teardown_request_funcs\n            .setdefault(None, []).append(f))\n        return f"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nliking :meth:`Flask.context_processor` but for a blueprint. This function is only executed for requests handled by a blueprint.", "response": "def context_processor(self, f):\n        \"\"\"Like :meth:`Flask.context_processor` but for a blueprint.  This\n        function is only executed for requests handled by a blueprint.\n        \"\"\"\n        self.record_once(lambda s: s.app.template_context_processors\n            .setdefault(self.name, []).append(f))\n        return f"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef app_context_processor(self, f):\n        self.record_once(lambda s: s.app.template_context_processors\n            .setdefault(None, []).append(f))\n        return f", "response": "A decorator that registers a function as a context processor for the application."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef app_errorhandler(self, code):\n        def decorator(f):\n            self.record_once(lambda s: s.app.errorhandler(code)(f))\n            return f\n        return decorator", "response": "Decorator for Flask. errorhandler."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef url_value_preprocessor(self, f):\n        self.record_once(lambda s: s.app.url_value_preprocessors\n            .setdefault(self.name, []).append(f))\n        return f", "response": "Registers a function as URL value preprocessor for this\n        blueprint."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef url_defaults(self, f):\n        self.record_once(lambda s: s.app.url_default_functions\n            .setdefault(self.name, []).append(f))\n        return f", "response": "Callback function for URL defaults for this blueprint."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a url value preprocessor function to the application wide list of url value parsers.", "response": "def app_url_value_preprocessor(self, f):\n        \"\"\"Same as :meth:`url_value_preprocessor` but application wide.\n        \"\"\"\n        self.record_once(lambda s: s.app.url_value_preprocessors\n            .setdefault(None, []).append(f))\n        return f"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef errorhandler(self, code_or_exception):\n        def decorator(f):\n            self.record_once(lambda s: s.app._register_error_handler(\n                self.name, code_or_exception, f))\n            return f\n        return decorator", "response": "Decorator that registers an error handler that becomes active for this blueprint\n        only."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrequest contexts disappear when the response is started on the server. This is done for efficiency reasons and to make it less likely to encounter memory leaks with badly written WSGI middlewares. The downside is that if you are using streamed responses, the generator cannot access request bound information any more. This function however can help you keep the context around for longer:: from flask import stream_with_context, request, Response @app.route('/stream') def streamed_response(): @stream_with_context def generate(): yield 'Hello ' yield request.args['name'] yield '!' return Response(generate()) Alternatively it can also be used around a specific generator:: from flask import stream_with_context, request, Response @app.route('/stream') def streamed_response(): def generate(): yield 'Hello ' yield request.args['name'] yield '!' return Response(stream_with_context(generate())) .. versionadded:: 0.9", "response": "def stream_with_context(generator_or_function):\n    \"\"\"Request contexts disappear when the response is started on the server.\n    This is done for efficiency reasons and to make it less likely to encounter\n    memory leaks with badly written WSGI middlewares.  The downside is that if\n    you are using streamed responses, the generator cannot access request bound\n    information any more.\n\n    This function however can help you keep the context around for longer::\n\n        from flask import stream_with_context, request, Response\n\n        @app.route('/stream')\n        def streamed_response():\n            @stream_with_context\n            def generate():\n                yield 'Hello '\n                yield request.args['name']\n                yield '!'\n            return Response(generate())\n\n    Alternatively it can also be used around a specific generator::\n\n        from flask import stream_with_context, request, Response\n\n        @app.route('/stream')\n        def streamed_response():\n            def generate():\n                yield 'Hello '\n                yield request.args['name']\n                yield '!'\n            return Response(stream_with_context(generate()))\n\n    .. versionadded:: 0.9\n    \"\"\"\n    try:\n        gen = iter(generator_or_function)\n    except TypeError:\n        def decorator(*args, **kwargs):\n            gen = generator_or_function()\n            return stream_with_context(gen)\n        return update_wrapper(decorator, generator_or_function)\n\n    def generator():\n        ctx = _request_ctx_stack.top\n        if ctx is None:\n            raise RuntimeError('Attempted to stream with context but '\n                'there was no context in the first place to keep around.')\n        with ctx:\n            # Dummy sentinel.  Has to be inside the context block or we're\n            # not actually keeping the context around.\n            yield None\n\n            # The try/finally is here so that if someone passes a WSGI level\n            # iterator in we're still running the cleanup logic.  Generators\n            # don't need that because they are closed on their destruction\n            # automatically.\n            try:\n                for item in gen:\n                    yield item\n            finally:\n                if hasattr(gen, 'close'):\n                    gen.close()\n\n    # The trick is to start the generator.  Then the code execution runs until\n    # the first dummy None is yielded at which point the context was already\n    # pushed.  This item is discarded.  Then when the iteration continues the\n    # real generator is executed.\n    wrapped_g = generator()\n    next(wrapped_g)\n    return wrapped_g"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef url_for(endpoint, **values):\n    appctx = _app_ctx_stack.top\n    reqctx = _request_ctx_stack.top\n    if appctx is None:\n        raise RuntimeError('Attempted to generate a URL without the '\n                           'application context being pushed. This has to be '\n                           'executed when application context is available.')\n\n    # If request specific information is available we have some extra\n    # features that support \"relative\" urls.\n    if reqctx is not None:\n        url_adapter = reqctx.url_adapter\n        blueprint_name = request.blueprint\n        if not reqctx.request._is_old_module:\n            if endpoint[:1] == '.':\n                if blueprint_name is not None:\n                    endpoint = blueprint_name + endpoint\n                else:\n                    endpoint = endpoint[1:]\n        else:\n            # TODO: get rid of this deprecated functionality in 1.0\n            if '.' not in endpoint:\n                if blueprint_name is not None:\n                    endpoint = blueprint_name + '.' + endpoint\n            elif endpoint.startswith('.'):\n                endpoint = endpoint[1:]\n        external = values.pop('_external', False)\n\n    # Otherwise go with the url adapter from the appctx and make\n    # the urls external by default.\n    else:\n        url_adapter = appctx.url_adapter\n        if url_adapter is None:\n            raise RuntimeError('Application was not able to create a URL '\n                               'adapter for request independent URL generation. '\n                               'You might be able to fix this by setting '\n                               'the SERVER_NAME config variable.')\n        external = values.pop('_external', True)\n\n    anchor = values.pop('_anchor', None)\n    method = values.pop('_method', None)\n    scheme = values.pop('_scheme', None)\n    appctx.app.inject_url_defaults(endpoint, values)\n\n    if scheme is not None:\n        if not external:\n            raise ValueError('When specifying _scheme, _external must be True')\n        url_adapter.url_scheme = scheme\n\n    try:\n        rv = url_adapter.build(endpoint, values, method=method,\n                               force_external=external)\n    except BuildError as error:\n        # We need to inject the values again so that the app callback can\n        # deal with that sort of stuff.\n        values['_external'] = external\n        values['_anchor'] = anchor\n        values['_method'] = method\n        return appctx.app.handle_url_build_error(error, endpoint, values)\n\n    if anchor is not None:\n        rv += '#' + url_quote(anchor)\n    return rv", "response": "Generates a URL to the given endpoint with the given values."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading a macro or variable a template exports.", "response": "def get_template_attribute(template_name, attribute):\n    \"\"\"Loads a macro (or variable) a template exports.  This can be used to\n    invoke a macro from within Python code.  If you for example have a\n    template named `_cider.html` with the following contents:\n\n    .. sourcecode:: html+jinja\n\n       {% macro hello(name) %}Hello {{ name }}!{% endmacro %}\n\n    You can access this from Python code like this::\n\n        hello = get_template_attribute('_cider.html', 'hello')\n        return hello('World')\n\n    .. versionadded:: 0.2\n\n    :param template_name: the name of the template\n    :param attribute: the name of the variable of macro to access\n    \"\"\"\n    return getattr(current_app.jinja_env.get_template(template_name).module,\n                   attribute)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nflashes a message to the next request.", "response": "def flash(message, category='message'):\n    \"\"\"Flashes a message to the next request.  In order to remove the\n    flashed message from the session and to display it to the user,\n    the template has to call :func:`get_flashed_messages`.\n\n    .. versionchanged:: 0.3\n       `category` parameter added.\n\n    :param message: the message to be flashed.\n    :param category: the category for the message.  The following values\n                     are recommended: ``'message'`` for any kind of message,\n                     ``'error'`` for errors, ``'info'`` for information\n                     messages and ``'warning'`` for warnings.  However any\n                     kind of string can be used as category.\n    \"\"\"\n    # Original implementation:\n    #\n    #     session.setdefault('_flashes', []).append((category, message))\n    #\n    # This assumed that changes made to mutable structures in the session are\n    # are always in sync with the sess on object, which is not true for session\n    # implementations that use external storage for keeping their keys/values.\n    flashes = session.get('_flashes', [])\n    flashes.append((category, message))\n    session['_flashes'] = flashes\n    message_flashed.send(current_app._get_current_object(),\n                         message=message, category=category)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_flashed_messages(with_categories=False, category_filter=[]):\n    flashes = _request_ctx_stack.top.flashes\n    if flashes is None:\n        _request_ctx_stack.top.flashes = flashes = session.pop('_flashes') \\\n            if '_flashes' in session else []\n    if category_filter:\n        flashes = list(filter(lambda f: f[0] in category_filter, flashes))\n    if not with_categories:\n        return [x[1] for x in flashes]\n    return flashes", "response": "Pulls all flashed messages from the session and returns them."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef send_file(filename_or_fp, mimetype=None, as_attachment=False,\n              attachment_filename=None, add_etags=True,\n              cache_timeout=None, conditional=False):\n    \"\"\"Sends the contents of a file to the client.  This will use the\n    most efficient method available and configured.  By default it will\n    try to use the WSGI server's file_wrapper support.  Alternatively\n    you can set the application's :attr:`~Flask.use_x_sendfile` attribute\n    to ``True`` to directly emit an `X-Sendfile` header.  This however\n    requires support of the underlying webserver for `X-Sendfile`.\n\n    By default it will try to guess the mimetype for you, but you can\n    also explicitly provide one.  For extra security you probably want\n    to send certain files as attachment (HTML for instance).  The mimetype\n    guessing requires a `filename` or an `attachment_filename` to be\n    provided.\n\n    Please never pass filenames to this function from user sources without\n    checking them first.  Something like this is usually sufficient to\n    avoid security problems::\n\n        if '..' in filename or filename.startswith('/'):\n            abort(404)\n\n    .. versionadded:: 0.2\n\n    .. versionadded:: 0.5\n       The `add_etags`, `cache_timeout` and `conditional` parameters were\n       added.  The default behavior is now to attach etags.\n\n    .. versionchanged:: 0.7\n       mimetype guessing and etag support for file objects was\n       deprecated because it was unreliable.  Pass a filename if you are\n       able to, otherwise attach an etag yourself.  This functionality\n       will be removed in Flask 1.0\n\n    .. versionchanged:: 0.9\n       cache_timeout pulls its default from application config, when None.\n\n    :param filename_or_fp: the filename of the file to send.  This is\n                           relative to the :attr:`~Flask.root_path` if a\n                           relative path is specified.\n                           Alternatively a file object might be provided\n                           in which case `X-Sendfile` might not work and\n                           fall back to the traditional method.  Make sure\n                           that the file pointer is positioned at the start\n                           of data to send before calling :func:`send_file`.\n    :param mimetype: the mimetype of the file if provided, otherwise\n                     auto detection happens.\n    :param as_attachment: set to `True` if you want to send this file with\n                          a ``Content-Disposition: attachment`` header.\n    :param attachment_filename: the filename for the attachment if it\n                                differs from the file's filename.\n    :param add_etags: set to `False` to disable attaching of etags.\n    :param conditional: set to `True` to enable conditional responses.\n\n    :param cache_timeout: the timeout in seconds for the headers. When `None`\n                          (default), this value is set by\n                          :meth:`~Flask.get_send_file_max_age` of\n                          :data:`~flask.current_app`.\n    \"\"\"\n    mtime = None\n    if isinstance(filename_or_fp, string_types):\n        filename = filename_or_fp\n        file = None\n    else:\n        from warnings import warn\n        file = filename_or_fp\n        filename = getattr(file, 'name', None)\n\n        # XXX: this behavior is now deprecated because it was unreliable.\n        # removed in Flask 1.0\n        if not attachment_filename and not mimetype \\\n           and isinstance(filename, string_types):\n            warn(DeprecationWarning('The filename support for file objects '\n                'passed to send_file is now deprecated.  Pass an '\n                'attach_filename if you want mimetypes to be guessed.'),\n                stacklevel=2)\n        if add_etags:\n            warn(DeprecationWarning('In future flask releases etags will no '\n                'longer be generated for file objects passed to the send_file '\n                'function because this behavior was unreliable.  Pass '\n                'filenames instead if possible, otherwise attach an etag '\n                'yourself based on another value'), stacklevel=2)\n\n    if filename is not None:\n        if not os.path.isabs(filename):\n            filename = os.path.join(current_app.root_path, filename)\n    if mimetype is None and (filename or attachment_filename):\n        mimetype = mimetypes.guess_type(filename or attachment_filename)[0]\n    if mimetype is None:\n        mimetype = 'application/octet-stream'\n\n    headers = Headers()\n    if as_attachment:\n        if attachment_filename is None:\n            if filename is None:\n                raise TypeError('filename unavailable, required for '\n                                'sending as attachment')\n            attachment_filename = os.path.basename(filename)\n        headers.add('Content-Disposition', 'attachment',\n                    filename=attachment_filename)\n\n    if current_app.use_x_sendfile and filename:\n        if file is not None:\n            file.close()\n        headers['X-Sendfile'] = filename\n        headers['Content-Length'] = os.path.getsize(filename)\n        data = None\n    else:\n        if file is None:\n            file = open(filename, 'rb')\n            mtime = os.path.getmtime(filename)\n            headers['Content-Length'] = os.path.getsize(filename)\n        data = wrap_file(request.environ, file)\n\n    rv = current_app.response_class(data, mimetype=mimetype, headers=headers,\n                                    direct_passthrough=True)\n\n    # if we know the file modification date, we can store it as the\n    # the time of the last modification.\n    if mtime is not None:\n        rv.last_modified = int(mtime)\n\n    rv.cache_control.public = True\n    if cache_timeout is None:\n        cache_timeout = current_app.get_send_file_max_age(filename)\n    if cache_timeout is not None:\n        rv.cache_control.max_age = cache_timeout\n        rv.expires = int(time() + cache_timeout)\n\n    if add_etags and filename is not None:\n        rv.set_etag('flask-%s-%s-%s' % (\n            os.path.getmtime(filename),\n            os.path.getsize(filename),\n            adler32(\n                filename.encode('utf-8') if isinstance(filename, text_type)\n                else filename\n            ) & 0xffffffff\n        ))\n        if conditional:\n            rv = rv.make_conditional(request)\n            # make sure we don't send x-sendfile for servers that\n            # ignore the 304 status code for x-sendfile.\n            if rv.status_code == 304:\n                rv.headers.pop('x-sendfile', None)\n    return rv", "response": "Sends a file to the client."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef safe_join(directory, filename):\n    filename = posixpath.normpath(filename)\n    for sep in _os_alt_seps:\n        if sep in filename:\n            raise NotFound()\n    if os.path.isabs(filename) or \\\n       filename == '..' or \\\n       filename.startswith('../'):\n        raise NotFound()\n    return os.path.join(directory, filename)", "response": "Safely joins directory and filename."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef send_from_directory(directory, filename, **options):\n    filename = safe_join(directory, filename)\n    if not os.path.isfile(filename):\n        raise NotFound()\n    options.setdefault('conditional', True)\n    return send_file(filename, **options)", "response": "Send a file from a given directory with a custom send_file function."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_root_path(import_name):\n    # Module already imported and has a file attribute.  Use that first.\n    mod = sys.modules.get(import_name)\n    if mod is not None and hasattr(mod, '__file__'):\n        return os.path.dirname(os.path.abspath(mod.__file__))\n\n    # Next attempt: check the loader.\n    loader = pkgutil.get_loader(import_name)\n\n    # Loader does not exist or we're referring to an unloaded main module\n    # or a main module without path (interactive sessions), go with the\n    # current working directory.\n    if loader is None or import_name == '__main__':\n        return os.getcwd()\n\n    # For .egg, zipimporter does not have get_filename until Python 2.7.\n    # Some other loaders might exhibit the same behavior.\n    if hasattr(loader, 'get_filename'):\n        filepath = loader.get_filename(import_name)\n    else:\n        # Fall back to imports.\n        __import__(import_name)\n        filepath = sys.modules[import_name].__file__\n\n    # filepath is import_name.py for a module, or __init__.py for a package.\n    return os.path.dirname(os.path.abspath(filepath))", "response": "Returns the path to a package or cwd if that cannot be found."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef find_package(import_name):\n    root_mod_name = import_name.split('.')[0]\n    loader = pkgutil.get_loader(root_mod_name)\n    if loader is None or import_name == '__main__':\n        # import name is not found, or interactive/main module\n        package_path = os.getcwd()\n    else:\n        # For .egg, zipimporter does not have get_filename until Python 2.7.\n        if hasattr(loader, 'get_filename'):\n            filename = loader.get_filename(root_mod_name)\n        elif hasattr(loader, 'archive'):\n            # zipimporter's loader.archive points to the .egg or .zip\n            # archive filename is dropped in call to dirname below.\n            filename = loader.archive\n        else:\n            # At least one loader is missing both get_filename and archive:\n            # Google App Engine's HardenedModulesHook\n            #\n            # Fall back to imports.\n            __import__(import_name)\n            filename = sys.modules[import_name].__file__\n        package_path = os.path.abspath(os.path.dirname(filename))\n        # package_path ends with __init__.py for a package\n        if loader.is_package(root_mod_name):\n            package_path = os.path.dirname(package_path)\n\n    site_parent, site_folder = os.path.split(package_path)\n    py_prefix = os.path.abspath(sys.prefix)\n    if package_path.startswith(py_prefix):\n        return py_prefix, package_path\n    elif site_folder.lower() == 'site-packages':\n        parent, folder = os.path.split(site_parent)\n        # Windows like installations\n        if folder.lower() == 'lib':\n            base_dir = parent\n        # UNIX like installations\n        elif os.path.basename(parent).lower() == 'lib':\n            base_dir = os.path.dirname(parent)\n        else:\n            base_dir = site_parent\n        return base_dir, package_path\n    return None, package_path", "response": "Finds a package and returns the prefix and folder that contains the package or\n    module."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nopen a resource from the application s resource folder.", "response": "def open_resource(self, resource, mode='rb'):\n        \"\"\"Opens a resource from the application's resource folder.  To see\n        how this works, consider the following folder structure::\n\n            /myapplication.py\n            /schema.sql\n            /static\n                /style.css\n            /templates\n                /layout.html\n                /index.html\n\n        If you want to open the `schema.sql` file you would do the\n        following::\n\n            with app.open_resource('schema.sql') as f:\n                contents = f.read()\n                do_something_with(contents)\n\n        :param resource: the name of the resource.  To access resources within\n                         subfolders use forward slashes as separator.\n        :param mode: resource file opening mode, default is 'rb'.\n        \"\"\"\n        if mode not in ('r', 'rb'):\n            raise ValueError('Resources can only be opened for reading')\n        return open(os.path.join(self.root_path, resource), mode)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef run(self, options, args):\n        shells = COMPLETION_SCRIPTS.keys()\n        shell_options = ['--' + shell for shell in sorted(shells)]\n        if options.shell in shells:\n            script = COMPLETION_SCRIPTS.get(options.shell, '')\n            print(BASE_COMPLETION % {'script': script, 'shell': options.shell})\n        else:\n            sys.stderr.write(\n                'ERROR: You must pass %s\\n' % ' or '.join(shell_options)\n            )", "response": "Prints the completion code of the given shell"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a directory to store cached wheels for a link.", "response": "def _cache_for_link(cache_dir, link):\n    \"\"\"\n    Return a directory to store cached wheels in for link.\n\n    Because there are M wheels for any one sdist, we provide a directory\n    to cache them in, and then consult that directory when looking up\n    cache hits.\n\n    We only insert things into the cache if they have plausible version\n    numbers, so that we don't contaminate the cache with things that were not\n    unique. E.g. ./package might have dozens of installs done for it and build\n    a version of 0.0...and if we built and cached a wheel, we'd end up using\n    the same wheel even if the source has been edited.\n\n    :param cache_dir: The cache_dir being used by pip.\n    :param link: The link of the sdist for which this will cache wheels.\n    \"\"\"\n\n    # We want to generate an url to use as our cache key, we don't want to just\n    # re-use the URL because it might have other items in the fragment and we\n    # don't care about those.\n    key_parts = [link.url_without_fragment]\n    if link.hash_name is not None and link.hash is not None:\n        key_parts.append(\"=\".join([link.hash_name, link.hash]))\n    key_url = \"#\".join(key_parts)\n\n    # Encode our key url with sha224, we'll use this because it has similar\n    # security properties to sha256, but with a shorter total output (and thus\n    # less secure). However the differences don't make a lot of difference for\n    # our use case here.\n    hashed = hashlib.sha224(key_url.encode()).hexdigest()\n\n    # We want to nest the directories some to prevent having a ton of top level\n    # directories where we might run out of sub directories on some FS.\n    parts = [hashed[:2], hashed[2:4], hashed[4:6], hashed[6:]]\n\n    # Inside of the base location for cached wheels, expand our parts and join\n    # them all together.\n    return os.path.join(cache_dir, \"wheels\", *parts)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a hash and length for path using hashlib. new", "response": "def rehash(path, algo='sha256', blocksize=1 << 20):\n    \"\"\"Return (hash, length) for path using hashlib.new(algo)\"\"\"\n    h = hashlib.new(algo)\n    length = 0\n    with open(path, 'rb') as f:\n        block = f.read(blocksize)\n        while block:\n            length += len(block)\n            h.update(block)\n            block = f.read(blocksize)\n    digest = 'sha256=' + urlsafe_b64encode(\n        h.digest()\n    ).decode('latin1').rstrip('=')\n    return (digest, length)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fix_script(path):\n    # XXX RECORD hashes will need to be updated\n    if os.path.isfile(path):\n        with open(path, 'rb') as script:\n            firstline = script.readline()\n            if not firstline.startswith(b'#!python'):\n                return False\n            exename = sys.executable.encode(sys.getfilesystemencoding())\n            firstline = b'#!' + exename + os.linesep.encode(\"ascii\")\n            rest = script.read()\n        with open(path, 'wb') as script:\n            script.write(firstline)\n            script.write(rest)\n        return True", "response": "Replace Python with Python if file was changed Return True if file was changed."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef root_is_purelib(name, wheeldir):\n    name_folded = name.replace(\"-\", \"_\")\n    for item in os.listdir(wheeldir):\n        match = dist_info_re.match(item)\n        if match and match.group('name') == name_folded:\n            with open(os.path.join(wheeldir, item, 'WHEEL')) as wheel:\n                for line in wheel:\n                    line = line.lower().rstrip()\n                    if line == \"root-is-purelib: true\":\n                        return True\n    return False", "response": "Return True if the extracted wheel in wheeldir should go into purelib."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef uninstallation_paths(dist):\n    from pip.utils import FakeFile  # circular import\n    r = csv.reader(FakeFile(dist.get_metadata_lines('RECORD')))\n    for row in r:\n        path = os.path.join(dist.location, row[0])\n        yield path\n        if path.endswith('.py'):\n            dn, fn = os.path.split(path)\n            base = fn[:-3]\n            path = os.path.join(dn, base + '.pyc')\n            yield path", "response": "Yields all the uninstallation paths for the given distribution."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_compatibility(version, name):\n    if not version:\n        raise UnsupportedWheel(\n            \"%s is in an unsupported or invalid wheel\" % name\n        )\n    if version[0] > VERSION_COMPATIBLE[0]:\n        raise UnsupportedWheel(\n            \"%s's Wheel-Version (%s) is not compatible with this version \"\n            \"of pip\" % (name, '.'.join(map(str, version)))\n        )\n    elif version > VERSION_COMPATIBLE:\n        logger.warning(\n            'Installing from a newer Wheel-Version (%s)',\n            '.'.join(map(str, version)),\n        )", "response": "Checks that a given version of a Wheel - Version is compatible with the given pip."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _build_one(self, req, output_dir):\n        tempd = tempfile.mkdtemp('pip-wheel-')\n        try:\n            if self.__build_one(req, tempd):\n                try:\n                    wheel_name = os.listdir(tempd)[0]\n                    wheel_path = os.path.join(output_dir, wheel_name)\n                    shutil.move(os.path.join(tempd, wheel_name), wheel_path)\n                    logger.info('Stored in directory: %s', output_dir)\n                    return wheel_path\n                except:\n                    return None\n            return None\n        finally:\n            rmtree(tempd)", "response": "Build one wheel.\n\n        :return: The filename of the built wheel, or None if the build failed."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nbuilding wheels. :param unpack: If True, replace the sdist we built from the with the newly built wheel, in preparation for installation. :return: True if all the wheels built correctly.", "response": "def build(self, autobuilding=False):\n        \"\"\"Build wheels.\n\n        :param unpack: If True, replace the sdist we built from the with the\n            newly built wheel, in preparation for installation.\n        :return: True if all the wheels built correctly.\n        \"\"\"\n        assert self._wheel_dir or (autobuilding and self._cache_root)\n        # unpack sdists and constructs req set\n        self.requirement_set.prepare_files(self.finder)\n\n        reqset = self.requirement_set.requirements.values()\n\n        buildset = []\n        for req in reqset:\n            if req.is_wheel:\n                if not autobuilding:\n                    logger.info(\n                        'Skipping %s, due to already being wheel.', req.name)\n            elif req.editable:\n                if not autobuilding:\n                    logger.info(\n                        'Skipping bdist_wheel for %s, due to being editable',\n                        req.name)\n            elif autobuilding and req.link and not req.link.is_artifact:\n                pass\n            elif autobuilding and not req.source_dir:\n                pass\n            else:\n                if autobuilding:\n                    link = req.link\n                    base, ext = link.splitext()\n                    if pip.index.egg_info_matches(base, None, link) is None:\n                        # Doesn't look like a package - don't autobuild a wheel\n                        # because we'll have no way to lookup the result sanely\n                        continue\n                    if \"binary\" not in pip.index.fmt_ctl_formats(\n                            self.finder.format_control,\n                            pkg_resources.safe_name(req.name).lower()):\n                        logger.info(\n                            \"Skipping bdist_wheel for %s, due to binaries \"\n                            \"being disabled for it.\", req.name)\n                        continue\n                buildset.append(req)\n\n        if not buildset:\n            return True\n\n        # Build the wheels.\n        logger.info(\n            'Building wheels for collected packages: %s',\n            ', '.join([req.name for req in buildset]),\n        )\n        with indent_log():\n            build_success, build_failure = [], []\n            for req in buildset:\n                if autobuilding:\n                    output_dir = _cache_for_link(self._cache_root, req.link)\n                    ensure_dir(output_dir)\n                else:\n                    output_dir = self._wheel_dir\n                wheel_file = self._build_one(req, output_dir)\n                if wheel_file:\n                    build_success.append(req)\n                    if autobuilding:\n                        # XXX: This is mildly duplicative with prepare_files,\n                        # but not close enough to pull out to a single common\n                        # method.\n                        # The code below assumes temporary source dirs -\n                        # prevent it doing bad things.\n                        if req.source_dir and not os.path.exists(os.path.join(\n                                req.source_dir, PIP_DELETE_MARKER_FILENAME)):\n                            raise AssertionError(\n                                \"bad source dir - missing marker\")\n                        # Delete the source we built the wheel from\n                        req.remove_temporary_source()\n                        # set the build directory again - name is known from\n                        # the work prepare_files did.\n                        req.source_dir = req.build_location(\n                            self.requirement_set.build_dir)\n                        # Update the link for this.\n                        req.link = pip.index.Link(\n                            path_to_url(wheel_file), trusted=True)\n                        assert req.link.is_wheel\n                        # extract the wheel into the dir\n                        unpack_url(\n                            req.link, req.source_dir, None, False,\n                            session=self.requirement_set.session)\n                else:\n                    build_failure.append(req)\n\n        # notify success/failure\n        if build_success:\n            logger.info(\n                'Successfully built %s',\n                ' '.join([req.name for req in build_success]),\n            )\n        if build_failure:\n            logger.info(\n                'Failed to build %s',\n                ' '.join([req.name for req in build_failure]),\n            )\n        # Return True if all builds were successful\n        return len(build_failure) == 0"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nyield names and strings used by code and its nested code objects", "response": "def iter_symbols(code):\n    \"\"\"Yield names and strings used by `code` and its nested code objects\"\"\"\n    for name in code.co_names:\n        yield name\n    for const in code.co_consts:\n        if isinstance(const, basestring):\n            yield const\n        elif isinstance(const, CodeType):\n            for name in iter_symbols(const):\n                yield name"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the quotation between two currencies", "response": "def quotation(self, origin, target):\n        \"\"\"Return quotation between two currencies (origin, target)\"\"\"\n        a = self.rate(origin)\n        b = self.rate(target)\n        if a and b:\n            return Decimal(b) / Decimal(a)\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd paths for egg - info files for an external egg - base.", "response": "def _add_egg_info(self, cmd):\n        \"\"\"\n        Add paths for egg-info files for an external egg-base.\n\n        The egg-info files are written to egg-base. If egg-base is\n        outside the current working directory, this method\n        searchs the egg-base directory for files to include\n        in the manifest. Uses distutils.filelist.findall (which is\n        really the version monkeypatched in by setuptools/__init__.py)\n        to perform the search.\n\n        Since findall records relative paths, prefix the returned\n        paths with cmd.egg_base, so add_default's include_pattern call\n        (which is looking for the absolute cmd.egg_info) will match\n        them.\n        \"\"\"\n        if cmd.egg_base == os.curdir:\n            # egg-info files were already added by something else\n            return\n\n        discovered = distutils.filelist.findall(cmd.egg_base)\n        resolved = (os.path.join(cmd.egg_base, path) for path in discovered)\n        self.filelist.allfiles.extend(resolved)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef write_delete_marker_file(directory):\n    filepath = os.path.join(directory, PIP_DELETE_MARKER_FILENAME)\n    with open(filepath, 'w') as marker_fp:\n        marker_fp.write(DELETE_MARKER_MESSAGE)", "response": "Writes the pip delete marker file into this directory."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn True if we re running inside a virtualenv False otherwise.", "response": "def running_under_virtualenv():\n    \"\"\"\n    Return True if we're running inside a virtualenv, False otherwise.\n\n    \"\"\"\n    if hasattr(sys, 'real_prefix'):\n        return True\n    elif sys.prefix != getattr(sys, \"base_prefix\", sys.prefix):\n        return True\n\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __get_username():\n    if WINDOWS:\n        return getpass.getuser()\n    import pwd\n    return pwd.getpwuid(os.geteuid()).pw_name", "response": "Returns the effective username of the current process."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a distutils install scheme for the given distribution name.", "response": "def distutils_scheme(dist_name, user=False, home=None, root=None,\n                     isolated=False):\n    \"\"\"\n    Return a distutils install scheme\n    \"\"\"\n    from distutils.dist import Distribution\n\n    scheme = {}\n\n    if isolated:\n        extra_dist_args = {\"script_args\": [\"--no-user-cfg\"]}\n    else:\n        extra_dist_args = {}\n    dist_args = {'name': dist_name}\n    dist_args.update(extra_dist_args)\n\n    d = Distribution(dist_args)\n    d.parse_config_files()\n    i = d.get_command_obj('install', create=True)\n    # NOTE: setting user or home has the side-effect of creating the home dir\n    # or user base for installations during finalize_options()\n    # ideally, we'd prefer a scheme class that has no side-effects.\n    i.user = user or i.user\n    i.home = home or i.home\n    i.root = root or i.root\n    i.finalize_options()\n    for key in SCHEME_KEYS:\n        scheme[key] = getattr(i, 'install_' + key)\n\n    if i.install_lib is not None:\n        # install_lib takes precedence over purelib and platlib\n        scheme.update(dict(purelib=i.install_lib, platlib=i.install_lib))\n\n    if running_under_virtualenv():\n        scheme['headers'] = os.path.join(\n            sys.prefix,\n            'include',\n            'site',\n            'python' + sys.version[:3],\n            dist_name,\n        )\n\n        if root is not None:\n            scheme[\"headers\"] = os.path.join(\n                root,\n                os.path.abspath(scheme[\"headers\"])[1:],\n            )\n\n    return scheme"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing the cache - control headers returning a dictionary with values for the different directives.", "response": "def parse_cache_control(self, headers):\n        \"\"\"\n        Parse the cache control headers returning a dictionary with values\n        for the different directives.\n        \"\"\"\n        retval = {}\n\n        cc_header = 'cache-control'\n        if 'Cache-Control' in headers:\n            cc_header = 'Cache-Control'\n\n        if cc_header in headers:\n            parts = headers[cc_header].split(',')\n            parts_with_args = [\n                tuple([x.strip().lower() for x in part.split(\"=\", 1)])\n                for part in parts if -1 != part.find(\"=\")\n            ]\n            parts_wo_args = [\n                (name.strip().lower(), 1)\n                for name in parts if -1 == name.find(\"=\")\n            ]\n            retval = dict(parts_with_args + parts_wo_args)\n        return retval"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a cached response if it exists in the cache otherwise return False.", "response": "def cached_request(self, request):\n        \"\"\"\n        Return a cached response if it exists in the cache, otherwise\n        return False.\n        \"\"\"\n        cache_url = self.cache_url(request.url)\n        cc = self.parse_cache_control(request.headers)\n\n        # non-caching states\n        no_cache = True if 'no-cache' in cc else False\n        if 'max-age' in cc and cc['max-age'] == 0:\n            no_cache = True\n\n        # Bail out if no-cache was set\n        if no_cache:\n            return False\n\n        # It is in the cache, so lets see if it is going to be\n        # fresh enough\n        resp = self.serializer.loads(request, self.cache.get(cache_url))\n\n        # Check to see if we have a cached object\n        if not resp:\n            return False\n\n        # If we have a cached 301, return it immediately. We don't\n        # need to test our response for other headers b/c it is\n        # intrinsically \"cacheable\" as it is Permanent.\n        # See:\n        #   https://tools.ietf.org/html/rfc7231#section-6.4.2\n        #\n        # Client can try to refresh the value by repeating the request\n        # with cache busting headers as usual (ie no-cache).\n        if resp.status == 301:\n            return resp\n\n        headers = CaseInsensitiveDict(resp.headers)\n        if not headers or 'date' not in headers:\n            # With date or etag, the cached response can never be used\n            # and should be deleted.\n            if 'etag' not in headers:\n                self.cache.delete(cache_url)\n            return False\n\n        now = time.time()\n        date = calendar.timegm(\n            parsedate_tz(headers['date'])\n        )\n        current_age = max(0, now - date)\n\n        # TODO: There is an assumption that the result will be a\n        #       urllib3 response object. This may not be best since we\n        #       could probably avoid instantiating or constructing the\n        #       response until we know we need it.\n        resp_cc = self.parse_cache_control(headers)\n\n        # determine freshness\n        freshness_lifetime = 0\n\n        # Check the max-age pragma in the cache control header\n        if 'max-age' in resp_cc and resp_cc['max-age'].isdigit():\n            freshness_lifetime = int(resp_cc['max-age'])\n\n        # If there isn't a max-age, check for an expires header\n        elif 'expires' in headers:\n            expires = parsedate_tz(headers['expires'])\n            if expires is not None:\n                expire_time = calendar.timegm(expires) - date\n                freshness_lifetime = max(0, expire_time)\n\n        # determine if we are setting freshness limit in the req\n        if 'max-age' in cc:\n            try:\n                freshness_lifetime = int(cc['max-age'])\n            except ValueError:\n                freshness_lifetime = 0\n\n        if 'min-fresh' in cc:\n            try:\n                min_fresh = int(cc['min-fresh'])\n            except ValueError:\n                min_fresh = 0\n            # adjust our current age by our min fresh\n            current_age += min_fresh\n\n        # see how fresh we actually are\n        fresh = (freshness_lifetime > current_age)\n\n        if fresh:\n            return resp\n\n        # we're not fresh. If we don't have an Etag, clear it out\n        if 'etag' not in headers:\n            self.cache.delete(cache_url)\n\n        # return the original handler\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cache_response(self, request, response, body=None):\n        # From httplib2: Don't cache 206's since we aren't going to\n        #                handle byte range requests\n        if response.status not in [200, 203, 300, 301]:\n            return\n\n        response_headers = CaseInsensitiveDict(response.headers)\n\n        cc_req = self.parse_cache_control(request.headers)\n        cc = self.parse_cache_control(response_headers)\n\n        cache_url = self.cache_url(request.url)\n\n        # Delete it from the cache if we happen to have it stored there\n        no_store = cc.get('no-store') or cc_req.get('no-store')\n        if no_store and self.cache.get(cache_url):\n            self.cache.delete(cache_url)\n\n        # If we've been given an etag, then keep the response\n        if self.cache_etags and 'etag' in response_headers:\n            self.cache.set(\n                cache_url,\n                self.serializer.dumps(request, response, body=body),\n            )\n\n        # Add to the cache any 301s. We do this before looking that\n        # the Date headers.\n        elif response.status == 301:\n            self.cache.set(\n                cache_url,\n                self.serializer.dumps(request, response)\n            )\n\n        # Add to the cache if the response headers demand it. If there\n        # is no date header then we can't do anything about expiring\n        # the cache.\n        elif 'date' in response_headers:\n            # cache when there is a max-age > 0\n            if cc and cc.get('max-age'):\n                if int(cc['max-age']) > 0:\n                    self.cache.set(\n                        cache_url,\n                        self.serializer.dumps(request, response, body=body),\n                    )\n\n            # If the request can expire, it means we should cache it\n            # in the meantime.\n            elif 'expires' in response_headers:\n                if response_headers['expires']:\n                    self.cache.set(\n                        cache_url,\n                        self.serializer.dumps(request, response, body=body),\n                    )", "response": "Algorithm for caching requests.\n\n        This assumes a requests Response object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating the zipimporter cache data for a given normalized path.", "response": "def _update_zipimporter_cache(normalized_path, cache, updater=None):\n    \"\"\"\n    Update zipimporter cache data for a given normalized path.\n\n    Any sub-path entries are processed as well, i.e. those corresponding to zip\n    archives embedded in other zip archives.\n\n    Given updater is a callable taking a cache entry key and the original entry\n    (after already removing the entry from the cache), and expected to update\n    the entry and possibly return a new one to be inserted in its place.\n    Returning None indicates that the entry should not be replaced with a new\n    one. If no updater is given, the cache entries are simply removed without\n    any additional processing, the same as if the updater simply returned None.\n\n    \"\"\"\n    for p in _collect_zipimporter_cache_entries(normalized_path, cache):\n        # N.B. pypy's custom zipimport._zip_directory_cache implementation does\n        # not support the complete dict interface:\n        # * Does not support item assignment, thus not allowing this function\n        #    to be used only for removing existing cache entries.\n        #  * Does not support the dict.pop() method, forcing us to use the\n        #    get/del patterns instead. For more detailed information see the\n        #    following links:\n        #      https://bitbucket.org/pypa/setuptools/issue/202/more-robust-zipimporter-cache-invalidation#comment-10495960\n        #      https://bitbucket.org/pypy/pypy/src/dd07756a34a41f674c0cacfbc8ae1d4cc9ea2ae4/pypy/module/zipimport/interp_zipimport.py#cl-99\n        old_entry = cache[p]\n        del cache[p]\n        new_entry = updater and updater(p, old_entry)\n        if new_entry is not None:\n            cache[p] = new_entry"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_win_launcher(type):\n    launcher_fn = '%s.exe' % type\n    if platform.machine().lower() == 'arm':\n        launcher_fn = launcher_fn.replace(\".\", \"-arm.\")\n    if is_64bit():\n        launcher_fn = launcher_fn.replace(\".\", \"-64.\")\n    else:\n        launcher_fn = launcher_fn.replace(\".\", \"-32.\")\n    return resource_string('setuptools', launcher_fn)", "response": "Load the Windows launcher suitable for launching a script."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a pseudo - tempdir base in the install directory.", "response": "def pseudo_tempname(self):\n        \"\"\"Return a pseudo-tempname base in the install directory.\n        This code is intentionally naive; if a malicious party can write to\n        the target directory you're already in deep doodoo.\n        \"\"\"\n        try:\n            pid = os.getpid()\n        except:\n            pid = random.randint(0, maxsize)\n        return os.path.join(self.install_dir, \"test-easy-install-%s\" % pid)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef install_script(self, dist, script_name, script_text, dev_path=None):\n        spec = str(dist.as_requirement())\n        is_script = is_python_script(script_text, script_name)\n\n        if is_script:\n            script_text = (ScriptWriter.get_header(script_text) +\n                           self._load_template(dev_path) % locals())\n        self.write_script(script_name, _to_ascii(script_text), 'b')", "response": "Generate a legacy script wrapper and install it"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload the template file and return it as a string.", "response": "def _load_template(dev_path):\n        \"\"\"\n        There are a couple of template scripts in the package. This\n        function loads one of them and prepares it for use.\n        \"\"\"\n        # See https://bitbucket.org/pypa/setuptools/issue/134 for info\n        # on script file naming and downstream issues with SVR4\n        name = 'script.tmpl'\n        if dev_path:\n            name = name.replace('.tmpl', ' (dev).tmpl')\n\n        raw_bytes = resource_string('setuptools', name)\n        return raw_bytes.decode('utf-8')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef install_site_py(self):\n\n        if self.sitepy_installed:\n            return  # already did it, or don't need to\n\n        sitepy = os.path.join(self.install_dir, \"site.py\")\n        source = resource_string(\"setuptools\", \"site-patch.py\")\n        current = \"\"\n\n        if os.path.exists(sitepy):\n            log.debug(\"Checking existing site.py in %s\", self.install_dir)\n            f = open(sitepy, 'rb')\n            current = f.read()\n            # we want str, not bytes\n            if PY3:\n                current = current.decode()\n\n            f.close()\n            if not current.startswith('def __boot():'):\n                raise DistutilsError(\n                    \"%s is not a setuptools-generated site.py; please\"\n                    \" remove it.\" % sitepy\n                )\n\n        if current != source:\n            log.info(\"Creating %s\", sitepy)\n            if not self.dry_run:\n                ensure_directory(sitepy)\n                f = open(sitepy, 'wb')\n                f.write(source)\n                f.close()\n            self.byte_compile([sitepy])\n\n        self.sitepy_installed = True", "response": "Install site. py if it doesn t exist."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef save(self):\n        if not self.dirty:\n            return\n\n        data = '\\n'.join(map(self.make_relative, self.paths))\n        if data:\n            log.debug(\"Saving %s\", self.filename)\n            data = (\n                \"import sys; sys.__plen = len(sys.path)\\n\"\n                \"%s\\n\"\n                \"import sys; new=sys.path[sys.__plen:];\"\n                \" del sys.path[sys.__plen:];\"\n                \" p=getattr(sys,'__egginsert',0); sys.path[p:p]=new;\"\n                \" sys.__egginsert = p+len(new)\\n\"\n            ) % data\n\n            if os.path.islink(self.filename):\n                os.unlink(self.filename)\n            f = open(self.filename, 'wt')\n            f.write(data)\n            f.close()\n\n        elif os.path.exists(self.filename):\n            log.debug(\"Deleting empty %s\", self.filename)\n            os.unlink(self.filename)\n\n        self.dirty = False", "response": "Write changed. pth file back to disk"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef as_header(self):\n        if not is_sh(self[0]):\n            return super(JythonCommandSpec, self).as_header()\n\n        if self.options:\n            # Can't apply the workaround, leave it broken\n            log.warn(\n                \"WARNING: Unable to adapt shebang line for Jython,\"\n                \" the following script is NOT executable\\n\"\n                \"         see http://bugs.jython.org/issue1112 for\"\n                \" more information.\")\n            return super(JythonCommandSpec, self).as_header()\n\n        items = ['/usr/bin/env'] + self + list(self.options)\n        return self._render(items)", "response": "Returns the command line as a header string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _adjust_header(type_, orig_header):\n        pattern = 'pythonw.exe'\n        repl = 'python.exe'\n        if type_ == 'gui':\n            pattern, repl = repl, pattern\n        pattern_ob = re.compile(re.escape(pattern), re.IGNORECASE)\n        new_header = pattern_ob.sub(string=orig_header, repl=repl)\n        clean_header = new_header[2:-1].strip('\"')\n        if sys.platform == 'win32' and not os.path.exists(clean_header):\n            # the adjusted version doesn't exist, so return the original\n            return orig_header\n        return new_header", "response": "Adjust the header to include the version of the entry point."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert the value to an appropriate type.", "response": "def convert(self, value):\n        \"\"\"\n        Convert values to an appropriate type. dicts, lists and tuples are\n        replaced by their converting alternatives. Strings are checked to\n        see if they have a conversion format and are converted if they do.\n        \"\"\"\n        if not isinstance(value, ConvertingDict) and isinstance(value, dict):\n            value = ConvertingDict(value)\n            value.configurator = self\n        elif not isinstance(value, ConvertingList) and isinstance(value, list):\n            value = ConvertingList(value)\n            value.configurator = self\n        elif not isinstance(value, ConvertingTuple) and\\\n                 isinstance(value, tuple):\n            value = ConvertingTuple(value)\n            value.configurator = self\n        elif isinstance(value, six.string_types):  # str for py3k\n            m = self.CONVERT_PATTERN.match(value)\n            if m:\n                d = m.groupdict()\n                prefix = d['prefix']\n                converter = self.value_converters.get(prefix, None)\n                if converter:\n                    suffix = d['suffix']\n                    converter = getattr(self, converter)\n                    value = converter(suffix)\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd filters to a filterer from a list of names.", "response": "def add_filters(self, filterer, filters):\n        \"\"\"Add filters to a filterer from a list of names.\"\"\"\n        for f in filters:\n            try:\n                filterer.addFilter(self.config['filters'][f])\n            except StandardError as e:\n                raise ValueError('Unable to add filter %r: %s' % (f, e))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef configure_handler(self, config):\n        formatter = config.pop('formatter', None)\n        if formatter:\n            try:\n                formatter = self.config['formatters'][formatter]\n            except StandardError as e:\n                raise ValueError('Unable to set formatter '\n                                 '%r: %s' % (formatter, e))\n        level = config.pop('level', None)\n        filters = config.pop('filters', None)\n        if '()' in config:\n            c = config.pop('()')\n            if not hasattr(c, '__call__') and hasattr(types, 'ClassType') and type(c) != types.ClassType:\n                c = self.resolve(c)\n            factory = c\n        else:\n            klass = self.resolve(config.pop('class'))\n            # Special case for handler which refers to another handler\n            if issubclass(klass, logging.handlers.MemoryHandler) and\\\n                'target' in config:\n                try:\n                    config['target'] = self.config['handlers'][config['target']]\n                except StandardError as e:\n                    raise ValueError('Unable to set target handler '\n                                     '%r: %s' % (config['target'], e))\n            elif issubclass(klass, logging.handlers.SMTPHandler) and\\\n                'mailhost' in config:\n                config['mailhost'] = self.as_tuple(config['mailhost'])\n            elif issubclass(klass, logging.handlers.SysLogHandler) and\\\n                'address' in config:\n                config['address'] = self.as_tuple(config['address'])\n            factory = klass\n        kwargs = dict((k, config[k]) for k in config if valid_ident(k))\n        try:\n            result = factory(**kwargs)\n        except TypeError as te:\n            if \"'stream'\" not in str(te):\n                raise\n            # The argument name changed from strm to stream\n            # Retry with old name.\n            # This is so that code can be used with older Python versions\n            #(e.g. by Django)\n            kwargs['strm'] = kwargs.pop('stream')\n            result = factory(**kwargs)\n        if formatter:\n            result.setFormatter(formatter)\n        if level is not None:\n            result.setLevel(_checkLevel(level))\n        if filters:\n            self.add_filters(result, filters)\n        return result", "response": "Configure a handler from a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd handlers to a logger from a list of names.", "response": "def add_handlers(self, logger, handlers):\n        \"\"\"Add handlers to a logger from a list of names.\"\"\"\n        for h in handlers:\n            try:\n                logger.addHandler(self.config['handlers'][h])\n            except StandardError as e:\n                raise ValueError('Unable to add handler %r: %s' % (h, e))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nperforms configuration which is common to root and non - root loggers.", "response": "def common_logger_config(self, logger, config, incremental=False):\n        \"\"\"\n        Perform configuration which is common to root and non-root loggers.\n        \"\"\"\n        level = config.get('level', None)\n        if level is not None:\n            logger.setLevel(_checkLevel(level))\n        if not incremental:\n            # Remove any existing handlers\n            for h in logger.handlers[:]:\n                logger.removeHandler(h)\n            handlers = config.get('handlers', None)\n            if handlers:\n                self.add_handlers(logger, handlers)\n            filters = config.get('filters', None)\n            if filters:\n                self.add_filters(logger, filters)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef from_envvar(self, variable_name, silent=False):\n        rv = os.environ.get(variable_name)\n        if not rv:\n            if silent:\n                return False\n            raise RuntimeError('The environment variable %r is not set '\n                               'and as such configuration could not be '\n                               'loaded.  Set this variable and make it '\n                               'point to a configuration file' %\n                               variable_name)\n        return self.from_pyfile(rv, silent=silent)", "response": "Loads a configuration from an environment variable pointing to a configuration file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating the values in the config from a Python file.", "response": "def from_pyfile(self, filename, silent=False):\n        \"\"\"Updates the values in the config from a Python file.  This function\n        behaves as if the file was imported as module with the\n        :meth:`from_object` function.\n\n        :param filename: the filename of the config.  This can either be an\n                         absolute filename or a filename relative to the\n                         root path.\n        :param silent: set to `True` if you want silent failure for missing\n                       files.\n\n        .. versionadded:: 0.7\n           `silent` parameter.\n        \"\"\"\n        filename = os.path.join(self.root_path, filename)\n        d = imp.new_module('config')\n        d.__file__ = filename\n        try:\n            with open(filename) as config_file:\n                exec(compile(config_file.read(), filename, 'exec'), d.__dict__)\n        except IOError as e:\n            if silent and e.errno in (errno.ENOENT, errno.EISDIR):\n                return False\n            e.strerror = 'Unable to load configuration file (%s)' % e.strerror\n            raise\n        self.from_object(d)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_object(self, obj):\n        if isinstance(obj, string_types):\n            obj = import_string(obj)\n        for key in dir(obj):\n            if key.isupper():\n                self[key] = getattr(obj, key)", "response": "Updates the values in the config object with the values from the given object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nexecute a file in Python 3.", "response": "def _execfile(filename, globals, locals=None):\n    \"\"\"\n    Python 3 implementation of execfile.\n    \"\"\"\n    mode = 'rb'\n    with open(filename, mode) as stream:\n        script = stream.read()\n    # compile() function in Python 2.6 and 3.1 requires LF line endings.\n    if sys.version_info[:2] < (2, 7) or sys.version_info[:2] >= (3, 0) and sys.version_info[:2] < (3, 2):\n        script = script.replace(b'\\r\\n', b'\\n')\n        script = script.replace(b'\\r', b'\\n')\n    if locals is None:\n        locals = globals\n    code = compile(script, filename, 'exec')\n    exec(code, globals, locals)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef run_setup(setup_script, args):\n    setup_dir = os.path.abspath(os.path.dirname(setup_script))\n    with setup_context(setup_dir):\n        try:\n            sys.argv[:] = [setup_script]+list(args)\n            sys.path.insert(0, setup_dir)\n            # reset to include setup dir, w/clean callback list\n            working_set.__init__()\n            working_set.callbacks.append(lambda dist:dist.activate())\n            def runner():\n                ns = dict(__file__=setup_script, __name__='__main__')\n                _execfile(setup_script, ns)\n            DirectorySandbox(setup_dir).run(runner)\n        except SystemExit as v:\n            if v.args and v.args[0]:\n                raise", "response": "Run a distutils setup script sandboxed in its directory"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndumping a type and exception into a string.", "response": "def dump(cls, type, exc):\n        \"\"\"\n        Always return a dumped (pickled) type and exc. If exc can't be pickled,\n        wrap it in UnpickleableException first.\n        \"\"\"\n        try:\n            return pickle.dumps(type), pickle.dumps(exc)\n        except Exception:\n            return cls.dump(cls, cls(repr(exc)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_rev_options(self, rev, dest, rev_options):\n        revisions = self.get_refs(dest)\n\n        origin_rev = 'origin/%s' % rev\n        if origin_rev in revisions:\n            # remote branch\n            return [revisions[origin_rev]]\n        elif rev in revisions:\n            # a local tag or branch name\n            return [revisions[rev]]\n        else:\n            logger.warning(\n                \"Could not find a tag or branch '%s', assuming commit.\", rev,\n            )\n            return rev_options", "response": "Check the revision options before checkout to compensate that tags\n            and branches may need origin as a prefix."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the URL and revision of the current object.", "response": "def get_url_rev(self):\n        \"\"\"\n        Prefixes stub URLs like 'user@hostname:user/repo.git' with 'ssh://'.\n        That's required because although they use SSH they sometimes doesn't\n        work with a ssh:// scheme (e.g. Github). But we need a scheme for\n        parsing. Hence we remove it again afterwards and return it as a stub.\n        \"\"\"\n        if '://' not in self.url:\n            assert 'file:' not in self.url\n            self.url = self.url.replace('git+', 'git+ssh://')\n            url, rev = super(Git, self).get_url_rev()\n            url = url.replace('ssh://', '')\n        else:\n            url, rev = super(Git, self).get_url_rev()\n\n        return url, rev"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_important_traceback(self, important_module, tb):\n        while tb is not None:\n            if self.is_important_frame(important_module, tb):\n                return True\n            tb = tb.tb_next\n        return False", "response": "Checks if a traceback is an important module."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting an item or attribute of an object but prefer the item.", "response": "def getitem(self, obj, argument):\n        \"\"\"Get an item or attribute of an object but prefer the item.\"\"\"\n        try:\n            return obj[argument]\n        except (TypeError, LookupError):\n            if isinstance(argument, string_types):\n                try:\n                    attr = str(argument)\n                except Exception:\n                    pass\n                else:\n                    try:\n                        return getattr(obj, attr)\n                    except AttributeError:\n                        pass\n            return self.undefined(obj=obj, name=argument)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncompiles all the templates in the target directory and store them in the zip.", "response": "def compile_templates(self, target, extensions=None, filter_func=None,\n                          zip='deflated', log_function=None,\n                          ignore_errors=True, py_compile=False):\n        \"\"\"Finds all the templates the loader can find, compiles them\n        and stores them in `target`.  If `zip` is `None`, instead of in a\n        zipfile, the templates will be will be stored in a directory.\n        By default a deflate zip algorithm is used, to switch to\n        the stored algorithm, `zip` can be set to ``'stored'``.\n\n        `extensions` and `filter_func` are passed to :meth:`list_templates`.\n        Each template returned will be compiled to the target folder or\n        zipfile.\n\n        By default template compilation errors are ignored.  In case a\n        log function is provided, errors are logged.  If you want template\n        syntax errors to abort the compilation you can set `ignore_errors`\n        to `False` and you will get an exception on syntax errors.\n\n        If `py_compile` is set to `True` .pyc files will be written to the\n        target instead of standard .py files.  This flag does not do anything\n        on pypy and Python 3 where pyc files are not picked up by itself and\n        don't give much benefit.\n\n        .. versionadded:: 2.4\n        \"\"\"\n        from jinja2.loaders import ModuleLoader\n\n        if log_function is None:\n            log_function = lambda x: None\n\n        if py_compile:\n            if not PY2 or PYPY:\n                from warnings import warn\n                warn(Warning('py_compile has no effect on pypy or Python 3'))\n                py_compile = False\n            else:\n                import imp, marshal\n                py_header = imp.get_magic() + \\\n                    u'\\xff\\xff\\xff\\xff'.encode('iso-8859-15')\n\n                # Python 3.3 added a source filesize to the header\n                if sys.version_info >= (3, 3):\n                    py_header += u'\\x00\\x00\\x00\\x00'.encode('iso-8859-15')\n\n        def write_file(filename, data, mode):\n            if zip:\n                info = ZipInfo(filename)\n                info.external_attr = 0o755 << 16\n                zip_file.writestr(info, data)\n            else:\n                f = open(os.path.join(target, filename), mode)\n                try:\n                    f.write(data)\n                finally:\n                    f.close()\n\n        if zip is not None:\n            from zipfile import ZipFile, ZipInfo, ZIP_DEFLATED, ZIP_STORED\n            zip_file = ZipFile(target, 'w', dict(deflated=ZIP_DEFLATED,\n                                                 stored=ZIP_STORED)[zip])\n            log_function('Compiling into Zip archive \"%s\"' % target)\n        else:\n            if not os.path.isdir(target):\n                os.makedirs(target)\n            log_function('Compiling into folder \"%s\"' % target)\n\n        try:\n            for name in self.list_templates(extensions, filter_func):\n                source, filename, _ = self.loader.get_source(self, name)\n                try:\n                    code = self.compile(source, name, filename, True, True)\n                except TemplateSyntaxError as e:\n                    if not ignore_errors:\n                        raise\n                    log_function('Could not compile \"%s\": %s' % (name, e))\n                    continue\n\n                filename = ModuleLoader.get_module_filename(name)\n\n                if py_compile:\n                    c = self._compile(code, encode_filename(filename))\n                    write_file(filename + 'c', py_header +\n                               marshal.dumps(c), 'wb')\n                    log_function('Byte-compiled \"%s\" as %s' %\n                                 (name, filename + 'c'))\n                else:\n                    write_file(filename, code, 'w')\n                    log_function('Compiled \"%s\" as %s' % (name, filename))\n        finally:\n            if zip:\n                zip_file.close()\n\n        log_function('Finished compiling templates')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of templates for this environment.", "response": "def list_templates(self, extensions=None, filter_func=None):\n        \"\"\"Returns a list of templates for this environment.  This requires\n        that the loader supports the loader's\n        :meth:`~BaseLoader.list_templates` method.\n\n        If there are other files in the template folder besides the\n        actual templates, the returned list can be filtered.  There are two\n        ways: either `extensions` is set to a list of file extensions for\n        templates, or a `filter_func` can be provided which is a callable that\n        is passed a template name and should return `True` if it should end up\n        in the result list.\n\n        If the loader does not support that, a :exc:`TypeError` is raised.\n\n        .. versionadded:: 2.4\n        \"\"\"\n        x = self.loader.list_templates()\n        if extensions is not None:\n            if filter_func is not None:\n                raise TypeError('either extensions or filter_func '\n                                'can be passed, but not both')\n            filter_func = lambda x: '.' in x and \\\n                                    x.rsplit('.', 1)[1] in extensions\n        if filter_func is not None:\n            x = ifilter(filter_func, x)\n        return x"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndetermine the default cache location for the current user.", "response": "def get_default_cache():\n    \"\"\"Determine the default cache location\n\n    This returns the ``PYTHON_EGG_CACHE`` environment variable, if set.\n    Otherwise, on Windows, it returns a \"Python-Eggs\" subdirectory of the\n    \"Application Data\" directory.  On all other systems, it's \"~/.python-eggs\".\n    \"\"\"\n    try:\n        return os.environ['PYTHON_EGG_CACHE']\n    except KeyError:\n        pass\n\n    if os.name!='nt':\n        return os.path.expanduser('~/.python-eggs')\n\n    # XXX this may be locale-specific!\n    app_data = 'Application Data'\n    app_homes = [\n        # best option, should be locale-safe\n        (('APPDATA',), None),\n        (('USERPROFILE',), app_data),\n        (('HOMEDRIVE','HOMEPATH'), app_data),\n        (('HOMEPATH',), app_data),\n        (('HOME',), None),\n        # 95/98/ME\n        (('WINDIR',), app_data),\n    ]\n\n    for keys, subdir in app_homes:\n        dirname = ''\n        for key in keys:\n            if key in os.environ:\n                dirname = os.path.join(dirname, os.environ[key])\n            else:\n                break\n        else:\n            if subdir:\n                dirname = os.path.join(dirname, subdir)\n            return os.path.join(dirname, 'Python-Eggs')\n    else:\n        raise RuntimeError(\n            \"Please set the PYTHON_EGG_CACHE enviroment variable\"\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfind eggs in zip files.", "response": "def find_eggs_in_zip(importer, path_item, only=False):\n    \"\"\"\n    Find eggs in zip files; possibly multiple nested eggs.\n    \"\"\"\n    if importer.archive.endswith('.whl'):\n        # wheels are not supported with this finder\n        # they don't have PKG-INFO metadata, and won't ever contain eggs\n        return\n    metadata = EggMetadata(importer)\n    if metadata.has_metadata('PKG-INFO'):\n        yield Distribution.from_filename(path_item, metadata=metadata)\n    if only:\n        # don't yield nested distros\n        return\n    for subitem in metadata.resource_listdir('/'):\n        if subitem.endswith('.egg'):\n            subpath = os.path.join(path_item, subitem)\n            for dist in find_eggs_in_zip(zipimport.zipimporter(subpath), subpath):\n                yield dist"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef find_on_path(importer, path_item, only=False):\n    path_item = _normalize_cached(path_item)\n\n    if os.path.isdir(path_item) and os.access(path_item, os.R_OK):\n        if path_item.lower().endswith('.egg'):\n            # unpacked egg\n            yield Distribution.from_filename(\n                path_item, metadata=PathMetadata(\n                    path_item, os.path.join(path_item,'EGG-INFO')\n                )\n            )\n        else:\n            # scan for .egg and .egg-info in directory\n            for entry in os.listdir(path_item):\n                lower = entry.lower()\n                if lower.endswith('.egg-info') or lower.endswith('.dist-info'):\n                    fullpath = os.path.join(path_item, entry)\n                    if os.path.isdir(fullpath):\n                        # egg-info directory, allow getting metadata\n                        metadata = PathMetadata(path_item, fullpath)\n                    else:\n                        metadata = FileMetadata(fullpath)\n                    yield Distribution.from_location(\n                        path_item, entry, metadata, precedence=DEVELOP_DIST\n                    )\n                elif not only and lower.endswith('.egg'):\n                    dists = find_distributions(os.path.join(path_item, entry))\n                    for dist in dists:\n                        yield dist\n                elif not only and lower.endswith('.egg-link'):\n                    with open(os.path.join(path_item, entry)) as entry_file:\n                        entry_lines = entry_file.readlines()\n                    for line in entry_lines:\n                        if not line.strip():\n                            continue\n                        path = os.path.join(path_item, line.rstrip())\n                        dists = find_distributions(path)\n                        for item in dists:\n                            yield item\n                        break", "response": "Yields distributions accessible on a sys. path directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndeclares that package packageName is a namespace package.", "response": "def declare_namespace(packageName):\n    \"\"\"Declare that package 'packageName' is a namespace package\"\"\"\n\n    imp.acquire_lock()\n    try:\n        if packageName in _namespace_packages:\n            return\n\n        path, parent = sys.path, None\n        if '.' in packageName:\n            parent = '.'.join(packageName.split('.')[:-1])\n            declare_namespace(parent)\n            if parent not in _namespace_packages:\n                __import__(parent)\n            try:\n                path = sys.modules[parent].__path__\n            except AttributeError:\n                raise TypeError(\"Not a package:\", parent)\n\n        # Track what packages are namespaces, so when new path items are added,\n        # they can be updated\n        _namespace_packages.setdefault(parent,[]).append(packageName)\n        _namespace_packages.setdefault(packageName,[])\n\n        for path_item in path:\n            # Ensure all the parent's path items are reflected in the child,\n            # if they apply\n            _handle_ns(packageName, path_item)\n\n    finally:\n        imp.release_lock()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nyield non - empty lines of a string or sequence of lines", "response": "def yield_lines(strs):\n    \"\"\"Yield non-empty/non-comment lines of a string or sequence\"\"\"\n    if isinstance(strs, string_types):\n        for s in strs.splitlines():\n            s = s.strip()\n            # skip blank lines/comments\n            if s and not s.startswith('#'):\n                yield s\n    else:\n        for ss in strs:\n            for s in yield_lines(ss):\n                yield s"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting an mro for a class or a type", "response": "def _get_mro(cls):\n    \"\"\"Get an mro for a type or classic class\"\"\"\n    if not isinstance(cls, type):\n        class cls(cls, object): pass\n        return cls.__mro__[1:]\n    return cls.__mro__"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn an adapter factory for an object from the registry", "response": "def _find_adapter(registry, ob):\n    \"\"\"Return an adapter factory for `ob` from `registry`\"\"\"\n    for t in _get_mro(getattr(ob, '__class__', type(ob))):\n        if t in registry:\n            return registry[t]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ensure_directory(path):\n    dirname = os.path.dirname(path)\n    if not os.path.isdir(dirname):\n        os.makedirs(dirname)", "response": "Ensure that the parent directory of path exists"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef iter_entry_points(self, group, name=None):\n        for dist in self:\n            entries = dist.get_entry_map(group)\n            if name is None:\n                for ep in entries.values():\n                    yield ep\n            elif name in entries:\n                yield entries[name]", "response": "Yields all entry points in a group matching name."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsubscribe to all distributions including existing ones.", "response": "def subscribe(self, callback):\n        \"\"\"Invoke `callback` for all distributions (including existing ones)\"\"\"\n        if callback in self.callbacks:\n            return\n        self.callbacks.append(callback)\n        for dist in self:\n            callback(dist)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef can_add(self, dist):\n        return (self.python is None or dist.py_version is None\n            or dist.py_version==self.python) \\\n            and compatible_platforms(dist.platform, self.platform)", "response": "Is distribution dist acceptable for this environment?"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfind the best matching distribution that matches the given requirement and usable on the given working_set.", "response": "def best_match(self, req, working_set, installer=None):\n        \"\"\"Find distribution best matching `req` and usable on `working_set`\n\n        This calls the ``find(req)`` method of the `working_set` to see if a\n        suitable distribution is already active.  (This may raise\n        ``VersionConflict`` if an unsuitable version of the project is already\n        active in the specified `working_set`.)  If a suitable distribution\n        isn't active, this method returns the newest distribution in the\n        environment that meets the ``Requirement`` in `req`.  If no suitable\n        distribution is found, and `installer` is supplied, then the result of\n        calling the environment's ``obtain(req, installer)`` method will be\n        returned.\n        \"\"\"\n        dist = working_set.find(req)\n        if dist is not None:\n            return dist\n        for dist in self[req.key]:\n            if dist in req:\n                return dist\n        # try to download/install\n        return self.obtain(req, installer)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngives an error message for problems extracting file(s", "response": "def extraction_error(self):\n        \"\"\"Give an error message for problems extracting file(s)\"\"\"\n\n        old_exc = sys.exc_info()[1]\n        cache_path = self.extraction_path or get_default_cache()\n\n        err = ExtractionError(\"\"\"Can't extract file(s) to egg cache\n\nThe following error occurred while trying to extract file(s) to the Python egg\ncache:\n\n  %s\n\nThe Python egg cache directory is currently set to:\n\n  %s\n\nPerhaps your account does not have write access to this directory?  You can\nchange the cache directory by setting the PYTHON_EGG_CACHE environment\nvariable to point to an accessible directory.\n\"\"\" % (old_exc, cache_path)\n        )\n        err.manager = self\n        err.cache_path = cache_path\n        err.original_error = old_exc\n        raise err"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_invalid_marker(cls, text):\n        try:\n            cls.evaluate_marker(text)\n        except SyntaxError as e:\n            return cls.normalize_exception(e)\n        return False", "response": "Validate text as a PEP 426 environment marker ; return an exception\n        if invalid or False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngive an exception from a marker evaluation normalize the error message and return the exception.", "response": "def normalize_exception(exc):\n        \"\"\"\n        Given a SyntaxError from a marker evaluation, normalize the error\n        message:\n         - Remove indications of filename and line number.\n         - Replace platform-specific error messages with standard error\n           messages.\n        \"\"\"\n        subs = {\n            'unexpected EOF while parsing': 'invalid syntax',\n            'parenthesis is never closed': 'invalid syntax',\n        }\n        exc.filename = None\n        exc.lineno = None\n        exc.msg = subs.get(exc.msg, exc.msg)\n        return exc"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef evaluate_marker(cls, text, extra=None):\n        return cls.interpret(parser.expr(text).totuple(1)[1])", "response": "Evaluate a PEP 426 environment marker on CPython 2. 4 +."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nevaluating a PEP 426 environment marker using markerlib.", "response": "def _markerlib_evaluate(cls, text):\n        \"\"\"\n        Evaluate a PEP 426 environment marker using markerlib.\n        Return a boolean indicating the marker result in this environment.\n        Raise SyntaxError if marker is invalid.\n        \"\"\"\n        from pip._vendor import _markerlib\n        # markerlib implements Metadata 1.2 (PEP 345) environment markers.\n        # Translate the variables to Metadata 2.0 (PEP 426).\n        env = _markerlib.default_environment()\n        for key in env.keys():\n            new_key = key.replace('.', '_')\n            env[new_key] = env.pop(key)\n        try:\n            result = _markerlib.interpret(text, env)\n        except NameError as e:\n            raise SyntaxError(e.args[0])\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ninserts self. location in path before its nearest parent directory.", "response": "def insert_on(self, path, loc = None):\n        \"\"\"Insert self.location in path before its nearest parent directory\"\"\"\n\n        loc = loc or self.location\n        if not loc:\n            return\n\n        nloc = _normalize_cached(loc)\n        bdir = os.path.dirname(nloc)\n        npath= [(p and _normalize_cached(p) or p) for p in path]\n\n        for p, item in enumerate(npath):\n            if item == nloc:\n                break\n            elif item == bdir and self.precedence == EGG_DIST:\n                # if it's an .egg, give it precedence over its directory\n                if path is sys.path:\n                    self.check_version_conflict()\n                path.insert(p, loc)\n                npath.insert(p, nloc)\n                break\n        else:\n            if path is sys.path:\n                self.check_version_conflict()\n            path.append(loc)\n            return\n\n        # p is the spot where we found or inserted loc; now remove duplicates\n        while True:\n            try:\n                np = npath.index(nloc, p+1)\n            except ValueError:\n                break\n            else:\n                del npath[np], path[np]\n                # ha!\n                p = np\n\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert a string containing a requirement into a tuple of the distvers and mark.", "response": "def _preparse_requirement(self, requires_dist):\n        \"\"\"Convert 'Foobar (1); baz' to ('Foobar ==1', 'baz')\n        Split environment marker, add == prefix to version specifiers as\n        necessary, and remove parenthesis.\n        \"\"\"\n        parts = requires_dist.split(';', 1) + ['']\n        distvers = parts[0].strip()\n        mark = parts[1].strip()\n        distvers = re.sub(self.EQEQ, r\"\\1==\\2\\3\", distvers)\n        distvers = distvers.replace('(', '').replace(')', '')\n        return (distvers, mark)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nformats the log record with the current indentation level.", "response": "def format(self, record):\n        \"\"\"\n        Calls the standard formatter, but will indent all of the log messages\n        by our current indentation level.\n        \"\"\"\n        formatted = logging.Formatter.format(self, record)\n        formatted = \"\".join([\n            (\" \" * get_indentation()) + line\n            for line in formatted.splitlines(True)\n        ])\n        return formatted"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef format_currency(number, currency, format=None,\n                    locale=LC_NUMERIC, currency_digits=True,\n                    format_type='standard', decimal_quantization=True):\n\n    \"\"\"Return formatted currency value.\n\n    >>> format_currency(1099.98, 'USD', locale='en_US')\n    u'$1,099.98'\n    >>> format_currency(1099.98, 'USD', locale='es_CO')\n    u'US$\\\\xa01.099,98'\n    >>> format_currency(1099.98, 'EUR', locale='de_DE')\n    u'1.099,98\\\\xa0\\\\u20ac'\n\n    The format can also be specified explicitly.  The currency is\n    placed with the '\u00a4' sign.  As the sign gets repeated the format\n    expands (\u00a4 being the symbol, \u00a4\u00a4 is the currency abbreviation and\n    \u00a4\u00a4\u00a4 is the full name of the currency):\n\n    >>> format_currency(1099.98, 'EUR', u'\\xa4\\xa4 #,##0.00', locale='en_US')\n    u'EUR 1,099.98'\n    >>> format_currency(1099.98, 'EUR', u'#,##0.00 \\xa4\\xa4\\xa4',\n    ...                 locale='en_US')\n    u'1,099.98 euros'\n\n    Currencies usually have a specific number of decimal digits. This function\n    favours that information over the given format:\n\n    >>> format_currency(1099.98, 'JPY', locale='en_US')\n    u'\\\\xa51,100'\n    >>> format_currency(1099.98, 'COP', u'#,##0.00', locale='es_ES')\n    u'1.100'\n\n    However, the number of decimal digits can be overriden from the currency\n    information, by setting the last parameter to ``False``:\n\n    >>> format_currency(1099.98, 'JPY', locale='en_US', currency_digits=False)\n    u'\\\\xa51,099.98'\n    >>> format_currency(1099.98, 'COP', u'#,##0.00', locale='es_ES',\n    ...                 currency_digits=False)\n    u'1.099,98'\n\n    If a format is not specified the type of currency format to use\n    from the locale can be specified:\n\n    >>> format_currency(1099.98, 'EUR', locale='en_US', format_type='standard')\n    u'\\\\u20ac1,099.98'\n\n    When the given currency format type is not available, an exception is\n    raised:\n\n    >>> format_currency('1099.98', 'EUR', locale='root', format_type='unknown')\n    Traceback (most recent call last):\n        ...\n    UnknownCurrencyFormatError: \"'unknown' is not a known currency format type\"\n\n    By default the locale is allowed to truncate and round a high-precision\n    number by forcing its format pattern onto the decimal part. You can bypass\n    this behavior with the `decimal_quantization` parameter:\n\n    >>> format_currency(1099.9876, 'USD', locale='en_US')\n    u'$1,099.99'\n    >>> format_currency(1099.9876, 'USD', locale='en_US',\n    ...                 decimal_quantization=False)\n    u'$1,099.9876'\n\n    :param number: the number to format\n    :param currency: the currency code\n    :param format: the format string to use\n    :param locale: the `Locale` object or locale identifier\n    :param currency_digits: use the currency's natural number of decimal digits\n    :param format_type: the currency format type to use\n    :param decimal_quantization: Truncate and round high-precision numbers to\n                                 the format pattern. Defaults to `True`.\n    \"\"\"\n\n    locale = Locale.parse(locale)\n    if format:\n        pattern = parse_pattern(format)\n    else:\n        try:\n            p = locale.currency_formats[format_type]\n            pattern = NumberPattern(\n                p.pattern, p.prefix, p.suffix, p.grouping, p.int_prec,\n                p.frac_prec, p.exp_prec, p.exp_plus)\n\n        except KeyError:\n            raise UnknownCurrencyFormatError(\n                \"%r is not a known currency format type\" % format_type)\n    return pattern.apply(\n        number, locale, currency=currency, currency_digits=currency_digits,\n        decimal_quantization=decimal_quantization)", "response": "Return formatted currency value."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_pattern(pattern):\n    if isinstance(pattern, NumberPattern):\n        return pattern\n\n    def _match_number(pattern):\n        rv = number_re.search(pattern)\n        if rv is None:\n            raise ValueError('Invalid number pattern %r' % pattern)\n        return rv.groups()\n\n    pos_pattern = pattern\n\n    # Do we have a negative subpattern?\n    if ';' in pattern:\n        pos_pattern, neg_pattern = pattern.split(';', 1)\n        pos_prefix, number, pos_suffix = _match_number(pos_pattern)\n        neg_prefix, _, neg_suffix = _match_number(neg_pattern)\n    else:\n        pos_prefix, number, pos_suffix = _match_number(pos_pattern)\n        neg_prefix = '-' + pos_prefix\n        neg_suffix = pos_suffix\n    if 'E' in number:\n        number, exp = number.split('E', 1)\n    else:\n        exp = None\n    if '@' in number:\n        if '.' in number and '0' in number:\n            raise ValueError('Significant digit patterns can not contain '\n                             '\"@\" or \"0\"')\n    if '.' in number:\n        integer, fraction = number.rsplit('.', 1)\n    else:\n        integer = number\n        fraction = ''\n\n    def parse_precision(p):\n        \"\"\"Calculate the min and max allowed digits\"\"\"\n        min = max = 0\n        for c in p:\n            if c in '@0':\n                min += 1\n                max += 1\n            elif c == '#':\n                max += 1\n            elif c == ',':\n                continue\n            else:\n                break\n        return min, max\n\n    int_prec = parse_precision(integer)\n    frac_prec = parse_precision(fraction)\n    if exp:\n        exp_plus = exp.startswith('+')\n        exp = exp.lstrip('+')\n        exp_prec = parse_precision(exp)\n    else:\n        exp_plus = None\n        exp_prec = None\n    grouping = babel.numbers.parse_grouping(integer)\n    return NumberPattern(pattern, (pos_prefix, neg_prefix),\n                         (pos_suffix, neg_suffix), grouping,\n                         int_prec, frac_prec,\n                         exp_prec, exp_plus)", "response": "Parse a number format pattern and return a list of all possible number patterns."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_decimal_quantum(precision):\n    assert isinstance(precision, (int, decimal.Decimal))\n    return decimal.Decimal(10) ** (-precision)", "response": "Return minimal quantum of a number as defined by precision."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_decimal_precision(number):\n    # Copied from: https://github.com/mahmoud/boltons/pull/59\n    assert isinstance(number, decimal.Decimal)\n    decimal_tuple = number.normalize().as_tuple()\n    if decimal_tuple.exponent >= 0:\n        return 0\n    return abs(decimal_tuple.exponent)", "response": "Returns the maximum precision of a decimal instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef apply(\n            self, value, locale, currency=None, currency_digits=True,\n            decimal_quantization=True):\n        \"\"\"Renders into a string a number following the defined pattern.\n        Forced decimal quantization is active by default so we'll produce a\n        number string that is strictly following CLDR pattern definitions.\n        \"\"\"\n        if not isinstance(value, decimal.Decimal):\n            value = decimal.Decimal(str(value))\n\n        value = value.scaleb(self.scale)\n\n        # Separate the absolute value from its sign.\n        is_negative = int(value.is_signed())\n        value = abs(value).normalize()\n\n        # Prepare scientific notation metadata.\n        if self.exp_prec:\n            value, exp, exp_sign = self.scientific_notation_elements(\n                value, locale)\n\n        # Adjust the precision of the fractionnal part and force it to the\n        # currency's if neccessary.\n        frac_prec = self.frac_prec\n        if currency and currency_digits:\n            frac_prec = (babel.numbers.get_currency_precision(currency), ) * 2\n\n        # Bump decimal precision to the natural precision of the number if it\n        # exceeds the one we're about to use. This adaptative precision is only\n        # triggered if the decimal quantization is disabled or if a scientific\n        # notation pattern has a missing mandatory fractional part (as in the\n        # default '#E0' pattern). This special case has been extensively\n        # discussed at\n        # https://github.com/python-babel/babel/pull/494#issuecomment-307649969\n        if not decimal_quantization or (self.exp_prec and frac_prec == (0, 0)):\n            frac_prec = (frac_prec[0], max([frac_prec[1],\n                                            get_decimal_precision(value)]))\n\n        # Render scientific notation.\n        if self.exp_prec:\n            number = ''.join([\n                self._quantize_value(value, locale, frac_prec),\n                babel.numbers.get_exponential_symbol(locale),\n                exp_sign,\n                self._format_int(\n                    str(exp), self.exp_prec[0], self.exp_prec[1], locale)])\n\n        # Is it a siginificant digits pattern?\n        elif '@' in self.pattern:\n            text = self._format_significant(value,\n                                            self.int_prec[0],\n                                            self.int_prec[1])\n            a, sep, b = text.partition(\".\")\n            number = self._format_int(a, 0, 1000, locale)\n            if sep:\n                number += babel.numbers.get_decimal_symbol(locale) + b\n\n        # A normal number pattern.\n        else:\n            number = self._quantize_value(value, locale, frac_prec)\n\n        retval = ''.join([\n            self.prefix[is_negative],\n            number,\n            self.suffix[is_negative]])\n\n        if u'\u00a4' in retval:\n            retval = retval.replace(u'\u00a4\u00a4\u00a4',\n                                    babel.numbers.get_currency_name(\n                                        currency, value, locale))\n            retval = retval.replace(u'\u00a4\u00a4', currency.upper())\n            retval = retval.replace(u'\u00a4', babel.numbers.get_currency_symbol(\n                currency, locale))\n\n        return retval", "response": "Applies the values to the CLDR number metadata."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn normalized scientific notation components of a value.", "response": "def scientific_notation_elements(self, value, locale):\n        \"\"\" Returns normalized scientific notation components of a value.\"\"\"\n        # Normalize value to only have one lead digit.\n        exp = value.adjusted()\n        value = value * get_decimal_quantum(exp)\n        assert value.adjusted() == 0\n\n        # Shift exponent and value by the minimum number of leading digits\n        # imposed by the rendering pattern. And always make that number\n        # greater or equal to 1.\n        lead_shift = max([1, min(self.int_prec)]) - 1\n        exp = exp - lead_shift\n        value = value * get_decimal_quantum(-lead_shift)\n\n        # Get exponent sign symbol.\n        exp_sign = ''\n        if exp < 0:\n            exp_sign = babel.numbers.get_minus_sign_symbol(locale)\n        elif self.exp_plus:\n            exp_sign = babel.numbers.get_plus_sign_symbol(locale)\n\n        # Normalize exponent value now that we have the sign.\n        exp = abs(exp)\n\n        return value, exp, exp_sign"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\npatch distutils. msvc9compiler to use the standalone compiler build for Python.", "response": "def patch_for_specialized_compiler():\n    \"\"\"\n    Patch functions in distutils.msvc9compiler to use the standalone compiler\n    build for Python (Windows only). Fall back to original behavior when the\n    standalone compiler is not available.\n    \"\"\"\n    if 'distutils' not in globals():\n        # The module isn't available to be patched\n        return\n\n    if unpatched:\n        # Already patched\n        return\n\n    unpatched.update(vars(distutils.msvc9compiler))\n\n    distutils.msvc9compiler.find_vcvarsall = find_vcvarsall\n    distutils.msvc9compiler.query_vcvarsall = query_vcvarsall"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef total_seconds(td):\n    if hasattr(td, 'total_seconds'):\n        return td.total_seconds()\n\n    ms = td.microseconds\n    secs = (td.seconds + td.days * 24 * 3600)\n    return (ms + secs * 10**6) / 10**6", "response": "Python 2. 6 compatability"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_requirements(strs):\n    # create a steppable iterator, so we can handle \\-continuations\n    lines = iter(yield_lines(strs))\n\n    def scan_list(ITEM, TERMINATOR, line, p, groups, item_name):\n\n        items = []\n\n        while not TERMINATOR(line, p):\n            if CONTINUE(line, p):\n                try:\n                    line = next(lines)\n                    p = 0\n                except StopIteration:\n                    msg = \"\\\\ must not appear on the last nonblank line\"\n                    raise RequirementParseError(msg)\n\n            match = ITEM(line, p)\n            if not match:\n                msg = \"Expected \" + item_name + \" in\"\n                raise RequirementParseError(msg, line, \"at\", line[p:])\n\n            items.append(match.group(*groups))\n            p = match.end()\n\n            match = COMMA(line, p)\n            if match:\n                # skip the comma\n                p = match.end()\n            elif not TERMINATOR(line, p):\n                msg = \"Expected ',' or end-of-list in\"\n                raise RequirementParseError(msg, line, \"at\", line[p:])\n\n        match = TERMINATOR(line, p)\n        # skip the terminator, if any\n        if match:\n            p = match.end()\n        return line, p, items\n\n    for line in lines:\n        match = DISTRO(line)\n        if not match:\n            raise RequirementParseError(\"Missing distribution spec\", line)\n        project_name = match.group(1)\n        p = match.end()\n        extras = []\n\n        match = OBRACKET(line, p)\n        if match:\n            p = match.end()\n            line, p, extras = scan_list(\n                DISTRO, CBRACKET, line, p, (1,), \"'extra' name\"\n            )\n\n        line, p, specs = scan_list(VERSION, LINE_END, line, p, (1, 2),\n            \"version spec\")\n        specs = [(op, val) for op, val in specs]\n        yield Requirement(project_name, specs, extras)", "response": "Parse a list of requirements from a string."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets up global resource manager ( deliberately not state - saved )", "response": "def _initialize(g=globals()):\n    \"Set up global resource manager (deliberately not state-saved)\"\n    manager = ResourceManager()\n    g['_manager'] = manager\n    for name in dir(manager):\n        if not name.startswith('_'):\n            g[name] = getattr(manager, name)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ninitialize the master working set and sets the entry points and the main run script.", "response": "def _initialize_master_working_set():\n    \"\"\"\n    Prepare the master working set and make the ``require()``\n    API available.\n\n    This function has explicit effects on the global state\n    of pkg_resources. It is intended to be invoked once at\n    the initialization of this module.\n\n    Invocation by other packages is unsupported and done\n    at their own risk.\n    \"\"\"\n    working_set = WorkingSet._build_master()\n    _declare_state('object', working_set=working_set)\n\n    require = working_set.require\n    iter_entry_points = working_set.iter_entry_points\n    add_activation_listener = working_set.subscribe\n    run_script = working_set.run_script\n    # backward compatibility\n    run_main = run_script\n    # Activate all distributions already on sys.path, and ensure that\n    # all distributions added to the working set in the future (e.g. by\n    # calling ``require()``) will get activated as well.\n    add_activation_listener(lambda dist: dist.activate())\n    working_set.entries=[]\n    # match order\n    list(map(working_set.add_entry, sys.path))\n    globals().update(locals())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nprotecting against re - patching distutils if reloaded", "response": "def _get_unpatched(cls):\n    \"\"\"Protect against re-patching the distutils if reloaded\n\n    Also ensures that no other distutils extension monkeypatched the distutils\n    first.\n    \"\"\"\n    while cls.__module__.startswith('setuptools'):\n        cls, = cls.__bases__\n    if not cls.__module__.startswith('distutils'):\n        raise AssertionError(\n            \"distutils has already been patched by %r\" % cls\n        )\n    return cls"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _patch_distribution_metadata_write_pkg_info():\n    environment_local = (3,) <= sys.version_info[:3] < (3, 2, 2)\n    if not environment_local:\n        return\n\n    # from Python 3.4\n    def write_pkg_info(self, base_dir):\n        \"\"\"Write the PKG-INFO file into the release tree.\n        \"\"\"\n        with open(os.path.join(base_dir, 'PKG-INFO'), 'w',\n                  encoding='UTF-8') as pkg_info:\n            self.write_pkg_file(pkg_info)\n\n    distutils.dist.DistributionMetadata.write_pkg_info = write_pkg_info", "response": "Patch distutils. dist. DistributionMetadata. write_pkg_info to use the PKG - INFO file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef check_extras(dist, attr, value):\n    try:\n        for k,v in value.items():\n            if ':' in k:\n                k,m = k.split(':',1)\n                if pkg_resources.invalid_marker(m):\n                    raise DistutilsSetupError(\"Invalid environment marker: \"+m)\n            list(pkg_resources.parse_requirements(v))\n    except (TypeError,ValueError,AttributeError):\n        raise DistutilsSetupError(\n            \"'extras_require' must be a dictionary whose values are \"\n            \"strings or lists of strings containing valid project/version \"\n            \"requirement specifiers.\"\n        )", "response": "Verify that extras_require mapping is valid."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef check_requirements(dist, attr, value):\n    try:\n        list(pkg_resources.parse_requirements(value))\n    except (TypeError, ValueError) as error:\n        tmpl = (\n            \"{attr!r} must be a string or list of strings \"\n            \"containing valid project/version requirement specifiers; {error}\"\n        )\n        raise DistutilsSetupError(tmpl.format(attr=attr, error=error))", "response": "Verify that install_requires is a valid requirements list"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfetch an egg needed for building", "response": "def fetch_build_egg(self, req):\n        \"\"\"Fetch an egg needed for building\"\"\"\n\n        try:\n            cmd = self._egg_fetcher\n            cmd.package_index.to_scan = []\n        except AttributeError:\n            from setuptools.command.easy_install import easy_install\n            dist = self.__class__({'script_args':['easy_install']})\n            dist.parse_config_files()\n            opts = dist.get_option_dict('easy_install')\n            keep = (\n                'find_links', 'site_dirs', 'index_url', 'optimize',\n                'site_dirs', 'allow_hosts'\n            )\n            for key in list(opts):\n                if key not in keep:\n                    del opts[key]   # don't use any other settings\n            if self.dependency_links:\n                links = self.dependency_links[:]\n                if 'find_links' in opts:\n                    links = opts['find_links'][1].split() + links\n                opts['find_links'] = ('setup', links)\n            install_dir = self.get_egg_cache_dir()\n            cmd = easy_install(\n                dist, args=[\"x\"], install_dir=install_dir, exclude_scripts=True,\n                always_copy=False, build_directory=None, editable=False,\n                upgrade=False, multi_version=True, no_report=True, user=False\n            )\n            cmd.ensure_finalized()\n            self._egg_fetcher = cmd\n        return cmd.easy_install(req)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nhandle include()' for list or tuple attrs without a special handler.", "response": "def _include_misc(self,name,value):\n        \"\"\"Handle 'include()' for list/tuple attrs without a special handler\"\"\"\n\n        if not isinstance(value,sequence):\n            raise DistutilsSetupError(\n                \"%s: setting must be a list (%r)\" % (name, value)\n            )\n        try:\n            old = getattr(self,name)\n        except AttributeError:\n            raise DistutilsSetupError(\n                \"%s: No such distribution setting\" % name\n            )\n        if old is None:\n            setattr(self,name,value)\n        elif not isinstance(old,sequence):\n            raise DistutilsSetupError(\n                name+\": this setting cannot be changed via include/exclude\"\n            )\n        else:\n            setattr(self,name,old+[item for item in value if item not in old])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrolling n - sided dice and return each result and the total", "response": "def do_dice_roll():\n\t\"\"\"\n\tRoll n-sided dice and return each result and the total\n\t\"\"\"\n\toptions = get_options()\n\tdice = Dice(options.sides)\n\trolls = [dice.roll() for n in range(options.number)]\n\tfor roll in rolls:\n\t\tprint('rolled', roll)\n\tif options.number > 1:\n\t\tprint('total', sum(rolls))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef price_converter(obj):\n    if isinstance(obj, str):\n        obj = PriceClass.parse(obj)\n    return obj", "response": "Ensures that string prices are converted into Price objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a new attribute that can be used to set the price of the current object.", "response": "def price(*args, **kwargs):\n    \"\"\"Price field for attrs.\n\n    See `help(attr.ib)` for full signature.\n\n    Usage:\n\n        >>> from pricing import fields\n        ... @attr.s\n        ... class Test:\n        ...     price: Price = fields.price(default='USD 5.00')\n        ...\n        ... Test()\n        Test(price=USD 5.00)\n    \"\"\"\n\n    kwargs.setdefault('default', 'USD 0.00')\n    kwargs.setdefault('converter', price_converter)\n\n    if 'validator' in kwargs:\n        validator = kwargs.pop('validator')\n        if not isinstance(validator, (tuple, list)):\n            validator = [validator]\n    else:\n        validator = []\n    validator.append(instance_of(PriceClass))\n    return attr.ib(validator=validator, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef validate(self, request):\n\n        try:\n            validate_version(request)\n            validate_method(request)\n            validate_params(request)\n            validate_id(request)\n        except (AssertionError, KeyError) as error:\n            invalid_request(error)", "response": "Validate the JSON - RPC request."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_method(self, args):\n\n        try:\n            method = self.app[args['method']]\n        except KeyError:\n            method_not_found(args['id'])\n        else:\n            return method", "response": "Get request method for service application."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef module(self):\n        from warnings import warn\n        warn(DeprecationWarning('modules were deprecated in favor of '\n                                'blueprints.  Use request.blueprint '\n                                'instead.'), stacklevel=2)\n        if self._is_old_module:\n            return self.blueprint", "response": "The name of the current module if the request was dispatched\n        to an actual module."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_json(self, force=False, silent=False, cache=True):\n        rv = getattr(self, '_cached_json', _missing)\n        if rv is not _missing:\n            return rv\n\n        if self.mimetype != 'application/json' and not force:\n            return None\n\n        # We accept a request charset against the specification as\n        # certain clients have been using this in the past.  This\n        # fits our general approach of being nice in what we accept\n        # and strict in what we send out.\n        request_charset = self.mimetype_params.get('charset')\n        try:\n            data = _get_data(self, cache)\n            if request_charset is not None:\n                rv = json.loads(data, encoding=request_charset)\n            else:\n                rv = json.loads(data)\n        except ValueError as e:\n            if silent:\n                rv = None\n            else:\n                rv = self.on_json_loading_failed(e)\n        if cache:\n            self._cached_json = rv\n        return rv", "response": "Parses the incoming JSON request data and returns it."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef attach_enctype_error_multidict(request):\n    oldcls = request.files.__class__\n    class newcls(oldcls):\n        def __getitem__(self, key):\n            try:\n                return oldcls.__getitem__(self, key)\n            except KeyError as e:\n                if key not in request.form:\n                    raise\n                raise DebugFilesKeyError(request, key)\n    newcls.__name__ = oldcls.__name__\n    newcls.__module__ = oldcls.__module__\n    request.files.__class__ = newcls", "response": "Monkeypatch the request. files object in case of multipart form data but the files object is accessed."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a install_req as a requirement to the set.", "response": "def add_requirement(self, install_req, parent_req_name=None):\n        \"\"\"Add install_req as a requirement to install.\n\n        :param parent_req_name: The name of the requirement that needed this\n            added. The name is used because when multiple unnamed requirements\n            resolve to the same name, we could otherwise end up with dependency\n            links that point outside the Requirements set. parent_req must\n            already be added. Note that None implies that this is a user\n            supplied requirement, vs an inferred one.\n        :return: Additional requirements to scan. That is either [] if\n            the requirement is not applicable, or [install_req] if the\n            requirement is applicable and has just been added.\n        \"\"\"\n        name = install_req.name\n        if not install_req.match_markers():\n            logger.warning(\"Ignoring %s: markers %r don't match your \"\n                           \"environment\", install_req.name,\n                           install_req.markers)\n            return []\n\n        install_req.as_egg = self.as_egg\n        install_req.use_user_site = self.use_user_site\n        install_req.target_dir = self.target_dir\n        install_req.pycompile = self.pycompile\n        if not name:\n            # url or path requirement w/o an egg fragment\n            self.unnamed_requirements.append(install_req)\n            return [install_req]\n        else:\n            if parent_req_name is None and self.has_requirement(name):\n                raise InstallationError(\n                    'Double requirement given: %s (already in %s, name=%r)'\n                    % (install_req, self.get_requirement(name), name))\n            if not self.has_requirement(name):\n                # Add requirement\n                self.requirements[name] = install_req\n                # FIXME: what about other normalizations?  E.g., _ vs. -?\n                if name.lower() != name:\n                    self.requirement_aliases[name.lower()] = name\n                result = [install_req]\n            else:\n                # Canonicalise to the already-added object\n                install_req = self.get_requirement(name)\n                # No need to scan, this is a duplicate requirement.\n                result = []\n            if parent_req_name:\n                parent_req = self.get_requirement(parent_req_name)\n                self._dependencies[parent_req].append(install_req)\n            return result"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _walk_req_to_install(self, handler):\n        # The list() here is to avoid potential mutate-while-iterating bugs.\n        discovered_reqs = []\n        reqs = itertools.chain(\n            list(self.unnamed_requirements), list(self.requirements.values()),\n            discovered_reqs)\n        for req_to_install in reqs:\n            more_reqs = handler(req_to_install)\n            if more_reqs:\n                discovered_reqs.extend(more_reqs)", "response": "Walks the list of pending requirements and calls handler for all pending requirements."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating temp directories download and unpack files.", "response": "def prepare_files(self, finder):\n        \"\"\"\n        Prepare process. Create temp directories, download and/or unpack files.\n        \"\"\"\n        # make the wheelhouse\n        if self.wheel_download_dir:\n            ensure_dir(self.wheel_download_dir)\n\n        self._walk_req_to_install(\n            functools.partial(self._prepare_file, finder))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if the req_to_install should be skipped.", "response": "def _check_skip_installed(self, req_to_install, finder):\n        \"\"\"Check if req_to_install should be skipped.\n\n        This will check if the req is installed, and whether we should upgrade\n        or reinstall it, taking into account all the relevant user options.\n\n        After calling this req_to_install will only have satisfied_by set to\n        None if the req_to_install is to be upgraded/reinstalled etc. Any\n        other value will be a dist recording the current thing installed that\n        satisfies the requirement.\n\n        Note that for vcs urls and the like we can't assess skipping in this\n        routine - we simply identify that we need to pull the thing down,\n        then later on it is pulled down and introspected to assess upgrade/\n        reinstalls etc.\n\n        :return: A text reason for why it was skipped, or None.\n        \"\"\"\n        # Check whether to upgrade/reinstall this req or not.\n        req_to_install.check_if_exists()\n        if req_to_install.satisfied_by:\n            skip_reason = 'satisfied (use --upgrade to upgrade)'\n            if self.upgrade:\n                best_installed = False\n                # For link based requirements we have to pull the\n                # tree down and inspect to assess the version #, so\n                # its handled way down.\n                if not (self.force_reinstall or req_to_install.link):\n                    try:\n                        finder.find_requirement(req_to_install, self.upgrade)\n                    except BestVersionAlreadyInstalled:\n                        skip_reason = 'up-to-date'\n                        best_installed = True\n                    except DistributionNotFound:\n                        # No distribution found, so we squash the\n                        # error - it will be raised later when we\n                        # re-try later to do the install.\n                        # Why don't we just raise here?\n                        pass\n\n                if not best_installed:\n                    # don't uninstall conflict if user install and\n                    # conflict is not user install\n                    if not (self.use_user_site and not\n                            dist_in_usersite(req_to_install.satisfied_by)):\n                        req_to_install.conflicts_with = \\\n                            req_to_install.satisfied_by\n                    req_to_install.satisfied_by = None\n            return skip_reason\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _prepare_file(self, finder, req_to_install):\n        # Tell user what we are doing for this requirement:\n        # obtain (editable), skipping, processing (local url), collecting\n        # (remote url or package name)\n        if req_to_install.editable:\n            logger.info('Obtaining %s', req_to_install)\n        else:\n            # satisfied_by is only evaluated by calling _check_skip_installed,\n            # so it must be None here.\n            assert req_to_install.satisfied_by is None\n            if not self.ignore_installed:\n                skip_reason = self._check_skip_installed(\n                    req_to_install, finder)\n\n            if req_to_install.satisfied_by:\n                assert skip_reason is not None, (\n                    '_check_skip_installed returned None but '\n                    'req_to_install.satisfied_by is set to %r'\n                    % (req_to_install.satisfied_by,))\n                logger.info(\n                    'Requirement already %s: %s', skip_reason,\n                    req_to_install)\n            else:\n                if (req_to_install.link and\n                        req_to_install.link.scheme == 'file'):\n                    path = url_to_path(req_to_install.link.url)\n                    logger.info('Processing %s', display_path(path))\n                else:\n                    logger.info('Collecting %s', req_to_install)\n\n        with indent_log():\n            # ################################ #\n            # # vcs update or unpack archive # #\n            # ################################ #\n            if req_to_install.editable:\n                req_to_install.ensure_has_source_dir(self.src_dir)\n                req_to_install.update_editable(not self.is_download)\n                abstract_dist = make_abstract_dist(req_to_install)\n                abstract_dist.prep_for_dist()\n                if self.is_download:\n                    req_to_install.archive(self.download_dir)\n            elif req_to_install.satisfied_by:\n                abstract_dist = Installed(req_to_install)\n            else:\n                # @@ if filesystem packages are not marked\n                # editable in a req, a non deterministic error\n                # occurs when the script attempts to unpack the\n                # build directory\n                req_to_install.ensure_has_source_dir(self.build_dir)\n                # If a checkout exists, it's unwise to keep going.  version\n                # inconsistencies are logged later, but do not fail the\n                # installation.\n                # FIXME: this won't upgrade when there's an existing\n                # package unpacked in `req_to_install.source_dir`\n                if os.path.exists(\n                        os.path.join(req_to_install.source_dir, 'setup.py')):\n                    raise PreviousBuildDirError(\n                        \"pip can't proceed with requirements '%s' due to a\"\n                        \" pre-existing build directory (%s). This is \"\n                        \"likely due to a previous installation that failed\"\n                        \". pip is being responsible and not assuming it \"\n                        \"can delete this. Please delete it and try again.\"\n                        % (req_to_install, req_to_install.source_dir)\n                    )\n                req_to_install.populate_link(finder, self.upgrade)\n                # We can't hit this spot and have populate_link return None.\n                # req_to_install.satisfied_by is None here (because we're\n                # guarded) and upgrade has no impact except when satisfied_by\n                # is not None.\n                # Then inside find_requirement existing_applicable -> False\n                # If no new versions are found, DistributionNotFound is raised,\n                # otherwise a result is guaranteed.\n                assert req_to_install.link\n                try:\n                    download_dir = self.download_dir\n                    # We always delete unpacked sdists after pip ran.\n                    autodelete_unpacked = True\n                    if req_to_install.link.is_wheel \\\n                            and self.wheel_download_dir:\n                        # when doing 'pip wheel` we download wheels to a\n                        # dedicated dir.\n                        download_dir = self.wheel_download_dir\n                    if req_to_install.link.is_wheel:\n                        if download_dir:\n                            # When downloading, we only unpack wheels to get\n                            # metadata.\n                            autodelete_unpacked = True\n                        else:\n                            # When installing a wheel, we use the unpacked\n                            # wheel.\n                            autodelete_unpacked = False\n                    unpack_url(\n                        req_to_install.link, req_to_install.source_dir,\n                        download_dir, autodelete_unpacked,\n                        session=self.session)\n                except requests.HTTPError as exc:\n                    logger.critical(\n                        'Could not install requirement %s because '\n                        'of error %s',\n                        req_to_install,\n                        exc,\n                    )\n                    raise InstallationError(\n                        'Could not install requirement %s because '\n                        'of HTTP error %s for URL %s' %\n                        (req_to_install, exc, req_to_install.link)\n                    )\n                abstract_dist = make_abstract_dist(req_to_install)\n                abstract_dist.prep_for_dist()\n                if self.is_download:\n                    # Make a .zip of the source_dir we already created.\n                    if req_to_install.link.scheme in vcs.all_schemes:\n                        req_to_install.archive(self.download_dir)\n                # req_to_install.req is only avail after unpack for URL\n                # pkgs repeat check_if_exists to uninstall-on-upgrade\n                # (#14)\n                if not self.ignore_installed:\n                    req_to_install.check_if_exists()\n                if req_to_install.satisfied_by:\n                    if self.upgrade or self.ignore_installed:\n                        # don't uninstall conflict if user install and\n                        # conflict is not user install\n                        if not (self.use_user_site and not\n                                dist_in_usersite(\n                                    req_to_install.satisfied_by)):\n                            req_to_install.conflicts_with = \\\n                                req_to_install.satisfied_by\n                        req_to_install.satisfied_by = None\n                    else:\n                        logger.info(\n                            'Requirement already satisfied (use '\n                            '--upgrade to upgrade): %s',\n                            req_to_install,\n                        )\n\n            # ###################### #\n            # # parse dependencies # #\n            # ###################### #\n            dist = abstract_dist.dist(finder)\n            more_reqs = []\n\n            def add_req(subreq):\n                sub_install_req = InstallRequirement(\n                    str(subreq),\n                    req_to_install,\n                    isolated=self.isolated,\n                    wheel_cache=self._wheel_cache,\n                )\n                more_reqs.extend(self.add_requirement(\n                    sub_install_req, req_to_install.name))\n\n            # We add req_to_install before its dependencies, so that we\n            # can refer to it when adding dependencies.\n            if not self.has_requirement(req_to_install.name):\n                # 'unnamed' requirements will get added here\n                self.add_requirement(req_to_install, None)\n\n            if not self.ignore_dependencies:\n                if (req_to_install.extras):\n                    logger.debug(\n                        \"Installing extra requirements: %r\",\n                        ','.join(req_to_install.extras),\n                    )\n                missing_requested = sorted(\n                    set(req_to_install.extras) - set(dist.extras)\n                )\n                for missing in missing_requested:\n                    logger.warning(\n                        '%s does not provide the extra \\'%s\\'',\n                        dist, missing\n                    )\n\n                available_requested = sorted(\n                    set(dist.extras) & set(req_to_install.extras)\n                )\n                for subreq in dist.requires(available_requested):\n                    add_req(subreq)\n\n            # cleanup tmp src\n            self.reqs_to_cleanup.append(req_to_install)\n\n            if not req_to_install.editable and not req_to_install.satisfied_by:\n                # XXX: --no-install leads this to report 'Successfully\n                # downloaded' for only non-editable reqs, even though we took\n                # action on them.\n                self.successfully_downloaded.append(req_to_install)\n\n        return more_reqs", "response": "Prepare a single file for installing."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cleanup_files(self):\n        logger.debug('Cleaning up...')\n        with indent_log():\n            for req in self.reqs_to_cleanup:\n                req.remove_temporary_source()", "response": "Clean up files remove builds."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating the installation order.", "response": "def _to_install(self):\n        \"\"\"Create the installation order.\n\n        The installation order is topological - requirements are installed\n        before the requiring thing. We break cycles at an arbitrary point,\n        and make no other guarantees.\n        \"\"\"\n        # The current implementation, which we may change at any point\n        # installs the user specified things in the order given, except when\n        # dependencies must come earlier to achieve topological order.\n        order = []\n        ordered_reqs = set()\n\n        def schedule(req):\n            if req.satisfied_by or req in ordered_reqs:\n                return\n            ordered_reqs.add(req)\n            for dep in self._dependencies[req]:\n                schedule(dep)\n            order.append(req)\n        for install_req in self.requirements.values():\n            schedule(install_req)\n        return order"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ninstalls all packages in this set.", "response": "def install(self, install_options, global_options=(), *args, **kwargs):\n        \"\"\"\n        Install everything in this set (after having downloaded and unpacked\n        the packages)\n        \"\"\"\n        to_install = self._to_install()\n\n        if to_install:\n            logger.info(\n                'Installing collected packages: %s',\n                ', '.join([req.name for req in to_install]),\n            )\n\n        with indent_log():\n            for requirement in to_install:\n                if requirement.conflicts_with:\n                    logger.info(\n                        'Found existing installation: %s',\n                        requirement.conflicts_with,\n                    )\n                    with indent_log():\n                        requirement.uninstall(auto_confirm=True)\n                try:\n                    requirement.install(\n                        install_options,\n                        global_options,\n                        *args,\n                        **kwargs\n                    )\n                except:\n                    # if install did not succeed, rollback previous uninstall\n                    if (requirement.conflicts_with and not\n                            requirement.install_succeeded):\n                        requirement.rollback_uninstall()\n                    raise\n                else:\n                    if (requirement.conflicts_with and\n                            requirement.install_succeeded):\n                        requirement.commit_uninstall()\n                requirement.remove_temporary_source()\n\n        self.successfully_installed = to_install"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning sorted list of all package namespaces", "response": "def _get_all_ns_packages(self):\n        \"\"\"Return sorted list of all package namespaces\"\"\"\n        nsp = set()\n        for pkg in self.distribution.namespace_packages or []:\n            pkg = pkg.split('.')\n            while pkg:\n                nsp.add('.'.join(pkg))\n                pkg.pop()\n        return sorted(nsp)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef default(self, obj):\n        if isinstance(obj, models.Model):\n            return self.encode(model_to_dict(obj))\n        elif isinstance(obj, models.query.QuerySet):\n            return serializers.serialize('json', obj)\n        else:\n            return super(JsonResponseEncoder, self).default(obj)", "response": "Convert the given object into a list of counter - parts."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntakes a list of documents and returns a list of HTML documents that are annotated with the given markup.", "response": "def html_annotate(doclist, markup=default_markup):\n    \"\"\"\n    doclist should be ordered from oldest to newest, like::\n\n        >>> version1 = 'Hello World'\n        >>> version2 = 'Goodbye World'\n        >>> print(html_annotate([(version1, 'version 1'),\n        ...                      (version2, 'version 2')]))\n        <span title=\"version 2\">Goodbye</span> <span title=\"version 1\">World</span>\n\n    The documents must be *fragments* (str/UTF8 or unicode), not\n    complete documents\n\n    The markup argument is a function to markup the spans of words.\n    This function is called like markup('Hello', 'version 2'), and\n    returns HTML.  The first argument is text and never includes any\n    markup.  The default uses a span with a title:\n\n        >>> print(default_markup('Some Text', 'by Joe'))\n        <span title=\"by Joe\">Some Text</span>\n    \"\"\"\n    # The basic strategy we have is to split the documents up into\n    # logical tokens (which are words with attached markup).  We then\n    # do diffs of each of the versions to track when a token first\n    # appeared in the document; the annotation attached to the token\n    # is the version where it first appeared.\n    tokenlist = [tokenize_annotated(doc, version)\n                 for doc, version in doclist]\n    cur_tokens = tokenlist[0]\n    for tokens in tokenlist[1:]:\n        html_annotate_merge_annotations(cur_tokens, tokens)\n        cur_tokens = tokens\n\n    # After we've tracked all the tokens, we can combine spans of text\n    # that are adjacent and have the same annotation\n    cur_tokens = compress_tokens(cur_tokens)\n    # And finally add markup\n    result = markup_serialize_tokens(cur_tokens, markup)\n    return ''.join(result).strip()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef tokenize_annotated(doc, annotation): \n    tokens = tokenize(doc, include_hrefs=False)\n    for tok in tokens: \n        tok.annotation = annotation\n    return tokens", "response": "Tokenize a document and add an annotation attribute to each token\n   "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef html_annotate_merge_annotations(tokens_old, tokens_new): \n    s = InsensitiveSequenceMatcher(a=tokens_old, b=tokens_new)\n    commands = s.get_opcodes()\n\n    for command, i1, i2, j1, j2 in commands:\n        if command == 'equal': \n            eq_old = tokens_old[i1:i2]\n            eq_new = tokens_new[j1:j2]\n            copy_annotations(eq_old, eq_new)", "response": "Merge the annotations from tokens_old into tokens_new when the\n    tokens in the old document already existed in the new document."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncopy annotations from the tokens listed in src to the tokens listed in dest.", "response": "def copy_annotations(src, dest): \n    \"\"\"\n    Copy annotations from the tokens listed in src to the tokens in dest\n    \"\"\"\n    assert len(src) == len(dest)\n    for src_tok, dest_tok in zip(src, dest): \n        dest_tok.annotation = src_tok.annotation"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef compress_tokens(tokens):\n    result = [tokens[0]] \n    for tok in tokens[1:]: \n        if (not result[-1].post_tags and \n            not tok.pre_tags and \n            result[-1].annotation == tok.annotation): \n            compress_merge_back(result, tok)\n        else: \n            result.append(tok)\n    return result", "response": "Combine adjacent tokens when there is no HTML between the tokens and their annotations."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmerge tok into the last element of tokens in - place.", "response": "def compress_merge_back(tokens, tok): \n    \"\"\" Merge tok into the last element of tokens (modifying the list of\n    tokens in-place).  \"\"\"\n    last = tokens[-1]\n    if type(last) is not token or type(tok) is not token: \n        tokens.append(tok)\n    else:\n        text = _unicode(last)\n        if last.trailing_whitespace:\n            text += last.trailing_whitespace\n        text += tok\n        merged = token(text,\n                       pre_tags=last.pre_tags,\n                       post_tags=tok.post_tags,\n                       trailing_whitespace=tok.trailing_whitespace)\n        merged.annotation = last.annotation\n        tokens[-1] = merged"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef markup_serialize_tokens(tokens, markup_func):\n    for token in tokens:\n        for pre in token.pre_tags:\n            yield pre\n        html = token.html()\n        html = markup_func(html, token.annotation)\n        if token.trailing_whitespace:\n            html += token.trailing_whitespace\n        yield html\n        for post in token.post_tags:\n            yield post", "response": "Serialize the list of tokens into a list of text chunks calling markup_func around text to add annotations."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef htmldiff(old_html, new_html):\n    ## FIXME: this should take parsed documents too, and use their body\n    ## or other content.\n    \"\"\" Do a diff of the old and new document.  The documents are HTML\n    *fragments* (str/UTF8 or unicode), they are not complete documents\n    (i.e., no <html> tag).\n\n    Returns HTML with <ins> and <del> tags added around the\n    appropriate text.  \n\n    Markup is generally ignored, with the markup from new_html\n    preserved, and possibly some markup from old_html (though it is\n    considered acceptable to lose some of the old markup).  Only the\n    words in the HTML are diffed.  The exception is <img> tags, which\n    are treated like words, and the href attribute of <a> tags, which\n    are noted inside the tag itself when there are changes.\n    \"\"\" \n    old_html_tokens = tokenize(old_html)\n    new_html_tokens = tokenize(new_html)\n    result = htmldiff_tokens(old_html_tokens, new_html_tokens)\n    result = ''.join(result).strip()\n    return fixup_ins_del_tags(result)", "response": "Do a diff of the old and new HTML document."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef htmldiff_tokens(html1_tokens, html2_tokens):\n    # There are several passes as we do the differences.  The tokens\n    # isolate the portion of the content we care to diff; difflib does\n    # all the actual hard work at that point.  \n    #\n    # Then we must create a valid document from pieces of both the old\n    # document and the new document.  We generally prefer to take\n    # markup from the new document, and only do a best effort attempt\n    # to keep markup from the old document; anything that we can't\n    # resolve we throw away.  Also we try to put the deletes as close\n    # to the location where we think they would have been -- because\n    # we are only keeping the markup from the new document, it can be\n    # fuzzy where in the new document the old text would have gone.\n    # Again we just do a best effort attempt.\n    s = InsensitiveSequenceMatcher(a=html1_tokens, b=html2_tokens)\n    commands = s.get_opcodes()\n    result = []\n    for command, i1, i2, j1, j2 in commands:\n        if command == 'equal':\n            result.extend(expand_tokens(html2_tokens[j1:j2], equal=True))\n            continue\n        if command == 'insert' or command == 'replace':\n            ins_tokens = expand_tokens(html2_tokens[j1:j2])\n            merge_insert(ins_tokens, result)\n        if command == 'delete' or command == 'replace':\n            del_tokens = expand_tokens(html1_tokens[i1:i2])\n            merge_delete(del_tokens, result)\n    # If deletes were inserted directly as <del> then we'd have an\n    # invalid document at this point.  Instead we put in special\n    # markers, and when the complete diffed document has been created\n    # we try to move the deletes around and resolve any problems.\n    result = cleanup_delete(result)\n\n    return result", "response": "Does a diff on the given HTML tokens returning a list of text\n    chunks."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngives a list of tokens return a generator of the chunks of the text for the data in the tokens.", "response": "def expand_tokens(tokens, equal=False):\n    \"\"\"Given a list of tokens, return a generator of the chunks of\n    text for the data in the tokens.\n    \"\"\"\n    for token in tokens:\n        for pre in token.pre_tags:\n            yield pre\n        if not equal or not token.hide_when_equal:\n            if token.trailing_whitespace:\n                yield token.html() + token.trailing_whitespace\n            else:\n                yield token.html()\n        for post in token.post_tags:\n            yield post"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmerging the text chunks in ins_chunks into the document doc.", "response": "def merge_insert(ins_chunks, doc):\n    \"\"\" doc is the already-handled document (as a list of text chunks);\n    here we add <ins>ins_chunks</ins> to the end of that.  \"\"\"\n    # Though we don't throw away unbalanced_start or unbalanced_end\n    # (we assume there is accompanying markup later or earlier in the\n    # document), we only put <ins> around the balanced portion.\n    unbalanced_start, balanced, unbalanced_end = split_unbalanced(ins_chunks)\n    doc.extend(unbalanced_start)\n    if doc and not doc[-1].endswith(' '):\n        # Fix up the case where the word before the insert didn't end with \n        # a space\n        doc[-1] += ' '\n    doc.append('<ins>')\n    if balanced and balanced[-1].endswith(' '):\n        # We move space outside of </ins>\n        balanced[-1] = balanced[-1][:-1]\n    doc.extend(balanced)\n    doc.append('</ins> ')\n    doc.extend(unbalanced_end)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding the text chunks in del_chunks to the document doc.", "response": "def merge_delete(del_chunks, doc):\n    \"\"\" Adds the text chunks in del_chunks to the document doc (another\n    list of text chunks) with marker to show it is a delete.\n    cleanup_delete later resolves these markers into <del> tags.\"\"\"\n    doc.append(DEL_START)\n    doc.extend(del_chunks)\n    doc.append(DEL_END)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cleanup_delete(chunks):\n    while 1:\n        # Find a pending DEL_START/DEL_END, splitting the document\n        # into stuff-preceding-DEL_START, stuff-inside, and\n        # stuff-following-DEL_END\n        try:\n            pre_delete, delete, post_delete = split_delete(chunks)\n        except NoDeletes:\n            # Nothing found, we've cleaned up the entire doc\n            break\n        # The stuff-inside-DEL_START/END may not be well balanced\n        # markup.  First we figure out what unbalanced portions there are:\n        unbalanced_start, balanced, unbalanced_end = split_unbalanced(delete)\n        # Then we move the span forward and/or backward based on these\n        # unbalanced portions:\n        locate_unbalanced_start(unbalanced_start, pre_delete, post_delete)\n        locate_unbalanced_end(unbalanced_end, pre_delete, post_delete)\n        doc = pre_delete\n        if doc and not doc[-1].endswith(' '):\n            # Fix up case where the word before us didn't have a trailing space\n            doc[-1] += ' '\n        doc.append('<del>')\n        if balanced and balanced[-1].endswith(' '):\n            # We move space outside of </del>\n            balanced[-1] = balanced[-1][:-1]\n        doc.extend(balanced)\n        doc.append('</del> ')\n        doc.extend(post_delete)\n        chunks = doc\n    return chunks", "response": "Cleans up any pending DELETE markers in the document and returns a list of the deleted tags."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsplits the unbalanced tags into two lists.", "response": "def split_unbalanced(chunks):\n    \"\"\"Return (unbalanced_start, balanced, unbalanced_end), where each is\n    a list of text and tag chunks.\n\n    unbalanced_start is a list of all the tags that are opened, but\n    not closed in this span.  Similarly, unbalanced_end is a list of\n    tags that are closed but were not opened.  Extracting these might\n    mean some reordering of the chunks.\"\"\"\n    start = []\n    end = []\n    tag_stack = []\n    balanced = []\n    for chunk in chunks:\n        if not chunk.startswith('<'):\n            balanced.append(chunk)\n            continue\n        endtag = chunk[1] == '/'\n        name = chunk.split()[0].strip('<>/')\n        if name in empty_tags:\n            balanced.append(chunk)\n            continue\n        if endtag:\n            if tag_stack and tag_stack[-1][0] == name:\n                balanced.append(chunk)\n                name, pos, tag = tag_stack.pop()\n                balanced[pos] = tag\n            elif tag_stack:\n                start.extend([tag for name, pos, tag in tag_stack])\n                tag_stack = []\n                end.append(chunk)\n            else:\n                end.append(chunk)\n        else:\n            tag_stack.append((name, len(balanced), chunk))\n            balanced.append(None)\n    start.extend(\n        [chunk for name, pos, chunk in tag_stack])\n    balanced = [chunk for chunk in balanced if chunk is not None]\n    return start, balanced, end"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsplits a list of delete strings into two lists.", "response": "def split_delete(chunks):\n    \"\"\" Returns (stuff_before_DEL_START, stuff_inside_DEL_START_END,\n    stuff_after_DEL_END).  Returns the first case found (there may be\n    more DEL_STARTs in stuff_after_DEL_END).  Raises NoDeletes if\n    there's no DEL_START found. \"\"\"\n    try:\n        pos = chunks.index(DEL_START)\n    except ValueError:\n        raise NoDeletes\n    pos2 = chunks.index(DEL_END)\n    return chunks[:pos], chunks[pos+1:pos2], chunks[pos2+1:]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nliking locate_unbalanced_start except handling end tags and handling delete tags and insert them into the document.", "response": "def locate_unbalanced_end(unbalanced_end, pre_delete, post_delete):\n    \"\"\" like locate_unbalanced_start, except handling end tags and\n    possibly moving the point earlier in the document.  \"\"\"\n    while 1:\n        if not unbalanced_end:\n            # Success\n            break\n        finding = unbalanced_end[-1]\n        finding_name = finding.split()[0].strip('<>/')\n        if not pre_delete:\n            break\n        next = pre_delete[-1]\n        if next is DEL_END or not next.startswith('</'):\n            # A word or a start tag\n            break\n        name = next.split()[0].strip('<>/')\n        if name == 'ins' or name == 'del':\n            # Can't move into an insert or delete\n            break\n        if name == finding_name:\n            unbalanced_end.pop()\n            post_delete.insert(0, pre_delete.pop())\n        else:\n            # Found a tag that doesn't match\n            break"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing the given HTML and returns a list of token objects.", "response": "def tokenize(html, include_hrefs=True):\n    \"\"\"\n    Parse the given HTML and returns token objects (words with attached tags).\n\n    This parses only the content of a page; anything in the head is\n    ignored, and the <head> and <body> elements are themselves\n    optional.  The content is then parsed by lxml, which ensures the\n    validity of the resulting parsed document (though lxml may make\n    incorrect guesses when the markup is particular bad).\n\n    <ins> and <del> tags are also eliminated from the document, as\n    that gets confusing.\n\n    If include_hrefs is true, then the href attribute of <a> tags is\n    included as a special kind of diffable token.\"\"\"\n    if etree.iselement(html):\n        body_el = html\n    else:\n        body_el = parse_html(html, cleanup=True)\n    # Then we split the document into text chunks for each tag, word, and end tag:\n    chunks = flatten_el(body_el, skip_tag=True, include_hrefs=include_hrefs)\n    # Finally re-joining them into token objects:\n    return fixup_chunks(chunks)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses an HTML fragment returning an lxml element.", "response": "def parse_html(html, cleanup=True):\n    \"\"\"\n    Parses an HTML fragment, returning an lxml element.  Note that the HTML will be\n    wrapped in a <div> tag that was not in the original document.\n\n    If cleanup is true, make sure there's no <head> or <body>, and get\n    rid of any <ins> and <del> tags.\n    \"\"\"\n    if cleanup:\n        # This removes any extra markup or structure like <head>:\n        html = cleanup_html(html)\n    return fragment_fromstring(html, create_parent=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef split_trailing_whitespace(word):\n    stripped_length = len(word.rstrip())\n    return word[0:stripped_length], word[stripped_length:]", "response": "This function splits a word into a list of trailing whitespace and the rest of the word."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntakes an lxml element el and generates all the text chunks for that tag is not in empty_tags.", "response": "def flatten_el(el, include_hrefs, skip_tag=False):\n    \"\"\" Takes an lxml element el, and generates all the text chunks for\n    that tag.  Each start tag is a chunk, each word is a chunk, and each\n    end tag is a chunk.\n\n    If skip_tag is true, then the outermost container tag is\n    not returned (just its contents).\"\"\"\n    if not skip_tag:\n        if el.tag == 'img':\n            yield ('img', el.get('src'), start_tag(el))\n        else:\n            yield start_tag(el)\n    if el.tag in empty_tags and not el.text and not len(el) and not el.tail:\n        return\n    start_words = split_words(el.text)\n    for word in start_words:\n        yield html_escape(word)\n    for child in el:\n        for item in flatten_el(child, include_hrefs=include_hrefs):\n            yield item\n    if el.tag == 'a' and el.get('href') and include_hrefs:\n        yield ('href', el.get('href'))\n    if not skip_tag:\n        yield end_tag(el)\n        end_words = split_words(el.tail)\n        for word in end_words:\n            yield html_escape(word)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef split_words(text):\n    if not text or not text.strip():\n        return []\n\n    words = split_words_re.findall(text)\n    return words", "response": "Splits some text into words. Includes trailing whitespace\n    on each word when appropriate."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the text representation of the start tag for a tag.", "response": "def start_tag(el):\n    \"\"\"\n    The text representation of the start tag for a tag.\n    \"\"\"\n    return '<%s%s>' % (\n        el.tag, ''.join([' %s=\"%s\"' % (name, html_escape(value, True))\n                         for name, value in el.attrib.items()]))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef end_tag(el):\n    if el.tail and start_whitespace_re.search(el.tail):\n        extra = ' '\n    else:\n        extra = ''\n    return '</%s>%s' % (el.tag, extra)", "response": "Returns the text representation of an end tag for a tag."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngives an html string move any ins or del tags inside of any block - level elements e. g. transform <ins > word to <p > word to <p > word to <p > word to <p > word to <p > word to <p > word to <p > word to <p > word to word to word to word to", "response": "def fixup_ins_del_tags(html):\n    \"\"\" Given an html string, move any <ins> or <del> tags inside of any\n    block-level elements, e.g. transform <ins><p>word</p></ins> to\n    <p><ins>word</ins></p> \"\"\"\n    doc = parse_html(html, cleanup=False)\n    _fixup_ins_del_tags(doc)\n    html = serialize_html_fragment(doc, skip_outer=True)\n    return html"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nserializing a single lxml element as HTML.", "response": "def serialize_html_fragment(el, skip_outer=False):\n    \"\"\" Serialize a single lxml element as HTML.  The serialized form\n    includes the elements tail.  \n\n    If skip_outer is true, then don't serialize the outermost tag\n    \"\"\"\n    assert not isinstance(el, basestring), (\n        \"You should pass in an element, not a string like %r\" % el)\n    html = etree.tostring(el, method=\"html\", encoding=_unicode)\n    if skip_outer:\n        # Get rid of the extra starting tag:\n        html = html[html.find('>')+1:]\n        # Get rid of the extra end tag:\n        html = html[:html.rfind('<')]\n        return html.strip()\n    else:\n        return html"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _fixup_ins_del_tags(doc):\n    for tag in ['ins', 'del']:\n        for el in doc.xpath('descendant-or-self::%s' % tag):\n            if not _contains_block_level_tag(el):\n                continue\n            _move_el_inside_block(el, tag=tag)\n            el.drop_tag()", "response": "fixup_ins_del_tags that works on an lxml document in - place\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _contains_block_level_tag(el):\n    if el.tag in block_level_tags or el.tag in block_level_container_tags:\n        return True\n    for child in el:\n        if _contains_block_level_tag(child):\n            return True\n    return False", "response": "True if the element contains any block - level elements like p td etc."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _move_el_inside_block(el, tag):\n    for child in el:\n        if _contains_block_level_tag(child):\n            break\n    else:\n        import sys\n        # No block-level tags in any child\n        children_tag = etree.Element(tag)\n        children_tag.text = el.text\n        el.text = None\n        children_tag.extend(list(el))\n        el[:] = [children_tag]\n        return\n    for child in list(el):\n        if _contains_block_level_tag(child):\n            _move_el_inside_block(child, tag)\n            if child.tail:\n                tail_tag = etree.Element(tag)\n                tail_tag.text = child.tail\n                child.tail = None\n                el.insert(el.index(child)+1, tail_tag)\n        else:\n            child_tag = etree.Element(tag)\n            el.replace(child, child_tag)\n            child_tag.append(child)\n    if el.text:\n        text_tag = etree.Element(tag)\n        text_tag.text = el.text\n        el.text = None\n        el.insert(0, text_tag)", "response": "helper for _fixup_ins_del_tags ; actually takes the ins etc tags\n    and moves them inside any block - level tags."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nremoves an element and merges its contents into its place.", "response": "def _merge_element_contents(el):\n    \"\"\"\n    Removes an element, but merges its contents into its place, e.g.,\n    given <p>Hi <i>there!</i></p>, if you remove the <i> element you get\n    <p>Hi there!</p>\n    \"\"\"\n    parent = el.getparent()\n    text = el.text or ''\n    if el.tail:\n        if not len(el):\n            text += el.tail\n        else:\n            if el[-1].tail:\n                el[-1].tail += el.tail\n            else:\n                el[-1].tail = el.tail\n    index = parent.index(el)\n    if text:\n        if index == 0:\n            previous = None\n        else:\n            previous = parent[index-1]\n        if previous is None:\n            if parent.text:\n                parent.text += text\n            else:\n                parent.text = text\n        else:\n            if previous.tail:\n                previous.tail += text\n            else:\n                previous.tail = text\n    parent[index:index+1] = el.getchildren()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\niterating over the code object.", "response": "def _iter_code(code):\n\n    \"\"\"Yield '(op,arg)' pair for each operation in code object 'code'\"\"\"\n\n    from array import array\n    from dis import HAVE_ARGUMENT, EXTENDED_ARG\n\n    bytes = array('b',code.co_code)\n    eof = len(code.co_code)\n\n    ptr = 0\n    extended_arg = 0\n\n    while ptr<eof:\n\n        op = bytes[ptr]\n\n        if op>=HAVE_ARGUMENT:\n\n            arg = bytes[ptr+1] + bytes[ptr+2]*256 + extended_arg\n            ptr += 3\n\n            if op==EXTENDED_ARG:\n                extended_arg = arg * compat.long_type(65536)\n                continue\n\n        else:\n            arg = None\n            ptr += 1\n\n        yield op,arg"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef extract_constant(code, symbol, default=-1):\n\n    if symbol not in code.co_names:\n        # name's not there, can't possibly be an assigment\n        return None\n\n    name_idx = list(code.co_names).index(symbol)\n\n    STORE_NAME = 90\n    STORE_GLOBAL = 97\n    LOAD_CONST = 100\n\n    const = default\n\n    for op, arg in _iter_code(code):\n\n        if op==LOAD_CONST:\n            const = code.co_consts[arg]\n        elif arg==name_idx and (op==STORE_NAME or op==STORE_GLOBAL):\n            return const\n        else:\n            const = default", "response": "Extract the constant value of symbol from code."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef autolink(el, link_regexes=_link_regexes,\n             avoid_elements=_avoid_elements,\n             avoid_hosts=_avoid_hosts,\n             avoid_classes=_avoid_classes):\n    \"\"\"\n    Turn any URLs into links.\n\n    It will search for links identified by the given regular\n    expressions (by default mailto and http(s) links).\n\n    It won't link text in an element in avoid_elements, or an element\n    with a class in avoid_classes.  It won't link to anything with a\n    host that matches one of the regular expressions in avoid_hosts\n    (default localhost and 127.0.0.1).\n\n    If you pass in an element, the element's tail will not be\n    substituted, only the contents of the element.\n    \"\"\"\n    if el.tag in avoid_elements:\n        return\n    class_name = el.get('class')\n    if class_name:\n        class_name = class_name.split()\n        for match_class in avoid_classes:\n            if match_class in class_name:\n                return\n    for child in list(el):\n        autolink(child, link_regexes=link_regexes,\n                 avoid_elements=avoid_elements,\n                 avoid_hosts=avoid_hosts,\n                 avoid_classes=avoid_classes)\n        if child.tail:\n            text, tail_children = _link_text(\n                child.tail, link_regexes, avoid_hosts, factory=el.makeelement)\n            if tail_children:\n                child.tail = text\n                index = el.index(child)\n                el[index+1:index+1] = tail_children\n    if el.text:\n        text, pre_children = _link_text(\n            el.text, link_regexes, avoid_hosts, factory=el.makeelement)\n        if pre_children:\n            el.text = text\n            el[:0] = pre_children", "response": "Autolinks an element into a tree of links."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbreaking the text of the element el into words.", "response": "def word_break(el, max_width=40,\n               avoid_elements=_avoid_word_break_elements,\n               avoid_classes=_avoid_word_break_classes,\n               break_character=unichr(0x200b)):\n    \"\"\"\n    Breaks any long words found in the body of the text (not attributes).\n\n    Doesn't effect any of the tags in avoid_elements, by default\n    ``<textarea>`` and ``<pre>``\n\n    Breaks words by inserting &#8203;, which is a unicode character\n    for Zero Width Space character.  This generally takes up no space\n    in rendering, but does copy as a space, and in monospace contexts\n    usually takes up space.\n\n    See http://www.cs.tut.fi/~jkorpela/html/nobr.html for a discussion\n    \"\"\"\n    # Character suggestion of &#8203 comes from:\n    #   http://www.cs.tut.fi/~jkorpela/html/nobr.html\n    if el.tag in _avoid_word_break_elements:\n        return\n    class_name = el.get('class')\n    if class_name:\n        dont_break = False\n        class_name = class_name.split()\n        for avoid in avoid_classes:\n            if avoid in class_name:\n                dont_break = True\n                break\n        if dont_break:\n            return\n    if el.text:\n        el.text = _break_text(el.text, max_width, break_character)\n    for child in el:\n        word_break(child, max_width=max_width,\n                   avoid_elements=avoid_elements,\n                   avoid_classes=avoid_classes,\n                   break_character=break_character)\n        if child.tail:\n            child.tail = _break_text(child.tail, max_width, break_character)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nkilling any conditional comments in the given document.", "response": "def kill_conditional_comments(self, doc):\n        \"\"\"\n        IE conditional comments basically embed HTML that the parser\n        doesn't normally see.  We can't allow anything like that, so\n        we'll kill any comments that could be conditional.\n        \"\"\"\n        bad = []\n        self._kill_elements(\n            doc, lambda el: _conditional_comment_re.search(el.text),\n            etree.Comment)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking if the style contains a sneaky javascript.", "response": "def _has_sneaky_javascript(self, style):\n        \"\"\"\n        Depending on the browser, stuff like ``e x p r e s s i o n(...)``\n        can get interpreted, or ``expre/* stuff */ssion(...)``.  This\n        checks for attempt to do stuff like this.\n\n        Typically the response will be to kill the entire style; if you\n        have just a bit of Javascript in the style another rule will catch\n        that and remove only the Javascript from the style; this catches\n        more sneaky attempts.\n        \"\"\"\n        style = self._substitute_comments('', style)\n        style = style.replace('\\\\', '')\n        style = _substitute_whitespace('', style)\n        style = style.lower()\n        if 'javascript:' in style:\n            return True\n        if 'expression(' in style:\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse a whole document into a string.", "response": "def document_fromstring(html, guess_charset=True, parser=None):\n    \"\"\"Parse a whole document into a string.\"\"\"\n    if not isinstance(html, _strings):\n        raise TypeError('string required')\n\n    if parser is None:\n        parser = html_parser\n\n    return parser.parse(html, useChardet=guess_charset).getroot()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses several HTML elements returning a list of elements.", "response": "def fragments_fromstring(html, no_leading_text=False,\n                         guess_charset=False, parser=None):\n    \"\"\"Parses several HTML elements, returning a list of elements.\n\n    The first item in the list may be a string.  If no_leading_text is true,\n    then it will be an error if there is leading text, and it will always be\n    a list of only elements.\n\n    If `guess_charset` is `True` and the text was not unicode but a\n    bytestring, the `chardet` library will perform charset guessing on the\n    string.\n    \"\"\"\n    if not isinstance(html, _strings):\n        raise TypeError('string required')\n\n    if parser is None:\n        parser = html_parser\n\n    children = parser.parseFragment(html, 'div', useChardet=guess_charset)\n    if children and isinstance(children[0], _strings):\n        if no_leading_text:\n            if children[0].strip():\n                raise etree.ParserError('There is leading text: %r' %\n                                        children[0])\n            del children[0]\n    return children"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing a single HTML element and returns a node containing the fragment.", "response": "def fragment_fromstring(html, create_parent=False,\n                        guess_charset=False, parser=None):\n    \"\"\"Parses a single HTML element; it is an error if there is more than\n    one element, or if anything but whitespace precedes or follows the\n    element.\n\n    If create_parent is true (or is a tag name) then a parent node\n    will be created to encapsulate the HTML in a single element.  In\n    this case, leading or trailing text is allowed.\n    \"\"\"\n    if not isinstance(html, _strings):\n        raise TypeError('string required')\n\n    accept_leading_text = bool(create_parent)\n\n    elements = fragments_fromstring(\n        html, guess_charset=guess_charset, parser=parser,\n        no_leading_text=not accept_leading_text)\n\n    if create_parent:\n        if not isinstance(create_parent, _strings):\n            create_parent = 'div'\n        new_root = Element(create_parent)\n        if elements:\n            if isinstance(elements[0], _strings):\n                new_root.text = elements[0]\n                del elements[0]\n            new_root.extend(elements)\n        return new_root\n\n    if not elements:\n        raise etree.ParserError('No elements found')\n    if len(elements) > 1:\n        raise etree.ParserError('Multiple elements found')\n    result = elements[0]\n    if result.tail and result.tail.strip():\n        raise etree.ParserError('Element followed by text: %r' % result.tail)\n    result.tail = None\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses the html string and return a single element or document.", "response": "def fromstring(html, guess_charset=True, parser=None):\n    \"\"\"Parse the html, returning a single element/document.\n\n    This tries to minimally parse the chunk of text, without knowing if it\n    is a fragment or a document.\n\n    base_url will set the document's base_url attribute (and the tree's docinfo.URL)\n    \"\"\"\n    if not isinstance(html, _strings):\n        raise TypeError('string required')\n    doc = document_fromstring(html, parser=parser,\n                              guess_charset=guess_charset)\n\n    # document starts with doctype or <html>, full document!\n    start = html[:50].lstrip().lower()\n    if start.startswith('<html') or start.startswith('<!doctype'):\n        return doc\n\n    head = _find_tag(doc, 'head')\n\n    # if the head is not empty we have a full document\n    if len(head):\n        return doc\n\n    body = _find_tag(doc, 'body')\n\n    # The body has just one element, so it was probably a single\n    # element passed in\n    if (len(body) == 1 and (not body.text or not body.text.strip())\n        and (not body[-1].tail or not body[-1].tail.strip())):\n        return body[0]\n\n    # Now we have a body which represents a bunch of tags which have the\n    # content that was passed in.  We will create a fake container, which\n    # is the body tag, except <body> implies too much structure.\n    if _contains_block_level_tag(body):\n        body.tag = 'div'\n    else:\n        body.tag = 'span'\n    return body"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse(filename_url_or_file, guess_charset=True, parser=None):\n    if parser is None:\n        parser = html_parser\n    if not isinstance(filename_url_or_file, _strings):\n        fp = filename_url_or_file\n    elif _looks_like_url(filename_url_or_file):\n        fp = urlopen(filename_url_or_file)\n    else:\n        fp = open(filename_url_or_file, 'rb')\n    return parser.parse(fp, useChardet=guess_charset)", "response": "Parse a filename URL or file - like object into an HTML document\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef api_accepts(fields):\n    def decorator(func):\n        @wraps(func)\n        def wrapped_func(request, *args, **kwargs):\n            if request.method not in ['GET', 'POST']:\n                return func(request, *args, **kwargs)\n\n            # The fields dict passed into the type() function is modified, so\n            # send in a copy instead.\n            form_class = type('ApiForm', (forms.Form,), fields.copy())\n            form = form_class(getattr(request, request.method))\n\n            if not form.is_valid():\n                if settings.DEBUG:\n                    return JsonResponseBadRequest(\n                        'failed to validate: %s' % dict(form.errors)\n                    )\n                else:\n                    logger.warn(\n                        'input to \\'%s\\' failed to validate: %s',\n                        request.path,\n                        dict(form.errors)\n                    )\n                    return func(request, *args, **kwargs)\n\n            # Clean any models.Model fields, by looking up object based on\n            # primary key in request.\n            for (field_name, field_instance) in fields.items():\n                if isinstance(field_instance, models.Model):\n                    field_type = type(field_instance)\n                    # TODO: irregular, should we remove?\n                    field_id = '%s-id' % field_name\n                    if field_id not in request.REQUEST:\n                        return JsonResponseBadRequest(\n                            'field %s not present' % field_name\n                        )\n                    field_pk = int(request.REQUEST[field_id])\n                    try:\n                        field_value = field_type.objects.get(pk=field_pk)\n                    except field_type.DoesNotExist:\n                        return JsonResponseNotFound(\n                            '%s with pk=%d does not exist' % (\n                                field_type, field_pk\n                            )\n                        )\n                    form.cleaned_data[field_name] = field_value\n\n            validated_request = ValidatedRequest(request, form)\n            return func(validated_request, *args, **kwargs)\n        return wrapped_func\n    return decorator", "response": "Decorator that returns a view function that accepts the given fields."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef api_returns(return_values):\n    def decorator(func):\n        @wraps(func)\n        def wrapped_func(request, *args, **kwargs):\n            return_value = func(request, *args, **kwargs)\n\n            if not isinstance(return_value, JsonResponse):\n                if settings.DEBUG:\n                    return JsonResponseBadRequest('API did not return JSON')\n                else:\n                    logger.warn('API did not return JSON')\n\n            accepted_return_codes = return_values.keys()\n            # Never block 500s - these should be handled by other\n            # reporting mechanisms\n            accepted_return_codes.append(500)\n\n            if return_value.status_code not in accepted_return_codes:\n                if settings.DEBUG:\n                    return JsonResponseBadRequest(\n                        'API returned %d instead of acceptable values %s' %\n                        (return_value.status_code, accepted_return_codes)\n                    )\n                else:\n                    logger.warn(\n                        'API returned %d instead of acceptable values %s',\n                        return_value.status_code,\n                        accepted_return_codes,\n                    )\n\n            return return_value\n        return wrapped_func\n    return decorator", "response": "Decorator for returning a single API resource."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef api(accept_return_dict):\n    def decorator(func):\n        @wraps(func)\n        def wrapped_func(request, *args, **kwargs):\n            @api_accepts(accept_return_dict['accepts'])\n            @api_returns(accept_return_dict['returns'])\n            def apid_fnc(request, *args, **kwargs):\n                return func(request, *args, **kwargs)\n\n            return apid_fnc(request, *args, **kwargs)\n        return wrapped_func\n    return decorator", "response": "Decorator that returns a function that returns a response in sequence."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a decorator that ensures that the request passed to the view function/method has a valid JSON request body with the given required fields. The dict parsed from the JSON is then passed as the second argument to the decorated function/method. For example: @json_request({'name', 'date'}) def view_func(request, request_dict): ...", "response": "def validate_json_request(required_fields):\n    \"\"\"\n    Return a decorator that ensures that the request passed to the view\n    function/method has a valid JSON request body with the given required\n    fields.  The dict parsed from the JSON is then passed as the second\n    argument to the decorated function/method.  For example:\n\n    @json_request({'name', 'date'})\n    def view_func(request, request_dict):\n        ...\n    \"\"\"\n    def decorator(func):\n        @wraps(func)\n        def wrapped_func(request, *args, **kwargs):\n            try:\n                request_dict = json.loads(request.raw_post_data)\n            except ValueError as e:\n                return JsonResponseBadRequest('invalid POST JSON: %s' % e)\n\n            for k in required_fields:\n                if k not in request_dict:\n                    return JsonResponseBadRequest(\n                        'POST JSON must contain property \\'%s\\'' % k)\n\n            return func(request, request_dict, *args, **kwargs)\n        return wrapped_func\n    return decorator"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getTreeWalker(treeType, implementation=None, **kwargs):\n\n    treeType = treeType.lower()\n    if treeType not in treeWalkerCache:\n        if treeType in (\"dom\", \"pulldom\"):\n            name = \"%s.%s\" % (__name__, treeType)\n            __import__(name)\n            mod = sys.modules[name]\n            treeWalkerCache[treeType] = mod.TreeWalker\n        elif treeType == \"genshi\":\n            from . import genshistream\n            treeWalkerCache[treeType] = genshistream.TreeWalker\n        elif treeType == \"lxml\":\n            from . import lxmletree\n            treeWalkerCache[treeType] = lxmletree.TreeWalker\n        elif treeType == \"etree\":\n            from . import etree\n            if implementation is None:\n                implementation = default_etree\n            # XXX: NEVER cache here, caching is done in the etree submodule\n            return etree.getETreeModule(implementation, **kwargs).TreeWalker\n    return treeWalkerCache.get(treeType)", "response": "Get a TreeWalker class for various types of tree with built - in support."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_include():\n    import os\n    lxml_path = __path__[0]\n    include_path = os.path.join(lxml_path, 'includes')\n    includes = [include_path, lxml_path]\n\n    for name in os.listdir(include_path):\n        path = os.path.join(include_path, name)\n        if os.path.isdir(path):\n            includes.append(path)\n\n    return includes", "response": "Returns a list of include paths needed to compile C code against lxml."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nexporting the svn repository at the url to the destination location", "response": "def export(self, location):\n        \"\"\"Export the svn repository at the url to the destination location\"\"\"\n        url, rev = self.get_url_rev()\n        rev_options = get_rev_options(url, rev)\n        logger.info('Exporting svn repository %s to %s', url, location)\n        with indent_log():\n            if os.path.exists(location):\n                # Subversion doesn't like to check out over an existing\n                # directory --force fixes this, but was only added in svn 1.5\n                rmtree(location)\n            self.run_command(\n                ['export'] + rev_options + [url, location],\n                show_stdout=False)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_revision(self, location):\n        # Note: taken from setuptools.command.egg_info\n        revision = 0\n\n        for base, dirs, files in os.walk(location):\n            if self.dirname not in dirs:\n                dirs[:] = []\n                continue    # no sense walking uncontrolled subdirs\n            dirs.remove(self.dirname)\n            entries_fn = os.path.join(base, self.dirname, 'entries')\n            if not os.path.exists(entries_fn):\n                # FIXME: should we warn?\n                continue\n\n            dirurl, localrev = self._get_svn_url_rev(base)\n\n            if base == location:\n                base_url = dirurl + '/'   # save the root url\n            elif not dirurl or not dirurl.startswith(base_url):\n                dirs[:] = []\n                continue    # not part of the same svn tree, skip it\n            revision = max(revision, localrev)\n        return revision", "response": "Return the maximum revision for all files under a given location."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef name(self):\n        if self.import_name == '__main__':\n            fn = getattr(sys.modules['__main__'], '__file__', None)\n            if fn is None:\n                return '__main__'\n            return os.path.splitext(os.path.basename(fn))[0]\n        return self.import_name", "response": "The name of the application."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef propagate_exceptions(self):\n        rv = self.config['PROPAGATE_EXCEPTIONS']\n        if rv is not None:\n            return rv\n        return self.testing or self.debug", "response": "Returns the value of the PROPAGATE_EXCEPTIONS configuration value in case it s set otherwise a sensible default is returned."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef logger(self):\n        if self._logger and self._logger.name == self.logger_name:\n            return self._logger\n        with _logger_lock:\n            if self._logger and self._logger.name == self.logger_name:\n                return self._logger\n            from flask.logging import create_logger\n            self._logger = rv = create_logger(self)\n            return rv", "response": "A logger object for this application."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef make_config(self, instance_relative=False):\n        root_path = self.root_path\n        if instance_relative:\n            root_path = self.instance_path\n        return Config(root_path, self.default_config)", "response": "Used to create the config attribute by the Flask constructor."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntry to find the instance path if it was not provided.", "response": "def auto_find_instance_path(self):\n        \"\"\"Tries to locate the instance path if it was not provided to the\n        constructor of the application class.  It will basically calculate\n        the path to a folder named ``instance`` next to your main file or\n        the package.\n\n        .. versionadded:: 0.8\n        \"\"\"\n        prefix, package_path = find_package(self.import_name)\n        if prefix is None:\n            return os.path.join(package_path, 'instance')\n        return os.path.join(prefix, 'var', self.name + '-instance')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef open_instance_resource(self, resource, mode='rb'):\n        return open(os.path.join(self.instance_path, resource), mode)", "response": "Opens a resource from the application s instance folder."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate the Jinja2 environment based on the current configuration and the current context processor.", "response": "def create_jinja_environment(self):\n        \"\"\"Creates the Jinja2 environment based on :attr:`jinja_options`\n        and :meth:`select_jinja_autoescape`.  Since 0.7 this also adds\n        the Jinja2 globals and filters after initialization.  Override\n        this function to customize the behavior.\n\n        .. versionadded:: 0.5\n        \"\"\"\n        options = dict(self.jinja_options)\n        if 'autoescape' not in options:\n            options['autoescape'] = self.select_jinja_autoescape\n        rv = Environment(self, **options)\n        rv.globals.update(\n            url_for=url_for,\n            get_flashed_messages=get_flashed_messages,\n            config=self.config,\n            # request, session and g are normally added with the\n            # context processor for efficiency reasons but for imported\n            # templates we also want the proxies in there.\n            request=request,\n            session=session,\n            g=g\n        )\n        rv.filters['tojson'] = json.tojson_filter\n        return rv"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update_template_context(self, context):\n        funcs = self.template_context_processors[None]\n        reqctx = _request_ctx_stack.top\n        if reqctx is not None:\n            bp = reqctx.request.blueprint\n            if bp is not None and bp in self.template_context_processors:\n                funcs = chain(funcs, self.template_context_processors[bp])\n        orig_ctx = context.copy()\n        for func in funcs:\n            context.update(func())\n        # make sure the original values win.  This makes it possible to\n        # easier add new variables in context processors without breaking\n        # existing views.\n        context.update(orig_ctx)", "response": "Update the template context with some commonly used variables."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef run(self, host=None, port=None, debug=None, **options):\n        from werkzeug.serving import run_simple\n        if host is None:\n            host = '127.0.0.1'\n        if port is None:\n            server_name = self.config['SERVER_NAME']\n            if server_name and ':' in server_name:\n                port = int(server_name.rsplit(':', 1)[1])\n            else:\n                port = 5000\n        if debug is not None:\n            self.debug = bool(debug)\n        options.setdefault('use_reloader', self.debug)\n        options.setdefault('use_debugger', self.debug)\n        try:\n            run_simple(host, port, self, **options)\n        finally:\n            # reset the first request information if the development server\n            # resetted normally.  This makes it possible to restart the server\n            # without reloader and that stuff from an interactive shell.\n            self._got_first_request = False", "response": "Runs the application on a local development server."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef save_session(self, session, response):\n        return self.session_interface.save_session(self, session, response)", "response": "Saves the session if it needs updates."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nregistering a module with this application.", "response": "def register_module(self, module, **options):\n        \"\"\"Registers a module with this application.  The keyword argument\n        of this function are the same as the ones for the constructor of the\n        :class:`Module` class and will override the values of the module if\n        provided.\n\n        .. versionchanged:: 0.7\n           The module system was deprecated in favor for the blueprint\n           system.\n        \"\"\"\n        assert blueprint_is_module(module), 'register_module requires ' \\\n            'actual module objects.  Please upgrade to blueprints though.'\n        if not self.enable_modules:\n            raise RuntimeError('Module support was disabled but code '\n                'attempted to register a module named %r' % module)\n        else:\n            from warnings import warn\n            warn(DeprecationWarning('Modules are deprecated.  Upgrade to '\n                'using blueprints.  Have a look into the documentation for '\n                'more information.  If this module was registered by a '\n                'Flask-Extension upgrade the extension or contact the author '\n                'of that extension instead.  (Registered %r)' % module),\n                stacklevel=2)\n\n        self.register_blueprint(module, **options)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_url_rule(self, rule, endpoint=None, view_func=None, **options):\n        if endpoint is None:\n            endpoint = _endpoint_from_view_func(view_func)\n        options['endpoint'] = endpoint\n        methods = options.pop('methods', None)\n\n        # if the methods are not given and the view_func object knows its\n        # methods we can use that instead.  If neither exists, we go with\n        # a tuple of only `GET` as default.\n        if methods is None:\n            methods = getattr(view_func, 'methods', None) or ('GET',)\n        methods = set(methods)\n\n        # Methods that should always be added\n        required_methods = set(getattr(view_func, 'required_methods', ()))\n\n        # starting with Flask 0.8 the view_func object can disable and\n        # force-enable the automatic options handling.\n        provide_automatic_options = getattr(view_func,\n            'provide_automatic_options', None)\n\n        if provide_automatic_options is None:\n            if 'OPTIONS' not in methods:\n                provide_automatic_options = True\n                required_methods.add('OPTIONS')\n            else:\n                provide_automatic_options = False\n\n        # Add the required methods now.\n        methods |= required_methods\n\n        # due to a werkzeug bug we need to make sure that the defaults are\n        # None if they are an empty dictionary.  This should not be necessary\n        # with Werkzeug 0.7\n        options['defaults'] = options.get('defaults') or None\n\n        rule = self.url_rule_class(rule, methods=methods, **options)\n        rule.provide_automatic_options = provide_automatic_options\n\n        self.url_map.add(rule)\n        if view_func is not None:\n            old_func = self.view_functions.get(endpoint)\n            if old_func is not None and old_func != view_func:\n                raise AssertionError('View function mapping is overwriting an '\n                                     'existing endpoint function: %s' % endpoint)\n            self.view_functions[endpoint] = view_func", "response": "Connects a URL rule to the application."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef endpoint(self, endpoint):\n        def decorator(f):\n            self.view_functions[endpoint] = f\n            return f\n        return decorator", "response": "A decorator to register a function as an endpoint.\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef template_filter(self, name=None):\n        def decorator(f):\n            self.add_template_filter(f, name=name)\n            return f\n        return decorator", "response": "A decorator that is used to register custom template filter."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nregisters a custom template filter. Works exactly like the decorator.", "response": "def add_template_filter(self, f, name=None):\n        \"\"\"Register a custom template filter.  Works exactly like the\n        :meth:`template_filter` decorator.\n\n        :param name: the optional name of the filter, otherwise the\n                     function name will be used.\n        \"\"\"\n        self.jinja_env.filters[name or f.__name__] = f"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nregister a custom template global function. Works exactly like the decorator.", "response": "def add_template_global(self, f, name=None):\n        \"\"\"Register a custom template global function. Works exactly like the\n        :meth:`template_global` decorator.\n\n        .. versionadded:: 0.10\n\n        :param name: the optional name of the global function, otherwise the\n                     function name will be used.\n        \"\"\"\n        self.jinja_env.globals[name or f.__name__] = f"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nhandling an HTTP exception.", "response": "def handle_http_exception(self, e):\n        \"\"\"Handles an HTTP exception.  By default this will invoke the\n        registered error handlers and fall back to returning the\n        exception as response.\n\n        .. versionadded:: 0.3\n        \"\"\"\n        handlers = self.error_handler_spec.get(request.blueprint)\n        # Proxy exceptions don't have error codes.  We want to always return\n        # those unchanged as errors\n        if e.code is None:\n            return e\n        if handlers and e.code in handlers:\n            handler = handlers[e.code]\n        else:\n            handler = self.error_handler_spec[None].get(e.code)\n        if handler is None:\n            return e\n        return handler(e)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if an HTTP exception should be trapped or not.", "response": "def trap_http_exception(self, e):\n        \"\"\"Checks if an HTTP exception should be trapped or not.  By default\n        this will return `False` for all exceptions except for a bad request\n        key error if ``TRAP_BAD_REQUEST_ERRORS`` is set to `True`.  It\n        also returns `True` if ``TRAP_HTTP_EXCEPTIONS`` is set to `True`.\n\n        This is called for all HTTP exceptions raised by a view function.\n        If it returns `True` for any exception the error handler for this\n        exception is not called and it shows up as regular exception in the\n        traceback.  This is helpful for debugging implicitly raised HTTP\n        exceptions.\n\n        .. versionadded:: 0.8\n        \"\"\"\n        if self.config['TRAP_HTTP_EXCEPTIONS']:\n            return True\n        if self.config['TRAP_BAD_REQUEST_ERRORS']:\n            return isinstance(e, BadRequest)\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef handle_user_exception(self, e):\n        exc_type, exc_value, tb = sys.exc_info()\n        assert exc_value is e\n\n        # ensure not to trash sys.exc_info() at that point in case someone\n        # wants the traceback preserved in handle_http_exception.  Of course\n        # we cannot prevent users from trashing it themselves in a custom\n        # trap_http_exception method so that's their fault then.\n        if isinstance(e, HTTPException) and not self.trap_http_exception(e):\n            return self.handle_http_exception(e)\n\n        blueprint_handlers = ()\n        handlers = self.error_handler_spec.get(request.blueprint)\n        if handlers is not None:\n            blueprint_handlers = handlers.get(None, ())\n        app_handlers = self.error_handler_spec[None].get(None, ())\n        for typecheck, handler in chain(blueprint_handlers, app_handlers):\n            if isinstance(e, typecheck):\n                return handler(e)\n\n        reraise(exc_type, exc_value, tb)", "response": "This method handles the exception raised by the user."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef handle_exception(self, e):\n        exc_type, exc_value, tb = sys.exc_info()\n\n        got_request_exception.send(self, exception=e)\n        handler = self.error_handler_spec[None].get(500)\n\n        if self.propagate_exceptions:\n            # if we want to repropagate the exception, we can attempt to\n            # raise it with the whole traceback in case we can do that\n            # (the function was actually called from the except part)\n            # otherwise, we just raise the error again\n            if exc_value is e:\n                reraise(exc_type, exc_value, tb)\n            else:\n                raise e\n\n        self.log_exception((exc_type, exc_value, tb))\n        if handler is None:\n            return InternalServerError()\n        return handler(e)", "response": "Default exception handling that kicks in when an exception occurs that is not caught."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef log_exception(self, exc_info):\n        self.logger.error('Exception on %s [%s]' % (\n            request.path,\n            request.method\n        ), exc_info=exc_info)", "response": "Logs an exception.  This is called by :meth:`handle_exception`\n        if debugging is disabled and right before the handler is called.\n        The default implementation logs the exception as error on the\n        :attr:`logger`.\n\n        .. versionadded:: 0.8"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nraise the routing exception that is not handled by the routing system.", "response": "def raise_routing_exception(self, request):\n        \"\"\"Exceptions that are recording during routing are reraised with\n        this method.  During debug we are not reraising redirect requests\n        for non ``GET``, ``HEAD``, or ``OPTIONS`` requests and we're raising\n        a different error instead to help debug situations.\n\n        :internal:\n        \"\"\"\n        if not self.debug \\\n           or not isinstance(request.routing_exception, RequestRedirect) \\\n           or request.method in ('GET', 'HEAD', 'OPTIONS'):\n            raise request.routing_exception\n\n        from .debughelpers import FormDataRoutingRedirect\n        raise FormDataRoutingRedirect(request)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dispatch_request(self):\n        req = _request_ctx_stack.top.request\n        if req.routing_exception is not None:\n            self.raise_routing_exception(req)\n        rule = req.url_rule\n        # if we provide automatic options for this URL and the\n        # request came with the OPTIONS method, reply automatically\n        if getattr(rule, 'provide_automatic_options', False) \\\n           and req.method == 'OPTIONS':\n            return self.make_default_options_response()\n        # otherwise dispatch to the handler for that endpoint\n        return self.view_functions[rule.endpoint](**req.view_args)", "response": "Does the request dispatching."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndispatch the request and on top of that performs request pre and post processing and returns the response.", "response": "def full_dispatch_request(self):\n        \"\"\"Dispatches the request and on top of that performs request\n        pre and postprocessing as well as HTTP exception catching and\n        error handling.\n\n        .. versionadded:: 0.7\n        \"\"\"\n        self.try_trigger_before_first_request_functions()\n        try:\n            request_started.send(self)\n            rv = self.preprocess_request()\n            if rv is None:\n                rv = self.dispatch_request()\n        except Exception as e:\n            rv = self.handle_user_exception(e)\n        response = self.make_response(rv)\n        response = self.process_response(response)\n        request_finished.send(self, response=response)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalls before each request and will ensure that it triggers the before_first_request_funcs and only exactly once per application instance.", "response": "def try_trigger_before_first_request_functions(self):\n        \"\"\"Called before each request and will ensure that it triggers\n        the :attr:`before_first_request_funcs` and only exactly once per\n        application instance (which means process usually).\n\n        :internal:\n        \"\"\"\n        if self._got_first_request:\n            return\n        with self._before_request_lock:\n            if self._got_first_request:\n                return\n            self._got_first_request = True\n            for func in self.before_first_request_funcs:\n                func()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef make_default_options_response(self):\n        adapter = _request_ctx_stack.top.url_adapter\n        if hasattr(adapter, 'allowed_methods'):\n            methods = adapter.allowed_methods()\n        else:\n            # fallback for Werkzeug < 0.7\n            methods = []\n            try:\n                adapter.match(method='--')\n            except MethodNotAllowed as e:\n                methods = e.valid_methods\n            except HTTPException as e:\n                pass\n        rv = self.response_class()\n        rv.allow.update(methods)\n        return rv", "response": "This method is called to create the default OPTIONS response. It is called through subclassing to change the default OPTIONS response behavior of the HTTP response."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts the return value from a view function to a real response object that is an instance of self. response_class.", "response": "def make_response(self, rv):\n        \"\"\"Converts the return value from a view function to a real\n        response object that is an instance of :attr:`response_class`.\n\n        The following types are allowed for `rv`:\n\n        .. tabularcolumns:: |p{3.5cm}|p{9.5cm}|\n\n        ======================= ===========================================\n        :attr:`response_class`  the object is returned unchanged\n        :class:`str`            a response object is created with the\n                                string as body\n        :class:`unicode`        a response object is created with the\n                                string encoded to utf-8 as body\n        a WSGI function         the function is called as WSGI application\n                                and buffered as response object\n        :class:`tuple`          A tuple in the form ``(response, status,\n                                headers)`` where `response` is any of the\n                                types defined here, `status` is a string\n                                or an integer and `headers` is a list of\n                                a dictionary with header values.\n        ======================= ===========================================\n\n        :param rv: the return value from the view function\n\n        .. versionchanged:: 0.9\n           Previously a tuple was interpreted as the arguments for the\n           response object.\n        \"\"\"\n        status = headers = None\n        if isinstance(rv, tuple):\n            rv, status, headers = rv + (None,) * (3 - len(rv))\n\n        if rv is None:\n            raise ValueError('View function did not return a response')\n\n        if not isinstance(rv, self.response_class):\n            # When we create a response object directly, we let the constructor\n            # set the headers and status.  We do this because there can be\n            # some extra logic involved when creating these objects with\n            # specific values (like default content type selection).\n            if isinstance(rv, (text_type, bytes, bytearray)):\n                rv = self.response_class(rv, headers=headers, status=status)\n                headers = status = None\n            else:\n                rv = self.response_class.force_type(rv, request.environ)\n\n        if status is not None:\n            if isinstance(status, string_types):\n                rv.status = status\n            else:\n                rv.status_code = status\n        if headers:\n            rv.headers.extend(headers)\n\n        return rv"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a URL adapter for the given request.", "response": "def create_url_adapter(self, request):\n        \"\"\"Creates a URL adapter for the given request.  The URL adapter\n        is created at a point where the request context is not yet set up\n        so the request is passed explicitly.\n\n        .. versionadded:: 0.6\n\n        .. versionchanged:: 0.9\n           This can now also be called without a request object when the\n           URL adapter is created for the application context.\n        \"\"\"\n        if request is not None:\n            return self.url_map.bind_to_environ(request.environ,\n                server_name=self.config['SERVER_NAME'])\n        # We need at the very least the server name to be set for this\n        # to work.\n        if self.config['SERVER_NAME'] is not None:\n            return self.url_map.bind(\n                self.config['SERVER_NAME'],\n                script_name=self.config['APPLICATION_ROOT'] or '/',\n                url_scheme=self.config['PREFERRED_URL_SCHEME'])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef inject_url_defaults(self, endpoint, values):\n        funcs = self.url_default_functions.get(None, ())\n        if '.' in endpoint:\n            bp = endpoint.rsplit('.', 1)[0]\n            funcs = chain(funcs, self.url_default_functions.get(bp, ()))\n        for func in funcs:\n            func(endpoint, values)", "response": "Injects the URL defaults for the given endpoint into the values dictionary passed."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nhandle a BuildError exception on the url_for endpoint.", "response": "def handle_url_build_error(self, error, endpoint, values):\n        \"\"\"Handle :class:`~werkzeug.routing.BuildError` on :meth:`url_for`.\n        \"\"\"\n        exc_type, exc_value, tb = sys.exc_info()\n        for handler in self.url_build_error_handlers:\n            try:\n                rv = handler(error, endpoint, values)\n                if rv is not None:\n                    return rv\n            except BuildError as error:\n                pass\n\n        # At this point we want to reraise the exception.  If the error is\n        # still the same one we can reraise it with the original traceback,\n        # otherwise we raise it from here.\n        if error is exc_value:\n            reraise(exc_type, exc_value, tb)\n        raise error"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncall before the actual request dispatching and will call every as before_request decorated function.", "response": "def preprocess_request(self):\n        \"\"\"Called before the actual request dispatching and will\n        call every as :meth:`before_request` decorated function.\n        If any of these function returns a value it's handled as\n        if it was the return value from the view and further\n        request handling is stopped.\n\n        This also triggers the :meth:`url_value_processor` functions before\n        the actual :meth:`before_request` functions are called.\n        \"\"\"\n        bp = _request_ctx_stack.top.request.blueprint\n\n        funcs = self.url_value_preprocessors.get(None, ())\n        if bp is not None and bp in self.url_value_preprocessors:\n            funcs = chain(funcs, self.url_value_preprocessors[bp])\n        for func in funcs:\n            func(request.endpoint, request.view_args)\n\n        funcs = self.before_request_funcs.get(None, ())\n        if bp is not None and bp in self.before_request_funcs:\n            funcs = chain(funcs, self.before_request_funcs[bp])\n        for func in funcs:\n            rv = func()\n            if rv is not None:\n                return rv"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef process_response(self, response):\n        ctx = _request_ctx_stack.top\n        bp = ctx.request.blueprint\n        funcs = ctx._after_request_functions\n        if bp is not None and bp in self.after_request_funcs:\n            funcs = chain(funcs, reversed(self.after_request_funcs[bp]))\n        if None in self.after_request_funcs:\n            funcs = chain(funcs, reversed(self.after_request_funcs[None]))\n        for handler in funcs:\n            response = handler(response)\n        if not self.session_interface.is_null_session(ctx.session):\n            self.save_session(ctx.session, response)\n        return response", "response": "This method is used to process the response object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef do_teardown_request(self, exc=None):\n        if exc is None:\n            exc = sys.exc_info()[1]\n        funcs = reversed(self.teardown_request_funcs.get(None, ()))\n        bp = _request_ctx_stack.top.request.blueprint\n        if bp is not None and bp in self.teardown_request_funcs:\n            funcs = chain(funcs, reversed(self.teardown_request_funcs[bp]))\n        for func in funcs:\n            rv = func(exc)\n        request_tearing_down.send(self, exc=exc)", "response": "Called after the request dispatching and will\n        call every as a teardown_request decorated function."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef do_teardown_appcontext(self, exc=None):\n        if exc is None:\n            exc = sys.exc_info()[1]\n        for func in reversed(self.teardown_appcontext_funcs):\n            func(exc)\n        appcontext_tearing_down.send(self, exc=exc)", "response": "Called when an application context is popped."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nyields unique values in iterable preserving order.", "response": "def unique(iterable):\n    \"\"\"\n    Yield unique values in iterable, preserving order.\n    \"\"\"\n    seen = set()\n    for value in iterable:\n        if not value in seen:\n            seen.add(value)\n            yield value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd the runtime requirements from pkg_info into the metadata.", "response": "def handle_requires(metadata, pkg_info, key):\n    \"\"\"\n    Place the runtime requirements from pkg_info into metadata.\n    \"\"\"\n    may_requires = defaultdict(list)\n    for value in pkg_info.get_all(key):\n        extra_match = EXTRA_RE.search(value)\n        if extra_match:\n            groupdict = extra_match.groupdict()\n            condition = groupdict['condition']\n            extra = groupdict['extra']\n            package = groupdict['package']\n            if condition.endswith(' and '):\n                condition = condition[:-5]\n        else:\n            condition, extra = None, None\n            package = value\n        key = MayRequiresKey(condition, extra)\n        may_requires[key].append(package)\n\n    if may_requires:\n        metadata['run_requires'] = []\n        for key, value in may_requires.items():\n            may_requirement = {'requires':value}\n            if key.extra:\n                may_requirement['extra'] = key.extra\n            if key.condition:\n                may_requirement['environment'] = key.condition\n            metadata['run_requires'].append(may_requirement)\n\n        if not 'extras' in metadata:\n            metadata['extras'] = []\n        metadata['extras'].extend([key.extra for key in may_requires.keys() if key.extra])"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts PKG - INFO file to a prototype Metadata 2. 0 dict.", "response": "def pkginfo_to_dict(path, distribution=None):\n    \"\"\"\n    Convert PKG-INFO to a prototype Metadata 2.0 (PEP 426) dict.\n\n    The description is included under the key ['description'] rather than\n    being written to a separate file.\n\n    path: path to PKG-INFO file\n    distribution: optional distutils Distribution()\n    \"\"\"\n\n    metadata = defaultdict(lambda: defaultdict(lambda: defaultdict(dict)))\n    metadata[\"generator\"] = \"bdist_wheel (\" + wheel.__version__ + \")\"\n    try:\n        unicode\n        pkg_info = read_pkg_info(path)\n    except NameError:\n        pkg_info = email.parser.Parser().parsestr(open(path, 'rb').read().decode('utf-8'))\n    description = None\n\n    if pkg_info['Summary']:\n        metadata['summary'] = pkginfo_unicode(pkg_info, 'Summary')\n        del pkg_info['Summary']\n\n    if pkg_info['Description']:\n        description = dedent_description(pkg_info)\n        del pkg_info['Description']\n    else:\n        payload = pkg_info.get_payload()\n        if isinstance(payload, bytes):\n            # Avoid a Python 2 Unicode error.\n            # We still suffer ? glyphs on Python 3.\n            payload = payload.decode('utf-8')\n        if payload:\n            description = payload\n\n    if description:\n        pkg_info['description'] = description\n\n    for key in unique(k.lower() for k in pkg_info.keys()):\n        low_key = key.replace('-', '_')\n\n        if low_key in SKIP_FIELDS:\n            continue\n\n        if low_key in UNKNOWN_FIELDS and pkg_info.get(key) == 'UNKNOWN':\n            continue\n\n        if low_key in PLURAL_FIELDS:\n            metadata[PLURAL_FIELDS[low_key]] = pkg_info.get_all(key)\n\n        elif low_key == \"requires_dist\":\n            handle_requires(metadata, pkg_info, key)\n\n        elif low_key == 'provides_extra':\n            if not 'extras' in metadata:\n                metadata['extras'] = []\n            metadata['extras'].extend(pkg_info.get_all(key))\n\n        elif low_key == 'home_page':\n            metadata['extensions']['python.details']['project_urls'] = {'Home':pkg_info[key]}\n\n        elif low_key == 'keywords':\n            metadata['keywords'] = KEYWORDS_RE.split(pkg_info[key])\n\n        else:\n            metadata[low_key] = pkg_info[key]\n\n    metadata['metadata_version'] = METADATA_VERSION\n\n    if 'extras' in metadata:\n        metadata['extras'] = sorted(set(metadata['extras']))\n\n    # include more information if distribution is available\n    if distribution:\n        for requires, attr in (('test_requires', 'tests_require'),):\n            try:\n                requirements = getattr(distribution, attr)\n                if isinstance(requirements, list):\n                    new_requirements = list(convert_requirements(requirements))\n                    metadata[requires] = [{'requires':new_requirements}]\n            except AttributeError:\n                pass\n\n    # handle contacts\n    contacts = []\n    for contact_type, role in CONTACT_FIELDS:\n        contact = {}\n        for key in contact_type:\n            if contact_type[key] in metadata:\n                contact[key] = metadata.pop(contact_type[key])\n        if contact:\n            contact['role'] = role\n            contacts.append(contact)\n    if contacts:\n        metadata['extensions']['python.details']['contacts'] = contacts\n\n    # convert entry points to exports\n    try:\n        with open(os.path.join(os.path.dirname(path), \"entry_points.txt\"), \"r\") as ep_file:\n            ep_map = pkg_resources.EntryPoint.parse_map(ep_file.read())\n        exports = {}\n        for group, items in ep_map.items():\n            exports[group] = {}\n            for item in items.values():\n                name, export = str(item).split(' = ', 1)\n                exports[group][name] = export\n        if exports:\n            metadata['extensions']['python.exports'] = exports\n    except IOError:\n        pass\n\n    # copy console_scripts entry points to commands\n    if 'python.exports' in metadata['extensions']:\n        for (ep_script, wrap_script) in (('console_scripts', 'wrap_console'),\n                                         ('gui_scripts', 'wrap_gui')):\n            if ep_script in metadata['extensions']['python.exports']:\n                metadata['extensions']['python.commands'][wrap_script] = \\\n                    metadata['extensions']['python.exports'][ep_script]\n\n    return metadata"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncompose the version predicates for a given requirement in PEP 345 fashion.", "response": "def requires_to_requires_dist(requirement):\n    \"\"\"Compose the version predicates for requirement in PEP 345 fashion.\"\"\"\n    requires_dist = []\n    for op, ver in requirement.specs:\n        requires_dist.append(op + ver)\n    if not requires_dist:\n        return ''\n    return \" (%s)\" % ','.join(requires_dist)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert egg - info directory with PKG - INFO to the Metadata 1. 3 aka old - draft Metadata 2. 0 format.", "response": "def pkginfo_to_metadata(egg_info_path, pkginfo_path):\n    \"\"\"\n    Convert .egg-info directory with PKG-INFO to the Metadata 1.3 aka\n    old-draft Metadata 2.0 format.\n    \"\"\"\n    pkg_info = read_pkg_info(pkginfo_path)\n    pkg_info.replace_header('Metadata-Version', '2.0')\n    requires_path = os.path.join(egg_info_path, 'requires.txt')\n    if os.path.exists(requires_path):\n        requires = open(requires_path).read()\n        for extra, reqs in pkg_resources.split_sections(requires):\n            condition = ''\n            if extra and ':' in extra: # setuptools extra:condition syntax\n                extra, condition = extra.split(':', 1)\n            if extra:\n                pkg_info['Provides-Extra'] = extra\n                if condition:\n                    condition += \" and \"\n                condition += 'extra == %s' % repr(extra)\n            if condition:\n                condition = '; ' + condition\n            for new_req in convert_requirements(reqs):\n                pkg_info['Requires-Dist'] = new_req + condition\n\n    description = pkg_info['Description']\n    if description:\n        pkg_info.set_payload(dedent_description(pkg_info))\n        del pkg_info['Description']\n\n    return pkg_info"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_possible(self):\n        '''\n        break up a module path to its various parts (prefix, module, class, method)\n\n        this uses PEP 8 conventions, so foo.Bar would be foo module with class Bar\n\n        return -- list -- a list of possible interpretations of the module path\n            (eg, foo.bar can be bar module in foo module, or bar method in foo module)\n        '''\n        possible = []\n        name = self.name\n        logger.debug('Guessing test name: {}'.format(name))\n\n        name_f = self.name.lower()\n        filepath = \"\"\n        if name_f.endswith(\".py\") or \".py:\" in name_f:\n            # path/something:Class.method\n            bits = name.split(\":\", 1)\n            filepath = bits[0]\n            logger.debug('Found filepath: {}'.format(filepath))\n\n            name = bits[1] if len(bits) > 1 else \"\"\n            if name:\n                logger.debug('Found test name: {} for filepath: {}'.format(name, filepath))\n\n        bits = name.split('.')\n        basedir = self.basedir\n        method_prefix = self.method_prefix\n\n        # check if the last bit is a Class\n        if re.search(r'^\\*?[A-Z]', bits[-1]):\n            logger.debug('Found class in name: {}'.format(bits[-1]))\n            possible.append(PathFinder(basedir, method_prefix, **{\n                'class_name': bits[-1],\n                'module_name': bits[-2] if len(bits) > 1 else '',\n                'prefix': os.sep.join(bits[0:-2]),\n                'filepath': filepath,\n            }))\n        elif len(bits) > 1 and re.search(r'^\\*?[A-Z]', bits[-2]):\n            logger.debug('Found class in name: {}'.format(bits[-2]))\n            possible.append(PathFinder(basedir, method_prefix, **{\n                'class_name': bits[-2],\n                'method_name': bits[-1],\n                'module_name': bits[-3] if len(bits) > 2 else '',\n                'prefix': os.sep.join(bits[0:-3]),\n                'filepath': filepath,\n            }))\n        else:\n            if self.name:\n                if filepath:\n                    if len(bits):\n                        possible.append(PathFinder(basedir, method_prefix, **{\n                            'filepath': filepath,\n                            'method_name': bits[0],\n                        }))\n                    else:\n                        possible.append(PathFinder(basedir, method_prefix, **{\n                            'filepath': filepath,\n                        }))\n\n                else:\n                    logger.debug('Test name is ambiguous')\n                    possible.append(PathFinder(basedir, method_prefix, **{\n                        'module_name': bits[-1],\n                        'prefix': os.sep.join(bits[0:-1]),\n                        'filepath': filepath,\n                    }))\n                    possible.append(PathFinder(basedir, method_prefix, **{\n                        'method_name': bits[-1],\n                        'module_name': bits[-2] if len(bits) > 1 else '',\n                        'prefix': os.sep.join(bits[0:-2]),\n                        'filepath': filepath,\n                    }))\n                    possible.append(PathFinder(basedir, method_prefix, **{\n                        'prefix': os.sep.join(bits),\n                        'filepath': filepath,\n                    }))\n\n            else:\n                possible.append(PathFinder(basedir, method_prefix, filepath=filepath))\n\n        logger.debug(\"Found {} possible test names\".format(len(possible)))\n        self.possible = possible", "response": "This method sets the possible test names for the current object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning modules that match module_name", "response": "def modules(self):\n        \"\"\"return modules that match module_name\"\"\"\n\n        # since the module has to be importable we go ahead and put the\n        # basepath as the very first path to check as that should minimize\n        # namespace collisions, this is what unittest does also\n        sys.path.insert(0, self.basedir)\n        for p in self.paths():\n            # http://stackoverflow.com/questions/67631/\n            try:\n                module_name = self.module_path(p)\n                logger.debug(\"Importing {} from path {}\".format(module_name, p))\n                m = importlib.import_module(module_name)\n                yield m\n\n            except Exception as e:\n                logger.warning('Caught exception while importing {}: {}'.format(p, e))\n                logger.warning(e, exc_info=True)\n                error_info = getattr(self, 'error_info', None)\n                if not error_info:\n                    exc_info = sys.exc_info()\n                    #raise e.__class__, e, exc_info[2]\n                    #self.error_info = (e, exc_info)\n                    self.error_info = exc_info\n                continue\n\n        sys.path.pop(0)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef classes(self):\n        for module in self.modules():\n            cs = inspect.getmembers(module, inspect.isclass)\n            class_name = getattr(self, 'class_name', '')\n            class_regex = ''\n            if class_name:\n                if class_name.startswith(\"*\"):\n                    class_name = class_name.strip(\"*\")\n                    class_regex = re.compile(r'.*?{}'.format(class_name), re.I)\n                else:\n                    class_regex = re.compile(r'^{}'.format(class_name), re.I)\n\n            for c_name, c in cs:\n                can_yield = True\n                if class_regex and not class_regex.match(c_name):\n                #if class_name and class_name not in c_name:\n                    can_yield = False\n\n                if can_yield and issubclass(c, unittest.TestCase):\n                    if c is not unittest.TestCase: # ignore actual TestCase class\n                        logger.debug('class: {} matches {}'.format(c_name, class_name))\n                        yield c", "response": "the partial self. class_name will be used to find actual TestCase classes"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the actual test methods that matched self. method_name", "response": "def method_names(self):\n        \"\"\"return the actual test methods that matched self.method_name\"\"\"\n        for c in self.classes():\n            #ms = inspect.getmembers(c, inspect.ismethod)\n            # http://stackoverflow.com/questions/17019949/\n            ms = inspect.getmembers(c, lambda f: inspect.ismethod(f) or inspect.isfunction(f))\n            method_name = getattr(self, 'method_name', '')\n            method_regex = ''\n            if method_name:\n                if method_name.startswith(self.method_prefix):\n                    method_regex = re.compile(r'^{}'.format(method_name), flags=re.I)\n\n                else:\n\n                    if method_name.startswith(\"*\"):\n                        method_name = method_name.strip(\"*\")\n                        method_regex = re.compile(\n                            r'^{}[_]{{0,1}}.*?{}'.format(self.method_prefix, method_name),\n                            flags=re.I\n                        )\n                    else:\n                        method_regex = re.compile(\n                            r'^{}[_]{{0,1}}{}'.format(self.method_prefix, method_name),\n                            flags=re.I\n                        )\n\n            for m_name, m in ms:\n                if not m_name.startswith(self.method_prefix): continue\n\n                can_yield = True\n                if method_regex and not method_regex.match(m_name):\n                    can_yield = False\n\n                if can_yield:\n                    logger.debug('method: {} matches {}'.format(m_name, method_name))\n                    yield c, m_name"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsearches for a basename in the list of basenames or postfixes", "response": "def _find_basename(self, name, basenames, is_prefix=False):\n        \"\"\"check if name combined with test prefixes or postfixes is found anywhere\n        in the list of basenames\n\n        :param name: string, the name you're searching for\n        :param basenames: list, a list of basenames to check\n        :param is_prefix: bool, True if this is a prefix search, which means it will\n            also check if name matches any of the basenames without the prefixes or\n            postfixes, if it is False then the prefixes or postfixes must be present\n            (ie, the module we're looking for is the actual test module, not the parent\n             modules it's contained in)\n        :returns: string, the basename if it is found\n        \"\"\"\n        ret = \"\"\n        fileroots = [(os.path.splitext(n)[0], n) for n in basenames]\n        glob = False\n        if name.startswith(\"*\"):\n            glob = True\n        name = name.strip(\"*\")\n\n        for fileroot, basename in fileroots:\n            if name in fileroot or fileroot in name:\n                for pf in self.module_postfixes:\n                    logger.debug(\n                        'Checking if basename {} starts with {} and ends with {}'.format(\n                        basename,\n                        name,\n                        pf\n                    ))\n                    if glob:\n                        if name in fileroot and fileroot.endswith(pf):\n                            ret = basename\n                            break\n                    else:\n                        if fileroot.startswith(name) and fileroot.endswith(pf):\n                            ret = basename\n                            break\n\n                if not ret:\n                    for pf in self.module_prefixes:\n                        n = pf + name\n                        logger.debug('Checking if basename {} starts with {}'.format(basename, n))\n                        if glob:\n                            if fileroot.startswith(pf) and name in fileroot:\n                                ret = basename\n                                break\n                        else:\n                            if fileroot.startswith(n):\n                                ret = basename\n                                break\n\n                if not ret:\n                    if is_prefix:\n                        logger.debug('Checking if basename {} starts with {}'.format(basename, name))\n                        if basename.startswith(name) or (glob and name in basename):\n                            ret = basename\n\n                        else:\n                            logger.debug(\n                                'Checking if basename {} starts with {} and is a test module'.format(\n                                basename,\n                                name\n                            ))\n                            if glob:\n                                if name in basename and self._is_module_path(basename):\n                                    ret = basename\n\n                            else:\n                                if basename.startswith(name) and self._is_module_path(basename):\n                                    ret = basename\n\n                if ret:\n                    logger.debug('Found basename {}'.format(ret))\n                    break\n\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _find_prefix_path(self, basedir, prefix):\n        ret = \"\"\n        for ret in self._find_prefix_paths(basedir, prefix):\n            break\n\n        if not ret:\n            raise IOError(\"Could not find prefix {} in path {}\".format(prefix, basedir))\n\n        return ret", "response": "Similar to _find_prefix_paths but only returns the first match"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn true if the passed in path is a test module path False otherwise", "response": "def _is_module_path(self, path):\n        \"\"\"Returns true if the passed in path is a test module path\n\n        :param path: string, the path to check, will need to start or end with the\n            module test prefixes or postfixes to be considered valid\n        :returns: boolean, True if a test module path, False otherwise\n        \"\"\"\n        ret = False\n        basename = os.path.basename(path)\n        fileroot = os.path.splitext(basename)[0]\n        for pf in self.module_postfixes:\n            if fileroot.endswith(pf):\n                ret = True\n                break\n\n        if not ret:\n            for pf in self.module_prefixes:\n                if fileroot.startswith(pf):\n                    ret = True\n                    break\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef walk(self, basedir):\n        system_d = SitePackagesDir()\n        filter_system_d = system_d and os.path.commonprefix([system_d, basedir]) != system_d\n\n        for root, dirs, files in os.walk(basedir, topdown=True):\n            # ignore dot directories and private directories (start with underscore)\n            dirs[:] = [d for d in dirs if d[0] != '.' and d[0] != \"_\"]\n\n            if filter_system_d:\n                dirs[:] = [d for d in dirs if not d.startswith(system_d)]\n\n            yield root, dirs, files", "response": "Walk all the directories of basedir except hidden directories\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef paths(self):\n        '''\n        given a basedir, yield all test modules paths recursively found in\n        basedir that are test modules\n\n        return -- generator\n        '''\n        module_name = getattr(self, 'module_name', '')\n        module_prefix = getattr(self, 'prefix', '')\n        filepath = getattr(self, 'filepath', '')\n\n        if filepath:\n            if os.path.isabs(filepath):\n                yield filepath\n\n            else:\n                yield os.path.join(self.basedir, filepath)\n\n        else:\n            if module_prefix:\n                basedirs = self._find_prefix_paths(self.basedir, module_prefix)\n            else:\n                basedirs = [self.basedir]\n\n            for basedir in basedirs:\n                try:\n                    if module_name:\n                        path = self._find_module_path(basedir, module_name)\n\n                    else:\n                        path = basedir\n\n                    if os.path.isfile(path):\n                        logger.debug('Module path: {}'.format(path))\n                        yield path\n\n                    else:\n                        seen_paths = set()\n                        for root, dirs, files in self.walk(path):\n                            for basename in files:\n                                if basename.startswith(\"__init__\"):\n                                    if self._is_module_path(root):\n                                        filepath = os.path.join(root, basename)\n                                        if filepath not in seen_paths:\n                                            logger.debug('Module package path: {}'.format(filepath))\n                                            seen_paths.add(filepath)\n                                            yield filepath\n\n                                else:\n                                    fileroot = os.path.splitext(basename)[0]\n                                    for pf in self.module_postfixes:\n                                        if fileroot.endswith(pf):\n                                            filepath = os.path.join(root, basename)\n                                            if filepath not in seen_paths:\n                                                logger.debug('Module postfix path: {}'.format(filepath))\n                                                seen_paths.add(filepath)\n                                                yield filepath\n\n                                    for pf in self.module_prefixes:\n                                        if fileroot.startswith(pf):\n                                            filepath = os.path.join(root, basename)\n                                            if filepath not in seen_paths:\n                                                logger.debug('Module prefix path: {}'.format(filepath))\n                                                seen_paths.add(filepath)\n                                                yield filepath\n\n                except IOError as e:\n                    # we failed to find a suitable path\n                    logger.warning(e, exc_info=True)\n                    pass", "response": "yields all test modules paths recursively found in\n        basedir"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef module_path(self, filepath):\n        possible_modbits = re.split('[\\\\/]', filepath.strip('\\\\/'))\n        basename = possible_modbits[-1]\n        prefixes = possible_modbits[0:-1]\n        modpath = []\n        discarded = []\n\n        # find the first directory that has an __init__.py\n        for i in range(len(prefixes)):\n            path_args = [\"/\"]\n            path_args.extend(prefixes[0:i+1])\n            path_args.append('__init__.py')\n            prefix_module = os.path.join(*path_args)\n            #logger.debug(\"Checking prefix modulepath: {}\".format(prefix_module))\n            if os.path.isfile(prefix_module):\n                #logger.debug(\"Found start of modulepath: {}\".format(prefixes[i]))\n                modpath = prefixes[i:]\n                break\n\n            else:\n                discarded = path_args[0:-1]\n\n        modpath.append(basename)\n\n        # convert the remaining file path to a python module path that can be imported\n        module_name = '.'.join(modpath)\n        module_name = re.sub(r'(?:\\.__init__)?\\.py$', '', module_name, flags=re.I)\n        logger.debug(\"Module path {} found in filepath {}\".format(module_name, filepath))\n        return module_name", "response": "given a filepath like base. path. to. module this will convert it to\n        path. to. module so it can be imported"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving paths in self. paths with confirmation.", "response": "def remove(self, auto_confirm=False):\n        \"\"\"Remove paths in ``self.paths`` with confirmation (unless\n        ``auto_confirm`` is True).\"\"\"\n        if not self._can_uninstall():\n            return\n        if not self.paths:\n            logger.info(\n                \"Can't uninstall '%s'. No files were found to uninstall.\",\n                self.dist.project_name,\n            )\n            return\n        logger.info(\n            'Uninstalling %s-%s:',\n            self.dist.project_name, self.dist.version\n        )\n\n        with indent_log():\n            paths = sorted(self.compact(self.paths))\n\n            if auto_confirm:\n                response = 'y'\n            else:\n                for path in paths:\n                    logger.info(path)\n                response = ask('Proceed (y/n)? ', ('y', 'n'))\n            if self._refuse:\n                logger.info('Not removing or modifying (outside of prefix):')\n                for path in self.compact(self._refuse):\n                    logger.info(path)\n            if response == 'y':\n                self.save_dir = tempfile.mkdtemp(suffix='-uninstall',\n                                                 prefix='pip-')\n                for path in paths:\n                    new_path = self._stash(path)\n                    logger.debug('Removing file or directory %s', path)\n                    self._moved_paths.append(path)\n                    renames(path, new_path)\n                for pth in self.pth.values():\n                    pth.remove()\n                logger.info(\n                    'Successfully uninstalled %s-%s',\n                    self.dist.project_name, self.dist.version\n                )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef rollback(self):\n        if self.save_dir is None:\n            logger.error(\n                \"Can't roll back %s; was not uninstalled\",\n                self.dist.project_name,\n            )\n            return False\n        logger.info('Rolling back uninstall of %s', self.dist.project_name)\n        for path in self._moved_paths:\n            tmp_path = self._stash(path)\n            logger.debug('Replacing %s', path)\n            renames(tmp_path, path)\n        for pth in self.pth.values():\n            pth.rollback()", "response": "Rollback the changes made by remove."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef commit(self):\n        if self.save_dir is not None:\n            rmtree(self.save_dir)\n            self.save_dir = None\n            self._moved_paths = []", "response": "Remove temporary save dir and rollback will no longer be possible."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _dump_arg_defaults(kwargs):\n    if current_app:\n        kwargs.setdefault('cls', current_app.json_encoder)\n        if not current_app.config['JSON_AS_ASCII']:\n            kwargs.setdefault('ensure_ascii', False)\n        kwargs.setdefault('sort_keys', current_app.config['JSON_SORT_KEYS'])\n    else:\n        kwargs.setdefault('sort_keys', True)\n        kwargs.setdefault('cls', JSONEncoder)", "response": "Inject default arguments for dump functions."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _load_arg_defaults(kwargs):\n    if current_app:\n        kwargs.setdefault('cls', current_app.json_decoder)\n    else:\n        kwargs.setdefault('cls', JSONDecoder)", "response": "Inject default arguments for load functions."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nserializes obj to a JSON formatted str by using the application s json_encoder.", "response": "def dumps(obj, **kwargs):\n    \"\"\"Serialize ``obj`` to a JSON formatted ``str`` by using the application's\n    configured encoder (:attr:`~flask.Flask.json_encoder`) if there is an\n    application on the stack.\n\n    This function can return ``unicode`` strings or ascii-only bytestrings by\n    default which coerce into unicode strings automatically.  That behavior by\n    default is controlled by the ``JSON_AS_ASCII`` configuration variable\n    and can be overriden by the simplejson ``ensure_ascii`` parameter.\n    \"\"\"\n    _dump_arg_defaults(kwargs)\n    encoding = kwargs.pop('encoding', None)\n    rv = _json.dumps(obj, **kwargs)\n    if encoding is not None and isinstance(rv, text_type):\n        rv = rv.encode(encoding)\n    return rv"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dump(obj, fp, **kwargs):\n    _dump_arg_defaults(kwargs)\n    encoding = kwargs.pop('encoding', None)\n    if encoding is not None:\n        fp = _wrap_writer_for_text(fp, encoding)\n    _json.dump(obj, fp, **kwargs)", "response": "Like dump but writes into a file object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load(fp, **kwargs):\n    _load_arg_defaults(kwargs)\n    if not PY2:\n        fp = _wrap_reader_for_text(fp, kwargs.pop('encoding', None) or 'utf-8')\n    return _json.load(fp, **kwargs)", "response": "Like load but reads from a file object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef htmlsafe_dumps(obj, **kwargs):\n    rv = dumps(obj, **kwargs) \\\n        .replace(u'<', u'\\\\u003c') \\\n        .replace(u'>', u'\\\\u003e') \\\n        .replace(u'&', u'\\\\u0026') \\\n        .replace(u\"'\", u'\\\\u0027')\n    if not _slash_escape:\n        rv = rv.replace('\\\\/', '/')\n    return rv", "response": "This function dumps is safe for use in HTML tags."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nlike htmlsafe_dumps but writes into a file object.", "response": "def htmlsafe_dump(obj, fp, **kwargs):\n    \"\"\"Like :func:`htmlsafe_dumps` but writes into a file object.\"\"\"\n    fp.write(unicode(htmlsafe_dumps(obj, **kwargs)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a Flask. Response object with the JSON representation of the given arguments with an application / json mimetype.", "response": "def jsonify(*args, **kwargs):\n    \"\"\"Creates a :class:`~flask.Response` with the JSON representation of\n    the given arguments with an `application/json` mimetype.  The arguments\n    to this function are the same as to the :class:`dict` constructor.\n\n    Example usage::\n\n        from flask import jsonify\n\n        @app.route('/_get_current_user')\n        def get_current_user():\n            return jsonify(username=g.user.username,\n                           email=g.user.email,\n                           id=g.user.id)\n\n    This will send a JSON response like this to the browser::\n\n        {\n            \"username\": \"admin\",\n            \"email\": \"admin@localhost\",\n            \"id\": 42\n        }\n\n    For security reasons only objects are supported toplevel.  For more\n    information about this, have a look at :ref:`json-security`.\n\n    This function's response will be pretty printed if it was not requested\n    with ``X-Requested-With: XMLHttpRequest`` to simplify debugging unless\n    the ``JSONIFY_PRETTYPRINT_REGULAR`` config parameter is set to false.\n\n    .. versionadded:: 0.2\n    \"\"\"\n    indent = None\n    if current_app.config['JSONIFY_PRETTYPRINT_REGULAR'] \\\n        and not request.is_xhr:\n        indent = 2\n    return current_app.response_class(dumps(dict(*args, **kwargs),\n        indent=indent),\n        mimetype='application/json')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nimplementing this method in a subclass such that it returns a serializable object for o.", "response": "def default(self, o):\n        \"\"\"Implement this method in a subclass such that it returns a\n        serializable object for ``o``, or calls the base implementation (to\n        raise a ``TypeError``).\n\n        For example, to support arbitrary iterators, you could implement\n        default like this::\n\n            def default(self, o):\n                try:\n                    iterable = iter(o)\n                except TypeError:\n                    pass\n                else:\n                    return list(iterable)\n                return JSONEncoder.default(self, o)\n        \"\"\"\n        if isinstance(o, datetime):\n            return http_date(o)\n        if isinstance(o, uuid.UUID):\n            return str(o)\n        if hasattr(o, '__html__'):\n            return text_type(o.__html__())\n        return _json.JSONEncoder.default(self, o)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting the characters & and < and > and return a Markup string.", "response": "def escape(s):\n    \"\"\"Convert the characters &, <, >, ' and \" in string s to HTML-safe\n    sequences.  Use this if you need to display text that might contain\n    such characters in HTML.  Marks return value as markup string.\n    \"\"\"\n    if hasattr(s, '__html__'):\n        return s.__html__()\n    return Markup(text_type(s)\n        .replace('&', '&amp;')\n        .replace('>', '&gt;')\n        .replace('<', '&lt;')\n        .replace(\"'\", '&#39;')\n        .replace('\"', '&#34;')\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_many(self, mapping, timeout=None):\n        rv = True\n        for key, value in _items(mapping):\n            if not self.set(key, value, timeout):\n                rv = False\n        return rv", "response": "Sets multiple keys and values from a mapping."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nincrement the value of a key by delta.", "response": "def inc(self, key, delta=1):\n        \"\"\"Increments the value of a key by `delta`.  If the key does\n        not yet exist it is initialized with `delta`.\n\n        For supporting caches this is an atomic operation.\n\n        :param key: the key to increment.\n        :param delta: the delta to add.\n        :returns: The new value or ``None`` for backend errors.\n        \"\"\"\n        value = (self.get(key) or 0) + delta\n        return value if self.set(key, value) else None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndumping an object into a string for redis.", "response": "def dump_object(self, value):\n        \"\"\"Dumps an object into a string for redis.  By default it serializes\n        integers as regular string and pickle dumps everything else.\n        \"\"\"\n        t = type(value)\n        if t in integer_types:\n            return str(value).encode('ascii')\n        return b'!' + pickle.dumps(value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load_object(self, value):\n        if value is None:\n            return None\n        if value.startswith(b'!'):\n            try:\n                return pickle.loads(value[1:])\n            except pickle.PickleError:\n                return None\n        try:\n            return int(value)\n        except ValueError:\n            # before 0.8 we did not have serialization.  Still support that.\n            return value", "response": "The reversal of dump_object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _strip_postfix(req):\n    # FIXME: use package_to_requirement?\n    match = re.search(r'^(.*?)(?:-dev|-\\d.*)$', req)\n    if match:\n        # Strip off -dev, -0.2, etc.\n        req = match.group(1)\n    return req", "response": "Strip the postfix from a package name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _build_editable_options(req):\n\n    \"\"\"\n        This method generates a dictionary of the query string\n        parameters contained in a given editable URL.\n    \"\"\"\n    regexp = re.compile(r\"[\\?#&](?P<name>[^&=]+)=(?P<value>[^&=]+)\")\n    matched = regexp.findall(req)\n\n    if matched:\n        ret = dict()\n        for option in matched:\n            (name, value) = option\n            if name in ret:\n                raise Exception(\"%s option already defined\" % name)\n            ret[name] = value\n        return ret\n    return None", "response": "This method builds a dictionary of the query string\nAttributeNames parameters contained in a given editable URL."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_editable(editable_req, default_vcs=None):\n\n    url = editable_req\n    extras = None\n\n    # If a file path is specified with extras, strip off the extras.\n    m = re.match(r'^(.+)(\\[[^\\]]+\\])$', url)\n    if m:\n        url_no_extras = m.group(1)\n        extras = m.group(2)\n    else:\n        url_no_extras = url\n\n    if os.path.isdir(url_no_extras):\n        if not os.path.exists(os.path.join(url_no_extras, 'setup.py')):\n            raise InstallationError(\n                \"Directory %r is not installable. File 'setup.py' not found.\" %\n                url_no_extras\n            )\n        # Treating it as code that has already been checked out\n        url_no_extras = path_to_url(url_no_extras)\n\n    if url_no_extras.lower().startswith('file:'):\n        if extras:\n            return (\n                None,\n                url_no_extras,\n                pkg_resources.Requirement.parse(\n                    '__placeholder__' + extras\n                ).extras,\n                {},\n            )\n        else:\n            return None, url_no_extras, None, {}\n\n    for version_control in vcs:\n        if url.lower().startswith('%s:' % version_control):\n            url = '%s+%s' % (version_control, url)\n            break\n\n    if '+' not in url:\n        if default_vcs:\n            url = default_vcs + '+' + url\n        else:\n            raise InstallationError(\n                '%s should either be a path to a local project or a VCS url '\n                'beginning with svn+, git+, hg+, or bzr+' %\n                editable_req\n            )\n\n    vc_type = url.split('+', 1)[0].lower()\n\n    if not vcs.get_backend(vc_type):\n        error_message = 'For --editable=%s only ' % editable_req + \\\n            ', '.join([backend.name + '+URL' for backend in vcs.backends]) + \\\n            ' is currently supported'\n        raise InstallationError(error_message)\n\n    try:\n        options = _build_editable_options(editable_req)\n    except Exception as exc:\n        raise InstallationError(\n            '--editable=%s error in editable options:%s' % (editable_req, exc)\n        )\n    if not options or 'egg' not in options:\n        req = _build_req_from_url(editable_req)\n        if not req:\n            raise InstallationError(\n                '--editable=%s is not the right format; it must have '\n                '#egg=Package' % editable_req\n            )\n    else:\n        req = options['egg']\n\n    package = _strip_postfix(req)\n    return package, url, None, options", "response": "Parses an editable requirement into a list of tuples."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef from_line(\n            cls, name, comes_from=None, isolated=False, options=None,\n            wheel_cache=None):\n        \"\"\"Creates an InstallRequirement from a name, which might be a\n        requirement, directory containing 'setup.py', filename, or URL.\n        \"\"\"\n        from pip.index import Link\n\n        if is_url(name):\n            marker_sep = '; '\n        else:\n            marker_sep = ';'\n        if marker_sep in name:\n            name, markers = name.split(marker_sep, 1)\n            markers = markers.strip()\n            if not markers:\n                markers = None\n        else:\n            markers = None\n        name = name.strip()\n        req = None\n        path = os.path.normpath(os.path.abspath(name))\n        link = None\n        extras = None\n\n        if is_url(name):\n            link = Link(name)\n        else:\n            p, extras = _strip_extras(path)\n            if (os.path.isdir(p) and\n                    (os.path.sep in name or name.startswith('.'))):\n\n                if not is_installable_dir(p):\n                    raise InstallationError(\n                        \"Directory %r is not installable. File 'setup.py' \"\n                        \"not found.\" % name\n                    )\n                link = Link(path_to_url(p))\n            elif is_archive_file(p):\n                if not os.path.isfile(p):\n                    logger.warning(\n                        'Requirement %r looks like a filename, but the '\n                        'file does not exist',\n                        name\n                    )\n                link = Link(path_to_url(p))\n\n        # it's a local file, dir, or url\n        if link:\n            # Handle relative file URLs\n            if link.scheme == 'file' and re.search(r'\\.\\./', link.url):\n                link = Link(\n                    path_to_url(os.path.normpath(os.path.abspath(link.path))))\n            # wheel file\n            if link.is_wheel:\n                wheel = Wheel(link.filename)  # can raise InvalidWheelFilename\n                if not wheel.supported():\n                    raise UnsupportedWheel(\n                        \"%s is not a supported wheel on this platform.\" %\n                        wheel.filename\n                    )\n                req = \"%s==%s\" % (wheel.name, wheel.version)\n            else:\n                # set the req to the egg fragment.  when it's not there, this\n                # will become an 'unnamed' requirement\n                req = link.egg_fragment\n\n        # a requirement specifier\n        else:\n            req = name\n\n        options = options if options else {}\n        res = cls(req, comes_from, link=link, markers=markers,\n                  isolated=isolated, options=options,\n                  wheel_cache=wheel_cache)\n\n        if extras:\n            res.extras = pkg_resources.Requirement.parse('__placeholder__' +\n                                                         extras).extras\n\n        return res", "response": "Creates an InstallRequirement object from a line of text."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\npopulate the link attribute with the link information from the given finder.", "response": "def populate_link(self, finder, upgrade):\n        \"\"\"Ensure that if a link can be found for this, that it is found.\n\n        Note that self.link may still be None - if Upgrade is False and the\n        requirement is already installed.\n        \"\"\"\n        if self.link is None:\n            self.link = finder.find_requirement(self, upgrade)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _correct_build_location(self):\n        if self.source_dir is not None:\n            return\n        assert self.req is not None\n        assert self._temp_build_dir\n        assert self._ideal_build_dir\n        old_location = self._temp_build_dir\n        self._temp_build_dir = None\n        new_location = self.build_location(self._ideal_build_dir)\n        if os.path.exists(new_location):\n            raise InstallationError(\n                'A package already exists in %s; please remove it to continue'\n                % display_path(new_location))\n        logger.debug(\n            'Moving package %s from %s to new location %s',\n            self, display_path(old_location), display_path(new_location),\n        )\n        shutil.move(old_location, new_location)\n        self._temp_build_dir = new_location\n        self._ideal_build_dir = None\n        self.source_dir = new_location\n        self._egg_info_path = None", "response": "Move the build directory to the correct location."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ensure_has_source_dir(self, parent_dir):\n        if self.source_dir is None:\n            self.source_dir = self.build_location(parent_dir)\n        return self.source_dir", "response": "Ensure that a source_dir is set."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef remove_temporary_source(self):\n        if self.source_dir and os.path.exists(\n                os.path.join(self.source_dir, PIP_DELETE_MARKER_FILENAME)):\n            logger.debug('Removing source in %s', self.source_dir)\n            rmtree(self.source_dir)\n        self.source_dir = None\n        if self._temp_build_dir and os.path.exists(self._temp_build_dir):\n            rmtree(self._temp_build_dir)\n        self._temp_build_dir = None", "response": "Remove the source files from this requirement if they are marked\n        for deletion"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a pkg_resources. Distribution built from self. egg_info_path", "response": "def get_dist(self):\n        \"\"\"Return a pkg_resources.Distribution built from self.egg_info_path\"\"\"\n        egg_info = self.egg_info_path('').rstrip('/')\n        base_dir = os.path.dirname(egg_info)\n        metadata = pkg_resources.PathMetadata(base_dir, egg_info)\n        dist_name = os.path.splitext(os.path.basename(egg_info))[0]\n        return pkg_resources.Distribution(\n            os.path.dirname(egg_info),\n            project_name=dist_name,\n            metadata=metadata)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses the contents of the egg - info file into a list of metadata items needed.", "response": "def parse_info(wininfo_name, egginfo_name):\n    \"\"\"Extract metadata from filenames.\n    \n    Extracts the 4 metadataitems needed (name, version, pyversion, arch) from\n    the installer filename and the name of the egg-info directory embedded in\n    the zipfile (if any).\n\n    The egginfo filename has the format::\n\n        name-ver(-pyver)(-arch).egg-info\n\n    The installer filename has the format::\n\n        name-ver.arch(-pyver).exe\n\n    Some things to note:\n\n    1. The installer filename is not definitive. An installer can be renamed\n       and work perfectly well as an installer. So more reliable data should\n       be used whenever possible.\n    2. The egg-info data should be preferred for the name and version, because\n       these come straight from the distutils metadata, and are mandatory.\n    3. The pyver from the egg-info data should be ignored, as it is\n       constructed from the version of Python used to build the installer,\n       which is irrelevant - the installer filename is correct here (even to\n       the point that when it's not there, any version is implied).\n    4. The architecture must be taken from the installer filename, as it is\n       not included in the egg-info data.\n    5. Architecture-neutral installers still have an architecture because the\n       installer format itself (being executable) is architecture-specific. We\n       should therefore ignore the architecture if the content is pure-python.\n    \"\"\"\n\n    egginfo = None\n    if egginfo_name:\n        egginfo = egg_info_re.search(egginfo_name)\n        if not egginfo:\n            raise ValueError(\"Egg info filename %s is not valid\" %\n                    (egginfo_name,))\n\n    # Parse the wininst filename\n    # 1. Distribution name (up to the first '-')\n    w_name, sep, rest = wininfo_name.partition('-')\n    if not sep:\n        raise ValueError(\"Installer filename %s is not valid\" %\n                (wininfo_name,))\n    # Strip '.exe'\n    rest = rest[:-4]\n    # 2. Python version (from the last '-', must start with 'py')\n    rest2, sep, w_pyver = rest.rpartition('-')\n    if sep and w_pyver.startswith('py'):\n        rest = rest2\n        w_pyver = w_pyver.replace('.', '')\n    else:\n        # Not version specific - use py2.py3. While it is possible that\n        # pure-Python code is not compatible with both Python 2 and 3, there\n        # is no way of knowing from the wininst format, so we assume the best\n        # here (the user can always manually rename the wheel to be more\n        # restrictive if needed).\n        w_pyver = 'py2.py3'\n    # 3. Version and architecture\n    w_ver, sep, w_arch = rest.rpartition('.')\n    if not sep:\n        raise ValueError(\"Installer filename %s is not valid\" %\n                (wininfo_name,))\n\n    if egginfo:\n        w_name = egginfo.group('name')\n        w_ver = egginfo.group('ver')\n\n    return dict(name=w_name, ver=w_ver, arch=w_arch, pyver=w_pyver)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_internal_attribute(obj, attr):\n    if isinstance(obj, function_type):\n        if attr in UNSAFE_FUNCTION_ATTRIBUTES:\n            return True\n    elif isinstance(obj, method_type):\n        if attr in UNSAFE_FUNCTION_ATTRIBUTES or \\\n           attr in UNSAFE_METHOD_ATTRIBUTES:\n            return True\n    elif isinstance(obj, type):\n        if attr == 'mro':\n            return True\n    elif isinstance(obj, (code_type, traceback_type, frame_type)):\n        return True\n    elif isinstance(obj, generator_type):\n        if attr in UNSAFE_GENERATOR_ATTRIBUTES:\n            return True\n    return attr.startswith('__')", "response": "Test if the attribute given is an internal python attribute."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_stream_for_parsing(self):\n        cached_data = getattr(self, '_cached_data', None)\n        if cached_data is not None:\n            return BytesIO(cached_data)\n        return self.stream", "response": "This is the same as accessing the stream with the difference\n        that is found in the cache."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_data(self, cache=True, as_text=False, parse_form_data=False):\n        rv = getattr(self, '_cached_data', None)\n        if rv is None:\n            if parse_form_data:\n                self._load_form_data()\n            rv = self.stream.read()\n            if cache:\n                self._cached_data = rv\n        if as_text:\n            rv = rv.decode(self.charset, self.encoding_errors)\n        return rv", "response": "This method reads the buffered incoming data from the client into one - element bytestring."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef url_fix(s, charset='utf-8'):\n    # First step is to switch to unicode processing and to convert\n    # backslashes (which are invalid in URLs anyways) to slashes.  This is\n    # consistent with what Chrome does.\n    s = to_unicode(s, charset, 'replace').replace('\\\\', '/')\n\n    # For the specific case that we look like a malformed windows URL\n    # we want to fix this up manually:\n    if s.startswith('file://') and s[7:8].isalpha() and s[8:10] in (':/', '|/'):\n        s = 'file:///' + s[7:]\n\n    url = url_parse(s)\n    path = url_quote(url.path, charset, safe='/%+$!*\\'(),')\n    qs = url_quote_plus(url.query, charset, safe=':&%=+$!*\\'(),')\n    anchor = url_quote_plus(url.fragment, charset, safe=':&%=+$!*\\'(),')\n    return to_native(url_unparse((url.scheme, url.encode_netloc(),\n                                  path, qs, anchor)))", "response": "Fixes the URL by a user that just isn t a real URL."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef user_cache_dir(appname):\n    if WINDOWS:\n        # Get the base path\n        path = os.path.normpath(_get_win_folder(\"CSIDL_LOCAL_APPDATA\"))\n\n        # Add our app name and Cache directory to it\n        path = os.path.join(path, appname, \"Cache\")\n    elif sys.platform == \"darwin\":\n        # Get the base path\n        path = os.path.expanduser(\"~/Library/Caches\")\n\n        # Add our app name to it\n        path = os.path.join(path, appname)\n    else:\n        # Get the base path\n        path = os.getenv(\"XDG_CACHE_HOME\", os.path.expanduser(\"~/.cache\"))\n\n        # Add our app name to it\n        path = os.path.join(path, appname)\n\n    return path", "response": "r Returns full path to the user - specific cache dir for this application."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef user_data_dir(appname, roaming=False):\n    if WINDOWS:\n        const = roaming and \"CSIDL_APPDATA\" or \"CSIDL_LOCAL_APPDATA\"\n        path = os.path.join(os.path.normpath(_get_win_folder(const)), appname)\n    elif sys.platform == \"darwin\":\n        path = os.path.join(\n            os.path.expanduser('~/Library/Application Support/'),\n            appname,\n        )\n    else:\n        path = os.path.join(\n            os.getenv('XDG_DATA_HOME', os.path.expanduser(\"~/.local/share\")),\n            appname,\n        )\n\n    return path", "response": "Return full path to the user - specific data directory for this application."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns full path to the user - specific log dir for this application.", "response": "def user_log_dir(appname):\n    \"\"\"\n    Return full path to the user-specific log dir for this application.\n\n        \"appname\" is the name of application.\n            If None, just the system directory is returned.\n\n    Typical user cache directories are:\n        Mac OS X:   ~/Library/Logs/<AppName>\n        Unix:       ~/.cache/<AppName>/log  # or under $XDG_CACHE_HOME if\n                    defined\n        Win XP:     C:\\Documents and Settings\\<username>\\Local Settings\\ ...\n                    ...Application Data\\<AppName>\\Logs\n        Vista:      C:\\\\Users\\<username>\\AppData\\Local\\<AppName>\\Logs\n\n    On Windows the only suggestion in the MSDN docs is that local settings\n    go in the `CSIDL_LOCAL_APPDATA` directory. (Note: I'm interested in\n    examples of what some windows apps use for a logs dir.)\n\n    OPINION: This function appends \"Logs\" to the `CSIDL_LOCAL_APPDATA`\n    value for Windows and appends \"log\" to the user cache dir for Unix.\n    \"\"\"\n    if WINDOWS:\n        path = os.path.join(user_data_dir(appname), \"Logs\")\n    elif sys.platform == \"darwin\":\n        path = os.path.join(os.path.expanduser('~/Library/Logs'), appname)\n    else:\n        path = os.path.join(user_cache_dir(appname), \"log\")\n\n    return path"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef user_config_dir(appname, roaming=True):\n    if WINDOWS:\n        path = user_data_dir(appname, roaming=roaming)\n    elif sys.platform == \"darwin\":\n        path = user_data_dir(appname)\n    else:\n        path = os.getenv('XDG_CONFIG_HOME', os.path.expanduser(\"~/.config\"))\n        path = os.path.join(path, appname)\n\n    return path", "response": "Return full path to the user - specific config dir for this application."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of potential user - shared config dirs for this application.", "response": "def site_config_dirs(appname):\n    \"\"\"Return a list of potential user-shared config dirs for this application.\n\n        \"appname\" is the name of application.\n\n    Typical user config directories are:\n        Mac OS X:   /Library/Application Support/<AppName>/\n        Unix:       /etc or $XDG_CONFIG_DIRS[i]/<AppName>/ for each value in\n                    $XDG_CONFIG_DIRS\n        Win XP:     C:\\Documents and Settings\\All Users\\Application ...\n                    ...Data\\<AppName>\\\n        Vista:      (Fail! \"C:\\ProgramData\" is a hidden *system* directory\n                    on Vista.)\n        Win 7:      Hidden, but writeable on Win 7:\n                    C:\\ProgramData\\<AppName>\\\n    \"\"\"\n    if WINDOWS:\n        path = os.path.normpath(_get_win_folder(\"CSIDL_COMMON_APPDATA\"))\n        pathlist = [os.path.join(path, appname)]\n    elif sys.platform == 'darwin':\n        pathlist = [os.path.join('/Library/Application Support', appname)]\n    else:\n        # try looking in $XDG_CONFIG_DIRS\n        xdg_config_dirs = os.getenv('XDG_CONFIG_DIRS', '/etc/xdg')\n        if xdg_config_dirs:\n            pathlist = [\n                os.sep.join([os.path.expanduser(x), appname])\n                for x in xdg_config_dirs.split(os.pathsep)\n            ]\n        else:\n            pathlist = []\n\n        # always look in /etc directly as well\n        pathlist.append('/etc')\n\n    return pathlist"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _iter_module_files():\n    # The list call is necessary on Python 3 in case the module\n    # dictionary modifies during iteration.\n    for module in list(sys.modules.values()):\n        if module is None:\n            continue\n        filename = getattr(module, '__file__', None)\n        if filename:\n            old = None\n            while not os.path.isfile(filename):\n                old = filename\n                filename = os.path.dirname(filename)\n                if filename == old:\n                    break\n            else:\n                if filename[-4:] in ('.pyc', '.pyo'):\n                    filename = filename[:-1]\n                yield filename", "response": "This function iterates over all relevant Python files in the modules and returns a generator of all relevant files."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nspawns a new Python interpreter with the same arguments as this one and running the reloader thread.", "response": "def restart_with_reloader(self):\n        \"\"\"Spawn a new Python interpreter with the same arguments as this one,\n        but running the reloader thread.\n        \"\"\"\n        while 1:\n            _log('info', ' * Restarting with %s' % self.name)\n            args = [sys.executable] + sys.argv\n            new_environ = os.environ.copy()\n            new_environ['WERKZEUG_RUN_MAIN'] = 'true'\n\n            # a weird bug on windows. sometimes unicode strings end up in the\n            # environment and subprocess.call does not like this, encode them\n            # to latin1 and continue.\n            if os.name == 'nt' and PY2:\n                for key, value in iteritems(new_environ):\n                    if isinstance(value, text_type):\n                        new_environ[key] = value.encode('iso-8859-1')\n\n            exit_code = subprocess.call(args, env=new_environ)\n            if exit_code != 3:\n                return exit_code"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwraps around six. text_type to convert None to empty string", "response": "def to_text(s, blank_if_none=True):\n    \"\"\"Wrapper around six.text_type to convert None to empty string\"\"\"\n    if s is None:\n        if blank_if_none:\n            return \"\"\n        else:\n            return None\n    elif isinstance(s, text_type):\n        return s\n    else:\n        return text_type(s)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning an existing CA bundle path or None if no CA bundle exists.", "response": "def find_ca_bundle():\n    \"\"\"Return an existing CA bundle path, or None\"\"\"\n    if os.name=='nt':\n        return get_win_certfile()\n    else:\n        for cert_path in cert_paths:\n            if os.path.isfile(cert_path):\n                return cert_path\n    try:\n        return pkg_resources.resource_filename('certifi', 'cacert.pem')\n    except (ImportError, ResolutionError, ExtractionError):\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse a string or file - like object into a tree", "response": "def parse(doc, treebuilder=\"etree\", encoding=None,\n          namespaceHTMLElements=True):\n    \"\"\"Parse a string or file-like object into a tree\"\"\"\n    tb = treebuilders.getTreeBuilder(treebuilder)\n    p = HTMLParser(tb, namespaceHTMLElements=namespaceHTMLElements)\n    return p.parse(doc, encoding=encoding)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse a well - formed tree into a well - formed tree object", "response": "def parse(self, stream, encoding=None, parseMeta=True, useChardet=True):\n        \"\"\"Parse a HTML document into a well-formed tree\n\n        stream - a filelike object or string containing the HTML to be parsed\n\n        The optional encoding parameter must be a string that indicates\n        the encoding.  If specified, that encoding will be used,\n        regardless of any BOM or later declaration (such as in a meta\n        element)\n        \"\"\"\n        self._parse(stream, innerHTML=False, encoding=encoding,\n                    parseMeta=parseMeta, useChardet=useChardet)\n        return self.tree.getDocument()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse a fragment into a well - formed tree fragment", "response": "def parseFragment(self, stream, container=\"div\", encoding=None,\n                      parseMeta=False, useChardet=True):\n        \"\"\"Parse a HTML fragment into a well-formed tree fragment\n\n        container - name of the element we're setting the innerHTML property\n        if set to None, default to 'div'\n\n        stream - a filelike object or string containing the HTML to be parsed\n\n        The optional encoding parameter must be a string that indicates\n        the encoding.  If specified, that encoding will be used,\n        regardless of any BOM or later declaration (such as in a meta\n        element)\n        \"\"\"\n        self._parse(stream, True, container=container, encoding=encoding)\n        return self.tree.getFragment()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntranslate a word into a list of transcription keys.", "response": "def translate(self, word):\n        \"\"\"\n        pass in a word string that you\n        would like to see probable matches for.\n        \"\"\"\n        if (word not in self.transmissions):\n            raise NoMatchError('no matches found')\n        else:\n            trans = self.transmissions[word]\n            # print out a sorted list of all non-zero trans\n            return sorted(((k, v) for k, v in trans.iteritems() if v != 0), \n                                                                reverse=True)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef initTef(self):\n        ''' \n        get all probable matches\n        and then initialize t(f|e)\n        '''\n        probs = {}\n        transmissions = {}\n\n        # go through each german word\n        for word in self.en_words:\n            word_poss = []\n            # if word in sentence.. then\n            for sent in self.en_dict:\n                if word in sent:\n                    matching = self.de_dict[self.en_dict.index(sent)]\n                    word_poss = word_poss + matching.split()\n\n            # remove the duplicates\n            word_poss = list(set(word_poss))\n            # add the probable matches\n            probs[word] = word_poss\n\n        self.probs = probs\n        print self.probs\n\n        for word in self.en_words:\n            # print self.probs\n            word_probs = self.probs[word]\n            if (len(word_probs) == 0):\n                print word, word_probs\n            uniform_prob = 1.0 / len(word_probs)\n\n            word_probs = dict([(w, uniform_prob) for w in word_probs])\n\n            # save word_probs\n            transmissions[word] = word_probs\n\n        self.transmissions = transmissions", "response": "get all probable matches and then initialize t"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef iterateEM(self, count):\n        '''\n        Iterate through all transmissions of english to\n        foreign words. keep count of repeated occurences\n         do until convergence\n           set count(e|f) to 0 for all e,f\n           set total(f) to 0 for all f\n           for all sentence pairs (e_s,f_s)\n             set total_s(e) = 0 for all e\n             for all words e in e_s\n               for all words f in f_s\n                 total_s(e) += t(e|f)\n             for all words e in e_s\n               for all words f in f_s\n                 count(e|f) += t(e|f) / total_s(e)\n                 total(f)   += t(e|f) / total_s(e)\n           for all f\n             for all e\n               t(e|f) = count(e|f) / total(f)\n        '''\n\n        for iter in range(count):\n\n            countef = {}\n            totalf = {}\n            # set the count of the words to zero\n            for word in self.en_words:\n                if(word not in self.probs):\n                    continue\n\n                word_probs = self.probs[word]\n\n                count = dict([(w, 0) for w in word_probs])\n                countef[word] = count\n                totalf[word] = 0\n\n            self.countef = countef\n\n            self.totalf = totalf\n\n            # NOW iterate over each word pair\n            for (es, ds) in self.sent_pairs:\n                es_split = es.split()\n                ds_split = ds.split()\n\n                for d in ds_split:\n                    self.totals[d] = 0\n                    for e in es_split:\n\n                        if (e not in self.transmissions):\n                            continue\n\n                        e_trans = self.transmissions[e]\n\n                        if (d not in e_trans):\n                            continue\n\n                        self.totals[d] += e_trans[d]\n\n                    # Get count(e|f) and total(f)\n                    for e in es_split:\n                        if(e not in self.transmissions):\n                            continue\n                        if (d not in self.transmissions[e]):\n                            continue\n                        self.countef[e][\n                            d] += self.transmissions[e][d] / self.totals[d]\n                        self.totalf[\n                            e] += self.transmissions[e][d] / self.totals[d]\n\n            for e in self.en_words:\n                if (e not in self.probs):\n                    continue\n                e_prob = self.probs[e]\n                for d in e_prob:\n                    self.transmissions[e][d] = self.countef[\n                        e][d] / self.totalf[e]", "response": "Iterate through all transmissions of english to\n        foreign words and update the internal state of the object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef bind(self):\n\n        HTTPServer.__init__(self, (self.host, self.port), HTTPRequestHandler)\n        self.port = self.server_port", "response": "Bind and activate HTTP server."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreport startup info to stdout.", "response": "def report(self):\n        \"\"\"Report startup info to stdout.\"\"\"\n\n        print(\n            self.report_message.format(\n                service=self.service,\n                host=self.host,\n                port=self.port,\n            )\n        )\n        sys.stdout.flush()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef make_ssl_devcert(base_path, host=None, cn=None):\n    from OpenSSL import crypto\n    if host is not None:\n        cn = '*.%s/CN=%s' % (host, host)\n    cert, pkey = generate_adhoc_ssl_pair(cn=cn)\n\n    cert_file = base_path + '.crt'\n    pkey_file = base_path + '.key'\n\n    with open(cert_file, 'wb') as f:\n        f.write(crypto.dump_certificate(crypto.FILETYPE_PEM, cert))\n    with open(pkey_file, 'wb') as f:\n        f.write(crypto.dump_privatekey(crypto.FILETYPE_PEM, pkey))\n\n    return cert_file, pkey_file", "response": "Creates an SSL certificate and key for development."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load_bytecode(self, f):\n        # make sure the magic header is correct\n        magic = f.read(len(bc_magic))\n        if magic != bc_magic:\n            self.reset()\n            return\n        # the source code of the file changed, we need to reload\n        checksum = pickle.load(f)\n        if self.checksum != checksum:\n            self.reset()\n            return\n        self.code = marshal_load(f)", "response": "Loads bytecode from a file or file like object."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert native Python keyword args to a dictionary of stylesheet parameters.", "response": "def stylesheet_params(**kwargs):\n    \"\"\"Convert keyword args to a dictionary of stylesheet parameters.\n    XSL stylesheet parameters must be XPath expressions, i.e.:\n\n    * string expressions, like \"'5'\"\n    * simple (number) expressions, like \"5\"\n    * valid XPath expressions, like \"/a/b/text()\"\n\n    This function converts native Python keyword arguments to stylesheet\n    parameters following these rules:\n    If an arg is a string wrap it with XSLT.strparam().\n    If an arg is an XPath object use its path string.\n    If arg is None raise TypeError.\n    Else convert arg to string.\n    \"\"\"\n    result = {}\n    for key, val in kwargs.items():\n        if isinstance(val, basestring):\n            val = _etree.XSLT.strparam(val)\n        elif val is None:\n            raise TypeError('None not allowed as a stylesheet parameter')\n        elif not isinstance(val, _etree.XPath):\n            val = unicode(val)\n        result[key] = val\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a copy of paramsDict updated with kwargsDict entries wrapped as stylesheet arguments.", "response": "def _stylesheet_param_dict(paramsDict, kwargsDict):\n    \"\"\"Return a copy of paramsDict, updated with kwargsDict entries, wrapped as\n    stylesheet arguments.\n    kwargsDict entries with a value of None are ignored.\n    \"\"\"\n    # beware of changing mutable default arg\n    paramsDict = dict(paramsDict)\n    for k, v in kwargsDict.items():\n        if v is not None: # None values do not override\n            paramsDict[k] = v\n    paramsDict = stylesheet_params(**paramsDict)\n    return paramsDict"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nextract embedded schematron schema from an XML element.", "response": "def _extract(self, element):\n        \"\"\"Extract embedded schematron schema from non-schematron host schema.\n        This method will only be called by __init__ if the given schema document\n        is not a schematron schema by itself.\n        Must return a schematron schema document tree or None.\n        \"\"\"\n        schematron = None\n        if element.tag == _xml_schema_root:\n            schematron = self._extract_xsd(element)\n        elif element.nsmap[element.prefix] == RELAXNG_NS:\n            # RelaxNG does not have a single unique root element\n            schematron = self._extract_rng(element)\n        return schematron"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_backend_name(self, location):\n        for vc_type in self._registry.values():\n            logger.debug('Checking in %s for %s (%s)...',\n                         location, vc_type.dirname, vc_type.name)\n            path = os.path.join(location, vc_type.dirname)\n            if os.path.exists(path):\n                logger.debug('Determine that %s uses VCS: %s',\n                             location, vc_type.name)\n                return vc_type.name\n        return None", "response": "Return the name of the version control backend if found at given location."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn True if the repository is local.", "response": "def _is_local_repository(self, repo):\n        \"\"\"\n           posix absolute paths start with os.path.sep,\n           win32 ones ones start with drive (like c:\\\\folder)\n        \"\"\"\n        drive, tail = os.path.splitdrive(repo)\n        return repo.startswith(os.path.sep) or drive"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_info(self, location):\n        assert not location.rstrip('/').endswith(self.dirname), \\\n            'Bad directory: %s' % location\n        return self.get_url(location), self.get_revision(location)", "response": "Returns (url, revision), where both are strings"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef unpack(self, location):\n        if os.path.exists(location):\n            rmtree(location)\n        self.obtain(location)", "response": "Unpack the current repository into location."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run_command(self, cmd, show_stdout=True, cwd=None,\n                    raise_on_returncode=True,\n                    command_level=logging.DEBUG, command_desc=None,\n                    extra_environ=None):\n        \"\"\"\n        Run a VCS subcommand\n        This is simply a wrapper around call_subprocess that adds the VCS\n        command name, and checks that the VCS is available\n        \"\"\"\n        cmd = [self.name] + cmd\n        try:\n            return call_subprocess(cmd, show_stdout, cwd,\n                                   raise_on_returncode, command_level,\n                                   command_desc, extra_environ)\n        except OSError as e:\n            # errno.ENOENT = no such file or directory\n            # In other words, the VCS executable isn't available\n            if e.errno == errno.ENOENT:\n                raise BadCommand('Cannot find command %r' % self.name)\n            else:\n                raise", "response": "Run a VCS command"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of tags that are supported by each version specified in versions.", "response": "def get_supported(versions=None):\n    \"\"\"Return a list of supported tags for each version specified in\n    `versions`.\n\n    :param versions: a list of string versions, of the form [\"33\", \"32\"], \n        or None. The first version will be assumed to support our ABI.\n    \"\"\"\n    supported = []\n    \n    # Versions must be given with respect to the preference\n    if versions is None:\n        versions = []\n        major = sys.version_info[0]\n        # Support all previous minor Python versions.\n        for minor in range(sys.version_info[1], -1, -1):\n            versions.append(''.join(map(str, (major, minor))))\n            \n    impl = get_abbr_impl()\n    \n    abis = []\n\n    soabi = sysconfig.get_config_var('SOABI')\n    if soabi and soabi.startswith('cpython-'):\n        abis[0:0] = ['cp' + soabi.split('-', 1)[-1]]\n \n    abi3s = set()\n    import imp\n    for suffix in imp.get_suffixes():\n        if suffix[0].startswith('.abi'):\n            abi3s.add(suffix[0].split('.', 2)[1])\n\n    abis.extend(sorted(list(abi3s)))\n\n    abis.append('none')\n\n    arch = get_platform()\n    \n    # Current version, current API (built specifically for our Python):\n    for abi in abis:\n        supported.append(('%s%s' % (impl, versions[0]), abi, arch))\n            \n    # No abi / arch, but requires our implementation:\n    for i, version in enumerate(versions):\n        supported.append(('%s%s' % (impl, version), 'none', 'any'))\n        if i == 0:\n            # Tagged specifically as being cross-version compatible \n            # (with just the major version specified)\n            supported.append(('%s%s' % (impl, versions[0][0]), 'none', 'any')) \n            \n    # No abi / arch, generic Python\n    for i, version in enumerate(versions):\n        supported.append(('py%s' % (version,), 'none', 'any'))\n        if i == 0:\n            supported.append(('py%s' % (version[0]), 'none', 'any'))\n        \n    return supported"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_host(environ, trusted_hosts=None):\n    if 'HTTP_X_FORWARDED_HOST' in environ:\n        rv = environ['HTTP_X_FORWARDED_HOST'].split(',', 1)[0].strip()\n    elif 'HTTP_HOST' in environ:\n        rv = environ['HTTP_HOST']\n    else:\n        rv = environ['SERVER_NAME']\n        if (environ['wsgi.url_scheme'], environ['SERVER_PORT']) not \\\n           in (('https', '443'), ('http', '80')):\n            rv += ':' + environ['SERVER_PORT']\n    if trusted_hosts is not None:\n        if not host_is_trusted(rv, trusted_hosts):\n            from werkzeug.exceptions import SecurityError\n            raise SecurityError('Host \"%s\" is not trusted' % rv)\n    return rv", "response": "Returns the real host for the given WSGI environment."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef distros_for_location(location, basename, metadata=None):\n    if basename.endswith('.egg.zip'):\n        basename = basename[:-4]    # strip the .zip\n    if basename.endswith('.egg') and '-' in basename:\n        # only one, unambiguous interpretation\n        return [Distribution.from_location(location, basename, metadata)]\n    if basename.endswith('.exe'):\n        win_base, py_ver, platform = parse_bdist_wininst(basename)\n        if win_base is not None:\n            return interpret_distro_name(\n                location, win_base, metadata, py_ver, BINARY_DIST, platform\n            )\n    # Try source distro extensions (.zip, .tgz, etc.)\n    #\n    for ext in EXTENSIONS:\n        if basename.endswith(ext):\n            basename = basename[:-len(ext)]\n            return interpret_distro_name(location, basename, metadata)\n    return []", "response": "Yields a list of distributions for a given location."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find_external_links(url, page):\n\n    for match in REL.finditer(page):\n        tag, rel = match.groups()\n        rels = set(map(str.strip, rel.lower().split(',')))\n        if 'homepage' in rels or 'download' in rels:\n            for match in HREF.finditer(tag):\n                yield urljoin(url, htmldecode(match.group(1)))\n\n    for tag in (\"<th>Home Page\", \"<th>Download URL\"):\n        pos = page.find(tag)\n        if pos!=-1:\n            match = HREF.search(page,pos)\n            if match:\n                yield urljoin(url, htmldecode(match.group(1)))", "response": "Find external links in page yielding URLs"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _encode_auth(auth):\n    auth_s = unquote(auth)\n    # convert to bytes\n    auth_bytes = auth_s.encode()\n    # use the legacy interface for Python 2.3 support\n    encoded_bytes = base64.encodestring(auth_bytes)\n    # convert back to a string\n    encoded = encoded_bytes.decode()\n    # strip the trailing carriage return\n    return encoded.replace('\\n','')", "response": "Encode auth string into base64 encoded string."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef local_open(url):\n    scheme, server, path, param, query, frag = urlparse(url)\n    filename = url2pathname(path)\n    if os.path.isfile(filename):\n        return urllib2.urlopen(url)\n    elif path.endswith('/') and os.path.isdir(filename):\n        files = []\n        for f in os.listdir(filename):\n            if f=='index.html':\n                with open(os.path.join(filename,f),'r') as fp:\n                    body = fp.read()\n                break\n            elif os.path.isdir(os.path.join(filename,f)):\n                f+='/'\n            files.append(\"<a href=%r>%s</a>\" % (f,f))\n        else:\n            body = (\"<html><head><title>%s</title>\" % url) + \\\n                \"</head><body>%s</body></html>\" % '\\n'.join(files)\n        status, message = 200, \"OK\"\n    else:\n        status, message, body = 404, \"Path not found\", \"Not found\"\n\n    headers = {'content-type': 'text/html'}\n    return HTTPError(url, status, message, headers, StringIO(body))", "response": "Open a local path with special support for files and directories"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef from_url(cls, url):\n        \"Construct a (possibly null) ContentChecker from a URL\"\n        fragment = urlparse(url)[-1]\n        if not fragment:\n            return ContentChecker()\n        match = cls.pattern.search(fragment)\n        if not match:\n            return ContentChecker()\n        return cls(**match.groupdict())", "response": "Construct a ( possibly null ) ContentChecker from a URL"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nevaluate a URL and process it", "response": "def process_url(self, url, retrieve=False):\n        \"\"\"Evaluate a URL as a possible download, and maybe retrieve it\"\"\"\n        if url in self.scanned_urls and not retrieve:\n            return\n        self.scanned_urls[url] = True\n        if not URL_SCHEME(url):\n            self.process_filename(url)\n            return\n        else:\n            dists = list(distros_for_url(url))\n            if dists:\n                if not self.url_ok(url):\n                    return\n                self.debug(\"Found link: %s\", url)\n\n        if dists or not retrieve or url in self.fetched_urls:\n            list(map(self.add, dists))\n            return  # don't need the actual page\n\n        if not self.url_ok(url):\n            self.fetched_urls[url] = True\n            return\n\n        self.info(\"Reading %s\", url)\n        self.fetched_urls[url] = True   # prevent multiple fetch attempts\n        f = self.open_url(url, \"Download error on %s: %%s -- Some packages may not be found!\" % url)\n        if f is None: return\n        self.fetched_urls[f.url] = True\n        if 'html' not in f.headers.get('content-type', '').lower():\n            f.close()   # not html, we can't process it\n            return\n\n        base = f.url     # handle redirects\n        page = f.read()\n        if not isinstance(page, str): # We are in Python 3 and got bytes. We want str.\n            if isinstance(f, HTTPError):\n                # Errors have no charset, assume latin1:\n                charset = 'latin-1'\n            else:\n                charset = f.headers.get_param('charset') or 'latin-1'\n            page = page.decode(charset, \"ignore\")\n        f.close()\n        for match in HREF.finditer(page):\n            link = urljoin(base, htmldecode(match.group(1)))\n            self.process_url(link)\n        if url.startswith(self.index_url) and getattr(f,'code',None)!=404:\n            page = self.process_index(url, page)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_supported(versions=None, noarch=False):\n    supported = []\n\n    # Versions must be given with respect to the preference\n    if versions is None:\n        versions = []\n        major = sys.version_info[0]\n        # Support all previous minor Python versions.\n        for minor in range(sys.version_info[1], -1, -1):\n            versions.append(''.join(map(str, (major, minor))))\n\n    impl = get_abbr_impl()\n\n    abis = []\n\n    try:\n        soabi = sysconfig.get_config_var('SOABI')\n    except IOError as e:  # Issue #1074\n        warnings.warn(\"{0}\".format(e), RuntimeWarning)\n        soabi = None\n\n    if soabi and soabi.startswith('cpython-'):\n        abis[0:0] = ['cp' + soabi.split('-', 1)[-1]]\n\n    abi3s = set()\n    import imp\n    for suffix in imp.get_suffixes():\n        if suffix[0].startswith('.abi'):\n            abi3s.add(suffix[0].split('.', 2)[1])\n\n    abis.extend(sorted(list(abi3s)))\n\n    abis.append('none')\n\n    if not noarch:\n        arch = get_platform()\n        if sys.platform == 'darwin':\n            # support macosx-10.6-intel on macosx-10.9-x86_64\n            match = _osx_arch_pat.match(arch)\n            if match:\n                name, major, minor, actual_arch = match.groups()\n                actual_arches = [actual_arch]\n                if actual_arch in ('i386', 'ppc'):\n                    actual_arches.append('fat')\n                if actual_arch in ('i386', 'x86_64'):\n                    actual_arches.append('intel')\n                if actual_arch in ('i386', 'ppc', 'x86_64'):\n                    actual_arches.append('fat3')\n                if actual_arch in ('ppc64', 'x86_64'):\n                    actual_arches.append('fat64')\n                if actual_arch in ('i386', 'x86_64', 'intel', 'ppc', 'ppc64'):\n                    actual_arches.append('universal')\n                tpl = '{0}_{1}_%i_%s'.format(name, major)\n                arches = []\n                for m in range(int(minor) + 1):\n                    for a in actual_arches:\n                        arches.append(tpl % (m, a))\n            else:\n                # arch pattern didn't match (?!)\n                arches = [arch]\n        else:\n            arches = [arch]\n\n        # Current version, current API (built specifically for our Python):\n        for abi in abis:\n            for arch in arches:\n                supported.append(('%s%s' % (impl, versions[0]), abi, arch))\n\n        # Has binaries, does not use the Python API:\n        supported.append(('py%s' % (versions[0][0]), 'none', arch))\n\n    # No abi / arch, but requires our implementation:\n    for i, version in enumerate(versions):\n        supported.append(('%s%s' % (impl, version), 'none', 'any'))\n        if i == 0:\n            # Tagged specifically as being cross-version compatible\n            # (with just the major version specified)\n            supported.append(('%s%s' % (impl, versions[0][0]), 'none', 'any'))\n\n    # No abi / arch, generic Python\n    for i, version in enumerate(versions):\n        supported.append(('py%s' % (version,), 'none', 'any'))\n        if i == 0:\n            supported.append(('py%s' % (version[0]), 'none', 'any'))\n\n    return supported", "response": "Return a list of supported tags for each version specified in versions."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove duplicate entries from sys. path along with making them absolute.", "response": "def removeduppaths():\n    \"\"\" Remove duplicate entries from sys.path along with making them\n    absolute\"\"\"\n    # This ensures that the initial path provided by the interpreter contains\n    # only absolute pathnames, even if we're running from the build directory.\n    L = []\n    known_paths = set()\n    for dir in sys.path:\n        # Filter out duplicate paths (on case-insensitive file systems also\n        # if they only differ in case); turn relative paths into absolute\n        # paths.\n        dir, dircase = makepath(dir)\n        if not dircase in known_paths:\n            L.append(dir)\n            known_paths.add(dircase)\n    sys.path[:] = L\n    return known_paths"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef addbuilddir():\n    from distutils.util import get_platform\n    s = \"build/lib.%s-%.3s\" % (get_platform(), sys.version)\n    if hasattr(sys, 'gettotalrefcount'):\n        s += '-pydebug'\n    s = os.path.join(os.path.dirname(sys.path[-1]), s)\n    sys.path.append(s)", "response": "Append. build. lib. <platform > in case we re running in the build dir"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a set containing all existing directory entries from sys. path", "response": "def _init_pathinfo():\n    \"\"\"Return a set containing all existing directory entries from sys.path\"\"\"\n    d = set()\n    for dir in sys.path:\n        try:\n            if os.path.isdir(dir):\n                dir, dircase = makepath(dir)\n                d.add(dircase)\n        except TypeError:\n            continue\n    return d"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef addpackage(sitedir, name, known_paths):\n    if known_paths is None:\n        _init_pathinfo()\n        reset = 1\n    else:\n        reset = 0\n    fullname = os.path.join(sitedir, name)\n    try:\n        f = open(fullname, \"rU\")\n    except IOError:\n        return\n    try:\n        for line in f:\n            if line.startswith(\"#\"):\n                continue\n            if line.startswith(\"import\"):\n                exec(line)\n                continue\n            line = line.rstrip()\n            dir, dircase = makepath(sitedir, line)\n            if not dircase in known_paths and os.path.exists(dir):\n                sys.path.append(dir)\n                known_paths.add(dircase)\n    finally:\n        f.close()\n    if reset:\n        known_paths = None\n    return known_paths", "response": "Add a new path to known_paths by combining sitedir and name or execute it if it starts with import"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef addsitedir(sitedir, known_paths=None):\n    if known_paths is None:\n        known_paths = _init_pathinfo()\n        reset = 1\n    else:\n        reset = 0\n    sitedir, sitedircase = makepath(sitedir)\n    if not sitedircase in known_paths:\n        sys.path.append(sitedir)        # Add path component\n    try:\n        names = os.listdir(sitedir)\n    except os.error:\n        return\n    names.sort()\n    for name in names:\n        if name.endswith(os.extsep + \"pth\"):\n            addpackage(sitedir, name, known_paths)\n    if reset:\n        known_paths = None\n    return known_paths", "response": "Add the path of the given directory to sys. path if it doesn t already exist."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef addsitepackages(known_paths, sys_prefix=sys.prefix, exec_prefix=sys.exec_prefix):\n    prefixes = [os.path.join(sys_prefix, \"local\"), sys_prefix]\n    if exec_prefix != sys_prefix:\n        prefixes.append(os.path.join(exec_prefix, \"local\"))\n\n    for prefix in prefixes:\n        if prefix:\n            if sys.platform in ('os2emx', 'riscos') or _is_jython:\n                sitedirs = [os.path.join(prefix, \"Lib\", \"site-packages\")]\n            elif _is_pypy:\n                sitedirs = [os.path.join(prefix, 'site-packages')]\n            elif sys.platform == 'darwin' and prefix == sys_prefix:\n\n                if prefix.startswith(\"/System/Library/Frameworks/\"): # Apple's Python\n\n                    sitedirs = [os.path.join(\"/Library/Python\", sys.version[:3], \"site-packages\"),\n                                os.path.join(prefix, \"Extras\", \"lib\", \"python\")]\n\n                else: # any other Python distros on OSX work this way\n                    sitedirs = [os.path.join(prefix, \"lib\",\n                                             \"python\" + sys.version[:3], \"site-packages\")]\n\n            elif os.sep == '/':\n                sitedirs = [os.path.join(prefix,\n                                         \"lib\",\n                                         \"python\" + sys.version[:3],\n                                         \"site-packages\"),\n                            os.path.join(prefix, \"lib\", \"site-python\"),\n                            os.path.join(prefix, \"python\" + sys.version[:3], \"lib-dynload\")]\n                lib64_dir = os.path.join(prefix, \"lib64\", \"python\" + sys.version[:3], \"site-packages\")\n                if (os.path.exists(lib64_dir) and\n                    os.path.realpath(lib64_dir) not in [os.path.realpath(p) for p in sitedirs]):\n                    if _is_64bit:\n                        sitedirs.insert(0, lib64_dir)\n                    else:\n                        sitedirs.append(lib64_dir)\n                try:\n                    # sys.getobjects only available in --with-pydebug build\n                    sys.getobjects\n                    sitedirs.insert(0, os.path.join(sitedirs[0], 'debug'))\n                except AttributeError:\n                    pass\n                # Debian-specific dist-packages directories:\n                sitedirs.append(os.path.join(prefix, \"local/lib\",\n                                             \"python\" + sys.version[:3],\n                                             \"dist-packages\"))\n                if sys.version[0] == '2':\n                    sitedirs.append(os.path.join(prefix, \"lib\",\n                                                 \"python\" + sys.version[:3],\n                                                 \"dist-packages\"))\n                else:\n                    sitedirs.append(os.path.join(prefix, \"lib\",\n                                                 \"python\" + sys.version[0],\n                                                 \"dist-packages\"))\n                sitedirs.append(os.path.join(prefix, \"lib\", \"dist-python\"))\n            else:\n                sitedirs = [prefix, os.path.join(prefix, \"lib\", \"site-packages\")]\n            if sys.platform == 'darwin':\n                # for framework builds *only* we add the standard Apple\n                # locations. Currently only per-user, but /Library and\n                # /Network/Library could be added too\n                if 'Python.framework' in prefix:\n                    home = os.environ.get('HOME')\n                    if home:\n                        sitedirs.append(\n                            os.path.join(home,\n                                         'Library',\n                                         'Python',\n                                         sys.version[:3],\n                                         'site-packages'))\n            for sitedir in sitedirs:\n                if os.path.isdir(sitedir):\n                    addsitedir(sitedir, known_paths)\n    return None", "response": "Add site - packages and possibly site - python to sys. path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if the user site directory is safe for inclusion.", "response": "def check_enableusersite():\n    \"\"\"Check if user site directory is safe for inclusion\n\n    The function tests for the command line flag (including environment var),\n    process uid/gid equal to effective uid/gid.\n\n    None: Disabled for security reasons\n    False: Disabled by user (command line option)\n    True: Safe and enabled\n    \"\"\"\n    if hasattr(sys, 'flags') and getattr(sys.flags, 'no_user_site', False):\n        return False\n\n    if hasattr(os, \"getuid\") and hasattr(os, \"geteuid\"):\n        # check process uid == effective uid\n        if os.geteuid() != os.getuid():\n            return None\n    if hasattr(os, \"getgid\") and hasattr(os, \"getegid\"):\n        # check process gid == effective gid\n        if os.getegid() != os.getgid():\n            return None\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a per user site - package to sys. path.", "response": "def addusersitepackages(known_paths):\n    \"\"\"Add a per user site-package to sys.path\n\n    Each user has its own python directory with site-packages in the\n    home directory.\n\n    USER_BASE is the root directory for all Python versions\n\n    USER_SITE is the user specific site-packages directory\n\n    USER_SITE/.. can be used for data.\n    \"\"\"\n    global USER_BASE, USER_SITE, ENABLE_USER_SITE\n    env_base = os.environ.get(\"PYTHONUSERBASE\", None)\n\n    def joinuser(*args):\n        return os.path.expanduser(os.path.join(*args))\n\n    #if sys.platform in ('os2emx', 'riscos'):\n    #    # Don't know what to put here\n    #    USER_BASE = ''\n    #    USER_SITE = ''\n    if os.name == \"nt\":\n        base = os.environ.get(\"APPDATA\") or \"~\"\n        if env_base:\n            USER_BASE = env_base\n        else:\n            USER_BASE = joinuser(base, \"Python\")\n        USER_SITE = os.path.join(USER_BASE,\n                                 \"Python\" + sys.version[0] + sys.version[2],\n                                 \"site-packages\")\n    else:\n        if env_base:\n            USER_BASE = env_base\n        else:\n            USER_BASE = joinuser(\"~\", \".local\")\n        USER_SITE = os.path.join(USER_BASE, \"lib\",\n                                 \"python\" + sys.version[:3],\n                                 \"site-packages\")\n\n    if ENABLE_USER_SITE and os.path.isdir(USER_SITE):\n        addsitedir(USER_SITE, known_paths)\n    if ENABLE_USER_SITE:\n        for dist_libdir in (\"lib\", \"local/lib\"):\n            user_site = os.path.join(USER_BASE, dist_libdir,\n                                     \"python\" + sys.version[:3],\n                                     \"dist-packages\")\n            if os.path.isdir(user_site):\n                addsitedir(user_site, known_paths)\n    return known_paths"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the environment variable BEGINLIBPATH to the path where the DLLs are located.", "response": "def setBEGINLIBPATH():\n    \"\"\"The OS/2 EMX port has optional extension modules that do double duty\n    as DLLs (and must use the .DLL file extension) for other extensions.\n    The library search path needs to be amended so these will be found\n    during module import.  Use BEGINLIBPATH so that these are at the start\n    of the library search path.\n\n    \"\"\"\n    dllpath = os.path.join(sys.prefix, \"Lib\", \"lib-dynload\")\n    libpath = os.environ['BEGINLIBPATH'].split(';')\n    if libpath[-1]:\n        libpath.append(dllpath)\n    else:\n        libpath[-1] = dllpath\n    os.environ['BEGINLIBPATH'] = ';'.join(libpath)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndefine new built - ins quit and exit.", "response": "def setquit():\n    \"\"\"Define new built-ins 'quit' and 'exit'.\n    These are simply strings that display a hint on how to exit.\n\n    \"\"\"\n    if os.sep == ':':\n        eof = 'Cmd-Q'\n    elif os.sep == '\\\\':\n        eof = 'Ctrl-Z plus Return'\n    else:\n        eof = 'Ctrl-D (i.e. EOF)'\n\n    class Quitter(object):\n        def __init__(self, name):\n            self.name = name\n        def __repr__(self):\n            return 'Use %s() or %s to exit' % (self.name, eof)\n        def __call__(self, code=None):\n            # Shells like IDLE catch the SystemExit, but listen when their\n            # stdin wrapper is closed.\n            try:\n                sys.stdin.close()\n            except:\n                pass\n            raise SystemExit(code)\n    builtins.quit = Quitter('quit')\n    builtins.exit = Quitter('exit')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting copyright and credits in __builtin__.", "response": "def setcopyright():\n    \"\"\"Set 'copyright' and 'credits' in __builtin__\"\"\"\n    builtins.copyright = _Printer(\"copyright\", sys.copyright)\n    if _is_jython:\n        builtins.credits = _Printer(\n            \"credits\",\n            \"Jython is maintained by the Jython developers (www.jython.org).\")\n    elif _is_pypy:\n        builtins.credits = _Printer(\n            \"credits\",\n            \"PyPy is maintained by the PyPy developers: http://pypy.org/\")\n    else:\n        builtins.credits = _Printer(\"credits\", \"\"\"\\\n    Thanks to CWI, CNRI, BeOpen.com, Zope Corporation and a cast of thousands\n    for supporting Python development.  See www.python.org for more information.\"\"\")\n    here = os.path.dirname(os.__file__)\n    builtins.license = _Printer(\n        \"license\", \"See http://www.python.org/%.3s/license.html\" % sys.version,\n        [\"LICENSE.txt\", \"LICENSE\"],\n        [os.path.join(here, os.pardir), here, os.curdir])"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\naliases the default encodings of the current locale to the mbcs encoding.", "response": "def aliasmbcs():\n    \"\"\"On Windows, some default encodings are not provided by Python,\n    while they are always available as \"mbcs\" in each locale. Make\n    them usable by aliasing to \"mbcs\" in such a case.\"\"\"\n    if sys.platform == 'win32':\n        import locale, codecs\n        enc = locale.getdefaultlocale()[1]\n        if enc.startswith('cp'):            # \"cp***\" ?\n            try:\n                codecs.lookup(enc)\n            except LookupError:\n                import encodings\n                encodings._cache[enc] = encodings._unknown\n                encodings.aliases.aliases[enc] = 'mbcs'"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef setencoding():\n    encoding = \"ascii\" # Default value set by _PyUnicode_Init()\n    if 0:\n        # Enable to support locale aware default string encodings.\n        import locale\n        loc = locale.getdefaultlocale()\n        if loc[1]:\n            encoding = loc[1]\n    if 0:\n        # Enable to switch off string to Unicode coercion and implicit\n        # Unicode to string conversion.\n        encoding = \"undefined\"\n    if encoding != \"ascii\":\n        # On Non-Unicode builds this will raise an AttributeError...\n        sys.setdefaultencoding(encoding)", "response": "Set the string encoding used by Unicode implementation."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nforces easy_installed eggs in the global environment to get placed in sys. path after all local site packages inside the virtualenv.", "response": "def force_global_eggs_after_local_site_packages():\n    \"\"\"\n    Force easy_installed eggs in the global environment to get placed\n    in sys.path after all packages inside the virtualenv.  This\n    maintains the \"least surprise\" result that packages in the\n    virtualenv always mask global packages, never the other way\n    around.\n\n    \"\"\"\n    egginsert = getattr(sys, '__egginsert', 0)\n    for i, path in enumerate(sys.path):\n        if i > egginsert and path.startswith(sys.prefix):\n            egginsert = i\n    sys.__egginsert = egginsert + 1"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadjust the special classpath sys. path entries for Jython.", "response": "def fixclasspath():\n    \"\"\"Adjust the special classpath sys.path entries for Jython. These\n    entries should follow the base virtualenv lib directories.\n    \"\"\"\n    paths = []\n    classpaths = []\n    for path in sys.path:\n        if path == '__classpath__' or path.startswith('__pyclasspath__'):\n            classpaths.append(path)\n        else:\n            paths.append(path)\n    sys.path = paths\n    sys.path.extend(classpaths)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef Popen_nonblocking(*args, **kwargs):\n\tkwargs.setdefault('close_fds', 'posix' in sys.builtin_module_names)\n\tkwargs.setdefault('bufsize', 1)\n\tproc = subprocess.Popen(*args, **kwargs)\n\tif proc.stdout:\n\t\tq = queue.Queue()\n\t\tt = threading.Thread(\n\t\t\ttarget=enqueue_lines,\n\t\t\targs=(proc.stdout, q))\n\t\tproc.stdout = q\n\t\t# thread dies with the parent\n\t\tt.daemon = True\n\t\tt.start()\n\tif proc.stderr:\n\t\tq = queue.Queue()\n\t\tt = threading.Thread(\n\t\t\ttarget=enqueue_lines,\n\t\t\targs=(proc.stderr, q))\n\t\tproc.stderr = q\n\t\tt.daemon = True\n\t\tt.start()\n\treturn proc", "response": "Return a subprocess handle with any wcsdb output streams replaced by queues of lines from that stream."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns True if Cython or Pyrex can be imported.", "response": "def have_pyrex():\n    \"\"\"\n    Return True if Cython or Pyrex can be imported.\n    \"\"\"\n    pyrex_impls = 'Cython.Distutils.build_ext', 'Pyrex.Distutils.build_ext'\n    for pyrex_impl in pyrex_impls:\n        try:\n            # from (pyrex_impl) import build_ext\n            __import__(pyrex_impl, fromlist=['build_ext']).build_ext\n            return True\n        except Exception:\n            pass\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _convert_pyx_sources_to_lang(self):\n        if have_pyrex():\n            # the build has Cython, so allow it to compile the .pyx files\n            return\n        lang = self.language or ''\n        target_ext = '.cpp' if lang.lower() == 'c++' else '.c'\n        sub = functools.partial(re.sub, '.pyx$', target_ext)\n        self.sources = list(map(sub, self.sources))", "response": "Replace sources with. pyx extensions to sources with the target\n        language extension."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrun the application and conserve the traceback frames.", "response": "def debug_application(self, environ, start_response):\n        \"\"\"Run the application and conserve the traceback frames.\"\"\"\n        app_iter = None\n        try:\n            app_iter = self.app(environ, start_response)\n            for item in app_iter:\n                yield item\n            if hasattr(app_iter, 'close'):\n                app_iter.close()\n        except Exception:\n            if hasattr(app_iter, 'close'):\n                app_iter.close()\n            traceback = get_current_traceback(skip=1, show_hidden_frames=\n                                              self.show_hidden_frames,\n                                              ignore_system_exceptions=True)\n            for frame in traceback.frames:\n                self.frames[frame.id] = frame\n            self.tracebacks[traceback.id] = traceback\n\n            try:\n                start_response('500 INTERNAL SERVER ERROR', [\n                    ('Content-Type', 'text/html; charset=utf-8'),\n                    # Disable Chrome's XSS protection, the debug\n                    # output can cause false-positives.\n                    ('X-XSS-Protection', '0'),\n                ])\n            except Exception:\n                # if we end up here there has been output but an error\n                # occurred.  in that situation we can do nothing fancy any\n                # more, better log something into the error log and fall\n                # back gracefully.\n                environ['wsgi.errors'].write(\n                    'Debugging middleware caught exception in streamed '\n                    'response at a point where response headers were already '\n                    'sent.\\n')\n            else:\n                yield traceback.render_full(evalex=self.evalex,\n                                            secret=self.secret) \\\n                               .encode('utf-8', 'replace')\n\n            traceback.log(environ['wsgi.errors'])"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a static resource from the shared folder.", "response": "def get_resource(self, request, filename):\n        \"\"\"Return a static resource from the shared folder.\"\"\"\n        filename = join(dirname(__file__), 'shared', basename(filename))\n        if isfile(filename):\n            mimetype = mimetypes.guess_type(filename)[0] \\\n                or 'application/octet-stream'\n            f = open(filename, 'rb')\n            try:\n                return Response(f.read(), mimetype=mimetype)\n            finally:\n                f.close()\n        return Response('Not Found', status=404)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef user_agent():\n    data = {\n        \"installer\": {\"name\": \"pip\", \"version\": pip.__version__},\n        \"python\": platform.python_version(),\n        \"implementation\": {\n            \"name\": platform.python_implementation(),\n        },\n    }\n\n    if data[\"implementation\"][\"name\"] == 'CPython':\n        data[\"implementation\"][\"version\"] = platform.python_version()\n    elif data[\"implementation\"][\"name\"] == 'PyPy':\n        if sys.pypy_version_info.releaselevel == 'final':\n            pypy_version_info = sys.pypy_version_info[:3]\n        else:\n            pypy_version_info = sys.pypy_version_info\n        data[\"implementation\"][\"version\"] = \".\".join(\n            [str(x) for x in pypy_version_info]\n        )\n    elif data[\"implementation\"][\"name\"] == 'Jython':\n        # Complete Guess\n        data[\"implementation\"][\"version\"] = platform.python_version()\n    elif data[\"implementation\"][\"name\"] == 'IronPython':\n        # Complete Guess\n        data[\"implementation\"][\"version\"] = platform.python_version()\n\n    if sys.platform.startswith(\"linux\"):\n        distro = dict(filter(\n            lambda x: x[1],\n            zip([\"name\", \"version\", \"id\"], platform.linux_distribution()),\n        ))\n        libc = dict(filter(\n            lambda x: x[1],\n            zip([\"lib\", \"version\"], platform.libc_ver()),\n        ))\n        if libc:\n            distro[\"libc\"] = libc\n        if distro:\n            data[\"distro\"] = distro\n\n    if sys.platform.startswith(\"darwin\") and platform.mac_ver()[0]:\n        data[\"distro\"] = {\"name\": \"OS X\", \"version\": platform.mac_ver()[0]}\n\n    if platform.system():\n        data.setdefault(\"system\", {})[\"name\"] = platform.system()\n\n    if platform.release():\n        data.setdefault(\"system\", {})[\"release\"] = platform.release()\n\n    if platform.machine():\n        data[\"cpu\"] = platform.machine()\n\n    return \"{data[installer][name]}/{data[installer][version]} {json}\".format(\n        data=data,\n        json=json.dumps(data, separators=(\",\", \":\"), sort_keys=True),\n    )", "response": "Return a string representing the user agent."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the content of a file.", "response": "def get_file_content(url, comes_from=None, session=None):\n    \"\"\"Gets the content of a file; it may be a filename, file: URL, or\n    http: URL.  Returns (location, content).  Content is unicode.\"\"\"\n    if session is None:\n        raise TypeError(\n            \"get_file_content() missing 1 required keyword argument: 'session'\"\n        )\n\n    match = _scheme_re.search(url)\n    if match:\n        scheme = match.group(1).lower()\n        if (scheme == 'file' and comes_from and\n                comes_from.startswith('http')):\n            raise InstallationError(\n                'Requirements file %s references URL %s, which is local'\n                % (comes_from, url))\n        if scheme == 'file':\n            path = url.split(':', 1)[1]\n            path = path.replace('\\\\', '/')\n            match = _url_slash_drive_re.match(path)\n            if match:\n                path = match.group(1) + ':' + path.split('|', 1)[1]\n            path = urllib_parse.unquote(path)\n            if path.startswith('/'):\n                path = '/' + path.lstrip('/')\n            url = path\n        else:\n            # FIXME: catch some errors\n            resp = session.get(url)\n            resp.raise_for_status()\n\n            if six.PY3:\n                return resp.url, resp.text\n            else:\n                return resp.url, resp.content\n    try:\n        with open(url) as f:\n            content = f.read()\n    except IOError as exc:\n        raise InstallationError(\n            'Could not open requirements file: %s' % str(exc)\n        )\n    return url, content"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning true if the name looks like a URL", "response": "def is_url(name):\n    \"\"\"Returns true if the name looks like a URL\"\"\"\n    if ':' not in name:\n        return False\n    scheme = name.split(':', 1)[0].lower()\n    return scheme in ['http', 'https', 'file', 'ftp'] + vcs.all_schemes"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef unpack_file_url(link, location, download_dir=None):\n\n    link_path = url_to_path(link.url_without_fragment)\n\n    # If it's a url to a local directory\n    if os.path.isdir(link_path):\n        if os.path.isdir(location):\n            rmtree(location)\n        shutil.copytree(link_path, location, symlinks=True)\n        if download_dir:\n            logger.info('Link is a directory, ignoring download_dir')\n        return\n\n    # if link has a hash, let's confirm it matches\n    if link.hash:\n        link_path_hash = _get_hash_from_file(link_path, link)\n        _check_hash(link_path_hash, link)\n\n    # If a download dir is specified, is the file already there and valid?\n    already_downloaded_path = None\n    if download_dir:\n        already_downloaded_path = _check_download_dir(link, download_dir)\n\n    if already_downloaded_path:\n        from_path = already_downloaded_path\n    else:\n        from_path = link_path\n\n    content_type = mimetypes.guess_type(from_path)[0]\n\n    # unpack the archive to the build dir location. even when only downloading\n    # archives, they have to be unpacked to parse dependencies\n    unpack_file(from_path, location, content_type, link)\n\n    # a download dir is specified and not already downloaded\n    if download_dir and not already_downloaded_path:\n        _copy_file(from_path, download_dir, content_type, link)", "response": "Unpack a link into the build dir location."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndownloading a link url into temp_dir using provided session", "response": "def _download_http_url(link, session, temp_dir):\n    \"\"\"Download link url into temp_dir using provided session\"\"\"\n    target_url = link.url.split('#', 1)[0]\n    try:\n        resp = session.get(\n            target_url,\n            # We use Accept-Encoding: identity here because requests\n            # defaults to accepting compressed responses. This breaks in\n            # a variety of ways depending on how the server is configured.\n            # - Some servers will notice that the file isn't a compressible\n            #   file and will leave the file alone and with an empty\n            #   Content-Encoding\n            # - Some servers will notice that the file is already\n            #   compressed and will leave the file alone and will add a\n            #   Content-Encoding: gzip header\n            # - Some servers won't notice anything at all and will take\n            #   a file that's already been compressed and compress it again\n            #   and set the Content-Encoding: gzip header\n            # By setting this to request only the identity encoding We're\n            # hoping to eliminate the third case. Hopefully there does not\n            # exist a server which when given a file will notice it is\n            # already compressed and that you're not asking for a\n            # compressed file and will then decompress it before sending\n            # because if that's the case I don't think it'll ever be\n            # possible to make this work.\n            headers={\"Accept-Encoding\": \"identity\"},\n            stream=True,\n        )\n        resp.raise_for_status()\n    except requests.HTTPError as exc:\n        logger.critical(\n            \"HTTP error %s while getting %s\", exc.response.status_code, link,\n        )\n        raise\n\n    content_type = resp.headers.get('content-type', '')\n    filename = link.filename  # fallback\n    # Have a look at the Content-Disposition header for a better guess\n    content_disposition = resp.headers.get('content-disposition')\n    if content_disposition:\n        type, params = cgi.parse_header(content_disposition)\n        # We use ``or`` here because we don't want to use an \"empty\" value\n        # from the filename param.\n        filename = params.get('filename') or filename\n    ext = splitext(filename)[1]\n    if not ext:\n        ext = mimetypes.guess_extension(content_type)\n        if ext:\n            filename += ext\n    if not ext and link.url != resp.url:\n        ext = os.path.splitext(resp.url)[1]\n        if ext:\n            filename += ext\n    file_path = os.path.join(temp_dir, filename)\n    with open(file_path, 'wb') as content_file:\n        _download_url(resp, link, content_file)\n    return file_path, content_type"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _check_download_dir(link, download_dir):\n    download_path = os.path.join(download_dir, link.filename)\n    if os.path.exists(download_path):\n        # If already downloaded, does its hash match?\n        logger.info('File was already downloaded %s', download_path)\n        if link.hash:\n            download_hash = _get_hash_from_file(download_path, link)\n            try:\n                _check_hash(download_hash, link)\n            except HashMismatch:\n                logger.warning(\n                    'Previously-downloaded file %s has bad hash, '\n                    're-downloading.',\n                    download_path\n                )\n                os.unlink(download_path)\n                return None\n        return download_path\n    return None", "response": "Check download_dir for previously downloaded file with correct hash and return its path else None."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nhandles currency format subdirectives.", "response": "def currencyFormat(_context, code, symbol, format,\n                       currency_digits=True, decimal_quantization=True,\n                       name=''):\n        \"\"\"Handle currencyFormat subdirectives.\"\"\"\n        _context.action(\n            discriminator=('currency', name, code),\n            callable=_register_currency,\n            args=(name, code, symbol, format, currency_digits,\n                  decimal_quantization)\n            )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef print_results(distributions, list_all_files):\n    results_printed = False\n    for dist in distributions:\n        results_printed = True\n        logger.info(\"---\")\n        logger.info(\"Metadata-Version: %s\" % dist.get('metadata-version'))\n        logger.info(\"Name: %s\" % dist['name'])\n        logger.info(\"Version: %s\" % dist['version'])\n        logger.info(\"Summary: %s\" % dist.get('summary'))\n        logger.info(\"Home-page: %s\" % dist.get('home-page'))\n        logger.info(\"Author: %s\" % dist.get('author'))\n        logger.info(\"Author-email: %s\" % dist.get('author-email'))\n        logger.info(\"License: %s\" % dist.get('license'))\n        logger.info(\"Location: %s\" % dist['location'])\n        logger.info(\"Requires: %s\" % ', '.join(dist['requires']))\n        if list_all_files:\n            logger.info(\"Files:\")\n            if dist['files'] is not None:\n                for line in dist['files']:\n                    logger.info(\"  %s\" % line.strip())\n            else:\n                logger.info(\"Cannot locate installed-files.txt\")\n        if 'entry_points' in dist:\n            logger.info(\"Entry-points:\")\n            for line in dist['entry_points']:\n                logger.info(\"  %s\" % line.strip())\n    return results_printed", "response": "Print the informations from installed distributions found."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndecode the data passed in and potentially flush the decoder.", "response": "def _decode(self, data, decode_content, flush_decoder):\n        \"\"\"\n        Decode the data passed in and potentially flush the decoder.\n        \"\"\"\n        try:\n            if decode_content and self._decoder:\n                data = self._decoder.decompress(data)\n        except (IOError, zlib.error) as e:\n            content_encoding = self.headers.get('content-encoding', '').lower()\n            raise DecodeError(\n                \"Received response with content-encoding: %s, but \"\n                \"failed to decode it.\" % content_encoding, e)\n\n        if flush_decoder and decode_content and self._decoder:\n            buf = self._decoder.decompress(binary_type())\n            data += buf + self._decoder.flush()\n\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read(self, amt=None, decode_content=None, cache_content=False):\n        self._init_decoder()\n        if decode_content is None:\n            decode_content = self.decode_content\n\n        if self._fp is None:\n            return\n\n        flush_decoder = False\n\n        try:\n            try:\n                if amt is None:\n                    # cStringIO doesn't like amt=None\n                    data = self._fp.read()\n                    flush_decoder = True\n                else:\n                    cache_content = False\n                    data = self._fp.read(amt)\n                    if amt != 0 and not data:  # Platform-specific: Buggy versions of Python.\n                        # Close the connection when no data is returned\n                        #\n                        # This is redundant to what httplib/http.client _should_\n                        # already do.  However, versions of python released before\n                        # December 15, 2012 (http://bugs.python.org/issue16298) do\n                        # not properly close the connection in all cases. There is\n                        # no harm in redundantly calling close.\n                        self._fp.close()\n                        flush_decoder = True\n\n            except SocketTimeout:\n                # FIXME: Ideally we'd like to include the url in the ReadTimeoutError but\n                # there is yet no clean way to get at it from this context.\n                raise ReadTimeoutError(self._pool, None, 'Read timed out.')\n\n            except BaseSSLError as e:\n                # FIXME: Is there a better way to differentiate between SSLErrors?\n                if 'read operation timed out' not in str(e):  # Defensive:\n                    # This shouldn't happen but just in case we're missing an edge\n                    # case, let's avoid swallowing SSL errors.\n                    raise\n\n                raise ReadTimeoutError(self._pool, None, 'Read timed out.')\n\n            except HTTPException as e:\n                # This includes IncompleteRead.\n                raise ProtocolError('Connection broken: %r' % e, e)\n\n            self._fp_bytes_read += len(data)\n\n            data = self._decode(data, decode_content, flush_decoder)\n\n            if cache_content:\n                self._body = data\n\n            return data\n\n        finally:\n            if self._original_response and self._original_response.isclosed():\n                self.release_conn()", "response": "Read the content of the response and return it as a dict."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _default_template_ctx_processor():\n    reqctx = _request_ctx_stack.top\n    appctx = _app_ctx_stack.top\n    rv = {}\n    if appctx is not None:\n        rv['g'] = appctx.g\n    if reqctx is not None:\n        rv['request'] = reqctx.request\n        rv['session'] = reqctx.session\n    return rv", "response": "Default template context processor."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _render(template, context, app):\n    rv = template.render(context)\n    template_rendered.send(app, template=template, context=context)\n    return rv", "response": "Renders the template and fires the signal"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef render_template(template_name_or_list, **context):\n    ctx = _app_ctx_stack.top\n    ctx.app.update_template_context(context)\n    return _render(ctx.app.jinja_env.get_or_select_template(template_name_or_list),\n                   context, ctx.app)", "response": "Renders a template from the template folder with the given context."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef render_template_string(source, **context):\n    ctx = _app_ctx_stack.top\n    ctx.app.update_template_context(context)\n    return _render(ctx.app.jinja_env.from_string(source),\n                   context, ctx.app)", "response": "Renders a template from the given source code string with the given context."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nusing parse_version from pkg_resources or distutils as available.", "response": "def parse_version(version):\n    \"\"\"Use parse_version from pkg_resources or distutils as available.\"\"\"\n    global parse_version\n    try:\n        from pkg_resources import parse_version\n    except ImportError:\n        from distutils.version import LooseVersion as parse_version\n    return parse_version(version)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninstalls the wheel into site - packages.", "response": "def install(self, force=False, overrides={}):\n        \"\"\"\n        Install the wheel into site-packages.\n        \"\"\"\n\n        # Utility to get the target directory for a particular key\n        def get_path(key):\n            return overrides.get(key) or self.install_paths[key]\n\n        # The base target location is either purelib or platlib\n        if self.parsed_wheel_info['Root-Is-Purelib'] == 'true':\n            root = get_path('purelib')\n        else:\n            root = get_path('platlib')\n\n        # Parse all the names in the archive\n        name_trans = {}\n        for info in self.zipfile.infolist():\n            name = info.filename\n            # Zip files can contain entries representing directories.\n            # These end in a '/'.\n            # We ignore these, as we create directories on demand.\n            if name.endswith('/'):\n                continue\n\n            # Pathnames in a zipfile namelist are always /-separated.\n            # In theory, paths could start with ./ or have other oddities\n            # but this won't happen in practical cases of well-formed wheels.\n            # We'll cover the simple case of an initial './' as it's both easy\n            # to do and more common than most other oddities.\n            if name.startswith('./'):\n                name = name[2:]\n\n            # Split off the base directory to identify files that are to be\n            # installed in non-root locations\n            basedir, sep, filename = name.partition('/')\n            if sep and basedir == self.datadir_name:\n                # Data file. Target destination is elsewhere\n                key, sep, filename = filename.partition('/')\n                if not sep:\n                    raise ValueError(\"Invalid filename in wheel: {0}\".format(name))\n                target = get_path(key)\n            else:\n                # Normal file. Target destination is root\n                key = ''\n                target = root\n                filename = name\n\n            # Map the actual filename from the zipfile to its intended target\n            # directory and the pathname relative to that directory.\n            dest = os.path.normpath(os.path.join(target, filename))\n            name_trans[info] = (key, target, filename, dest)\n\n        # We're now ready to start processing the actual install. The process\n        # is as follows:\n        #   1. Prechecks - is the wheel valid, is its declared architecture\n        #      OK, etc. [[Responsibility of the caller]]\n        #   2. Overwrite check - do any of the files to be installed already\n        #      exist?\n        #   3. Actual install - put the files in their target locations.\n        #   4. Update RECORD - write a suitably modified RECORD file to\n        #      reflect the actual installed paths.\n\n        if not force:\n            for info, v in name_trans.items():\n                k = info.filename\n                key, target, filename, dest = v\n                if os.path.exists(dest):\n                    raise ValueError(\"Wheel file {0} would overwrite {1}. Use force if this is intended\".format(k, dest))\n\n        # Get the name of our executable, for use when replacing script\n        # wrapper hashbang lines.\n        # We encode it using getfilesystemencoding, as that is \"the name of\n        # the encoding used to convert Unicode filenames into system file\n        # names\".\n        exename = sys.executable.encode(sys.getfilesystemencoding())\n        record_data = []\n        record_name = self.distinfo_name + '/RECORD'\n        for info, (key, target, filename, dest) in name_trans.items():\n            name = info.filename\n            source = self.zipfile.open(info)\n            # Skip the RECORD file\n            if name == record_name:\n                continue\n            ddir = os.path.dirname(dest)\n            if not os.path.isdir(ddir):\n                os.makedirs(ddir)\n            destination = HashingFile(open(dest, 'wb'))\n            if key == 'scripts':\n                hashbang = source.readline()\n                if hashbang.startswith(b'#!python'):\n                    hashbang = b'#!' + exename + binary(os.linesep)\n                destination.write(hashbang)\n            shutil.copyfileobj(source, destination)\n            reldest = os.path.relpath(dest, root)\n            reldest.replace(os.sep, '/')\n            record_data.append((reldest, destination.digest(), destination.length))\n            destination.close()\n            source.close()\n            # preserve attributes (especially +x bit for scripts)\n            attrs = info.external_attr >> 16\n            if attrs:  # tends to be 0 if Windows.\n                os.chmod(dest, info.external_attr >> 16)\n\n        record_name = os.path.join(root, self.record_name)\n        writer = csv.writer(open_for_csv(record_name, 'w+'))\n        for reldest, digest, length in sorted(record_data):\n            writer.writerow((reldest, digest, length))\n        writer.writerow((self.record_name, '', ''))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconfiguring the VerifyingZipFile zipfile by verifying its signature and setting expected hashes for every hash in RECORD.", "response": "def verify(self, zipfile=None):\n        \"\"\"Configure the VerifyingZipFile `zipfile` by verifying its signature \n        and setting expected hashes for every hash in RECORD.\n        Caller must complete the verification process by completely reading \n        every file in the archive (e.g. with extractall).\"\"\"\n        sig = None\n        if zipfile is None:\n            zipfile = self.zipfile\n        zipfile.strict = True\n\n        record_name = '/'.join((self.distinfo_name, 'RECORD'))\n        sig_name = '/'.join((self.distinfo_name, 'RECORD.jws'))\n        # tolerate s/mime signatures:\n        smime_sig_name = '/'.join((self.distinfo_name, 'RECORD.p7s'))\n        zipfile.set_expected_hash(record_name, None)\n        zipfile.set_expected_hash(sig_name, None)\n        zipfile.set_expected_hash(smime_sig_name, None)\n        record = zipfile.read(record_name)\n\n        record_digest = urlsafe_b64encode(hashlib.sha256(record).digest())\n        try:\n            sig = from_json(native(zipfile.read(sig_name)))\n        except KeyError:  # no signature\n            pass\n        if sig:\n            headers, payload = signatures.verify(sig)\n            if payload['hash'] != \"sha256=\" + native(record_digest):\n                msg = \"RECORD.sig claimed RECORD hash {0} != computed hash {1}.\"\n                raise BadWheelFile(msg.format(payload['hash'],\n                                              native(record_digest)))\n\n        reader = csv.reader((native(r) for r in record.splitlines()))\n\n        for row in reader:\n            filename = row[0]\n            hash = row[1]\n            if not hash:\n                if filename not in (record_name, sig_name):\n                    sys.stderr.write(\"%s has no hash!\\n\" % filename)\n                continue\n            algo, data = row[1].split('=', 1)\n            assert algo == \"sha256\", \"Unsupported hash algorithm\"\n            zipfile.set_expected_hash(filename, urlsafe_b64decode(binary(data)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if a name is declared in this or an outer scope.", "response": "def is_declared(self, name):\n        \"\"\"Check if a name is declared in this or an outer scope.\"\"\"\n        if name in self.declared_locally or name in self.declared_parameter:\n            return True\n        return name in self.declared"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef inspect(self, nodes):\n        visitor = FrameIdentifierVisitor(self.identifiers)\n        for node in nodes:\n            visitor.visit(node)", "response": "Walk the node and check for identifiers."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef visit_Name(self, node):\n        if node.ctx == 'store':\n            self.identifiers.declared_locally.add(node.name)\n        elif node.ctx == 'param':\n            self.identifiers.declared_parameter.add(node.name)\n        elif node.ctx == 'load' and not \\\n             self.identifiers.is_declared(node.name):\n            self.identifiers.undeclared.add(node.name)", "response": "All assignments to names go through this function."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a whl file from all the files under base_dir.", "response": "def make_wheelfile_inner(base_name, base_dir='.'):\n    \"\"\"Create a whl file from all the files under 'base_dir'.\n\n    Places .dist-info at the end of the archive.\"\"\"\n\n    zip_filename = base_name + \".whl\"\n\n    log.info(\"creating '%s' and adding '%s' to it\", zip_filename, base_dir)\n\n    # XXX support bz2, xz when available\n    zip = zipfile.ZipFile(open(zip_filename, \"wb+\"), \"w\",\n                          compression=zipfile.ZIP_DEFLATED)\n\n    score = {'WHEEL': 1, 'METADATA': 2, 'RECORD': 3}\n    deferred = []\n\n    def writefile(path):\n        zip.write(path, path)\n        log.info(\"adding '%s'\" % path)\n\n    for dirpath, dirnames, filenames in os.walk(base_dir):\n        for name in filenames:\n            path = os.path.normpath(os.path.join(dirpath, name))\n\n            if os.path.isfile(path):\n                if dirpath.endswith('.dist-info'):\n                    deferred.append((score.get(name, 0), path))\n                else:\n                    writefile(path)\n\n    deferred.sort()\n    for score, path in deferred:\n        writefile(path)\n\n    zip.close()\n\n    return zip_filename"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef atomize(f, lock=None):\r\n\tlock = lock or threading.RLock()\r\n\r\n\t@functools.wraps(f)\r\n\tdef exec_atomic(*args, **kwargs):\r\n\t\tlock.acquire()\r\n\t\ttry:\r\n\t\t\treturn f(*args, **kwargs)\r\n\t\tfinally:\r\n\t\t\tlock.release()\r\n\treturn exec_atomic", "response": "Decorate a function with a reentrant lock to prevent multiple threads from calling said thread simultaneously."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a service and start server.", "response": "def service_factory(app, host, port,\n                    report_message='service factory port {port}',\n                    provider_cls=HTTPServiceProvider):\n    \"\"\"Create service, start server.\n\n    :param app: application to instantiate a service\n    :param host: interface to bound provider\n    :param port: port to bound provider\n    :param report_message: message format to report port\n    :param provider_cls: server class provide a service\n\n    \"\"\"\n\n    service = Service(app)\n    server = provider_cls(service, host, port, report_message)\n    server.serve_forever()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef unicode_urlencode(obj, charset='utf-8'):\n    if not isinstance(obj, string_types):\n        obj = text_type(obj)\n    if isinstance(obj, text_type):\n        obj = obj.encode(charset)\n    return text_type(url_quote(obj))", "response": "URL escapes a single bytestring or unicode string with the given charset if applicable to URL safe quoting under all supported Python versions."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef matches_requirement(req, wheels):\n    try:\n        from pkg_resources import Distribution, Requirement\n    except ImportError:\n        raise RuntimeError(\"Cannot use requirements without pkg_resources\")\n\n    req = Requirement.parse(req)\n\n    selected = []\n    for wf in wheels:\n        f = wf.parsed_filename\n        dist = Distribution(project_name=f.group(\"name\"), version=f.group(\"ver\"))\n        if dist in req:\n            selected.append(wf)\n    return selected", "response": "Returns a list of wheels that satisfy a requirement."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\npopulates a requirement set with the contents of the command line args.", "response": "def populate_requirement_set(requirement_set, args, options, finder,\n                                 session, name, wheel_cache):\n        \"\"\"\n        Marshal cmd line args into a requirement set.\n        \"\"\"\n        for req in args:\n            requirement_set.add_requirement(\n                InstallRequirement.from_line(\n                    req, None, isolated=options.isolated_mode,\n                    wheel_cache=wheel_cache\n                )\n            )\n\n        for req in options.editables:\n            requirement_set.add_requirement(\n                InstallRequirement.from_editable(\n                    req,\n                    default_vcs=options.default_vcs,\n                    isolated=options.isolated_mode,\n                    wheel_cache=wheel_cache\n                )\n            )\n\n        found_req_in_file = False\n        for filename in options.requirements:\n            for req in parse_requirements(\n                    filename,\n                    finder=finder, options=options, session=session,\n                    wheel_cache=wheel_cache):\n                found_req_in_file = True\n                requirement_set.add_requirement(req)\n\n        if not (args or options.editables or found_req_in_file):\n            opts = {'name': name}\n            if options.find_links:\n                msg = ('You must give at least one requirement to '\n                       '%(name)s (maybe you meant \"pip %(name)s '\n                       '%(links)s\"?)' %\n                       dict(opts, links=' '.join(options.find_links)))\n            else:\n                msg = ('You must give at least one requirement '\n                       'to %(name)s (see \"pip help %(name)s\")' % opts)\n            logger.warning(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalling the callable with the arguments and keyword arguments provided but inject the active context or environment as first argument if the callable is a contextfunction or environmentfunction.", "response": "def call(__self, __obj, *args, **kwargs):\n        \"\"\"Call the callable with the arguments and keyword arguments\n        provided but inject the active context or environment as first\n        argument if the callable is a :func:`contextfunction` or\n        :func:`environmentfunction`.\n        \"\"\"\n        if __debug__:\n            __traceback_hide__ = True\n\n        # Allow callable classes to take a context\n        fn = __obj.__call__\n        for fn_type in ('contextfunction',\n                        'evalcontextfunction',\n                        'environmentfunction'):\n            if hasattr(fn, fn_type):\n                __obj = fn\n                break\n\n        if isinstance(__obj, _context_function_types):\n            if getattr(__obj, 'contextfunction', 0):\n                args = (__self,) + args\n            elif getattr(__obj, 'evalcontextfunction', 0):\n                args = (__self.eval_ctx,) + args\n            elif getattr(__obj, 'environmentfunction', 0):\n                args = (__self.environment,) + args\n        try:\n            return __obj(*args, **kwargs)\n        except StopIteration:\n            return __self.environment.undefined('value was undefined because '\n                                                'a callable raised a '\n                                                'StopIteration exception')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef export(self, location):\n        temp_dir = tempfile.mkdtemp('-export', 'pip-')\n        self.unpack(temp_dir)\n        if os.path.exists(location):\n            # Remove the location to make sure Bazaar can export it correctly\n            rmtree(location)\n        try:\n            self.run_command(['export', location], cwd=temp_dir,\n                             show_stdout=False)\n        finally:\n            rmtree(temp_dir)", "response": "Export the Bazaar repository at the url to the destination location"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pip_version_check(session):\n    import pip  # imported here to prevent circular imports\n    pypi_version = None\n\n    try:\n        state = load_selfcheck_statefile()\n\n        current_time = datetime.datetime.utcnow()\n        # Determine if we need to refresh the state\n        if \"last_check\" in state.state and \"pypi_version\" in state.state:\n            last_check = datetime.datetime.strptime(\n                state.state[\"last_check\"],\n                SELFCHECK_DATE_FMT\n            )\n            if total_seconds(current_time - last_check) < 7 * 24 * 60 * 60:\n                pypi_version = state.state[\"pypi_version\"]\n\n        # Refresh the version if we need to or just see if we need to warn\n        if pypi_version is None:\n            resp = session.get(\n                PyPI.pip_json_url,\n                headers={\"Accept\": \"application/json\"},\n            )\n            resp.raise_for_status()\n            pypi_version = [\n                v for v in sorted(\n                    list(resp.json()[\"releases\"]),\n                    key=packaging_version.parse,\n                )\n                if not packaging_version.parse(v).is_prerelease\n            ][-1]\n\n            # save that we've performed a check\n            state.save(pypi_version, current_time)\n\n        pip_version = packaging_version.parse(pip.__version__)\n        remote_version = packaging_version.parse(pypi_version)\n\n        # Determine if our pypi_version is older\n        if (pip_version < remote_version and\n                pip_version.base_version != remote_version.base_version):\n            # Advise \"python -m pip\" on Windows to avoid issues\n            # with overwriting pip.exe.\n            if WINDOWS:\n                pip_cmd = \"python -m pip\"\n            else:\n                pip_cmd = \"pip\"\n            logger.warning(\n                \"You are using pip version %s, however version %s is \"\n                \"available.\\nYou should consider upgrading via the \"\n                \"'%s install --upgrade pip' command.\" % (pip.__version__,\n                                                         pypi_version,\n                                                         pip_cmd)\n            )\n\n    except Exception:\n        logger.debug(\n            \"There was an error checking the latest version of pip\",\n            exc_info=True,\n        )", "response": "Checks if pip version is older than the current one."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\niterate over all pages.", "response": "def iterate_pages(self):\n        \"\"\"Iterate Pages.\n\n        A generator which iterates over all pages.\n        Keep in mind that Amazon limits the number of pages it makes available.\n\n        :return:\n            Yields lxml root elements.\n        \"\"\"\n        try:\n            while True:\n                yield self._query(ItemPage=self.current_page, **self.kwargs)\n                self.current_page += 1\n        except NoMorePages:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nqueries Amazon Search and check for errors.", "response": "def _query(self, ResponseGroup=\"Large\", **kwargs):\n        \"\"\"Query.\n\n        Query Amazon search and check for errors.\n\n        :return:\n            An lxml root element.\n        \"\"\"\n        response = self.api.ItemSearch(ResponseGroup=ResponseGroup, **kwargs)\n        root = objectify.fromstring(response)\n        if root.Items.Request.IsValid == 'False':\n            code = root.Items.Request.Errors.Error.Code\n            msg = root.Items.Request.Errors.Error.Message\n            if code == 'AWS.ParameterOutOfRange':\n                raise NoMorePages(msg)\n            else:\n                raise SearchException(\n                    \"Amazon Search Error: '{0}', '{1}'\".format(code, msg))\n        return root"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsafes Get Element. Get a child element of root (multiple levels deep) failing silently if any descendant does not exist. :param root: Lxml element. :param path: String path (i.e. 'Items.Item.Offers.Offer'). :return: Element or None.", "response": "def _safe_get_element(self, path, root=None):\n        \"\"\"Safe Get Element.\n\n        Get a child element of root (multiple levels deep) failing silently\n        if any descendant does not exist.\n\n        :param root:\n            Lxml element.\n        :param path:\n            String path (i.e. 'Items.Item.Offers.Offer').\n        :return:\n            Element or None.\n        \"\"\"\n        elements = path.split('.')\n        parent = root if root is not None else self.item\n        for element in elements[:-1]:\n            parent = getattr(parent, element, None)\n            if parent is None:\n                return None\n        return getattr(parent, elements[-1], None)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsafes get element text.", "response": "def _safe_get_element_text(self, path, root=None):\n        \"\"\"Safe get element text.\n\n        Get element as string or None,\n        :param root:\n            Lxml element.\n        :param path:\n            String path (i.e. 'Items.Item.Offers.Offer').\n        :return:\n            String or None.\n        \"\"\"\n        element = self._safe_get_element(path, root)\n        if element:\n            return element.text\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _safe_get_element_date(self, path, root=None):\n        value = self._safe_get_element_text(path=path, root=root)\n        if value is not None:\n            try:\n                value = datetime.datetime.strptime(value, '%Y-%m-%d').date()\n            except ValueError:\n                value = None\n\n        return value", "response": "Safe get elemnent date."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef price_and_currency(self):\n        price = self._safe_get_element_text(\n            'Offers.Offer.OfferListing.SalePrice.Amount')\n        if price:\n            currency = self._safe_get_element_text(\n                'Offers.Offer.OfferListing.SalePrice.CurrencyCode')\n        else:\n            price = self._safe_get_element_text(\n                'Offers.Offer.OfferListing.Price.Amount')\n            if price:\n                currency = self._safe_get_element_text(\n                    'Offers.Offer.OfferListing.Price.CurrencyCode')\n            else:\n                price = self._safe_get_element_text(\n                    'OfferSummary.LowestNewPrice.Amount')\n                currency = self._safe_get_element_text(\n                    'OfferSummary.LowestNewPrice.CurrencyCode')\n        if price:\n            return float(price) / 100, currency\n        else:\n            return None, None", "response": "Get Offer Price and Currency."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a tuple containing the float representation of price.", "response": "def list_price(self):\n        \"\"\"List Price.\n\n        :return:\n            A tuple containing:\n\n                1. Float representation of price.\n                2. ISO Currency code (string).\n        \"\"\"\n        price = self._safe_get_element_text('ItemAttributes.ListPrice.Amount')\n        currency = self._safe_get_element_text(\n            'ItemAttributes.ListPrice.CurrencyCode')\n        if price:\n            return float(price) / 100, currency\n        else:\n            return None, None"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsends a request to the cache.", "response": "def send(self, request, **kw):\n        \"\"\"\n        Send a request. Use the request information to see if it\n        exists in the cache and cache the response if we need to and can.\n        \"\"\"\n        if request.method == 'GET':\n            cached_response = self.controller.cached_request(request)\n            if cached_response:\n                return self.build_response(request, cached_response,\n                                           from_cache=True)\n\n            # check for etags and add headers if appropriate\n            request.headers.update(\n                self.controller.conditional_headers(request)\n            )\n\n        resp = super(CacheControlAdapter, self).send(request, **kw)\n\n        return resp"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef build_response(self, request, response, from_cache=False):\n        if not from_cache and request.method == 'GET':\n\n            # apply any expiration heuristics\n            if response.status == 304:\n                # We must have sent an ETag request. This could mean\n                # that we've been expired already or that we simply\n                # have an etag. In either case, we want to try and\n                # update the cache if that is the case.\n                cached_response = self.controller.update_cached_response(\n                    request, response\n                )\n\n                if cached_response is not response:\n                    from_cache = True\n\n                # We are done with the server response, read a\n                # possible response body (compliant servers will\n                # not return one, but we cannot be 100% sure) and\n                # release the connection back to the pool.\n                response.read(decode_content=False)\n                response.release_conn()\n\n                response = cached_response\n\n            # We always cache the 301 responses\n            elif response.status == 301:\n                self.controller.cache_response(request, response)\n            else:\n                # Check for any heuristics that might update headers\n                # before trying to cache.\n                if self.heuristic:\n                    response = self.heuristic.apply(response)\n\n                # Wrap the response file with a wrapper that will cache the\n                #   response when the stream has been consumed.\n                response._fp = CallbackFileWrapper(\n                    response._fp,\n                    functools.partial(\n                        self.controller.cache_response,\n                        request,\n                        response,\n                    )\n                )\n\n        resp = super(CacheControlAdapter, self).build_response(\n            request, response\n        )\n\n        # See if we should invalidate the cache.\n        if request.method in self.invalidating_methods and resp.ok:\n            cache_url = self.controller.cache_url(request.url)\n            self.cache.delete(cache_url)\n\n        # Give the request a from_cache attr to let people use it\n        resp.from_cache = from_cache\n\n        return resp", "response": "Build a response by making a request or using the cache."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a callable that looks up the given attribute from a passed object with the rules of the environment.", "response": "def make_attrgetter(environment, attribute):\n    \"\"\"Returns a callable that looks up the given attribute from a\n    passed object with the rules of the environment.  Dots are allowed\n    to access attributes of attributes.  Integer parts in paths are\n    looked up as integers.\n    \"\"\"\n    if not isinstance(attribute, string_types) \\\n       or ('.' not in attribute and not attribute.isdigit()):\n        return lambda x: environment.getitem(x, attribute)\n    attribute = attribute.split('.')\n    def attrgetter(item):\n        for part in attribute:\n            if part.isdigit():\n                part = int(part)\n            item = environment.getitem(item, part)\n        return item\n    return attrgetter"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef do_title(s):\n    rv = []\n    for item in re.compile(r'([-\\s]+)(?u)').split(s):\n        if not item:\n            continue\n        rv.append(item[0].upper() + item[1:].lower())\n    return ''.join(rv)", "response": "Return a titlecased version of the value. I. e. words will start with\n    uppercase letters all remaining characters are lowercase."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsorting a dict and yield key value pairs.", "response": "def do_dictsort(value, case_sensitive=False, by='key'):\n    \"\"\"Sort a dict and yield (key, value) pairs. Because python dicts are\n    unsorted you may want to use this function to order them by either\n    key or value:\n\n    .. sourcecode:: jinja\n\n        {% for item in mydict|dictsort %}\n            sort the dict by key, case insensitive\n\n        {% for item in mydict|dictsort(true) %}\n            sort the dict by key, case sensitive\n\n        {% for item in mydict|dictsort(false, 'value') %}\n            sort the dict by key, case insensitive, sorted\n            normally and ordered by value.\n    \"\"\"\n    if by == 'key':\n        pos = 0\n    elif by == 'value':\n        pos = 1\n    else:\n        raise FilterArgumentError('You can only sort by either '\n                                  '\"key\" or \"value\"')\n    def sort_func(item):\n        value = item[pos]\n        if isinstance(value, string_types) and not case_sensitive:\n            value = value.lower()\n        return value\n\n    return sorted(value.items(), key=sort_func)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef do_sort(environment, value, reverse=False, case_sensitive=False,\n            attribute=None):\n    \"\"\"Sort an iterable.  Per default it sorts ascending, if you pass it\n    true as first argument it will reverse the sorting.\n\n    If the iterable is made of strings the third parameter can be used to\n    control the case sensitiveness of the comparison which is disabled by\n    default.\n\n    .. sourcecode:: jinja\n\n        {% for item in iterable|sort %}\n            ...\n        {% endfor %}\n\n    It is also possible to sort by an attribute (for example to sort\n    by the date of an object) by specifying the `attribute` parameter:\n\n    .. sourcecode:: jinja\n\n        {% for item in iterable|sort(attribute='date') %}\n            ...\n        {% endfor %}\n\n    .. versionchanged:: 2.6\n       The `attribute` parameter was added.\n    \"\"\"\n    if not case_sensitive:\n        def sort_func(item):\n            if isinstance(item, string_types):\n                item = item.lower()\n            return item\n    else:\n        sort_func = None\n    if attribute is not None:\n        getter = make_attrgetter(environment, attribute)\n        def sort_func(item, processor=sort_func or (lambda x: x)):\n            return processor(getter(item))\n    return sorted(value, key=sort_func, reverse=reverse)", "response": "Sort an iterable.  Per default it sorts ascending, if you pass it\n    true as first argument it will reverse the sorting.\n\n    If the iterable is made of strings the third parameter can be used to\n    control the case sensitiveness of the comparison which is disabled by\n    default.\n\n    .. sourcecode:: jinja\n\n        {% for item in iterable|sort %}\n            ...\n        {% endfor %}\n\n    It is also possible to sort by an attribute (for example to sort\n    by the date of an object) by specifying the `attribute` parameter:\n\n    .. sourcecode:: jinja\n\n        {% for item in iterable|sort(attribute='date') %}\n            ...\n        {% endfor %}\n\n    .. versionchanged:: 2.6\n       The `attribute` parameter was added."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngrouping a sequence of objects by a common attribute.", "response": "def do_groupby(environment, value, attribute):\n    \"\"\"Group a sequence of objects by a common attribute.\n\n    If you for example have a list of dicts or objects that represent persons\n    with `gender`, `first_name` and `last_name` attributes and you want to\n    group all users by genders you can do something like the following\n    snippet:\n\n    .. sourcecode:: html+jinja\n\n        <ul>\n        {% for group in persons|groupby('gender') %}\n            <li>{{ group.grouper }}<ul>\n            {% for person in group.list %}\n                <li>{{ person.first_name }} {{ person.last_name }}</li>\n            {% endfor %}</ul></li>\n        {% endfor %}\n        </ul>\n\n    Additionally it's possible to use tuple unpacking for the grouper and\n    list:\n\n    .. sourcecode:: html+jinja\n\n        <ul>\n        {% for grouper, list in persons|groupby('gender') %}\n            ...\n        {% endfor %}\n        </ul>\n\n    As you can see the item we're grouping by is stored in the `grouper`\n    attribute and the `list` contains all the objects that have this grouper\n    in common.\n\n    .. versionchanged:: 2.6\n       It's now possible to use dotted notation to group by the child\n       attribute of another attribute.\n    \"\"\"\n    expr = make_attrgetter(environment, attribute)\n    return sorted(map(_GroupTuple, groupby(sorted(value, key=expr), expr)))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef do_map(*args, **kwargs):\n    context = args[0]\n    seq = args[1]\n\n    if len(args) == 2 and 'attribute' in kwargs:\n        attribute = kwargs.pop('attribute')\n        if kwargs:\n            raise FilterArgumentError('Unexpected keyword argument %r' %\n                next(iter(kwargs)))\n        func = make_attrgetter(context.environment, attribute)\n    else:\n        try:\n            name = args[2]\n            args = args[3:]\n        except LookupError:\n            raise FilterArgumentError('map requires a filter argument')\n        func = lambda item: context.environment.call_filter(\n            name, item, args, kwargs, context=context)\n\n    if seq:\n        for item in seq:\n            yield func(item)", "response": "Applies a filter on a sequence of objects or looks up an attribute."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_logger(app):\n    Logger = getLoggerClass()\n\n    class DebugLogger(Logger):\n        def getEffectiveLevel(x):\n            if x.level == 0 and app.debug:\n                return DEBUG\n            return Logger.getEffectiveLevel(x)\n\n    class DebugHandler(StreamHandler):\n        def emit(x, record):\n            StreamHandler.emit(x, record) if app.debug else None\n\n    handler = DebugHandler()\n    handler.setLevel(DEBUG)\n    handler.setFormatter(Formatter(app.debug_log_format))\n    logger = getLogger(app.logger_name)\n    # just in case that was not a new logger, get rid of all the handlers\n    # already attached to it.\n    del logger.handlers[:]\n    logger.__class__ = DebugLogger\n    logger.addHandler(handler)\n    return logger", "response": "Creates a logger for the given application."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef constant_time_compare(val1, val2):\n    if _builtin_constant_time_compare is not None:\n        return _builtin_constant_time_compare(val1, val2)\n    len_eq = len(val1) == len(val2)\n    if len_eq:\n        result = 0\n        left = val1\n    else:\n        result = 1\n        left = val2\n    for x, y in izip(bytearray(left), bytearray(val2)):\n        result |= x ^ y\n    return result == 0", "response": "Returns True if the two strings are equal False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef base64_decode(string):\n    string = want_bytes(string, encoding='ascii', errors='ignore')\n    return base64.urlsafe_b64decode(string + b'=' * (-len(string) % 4))", "response": "base64 decodes a single bytestring"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nverifying the given signature matches the expected signature", "response": "def verify_signature(self, key, value, sig):\n        \"\"\"Verifies the given signature matches the expected signature\"\"\"\n        return constant_time_compare(sig, self.get_signature(key, value))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the signature for the given value", "response": "def get_signature(self, value):\n        \"\"\"Returns the signature for the given value\"\"\"\n        value = want_bytes(value)\n        key = self.derive_key()\n        sig = self.algorithm.get_signature(key, value)\n        return base64_encode(sig)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsigns the given string.", "response": "def sign(self, value):\n        \"\"\"Signs the given string.\"\"\"\n        return value + want_bytes(self.sep) + self.get_signature(value)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef verify_signature(self, value, sig):\n        key = self.derive_key()\n        try:\n            sig = base64_decode(sig)\n        except Exception:\n            return False\n        return self.algorithm.verify_signature(key, value, sig)", "response": "Verifies the signature for the given value."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sign(self, value):\n        value = want_bytes(value)\n        timestamp = base64_encode(int_to_bytes(self.get_timestamp()))\n        sep = want_bytes(self.sep)\n        value = value + sep + timestamp\n        return value + sep + self.get_signature(value)", "response": "Signs the given string and also attaches a time information."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nworking like the regular :meth:`~Signer.unsign` but can also validate the time. See the base docstring of the class for the general behavior. If `return_timestamp` is set to `True` the timestamp of the signature will be returned as naive :class:`datetime.datetime` object in UTC.", "response": "def unsign(self, value, max_age=None, return_timestamp=False):\n        \"\"\"Works like the regular :meth:`~Signer.unsign` but can also\n        validate the time.  See the base docstring of the class for\n        the general behavior.  If `return_timestamp` is set to `True`\n        the timestamp of the signature will be returned as naive\n        :class:`datetime.datetime` object in UTC.\n        \"\"\"\n        try:\n            result = Signer.unsign(self, value)\n            sig_error = None\n        except BadSignature as e:\n            sig_error = e\n            result = e.payload or b''\n        sep = want_bytes(self.sep)\n\n        # If there is no timestamp in the result there is something\n        # seriously wrong.  In case there was a signature error, we raise\n        # that one directly, otherwise we have a weird situation in which\n        # we shouldn't have come except someone uses a time-based serializer\n        # on non-timestamp data, so catch that.\n        if not sep in result:\n            if sig_error:\n                raise sig_error\n            raise BadTimeSignature('timestamp missing', payload=result)\n\n        value, timestamp = result.rsplit(sep, 1)\n        try:\n            timestamp = bytes_to_int(base64_decode(timestamp))\n        except Exception:\n            timestamp = None\n\n        # Signature is *not* okay.  Raise a proper error now that we have\n        # split the value and the timestamp.\n        if sig_error is not None:\n            raise BadTimeSignature(text_type(sig_error), payload=value,\n                                   date_signed=timestamp)\n\n        # Signature was okay but the timestamp is actually not there or\n        # malformed.  Should not happen, but well.  We handle it nonetheless\n        if timestamp is None:\n            raise BadTimeSignature('Malformed timestamp', payload=value)\n\n        # Check timestamp is not older than max_age\n        if max_age is not None:\n            age = self.get_timestamp() - timestamp\n            if age > max_age:\n                raise SignatureExpired(\n                    'Signature age %s > %s seconds' % (age, max_age),\n                    payload=value,\n                    date_signed=self.timestamp_to_datetime(timestamp))\n\n        if return_timestamp:\n            return value, self.timestamp_to_datetime(timestamp)\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn True if the given signed value is valid False otherwise.", "response": "def validate(self, signed_value, max_age=None):\n        \"\"\"Just validates the given signed value.  Returns `True` if the\n        signature exists and is valid, `False` otherwise.\"\"\"\n        try:\n            self.unsign(signed_value, max_age=max_age)\n            return True\n        except BadSignature:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading the encoded object.", "response": "def load_payload(self, payload, serializer=None):\n        \"\"\"Loads the encoded object.  This function raises :class:`BadPayload`\n        if the payload is not valid.  The `serializer` parameter can be used to\n        override the serializer stored on the class.  The encoded payload is\n        always byte based.\n        \"\"\"\n        if serializer is None:\n            serializer = self.serializer\n            is_text = self.is_text_serializer\n        else:\n            is_text = is_text_serializer(serializer)\n        try:\n            if is_text:\n                payload = payload.decode('utf-8')\n            return serializer.loads(payload)\n        except Exception as e:\n            raise BadPayload('Could not load the payload because an '\n                'exception occurred on unserializing the data',\n                original_error=e)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a signed string serialized with the internal serializer.", "response": "def dumps(self, obj, salt=None):\n        \"\"\"Returns a signed string serialized with the internal serializer.\n        The return value can be either a byte or unicode string depending\n        on the format of the internal serializer.\n        \"\"\"\n        payload = want_bytes(self.dump_payload(obj))\n        rv = self.make_signer(salt).sign(payload)\n        if self.is_text_serializer:\n            rv = rv.decode('utf-8')\n        return rv"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dump(self, obj, f, salt=None):\n        f.write(self.dumps(obj, salt))", "response": "Like dumps but writes to a file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreverse of dumps raises BadSignature exception", "response": "def loads(self, s, salt=None):\n        \"\"\"Reverse of :meth:`dumps`, raises :exc:`BadSignature` if the\n        signature validation fails.\n        \"\"\"\n        s = want_bytes(s)\n        return self.load_payload(self.make_signer(salt).unsign(s))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _loads_unsafe_impl(self, s, salt, load_kwargs=None,\n                           load_payload_kwargs=None):\n        \"\"\"Lowlevel helper function to implement :meth:`loads_unsafe` in\n        serializer subclasses.\n        \"\"\"\n        try:\n            return True, self.loads(s, salt=salt, **(load_kwargs or {}))\n        except BadSignature as e:\n            if e.payload is None:\n                return False, None\n            try:\n                return False, self.load_payload(e.payload,\n                    **(load_payload_kwargs or {}))\n            except BadPayload:\n                return False, None", "response": "Lowlevel helper function to implement loads_unsafe in\n            serializer subclasses."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load_unsafe(self, f, *args, **kwargs):\n        return self.loads_unsafe(f.read(), *args, **kwargs)", "response": "Like loads_unsafe but loads from a file."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngives a string s returns a base64 - encoded payload and a timestamp.", "response": "def loads(self, s, max_age=None, return_timestamp=False, salt=None):\n        \"\"\"Reverse of :meth:`dumps`, raises :exc:`BadSignature` if the\n        signature validation fails.  If a `max_age` is provided it will\n        ensure the signature is not older than that time in seconds.  In\n        case the signature is outdated, :exc:`SignatureExpired` is raised\n        which is a subclass of :exc:`BadSignature`.  All arguments are\n        forwarded to the signer's :meth:`~TimestampSigner.unsign` method.\n        \"\"\"\n        base64d, timestamp = self.make_signer(salt) \\\n            .unsign(s, max_age, return_timestamp=True)\n        payload = self.load_payload(base64d)\n        if return_timestamp:\n            return payload, timestamp\n        return payload"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dumps(self, obj, salt=None, header_fields=None):\n        header = self.make_header(header_fields)\n        signer = self.make_signer(salt, self.algorithm)\n        return signer.sign(self.dump_payload(header, obj))", "response": "Like : meth : ~Serializer. dumps but creates a JSON Web Signature."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreverses of :meth:`dumps`. If requested via `return_header` it will return a tuple of payload and header.", "response": "def loads(self, s, salt=None, return_header=False):\n        \"\"\"Reverse of :meth:`dumps`. If requested via `return_header` it will\n        return a tuple of payload and header.\n        \"\"\"\n        payload, header = self.load_payload(\n            self.make_signer(salt, self.algorithm).unsign(want_bytes(s)),\n            return_header=True)\n        if header.get('alg') != self.algorithm_name:\n            raise BadHeader('Algorithm mismatch', header=header,\n                            payload=payload)\n        if return_header:\n            return payload, header\n        return payload"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef server_error(request_id, error):\n\n    response = {\n        'jsonrpc': '2.0',\n        'id': request_id,\n        'error': {\n            'code': -32000,\n            'message': 'Server error',\n            'data': repr(error),\n        },\n    }\n    raise ServiceException(500, dumps(response))", "response": "JSON - RPC server error."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef findall(dir = os.curdir):\n    all_files = []\n    for base, dirs, files in os.walk(dir, followlinks=True):\n        if base==os.curdir or base.startswith(os.curdir+os.sep):\n            base = base[2:]\n        if base:\n            files = [os.path.join(base, f) for f in files]\n        all_files.extend(filter(os.path.isfile, files))\n    return all_files", "response": "Find all files under dir and return the list of full filenames."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of Python packages found within a directory where.", "response": "def find(cls, where='.', exclude=(), include=('*',)):\n        \"\"\"Return a list all Python packages found within directory 'where'\n\n        'where' should be supplied as a \"cross-platform\" (i.e. URL-style)\n        path; it will be converted to the appropriate local path syntax.\n        'exclude' is a sequence of package names to exclude; '*' can be used\n        as a wildcard in the names, such that 'foo.*' will exclude all\n        subpackages of 'foo' (but not 'foo' itself).\n\n        'include' is a sequence of package names to include.  If it's\n        specified, only the named packages will be included.  If it's not\n        specified, all found packages will be included.  'include' can contain\n        shell style wildcard patterns just like 'exclude'.\n\n        The list of included packages is built up first and then any\n        explicitly excluded packages are removed from it.\n        \"\"\"\n        out = cls._find_packages_iter(convert_path(where))\n        out = cls.require_parents(out)\n        includes = cls._build_filter(*include)\n        excludes = cls._build_filter('ez_setup', '*__pycache__', *exclude)\n        out = filter(includes, out)\n        out = filterfalse(excludes, out)\n        return list(out)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nyield the packages that are not included in the list of packages.", "response": "def require_parents(packages):\n        \"\"\"\n        Exclude any apparent package that apparently doesn't include its\n        parent.\n\n        For example, exclude 'foo.bar' if 'foo' is not present.\n        \"\"\"\n        found = []\n        for pkg in packages:\n            base, sep, child = pkg.rpartition('.')\n            if base and base not in found:\n                continue\n            found.append(pkg)\n            yield pkg"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _all_dirs(base_path):\n        for root, dirs, files in os.walk(base_path, followlinks=True):\n            for dir in dirs:\n                yield os.path.relpath(os.path.join(root, dir), base_path)", "response": "Return all dirs in base_path relative to base_path"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nverifying our vary headers match and construct a real urllib3 HTTPResponse object.", "response": "def prepare_response(self, request, cached):\n        \"\"\"Verify our vary headers match and construct a real urllib3\n        HTTPResponse object.\n        \"\"\"\n        # Special case the '*' Vary value as it means we cannot actually\n        # determine if the cached response is suitable for this request.\n        if \"*\" in cached.get(\"vary\", {}):\n            return\n\n        # Ensure that the Vary headers for the cached response match our\n        # request\n        for header, value in cached.get(\"vary\", {}).items():\n            if request.headers.get(header, None) != value:\n                return\n\n        body_raw = cached[\"response\"].pop(\"body\")\n\n        try:\n            body = io.BytesIO(body_raw)\n        except TypeError:\n            # This can happen if cachecontrol serialized to v1 format (pickle)\n            # using Python 2. A Python 2 str(byte string) will be unpickled as\n            # a Python 3 str (unicode string), which will cause the above to\n            # fail with:\n            #\n            #     TypeError: 'str' does not support the buffer interface\n            body = io.BytesIO(body_raw.encode('utf8'))\n\n        return HTTPResponse(\n            body=body,\n            preload_content=False,\n            **cached[\"response\"]\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate a public or private key pair.", "response": "def keygen(get_keyring=get_keyring):\n    \"\"\"Generate a public/private key pair.\"\"\"\n    WheelKeys, keyring = get_keyring()\n\n    ed25519ll = signatures.get_ed25519ll()\n\n    wk = WheelKeys().load()\n\n    keypair = ed25519ll.crypto_sign_keypair()\n    vk = native(urlsafe_b64encode(keypair.vk))\n    sk = native(urlsafe_b64encode(keypair.sk))\n    kr = keyring.get_keyring()\n    kr.set_password(\"wheel\", vk, sk)\n    sys.stdout.write(\"Created Ed25519 keypair with vk={0}\\n\".format(vk))\n    if isinstance(kr, keyring.backends.file.BaseKeyring):\n        sys.stdout.write(\"in {0}\\n\".format(kr.file_path))\n    else:\n        sys.stdout.write(\"in %r\\n\" % kr.__class__)\n\n    sk2 = kr.get_password('wheel', vk)\n    if sk2 != sk:\n        raise WheelError(\"Keyring is broken. Could not retrieve secret key.\")\n\n    sys.stdout.write(\"Trusting {0} to sign and verify all packages.\\n\".format(vk))\n    wk.add_signer('+', vk)\n    wk.trust('+', vk)\n    wk.save()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef unsign(wheelfile):\n    import wheel.install\n    vzf = wheel.install.VerifyingZipFile(wheelfile, \"a\")\n    info = vzf.infolist()\n    if not (len(info) and info[-1].filename.endswith('/RECORD.jws')):\n        raise WheelError(\"RECORD.jws not found at end of archive.\")\n    vzf.pop()\n    vzf.close()", "response": "Unsign a WHEEL file."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nverifies a wheel. The signature will be verified for internal consistency ONLY and printed. Wheel's own unpack/install commands verify the manifest against the signature and file contents.", "response": "def verify(wheelfile):\n    \"\"\"Verify a wheel.\n    \n    The signature will be verified for internal consistency ONLY and printed. \n    Wheel's own unpack/install commands verify the manifest against the\n    signature and file contents.\n    \"\"\"\n    wf = WheelFile(wheelfile)\n    sig_name = wf.distinfo_name + '/RECORD.jws'\n    sig = json.loads(native(wf.zipfile.open(sig_name).read()))\n    verified = signatures.verify(sig)\n    sys.stderr.write(\"Signatures are internally consistent.\\n\")\n    sys.stdout.write(json.dumps(verified, indent=2))\n    sys.stdout.write('\\n')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nunpack a wheel. Wheel content will be unpacked to {dest}/{name}-{ver}, where {name} is the package name and {ver} its version. :param wheelfile: The path to the wheel. :param dest: Destination directory (default to current directory).", "response": "def unpack(wheelfile, dest='.'):\n    \"\"\"Unpack a wheel.\n\n    Wheel content will be unpacked to {dest}/{name}-{ver}, where {name}\n    is the package name and {ver} its version.\n\n    :param wheelfile: The path to the wheel.\n    :param dest: Destination directory (default to current directory).\n    \"\"\"\n    wf = WheelFile(wheelfile)\n    namever = wf.parsed_filename.group('namever')\n    destination = os.path.join(dest, namever)\n    sys.stderr.write(\"Unpacking to: %s\\n\" % (destination))\n    wf.zipfile.extractall(destination)\n    wf.zipfile.close()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef install(requirements, requirements_file=None,\n            wheel_dirs=None, force=False, list_files=False,\n            dry_run=False):\n    \"\"\"Install wheels.\n    \n    :param requirements: A list of requirements or wheel files to install.\n    :param requirements_file: A file containing requirements to install.\n    :param wheel_dirs: A list of directories to search for wheels.\n    :param force: Install a wheel file even if it is not compatible.\n    :param list_files: Only list the files to install, don't install them.\n    :param dry_run: Do everything but the actual install.\n    \"\"\"\n\n    # If no wheel directories specified, use the WHEELPATH environment\n    # variable, or the current directory if that is not set.\n    if not wheel_dirs:\n        wheelpath = os.getenv(\"WHEELPATH\")\n        if wheelpath:\n            wheel_dirs = wheelpath.split(os.pathsep)\n        else:\n            wheel_dirs = [ os.path.curdir ]\n\n    # Get a list of all valid wheels in wheel_dirs\n    all_wheels = []\n    for d in wheel_dirs:\n        for w in os.listdir(d):\n            if w.endswith('.whl'):\n                wf = WheelFile(os.path.join(d, w))\n                if wf.compatible:\n                    all_wheels.append(wf)\n\n    # If there is a requirements file, add it to the list of requirements\n    if requirements_file:\n        # If the file doesn't exist, search for it in wheel_dirs\n        # This allows standard requirements files to be stored with the\n        # wheels.\n        if not os.path.exists(requirements_file):\n            for d in wheel_dirs:\n                name = os.path.join(d, requirements_file)\n                if os.path.exists(name):\n                    requirements_file = name\n                    break\n\n        with open(requirements_file) as fd:\n            requirements.extend(fd)\n\n    to_install = []\n    for req in requirements:\n        if req.endswith('.whl'):\n            # Explicitly specified wheel filename\n            if os.path.exists(req):\n                wf = WheelFile(req)\n                if wf.compatible or force:\n                    to_install.append(wf)\n                else:\n                    msg = (\"{0} is not compatible with this Python. \"\n                           \"--force to install anyway.\".format(req))\n                    raise WheelError(msg)\n            else:\n                # We could search on wheel_dirs, but it's probably OK to\n                # assume the user has made an error.\n                raise WheelError(\"No such wheel file: {}\".format(req))\n            continue\n\n        # We have a requirement spec\n        # If we don't have pkg_resources, this will raise an exception\n        matches = matches_requirement(req, all_wheels)\n        if not matches:\n            raise WheelError(\"No match for requirement {}\".format(req))\n        to_install.append(max(matches))\n\n    # We now have a list of wheels to install\n    if list_files:\n        sys.stdout.write(\"Installing:\\n\")\n\n    if dry_run:\n        return\n\n    for wf in to_install:\n        if list_files:\n            sys.stdout.write(\"    {0}\\n\".format(wf.filename))\n            continue\n        wf.install(force=force)\n        wf.zipfile.close()", "response": "Installs the given requirements or wheel files into the list of wheels."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninstall the entry_points console_scripts for the named distributions.", "response": "def install_scripts(distributions):\n    \"\"\"\n    Regenerate the entry_points console_scripts for the named distribution.\n    \"\"\"\n    try:\n        from setuptools.command import easy_install\n        import pkg_resources\n    except ImportError:\n        raise RuntimeError(\"'wheel install_scripts' needs setuptools.\")\n\n    for dist in distributions:\n        pkg_resources_dist = pkg_resources.get_distribution(dist)\n        install = wheel.paths.get_install_command(dist)\n        command = easy_install.easy_install(install.distribution)\n        command.args = ['wheel'] # dummy argument\n        command.finalize_options()\n        command.install_egg_scripts(pkg_resources_dist)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef arrange_all(self):\n        import godot.dot_data_parser\n\n        parser = godot.dot_data_parser.GodotDataParser()\n\n        xdot_data = self.create( format = \"xdot\" )\n#        print \"GRAPH DOT:\\n\", str( self )\n#        print \"XDOT DATA:\\n\", xdot_data\n\n        parser.dotparser.parseWithTabs()\n        ndata = xdot_data.replace( \"\\\\\\n\", \"\" )\n        tokens = parser.dotparser.parseString( ndata )[0]\n        parser.build_graph( graph=self, tokens=tokens[3] )\n\n        self.redraw_canvas()", "response": "Set for the _draw_ and _ldraw_ attributes for each of the graph\n            sub - elements by processing the xdot format of the graph and building the graph."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nredraws the canvas of the current node and edge graph.", "response": "def redraw_canvas(self):\n        \"\"\" Parses the Xdot attributes of all graph components and adds\n            the components to a new canvas.\n        \"\"\"\n        from xdot_parser import XdotAttrParser\n\n        xdot_parser = XdotAttrParser()\n        canvas = self._component_default()\n\n        for node in self.nodes:\n            components = xdot_parser.parse_xdot_data( node._draw_ )\n            canvas.add( *components )\n\n            components = xdot_parser.parse_xdot_data( node._ldraw_ )\n            canvas.add( *components )\n\n        for edge in self.edges:\n            components = xdot_parser.parse_xdot_data( edge._draw_ )\n            canvas.add( *components )\n            components = xdot_parser.parse_xdot_data( edge._ldraw_ )\n            canvas.add( *components )\n            components = xdot_parser.parse_xdot_data( edge._hdraw_ )\n            canvas.add( *components )\n            components = xdot_parser.parse_xdot_data( edge._tdraw_ )\n            canvas.add( *components )\n            components = xdot_parser.parse_xdot_data( edge._hldraw_ )\n            canvas.add( *components )\n            components = xdot_parser.parse_xdot_data( edge._tldraw_ )\n            canvas.add( *components )\n\n        self.component = canvas\n        self.vp.request_redraw()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_node(self, ID):\n        node = super(Graph, self).get_node(ID)\n        if node is not None:\n            return node\n\n        for graph in self.all_graphs:\n            for each_node in graph.nodes:\n                if each_node.ID == ID:\n                    return each_node\n        else:\n            return None", "response": "Returns a node given an ID or None if no such node exists."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the maximum number of nodes in the current state.", "response": "def _maxiter_default(self):\n        \"\"\" Trait initialiser.\n        \"\"\"\n        mode = self.mode\n        if mode == \"KK\":\n            return 100 * len(self.nodes)\n        elif mode == \"major\":\n            return 200\n        else:\n            return 600"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the connection string for all edges.", "response": "def _directed_changed(self, new):\n        \"\"\" Sets the connection string for all edges.\n        \"\"\"\n        if new:\n            conn = \"->\"\n        else:\n            conn = \"--\"\n\n        for edge in [e for g in self.all_graphs for e in g.edges]:\n            edge.conn = conn"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmaintain each branch s list of available nodes in order that they can move themselves.", "response": "def _on_nodes(self):\n        \"\"\" Maintains each branch's list of available nodes in order that they\n            may move themselves (InstanceEditor values).\n        \"\"\"\n        all_graphs = self.all_graphs\n        all_nodes = [n for g in all_graphs for n in g.nodes]\n\n        for graph in all_graphs:\n            for edge in graph.edges:\n                edge._nodes = all_nodes"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _on_edges(self, object, name, old, new):\n        if name == \"edges_items\":\n            edges = new.added\n        elif name == \"edges\":\n            edges = new\n        else:\n            edges = []\n\n        all_nodes = [n for g in self.all_graphs for n in g.nodes]\n\n        for each_edge in edges:\n            # Ensure the edge's nodes exist in the graph.\n            if each_edge.tail_node not in all_nodes:\n                object.nodes.append( each_edge.tail_node )\n\n            if each_edge.head_node not in all_nodes:\n                object.nodes.append( each_edge.head_node )\n\n            # Initialise the edge's list of available nodes.\n            each_edge._nodes = all_nodes", "response": "Handles the list of edges for any graph changing."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _viewport_default(self):\n\n        viewport = Viewport(component=self.canvas, enable_zoom=True)\n        viewport.tools.append(ViewportPanTool(viewport))\n        return viewport", "response": "Create a default Viewport instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nhandles the component being changed.", "response": "def _component_changed(self, old, new):\n        \"\"\" Handles the component being changed.\n        \"\"\"\n        canvas = self.canvas\n        if old is not None:\n            canvas.remove(old)\n        if new is not None:\n            canvas.add(new)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef normal_left_dclick(self, event):\n        x = event.x\n        y = event.y\n\n        # First determine what component or components we are going to hittest\n        # on.  If our component is a container, then we add its non-container\n        # components to the list of candidates.\n#        candidates = []\n        component = self.component\n#        if isinstance(component, Container):\n#            candidates = get_nested_components(self.component)\n#        else:\n#            # We don't support clicking on unrecognized components\n#            return\n#\n#        # Hittest against all the candidate and take the first one\n#        item = None\n#        for candidate, offset in candidates:\n#            if candidate.is_in(x-offset[0], y-offset[1]):\n#                item = candidate\n#                break\n\n        if hasattr(component, \"element\"):\n            if component.element is not None:\n                component.active_tool = self\n                component.element.edit_traits(kind=\"livemodal\")\n                event.handled = True\n                component.active_tool = None\n                component.request_redraw()\n        return", "response": "Handles the left mouse button being double - clicked when the tool is in the normal state."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a default canvas for this instance.", "response": "def _diagram_canvas_default(self):\n        \"\"\" Trait initialiser \"\"\"\n\n        canvas = Canvas()\n\n        for tool in self.tools:\n            canvas.tools.append(tool(canvas))\n\n        return canvas"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a Viewport object with default view position and pan tools.", "response": "def _viewport_default(self):\n        \"\"\" Trait initialiser \"\"\"\n\n        vp = Viewport(component=self.diagram_canvas, enable_zoom=True)\n        vp.view_position = [0,0]\n        vp.tools.append(ViewportPanTool(vp))\n        return vp"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _diagram_canvas_changed(self, new):\n\n        logger.debug(\"Diagram canvas changed!\")\n        canvas = self.diagram_canvas\n\n        for tool in self.tools:\n            if canvas is not None:\n                print \"Adding tool: %s\" % tool\n                canvas.tools.append(tool(canvas))", "response": "Handles the diagram canvas being changed"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef clear_canvas(self):\n\n        logger.debug(\"Clearing the diagram canvas!\")\n        old_canvas = self.diagram_canvas\n\n#        logger.debug(\"Canvas components: %s\" % canvas.components)\n#        for component in canvas.components:\n#            canvas.remove(component)\n#        logger.debug(\"Canvas components: %s\" % canvas.components)\n#        for component in canvas.components:\n#            canvas.remove(component)\n#        logger.debug(\"Canvas components: %s\" % canvas.components)\n#        canvas.request_redraw()\n\n        new_canvas = Canvas()\n        new_canvas.copy_traits(old_canvas, [\"bgcolor\", \"draw_axes\"])\n        self.diagram_canvas = new_canvas\n\n        self.viewport.component=new_canvas\n        self.viewport.request_redraw()\n\n        return", "response": "Removes all components from the diagram canvas"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nhandling the domain model changes for the diagram.", "response": "def _domain_model_changed_for_diagram(self, obj, name, old, new):\n        \"\"\" Handles the domain model changing \"\"\"\n\n        if old is not None:\n            self.unmap_model(old)\n        if new is not None:\n            self.map_model(new)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmap a domain model to the diagram.", "response": "def map_model(self, new):\n        \"\"\" Maps a domain model to the diagram \"\"\"\n\n        logger.debug(\"Mapping the domain model!\")\n        dot = Dot()\n\n        self.diagram.clear_canvas()\n\n        for node_mapping in self.nodes:\n            ct = node_mapping.containment_trait\n            logger.debug(\"Mapping elements contained by the '%s' trait\" % ct)\n            if hasattr(new, ct):\n                elements = getattr(new, ct)\n                logger.debug(\"%d element(s) found\" % len(elements))\n                for element in elements:\n                    pydot_node = Node(str(id(element)))\n                    dot_attrs = node_mapping.dot_node\n                    if dot_attrs is not None:\n                        self._style_node(pydot_node, dot_attrs)\n                    dot.add_node(pydot_node)\n\n                    new.on_trait_change(self.map_element, ct+\"_items\")\n\n        logger.debug(\"Retrieving xdot data and forming pydot graph!\")\n        xdot = graph_from_dot_data(dot.create(self.program, \"xdot\"))\n        parser = XDotParser()\n\n        for node in xdot.get_node_list():\n            diagram_node = parser.parse_node(node)\n            logger.debug(\n                \"Parsed node [%s] and received diagram node [%s]\" %\n                (node, diagram_node)\n            )\n            if diagram_node is not None:\n                for node_mapping in self.nodes: # FIXME: slow\n                    ct = node_mapping.containment_trait\n                    for element in getattr(new, ct):\n                        if str(id(element)) == diagram_node.dot_node.get_name():\n                            logger.debug(\n                                \"Referencing element [%s] from diagram node [%s]\" %\n                                (element, diagram_node)\n                            )\n                            diagram_node.element = element\n                            break\n\n                    # Tools\n                    if isinstance(diagram_node.element, node_mapping.element):\n                        for tool in node_mapping.tools:\n                            logger.debug(\n                                \"Adding tool [%s] to diagram node [%s]\" %\n                                (tool, diagram_node)\n                            )\n                            diagram_node.tools.append(tool(diagram_node))\n\n                else:\n                    if diagram_node.element is None:\n                        logger.warning(\"Diagram node not referenced to element\")\n\n                self.diagram.diagram_canvas.add(diagram_node)\n\n        del parser"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef unmap_model(self, old):\n\n        for node_mapping in self.nodes:\n            ct = node_mapping.containment_trait\n            if hasattr(old, ct):\n                old_elements = getattr(old, ct)\n                for old_element in old_elements:\n                    old.on_trait_change(\n                        self.map_element, ct+\"_items\", remove=True\n                    )", "response": "Removes listeners from a domain model"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nhandling mapping elements to diagram components", "response": "def map_element(self, obj, name, event):\n        \"\"\" Handles mapping elements to diagram components \"\"\"\n\n        canvas = self.diagram.diagram_canvas\n        parser = XDotParser()\n\n        for element in event.added:\n            logger.debug(\"Mapping new element [%s] to diagram node\" % element)\n            for node_mapping in self.nodes:\n                ct = name[:-6] #strip '_items'\n                if node_mapping.containment_trait == ct:\n                    dot_attrs = node_mapping.dot_node\n                    dot = Dot()\n                    graph_node = Node(str(id(element)))\n                    self._style_node(graph_node, dot_attrs)\n                    dot.add_node(graph_node)\n                    xdot = graph_from_dot_data(dot.create(self.program,\"xdot\"))\n                    diagram_nodes = parser.parse_nodes(xdot)#.get_node_list())\n                    for dn in diagram_nodes:\n                        if dn is not None:\n                            dn.element = element\n                            # Tools\n                            for tool in node_mapping.tools:\n                                dn.tools.append(tool(dn))\n\n                            canvas.add(dn)\n                            canvas.request_redraw()\n\n        for element in event.removed:\n            logger.debug(\"Unmapping element [%s] from diagram\" % element)\n            for component in canvas.components:\n                if element == component.element:\n                    canvas.remove(component)\n                    canvas.request_redraw()\n                    break"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse xdot data and returns the associated components.", "response": "def parse_xdot_data(self, data):\n        \"\"\" Parses xdot data and returns the associated components. \"\"\"\n\n        parser = self.parser\n#        if pyparsing_version >= \"1.2\":\n#            parser.parseWithTabs()\n        if data:\n            return parser.parseString(data)\n        else:\n            return []"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndefine the parser for the internal parser.", "response": "def define_parser(self):\n        \"\"\" Defines xdot grammar.\n\n        @see: http://graphviz.org/doc/info/output.html#d:xdot \"\"\"\n\n        # Common constructs.\n        point = Group(integer.setResultsName(\"x\") +\n                      integer.setResultsName(\"y\"))\n        n_points = (integer.setResultsName(\"n\") +\n            OneOrMore(point).setResultsName(\"points\"))\n        n_bytes = Suppress(integer) + Suppress(minus) + \\\n            Word(printables).setResultsName(\"b\")\n        justify = ToInteger(\n            Literal(\"-1\") | Literal(\"0\") | Literal(\"1\")\n        ).setResultsName(\"j\")\n\n        # Attributes ----------------------------------------------------------\n\n        # Set fill color. The color value consists of the n bytes following\n        # the '-'.\n        fill = (Literal(\"C\").suppress() + Suppress(integer) + Suppress(minus) +\n            colour.setResultsName(\"color\")).setResultsName(\"fill\")\n\n        # Set pen color. The color value consists of the n bytes following '-'.\n        stroke = (Literal(\"c\").suppress() + Suppress(integer) +\n            Suppress(minus) + colour.setResultsName(\"color\")\n        ).setResultsName(\"stroke\")\n\n        # Set font. The font size is s points. The font name consists of the\n        # n bytes following '-'.\n        font = (Literal(\"F\").suppress() + real.setResultsName(\"s\") +\n            n_bytes).setResultsName(\"font\")\n\n        # Set style attribute. The style value consists of the n bytes\n        # following '-'. The syntax of the value is the same as specified for\n        # a styleItem in style.\n        style = (Literal(\"S\").suppress() + n_bytes).setResultsName(\"style\")\n\n        # Shapes --------------------------------------------------------------\n\n        # Filled ellipse ((x-x0)/w)^2 + ((y-y0)/h)^2 = 1\n        filled_ellipse = (Literal(\"E\").suppress() +\n            integer.setResultsName(\"x0\") + integer.setResultsName(\"y0\") +\n            integer.setResultsName(\"w\") + integer.setResultsName(\"h\")\n        ).setResultsName(\"filled_ellipse\")\n\n        # Unfilled ellipse ((x-x0)/w)^2 + ((y-y0)/h)^2 = 1\n        ellipse = (Literal(\"e\").suppress() +\n            integer.setResultsName(\"x0\") + integer.setResultsName(\"y0\") +\n            integer.setResultsName(\"w\") + integer.setResultsName(\"h\")\n        ).setResultsName(\"ellipse\")\n\n        # Filled polygon using the given n points.\n        filled_polygon = (Literal(\"P\").suppress() +\n            n_points).setResultsName(\"filled_polygon\")\n\n        # Unfilled polygon using the given n points.\n        polygon = (Literal(\"p\").suppress() +\n            n_points).setResultsName(\"polygon\")\n\n        # Polyline using the given n points.\n        polyline = (Literal(\"L\").suppress() +\n            n_points).setResultsName(\"polyline\")\n\n        # B-spline using the given n control points.\n        bspline = (Literal(\"B\").suppress() +\n            n_points).setResultsName(\"bspline\")\n\n        # Filled B-spline using the given n control points.\n        filled_bspline = (Literal(\"b\").suppress() +\n            n_points).setResultsName(\"filled_bspline\")\n\n        # Text drawn using the baseline point (x,y). The text consists of the\n        # n bytes following '-'. The text should be left-aligned (centered,\n        # right-aligned) on the point if j is -1 (0, 1), respectively. The\n        # value w gives the width of the text as computed by the library.\n        text = (Literal(\"T\").suppress() + integer.setResultsName(\"x\") +\n            integer.setResultsName(\"y\") + justify +\n            integer.setResultsName(\"w\") + n_bytes).setResultsName(\"text\")\n\n        # Externally-specified image drawn in the box with lower left corner\n        # (x,y) and upper right corner (x+w,y+h). The name of the image\n        # consists of the n bytes following '-'. This is usually a bitmap\n        # image. Note that the image size, even when converted from pixels to\n        # points, might be different from the required size (w,h). It is\n        # assumed the renderer will perform the necessary scaling.\n        image = (Literal(\"I\").suppress() + integer.setResultsName(\"x\") +\n            integer.setResultsName(\"y\") + integer.setResultsName(\"w\") +\n            integer.setResultsName(\"h\") + n_bytes).setResultsName(\"image\")\n\n\n        # The value of the drawing attributes consists of the concatenation of\n        # some (multi-)set of the 13 rendering or attribute operations.\n        value = (Optional(quote).suppress() + OneOrMore(filled_ellipse |\n            ellipse | filled_polygon | polygon | polyline | bspline |\n            filled_bspline | text | fill | stroke | font | style | image) +\n            Optional(quote).suppress()).setResultsName(\"value\")\n\n        # Drawing operation.\n#        draw_ = Literal(\"_draw_\") + Suppress(equals) + value\n#        # Label drawing.\n#        ldraw_ = Literal(\"_ldraw_\") + Suppress(equals) + value\n#        # Edge head arrowhead drawing.\n#        hdraw_ = Literal(\"_hdraw_\") + Suppress(equals) + value\n#        # Edge tail arrowhead drawing.\n#        tdraw_ = Literal(\"_tdraw_\") + Suppress(equals) + value\n#        # Edge head label drawing.\n#        hldraw_ = Literal(\"_hldraw_\") + Suppress(equals) + value\n#        # Edge tail label drawing.\n#        tldraw_ = Literal(\"_tldraw_\") + Suppress(equals) + value\n\n        # Parse actions.\n#        n_points.setParseAction(self.proc_points)\n\n        # Attribute parse actions.\n        fill.setParseAction(self.proc_fill_color)\n        stroke.setParseAction(self.proc_stroke_color)\n        font.setParseAction(self.proc_font)\n        style.setParseAction(self.proc_style)\n\n        # Shape parse actions.\n        filled_ellipse.setParseAction(self.proc_filled_ellipse)\n        ellipse.setParseAction(self.proc_unfilled_ellipse)\n        filled_polygon.setParseAction(self.proc_filled_polygon)\n        polygon.setParseAction(self.proc_unfilled_polygon)\n        polyline.setParseAction(self.proc_polyline)\n        bspline.setParseAction(self.proc_unfilled_bspline)\n        filled_bspline.setParseAction(self.proc_filled_bspline)\n        text.setParseAction(self.proc_text)\n        image.setParseAction(self.proc_image)\n\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _proc_color(self, tokens):\n\n        keys = tokens.keys()\n        if \"red\" in keys: # RGB(A)\n            rr, gg, bb = tokens[\"red\"], tokens[\"green\"], tokens[\"blue\"]\n            hex2int = lambda h: int(h, 16)\n            if \"alpha\" in keys:\n                a = tokens[\"alpha\"]\n                c = str((hex2int(rr), hex2int(gg), hex2int(bb), hex2int(a)))\n            else:\n                c = str((hex2int(rr), hex2int(gg), hex2int(bb)))\n        elif \"hue\" in keys: # HSV\n            r, g, b = hsv_to_rgb(tokens[\"hue\"],\n                                 tokens[\"saturation\"],\n                                 tokens[\"value\"])\n            c = str((int(r*255), int(g*255), int(b*255)))\n        else:\n            c = tokens[\"color\"]\n\n        return c", "response": "Process the color traits of a Pen instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the components of an ellipse.", "response": "def _proc_ellipse(self, tokens, filled):\n        \"\"\" Returns the components of an ellipse. \"\"\"\n\n        component = Ellipse(pen=self.pen,\n                            x_origin=tokens[\"x0\"],\n                            y_origin=tokens[\"y0\"],\n                            e_width=tokens[\"w\"],\n                            e_height=tokens[\"h\"],\n                            filled=filled)\n\n        return component"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _proc_polygon(self, tokens, filled):\n\n        pts = [(p[\"x\"], p[\"y\"]) for p in tokens[\"points\"]]\n        component = Polygon(pen=self.pen, points=pts, filled=filled)\n\n        return component", "response": "Returns the components of a polygon."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the components of a polyline.", "response": "def proc_polyline(self, tokens):\n        \"\"\" Returns the components of a polyline. \"\"\"\n\n        pts = [(p[\"x\"], p[\"y\"]) for p in tokens[\"points\"]]\n        component = Polyline(pen=self.pen, points=pts)\n\n        return component"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _proc_bspline(self, tokens, filled):\n\n        pts = [(p[\"x\"], p[\"y\"]) for p in tokens[\"points\"]]\n        component = BSpline(pen=self.pen, points=pts, filled=filled)\n\n        return component", "response": "Processes a B - spline."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef proc_image(self, tokens):\n\n        print \"IMAGE:\", tokens, tokens.asList(), tokens.keys()\n\n        raise NotImplementedError", "response": "Returns the components of an image."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef render_grid_file(context, f):\n\t\n\tf.seek(0)  # Ensure we are reading from the beginning.\n\tresponse = context.response  # Frequently accessed, so made local.  Useless optimization on Pypy.\n\t\n\tif __debug__:  # We add some useful diagnostic information in development, omitting from production due to sec.\n\t\tresponse.headers['Grid-ID'] = str(f._id)  # The GridFS file ID.\n\t\tlog.debug(\"Serving GridFS file.\", extra=dict(\n\t\t\t\tidentifier = str(f._id),\n\t\t\t\tfilename = f.filename,\n\t\t\t\tlength = f.length,\n\t\t\t\tmimetype = f.content_type\n\t\t\t))\n\t\n\tresponse.conditional_response = True\n\tresponse.accept_ranges = 'bytes'  # We allow returns of partial content, if requested.\n\tresponse.content_type = f.content_type  # Direct transfer of GridFS-stored MIME type.\n\tresponse.content_length = f.length  # The length was pre-computed when the file was uploaded.\n\tresponse.content_md5 = response.etag = f.md5  # As was the MD5, used for simple integrity testing.\n\tresponse.last_modified = f.metadata.get('modified', None)  # Optional additional metadata.\n\tresponse.content_disposition = 'attachment; filename=' + f.name  # Preserve the filename through to the client.\n\t\n\t# Being asked for a range or not determines the streaming style used.\n\tif context.request.if_range.match_response(response):\n\t\tresponse.body_file = f  # Support seek + limited read.\n\telse:\n\t\tresponse.app_iter = iter(f)  # Assign the body as a streaming, chunked iterator.\n\t\n\treturn True", "response": "Allow direct use of GridOut GridFS file wrappers as endpoint responses."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _draw_mainlayer(self, gc, view_bounds=None, mode=\"default\"):\n\n        x_origin = self.x_origin\n        y_origin = self.y_origin\n\n        gc.save_state()\n        try:\n#            self._draw_bounds(gc)\n            gc.begin_path()\n            gc.translate_ctm(x_origin, y_origin)\n            gc.scale_ctm(self.e_width, self.e_height)\n            gc.arc(0.0, 0.0, 1.0, 0, 2.0*pi)\n            gc.close_path()\n\n            # Draw stroke at same scale as graphics context\n#            ctm = gc.get_ctm()\n#            if hasattr(ctm, \"__len__\") and len(ctm) == 6:\n#                scale = sqrt( (ctm[0]+ctm[1]) * (ctm[0]+ctm[1]) / 2.0 + \\\n#                              (ctm[2]+ctm[3]) * (ctm[2]+ctm[3]) / 2.0 )\n#            elif hasattr(gc, \"get_ctm_scale\"):\n#                scale = gc.get_ctm_scale()\n#            else:\n#                raise RuntimeError(\"Unable to get scale from GC.\")\n\n            gc.set_line_width(self.pen.line_width)\n            gc.set_stroke_color(self.pen.color_)\n\n            if self.filled:\n                gc.set_fill_color(self.pen.fill_color_)\n                gc.draw_path(FILL_STROKE)\n            else:\n                gc.stroke_path()\n        finally:\n            gc.restore_state()", "response": "Draws the mainlayer of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntests if the point is within this ellipse", "response": "def is_in(self, point_x, point_y):\n        \"\"\" Test if the point is within this ellipse \"\"\"\n\n        x = self.x_origin\n        y = self.y_origin\n        a = self.e_width#/2 # FIXME: Why divide by two\n        b = self.e_height#/2\n\n        return ((point_x-x)**2/(a**2)) + ((point_y-y)**2/(b**2)) < 1.0"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _draw_bounds(self, gc):\n\n        dx, dy = self.bounds\n        x, y = self.position\n        gc.rect(x, y, dx, dy)\n        gc.stroke_path()", "response": "Draw the component bounds for testing purposes"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef polar(x, y, deg=0):        # radian if deg=0; degree if deg=1\n\n    if deg:\n        return hypot(x, y), 180.0 * atan2(y, x) / pi\n    else:\n        return hypot(x, y), atan2(y, x)", "response": "Convert from rectangular x y to polar"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cubic(a, b, c, d=None):\n\n    if d: # (ax^3 + bx^2 + cx + d = 0)\n        a, b, c = b / float(a), c / float(a), d / float(a)\n\n    t = a / 3.0\n    p, q = b - 3 * t**2, c - b * t + 2 * t**3\n    u, v = quadratic(q, -(p/3.0)**3)\n\n    if type(u) == type(0j): # complex cubic root\n        r, w = polar(u.real, u.imag)\n        y1 = 2 * cbrt(r) * cos(w / 3.0)\n    else: # real root\n        y1 = cbrt(u) + cbrt(v)\n    y2, y3 = quadratic(y1, p + y1**2)\n\n    return y1 - t, y2 - t, y3 - t", "response": "This function calculates the cubic root of a set of roots."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef start(self, context):\n\t\t\n\t\tif __debug__:\n\t\t\tlog.info(\"Connecting SQLAlchemy database layer.\", extra=dict(\n\t\t\t\t\turi = redact_uri(self.uri),\n\t\t\t\t\tconfig = self.config,\n\t\t\t\t\talias = self.alias,\n\t\t\t\t))\n\t\t\n\t\t# Construct the engine.\n\t\tengine = self.engine = create_engine(self.uri, **self.config)\n\t\t\n\t\t# Construct the session factory.\n\t\tself.Session = scoped_session(sessionmaker(bind=engine))\n\t\t\n\t\t# Test the connection.\n\t\tengine.connect().close()\n\t\t\n\t\t# Assign the engine to our database alias.\n\t\tcontext.db[self.alias] = engine", "response": "Construct the SQLAlchemy engine and session factory."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses the dot_code string and replaces the existing model with the graph.", "response": "def _parse_dot_code_fired(self):\n        \"\"\" Parses the dot_code string and replaces the existing model.\n        \"\"\"\n        parser = GodotDataParser()\n        graph  = parser.parse_dot_data(self.dot_code)\n        if graph is not None:\n            self.model = graph"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nhandle the new Graph action.", "response": "def new_model(self, info):\n        \"\"\" Handles the new Graph action. \"\"\"\n\n        if info.initialized:\n            retval = confirm(parent  = info.ui.control,\n                             message = \"Replace existing graph?\",\n                             title   = \"New Graph\",\n                             default = YES)\n            if retval == YES:\n                self.model = Graph()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef open_file(self, info):\n\n        if not info.initialized: return # Escape.\n\n#        retval = self.edit_traits(parent=info.ui.control, view=\"file_view\")\n\n        dlg = FileDialog( action = \"open\",\n            wildcard = \"Graphviz Files (*.dot, *.xdot, *.txt)|\"\n                \"*.dot;*.xdot;*.txt|Dot Files (*.dot)|*.dot|\"\n                \"All Files (*.*)|*.*|\")\n\n        if dlg.open() == OK:\n            parser = GodotDataParser()\n            model = parser.parse_dot_file(dlg.path)\n            if model is not None:\n                self.model = model\n            else:\n                print \"error parsing: %s\" % dlg.path\n\n            self.save_file = dlg.path\n\n        del dlg", "response": "Handles the open action."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsaving the current model to the last file.", "response": "def save(self, info):\n        \"\"\" Handles saving the current model to the last file.\n        \"\"\"\n        save_file = self.save_file\n\n        if not isfile(save_file):\n            self.save_as(info)\n        else:\n            fd = None\n            try:\n                fd = open(save_file, \"wb\")\n                dot_code = str(self.model)\n                fd.write(dot_code)\n            finally:\n                if fd is not None:\n                    fd.close()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsave the current model to file.", "response": "def save_as(self, info):\n        \"\"\" Handles saving the current model to file.\n        \"\"\"\n        if not info.initialized:\n            return\n\n#        retval = self.edit_traits(parent=info.ui.control, view=\"file_view\")\n\n        dlg = FileDialog( action = \"save as\",\n            wildcard = \"Graphviz Files (*.dot, *.xdot, *.txt)|\" \\\n                \"*.dot;*.xdot;*.txt|Dot Files (*.dot)|*.dot|\" \\\n                \"All Files (*.*)|*.*|\")\n\n        if dlg.open() == OK:\n            fd = None\n            try:\n                fd = open(dlg.path, \"wb\")\n                dot_code = str(self.model)\n                fd.write(dot_code)\n\n                self.save_file = dlg.path\n\n            except:\n                error(parent=info.ui.control, title=\"Save Error\",\n                      message=\"An error was encountered when saving\\nto %s\"\n                      % self.file)\n\n            finally:\n                if fd is not None:\n                    fd.close()\n\n        del dlg"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef configure_graph(self, info):\n        if info.initialized:\n            self.model.edit_traits(parent=info.ui.control,\n                kind=\"live\", view=attr_view)", "response": "Configures the graph of the node."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nhandle display of the nodes editor.", "response": "def configure_nodes(self, info):\n        \"\"\" Handles display of the nodes editor.\n        \"\"\"\n        if info.initialized:\n            self.model.edit_traits(parent=info.ui.control,\n                kind=\"live\", view=nodes_view)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nhandling display of the edges editor.", "response": "def configure_edges(self, info):\n        \"\"\" Handles display of the edges editor.\n        \"\"\"\n        if info.initialized:\n            self.model.edit_traits(parent=info.ui.control,\n                kind=\"live\", view=edges_view)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nhandling displaying a view about Godot.", "response": "def about_godot(self, info):\n        \"\"\" Handles displaying a view about Godot.\n        \"\"\"\n        if info.initialized:\n            self.edit_traits(parent=info.ui.control,\n                kind=\"livemodal\", view=about_view)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_node(self, info):\n        if not info.initialized:\n            return\n\n        graph = self._request_graph(info.ui.control)\n\n        if graph is None:\n            return\n\n        IDs = [v.ID for v in graph.nodes]\n        node = Node(ID=make_unique_name(\"node\", IDs))\n        graph.nodes.append(node)\n\n        retval = node.edit_traits(parent=info.ui.control, kind=\"livemodal\")\n\n        if not retval.result:\n            graph.nodes.remove(node)", "response": "Adds a Node to the graph."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_edge(self, info):\n        if not info.initialized:\n            return\n\n        graph = self._request_graph(info.ui.control)\n\n        if graph is None:\n            return\n\n        n_nodes = len(graph.nodes)\n        IDs = [v.ID for v in graph.nodes]\n\n        if n_nodes == 0:\n            tail_node = Node(ID=make_unique_name(\"node\", IDs))\n            head_name = make_unique_name(\"node\", IDs + [tail_node.ID])\n            head_node = Node(ID=head_name)\n        elif n_nodes == 1:\n            tail_node = graph.nodes[0]\n            head_node = Node(ID=make_unique_name(\"node\", IDs))\n        else:\n            tail_node = graph.nodes[0]\n            head_node = graph.nodes[1]\n\n        edge = Edge(tail_node, head_node, _nodes=graph.nodes)\n\n        retval = edge.edit_traits(parent=info.ui.control, kind=\"livemodal\")\n\n        if retval.result:\n            graph.edges.append(edge)", "response": "Adds an edge to the graph."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_subgraph(self, info):\n        if not info.initialized:\n            return\n\n        graph = self._request_graph(info.ui.control)\n\n        if graph is not None:\n            subgraph = Subgraph()#root=graph, parent=graph)\n            retval = subgraph.edit_traits(parent = info.ui.control,\n                                          kind   = \"livemodal\")\n            if retval.result:\n                graph.subgraphs.append(subgraph)", "response": "Handles adding a subgraph to the main graph."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_cluster(self, info):\n\n        if not info.initialized:\n            return\n\n        graph = self._request_graph(info.ui.control)\n\n        if graph is not None:\n            cluster = Cluster()#root=graph, parent=graph)\n            retval = cluster.edit_traits(parent = info.ui.control,\n                                         kind   = \"livemodal\")\n            if retval.result:\n                graph.clusters.append(cluster)", "response": "Handles adding a Cluster to the main graph."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndisplay a dialog for graph selection if more than one exists. Returns None if the dialog is canceled.", "response": "def _request_graph(self, parent=None):\n        \"\"\" Displays a dialog for graph selection if more than one exists.\n            Returns None if the dialog is canceled.\n        \"\"\"\n\n        if (len(self.all_graphs) > 1) and (self.select_graph):\n            retval = self.edit_traits(parent = parent,\n                                      view   = \"all_graphs_view\")\n            if not retval.result:\n                return None\n\n        if self.selected_graph is not None:\n            return self.selected_graph\n        else:\n            return self.model"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef godot_options(self, info):\n\n        if info.initialized:\n            self.edit_traits( parent = info.ui.control,\n                              kind   = \"livemodal\",\n                              view   = \"options_view\" )", "response": "Handles the options menu."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef configure_dot_code(self, info):\n        if not info.initialized:\n            return\n\n        self.dot_code = str(self.model)\n        retval = self.edit_traits( parent = info.ui.control,\n                                   kind   = \"livemodal\",\n                                   view   = \"dot_code_view\" )", "response": "Configures the dot code in a text editor."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nhandles the user attempting to exit Godot.", "response": "def on_exit(self, info):\n        \"\"\" Handles the user attempting to exit Godot.\n        \"\"\"\n        if self.prompt_on_exit:# and (not is_ok):\n            retval = confirm(parent  = info.ui.control,\n                             message = \"Exit Godot?\",\n                             title   = \"Confirm exit\",\n                             default = YES)\n            if retval == YES:\n                self._on_close( info )\n        else:\n            self._on_close( info )"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmoves components relative to their origin.", "response": "def move_to_origin(components):\n    \"\"\" Components are positioned relative to their container. Use this\n        method to position the bottom-left corner of the components at\n        the origin.\n    \"\"\"\n    for component in components:\n        if isinstance(component, Ellipse):\n            component.x_origin = component.e_width\n            component.y_origin = component.e_height\n\n        elif isinstance(component, (Polygon, BSpline)):\n            min_x = min( [t[0] for t in component.points] )\n            min_y = min( [t[1] for t in component.points] )\n\n            component.points = [\n                ( p[0]-min_x, p[1]-min_y ) for p in component.points\n            ]\n\n        elif isinstance(component, Text):\n            font = str_to_font( str(component.pen.font) )\n            component.text_x = 0#-( component.text_w / 2 )\n            component.text_y = 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef save_to_file_like(self, flo, format=None, **kwargs):\n        format = self.format if format is None else format\n        save = getattr(self, \"save_%s\" % format, None)\n        if save is None:\n            raise ValueError(\"Unknown format '%s'.\" % format)\n        save(flo, **kwargs)", "response": "Save the object to a given file like object in the given format."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading the object from a given file like object with the given protocol.", "response": "def load_from_file_like(cls, flo, format=None):\n        \"\"\" Load the object to a given file like object with the given\n            protocol.\n        \"\"\"\n        format = self.format if format is None else format\n        load = getattr(cls, \"load_%s\" % format, None)\n        if load is None:\n            raise ValueError(\"Unknown format '%s'.\" % format)\n        return load(flo)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef save_to_file(self, filename, format=None, **kwargs):\n        if format is None:\n            # try to derive protocol from file extension\n            format = format_from_extension(filename)\n        with file(filename, 'wb') as fp:\n            self.save_to_file_like(fp, format, **kwargs)", "response": "Save the object to file given by filename."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef load_from_file(cls, filename, format=None):\n        if format is None:\n            # try to derive protocol from file extension\n            format = format_from_extension(filename)\n        with file(filename,'rbU') as fp:\n            obj = cls.load_from_file_like(fp, format)\n            obj.filename = filename\n            return obj", "response": "Load an instance of the class from the given file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef Alias(name, **metadata):\n\n    return Property(lambda obj: getattr(obj, name),\n                    lambda obj, val: setattr(obj, name, val),\n                    **metadata)", "response": "Syntactically concise alias trait but creates a pair of lambda\n    functions for every alias you declare."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse(filename, encoding=None):\n\n    with open(filename, encoding=encoding) as source:\n        for line in source:\n            for word in line.split():\n                yield word", "response": "Simple file parsing generator"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef startwords(self):\n\n        if self._start_words is not None:\n            return self._start_words\n        else:\n            self._start_words = list(filter(\n                lambda x: str.isupper(x[0][0]) and x[0][-1] not in ['.', '?', '!'],\n                self.content.keys()\n            ))\n            return self._start_words", "response": "Return a list of start words for the current language."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a new chain to the current shelve file.", "response": "def add_chain(self, name, order):\n        \"\"\"\n        Add chain to current shelve file\n\n        Args:\n            name: chain name\n            order: markov chain order\n        \"\"\"\n\n        if name not in self.chains:\n            setattr(self.chains, name, MarkovChain(order=order))\n        else:\n            raise ValueError(\"Chain with this name already exists\")"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving a chain from the current shelve file.", "response": "def remove_chain(self, name):\n        \"\"\"\n        Remove chain from current shelve file\n\n        Args:\n            name: chain name\n        \"\"\"\n\n        if name in self.chains:\n            delattr(self.chains, name)\n        else:\n            raise ValueError(\"Chain with this name not found\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nbuild a markov chain from source on top of existin chain.", "response": "def build_chain(self, source, chain):\n        \"\"\"\n        Build markov chain from source on top of existin chain\n\n        Args:\n            source: iterable which will be used to build chain\n            chain: MarkovChain in currently loaded shelve file that\n                   will be extended by source\n        \"\"\"\n\n        for group in WalkByGroup(source, chain.order+1):\n            pre = group[:-1]\n            res = group[-1]\n\n            if pre not in chain.content:\n                chain.content[pre] = {res: 1}\n            else:\n                if res not in chain.content[pre]:\n                    chain.content[pre][res] = 1\n                else:\n                    chain.content[pre][res] += 1\n\n        chain.decache()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create(self, prog=None, format=None):\n        prog = self.program if prog is None else prog\n        format = self.format if format is None else format\n\n        # Make a temporary file ...\n        tmp_fd, tmp_name = tempfile.mkstemp()\n        os.close( tmp_fd )\n        # ... and save the graph to it.\n        dot_fd = file( tmp_name, \"w+b\" )\n        self.save_dot( dot_fd )\n        dot_fd.close()\n\n        # Get the temporary file directory name.\n        tmp_dir = os.path.dirname( tmp_name )\n\n        # TODO: Shape image files (See PyDot). Important.\n\n        # Process the file using the layout program, specifying the format.\n        p = subprocess.Popen(\n            ( self.programs[ prog ], '-T'+format, tmp_name ),\n            cwd=tmp_dir,\n            stderr=subprocess.PIPE, stdout=subprocess.PIPE)\n\n        stderr = p.stderr\n        stdout = p.stdout\n\n        # Make sense of the standard output form the process.\n        stdout_output = list()\n        while True:\n            data = stdout.read()\n            if not data:\n                break\n            stdout_output.append(data)\n        stdout.close()\n\n        if stdout_output:\n            stdout_output = ''.join(stdout_output)\n\n        # Similarly so for any standard error.\n        if not stderr.closed:\n            stderr_output = list()\n            while True:\n                data = stderr.read()\n                if not data:\n                    break\n                stderr_output.append(data)\n            stderr.close()\n\n            if stderr_output:\n                stderr_output = ''.join(stderr_output)\n\n        #pid, status = os.waitpid(p.pid, 0)\n        status = p.wait()\n\n        if status != 0 :\n            logger.error(\"Program terminated with status: %d. stderr \" \\\n                \"follows: %s\" % ( status, stderr_output ) )\n        elif stderr_output:\n            logger.error( \"%s\", stderr_output )\n\n        # TODO: Remove shape image files from the temporary directory.\n\n        # Remove the temporary file.\n        os.unlink(tmp_name)\n\n        return stdout_output", "response": "Creates and returns a representation of the graph using the given layout program."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a node to the graph.", "response": "def add_node(self, node_or_ID, **kwds):\n        \"\"\" Adds a node to the graph.\n        \"\"\"\n        if not isinstance(node_or_ID, Node):\n            nodeID = str( node_or_ID )\n            if nodeID in self.nodes:\n                node = self.nodes[ self.nodes.index(nodeID) ]\n            else:\n                if self.default_node is not None:\n                    node = self.default_node.clone_traits(copy=\"deep\")\n                    node.ID = nodeID\n                else:\n                    node = Node(nodeID)\n                self.nodes.append( node )\n        else:\n            node = node_or_ID\n            if node in self.nodes:\n                node = self.nodes[ self.nodes.index(node_or_ID) ]\n            else:\n                self.nodes.append( node )\n\n        node.set( **kwds )\n\n        return node"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete_node(self, node_or_ID):\n        if isinstance(node_or_ID, Node):\n#            name = node_or_ID.ID\n            node = node_or_ID\n        else:\n#            name = node_or_ID\n            node = self.get_node(node_or_ID)\n            if node is None:\n                raise ValueError(\"Node %s does not exists\" % node_or_ID)\n\n#        try:\n#            del self.nodes[name]\n#        except:\n#            raise ValueError(\"Node %s does not exists\" % name)\n\n#        self.nodes = [n for n in self.nodes if n.ID != name]\n#        idx = self.nodes.index(name)\n#        return self.nodes.pop(idx)\n\n        self.nodes.remove(node)", "response": "Removes a node from the graph."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_node(self, ID):\n        for node in self.nodes:\n            if node.ID == str(ID):\n                return node\n        return None", "response": "Returns the node with the given ID or None if no node with the given ID is found."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delete_edge(self, tail_node_or_ID, head_node_or_ID):\n        if isinstance(tail_node_or_ID, Node):\n            tail_node = tail_node_or_ID\n        else:\n            tail_node = self.get_node(tail_node_or_ID)\n\n        if isinstance(head_node_or_ID, Node):\n            head_node = head_node_or_ID\n        else:\n            head_node = self.get_node(head_node_or_ID)\n\n        if (tail_node is None) or (head_node is None):\n            return None\n\n        for i, edge in enumerate(self.edges):\n            if (edge.tail_node == tail_node) and (edge.head_node == head_node):\n                edge = self.edges.pop(i)\n                return edge\n\n        return None", "response": "Removes an edge from the graph. Returns the deleted edge or None."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding an edge to the graph.", "response": "def add_edge(self, tail_node_or_ID, head_node_or_ID, **kwds):\n        \"\"\" Adds an edge to the graph.\n        \"\"\"\n        tail_node = self.add_node(tail_node_or_ID)\n        head_node = self.add_node(head_node_or_ID)\n\n        # Only top level graphs are directed and/or strict.\n        if \"directed\" in self.trait_names():\n            directed = self.directed\n        else:\n            directed = False\n\n        if self.default_edge is not None:\n            edge = self.default_edge.clone_traits(copy=\"deep\")\n            edge.tail_node = tail_node\n            edge.head_node = head_node\n            edge.conn = \"->\" if directed else \"--\"\n            edge.set( **kwds )\n        else:\n            edge = Edge(tail_node, head_node, directed, **kwds)\n\n        if \"strict\" in self.trait_names():\n            if not self.strict:\n                self.edges.append(edge)\n            else:\n                self.edges.append(edge)\n                # FIXME: Implement strict graphs.\n#                raise NotImplementedError\n        else:\n            self.edges.append(edge)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_subgraph(self, subgraph_or_ID):\n        if not isinstance(subgraph_or_ID, (godot.subgraph.Subgraph,\n                                           godot.cluster.Cluster)):\n            subgraphID = str( subgraph_or_ID )\n            if subgraph_or_ID.startswith(\"cluster\"):\n                subgraph = godot.cluster.Cluster(ID=subgraphID)\n            else:\n                subgraph = godot.subgraph.Subgraph(ID=subgraphID)\n        else:\n            subgraph = subgraph_or_ID\n\n        subgraph.default_node = self.default_node\n        subgraph.default_edge = self.default_edge\n#        subgraph.level = self.level + 1\n#        subgraph.padding += self.padding\n\n        if isinstance(subgraph, godot.subgraph.Subgraph):\n            self.subgraphs.append(subgraph)\n        elif isinstance(subgraph, godot.cluster.Cluster):\n            self.clusters.append(subgraph)\n        else:\n            raise\n\n        return subgraph", "response": "Adds a subgraph to the graph."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nhandle the Graphviz layout program selection changing.", "response": "def _program_changed(self, new):\n        \"\"\" Handles the Graphviz layout program selection changing.\n        \"\"\"\n        progs = self.progs\n\n        if not progs.has_key(prog):\n            logger.warning( 'GraphViz\\'s executable \"%s\" not found' % prog )\n\n        if not os.path.exists( progs[prog] ) or not \\\n            os.path.isfile( progs[prog] ):\n            logger.warning( \"GraphViz's executable '%s' is not a \"\n                \"file or doesn't exist\" % progs[prog] )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmaintain each edge s list of available nodes.", "response": "def _set_node_lists(self, new):\n        \"\"\" Maintains each edge's list of available nodes.\n        \"\"\"\n        for edge in self.edges:\n            edge._nodes = self.nodes"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse a DOT file and returns a Godot graph.", "response": "def parse_dot_file(filename):\n    \"\"\" Parses a DOT file and returns a Godot graph.\n    \"\"\"\n    parser = GodotDataParser()\n    graph  = parser.parse_dot_file(filename)\n    del parser\n\n    return graph"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _proc_node_stmt(self, toks):\n        opts = toks[1]\n        dummy_node = Node(\"dummy\")\n        # Coerce attribute types.\n        for key, value in opts.iteritems():\n            trait = dummy_node.trait(key)\n            if trait is not None:\n                if trait.is_trait_type( Float ):\n                    opts[key] = float( value )\n\n                elif trait.is_trait_type( Tuple ):\n                    opts[key] = tuple( [float(c) for c in value.split(\",\")] )\n\n        return super(GodotDataParser, self)._proc_node_stmt(toks)", "response": "Return (ADD_NODE, node_name, options)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _proc_edge_stmt(self, toks):\n        opts = toks[3]\n        dummy_edge = Edge(\"dummy1\", \"dummy2\")\n        # Coerce attribute types.\n        for key, value in opts.iteritems():\n            trait = dummy_edge.trait(key)\n            if trait is not None:\n                # FIXME: Implement Graphviz spline types.\n                if trait.is_trait_type( List ):\n                    p = [] # List of float doublets.\n                    for t in value.split( \" \" ):\n                        l = t.split( \",\" )\n                        if len(l) == 3: # pos=\"e,39,61 39,97 39,89 39,80 39,71\"\n                            l.pop(0)\n                        f = [ float(a) for a in l ]\n                        p.append( tuple(f) )\n                    opts[key] = p\n\n                elif trait.is_trait_type( Float ):\n                    opts[key] = float( value )\n\n                elif trait.is_trait_type( Tuple ):\n                    opts[key] = tuple( [float(c) for c in value.split(\",\")] )\n\n        return super(GodotDataParser, self)._proc_edge_stmt(toks)", "response": "Process the edge statement."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_dot_file(self, file_or_filename):\n        if isinstance(file_or_filename, basestring):\n            file = None\n            try:\n                file = open(file_or_filename, \"rb\")\n                data = file.read()\n            except:\n                print \"Could not open %s.\" % file_or_filename\n                return None\n            finally:\n                if file is not None:\n                    file.close()\n        else:\n            file = file_or_filename\n            data = file.read()\n\n        return self.parse_dot_data(data)", "response": "Parses a dot file and returns a graph given a file or a filename."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nbuild a Godot graph instance from parsed data.", "response": "def build_top_graph(self,tokens):\n        \"\"\" Build a Godot graph instance from parsed data.\n        \"\"\"\n        # Get basic graph information.\n        strict = tokens[0] == 'strict'\n        graphtype = tokens[1]\n        directed = graphtype == 'digraph'\n        graphname = tokens[2]\n        # Build the graph\n        graph = Graph(ID=graphname, strict=strict, directed=directed)\n        self.graph = self.build_graph(graph, tokens[3])"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef build_graph(self, graph, tokens):\n        subgraph = None\n\n        for element in tokens:\n            cmd = element[0]\n            if cmd == ADD_NODE:\n                cmd, nodename, opts = element\n                graph.add_node(nodename, **opts)\n\n            elif cmd == ADD_EDGE:\n                cmd, src, dest, opts = element\n                srcport = destport = \"\"\n                if isinstance(src,tuple):\n                    srcport = src[1]\n                    src = src[0]\n                if isinstance(dest,tuple):\n                    destport = dest[1]\n                    dest = dest[0]\n\n                graph.add_edge(src, dest, tailport=srcport, headport=destport,\n                               **opts)\n\n            elif cmd in [ADD_GRAPH_TO_NODE_EDGE,\n                         ADD_GRAPH_TO_GRAPH_EDGE,\n                         ADD_NODE_TO_GRAPH_EDGE]:\n                cmd, src, dest, opts = element\n                srcport = destport = \"\"\n\n                if isinstance(src,tuple):\n                    srcport = src[1]\n\n                if isinstance(dest,tuple):\n                    destport = dest[1]\n\n                if not (cmd == ADD_NODE_TO_GRAPH_EDGE):\n                    if cmd == ADD_GRAPH_TO_NODE_EDGE:\n                        src = subgraph\n                    else:\n                        src = prev_subgraph\n                        dest = subgraph\n                else:\n                    dest = subgraph\n\n                src_is_graph = isinstance(src, (Subgraph, Cluster))\n                dst_is_graph = isinstance(dst, (Subgraph, Cluster))\n\n                if src_is_graph:\n                    src_nodes = src.nodes\n                else:\n                    src_nodes = [src]\n                if dst_is_graph:\n                    dst_nodes = dst.nodes\n                else:\n                    dst_nodes = [dst]\n\n                for src_node in src_nodes:\n                    for dst_node in dst_nodes:\n                        graph.add_edge(from_node=src_node, to_node=dst_node,\n                                       tailport=srcport, headport=destport,\n                                       **kwds)\n\n            elif cmd == SET_GRAPH_ATTR:\n                graph.set( **element[1] )\n\n            elif cmd == SET_DEF_NODE_ATTR:\n                graph.default_node.set( **element[1] )\n\n            elif cmd == SET_DEF_EDGE_ATTR:\n                graph.default_edge.set( **element[1] )\n\n            elif cmd == SET_DEF_GRAPH_ATTR:\n                graph.default_graph.set( **element[1] )\n\n            elif cmd == ADD_SUBGRAPH:\n                cmd, name, elements = element\n                if subgraph:\n                    prev_subgraph = subgraph\n                if name.startswith(\"cluster\"):\n                    cluster = Cluster(ID=name)\n                    cluster = self.build_graph(cluster, elements)\n                    graph.add_cluster(cluster)\n                else:\n                    subgraph = Subgraph(ID=name)\n                    subgraph = self.build_graph(subgraph, elements)\n                    graph.add_subgraph(subgraph)\n\n        return graph", "response": "Builds a Godot graph from a list of tokens."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_time_units_and_multiplier(seconds):\n    for cutoff, units, multiplier in units_table:\n        if seconds < cutoff:\n            break\n    return units, multiplier", "response": "Given a duration in seconds determines the best units and multiplier to use to display the time."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef format_duration(seconds):\n    units, divider = get_time_units_and_multiplier(seconds)\n    seconds *= divider\n    return \"%.3f %s\" % (seconds, units)", "response": "Formats a number of seconds using the best units."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the name of the object.", "response": "def _name_default(self):\n        \"\"\" Trait initialiser.\n        \"\"\"\n        # 'obj' is a io.File\n        self.obj.on_trait_change(self.on_path, \"path\")\n\n        return basename(self.obj.path)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nhandle the file path changing.", "response": "def on_path(self, new):\n        \"\"\" Handle the file path changing.\n        \"\"\"\n        self.name = basename(new)\n        self.graph = self.editor_input.load()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate the toolkit - specific control that represents the editor.", "response": "def create_ui(self, parent):\n        \"\"\" Creates the toolkit-specific control that represents the\n            editor. 'parent' is the toolkit-specific control that is\n            the editor's parent.\n        \"\"\"\n        self.graph = self.editor_input.load()\n\n        view = View(Item(name=\"graph\", editor=graph_tree_editor,\n                show_label=False),\n            id=\"godot.graph_editor\", kind=\"live\", resizable=True)\n\n        ui = self.edit_traits(view=view, parent=parent, kind=\"subpanel\")\n\n        return ui"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsplitting a sequence into pieces of length n.", "response": "def nsplit(seq, n=2):\n    \"\"\" Split a sequence into pieces of length n\n\n    If the length of the sequence isn't a multiple of n, the rest is discarded.\n    Note that nsplit will split strings into individual characters.\n\n    Examples:\n    >>> nsplit(\"aabbcc\")\n    [(\"a\", \"a\"), (\"b\", \"b\"), (\"c\", \"c\")]\n    >>> nsplit(\"aabbcc\",n=3)\n    [(\"a\", \"a\", \"b\"), (\"b\", \"c\", \"c\")]\n\n    # Note that cc is discarded\n    >>> nsplit(\"aabbcc\",n=4)\n    [(\"a\", \"a\", \"b\", \"b\")]\n\n    \"\"\"\n\n    return [xy for xy in itertools.izip(*[iter(seq)]*n)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nyields a sequence of unique items from an iterable.", "response": "def windows(iterable, length=2, overlap=0, padding=True):\n    \"\"\" Code snippet from Python Cookbook, 2nd Edition by David Ascher,\n    Alex Martelli and Anna Ravenscroft; O'Reilly 2005\n\n    Problem: You have an iterable s and need to make another iterable whose\n    items are sublists (i.e., sliding windows), each of the same given length,\n    over s' items, with successive windows overlapping by a specified amount.\n\n    \"\"\"\n\n    it = iter(iterable)\n    results = list(itertools.islice(it, length))\n    while len(results) == length:\n        yield results\n        results = results[length-overlap:]\n        results.extend(itertools.islice(it, length-overlap))\n    if padding and results:\n        results.extend(itertools.repeat(None, length-len(results)))\n        yield results"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef main():\n    application = GodotApplication( id=\"godot\",\n        plugins=[CorePlugin(),\n                 PuddlePlugin(),\n                 WorkbenchPlugin(),\n                 ResourcePlugin(),\n                 GodotPlugin()] )\n\n    application.run()", "response": "Runs the main application."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_children ( self, object ):\n        children = []\n        children.extend( object.subgraphs )\n        children.extend( object.clusters )\n        children.extend( object.nodes )\n        children.extend( object.edges )\n        return children", "response": "Gets the object s children."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nappend a child to the object s children.", "response": "def append_child ( self, object, child ):\n        \"\"\" Appends a child to the object's children.\n        \"\"\"\n        if isinstance( child, Subgraph ):\n            object.subgraphs.append( child )\n\n        elif isinstance( child, Cluster ):\n            object.clusters.append( child )\n\n        elif isinstance( child, Node ):\n            object.nodes.append( child )\n\n        elif isinstance( child, Edge ):\n            object.edges.append( child )\n\n        else:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninserts a child into the object s children.", "response": "def insert_child ( self, object, index, child ):\n        \"\"\" Inserts a child into the object's children.\n        \"\"\"\n        if isinstance( child, Subgraph ):\n            object.subgraphs.insert( index, child )\n\n        elif isinstance( child, Cluster ):\n            object.clusters.insert( index, child )\n\n        elif isinstance( child, Node ):\n            object.nodes.insert( index, child )\n\n        elif isinstance( child, Edge ):\n            object.edges.insert( index, child )\n\n        else:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndelete a child at a specified index from the object s children.", "response": "def delete_child ( self, object, index ):\n        \"\"\" Deletes a child at a specified index from the object's children.\n        \"\"\"\n        if isinstance( child, Subgraph ):\n            object.subgraphs.pop(index)\n\n        elif isinstance( child, Cluster ):\n            object.clusters.pop( index )\n\n        elif isinstance( child, Node ):\n            object.nodes.pop( index )\n\n        elif isinstance( child, Edge ):\n            object.edges.pop( index )\n\n        else:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset up or removes a listener for children being replaced on a specified object.", "response": "def when_children_replaced ( self, object, listener, remove ):\n        \"\"\" Sets up or removes a listener for children being replaced on a\n            specified object.\n        \"\"\"\n        object.on_trait_change( listener, \"subgraphs\", remove = remove,\n                                dispatch = \"fast_ui\" )\n        object.on_trait_change( listener, \"clusters\", remove = remove,\n                                dispatch = \"fast_ui\" )\n        object.on_trait_change( listener, \"nodes\", remove = remove,\n                                dispatch = \"fast_ui\" )\n        object.on_trait_change( listener, \"edges\", remove = remove,\n                                dispatch = \"fast_ui\" )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef when_children_changed ( self, object, listener, remove ):\n        object.on_trait_change( listener, \"subgraphs_items\",\n                                remove = remove, dispatch = \"fast_ui\" )\n        object.on_trait_change( listener, \"clusters_items\",\n                                remove = remove, dispatch = \"fast_ui\" )\n        object.on_trait_change( listener, \"nodes_items\",\n                                remove = remove, dispatch = \"fast_ui\" )\n        object.on_trait_change( listener, \"edges_items\",\n                                remove = remove, dispatch = \"fast_ui\" )", "response": "Called by the parent class when children of the a\n            object have changed."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the label to display for a specified object.", "response": "def get_label ( self, object ):\n        \"\"\" Gets the label to display for a specified object.\n        \"\"\"\n        label = self.label\n        if label[:1] == '=':\n            return label[1:]\n\n        label = xgetattr( object, label, '' )\n\n        if self.formatter is None:\n            return label\n\n        return self.formatter( object, label )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the label for a specified object.", "response": "def set_label ( self, object, label ):\n        \"\"\" Sets the label for a specified object.\n        \"\"\"\n        label_name = self.label\n        if label_name[:1] != '=':\n            xsetattr( object, label_name, label )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef when_label_changed ( self, object, listener, remove ):\n        label = self.label\n        if label[:1] != '=':\n            object.on_trait_change( listener, label, remove = remove,\n                                    dispatch = 'ui' )", "response": "Called when the label of the a\n            specified object has changed."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ninitializes the editor by creating the underlying toolkit widget.", "response": "def init ( self, parent ):\n        \"\"\" Finishes initialising the editor by creating the underlying toolkit\n            widget.\n        \"\"\"\n        self._graph = graph = Graph()\n        ui = graph.edit_traits(parent=parent, kind=\"panel\")\n        self.control = ui.control"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update_editor ( self ):\n        object = self.value\n        # Graph the new object...\n        canvas = self.factory.canvas\n        if canvas is not None:\n            for nodes_name in canvas.node_children:\n                node_children = getattr(object, nodes_name)\n                self._add_nodes(node_children)\n\n            for edges_name in canvas.edge_children:\n                edge_children = getattr(object, edges_name)\n                self._add_edges(edge_children)\n\n        # ...then listen for changes.\n        self._add_listeners()", "response": "Updates the editor when the object trait changes externally to the\n            editor."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _add_listeners ( self ):\n        object = self.value\n        canvas = self.factory.canvas\n        if canvas is not None:\n            for name in canvas.node_children:\n                object.on_trait_change(self._nodes_replaced, name)\n                object.on_trait_change(self._nodes_changed, name + \"_items\")\n\n            for name in canvas.edge_children:\n                object.on_trait_change(self._edges_replaced, name)\n                object.on_trait_change(self._edges_changed, name + \"_items\")\n        else:\n            raise ValueError(\"Graph canvas not set for graph editor.\")", "response": "Adds the event listeners for a specified object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nhandle a list of nodes being replaced.", "response": "def _nodes_replaced(self, object, name, old, new):\n        \"\"\" Handles a list of nodes being set.\n        \"\"\"\n        self._delete_nodes(old)\n        self._add_nodes(new)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _nodes_changed(self, object, name, undefined, event):\n        self._delete_nodes(event.removed)\n        self._add_nodes(event.added)", "response": "Handles addition and removal of nodes."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a node to the graph for each item in features", "response": "def _add_nodes(self, features):\n        \"\"\" Adds a node to the graph for each item in 'features' using\n            the GraphNodes from the editor factory.\n        \"\"\"\n        graph = self._graph\n\n        if graph is not None:\n            for feature in features:\n                for graph_node in self.factory.nodes:\n                    if feature.__class__ in graph_node.node_for:\n                        graph.add_node( id(feature), **graph_node.dot_attr )\n                        break\n\n        graph.arrange_all()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _delete_nodes(self, features):\n        graph = self._graph\n\n        if graph is not None:\n            for feature in features:\n                graph.delete_node( id(feature) )\n\n        graph.arrange_all()", "response": "Removes the nodes corresponding to each item in features."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _edges_replaced(self, object, name, old, new):\n        self._delete_edges(old)\n        self._add_edges(new)", "response": "Handles a list of edges being replaced."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _edges_changed(self, object, name, undefined, event):\n        self._delete_edges(event.removed)\n        self._add_edges(event.added)", "response": "Handles edges changed event."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _add_edges(self, features):\n        graph = self._graph\n\n        if graph is not None:\n            for feature in features:\n                for graph_edge in self.factory.edges:\n                    if feature.__class__ in graph_edge.edge_for:\n                        tail_feature = getattr(feature, graph_edge.tail_name)\n                        head_feature = getattr(feature, graph_edge.head_name)\n\n                        graph.add_edge( id(tail_feature), id(head_feature),\n                            **graph_edge.dot_attr )\n\n                        break\n\n        graph.arrange_all()", "response": "Adds an edge to the graph for each item in features using\n            the GraphEdges from the editor factory."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _delete_edges(self, features):\n        graph = self._graph\n\n        if graph is not None:\n            for feature in features:\n                for graph_edge in self.factory.edges:\n                    if feature.__class__ in graph_edge.edge_for:\n                        tail_feature = getattr(feature, graph_edge.tail_name)\n                        head_feature = getattr(feature, graph_edge.head_name)\n\n                        graph.delete_edge( id(tail_feature), id(head_feature) )\n\n        graph.arrange_all()", "response": "Removes the edges corresponding to each item in features."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\narrange the components of the node using Graphviz.", "response": "def arrange_all(self):\n        \"\"\" Arrange the components of the node using Graphviz.\n        \"\"\"\n        # FIXME: Circular reference avoidance.\n        import godot.dot_data_parser\n        import godot.graph\n\n        graph = godot.graph.Graph( ID=\"g\", directed=True )\n        self.conn = \"->\"\n        graph.edges.append( self )\n\n        xdot_data = graph.create( format=\"xdot\" )\n#        print \"XDOT DATA:\", xdot_data\n\n        parser = godot.dot_data_parser.GodotDataParser()\n        ndata = xdot_data.replace('\\\\\\n','')\n        tokens = parser.dotparser.parseString(ndata)[0]\n\n        for element in tokens[3]:\n            cmd = element[0]\n            if cmd == \"add_edge\":\n                cmd, src, dest, opts = element\n                self.set( **opts )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _parse_xdot_directive(self, name, new):\n        parser = XdotAttrParser()\n        components = parser.parse_xdot_data(new)\n\n        # The absolute coordinate of the drawing container wrt graph origin.\n        x1 = min( [c.x for c in components] )\n        y1 = min( [c.y for c in components] )\n\n        print \"X1/Y1:\", name, x1, y1\n\n        # Components are positioned relative to their container. This\n        # function positions the bottom-left corner of the components at\n        # their origin rather than relative to the graph.\n#        move_to_origin( components )\n\n        for c in components:\n            if isinstance(c, Ellipse):\n                component.x_origin -= x1\n                component.y_origin -= y1\n#                c.position = [ c.x - x1, c.y - y1 ]\n\n            elif isinstance(c, (Polygon, BSpline)):\n                print \"Points:\", c.points\n                c.points = [ (t[0] - x1, t[1] - y1) for t in c.points ]\n                print \"Points:\", c.points\n\n            elif isinstance(c, Text):\n#                font = str_to_font( str(c.pen.font) )\n                c.text_x, c.text_y = c.x - x1, c.y - y1\n\n        container = Container(auto_size=True,\n            position=[ x1, y1 ],\n            bgcolor=\"yellow\")\n\n        container.add( *components )\n\n        if name == \"_draw_\":\n            self.drawing = container\n        elif name == \"_hdraw_\":\n            self.arrowhead_drawing = container\n        else:\n            raise", "response": "Handles parsing Xdot drawing directives."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nhandle the drawing event for the current application.", "response": "def _on_drawing(self, object, name, old, new):\n        \"\"\" Handles the containers of drawing components being set.\n        \"\"\"\n        attrs = [ \"drawing\", \"arrowhead_drawing\" ]\n\n        others = [getattr(self, a) for a in attrs \\\n            if (a != name) and (getattr(self, a) is not None)]\n\n        x, y = self.component.position\n        print \"POS:\", x, y, self.component.position\n\n        abs_x = [d.x + x for d in others]\n        abs_y = [d.y + y for d in others]\n\n        print \"ABS:\", abs_x, abs_y\n\n        # Assume that he new drawing is positioned relative to graph origin.\n        x1 = min( abs_x + [new.x] )\n        y1 = min( abs_y + [new.y] )\n\n        print \"DRAW:\", new.position\n        new.position = [ new.x - x1, new.y - y1 ]\n        print \"DRAW:\", new.position\n\n#        for i, b in enumerate( others ):\n#            self.drawing.position = [100, 100]\n#            self.drawing.request_redraw()\n#            print \"OTHER:\", b.position, abs_x[i] - x1\n#            b.position = [ abs_x[i] - x1, abs_y[i] - y1 ]\n#            b.x = 50\n#            b.y = 50\n#            print \"OTHER:\", b.position, abs_x[i], x1\n\n#        for attr in attrs:\n#            if attr != name:\n#                if getattr(self, attr) is not None:\n#                    drawing = getattr(self, attr)\n#                    drawing.position = [50, 50]\n\n        if old is not None:\n            self.component.remove( old )\n        if new is not None:\n            self.component.add( new )\n\n        print \"POS NEW:\", self.component.position\n        self.component.position = [ x1, y1 ]\n        print \"POS NEW:\", self.component.position\n        self.component.request_redraw()\n        print \"POS NEW:\", self.component.position"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef node_factory(**row_factory_kw):\n\n    if \"__table_editor__\" in row_factory_kw:\n        graph = row_factory_kw[\"__table_editor__\"].object\n        ID = make_unique_name(\"n\", [node.ID for node in graph.nodes])\n        del row_factory_kw[\"__table_editor__\"]\n        return godot.node.Node(ID)\n    else:\n        return godot.node.Node(uuid.uuid4().hex[:6])", "response": "Returns a new node."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef edge_factory(**row_factory_kw):\n\n    if \"__table_editor__\" in row_factory_kw:\n        table_editor = row_factory_kw[\"__table_editor__\"]\n        graph = table_editor.object\n        ID = make_unique_name(\"node\", [node.ID for node in graph.nodes])\n\n        n_nodes = len(graph.nodes)\n        IDs = [v.ID for v in graph.nodes]\n\n        if n_nodes == 0:\n            tail_node = godot.Node(ID=make_unique_name(\"n\", IDs))\n            head_node = godot.Node(ID=make_unique_name(\"n\", IDs))\n        elif n_nodes == 1:\n            tail_node = graph.nodes[0]\n            head_node = godot.Node(ID=make_unique_name(\"n\", IDs))\n        else:\n            tail_node = graph.nodes[0]\n            head_node = graph.nodes[1]\n\n        return godot.edge.Edge(tail_node, head_node, _nodes=graph.nodes)\n    else:\n        return None", "response": "Gives new edges a unique ID."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ninitializes the database connection.", "response": "def start(self, context):\n\t\t\"\"\"Initialize the database connection.\"\"\"\n\t\t\n\t\tself.config['alias'] = self.alias\n\t\tsafe_config = dict(self.config)\n\t\tdel safe_config['host']\n\t\t\n\t\tlog.info(\"Connecting MongoEngine database layer.\", extra=dict(\n\t\t\t\turi = redact_uri(self.config['host']),\n\t\t\t\tconfig = self.config,\n\t\t\t))\n\t\t\n\t\tself.connection = connect(**self.config)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nattaching this connection s default database to the context using our alias.", "response": "def prepare(self, context):\n\t\t\"\"\"Attach this connection's default database to the context using our alias.\"\"\"\n\t\t\n\t\tcontext.db[self.alias] = MongoEngineProxy(self.connection)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _component_default(self):\n        component = Container(fit_window=False, auto_size=True,\n            bgcolor=\"green\")#, position=list(self.pos) )\n        component.tools.append( MoveTool(component) )\n#        component.tools.append( TraitsTool(component) )\n        return component", "response": "Default component for Trait initialiser."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a Viewport object with default settings.", "response": "def _vp_default(self):\n        \"\"\" Trait initialiser.\n        \"\"\"\n        vp = Viewport(component=self.component)\n        vp.enable_zoom=True\n#        vp.view_position = [-10, -10]\n        vp.tools.append(ViewportPanTool(vp))\n        return vp"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef arrange_all(self):\n        # FIXME: Circular reference avoidance.\n        import godot.dot_data_parser\n        import godot.graph\n\n        graph = godot.graph.Graph(ID=\"g\")\n        graph.add_node(self)\n\n        print \"GRAPH DOT:\\n\", str(graph)\n\n        xdot_data = graph.create( format = \"xdot\" )\n\n        print \"XDOT DATA:\\n\", xdot_data\n        parser = godot.dot_data_parser.GodotDataParser()\n\n#        parser.parse_dot_data(xdot_data)\n\n        flat_data = xdot_data.replace('\\\\\\n','')\n        tokens = parser.dotparser.parseString(flat_data)[0]\n\n        for element in tokens[3]:\n            print \"TOK:\", element\n            cmd = element[0]\n            if cmd == 'add_node':\n                cmd, nodename, opts = element\n                assert nodename == self.ID\n                print \"OPTIONS:\", opts\n                self.set( **opts )", "response": "Arrange the components of the node using Graphviz."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing the drawing directive and updates the node components.", "response": "def parse_xdot_drawing_directive(self, new):\n        \"\"\" Parses the drawing directive, updating the node components.\n        \"\"\"\n        components = XdotAttrParser().parse_xdot_data(new)\n\n        max_x = max( [c.bounds[0] for c in components] + [1] )\n        max_y = max( [c.bounds[1] for c in components] + [1] )\n\n        pos_x = min( [c.x for c in components] )\n        pos_y = min( [c.y for c in components] )\n\n        move_to_origin(components)\n\n        container = Container(auto_size=True,\n            position=[pos_x-self.pos[0], pos_y-self.pos[1]],\n            bgcolor=\"blue\")\n#        self.bounds = bounds=[max_x, max_y]\n\n#        container = Container(fit_window=False, auto_size=True, bgcolor=\"blue\")\n\n        container.add( *components )\n\n        self.drawing = container"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_xdot_label_directive(self, new):\n        components = XdotAttrParser().parse_xdot_data(new)\n\n        pos_x = min( [c.x for c in components] )\n        pos_y = min( [c.y for c in components] )\n\n        move_to_origin(components)\n\n        container = Container(auto_size=True,\n            position=[pos_x-self.pos[0], pos_y-self.pos[1]],\n            bgcolor=\"red\")\n\n        container.add( *components )\n\n        self.label_drawing = container", "response": "Parses the xdot label drawing directive and updates the label_drawing attribute."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nhandles the container of drawing components changing.", "response": "def _drawing_changed(self, old, new):\n        \"\"\" Handles the container of drawing components changing.\n        \"\"\"\n        if old is not None:\n            self.component.remove( old )\n        if new is not None:\n#            new.bgcolor=\"pink\"\n            self.component.add( new )\n\n        w, h = self.component.bounds\n        self.component.position = [ self.pos[0] - (w/2), self.pos[1] - (h/2) ]\n#        self.component.position = [ self.pos[0], self.pos[1] ]\n        self.component.request_redraw()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _on_position_change(self, new):\n        w, h = self.component.bounds\n        self.pos = tuple([ new[0] + (w/2), new[1] + (h/2) ])", "response": "Handles the poition of the component changing."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _pos_changed(self, new):\n        w, h = self.component.bounds\n        self.component.position = [ new[0] - (w/2), new[1] - (h/2) ]\n#        self.component.position = list( new )\n        self.component.request_redraw()", "response": "Handles the Graphviz position attribute changing."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nhandles the right mouse button being clicked when the tool is in the normal state.", "response": "def normal_right_down(self, event):\n        \"\"\" Handles the right mouse button being clicked when the tool is in\n        the 'normal' state.\n\n        If the event occurred on this tool's component (or any contained\n        component of that component), the method opens a context menu with\n        menu items from any tool of the parent component that implements\n        MenuItemTool interface i.e. has a get_item() method.\n\n        \"\"\"\n\n        x = event.x\n        y = event.y\n\n        # First determine what component or components we are going to hittest\n        # on.  If our component is a container, then we add its non-container\n        # components to the list of candidates.\n#        candidates = []\n        component = self.component\n#        if isinstance(component, Container):\n#            candidates = get_nested_components(self.component)\n#        else:\n#            # We don't support clicking on unrecognized components\n#            return\n#\n#        # Hittest against all the candidate and take the first one\n#        item = None\n#        for candidate, offset in candidates:\n#            if candidate.is_in(x-offset[0], y-offset[1]):\n#                item = candidate\n#                break\n\n        for tool in component.tools:\n            component.active_tool = self\n            # Do it\n            event.handled = True\n            component.active_tool = None\n            component.request_redraw()\n\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef highlight_info(ctx, style):\n    click.secho(\"The following styles are available to choose from:\", fg=\"green\")\n    click.echo(list(pygments.styles.get_all_styles()))\n    click.echo()\n    click.secho(\n        f'The following CSS for the \"{style}\" style can be customized:', fg=\"green\"\n    )\n    click.echo(pygments.formatters.HtmlFormatter(style=style).get_style_defs())", "response": "Outputs the CSS which can be customized for highlighted code"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndraw a closed polygon", "response": "def _draw_mainlayer(self, gc, view_bounds=None, mode=\"default\"):\n        \"\"\" Draws a closed polygon \"\"\"\n\n        gc.save_state()\n        try:\n#            self._draw_bounds(gc)\n            if len(self.points) >= 2:\n                # Set the drawing parameters.\n                gc.set_fill_color(self.pen.fill_color_)\n                gc.set_stroke_color(self.pen.color_)\n                gc.set_line_width(self.pen.line_width)\n\n                # Draw the path.\n                gc.begin_path()\n#                x0 = self.points[0][0] - self.x\n#                y0 = self.points[0][1] + self.y\n#                gc.move_to(x0, y0)\n#                offset_points = [(x-self.x, y+self.y) for x, y in self.points]\n                gc.lines(self.points)\n\n                gc.close_path()\n                if self.filled:\n                    gc.draw_path(self.inside_rule_)\n                else:\n                    gc.stroke_path()\n        finally:\n            gc.restore_state()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_in(self, point_x, point_y):\n\n        point_array = array(((point_x, point_y),))\n        vertices = array(self.points)\n        winding = self.inside_rule == \"winding\"\n        result = points_in_polygon(point_array, vertices, winding)\n        return result[0]", "response": "Test if a point is within this polygonal region"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _draw_mainlayer(self, gc, view_bounds=None, mode=\"default\"):\n\n        if not self.points: return\n        gc.save_state()\n        try:\n            gc.set_fill_color(self.pen.fill_color_)\n\n            gc.set_line_width(self.pen.line_width)\n            gc.set_stroke_color(self.pen.color_)\n\n            gc.begin_path()\n            start_x, start_y = self.points[0]\n            gc.move_to(start_x, start_y)\n            for triple in nsplit(self.points[1:], 3):\n                x1, y1 = triple[0]\n                x2, y2 = triple[1]\n                end_x, end_y = triple[2]\n                gc.curve_to(x1, y1, x2, y2, end_x, end_y)\n                # One point overlap\n                gc.move_to(end_x, end_y)\n            gc.stroke_path()\n        finally:\n            gc.restore_state()", "response": "Draws the Bezier component"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninitializing the database connection.", "response": "def _connect(self, context):\n\t\t\"\"\"Initialize the database connection.\"\"\"\n\t\t\n\t\tif __debug__:\n\t\t\tlog.info(\"Connecting \" + self.engine.partition(':')[0] + \" database layer.\", extra=dict(\n\t\t\t\t\turi = redact_uri(self.uri, self.protect),\n\t\t\t\t\tconfig = self.config,\n\t\t\t\t\talias = self.alias,\n\t\t\t\t))\n\t\t\n\t\tself.connection = context.db[self.alias] = self._connector(self.uri, **self.config)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _handle_event(self, event, *args, **kw):\n\t\t\n\t\tfor engine in self.engines.values():\n\t\t\tif hasattr(engine, event):\n\t\t\t\tgetattr(engine, event)(*args, **kw)", "response": "Broadcast an event to the database connections registered."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the full URL for this page optinally with the passed in URL scheme", "response": "def get_full_page_url(self, page_number, scheme=None):\n        \"\"\"Get the full, external URL for this page, optinally with the passed in URL scheme\"\"\"\n        args = dict(\n            request.view_args,\n            _external=True,\n        )\n\n        if scheme is not None:\n            args['_scheme'] = scheme\n        \n        if page_number != 1:\n            args['page'] = page_number\n\n        return url_for(request.endpoint, **args)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nrenders the rel = prev and rel = next links to a Markup object for injection into a template", "response": "def render_prev_next_links(self, scheme=None):\n        \"\"\"Render the rel=prev and rel=next links to a Markup object for injection into a template\"\"\"\n        output = ''\n\n        if self.has_prev:\n            output += '<link rel=\"prev\" href=\"{}\" />\\n'.format(self.get_full_page_url(self.prev, scheme=scheme))\n        \n        if self.has_next:\n            output += '<link rel=\"next\" href=\"{}\" />\\n'.format(self.get_full_page_url(self.next, scheme=scheme))\n\n        return Markup(output)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef render_seo_links(self, scheme=None):\n        out = self.render_prev_next_links(scheme=scheme)\n\n        if self.total_pages == 1:\n            out += self.render_canonical_link(scheme=scheme)\n\n        return out", "response": "Render the rel = canonical prev and rel = next links to a Markup object for injection into a template"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the last item number in the user s list", "response": "def last_item_number(self):\n        \"\"\"\n        :return: The last \"item number\", used when displaying messages to the user\n        like \"Displaying items 1 to 10 of 123\" - in this example 10 would be returned\n        \"\"\"\n        n = self.first_item_number + self.page_size - 1\n        if n > self.total_items:\n            return self.total_items\n        return n"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nis candidate an exact match or sub - type of pattern?", "response": "def _content_type_matches(candidate, pattern):\n    \"\"\"Is ``candidate`` an exact match or sub-type of ``pattern``?\"\"\"\n    def _wildcard_compare(type_spec, type_pattern):\n        return type_pattern == '*' or type_spec == type_pattern\n\n    return (\n        _wildcard_compare(candidate.content_type, pattern.content_type) and\n        _wildcard_compare(candidate.content_subtype, pattern.content_subtype)\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef select_content_type(requested, available):\n\n    class Match(object):\n        \"\"\"Sorting assistant.\n\n        Sorting matches is a tricky business.  We need a way to\n        prefer content types by *specificity*.  The definition of\n        *more specific* is a little less than clear.  This class\n        treats the strength of a match as the most important thing.\n        Wild cards are less specific in all cases.  This is tracked\n        by the ``match_type`` attribute.\n\n        If we the candidate and pattern differ only by parameters,\n        then the strength is based on the number of pattern parameters\n        that match parameters from the candidate.  The easiest way to\n        track this is to count the number of candidate parameters that\n        are matched by the pattern.  This is what ``parameter_distance``\n        tracks.\n\n        The final key to the solution is to order the result set such\n        that the most specific matches are first in the list.  This\n        is done by carefully choosing values for ``match_type`` such\n        that full matches bubble up to the front.  We also need a\n        scheme of counting matching parameters that pushes stronger\n        matches to the front of the list.  The ``parameter_distance``\n        attribute starts at the number of candidate parameters and\n        decreases for each matching parameter - the lesser the value,\n        the stronger the match.\n\n        \"\"\"\n        WILDCARD, PARTIAL, FULL_TYPE, = 2, 1, 0\n\n        def __init__(self, candidate, pattern):\n            self.candidate = candidate\n            self.pattern = pattern\n\n            if pattern.content_type == pattern.content_subtype == '*':\n                self.match_type = self.WILDCARD\n            elif pattern.content_subtype == '*':\n                self.match_type = self.PARTIAL\n            else:\n                self.match_type = self.FULL_TYPE\n\n            self.parameter_distance = len(self.candidate.parameters)\n            for key, value in candidate.parameters.items():\n                if key in pattern.parameters:\n                    if pattern.parameters[key] == value:\n                        self.parameter_distance -= 1\n                    else:\n                        self.parameter_distance += 1\n\n    def extract_quality(obj):\n        return getattr(obj, 'quality', 1.0)\n\n    matches = []\n    for pattern in sorted(requested, key=extract_quality, reverse=True):\n        for candidate in sorted(available):\n            if _content_type_matches(candidate, pattern):\n                if candidate == pattern:  # exact match!!!\n                    if extract_quality(pattern) == 0.0:\n                        raise errors.NoMatch  # quality of 0 means NO\n                    return candidate, pattern\n                matches.append(Match(candidate, pattern))\n\n    if not matches:\n        raise errors.NoMatch\n\n    matches = sorted(matches,\n                     key=attrgetter('match_type', 'parameter_distance'))\n    return matches[0].candidate, matches[0].pattern", "response": "Selects the best content type for the given content type."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef rewrite_url(input_url, **kwargs):\n    scheme, netloc, path, query, fragment = parse.urlsplit(input_url)\n\n    if 'scheme' in kwargs:\n        scheme = kwargs['scheme']\n\n    ident, host_n_port = parse.splituser(netloc)\n\n    user, password = parse.splitpasswd(ident) if ident else (None, None)\n    if 'user' in kwargs:\n        user = kwargs['user']\n    elif user is not None:\n        user = parse.unquote_to_bytes(user).decode('utf-8')\n    if 'password' in kwargs:\n        password = kwargs['password']\n    elif password is not None:\n        password = parse.unquote_to_bytes(password).decode('utf-8')\n    ident = _create_url_identifier(user, password)\n\n    host, port = parse.splitnport(host_n_port, defport=None)\n    if 'host' in kwargs:\n        host = kwargs['host']\n        if host is not None:\n            host = _normalize_host(\n                host,\n                enable_long_host=kwargs.get('enable_long_host', False),\n                encode_with_idna=kwargs.get('encode_with_idna', None),\n                scheme=scheme,\n            )\n\n    if 'port' in kwargs:\n        port = kwargs['port']\n        if port is not None:\n            port = int(kwargs['port'])\n            if port < 0:\n                raise ValueError('port is required to be non-negative')\n\n    if host is None or host == '':\n        host_n_port = None\n    elif port is None:\n        host_n_port = host\n    else:\n        host_n_port = '{0}:{1}'.format(host, port)\n\n    if 'path' in kwargs:\n        path = kwargs['path']\n        if path is None:\n            path = '/'\n        else:\n            path = parse.quote(path.encode('utf-8'), safe=PATH_SAFE_CHARS)\n\n    netloc = '{0}@{1}'.format(ident, host_n_port) if ident else host_n_port\n\n    if 'query' in kwargs:\n        new_query = kwargs['query']\n        if new_query is None:\n            query = None\n        else:\n            params = []\n            try:\n                for param in sorted(new_query.keys()):\n                    params.append((param, new_query[param]))\n            except AttributeError:  # arg is None or not a dict\n                pass\n\n            if not params:  # maybe a sequence of tuples?\n                try:\n                    params = [(param, value) for param, value in new_query]\n                except ValueError:  # guess not...\n                    pass\n\n            if params:\n                query = parse.urlencode(params)\n            else:\n                query = new_query\n\n    if 'fragment' in kwargs:\n        fragment = kwargs['fragment']\n        if fragment is not None:\n            fragment = parse.quote(fragment.encode('utf-8'),\n                                   safe=FRAGMENT_SAFE_CHARS)\n\n    # The following is necessary to get around some interesting special\n    # case code in urllib.parse._coerce_args in Python 3.4.  Setting\n    # scheme to None causes urlunsplit to assume that all non-``None``\n    # parameters with be byte strings....\n    if scheme is None:\n        scheme = ''\n\n    return parse.urlunsplit((scheme, netloc, path, query, fragment))", "response": "This function will create a new URL from input_url with modifications applied applied."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove the user & password and returns them along with a new url.", "response": "def remove_url_auth(url):\n    \"\"\"\n    Removes the user & password and returns them along with a new url.\n\n    :param str url: the URL to sanitize\n    :return: a :class:`tuple` containing the authorization portion and\n        the sanitized URL.  The authorization is a simple user & password\n        :class:`tuple`.\n\n    >>> auth, sanitized = remove_url_auth('http://foo:bar@example.com')\n    >>> auth\n    ('foo', 'bar')\n    >>> sanitized\n    'http://example.com'\n\n    The return value from this function is simple named tuple with the\n    following fields:\n\n    - *auth* the username and password as a tuple\n    - *username* the username portion of the URL or :data:`None`\n    - *password* the password portion of the URL or :data:`None`\n    - *url* the sanitized URL\n\n    >>> result = remove_url_auth('http://me:secret@example.com')\n    >>> result.username\n    'me'\n    >>> result.password\n    'secret'\n    >>> result.url\n    'http://example.com'\n\n    \"\"\"\n    parts = parse.urlsplit(url)\n    return RemoveUrlAuthResult(auth=(parts.username or None, parts.password),\n                               url=rewrite_url(url, user=None, password=None))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _create_url_identifier(user, password):\n    if user is not None:\n        user = parse.quote(user.encode('utf-8'), safe=USERINFO_SAFE_CHARS)\n        if password:\n            password = parse.quote(password.encode('utf-8'),\n                                   safe=USERINFO_SAFE_CHARS)\n            return '{0}:{1}'.format(user, password)\n        return user\n    return None", "response": "Generate the user + password portion of a URL."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nnormalizing a host for a URL.", "response": "def _normalize_host(host, enable_long_host=False, encode_with_idna=None,\n                    scheme=None):\n    \"\"\"\n    Normalize a host for a URL.\n\n    :param str host: the host name to normalize\n\n    :keyword bool enable_long_host: if this keyword is specified\n        and it is :data:`True`, then the host name length restriction\n        from :rfc:`3986#section-3.2.2` is relaxed.\n    :keyword bool encode_with_idna: if this keyword is specified\n        and it is :data:`True`, then the ``host`` parameter will be\n        encoded using IDN.  If this value is provided as :data:`False`,\n        then the percent-encoding scheme is used instead.  If this\n        parameter is omitted or included with a different value, then\n        the ``host`` parameter is processed using :data:`IDNA_SCHEMES`.\n    :keyword str scheme: if this keyword is specified, then it is\n        used to determine whether to apply IDN rules or not.  This\n        parameter is ignored if `encode_with_idna` is not :data:`None`.\n\n    :return: the normalized and encoded string ready for inclusion\n        into a URL\n\n    \"\"\"\n    if encode_with_idna is not None:\n        enable_idna = encode_with_idna\n    else:\n        enable_idna = scheme.lower() in IDNA_SCHEMES if scheme else False\n    if enable_idna:\n        try:\n            host = '.'.join(segment.encode('idna').decode()\n                            for segment in host.split('.'))\n        except UnicodeError as exc:\n            raise ValueError('host is invalid - {0}'.format(exc))\n    else:\n        host = parse.quote(host.encode('utf-8'), safe=HOST_SAFE_CHARS)\n\n    if len(host) > 255 and not enable_long_host:\n        raise ValueError('host too long')\n\n    return host"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef transform(self, X):\n        '''\n        :X: numpy ndarray \n        '''\n        noise = self._noise_func(*self._args, size=X.shape)\n        results = X + noise\n        self.relative_noise_size_ = self.relative_noise_size(X, results)\n        return results", "response": "Apply the noise to the data X."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef relative_noise_size(self, data, noise):\n        '''\n        :data: original data as numpy matrix\n        :noise: noise matrix as numpy matrix\n        '''\n        return np.mean([\n            sci_dist.cosine(u / la.norm(u), v / la.norm(v))\n            for u, v in zip(noise, data)\n        ])", "response": "calculate relative noise size"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfinds all of the modules and submodules within a given directory tree.", "response": "def discover_modules(directory):\n    \"\"\"\n    Attempts to list all of the modules and submodules found within a given\n    directory tree. This function searches the top-level of the directory\n    tree for potential python modules and returns a list of candidate names.\n\n    **Note:** This function returns a list of strings representing\n    discovered module names, not the actual, loaded modules.\n\n    :param directory: the directory to search for modules.\n    \"\"\"\n    found = list()\n\n    if os.path.isdir(directory):\n        for entry in os.listdir(directory):\n            next_dir = os.path.join(directory, entry)\n\n            # Scan only if there's an __init__.py file\n            if os.path.isfile(os.path.join(next_dir, MODULE_INIT_FILE)):\n                found.append(entry)\n\n    return found"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef rdiscover_modules(directory):\n    found = list()\n\n    if os.path.isdir(directory):\n        for entry in os.listdir(directory):\n            next_dir = os.path.join(directory, entry)\n\n            # Scan only if there's an __init__.py file\n            if os.path.isfile(os.path.join(next_dir, MODULE_INIT_FILE)):\n                modules = _search_for_modules(next_dir, True, entry)\n                found.extend(modules)\n\n    return found", "response": "This function returns a list of all of the modules and submodules found within a given directory tree."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nattempting to the submodules under a module recursively. This function works for modules located in the default path as well as extended paths via the sys.meta_path hooks. This function carries the expectation that the hidden module variable '__path__' has been set correctly. :param mname: the module name to descend into", "response": "def rlist_modules(mname):\n    \"\"\"\n    Attempts to the submodules under a module recursively. This function\n    works for modules located in the default path as well as extended paths\n    via the sys.meta_path hooks.\n\n    This function carries the expectation that the hidden module variable\n    '__path__' has been set correctly.\n\n    :param mname: the module name to descend into\n    \"\"\"\n    module = import_module(mname)\n    if not module:\n        raise ImportError('Unable to load module {}'.format(mname))\n\n    found = list()\n    if _should_use_module_path(module):\n        mpath = module.__path__[0]\n    else:\n        mpaths = sys.path\n        mpath = _scan_paths_for(mname, mpaths)\n\n    if mpath:\n        for pmname in _search_for_modules(mpath, recursive=True):\n            found_mod = MODULE_PATH_SEP.join((mname, pmname))\n            found.append(found_mod)\n    return found"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef list_classes(mname, cls_filter=None):\n    found = list()\n    module = import_module(mname)\n    if inspect.ismodule(module):\n        [found.append(mod) for mod in _list_classes(module, cls_filter)]\n    return found", "response": "This function returns a list of all of the classes within a module."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef rlist_classes(module, cls_filter=None):\n    found = list()\n    mnames = rlist_modules(module)\n    for mname in mnames:\n        [found.append(c) for c in list_classes(mname, cls_filter)]\n    return found", "response": "This method will list all of the classes within a given module namespace."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert an RGB color value to an HSL representation.", "response": "def rgb_to_hsl(r, g, b):\n    \"\"\"\n    Converts an RGB color value to HSL.\n    :param r: The red color value\n    :param g: The green color value\n    :param b: The blue color value\n    :return: The HSL representation\n    \"\"\"\n    r = float(r) / 255.0\n    g = float(g) / 255.0\n    b = float(b) / 255.0\n\n    max_value = max(r, g, b)\n    min_value = min(r, g, b)\n\n    h = None\n    s = None\n    l = (max_value + min_value) / 2\n    d = max_value - min_value\n\n    if d == 0:\n        # achromatic\n        h = 0\n        s = 0\n    else:\n        s = d / (1 - abs(2 * l - 1))\n\n        if r == max_value:\n            h = 60 * ((g - b) % 6)\n            if b > g:\n                h += 360\n        if g == max_value:\n            h = 60 * ((b - r) / d + 2)\n        if b == max_value:\n            h = 60 * ((r - g) / d + 4)\n\n    return round(h, 2), round(s, 2), round(l, 2)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert a html colour to RGBA", "response": "def html_color_to_rgba(html_colour, alpha):\n    \"\"\"\n    :param html_colour: Colour string like FF0088\n    :param alpha: Alpha value (opacity)\n    :return: RGBA semitransparent version of colour for use in css\n    \"\"\"\n    html_colour = html_colour.upper()\n    if html_colour[0] == '#':\n        html_colour = html_colour[1:]\n\n    r_str = html_colour[0:2]\n    g_str = html_colour[2:4]\n    b_str = html_colour[4:6]\n\n    r = int(r_str, 16)\n    g = int(g_str, 16)\n    b = int(b_str, 16)\n\n    return 'rgba(%s, %s, %s, %s)' % (r, g, b, alpha)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef blend_html_colour_to_white(html_colour, alpha):\n    html_colour = html_colour.upper()\n    has_hash = False\n    if html_colour[0] == '#':\n        has_hash = True\n        html_colour = html_colour[1:]\n\n    r_str = html_colour[0:2]\n    g_str = html_colour[2:4]\n    b_str = html_colour[4:6]\n\n    r = int(r_str, 16)\n    g = int(g_str, 16)\n    b = int(b_str, 16)\n\n    r = int(alpha * r + (1 - alpha) * 255)\n    g = int(alpha * g + (1 - alpha) * 255)\n    b = int(alpha * b + (1 - alpha) * 255)\n    \n    out = '{:02X}{:02X}{:02X}'.format(r, g, b)\n    if has_hash:\n        out = '#' + out\n\n    return out", "response": "Blend a string of html colour alpha to white."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fit(self, X, y):\n        '''\n        :X: list of dict\n        :y: labels\n        '''\n        self._avgs = average_by_label(X, y, self.reference_label)\n        return self", "response": "Fits the classifier to the data"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntransforming a list of dict items into a list of dict items.", "response": "def transform(self, X, y=None):\n        '''\n        :X: list of dict\n        '''\n        return map_dict_list(\n            X,\n            key_func=lambda k, v: self.names[k.lower()],\n            if_func=lambda k, v: k.lower() in self.names)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef format_price_commas(price):\n    if price is None:\n        return None\n    if price >= 0:\n        return jinja2.Markup('&pound;{:,.2f}'.format(price))\n    else:\n        return jinja2.Markup('-&pound;{:,.2f}'.format(-price))", "response": "Formats a single price with commas"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef format_multiline_html(text):\n    if text is None:\n        return None\n\n    if '\\n' not in text:\n        return text.replace('\\r', '')\n\n    parts = text.replace('\\r', '').split('\\n')\n    out = flask.Markup()\n    for part in parts:\n        if out:\n            out += flask.Markup('<br>')\n        out += flask.escape(part)\n    return out", "response": "Converts a string like a \\ nb \\ nc into a <br > b<br > c and marks as Markup\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nensuring that a needed directory exists creating it if it doesn t.", "response": "def ensure_dir(path):\n    \"\"\"Ensure that a needed directory exists, creating it if it doesn't\"\"\"\n    try:\n        log.info('Ensuring directory exists: %s' % path)\n        os.makedirs(path)\n    except OSError:\n        if not os.path.isdir(path):\n            raise"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef make_csv_response(csv_data, filename):\n    resp = make_response(csv_data)\n    resp.headers['Content-Type'] = 'application/octet-stream'\n    resp.headers['Content-Disposition'] = 'attachment; filename=%s' % filename\n\n    return resp", "response": "Returns a response to the web connection to the user"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef to_base62(n):\n    remainder = n % 62\n    result = BASE62_MAP[remainder]\n    num = n // 62\n\n    while num > 0:\n        remainder = num % 62\n        result = '%s%s' % (BASE62_MAP[remainder], result)\n        num = num // 62\n\n    return result", "response": "Converts a number to base 62 representation"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting a base62 encoded String back into a number", "response": "def from_base62(s):\n    \"\"\"\n    Convert a base62 String back into a number\n    :param s: The base62 encoded String\n    :return: The number encoded in the String (integer)\n    \"\"\"\n    result = 0\n\n    for c in s:\n        if c not in BASE62_MAP:\n            raise Exception('Invalid base64 string: %s' % s)\n\n        result = result * 62 + BASE62_MAP.index(c)\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef list_dataset_uris(cls, base_uri, config_path):\n\n        storage_account_name = generous_parse_uri(base_uri).netloc\n        blobservice = get_blob_service(storage_account_name, config_path)\n        containers = blobservice.list_containers(include_metadata=True)\n\n        uri_list = []\n        for c in containers:\n            admin_metadata = c.metadata\n            uri = cls.generate_uri(\n                admin_metadata['name'],\n                admin_metadata['uuid'],\n                base_uri\n            )\n            uri_list.append(uri)\n\n        return uri_list", "response": "Return list containing URIs with base URI."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning list of overlay names.", "response": "def list_overlay_names(self):\n        \"\"\"Return list of overlay names.\"\"\"\n\n        overlay_names = []\n        for blob in self._blobservice.list_blobs(\n            self.uuid,\n            prefix=self.overlays_key_prefix\n        ):\n            overlay_file = blob.name.rsplit('/', 1)[-1]\n            overlay_name, ext = overlay_file.split('.')\n            overlay_names.append(overlay_name)\n\n        return overlay_names"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nstoring the given key value pair for the item associated with handle.", "response": "def add_item_metadata(self, handle, key, value):\n        \"\"\"Store the given key:value pair for the item associated with handle.\n\n        :param handle: handle for accessing an item before the dataset is\n                       frozen\n        :param key: metadata key\n        :param value: metadata value\n        \"\"\"\n\n        identifier = generate_identifier(handle)\n\n        metadata_blob_suffix = \"{}.{}.json\".format(identifier, key)\n        metadata_blob_name = self.fragments_key_prefix + metadata_blob_suffix\n\n        self._blobservice.create_blob_from_text(\n            self.uuid,\n            metadata_blob_name,\n            json.dumps(value)\n        )\n\n        self._blobservice.set_blob_metadata(\n            container_name=self.uuid,\n            blob_name=metadata_blob_name,\n            metadata={\n                \"type\": \"item_metadata\"\n            }\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef put_text(self, key, contents):\n\n        self._blobservice.create_blob_from_text(\n            self.uuid,\n            key,\n            contents\n        )", "response": "Store the given text contents so that they are later retrieved by\n            the given key."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_item_abspath(self, identifier):\n        admin_metadata = self.get_admin_metadata()\n        uuid = admin_metadata[\"uuid\"]\n        # Create directory for the specific dataset.\n        dataset_cache_abspath = os.path.join(self._azure_cache_abspath, uuid)\n        mkdir_parents(dataset_cache_abspath)\n\n        metadata = self._blobservice.get_blob_metadata(\n            self.uuid,\n            identifier\n        )\n\n        relpath = metadata['relpath']\n        _, ext = os.path.splitext(relpath)\n\n        local_item_abspath = os.path.join(\n            dataset_cache_abspath,\n            identifier + ext\n        )\n        if not os.path.isfile(local_item_abspath):\n\n            tmp_local_item_abspath = local_item_abspath + \".tmp\"\n            self._blobservice.get_blob_to_path(\n                self.uuid,\n                identifier,\n                tmp_local_item_abspath\n            )\n            os.rename(tmp_local_item_abspath, local_item_abspath)\n\n        return local_item_abspath", "response": "Return absolute path at which the item content can be accessed."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef iter_item_handles(self):\n\n        blob_generator = self._blobservice.list_blobs(\n            self.uuid,\n            include='metadata'\n        )\n\n        for blob in blob_generator:\n            if 'type' in blob.metadata:\n                if blob.metadata['type'] == 'item':\n                    handle = blob.metadata['relpath']\n                    yield handle", "response": "Return iterator over item handles."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning dictionary containing all the metadata associated with handle.", "response": "def get_item_metadata(self, handle):\n        \"\"\"Return dictionary containing all metadata associated with handle.\n\n        In other words all the metadata added using the ``add_item_metadata``\n        method.\n\n        :param handle: handle for accessing an item before the dataset is\n                       frozen\n        :returns: dictionary containing item metadata\n        \"\"\"\n\n        metadata = {}\n\n        identifier = generate_identifier(handle)\n        prefix = self.fragments_key_prefix + '{}'.format(identifier)\n\n        blob_generator = self._blobservice.list_blobs(\n            self.uuid,\n            include='metadata',\n            prefix=prefix\n        )\n\n        for blob in blob_generator:\n            metadata_key = blob.name.split('.')[-2]\n            value_as_string = self.get_text(blob.name)\n            value = json.loads(value_as_string)\n\n            metadata[metadata_key] = value\n\n        return metadata"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef file_md5sum(filename):\n    hash_md5 = hashlib.md5()\n    with open(filename, 'rb') as f:\n        for chunk in iter(lambda: f.read(1024 * 4), b''):\n            hash_md5.update(chunk)\n    return hash_md5.hexdigest()", "response": "Returns the MD5 sum of the file"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef luhn_check(card_number):\n    sum = 0\n    num_digits = len(card_number)\n    oddeven = num_digits & 1\n\n    for count in range(0, num_digits):\n        digit = int(card_number[count])\n\n        if not ((count & 1) ^ oddeven):\n            digit *= 2\n        if digit > 9:\n            digit -= 9\n\n        sum += digit\n\n    return (sum % 10) == 0", "response": "checks to make sure that the card number passes a luhn mod - 10 checksum"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the git revision as a string.", "response": "def get_git_version():\n    \"\"\"\n    Return the git hash as a string.\n\n    Apparently someone got this from numpy's setup.py. It has since been\n    modified a few times.\n    \"\"\"\n    # Return the git revision as a string\n    # copied from numpy setup.py\n    def _minimal_ext_cmd(cmd):\n        # construct minimal environment\n        env = {}\n        for k in ['SYSTEMROOT', 'PATH']:\n            v = os.environ.get(k)\n            if v is not None:\n                env[k] = v\n        # LANGUAGE is used on win32\n        env['LANGUAGE'] = 'C'\n        env['LANG'] = 'C'\n        env['LC_ALL'] = 'C'\n        with open(os.devnull, 'w') as err_out:\n            out = subprocess.Popen(cmd,\n                                   stdout=subprocess.PIPE,\n                                   stderr=err_out, # maybe debug later?\n                                   env=env).communicate()[0]\n        return out\n\n    try:\n        git_dir = os.path.dirname(os.path.realpath(__file__))\n        out = _minimal_ext_cmd(['git', '-C', git_dir, 'rev-parse', 'HEAD'])\n        GIT_REVISION = out.strip().decode('ascii')\n    except OSError:\n        GIT_REVISION = 'Unknown'\n\n    return GIT_REVISION"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef partial_fit(self, X, y):\n        X, y = filter_by_label(X, y, self.reference_label)\n        super().partial_fit(X, y)\n        return self", "response": "This method is called by the base class to compute the mean and standard deviation of the class entry."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load_module(self, module_name):\n        if module_name != self.module_name:\n            raise LoaderError(\n                'Requesting a module that the loader is unaware of.')\n\n        if module_name in sys.modules:\n            return sys.modules[module_name]\n\n        module = self.load_module_py_path(module_name, self.load_target)\n        if self.is_pkg:\n            module.__path__ = [self.module_path]\n            module.__package__ = module_name\n        else:\n            module.__package__ = module_name.rpartition('.')[0]\n\n        sys.modules[module_name] = module\n        return module", "response": "Loads a module s code and sets the module s expected hidden\n        variables."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a path to search through when attempting to look up a module.", "response": "def add_path(self, path):\n        \"\"\"\n        Adds a path to search through when attempting to look up a module.\n\n        :param path: the path the add to the list of searchable paths\n        \"\"\"\n        if path not in self.paths:\n            self.paths.append(path)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef find_module(self, module_name, path=None):\n        module_path = os.path.join(*module_name.split(MODULE_PATH_SEP))\n\n        for search_root in self.paths:\n            target_path = os.path.join(search_root, module_path)\n            is_pkg = False\n\n            # If the target references a directory, try to load it as\n            # a module by referencing the __init__.py file, otherwise\n            # append .py and attempt to resolve it.\n            if os.path.isdir(target_path):\n                target_file = os.path.join(target_path, '__init__.py')\n                is_pkg = True\n            else:\n                target_file = '{}.py'.format(target_path)\n\n            if os.path.exists(target_file):\n                return ModuleLoader(\n                    target_path, module_name, target_file, is_pkg)\n        return None", "response": "Searches the paths for the required module."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting a Tag object into a text string.", "response": "def tag_to_text(tag):\n    \"\"\"\n    :param tag: Beautiful soup tag\n    :return: Flattened text\n    \"\"\"\n    out = []\n    for item in tag.contents:\n        # If it has a name, it is a tag\n        if item.name:\n            out.append(tag_to_text(item))\n        else:\n            # Just text!\n            out.append(item)\n\n    return ' '.join(out)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef split_line(line, min_line_length=30, max_line_length=100):\n    if len(line) <= max_line_length:\n        # No need to split!\n        return [line]\n\n    # First work out the indentation on the beginning of the line\n    indent = 0\n    while line[indent] == ' ' and indent < len(line):\n        indent += 1\n\n    # Try to split the line\n    # Start looking for a space at character max_line_length working backwards\n    i = max_line_length\n    split_point = None\n    while i > min_line_length:\n        if line[i] == ' ':\n            split_point = i\n            break\n        i -= 1\n\n    if split_point is None:\n        # We didn't find a split point - search beyond the end of the line\n        i = max_line_length + 1\n        while i < len(line):\n            if line[i] == ' ':\n                split_point = i\n                break\n            i += 1\n\n    if split_point is None:\n        # There is nowhere to split the line!\n        return [line]\n    else:\n        # Split it!\n        line1 = line[:split_point]\n        line2 = ' ' * indent + line[split_point + 1:]\n        return [line1] + split_line(line2, min_line_length, max_line_length)", "response": "This function splits a line into two lists of lines."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef transform(self, X, y=None):\n        '''\n        :X: list of dict\n        :y: labels\n        '''\n        return [{\n            new_feature: self._fisher_pval(x, old_features)\n            for new_feature, old_features in self.feature_groups.items()\n            if len(set(x.keys()) & set(old_features))\n        } for x in X]", "response": "Transform a list of dict to a list of labels."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list of values which shows number of feature makes filter function true or false", "response": "def _filtered_values(self, x: dict, feature_set: list=None):\n        '''\n        :x: dict which contains feature names and values\n        :return: pairs of values which shows number of feature makes filter function true or false\n        '''\n        feature_set = feature_set or x\n        n = sum(self.filter_func(x[i]) for i in feature_set if i in x)\n        return [len(feature_set) - n, n]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprinting the location of the current object.", "response": "def print_location(**kwargs):\n    \"\"\"\n    :param kwargs: Pass in the arguments to the function and they will be printed too!\n    \"\"\"\n    stack = inspect.stack()[1]\n    debug_print('{}:{} {}()'.format(stack[1], stack[2], stack[3]))\n\n    for k, v in kwargs.items():\n        lesser_debug_print('{} = {}'.format(k, v))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalls this on an lxml. etree. ElementTree to remove all namespaces", "response": "def remove_namespaces(root):\n    \"\"\"Call this on an lxml.etree document to remove all namespaces\"\"\"\n    for elem in root.getiterator():\n        if not hasattr(elem.tag, 'find'):\n            continue\n\n        i = elem.tag.find('}')\n        if i >= 0:\n            elem.tag = elem.tag[i + 1:]\n\n    objectify.deannotate(root, cleanup_namespaces=True)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef consistency(self, desired_version=None, include_package=False,\n                    strictness=None):\n        \"\"\"Checks that the versions are consistent\n\n        Parameters\n        ----------\n        desired_version: str\n            optional; the version that all of these should match\n        include_package: bool\n            whether to check the special 'package' version for consistency\n            (default False)\n        strictness: str\n\n        \"\"\"\n        keys_to_check = list(self.versions.keys())\n        if not include_package and 'package' in keys_to_check:\n            keys_to_check.remove('package')\n\n        if desired_version is None:\n            # if we have to guess, we trust setup.py\n            try:\n                desired_version = self.versions['setup.py']\n            except KeyError:\n                desired_version = self.versions[keys_to_check[0]]\n\n        if strictness is None:\n            strictness = self.strictness\n        desired = self._version(desired_version, strictness)\n\n        error_keys = []\n        for key in keys_to_check:\n            test = self._version(self.versions[key], strictness)\n            if test != desired:\n                error_keys += [key]\n\n        # make the error message\n        msg = \"\"\n        for key in error_keys:\n            msg += \"Error: desired {d} != {v} ({k})\\n\".format(\n                d=str(desired),\n                v=str(self.versions[key]),\n                k=str(key)\n            )\n        return msg", "response": "Checks that the versions of the current object are consistent with the desired version."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef setup_is_release(setup, expected=True):\n    try:\n        is_release = setup.IS_RELEASE\n    except AttributeError:\n        return None\n    else:\n        if is_release and expected:\n            return \"\"\n        elif not is_release and not expected:\n            return \"\"\n        else:\n            return (\"Unexpected value of setup.py IS_RELEASE. Found \"\n                    + str(is_release) + \".\\n\")", "response": "Check if the current environment is a release."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef from_yaml(cls, **kwargs):\n        ret = cls()\n\n        for k, v in kwargs.iteritems():\n            ret.__dict__[k] = v\n        return ret", "response": "Creates a new instance of the class from the given dictionary."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef merge(self, new_dict):\n        actions = new_dict.pop(\"actions\")\n        for action in actions:\n            self.add_action(action)\n\n        self.__dict__.update(new_dict)", "response": "Merges a dictionary into the Rule object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nexecute the actions in order.", "response": "def execute_actions(self, cwd):\n        \"\"\"Iterates over the actions and executes them in order.\"\"\"\n        self._execute_globals(cwd)\n        for action in self.actions:\n            logger.info(\"executing {}\".format(action))\n            p = subprocess.Popen(action, shell=True, cwd=cwd)\n            p.wait()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_yaml(cls, defaults, **kwargs):\n        # TODO: I hate myself for this. Fix it later mmkay?\n        if \"token\" not in defaults:\n            kwargs[\"token\"] = None\n\n        defaults = copy.deepcopy(defaults)\n        return cls(\n            defaults=defaults,\n            token=kwargs.pop(\"token\"),\n            directory=kwargs.pop(\"directory\"),\n            **kwargs\n        )", "response": "Creates a new instance of a rule by merging two dictionaries."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing a string like email@address. com into a tuple of the email and name.", "response": "def parse_address(formatted_address):\n    \"\"\"\n    :param formatted_address: A string like \"email@address.com\" or \"My Email <email@address.com>\"\n    \n    :return: Tuple: (address, name)\n    \"\"\"\n    if email_regex.match(formatted_address):\n        # Just a raw address\n        return (formatted_address, None)\n    \n    match = formatted_address_regex.match(formatted_address)\n\n    if match:\n        (name, email) = match.group(1, 2)\n        return email.strip(), name.strip()\n\n    raise ValueError('\"{}\" is not a valid formatted address'.format(formatted_address))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef send_mail(recipient_list, subject, body, html=False, from_address=None):\n    if not _configured:\n        raise Exception('LFS Mailer hasn\\'t been configured')\n\n    if from_address is None:\n        from_address = default_email_from\n    \n    mime_type = 'html' if html else 'plain'\n    log.debug('Sending {} mail to {}: {}'.format(mime_type, ', '.join(recipient_list), subject))\n    if dump_email_body:\n        log.info(body)\n\n    s = smtplib.SMTP(host, port)\n\n    if use_tls:\n        s.ehlo()\n        s.starttls()\n        s.ehlo()\n    \n    if username:\n        s.login(username, password)\n\n    if email_to_override:\n        subject = '[to %s] %s' % (', '.join(recipient_list), subject)\n        recipient_list = [email_to_override]\n        log.info('Using email override: %s' % ', '.join(recipient_list))\n\n    msg = MIMEText(body, mime_type, 'utf-8')\n    msg['To'] = ', '.join(recipient_list)\n    msg['Subject'] = subject\n    msg['From'] = from_address\n    msg['Date'] = email.utils.formatdate()\n\n    s.sendmail(from_address, recipient_list, msg.as_string())\n    s.quit()", "response": "Send an email to a list of recipients."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_details(self, message):\n        msg = message\n        # Try to append Flask request details\n        try:\n            from flask import request\n            url = request.url\n            method = request.method\n            endpoint = request.endpoint\n\n            # Obscure password field and prettify a little bit\n            form_dict = dict(request.form)\n            for key in form_dict:\n                if key.lower() in _error_reporting_obscured_fields:\n                    form_dict[key] = '******'\n                elif len(form_dict[key]) == 1:\n                    form_dict[key] = form_dict[key][0]\n\n            form = pprint.pformat(form_dict).replace('\\n', '\\n          ')\n\n            msg = '%s\\nRequest:\\n\\nurl:      %s\\nmethod:   %s\\nendpoint: %s\\nform:     %s\\n' % \\\n                (msg, url, method, endpoint, form)\n        except Exception:\n            traceback.print_exc()\n\n        # Try to append the session\n        try:\n            from flask import session\n            from flask.json import JSONEncoder\n            session_str = json.dumps(\n                dict(**session),\n                indent=2,\n                cls=JSONEncoder\n            )\n            msg = '%s\\nSession:\\n\\n%s\\n' % (msg, session_str)\n        except Exception:\n            traceback.print_exc()\n        \n        return msg", "response": "Add extra details to the message."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef emit(self, record):\n        try:\n            # First, remove all records from the rate limiter list that are over a minute old\n            now = timetool.unix_time()\n            one_minute_ago = now - 60\n            new_rate_limiter = [x for x in self.rate_limiter if x > one_minute_ago]\n            log.debug('Rate limiter %s -> %s' % (len(self.rate_limiter), len(new_rate_limiter)))\n            self.rate_limiter = new_rate_limiter\n\n            # Now, get the number of emails sent in the last minute.  If it's less than the threshold, add another\n            # entry to the rate limiter list\n            recent_sends = len(self.rate_limiter)\n            send_email = recent_sends < self.max_sends_per_minute\n            if send_email:\n                self.rate_limiter.append(now)\n\n            msg = self.format(record)\n            msg = self.add_details(msg)\n\n            # Finally send the message!\n            if send_email:\n                if DEBUG_ERROR_EMAIL_SENDING:\n                    log.info('@@@> ! Sending error email to {} !'.format(self.toaddrs))\n                send_text_mail(self.toaddrs, self.subject, msg, self.fromaddr)\n            else:\n                log.info('!! WARNING: Not sending email as too many emails have been sent in the past minute !!')\n                log.info(msg)\n\n        except (KeyboardInterrupt, SystemExit):\n            raise\n        except Exception:\n            self.handleError(record)", "response": "Format the record and send it to the specified addressees."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_context(self, value):\n        context = super(RenditionAwareStructBlock, self).get_context(value)\n        context['image_rendition'] = self.rendition.\\\n            image_rendition or 'original'\n        return context", "response": "Ensure image_rendition is added to the global context."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef log_attempt(self, key):\n        with self.lock:\n            if key not in self.attempts:\n                self.attempts[key] = 1\n            else:\n                self.attempts[key] += 1\n\n                if self.attempts[key] >= self.max_attempts:\n                    log.info('Account %s locked due to too many login attempts' % key)\n                    # lock account\n                    self.locks[key] = datetime.datetime.utcnow() + datetime.timedelta(seconds=self.lock_duration)", "response": "Log an attempt against a key"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef service(self):\n        with self.lock:\n            # Decrement / remove all attempts\n            for key in list(self.attempts.keys()):\n                log.debug('Decrementing count for %s' % key)\n                if key in self.attempts:\n                    if self.attempts[key] <= 1:\n                        del self.attempts[key]\n                    else:\n                        self.attempts[key] -= 1\n\n            # Remove expired locks\n            now = datetime.datetime.utcnow()\n            for key in list(self.locks.keys()):\n                if key in self.locks and self.locks[key] < now:\n                    log.info('Expiring login lock for %s' % key)\n                    del self.locks[key]", "response": "Decrease the countdowns and remove any expired locks."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_to_queue(self, url):\n\n        if self.connection_handler.current_music is None:\n            log.error('Music service is not initialized. URL was not added to queue.')\n        elif self.connection_handler.current_storage is None:\n            log.error('Drive service is not initialized. URL was not added to queue.')\n        else:\n            self.queues['download'].put(url)", "response": "Adds an URL to the download queue."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the current music service to service_name.", "response": "def use_music_service(self, service_name, api_key=None):\n        \"\"\"\n        Sets the current music service to service_name.\n        \n        :param str service_name: Name of the music service\n        :param str api_key: Optional API key if necessary\n        \"\"\"\n\n        self.connection_handler.use_music_service(service_name, api_key=api_key)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the current storage service to service_name attempts to connect to it.", "response": "def use_storage_service(self, service_name, custom_path=None):\n        \"\"\"\n        Sets the current storage service to service_name and attempts to connect to it.\n        \n        :param str service_name: Name of the storage service\n        :param str custom_path: Custom path where to download tracks for local storage (optional, and must already exist, use absolute paths only)\n        \"\"\"\n\n        self.connection_handler.use_storage_service(service_name, custom_path=custom_path)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating and starts the workers.", "response": "def start_workers(self, workers_per_task=1):\n        \"\"\"\n        Creates and starts the workers, as well as attaching a handler to terminate them gracefully when a SIGINT signal is received.\n\n        :param int workers_per_task: Number of workers to create for each task in the pipeline\n        \"\"\"\n\n        if not self.workers:\n            for _ in range(workers_per_task):\n                self.workers.append(Worker(self._download, self.queues['download'], self.queues['convert'], self.stopper))\n                self.workers.append(Worker(self._convert, self.queues['convert'], self.queues['upload'], self.stopper))\n                self.workers.append(Worker(self._upload, self.queues['upload'], self.queues['delete'], self.stopper))\n                self.workers.append(Worker(self._delete, self.queues['delete'], self.queues['done'], self.stopper))\n\n            self.signal_handler = SignalHandler(self.workers, self.stopper)\n            signal.signal(signal.SIGINT, self.signal_handler)\n\n            for worker in self.workers:\n                worker.start()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding or update a key value pair to the database", "response": "def set(self, k, v):\n        \"\"\"Add or update a key, value pair to the database\"\"\"\n        k = k.lstrip('/')\n        url = '{}/{}'.format(self.endpoint, k)\n        r = requests.put(url, data=str(v))\n        if r.status_code != 200 or r.json() is not True:\n            raise KVStoreError('PUT returned {}'.format(r.status_code))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get(self, k, wait=False, wait_index=False, timeout='5m'):\n        k = k.lstrip('/')\n        url = '{}/{}'.format(self.endpoint, k)\n        params = {}\n        if wait:\n            params['index'] = wait_index\n            params['wait'] = timeout\n        r = requests.get(url, params=params)\n        if r.status_code == 404:\n            raise KeyDoesNotExist(\"Key \" + k + \" does not exist\")\n        if r.status_code != 200:\n            raise KVStoreError('GET returned {}'.format(r.status_code))\n\n        try:\n            return base64.b64decode(r.json()[0]['Value'])\n        except TypeError as e:\n            # Value was empty and wild None appeared\n            return \"\"", "response": "Get the value of a given key"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef recurse(self, k, wait=False, wait_index=None, timeout='5m'):\n        k = k.lstrip('/')\n        url = '{}/{}'.format(self.endpoint, k)\n        params = {}\n        params['recurse'] = 'true'\n        if wait:\n            params['wait'] = timeout\n            if not wait_index:\n                params['index'] = self.index(k, recursive=True)\n            else:\n                params['index'] = wait_index\n        r = requests.get(url, params=params)\n        if r.status_code == 404:\n            raise KeyDoesNotExist(\"Key \" + k + \" does not exist\")\n        if r.status_code != 200:\n            raise KVStoreError('GET returned {}'.format(r.status_code))\n        entries = {} \n        for e in r.json():\n            if e['Value']:\n                entries[e['Key']] = base64.b64decode(e['Value'])\n            else:\n                entries[e['Key']] = ''\n        return entries", "response": "Recursively get the tree below the given key"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the current index of the key or the subtree.", "response": "def index(self, k, recursive=False):\n        \"\"\"Get the current index of the key or the subtree.\n        This is needed for later creating long polling requests\n        \"\"\"\n        k = k.lstrip('/')\n        url = '{}/{}'.format(self.endpoint, k)\n        params = {}\n        if recursive:\n            params['recurse'] = ''\n        r = requests.get(url, params=params)\n        return r.headers['X-Consul-Index']"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndeleting a given key or recursively delete the tree below it", "response": "def delete(self, k, recursive=False):\n        \"\"\"Delete a given key or recursively delete the tree below it\"\"\"\n        k = k.lstrip('/')\n        url = '{}/{}'.format(self.endpoint, k)\n        params = {}\n        if recursive:\n            params['recurse'] = ''\n        r = requests.delete(url, params=params)\n        if r.status_code != 200:\n            raise KVStoreError('DELETE returned {}'.format(r.status_code))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef internal_error(exception, template_path, is_admin, db=None):\n    if db:\n        try:\n            db.session.rollback()\n        except:  # noqa: E722\n            pass\n\n    title = str(exception)\n    message = traceback.format_exc()\n    preformat = True\n \n    log.error('Exception caught: {}\\n{}'.format(title, message))\n\n    if current_app.config.get('TEST_MODE'):\n        show_detailed_error = True\n        message = 'Note: You are seeing this error message because the server is in test mode.\\n\\n{}'.format(message)\n    elif is_admin:\n        show_detailed_error = True\n        message = 'Note: You are seeing this error message because you are a member of staff.\\n\\n{}'.format(message)\n    else:\n        title = '500 Internal Server Error'\n        message = 'Something went wrong while processing your request.'\n        preformat = False\n        show_detailed_error = False\n    \n    try:\n        return render_template(template_path, title=title, message=message, preformat=preformat,\n                               exception=exception, is_admin=is_admin,\n                               show_detailed_error=show_detailed_error), 500\n    except:  # noqa: E722\n        log.exception('Error rendering error page!')\n        return '500 Internal Server Error', 500", "response": "Render an internal error page."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef plot_heatmap(X, y, top_n=10, metric='correlation', method='complete'):\n    '''\n    Plot heatmap which shows features with classes.\n\n    :param X: list of dict\n    :param y: labels\n    :param top_n: most important n feature\n    :param metric: metric which will be used for clustering\n    :param method: method which will be used for clustering\n    '''\n    sns.set(color_codes=True)\n\n    df = feature_importance_report(X, y)\n\n    df_sns = pd.DataFrame().from_records(X)[df[:top_n].index].T\n    df_sns.columns = y\n\n    color_mapping = dict(zip(set(y), sns.mpl_palette(\"Set2\", len(set(y)))))\n\n    return sns.clustermap(df_sns, figsize=(22, 22), z_score=0,\n                          metric=metric, method=method,\n                          col_colors=[color_mapping[i] for i in y])", "response": "Plot heatmap which shows features with classes."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the version of the current Python version.", "response": "def get_setup_version():\n    \"\"\"\n    \u83b7\u53d6\u6253\u5305\u4f7f\u7528\u7684\u7248\u672c\u53f7\uff0c\u7b26\u5408 PYPI \u5b98\u65b9\u63a8\u8350\u7684\u7248\u672c\u53f7\u65b9\u6848\n\n    :return: PYPI \u6253\u5305\u7248\u672c\u53f7\n    :rtype: str\n    \"\"\"\n    ver = '.'.join(map(str, VERSION[:3]))\n\n    # \u82e5\u540e\u7f00\u63cf\u8ff0\u5b57\u4e32\u4e3a None \uff0c\u5219\u76f4\u63a5\u8fd4\u56de\u4e3b\u7248\u672c\u53f7\n    if not VERSION[3]:\n        return ver\n\n    # \u5426\u5219\uff0c\u8ffd\u52a0\u7248\u672c\u53f7\u540e\u7f00\n    hyphen = ''\n    suffix = hyphen.join(map(str, VERSION[-2:]))\n    if VERSION[3] in [VERSION_SUFFIX_DEV, VERSION_SUFFIX_POST]:\n        hyphen = '.'\n    ver = hyphen.join([ver, suffix])\n\n    return ver"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a number of months to a timestamp", "response": "def add_months(months, timestamp=datetime.datetime.utcnow()):\n    \"\"\"Add a number of months to a timestamp\"\"\"\n    month = timestamp.month\n    new_month = month + months\n    years = 0\n    \n    while new_month < 1:\n        new_month += 12\n        years -= 1\n    \n    while new_month > 12:\n        new_month -= 12\n        years += 1\n    \n    # month = timestamp.month\n    year = timestamp.year + years\n\n    try:\n        return datetime.datetime(year, new_month, timestamp.day, timestamp.hour, timestamp.minute, timestamp.second)\n    except ValueError:\n        # This means that the day exceeds the last day of the month, i.e. it is 30th March, and we are finding the day\n        # 1 month ago, and it is trying to return 30th February\n        if months > 0:\n            # We are adding, so use the first day of the next month\n            new_month += 1\n            if new_month > 12:\n                new_month -= 12\n                year += 1\n            \n            return datetime.datetime(year, new_month, 1, timestamp.hour, timestamp.minute, timestamp.second)\n        else:\n            # We are subtracting - use the last day of the same month\n            new_day = calendar.monthrange(year, new_month)[1]\n            return datetime.datetime(year, new_month, new_day, timestamp.hour, timestamp.minute, timestamp.second)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_months_to_date(months, date):\n    month = date.month\n    new_month = month + months\n    years = 0\n\n    while new_month < 1:\n        new_month += 12\n        years -= 1\n\n    while new_month > 12:\n        new_month -= 12\n        years += 1\n\n    # month = timestamp.month\n    year = date.year + years\n\n    try:\n        return datetime.date(year, new_month, date.day)\n    except ValueError:\n        # This means that the day exceeds the last day of the month, i.e. it is 30th March, and we are finding the day\n        # 1 month ago, and it is trying to return 30th February\n        if months > 0:\n            # We are adding, so use the first day of the next month\n            new_month += 1\n            if new_month > 12:\n                new_month -= 12\n                year += 1\n\n            return datetime.datetime(year, new_month, 1)\n        else:\n            # We are subtracting - use the last day of the same month\n            new_day = calendar.monthrange(year, new_month)[1]\n            return datetime.datetime(year, new_month, new_day)", "response": "Add a number of months to a date"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef unix_time(dt=None, as_int=False):\n    if dt is None:\n        dt = datetime.datetime.utcnow()\n\n    if type(dt) is datetime.date:\n        dt = date_to_datetime(dt)\n\n    epoch = datetime.datetime.utcfromtimestamp(0)\n    delta = dt - epoch\n    \n    if as_int:\n        return int(delta.total_seconds())\n\n    return delta.total_seconds()", "response": "Generate a unix style timestamp ( in seconds"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_christmas_period():\n    now = datetime.date.today()\n    if now.month != 12:\n        return False\n    if now.day < 15:\n        return False\n    if now.day > 27:\n        return False\n    return True", "response": "Is this the christmas period?"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngive a date or datetime return a datetime at 23 : 59 : 59 on that day", "response": "def get_end_of_day(timestamp):\n    \"\"\"\n    Given a date or a datetime, return a datetime at 23:59:59 on that day\n    \"\"\"\n    return datetime.datetime(timestamp.year, timestamp.month, timestamp.day, 23, 59, 59)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntransform the object X by applying the transformer and inverse transform on the object X.", "response": "def transform(self, X):\n        '''\n        :param X: features.\n        '''\n        inverser_tranformer = self.dict_vectorizer_\n        if self.feature_selection:\n            inverser_tranformer = self.clone_dict_vectorizer_\n\n        return inverser_tranformer.inverse_transform(\n            self.transformer.transform(\n                self.dict_vectorizer_.transform(X)))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef use_music_service(self, service_name, api_key):\n\n        try:\n            self.current_music = self.music_services[service_name]\n        except KeyError:\n            if service_name == 'youtube':\n                self.music_services['youtube'] = Youtube()\n                self.current_music = self.music_services['youtube']\n            elif service_name == 'soundcloud':\n                self.music_services['soundcloud'] = Soundcloud(api_key=api_key)\n                self.current_music = self.music_services['soundcloud']\n            else:\n                log.error('Music service name is not recognized.')", "response": "Sets the current music service to service_name."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the current storage service to service_name and runs the connect method on the service.", "response": "def use_storage_service(self, service_name, custom_path):\n        \"\"\"\n        Sets the current storage service to service_name and runs the connect method on the service.\n\n        :param str service_name: Name of the storage service\n        :param str custom_path: Custom path where to download tracks for local storage (optional, and must already exist, use absolute paths only)\n        \"\"\"\n\n        try:\n            self.current_storage = self.storage_services[service_name]\n        except KeyError:\n            if service_name == 'google drive':\n                self.storage_services['google drive'] = GoogleDrive()\n                self.current_storage = self.storage_services['google drive']\n                self.current_storage.connect()\n            elif service_name == 'dropbox':\n                log.error('Dropbox is not supported yet.')\n            elif service_name == 'local':\n                self.storage_services['local'] = LocalStorage(custom_path=custom_path)\n                self.current_storage = self.storage_services['local']\n                self.current_storage.connect()\n            else:\n                log.error('Storage service name is not recognized.')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading dataset from csv.", "response": "def from_csv(self, label_column='labels'):\n        '''\n        Read dataset from csv.\n        '''\n        df = pd.read_csv(self.path, header=0)\n        X = df.loc[:, df.columns != label_column].to_dict('records')\n        X = map_dict_list(X, if_func=lambda k, v: v and math.isfinite(v))\n        y = list(df[label_column].values)\n        return X, y"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread dataset from json.", "response": "def from_json(self):\n        '''\n        Reads dataset from json.\n        '''\n        with gzip.open('%s.gz' % self.path,\n                       'rt') if self.gz else open(self.path) as file:\n            return list(map(list, zip(*json.load(file))))[::-1]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_json(self, X, y):\n        '''\n        Reads dataset to csv.\n\n        :param X: dataset as list of dict.\n        :param y: labels.\n        '''\n        with gzip.open('%s.gz' % self.path, 'wt') if self.gz else open(\n                self.path, 'w') as file:\n            json.dump(list(zip(y, X)), file)", "response": "Reads dataset to json."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef filter_by_label(X, y, ref_label, reverse=False):\n    '''\n    Select items with label from dataset.\n\n    :param X: dataset\n    :param y: labels\n    :param ref_label: reference label\n    :param bool reverse: if false selects ref_labels else eliminates\n    '''\n    check_reference_label(y, ref_label)\n\n    return list(zip(*filter(lambda t: (not reverse) == (t[1] == ref_label),\n                            zip(X, y))))", "response": "Filter items by label from dataset."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalculating average dictinary from list of dictionary for give label", "response": "def average_by_label(X, y, ref_label):\n    '''\n    Calculates average dictinary from list of dictionary for give label\n\n    :param List[Dict] X: dataset\n    :param list y: labels\n    :param ref_label: reference label\n    '''\n    # TODO: consider to delete defaultdict\n    return defaultdict(float,\n                       pd.DataFrame.from_records(\n                           filter_by_label(X, y, ref_label)[0]\n                       ).mean().to_dict())"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef map_dict_list(ds, key_func=None, value_func=None, if_func=None):\n    '''\n    :param List[Dict] ds: list of dict\n    :param func key_func: func which will run on key.\n    :param func value_func: func which will run on values.\n    '''\n    return [map_dict(d, key_func, value_func, if_func) for d in ds]", "response": "Maps a list of dictionaries into a list of dicts."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_reference_label(y, ref_label):\n    '''\n    :param list y: label\n    :param ref_label: reference label\n    '''\n    set_y = set(y)\n    if ref_label not in set_y:\n        raise ValueError('There is not reference label in dataset. '\n                         \"Reference label: '%s' \"\n                         'Labels in dataset: %s' % (ref_label, set_y))", "response": "Check that the reference label is in the list y."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfeature importance report for a set of features in dataset with anova using multiple hypotesis testing.", "response": "def feature_importance_report(X,\n                              y,\n                              threshold=0.001,\n                              correcting_multiple_hypotesis=True,\n                              method='fdr_bh',\n                              alpha=0.1,\n                              sort_by='pval'):\n    '''\n    Provide signifance for features in dataset with anova using multiple hypostesis testing\n\n    :param X: List of dict with key as feature names and values as features\n    :param y: Labels\n    :param threshold: Low-variens threshold to eliminate low varience features\n    :param correcting_multiple_hypotesis: corrects p-val with multiple hypotesis testing\n    :param method: method of multiple hypotesis testing\n    :param alpha: alpha of multiple hypotesis testing\n    :param sort_by: sorts output dataframe by pval or F\n    :return: DataFrame with F and pval for each feature with their average values \n    '''\n    df = variance_threshold_on_df(\n        pd.DataFrame.from_records(X), threshold=threshold)\n\n    F, pvals = f_classif(df.values, y)\n\n    if correcting_multiple_hypotesis:\n        _, pvals, _, _ = multipletests(pvals, alpha=alpha, method=method)\n\n    df['labels'] = y\n    df_mean = df.groupby('labels').mean().T\n\n    df_mean['F'] = F\n    df_mean['pval'] = pvals\n\n    return df_mean.sort_values(sort_by, ascending=True)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef restore_data(self, data_dict):\n        session[self._base_key] = data_dict\n        self._data_dict = session[self._base_key]", "response": "Restore the data dict in the flask session and this object"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef multi(dispatch_fn, default=None):\n\n    def _inner(*args, **kwargs):\n        dispatch_value = dispatch_fn(*args, **kwargs)\n        f = _inner.__multi__.get(dispatch_value, _inner.__multi_default__)\n        if f is None:\n            raise Exception(\n                f\"No implementation of {dispatch_fn.__name__} \"\n                f\"for dispatch value {dispatch_value}\"\n            )\n        return f(*args, **kwargs)\n\n    _inner.__multi__ = {}\n    _inner.__multi_default__ = default\n    _inner.__dispatch_fn__ = dispatch_fn\n    return _inner", "response": "A decorator for a function to dispatch on."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef method(dispatch_fn, dispatch_key=None):\n\n    def apply_decorator(fn):\n        if dispatch_key is None:\n            # Default case\n            dispatch_fn.__multi_default__ = fn\n        else:\n            dispatch_fn.__multi__[dispatch_key] = fn\n        return fn\n\n    return apply_decorator", "response": "A decorator for a function implementing dispatch_fn for dispatch_key."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_blocks():\n\n    for app in settings.INSTALLED_APPS:\n        mod = import_module(app)\n        # Attempt to import the app's sizedimage module.\n        try:\n            before_import_block_registry = copy.copy(\n                block_registry._registry\n            )\n            import_module('{}.registered_blocks'.format(app))\n        except:\n            # Reset the block_registry to the state before the last\n            # import as this import will have to reoccur on the next request\n            # and this could raise NotRegistered and AlreadyRegistered\n            # exceptions (see django ticket #8245).\n            block_registry._registry = before_import_block_registry\n\n            # Decide whether to bubble up this error. If the app just\n            # doesn't have a stuff module, we can ignore the error\n            # attempting to import it, otherwise we want it to bubble up.\n            if module_has_submodule(mod, 'registered_blocks'):\n                raise", "response": "Find all blocks in INSTALLED_APPS and fail them silently when not present."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _verify_block(self, block_type, block):\n        if block_type in self._registry:\n            raise AlreadyRegistered(\n                \"A block has already been registered to the {} `block_type` \"\n                \"in the registry. Either unregister that block before trying \"\n                \"to register this block under a different `block_type`\".format(\n                    block_type\n                )\n            )\n        if not isinstance(block, Block):\n            raise InvalidBlock(\n                \"The block you tried register to {} is invalid. Only \"\n                \"instances of `wagtail.wagtailcore.blocks.Block` may be \"\n                \"registered with the the block_registry.\".format(block_type)\n            )", "response": "Verifies that a block is valid and raises an exception if it is not."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef register_block(self, block_type, block):\n\n        self._verify_block(block_type, block)\n        self._registry[block_type] = block", "response": "Registers a block to the registry."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef convert_to_mp3(file_name, delete_queue):\n\n\n    file = os.path.splitext(file_name)\n\n    if file[1] == '.mp3':\n        log.info(f\"{file_name} is already a MP3 file, no conversion needed.\")\n        return file_name\n\n    new_file_name = file[0] + '.mp3'\n\n    ff = FFmpeg(\n        inputs={file_name: None},\n        outputs={new_file_name: None}\n    )\n\n    log.info(f\"Conversion for {file_name} has started\")\n    start_time = time()\n    try:\n        ff.run(stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n    except FFRuntimeError:\n        os.remove(new_file_name)\n        ff.run(stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n    end_time = time()\n    log.info(f\"Conversion for {file_name} has finished in {end_time - start_time} seconds\")\n\n    delete_queue.put(file_name)\n    return new_file_name", "response": "Converts the file associated with the file_name passed into a MP3 file."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndelete the file associated with the file_name from local storage.", "response": "def delete_local_file(file_name):\n    \"\"\"\n    Deletes the file associated with the file_name passed from local storage.\n    \n    :param str file_name: Filename of the file to be deleted\n    :return str: Filename of the file that was just deleted\n    \"\"\"\n\n    try:\n        os.remove(file_name)\n        log.info(f\"Deletion for {file_name} has finished\")\n        return file_name\n    except OSError:\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _is_package(path):\n    def _exists(s):\n        return os.path.exists(os.path.join(path, s))\n\n    return (\n        os.path.isdir(path) and\n        (_exists('__init__.py') or _exists('__init__.pyc'))\n    )", "response": "Check if a path is a Python package."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef find_handfile(names=None):\n    # \u5982\u679c\u6ca1\u6709\u660e\u786e\u6307\u5b9a\uff0c\u5219\u5305\u542b env \u4e2d\u7684\u503c\n    names = names or [env.handfile]\n\n    # \u82e5\u65e0 ``.py`` \u6269\u5c55\u540d\uff0c\u5219\u4f5c\u4e3a\u5f85\u67e5\u8be2\u540d\u79f0\uff0c\u8ffd\u52a0\u5230 names \u672b\u5c3e\n    if not names[0].endswith('.py'):\n        names += [names[0] + '.py']\n\n    # name \u4e2d\u662f\u5426\u5305\u542b\u8def\u5f84\u5143\u7d20\n    if os.path.dirname(names[0]):\n        # \u82e5\u5b58\u5728\uff0c\u5219\u6269\u5c55 Home \u8def\u5f84\u6807\u5fd7\uff0c\u5e76\u6d4b\u8bd5\u662f\u5426\u5b58\u5728\n        for name in names:\n            expanded = os.path.expanduser(name)\n            if os.path.exists(expanded):\n                if name.endswith('.py') or _is_package(expanded):\n                    return os.path.abspath(expanded)\n    else:\n        # \u5426\u5219\uff0c\u9010\u7ea7\u5411\u4e0a\u641c\u7d22\uff0c\u76f4\u5230\u6839\u8def\u5f84\n        path = '.'\n\n        # \u5728\u5230\u7cfb\u7edf\u6839\u8def\u5f84\u4e4b\u524d\u505c\u6b62\n        while os.path.split(os.path.abspath(path))[1]:\n            for name in names:\n                joined = os.path.join(path, name)\n                if os.path.exists(joined):\n                    if name.endswith('.py') or _is_package(joined):\n                        return os.path.abspath(joined)\n            path = os.path.join('..', path)\n\n    return None", "response": "find_handfile - Finds the first. py file in the list of names"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_commands_from_module(imported):\n    # \u5982\u679c\u5b58\u5728 <module>.__all__ \uff0c\u5219\u9075\u5b88\n    imported_vars = vars(imported)\n    if \"__all__\" in imported_vars:\n        imported_vars = [\n            (name, imported_vars[name]) for name in\n            imported_vars if name in imported_vars[\"__all__\"]]\n    else:\n        imported_vars = imported_vars.items()\n\n    cmd_dict = extract_commands(imported_vars)\n    return imported.__doc__, cmd_dict", "response": "Get commands from a Python module."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef extract_commands(imported_vars):\n    commands = dict()\n    for tup in imported_vars:\n        name, obj = tup\n        if is_command_object(obj):\n            commands.setdefault(name, obj)\n    return commands", "response": "Extract commands from dict_items."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading a handfile into a dict.", "response": "def load_handfile(path, importer=None):\n    \"\"\"\n    \u5bfc\u5165\u4f20\u5165\u7684 ``handfile`` \u6587\u4ef6\u8def\u5f84\uff0c\u5e76\u8fd4\u56de(docstring, callables)\n\n    \u4e5f\u5c31\u662f handfile \u5305\u7684 ``__doc__`` \u5c5e\u6027 (\u5b57\u7b26\u4e32) \u548c\u4e00\u4e2a ``{'name': callable}``\n    \u7684\u5b57\u5178\uff0c\u5305\u542b\u6240\u6709\u901a\u8fc7 mohand \u7684 command \u6d4b\u8bd5\u7684 callables\n\n    :param str path: \u5f85\u5bfc\u5165\u7684 handfile \u6587\u4ef6\u8def\u5f84\n    :param function importer: \u53ef\u9009\uff0c\u5305\u5bfc\u5165\u51fd\u6570\uff0c\u9ed8\u8ba4\u4e3a ``__import__``\n    :return: \u5305\u63cf\u8ff0\u6587\u6863\uff0c\u4ec5\u542b\u7ec8\u7aef\u547d\u4ee4\u51fd\u6570\u7684\u5bf9\u8c61\u5b57\u5178\n    :rtype: (str, dict(str, object))\n    \"\"\"\n    if importer is None:\n        importer = __import__\n\n    # \u83b7\u53d6\u8def\u5f84&\u6587\u4ef6\u540d\n    directory, handfile = os.path.split(path)\n\n    # \u5982\u679c\u8def\u5f84\u4e0d\u5728 ``PYTHONPATH`` \u4e2d\uff0c\u5219\u6dfb\u52a0\uff0c\u4ee5\u4fbf\u4e8e\u6211\u4eec\u7684\u5bfc\u5165\u6b63\u5e38\u5de5\u4f5c\n    added_to_path = False\n    index = None\n    if directory not in sys.path:\n        sys.path.insert(0, directory)\n        added_to_path = True\n\n    # \u5982\u679c\u8def\u5f84\u5728 ``PYTHONPATH`` \u4e2d\uff0c\u5219\u4e34\u65f6\u5c06\u5176\u79fb\u5230\u6700\u524d\uff0c\u5426\u5219\u5176\u4ed6\u7684 ``handfile``\n    # \u6587\u4ef6\u5c06\u4f1a\u88ab\u4f18\u5148\u5bfc\u5165\uff0c\u800c\u4e0d\u662f\u6211\u4eec\u60f3\u8981\u5bfc\u5165\u7684\u90a3\u4e2a\n    else:\n        i = sys.path.index(directory)\n        if i != 0:\n            # \u4e3a\u4e4b\u540e\u7684\u6062\u590d\u4fdd\u5b58\u7d22\u5f15\u53f7\n            index = i\n            # \u6dfb\u52a0\u5230\u6700\u524d\uff0c\u7136\u540e\u5220\u9664\u539f\u59cb\u4f4d\u7f6e\n            sys.path.insert(0, directory)\n            del sys.path[i + 1]\n\n    # \u6267\u884c\u5bfc\u5165\uff08\u53bb\u9664 .py \u6269\u5c55\u540d\uff09\n    sys_byte_code_bak = sys.dont_write_bytecode\n    sys.dont_write_bytecode = True\n    imported = importer(os.path.splitext(handfile)[0])\n    sys.dont_write_bytecode = sys_byte_code_bak\n\n    # \u4ece ``PYTHONPATH`` \u4e2d\u79fb\u9664\u6211\u4eec\u81ea\u5df1\u6dfb\u52a0\u7684\u8def\u5f84\n    # \uff08\u4ec5\u4ec5\u51fa\u4e8e\u4e25\u8c28\uff0c\u5c3d\u91cf\u4e0d\u6c61\u67d3 ``PYTHONPATH`` \uff09\n    if added_to_path:\n        del sys.path[0]\n\n    # \u5c06\u6211\u4eec\u79fb\u52a8\u7684 PATH \u653e\u56de\u539f\u5904\n    if index is not None:\n        sys.path.insert(index + 1, directory)\n        del sys.path[0]\n\n    # \u5b9e\u9645\u52a0\u8f7d Command\n    docstring, commands = get_commands_from_module(imported)\n\n    return docstring, commands"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndetermines whether the desired version is a reasonable next version.", "response": "def reasonable_desired_version(self, desired_version, allow_equal=False,\n                                  allow_patch_skip=False):\n        \"\"\"\n        Determine whether the desired version is a reasonable next version.\n\n        Parameters\n        ----------\n        desired_version: str\n            the proposed next version name\n        \"\"\"\n        try:\n            desired_version = desired_version.base_version\n        except:\n            pass\n        (new_major, new_minor, new_patch) = \\\n                map(int, desired_version.split('.'))\n\n        tag_versions = self._versions_from_tags()\n        if not tag_versions:\n            # no tags yet, and legal version is legal!\n            return \"\"\n        max_version = max(self._versions_from_tags()).base_version\n        (old_major, old_minor, old_patch) = \\\n                map(int, str(max_version).split('.'))\n\n        update_str = str(max_version) + \" -> \" + str(desired_version)\n\n        v_desired = vers.Version(desired_version)\n        v_max = vers.Version(max_version)\n\n        if allow_equal and v_desired == v_max:\n            return \"\"\n\n        if v_desired < v_max:\n            return (\"Bad update: New version doesn't increase on last tag: \"\n                    + update_str + \"\\n\")\n\n        bad_update = skipped_version((old_major, old_minor, old_patch),\n                                     (new_major, new_minor, new_patch),\n                                     allow_patch_skip)\n\n        msg = \"\"\n        if bad_update:\n            msg = (\"Bad update: Did you skip a version from \"\n                   + update_str + \"?\\n\")\n\n        return msg"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks if a route needs ssl and redirects it if not.", "response": "def handle_ssl_redirect():\n    \"\"\"\n    Check if a route needs ssl, and redirect it if not.  Also redirects back to http for non-ssl routes.  Static routes\n    are served as both http and https\n\n    :return: A response to be returned or None\n    \"\"\"\n    if request.endpoint and request.endpoint not in ['static', 'filemanager.static']:\n        needs_ssl = False\n        ssl_enabled = False\n        view_function = current_app.view_functions[request.endpoint]\n        if request.endpoint.startswith('admin.') or \\\n                (hasattr(view_function, 'ssl_required') and view_function.ssl_required):\n            needs_ssl = True\n            ssl_enabled = True\n\n        if hasattr(view_function, 'ssl_allowed') and view_function.ssl_allowed:\n            ssl_enabled = True\n\n        if (hasattr(view_function, 'ssl_disabled') and view_function.ssl_disabled):\n            needs_ssl = False\n            ssl_enabled = False\n\n        if current_app.config['SSL_ENABLED']:\n            if needs_ssl and not request.is_secure:\n                log.debug('Redirecting to https: %s' % request.endpoint)\n                return redirect(request.url.replace(\"http://\", \"https://\"))\n            elif not ssl_enabled and request.is_secure:\n                log.debug('Redirecting to http: %s' % request.endpoint)\n                return redirect(request.url.replace(\"https://\", \"http://\"))\n        elif needs_ssl:\n            log.info('Not redirecting to HTTPS for endpoint %s as SSL_ENABLED is set to False' % request.endpoint)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninitialize the base library.", "response": "def init(app):\n    \"\"\"\n    Initialise this library.  The following config variables need to be in your Flask config:\n\n    REDIS_HOST: The host of the Redis server\n    REDIS_PORT: The port of the Redis server\n    REDIS_PASSWORD: The password used to connect to Redis or None\n    REDIS_GLOBAL_KEY_PREFIX: A short string unique to your application i.e. 'MYAPP'.  This will be turned into\n                             a prefix like '~~MYAPP~~:' and will be used to allow multiple applications to share\n                             a single redis server\n    REDIS_LOCK_TIMEOUT: An integer with the number of seconds to wait before automatically releasing a lock.\n                        A good number is 60 * 5 for 5 minutes.  This stops locks from being held indefinitely\n                        if something goes wrong, but bear in mind this can also cause concurrency issues if\n                        you ave a locking process that takes longer than this timeout!\n    \"\"\"\n    global connection, LOCK_TIMEOUT, GLOBAL_KEY_PREFIX\n\n    host = app.config['REDIS_HOST']\n    port = app.config['REDIS_PORT']\n    password = app.config['REDIS_PASSWORD']\n    \n    GLOBAL_KEY_PREFIX = '~~{}~~:'.format(app.config['REDIS_GLOBAL_KEY_PREFIX'])\n    LOCK_TIMEOUT = app.config['REDIS_LOCK_TIMEOUT']\n\n    connection = redis.StrictRedis(host=host, port=port, password=password)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a function that will enable error reporting for a Celery site.", "response": "def get_enable_celery_error_reporting_function(site_name, from_address):\n    \"\"\"\n    Use this to enable error reporting.  You need to put the following in your tasks.py or wherever you\n    want to create your celery instance:\n\n    celery = Celery(__name__)\n\n    enable_celery_email_logging = get_enable_celery_error_reporting_function('My Website [LIVE]', 'errors@mywebsite.com')\n    after_setup_logger.connect(enable_celery_email_logging)\n    after_setup_task_logger.connect(enable_celery_email_logging)\n    \"\"\"\n    def enable_celery_email_logging(sender, signal, logger, loglevel, logfile, format, colorize, **kwargs):\n        from celery import current_app\n        log.info('>> Initialising Celery task error reporting for logger {}'.format(logger.name))\n        \n        send_errors = current_app.conf['CELERY_SEND_TASK_ERROR_EMAILS']\n        send_warnings = current_app.conf['CELERY_SEND_TASK_WARNING_EMAILS']\n\n        if send_errors or send_warnings:\n            error_email_subject = '{} Celery ERROR!'.format(site_name)\n            celery_handler = CeleryEmailHandler(from_address, current_app.conf['ADMIN_EMAILS'],\n                                                error_email_subject)\n\n            if send_warnings:\n                celery_handler.setLevel(logging.WARNING)\n            else:\n                celery_handler.setLevel(logging.ERROR)\n            \n            logger.addHandler(celery_handler)\n\n    return enable_celery_email_logging"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef init_celery(app, celery):\n    celery.conf.update(app.config)\n    \n    TaskBase = celery.Task\n\n    class ContextTask(TaskBase):\n        abstract = True\n\n        def __call__(self, *args, **kwargs):\n            with app.app_context():\n                return TaskBase.__call__(self, *args, **kwargs)\n\n    celery.Task = ContextTask\n    \n    return celery", "response": "Initialise Celery and set up logging\nalues"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a new email to the queue.", "response": "def queue_email(to_addresses, from_address, subject, body, commit=True, html=True, session=None):\n    \"\"\"\n    Add a mail to the queue to be sent.\n\n    WARNING: Commits by default!\n\n    :param to_addresses: The names and addresses to send the email to, i.e. \"Steve<steve@fig14.com>, info@fig14.com\"\n    :param from_address: Who the email is from i.e. \"Stephen Brown <s@fig14.com>\"\n    :param subject: The email subject\n    :param body: The html / text body of the email\n    :param commit: Whether to commit to the database\n    :param html: Is this a html email?\n    :param session: The sqlalchemy session or None to use db.session\n    \"\"\"\n    from models import QueuedEmail\n\n    if session is None:\n        session = _db.session\n\n    log.info('Queuing mail to %s: %s' % (to_addresses, subject))\n    queued_email = QueuedEmail(html, to_addresses, from_address, subject, body, STATUS_QUEUED)\n    session.add(queued_email)\n    session.commit()\n\n    return queued_email"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_accept(header_value):\n    next_explicit_q = decimal.ExtendedContext.next_plus(decimal.Decimal('5.0'))\n    headers = [parse_content_type(header)\n               for header in parse_list(header_value)]\n    for header in headers:\n        q = header.parameters.pop('q', None)\n        if q is None:\n            q = '1.0'\n        elif float(q) == 1.0:\n            q = float(next_explicit_q)\n            next_explicit_q = next_explicit_q.next_minus()\n        header.quality = float(q)\n\n    def ordering(left, right):\n        \"\"\"\n        Method for sorting the header values\n\n        :param mixed left:\n        :param mixed right:\n        :rtype: mixed\n\n        \"\"\"\n        if left.quality != right.quality:\n            return right.quality - left.quality\n        if left == right:\n            return 0\n        if left > right:\n            return -1\n        return 1\n\n    return sorted(headers, key=functools.cmp_to_key(ordering))", "response": "Parses an HTTP Accept - like header and returns a list of content types and their corresponding content types in decreasing quality order."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses a Cache - Control header value and returns a dictionary of key - value pairs.", "response": "def parse_cache_control(header_value):\n    \"\"\"\n    Parse a `Cache-Control`_ header, returning a dictionary of key-value pairs.\n\n    Any of the ``Cache-Control`` parameters that do not have directives, such\n    as ``public`` or ``no-cache`` will be returned with a value of ``True``\n    if they are set in the header.\n\n    :param str header_value: ``Cache-Control`` header value to parse\n    :return: the parsed ``Cache-Control`` header values\n    :rtype: dict\n\n    .. _Cache-Control: https://tools.ietf.org/html/rfc7234#section-5.2\n\n    \"\"\"\n    directives = {}\n\n    for segment in parse_list(header_value):\n        name, sep, value = segment.partition('=')\n        if sep != '=':\n            directives[name] = None\n        elif sep and value:\n            value = _dequote(value.strip())\n            try:\n                directives[name] = int(value)\n            except ValueError:\n                directives[name] = value\n        # NB ``name='' is never valid and is ignored!\n\n    # convert parameterless boolean directives\n    for name in _CACHE_CONTROL_BOOL_DIRECTIVES:\n        if directives.get(name, '') is None:\n            directives[name] = True\n\n    return directives"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_content_type(content_type, normalize_parameter_values=True):\n    parts = _remove_comments(content_type).split(';')\n    content_type, content_subtype = parts.pop(0).split('/')\n    if '+' in content_subtype:\n        content_subtype, content_suffix = content_subtype.split('+')\n    else:\n        content_suffix = None\n    parameters = _parse_parameter_list(\n        parts, normalize_parameter_values=normalize_parameter_values)\n\n    return datastructures.ContentType(content_type, content_subtype,\n                                      dict(parameters),\n                                      content_suffix)", "response": "Parses a content type like header."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses the RFC 7239 Forwarded header.", "response": "def parse_forwarded(header_value, only_standard_parameters=False):\n    \"\"\"\n    Parse RFC7239 Forwarded header.\n\n    :param str header_value: value to parse\n    :keyword bool only_standard_parameters: if this keyword is specified\n        and given a *truthy* value, then a non-standard parameter name\n        will result in :exc:`~ietfparse.errors.StrictHeaderParsingFailure`\n    :return: an ordered :class:`list` of :class:`dict` instances\n    :raises: :exc:`ietfparse.errors.StrictHeaderParsingFailure` is\n        raised if `only_standard_parameters` is enabled and a non-standard\n        parameter name is encountered\n\n    This function parses a :rfc:`7239` HTTP header into a :class:`list`\n    of :class:`dict` instances with each instance containing the param\n    values.  The list is ordered as received from left to right and the\n    parameter names are folded to lower case strings.\n\n    \"\"\"\n    result = []\n    for entry in parse_list(header_value):\n        param_tuples = _parse_parameter_list(entry.split(';'),\n                                             normalize_parameter_names=True,\n                                             normalize_parameter_values=False)\n        if only_standard_parameters:\n            for name, _ in param_tuples:\n                if name not in ('for', 'proto', 'by', 'host'):\n                    raise errors.StrictHeaderParsingFailure('Forwarded',\n                                                            header_value)\n        result.append(dict(param_tuples))\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_link(header_value, strict=True):\n    sanitized = _remove_comments(header_value)\n    links = []\n\n    def parse_links(buf):\n        \"\"\"\n        Find quoted parts, these are allowed to contain commas\n        however, it is much easier to parse if they do not so\n        replace them with \\000.  Since the NUL byte is not allowed\n        to be there, we can replace it with a comma later on.\n        A similar trick is performed on semicolons with \\001.\n\n        :param str buf: The link buffer\n        :return:\n        \"\"\"\n        quoted = re.findall('\"([^\"]*)\"', buf)\n        for segment in quoted:\n            left, match, right = buf.partition(segment)\n            match = match.replace(',', '\\000')\n            match = match.replace(';', '\\001')\n            buf = ''.join([left, match, right])\n\n        while buf:\n            matched = re.match(r'<(?P<link>[^>]*)>\\s*(?P<params>.*)', buf)\n            if matched:\n                groups = matched.groupdict()\n                params, _, buf = groups['params'].partition(',')\n                params = params.replace('\\000', ',')  # undo comma hackery\n                if params and not params.startswith(';'):\n                    raise errors.MalformedLinkValue(\n                        'Param list missing opening semicolon ')\n\n                yield (groups['link'].strip(),\n                       [p.replace('\\001', ';').strip()\n                        for p in params[1:].split(';') if p])\n                buf = buf.strip()\n            else:\n                raise errors.MalformedLinkValue('Malformed link header', buf)\n\n    for target, param_list in parse_links(sanitized):\n        parser = _helpers.ParameterParser(strict=strict)\n        for name, value in _parse_parameter_list(param_list):\n            parser.add_value(name, value)\n\n        links.append(datastructures.LinkHeader(target=target,\n                                               parameters=parser.values))\n    return links", "response": "Parses a HTTP Link header value into a sequence of tuples."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_list(value):\n    segments = _QUOTED_SEGMENT_RE.findall(value)\n    for segment in segments:\n        left, match, right = value.partition(segment)\n        value = ''.join([left, match.replace(',', '\\000'), right])\n    return [_dequote(x.strip()).replace('\\000', ',')\n            for x in value.split(',')]", "response": "Parse a comma - separated list header."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse a named parameter list in the common format.", "response": "def _parse_parameter_list(parameter_list,\n                          normalized_parameter_values=_DEF_PARAM_VALUE,\n                          normalize_parameter_names=False,\n                          normalize_parameter_values=True):\n    \"\"\"\n    Parse a named parameter list in the \"common\" format.\n\n    :param parameter_list: sequence of string values to parse\n    :keyword bool normalize_parameter_names: if specified and *truthy*\n        then parameter names will be case-folded to lower case\n    :keyword bool normalize_parameter_values: if omitted or specified\n        as *truthy*, then parameter values are case-folded to lower case\n    :keyword bool normalized_parameter_values: alternate way to spell\n        ``normalize_parameter_values`` -- this one is deprecated\n    :return: a sequence containing the name to value pairs\n\n    The parsed values are normalized according to the keyword parameters\n    and returned as :class:`tuple` of name to value pairs preserving the\n    ordering from `parameter_list`.  The values will have quotes removed\n    if they were present.\n\n    \"\"\"\n    if normalized_parameter_values is not _DEF_PARAM_VALUE:  # pragma: no cover\n        warnings.warn('normalized_parameter_values keyword to '\n                      '_parse_parameter_list is deprecated, use '\n                      'normalize_parameter_values instead',\n                      DeprecationWarning)\n        normalize_parameter_values = normalized_parameter_values\n    parameters = []\n    for param in parameter_list:\n        param = param.strip()\n        if param:\n            name, value = param.split('=')\n            if normalize_parameter_names:\n                name = name.lower()\n            if normalize_parameter_values:\n                value = value.lower()\n            parameters.append((name, _dequote(value.strip())))\n    return parameters"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _parse_qualified_list(value):\n    found_wildcard = False\n    values, rejected_values = [], []\n    parsed = parse_list(value)\n    default = float(len(parsed) + 1)\n    highest = default + 1.0\n    for raw_str in parsed:\n        charset, _, parameter_str = raw_str.replace(' ', '').partition(';')\n        if charset == '*':\n            found_wildcard = True\n            continue\n        params = dict(_parse_parameter_list(parameter_str.split(';')))\n        quality = float(params.pop('q', default))\n        if quality < 0.001:\n            rejected_values.append(charset)\n        elif quality == 1.0:\n            values.append((highest + default, charset))\n        else:\n            values.append((quality, charset))\n        default -= 1.0\n    parsed = [value[1] for value in sorted(values, reverse=True)]\n    if found_wildcard:\n        parsed.append('*')\n    parsed.extend(rejected_values)\n    return parsed", "response": "Parse a qualified list of values based upon the quality rules specified in RFC 7231."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_link_header(header_value, strict=True):\n    warnings.warn(\"deprecated\", DeprecationWarning)\n    return parse_link(header_value, strict)", "response": "Parse a HTTP Link header value."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef resize_image_to_fit(image, dest_w, dest_h):\n    dest_w = float(dest_w)\n    dest_h = float(dest_h)\n    dest_ratio = dest_w / dest_h\n\n    # Calculate the apect ratio of the image\n    src_w = float(image.size[0])\n    src_h = float(image.size[1])\n    src_ratio = src_w / src_h\n\n    if src_ratio < dest_ratio:\n        # Image is tall and thin - we need to scale to the right height and then pad\n        scale = dest_h / src_h\n        scaled_h = dest_h\n        scaled_w = src_w * scale\n\n    else:\n        # Image is short and wide - we need to scale to the right height and then crop\n        scale = dest_w / src_w\n        scaled_w = dest_w\n        scaled_h = src_h * scale\n\n    scaled_image = image.resize((int(scaled_w), int(scaled_h)), PIL.Image.ANTIALIAS)\n\n    return scaled_image", "response": "Resize the image to fit inside the dest rectangle."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef resize_pad_image(image, dest_w, dest_h, pad_with_transparent=False):\n    dest_w = float(dest_w)\n    dest_h = float(dest_h)\n    dest_ratio = dest_w / dest_h\n\n    # Calculate the apect ratio of the image\n    src_w = float(image.size[0])\n    src_h = float(image.size[1])\n    src_ratio = src_w / src_h\n\n    if src_ratio < dest_ratio:\n        # Image is tall and thin - we need to scale to the right height and then pad\n        scale = dest_h / src_h\n        scaled_h = dest_h\n        scaled_w = src_w * scale\n\n        offset = (int((dest_w - scaled_w) / 2), 0)\n\n    else:\n        # Image is short and wide - we need to scale to the right height and then crop\n        scale = dest_w / src_w\n        scaled_w = dest_w\n        scaled_h = src_h * scale\n\n        offset = (0, int((dest_h - scaled_h) / 2))\n\n    scaled_image = image.resize((int(scaled_w), int(scaled_h)), PIL.Image.ANTIALIAS)\n    # Normally we will want to copy the source mode for the destination image, but in some\n    # cases the source image will use a Palletted (mode=='P') in which case we need to change\n    # the mode\n    mode = scaled_image.mode\n    log.debug('Padding image with mode: \"{}\"'.format(mode))\n    if pad_with_transparent and mode != 'RGBA':\n        old_mode = mode\n        mode = 'RGBA'\n        scaled_image = scaled_image.convert(mode)\n        log.debug('Changed mode from \"{}\" to \"{}\"'.format(old_mode, mode))\n\n    elif mode == 'P':\n        if 'transparency' in scaled_image.info:\n            mode = 'RGBA'\n        else:\n            mode = 'RGB'\n\n        scaled_image = scaled_image.convert(mode)\n        log.debug('Changed mode from \"P\" to \"{}\"'.format(mode))\n    \n    if pad_with_transparent:\n        pad_colour = (255, 255, 255, 0)\n    else:\n        # Get the pixel colour for coordinate (0,0)\n        pixels = scaled_image.load()\n        pad_colour = pixels[0, 0]\n    \n    padded_image = PIL.Image.new(mode, (int(dest_w), int(dest_h)), pad_colour)\n    padded_image.paste(scaled_image, offset)\n\n    return padded_image", "response": "Resize the image and pad the image to the correct aspect ratio."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a new value to the list of values that can be parsed from the URL.", "response": "def add_value(self, name, value):\n        \"\"\"\n        Add a new value to the list.\n\n        :param str name: name of the value that is being parsed\n        :param str value: value that is being parsed\n        :raises ietfparse.errors.MalformedLinkValue:\n            if *strict mode* is enabled and a validation error\n            is detected\n\n        This method implements most of the validation mentioned in\n        sections 5.3 and 5.4 of :rfc:`5988`.  The ``_rfc_values``\n        dictionary contains the appropriate values for the attributes\n        that get special handling.  If *strict mode* is enabled, then\n        only values that are acceptable will be added to ``_values``.\n\n        \"\"\"\n        try:\n            if self._rfc_values[name] is None:\n                self._rfc_values[name] = value\n            elif self.strict:\n                if name in ('media', 'type'):\n                    raise errors.MalformedLinkValue(\n                        'More than one {} parameter present'.format(name))\n                return\n        except KeyError:\n            pass\n\n        if self.strict and name in ('title', 'title*'):\n            return\n\n        self._values.append((name, value))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef values(self):\n        values = self._values[:]\n        if self.strict:\n            if self._rfc_values['title*']:\n                values.append(('title*', self._rfc_values['title*']))\n                if self._rfc_values['title']:\n                    values.append(('title', self._rfc_values['title*']))\n            elif self._rfc_values['title']:\n                values.append(('title', self._rfc_values['title']))\n        return values", "response": "Returns a sequence of name value pairs."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef download(self, url):\n\n        try:\n            yt = YouTube(url)\n        except RegexMatchError:\n            log.error(f\"Cannot download file at {url}\")\n        else:\n            stream = yt.streams.first()\n            log.info(f\"Download for {stream.default_filename} has started\")\n            start_time = time()\n            stream.download()\n            end_time = time()\n            log.info(f\"Download for {stream.default_filename} has finished in {end_time - start_time} seconds\")\n            return stream.default_filename", "response": "Downloads a MP4 or WebM file from YouTube."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndownloads a MP3 file that is associated with the given URL.", "response": "def download(self, url):\n        \"\"\"\n        Downloads a MP3 file that is associated with the track at the URL passed.\n        \n        :param str url: URL of the track to be downloaded\n        \"\"\"\n\n        try:\n            track = self.client.get('/resolve', url=url)\n        except HTTPError:\n            log.error(f\"{url} is not a Soundcloud URL.\")\n            return\n        r = requests.get(self.client.get(track.stream_url, allow_redirects=False).location, stream=True)\n        total_size = int(r.headers['content-length'])\n        chunk_size = 1000000\n        file_name = track.title + '.mp3'\n        with open(file_name, 'wb') as f:\n            for data in tqdm(r.iter_content(chunk_size), desc=track.title, total=total_size / chunk_size, unit='MB', file=sys.stdout):\n                f.write(data)\n        return file_name"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a connection to the Google Drive API and creates the Music folder if it doesn t exist.", "response": "def connect(self):\n        \"\"\"Creates connection to the Google Drive API, sets the connection attribute to make requests, and creates the Music folder if it doesn't exist.\"\"\"\n\n        SCOPES = 'https://www.googleapis.com/auth/drive'\n        store = file.Storage('drive_credentials.json')\n        creds = store.get()\n        if not creds or creds.invalid:\n            try:\n                flow = client.flow_from_clientsecrets('client_secret.json', SCOPES)\n            except InvalidClientSecretsError:\n                log.error('ERROR: Could not find client_secret.json in current directory, please obtain it from the API console.')\n                return\n            creds = tools.run_flow(flow, store)\n        self.connection = build('drive', 'v3', http=creds.authorize(Http()))\n\n        response = self.connection.files().list(q=\"name='Music' and mimeType='application/vnd.google-apps.folder' and trashed=false\").execute()\n        try:\n            folder_id = response.get('files', [])[0]['id']\n        except IndexError:\n            log.warning('Music folder is missing. Creating it.')\n            folder_metadata = {'name': 'Music', 'mimeType': 'application/vnd.google-apps.folder'}\n            folder = self.connection.files().create(body=folder_metadata, fields='id').execute()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nuploading the file to Google Drive in the Music folder.", "response": "def upload(self, file_name):\n        \"\"\"\n        Uploads the file associated with the file_name passed to Google Drive in the Music folder.\n\n        :param str file_name: Filename of the file to be uploaded\n        :return str: Original filename passed as an argument (in order for the worker to send it to the delete queue)\n        \"\"\"\n\n        response = self.connection.files().list(q=\"name='Music' and mimeType='application/vnd.google-apps.folder' and trashed=false\").execute()\n        folder_id = response.get('files', [])[0]['id']\n        file_metadata = {'name': file_name, 'parents': [folder_id]}\n        media = MediaFileUpload(file_name, mimetype='audio/mpeg')\n        \n        log.info(f\"Upload for {file_name} has started\")\n        start_time = time()\n        self.connection.files().create(body=file_metadata, media_body=media, fields='id').execute()\n        end_time = time()\n        log.info(f\"Upload for {file_name} has finished in {end_time - start_time} seconds\")\n\n        return file_name"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninitializes the connection attribute with the path to the user home folder s Music folder and creates it if it doesn t exist.", "response": "def connect(self):\n        \"\"\"Initializes the connection attribute with the path to the user home folder's Music folder, and creates it if it doesn't exist.\"\"\"\n\n        if self.music_folder is None:\n            music_folder = os.path.join(os.path.expanduser('~'), 'Music')\n            if not os.path.exists(music_folder):\n                os.makedirs(music_folder)\n            self.music_folder = music_folder"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef upload(self, file_name):\n        \n        log.info(f\"Upload for {file_name} has started\")\n        start_time = time()\n        os.rename(file_name, os.path.join(self.music_folder, file_name))\n        end_time = time()\n        log.info(f\"Upload for {file_name} has finished in {end_time - start_time} seconds\")", "response": "Uploads the file associated with the file_name to the Music folder in the local storage."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrite the run parameters to a text file", "response": "def write_run_parameters_to_file(self):\n        \"\"\"All of the class properties are written to a text file\n\n        Each property is on a new line with the key and value seperated with an equals sign '='\n        This is the mane planarrad properties file used by slabtool\n        \"\"\"\n\n        self.update_filenames()\n\n        lg.info('Writing Inputs to file : ' + self.project_file)\n\n        # First update the file names in case we changed the file values.  the file name includes the file values\n        # self.updateFileNames()\n\n        f = open(self.project_file, 'w')\n\n        f.write('name = ' + self.project_file + '\\n')\n        f.write('band_count = ' + str(len(self.wavelengths)) + '\\n')\n        f.write('bs_name = ' + str(len(self.wavelengths)) + ' Bands (' + str(self.wavelengths[0]) + '-' + str(\n            self.wavelengths[len(self.wavelengths) - 1]) + ' nm) \\n')\n        f.write('bs_code = ' + str(len(self.wavelengths)) + '\\n')\n        f.write('band_centres_data = ')\n        f.write(\",\".join([str(wave) for wave in self.wavelengths]) + '\\n')\n        # f.write('band_widths_data = ')\n        # for i in range(0, len(self.wavelengths) - 1):  # Find better way to do this!\n        # width = self.wavelengths[i + 1] - self.wavelengths[i]\n        #     f.write(str(width))\n        #     if i < len(self.wavelengths) - 2:\n        #         f.write(',')\n        f.write('\\n')\n        f.write('ds_name = ' + self.ds_name + '\\n')\n        f.write('ds_code = ' + self.ds_code + '\\n')\n        f.write('partition = ' + self.partition + '\\n')\n        f.write('vn = ' + str(self.vn) + '\\n')\n        f.write('hn = ' + str(self.hn) + '\\n')\n        f.write('theta_points=')\n        f.write(\",\".join([str(theta) for theta in self.theta_points]) + '\\n')\n        f.write('depth = ' + str(self.depth) + '\\n')\n        f.write('sample_point_distance = ' + str(self.sample_point_distance) + '\\n')\n        f.write('sample_point_delta_distance = ' + str(self.sample_point_delta_distance) + '\\n')\n        f.write('\\n')\n        f.write('sky_fp = ' + self.sky_file + '\\n')  # need to create these files from sky tool\n        f.write('water_surface_fp =' + self.water_surface_file)\n        f.write('\\n')\n        f.write('atten_fp = ' + self.attenuation_file + '\\n')\n        f.write('scat_fp = ' + self.scattering_file + '\\n')\n        f.write('pf_fp = ' + self.phase_function_file + '\\n')\n        f.write('bottom_reflec_diffuse_fp = ' + self.bottom_reflectance_file + '\\n')\n        f.write('sky_type = ' + self.sky_type + '\\n')\n        f.write('sky_azimuth = ' + str(self.sky_azimuth) + '\\n')\n        f.write('sky_zenith = ' + str(self.sky_zenith) + '\\n')\n        f.write('sky_C = ' + str(self.sky_c) + '\\n')\n        f.write('sky_rdif = ' + str(self.sky_r_dif) + '\\n')\n        f.write('iface_type = ' + self.iface_type + '\\n')\n        f.write('iface_refrac_index_0 = ' + str(self.iface_0_ri) + '\\n')\n        f.write('iface_refrac_index_1 = ' + str(self.iface_1_ri) + '\\n')\n        #        f.write('iop_atten_data = 1\\n')\n        #        f.write('iop_absorp_data = 0\\n')\n        f.write('iop_type = ' + self.iop_type + '\\n')\n        f.write('iop_backscatter_proportion_list = ' + str(self.iop_backscatter_proportion_list) + '\\n')\n        f.write('bound_bottom_reflec_diffuse_data = ' + str(self.bound_bottom_reflec_diffuse_data) + '\\n')\n        f.write('sky_sub_quad_count = ' + self.sky_sub_quad_count + '\\n')\n        f.write('iface_sub_quad_count = ' + self.iface_sub_quad_count + '\\n')\n        f.write('pf_sub_quad_count = ' + self.pf_sub_quad_count + '\\n')\n        f.write('integrator = ' + self.integrator + '\\n')\n        f.write('euler_steps_per_optical_depth = ' + str(self.euler_steps_per_optical_depth) + '\\n')\n        f.write('midpoint_steps_per_optical_depth = ' + str(self.midpoint_steps_per_optical_depth) + '\\n')\n        f.write('runga4_steps_per_optical_depth = ' + str(self.runga4_steps_per_optical_depth) + '\\n')\n        f.write('runga4adap_min_steps_per_optical_depth = ' + str(self.runga4adap_min_steps_per_optical_depth) + '\\n')\n        f.write('runga4adap_max_steps_per_optical_depth = ' + str(self.runga4adap_max_steps_per_optical_depth) + '\\n')\n        f.write('runga4adap_min_error = ' + str(self.runga4adap_min_error) + '\\n')\n        f.write('runga4adap_max_error = ' + str(self.runga4adap_max_error) + '\\n')\n        f.write('\\n')\n\n        f.write('Ld_b_image_save_fp = ' + os.path.join(self.output_path,\n                                                       'image_Ld_b.ppm') + '\\n')  #todo update this in the constructor not here\n\n        f.write('Ld_b_image_sens_k = ' + str(self.ld_b_image_sens_k) + '\\n')\n        f.write('\\n')\n        f.write('Ld_b_save_fp = ' + os.path.join(self.output_path,\n                                                 'Ld_b_data') + '\\n')\n        f.write('\\n')\n        f.write('report_save_fp = ' + self.report_file)\n        f.write('\\n')\n        f.write('verbose = ' + str(self.verbose) + '\\n')\n        f.close()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite the params to file that skytool_Free needs to generate the sky radiance distribution.", "response": "def write_sky_params_to_file(self):\n        \"\"\"Writes the params to file that skytool_Free needs to generate the sky radiance distribution.\"\"\"\n\n        inp_file = self.sky_file + '_params.txt'\n        lg.info('Writing Inputs to file : ' + inp_file)\n\n        f = open(inp_file, 'w')\n\n        f.write('verbose= ' + str(self.verbose) + '\\n')\n        f.write('band_count= ' + str(self.num_bands) + '\\n')\n        f.write('band_centres_data= ')\n        f.write(\",\".join([str(wave) for wave in self.wavelengths]) + '\\n')\n        f.write('partition= ' + self.partition + '\\n')\n        f.write('vn= ' + str(self.vn) + '\\n')\n        f.write('hn= ' + str(self.hn) + '\\n')\n        f.write('rdif= ' + str(self.sky_r_dif) + '\\n')\n        f.write('theta_points= ')\n        f.write(\",\".join([str(theta) for theta in self.theta_points]) + '\\n')\n        f.write('type= ' + self.sky_type + '\\n')\n        f.write('azimuth= ' + str(self.sky_azimuth) + '\\n')\n        f.write('zenith= ' + str(self.sky_zenith) + '\\n')\n        f.write('sky_save_fp= ' + inp_file.strip('_params.txt') + '\\n')\n        f.write('sky_image_save_fp= ' + self.sky_file + '.ppm' + '\\n')\n        f.write('sky_image_size= 256' + '\\n')\n        if self.sky_type == 'hlideal':\n            f.write('C= ' + str(self.sky_c) + '\\n')\n            f.write('rdif= ' + str(self.sky_r_dif) + '\\n')\n        f.flush()\n        f.close()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwriting the params to file that surftool_Free needs to generate the surface facets", "response": "def write_surf_params_to_file(self):\n        \"\"\"Write the params to file that surftool_Free needs to generate the surface facets\"\"\"\n\n        inp_file = self.water_surface_file + '_params.txt'\n        lg.info('Writing Inputs to file : ' + inp_file)\n\n        if self.surf_state == 'flat':  # this is the only one that currently works.\n            lg.info('Surface Type is :: flat')\n            f = open(inp_file, 'w')\n\n            f.write('verbose= ' + str(self.verbose) + '\\n')\n            f.write('band_count= ' + str(self.num_bands) + '\\n')\n            f.write('band_centres_data= ')\n            f.write(\",\".join([str(wave) for wave in self.wavelengths]) + '\\n')\n            f.write('partition= ' + self.partition + '\\n')\n            f.write('vn= ' + str(self.vn) + '\\n')\n            f.write('hn= ' + str(self.hn) + '\\n')\n            f.write('theta_points= ')\n            f.write(\",\".join([str(theta) for theta in self.theta_points]) + '\\n')\n            f.write('type= ' + self.iface_type + '\\n')\n            f.write('refrac_index_0= ' + str(self.iface_0_ri) + '\\n')\n            f.write('refrac_index_1= ' + str(self.iface_1_ri) + '\\n')\n            f.write('wind_speed= ' + str(self.wind_speed) + '\\n')\n            f.write('wind_direc= ' + str(self.wind_direc) + '\\n')\n            f.write('crosswind_vertices= ' + str(self.crosswind_vertices) + '\\n')\n            f.write('upwind_vertices= ' + str(self.upwind_vertices) + '\\n')\n            f.write('surface_size= ' + str(self.surface_size) + '\\n')\n            f.write('surface_radius=' + str(self.surface_radius) + '\\n')\n            f.write('target_size= ' + str(self.target_size) + '\\n')\n            f.write('rays_per_quad= ' + str(self.rays_per_quad) + '\\n')\n            f.write('surface_count= ' + str(self.surface_count) + '\\n')\n            f.write('azimuthally_average= ' + str(self.azimuthally_average) + '\\n')\n            f.write('surface_save_fp= ' + inp_file.strip('_params.txt') + '\\n')\n            f.flush()\n            f.close()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrite the params to file that surftool_Free needs to generate the surface facets", "response": "def write_phase_params_to_file(self):\n        \"\"\"Write the params to file that surftool_Free needs to generate the surface facets\"\"\"\n        inp_file = os.path.join(os.path.join(self.input_path, 'phase_files'), self.phase_function_file) + '_params.txt'\n        lg.info('Writing Inputs to file : ' + inp_file)\n\n        if self.iop_type == 'isotropic' or 'isotropic_integ' or 'petzold' or 'pure_water ':\n            lg.info('Iop type is :: ' + self.iop_type)\n\n            f = open(inp_file, 'w')\n\n            f.write('verbose = ' + str(self.verbose) + '\\n')\n            f.write('band_count = ' + str(self.num_bands) + '\\n')\n            f.write('band_centres_data = ')\n            f.write(\",\".join([str(wave) for wave in self.wavelengths]) + '\\n')\n            f.write('partition = ' + self.partition + '\\n')\n            f.write('vn = ' + str(self.vn) + '\\n')\n            f.write('hn = ' + str(self.hn) + '\\n')\n            f.write('theta_points = ')\n            f.write(\",\".join([str(theta) for theta in self.theta_points]) + '\\n')\n            f.write('type = ' + self.iop_type + '\\n')\n            f.write('phase_func_save_fp = ' + inp_file.strip('_params.txt') + '\\n')\n            f.flush()\n            f.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_filenames(self):\n        self.sky_file = os.path.abspath(os.path.join(os.path.join(self.input_path, 'sky_files'),\n                                                     'sky_' + self.sky_state + '_z' + str(\n                                                         self.sky_zenith) + '_a' + str(\n                                                         self.sky_azimuth) + '_' + str(\n                                                         self.num_bands) + '_' + self.ds_code))", "response": "Does nothing currently. May not need this method."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nbuild the particle backscattering function for the current species", "response": "def build_bbp(self, x, y, wave_const=550):\n        \"\"\"\n        Builds the particle backscattering function  :math:`X(\\\\frac{550}{\\\\lambda})^Y`\n\n        :param x: function coefficient\n        :param y: order of the power function\n        :param wave_const: wave constant default 550 (nm)\n        :returns null:\n        \"\"\"\n        lg.info('Building b_bp spectra')\n        self.b_bp = x * (wave_const / self.wavelengths) ** y"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nbuilds the CDOM absorption function", "response": "def build_a_cdom(self, g, s, wave_const=400):\n        \"\"\"\n        Builds the CDOM absorption function :: :math:`G \\exp (-S(\\lambda - 400))`\n\n        :param g: function coefficient\n        :param s: slope factor\n        :param wave_const: wave constant default = 400 (nm)\n        :returns null:\n        \"\"\"\n        lg.info('building CDOM absorption')\n        self.a_cdom = g * scipy.exp(-s * (self.wavelengths - wave_const))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading the phytoplankton absorption file from a csv formatted file.", "response": "def read_aphi_from_file(self, file_name):\n        \"\"\"Read the phytoplankton absorption file from a csv formatted file\n\n        :param file_name: filename and path of the csv file\n        \"\"\"\n        lg.info('Reading ahpi absorption')\n        try:\n            self.a_phi = self._read_iop_from_file(file_name)\n        except:\n            lg.exception('Problem reading file :: ' + file_name)\n            self.a_phi = -1"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nscale the spectra by multiplying by linear scaling factor.", "response": "def scale_aphi(self, scale_parameter):\n        \"\"\"Scale the spectra by multiplying by linear scaling factor\n\n        :param scale_parameter: Linear scaling factor\n        \"\"\"\n        lg.info('Scaling a_phi by :: ' + str(scale_parameter))\n        try:\n            self.a_phi = self.a_phi * scale_parameter\n        except:\n            lg.exception(\"Can't scale a_phi, check that it has been defined \")"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read_pure_water_absorption_from_file(self, file_name):\n        lg.info('Reading water absorption from file')\n        try:\n            self.a_water = self._read_iop_from_file(file_name)\n        except:\n            lg.exception('Problem reading file :: ' + file_name)", "response": "Read the pure water absorption from a csv formatted file"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading the pure water scattering from a csv formatted file", "response": "def read_pure_water_scattering_from_file(self, file_name):\n        \"\"\"Read the pure water scattering from a csv formatted file\n\n        :param file_name: filename and path of the csv file\n        \"\"\"\n        lg.info('Reading water scattering from file')\n        try:\n            self.b_water = self._read_iop_from_file(file_name)\n        except:\n            lg.exception('Problem reading file :: ' + file_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads the IOP from a file and interpolates it to the common wavelengths defined in the constructor.", "response": "def _read_iop_from_file(self, file_name):\n        \"\"\"\n        Generic IOP reader that interpolates the iop to the common wavelengths defined in the constructor\n\n        :param file_name: filename and path of the csv file\n        :returns interpolated iop\n        \"\"\"\n        lg.info('Reading :: ' + file_name + ' :: and interpolating to ' + str(self.wavelengths))\n\n        if os.path.isfile(file_name):\n            iop_reader = csv.reader(open(file_name), delimiter=',', quotechar='\"')\n            wave = iop_reader.next()\n            iop = iop_reader.next()\n        else:\n            lg.exception('Problem reading file :: ' + file_name)\n            raise IOError\n\n        try:\n            wave = map(float, wave)\n            iop = map(float, iop)\n            return scipy.interp(self.wavelengths, wave, iop)\n        except IOError:\n            lg.exception('Error interpolating IOP to common wavelength')\n            return -1"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _write_iop_to_file(self, iop, file_name):\n        lg.info('Writing :: ' + file_name)\n        f = open(file_name, 'w')\n        for i in scipy.nditer(iop):\n            f.write(str(i) + '\\n')", "response": "Generic iop file writer"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef build_b(self, scattering_fraction=0.01833):\n        lg.info('Building b with scattering fraction of :: ' + str(scattering_fraction))\n        self.b = (self.b_b + self.b_water / 2.0) / scattering_fraction", "response": "Calculates the total scattering from back - scattering\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalculates the total absorption from water phytoplankton and CDOM a", "response": "def build_a(self):\n        \"\"\"Calculates the total absorption from water, phytoplankton and CDOM\n\n        a = awater + acdom + aphi\n        \"\"\"\n        lg.info('Building total absorption')\n        self.a = self.a_water + self.a_cdom + self.a_phi"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate the total attenuation from the total absorption and total scattering", "response": "def build_c(self):\n        \"\"\"Calculates the total attenuation from the total absorption and total scattering\n\n        c = a + b\n        \"\"\"\n        lg.info('Building total attenuation C')\n        self.c = self.a + self.b"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef build_all_iop(self):\n        lg.info('Building all b and c from IOPs')\n\n        self.build_a()\n        self.build_bb()\n        self.build_b()\n        self.build_c()", "response": "Build all the b and c IOPs"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef run(self):\n        done = False\n        dir_list = []\n        tic = time.clock()\n        lg.info('Starting batch run at :: ' + str(tic))\n\n        if self.run_params.num_cpus == -1:  # user hasn't set a throttle\n            self.run_params.num_cpus = os.sysconf(\"SC_NPROCESSORS_ONLN\")\n            lg.info('Found ' + str(self.run_params.num_cpus) + ' CPUs')\n\n        # --------------------------------------------------#\n        # COUNT THE NUMBER OF DIRECTORIES TO ITERATE THROUGH\n        # --------------------------------------------------#\n        tmp_dir_list = os.listdir(self.batch_output)\n        for direc in tmp_dir_list:\n            dir_list.append(os.path.join(self.batch_output, direc))\n\n        num_dirs = len(dir_list)\n        lg.info('Found ' + str(num_dirs) + ' directories to process in ' + self.batch_output)\n\n        sub = scipy.floor(num_dirs / self.run_params.num_cpus)\n        remainder = num_dirs - (sub * self.run_params.num_cpus)\n        if remainder > 0:\n            lg.warning('Number of variations not evenly divisible by number of CPUs')\n            lg.warning('This is not a problem, last block will not use all available CPUs')\n            lg.warning('The remainder is :: ' + str(remainder))\n\n        while not done:\n            for l in range(0, int(sub)):\n                lg.info('Starting processing block of :: ' + str(self.run_params.num_cpus) + ' processes')\n\n                for m in range(0, self.run_params.num_cpus):\n                    #row = (m * sub) + l\n                    _dir = dir_list.pop()\n\n                    #--------------------------------------------------#\n                    # CHECK TO SEE IF REPORT HAS BEEN GENERATED AND DON'T\n                    # BOTHER RUNNING AGAIN IF THEY DO EXIST\n                    #--------------------------------------------------#\n\n                    report_dir, report_file_name = os.path.split(self.run_params.report_file)\n                    lg.debug(report_file_name)\n                    lg.debug(os.path.join(_dir, report_file_name))\n\n                    try:\n                        rep_size = os.path.getsize(os.path.join(_dir, report_file_name.strip('\\n')))\n                        lg.debug('report size is :: ' + str(rep_size))\n                    except:\n                        rep_size = 0\n\n                    if rep_size < 1.0:  # TODO this is a spoof!\n                        lg.info('No report file found, running process')\n                        p = Process(target=self._run, args=(_dir,))\n                    else:\n                        lg.warning('Report file found :: ' + os.path.join(_dir, report_file_name.strip(\n                            '\\n')) + ' not redoing run ')\n                        p = Process(target=self._dummy, args=(_dir,))\n\n                    # !! for testing\n                    #p = Process(target=self._dummy, args=(_dir,))\n                    p.start()\n                    lg.info('Starting Process :: Process ID :: ' + str(p.pid))\n\n                p.join()\n\n            self.run_params.num_cpus = remainder\n            remainder = 0\n            lg.info('Processing remainder')\n            sub = 1\n            if remainder == 0:\n                done = True\n\n        toc = time.clock()  # this isn't working\n        lg.info('Ending batch run at :: ' + str(toc))\n        timeTaken = toc - tic\n        lg.info('Time taken ::' + str(timeTaken))", "response": "This function is called by the _run method. It is responsible for performing the actual work across the CPUs."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _run(self, run_dir):\n\n        # Check to see if the required run_params files exist, if they dont use the tools to generate them\n\n        # --------------------------------------------------#\n        # HERE WE RECREATE OUR RUN_PARAMS OBJECT FROM\n        # THE RUN FILE WE WROTE TO DISK EARLIER\n        # --------------------------------------------------#\n        file_tools = FileTools()\n        run_dict = file_tools.read_param_file_to_dict(os.path.join(run_dir, 'batch.txt'))\n        #print(run_dict['band_centres_data'])\n\n        #self.run_params.wavelengths = run_dict['wavelengths']\n        #run_params = RunParameters()\n        #run_params = file_tools.dict_to_object(run_params, run_dict)\n        #------------------------------------------------#\n        # Sky inputs\n        #------------------------------------------------#\n        #lg.debug(run_dict.keys())\n        #self.run_params.update_filenames()\n        #lg.debug('!!!!!!!!!' + run_dict['sky_fp'])\n        if os.path.isfile(run_dict['sky_fp']):\n            sky_file_exists = True\n            lg.info('Found sky_tool generated file' + run_dict['sky_fp'])\n        else:\n            lg.info('No sky_tool generated file, generating one')\n            #try:\n            inp_file = run_dict['sky_fp'] + '_params.txt'\n            #self.run_params.sky_file = inp_file\n            self.run_params.write_sky_params_to_file()\n            #if not os.path.isfile(inp_file):\n            #    lg.error(inp_file + ' : is not a valid parameter file')\n            lg.debug('Runing skytool' + os.path.join(self.run_params.exec_path, 'skytool_free') + '#')\n            lg.debug(os.path.join(self.run_params.exec_path, 'skytool_free') + ' params=' + inp_file)\n            os.system(os.path.join(self.run_params.exec_path, 'skytool_free') + ' params=' + inp_file)\n            #except OSError:\n            #    lg.exception('Cannot execute PlannarRad, cannot find executable file to skytool_free')\n\n        #------------------------------------------------#\n        # Water surface inputs\n        #------------------------------------------------#\n        if os.path.isfile(run_dict['water_surface_fp']):\n            surface_file_exists = True\n            lg.info('Found surf_tool generated file' + run_dict['water_surface_fp'])\n        else:\n            lg.info('No surf_tool generated file, generating one')\n            try:\n                inp_file = run_dict['water_surface_fp'] + '_params.txt'\n                self.run_params.write_surf_params_to_file()\n                if not os.path.isfile(inp_file):\n                    lg.error(inp_file + ' : is not a valid parameter file')\n                os.system(os.path.join(self.run_params.exec_path, 'surftool_free') + ' params=' + inp_file)\n            except OSError:\n                lg.exception('Cannot execute PlannarRad, cannot find executable file to surftool_free')\n\n        #------------------------------------------------#\n        # Phase functions inputs\n        #------------------------------------------------#\n        if os.path.isfile(run_dict['pf_fp']):\n            phase_file_exists = True\n            lg.info('Found phase_tool generated file' + run_dict['pf_fp'])\n        else:\n            lg.info('No sky_tool generated file, generating one')\n            try:\n                inp_file = run_dict['pf_fp'] + '_params.txt'\n                self.run_params.write_phase_params_to_file()\n                if not os.path.isfile(inp_file):\n                    lg.error(inp_file + ' : is not a valid parameter file')\n                os.system(os.path.join(self.run_params.exec_path, 'phasetool_free') + ' params=' + inp_file)\n            except OSError:\n                lg.exception('Cannot execute PlannarRad, cannot find executable file to phasetool_free')\n\n        #------------------------------------------------#\n        # slabtool inputs [Run planarrad]\n        #------------------------------------------------#\n\n        inp_file = run_dict['name']\n\n        if not os.path.isfile(inp_file):\n            lg.error(inp_file + ' : is not a valid batch file')\n\n        try:\n            os.system(os.path.join(self.run_params.exec_path, 'slabtool_free') + ' params=' + inp_file)\n        except OSError:\n            lg.exception('Cannot execute PlannarRad, cannot find executable file to slabtool_free')", "response": "Run the distributed process."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef generate_directories(self, overwrite=False):\n        if not os.path.exists(self.batch_output):\n            try:\n                lg.info('Creating batch project directory')\n                if self.batch_output == self.run_params.output_path + 'batch':\n                    lg.warning('Using default project name.  Consider renaming!')\n                os.makedirs(self.batch_output)\n            except OSError:\n                lg.exception('Could not create project directory')\n\n        elif os.path.exists(self.batch_output) and overwrite == True:\n            try:\n                lg.info('Creating batch project directory')\n                lg.warning('Overwriting existing directories')\n                if self.batch_output == self.run_params.output_path + 'batch':\n                    lg.warning('Using default project name.  Consider renaming!')\n                os.makedirs(self.batch_output)\n            except OSError:\n                lg.exception('Could not create project directory')\n\n\n\n        # --------------------------------------------------#\n        # GENERATE ALL THE IOPS FROM BIOP\n        # --------------------------------------------------#\n\n        #--------------------------------------------------#\n        # WRITE EACH BIOP TO CSV FILE INTO THE INPUT\n        # DIRECTORY IF IT DOESNT EXIST\n        #--------------------------------------------------#\n\n        #--------------------------------------------------#\n        # GENERATE A LIST OF ALL COMBINATIONS OF BIOPS\n        #--------------------------------------------------#\n\n        #--------------------------------------------------#\n        # WRITE THE DIRECTORIES FOR EACH BIOP AND NAME APPROPRIATELY\n        # DON'T OVERWRITE IF THEY EXIST ALREADY\n        #--------------------------------------------------#\n\n        self.bio_params.read_pure_water_absorption_from_file(\n            self.run_params.pure_water_absorption_file)\n        self.bio_params.read_pure_water_scattering_from_file(\n            self.run_params.pure_water_scattering_file)\n        self.bio_params.read_aphi_from_file(self.run_params.phytoplankton_absorption_file)\n\n        for saa in self.saa_list:\n            # update the saa in the run file & the todo filename!\n            self.run_params.sky_aziumth = saa\n            self.run_params.sky_file = os.path.abspath(\n                os.path.join(os.path.join(self.run_params.input_path, 'sky_files'),\n                             'sky_' + self.run_params.sky_state + '_z' + str(self.run_params.sky_zenith) + '_a' + str(\n                                 self.run_params.sky_azimuth) + '_' + str(\n                                 self.run_params.num_bands) + '_' + self.run_params.ds_code))\n\n            for sza in self.sza_list:\n                # update the saz in the run file\n                self.run_params.sky_zenith = sza\n                self.run_params.sky_file = os.path.abspath(\n                    os.path.join(os.path.join(self.run_params.input_path, 'sky_files'),\n                                 'sky_' + self.run_params.sky_state + '_z' + str(\n                                     self.run_params.sky_zenith) + '_a' + str(self.run_params.sky_azimuth) + '_' + str(\n                                     self.run_params.num_bands) + '_' + self.run_params.ds_code))\n                for p in self.p_list:\n                    for x in self.x_list:\n                        for y in self.y_list:\n                            for g in self.g_list:\n                                for s in self.s_list:\n                                    for z in self.z_list:\n                                        file_name = 'SAA' + str(saa) + '_SZA' + str(sza) + '_P' + str(p) + '_X' + str(\n                                            x) + '_Y' + str(y) + '_G' + str(g) + '_S' + str(s) + '_Z' + str(z)\n                                        dir_name = os.path.join(self.batch_output, file_name)\n                                        self.run_params.output_path = dir_name\n                                        #--------------------------------------------------#\n                                        # UPDATE THE IOP PARAMETERS FOR THE RUN FILE\n                                        #--------------------------------------------------#\n                                        self.run_params.sky_azimuth = saa\n                                        self.run_params.sky_zenith = sza\n                                        self.run_params.depth = z\n                                        self.bio_params.build_bbp(x, y)  # todo add wave const as a kwarg\n                                        self.bio_params.build_a_cdom(g, s)\n                                        # Need to re-read the file as it was scaled in a the other run!\n                                        self.bio_params.read_aphi_from_file(\n                                            self.run_params.phytoplankton_absorption_file)\n                                        self.bio_params.scale_aphi(p)\n\n                                        self.bio_params.build_all_iop()\n                                        self.run_params.scattering_file = os.path.join(\n                                            os.path.join(self.run_params.input_path, 'iop_files'), 'b_' + file_name)\n                                        self.bio_params.write_b_to_file(self.run_params.scattering_file)\n\n                                        self.run_params.attenuation_file = os.path.join(\n                                            os.path.join(self.run_params.input_path, 'iop_files'), 'c_' + file_name)\n                                        self.bio_params.write_c_to_file(self.run_params.attenuation_file)\n\n                                        self.run_params.project_file = os.path.join(dir_name, 'batch.txt')\n                                        self.run_params.report_file = os.path.join(dir_name, 'report.txt')\n\n                                        self.run_params.write_sky_params_to_file()\n                                        self.run_params.write_surf_params_to_file()\n                                        self.run_params.write_phase_params_to_file()\n\n                                        if not os.path.exists(dir_name):\n                                            try:\n                                                lg.info('Creating run directory')\n                                                os.makedirs(dir_name)\n                                                self.run_params.write_run_parameters_to_file()\n                                            except OSError:\n                                                lg.exception('Could not create run directory')\n\n                                        elif os.path.exists(dir_name) and overwrite == True:\n                                            try:\n                                                lg.info('Creating run directory')\n                                                lg.warning('Overwriting existing directories')\n                                                os.makedirs(dir_name)\n                                                self.run_params.write_run_parameters_to_file()\n                                            except OSError:\n                                                lg.exception('Could not create run directory')", "response": "Generate a list of directories that are used to store the run parameters in the output directory."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntaking lists for parameters and saves them as class properties", "response": "def batch_parameters(self, saa, sza, p, x, y, g, s, z):\n        \"\"\"Takes lists for parameters and saves them as class properties\n\n        :param saa: <list> Sun Azimuth Angle (deg)\n        :param sza: <list> Sun Zenith Angle (deg)\n        :param p: <list> Phytoplankton linear scalling factor\n        :param x: <list> Scattering scaling factor\n        :param y: <list> Scattering slope factor\n        :param g: <list> CDOM absorption scaling factor\n        :param s: <list> CDOM absorption slope factor\n        :param z: <list> depth (m)\"\"\"\n        self.saa_list = saa\n        self.sza_list = sza\n        self.p_list = p\n        self.x_list = x\n        self.y_list = y\n        self.g_list = g\n        self.s_list = s\n        self.z_list = z"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads a text file to a python dictionary using = as the delimiter", "response": "def read_param_file_to_dict(file_name):\n        \"\"\"Loads a text file to a python dictionary using '=' as the delimiter\n\n        :param file_name: the name and path of the text file\n        \"\"\"\n        data = loadtxt(file_name, delimiter='=', dtype=scipy.string0)\n        data_dict = dict(data)\n        for key in data_dict.keys():\n            data_dict[key] = data_dict[key].strip()\n            data_dict[key.strip()] = data_dict[key]\n            del data_dict[key]\n\n        return data_dict"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef string_to_float_list(string_var):\n        try:\n            return [float(s) for s in string_var.strip('[').strip(']').split(', ')]\n        except:\n            return [float(s) for s in string_var.strip('[').strip(']').split(',')]", "response": "Pull comma separated string values out of a text file and converts them to float list"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef read_pr_report(self, filename):\n        done = False\n        f = open(filename)\n        while f:\n        #for line in open(filename):\n            line = f.readline()\n            if not line:\n                done = True\n                break\n\n            if \"# Quad solid angle mean point theta table (rows are horizontal, columns are vertical):\" in line.strip():\n                # read in the bunch of lines.\n                tmp = []\n                for i_iter in range(0, len(self.data_dictionary['theta_points_deg']) - 2):\n                    tmp.append(f.readline())\n\n                self.data_dictionary['Quad_solid_angle_mean_point_theta'] = tmp\n\n            elif '#' not in line or not line.strip():\n                element = line.split(',')\n                self.data_dictionary[element[0]] = element[1:]\n\n            if \"# Quad solid angle mean point phi table (rows are horizontal, columns are vertical):\" in line.strip():\n                # read in the bunch of lines.\n                tmp = []\n                for i_iter in range(0, len(self.data_dictionary['theta_points_deg']) - 2):\n                    tmp.append(f.readline())\n\n                self.data_dictionary['Quad_solid_angle_mean_point_phi'] = tmp\n\n            elif '#' not in line or not line.strip():\n                element = line.split(',')\n                self.data_dictionary[element[0]] = element[1:]\n\n            if \"L_w band\" in line.strip():\n\n                for i_iter in range(0, int(self.data_dictionary['band_count'][1])):\n                    tmp = []\n                    for j_iter in range(0, len(self.data_dictionary['theta_points_deg']) - 2):\n                        tmp.append(f.readline())\n\n                    self.data_dictionary['L_w_band_' + str(i_iter + 1)] = tmp\n                    f.readline()\n                    f.readline()  # skip the next 2 lines\n\n            if \"L_it band\" in line.strip():\n\n                for i_iter in range(0, int(self.data_dictionary['band_count'][1])):\n                    tmp = []\n                    for j_iter in range(0, len(self.data_dictionary['theta_points_deg']) - 2):\n                        tmp.append(f.readline())\n\n                    self.data_dictionary['L_it_band_' + str(i_iter + 1)] = tmp\n                    f.readline()\n                    f.readline()  # skip the next 2 lines\n\n\n\n\n        return self.data_dictionary", "response": "Reads in a PlanarRad generated report and saves the parameters as a python dictionary"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalculates the directional AOP for the current region.", "response": "def calc_directional_aop(self, report, parameter, parameter_dir):\n        \"\"\"\n        Will calcuate the directional AOP (only sub-surface rrs for now) if the direction is defined using @\n        e.g. rrs@32.0:45  where <zenith-theta>:<azimuth-phi>\n\n        :param report: The planarrad report dictionary.  should include the quadtables and the directional info\n        :param parameter: parameter to calc.  Currently only sub-surface reflectance rrs.\n        :return:\n        \"\"\"\n        lg.debug('calculating the directional ' + parameter)\n        tmp_zenith = []\n\n        param_zenith = parameter_dir.split(':')[0]\n        param_azimuth = parameter_dir.split(':')[1]\n\n        # --------------------------------------------------#\n        # find the mean directions values\n        # --------------------------------------------------#\n        for i_iter in range(0, int(report['vn'][1])):\n            tmp_zenith.append(report['Quad_solid_angle_mean_point_theta'][i_iter][:].split(',')[0]) #that was a pain!\n\n        tmp_azimuth = report['Quad_solid_angle_mean_point_phi'][1]\n        zenith = scipy.asarray(tmp_zenith, dtype=float)\n        azimuth = scipy.fromstring(tmp_azimuth, dtype=float, sep=',')\n\n        # --------------------------------------------------#\n        # now grab the min and max index of the closest match\n        # --------------------------------------------------#\n        #min_zenith_idx = (scipy.abs(zenith - param_zenith)).argmin()\n\n        from scipy import interpolate\n\n\n        lw = scipy.zeros(int(report['band_count'][1]))\n\n        for j_iter in range(0, int(report['band_count'][1])):\n\n            if parameter == 'rrs':\n                lg.info('Calculating directional rrs')\n                tmp_lw = report['L_w_band_' + str(j_iter + 1)]\n            elif parameter == 'Rrs':\n                lg.info('Calculating directional Rrs')\n                print(report.keys())\n                tmp_lw = report['L_it_band_' + str(j_iter + 1)]\n\n            lw_scal = scipy.zeros((int(report['vn'][1]), int(report['hn'][1])))\n\n            # for the fist and last line we have to replicate the top and bottom circle\n            for i_iter in range(0, int(report['hn'][1])):\n                lw_scal[0, i_iter] = tmp_lw[0].split(',')[0]\n                lw_scal[int(report['vn'][1]) - 1, i_iter] = tmp_lw[-1].split(',')[0]\n\n            for i_iter in range(1, int(report['vn'][1]) - 1):\n                lw_scal[i_iter, :] = scipy.asarray(tmp_lw[i_iter].split(','), dtype=float)\n\n            # to do, make an array of zeros and loop over each list an apply to eah line.  bruteforce\n\n            f1 = interpolate.interp2d(zenith, azimuth, lw_scal)\n            lw[j_iter] = f1(float(param_zenith), float(param_azimuth))\n\n        # ----\n        # Now we finally have L_w we calculate the rrs\n        # ----\n\n        if parameter == 'rrs':\n            tmp_rrs = lw / scipy.asarray(report['Ed_w'], dtype=float)[1:]  # ignore the first val as that is depth of val\n        elif parameter == 'Rrs':\n            tmp_rrs = lw / scipy.asarray(report['Ed_a'], dtype=float)[1:]  # ignore the first val as that is depth of val\n\n        # make rrs a string so it can be written to file.\n\n        rrs = \",\".join(map(str, tmp_rrs))\n\n        return \" ,\" + rrs"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write_batch_report(self, input_directory, parameter):\n\n        # Check to see if there is an @ in the parameter.  If there is split\n        if '@' in parameter:\n            parameter_dir = parameter.split('@')[1]\n            parameter = parameter.split('@')[0]\n\n        # --------------------------------------------------#\n        # we put the batch report one directory up in the tree\n        # --------------------------------------------------#\n        batch_report_file = 'batch_report.txt'\n        batch_report_file = os.path.join(input_directory, batch_report_file)\n        f = open(batch_report_file, 'w')\n        w = csv.writer(f, delimiter=',')\n\n        #--------------------------------------------------#\n        # Read in the report from planarrad and pull out the parameter that we want\n        #--------------------------------------------------#\n        dir_list = os.listdir(input_directory)\n\n        #--------------------------------------------------#\n        # Sometimes the report isn't generated for some reason.\n        # this checks to see if the first file in the dir list exists and skips if it doesn't\n        #--------------------------------------------------#\n        read_first_file = True\n        i_iter = 0\n        while read_first_file:\n            if os.path.exists(os.path.join(input_directory, os.path.join(dir_list[i_iter], 'report.txt'))):\n                report = self.read_pr_report(\n                    os.path.join(input_directory, os.path.join(dir_list[i_iter], 'report.txt')))\n                read_first_file = False\n            else:\n                lg.warning('Missing report file in' + dir_list[i_iter])\n                i_iter += 1\n\n        try:\n            wave_val = report['band_centres']\n            param_val = report[parameter]\n        except:\n            lg.exception('Parameter :: ' + str(parameter) + ' :: Not in report')\n\n        wave_str = str(wave_val)\n        wave_str = wave_str.strip('[').strip(']').replace('\\'', '').replace('\\\\n', '').replace('  ', '').replace(' -,',\n                                                                                                                 '').replace(\n            ',', '\\\",\\\"')\n\n        f.write(\n            '\\\"Sun Azimuth (deg)\\\",\\\"Sun Zenith (deg)\\\",\\\"Phytoplankton\\\",\\\"Scattering X\\\",\\\"Scattering Y\\\",\\\"CDOM G\\\",\\\"CDOM S\\\",\\\"Depth (m)\\\",\\\"#wave length (nm) ->\\\",\\\"' + wave_str + '\\\"\\n')\n\n        #--------------------------------------------------#\n        # Get all of the directories under the batch directories\n        # The directory names have the IOP parameters in the names\n        #--------------------------------------------------#\n\n        for dir in dir_list:\n            if os.path.isdir(os.path.abspath(os.path.join(input_directory, dir))):\n                tmp_str_list = dir.split('_')\n                #for tmp_str in tmp_str_list:\n                saa = ''.join(c for c in tmp_str_list[0] if not c.isalpha())\n                sza = ''.join(c for c in tmp_str_list[1] if not c.isalpha())\n                p = ''.join(c for c in tmp_str_list[2] if not c.isalpha())\n                x = ''.join(c for c in tmp_str_list[3] if not c.isalpha())\n                y = ''.join(c for c in tmp_str_list[4] if not c.isalpha())\n                g = ''.join(c for c in tmp_str_list[5] if not c.isalpha())\n                s = ''.join(c for c in tmp_str_list[6] if not c.isalpha())\n                z = ''.join(c for c in tmp_str_list[7] if not c.isalpha())\n\n                #--------------------------------------------------#\n                # Write the report header and then the values above in the columns\n                #--------------------------------------------------#\n                try:\n                    f.write(saa + ',' + sza + ',' + p + ',' + x + ',' + y + ',' + g + ',' + s + ',' + z + ',')\n\n                    report = self.read_pr_report(os.path.join(input_directory, os.path.join(dir, 'report.txt')))\n                    try:\n                        # check to see if the parameter has the @ parameter.  If it does pass to directional calculator\n                        if 'parameter_dir' in locals():\n                            param_val = self.calc_directional_aop(report, parameter, parameter_dir)\n                        else:\n                            param_val = report[parameter]\n\n                        param_str = str(param_val)\n                        param_str = param_str.strip('[').strip(']').replace('\\'', '').replace('\\\\n', '').replace('  ',\n                                                                                                                 '')\n                        f.write(param_str + '\\n')\n                    except:\n                        lg.exception('Parameter :: ' + str(parameter) + ' :: Not in report')\n                except:\n                    lg.warning('Cannot find a report in directory :: ' + dir)", "response": "This function writes a batch report from the planarrad and returns a file containing the results."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef write_batch_to_file(self, filename='batch_test_default.txt'):\n\n        #---------------------------------------------------------#\n        # The following is the file which is passed to planarradpy.\n        #---------------------------------------------------------#\n        self.batch_file = open(str(filename), 'w')\n\n        self.batch_file.write(\"\"\"#----------------------------------------#\n# Name of the batch run\n#----------------------------------------#\nbatch_name = \"\"\")\n        self.batch_file.write(str(self.batch_name))\n        self.batch_file.write(\"\"\"\n\n#----------------------------------------#\n# Bio-optical parameters list\n#----------------------------------------#\nsaa_list = \"\"\")\n        self.batch_file.write(str(self.saa_values))\n        self.batch_file.write(\"\"\"\nsza_list = \"\"\")\n        self.batch_file.write(str(self.sza_values))\n        self.batch_file.write(\"\"\"\np_list = \"\"\")\n        self.batch_file.write(str(self.p_values))\n        self.batch_file.write(\"\"\"\nx_list = \"\"\")\n        self.batch_file.write(str(self.x_value))\n        self.batch_file.write(\"\"\"\ny_list = \"\"\")\n        self.batch_file.write(str(self.y_value))\n        self.batch_file.write(\"\"\"\ng_list = \"\"\")\n        self.batch_file.write(str(self.g_value))\n        self.batch_file.write(\"\"\"\ns_list = \"\"\")\n        self.batch_file.write(str(self.s_value))\n        self.batch_file.write(\"\"\"\nz_list = \"\"\")\n        self.batch_file.write(str(self.z_value))\n        self.batch_file.write(\"\"\"\n\n#----------------------------------------#\n# Wavelengths\n# All IOPs are interpolated to these \n# Wavelengths\n#----------------------------------------#\nwavelengths = \"\"\")\n        self.batch_file.write(str(self.wavelength_values))\n        self.batch_file.write(\"\"\"\n\n#----------------------------------------#\n# Number of CPUs\n# -1 means query the number of CPUs\n#----------------------------------------#\nnum_cpus = \"\"\")\n        self.batch_file.write(str(self.nb_cpu))\n        self.batch_file.write(\"\"\"\n\n#----------------------------------------#\n# Path of Planarrad\n#----------------------------------------#\nexec_path = \"\"\")\n        self.batch_file.write(self.executive_path)\n        self.batch_file.write(\"\"\"\n\n#----------------------------------------#\n# Logging level\n#----------------------------------------#\nverbose = \"\"\")\n        self.batch_file.write(str(self.verbose_value))\n        self.batch_file.write(\"\"\"\n\n#----------------------------------------#\n# File paths\n# Using absolute paths\n#----------------------------------------#\nphytoplankton_absorption_file =\"\"\")\n        self.batch_file.write(self.phytoplankton_path)\n        self.batch_file.write(\"\"\"\nbottom_reflectance_file = \"\"\")\n        self.batch_file.write(self.bottom_path)\n        self.batch_file.write(\"\"\"\n\n#----------------------------------------#\n# Set the parameter to report\n#----------------------------------------#\nreport_parameter = \"\"\")\n        self.batch_file.write(str(self.report_parameter_value))\n\n        self.batch_file.write(\"\"\"\n\n\"\"\")\n\n        self.batch_file.close()\n\n        #-------------------------------------------------------------------#\n        # The following is the action to move the file to the good directory.\n        #-------------------------------------------------------------------#\n        src = './' + filename\n        dst = './inputs/batch_files'\n        os.system(\"mv\" + \" \" + src + \" \" + dst)", "response": "This function creates a new file and writes the data and comments associated to the species."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update_fields(self, x_data, y_data, num_plot):\n        self.x_data = x_data\n        self.y_data = y_data\n        self.num_plot = num_plot", "response": "This function will update the x_data y_data and num_plot fields of the neccesary data structures that we need to display."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_handler(self, signals, handler=signal.SIG_DFL):\n        for sig in signals:\n            self.log.debug(\"Creating handler for signal: {0}\".format(sig))\n            signal.signal(sig, handler)", "response": "Sets a handler for the given list of signals."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndefaults handler for signals", "response": "def default_handler(self, signum, frame):\n        \"\"\" Default handler, a generic callback method for signal processing\"\"\"\n        self.log.debug(\"Signal handler called with signal: {0}\".format(signum))\n        # 1. If signal is HUP restart the python process\n        # 2. If signal is TERM, INT or QUIT we try to cleanup then exit with -1\n        # 3. If signal is STOP or TSTP we pause\n        # 4. If signal is CONT or USR1 we continue\n        # 5. If signal is INFO we print status\n        # 6. If signal is USR2 we we abort and then exit with -1\n\n        if signum in self.restart_signals:\n            self.set_handler(self.handled_signals, self.pseudo_handler)\n            self._cleanup()\n            os.execl('python', 'python', * sys.argv)\n        elif signum in self.abort_signals:\n            self.abort(signum)\n        elif signum in self.pause_signals:\n            self.pause(signum)\n        elif signum in self.resume_signals:\n            self.resume(signum)\n        elif signum in self.status_signals:\n            self.status(signum)\n        elif signum in self.error_signals:\n            self.log.error('Signal handler received error signal from an external process, aborting')\n            self.abort(signum)\n        else:\n            self.log.error(\"Unhandled signal received: {0}\".format(signum))\n            raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pause(self, signum, seconds=0, callback_function=None):\n        if callback_function is None:\n            callback_function = self.default_handler\n        if seconds > 0:\n            self.log.info(\"Signal handler pausing for {0} seconds or until it receives SIGALRM or SIGCONT\".format(seconds))\n            signal.signal(signal.SIGALRM, callback_function)\n            signal.alarm(seconds)\n        else:\n            self.log.info('Signal handler pausing until it receives SIGALRM or SIGCONT')\n        signal.signal(signal.SIGCONT, callback_function)\n        signal.pause()\n        self.log.info('Signal handler resuming from pause')\n        if signum == signal.SIGALRM:\n            return True\n        else:\n            return False", "response": "Pause execution will pause for the specified number of seconds or until the signal handler receives SIGALRM or SIGCONT."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nruns all abort tasks then exit with error return status", "response": "def abort(self, signum):\n        \"\"\" Run all abort tasks, then all exit tasks, then exit with error\n        return status\"\"\"\n        self.log.info('Signal handler received abort request')\n        self._abort(signum)\n        self._exit(signum)\n        os._exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalling when the status signal is received from the status queue.", "response": "def status(self, signum):\n        \"\"\" Run all status tasks, then run all tasks in the resume queue\"\"\"\n        self.log.debug('Signal handler got status signal')\n        new_status_callbacks = []\n        for status_call in self.status_callbacks:\n            # If callback is non persistent we remove it\n            try:\n                self.log.debug(\"Calling {0}({1},{2})\".format(status_call['function'].__name__, status_call['args'], status_call['kwargs']))\n            except AttributeError:\n                self.log.debug(\"Calling unbound function/method {0}\".format(str(status_call)))\n\n            apply(status_call['function'], status_call['args'], status_call['kwargs'])\n            if status_call['persistent']:\n                new_status_callbacks.append(status_call)\n        self.status_callbacks = new_status_callbacks\n        self._resume(signum)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving an event from the event list", "response": "def _unreg_event(self, event_list, event):\n        \"\"\" Tries to remove a registered event without triggering it \"\"\"\n        try:\n            self.log.debug(\"Removing event {0}({1},{2})\".format(event['function'].__name__, event['args'], event['kwargs']))\n        except AttributeError:\n            self.log.debug(\"Removing event {0}\".format(str(event)))\n\n        try:\n            event_list.remove(event)\n        except ValueError:\n            try:\n                self.log.warn(\"Unable to remove event {0}({1},{2}) , not found in list: {3}\".format(event['function'].__name__, event['args'], event['kwargs'], event_list))\n            except AttributeError:\n                self.log.debug(\"Unable to remove event {0}\".format(str(event)))\n            raise KeyError('Unable to unregister the specified event from the signals specified')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nregistering a function or method to be called on program exit", "response": "def reg_on_exit(self, callable_object, *args, **kwargs):\n        \"\"\" Register a function/method to be called on program exit,\n        will get executed regardless of successs/failure of the program running \"\"\"\n        persistent = kwargs.pop('persistent', False)\n        event = self._create_event(callable_object, 'exit', persistent, *args, **kwargs)\n        self.exit_callbacks.append(event)\n        return event"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef reg_on_abort(self, callable_object, *args, **kwargs):\n        persistent = kwargs.pop('persistent', False)\n        event = self._create_event(callable_object, 'abort', persistent, *args, **kwargs)\n        self.abort_callbacks.append(event)\n        return event", "response": "Register a function or method to be called when execution is aborted"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef reg_on_status(self, callable_object, *args, **kwargs):\n        persistent = kwargs.pop('persistent', False)\n        event = self._create_event(callable_object, 'status', persistent, *args, **kwargs)\n        self.status_callbacks.append(event)\n        return event", "response": "Register a function to be called when a user or another\n        program asks for an update"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nregisters a function or method to be called when the system needs to have to resumed or paused execution.", "response": "def reg_on_resume(self, callable_object, *args, **kwargs):\n        \"\"\" Register a function/method to be called if the system needs to\n        resume a previously halted or paused execution, including status\n        requests.\"\"\"\n        persistent = kwargs.pop('persistent', False)\n        event = self._create_event(callable_object, 'resume', persistent, *args, **kwargs)\n        self.resume_callbacks.append(event)\n        return event"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fetch_metric(self, metric, start, end, tags={}, aggregator=\"sum\",\n        downsample=None, ms_resolution=True):\n        \"\"\"Fetch time series data from OpenTSDB\n\n        Parameters:\n            metric:\n                A string representing a valid OpenTSDB metric.\n\n            tags:\n                A dict mapping tag names to tag values. Tag names and values are\n                always strings.\n\n                { 'user_id': '44' }\n\n            start:\n                A datetime.datetime-like object representing the start of the\n                range to query over.\n\n            end:\n                A datetime.datetime-like object representing the end of the\n                range to query over.\n\n            aggregator:\n                The function for merging multiple time series together. For\n                example, if the \"user_id\" tag is not specified, this aggregator\n                function is used to combine all heart rate time series into one\n                time series. (Yes, this isn't very useful.)\n\n                For queries that return only one time series, this parameter is\n                not relevant.\n\n                Valid values: \"sum\", \"min\", \"max\", \"avg\", \"dev\"\n\n                See: http://opentsdb.net/docs/build/html/user_guide/query/aggregators.html\n\n            downsampling:\n                A relative time interval to \"downsample\". This isn't true\n                downsampling; rather, if you specify a downsampling of \"5m\"\n                (five minutes), OpenTSDB will split data into five minute\n                intervals, and return one data point in the middle of each\n                interval whose value is the average of all data points within\n                that interval.\n\n                Valid relative time values are strings of the following format:\n\n                    \"<amount><time_unit>\"\n\n                Valid time units: \"ms\", \"s\", \"m\", \"h\", \"d\", \"w\", \"n\", \"y\"\n\n                Date and time format: http://opentsdb.net/docs/build/html/user_guide/query/dates.html\n\n            ms_resolution:\n                Whether or not to output data point timestamps in milliseconds\n                or seconds. If this flag is false and there are multiple\n                data points within a second, those data points will be down\n                sampled using the query's aggregation function.\n\n        Returns:\n            A dict mapping timestamps to data points\n        \"\"\"\n        query = \"{aggregator}:{downsample}{metric}{{{tags}}}\".format(\n            aggregator=aggregator,\n            downsample=downsample + \"-avg:\" if downsample else \"\",\n            metric=metric,\n            tags=','.join(\"%s=%s\" % (k, v) for k, v in tags.items())\n        )\n        params = {\n            'ms': ms_resolution,\n            'start': '{0:.3f}'.format(start.timestamp()),\n            'end': '{0:.3f}'.format(end.timestamp()),\n            'm': query\n        }\n        response = self.__request(\"/query\", params)\n\n        if response.status_code == 200:\n            try:\n                return response.json()[0]['dps']\n            except IndexError:\n                # empty data set\n                return {}\n\n        raise QueryError(response.json())", "response": "Fetch time series data from OpenTSDB."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfetch and sort time series data from OpenTSDB Takes the same parameters as fetch_metric but returns a list of tuples sorted by timestamp.", "response": "def fetch_sorted_metric(self, *args, **kwargs):\n        \"\"\"Fetch and sort time series data from OpenTSDB\n\n        Takes the same parameters as `fetch_metric`, but returns a list of\n        (timestamp, value) tuples sorted by timestamp.\n        \"\"\"\n        return sorted(self.fetch_metric(*args, **kwargs).items(),\n            key=lambda x: float(x[0]))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pfreduce(func, iterable, initial=None):\n\n    iterator = iter(iterable)\n    try:\n        first_item = next(iterator)\n        if initial:\n            value = func(initial, first_item)\n        else:\n            value = first_item\n    except StopIteration:\n        return initial\n\n    for item in iterator:\n        value = func(value, item)\n    return value", "response": "A pointfree reduce function that applies a function of two arguments cumulatively to the items supplied by the given iterable so\n    as to reduce the iterable to a single value."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncollecting and returns a list of values from the given iterable. If n is not specified returns all values from the given iterable.", "response": "def pfcollect(iterable, n=None):\n    \"\"\"Collects and returns a list of values from the given iterable.  If\n    the n parameter is not specified, collects all values from the\n    iterable.\n\n    :param iterable: An iterable yielding values for the list\n    :param n: An optional maximum number of items to collect\n    :rtype: List of values from the iterable\n\n    Example::\n\n        >>> @pointfree\n        ... def fibonaccis():\n        ...     a, b = 0, 1\n        ...     while True:\n        ...         a, b = b, a+b\n        ...         yield a\n\n        >>> (pfcollect(n=10) * fibonaccis)()\n        [1, 1, 2, 3, 5, 8, 13, 21, 34, 55]\n\n    \"\"\"\n\n    if n:\n        return list(itertools.islice(iterable, n))\n    else:\n        return list(iterable)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprint an item to stdout.", "response": "def pfprint(item, end='\\n', file=None):\n    \"\"\"Prints an item.\n\n    :param item: The item to print\n    :param end: String to append to the end of printed output\n    :param file: File to which output is printed\n    :rtype: None\n\n    Example::\n\n        >>> from operator import add\n\n        >>> fn = pfreduce(add, initial=0) >> pfprint\n        >>> fn([1, 2, 3, 4])\n        10\n\n    \"\"\"\n\n    # Can't just make sys.stdout the file argument's default value, because\n    # then we would be capturing the stdout file descriptor, and then\n    # doctest -- which works by redefining sys.stdout -- would fail:\n    if file is None:\n        file = sys.stdout\n\n    print(item, end=end, file=file)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprinting each item from an iterable yielding values to a file.", "response": "def pfprint_all(iterable, end='\\n', file=None):\n    \"\"\"Prints each item from an iterable.\n\n    :param iterable: An iterable yielding values to print\n    :param end: String to append to the end of printed output\n    :param file: File to which output is printed\n    :rtype: None\n\n    Example::\n\n        >>> @pointfree\n        ... def prefix_all(prefix, iterable):\n        ...     for item in iterable:\n        ...         yield \"%s%s\" % (prefix, item)\n\n        >>> fn = prefix_all(\"An item: \") >> pfprint_all\n\n        >>> fn([\"foo\", \"bar\", \"baz\"])\n        An item: foo\n        An item: bar\n        An item: baz\n\n    \"\"\"\n\n    for item in iterable:\n        pfprint(item, end=end, file=file)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __sig_from_func(self, func):\n\n        if isinstance(func, types.MethodType):\n            # A bound instance or class method.\n            argspec = getfullargspec(func.__func__)\n            self.pargl = argspec[0][1:]\n        else:\n            # A regular function, an unbound instance method, or a\n            # bound static method.\n            argspec = getfullargspec(func)\n            self.pargl = argspec[0][:]\n\n        if argspec[3] is not None:\n            def_offset = len(self.pargl) - len(argspec[3])\n            self.def_argv = dict((self.pargl[def_offset+i],argspec[3][i]) \\\n                                     for i in range(len(argspec[3])))\n        else:\n            self.def_argv = {}\n\n        self.var_pargs = argspec[1] is not None\n        self.var_kargs = argspec[2] is not None\n        self.kargl     = argspec[4]\n\n        # We need keyword-only arguments' default values too.\n        if argspec[5] is not None:\n            self.def_argv.update(argspec[5])", "response": "Extract function signature default arguments keyword - only\n        arguments and whether or not variable positional or keyword - only\n        arguments are allowed."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nextracting function signature from an existing partial instance.", "response": "def __sig_from_partial(self, inst):\n        \"\"\"Extract function signature from an existing partial instance.\"\"\"\n\n        self.pargl     = list(inst.pargl)\n        self.kargl     = list(inst.kargl)\n        self.def_argv  = inst.def_argv.copy()\n        self.var_pargs = inst.var_pargs\n        self.var_kargs = inst.var_kargs"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmake a new instance of the partial application wrapper based on an existing instance optionally overriding the original s wrapped function and optionally overriding the original s saved arguments.", "response": "def make_copy(klass, inst, func=None, argv=None, extra_argv=None, copy_sig=True):\n        \"\"\"Makes a new instance of the partial application wrapper based on\n        an existing instance, optionally overriding the original's wrapped\n        function and/or saved arguments.\n\n        :param inst: The partial instance we're copying\n        :param func: Override the original's wrapped function\n        :param argv: Override saved argument values\n        :param extra_argv: Override saved extra positional arguments\n        :param copy_sig: Copy original's signature?\n        :rtype: New partial wrapper instance\n\n        \"\"\"\n\n        dest            = klass(func or inst.func)\n        dest.argv       = (argv or inst.argv).copy()\n        dest.extra_argv = list(extra_argv if extra_argv else inst.extra_argv)\n\n        if copy_sig:\n            dest.__sig_from_partial(inst)\n\n        return dest"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __new_argv(self, *new_pargs, **new_kargs):\n\n        new_argv = self.argv.copy()\n        new_extra_argv = list(self.extra_argv)\n\n        for v in new_pargs:\n            arg_name = None\n            for name in self.pargl:\n                if not name in new_argv:\n                    arg_name = name\n                    break\n\n            if arg_name:\n                new_argv[arg_name] = v\n            elif self.var_pargs:\n                new_extra_argv.append(v)\n            else:\n                num_prev_pargs = len([name for name in self.pargl if name in self.argv])\n                raise TypeError(\"%s() takes exactly %d positional arguments (%d given)\" \\\n                                    % (self.__name__,\n                                       len(self.pargl),\n                                       num_prev_pargs + len(new_pargs)))\n\n        for k,v in new_kargs.items():\n            if not (self.var_kargs or (k in self.pargl) or (k in self.kargl)):\n                raise TypeError(\"%s() got an unexpected keyword argument '%s'\" \\\n                                    % (self.__name__, k))\n            new_argv[k] = v\n\n        return (new_argv, new_extra_argv)", "response": "Calculate new argv and extra_argv values resulting from adding\n        the specified positional and keyword arguments."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ignore_certain_metainf_files(filename):\n    ignore = (\"META-INF/manifest.mf\",\n              \"META-INF/*.sf\",\n              \"META-INF/*.rsa\",\n              \"META-INF/*.dsa\",\n              \"META-INF/ids.json\")\n\n    for glob in ignore:\n        # Explicitly match against all upper case to prevent the kind of\n        # runtime errors that lead to https://bugzil.la/1169574\n        if fnmatch.fnmatchcase(filename.upper(), glob.upper()):\n            return True\n    return False", "response": "This function is used to prevent multiple signatures in XPI signing on a given JAR file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef file_key(filename):\n    '''Sort keys for xpi files\n\n    The filenames in a manifest are ordered so that files not in a\n    directory come before files in any directory, ordered\n    alphabetically but ignoring case, with a few exceptions\n    (install.rdf, chrome.manifest, icon.png and icon64.png come at the\n    beginning; licenses come at the end).\n\n    This order does not appear to affect anything in any way, but it\n    looks nicer.\n    '''\n    prio = 4\n    if filename == 'install.rdf':\n        prio = 1\n    elif filename in [\"chrome.manifest\", \"icon.png\", \"icon64.png\"]:\n        prio = 2\n    elif filename in [\"MPL\", \"GPL\", \"LGPL\", \"COPYING\",\n                      \"LICENSE\", \"license.txt\"]:\n        prio = 5\n    return (prio, os.path.split(filename.lower()))", "response": "Sort keys for xpi files in a\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef vlq2int(data):\n    # The VLQ is little-endian.\n    byte = ord(data.read(1)) \n    value = byte & 0x7F\n    shift = 1\n    while byte & 0x80 != 0:\n        byte = ord(data.read(1))\n        value = ((byte & 0x7F) << shift * 7) | value\n        shift += 1\n    return value", "response": "Read one VLQ - encoded integer value from an input data stream."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read_table(data, fields):\n    def read_field(field_name):\n        data.read(2)\n        table[field_name] = vlq2int(data) / 2\n        # Discard unknown fields.\n        if field_name == 'unknown':\n            del table[field_name]\n\n    table = {}\n    for field in fields:\n        read_field(field)\n    return table", "response": "Read a table structure from data."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses the user data header portion of the replay.", "response": "def _parse_header(self):\n        \"\"\"Parse the user data header portion of the replay.\"\"\"\n        header = OrderedDict()\n        user_data_header = self.archive.header['user_data_header']['content']\n        if re.search(r'StarCraft II replay', user_data_header):\n            user_data_header = StringIO.StringIO(user_data_header)\n            user_data_header.seek(30) # Just skip the beginning.\n            header.update(read_table(user_data_header, ['release_flag',\n                                                        'major_version',\n                                                        'minor_version',\n                                                        'maintenance_version',\n                                                        'build_number',\n                                                        'unknown',\n                                                        'unknown',\n                                                        'duration']))\n\n            # Some post processing is required.\n            header['version'] = '%s.%s.%s.%s' % (header['major_version'],\n                                                 header['minor_version'],\n                                                 header['maintenance_version'],\n                                                 header['build_number'])\n            if not header['release_flag']:\n                header['version'] += ' (dev)'\n\n            # Duration is actually stored as 1/16th of a seconds. Go figure.\n            header['duration'] /= 16\n        else:\n            raise ValueError(\"The given file is not a StarCraft II replay.\")\n        return header"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntransforms duration into a human - readable form.", "response": "def get_duration(self, seconds):\n        \"\"\"Transform duration into a human-readable form.\"\"\"\n        duration = \"\"\n        minutes, seconds = divmod(seconds, 60)\n        if minutes >= 60:\n            hours, minutes = divmod(minutes, 60)\n            duration = \"%sh \" % hours\n        duration += \"%sm %ss\" % (minutes, seconds)\n        return duration"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprinting a summary of the game details.", "response": "def print_details(self):\n        \"\"\"Print a summary of the game details.\"\"\"\n        print 'Map      ', self.map\n        print 'Duration ', self.duration\n        print 'Version  ', self.version\n        print 'Team  Player       Race       Color'\n        print '-----------------------------------'\n        for player in self.players:\n            print '{team:<5} {name:12} {race:10} {color}'.format(**player)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef data_processing(self):\n        the_file_name = str(self.result_file)\n        the_file = open(the_file_name, 'r')\n\n        lines = the_file.readlines()\n\n        # We put all lines in an array and we put each cell of the line in a column.\n        lines_array = []\n        for line in lines:\n            line = line.split(',')  # Each time there is a tabulation, there is a new cell\n            lines_array.append(line)\n\n        labels_line = lines_array[0]\n        cell_labels_line = 0  # Iterator on each cell of the line labels_line.\n        flag = True  # Become FALSE when we find the word which separate data from wavelength values.\n\n        try:\n            while flag:  # While it is TRUE, so if the word doesn't match, it's an infinite loop,\n                if \"wave length (nm)\" in labels_line[cell_labels_line]:\n                    index = labels_line.index(labels_line[cell_labels_line])  # Find the index of the string searched.\n                    flag = False\n                else:\n                    cell_labels_line += 1\n        except IndexError:  # In case of an infinite loop.\n            raise sys.exit(\"Warning : There is no value named 'wavelength' in the file used to plot curves. \"\n                           \"So, I can't separate data to plot curves and data about tests linking with these curves.\")\n\n        self.information = []  # This array will contain the data displayed under the curves.\n        data_wavelength = []  # This array will contain the data to plot curves.\n        self.num_line = 0  # Iterator on each line of lines_array,\n        # The array containing data about information and wavelength.\n        for line in lines_array:\n            cell_line = 0  # Iterator on each cell of the line.\n            self.information.append([])\n            data_wavelength.append([])\n            while cell_line < len(line):\n                if cell_line < index:\n                    self.information[self.num_line].append(line[cell_line])\n                elif cell_line > index:\n                    data_wavelength[self.num_line].append(line[cell_line])\n                cell_line += 1\n            self.num_line += 1\n\n        # We transform wavelengths from strings to floats.\n        line_wavelength = 0  # Iterator on each line of data_wavelength\n        for row_data_wavelength in data_wavelength:\n            row_data_wavelength = [float(item.strip('\\n').strip('\\\"')) for item in row_data_wavelength]\n            data_wavelength[line_wavelength] = row_data_wavelength\n            line_wavelength += 1\n\n        self.wavelength = data_wavelength[0]  # The first line contains wavelength\n        self.data_wanted = data_wavelength[1:]  # The others contain data useful to plot curves.\n\n        the_file.close()", "response": "This function handles the data processing of the result file and stores the data in the good arrays."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndisplay the information of the current CPU CPU.", "response": "def display_the_graphic_connection(self):\n        \"\"\"\n        The following permits to attribute the function \"display_the_graphic\" to the slider.\n        Because, to make a connection, we can not have parameters for the function, but \"display_the_graphic\" has some.\n        \"\"\"\n        self.display_the_graphic(self.num_line, self.wavelength, self.data_wanted, self.information)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef hide_error_message(self):\n        self.ui.error_label.setScaledContents(False)  # Warning image hiden.\n        self.ui.error_text_label.hide()", "response": "This function hides the error message when all values are correct."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nquitting the current instance of the class.", "response": "def quit(self):\n        \"\"\"\n        This function quits PlanarRad, checking if PlanarRad is running before.\n        \"\"\"\n\n        \"\"\"\n        Nothing programmed for displaying a message box when the user clicks on the window cross in order to quit.\n        \"\"\"\n\n        if self.is_running == True:\n            warning_planarrad_running = QtGui.QMessageBox.warning(self.ui.quit, 'Warning !',\n                                                                  \"PlanarRad is running. Stop it before quit !\",\n                                                                  QtGui.QMessageBox.Ok)\n\n        else:\n            quit = QtGui.QMessageBox.question(self.ui.quit, 'Quit PlanarRad', \"Are you sure to quit ?\",\n                                              QtGui.QMessageBox.Yes,\n                                              QtGui.QMessageBox.No)\n            if quit == QtGui.QMessageBox.Yes:\n                QtGui.qApp.quit()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef open_log_file(self):\n        \"\"\"\n        TO DO.\n        \"\"\"\n        # webbrowser.open('https://marrabld.github.io/planarradpy/')\n        f = open(os.path.expanduser('~/.planarradpy/log/libplanarradpy.log'))\n        # self.uiLog.textEdit.setText(str(f.readlines()))\n        self.uiLog.textEdit.setPlainText(str(f.read()))\n        self.log_window.show()", "response": "Open the log file of PlanarRad."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nopening the documentation file.", "response": "def open_documentation(self):\n        \"\"\"\n        The following opens the documentation file.\n        \"\"\"\n        \"\"\"\n        TO DO.\n        \"\"\"\n        # webbrowser.open('https://marrabld.github.io/planarradpy/')\n\n        window = Window()\n        html = QtCore.QUrl.fromLocalFile(os.path.join(os.getcwd(), './docs/_build/html/index.html')) #open('./docs/_build/html/index.html').read()\n        #window.show()\n        window.view.load(html)\n        window.show()\n        window.exec_()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef click(self, event):\n        if event.button == 3:\n            if self.ui.tabWidget.currentIndex() == TabWidget.NORMAL_MODE:\n                self.pos = QtGui.QCursor().pos()\n                self.graphic_context_menu(self.pos)", "response": "This function intercepts the mouse s right click and its position."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef mouse_move(self, event):\n        if (self.ui.tabWidget.currentIndex() == TabWidget.NORMAL_MODE):\n            self.posX = event.xdata\n            self.posY = event.ydata\n\n            self.graphic_target(self.posX, self.posY)", "response": "Handles mouse move events."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef graphic_target(self, x, y):\n\n        if self.authorized_display == True:\n            try:\n                self.display_the_graphic(self.num_line, self.wavelength, self.data_wanted, self.information)\n                self.ui.mouse_coordinate.setText(\"(%0.3f, %0.3f)\" % (x, y))\n            except:\n                pass", "response": "Update the mouse coordinates."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef genesis_signing_lockset(genesis, privkey):\n    v = VoteBlock(0, 0, genesis.hash)\n    v.sign(privkey)\n    ls = LockSet(num_eligible_votes=1)\n    ls.add(v)\n    assert ls.has_quorum\n    return ls", "response": "This function creates a lockset that is a genesis_signing_lockset with one vote by any validator."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sign(self, privkey):\n        if self.v:\n            raise InvalidSignature(\"already signed\")\n\n        if privkey in (0, '', '\\x00' * 32):\n            raise InvalidSignature(\"Zero privkey cannot sign\")\n        rawhash = sha3(rlp.encode(self, self.__class__.exclude(['v', 'r', 's'])))\n\n        if len(privkey) == 64:\n            privkey = encode_privkey(privkey, 'bin')\n\n        pk = PrivateKey(privkey, raw=True)\n        signature = pk.ecdsa_recoverable_serialize(pk.ecdsa_sign_recoverable(rawhash, raw=True))\n\n        signature = signature[0] + chr(signature[1])\n\n        self.v = ord(signature[64]) + 27\n        self.r = big_endian_to_int(signature[0:32])\n        self.s = big_endian_to_int(signature[32:64])\n\n        self._sender = None\n        return self", "response": "Sign this object with a private key"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef hr(self):\n        assert len(self), 'no votes, can not determine height'\n        h = set([(v.height, v.round) for v in self.votes])\n        assert len(h) == 1, len(h)\n        return h.pop()", "response": "compute the height of the last entry in the set"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef has_quorum(self):\n        assert self.is_valid\n        bhs = self.blockhashes()\n        if bhs and bhs[0][1] > 2 / 3. * self.num_eligible_votes:\n            return bhs[0][0]", "response": "Returns True if there is a quorum for a given entry."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef has_noquorum(self):\n        assert self.is_valid\n        bhs = self.blockhashes()\n        if not bhs or bhs[0][1] <= 1 / 3. * self.num_eligible_votes:\n            assert not self.has_quorum_possible\n            return True", "response": "Returns True if there are no possible no - quorum possible cluster entries for the given cluster entry."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts the transient block to a Block object.", "response": "def to_block(self, env, parent=None):\n        \"\"\"Convert the transient block to a :class:`ethereum.blocks.Block`\"\"\"\n        return Block(self.header, self.transaction_list, self.uncles, env=env, parent=parent)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef validate_votes(self, validators_H, validators_prevH):\n        \"set of validators may change between heights\"\n        assert self.sender\n\n        def check(lockset, validators):\n            if not lockset.num_eligible_votes == len(validators):\n                raise InvalidProposalError('lockset num_eligible_votes mismatch')\n            for v in lockset:\n                if v.sender not in validators:\n                    raise InvalidProposalError('invalid signer')\n        if self.round_lockset:\n            check(self.round_lockset, validators_H)\n        check(self.signing_lockset, validators_prevH)\n\n        return True", "response": "set of validators may change between heights"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef validate_votes(self, validators_H):\n        \"set of validators may change between heights\"\n        assert self.sender\n        if not self.round_lockset.num_eligible_votes == len(validators_H):\n            raise InvalidProposalError('round_lockset num_eligible_votes mismatch')\n        for v in self.round_lockset:\n            if v.sender not in validators_H:\n                raise InvalidProposalError('invalid signer')", "response": "set of validators may change between heights"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef transfer(ctx, _to='address', _value='uint256', returns=STATUS):\n        log.DEV('In Fungible.transfer')\n        if ctx.accounts[ctx.msg_sender] >= _value:\n            ctx.accounts[ctx.msg_sender] -= _value\n            ctx.accounts[_to] += _value\n            ctx.Transfer(ctx.msg_sender, _to, _value)\n            return OK\n        else:\n            return INSUFFICIENTFUNDS", "response": "Standardized Contract API for Transfer"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef transferFrom(ctx, _from='address', _to='address', _value='uint256', returns=STATUS):\n        auth = ctx.allowances[_from][ctx.msg_sender]\n        if ctx.accounts[_from] >= _value and auth >= _value:\n            ctx.allowances[_from][ctx.msg_sender] -= _value\n            ctx.accounts[_from] -= _value\n            ctx.accounts[_to] += _value\n            ctx.Transfer(_from, _to, _value)\n            return OK\n        else:\n            return INSUFFICIENTFUNDS", "response": "Standardized Contract API for transferFrom"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef approve(ctx, _spender='address', _value='uint256', returns=STATUS):\n        ctx.allowances[ctx.msg_sender][_spender] += _value\n        ctx.Approval(ctx.msg_sender, _spender, _value)\n        return OK", "response": "Standardized Contract API approve"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef issue_funds(ctx, amount='uint256', rtgs_hash='bytes32', returns=STATUS):\n        \"In the IOU fungible the supply is set by Issuer, who issue funds.\"\n        # allocate new issue as result of a new cash entry\n        ctx.accounts[ctx.msg_sender] += amount\n        ctx.issued_amounts[ctx.msg_sender] += amount\n        # Store hash(rtgs)\n        ctx.Issuance(ctx.msg_sender, rtgs_hash, amount)\n        return OK", "response": "In the IOU fungible the supply is set by Issuer who issue funds."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef last_lock(self):\n        \"highest lock on height\"\n        rs = list(self.rounds)\n        assert len(rs) < 2 or rs[0] > rs[1]  # FIXME REMOVE\n        for r in self.rounds:  # is sorted highest to lowest\n            if self.rounds[r].lock is not None:\n                return self.rounds[r].lock", "response": "highest lock on height"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef last_valid_lockset(self):\n        \"highest valid lockset on height\"\n        for r in self.rounds:\n            ls = self.rounds[r].lockset\n            if ls.is_valid:\n                return ls\n        return None", "response": "highest valid lockset on height"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef request(self):\n        missing = self.missing\n        self.cm.log('sync.request', missing=len(missing), requested=len(self.requested),\n                    received=len(self.received))\n        if self.requested:\n            self.cm.log('waiting for requested')\n            return\n        if len(self.received) + self.max_getproposals_count >= self.max_queued:\n            self.cm.log('queue is full')\n            return\n        if not missing:\n            self.cm.log('insync')\n            return\n        if self.last_active_protocol is None:  # FIXME, check if it is active\n            self.cm.log('no active protocol', last_active_protocol=self.last_active_protocol)\n            return\n        self.cm.log('collecting')\n        blocknumbers = []\n        for h in missing:\n            if h not in self.received and h not in self.requested:\n                blocknumbers.append(h)\n                self.requested.add(h)\n                if len(blocknumbers) == self.max_getproposals_count:\n                    break\n        self.cm.log('collected', num=len(blocknumbers))\n        if not blocknumbers:\n            return\n        self.cm.log('requesting', num=len(blocknumbers),\n                    requesting_range=(blocknumbers[0], blocknumbers[-1]))\n        self.last_active_protocol.send_getblockproposals(*blocknumbers)\n        # setup alarm\n        self.cm.chainservice.setup_alarm(self.timeout, self.on_alarm, blocknumbers)", "response": "request the next set of locksets"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef on_proposal(self, proposal, proto):\n        \"called to inform about synced peers\"\n        assert isinstance(proto, HDCProtocol)\n        assert isinstance(proposal, Proposal)\n        if proposal.height >= self.cm.height:\n            assert proposal.lockset.is_valid\n            self.last_active_protocol = proto", "response": "called to inform about synced peers"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a wait_next_block function that will wait for a new block to appear.", "response": "def wait_next_block_factory(app, timeout=None):\n    \"\"\"Creates a `wait_next_block` function, that\n    will wait `timeout` seconds (`None` = indefinitely)\n    for a new block to appear.\n\n    :param app: the app-instance the function should work for\n    :param timeout: timeout in seconds\n    \"\"\"\n\n    chain = app.services.chain\n\n    # setup new block callbacks and events\n    new_block_evt = gevent.event.Event()\n\n    def _on_new_block(app):\n        log.DEV('new block mined')\n        new_block_evt.set()\n    chain.on_new_head_cbs.append(_on_new_block)\n\n    def wait_next_block():\n        bn = chain.chain.head.number\n        chain.consensus_manager.log('waiting for new block', block=bn)\n        new_block_evt.wait(timeout)\n        new_block_evt.clear()\n        if chain.chain.head.number > bn:\n            chain.consensus_manager.log('new block event', block=chain.chain.head.number)\n        elif chain.chain.head.number == bn:\n            chain.consensus_manager.log('wait_next_block timed out', block=bn)\n\n    return wait_next_block"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef mk_privkeys(num):\n    \"make privkeys that support coloring, see utils.cstr\"\n    privkeys = []\n    assert num <= num_colors\n    for i in range(num):\n        j = 0\n        while True:\n            k = sha3(str(j))\n            a = privtoaddr(k)\n            an = big_endian_to_int(a)\n            if an % num_colors == i:\n                break\n            j += 1\n        privkeys.append(k)\n    return privkeys", "response": "make privkeys that support coloring see utils. cstr"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef delay(self, sender, receiver, packet, add_delay=0):\n        bw = min(sender.ul_bandwidth, receiver.dl_bandwidth)\n        delay = sender.base_latency + receiver.base_latency\n        delay += len(packet) / bw\n        delay += add_delay\n        return delay", "response": "Calculate the delay between two packets."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndelivering on edge of timeout_window", "response": "def deliver(self, sender, receiver, packet):\n        \"deliver on edge of timeout_window\"\n        to = ConsensusManager.round_timeout\n        assert to > 0\n        print \"in slow transport deliver\"\n        super(SlowTransport, self).deliver(sender, receiver, packet, add_delay=to)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nencode args for method method_id | data", "response": "def abi_encode_args(method, args):\n    \"encode args for method: method_id|data\"\n    assert issubclass(method.im_class, NativeABIContract), method.im_class\n    m_abi = method.im_class._get_method_abi(method)\n    return zpad(encode_int(m_abi['id']), 4) + abi.encode_abi(m_abi['arg_types'], args)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating an object which acts as a proxy for the contract on the chain", "response": "def chain_nac_proxy(chain, sender, contract_address, value=0):\n    \"create an object which acts as a proxy for the contract on the chain\"\n    klass = registry[contract_address].im_self\n    assert issubclass(klass, NativeABIContract)\n\n    def mk_method(method):\n        def m(s, *args):\n            data = abi_encode_args(method, args)\n            block = chain.head_candidate\n            output = test_call(block, sender, contract_address, data)\n            if output is not None:\n                return abi_decode_return_vals(method, output)\n        return m\n\n    class cproxy(object):\n        pass\n    for m in klass._abi_methods():\n        setattr(cproxy, m.__func__.func_name, mk_method(m))\n\n    return cproxy()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning class _on_msg_unsafe use x. im_self to get class", "response": "def address_to_native_contract_class(self, address):\n        \"returns class._on_msg_unsafe, use x.im_self to get class\"\n        assert isinstance(address, bytes) and len(address) == 20\n        assert self.is_instance_address(address)\n        nca = self.native_contract_address_prefix + address[-4:]\n        return self.native_contracts[nca]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef validators_from_config(validators):\n    result = []\n    for validator in validators:\n        if len(validator) == 40:\n            validator = validator.decode('hex')\n        result.append(validator)\n    return result", "response": "Consolidate ( potentially hex - encoded ) list of validators\n    into list of binary address representations."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update(self, data):\n        \"returns True if unknown\"\n        if data not in self.filter:\n            self.filter.append(data)\n            if len(self.filter) > self.max_items:\n                self.filter.pop(0)\n            return True\n        else:\n            self.filter.append(self.filter.pop(0))\n            return False", "response": "returns True if unknown"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_transaction(self, tx, origin=None, force_broadcast=False):\n        self.consensus_manager.log(\n            'add_transaction', blk=self.chain.head_candidate, lock=self.proposal_lock)\n        log.debug('add_transaction', lock=self.proposal_lock)\n        block = self.proposal_lock.block\n        self.proposal_lock.acquire()\n        self.consensus_manager.log('add_transaction acquired lock', lock=self.proposal_lock)\n        assert not hasattr(self.chain.head_candidate, 'should_be_locked')\n        success = super(ChainService, self).add_transaction(tx, origin, force_broadcast)\n        if self.proposal_lock.is_locked():  # can be unlock if we are at a new block\n            self.proposal_lock.release(if_block=block)\n        log.debug('added transaction', num_txs=self.chain.head_candidate.num_transactions())\n        return success", "response": "Add a transaction to the chain."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef on_receive_transactions(self, proto, transactions):\n        \"receives rlp.decoded serialized\"\n        log.debug('----------------------------------')\n        log.debug('remote_transactions_received', count=len(transactions), remote_id=proto)\n\n        def _add_txs():\n            for tx in transactions:\n                self.add_transaction(tx, origin=proto)\n        gevent.spawn(_add_txs)", "response": "receives rlp. decoded serialized"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef img_from_vgg(x):\n    '''Decondition an image from the VGG16 model.'''\n    x = x.transpose((1, 2, 0))\n    x[:, :, 0] += 103.939\n    x[:, :, 1] += 116.779\n    x[:, :, 2] += 123.68\n    x = x[:,:,::-1]  # to RGB\n    return x", "response": "Decondition an image from the VGG16 model."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef img_to_vgg(x):\n    '''Condition an image for use with the VGG16 model.'''\n    x = x[:,:,::-1]  # to BGR\n    x[:, :, 0] -= 103.939\n    x[:, :, 1] -= 116.779\n    x[:, :, 2] -= 123.68\n    x = x.transpose((2, 0, 1))\n    return x", "response": "Condition an image for use with the VGG16 model."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a function for the response of a layer.", "response": "def get_f_layer(self, layer_name):\n        '''Create a function for the response of a layer.'''\n        inputs = [self.net_input]\n        if self.learning_phase is not None:\n            inputs.append(K.learning_phase())\n        return K.function(inputs, [self.get_layer_output(layer_name)])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting symbolic output of a layer.", "response": "def get_layer_output(self, name):\n        '''Get symbolic output of a layer.'''\n        if not name in self._f_layer_outputs:\n            layer = self.net.get_layer(name)\n            self._f_layer_outputs[name] = layer.output\n        return self._f_layer_outputs[name]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_features(self, x, layers):\n        '''Evaluate layer outputs for `x`'''\n        if not layers:\n            return None\n        inputs = [self.net.input]\n        if self.learning_phase is not None:\n            inputs.append(self.learning_phase)\n        f = K.function(inputs, [self.get_layer_output(layer_name) for layer_name in layers])\n        feature_outputs = f([x])\n        features = dict(zip(layers, feature_outputs))\n        return features", "response": "Evaluate layer outputs for x"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_key_file(path):\n    iv = \"{}{}\".format(os.urandom(32), time.time())\n    new_key = generate_key(ensure_bytes(iv))\n    with open(path, \"wb\") as f:\n        f.write(base64.b64encode(new_key))\n    os.chmod(path, 0o400)", "response": "Creates a new encryption key in the path provided and sets the filePermissions to 0o400."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cleanup(self):\n        threads = []\n        for i, table in enumerate(filter(lambda x: self.mload.exists(x), self.tables)):\n            log.info(\"BulkLoad\", \"Dropping table '{}'...\".format(table))\n            t = threading.Thread(target=self.mload.drop_table, args=(table,))\n            threads.append(t)\n            t.start()\n        for t in threads:\n            t.join()", "response": "Drops any existing work tables as returned by the mload. tables method."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef finish(self):\n        if self.finished:\n            return self.exit_code\n        checkpoint_status = self.checkpoint()\n        self.exit_code = self._exit_code()\n        if self.exit_code != 0:\n            raise TeradataPTError(\"BulkLoad job finished with return code '{}'\".format(self.exit_code))\n        # TODO(chris): should this happen every time?\n        if self.applied_count > 0:\n            self._end_acquisition()\n            self._apply_rows()\n        self.exit_code = self._exit_code()\n        if self.exit_code != 0:\n            raise TeradataPTError(\"BulkLoad job finished with return code '{}'\".format(self.exit_code))\n        self.finished = True\n        return self.exit_code", "response": "Finishes the load job. Called automatically when the connection closes."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_file(self, filename, table=None, delimiter='|', null='NULL',\n            panic=True, quotechar='\"', parse_dates=False):\n        \"\"\"\n        Load from a file into the target table, handling each step of the\n        load process.\n\n        Can load from text files, and properly formatted giraffez archive\n        files. In both cases, if Gzip compression is detected the file will be\n        decompressed while reading and handled appropriately. The encoding is\n        determined automatically by the contents of the file.\n\n        It is not necessary to set the columns in use prior to loading from a file.\n        In the case of a text file, the header is used to determine column names\n        and their order. Valid delimiters include '|', ',', and '\\\\t' (tab). When\n        loading an archive file, the column information is decoded alongside the data.\n\n        :param str filename: The location of the file to be loaded\n        :param str table: The name of the target table, if it was not specified\n            to the constructor for the isntance\n        :param str null: The string that indicates a null value in the rows being\n            inserted from a file. Defaults to 'NULL'\n        :param str delimiter: When loading a file, indicates that fields are\n            separated by this delimiter. Defaults to :code:`None`, which causes the\n            delimiter to be determined from the header of the file. In most\n            cases, this behavior is sufficient\n        :param str quotechar: The character used to quote fields containing special characters,\n            like the delimiter.\n        :param bool panic: If :code:`True`, when an error is encountered it will be\n            raised. Otherwise, the error will be logged and :code:`self.error_count`\n            is incremented.\n        :return: The output of the call to\n            :meth:`~giraffez.load.TeradataBulkLoad.finish`\n        :raises `giraffez.errors.GiraffeError`: if table was not set and :code:`table`\n            is :code:`None`, or if a Teradata error ocurred while retrieving table info.\n        :raises `giraffez.errors.GiraffeEncodeError`: if :code:`panic` is :code:`True` and there\n            are format errors in the row values.\n        \"\"\"\n        if not self.table:\n            if not table:\n                raise GiraffeError(\"Table must be set or specified to load a file.\")\n            self.table = table\n        if not isinstance(null, basestring):\n            raise GiraffeError(\"Expected 'null' to be str, received {}\".format(type(null)))\n        with Reader(filename, delimiter=delimiter, quotechar=quotechar) as f:\n            if not isinstance(f.delimiter, basestring):\n                raise GiraffeError(\"Expected 'delimiter' to be str, received {}\".format(type(delimiter)))\n            self.columns = f.header\n            if isinstance(f, ArchiveFileReader):\n                self.mload.set_encoding(ROW_ENCODING_RAW)\n                self.preprocessor = lambda s: s\n            if parse_dates:\n                self.preprocessor = DateHandler(self.columns)\n            self._initiate()\n            self.mload.set_null(null)\n            self.mload.set_delimiter(delimiter)\n            i = 0\n            for i, line in enumerate(f, 1):\n                self.put(line, panic=panic)\n                if i % self.checkpoint_interval == 1:\n                    log.info(\"\\rBulkLoad\", \"Processed {} rows\".format(i), console=True)\n                    checkpoint_status = self.checkpoint()\n                    self.exit_code = self._exit_code()\n                    if self.exit_code != 0:\n                        return self.exit_code\n            log.info(\"\\rBulkLoad\", \"Processed {} rows\".format(i))\n            return self.finish()", "response": "Load a new entry from a file into the target table."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef put(self, items, panic=True):\n        if not self.initiated:\n            self._initiate()\n        try:\n            row_status = self.mload.put_row(self.preprocessor(items))\n            self.applied_count += 1\n        except (TeradataPTError, EncoderError) as error:\n            self.error_count += 1\n            if panic:\n                raise error\n            log.info(\"BulkLoad\", error)", "response": "Load a single row into the target table."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef release(self):\n        if self.table is None:\n            raise GiraffeError(\"Cannot release. Target table has not been set.\")\n        log.info(\"BulkLoad\", \"Attempting release for table {}\".format(self.table))\n        self.mload.release(self.table)", "response": "Release the current object s mload table."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef tables(self):\n        if self.table is None:\n            raise GiraffeError(\"Target table has not been set.\")\n        return [\n            \"{}_wt\".format(self.table),\n            \"{}_log\".format(self.table),\n            \"{}_e1\".format(self.table),\n            \"{}_e2\".format(self.table),\n        ]", "response": "Returns a list of four tables each the name of the target table containing the added suffixes _wt _log _e1 and _e2."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fix_compile(remove_flags):\n    import distutils.ccompiler\n\n    def _fix_compile(self, sources, output_dir=None, macros=None, include_dirs=None, debug=0,\n            extra_preargs=None, extra_postargs=None, depends=None):\n        for flag in remove_flags:\n            if flag in self.compiler_so:\n                self.compiler_so.remove(flag)\n        macros, objects, extra_postargs, pp_opts, build = self._setup_compile(output_dir, macros,\n                include_dirs, sources, depends, extra_postargs)\n        cc_args = self._get_cc_args(pp_opts, debug, extra_preargs)\n        for obj in objects:\n            try:\n                src, ext = build[obj]\n            except KeyError:\n                continue\n            self._compile(obj, src, ext, cc_args, extra_postargs, pp_opts)\n        return objects\n\n    distutils.ccompiler.CCompiler.compile = _fix_compile", "response": "Monkey - patch compiler to allow for removal of default compiler flags."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find_teradata_home():\n    if platform.system() == 'Windows':\n        # The default installation path for Windows is split between the\n        # Windows directories for 32-bit/64-bit applications.  It is\n        # worth noting that Teradata archiecture installed should match\n        # the architecture of the Python architecture being used (i.e.\n        # TTU 32-bit is required /w Python 32-bit and TTU 64-bit is\n        # required for Python 64-bit).\n        if is_64bit():\n            return latest_teradata_version(\"C:/Program Files/Teradata/Client\")\n        else:\n            return latest_teradata_version(\"C:/Program Files (x86)/Teradata/Client\")\n    elif platform.system() == 'Linux':\n        return latest_teradata_version(\"/opt/teradata/client\")\n    elif platform.system() == 'Darwin':\n        return latest_teradata_version(\"/Library/Application Support/teradata/client\")\n    else:\n        # In the case nothing is found, the default for Linux is\n        # attempted as a last effort to find the correct install\n        # directory.\n        return latest_teradata_version(\"/opt/teradata/client\")", "response": "Finds the Teradata installation directory with the default set for the current platform."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nretrieve the decrypted value of a key in a giraffez configuration file.", "response": "def get(self, key):\n        \"\"\"\n        Retrieve the decrypted value of a key in a giraffez\n        configuration file.\n\n        :param str key: The key used to lookup the encrypted value\n        \"\"\"\n        if not key.startswith(\"secure.\") and not key.startswith(\"connections.\"):\n            key = \"secure.{0}\".format(key)\n        value = self.config.get_value(key)\n        if not isinstance(value, basestring):\n            value = None\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting a decrypted value by key in a giraffez configuration file.", "response": "def set(self, key, value):\n        \"\"\"\n        Set a decrypted value by key in a giraffez configuration file.\n\n        :param str key: The key used to lookup the encrypted value\n        :param value: Value to set at the given key, can be any value that is\n            YAML serializeable.\n        \"\"\"\n        if not key.startswith(\"secure.\"):\n            key = \"secure.{0}\".format(key)\n        self.config.set_value(key, value)\n        self.config.write()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndisplays results in table format", "response": "def do_table(self, line):\n        \"\"\"Display results in table format\"\"\"\n        if len(line) > 0:\n            if line.strip().lower() == \"on\":\n                log.write(\"Table ON\")\n                self.table_output = True\n                return\n            elif line.strip().lower() == \"off\":\n                log.write(\"Table OFF\")\n                self.table_output = False\n                return\n        log.write(\"Table output: {}\".format(\"ON\" if self.table_output else \"OFF\"))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the current encoder output as a dictionary.", "response": "def to_dict(self):\n        \"\"\"\n        Sets the current encoder output to Python `dict` and returns\n        the cursor.  This makes it possible to set the output encoding\n        and iterate over the results:\n\n        .. code-block:: python\n\n            with giraffez.Cmd() as cmd:\n                for row in cmd.execute(query).to_dict():\n                    print(row)\n\n        Or can be passed as a parameter to an object that consumes an iterator:\n\n        .. code-block:: python\n\n            result = cmd.execute(query)\n            list(result.to_dict())\n        \"\"\"\n        self.conn.set_encoding(ROW_ENCODING_DICT)\n        self.processor = lambda x, y: y\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the current encoder output to list format and return the cursor.", "response": "def to_list(self):\n        \"\"\"\n        Set the current encoder output to :class:`giraffez.Row` objects\n        and returns the cursor.  This is the default value so it is not\n        necessary to select this unless the encoder settings have been\n        changed already.\n        \"\"\"\n        self.conn.set_encoding(ROW_ENCODING_LIST)\n        self.processor = lambda x, y: Row(x, y)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef execute(self, command, coerce_floats=True, parse_dates=False, header=False, sanitize=True,\n            silent=False, panic=None,  multi_statement=False, prepare_only=False):\n        \"\"\"\n        Execute commands using CLIv2.\n\n        :param str command: The SQL command to be executed\n        :param bool coerce_floats: Coerce Teradata decimal types into Python floats\n        :param bool parse_dates: Parses Teradata datetime types into Python datetimes\n        :param bool header: Include row header\n        :param bool sanitize: Whether or not to call :func:`~giraffez.sql.prepare_statement`\n            on the command\n        :param bool silent: Silence console logging (within this function only)\n        :param bool panic: If :code:`True`, when an error is encountered it will be\n            raised.\n        :param bool multi_statement: Execute in multi-statement mode\n        :param bool prepare_only: Only prepare the command (no results)\n        :return: a cursor over the results of each statement in the command\n        :rtype: :class:`~giraffez.cmd.Cursor`\n        :raises `giraffez.TeradataError`: if the query is invalid\n        :raises `giraffez.errors.GiraffeError`: if the return data could not be decoded\n        \"\"\"\n        if panic is None:\n            panic = self.panic\n        self.options(\"panic\", panic)\n        self.options(\"multi-statement mode\", multi_statement, 3)\n        if isfile(command):\n            self.options(\"file\", command, 2)\n            with open(command, 'r') as f:\n                command = f.read()\n        else:\n            if log.level >= VERBOSE:\n                self.options(\"query\", command, 2)\n            else:\n                self.options(\"query\", truncate(command), 2)\n        if not silent and not self.silent:\n            log.info(\"Command\", \"Executing ...\")\n            log.info(self.options)\n        if sanitize:\n            command = prepare_statement(command) # accounts for comments and newlines\n            log.debug(\"Debug[2]\", \"Command (sanitized): {!r}\".format(command))\n        self.cmd.set_encoding(ENCODER_SETTINGS_DEFAULT)\n        return Cursor(self.cmd, command, multi_statement=multi_statement, header=header,\n            prepare_only=prepare_only, coerce_floats=coerce_floats, parse_dates=parse_dates,\n            panic=panic)", "response": "Executes a command and returns a cursor over the results of each statement."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if the object with the given name exists in the database.", "response": "def exists(self, object_name, silent=False):\n        \"\"\"\n        Check that object (table or view) :code:`object_name` exists, by executing a :code:`show table object_name` query, \n        followed by a :code:`show view object_name` query if :code:`object_name` is not a table.\n\n        :param str object_name: The name of the object to check for existence.\n        :param bool silent: Silence console logging (within this function only)\n        :return: :code:`True` if the object exists, :code:`False` otherwise.\n        :rtype: bool\n        \"\"\"\n        try:\n            self.execute(\"show table {}\".format(object_name), silent=silent)\n            return True\n        except TeradataError as error:\n            if error.code != TD_ERROR_OBJECT_NOT_TABLE:\n                return False\n        try:\n            self.execute(\"show view {}\".format(object_name), silent=silent)\n            return True\n        except TeradataError as error:\n            if error.code not in [TD_ERROR_OBJECT_NOT_VIEW, TD_ERROR_OBJECT_NOT_EXIST]:\n                    return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fetch_columns(self, table_name, silent=False):\n        return self.execute(\"select top 1 * from {}\".format(table_name), silent=silent, prepare_only=True).columns", "response": "Fetch the columns of the table_name by executing a select top 1 * from table_name query."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef insert(self, table_name, rows, fields=None, delimiter=None, null='NULL', parse_dates=False, quotechar='\"'):\n        if not isfile(rows):\n            return self._insert(table_name, rows, fields, parse_dates)\n        with Reader(rows, delimiter=delimiter, quotechar=quotechar) as f:\n            preprocessor = null_handler(null)\n            rows = (preprocessor(l) for l in f)\n            if isinstance(f, CSVReader):\n                self.options(\"delimiter\", unescape_string(f.reader.dialect.delimiter), 1)\n                self.options(\"quote char\", f.reader.dialect.quotechar, 2)\n            elif isinstance(f, JSONReader):\n                self.options(\"encoding\", \"json\", 1)\n            return self._insert(table_name, rows, f.header, parse_dates)", "response": "Load a text file into the specified table or Insert a list of rows into the specified table."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef connections(self):\n        if \"connections\" not in self.settings:\n            raise ConfigurationError(\"Could not retrieve connections from config file '{}'.\".format(self._config_file))\n        return self.settings.get(\"connections\")", "response": "Returns a dictionary of connections from the configuration settings."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_connection(self, dsn=None):\n        if dsn is None:\n            dsn = self.connections.get(\"default\", None)\n            if dsn is None:\n                raise ConfigurationError(\"No default DSN set\")\n        connection = self.connections.get(dsn, None)\n        if connection is None:\n            raise ConfigurationError(\"DSN '{}' does not exist\".format(dsn))\n        connection = self.decrypt(connection.copy())\n        if connection.get('lock', 0) > 1:\n            raise ConnectionLock(dsn)\n        connection['name'] = dsn\n        return connection", "response": "Retrieve a connection by the given DSN or the default connection."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_value(self, key, default={}, nested=True, decrypt=True):\n        key = key.lstrip()\n        if key.endswith(\".\"):\n            key = key[:-1]\n        if nested:\n            path = key.split(\".\")\n            curr = self.settings\n            for p in path[:-1]:\n                curr = curr.get(p, {})\n            try:\n                value = curr[path[-1]]\n            except KeyError:\n                return default\n            value = self.decrypt(value, path)\n            return value\n        else:\n            return self.settings.get(key, default)", "response": "Retrieves a value from the configuration based on its key."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef list_value(self, decrypt=False):\n        if decrypt:\n            settings = self.decrypt(self.settings)\n        else:\n            settings = self.settings\n        return yaml.dump(settings, default_flow_style=False)", "response": "Return the contents of the configuration file as a dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef lock_connection(cls, conf, dsn, key=None):\n        with Config(conf, \"w\", key) as c:\n            connection = c.get_connection(dsn)\n            if not connection:\n                raise ConfigurationError(\"Unable to lock connection\")\n            if dsn is None:\n                dsn = c.settings[\"connections\"][\"default\"]\n            value = \"connections.{}.lock\".format(dsn)\n            lock = c.get_value(\"connections.{}.lock\".format(dsn), default=0)\n            if lock >= 2:\n                raise ConnectionLock(dsn)\n            lock += 1\n            c.set_value(\"connections.{}.lock\".format(dsn), lock)\n            c.write()", "response": "A class method to lock a connection in the specified configuration file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_value(self, key, value):\n        if key.endswith(\".\"):\n            key = key[:-1]\n        path = key.split(\".\")\n        curr = self.settings\n        for p in path[:-1]:\n            if p not in curr:\n                curr[p] = {}\n            curr = curr[p]\n        if not isinstance(curr, dict):\n            raise ConfigurationError(\"Cannot set nested key '{}' in configuration value '{}' (destination is not a dictionary).\".format(path[-1], key))\n        value = self.encrypt(value, path)\n        if value in {'true', 'True'}:\n            value = True\n        if value in {'false', 'False'}:\n            value = False\n        curr[path[-1]] = value", "response": "Set a value within the configuration based on its key."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving a value at the given key and any nested values in the configuration.", "response": "def unset_value(self, key):\n        \"\"\"\n        Remove a value at the given key -- and any nested values --\n        from the configuration.\n        *Note*: In order to write changes to the file, ensure that\n        :meth:`~giraffez.config.Config.write` is called prior to exit.\n\n        :param str key: A path to the value destination, with nested levels joined by '.'\n        :raises `giraffez.errors.ConfigurationError`: if the key specifies an invalid path, or does not exist\n        \"\"\"\n        if key.endswith(\".\"):\n            key = key[:-1]\n        path = key.split(\".\")\n        curr = self.settings\n        for p in path[:-1]:\n            if p not in curr:\n                raise ConfigurationError(\"Cannot unset '{}', nested key '{}' does not exist.\".format(key, p))\n            curr = curr[p]\n        if not isinstance(curr, dict):\n            raise ConfigurationError(\"Cannot unset nested key '{}' in configuration value '{}'.\".format(path[-1], key))\n        if path[-1] not in curr:\n            raise ConfigurationError(\"Cannot unset '{}', nested key '{}' does not exist.\".format(key, path[-1]))\n        del curr[path[-1]]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef write(self, settings=None):\n        if \"r\" in self.mode:\n            raise ConfigReadOnly(\"Cannot write Config while in 'r' mode\")\n        try:\n            if settings:\n                self.settings = settings\n            with open(self._config_file, \"w\") as f:\n                f.write(repr(self))\n                return repr(self)\n        except OSError:\n            return None", "response": "Writes the current configuration to the file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef write_default(self, conf=None):\n        if conf is None:\n            conf = home_file(\".girafferc\")\n        contents = yaml.dump(default_config, default_flow_style=False)\n        with open(conf, \"w\") as f:\n            f.write(contents)\n        os.chmod(conf, 0o600)\n        return contents", "response": "A class method to write a default configuration file structure to a file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get(self, column_name):\n        column_name = column_name.lower()\n        for c in self.columns:\n            if c.name == column_name:\n                return c\n        return None", "response": "Retrieves a column from the list with name value column_name"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_filter(self, names=None):\n        _names = []\n        if names:\n            for name in names:\n                _safe_name = safe_name(name)\n                if _safe_name not in self._column_map:\n                    raise GiraffeTypeError(\"Column '{}' does not exist\".format(name))\n                if _safe_name in _names:\n                    continue\n                _names.append(_safe_name)\n        self._filtered_columns = _names", "response": "Sets the names of columns to be used when iterating through the list of names for the current page."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef serialize(self):\n        data = b\"\"\n        for column in self:\n            row = struct.pack(\"5H\", column.type, column.length, column.precision, column.scale,\n                len(column.name))\n            row += ensure_bytes(column.name)\n            data += row\n        return struct.pack(\"H\", len(data)) + data", "response": "Serializes the columns into the giraffez archive header and header."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef deserialize(cls, data):\n        column_list = cls()\n        while data:\n            tup, data = data[:10], data[10:]\n            column_type, length, prec, scale, title_len = struct.unpack(\"5H\", tup)\n            title, data = data[:title_len], data[title_len:]\n            try:\n                column_list.append((title, column_type, length, prec, scale))\n            except GiraffeTypeError as error:\n                raise GiraffeEncodeError(error)\n        return column_list", "response": "Deserializes giraffez archive header. See GiraffeEncodeError for more information."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef items(self):\n        return {k.name: v for k, v in zip(self.columns, self)}", "response": "Returns the contents of the row as a dict with the columnnames as keys and the row s fields as values."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nexecute a query and initiate the connection with Teradata.", "response": "def query(self, query):\n        \"\"\"\n        Set the query to be run and initiate the connection with Teradata.\n        Only necessary if the query/table name was not specified as an argument\n        to the constructor of the instance.\n\n        :param str query: Valid SQL query to be executed\n        \"\"\"\n        if query is None:\n            return\n        if log.level >= VERBOSE:\n            self.options(\"query\", query, 6)\n        else:\n            self.options(\"query\", truncate(query), 6)\n        statements = parse_statement(remove_curly_quotes(query))\n        if not statements:\n            raise GiraffeError(\"Unable to parse SQL statement\")\n        if len(statements) > 1:\n            show_warning((\"MORE THAN ONE STATEMENT RECEIVED, EXPORT OPERATIONS ALLOW ONE \"\n                \"STATEMENT - ONLY THE FIRST STATEMENT WILL BE USED.\"), RuntimeWarning)\n        statement = statements[0]\n        log.debug(\"Debug[2]\", \"Statement (sanitized): {!r}\".format(statement))\n        if not (statement.startswith(\"select \") or statement.startswith(\"sel \")):\n            statement = \"select * from {}\".format(statement)\n        if statement == self.query:\n            return\n        else:\n            self._query = statement\n        self.initiated = False\n        # Since CLIv2 is used in set_query (instead of relying on the\n        # colums from the TPT Export driver) and set_query will always\n        # happen before calls to initiate, set_query will always fail\n        # with InvalidCredentialsError before initiate despite initiate\n        # presumably failing after this point as well.\n        try:\n            self.export.set_query(statement)\n        except InvalidCredentialsError as error:\n            if self.protect:\n                Config.lock_connection(self.config, self.dsn, self.key_file)\n            raise error"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_archive(self, writer):\n        if 'b' not in writer.mode:\n            raise GiraffeError(\"Archive writer must be in binary mode\")\n        writer.write(GIRAFFE_MAGIC)\n        writer.write(self.columns.serialize())\n        i = 0\n        for n, chunk in enumerate(self._fetchall(ROW_ENCODING_RAW), 1):\n            writer.write(chunk)\n            yield TeradataEncoder.count(chunk)", "response": "Writes the table name to the Giraffez archive format."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef to_str(self, delimiter='|', null='NULL'):\n        self.export.set_null(null)\n        self.export.set_delimiter(delimiter)\n        self.options(\"delimiter\", escape_string(delimiter), 2)\n        self.options(\"null\", null, 3)\n        return self._fetchall(ENCODER_SETTINGS_STRING, coerce_floats=False)", "response": "Returns an iterator over the current encoder output as a string."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef float_with_multiplier(string):\n    match = re_float_with_multiplier.search(string)\n    if not match or not match.group('num'):\n        raise ValueError('String \"{}\" is not numeric!'.format(string))\n\n    num = float(match.group('num'))\n    multi = match.group('multi')\n    if multi:\n        try:\n            num *= multipliers[multi]\n        except KeyError:\n            raise ValueError('Unknown multiplier: {}'.format(multi))\n    return num", "response": "Convert string with optional k M G T multiplier to float"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef specific_gains(string):\n    if not string:\n        return {}\n\n    gains = {}\n    for gain in string.split(','):\n        amp_name, value = gain.split('=')\n        gains[amp_name.strip()] = float(value.strip())\n    return gains", "response": "Convert string with gains of individual amplification elements to dict"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef device_settings(string):\n    if not string:\n        return {}\n\n    settings = {}\n    for setting in string.split(','):\n        setting_name, value = setting.split('=')\n        settings[setting_name.strip()] = value.strip()\n    return settings", "response": "Convert string with SoapySDR device settings to dict"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwraps text to terminal width with default indentation", "response": "def wrap(text, indent='    '):\n    \"\"\"Wrap text to terminal width with default indentation\"\"\"\n    wrapper = textwrap.TextWrapper(\n        width=int(os.environ.get('COLUMNS', 80)),\n        initial_indent=indent,\n        subsequent_indent=indent\n    )\n    return '\\n'.join(wrapper.wrap(text))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef detect_devices(soapy_args=''):\n    devices = simplesoapy.detect_devices(soapy_args, as_string=True)\n    text = []\n    text.append('Detected SoapySDR devices:')\n    if devices:\n        for i, d in enumerate(devices):\n            text.append('  {}'.format(d))\n    else:\n        text.append('  No devices found!')\n    return (devices, '\\n'.join(text))", "response": "Returns detected SoapySDR devices"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning info about the selected SoapySDR device", "response": "def device_info(soapy_args=''):\n    \"\"\"Returns info about selected SoapySDR device\"\"\"\n    text = []\n    try:\n        device = simplesoapy.SoapyDevice(soapy_args)\n        text.append('Selected device: {}'.format(device.hardware))\n        text.append('  Available RX channels:')\n        text.append('    {}'.format(', '.join(str(x) for x in device.list_channels())))\n        text.append('  Available antennas:')\n        text.append('    {}'.format(', '.join(device.list_antennas())))\n        text.append('  Available tunable elements:')\n        text.append('    {}'.format(', '.join(device.list_frequencies())))\n        text.append('  Available amplification elements:')\n        text.append('    {}'.format(', '.join(device.list_gains())))\n        text.append('  Available device settings:')\n        for key, s in device.list_settings().items():\n            text.append(wrap('{} ... {} - {} (default: {})'.format(key, s['name'], s['description'], s['value'])))\n        text.append('  Available stream arguments:')\n        for key, s in device.list_stream_args().items():\n            text.append(wrap('{} ... {} - {} (default: {})'.format(key, s['name'], s['description'], s['value'])))\n        text.append('  Allowed gain range [dB]:')\n        text.append('    {:.2f} - {:.2f}'.format(*device.get_gain_range()))\n        text.append('  Allowed frequency range [MHz]:')\n        text.append('    {:.2f} - {:.2f}'.format(*[x / 1e6 for x in device.get_frequency_range()]))\n        text.append('  Allowed sample rates [MHz]:')\n        rates = []\n        for r in device.list_sample_rates():\n            if r[0] == r[1]:\n                rates.append('{:.2f}'.format(r[0] / 1e6))\n            else:\n                rates.append('{:.2f} - {:.2f}'.format(r[0] / 1e6, r[1] / 1e6))\n        text.append(wrap(', '.join(rates)))\n        text.append('  Allowed bandwidths [MHz]:')\n        bandwidths = []\n        for b in device.list_bandwidths():\n            if b[0] == b[1]:\n                bandwidths.append('{:.2f}'.format(b[0] / 1e6))\n            else:\n                bandwidths.append('{:.2f} - {:.2f}'.format(b[0] / 1e6, b[1] / 1e6))\n        if bandwidths:\n            text.append(wrap(', '.join(bandwidths)))\n        else:\n            text.append('    N/A')\n    except RuntimeError:\n        device = None\n        text.append('No devices found!')\n    return (device, '\\n'.join(text))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef setup_argument_parser():\n    # Fix help formatter width\n    if 'COLUMNS' not in os.environ:\n        os.environ['COLUMNS'] = str(shutil.get_terminal_size().columns)\n\n    parser = argparse.ArgumentParser(\n        prog='soapy_power',\n        formatter_class=argparse.RawDescriptionHelpFormatter,\n        description='Obtain a power spectrum from SoapySDR devices',\n        add_help=False\n    )\n\n    # Fix recognition of optional argements of type float_with_multiplier\n    parser._negative_number_matcher = re_float_with_multiplier_negative\n\n    main_title = parser.add_argument_group('Main options')\n    main_title.add_argument('-h', '--help', action='help',\n                            help='show this help message and exit')\n    main_title.add_argument('-f', '--freq', metavar='Hz|Hz:Hz', type=freq_or_freq_range, default='1420405752',\n                            help='center frequency or frequency range to scan, number '\n                            'can be followed by a k, M or G multiplier (default: %(default)s)')\n\n    output_group = main_title.add_mutually_exclusive_group()\n    output_group.add_argument('-O', '--output', metavar='FILE', type=argparse.FileType('w'), default=sys.stdout,\n                              help='output to file (incompatible with --output-fd, default is stdout)')\n    output_group.add_argument('--output-fd', metavar='NUM', type=int, default=None,\n                              help='output to existing file descriptor (incompatible with -O)')\n\n    main_title.add_argument('-F', '--format', choices=sorted(writer.formats.keys()), default='rtl_power',\n                            help='output format (default: %(default)s)')\n    main_title.add_argument('-q', '--quiet', action='store_true',\n                            help='limit verbosity')\n    main_title.add_argument('--debug', action='store_true',\n                            help='detailed debugging messages')\n    main_title.add_argument('--detect', action='store_true',\n                            help='detect connected SoapySDR devices and exit')\n    main_title.add_argument('--info', action='store_true',\n                            help='show info about selected SoapySDR device and exit')\n    main_title.add_argument('--version', action='version',\n                            version='%(prog)s {}'.format(__version__))\n\n    bins_title = parser.add_argument_group('FFT bins')\n    bins_group = bins_title.add_mutually_exclusive_group()\n    bins_group.add_argument('-b', '--bins', type=int, default=512,\n                            help='number of FFT bins (incompatible with -B, default: %(default)s)')\n    bins_group.add_argument('-B', '--bin-size', metavar='Hz', type=float_with_multiplier,\n                            help='bin size in Hz (incompatible with -b)')\n\n    spectra_title = parser.add_argument_group('Averaging')\n    spectra_group = spectra_title.add_mutually_exclusive_group()\n    spectra_group.add_argument('-n', '--repeats', type=int, default=1600,\n                               help='number of spectra to average (incompatible with -t and -T, default: %(default)s)')\n    spectra_group.add_argument('-t', '--time', metavar='SECONDS', type=float,\n                               help='integration time (incompatible with -T and -n)')\n    spectra_group.add_argument('-T', '--total-time', metavar='SECONDS', type=float,\n                               help='total integration time of all hops (incompatible with -t and -n)')\n\n    runs_title = parser.add_argument_group('Measurements')\n    runs_group = runs_title.add_mutually_exclusive_group()\n    runs_group.add_argument('-c', '--continue', dest='endless', action='store_true',\n                            help='repeat the measurement endlessly (incompatible with -u and -e)')\n    runs_group.add_argument('-u', '--runs', type=int, default=1,\n                            help='number of measurements (incompatible with -c and -e, default: %(default)s)')\n    runs_group.add_argument('-e', '--elapsed', metavar='SECONDS', type=float,\n                            help='scan session duration (time limit in seconds, incompatible with -c and -u)')\n\n    device_title = parser.add_argument_group('Device settings')\n    device_title.add_argument('-d', '--device', default='',\n                              help='SoapySDR device to use')\n    device_title.add_argument('-C', '--channel', type=int, default=0,\n                              help='SoapySDR RX channel (default: %(default)s)')\n    device_title.add_argument('-A', '--antenna', default='',\n                              help='SoapySDR selected antenna')\n    device_title.add_argument('-r', '--rate', metavar='Hz', type=float_with_multiplier, default=2e6,\n                              help='sample rate (default: %(default)s)')\n    device_title.add_argument('-w', '--bandwidth', metavar='Hz', type=float_with_multiplier, default=0,\n                              help='filter bandwidth (default: %(default)s)')\n    device_title.add_argument('-p', '--ppm', type=int, default=0,\n                              help='frequency correction in ppm')\n\n    gain_group = device_title.add_mutually_exclusive_group()\n    gain_group.add_argument('-g', '--gain', metavar='dB', type=float, default=37.2,\n                            help='total gain (incompatible with -G and -a, default: %(default)s)')\n    gain_group.add_argument('-G', '--specific-gains', metavar='STRING', type=specific_gains, default='',\n                            help='specific gains of individual amplification elements '\n                                 '(incompatible with -g and -a, example: LNA=28,VGA=12,AMP=0')\n    gain_group.add_argument('-a', '--agc', action='store_true',\n                            help='enable Automatic Gain Control (incompatible with -g and -G)')\n\n    device_title.add_argument('--lnb-lo', metavar='Hz', type=float_with_multiplier, default=0,\n                              help='LNB LO frequency, negative for upconverters (default: %(default)s)')\n    device_title.add_argument('--device-settings', metavar='STRING', type=device_settings, default='',\n                              help='SoapySDR device settings (example: biastee=true)')\n    device_title.add_argument('--force-rate', action='store_true',\n                              help='ignore list of sample rates provided by device and allow any value')\n    device_title.add_argument('--force-bandwidth', action='store_true',\n                              help='ignore list of filter bandwidths provided by device and allow any value')\n    device_title.add_argument('--tune-delay', metavar='SECONDS', type=float, default=0,\n                              help='time to delay measurement after changing frequency (to avoid artifacts)')\n    device_title.add_argument('--reset-stream', action='store_true',\n                              help='reset streaming after changing frequency (to avoid artifacts)')\n\n    crop_title = parser.add_argument_group('Crop')\n    crop_group = crop_title.add_mutually_exclusive_group()\n    crop_group.add_argument('-o', '--overlap', metavar='PERCENT', type=float, default=0,\n                            help='percent of overlap when frequency hopping (incompatible with -k)')\n    crop_group.add_argument('-k', '--crop', metavar='PERCENT', type=float, default=0,\n                            help='percent of crop when frequency hopping (incompatible with -o)')\n\n    perf_title = parser.add_argument_group('Performance options')\n    perf_title.add_argument('-s', '--buffer-size', type=int, default=0,\n                            help='base buffer size (number of samples, 0 = auto, default: %(default)s)')\n    perf_title.add_argument('-S', '--max-buffer-size', type=int, default=0,\n                            help='maximum buffer size (number of samples, -1 = unlimited, 0 = auto, default: %(default)s)')\n\n    fft_rules_group = perf_title.add_mutually_exclusive_group()\n    fft_rules_group.add_argument('--even', action='store_true',\n                                 help='use only even numbers of FFT bins')\n    fft_rules_group.add_argument('--pow2', action='store_true',\n                                 help='use only powers of 2 as number of FFT bins')\n\n    perf_title.add_argument('--max-threads', metavar='NUM', type=int, default=0,\n                            help='maximum number of PSD threads (0 = auto, default: %(default)s)')\n    perf_title.add_argument('--max-queue-size', metavar='NUM', type=int, default=0,\n                            help='maximum size of PSD work queue (-1 = unlimited, 0 = auto, default: %(default)s)')\n    perf_title.add_argument('--no-pyfftw', action='store_true',\n                            help='don\\'t use pyfftw library even if it is available (use scipy.fftpack or numpy.fft)')\n\n    other_title = parser.add_argument_group('Other options')\n    other_title.add_argument('-l', '--linear', action='store_true',\n                             help='linear power values instead of logarithmic')\n    other_title.add_argument('-R', '--remove-dc', action='store_true',\n                             help='interpolate central point to cancel DC bias (useful only with boxcar window)')\n    other_title.add_argument('-D', '--detrend', choices=['none', 'constant'], default='none',\n                             help='remove mean value from data to cancel DC bias (default: %(default)s)')\n    other_title.add_argument('--fft-window', choices=['boxcar', 'hann', 'hamming', 'blackman', 'bartlett', 'kaiser', 'tukey'],\n                             default='hann', help='Welch\\'s method window function (default: %(default)s)')\n    other_title.add_argument('--fft-window-param', metavar='FLOAT', type=float, default=None,\n                             help='shape parameter of window function (required for kaiser and tukey windows)')\n    other_title.add_argument('--fft-overlap', metavar='PERCENT', type=float, default=50,\n                             help='Welch\\'s method overlap between segments (default: %(default)s)')\n\n    return parser", "response": "Setup command line parser"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets center frequency and clear averaged PSD data", "response": "def set_center_freq(self, center_freq):\n        \"\"\"Set center frequency and clear averaged PSD data\"\"\"\n        psd_state = {\n            'repeats': 0,\n            'freq_array': self._base_freq_array + self._lnb_lo + center_freq,\n            'pwr_array': None,\n            'update_lock': threading.Lock(),\n            'futures': [],\n        }\n        return psd_state"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn frequencies and averaged PSD for given center frequency", "response": "def result(self, psd_state):\n        \"\"\"Return freqs and averaged PSD for given center frequency\"\"\"\n        freq_array = numpy.fft.fftshift(psd_state['freq_array'])\n        pwr_array = numpy.fft.fftshift(psd_state['pwr_array'])\n\n        if self._crop_factor:\n            crop_bins_half = round((self._crop_factor * self._bins) / 2)\n            freq_array = freq_array[crop_bins_half:-crop_bins_half]\n            pwr_array = pwr_array[crop_bins_half:-crop_bins_half]\n\n        if psd_state['repeats'] > 1:\n            pwr_array = pwr_array / psd_state['repeats']\n\n        if self._log_scale:\n            pwr_array = 10 * numpy.log10(pwr_array)\n\n        return (freq_array, pwr_array)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwaiting for all PSD threads to finish and return result", "response": "def wait_for_result(self, psd_state):\n        \"\"\"Wait for all PSD threads to finish and return result\"\"\"\n        if len(psd_state['futures']) > 1:\n            concurrent.futures.wait(psd_state['futures'])\n        elif psd_state['futures']:\n            psd_state['futures'][0].result()\n        return self.result(psd_state)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncomputes PSD from samples and update average for given center frequency", "response": "def update(self, psd_state, samples_array):\n        \"\"\"Compute PSD from samples and update average for given center frequency\"\"\"\n        freq_array, pwr_array = simplespectral.welch(samples_array, self._sample_rate, nperseg=self._bins,\n                                                     window=self._fft_window, noverlap=self._fft_overlap_bins,\n                                                     detrend=self._detrend)\n\n        if self._remove_dc:\n            pwr_array[0] = (pwr_array[1] + pwr_array[-1]) / 2\n\n        with psd_state['update_lock']:\n            psd_state['repeats'] += 1\n            if psd_state['pwr_array'] is None:\n                psd_state['pwr_array'] = pwr_array\n            else:\n                psd_state['pwr_array'] += pwr_array"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_async(self, psd_state, samples_array):\n        future = self._executor.submit(self.update, psd_state, samples_array)\n        future.add_done_callback(self._release_future_memory)\n        psd_state['futures'].append(future)\n        return future", "response": "Compute PSD from samples and update average for given center frequency"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write_async(self, psd_data_or_future, time_start, time_stop, samples):\n        return self._executor.submit(self.write, psd_data_or_future, time_start, time_stop, samples)", "response": "Write PSD data asynchronously in another thread."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef read(self, f):\n        magic = f.read(len(self.magic))\n        if not magic:\n            return None\n        if magic != self.magic:\n            raise ValueError('Magic bytes not found! Read data: {}'.format(magic))\n\n        header = self.header._make(\n            self.header_struct.unpack(f.read(self.header_struct.size))\n        )\n        pwr_array = numpy.fromstring(f.read(header.size), dtype='float32')\n        return (header, pwr_array)", "response": "Read data from file - like object"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef write(self, f, time_start, time_stop, start, stop, step, samples, pwr_array):\n        f.write(self.magic)\n        f.write(self.header_struct.pack(\n            self.version, time_start, time_stop, start, stop, step, samples, pwr_array.nbytes\n        ))\n        #pwr_array.tofile(f)\n        f.write(pwr_array.tobytes())\n        f.flush()", "response": "Write data to file - like object"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write(self, psd_data_or_future, time_start, time_stop, samples):\n        try:\n            # Wait for result of future\n            f_array, pwr_array = psd_data_or_future.result()\n        except AttributeError:\n            f_array, pwr_array = psd_data_or_future\n\n        try:\n            step = f_array[1] - f_array[0]\n            self.formatter.write(\n                self.output,\n                time_start.timestamp(),\n                time_stop.timestamp(),\n                f_array[0],\n                f_array[-1] + step,\n                step,\n                samples,\n                pwr_array\n            )\n        except Exception as e:\n            logging.exception('Error writing to output file: {}'.format(e))", "response": "Write PSD of one frequency hop to file"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwrites PSD of one frequency hop to the output stream.", "response": "def write(self, psd_data_or_future, time_start, time_stop, samples):\n        \"\"\"Write PSD of one frequency hop\"\"\"\n        try:\n            # Wait for result of future\n            f_array, pwr_array = psd_data_or_future.result()\n        except AttributeError:\n            f_array, pwr_array = psd_data_or_future\n\n        self.output.write('# soapy_power output\\n')\n        self.output.write('# Acquisition start: {}\\n'.format(time_start))\n        self.output.write('# Acquisition end: {}\\n'.format(time_stop))\n        self.output.write('#\\n')\n        self.output.write('# frequency [Hz] power spectral density [dB/Hz]\\n')\n\n        for f, pwr in zip(f_array, pwr_array):\n            self.output.write('{} {}\\n'.format(f, pwr))\n\n        self.output.write('\\n')\n        self.output.flush()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef write(self, psd_data_or_future, time_start, time_stop, samples):\n        try:\n            # Wait for result of future\n            f_array, pwr_array = psd_data_or_future.result()\n        except AttributeError:\n            f_array, pwr_array = psd_data_or_future\n\n        try:\n            step = f_array[1] - f_array[0]\n            row = [\n                time_stop.strftime('%Y-%m-%d'), time_stop.strftime('%H:%M:%S'),\n                f_array[0], f_array[-1] + step, step, samples\n            ]\n            row += list(pwr_array)\n            self.output.write('{}\\n'.format(', '.join(str(x) for x in row)))\n            self.output.flush()\n        except Exception as e:\n            logging.exception('Error writing to output file:')", "response": "Write PSD of one frequency hop to file"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef submit(self, fn, *args, **kwargs):\n        future = super().submit(fn, *args, **kwargs)\n        work_queue_size = self._work_queue.qsize()\n        if work_queue_size > self.max_queue_size_reached:\n            self.max_queue_size_reached = work_queue_size\n        return future", "response": "Submits a callable to be executed with the given arguments."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns nearest number of FFT bins", "response": "def nearest_bins(self, bins, even=False, pow2=False):\n        \"\"\"Return nearest number of FFT bins (even or power of two)\"\"\"\n        if pow2:\n            bins_log2 = math.log(bins, 2)\n            if bins_log2 % 1 != 0:\n                bins = 2**math.ceil(bins_log2)\n                logger.warning('number of FFT bins should be power of two, changing to {}'.format(bins))\n        elif even:\n            if bins % 2 != 0:\n                bins = math.ceil(bins / 2) * 2\n                logger.warning('number of FFT bins should be even, changing to {}'.format(bins))\n\n        return bins"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef nearest_overlap(self, overlap, bins):\n        bins_overlap = overlap * bins\n        if bins_overlap % 2 != 0:\n            bins_overlap = math.ceil(bins_overlap / 2) * 2\n            overlap = bins_overlap / bins\n            logger.warning('number of overlapping FFT bins should be even, '\n                           'changing overlap/crop factor to {:.5f}'.format(overlap))\n        return overlap", "response": "Return nearest overlap factor based on number of bins"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef time_to_repeats(self, bins, integration_time):\n        return math.ceil((self.device.sample_rate * integration_time) / bins)", "response": "Convert integration time to number of repeats"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of frequencies for frequency hopping", "response": "def freq_plan(self, min_freq, max_freq, bins, overlap=0, quiet=False):\n        \"\"\"Returns list of frequencies for frequency hopping\"\"\"\n        bin_size = self.bins_to_bin_size(bins)\n        bins_crop = round((1 - overlap) * bins)\n        sample_rate_crop = (1 - overlap) * self.device.sample_rate\n\n        freq_range = max_freq - min_freq\n        hopping = True if freq_range >= sample_rate_crop else False\n        hop_size = self.nearest_freq(sample_rate_crop, bin_size)\n        hops = math.ceil(freq_range / hop_size) if hopping else 1\n        min_center_freq = min_freq + (hop_size / 2) if hopping else min_freq + (freq_range / 2)\n        max_center_freq = min_center_freq + ((hops - 1) * hop_size)\n\n        freq_list = [min_center_freq + (i * hop_size) for i in range(hops)]\n\n        if not quiet:\n            logger.info('overlap: {:.5f}'.format(overlap))\n            logger.info('bin_size: {:.2f} Hz'.format(bin_size))\n            logger.info('bins: {}'.format(bins))\n            logger.info('bins (after crop): {}'.format(bins_crop))\n            logger.info('sample_rate: {:.3f} MHz'.format(self.device.sample_rate / 1e6))\n            logger.info('sample_rate (after crop): {:.3f} MHz'.format(sample_rate_crop / 1e6))\n            logger.info('freq_range: {:.3f} MHz'.format(freq_range / 1e6))\n            logger.info('hopping: {}'.format('YES' if hopping else 'NO'))\n            logger.info('hop_size: {:.3f} MHz'.format(hop_size / 1e6))\n            logger.info('hops: {}'.format(hops))\n            logger.info('min_center_freq: {:.3f} MHz'.format(min_center_freq / 1e6))\n            logger.info('max_center_freq: {:.3f} MHz'.format(max_center_freq / 1e6))\n            logger.info('min_freq (after crop): {:.3f} MHz'.format((min_center_freq - (hop_size / 2)) / 1e6))\n            logger.info('max_freq (after crop): {:.3f} MHz'.format((max_center_freq + (hop_size / 2)) / 1e6))\n\n            logger.debug('Frequency hops table:')\n            logger.debug('  {:8s}      {:8s}      {:8s}'.format('Min:', 'Center:', 'Max:'))\n            for f in freq_list:\n                logger.debug('  {:8.3f} MHz  {:8.3f} MHz  {:8.3f} MHz'.format(\n                    (f - (self.device.sample_rate / 2)) / 1e6,\n                    f / 1e6,\n                    (f + (self.device.sample_rate / 2)) / 1e6,\n                ))\n\n        return freq_list"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a buffer for reading samples", "response": "def create_buffer(self, bins, repeats, base_buffer_size, max_buffer_size=0):\n        \"\"\"Create buffer for reading samples\"\"\"\n        samples = bins * repeats\n        buffer_repeats = 1\n        buffer_size = math.ceil(samples / base_buffer_size) * base_buffer_size\n\n        if not max_buffer_size:\n            # Max buffer size about 100 MB\n            max_buffer_size = (100 * 1024**2) / 8\n\n        if max_buffer_size > 0:\n            max_buffer_size = math.ceil(max_buffer_size / base_buffer_size) * base_buffer_size\n            if buffer_size > max_buffer_size:\n                logger.warning('Required buffer size ({}) will be shrinked to max_buffer_size ({})!'.format(\n                    buffer_size, max_buffer_size\n                ))\n                buffer_repeats = math.ceil(buffer_size / max_buffer_size)\n                buffer_size = max_buffer_size\n\n        logger.info('repeats: {}'.format(repeats))\n        logger.info('samples: {} (time: {:.5f} s)'.format(samples, samples / self.device.sample_rate))\n        if max_buffer_size > 0:\n            logger.info('max_buffer_size (samples): {} (repeats: {:.2f}, time: {:.5f} s)'.format(\n                max_buffer_size, max_buffer_size / bins, max_buffer_size / self.device.sample_rate\n            ))\n        else:\n            logger.info('max_buffer_size (samples): UNLIMITED')\n        logger.info('buffer_size (samples): {} (repeats: {:.2f}, time: {:.5f} s)'.format(\n            buffer_size, buffer_size / bins, buffer_size / self.device.sample_rate\n        ))\n        logger.info('buffer_repeats: {}'.format(buffer_repeats))\n\n        return (buffer_repeats, zeros(buffer_size, numpy.complex64))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprepare samples buffer and start streaming samples from device", "response": "def setup(self, bins, repeats, base_buffer_size=0, max_buffer_size=0, fft_window='hann',\n              fft_overlap=0.5, crop_factor=0, log_scale=True, remove_dc=False, detrend=None,\n              lnb_lo=0, tune_delay=0, reset_stream=False, max_threads=0, max_queue_size=0):\n        \"\"\"Prepare samples buffer and start streaming samples from device\"\"\"\n        if self.device.is_streaming:\n            self.device.stop_stream()\n\n        base_buffer = self.device.start_stream(buffer_size=base_buffer_size)\n        self._bins = bins\n        self._repeats = repeats\n        self._base_buffer_size = len(base_buffer)\n        self._max_buffer_size = max_buffer_size\n        self._buffer_repeats, self._buffer = self.create_buffer(\n            bins, repeats, self._base_buffer_size, self._max_buffer_size\n        )\n        self._tune_delay = tune_delay\n        self._reset_stream = reset_stream\n        self._psd = psd.PSD(bins, self.device.sample_rate, fft_window=fft_window, fft_overlap=fft_overlap,\n                            crop_factor=crop_factor, log_scale=log_scale, remove_dc=remove_dc, detrend=detrend,\n                            lnb_lo=lnb_lo, max_threads=max_threads, max_queue_size=max_queue_size)\n        self._writer = writer.formats[self._output_format](self._output)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstops streaming samples from device and delete samples buffer", "response": "def stop(self):\n        \"\"\"Stop streaming samples from device and delete samples buffer\"\"\"\n        if not self.device.is_streaming:\n            return\n\n        self.device.stop_stream()\n        self._writer.close()\n\n        self._bins = None\n        self._repeats = None\n        self._base_buffer_size = None\n        self._max_buffer_size = None\n        self._buffer_repeats = None\n        self._buffer = None\n        self._tune_delay = None\n        self._reset_stream = None\n        self._psd = None\n        self._writer = None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef psd(self, freq):\n        if not self.device.is_streaming:\n            raise RuntimeError('Streaming is not initialized, you must run setup() first!')\n\n        # Tune to new frequency in main thread\n        logger.debug('  Frequency hop: {:.2f} Hz'.format(freq))\n        t_freq = time.time()\n        if self.device.freq != freq:\n            # Deactivate streaming before tuning\n            if self._reset_stream:\n                self.device.device.deactivateStream(self.device.stream)\n\n            # Actually tune to new center frequency\n            self.device.freq = freq\n\n            # Reactivate straming after tuning\n            if self._reset_stream:\n                self.device.device.activateStream(self.device.stream)\n\n            # Delay reading samples after tuning\n            if self._tune_delay:\n                t_delay = time.time()\n                while True:\n                    self.device.read_stream()\n                    t_delay_end = time.time()\n                    if t_delay_end - t_delay >= self._tune_delay:\n                        break\n                logger.debug('    Tune delay: {:.3f} s'.format(t_delay_end - t_delay))\n        else:\n            logger.debug('    Same frequency as before, tuning skipped')\n        psd_state = self._psd.set_center_freq(freq)\n        t_freq_end = time.time()\n        logger.debug('    Tune time: {:.3f} s'.format(t_freq_end - t_freq))\n\n        for repeat in range(self._buffer_repeats):\n            logger.debug('    Repeat: {}'.format(repeat + 1))\n            # Read samples from SDR in main thread\n            t_acq = time.time()\n            acq_time_start = datetime.datetime.utcnow()\n            self.device.read_stream_into_buffer(self._buffer)\n            acq_time_stop = datetime.datetime.utcnow()\n            t_acq_end = time.time()\n            logger.debug('      Acquisition time: {:.3f} s'.format(t_acq_end - t_acq))\n\n            # Start FFT computation in another thread\n            self._psd.update_async(psd_state, numpy.copy(self._buffer))\n\n            t_final = time.time()\n\n            if _shutdown:\n                break\n\n        psd_future = self._psd.result_async(psd_state)\n        logger.debug('    Total hop time: {:.3f} s'.format(t_final - t_freq))\n\n        return (psd_future, acq_time_start, acq_time_stop)", "response": "Tune to specified frequency and compute Power Spectral Density"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsweeping the audio file using frequency hopping.", "response": "def sweep(self, min_freq, max_freq, bins, repeats, runs=0, time_limit=0, overlap=0,\n              fft_window='hann', fft_overlap=0.5, crop=False, log_scale=True, remove_dc=False, detrend=None, lnb_lo=0,\n              tune_delay=0, reset_stream=False, base_buffer_size=0, max_buffer_size=0, max_threads=0, max_queue_size=0):\n        \"\"\"Sweep spectrum using frequency hopping\"\"\"\n        self.setup(\n            bins, repeats, base_buffer_size, max_buffer_size,\n            fft_window=fft_window, fft_overlap=fft_overlap, crop_factor=overlap if crop else 0,\n            log_scale=log_scale, remove_dc=remove_dc, detrend=detrend, lnb_lo=lnb_lo, tune_delay=tune_delay,\n            reset_stream=reset_stream, max_threads=max_threads, max_queue_size=max_queue_size\n        )\n\n        try:\n            freq_list = self.freq_plan(min_freq - lnb_lo, max_freq - lnb_lo, bins, overlap)\n            t_start = time.time()\n            run = 0\n            while not _shutdown and (runs == 0 or run < runs):\n                run += 1\n                t_run_start = time.time()\n                logger.debug('Run: {}'.format(run))\n\n                for freq in freq_list:\n                    # Tune to new frequency, acquire samples and compute Power Spectral Density\n                    psd_future, acq_time_start, acq_time_stop = self.psd(freq)\n\n                    # Write PSD to stdout (in another thread)\n                    self._writer.write_async(psd_future, acq_time_start, acq_time_stop,\n                                             len(self._buffer) * self._buffer_repeats)\n\n                    if _shutdown:\n                        break\n\n                # Write end of measurement marker (in another thread)\n                write_next_future = self._writer.write_next_async()\n                t_run = time.time()\n                logger.debug('  Total run time: {:.3f} s'.format(t_run - t_run_start))\n\n                # End measurement if time limit is exceeded\n                if time_limit and (time.time() - t_start) >= time_limit:\n                    logger.info('Time limit of {} s exceeded, completed {} runs'.format(time_limit, run))\n                    break\n\n            # Wait for last write to be finished\n            write_next_future.result()\n\n            # Debug thread pool queues\n            logging.debug('Number of USB buffer overflow errors: {}'.format(self.device.buffer_overflow_count))\n            logging.debug('PSD worker threads: {}'.format(self._psd._executor._max_workers))\n            logging.debug('Max. PSD queue size: {} / {}'.format(self._psd._executor.max_queue_size_reached,\n                                                                self._psd._executor.max_queue_size))\n            logging.debug('Writer worker threads: {}'.format(self._writer._executor._max_workers))\n            logging.debug('Max. Writer queue size: {} / {}'.format(self._writer._executor.max_queue_size_reached,\n                                                                   self._writer._executor.max_queue_size))\n        finally:\n            # Shutdown SDR\n            self.stop()\n            t_stop = time.time()\n            logger.info('Total time: {:.3f} s'.format(t_stop - t_start))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef close(self):\n        os.close(self._fd)\n        self._fd = -1\n        self._addr = -1\n        self._pec = 0", "response": "Disconnects the object from the bus."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nopening the object to the specified SMBus.", "response": "def open(self, bus):\n        \"\"\"open(bus)\n\n        Connects the object to the specified SMBus.\n        \"\"\"\n        bus = int(bus)\n        path = \"/dev/i2c-%d\" % (bus,)\n        if len(path) >= MAXPATH:\n                raise OverflowError(\"Bus number is invalid.\")\n        try:\n            self._fd = os.open(path, os.O_RDWR, 0)\n        except OSError as e:\n            raise IOError(e.errno)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nperforms SMBus Quick transaction.", "response": "def write_quick(self, addr):\n        \"\"\"write_quick(addr)\n\n        Perform SMBus Quick transaction.\n        \"\"\"\n        self._set_addr(addr)\n        if SMBUS.i2c_smbus_write_quick(self._fd, SMBUS.I2C_SMBUS_WRITE) != 0:\n            raise IOError(ffi.errno)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read_byte(self, addr):\n        self._set_addr(addr)\n        result = SMBUS.i2c_smbus_read_byte(self._fd)\n        if result == -1:\n            raise IOError(ffi.errno)\n        return result", "response": "Read a byte from the cache."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write_byte(self, addr, val):\n        self._set_addr(addr)\n        if SMBUS.i2c_smbus_write_byte(self._fd, ffi.cast(\"__u8\", val)) == -1:\n            raise IOError(ffi.errno)", "response": "Write a byte to the memory mapped by the base address."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nperforms a SMBus Read Byte Data transaction.", "response": "def read_byte_data(self, addr, cmd):\n        \"\"\"read_byte_data(addr, cmd) -> result\n\n        Perform SMBus Read Byte Data transaction.\n        \"\"\"\n        self._set_addr(addr)\n        res = SMBUS.i2c_smbus_read_byte_data(self._fd, ffi.cast(\"__u8\", cmd))\n        if res == -1:\n            raise IOError(ffi.errno)\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef write_byte_data(self, addr, cmd, val):\n        self._set_addr(addr)\n        if SMBUS.i2c_smbus_write_byte_data(self._fd,\n                                           ffi.cast(\"__u8\", cmd),\n                                           ffi.cast(\"__u8\", val)) == -1:\n            raise IOError(ffi.errno)", "response": "Write a byte to a resource in the current thread."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread word data from the specified address and return the result.", "response": "def read_word_data(self, addr, cmd):\n        \"\"\"read_word_data(addr, cmd) -> result\n\n        Perform SMBus Read Word Data transaction.\n        \"\"\"\n        self._set_addr(addr)\n        result = SMBUS.i2c_smbus_read_word_data(self._fd, ffi.cast(\"__u8\", cmd))\n        if result == -1:\n            raise IOError(ffi.errno)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef write_word_data(self, addr, cmd, val):\n        self._set_addr(addr)\n        if SMBUS.i2c_smbus_write_word_data(self._fd,\n                                           ffi.cast(\"__u8\", cmd),\n                                           ffi.cast(\"__u16\", val)) == -1:\n            raise IOError(ffi.errno)", "response": "Write word data to a resource in the cache."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef process_call(self, addr, cmd, val):\n        self._set_addr(addr)\n        ret = SMBUS.i2c_smbus_process_call(self._fd,\n                                           ffi.cast(\"__u8\", cmd),\n                                           ffi.cast(\"__u16\", val))\n        if ret == -1:\n            raise IOError(ffi.errno)\n        if self._compat:\n            return ret", "response": "Process a call from the specified address and return the result."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read_block_data(self, addr, cmd):\n        # XXX untested, the raspberry pi i2c driver does not support this\n        # command\n        self._set_addr(addr)\n        data = ffi.new(\"union i2c_smbus_data *\")\n        if SMBUS.i2c_smbus_access(self._fd,\n                                  int2byte(SMBUS.I2C_SMBUS_READ),\n                                  ffi.cast(\"__u8\", cmd),\n                                  SMBUS.I2C_SMBUS_BLOCK_DATA,\n                                  data):\n            raise IOError(ffi.errno)\n        return smbus_data_to_list(data)", "response": "Perform SMBus Read Block Data transaction."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef write_block_data(self, addr, cmd, vals):\n        self._set_addr(addr)\n        data = ffi.new(\"union i2c_smbus_data *\")\n        list_to_smbus_data(data, vals)\n        if SMBUS.i2c_smbus_access(self._fd,\n                                  int2byte(SMBUS.I2C_SMBUS_WRITE),\n                                  ffi.cast(\"__u8\", cmd),\n                                  SMBUS.I2C_SMBUS_BLOCK_DATA,\n                                  data):\n            raise IOError(ffi.errno)", "response": "Write block data to a resource."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef block_process_call(self, addr, cmd, vals):\n        self._set_addr(addr)\n        data = ffi.new(\"union i2c_smbus_data *\")\n        list_to_smbus_data(data, vals)\n        if SMBUS.i2c_smbus_access(self._fd, SMBUS.I2C_SMBUS_WRITE,\n                                  ffi.cast(\"__u8\", cmd),\n                                  SMBUS.I2C_SMBUS_BLOCK_PROC_CALL,\n                                  data):\n            raise IOError(ffi.errno)\n        return smbus_data_to_list(data)", "response": "Perform SMBus Block Process Call transaction."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read_i2c_block_data(self, addr, cmd, len=32):\n        self._set_addr(addr)\n        data = ffi.new(\"union i2c_smbus_data *\")\n        data.block[0] = len\n        if len == 32:\n            arg = SMBUS.I2C_SMBUS_I2C_BLOCK_BROKEN\n        else:\n            arg = SMBUS.I2C_SMBUS_I2C_BLOCK_DATA\n        if SMBUS.i2c_smbus_access(self._fd,\n                                  int2byte(SMBUS.I2C_SMBUS_READ),\n                                  ffi.cast(\"__u8\", cmd),\n                                  arg, data):\n            raise IOError(ffi.errno)\n        return smbus_data_to_list(data)", "response": "Read the block of data from the i2c bus."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pec(self, value):\n        pec = bool(value)\n        if pec != self._pec:\n            if ioctl(self._fd, SMBUS.I2C_PEC, pec):\n                raise IOError(ffi.errno)\n            self._pec = pec", "response": "Set Packet Error Codes ( PEC )."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef run_cmake(arg=\"\"):\n    if ds.find_executable('cmake') is None:\n        print \"CMake  is required to build zql\"\n        print \"Please install cmake version >= 2.8 and re-run setup\"\n        sys.exit(-1)\n\n    print \"Configuring zql build with CMake.... \"\n    cmake_args = arg\n    try:\n        build_dir = op.join(op.split(__file__)[0], 'build')\n        dd.mkpath(build_dir)\n        os.chdir(\"build\")\n        ds.spawn(['cmake', '..'] + cmake_args.split())\n        ds.spawn(['make', 'clean'])\n        ds.spawn(['make'])\n        os.chdir(\"..\")\n    except ds.DistutilsExecError:\n        print \"Error while running cmake\"\n        print \"run 'setup.py build --help' for build options\"\n        print \"You may also try editing the settings in CMakeLists.txt file and re-running setup\"\n        sys.exit(-1)", "response": "Run cmake with the given arguments"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef start(cls, now, number, **options):\n        return (cls.mask(now, **options) -\n                timedelta(**{cls.__name__.lower(): number - 1}))", "response": "Return the starting datetime of the specified number of units before now."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef filter(cls, datetimes, number, now=None, **options):\n        if not isinstance(number, int) or number < 0:\n            raise ValueError('Invalid number: %s' % number)\n\n        datetimes = tuple(datetimes)\n\n        # Sample the first datetime to see if it is timezone-aware\n        tzinfo = None\n        if datetimes and datetimes[0].tzinfo is not None:\n            tzinfo = UTC()\n\n        if now is None:\n            now = datetime.now(tzinfo)\n\n        if not hasattr(now, 'second'):\n            # now looks like a date, so convert it into a datetime\n            now = datetime.combine(now, time(23, 59, 59, 999999, tzinfo=tzinfo))\n\n        # Always keep datetimes from the future\n        future = set(dt for dt in datetimes if dt > now)\n\n        if number == 0:\n            return future\n\n        # Don't consider datetimes from before the start\n        start = cls.start(now, number, **options)\n        valid = (dt for dt in datetimes if start <= dt <= now)\n\n        # Deduplicate datetimes with the same mask() value by keeping\n        # the oldest.\n        kept = {}\n        for dt in sorted(valid):\n            kept.setdefault(cls.mask(dt, **options), dt)\n\n        return set(kept.values()) | future", "response": "Return a set of datetimes after filtering datetimes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef mask(cls, dt, **options):\n        return dt.replace(hour=0, minute=0, second=0, microsecond=0)", "response": "Return a datetime with the same value as dt to a\n        resolution of days."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the starting datetime for the given number of weeks before now.", "response": "def start(cls, now, number, firstweekday=calendar.SATURDAY, **options):\n        \"\"\"\n        Return the starting datetime: ``number`` of weeks before ``now``.\n\n        ``firstweekday`` determines when the week starts. It defaults\n        to Saturday.\n        \"\"\"\n        week = cls.mask(now, firstweekday=firstweekday, **options)\n        days = (number - 1) * cls.DAYS_IN_WEEK\n        return week - timedelta(days=days)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a datetime with the same value as dt.", "response": "def mask(cls, dt, firstweekday=calendar.SATURDAY, **options):\n        \"\"\"\n        Return a datetime with the same value as ``dt``, to a\n        resolution of weeks.\n\n        ``firstweekday`` determines when the week starts. It defaults\n        to Saturday.\n        \"\"\"\n        correction = (dt.weekday() - firstweekday) % cls.DAYS_IN_WEEK\n        week = dt - timedelta(days=correction)\n        return week.replace(hour=0, minute=0, second=0, microsecond=0)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the starting datetime for the given number of months before now.", "response": "def start(cls, now, number, **options):\n        \"\"\"\n        Return the starting datetime: ``number`` of months before ``now``.\n        \"\"\"\n        year = now.year\n        month = now.month - number + 1\n        # Handle negative months\n        if month < 0:\n            year = year + (month // cls.MONTHS_IN_YEAR)\n            month = month % cls.MONTHS_IN_YEAR\n        # Handle December\n        if month == 0:\n            year = year - 1\n            month = 12\n        return cls.mask(now, **options).replace(year=year, month=month)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the starting datetime of the specified number of years before now.", "response": "def start(cls, now, number, **options):\n        \"\"\"\n        Return the starting datetime: ``number`` of years before ``now``.\n        \"\"\"\n        return cls.mask(now).replace(year=(now.year - number + 1))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_keep(datetimes,\n            years=0, months=0, weeks=0, days=0,\n            hours=0, minutes=0, seconds=0,\n            firstweekday=SATURDAY, now=None):\n    \"\"\"\n    Return a set of datetimes that should be kept, out of ``datetimes``.\n\n    Keeps up to ``years``, ``months``, ``weeks``, ``days``,\n    ``hours``, ``minutes``, and ``seconds`` in the past.\n\n    When keeping weeks, it prefers to keep ``firstweekday``, which\n    defaults to Saturday.\n\n    If ``now`` is None, it will base its calculations on\n    ``datetime.datetime.now()``. Datetimes after this point will always be\n    kept.\n    \"\"\"\n    datetimes = set(datetimes)\n    return (filters.Years.filter(datetimes, number=years, now=now) |\n            filters.Months.filter(datetimes, number=months, now=now) |\n            filters.Weeks.filter(datetimes, number=weeks,\n                                 firstweekday=firstweekday, now=now) |\n            filters.Days.filter(datetimes, number=days, now=now) |\n            filters.Hours.filter(datetimes, number=hours, now=now) |\n            filters.Minutes.filter(datetimes, number=minutes, now=now) |\n            filters.Seconds.filter(datetimes, number=seconds, now=now))", "response": "Returns a set of datetimes that should be kept out of the current date."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_delete(datetimes,\n              years=0, months=0, weeks=0, days=0,\n              hours=0, minutes=0, seconds=0,\n              firstweekday=SATURDAY, now=None):\n    \"\"\"\n    Return a set of datetimes that should be deleted, out of ``datetimes``.\n\n    See ``to_keep`` for a description of arguments.\n    \"\"\"\n    datetimes = set(datetimes)\n    return datetimes - to_keep(datetimes,\n                               years=years, months=months,\n                               weeks=weeks, days=days,\n                               hours=hours, minutes=minutes, seconds=seconds,\n                               firstweekday=firstweekday, now=now)", "response": "Return a set of datetimes that should be deleted out of the specified datetimes."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a set of dates that should be kept out of dates.", "response": "def dates_to_keep(dates,\n                  years=0, months=0, weeks=0, days=0, firstweekday=SATURDAY,\n                  now=None):\n    \"\"\"\n    Return a set of dates that should be kept, out of ``dates``.\n\n    See ``to_keep`` for a description of arguments.\n    \"\"\"\n    datetimes = to_keep((datetime.combine(d, time()) for d in dates),\n                        years=years, months=months, weeks=weeks, days=days,\n                        hours=0, minutes=0, seconds=0,\n                        firstweekday=firstweekday, now=now)\n    return set(dt.date() for dt in datetimes)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dates_to_delete(dates,\n                    years=0, months=0, weeks=0, days=0, firstweekday=SATURDAY,\n                    now=None):\n    \"\"\"\n    Return a set of date that should be deleted, out of ``dates``.\n\n    See ``to_keep`` for a description of arguments.\n    \"\"\"\n    dates = set(dates)\n    return dates - dates_to_keep(dates,\n                                 years=years, months=months,\n                                 weeks=weeks, days=days,\n                                 firstweekday=firstweekday, now=now)", "response": "Return a set of dates that should be deleted out of a sequence of dates."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_spi_control_byte(self, read_write_cmd):\n        # board_addr_pattern = (self.hardware_addr & 0b111) << 1\n        board_addr_pattern = (self.hardware_addr << 1) & 0xE\n        rw_cmd_pattern = read_write_cmd & 1  # make sure it's just 1 bit long\n        return 0x40 | board_addr_pattern | rw_cmd_pattern", "response": "Returns an SPI control byte."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read_bit(self, bit_num, address):\n        value = self.read(address)\n        bit_mask = get_bit_mask(bit_num)\n        return 1 if value & bit_mask else 0", "response": "Reads a single bit from the address."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwriting the value given to the bit in the address specified.", "response": "def write_bit(self, value, bit_num, address):\n        \"\"\"Writes the value given to the bit in the address specified.\n\n        :param value: The value to write.\n        :type value: int\n        :param bit_num: The bit number to write to.\n        :type bit_num: int\n        :param address: The address to write to.\n        :type address: int\n        \"\"\"\n        bit_mask = get_bit_mask(bit_num)\n        old_byte = self.read(address)\n         # generate the new byte\n        if value:\n            new_byte = old_byte | bit_mask\n        else:\n            new_byte = old_byte & ~bit_mask\n        self.write(new_byte, address)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the lowest bit number from a given bit pattern.", "response": "def get_bit_num(bit_pattern):\n    \"\"\"Returns the lowest bit num from a given bit pattern. Returns None if no\n    bits set.\n\n    :param bit_pattern: The bit pattern.\n    :type bit_pattern: int\n    :returns: int -- the bit number\n    :returns: None -- no bits set\n\n    >>> pifacecommon.core.get_bit_num(0)\n    None\n    >>> pifacecommon.core.get_bit_num(0b1)\n    0\n    >>> pifacecommon.core.get_bit_num(0b11000)\n    3\n    \"\"\"\n    if bit_pattern == 0:\n        return None\n\n    bit_num = 0  # assume bit 0\n    while (bit_pattern & 1) == 0:\n        bit_pattern = bit_pattern >> 1\n        bit_num += 1\n        if bit_num > 7:\n            bit_num = 0\n            break\n\n    return bit_num"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwait for a port event.", "response": "def watch_port_events(port, chip, pin_function_maps, event_queue,\n                      return_after_kbdint=False):\n    \"\"\"Waits for a port event. When a port event occurs it is placed onto the\n    event queue.\n\n    :param port: The port we are waiting for interrupts on (GPIOA/GPIOB).\n    :type port: int\n    :param chip: The chip we are waiting for interrupts on.\n    :type chip: :class:`pifacecommon.mcp23s17.MCP23S17`\n    :param pin_function_maps: A list of classes that have inheritted from\n        :class:`FunctionMap`\\ s describing what to do with events.\n    :type pin_function_maps: list\n    :param event_queue: A queue to put events on.\n    :type event_queue: :py:class:`multiprocessing.Queue`\n    \"\"\"\n    # set up epoll\n    gpio25 = open(GPIO_INTERRUPT_DEVICE_VALUE, 'r')  # change to use 'with'?\n    epoll = select.epoll()\n    epoll.register(gpio25, select.EPOLLIN | select.EPOLLET)\n\n    while True:\n        # wait here until input\n        try:\n            events = epoll.poll()\n        except KeyboardInterrupt as e:\n            if return_after_kbdint:\n                return\n            else:\n                raise e\n        except IOError as e:\n            # ignore \"Interrupted system call\" error.\n            # I don't really like this solution. Ignoring problems is bad!\n            if e.errno != errno.EINTR:\n                raise\n\n        # find out where the interrupt came from and put it on the event queue\n        if port == pifacecommon.mcp23s17.GPIOA:\n            interrupt_flag = chip.intfa.value\n        else:\n            interrupt_flag = chip.intfb.value\n\n        if interrupt_flag == 0:\n            continue  # The interrupt has not been flagged on this board\n        else:\n            if port == pifacecommon.mcp23s17.GPIOA:\n                interrupt_capture = chip.intcapa.value\n            else:\n                interrupt_capture = chip.intcapb.value\n            event_queue.add_event(InterruptEvent(\n                interrupt_flag, interrupt_capture, chip, time.time()))\n\n    epoll.close()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwait for events on the event queue and calls the registered functions.", "response": "def handle_events(\n        function_maps, event_queue, event_matches_function_map,\n        terminate_signal):\n    \"\"\"Waits for events on the event queue and calls the registered functions.\n\n    :param function_maps: A list of classes that have inheritted from\n        :class:`FunctionMap`\\ s describing what to do with events.\n    :type function_maps: list\n    :param event_queue: A queue to put events on.\n    :type event_queue: :py:class:`multiprocessing.Queue`\n    :param event_matches_function_map: A function that determines if the given\n        event and :class:`FunctionMap` match.\n    :type event_matches_function_map: function\n    :param terminate_signal: The signal that, when placed on the event queue,\n        causes this function to exit.\n    \"\"\"\n    while True:\n        # print(\"HANDLE: Waiting for events!\")\n        event = event_queue.get()\n        # print(\"HANDLE: It's an event!\")\n        if event == terminate_signal:\n            return\n        # if matching get the callback function, else function is None\n        functions = map(\n            lambda fm: fm.callback\n            if event_matches_function_map(event, fm) else None,\n            function_maps)\n        # reduce to just the callback functions (remove None)\n        # TODO: I think this can just be filter(None, functions)\n        functions = filter(lambda f: f is not None, functions)\n\n        for function in functions:\n            function(event)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef bring_gpio_interrupt_into_userspace():  # activate gpio interrupt\n    try:\n        # is it already there?\n        with open(GPIO_INTERRUPT_DEVICE_VALUE):\n            return\n    except IOError:\n        # no, bring it into userspace\n        with open(GPIO_EXPORT_FILE, 'w') as export_file:\n            export_file.write(str(GPIO_INTERRUPT_PIN))\n\n        wait_until_file_exists(GPIO_INTERRUPT_DEVICE_VALUE)", "response": "Bring the interrupt pin on the GPIO into Linux userspace."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_gpio_interrupt_edge(edge='falling'):\n    # we're only interested in the falling edge (1 -> 0)\n    start_time = time.time()\n    time_limit = start_time + FILE_IO_TIMEOUT\n    while time.time() < time_limit:\n        try:\n            with open(GPIO_INTERRUPT_DEVICE_EDGE, 'w') as gpio_edge:\n                gpio_edge.write(edge)\n                return\n        except IOError:\n            pass", "response": "Set the interrupt edge on the userspace GPIO pin."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef wait_until_file_exists(filename):\n    start_time = time.time()\n    time_limit = start_time + FILE_IO_TIMEOUT\n    while time.time() < time_limit:\n        try:\n            with open(filename):\n                return\n        except IOError:\n            pass\n\n    raise Timeout(\"Waiting too long for %s.\" % filename)", "response": "Wait until a file exists."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds an event to the event queue.", "response": "def add_event(self, event):\n        \"\"\"Adds events to the queue. Will ignore events that occur before the\n        settle time for that pin/direction. Such events are assumed to be\n        bouncing.\n        \"\"\"\n        # print(\"Trying to add event:\")\n        # print(event)\n        # find out the pin settle time\n        for pin_function_map in self.pin_function_maps:\n            if _event_matches_pin_function_map(event, pin_function_map):\n            # if pin_function_map.pin_num == event.pin_num and (\n            #         pin_function_map.direction == event.direction or\n            #         pin_function_map.direction == IODIR_BOTH):\n                pin_settle_time = pin_function_map.settle_time\n                # print(\"EventQueue: Found event in map.\")\n                break\n        else:\n            # Couldn't find event in map, don't bother adding it to the queue\n            # print(\"EventQueue: Couldn't find event in map:\")\n            # for pin_function_map in self.pin_function_maps:\n            #     print(pin_function_map)\n            return\n\n        threshold_time = self.last_event_time[event.pin_num] + pin_settle_time\n        if event.timestamp > threshold_time:\n            self.put(event)\n            self.last_event_time[event.pin_num] = event.timestamp"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nregistering a pin number and direction to a callback function.", "response": "def register(self, pin_num, direction, callback,\n                 settle_time=DEFAULT_SETTLE_TIME):\n        \"\"\"Registers a pin number and direction to a callback function.\n\n        :param pin_num: The pin pin number.\n        :type pin_num: int\n        :param direction: The event direction\n            (use: IODIR_ON/IODIR_OFF/IODIR_BOTH)\n        :type direction: int\n        :param callback: The function to run when event is detected.\n        :type callback: function\n        :param settle_time: Time within which subsequent events are ignored.\n        :type settle_time: int\n        \"\"\"\n        self.pin_function_maps.append(\n            PinFunctionMap(pin_num, direction, callback, settle_time))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef deregister(self, pin_num=None, direction=None):\n        to_delete = []\n        for i, function_map in enumerate(self.pin_function_maps):\n            if ( pin_num == None\n                 or ( function_map.pin_num == pin_num\n                      and ( direction == None\n                            or function_map.direction == direction ) ) ):\n                to_delete.append(i)\n        for i in reversed(to_delete):\n            del self.pin_function_maps[i]", "response": "De - registers callback functions\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef deactivate(self):\n        self.event_queue.put(self.TERMINATE_SIGNAL)\n        self.dispatcher.join()\n        self.detector.terminate()\n        self.detector.join()", "response": "When the port event listener is deactivated the event dispatcher and detector are terminated."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef spisend(self, bytes_to_send):\n        # make some buffer space to store reading/writing\n        wbuffer = ctypes.create_string_buffer(bytes_to_send,\n                                              len(bytes_to_send))\n        rbuffer = ctypes.create_string_buffer(len(bytes_to_send))\n\n        # create the spi transfer struct\n        transfer = spi_ioc_transfer(\n            tx_buf=ctypes.addressof(wbuffer),\n            rx_buf=ctypes.addressof(rbuffer),\n            len=ctypes.sizeof(wbuffer),\n            speed_hz=ctypes.c_uint32(self.speed_hz)\n        )\n\n        if self.spi_callback is not None:\n            self.spi_callback(bytes_to_send)\n        # send the spi command\n        ioctl(self.fd, SPI_IOC_MESSAGE(1), transfer)\n        return ctypes.string_at(rbuffer, ctypes.sizeof(rbuffer))", "response": "Sends a number of bytes to the SPI bus."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef render(self, form, form_style, context, template_pack=TEMPLATE_PACK):\n        links, content = '', ''\n\n        # accordion group needs the parent div id to set `data-parent` (I don't\n        # know why). This needs to be a unique id\n        if not self.css_id:\n            self.css_id = \"-\".join([\"tabsholder\",\n                                    text_type(randint(1000, 9999))])\n\n        for tab in self.fields:\n            tab.active = False\n\n        # Activate item\n        self.open_target_group_for_form(form)\n\n        for tab in self.fields:\n            content += render_field(\n                tab, form, form_style, context, template_pack=template_pack\n            )\n            links += tab.render_link(form, template_pack)\n\n        context.update({\n            'tabs': self,\n            'links': links,\n            'content': content\n        })\n\n        template = self.get_template_name(template_pack)\n        return render_to_string(template, context.flatten())", "response": "Render the items of the current item."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn True if the given form has any errors.", "response": "def has_errors(self, form):\n        \"\"\"\n        Find tab fields listed as invalid\n        \"\"\"\n        return any([fieldname_error for fieldname_error in form.errors.keys()\n                    if fieldname_error in self])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef render_link(self, form, template_pack=TEMPLATE_PACK, **kwargs):\n        link_template = self.link_template % template_pack\n        return render_to_string(link_template,\n                                {\n                                    'link': self,\n                                    'item_has_errors': self.has_errors(form)\n                                })", "response": "Render the link for the tab - pane."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _extract_version(package_name):\n    try:\n        return pkg_resources.get_distribution(package_name).version\n    except pkg_resources.DistributionNotFound:\n        _conf = read_configuration(os.path.join(PROJECT_DIR, \"setup.cfg\"))\n    return _conf[\"metadata\"][\"version\"]", "response": "Get package version from installed distribution or configuration file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_form_kwargs(self):\n        kwargs = super(FormContainersMixin, self).get_form_kwargs()\n        kwargs.update({\n            'pack': \"foundation-{}\".format(self.kwargs.get('foundation_version'))\n        })\n        return kwargs", "response": "Pass template pack argument\n            = nationale - version"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _check_status(cls, response_json):\n        status = response_json['status']\n        msg = response_json['msg']\n\n        if status == 400:\n            raise BadRequestException(msg)\n        elif status == 403:\n            raise PermissionDeniedException(msg)\n        elif status == 404:\n            raise FileNotFoundException(msg)\n        elif status == 451:\n            raise UnavailableForLegalReasonsException(msg)\n        elif status == 509:\n            raise BandwidthUsageExceeded(msg)\n        elif status >= 500:\n            raise ServerErrorException(msg)", "response": "Check the status of the incoming response and raise exception if it is not 200."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get(self, url, params=None):\n        if not params:\n            params = {}\n\n        params.update({'login': self.login, 'key': self.key})\n\n        response_json = requests.get(self.api_url + url, params).json()\n\n        return self._process_response(response_json)", "response": "Used by every other method it makes a GET request with the given params."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrequesting direct download link for requested file, this method makes use of the response of prepare_download, prepare_download must be called first. Args: file_id (str): id of the file to be downloaded. ticket (str): preparation ticket is found in prepare_download response,\\ this is why we need to call prepare_download before get_download_link. captcha_response (:obj:`str`, optional): sometimes prepare_download will have captcha url to be solved, \\ first, this is the solution of the captcha. Returns: dict: dictionary containing (file info, download url, ...). :: { \"name\": \"The quick brown fox.txt\", \"size\": 12345, \"sha1\": \"2fd4e1c67a2d28fced849ee1bb76e7391b93eb12\", \"content_type\": \"plain/text\", \"upload_at\": \"2011-01-26 13:33:37\", \"url\": \"https://abvzps.example.com/dl/l/4spxX_-cSO4/The+quick+brown+fox.txt\", \"token\": \"4spxX_-cSO4\" }", "response": "def get_download_link(self, file_id, ticket, captcha_response=None):\n        \"\"\"Requests direct download link for requested file,\n        this method makes use of the response of prepare_download, prepare_download must be called first.\n\n        Args:\n            file_id (str): id of the file to be downloaded.\n\n            ticket (str): preparation ticket is found in prepare_download response,\\\n                          this is why we need to call prepare_download before get_download_link.\n\n            captcha_response (:obj:`str`, optional): sometimes prepare_download will have captcha url to be solved, \\\n                                                     first, this is the solution of the captcha.\n\n        Returns:\n            dict: dictionary containing (file info, download url, ...). ::\n\n                  {\n                    \"name\": \"The quick brown fox.txt\",\n                    \"size\": 12345,\n                    \"sha1\": \"2fd4e1c67a2d28fced849ee1bb76e7391b93eb12\",\n                    \"content_type\": \"plain/text\",\n                    \"upload_at\": \"2011-01-26 13:33:37\",\n                    \"url\": \"https://abvzps.example.com/dl/l/4spxX_-cSO4/The+quick+brown+fox.txt\",\n                    \"token\": \"4spxX_-cSO4\"\n                  }\n\n        \"\"\"\n        params = {'ticket': ticket, 'file': file_id}\n\n        if captcha_response:\n            params['captcha_response'] = captcha_response\n\n        return self._get('file/dl', params)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmake a request to prepare for file upload.", "response": "def upload_link(self, folder_id=None, sha1=None, httponly=False):\n        \"\"\"Makes a request to prepare for file upload.\n\n        Note:\n            If folder_id is not provided, it will make and upload link to the ``Home`` folder.\n\n        Args:\n            folder_id (:obj:`str`, optional): folder-ID to upload to.\n            sha1 (:obj:`str`, optional): expected sha1 If sha1 of uploaded file doesn't match this value, upload fails.\n            httponly (:obj:`bool`, optional): If this is set to true, use only http upload links.\n\n        Returns:\n            dict: dictionary containing (url: will be used in actual upload, valid_until). ::\n\n                {\n                    \"url\": \"https://1fiafqj.oloadcdn.net/uls/nZ8H3X9e0AotInbU\",\n                    \"valid_until\": \"2017-08-19 19:06:46\"\n                }\n\n        \"\"\"\n\n        kwargs = {'folder': folder_id, 'sha1': sha1, 'httponly': httponly}\n        params = {key: value for key, value in kwargs.items() if value}\n        return self._get('file/ul', params=params)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef upload_file(self, file_path, folder_id=None, sha1=None, httponly=False):\n\n        upload_url_response_json = self.upload_link(folder_id=folder_id, sha1=sha1, httponly=httponly)\n        upload_url = upload_url_response_json['url']\n\n        with open(file_path, 'rb') as f:\n            response_json = requests.post(upload_url, files={'upload_file': f}).json()\n\n        self._check_status(response_json)\n        return response_json['result']", "response": "Uploads a file to the Knw."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef remote_upload(self, remote_url, folder_id=None, headers=None):\n\n        kwargs = {'folder': folder_id, 'headers': headers}\n        params = {'url': remote_url}\n        params.update({key: value for key, value in kwargs.items() if value})\n\n        return self._get('remotedl/add', params=params)", "response": "Used to make a remote file upload to openload. co\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck a remote file upload to status.", "response": "def remote_upload_status(self, limit=None, remote_upload_id=None):\n        \"\"\"Checks a remote file upload to status.\n\n        Args:\n            limit (:obj:`int`, optional): Maximum number of results (Default: 5, Maximum: 100).\n            remote_upload_id (:obj:`str`, optional): Remote Upload ID.\n\n        Returns:\n            dict: dictionary containing all remote uploads, each dictionary element is a dictionary. ::\n\n                {\n                    \"24\": {\n                      \"id\": \"24\",\n                      \"remoteurl\": \"http://proof.ovh.net/files/100Mio.dat\",\n                      \"status\": \"new\",\n                      \"folderid\": \"4248\",\n                      \"added\": \"2015-02-21 09:20:26\",\n                      \"last_update\": \"2015-02-21 09:20:26\",\n                      \"extid\": False,\n                      \"url\": False\n                    },\n                    \"22\": {\n                      \"id\": \"22\",\n                      \"remoteurl\": \"http://proof.ovh.net/files/1Gio.dat\",\n                      \"status\": \"downloading\",\n                      \"bytes_loaded\": \"823997062\",\n                      \"bytes_total\": \"1073741824\",\n                      \"folderid\": \"4248\",\n                      \"added\": \"2015-02-21 09:20:26\",\n                      \"last_update\": \"2015-02-21 09:21:56\",\n                      \"extid\": False,\n                      \"url\": False\n                    },\n                    ...\n                }\n\n        \"\"\"\n\n        kwargs = {'limit': limit, 'id': remote_upload_id}\n        params = {key: value for key, value in kwargs.items() if value}\n\n        return self._get('remotedl/status', params=params)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrequest a list of files and folders in specified folder.", "response": "def list_folder(self, folder_id=None):\n        \"\"\"Request a list of files and folders in specified folder.\n\n        Note:\n            if folder_id is not provided, ``Home`` folder will be listed\n\n        Args:\n            folder_id (:obj:`str`, optional): id of the folder to be listed.\n\n        Returns:\n            dict: dictionary containing only two keys (\"folders\", \"files\"), \\\n                  each key represents a list of dictionaries. ::\n\n                      {\n                        \"folders\": [\n                          {\n                            \"id\": \"5144\",\n                            \"name\": \".videothumb\"\n                          },\n                          {\n                            \"id\": \"5792\",\n                            \"name\": \".subtitles\"\n                          },\n                          ...\n                        ],\n                        \"files\": [\n                          {\n                            \"name\": \"big_buck_bunny.mp4.mp4\",\n                            \"sha1\": \"c6531f5ce9669d6547023d92aea4805b7c45d133\",\n                            \"folderid\": \"4258\",\n                            \"upload_at\": \"1419791256\",\n                            \"status\": \"active\",\n                            \"size\": \"5114011\",\n                            \"content_type\": \"video/mp4\",\n                            \"download_count\": \"48\",\n                            \"cstatus\": \"ok\",\n                            \"link\": \"https://openload.co/f/UPPjeAk--30/big_buck_bunny.mp4.mp4\",\n                            \"linkextid\": \"UPPjeAk--30\"\n                          },\n                          ...\n                        ]\n                      }\n\n        \"\"\"\n        params = {'folder': folder_id} if folder_id else {}\n\n        return self._get('file/listfolder', params=params)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nshow running file converts by folder_id", "response": "def running_conversions(self, folder_id=None):\n        \"\"\"Shows running file converts by folder\n\n        Note:\n            If folder_id is not provided, ``Home`` folder will be used.\n\n        Args:\n            folder_id (:obj:`str`, optional): id of the folder to list conversions of files exist in it.\n\n        Returns:\n            list: list of dictionaries, each dictionary represents a file conversion info. ::\n\n                      [\n                        {\n                          \"name\": \"Geysir.AVI\",\n                          \"id\": \"3565411\",\n                          \"status\": \"pending\",\n                          \"last_update\": \"2015-08-23 19:41:40\",\n                          \"progress\": 0.32,\n                          \"retries\": \"0\",\n                          \"link\": \"https://openload.co/f/f02JFG293J8/Geysir.AVI\",\n                          \"linkextid\": \"f02JFG293J8\"\n                        },\n                        ....\n                      ]\n\n        \"\"\"\n        params = {'folder': folder_id} if folder_id else {}\n        return self._get('file/runningconverts', params=params)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef calc_heat_index(temp, hum):\n    '''\n    calculates the heat index based upon temperature (in F) and humidity.\n    http://www.srh.noaa.gov/bmx/tables/heat_index.html\n\n    returns the heat index in degrees F.\n    '''\n    \n    if (temp < 80):\n        return temp\n    else:\n        return -42.379 + 2.04901523 * temp + 10.14333127 * hum - 0.22475541 * \\\n               temp * hum - 6.83783 * (10 ** -3) * (temp ** 2) - 5.481717 * \\\n               (10 ** -2) * (hum ** 2) + 1.22874 * (10 ** -3) * (temp ** 2) * \\\n               hum + 8.5282 * (10 ** -4) * temp * (hum ** 2) - 1.99 * \\\n               (10 ** -6) * (temp ** 2) * (hum ** 2);", "response": "Calculates the heat index based upon temperature and humidity."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncalculate the wind chill value based upon the temperature F and windspeed and windspeed10min returns the wind chill in degrees F.", "response": "def calc_wind_chill(t, windspeed, windspeed10min=None):\n    '''\n    calculates the wind chill value based upon the temperature (F) and\n    wind.\n\n    returns the wind chill in degrees F.\n    '''\n\n    w = max(windspeed10min, windspeed)\n    return 35.74 + 0.6215 * t - 35.75 * (w ** 0.16) + 0.4275 * t * (w ** 0.16);"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef calc_humidity(temp, dewpoint):\n    '''\n    calculates the humidity via the formula from weatherwise.org\n    return the relative humidity\n    '''\n\n    t = fahrenheit_to_celsius(temp)\n    td = fahrenheit_to_celsius(dewpoint)\n\n    num = 112 - (0.1 * t) + td\n    denom = 112 + (0.9 * t)\n\n    rh = math.pow((num / denom), 8)\n    \n    return rh", "response": "Calculates the humidity via the formula from weatherwise. org\n    return the relative humidity\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncalculate the dewpoint via the formula from weatherwise. org return the dewpoint in degrees F.", "response": "def calc_dewpoint(temp, hum):\n    '''\n    calculates the dewpoint via the formula from weatherwise.org\n    return the dewpoint in degrees F.\n    '''\n\n    c = fahrenheit_to_celsius(temp)\n    x = 1 - 0.01 * hum;\n\n    dewpoint = (14.55 + 0.114 * c) * x;\n    dewpoint = dewpoint + ((2.5 + 0.007 * c) * x) ** 3;\n    dewpoint = dewpoint + (15.9 + 0.117 * c) * x ** 14;\n    dewpoint = c - dewpoint;\n\n    return celsius_to_fahrenheit(dewpoint)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nperform HTTP session to transmit defined weather values.", "response": "def publish(self):\n      '''\n      Perform HTTP session to transmit defined weather values.\n      '''\n      return self._publish( self.args, self.server, self.URI)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get(data):\n        '''\n        return CRC calc value from raw serial data\n        '''\n        crc = 0\n        for byte in array('B', data):\n            crc = (VProCRC.CRC_TABLE[(crc >> 8) ^ byte] ^ ((crc & 0xFF) << 8))\n        return crc", "response": "get the CRC value from raw serial data"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef verify(data):\n        '''\n        perform CRC check on raw serial data, return true if valid.\n        a valid CRC == 0.\n        '''\n        if len(data) == 0:\n            return False\n        crc = VProCRC.get(data)\n        if crc:\n            log.info(\"CRC Bad\")\n        else:\n            log.debug(\"CRC OK\")\n        return not crc", "response": "Verify that the data is valid for a specific object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngive a packed storm date field unpack and return YYYY - MM - DD string.", "response": "def _unpack_storm_date(date):\n        '''\n        given a packed storm date field, unpack and return 'YYYY-MM-DD' string.\n        '''\n        year = (date & 0x7f) + 2000  # 7 bits\n        day = (date >> 7) & 0x01f  # 5 bits\n        month = (date >> 12) & 0x0f  # 4 bits\n        return \"%s-%s-%s\" % (year, month, day)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning True if we re using Rev. B archives otherwise False.", "response": "def _use_rev_b_archive(self, records, offset):\n        '''\n        return True if weather station returns Rev.B archives\n        '''\n        # if pre-determined, return result\n        if type(self._ARCHIVE_REV_B) is bool:\n            return self._ARCHIVE_REV_B\n        # assume, B and check 'RecType' field\n        data = ArchiveBStruct.unpack_from(records, offset)\n        if data['RecType'] == 0:\n            log.info('detected archive rev. B')\n            self._ARCHIVE_REV_B = True\n        else:\n            log.info('detected archive rev. A')\n            self._ARCHIVE_REV_B = False\n\n        return self._ARCHIVE_REV_B"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _wakeup(self):\n        '''\n        issue wakeup command to device to take out of standby mode.\n        '''\n        log.info(\"send: WAKEUP\")\n        for i in xrange(3):\n            self.port.write('\\n')  # wakeup device\n            ack = self.port.read(len(self.WAKE_ACK))  # read wakeup string\n            log_raw('read', ack)\n            if ack == self.WAKE_ACK:\n                return\n        raise NoDeviceException('Can not access weather station')", "response": "wakeup device to device to take out of standby mode."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _cmd(self, cmd, *args, **kw):\n        '''\n        write a single command, with variable number of arguments. after the\n        command, the device must return ACK\n        '''\n        ok = kw.setdefault('ok', False)\n\n        self._wakeup()\n        if args:\n            cmd = \"%s %s\" % (cmd, ' '.join(str(a) for a in args))\n        for i in xrange(3):\n            log.info(\"send: \" + cmd)\n            self.port.write(cmd + '\\n')\n            if ok:\n                ack = self.port.read(len(self.OK))  # read OK\n                log_raw('read', ack)\n                if ack == self.OK:\n                    return\n            else:\n                ack = self.port.read(len(self.ACK))  # read ACK\n                log_raw('read', ack)\n                if ack == self.ACK:\n                    return\n        raise NoDeviceException('Can not access weather station')", "response": "write a single command with variable number of arguments. after the command the device must return ACK\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread a raw string containing data read from the device provided in / dev / XXX format. all reads are non - blocking.", "response": "def _loop_cmd(self):\n        '''\n        reads a raw string containing data read from the device\n        provided (in /dev/XXX) format. all reads are non-blocking.\n        '''\n        self._cmd('LOOP', 1)\n        raw = self.port.read(LoopStruct.size)  # read data\n        log_raw('read', raw)\n        return raw"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nissue a DMPAFT command to read the archive records after a known time stamp.", "response": "def _dmpaft_cmd(self, time_fields):\n        '''\n        issue a command to read the archive records after a known time stamp.\n        '''\n        records = []\n        # convert time stamp fields to buffer\n        tbuf = struct.pack('2H', *time_fields)\n\n        # 1. send 'DMPAFT' cmd\n        self._cmd('DMPAFT')\n\n        # 2. send time stamp + crc\n        crc = VProCRC.get(tbuf)\n        crc = struct.pack('>H', crc)  # crc in big-endian format\n        log_raw('send', tbuf + crc)\n        self.port.write(tbuf + crc)  # send time stamp + crc\n        ack = self.port.read(len(self.ACK))  # read ACK\n        log_raw('read', ack)\n        if ack != self.ACK: return  # if bad ack, return\n\n        # 3. read pre-amble data\n        raw = self.port.read(DmpStruct.size)\n        log_raw('read', raw)\n        if not VProCRC.verify(raw):  # check CRC value\n            log_raw('send ESC', self.ESC)\n            self.port.write(self.ESC)  # if bad, escape and abort\n            return\n        log_raw('send ACK', self.ACK)\n        self.port.write(self.ACK)  # send ACK\n\n        # 4. loop through all page records\n        dmp = DmpStruct.unpack(raw)\n        log.info('reading %d pages, start offset %d' %\n                 (dmp['Pages'], dmp['Offset']))\n        for i in xrange(dmp['Pages']):\n            # 5. read page data\n            raw = self.port.read(DmpPageStruct.size)\n            log_raw('read', raw)\n            if not VProCRC.verify(raw):  # check CRC value\n                log_raw('send ESC', self.ESC)\n                self.port.write(self.ESC)  # if bad, escape and abort\n                return\n            log_raw('send ACK', self.ACK)\n            self.port.write(self.ACK)  # send ACK\n\n            # 6. loop through archive records\n            page = DmpPageStruct.unpack(raw)\n            offset = 0  # assume offset at 0\n            if i == 0:\n                offset = dmp['Offset'] * ArchiveAStruct.size\n            while offset < ArchiveAStruct.size * 5:\n                log.info('page %d, reading record at offset %d' %\n                         (page['Index'], offset))\n                if self._use_rev_b_archive(page['Records'], offset):\n                    a = ArchiveBStruct.unpack_from(page['Records'], offset)\n                else:\n                    a = ArchiveAStruct.unpack_from(page['Records'], offset)\n                # 7. verify that record has valid data, and store\n                if a['DateStamp'] != 0xffff and a['TimeStamp'] != 0xffff:\n                    records.append(a)\n                offset += ArchiveAStruct.size\n        log.info('read all pages')\n        return records"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a dictionary of fields from the newest archive record in the device. return None when no records are new.", "response": "def _get_new_archive_fields(self):\n        '''\n        returns a dictionary of fields from the newest archive record in the\n        device. return None when no records are new.\n        '''\n        for i in xrange(3):\n            records = self._dmpaft_cmd(self._archive_time)\n            if records is not None: break\n            time.sleep(1)\n\n        if records is None:\n            raise NoDeviceException('Can not access weather station')\n\n        # find the newest record\n        new_rec = None\n        for r in records:\n            new_time = (r['DateStamp'], r['TimeStamp'])\n            if self._archive_time < new_time:\n                self._archive_time = new_time\n                new_rec = r\n\n        return new_rec"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _calc_derived_fields(self, fields):\n        '''\n        calculates the derived fields (those fields that are calculated)\n        '''\n        # convenience variables for the calculations below\n        temp = fields['TempOut']\n        hum = fields['HumOut']\n        wind = fields['WindSpeed']\n        wind10min = fields['WindSpeed10Min']\n        fields['HeatIndex'] = calc_heat_index(temp, hum)\n        fields['WindChill'] = calc_wind_chill(temp, wind, wind10min)\n        fields['DewPoint'] = calc_dewpoint(temp, hum)\n        # store current data string\n        now = time.localtime()\n        fields['DateStamp'] = time.strftime(\"%Y-%m-%d %H:%M:%S\", now)\n        fields['Year'] = now[0]\n        fields['Month'] = str(now[1]).zfill(2)\n        now = time.gmtime()\n        fields['DateStampUtc'] = time.strftime(\"%Y-%m-%d %H:%M:%S\", now)\n        fields['YearUtc'] = now[0]\n        fields['MonthUtc'] = str(now[1]).zfill(2)", "response": "Calculates the derived fields of the current log entry."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread and parse a set of data read from the console and set the fields variable to the values in the dict that are available in the fields variable.", "response": "def parse(self):\n        '''\n        read and parse a set of data read from the console.  after the\n        data is parsed it is available in the fields variable.\n        '''\n        fields = self._get_loop_fields()\n        fields['Archive'] = self._get_new_archive_fields()\n\n        self._calc_derived_fields(fields)\n\n        # set the fields variable the the values in the dict\n        self.fields = fields"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nunpack data from buf and returns a dication of named fields.", "response": "def unpack_from(self, buf, offset=0 ):\n        '''\n        unpacks data from 'buf' and returns a dication of named fields. the\n        fields can be post-processed by extending the _post_unpack() method.\n        '''\n        data = super(Struct,self).unpack_from( buf, offset)\n        items = dict(zip(self.fields,data))\n        return self._post_unpack(items)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget publication services from options", "response": "def get_pub_services(opts):\n   '''\n   use values in opts data to generate instances of publication services.\n   '''\n   sites = []\n   for p_key in vars(opts).keys():\n      args = getattr(opts,p_key)\n      if p_key in PUB_SERVICES and args:\n         if isinstance(args,tuple):\n            ps = PUB_SERVICES[p_key](*args)\n         else:\n            ps = PUB_SERVICES[p_key](args)\n         sites.append( ps )\n   return sites"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_options(parser):\n   '''\n   read command line options to configure program behavior.\n   '''\n   # station services\n   # publication services\n   pub_g = optparse.OptionGroup( parser, \"Publication Services\",\n         '''One or more publication service must be specified to enable upload\n         of weather data.''', )\n   pub_g.add_option('-w', '--wundergound', nargs=2, type='string', dest='wug',\n         help='Weather Underground service; WUG=[SID(station ID), PASSWORD]')\n   pub_g.add_option('-p', '--pws', nargs=2, type='string', dest='pws',\n         help='PWS service; PWS=[SID(station ID), PASSWORD]')\n   pub_g.add_option('-f', '--file', nargs=1, type='string', dest='file',\n         help='Local file; FILE=[FILE_NAME]')\n   parser.add_option_group(pub_g)\n\n   parser.add_option('-d', '--debug', dest='debug', action=\"store_true\",\n         default=False, help='enable verbose debug logging')\n   parser.add_option('-q', '--quiet', dest='quiet', action=\"store_true\",\n         default=False, help='disable all console logging')\n   parser.add_option('-t', '--tty', dest='tty', default='/dev/ttyS0',\n         help='set serial port device [/dev/ttyS0]')\n   parser.add_option('-n', '--interval', dest='interval', default=60,\n         type='int', help='polling/update interval in seconds [60]')\n   return parser.parse_args()", "response": "get command line options"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the gust value of the given station and interval", "response": "def get( self, station, interval ):\n      '''\n      return gust data, if above threshold value and current time is inside\n      reporting window period\n      '''\n      rec = station.fields['Archive']\n      # process new data\n      if rec:\n         threshold = station.fields['WindSpeed10Min'] + GUST_MPH_MIN\n         if rec['WindHi'] >= threshold:\n            self.value = (rec['WindHi'],rec['WindHiDir'])\n            self.count = GUST_TTL * 60 / interval\n         else:\n            self.value = self.NO_VALUE\n\n      # return gust value, if remaining time is left, and valid\n      if self.count:\n         self.count -= 1\n      else:\n         self.value = self.NO_VALUE\n\n      log.debug('wind gust of {0} mph from {1}'.format(*self.value))\n      return self.value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set( self, pressure='NA', dewpoint='NA', humidity='NA', tempf='NA',\n            rainin='NA', rainday='NA', dateutc='NA', windgust='NA',\n            windgustdir='NA', windspeed='NA', winddir='NA',\n            clouds='NA', weather='NA', *args, **kw):\n        '''\n        Useful for defining weather data published to the server. Parameters\n        not set will be reset and not sent to server. Unknown keyword args will\n        be silently ignored, so be careful. This is necessary for publishers\n        that support more fields than others.\n        '''\n        # see: http://wiki.wunderground.com/index.php/PWS_-_Upload_Protocol\n        # unused, but valid, parameters are:\n        #   windspdmph_avg2m, winddir_avg2m, windgustmph_10m, windgusdir_10m\n        #   soiltempf, soilmoisture, leafwetness, solarradiation, UV\n        #   indoortempf, indoorhumidity\n        self.args.update( {\n                'baromin':pressure,\n                'clouds':clouds,\n                'dailyrainin':rainday,\n                'dateutc':dateutc,\n                'dewptf':dewpoint,\n                'humidity':humidity,\n                'rainin':rainin,\n                'tempf':tempf,\n                'weather':weather,\n                'winddir':winddir,\n                'windgustdir':windgustdir,\n                'windgustmph':windgust,\n                'windspeedmph':windspeed,\n            } )\n        log.debug( self.args )", "response": "Sets the parameters of the object to the values in the passed in parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set( self, **kw):\n      '''\n      Store keyword args to be written to output file.\n      '''\n      self.args = kw\n      log.debug( self.args )", "response": "Store keyword args to be written to output file."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\npublishes the input file.", "response": "def publish(self):\n      '''\n      Write output file.\n      '''\n      with open( self.file_name, 'w') as fh:\n         for k,v in self.args.iteritems():\n            buf = StringIO.StringIO()\n            buf.write(k)\n            self._append_vals(buf,v)\n            fh.write(buf.getvalue() + '\\n')\n            buf.close()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef requires(*requirements, **opts):\n\n    identity = opts.get(\"identity\")\n    on_fail = opts.get(\"on_fail\")\n    throws = opts.get(\"throws\")\n\n    def decorator(f):\n        @wraps(f)\n        def allower(*args, **kwargs):\n\n            result = allows.run(\n                requirements,\n                identity=identity,\n                on_fail=on_fail,\n                throws=throws,\n                f_args=args,\n                f_kwargs=kwargs,\n            )\n\n            # authorization failed\n            if result is not None:\n                return result\n\n            return f(*args, **kwargs)\n\n        return allower\n\n    return decorator", "response": "Decorator to apply requirements to routes or class based views."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef guard_entire(requirements, identity=None, throws=None, on_fail=None):\n\n    def guarder():\n        if _should_run_requirements():\n            return allows.run(\n                requirements,\n                identity=identity,\n                on_fail=on_fail,\n                throws=throws,\n                f_kwargs=request.view_args,\n            )\n        return None\n\n    return guarder", "response": "This function guards an entire blueprint with a set of requirements."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef wants_request(f):\n\n    @wraps(f)\n    def wrapper(user):\n        return f(user, request)\n\n    return wrapper", "response": "Decorator for allowing a user to transition to user - only requirements."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a new combinator that uses the given set of requirements to reduce the result of the first False.", "response": "def And(cls, *requirements):\n        \"\"\"\n        Short cut helper to construct a combinator that uses\n        :meth:`operator.and_` to reduce requirement results and stops\n        evaluating on the first False.\n\n        This is also exported at the module level as ``And``\n        \"\"\"\n        return cls(*requirements, op=operator.and_, until=False)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef Or(cls, *requirements):\n        return cls(*requirements, op=operator.or_, until=True)", "response": "Return a combinator that uses the given set of requirements to reduce the result of evaluating the first True entry in the set."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninitializing the Flask - Allow object against the provided application.", "response": "def init_app(self, app):\n        \"\"\"\n        Initializes the Flask-Allows object against the provided application\n        \"\"\"\n        if not hasattr(app, \"extensions\"):  # pragma: no cover\n            app.extensions = {}\n        app.extensions[\"allows\"] = self\n\n        @app.before_request\n        def start_context(*a, **k):\n            self.overrides.push(Override())\n            self.additional.push(Additional())\n\n        @app.after_request\n        def cleanup(response):\n            self.clear_all_overrides()\n            self.clear_all_additional()\n            return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fulfill(self, requirements, identity=None):\n        identity = identity or self._identity_loader()\n\n        if self.additional.current:\n            all_requirements = chain(iter(self.additional.current), requirements)\n        else:\n            all_requirements = iter(requirements)\n\n        if self.overrides.current is not None:\n            all_requirements = (\n                r for r in all_requirements if r not in self.overrides.current\n            )\n\n        return all(_call_requirement(r, identity, request) for r in all_requirements)", "response": "Checks that the provided identity meets each requirement\n           ."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd an override to the current context.", "response": "def push(self, override, use_parent=False):\n        \"\"\"\n        Binds an override to the current context, optionally use the\n        current overrides in conjunction with this override\n\n        If ``use_parent`` is true, a new override is created from the\n        parent and child overrides rather than manipulating either\n        directly.\n        \"\"\"\n        current = self.current\n        if use_parent and current:\n            override = current + override\n\n        _override_ctx_stack.push((self, override))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef pop(self):\n        rv = _override_ctx_stack.pop()\n        if rv is None or rv[0] is not self:\n            raise RuntimeError(\n                \"popped wrong override context ({} instead of {})\".format(rv, self)\n            )", "response": "Pops the latest override context from the stack."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nallow temporarily pushing an override context, yields the new context into the following block.", "response": "def override(self, override, use_parent=False):\n        \"\"\"\n        Allows temporarily pushing an override context, yields the new context\n        into the following block.\n        \"\"\"\n        self.push(override, use_parent)\n        yield self.current\n        self.pop()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds an additional context to the current context.", "response": "def push(self, additional, use_parent=False):\n        \"\"\"\n        Binds an additional to the current context, optionally use the\n        current additionals in conjunction with this additional\n\n        If ``use_parent`` is true, a new additional is created from the\n        parent and child additionals rather than manipulating either\n        directly.\n        \"\"\"\n        current = self.current\n        if use_parent and current:\n            additional = current + additional\n\n        _additional_ctx_stack.push((self, additional))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pop(self):\n        rv = _additional_ctx_stack.pop()\n        if rv is None or rv[0] is not self:\n            raise RuntimeError(\n                \"popped wrong additional context ({} instead of {})\".format(rv, self)\n            )", "response": "Pops the latest additional context from the stack."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nallow temporarily pushing an additional context, yields the new context into the following block.", "response": "def additional(self, additional, use_parent=False):\n        \"\"\"\n        Allows temporarily pushing an additional context, yields the new context\n        into the following block.\n        \"\"\"\n        self.push(additional, use_parent)\n        yield self.current\n        self.pop()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nappend a number to duplicate field names to make them unique.", "response": "def unduplicate_field_names(field_names):\n    \"\"\"Append a number to duplicate field names to make them unique. \"\"\"\n    res = []\n    for k in field_names:\n        if k in res:\n            i = 1\n            while k + '_' + str(i) in res:\n                i += 1\n            k += '_' + str(i)\n        res.append(k)\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef interpret_stats(results):\n    stats = results.stats\n    contains_updates = stats.pop(\"contains_updates\", False) if stats else False\n    if not contains_updates:\n        result = '{} rows affected.'.format(len(results))\n    else:\n        result = ''\n        for stat, value in stats.items():\n            if value:\n                result = \"{}\\n{} {}.\".format(result, value,\n                                             stat.replace(\"_\", \" \"))\n    return result.strip()", "response": "Generates the string to be shown as updates after the execution of a\n                   ."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef extract_params_from_query(query, user_ns):\n    # TODO: Optmize this function\n    params = {}\n    for k, v in user_ns.items():\n        try:\n            json.dumps(v)\n            params[k] = v\n        except:\n            pass\n    return params", "response": "Extracts the parameters from a Cypher query"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nexecutes a Cypher query and returns raw data a Pandas DataFrame or a NetworkX graph.", "response": "def run(query, params=None, config=None, conn=None, **kwargs):\n    \"\"\"Executes a query and depending on the options of the extensions will\n    return raw data, a ``ResultSet``, a Pandas ``DataFrame`` or a\n    NetworkX graph.\n\n    :param query: string with the Cypher query\n    :param params: dictionary with parameters for the query (default=``None``)\n    :param config: Configurable or NamedTuple with extra IPython configuration\n                   details. If ``None``, a new object will be created\n                   (defaults=``None``)\n    :param conn: connection dictionary or string for the Neo4j backend.\n                 If ``None``, a new connection will be created\n                 (default=``None``)\n    :param **kwargs: Any of the cell configuration options.\n    \"\"\"\n    if params is None:\n        params = {}\n    if conn is None:\n        conn = Connection.get(DEFAULT_CONFIGURABLE[\"uri\"])\n    elif isinstance(conn, string_types):\n        conn = Connection.get(conn)\n    if config is None:\n        default_config = DEFAULT_CONFIGURABLE.copy()\n        kwargs.update(default_config)\n        config = DefaultConfigurable(**kwargs)\n    if query.strip():\n        # TODO: Handle multiple queries\n        params = extract_params_from_query(query, params)\n        result = conn.session.query(query, params,\n                                    data_contents=config.data_contents)\n        if config.feedback:\n            print(interpret_stats(result))\n        resultset = ResultSet(result, query, config)\n        if config.auto_pandas:\n            return resultset.get_dataframe()\n        elif config.auto_networkx:\n            graph = resultset.get_graph()\n            resultset.draw()\n            return graph\n        else:\n            return resultset  # returning only last result, intentionally\n    else:\n        return 'Connected: %s' % conn.name"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_dataframe(self):\n        if pd is None:\n            raise ImportError(\"Try installing Pandas first.\")\n        frame = pd.DataFrame(self[:], columns=(self and self.keys) or [])\n        return frame", "response": "Returns a Pandas DataFrame instance built from the result set."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_graph(self, directed=True):\n        if nx is None:\n            raise ImportError(\"Try installing NetworkX first.\")\n        if directed:\n            graph = nx.MultiDiGraph()\n        else:\n            graph = nx.MultiGraph()\n        for item in self._results.graph:\n            for node in item['nodes']:\n                properties = copy.deepcopy(node['properties'])\n                properties['labels'] = node['labels']\n                graph.add_node(node['id'], **properties)\n            for rel in item['relationships']:\n                properties = copy.deepcopy(rel['properties'])\n                properties.update(\n                    id=rel['id'],\n                    type=rel['type']\n                )\n                graph.add_edge(rel['startNode'], rel['endNode'],\n                               key=rel.get('type'), **properties)\n        return graph", "response": "Returns a NetworkX Multi - Graph instance built from the result set."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndraw a multi - graph instance of the current object.", "response": "def draw(self, directed=True, layout=\"spring\",\n             node_label_attr=None, show_node_labels=True,\n             edge_label_attr=None, show_edge_labels=True,\n             node_size=1600, node_color='blue', node_alpha=0.3,\n             node_text_size=12,\n             edge_color='blue', edge_alpha=0.3, edge_tickness=1,\n             edge_text_pos=0.3,\n             text_font='sans-serif', ax=None):\n        \"\"\"Plot of a NetworkX multi-graph instance\n\n        :param directed: boolean, optional (default=`True`).\n            Whether to return a directed graph or not.\n        :param layout: string, optional (default=`\"spring\"`).\n            Layout to apply. Any of the possible NetworkX layouts will work:\n            ``'circular_layout'``, ``'random_layout'``, ``'shell_layout'``,\n            ``'spring_layout'``, ``'spectral_layout'``,\n            or ``'fruchterman_reingold_layout'``.\n        :param node_label_attr: string, optional (default=`None`).\n            Attribute of the nodes that has to be used as the label.\n        :param show_node_labels: boolean, optional (default=`True`).\n            Whether to show or not the labels of the nodes.\n        :param edge_label_attr: boolean, optional (default=`None`).\n            Attribute of the edges that has to be used as the label.\n        :param show_edge_labels: . optional (default=`True`).\n            Whether to show or not the labels of the edges.\n        :param node_size: integer, optional (default=`1600`).\n            Desired size for nodes.\n        :param node_color: color string, or array of floats, (default=`'blue'`)\n            Node color. Can be a single color format string, or a sequence of\n            colors with the same length as nodelist. If numeric values are\n            specified they will be mapped to colors using the ``cmap`` and\n            ``vmin``, ``vmax`` parameters. See ``matplotlib.scatter`` for more\n            details.\n        :param node_alpha: float, optional (default=`0.3`).\n            Between 0 and 1 for transparency of nodes.\n        :param node_text_size: integer, optional (default=`12`).\n            Size of the node text.\n        :param edge_color: color string, or array of floats (default=`'blue'`)\n            Edge color. Can be a single color format string, or a sequence of\n            colors with the same length as edgelist. If numeric values are\n            specified they will be mapped to colors using the ``edge_cmap`` and\n            ``edge_vmin``, ``edge_vmax`` parameters.\n        :param edge_alpha: float, optional (default=`0.3`)\n            Transparency for thee edges.\n        :param edge_tickness: float or integer, optional (default=`1`).\n            Thickness of the lines drawn for the edges.\n        :param edge_text_pos: . Default to optional (d0)=\n        :param text_font: . Default to optional (default=`'sans-serif'`).\n        :param ax: ``matplotlib.Figure``, optional (default=`None`).\n            A ``matplotlib.Figure`` to use when rendering the graph. If `None`,\n            a new object is created and returned.----\n\n        :return: a ``matplotlib.Figure`` with the graph rendered.\n        \"\"\"\n        graph = self.get_graph(directed=directed)\n        pos = getattr(nx, \"{}_layout\".format(layout))(graph)\n        node_labels = {}\n        edge_labels = {}\n        node_colors = set()\n        if show_node_labels:\n            for node, props in graph.nodes(data=True):\n                labels = props.pop('labels', [])\n                for label in labels:\n                    node_colors.add(label)\n                if node_label_attr is None:\n                    node_labels[node] = \"$:{}$\\n{}\".format(\n                        \":\".join(labels),\n                        next(iter(props.values())) if props else \"\",\n                    )\n                else:\n                    props_list = [\"{}: {}\".format(k, v)\n                                  for k, v in props.items()]\n                    node_labels[node] = \"$:{}$\\n{}\".format(\n                        \":\".join(labels), \"\\n\".join(props_list)\n                    )\n        node_color = []\n        node_colors = list(node_colors)\n        legend_colors = []\n        colors = list(plt.matplotlib.colors.ColorConverter().cache.items())[2:]\n        for _, color_rgb in colors[:len(node_colors)]:\n            node_color.append(color_rgb)\n            legend_colors.append(color_rgb)\n        if show_edge_labels:\n            for start, end, props in graph.edges(data=True):\n                if edge_label_attr is None:\n                    edge_label = props.get(\"type\", '')\n                else:\n                    edge_label = props.get(edge_label_attr, '')\n                edge_labels[(start, end)] = edge_label\n        if not ax:\n            fig = plt.figure()\n            ax = fig.add_subplot(111)\n        nodes = nx.draw_networkx_nodes(\n            graph, pos=pos, node_color=node_color,\n            node_size=node_size, alpha=node_alpha,\n            ax=ax\n        )\n        nx.draw_networkx_labels(\n            graph, pos=pos, labels=node_labels,\n            font_size=node_text_size,\n            font_family=text_font,\n            ax=ax\n        )\n        nx.draw_networkx_edges(\n            graph, pos=pos, width=edge_tickness,\n            alpha=edge_alpha, edge_color=edge_color,\n            ax=ax\n        )\n        nx.draw_networkx_edge_labels(\n            graph, pos=pos, edge_labels=edge_labels,\n            ax=ax\n        )\n        ax.legend([plt.Line2D([0], [0], linestyle=\"none\", marker=\"o\",\n                              alpha=node_alpha,\n                              markersize=10, markerfacecolor=color)\n                  for color in legend_colors],\n                  node_colors, loc=(-0.25, 1), numpoints=1, frameon=False)\n        ax.set_axis_off()\n        return graph, ax, nodes"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef pie(self, key_word_sep=\" \", title=None, **kwargs):\n        if not plt:\n            raise ImportError(\"Try installing matplotlib first.\")\n        self.guess_pie_columns(xlabel_sep=key_word_sep)\n        pie = plt.pie(self.ys[0], labels=self.xlabels, **kwargs)\n        plt.title(title or self.ys[0].name)\n        return pie", "response": "Generates a pylab pie chart from the result set."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef plot(self, title=None, **kwargs):\n        if not plt:\n            raise ImportError(\"Try installing matplotlib first.\")\n        self.guess_plot_columns()\n        self.x = self.x or range(len(self.ys[0]))\n        coords = reduce(operator.add, [(self.x, y) for y in self.ys])\n        plot = plt.plot(*coords, **kwargs)\n        if hasattr(self.x, 'name'):\n            plt.xlabel(self.x.name)\n        ylabel = \", \".join(y.name for y in self.ys)\n        plt.title(title or ylabel)\n        plt.ylabel(ylabel)\n        return plot", "response": "Generates a pylab plot from the result set."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates a pylab bar plot from the result set.", "response": "def bar(self, key_word_sep=\" \", title=None, **kwargs):\n        \"\"\"Generates a pylab bar plot from the result set.\n\n        ``matplotlib`` must be installed, and in an\n        IPython Notebook, inlining must be on::\n\n            %%matplotlib inline\n\n        The last quantitative column is taken as the Y values;\n        all other columns are combined to label the X axis.\n\n        :param title: plot title, defaults to names of Y value columns\n        :param key_word_sep: string used to separate column values\n                             from each other in labels\n\n        Any additional keyword arguments will be passsed\n        through to ``matplotlib.pylab.bar``.\n        \"\"\"\n        if not plt:\n            raise ImportError(\"Try installing matplotlib first.\")\n        self.guess_pie_columns(xlabel_sep=key_word_sep)\n        plot = plt.bar(range(len(self.ys[0])), self.ys[0], **kwargs)\n        if self.xlabels:\n            plt.xticks(range(len(self.xlabels)), self.xlabels,\n                       rotation=45)\n        plt.xlabel(self.xlabel)\n        plt.ylabel(self.ys[0].name)\n        return plot"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates a CSV file from the table.", "response": "def csv(self, filename=None, **format_params):\n        \"\"\"Generates results in comma-separated form.  Write to ``filename``\n        if given. Any other parameter will be passed on to ``csv.writer``.\n\n        :param filename: if given, the CSV will be written to filename.\n\n        Any additional keyword arguments will be passsed\n        through to ``csv.writer``.\n        \"\"\"\n        if not self.pretty:\n            return None  # no results\n        if filename:\n            outfile = open(filename, 'w')\n        else:\n            outfile = StringIO()\n        writer = UnicodeWriter(outfile, **format_params)\n        writer.writerow(self.field_names)\n        for row in self:\n            writer.writerow(row)\n        if filename:\n            outfile.close()\n            return CsvResultDescriptor(filename)\n        else:\n            return outfile.getvalue()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding is_rendered to the context and the widget s context data.", "response": "def get_context_data(self, **kwargs):\n        \"\"\"\n        Adds ``is_rendered`` to the context and the widget's context data.\n\n        ``is_rendered`` signals that the AJAX view has been called and that\n        we are displaying the full widget now. When ``is_rendered`` is not\n        found in the widget template it means that we are seeing the first\n        page load and all widgets still have to get their real data from\n        this AJAX view.\n\n        \"\"\"\n        ctx = super(RenderWidgetMixin, self).get_context_data(**kwargs)\n        ctx.update({\n            'is_rendered': True,\n            'widget': self.widget,\n        })\n        ctx.update(self.widget.get_context_data())\n        return ctx"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_widgets_sorted(self):\n        result = []\n        for widget_name, widget in self.get_widgets().items():\n            result.append((widget_name, widget, widget.position))\n        result.sort(key=lambda x: x[2])\n        return result", "response": "Returns the widgets sorted by position."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning all widgets that need an update.", "response": "def get_widgets_that_need_update(self):\n        \"\"\"\n        Returns all widgets that need an update.\n\n        This should be scheduled every minute via crontab.\n\n        \"\"\"\n        result = []\n        for widget_name, widget in self.get_widgets().items():\n            if widget.should_update():\n                result.append(widget)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nregisters a widget with the given class.", "response": "def register_widget(self, widget_cls, **widget_kwargs):\n        \"\"\"\n        Registers the given widget.\n\n        Widgets must inherit ``DashboardWidgetBase`` and you cannot register\n        the same widget twice.\n\n        :widget_cls: A class that inherits ``DashboardWidgetBase``.\n\n        \"\"\"\n        if not issubclass(widget_cls, DashboardWidgetBase):\n            raise ImproperlyConfigured(\n                'DashboardWidgets must be subclasses of DashboardWidgetBase,'\n                ' {0} is not.'.format(widget_cls))\n\n        widget = widget_cls(**widget_kwargs)\n        widget_name = widget.get_name()\n        if widget_name in self.widgets:\n            raise WidgetAlreadyRegistered(\n                'Cannot register {0}, a plugin with this name {1} is already '\n                'registered.'.format(widget_cls, widget_name))\n\n        self.widgets[widget_name] = widget"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef unregister_widget(self, widget_cls):\n        if widget_cls.__name__ in self.widgets:\n            del self.widgets[widget_cls().get_name()]", "response": "Unregisters the given widget."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_last_update(self):\n        instance, created = \\\n            models.DashboardWidgetLastUpdate.objects.get_or_create(\n                widget_name=self.get_name())\n        return instance", "response": "Gets or creates the last update object for this widget."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the setting for this widget from the database.", "response": "def get_setting(self, setting_name, default=None):\n        \"\"\"\n        Returns the setting for this widget from the database.\n\n        :setting_name: The name of the setting.\n        :default: Optional default value if the setting cannot be found.\n\n        \"\"\"\n        try:\n            setting = models.DashboardWidgetSettings.objects.get(\n                widget_name=self.get_name(),\n                setting_name=setting_name)\n        except models.DashboardWidgetSettings.DoesNotExist:\n            setting = default\n        return setting"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef save_setting(self, setting_name, value):\n        setting = self.get_setting(setting_name)\n        if setting is None:\n            setting = models.DashboardWidgetSettings.objects.create(\n                widget_name=self.get_name(),\n                setting_name=setting_name,\n                value=value)\n        setting.value = value\n        setting.save()\n        return setting", "response": "Saves the setting value into the database."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if an update is needed.", "response": "def should_update(self):\n        \"\"\"\n        Checks if an update is needed.\n\n        Checks against ``self.update_interval`` and this widgets\n        ``DashboardWidgetLastUpdate`` instance if an update is overdue.\n\n        This should be called by\n        ``DashboardWidgetPool.get_widgets_that_need_update()``, which in turn\n        should be called by an admin command which should be scheduled every\n        minute via crontab.\n\n        \"\"\"\n        last_update = self.get_last_update()\n        time_since = now() - last_update.last_update\n        if time_since.seconds < self.update_interval:\n            return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getCityDetails(self, **kwargs):\n        params = {}\n        available_keys = [\"q\", \"lat\", \"lon\", \"city_ids\", \"count\"]\n        for key in available_keys:\n            if key in kwargs:\n                params[key] = kwargs[key]\n        cities = self.api.get(\"/cities\", params)\n        return cities", "response": "Get the details of a city in a Zomato city."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn Zomato Restaurant Collections in a city", "response": "def getCollectionsViaCityId(self, city_id, **kwargs):\n        \"\"\"\n        :param city_id: id of the city for which collections are needed\n        :param lat: latitude\n        :param lon: longitude\n        :param count: number of max results to display\n        Returns Zomato Restaurant Collections in a City. The location/City input can be provided in the following ways\n         - Using Zomato City ID\n         - Using coordinates of any location within a city\n         - List of all restaurants listed in any particular Zomato Collection can be obtained using the '/search' API with Collection ID and Zomato City ID as the input\n        \"\"\"\n        params = {\"city_id\": city_id}\n        optional_params = [\"lat\", \"lon\", \"count\"]\n\n        for key in optional_params:\n            if key in kwargs:\n                params[key] = kwargs[key]\n        collections = self.api.get(\"/collections\", params)\n        return collections"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a list of all restaurants in a given city.", "response": "def getEstablishments(self, city_id, **kwargs):\n        \"\"\"\n        :param city_id: id of the city for which collections are needed\n        :param lat: latitude\n        :param lon: longitude\n        Get a list of restaurant types in a city. The location/City input can be provided in the following ways\n        - Using Zomato City ID\n        - Using coordinates of any location within a city\n        List of all restaurants categorized under a particular restaurant type can obtained using\n        /Search API with Establishment ID and location details as inputs\n        \"\"\"\n        params = {\"city_id\": city_id}\n        optional_params = [\"lat\", \"lon\"]\n\n        for key in optional_params:\n            if key in kwargs:\n                params[key] = kwargs[key]\n        establishments = self.api.get(\"/establishments\", params)\n        return establishments"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the popular cuisines and nearby restaurants around the given coordinates.", "response": "def getByGeocode(self, lat, lon):\n        \"\"\"\n        :param lat: latitude\n        :param lon: longitude\n        Get Foodie and Nightlife Index, list of popular cuisines and nearby restaurants around the given coordinates\n        \"\"\"\n        params = {\"lat\": lat, \"lon\": lon}\n        response = self.api.get(\"/geocode\", params)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the location details for a given entity", "response": "def getLocationDetails(self, entity_id, entity_type):\n        \"\"\"\n        :param entity_id: location id obtained from locations api\n        :param entity_type: location type obtained from locations api\n        :return:\n        Get Foodie Index, Nightlife Index, Top Cuisines and Best rated restaurants in a given location\n        \"\"\"\n        params = {\"entity_id\": entity_id, \"entity_type\": entity_type}\n        location_details = self.api.get(\"/location_details\", params)\n        return location_details"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsearch for Zomato locations by keyword.", "response": "def getLocations(self, query, **kwargs):\n        \"\"\"\n        :param query: suggestion for location name\n        :param lat: latitude\n        :param lon: longitude\n        :param count: number of max results to display\n        :return: json response\n        Search for Zomato locations by keyword. Provide coordinates to get better search results\n        \"\"\"\n        params = {\"query\": query}\n        optional_params = [\"lat\", \"lon\", \"count\"]\n\n        for key in optional_params:\n            if key in kwargs:\n                params[key] = kwargs[key]\n        locations = self.api.get(\"/locations\", params)\n        return locations"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getDailyMenu(self, restaurant_id):\n        params = {\"res_id\": restaurant_id}\n        daily_menu = self.api.get(\"/dailymenu\", params)\n        return daily_menu", "response": "Get daily menu using Zomato restaurant ID."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget detailed restaurant details", "response": "def getRestaurantDetails(self, restaurant_id):\n        \"\"\"\n        :param restaurant_id: id of restaurant whose details are requested\n        :return: json response\n        Get detailed restaurant information using Zomato restaurant ID.\n        Partner Access is required to access photos and reviews.\n        \"\"\"\n        params = {\"res_id\": restaurant_id}\n        restaurant_details = self.api.get(\"/restaurant\", params)\n        return restaurant_details"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the restaurant reviews using the Zomato restaurant ID", "response": "def getRestaurantReviews(self, restaurant_id, **kwargs):\n        \"\"\"\n        :param restaurant_id: id of restaurant whose details are requested\n        :param start: fetch results after this offset\n        :param count: max number of results to retrieve\n        :return: json response\n        Get restaurant reviews using the Zomato restaurant ID\n        \"\"\"\n        params = {\"res_id\": restaurant_id}\n        optional_params = [\"start\", \"count\"]\n\n        for key in optional_params:\n            if key in kwargs:\n                params[key] = kwargs[key]\n        reviews = self.api.get(\"/reviews\", params)\n        return reviews"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsearches for restaurants in a Zomato location.", "response": "def search(self, **kwargs):\n        \"\"\"\n        :param entity_id: location id\n        :param entity_type: location type (city, subzone, zone, lanmark, metro , group)\n        :param q: search keyword\n        :param start: fetch results after offset\n        :param count: max number of results to display\n        :param lat: latitude\n        :param lon: longitude\n        :param radius: radius around (lat,lon); to define search area, defined in meters(M)\n        :param cuisines: list of cuisine id's separated by comma\n        :param establishment_type: estblishment id obtained from establishments call\n        :param collection_id: collection id obtained from collections call\n        :param category: category ids obtained from categories call\n        :param sort: sort restaurants by (cost, rating, real_distance)\n        :param order: used with 'sort' parameter to define ascending / descending\n        :return: json response\n        The location input can be specified using Zomato location ID or coordinates. Cuisine / Establishment /\n        Collection IDs can be obtained from respective api calls.\n\n        Partner Access is required to access photos and reviews.\n\n        Examples:\n        - To search for 'Italian' restaurants in 'Manhattan, New York City',\n        set cuisines = 55, entity_id = 94741 and entity_type = zone\n        - To search for 'cafes' in 'Manhattan, New York City',\n        set establishment_type = 1, entity_type = zone and entity_id = 94741\n        - Get list of all restaurants in 'Trending this Week' collection in 'New York City' by using\n        entity_id = 280, entity_type = city and collection_id = 1\n        \"\"\"\n        params = {}\n        available_params = [\n            \"entity_id\", \"entity_type\", \"q\", \"start\",\n            \"count\", \"lat\", \"lon\", \"radius\", \"cuisines\",\n            \"establishment_type\", \"collection_id\",\n            \"category\", \"sort\", \"order\"]\n\n        for key in available_params:\n            if key in kwargs:\n                params[key] = kwargs[key]\n        results = self.api.get(\"/search\", params)\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef array(a, context=None, axis=(0,), dtype=None, npartitions=None):\n        if dtype is None:\n            arry = asarray(a)\n            dtype = arry.dtype\n        else:\n            arry = asarray(a, dtype)\n        shape = arry.shape\n        ndim = len(shape)\n\n        # handle the axes specification and transpose if necessary\n        axes = ConstructSpark._format_axes(axis, arry.shape)\n        key_axes, value_axes = get_kv_axes(arry.shape, axes)\n        permutation = key_axes + value_axes\n        arry = arry.transpose(*permutation)\n        split = len(axes)\n\n        if split < 1:\n            raise ValueError(\"split axis must be greater than 0, got %g\" % split)\n        if split > len(shape):\n            raise ValueError(\"split axis must not exceed number of axes %g, got %g\" % (ndim, split))\n\n        key_shape = shape[:split]\n        val_shape = shape[split:]\n\n        keys = zip(*unravel_index(arange(0, int(prod(key_shape))), key_shape))\n        vals = arry.reshape((prod(key_shape),) + val_shape)\n\n        rdd = context.parallelize(zip(keys, vals), npartitions)\n        return BoltArraySpark(rdd, shape=shape, split=split, dtype=dtype)", "response": "Create a spark bolt array from an array - like object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ones(shape, context=None, axis=(0,), dtype=float64, npartitions=None):\n        from numpy import ones\n        return ConstructSpark._wrap(ones, shape, context, axis, dtype, npartitions)", "response": "Construct a spark bolt array of ones."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconcatenates two bolt arrays together along a given axis.", "response": "def concatenate(arrays, axis=0):\n        \"\"\"\n        Join two bolt arrays together, at least one of which is in spark.\n\n        Parameters\n        ----------\n        arrays : tuple\n            A pair of arrays. At least one must be a spark array,\n            the other can be a local bolt array, a local numpy array,\n            or an array-like.\n\n        axis : int, optional, default=0\n            The axis along which the arrays will be joined.\n\n        Returns\n        -------\n        BoltArraySpark\n        \"\"\"\n        if not isinstance(arrays, tuple):\n            raise ValueError(\"data type not understood\")\n        if not len(arrays) == 2:\n            raise NotImplementedError(\"spark concatenation only supports two arrays\")\n\n        first, second = arrays\n        if isinstance(first, BoltArraySpark):\n            return first.concatenate(second, axis)\n        elif isinstance(second, BoltArraySpark):\n            first = ConstructSpark.array(first, second._rdd.context)\n            return first.concatenate(second, axis)\n        else:\n            raise ValueError(\"at least one array must be a spark bolt array\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking that the arguments are consistent with Spark array construction.", "response": "def _argcheck(*args, **kwargs):\n        \"\"\"\n        Check that arguments are consistent with spark array construction.\n\n        Conditions are:\n        (1) a positional argument is a SparkContext\n        (2) keyword arg 'context' is a SparkContext\n        (3) an argument is a BoltArraySpark, or\n        (4) an argument is a nested list containing a BoltArraySpark\n        \"\"\"\n        try:\n            from pyspark import SparkContext\n        except ImportError:\n            return False\n\n        cond1 = any([isinstance(arg, SparkContext) for arg in args])\n        cond2 = isinstance(kwargs.get('context', None), SparkContext)\n        cond3 = any([isinstance(arg, BoltArraySpark) for arg in args])\n        cond4 = any([any([isinstance(sub, BoltArraySpark) for sub in arg])\n                     if isinstance(arg, (tuple, list)) else False for arg in args])\n        return cond1 or cond2 or cond3 or cond4"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _format_axes(axes, shape):\n        if isinstance(axes, int):\n            axes = (axes,)\n        elif isinstance(axes, list) or hasattr(axes, '__iter__'):\n            axes = tuple(axes)\n        if not isinstance(axes, tuple):\n            raise ValueError(\"axes argument %s in the constructor not specified correctly\" % str(axes))\n        if min(axes) < 0 or max(axes) > len(shape) - 1:\n            raise ValueError(\"invalid key axes %s given shape %s\" % (str(axes), str(shape)))\n        return axes", "response": "Format target axes given an array shape"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _wrap(func, shape, context=None, axis=(0,), dtype=None, npartitions=None):\n        if isinstance(shape, int):\n            shape = (shape,)\n        key_shape, value_shape = get_kv_shape(shape, ConstructSpark._format_axes(axis, shape))\n        split = len(key_shape)\n\n        # make the keys\n        rdd = context.parallelize(list(product(*[arange(x) for x in key_shape])), npartitions)\n\n        # use a map to make the arrays in parallel\n        rdd = rdd.map(lambda x: (x, func(value_shape, dtype, order='C')))\n        return BoltArraySpark(rdd, shape=shape, split=split, dtype=dtype)", "response": "Wrap an existing numpy constructor in a parallelized construction\n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nalign the local bolt array so that the specified axes for iteration are in the keys.", "response": "def _align(self, axes, key_shape=None):\n        \"\"\"\n        Align local bolt array so that axes for iteration are in the keys.\n\n        This operation is applied before most functional operators.\n        It ensures that the specified axes are valid, and might transpose/reshape\n        the underlying array so that the functional operators can be applied\n        over the correct records.\n\n        Parameters\n        ----------\n        axes: tuple[int]\n            One or more axes that will be iterated over by a functional operator\n\n        Returns\n        -------\n        BoltArrayLocal\n        \"\"\"\n\n        # ensure that the key axes are valid for an ndarray of this shape\n        inshape(self.shape, axes)\n\n        # compute the set of dimensions/axes that will be used to reshape\n        remaining = [dim for dim in range(len(self.shape)) if dim not in axes]\n        key_shape = key_shape if key_shape else [self.shape[axis] for axis in axes]\n        remaining_shape = [self.shape[axis] for axis in remaining]\n        linearized_shape = [prod(key_shape)] + remaining_shape\n\n        # compute the transpose permutation\n        transpose_order = axes + remaining\n\n        # transpose the array so that the keys being mapped over come first, then linearize keys\n        reshaped = self.transpose(*transpose_order).reshape(*linearized_shape)\n\n        return reshaped"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a new BoltArrayLocal containing only the entries in the log entry table that satisfy a function along a given axis.", "response": "def filter(self, func, axis=(0,)):\n        \"\"\"\n        Filter array along an axis.\n\n        Applies a function which should evaluate to boolean,\n        along a single axis or multiple axes. Array will be\n        aligned so that the desired set of axes are in the\n        keys, which may require a transpose/reshape.\n\n        Parameters\n        ----------\n        func : function\n            Function to apply, should return boolean\n\n        axis : tuple or int, optional, default=(0,)\n            Axis or multiple axes to filter along.\n\n        Returns\n        -------\n        BoltArrayLocal\n        \"\"\"\n        axes = sorted(tupleize(axis))\n        reshaped = self._align(axes)\n\n        filtered = asarray(list(filter(func, reshaped)))\n\n        return self._constructor(filtered)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef map(self, func, axis=(0,)):\n        axes = sorted(tupleize(axis))\n        key_shape = [self.shape[axis] for axis in axes]\n        reshaped = self._align(axes, key_shape=key_shape)\n\n        mapped = asarray(list(map(func, reshaped)))\n        elem_shape = mapped[0].shape\n\n        # invert the previous reshape operation, using the shape of the map result\n        linearized_shape_inv = key_shape + list(elem_shape)\n        reordered = mapped.reshape(*linearized_shape_inv)\n\n        return self._constructor(reordered)", "response": "Applies a function across an axis and returns a BoltArrayLocal object with the resulting array."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreduce the array along an axis.", "response": "def reduce(self, func, axis=0):\n        \"\"\"\n        Reduce an array along an axis.\n\n        Applies an associative/commutative function of two arguments\n        cumulatively to all arrays along an axis. Array will be aligned\n        so that the desired set of axes are in the keys, which may\n        require a transpose/reshape.\n\n        Parameters\n        ----------\n        func : function\n            Function of two arrays that returns a single array\n\n        axis : tuple or int, optional, default=(0,)\n            Axis or multiple axes to reduce along.\n\n        Returns\n        -------\n        BoltArrayLocal\n        \"\"\"\n        axes = sorted(tupleize(axis))\n\n        # if the function is a ufunc, it can automatically handle reducing over multiple axes\n        if isinstance(func, ufunc):\n            inshape(self.shape, axes)\n            reduced = func.reduce(self, axis=tuple(axes))\n        else:\n            reshaped = self._align(axes)\n            reduced = reduce(func, reshaped)\n\n        new_array = self._constructor(reduced)\n\n        # ensure that the shape of the reduced array is valid\n        expected_shape = [self.shape[i] for i in range(len(self.shape)) if i not in axes]\n        if new_array.shape != tuple(expected_shape):\n            raise ValueError(\"reduce did not yield a BoltArray with valid dimensions\")\n\n        return new_array"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconcatenates this array with another array.", "response": "def concatenate(self, arry, axis=0):\n        \"\"\"\n        Join this array with another array.\n\n        Paramters\n        ---------\n        arry : ndarray or BoltArrayLocal\n            Another array to concatenate with\n\n        axis : int, optional, default=0\n            The axis along which arrays will be joined.\n\n        Returns\n        -------\n        BoltArrayLocal\n        \"\"\"\n        if isinstance(arry, ndarray):\n            from bolt import concatenate\n            return concatenate((self, arry), axis)\n        else:\n            raise ValueError(\"other must be local array, got %s\" % type(arry))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert a BoltArrayLocal into a BoltArraySpark", "response": "def tospark(self, sc, axis=0):\n        \"\"\"\n        Converts a BoltArrayLocal into a BoltArraySpark\n\n        Parameters\n        ----------\n        sc : SparkContext\n            The SparkContext which will be used to create the BoltArraySpark\n\n        axis : tuple or int, optional, default=0\n            The axis (or axes) across which this array will be parallelized\n\n        Returns\n        -------\n        BoltArraySpark\n        \"\"\"\n        from bolt import array\n        return array(self.toarray(), sc, axis=axis)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef tordd(self, sc, axis=0):\n        from bolt import array\n        return array(self.toarray(), sc, axis=axis).tordd()", "response": "Converts a BoltArrayLocal into an RDD of the Topology s unique keys."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmake an intermediate RDD where all records are combined into a list of keys and larger ndarray along a new 0th dimension.", "response": "def stack(self, size):\n        \"\"\"\n        Make an intermediate RDD where all records are combined into a\n        list of keys and larger ndarray along a new 0th dimension.\n        \"\"\"\n        def tostacks(partition):\n            keys = []\n            arrs = []\n            for key, arr in partition:\n                keys.append(key)\n                arrs.append(arr)\n                if size and 0 <= size <= len(keys):\n                    yield (keys, asarray(arrs))\n                    keys, arrs = [], []\n            if keys:\n                yield (keys, asarray(arrs))\n\n        rdd = self._rdd.mapPartitions(tostacks)\n        return self._constructor(rdd).__finalize__(self)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef map(self, func):\n        vshape = self.shape[self.split:]\n        x = self._rdd.values().first()\n        if x.shape == vshape:\n            a, b = asarray([x]), asarray([x, x])\n        else:\n            a, b = x, concatenate((x, x))\n\n        try:\n            atest = func(a)\n            btest = func(b)\n        except Exception as e:\n            raise RuntimeError(\"Error evaluating function on test array, got error:\\n %s\" % e)\n\n        if not (isinstance(atest, ndarray) and isinstance(btest, ndarray)):\n            raise ValueError(\"Function must return ndarray\")\n\n        # different shapes map to the same new shape\n        elif atest.shape == btest.shape:\n            if self._rekeyed is True:\n                # we've already rekeyed\n                rdd = self._rdd.map(lambda kv: (kv[0], func(kv[1])))\n                shape = (self.shape[0],) + atest.shape\n            else:\n                # do the rekeying\n                count, rdd = zip_with_index(self._rdd.values())\n                rdd = rdd.map(lambda kv: ((kv[1],), func(kv[0])))\n                shape = (count,) + atest.shape\n            split = 1\n            rekeyed = True\n\n        # different shapes stay different (along the first dimension)\n        elif atest.shape[0] == a.shape[0] and btest.shape[0] == b.shape[0]:\n            shape = self.shape[0:self.split] + atest.shape[1:]\n            split = self.split\n            rdd = self._rdd.map(lambda kv: (kv[0], func(kv[1])))\n            rekeyed = self._rekeyed\n\n        else:\n            raise ValueError(\"Cannot infer effect of function on shape\")\n\n        return self._constructor(rdd, rekeyed=rekeyed, shape=shape, split=split).__finalize__(self)", "response": "Applies a function on each value in the intermediate RDD."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsplits the distributed array into chunks.", "response": "def _chunk(self, size=\"150\", axis=None, padding=None):\n        \"\"\"\n        Split values of distributed array into chunks.\n\n        Transforms an underlying pair RDD of (key, value) into\n        records of the form: (key, chunk id), (chunked value).\n        Here, chunk id is a tuple identifying the chunk and\n        chunked value is a subset of the data from each original value,\n        that has been divided along the specified dimensions.\n\n        Parameters\n        ----------\n        size : str or tuple or int\n            If str, the average size (in KB) of the chunks in all value dimensions.\n            If int or tuple, an explicit specification of the number chunks in\n            each value dimension.\n\n        axis : tuple, optional, default=None\n            One or more axes to estimate chunks for, if provided any\n            other axes will use one chunk.\n\n        padding: tuple or int, default = None\n            Number of elements per dimension that will overlap with the adjacent chunk.\n            If a tuple, specifies padding along each chunked dimension; if a int, same\n            padding will be applied to all chunked dimensions.\n        \"\"\"\n        if self.split == len(self.shape) and padding is None:\n            self._rdd = self._rdd.map(lambda kv: (kv[0]+(0,), array(kv[1], ndmin=1)))\n            self._shape = self._shape + (1,)\n            self._plan = (1,)\n            self._padding = array([0])\n            return self\n\n        rdd = self._rdd\n        self._plan, self._padding = self.getplan(size, axis, padding)\n\n        if any([x + y > z for x, y, z in zip(self.plan, self.padding, self.vshape)]):\n            raise ValueError(\"Chunk sizes %s plus padding sizes %s cannot exceed value dimensions %s along any axis\"\n                             % (tuple(self.plan), tuple(self.padding), tuple(self.vshape)))\n\n        if any([x > y for x, y in zip(self.padding, self.plan)]):\n            raise ValueError(\"Padding sizes %s cannot exceed chunk sizes %s along any axis\"\n                             % (tuple(self.padding), tuple(self.plan)))\n\n        slices = self.getslices(self.plan, self.padding, self.vshape)\n        labels = list(product(*[list(enumerate(s)) for s in slices]))\n        scheme = [list(zip(*s)) for s in labels]\n\n        def _chunk(record):\n            k, v = record[0], record[1]\n            for (chk, slc) in scheme:\n                if type(k) is int:\n                    k = (k,)\n                yield k + chk, v[slc]\n\n        rdd = rdd.flatMap(_chunk)\n        return self._constructor(rdd, shape=self.shape, split=self.split,\n                                 dtype=self.dtype, plan=self.plan, padding=self.padding, ordered=self._ordered)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting a chunked array back into a full array with ( key value ) pairs where key is a tuple of indices and value is an ndarray.", "response": "def unchunk(self):\n        \"\"\"\n        Convert a chunked array back into a full array with (key,value) pairs\n        where key is a tuple of indices, and value is an ndarray.\n        \"\"\"\n        plan, padding, vshape, split = self.plan, self.padding, self.vshape, self.split\n        nchunks = self.getnumber(plan, vshape)\n        full_shape = concatenate((nchunks, plan))\n        n = len(vshape)\n        perm = concatenate(list(zip(range(n), range(n, 2*n))))\n\n        if self.uniform:\n            def _unchunk(it):\n                ordered = sorted(it, key=lambda kv: kv[0][split:])\n                keys, values = zip(*ordered)\n                yield keys[0][:split], asarray(values).reshape(full_shape).transpose(perm).reshape(vshape)\n        else:\n            def _unchunk(it):\n                ordered = sorted(it, key=lambda kv: kv[0][split:])\n                keys, values = zip(*ordered)\n                k_chks = [k[split:] for k in keys]\n                arr = empty(nchunks, dtype='object')\n                for (i, d) in zip(k_chks, values):\n                    arr[i] = d\n                yield keys[0][:split], allstack(arr.tolist())\n\n        # remove padding\n        if self.padded:\n            removepad = self.removepad\n            rdd = self._rdd.map(lambda kv: (kv[0], removepad(kv[0][split:], kv[1], nchunks, padding, axes=range(n))))\n        else:\n            rdd = self._rdd\n\n        # skip partitionBy if there is not actually any chunking\n        if array_equal(self.plan, self.vshape):\n           rdd = rdd.map(lambda kv: (kv[0][:split], kv[1]))\n           ordered = self._ordered\n        else:\n            ranges = self.kshape\n            npartitions = int(prod(ranges))\n            if len(self.kshape) == 0:\n                partitioner = lambda k: 0\n            else:\n                partitioner = lambda k: ravel_multi_index(k[:split], ranges)\n            rdd = rdd.partitionBy(numPartitions=npartitions, partitionFunc=partitioner).mapPartitions(_unchunk)\n            ordered = True\n\n        if array_equal(self.vshape, [1]):\n            rdd = rdd.mapValues(lambda v: squeeze(v))\n            newshape = self.shape[:-1]\n        else:\n            newshape = self.shape\n\n        return BoltArraySpark(rdd, shape=newshape, split=self._split,\n                              dtype=self.dtype, ordered=ordered)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a new ChunkedArray containing the keys and values for the specified axes.", "response": "def keys_to_values(self, axes, size=None):\n        \"\"\"\n        Move indices in the keys into the values.\n\n        Padding on these new value-dimensions is not currently supported and is set to 0.\n\n        Parameters\n        ----------\n        axes : tuple\n            Axes from keys to move to values.\n\n        size : tuple, optional, default=None\n            Size of chunks for the values along the new dimensions.\n            If None, then no chunking for all axes (number of chunks = 1)\n\n        Returns\n        -------\n        ChunkedArray\n        \"\"\"\n        if len(axes) == 0:\n            return self\n\n        kmask = self.kmask(axes)\n\n        if size is None:\n            size = self.kshape[kmask]\n\n        # update properties\n        newplan = r_[size, self.plan]\n        newsplit = self._split - len(axes)\n        newshape = tuple(r_[self.kshape[~kmask], self.kshape[kmask], self.vshape].astype(int).tolist())\n        newpadding = r_[zeros(len(axes), dtype=int), self.padding]\n\n        result = self._constructor(None, shape=newshape, split=newsplit,\n                                   dtype=self.dtype, plan=newplan, padding=newpadding, ordered=True)\n\n        # convert keys into chunk + within-chunk label\n        split = self.split\n        def _relabel(record):\n            k, data = record\n            keys, chks = asarray(k[:split], 'int'), k[split:]\n            movingkeys, stationarykeys = keys[kmask], keys[~kmask]\n            newchks = [int(m) for m in movingkeys/size]  # element-wise integer division that works in Python 2 and 3\n            labels = mod(movingkeys, size)\n            return tuple(stationarykeys) + tuple(newchks) + tuple(chks) + tuple(labels), data\n\n        rdd = self._rdd.map(_relabel)\n\n        # group the new chunks together\n        nchunks = result.getnumber(result.plan, result.vshape)\n        npartitions = int(prod(result.kshape) * prod(nchunks))\n        ranges = tuple(result.kshape) + tuple(nchunks)\n        n = len(axes)\n        if n == 0:\n            s = slice(None)\n        else:\n            s = slice(-n)\n        partitioner = lambda k: ravel_multi_index(k[s], ranges)\n\n        rdd = rdd.partitionBy(numPartitions=npartitions, partitionFunc=partitioner)\n\n        # reassemble the pieces in the chunks by sorting and then stacking\n        uniform = result.uniform\n\n        def _rebuild(it):\n            ordered = sorted(it, key=lambda kv: kv[0][n:])\n            keys, data = zip(*ordered)\n\n            k = keys[0][s]\n            labels = asarray([x[-n:] for x in keys])\n\n            if uniform:\n                labelshape = tuple(size)\n            else:\n                labelshape = tuple(amax(labels, axis=0) - amin(labels, axis=0) + 1)\n\n            valshape = data[0].shape\n            fullshape = labelshape + valshape\n            yield k, asarray(data).reshape(fullshape)\n\n        result._rdd = rdd.mapPartitions(_rebuild)\n\n        if array_equal(self.vshape, [1]):\n            result._rdd = result._rdd.mapValues(lambda v: squeeze(v))\n            result._shape = result.shape[:-1]\n            result._plan = result.plan[:-1]\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\napply an array function to each subarray and returns a ChunkedArray containing the result.", "response": "def map(self, func, value_shape=None, dtype=None):\n        \"\"\"\n        Apply an array -> array function on each subarray.\n\n        The function can change the shape of the subarray, but only along\n        dimensions that are not chunked.\n\n        Parameters\n        ----------\n        func : function\n            Function of a single subarray to apply\n\n        value_shape:\n            Known shape of chunking plan after the map\n\n        dtype: numpy.dtype, optional, default=None\n            Known dtype of values resulting from operation\n\n        Returns\n        -------\n        ChunkedArray\n        \"\"\"\n\n        if value_shape is None or dtype is None:\n            # try to compute the size of each mapped element by applying func to a random array\n            try:\n                mapped = func(random.randn(*self.plan).astype(self.dtype))\n            except Exception:\n                first = self._rdd.first()\n                if first:\n                    # eval func on the first element\n                    mapped = func(first[1])\n            if value_shape is None:\n                value_shape = mapped.shape\n            if dtype is None:\n                dtype = mapped.dtype\n\n        chunked_dims = where(self.plan != self.vshape)[0]\n        unchunked_dims = where(self.plan == self.vshape)[0]\n\n        # check that no dimensions are dropped\n        if len(value_shape) != len(self.plan):\n            raise NotImplementedError('map on ChunkedArray cannot drop dimensions')\n\n        # check that chunked dimensions did not change shape\n        if any([value_shape[i] != self.plan[i] for i in chunked_dims]):\n            raise ValueError('map cannot change the sizes of chunked dimensions')\n\n        def check_and_apply(v):\n            new = func(v)\n            if len(unchunked_dims) > 0:\n                if any([new.shape[i] != value_shape[i] for i in unchunked_dims]):\n                    raise Exception(\"Map operation did not produce values of uniform shape.\")\n            if len(chunked_dims) > 0:\n                if any([v.shape[i] != new.shape[i] for i in chunked_dims]):\n                    raise Exception(\"Map operation changed the size of a chunked dimension\")\n            return new\n\n        rdd = self._rdd.mapValues(check_and_apply)\n\n        vshape = [value_shape[i] if i in unchunked_dims else self.vshape[i] for i in range(len(self.vshape))]\n        newshape = r_[self.kshape, vshape].astype(int).tolist()\n\n        return self._constructor(rdd, shape=tuple(newshape), dtype=dtype,\n                                 plan=asarray(value_shape)).__finalize__(self)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef map_generic(self, func):\n        def process_record(val):\n            newval = empty(1, dtype=\"object\")\n            newval[0]  = func(val)\n            return newval\n\n        rdd = self._rdd.mapValues(process_record)\n\n        nchunks = self.getnumber(self.plan, self.vshape)\n        newshape = tuple([int(s) for s in r_[self.kshape, nchunks]])\n        newsplit = len(self.shape)\n        return BoltArraySpark(rdd, shape=newshape, split=newsplit, ordered=self._ordered, dtype=\"object\")", "response": "Applies a generic array - > object to each subarray\n       "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getplan(self, size=\"150\", axes=None, padding=None):\n        from numpy import dtype as gettype\n\n        # initialize with all elements in one chunk\n        plan = self.vshape\n\n        # check for subset of axes\n        if axes is None:\n            if isinstance(size, str):\n                axes = arange(len(self.vshape))\n            else:\n                axes = arange(len(size))\n        else:\n            axes = asarray(axes, 'int')\n\n        # set padding\n        pad = array(len(self.vshape)*[0, ])\n        if padding is not None:\n            pad[axes] = padding\n\n        # set the plan\n        if isinstance(size, tuple):\n            plan[axes] = size\n\n        elif isinstance(size, str):\n            # convert from kilobytes\n            size = 1000.0 * float(size)\n\n            # calculate from dtype\n            elsize = gettype(self.dtype).itemsize\n            nelements = prod(self.vshape)\n            dims = self.vshape[self.vmask(axes)]\n\n            if size <= elsize:\n                s = ones(len(axes))\n\n            else:\n                remsize = 1.0 * nelements * elsize\n                s = []\n                for (i, d) in enumerate(dims):\n                    minsize = remsize/d\n                    if minsize >= size:\n                        s.append(1)\n                        remsize = minsize\n                        continue\n                    else:\n                        s.append(min(d, floor(size/minsize)))\n                        s[i+1:] = plan[i+1:]\n                        break\n\n            plan[axes] = s\n\n        else:\n            raise ValueError(\"Chunk size not understood, must be tuple or int\")\n\n        return plan, pad", "response": "Return a numpy array with the size of the specified size along each axis."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove the padding from chunks.", "response": "def removepad(idx, value, number, padding, axes=None):\n        \"\"\"\n        Remove the padding from chunks.\n\n        Given a chunk and its corresponding index, use the plan and padding to remove any\n        padding from the chunk along with specified axes.\n\n        Parameters\n        ----------\n        idx: tuple or array-like\n            The chunk index, indicating which chunk this is.\n\n        value: ndarray\n            The chunk that goes along with the index.\n\n        number: ndarray or array-like\n            The number of chunks along each dimension.\n\n        padding: ndarray or array-like\n            The padding scheme.\n\n        axes: tuple, optional, default = None\n            The axes (in the values) along which to remove padding.\n        \"\"\"\n        if axes is None:\n            axes = range(len(number))\n        mask = len(number)*[False, ]\n        for i in range(len(mask)):\n            if i in axes and padding[i] != 0:\n                mask[i] = True\n\n        starts = [0 if (i == 0 or not m) else p for (i, m, p) in zip(idx, mask, padding)]\n        stops = [None if (i == n-1 or not m) else -p for (i, m, p, n) in zip(idx, mask, padding, number)]\n        slices = [slice(i1, i2) for (i1, i2) in zip(starts, stops)]\n\n        return value[slices]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getnumber(plan, shape):\n        nchunks = []\n        for size, d in zip(plan, shape):\n            nchunks.append(int(ceil(1.0 * d/size)))\n        return nchunks", "response": "Returns the number of chunks for the given plan and shape."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of slices for the given dimensions padding and shape.", "response": "def getslices(plan, padding, shape):\n        \"\"\"\n        Obtain slices for the given dimensions, padding, and chunks.\n\n        Given a plan for the number of chunks along each dimension and the amount of padding,\n        calculate a list of slices required to generate those chunks.\n\n        Parameters\n        ----------\n        plan: tuple or array-like\n            Size of chunks (in number of elements) along each dimensions.\n            Length must be equal to the number of dimensions.\n\n        padding: tuple or array-like\n            Size of overlap (in number of elements) between chunks along each dimension.\n            Length must be equal to the number of dimensions.\n\n        shape: tuple\n             Dimensions of axes to be chunked.\n        \"\"\"\n        slices = []\n        for size, pad, d in zip(plan, padding, shape):\n            nchunks = int(floor(d/size))\n            remainder = d % size\n            start = 0\n            dimslices = []\n            for idx in range(nchunks):\n                end = start + size\n                # left endpoint\n                if idx == 0:\n                    left = start\n                else:\n                    left = start - pad\n                # right endpoint\n                if idx == nchunks:\n                    right = end\n                else:\n                    right = end + pad\n                dimslices.append(slice(left, right, 1))\n                start = end\n            if remainder:\n                dimslices.append(slice(end - pad, d, 1))\n            slices.append(dimslices)\n        return slices"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getmask(inds, n):\n        inds = asarray(inds, 'int')\n        mask = zeros(n, dtype=bool)\n        mask[inds] = True\n        return mask", "response": "Returns a binary mask by setting a subset of entries to true."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef repartition(self, npartitions):\n\n        rdd = self._rdd.repartition(npartitions)\n        return self._constructor(rdd, ordered=False).__finalize__(self)", "response": "Repartition the underlying RDD to a new number of partitions."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a new StackedArray object with the original records of the current distributed array.", "response": "def stack(self, size=None):\n        \"\"\"\n        Aggregates records of a distributed array.\n\n        Stacking should improve the performance of vectorized operations,\n        but the resulting StackedArray object only exposes a restricted set\n        of operations (e.g. map, reduce). The unstack method can be used\n        to restore the full bolt array.\n\n        Parameters\n        ----------\n        size : int, optional, default=None\n            The maximum size for each stack (number of original records),\n            will aggregate groups of records per partition up to this size,\n            if None will aggregate all records on each partition.\n\n        Returns\n        -------\n        StackedArray\n        \"\"\"\n        stk = StackedArray(self._rdd, shape=self.shape, split=self.split)\n        return stk.stack(size)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\naligning spark bolt array so that the specified axes for iteration are in the keys and values.", "response": "def _align(self, axis):\n        \"\"\"\n        Align spark bolt array so that axes for iteration are in the keys.\n\n        This operation is applied before most functional operators.\n        It ensures that the specified axes are valid, and swaps\n        key/value axes so that functional operators can be applied\n        over the correct records.\n\n        Parameters\n        ----------\n        axis: tuple[int]\n            One or more axes that wil be iterated over by a functional operator\n\n        Returns\n        -------\n        BoltArraySpark\n        \"\"\"\n        # ensure that the specified axes are valid\n        inshape(self.shape, axis)\n\n        # find the value axes that should be moved into the keys (axis >= split)\n        tokeys = [(a - self.split) for a in axis if a >= self.split]\n\n        # find the key axes that should be moved into the values (axis < split)\n        tovalues = [a for a in range(self.split) if a not in axis]\n\n        if tokeys or tovalues:\n            return self.swap(tovalues, tokeys)\n        else:\n            return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the first element of an array", "response": "def first(self):\n        \"\"\"\n        Return the first element of an array\n        \"\"\"\n        from bolt.local.array import BoltArrayLocal\n        rdd = self._rdd if self._ordered else self._rdd.sortByKey()\n        return BoltArrayLocal(rdd.values().first())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\napply a function across an axis and returns a BoltArraySpark object with the mapped elements.", "response": "def map(self, func, axis=(0,), value_shape=None, dtype=None, with_keys=False):\n        \"\"\"\n        Apply a function across an axis.\n\n        Array will be aligned so that the desired set of axes\n        are in the keys, which may incur a swap.\n\n        Parameters\n        ----------\n        func : function\n            Function of a single array to apply. If with_keys=True,\n            function should be of a (tuple, array) pair.\n\n        axis : tuple or int, optional, default=(0,)\n            Axis or multiple axes to apply function along.\n\n        value_shape : tuple, optional, default=None\n            Known shape of values resulting from operation\n\n        dtype: numpy.dtype, optional, default=None\n            Known dtype of values resulting from operation\n\n        with_keys : bool, optional, default=False\n            Include keys as an argument to the function\n\n        Returns\n        -------\n        BoltArraySpark\n        \"\"\"\n        axis = tupleize(axis)\n        swapped = self._align(axis)\n\n        if with_keys:\n            test_func = lambda x: func(((0,), x))\n        else:\n            test_func = func\n\n        if value_shape is None or dtype is None:\n            # try to compute the size of each mapped element by applying func to a random array\n            try:\n                mapped = test_func(random.randn(*swapped.values.shape).astype(self.dtype))\n            except Exception:\n                first = swapped._rdd.first()\n                if first:\n                    # eval func on the first element\n                    mapped = test_func(first[1])\n            if value_shape is None:\n                value_shape = mapped.shape\n            if dtype is None:\n                dtype = mapped.dtype\n\n        shape = tuple([swapped._shape[ax] for ax in range(len(axis))]) + tupleize(value_shape)\n\n        if with_keys:\n            rdd = swapped._rdd.map(lambda kv: (kv[0], func(kv)))\n        else:\n            rdd = swapped._rdd.mapValues(func)\n\n        # reshaping will fail if the elements aren't uniformly shaped\n        def check(v):\n            if len(v.shape) > 0 and v.shape != tupleize(value_shape):\n                raise Exception(\"Map operation did not produce values of uniform shape.\")\n            return v\n\n        rdd = rdd.mapValues(lambda v: check(v))\n\n        return self._constructor(rdd, shape=shape, dtype=dtype, split=swapped.split).__finalize__(swapped)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef filter(self, func, axis=(0,), sort=False):\n        axis = tupleize(axis)\n\n        swapped = self._align(axis)\n        def f(record):\n            return func(record[1])\n        rdd = swapped._rdd.filter(f)\n        if sort:\n            rdd = rdd.sortByKey().values()\n        else:\n            rdd = rdd.values()\n\n        # count the resulting array in order to reindex (linearize) the keys\n        count, zipped = zip_with_index(rdd)\n        if not count:\n            count = zipped.count()\n        reindexed = zipped.map(lambda kv: (tupleize(kv[1]), kv[0]))\n\n        # since we can only filter over one axis, the remaining shape is always the following\n        remaining = list(swapped.shape[len(axis):])\n        if count != 0:\n            shape = tuple([count] + remaining)\n        else:\n            shape = (0,)\n\n        return self._constructor(reindexed, shape=shape, split=1).__finalize__(swapped)", "response": "Filter array along an axis."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\napply a commutative or associative function of two arrays along an axis and returns a single array along that axis.", "response": "def reduce(self, func, axis=(0,), keepdims=False):\n        \"\"\"\n        Reduce an array along an axis.\n\n        Applies a commutative/associative function of two\n        arguments cumulatively to all arrays along an axis.\n        Array will be aligned so that the desired set of axes\n        are in the keys, which may incur a swap.\n\n        Parameters\n        ----------\n        func : function\n            Function of two arrays that returns a single array\n\n        axis : tuple or int, optional, default=(0,)\n            Axis or multiple axes to reduce along.\n\n        Returns\n        -------\n        BoltArraySpark\n        \"\"\"\n        from bolt.local.array import BoltArrayLocal\n        from numpy import ndarray\n\n        axis = tupleize(axis)\n        swapped = self._align(axis)\n        arr = swapped._rdd.values().treeReduce(func, depth=3)\n\n        if keepdims:\n            for i in axis:\n                arr = expand_dims(arr, axis=i)\n\n        if not isinstance(arr, ndarray):\n            # the result of a reduce can also be a scalar\n            return arr\n        elif arr.shape == (1,):\n            # ndarrays with single values in them should be converted into scalars\n            return arr[0]\n\n        return BoltArrayLocal(arr)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompute a statistic over an axis.", "response": "def _stat(self, axis=None, func=None, name=None, keepdims=False):\n        \"\"\"\n        Compute a statistic over an axis.\n\n        Can provide either a function (for use in a reduce)\n        or a name (for use by a stat counter).\n\n        Parameters\n        ----------\n        axis : tuple or int, optional, default=None\n            Axis to compute statistic over, if None\n            will compute over all axes\n\n        func : function, optional, default=None\n            Function for reduce, see BoltArraySpark.reduce\n\n        name : str\n            A named statistic, see StatCounter\n\n        keepdims : boolean, optional, default=False\n            Keep axis remaining after operation with size 1.\n        \"\"\"\n        if axis is None:\n            axis = list(range(len(self.shape)))\n        axis = tupleize(axis)\n\n        if func and not name:\n            return self.reduce(func, axis, keepdims)\n\n        if name and not func:\n            from bolt.local.array import BoltArrayLocal\n\n            swapped = self._align(axis)\n\n            def reducer(left, right):\n                return left.combine(right)\n\n            counter = swapped._rdd.values()\\\n                             .mapPartitions(lambda i: [StatCounter(values=i, stats=name)])\\\n                             .treeReduce(reducer, depth=3)\n\n            arr = getattr(counter, name)\n\n            if keepdims:\n                for i in axis:\n                    arr = expand_dims(arr, axis=i)\n\n            return BoltArrayLocal(arr).toscalar()\n\n        else:\n            raise ValueError('Must specify either a function or a statistic name.')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef mean(self, axis=None, keepdims=False):\n        return self._stat(axis, name='mean', keepdims=keepdims)", "response": "Return the mean of the array over the given axis."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the variance of the array over the given axis.", "response": "def var(self, axis=None, keepdims=False):\n        \"\"\"\n        Return the variance of the array over the given axis.\n\n        Parameters\n        ----------\n        axis : tuple or int, optional, default=None\n            Axis to compute statistic over, if None\n            will compute over all axes\n\n        keepdims : boolean, optional, default=False\n            Keep axis remaining after operation with size 1.\n        \"\"\"\n        return self._stat(axis, name='variance', keepdims=keepdims)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the standard deviation of the array over the given axis.", "response": "def std(self, axis=None, keepdims=False):\n        \"\"\"\n        Return the standard deviation of the array over the given axis.\n\n        Parameters\n        ----------\n        axis : tuple or int, optional, default=None\n            Axis to compute statistic over, if None\n            will compute over all axes\n\n        keepdims : boolean, optional, default=False\n            Keep axis remaining after operation with size 1.\n        \"\"\"\n        return self._stat(axis, name='stdev', keepdims=keepdims)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the sum of the array over the given axis.", "response": "def sum(self, axis=None, keepdims=False):\n        \"\"\"\n        Return the sum of the array over the given axis.\n\n        Parameters\n        ----------\n        axis : tuple or int, optional, default=None\n            Axis to compute statistic over, if None\n            will compute over all axes\n\n        keepdims : boolean, optional, default=False\n            Keep axis remaining after operation with size 1.\n        \"\"\"\n        from operator import add\n        return self._stat(axis, func=add, keepdims=keepdims)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef max(self, axis=None, keepdims=False):\n        from numpy import maximum\n        return self._stat(axis, func=maximum, keepdims=keepdims)", "response": "Return the maximum value over the given axis."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef min(self, axis=None, keepdims=False):\n        from numpy import minimum\n        return self._stat(axis, func=minimum, keepdims=keepdims)", "response": "Return the minimum value over the given axis."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconcatenates this array with another array.", "response": "def concatenate(self, arry, axis=0):\n        \"\"\"\n        Join this array with another array.\n\n        Paramters\n        ---------\n        arry : ndarray, BoltArrayLocal, or BoltArraySpark\n            Another array to concatenate with\n\n        axis : int, optional, default=0\n            The axis along which arrays will be joined.\n\n        Returns\n        -------\n        BoltArraySpark\n        \"\"\"\n        if isinstance(arry, ndarray):\n            from bolt.spark.construct import ConstructSpark\n            arry = ConstructSpark.array(arry, self._rdd.context, axis=range(0, self.split))\n        else:\n            if not isinstance(arry, BoltArraySpark):\n                raise ValueError(\"other must be local array or spark array, got %s\" % type(arry))\n\n        if not all([x == y if not i == axis else True\n                    for i, (x, y) in enumerate(zip(self.shape, arry.shape))]):\n            raise ValueError(\"all the input array dimensions except for \"\n                             \"the concatenation axis must match exactly\")\n\n        if not self.split == arry.split:\n            raise NotImplementedError(\"two arrays must have the same split \")\n\n        if axis < self.split:\n            shape = self.keys.shape\n\n            def key_func(key):\n                key = list(key)\n                key[axis] += shape[axis]\n                return tuple(key)\n\n            rdd = self._rdd.union(arry._rdd.map(lambda kv: (key_func(kv[0]), kv[1])))\n\n        else:\n            from numpy import concatenate as npconcatenate\n            shift = axis - self.split\n            rdd = self._rdd.join(arry._rdd).map(lambda kv: (kv[0], npconcatenate(kv[1], axis=shift)))\n\n        shape = tuple([x + y if i == axis else x\n                      for i, (x, y) in enumerate(zip(self.shape, arry.shape))])\n\n        return self._constructor(rdd, shape=shape, ordered=False).__finalize__(self)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _getbasic(self, index):\n        key_slices = index[0:self.split]\n        value_slices = index[self.split:]\n\n        def key_check(key):\n            def inrange(k, s):\n                if s.step > 0:\n                    return s.start <= k < s.stop\n                else:\n                    return s.stop < k <= s.start\n            def check(k, s):\n                return inrange(k, s) and mod(k - s.start, s.step) == 0\n            out = [check(k, s) for k, s in zip(key, key_slices)]\n            return all(out)\n\n        def key_func(key):\n            return tuple([(k - s.start)/s.step for k, s in zip(key, key_slices)])\n\n        filtered = self._rdd.filter(lambda kv: key_check(kv[0]))\n\n        if self._split == self.ndim:\n            rdd = filtered.map(lambda kv: (key_func(kv[0]), kv[1]))\n        else:\n            # handle use of use slice.stop = -1 for a special case (see utils.slicify)\n            value_slices = [s if s.stop != -1 else slice(s.start, None, s.step) for s in value_slices]\n            rdd = filtered.map(lambda kv: (key_func(kv[0]), kv[1][value_slices]))\n\n        shape = tuple([int(ceil((s.stop - s.start) / float(s.step))) for s in index])\n        split = self.split\n        return rdd, shape, split", "response": "Basic indexing for slices or ints."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _getadvanced(self, index):\n        index = [asarray(i) for i in index]\n        shape = index[0].shape\n        if not all([i.shape == shape for i in index]):\n            raise ValueError(\"shape mismatch: indexing arrays could not be broadcast \"\n                             \"together with shapes \" + (\"%s \" * self.ndim)\n                             % tuple([i.shape for i in index]))\n\n        index = tuple([listify(i, d) for (i, d) in zip(index, self.shape)])\n\n        # build tuples with target indices\n        key_tuples = list(zip(*index[0:self.split]))\n        value_tuples = list(zip(*index[self.split:]))\n\n        # build dictionary to look up targets in values\n        d = {}\n        for k, g in groupby(zip(value_tuples, key_tuples), lambda x: x[1]):\n            d[k] = map(lambda x: x[0], list(g))\n\n        def key_check(key):\n            return key in key_tuples\n\n        def key_func(key):\n            return unravel_index(key, shape)\n\n        # filter records based on key targets\n        filtered = self._rdd.filter(lambda kv: key_check(kv[0]))\n\n        # subselect and flatten records based on value targets (if they exist)\n        if len(value_tuples) > 0:\n            flattened = filtered.flatMap(lambda kv: [(kv[0], kv[1][i]) for i in d[kv[0]]])\n        else:\n            flattened = filtered\n\n        # reindex\n        indexed = flattened.zipWithIndex()\n        rdd = indexed.map(lambda kkv: (key_func(kkv[1]), kkv[0][1]))\n        split = len(shape)\n\n        return rdd, shape, split", "response": "Get the indices of the entries in the index."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _getmixed(self, index):\n        # find the single advanced index\n        loc = where([isinstance(i, (tuple, list, ndarray)) for i in index])[0][0]\n        idx = list(index[loc])\n\n        if isinstance(idx[0], (tuple, list, ndarray)):\n            raise ValueError(\"When mixing basic and advanced indexing, \"\n                             \"advanced index must be one-dimensional\")\n\n        # single advanced index is on a key -- filter and update key\n        if loc < self.split:\n            def newkey(key):\n                newkey = list(key)\n                newkey[loc] = idx.index(key[loc])\n                return tuple(newkey)\n            rdd = self._rdd.filter(lambda kv: kv[0][loc] in idx).map(lambda kv: (newkey(kv[0]), kv[1]))\n        # single advanced index is on a value -- use NumPy indexing\n        else:\n            slices = [slice(0, None, None) for _ in self.values.shape]\n            slices[loc - self.split] = idx\n            rdd = self._rdd.map(lambda kv: (kv[0], kv[1][slices]))\n        newshape = list(self.shape)\n        newshape[loc] = len(idx)\n        barray = self._constructor(rdd, shape=tuple(newshape)).__finalize__(self)\n\n        # apply the rest of the simple indices\n        new_index = index[:]\n        new_index[loc] = slice(0, None, None)\n        barray = barray[tuple(new_index)]\n        return barray._rdd, barray.shape, barray.split", "response": "Return a new RDD with the mixed entries."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a chunked version of the distributed array.", "response": "def chunk(self, size=\"150\", axis=None, padding=None):\n        \"\"\"\n        Chunks records of a distributed array.\n\n        Chunking breaks arrays into subarrays, using an specified\n        size of chunks along each value dimension. Can alternatively\n        specify an average chunk byte size (in kilobytes) and the size of\n        chunks (as ints) will be computed automatically.\n\n        Parameters\n        ----------\n        size : tuple, int, or str, optional, default = \"150\"\n            A string giving the size in kilobytes, or a tuple with the size\n            of chunks along each dimension.\n\n        axis : int or tuple, optional, default = None\n            One or more axis to chunk array along, if None\n            will use all axes,\n\n        padding: tuple or int, default = None\n            Number of elements per dimension that will overlap with the adjacent chunk.\n            If a tuple, specifies padding along each chunked dimension; if a int, same\n            padding will be applied to all chunked dimensions.\n\n        Returns\n        -------\n        ChunkedArray\n        \"\"\"\n        if type(size) is not str:\n            size = tupleize((size))\n        axis = tupleize((axis))\n        padding = tupleize((padding))\n\n        from bolt.spark.chunk import ChunkedArray\n\n        chnk = ChunkedArray(rdd=self._rdd, shape=self._shape, split=self._split, dtype=self._dtype)\n        return chnk._chunk(size, axis, padding)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nswaps axes from keys to values. This is the core operation underlying shape manipulation on the Spark bolt array. It exchanges an arbitrary set of axes between the keys and the valeus. If either is None, will only move axes in one direction (from keys to values, or values to keys). Keys moved to values will be placed immediately after the split; values moved to keys will be placed immediately before the split. Parameters ---------- kaxes : tuple Axes from keys to move to values vaxes : tuple Axes from values to move to keys size : tuple or int, optional, default = \"150\" Can either provide a string giving the size in kilobytes, or a tuple with the number of chunks along each value dimension being moved Returns ------- BoltArraySpark", "response": "def swap(self, kaxes, vaxes, size=\"150\"):\n        \"\"\"\n        Swap axes from keys to values.\n\n        This is the core operation underlying shape manipulation\n        on the Spark bolt array. It exchanges an arbitrary set of axes\n        between the keys and the valeus. If either is None, will only\n        move axes in one direction (from keys to values, or values to keys).\n        Keys moved to values will be placed immediately after the split;\n        values moved to keys will be placed immediately before the split.\n\n        Parameters\n        ----------\n        kaxes : tuple\n            Axes from keys to move to values\n\n        vaxes : tuple\n            Axes from values to move to keys\n\n        size : tuple or int, optional, default = \"150\"\n            Can either provide a string giving the size in kilobytes,\n            or a tuple with the number of chunks along each\n            value dimension being moved\n\n        Returns\n        -------\n        BoltArraySpark\n        \"\"\"\n        kaxes = asarray(tupleize(kaxes), 'int')\n        vaxes = asarray(tupleize(vaxes), 'int')\n        if type(size) is not str:\n            size = tupleize(size)\n\n        if len(kaxes) == self.keys.ndim and len(vaxes) == 0:\n            raise ValueError('Cannot perform a swap that would '\n                             'end up with all data on a single key')\n\n        if len(kaxes) == 0 and len(vaxes) == 0:\n            return self\n\n        from bolt.spark.chunk import ChunkedArray\n\n        chunks = self.chunk(size)\n\n        swapped = chunks.keys_to_values(kaxes).values_to_keys([v+len(kaxes) for v in vaxes])\n        barray = swapped.unchunk()\n\n        return barray"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef transpose(self, *axes):\n        if len(axes) == 0:\n            p = arange(self.ndim-1, -1, -1)\n        else:\n            p = asarray(argpack(axes))\n\n        istransposeable(p, range(self.ndim))\n\n        split = self.split\n\n        # compute the keys/value axes that need to be swapped\n        new_keys, new_values = p[:split], p[split:]\n        swapping_keys = sort(new_values[new_values < split])\n        swapping_values = sort(new_keys[new_keys >= split])\n        stationary_keys = sort(new_keys[new_keys < split])\n        stationary_values = sort(new_values[new_values >= split])\n\n        # compute the permutation that the swap causes\n        p_swap = r_[stationary_keys, swapping_values, swapping_keys, stationary_values]\n\n        # compute the extra permutation (p_x)  on top of this that\n        # needs to happen to get the full permutation desired\n        p_swap_inv = argsort(p_swap)\n        p_x = p_swap_inv[p]\n        p_keys, p_values = p_x[:split], p_x[split:]-split\n\n        # perform the swap and the the within key/value permutations\n        arr = self.swap(swapping_keys, swapping_values-split)\n        arr = arr.keys.transpose(tuple(p_keys.tolist()))\n        arr = arr.values.transpose(tuple(p_values.tolist()))\n\n        return arr", "response": "Return an array with the axes transposed."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the array with two axes interchanged.", "response": "def swapaxes(self, axis1, axis2):\n        \"\"\"\n        Return the array with two axes interchanged.\n\n        Parameters\n        ----------\n        axis1 : int\n            The first axis to swap\n\n        axis2 : int\n            The second axis to swap\n        \"\"\"\n        p = list(range(self.ndim))\n        p[axis1] = axis2\n        p[axis2] = axis1\n\n        return self.transpose(p)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn an array with the same data but a new shape.", "response": "def reshape(self, *shape):\n        \"\"\"\n        Return an array with the same data but a new shape.\n\n        Currently only supports reshaping that independently\n        reshapes the keys, or the values, or both.\n\n        Parameters\n        ----------\n        shape :  tuple of ints, or n ints\n            New shape\n        \"\"\"\n        new = argpack(shape)\n        isreshapeable(new, self.shape)\n\n        if new == self.shape:\n            return self\n\n        i = self._reshapebasic(new)\n        if i == -1:\n            raise NotImplementedError(\"Currently no support for reshaping between \"\n                                      \"keys and values for BoltArraySpark\")\n        else:\n            new_key_shape, new_value_shape = new[:i], new[i:]\n            return self.keys.reshape(new_key_shape).values.reshape(new_value_shape)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _reshapebasic(self, shape):\n        new = tupleize(shape)\n        old_key_size = prod(self.keys.shape)\n        old_value_size = prod(self.values.shape)\n\n        for i in range(len(new)):\n            new_key_size = prod(new[:i])\n            new_value_size = prod(new[i:])\n            if new_key_size == old_key_size and new_value_size == old_value_size:\n                return i\n\n        return -1", "response": "Check if the reshape can be broken into independant reshapes\n        on the keys and values. If it can return the index in the new shape\n        otherwise returns - 1."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef squeeze(self, axis=None):\n        if not any([d == 1 for d in self.shape]):\n            return self\n\n        if axis is None:\n            drop = where(asarray(self.shape) == 1)[0]\n        elif isinstance(axis, int):\n            drop = asarray((axis,))\n        elif isinstance(axis, tuple):\n            drop = asarray(axis)\n        else:\n            raise ValueError(\"an integer or tuple is required for the axis\")\n\n        if any([self.shape[i] > 1 for i in drop]):\n            raise ValueError(\"cannot select an axis to squeeze out which has size greater than one\")\n\n        if any(asarray(drop) < self.split):\n            kmask = set([d for d in drop if d < self.split])\n            kfunc = lambda k: tuple([kk for ii, kk in enumerate(k) if ii not in kmask])\n        else:\n            kfunc = lambda k: k\n\n        if any(asarray(drop) >= self.split):\n            vmask = tuple([d - self.split for d in drop if d >= self.split])\n            vfunc = lambda v: v.squeeze(vmask)\n        else:\n            vfunc = lambda v: v\n\n        rdd = self._rdd.map(lambda kv: (kfunc(kv[0]), vfunc(kv[1])))\n        shape = tuple([ss for ii, ss in enumerate(self.shape) if ii not in drop])\n        split = len([d for d in range(self.keys.ndim) if d not in drop])\n        return self._constructor(rdd, shape=shape, split=split).__finalize__(self)", "response": "Return a new array with only one or more single - dimensional axes removed."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef astype(self, dtype, casting='unsafe'):\n        rdd = self._rdd.mapValues(lambda v: v.astype(dtype, 'K', casting))\n        return self._constructor(rdd, dtype=dtype).__finalize__(self)", "response": "Cast the array to a specified type."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef clip(self, min=None, max=None):\n        rdd = self._rdd.mapValues(lambda v: v.clip(min=min, max=max))\n        return self._constructor(rdd).__finalize__(self)", "response": "Clip values above and below."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the contents as a local array.", "response": "def toarray(self):\n        \"\"\"\n        Returns the contents as a local array.\n\n        Will likely cause memory problems for large objects.\n        \"\"\"\n        rdd = self._rdd if self._ordered else self._rdd.sortByKey()\n        x = rdd.values().collect()\n        return asarray(x).reshape(self.shape)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncoercing singletons and lists and ndarrays to tuples.", "response": "def tupleize(arg):\n    \"\"\"\n    Coerce singletons and lists and ndarrays to tuples.\n\n    Parameters\n    ----------\n    arg : tuple, list, ndarray, or singleton\n        Item to coerce\n    \"\"\"\n    if arg is None:\n        return None\n    if not isinstance(arg, (tuple, list, ndarray, Iterable)):\n        return tuple((arg,))\n    elif isinstance(arg, (list, ndarray)):\n        return tuple(arg)\n    elif isinstance(arg, Iterable) and not isinstance(arg, str):\n        return tuple(arg)\n    else:\n        return arg"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncoerce a list of arguments into a tuple.", "response": "def argpack(args):\n    \"\"\"\n    Coerce a list of arguments to a tuple.\n\n    Parameters\n    ----------\n    args : tuple or nested tuple\n        Pack arguments into a tuple, converting ((,...),) or (,) -> (,)\n    \"\"\"\n    if isinstance(args[0], (tuple, list, ndarray)):\n        return tupleize(args[0])\n    elif isinstance(args[0], Iterable) and not isinstance(args[0], str):\n        # coerce any iterable into a list before calling tupleize (Python 3 compatibility)\n        return tupleize(list(args[0]))\n    else:\n        return tuple(args)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks to see if a list of axes are contained within an array shape.", "response": "def inshape(shape, axes):\n    \"\"\"\n    Checks to see if a list of axes are contained within an array shape.\n\n    Parameters\n    ----------\n    shape : tuple[int]\n        the shape of a BoltArray\n\n    axes : tuple[int]\n        the axes to check against shape\n    \"\"\"\n    valid = all([(axis < len(shape)) and (axis >= 0) for axis in axes])\n    if not valid:\n        raise ValueError(\"axes not valid for an ndarray of shape: %s\" % str(shape))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef allclose(a, b):\n    from numpy import allclose\n    return (a.shape == b.shape) and allclose(a, b)", "response": "Tests that a and b are all close and match in shape."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef listify(lst, dim):\n    if not all([l.dtype == int for l in lst]):\n        raise ValueError(\"indices must be integers\")\n\n    if npany(asarray(lst) >= dim):\n        raise ValueError(\"indices out of bounds for axis with size %s\" % dim)\n\n    return lst.flatten()", "response": "Flatten lists of indices and ensure bounded by a known dim."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef slicify(slc, dim):\n    if isinstance(slc, slice):\n\n        # default limits\n        start = 0 if slc.start is None else slc.start\n        stop = dim if slc.stop is None else slc.stop\n        step = 1 if slc.step is None else slc.step\n        # account for negative indices\n        if start < 0: start += dim\n        if stop < 0: stop += dim\n        # account for over-flowing the bounds\n        if step > 0:\n            if start < 0: start = 0\n            if stop > dim: stop = dim\n        else:\n            if stop < 0: stop = -1\n            if start > dim: start = dim-1\n\n        return slice(start, stop, step)\n\n    elif isinstance(slc, int):\n        if slc < 0:\n            slc += dim\n        return slice(slc, slc+1, 1)\n\n    else:\n        raise ValueError(\"Type for slice %s not recongized\" % type(slc))", "response": "Convert a slice to a sequence of items."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef istransposeable(new, old):\n\n    new, old = tupleize(new), tupleize(old)\n\n    if not len(new) == len(old):\n        raise ValueError(\"Axes do not match axes of keys\")\n\n    if not len(set(new)) == len(set(old)):\n        raise ValueError(\"Repeated axes\")\n\n    if any(n < 0 for n in new) or max(new) > len(old) - 1:\n        raise ValueError(\"Invalid axes\")", "response": "Checks to see if a proposed tuple of axes is a valid permutation\n    of an old set of axes."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks to see if a proposed tuple of axes can be reshaped of the old axes.", "response": "def isreshapeable(new, old):\n    \"\"\"\n    Check to see if a proposed tuple of axes is a valid reshaping of\n    the old axes by ensuring that they can be factored.\n\n    Parameters\n    ----------\n    new : tuple\n        tuple of proposed axes\n\n    old : tuple\n        tuple of old axes\n    \"\"\"\n\n    new, old = tupleize(new), tupleize(old)\n\n    if not prod(new) == prod(old):\n        raise ValueError(\"Total size of new keys must remain unchanged\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef allstack(vals, depth=0):\n    if type(vals[0]) is ndarray:\n        return concatenate(vals, axis=depth)\n    else:\n        return concatenate([allstack(x, depth+1) for x in vals], axis=depth)", "response": "This function creates a new array along a series of nested lists along a series of levels."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nexpands dimensions by iteratively append empty axes.", "response": "def iterexpand(arry, extra):\n    \"\"\"\n    Expand dimensions by iteratively append empty axes.\n\n    Parameters\n    ----------\n    arry : ndarray\n        The original array\n\n    extra : int\n        The number of empty axes to append\n    \"\"\"\n    for d in range(arry.ndim, arry.ndim+extra):\n        arry = expand_dims(arry, axis=d)\n    return arry"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef zip_with_index(rdd):\n    starts = [0]\n    if rdd.getNumPartitions() > 1:\n        nums = rdd.mapPartitions(lambda it: [sum(1 for _ in it)]).collect()\n        count = sum(nums)\n        for i in range(len(nums) - 1):\n            starts.append(starts[-1] + nums[i])\n    else:\n        count = rdd.count()\n\n    def func(k, it):\n        for i, v in enumerate(it, starts[k]):\n            yield v, i\n\n    return count, rdd.mapPartitionsWithIndex(func)", "response": "A version of Spark s zipWithIndex that eagerly returns count."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef wrapped(f):\n    import inspect\n\n    def extract(func):\n        append = \"\"\n        args = inspect.getargspec(func)\n        for i, a in enumerate(args.args):\n            if i < (len(args) - len(args.defaults)):\n                append += str(a) + \", \"\n            else:\n                default = args.defaults[i-len(args.defaults)]\n                if hasattr(default, \"__name__\"):\n                    default = default.__name__\n                else:\n                    default = str(default)\n                append += str(a) + \"=\" + default + \", \"\n        append = append[:-2] + \")\"\n        return append\n\n    doc = f.__doc__ + \"\\n\"\n    doc += \"    local -> array(\" + extract(getattr(ConstructLocal, f.__name__)) + \"\\n\"\n    doc += \"    spark -> array(\" + extract(getattr(ConstructSpark, f.__name__)) + \"\\n\"\n    f.__doc__ = doc\n    return f", "response": "Decorator to append routed docstrings\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the first constructor that matches the given arguments.", "response": "def lookup(*args, **kwargs):\n    \"\"\"\n    Use arguments to route constructor.\n\n    Applies a series of checks on arguments to identify constructor,\n    starting with known keyword arguments, and then applying\n    constructor-specific checks\n    \"\"\"\n    if 'mode' in kwargs:\n        mode = kwargs['mode']\n        if mode not in constructors:\n            raise ValueError('Mode %s not supported' % mode)\n        del kwargs['mode']\n        return constructors[mode]\n    else:\n        for mode, constructor in constructors:\n            if constructor._argcheck(*args, **kwargs):\n                return constructor\n    return ConstructLocal"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef transpose(self, *axes):\n        new = argpack(axes)\n        old = range(self.ndim)\n        istransposeable(new, old)\n\n        if new == old:\n            return self._barray\n\n        def f(k):\n            return tuple(k[i] for i in new)\n\n        newrdd = self._barray._rdd.map(lambda kv: (f(kv[0]), kv[1]))\n        newshape = tuple(self.shape[i] for i in new) + self._barray.values.shape\n\n        return BoltArraySpark(newrdd, shape=newshape, ordered=False).__finalize__(self._barray)", "response": "Transposes just the keys of a BoltArraySpark returning a new BoltArraySpark object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef reshape(self, *shape):\n        new = argpack(shape)\n        old = self.shape\n        isreshapeable(new, old)\n\n        if new == old:\n            return self._barray\n\n        def f(v):\n            return v.reshape(new)\n\n        newrdd = self._barray._rdd.mapValues(f)\n        newshape = self._barray.keys.shape + new\n\n        return BoltArraySpark(newrdd, shape=newshape).__finalize__(self._barray)", "response": "Reshape just the values of a BoltArraySpark returning a new BoltArraySpark object with the new shape."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntransposes just the values of a BoltArraySpark returning a new BoltArraySpark object.", "response": "def transpose(self, *axes):\n        \"\"\"\n        Transpose just the values of a BoltArraySpark, returning a\n        new BoltArraySpark.\n\n        Parameters\n        ----------\n        axes : tuple\n             New proposed axes.\n        \"\"\"\n        new = argpack(axes)\n        old = range(self.ndim)\n        istransposeable(new, old)\n\n        if new == old:\n            return self._barray\n\n        def f(v):\n            return v.transpose(new)\n\n        newrdd = self._barray._rdd.mapValues(f)\n        newshape = self._barray.keys.shape + tuple(self.shape[i] for i in new)\n\n        return BoltArraySpark(newrdd, shape=newshape).__finalize__(self._barray)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ones(shape, dtype=float64, order='C'):\n        from numpy import ones\n        return ConstructLocal._wrap(ones, shape, dtype, order)", "response": "Create a local bolt array of ones."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef zeros(shape, dtype=float64, order='C'):\n        from numpy import zeros\n        return ConstructLocal._wrap(zeros, shape, dtype, order)", "response": "Create a local bolt array of zeros."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef concatenate(arrays, axis=0):\n        if not isinstance(arrays, tuple):\n            raise ValueError(\"data type not understood\")\n        arrays = tuple([asarray(a) for a in arrays])\n        from numpy import concatenate\n        return BoltArrayLocal(concatenate(arrays, axis))", "response": "Concatenate a sequence of array - like objects together."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning A and B in y = Ax^B http://mathworld. wolfram. com / LeastSquaresFittingPowerLaw. html Returns A and B in y = Ax^B http://mathworld. wolfram. com / LeastSquaresFittingPowerLaw. html Returns A and B in y = Ax^B", "response": "def plfit_lsq(x,y):\n    \"\"\"\n    Returns A and B in y=Ax^B\n    http://mathworld.wolfram.com/LeastSquaresFittingPowerLaw.html\n    \"\"\"\n    n = len(x)\n    btop = n * (log(x)*log(y)).sum() - (log(x)).sum()*(log(y)).sum()\n    bbottom = n*(log(x)**2).sum() - (log(x).sum())**2\n    b = btop / bbottom\n    a = ( log(y).sum() - b * log(x).sum() ) / n\n\n    A = exp(a)\n    return A,b"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef plfit(x,nosmall=False,finite=False):\n    xmins = unique(x)\n    xmins = xmins[1:-1]\n    dat = xmins * 0 \n    z = sort(x)\n    for xm in arange(len(xmins)):\n        xmin = xmins[xm]\n        z    = z[z>=xmin] \n        n    = float(len(z))\n        # estimate alpha using direct MLE\n        a    =  n / sum( log(z/xmin) )\n        if nosmall:\n            # 4. For continuous data, PLFIT can return erroneously large estimates of \n            #    alpha when xmin is so large that the number of obs x >= xmin is very \n            #    small. To prevent this, we can truncate the search over xmin values \n            #    before the finite-size bias becomes significant by calling PLFIT as\n            if (a-1)/sqrt(n) > 0.1:\n                #dat(xm:end) = [];\n                dat = dat[:xm]\n                xm = len(xmins)+1\n                break\n        # compute KS statistic\n        cx   = arange(n)/float(n)  #data\n        cf   = 1-(xmin/z)**a  # fitted\n        dat[xm] = max( abs(cf-cx) )\n    D     = min(dat);\n    #xmin  = xmins(find(dat<=D,1,'first'));\n    xmin  = xmins[argmin(dat)]\n    z     = x[x>=xmin]\n    n     = len(z)\n    alpha = 1 + n / sum( log(z/xmin) )\n    if finite:\n        alpha = alpha*(n-1)/n+1/n\n    if n < 50 and ~finite:\n        print '(PLFIT) Warning: finite-size bias may be present.'\n    L = n*log((alpha-1)/xmin) - alpha*sum(log(z/xmin));\n    return xmin,alpha,L,dat", "response": "Return a new object of the same size as the original object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef plotcdf(x,xmin,alpha):\n\n    x=sort(x)\n    n=len(x)\n    xcdf = arange(n,0,-1,dtype='float')/float(n)\n\n    q = x[x>=xmin]\n    fcdf = (q/xmin)**(1-alpha)\n    nc = xcdf[argmax(x>=xmin)]\n    fcdf_norm = nc*fcdf\n\n    loglog(x,xcdf)\n    loglog(q,fcdf_norm)", "response": "Plot CDF and powerlaw of a single node."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef plotpdf(x,xmin,alpha,nbins=30,dolog=False):\n\n    x=sort(x)\n    n=len(x)\n\n    if dolog:\n        hb = hist(x,bins=logspace(log10(min(x)),log10(max(x)),nbins),log=True)\n        alpha += 1\n    else:\n        hb = hist(x,bins=linspace((min(x)),(max(x)),nbins))\n    h,b=hb[0],hb[1]\n    b = b[1:]\n\n    q = x[x>=xmin]\n    px = (alpha-1)/xmin * (q/xmin)**(-alpha)\n\n    arg = argmin(abs(b-xmin))\n    norm = mean( h[b>xmin] / ((alpha-1)/xmin * (b[b>xmin]/xmin)**(-alpha))  )\n    px = px*norm\n\n    loglog(q,px)\n\n    gca().set_xlim(min(x),max(x))", "response": "Plot PDF and powerlaw."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef plexp(x,xm=1,a=2.5):\n\n    C = 1/(-xm/(1 - a) - xm/a + math.exp(a)*xm/a)\n    Ppl = lambda X: 1+C*(xm/(1-a)*(X/xm)**(1-a))\n    Pexp = lambda X: C*xm/a*math.exp(a)-C*(xm/a)*math.exp(-a*(X/xm-1))\n    d=Ppl(x)\n    d[x<xm]=Pexp(x)\n    return d", "response": "Plexp is a function that returns a piecewise distribution exponential x<xmin powerlaw x > = xm"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ninverses CDF for a piecewise PDF as defined in eqn. 3. 10", "response": "def plexp_inv(P,xm,a):\n    \"\"\"\n    Inverse CDF for a piecewise PDF as defined in eqn. 3.10\n    of Clauset et al.  \n    \"\"\"\n\n    C = 1/(-xm/(1 - a) - xm/a + math.exp(a)*xm/a)\n    Pxm = 1+C*(xm/(1-a))\n    pp = P\n    x = xm*(pp-1)*(1-a)/(C*xm)**(1/(1-a)) if pp >= Pxm else (math.log( ((C*xm/a)*math.exp(a)-pp)/(C*xm/a)) - a) * (-xm/a)\n    #x[P>=Pxm] = xm*( (P[P>=Pxm]-1) * (1-a)/(C*xm) )**(1/(1-a)) # powerlaw\n    #x[P<Pxm] = (math.log( (C*xm/a*math.exp(a)-P[P<Pxm])/(C*xm/a) ) - a) * (-xm/a) # exp\n\n    return x"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef alpha_(self,x):\n        def alpha(xmin,x=x):\n            \"\"\"\n            given a sorted data set and a minimum, returns power law MLE fit\n            data is passed as a keyword parameter so that it can be vectorized\n            \"\"\"\n            x = [i for i in x if i>=xmin]\n            n = sum(x)\n            divsum = sum([math.log(i/xmin) for i in x])\n            if divsum == 0:\n                return float('inf')\n            # the \"1+\" here is unimportant because alpha_ is only used for minimization\n            a = 1 + float(n) / divsum\n            return a\n        return alpha", "response": "Create a mappable function alpha to apply to each xmin in a list of xmins."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates a mappable function alpha to apply to each xmin in a list of xmins.", "response": "def alpha_gen(x):\n    \"\"\" Create a mappable function alpha to apply to each xmin in a list of xmins.\n    This is essentially the slow version of fplfit/cplfit, though I bet it could\n    be speeded up with a clever use of parellel_map.  Not intended to be used by users.\n\n    Docstring for the generated alpha function::\n\n        Given a sorted data set and a minimum, returns power law MLE fit\n        data is passed as a keyword parameter so that it can be vectorized\n\n        If there is only one element, return alpha=0\n    \"\"\"\n    def alpha_(xmin,x=x):\n        \"\"\"\n        Given a sorted data set and a minimum, returns power law MLE fit\n        data is passed as a keyword parameter so that it can be vectorized\n\n        If there is only one element, return alpha=0\n        \"\"\"\n        gexmin = x>=xmin\n        n = np.count_nonzero(gexmin)\n        if n < 2:\n            return 0\n        x = x[gexmin]\n        a = 1 + float(n) / sum(log(x/xmin))\n        return a\n    return alpha_"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef plexp_cdf(x,xmin=1,alpha=2.5, pl_only=False, exp_only=False):\n\n    x = np.array(x)\n    C = 1/(-xmin/(1 - alpha) - xmin/alpha + exp(alpha)*xmin/alpha)\n    Ppl = lambda X: 1+C*(xmin/(1-alpha)*(X/xmin)**(1-alpha))\n    Pexp = lambda X: C*xmin/alpha*exp(alpha)-C*(xmin/alpha)*exp(-alpha*(X/xmin-1))\n\n    if exp_only:\n        return Pexp(x)\n    elif pl_only:\n        return Ppl(x)\n\n    d=Ppl(x)\n    d[x<xmin]=Pexp(x)[x<xmin]\n    return d", "response": "Returns the CDF version of the piecewise distribution exponential x<xmin and powerlaw x > = xmin"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninverse CDF for a piecewise PDF.", "response": "def plexp_inv(P, xmin, alpha, guess=1.):\n    \"\"\"\n    Inverse CDF for a piecewise PDF as defined in eqn. 3.10\n    of Clauset et al.\n\n    (previous version was incorrect and lead to weird discontinuities in the\n    distribution function)\n    \"\"\"\n    def equation(x,prob):\n        return plexp_cdf(x, xmin, alpha)-prob\n    # http://stackoverflow.com/questions/19840425/scipy-optimize-faster-root-finding-over-2d-grid\n    def solver(y, x0=guess):\n        return scipy.optimize.fsolve(equation, guess, args=(y,))\n    f = np.vectorize(solver)\n    return f(P)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalculating the discrete likelihood of a single node.", "response": "def discrete_likelihood(data, xmin, alpha):\n    \"\"\"\n    Equation B.8 in Clauset\n\n    Given a data set, an xmin value, and an alpha \"scaling parameter\", computes\n    the log-likelihood (the value to be maximized)\n    \"\"\"\n    if not scipyOK:\n        raise ImportError(\"Can't import scipy.  Need scipy for zeta function.\")\n    from scipy.special import zeta as zeta\n\n    zz = data[data>=xmin]\n    nn = len(zz)\n\n    sum_log_data = np.log(zz).sum()\n\n    zeta = zeta(alpha, xmin)\n\n    L_of_alpha = -1*nn*log(zeta) - alpha * sum_log_data\n\n    return L_of_alpha"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncomputes the discrete likelihood for all scaling parameters in the range alpharange", "response": "def discrete_likelihood_vector(data, xmin, alpharange=(1.5,3.5), n_alpha=201):\n    \"\"\"\n    Compute the likelihood for all \"scaling parameters\" in the range (alpharange)\n    for a given xmin.  This is only part of the discrete value likelihood\n    maximization problem as described in Clauset et al\n    (Equation B.8)\n\n    *alpharange* [ 2-tuple ]\n        Two floats specifying the upper and lower limits of the power law alpha to test\n    \"\"\"\n    from scipy.special import zeta as zeta\n\n    zz = data[data>=xmin]\n    nn = len(zz)\n\n    alpha_vector = np.linspace(alpharange[0],alpharange[1],n_alpha)\n    sum_log_data = np.log(zz).sum()\n\n    # alpha_vector is a vector, xmin is a scalar\n    zeta_vector = zeta(alpha_vector, xmin)\n\n    #xminvec = np.arange(1.0,xmin)\n\n    #xminalphasum = np.sum([xm**(-alpha_vector) for xm in xminvec])\n    #L = -1*alpha_vector*sum_log_data - nn*log(zeta_vector) - xminalphasum\n\n    L_of_alpha = -1*nn*log(zeta_vector) - alpha_vector * sum_log_data\n\n    return L_of_alpha"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef discrete_max_likelihood_arg(data, xmin, alpharange=(1.5,3.5), n_alpha=201):\n    likelihoods = discrete_likelihood_vector(data, xmin, alpharange=alpharange, n_alpha=n_alpha)\n    Largmax = np.argmax(likelihoods)\n    return Largmax", "response": "Returns the maximum likelihood of the data given an input xmin"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef discrete_max_likelihood(data, xmin, alpharange=(1.5,3.5), n_alpha=201):\n    likelihoods = discrete_likelihood_vector(data, xmin, alpharange=alpharange, n_alpha=n_alpha)\n    Lmax = np.max(likelihoods)\n    return Lmax", "response": "Returns the maximum likelihood of the data given an input xmin"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the most likely alpha for the data given an xmin", "response": "def most_likely_alpha(data, xmin, alpharange=(1.5,3.5), n_alpha=201):\n    \"\"\"\n    Return the most likely alpha for the data given an xmin\n    \"\"\"\n    alpha_vector = np.linspace(alpharange[0],alpharange[1],n_alpha)\n    return alpha_vector[discrete_max_likelihood_arg(data, xmin,\n                                                    alpharange=alpharange,\n                                                    n_alpha=n_alpha)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef discrete_alpha_mle(data, xmin):\n    # boolean indices of positive data\n    gexmin = (data>=xmin)\n    nn = gexmin.sum()\n    if nn < 2:\n        return 0\n    xx = data[gexmin]\n    alpha = 1.0 + float(nn) * (sum(log(xx/(float(xmin)-0.5))))**-1\n    return alpha", "response": "Return the discrete alpha in the continuous case"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef discrete_best_alpha(data, alpharangemults=(0.9,1.1), n_alpha=201, approximate=True, verbose=True):\n\n    xmins = np.unique(data)\n    if approximate:\n        alpha_of_xmin = [ discrete_alpha_mle(data,xmin) for xmin in xmins ]\n    else:\n        alpha_approx = [ discrete_alpha_mle(data,xmin) for xmin in xmins ]\n        alpharanges = [(0.9*a,1.1*a) for a in alpha_approx]\n        alpha_of_xmin = [ most_likely_alpha(data,xmin,alpharange=ar,n_alpha=n_alpha) for xmin,ar in zip(xmins,alpharanges) ]\n    ksvalues = [ discrete_ksD(data, xmin, alpha) for xmin,alpha in zip(xmins,alpha_of_xmin) ]\n\n    best_index = argmin(ksvalues)\n    best_alpha = alpha_of_xmin[best_index]\n    best_xmin = xmins[best_index]\n    best_ks = ksvalues[best_index]\n    best_likelihood = discrete_likelihood(data, best_xmin, best_alpha)\n\n    if verbose:\n        print(\"alpha = %f   xmin = %f   ksD = %f   L = %f   (n<x) = %i  (n>=x) = %i\" % (\n                best_alpha, best_xmin, best_ks, best_likelihood,\n                (data<best_xmin).sum(), (data>=best_xmin).sum()))\n\n    return best_alpha,best_xmin,best_ks,best_likelihood", "response": "Return the discrete best alpha for the given data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the power law ks - test D value w / data", "response": "def discrete_ksD(data, xmin, alpha):\n    \"\"\"\n    given a sorted data set, a minimum, and an alpha, returns the power law ks-test\n    D value w/data\n\n    The returned value is the \"D\" parameter in the ks test\n\n    (this is implemented differently from the continuous version because there\n    are potentially multiple identical points that need comparison to the power\n    law)\n    \"\"\"\n    zz = np.sort(data[data>=xmin])\n    nn = float(len(zz))\n    if nn < 2:\n        return np.inf\n    #cx = np.arange(nn,dtype='float')/float(nn)\n    #cf = 1.0-(zz/xmin)**(1.0-alpha)\n    model_cdf = 1.0-(zz.astype('float')/float(xmin))**(1.0-alpha)\n    data_cdf = np.searchsorted(zz,zz,side='left')/(float(nn))\n\n    ks = max(abs(model_cdf-data_cdf))\n    return ks"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef plfit(self, nosmall=True, finite=False, quiet=False, silent=False,\n              usefortran=False, usecy=False, xmin=None, verbose=False,\n              discrete=None, discrete_approx=True, discrete_n_alpha=1000,\n              skip_consistency_check=False):\n        \"\"\"\n        A Python implementation of the Matlab code\n        http://www.santafe.edu/~aaronc/powerlaws/plfit.m\n        from http://www.santafe.edu/~aaronc/powerlaws/\n\n        See A. Clauset, C.R. Shalizi, and M.E.J. Newman, \"Power-law distributions\n        in empirical data\" SIAM Review, 51, 661-703 (2009). (arXiv:0706.1062)\n        http://arxiv.org/abs/0706.1062\n\n        There are 3 implementations of xmin estimation.  The fortran version is\n        fastest, the C (cython) version is ~10% slower, and the python version\n        is ~3x slower than the fortran version.  Also, the cython code suffers\n        ~2% numerical error relative to the fortran and python for unknown\n        reasons.\n\n        There is also a discrete version implemented in python - it is\n        different from the continous version!\n\n        Parameters\n        ----------\n        discrete : bool or None\n            If *discrete* is None, the code will try to determine whether the\n            data set is discrete or continous based on the uniqueness of the\n            data; if your data set is continuous but you have any non-unique\n            data points (e.g., flagged \"bad\" data), the \"automatic\"\n            determination will fail.  If *discrete* is True or False, the\n            discrete or continuous fitter will be used, respectively.\n        xmin : float or int\n            If you specify xmin, the fitter will only determine alpha assuming\n            the given xmin; the rest of the code (and most of the complexity)\n            is determining an estimate for xmin and alpha.\n        nosmall : bool\n            When on, the code rejects low s/n points.  WARNING: This option,\n            which is on by default, may result in different answers than the\n            original Matlab code and the \"powerlaw\" python package\n        finite : bool\n            There is a 'finite-size bias' to the estimator.  The \"alpha\" the\n            code measures is \"alpha-hat\" s.t. \u03b1\u0342 = (n\u03b1-1)/(n-1), or \u03b1 = (1 + \u03b1\u0342\n            (n-1)) / n\n        quiet : bool\n            If False, delivers messages about what fitter is used and the fit\n            results\n        verbose : bool\n            Deliver descriptive messages about the fit parameters (only if\n            `quiet==False`)\n        silent : bool\n            If True, will print NO messages\n        skip_consistency_check : bool\n            The code will normally perform a consistency check to make sure the\n            alpha value computed by the fitter matches the alpha value computed\n            directly in python.  It is possible for numerical differences to\n            creep in, usually at the 10^-6 or less level.  If you see an\n            exception reporting this type of error, skipping the check can be\n            the appropriate next step.\n\n        Returns\n        -------\n        (xmin, alpha)\n        The best-fit xmin and alpha values\n        \"\"\"\n        x = self.data\n        if any(x < 0):\n            raise ValueError(\"Power law distributions are only valid for \"\n                             \"positive data.  Remove negative values before \"\n                             \"fitting.\")\n        z = np.sort(x)\n\n        # xmins = the unique values of x that can be used as the threshold for\n        # the power law fit\n        # argxmins = the index of each of these possible thresholds\n        xmins,argxmins = np.unique(z,return_index=True)\n        self._nunique = len(xmins)\n\n        if self._nunique == len(x) and discrete is None:\n            if verbose:\n                print(\"Using CONTINUOUS fitter because there are no repeated \"\n                      \"values.\")\n            discrete = False\n        elif self._nunique < len(x) and discrete is None:\n            if verbose:\n                print(\"Using DISCRETE fitter because there are repeated \"\n                      \"values.\")\n            discrete = True\n\n        t = time.time()\n        if xmin is None:\n            if discrete:\n                self.discrete_best_alpha(approximate=discrete_approx,\n                                         n_alpha=discrete_n_alpha,\n                                         verbose=verbose,\n                                         finite=finite)\n                return self._xmin,self._alpha\n            elif usefortran and fortranOK:\n                kstest_values,alpha_values = fplfit.plfit(z, 0)\n                if not quiet:\n                    print((\"FORTRAN plfit executed in %f seconds\" % (time.time()-t)))\n            elif usecy and cyOK:\n                kstest_values,alpha_values = cplfit.plfit_loop(z,\n                                                               nosmall=False,\n                                                               zunique=xmins,\n                                                               argunique=argxmins)\n                if not quiet:\n                    print((\"CYTHON plfit executed in %f seconds\" % (time.time()-t)))\n            else:\n                # python (numpy) version\n                f_alpha = alpha_gen(z)\n                f_kstest = kstest_gen(z)\n                alpha_values = np.asarray(list(map(f_alpha,xmins)),\n                                          dtype='float')\n                kstest_values = np.asarray(list(map(f_kstest,xmins)),\n                                           dtype='float')\n                if not quiet:\n                    print((\"PYTHON plfit executed in %f seconds\" % (time.time()-t)))\n\n            if not quiet:\n                if usefortran and not fortranOK:\n                    raise ImportError(\"fortran fplfit did not load\")\n                if usecy and not cyOK:\n                    raise ImportError(\"cython cplfit did not load\")\n\n            # For each alpha, the number of included data points is\n            # total data length - first index of xmin\n            # No +1 is needed: xmin is included.\n            sigma = (alpha_values-1)/np.sqrt(len(z)-argxmins)\n            # I had changed it to this, but I think this is wrong.\n            # sigma = (alpha_values-1)/np.sqrt(len(z)-np.arange(len(z)))\n\n            if nosmall:\n                # test to make sure the number of data points is high enough\n                # to provide a reasonable s/n on the computed alpha\n                goodvals = sigma<0.1\n                nmax = argmin(goodvals)\n                if nmax <= 0:\n                    nmax = len(xmins) - 1\n                    if not silent:\n                        print(\"Not enough data left after flagging \"\n                              \"low S/N points.  \"\n                              \"Using all data.\")\n            else:\n                # -1 to weed out the very last data point; it cannot be correct\n                # (can't have a power law with 1 data point).\n                nmax = len(xmins)-1\n\n            best_ks_index = argmin(kstest_values[:nmax])\n            xmin = xmins[best_ks_index]\n\n            self._alpha_values = alpha_values\n            self._xmin_kstest = kstest_values\n            if scipyOK:\n                # CHECK THIS\n                self._ks_prob_all = np.array([scipy.stats.ksone.sf(D_stat,\n                                                                   len(kstest_values)-ii)\n                                              for ii,D_stat in\n                                              enumerate(kstest_values)])\n            self._sigma = sigma\n\n            # sanity check\n            n = np.count_nonzero(z>=xmin)\n            alpha = 1. + float(n)/sum(log(z[z>=xmin]/xmin))\n            try:\n                if not skip_consistency_check:\n                    np.testing.assert_almost_equal(alpha,\n                                                   alpha_values[best_ks_index],\n                                                   decimal=4)\n            except AssertionError:\n                raise AssertionError(\"The alpha value computed was not self-\"\n                                     \"consistent.  This should not happen.  \"\n                                     \"However, it is possible that this is \"\n                                     \"a numerical uncertainty issue; the \"\n                                     \"values being compared are {0} and {1}.\"\n                                     \"If they are close enough, set \"\n                                     \"skip_consistency_check=True.\"\n                                     .format(alpha,\n                                             alpha_values[best_ks_index]))\n\n        z = z[z>=xmin]\n        n = len(z)\n        alpha = 1. + float(n) / sum(log(z/xmin))\n        if finite:\n            alpha = alpha*(n-1.)/n+1./n\n        if n < 50 and not finite and not silent:\n            print(('(PLFIT) Warning: finite-size bias may be present. n=%i' % n))\n\n        ks = max(abs( np.arange(n)/float(n) - (1-(xmin/z)**(alpha-1)) ))\n        # Parallels Eqn 3.5 in Clauset et al 2009, but zeta(alpha, xmin) =\n        # (alpha-1)/xmin.  Really is Eqn B3 in paper.\n        L = n*log((alpha-1)/xmin) - alpha*sum(log(z/xmin))\n        #requires another map... Larr = arange(len(unique(x))) * log((alpha_values-1)/unique(x)) - alpha_values*sum\n        self._likelihood = L\n        self._xmin = xmin\n        self._xmins = xmins\n        self._alpha= alpha\n        self._alphaerr = (alpha-1)/np.sqrt(n)\n\n        # this ks statistic may not have the same value as min(dat) because of unique()\n        self._ks = ks\n\n        if scipyOK:\n            self._ks_prob = scipy.stats.ksone.sf(ks, n)\n\n        self._ngtx = n\n        if n == 1:\n            if not silent:\n                print(\"Failure: only 1 point kept.  Probably not a power-law distribution.\")\n            self._alpha = alpha = 0\n            self._alphaerr = 0\n            self._likelihood = L = 0\n            self._ks = 0\n            self._ks_prob = 0\n            self._xmin = xmin\n            return xmin,0\n        if np.isnan(L) or np.isnan(xmin) or np.isnan(alpha):\n            raise ValueError(\"plfit failed; returned a nan\")\n\n        if not quiet:\n            if verbose: print(\"The lowest value included in the power-law fit, \", end=' ')\n            print(\"xmin: %g\" % xmin, end=' ')\n            if verbose: print(\"\\nThe number of values above xmin, \", end=' ')\n            print(\"n(>xmin): %i\" % n, end=' ')\n            if verbose: print(\"\\nThe derived power-law alpha (p(x)~x^-alpha) with MLE-derived error, \", end=' ')\n            print(\"alpha: %g +/- %g  \" % (alpha,self._alphaerr), end=' ')\n            if verbose: print(\"\\nThe log of the Likelihood (the maximized parameter; you minimized the negative log likelihood), \", end=' ')\n            print(\"Log-Likelihood: %g  \" % L, end=' ')\n            if verbose: print(\"\\nThe KS-test statistic between the best-fit power-law and the data, \", end=' ')\n            print(\"ks: %g\" % (ks), end=' ')\n            if scipyOK:\n                if verbose: print(\" occurs with probability  \", end=' ')\n                print(\"p(ks): %g\" % (self._ks_prob))\n            else:\n                print()\n\n        return xmin,alpha", "response": "This function is a wrapper for the Pfit function in the general case."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the discrete best alpha value for the current entry.", "response": "def discrete_best_alpha(self, alpharangemults=(0.9,1.1), n_alpha=201,\n                            approximate=True, verbose=True, finite=True):\n        \"\"\"\n        Use the maximum likelihood to determine the most likely value of alpha\n\n        *alpharangemults* [ 2-tuple ]\n            Pair of values indicating multiplicative factors above and below the\n            approximate alpha from the MLE alpha to use when determining the\n            \"exact\" alpha (by directly maximizing the likelihood function)\n        *n_alpha* [ int ]\n            Number of alpha values to use when measuring.  Larger number is more accurate.\n        *approximate* [ bool ]\n            If False, try to \"zoom-in\" around the MLE alpha and get the exact\n            best alpha value within some range around the approximate best\n        *vebose* [ bool ]\n        *finite* [ bool ]\n            Correction for finite data?\n        \"\"\"\n\n        data = self.data\n        self._xmins = xmins = np.unique(data)\n        if approximate:\n            alpha_of_xmin = [ discrete_alpha_mle(data,xmin) for xmin in xmins ]\n        else:\n            alpha_approx = [ discrete_alpha_mle(data,xmin) for xmin in xmins ]\n            alpharanges = [(0.9*a,1.1*a) for a in alpha_approx]\n            alpha_of_xmin = [ most_likely_alpha(data,xmin,alpharange=ar,n_alpha=n_alpha)\n                             for xmin,ar in zip(xmins,alpharanges) ]\n        ksvalues = np.array([discrete_ksD(data, xmin, alpha)\n                                for xmin,alpha in zip(xmins,alpha_of_xmin)\n                               ])\n        self._alpha_values = np.array(alpha_of_xmin)\n        self._xmin_kstest = ksvalues\n\n        ksvalues[np.isnan(ksvalues)] = np.inf\n\n        best_index = argmin(ksvalues)\n        self._alpha = best_alpha = alpha_of_xmin[best_index]\n        self._xmin = best_xmin = xmins[best_index]\n        self._ks = best_ks = ksvalues[best_index]\n        self._likelihood = best_likelihood = discrete_likelihood(data, best_xmin, best_alpha)\n\n        if finite:\n            self._alpha = self._alpha*(n-1.)/n+1./n\n\n        if verbose:\n            print(\"alpha = %f   xmin = %f   ksD = %f   L = %f   (n<x) = %i  (n>=x) = %i\" % (\n                    best_alpha, best_xmin, best_ks, best_likelihood,\n                    (data<best_xmin).sum(), (data>=best_xmin).sum()))\n\n\n        self._ngtx = n = (self.data>=self._xmin).sum()\n        self._alphaerr = (self._alpha-1.0)/np.sqrt(n)\n        if scipyOK:\n            self._ks_prob = scipy.stats.ksone.sf(self._ks, n)\n\n        return best_alpha,best_xmin,best_ks,best_likelihood"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nplot xmin versus the ks value for derived alpha.", "response": "def xminvsks(self, **kwargs):\n        \"\"\"\n        Plot xmin versus the ks value for derived alpha.  This plot can be used\n        as a diagnostic of whether you have derived the 'best' fit: if there are\n        multiple local minima, your data set may be well suited to a broken\n        powerlaw or a different function.\n        \"\"\"\n\n        pylab.plot(self._xmins,self._xmin_kstest,'.')\n        pylab.plot(self._xmin,self._ks,'s')\n        #pylab.errorbar([self._ks],self._alpha,yerr=self._alphaerr,fmt='+')\n\n        ax=pylab.gca()\n        ax.set_ylabel(\"KS statistic\")\n        ax.set_xlabel(\"min(x)\")\n        pylab.draw()\n\n        return ax"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef alphavsks(self,autozoom=True,**kwargs):\n\n        pylab.plot(self._alpha_values, self._xmin_kstest, '.')\n        pylab.errorbar(self._alpha, self._ks, xerr=self._alphaerr, fmt='+')\n\n        ax=pylab.gca()\n        if autozoom:\n            ax.set_ylim(0.8*(self._ks),3*(self._ks))\n            ax.set_xlim((self._alpha)-5*self._alphaerr,(self._alpha)+5*self._alphaerr)\n        ax.set_ylabel(\"KS statistic\")\n        ax.set_xlabel(r'$\\alpha$')\n        pylab.draw()\n\n        return ax", "response": "Plot alpha versus the ks value for derived alpha."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef plotcdf(self, x=None, xmin=None, alpha=None, pointcolor='k',\n                dolog=True, zoom=True, pointmarker='+', **kwargs):\n        \"\"\"\n        Plots CDF and powerlaw\n        \"\"\"\n        if x is None: x=self.data\n        if xmin is None: xmin=self._xmin\n        if alpha is None: alpha=self._alpha\n\n        x=np.sort(x)\n        n=len(x)\n        xcdf = np.arange(n,0,-1,dtype='float')/float(n)\n\n        q = x[x>=xmin]\n        fcdf = (q/xmin)**(1-alpha)\n        nc = xcdf[argmax(x>=xmin)]\n        fcdf_norm = nc*fcdf\n\n        D_location = argmax(xcdf[x>=xmin]-fcdf_norm)\n        pylab.vlines(q[D_location], xcdf[x>=xmin][D_location],\n                     fcdf_norm[D_location], color='m', linewidth=2, zorder=2)\n        pylab.plot([q[D_location]]*2,\n                   [xcdf[x>=xmin][D_location], fcdf_norm[D_location]],\n                   color='m',\n                   marker='s', zorder=3)\n\n        #plotx = pylab.linspace(q.min(),q.max(),1000)\n        #ploty = (plotx/xmin)**(1-alpha) * nc\n\n        if dolog:\n            pylab.loglog(x,xcdf,marker=pointmarker,color=pointcolor,**kwargs)\n            pylab.loglog(q,fcdf_norm,'r',**kwargs)\n        else:\n            pylab.semilogx(x,xcdf,marker=pointmarker,color=pointcolor,**kwargs)\n            pylab.semilogx(q,fcdf_norm,'r',**kwargs)\n\n        if zoom:\n            pylab.axis([xmin, x.max(), xcdf.min(), nc])", "response": "Plot CDF and powerlaw of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nplotting PDF of the current state of the object.", "response": "def plotpdf(self, x=None, xmin=None, alpha=None, nbins=50, dolog=True,\n                dnds=False, drawstyle='steps-post', histcolor='k', plcolor='r',\n                fill=False, dohist=True, **kwargs):\n        \"\"\"\n        Plots PDF and powerlaw.\n\n        kwargs is passed to pylab.hist and pylab.plot\n        \"\"\"\n        if x is None:\n            x=self.data\n        if xmin is None:\n            xmin=self._xmin\n        if alpha is None:\n            alpha=self._alpha\n\n        x=np.sort(x)\n        #n=len(x)\n\n        pylab.gca().set_xscale('log')\n        pylab.gca().set_yscale('log')\n\n        if dnds:\n            hb = pylab.histogram(x,bins=np.logspace(log10(min(x)),log10(max(x)),nbins))\n            h = hb[0]\n            b = hb[1]\n            db = hb[1][1:]-hb[1][:-1]\n            h = h/db\n            if dohist:\n                pylab.plot(b[:-1],h,drawstyle=drawstyle,color=histcolor,**kwargs)\n            #alpha -= 1\n        elif dolog:\n            hb = pylab.hist(x, bins=np.logspace(log10(min(x)), log10(max(x)),\n                                                nbins), log=True, fill=fill,\n                            edgecolor=histcolor, **kwargs)\n            alpha -= 1\n            h,b=hb[0],hb[1]\n            if not dohist:\n                for rect in hb[2]:\n                    rect.set_visible(False)\n        else:\n            hb = pylab.hist(x, bins=np.linspace((min(x)), (max(x)), nbins),\n                            fill=fill, edgecolor=histcolor, **kwargs)\n            h,b=hb[0],hb[1]\n            if not dohist:\n                for rect in hb[2]:\n                    rect.set_visible(False)\n        # plotting points are at the center of each bin\n        b = (b[1:]+b[:-1])/2.0\n\n        q = x[x>=xmin]\n        px = (alpha-1)/xmin * (q/xmin)**(-alpha)\n\n        # Normalize by the median ratio between the histogram and the power-law\n        # The normalization is semi-arbitrary; an average is probably just as valid\n        plotloc = (b>xmin)*(h>0)\n        norm = np.median(h[plotloc] / ((alpha-1)/xmin *\n                                       (b[plotloc]/xmin)**(-alpha)))\n        px = px*norm\n\n        plotx = pylab.linspace(q.min(),q.max(),1000)\n        ploty = (alpha-1)/xmin * (plotx/xmin)**(-alpha) * norm\n\n        #pylab.loglog(q,px,'r',**kwargs)\n        pylab.plot(plotx, ploty, color=plcolor, **kwargs)\n\n        axlims = pylab.axis()\n        pylab.vlines(xmin, axlims[2], max(px), colors=plcolor,\n                     linestyle='dashed')\n\n        if dolog and min(x) <= 0:\n            lolim = 0.1\n        else:\n            lolim = min(x)\n        pylab.gca().set_xlim(lolim, max(x))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nplots the power - law - predicted value on the Y - axis against the real value.", "response": "def plotppf(self,x=None,xmin=None,alpha=None,dolog=True,**kwargs):\n        \"\"\"\n        Plots the power-law-predicted value on the Y-axis against the real\n        values along the X-axis.  Can be used as a diagnostic of the fit\n        quality.\n        \"\"\"\n        if not(xmin): xmin=self._xmin\n        if not(alpha): alpha=self._alpha\n        if not(x): x=np.sort(self.data[self.data>xmin])\n        else: x=np.sort(x[x>xmin])\n\n        # N = M^(-alpha+1)\n        # M = N^(1/(-alpha+1))\n\n        m0 = min(x)\n        N = (1.0+np.arange(len(x)))[::-1]\n        xmodel = m0 * N**(1/(1-alpha)) / max(N)**(1/(1-alpha))\n\n        if dolog:\n            pylab.loglog(x,xmodel,'.',**kwargs)\n            pylab.gca().set_xlim(min(x),max(x))\n            pylab.gca().set_ylim(min(x),max(x))\n        else:\n            pylab.plot(x,xmodel,'.',**kwargs)\n        pylab.plot([min(x),max(x)],[min(x),max(x)],'k--')\n        pylab.xlabel(\"Real Value\")\n        pylab.ylabel(\"Power-Law Model Value\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef lognormal(self,doprint=True):\n        # N = float(self.data.shape[0])\n        # mu = log(self.data).sum() / N\n        # sigmasquared = ( ( log(self.data) - mu )**2 ).sum() / N\n        # self.lognormal_mu = mu\n        # self.lognormal_sigma = np.sqrt(sigmasquared)\n        # self.lognormal_likelihood = -N/2. * log(np.pi*2) - N/2. * log(sigmasquared) - 1/(2*sigmasquared) * (( self.data - mu )**2).sum()\n        # if doprint:\n        #     print \"Best fit lognormal is exp( -(x-%g)^2 / (2*%g^2)\" % (mu,np.sqrt(sigmasquared))\n        #     print \"Likelihood: %g\" % (self.lognormal_likelihood)\n        if scipyOK:\n            fitpars = scipy.stats.lognorm.fit(self.data)\n            self.lognormal_dist = scipy.stats.lognorm(*fitpars)\n            self.lognormal_ksD,self.lognormal_ksP = scipy.stats.kstest(self.data,self.lognormal_dist.cdf)\n            # nnlf = NEGATIVE log likelihood\n            self.lognormal_likelihood = -1*scipy.stats.lognorm.nnlf(fitpars,self.data)\n\n            # Is this the right likelihood ratio?\n            # Definition of L from eqn. B3 of Clauset et al 2009:\n            # L = log(p(x|alpha))\n            # _nnlf from scipy.stats.distributions:\n            # -sum(log(self._pdf(x, *args)),axis=0)\n            # Assuming the pdf and p(x|alpha) are both non-inverted, it looks\n            # like the _nnlf and L have opposite signs, which would explain the\n            # likelihood ratio I've used here:\n            self.power_lognorm_likelihood = (self._likelihood + self.lognormal_likelihood)\n            # a previous version had 2*(above).  That is the correct form if you want the likelihood ratio\n            # statistic \"D\": http://en.wikipedia.org/wiki/Likelihood-ratio_test\n            # The above explanation makes sense, since nnlf is the *negative* log likelihood function:\n            ## nnlf  -- negative log likelihood function (to minimize)\n            #\n            # Assuming we want the ratio between the POSITIVE likelihoods, the D statistic is:\n            # D = -2 log( L_power / L_lognormal )\n            self.likelihood_ratio_D = -2 * (log(self._likelihood/self.lognormal_likelihood))\n\n            if doprint:\n                print(\"Lognormal KS D: %g  p(D): %g\" % (self.lognormal_ksD,self.lognormal_ksP), end=' ')\n                print(\"  Likelihood Ratio Statistic (powerlaw/lognormal): %g\" % self.likelihood_ratio_D)\n                print(\"At this point, have a look at Clauset et al 2009 Appendix C: determining sigma(likelihood_ratio)\")", "response": "Produce the best fit lognormal distribution for a single object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef plot_lognormal_pdf(self,**kwargs):\n        if not hasattr(self,'lognormal_dist'):\n            return\n\n        normalized_pdf = self.lognormal_dist.pdf(self.data)/self.lognormal_dist.pdf(self.data).max()\n        minY,maxY = pylab.gca().get_ylim()\n        pylab.plot(self.data,normalized_pdf*maxY,'.',**kwargs)", "response": "Plot the fitted lognormal distribution of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef plot_lognormal_cdf(self,**kwargs):\n        if not hasattr(self,'lognormal_dist'):\n            return\n\n        x=np.sort(self.data)\n        n=len(x)\n        xcdf = np.arange(n,0,-1,dtype='float')/float(n)\n        lcdf = self.lognormal_dist.sf(x)\n\n        D_location = argmax(xcdf-lcdf)\n        pylab.vlines(x[D_location],xcdf[D_location],lcdf[D_location],color='m',linewidth=2)\n\n        pylab.plot(x, lcdf,',',**kwargs)", "response": "Plot the fitted lognormal distribution of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sanitize_turbo(html, allowed_tags=TURBO_ALLOWED_TAGS, allowed_attrs=TURBO_ALLOWED_ATTRS):\n    return clean(html, tags=allowed_tags, attributes=allowed_attrs, strip=True)", "response": "Sanitize HTML removing not allowed tags and attributes."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef configure_analytics_yandex(self, ident, params=None):\n        params = params or {}\n\n        data = {\n            'type': 'Yandex',\n            'id': ident,\n        }\n\n        if params:\n            data['params'] = '%s' % params\n\n        self.analytics.append(data)", "response": "Configure Yandex Metrika analytics counter."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef tag_list(self, tags):\n        return [\n            (tag.name, \"selected taggit-tag\" if tag.name in tags else \"taggit-tag\")\n            for tag in self.model.objects.all()\n        ]", "response": "Generates a list of tags identifying those previously submitted."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef gcd(self, lon1, lat1, lon2, lat2):\n        # convert decimal degrees to radians\n        lon1, lat1, lon2, lat2 = map(math.radians, [lon1, lat1, lon2, lat2])\n\n        # haversine formula\n        dlon = lon2 - lon1\n        dlat = lat2 - lat1\n        a = math.sin(dlat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2) ** 2\n        c = 2 * math.asin(math.sqrt(a))\n\n        dis = E.R * c\n        return dis", "response": "Calculate the great circle distance between two points lon1 lat1 lon2 lat2"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate md5 fingerprint. Shamelessly copied from http://stackoverflow. com/questions / 66682815 / deriving - an - ssh - fingerprint - from - a - public - key - in - python For specification 4. 1. 1", "response": "def hash_md5(self):\n        \"\"\"Calculate md5 fingerprint.\n\n        Shamelessly copied from http://stackoverflow.com/questions/6682815/deriving-an-ssh-fingerprint-from-a-public-key-in-python\n\n        For specification, see RFC4716, section 4.\"\"\"\n        fp_plain = hashlib.md5(self._decoded_key).hexdigest()\n        return \"MD5:\" + ':'.join(a + b for a, b in zip(fp_plain[::2], fp_plain[1::2]))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nunpacks the next data field from the given byte stream. Returns a tuple with ( location of next data field contents of requested data field.", "response": "def _unpack_by_int(self, data, current_position):\n        \"\"\"Returns a tuple with (location of next data field, contents of requested data field).\"\"\"\n        # Unpack length of data field\n        try:\n            requested_data_length = struct.unpack('>I', data[current_position:current_position + self.INT_LEN])[0]\n        except struct.error:\n            raise MalformedDataError(\"Unable to unpack %s bytes from the data\" % self.INT_LEN)\n\n        # Move pointer to the beginning of the data field\n        current_position += self.INT_LEN\n        remaining_data_length = len(data[current_position:])\n\n        if remaining_data_length < requested_data_length:\n            raise MalformedDataError(\n                \"Requested %s bytes, but only %s bytes available.\" % (requested_data_length, remaining_data_length)\n            )\n\n        next_data = data[current_position:current_position + requested_data_length]\n        # Move pointer to the end of the data field\n        current_position += requested_data_length\n        return current_position, next_data"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _parse_long(cls, data):\n        if sys.version < '3':\n            # this does not exist in python 3 - undefined-variable disabled to make pylint happier.\n            ret = long(0)  # pylint:disable=undefined-variable\n            for byte in data:\n                ret = (ret << 8) + ord(byte)\n        else:\n            ret = 0\n            for byte in data:\n                ret = (ret << 8) + byte\n        return ret", "response": "Calculate two s complement."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndecodes base64 coded part of the key.", "response": "def decode_key(cls, pubkey_content):\n        \"\"\"Decode base64 coded part of the key.\"\"\"\n        try:\n            decoded_key = base64.b64decode(pubkey_content.encode(\"ascii\"))\n        except (TypeError, binascii.Error):\n            raise MalformedDataError(\"Unable to decode the key\")\n        return decoded_key"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_options(self, options):\n        quote_open = False\n        parsed_options = {}\n\n        def parse_add_single_option(opt):\n            \"\"\"Parses and validates a single option, and adds it to parsed_options field.\"\"\"\n            if \"=\" in opt:\n                opt_name, opt_value = opt.split(\"=\", 1)\n                opt_value = opt_value.replace('\"', '')\n            else:\n                opt_name = opt\n                opt_value = True\n            if \" \" in opt_name or not self.OPTION_NAME_RE.match(opt_name):\n                raise InvalidOptionNameError(\"%s is not valid option name.\" % opt_name)\n            if self.strict_mode:\n                for valid_opt_name, value_required in self.OPTIONS_SPEC:\n                    if opt_name.lower() == valid_opt_name:\n                        if value_required and opt_value is True:\n                            raise MissingMandatoryOptionValueError(\"%s is missing mandatory value.\" % opt_name)\n                        break\n                else:\n                    raise UnknownOptionNameError(\"%s is unrecognized option name.\" % opt_name)\n            if opt_name not in parsed_options:\n                parsed_options[opt_name] = []\n            parsed_options[opt_name].append(opt_value)\n\n        start_of_current_opt = 0\n        i = 1  # Need to be set for empty options strings\n        for i, character in enumerate(options):\n            if character == '\"':  # only double quotes are allowed, no need to care about single quotes\n                quote_open = not quote_open\n            if quote_open:\n                continue\n            if character == \",\":\n                opt = options[start_of_current_opt:i]\n                parse_add_single_option(opt)\n                start_of_current_opt = i + 1\n                # Data begins after the first space\n        if start_of_current_opt + 1 != i:\n            opt = options[start_of_current_opt:]\n            parse_add_single_option(opt)\n        if quote_open:\n            raise InvalidOptionsError(\"Unbalanced quotes.\")\n        return parsed_options", "response": "Parses the ssh options string and returns a dictionary of parsed ssh options."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse ssh - rsa public keys.", "response": "def _process_ssh_rsa(self, data):\n        \"\"\"Parses ssh-rsa public keys.\"\"\"\n        current_position, raw_e = self._unpack_by_int(data, 0)\n        current_position, raw_n = self._unpack_by_int(data, current_position)\n\n        unpacked_e = self._parse_long(raw_e)\n        unpacked_n = self._parse_long(raw_n)\n\n        self.rsa = RSAPublicNumbers(unpacked_e, unpacked_n).public_key(default_backend())\n        self.bits = self.rsa.key_size\n\n        if self.strict_mode:\n            min_length = self.RSA_MIN_LENGTH_STRICT\n            max_length = self.RSA_MAX_LENGTH_STRICT\n        else:\n            min_length = self.RSA_MIN_LENGTH_LOOSE\n            max_length = self.RSA_MAX_LENGTH_LOOSE\n        if self.bits < min_length:\n            raise TooShortKeyError(\n                \"%s key data can not be shorter than %s bits (was %s)\" % (self.key_type, min_length, self.bits)\n            )\n        if self.bits > max_length:\n            raise TooLongKeyError(\n                \"%s key data can not be longer than %s bits (was %s)\" % (self.key_type, max_length, self.bits)\n            )\n        return current_position"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses the ssh - dss public keys.", "response": "def _process_ssh_dss(self, data):\n        \"\"\"Parses ssh-dsa public keys.\"\"\"\n        data_fields = {}\n        current_position = 0\n        for item in (\"p\", \"q\", \"g\", \"y\"):\n            current_position, value = self._unpack_by_int(data, current_position)\n            data_fields[item] = self._parse_long(value)\n\n        q_bits = self._bits_in_number(data_fields[\"q\"])\n        p_bits = self._bits_in_number(data_fields[\"p\"])\n        if q_bits != self.DSA_N_LENGTH:\n            raise InvalidKeyError(\"Incorrect DSA key parameters: bits(p)=%s, q=%s\" % (self.bits, q_bits))\n        if self.strict_mode:\n            min_length = self.DSA_MIN_LENGTH_STRICT\n            max_length = self.DSA_MAX_LENGTH_STRICT\n        else:\n            min_length = self.DSA_MIN_LENGTH_LOOSE\n            max_length = self.DSA_MAX_LENGTH_LOOSE\n        if p_bits < min_length:\n            raise TooShortKeyError(\"%s key can not be shorter than %s bits (was %s)\" % (self.key_type, min_length, p_bits))\n        if p_bits > max_length:\n            raise TooLongKeyError(\n                \"%s key data can not be longer than %s bits (was %s)\" % (self.key_type, max_length, p_bits)\n            )\n\n        dsa_parameters = DSAParameterNumbers(data_fields[\"p\"], data_fields[\"q\"], data_fields[\"g\"])\n        self.dsa = DSAPublicNumbers(data_fields[\"y\"], dsa_parameters).public_key(default_backend())\n        self.bits = self.dsa.key_size\n\n        return current_position"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses the ecdsa - sha public keys.", "response": "def _process_ecdsa_sha(self, data):\n        \"\"\"Parses ecdsa-sha public keys.\"\"\"\n        current_position, curve_information = self._unpack_by_int(data, 0)\n        if curve_information not in self.ECDSA_CURVE_DATA:\n            raise NotImplementedError(\"Invalid curve type: %s\" % curve_information)\n        curve, hash_algorithm = self.ECDSA_CURVE_DATA[curve_information]\n\n        current_position, key_data = self._unpack_by_int(data, current_position)\n        try:\n            # data starts with \\x04, which should be discarded.\n            ecdsa_key = ecdsa.VerifyingKey.from_string(key_data[1:], curve, hash_algorithm)\n        except AssertionError:\n            raise InvalidKeyError(\"Invalid ecdsa key\")\n        self.bits = int(curve_information.replace(b\"nistp\", b\"\"))\n        self.ecdsa = ecdsa_key\n        return current_position"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing ed25516 keys. This only validates the current bit length and returns the current bit position.", "response": "def _process_ed25516(self, data):\n        \"\"\"Parses ed25516 keys.\n\n        There is no (apparent) way to validate ed25519 keys. This only\n        checks data length (256 bits), but does not try to validate\n        the key in any way.\"\"\"\n\n        current_position, verifying_key = self._unpack_by_int(data, 0)\n        verifying_key_length = len(verifying_key) * 8\n        verifying_key = self._parse_long(verifying_key)\n\n        if verifying_key < 0:\n            raise InvalidKeyError(\"ed25519 verifying key must be >0.\")\n\n        self.bits = verifying_key_length\n        if self.bits != 256:\n            raise InvalidKeyLengthError(\"ed25519 keys must be 256 bits (was %s bits)\" % self.bits)\n        return current_position"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse(self, keydata=None):\n        if keydata is None:\n            if self.keydata is None:\n                raise ValueError(\"Key data must be supplied either in constructor or to parse()\")\n            keydata = self.keydata\n        else:\n            self.reset()\n            self.keydata = keydata\n\n        if keydata.startswith(\"---- BEGIN SSH2 PUBLIC KEY ----\"):\n            # SSH2 key format\n            key_type = None  # There is no redundant key-type field - skip comparing plain-text and encoded data.\n            pubkey_content = \"\".join([line for line in keydata.split(\"\\n\") if \":\" not in line and \"----\" not in line])\n        else:\n            key_parts = self._split_key(keydata)\n            key_type = key_parts[0]\n            pubkey_content = key_parts[1]\n\n        self._decoded_key = self.decode_key(pubkey_content)\n\n        # Check key type\n        current_position, unpacked_key_type = self._unpack_by_int(self._decoded_key, 0)\n        if key_type is not None and key_type != unpacked_key_type.decode():\n            raise InvalidTypeError(\"Keytype mismatch: %s != %s\" % (key_type, unpacked_key_type))\n\n        self.key_type = unpacked_key_type\n\n        key_data_length = self._process_key(self._decoded_key[current_position:])\n        current_position = current_position + key_data_length\n\n        if current_position != len(self._decoded_key):\n            raise MalformedDataError(\"Leftover data: %s bytes\" % (len(self._decoded_key) - current_position))\n\n        if self.disallow_options and self.options:\n            raise InvalidOptionsError(\"Options are disallowed.\")", "response": "Validates SSH public key. Returns None if invalid."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a list of strings describing the status codes of a single GSSAPI message.", "response": "def status_list(maj_status, min_status, status_type=C.GSS_C_GSS_CODE, mech_type=C.GSS_C_NO_OID):\n    \"\"\"\n    Creates a \"friendly\" error message from a GSS status code. This is used to create the\n    :attr:`GSSCException.message` of a :class:`GSSCException`.\n\n    :param maj_status: The major status reported by the C GSSAPI.\n    :type maj_status: int\n    :param min_status: The minor status reported by the C GSSAPI.\n    :type min_status: int\n    :param status_type: Whether the status is a general GSSAPI status or a mechanism status.\n    :type status_type: ``GSS_C_GSS_CODE`` or ``GSS_C_MECH_CODE``\n    :param mech_type: Optional mechanism type, if the status is a mechanism status.\n    :type mech_type: :class:`~gssapi.oids.OID`\n    :returns: a list of strings describing the error.\n    :rtype: list of strings\n    \"\"\"\n    from .oids import OID\n\n    statuses = []\n    message_context = ffi.new('OM_uint32[1]')\n    minor_status = ffi.new('OM_uint32[1]')\n\n    if isinstance(mech_type, OID):\n        mech_type = ffi.addressof(mech_type._oid)  # OID._oid is type \"struct gss_OID_desc\"\n    elif mech_type == C.GSS_C_NO_OID:\n        mech_type = ffi.cast('gss_OID', C.GSS_C_NO_OID)\n    elif not isinstance(mech_type, ffi.CData) or ffi.typeof(mech_type) != ffi.typeof('gss_OID'):\n        raise TypeError(\n            \"Expected mech_type to be a gssapi.oids.OID or gss_OID, got {0}\".format(type(mech_type))\n        )\n\n    while True:\n        status_buf = ffi.new('gss_buffer_desc[1]')\n\n        try:\n            retval = C.gss_display_status(\n                minor_status,\n                maj_status,\n                status_type,\n                mech_type,\n                message_context,\n                status_buf\n            )\n            if retval == C.GSS_S_COMPLETE:\n                statuses.append(\"({0}) {1}.\".format(\n                    maj_status,\n                    _buf_to_str(status_buf[0]).decode(\"utf-8\", errors=\"replace\")\n                ))\n            elif retval == C.GSS_S_BAD_MECH:\n                statuses.append(\"Unsupported mechanism type passed to GSSException\")\n                break\n            elif retval == C.GSS_S_BAD_STATUS:\n                statuses.append(\"Unrecognized status value passed to GSSException\")\n                break\n        finally:\n            C.gss_release_buffer(minor_status, status_buf)\n\n        if message_context[0] == 0:\n            break\n\n    if min_status:\n        minor_status_msgs = status_list(min_status, 0, C.GSS_C_MECH_CODE, mech_type)\n        if minor_status_msgs:\n            statuses.append(\"Minor code:\")\n            statuses.extend(minor_status_msgs)\n    return statuses"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a canonical name based on this internal name.", "response": "def canonicalize(self, mech):\n        \"\"\"\n        Create a canonical mechanism name (MechName) from an arbitrary internal name. The canonical\n        MechName would be set as the :attr:`~gssapi.ctx.AcceptContext.peer_name` property on an\n        acceptor's :class:`~gssapi.ctx.AcceptContext` if an initiator performed a successful\n        authentication to the acceptor using the given mechanism, using a\n        :class:`~gssapi.creds.Credential` obtained using this :class:`Name`.\n\n        :param mech: The mechanism to canonicalize this name for\n        :type mech: :class:`~gssapi.oids.OID`\n        :returns: a canonical mechanism name based on this internal name.\n        :rtype: :class:`MechName`\n        \"\"\"\n        if isinstance(mech, OID):\n            oid = mech._oid\n        else:\n            raise TypeError(\"Expected an OID, got \" + str(type(mech)))\n\n        minor_status = ffi.new('OM_uint32[1]')\n        out_name = ffi.new('gss_name_t[1]')\n        try:\n            retval = C.gss_canonicalize_name(\n                minor_status, self._name[0], ffi.addressof(oid), out_name\n            )\n            if GSS_ERROR(retval):\n                raise _exception_for_status(retval, minor_status[0])\n            return MechName(out_name, mech)\n        except:\n            C.gss_release_name(minor_status, out_name)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef export(self):\n        minor_status = ffi.new('OM_uint32[1]')\n        output_buffer = ffi.new('gss_buffer_desc[1]')\n        retval = C.gss_export_name(\n            minor_status,\n            self._name[0],\n            output_buffer\n        )\n        try:\n            if GSS_ERROR(retval):\n                if minor_status[0] and self._mech_type:\n                    raise _exception_for_status(retval, minor_status[0], self._mech_type)\n                else:\n                    raise _exception_for_status(retval, minor_status[0])\n\n            return _buf_to_str(output_buffer[0])\n        finally:\n            if output_buffer[0].length != 0:\n                C.gss_release_buffer(minor_status, output_buffer)", "response": "Returns a string representation of this Mechanism Name which can be used for direct comparison against other Mechanism Names."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns True if integrity protection has been negotiated in this context False otherwise.", "response": "def integrity_negotiated(self):\n        \"\"\"\n        After :meth:`step` has been called, this property will be set to\n        True if integrity protection (signing) has been negotiated in this context, False\n        otherwise. If this property is True, you can use :meth:`get_mic` to sign messages with a\n        message integrity code (MIC), which the peer application can verify.\n        \"\"\"\n        return (\n            self.flags & C.GSS_C_INTEG_FLAG\n        ) and (\n            self.established or (self.flags & C.GSS_C_PROT_READY_FLAG)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef confidentiality_negotiated(self):\n        return (\n            self.flags & C.GSS_C_CONF_FLAG\n        ) and (\n            self.established or (self.flags & C.GSS_C_PROT_READY_FLAG)\n        )", "response": "Returns True if confidentiality negotiated in this context False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns True if the security context can use replay detection for messages protected by the current user.", "response": "def replay_detection_negotiated(self):\n        \"\"\"\n        After :meth:`step` has been called, this property will be set to\n        True if the security context can use replay detection for messages protected by\n        :meth:`get_mic` and :meth:`wrap`. False if replay detection cannot be used.\n        \"\"\"\n        return (\n            self.flags & C.GSS_C_REPLAY_FLAG\n        ) and (\n            self.established or (self.flags & C.GSS_C_PROT_READY_FLAG)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sequence_detection_negotiated(self):\n        return (\n            self.flags & C.GSS_C_SEQUENCE_FLAG\n        ) and (\n            self.established or (self.flags & C.GSS_C_PROT_READY_FLAG)\n        )", "response": "Returns True if the security context is in sequence or OOS detection mode."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_mic(self, message, qop_req=C.GSS_C_QOP_DEFAULT):\n        if not (self.flags & C.GSS_C_INTEG_FLAG):\n            raise GSSException(\"No integrity protection negotiated.\")\n        if not (self.established or (self.flags & C.GSS_C_PROT_READY_FLAG)):\n            raise GSSException(\"Protection not yet ready.\")\n\n        minor_status = ffi.new('OM_uint32[1]')\n        output_token_buffer = ffi.new('gss_buffer_desc[1]')\n        message_buffer = ffi.new('gss_buffer_desc[1]')\n        message_buffer[0].length = len(message)\n        c_str_message = ffi.new('char[]', message)\n        message_buffer[0].value = c_str_message\n        retval = C.gss_get_mic(\n            minor_status,\n            self._ctx[0],\n            ffi.cast('gss_qop_t', qop_req),\n            message_buffer,\n            output_token_buffer\n        )\n        try:\n            if GSS_ERROR(retval):\n                if minor_status[0] and self.mech_type:\n                    raise _exception_for_status(retval, minor_status[0], self.mech_type)\n                else:\n                    raise _exception_for_status(retval, minor_status[0])\n\n            output_token = _buf_to_str(output_token_buffer[0])\n            return output_token\n        finally:\n            if output_token_buffer[0].length != 0:\n                C.gss_release_buffer(minor_status, output_token_buffer)", "response": "Calculates a MIC over an application message and returns the MIC in a token."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef verify_mic(self, message, mic, supplementary=False):\n        if not (self.flags & C.GSS_C_INTEG_FLAG):\n            raise GSSException(\"No integrity protection negotiated.\")\n        if not (self.established or (self.flags & C.GSS_C_PROT_READY_FLAG)):\n            raise GSSException(\"Protection not yet ready.\")\n\n        minor_status = ffi.new('OM_uint32[1]')\n        message_buffer = ffi.new('gss_buffer_desc[1]')\n        message_buffer[0].length = len(message)\n        c_str_message = ffi.new('char[]', message)\n        message_buffer[0].value = c_str_message\n        mic_buffer = ffi.new('gss_buffer_desc[1]')\n        mic_buffer[0].length = len(mic)\n        c_str_mic = ffi.new('char[]', mic)\n        mic_buffer[0].value = c_str_mic\n        qop_state = ffi.new('gss_qop_t[1]')\n\n        retval = C.gss_verify_mic(\n            minor_status,\n            self._ctx[0],\n            message_buffer,\n            mic_buffer,\n            qop_state\n        )\n        if GSS_ERROR(retval):\n            if minor_status[0] and self.mech_type:\n                raise _exception_for_status(retval, minor_status[0], self.mech_type)\n            else:\n                raise _exception_for_status(retval, minor_status[0])\n        supp_bits = _status_bits(retval)\n        if supplementary:\n            return qop_state[0], supp_bits\n        elif len(supp_bits) > 0:\n            # Raise if unseq/replayed token detected\n            raise _exception_for_status(retval, minor_status[0])\n        else:\n            return qop_state[0]", "response": "This method verifies that the message is valid for the given MIC."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwraps a message with a message integrity code and returns a byte array that can be used to encrypt the MIC.", "response": "def wrap(self, message, conf_req=True, qop_req=C.GSS_C_QOP_DEFAULT):\n        \"\"\"\n        Wraps a message with a message integrity code, and if `conf_req` is True, encrypts the\n        message. The message can be decrypted and the MIC verified by the peer by passing the\n        token returned from this method to :meth:`unwrap` on the peer's side.\n\n        :param message: The message to wrap\n        :type message: bytes\n        :param conf_req: Whether to require confidentiality (encryption)\n        :type conf_req: bool\n        :param qop_req: The quality of protection required. It is recommended to not change this\n            from the default as most GSSAPI implementations do not support it.\n        :returns: the wrapped message in a token suitable for passing to :meth:`unwrap`\n        :rtype: bytes\n        :raises: GSSException if integrity protection is not available\n            (:attr:`integrity_negotiated` is False), or if the `conf_req` parameter is True and\n            confidentiality protection is not available\n            (:attr:`confidentiality_negotiated` is False)\n        \"\"\"\n        if not (self.flags & C.GSS_C_INTEG_FLAG):\n            raise GSSException(\"No integrity protection negotiated.\")\n        if (conf_req and not (self.flags & C.GSS_C_CONF_FLAG)):\n            raise GSSException(\"No confidentiality protection negotiated.\")\n        if not (self.established or (self.flags & C.GSS_C_PROT_READY_FLAG)):\n            raise GSSException(\"Protection not yet ready.\")\n\n        minor_status = ffi.new('OM_uint32[1]')\n        output_token_buffer = ffi.new('gss_buffer_desc[1]')\n        message_buffer = ffi.new('gss_buffer_desc[1]')\n        message_buffer[0].length = len(message)\n        c_str_message = ffi.new('char[]', message)\n        message_buffer[0].value = c_str_message\n        conf_state = ffi.new('int[1]')\n\n        retval = C.gss_wrap(\n            minor_status,\n            self._ctx[0],\n            ffi.cast('int', conf_req),\n            ffi.cast('gss_qop_t', qop_req),\n            message_buffer,\n            conf_state,\n            output_token_buffer\n        )\n        try:\n            if GSS_ERROR(retval):\n                if minor_status[0] and self.mech_type:\n                    raise _exception_for_status(retval, minor_status[0], self.mech_type)\n                else:\n                    raise _exception_for_status(retval, minor_status[0])\n\n            output_token = _buf_to_str(output_token_buffer[0])\n            if conf_req and not conf_state[0]:\n                raise GSSException(\"No confidentiality protection.\")\n            return output_token\n        finally:\n            if output_token_buffer[0].length != 0:\n                C.gss_release_buffer(minor_status, output_token_buffer)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef unwrap(self, message, conf_req=True, qop_req=None, supplementary=False):\n        if not (self.flags & C.GSS_C_INTEG_FLAG):\n            raise GSSException(\"No integrity protection negotiated.\")\n        if not (self.established or (self.flags & C.GSS_C_PROT_READY_FLAG)):\n            raise GSSException(\"Protection not yet ready.\")\n\n        minor_status = ffi.new('OM_uint32[1]')\n        output_buffer = ffi.new('gss_buffer_desc[1]')\n        message_buffer = ffi.new('gss_buffer_desc[1]')\n        message_buffer[0].length = len(message)\n        c_str_message = ffi.new('char[]', message)\n        message_buffer[0].value = c_str_message\n        conf_state = ffi.new('int[1]')\n        qop_state = ffi.new('gss_qop_t[1]')\n\n        retval = C.gss_unwrap(\n            minor_status,\n            self._ctx[0],\n            message_buffer,\n            output_buffer,\n            conf_state,\n            qop_state\n        )\n        try:\n            if GSS_ERROR(retval):\n                if minor_status[0] and self.mech_type:\n                    raise _exception_for_status(retval, minor_status[0], self.mech_type)\n                else:\n                    raise _exception_for_status(retval, minor_status[0])\n\n            output = _buf_to_str(output_buffer[0])\n            if conf_req and not conf_state[0]:\n                raise GSSException(\"No confidentiality protection.\")\n            if qop_req is not None and qop_req != qop_state[0]:\n                raise GSSException(\"QOP {0} does not match required value {1}.\".format(qop_state[0], qop_req))\n            supp_bits = _status_bits(retval)\n            if supplementary:\n                return output, supp_bits\n            elif len(supp_bits) > 0:\n                # Raise if unseq/replayed token detected\n                raise _exception_for_status(retval, minor_status[0], token=output)\n            else:\n                return output\n        finally:\n            if output_buffer[0].length != 0:\n                C.gss_release_buffer(minor_status, output_buffer)", "response": "Unwraps a message with the security context s cryptographic keys."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating the maximum size of a wrapped token.", "response": "def get_wrap_size_limit(self, output_size, conf_req=True, qop_req=C.GSS_C_QOP_DEFAULT):\n        \"\"\"\n        Calculates the maximum size of message that can be fed to :meth:`wrap` so that the size of\n        the resulting wrapped token (message plus wrapping overhead) is no more than a given\n        maximum output size.\n\n        :param output_size: The maximum output size (in bytes) of a wrapped token\n        :type output_size: int\n        :param conf_req: Whether to calculate the wrapping overhead for confidentiality protection\n            (if True) or just integrity protection (if False).\n        :type conf_req: bool\n        :returns: The maximum input size (in bytes) of message that can be passed to :meth:`wrap`\n        :rtype: int\n        \"\"\"\n\n        minor_status = ffi.new('OM_uint32[1]')\n        max_input_size = ffi.new('OM_uint32[1]')\n        retval = C.gss_wrap_size_limit(\n            minor_status,\n            self._ctx[0],\n            ffi.cast('int', conf_req),\n            ffi.cast('gss_qop_t', qop_req),\n            ffi.cast('OM_uint32', output_size),\n            max_input_size\n        )\n        if GSS_ERROR(retval):\n            if minor_status[0] and self.mech_type:\n                raise _exception_for_status(retval, minor_status[0], self.mech_type)\n            else:\n                raise _exception_for_status(retval, minor_status[0])\n\n        return max_input_size[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprocesses a context token and return a new token.", "response": "def process_context_token(self, context_token):\n        \"\"\"\n        Provides a way to pass an asynchronous token to the security context, outside of the normal\n        context-establishment token passing flow. This method is not normally used, but some\n        example uses are:\n\n        * when the initiator's context is established successfully but the acceptor's context isn't\n          and the acceptor needs to signal to the initiator that the context shouldn't be used.\n        * if :meth:`delete` on one peer's context returns a final token that can be passed to the\n          other peer to indicate the other peer's context should be torn down as well (though it's\n          recommended that :meth:`delete` should return nothing, i.e. this method should not be\n          used by GSSAPI mechanisms).\n\n        :param context_token: The context token to pass to the security context\n        :type context_token: bytes\n        :raises: :exc:`~gssapi.error.DefectiveToken` if consistency checks on the token failed.\n            :exc:`~gssapi.error.NoContext` if this context is invalid.\n            :exc:`~gssapi.error.GSSException` for any other GSSAPI errors.\n        \"\"\"\n        minor_status = ffi.new('OM_uint32[1]')\n        context_token_buffer = ffi.new('gss_buffer_desc[1]')\n        context_token_buffer[0].length = len(context_token)\n        c_str_context_token = ffi.new('char[]', context_token)\n        context_token_buffer[0].value = c_str_context_token\n        retval = C.gss_process_context_token(\n            minor_status,\n            self._ctx[0],\n            context_token_buffer\n        )\n        if GSS_ERROR(retval):\n            if minor_status[0] and self.mech_type:\n                raise _exception_for_status(retval, minor_status[0], self.mech_type)\n            else:\n                raise _exception_for_status(retval, minor_status[0])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef export(self):\n        if not (self.flags & C.GSS_C_TRANS_FLAG):\n            raise GSSException(\"Context is not transferable.\")\n        if not self._ctx:\n            raise GSSException(\"Can't export empty/invalid context.\")\n\n        minor_status = ffi.new('OM_uint32[1]')\n        output_token_buffer = ffi.new('gss_buffer_desc[1]')\n        retval = C.gss_export_sec_context(\n            minor_status,\n            self._ctx,\n            output_token_buffer\n        )\n        try:\n            if GSS_ERROR(retval):\n                if minor_status[0] and self.mech_type:\n                    raise _exception_for_status(retval, minor_status[0], self.mech_type)\n                else:\n                    raise _exception_for_status(retval, minor_status[0])\n\n            exported_token = _buf_to_str(output_token_buffer[0])\n            # Set our context to a 'blank' context\n            self._ctx = ffi.new('gss_ctx_id_t[1]')\n            return exported_token\n        finally:\n            if output_token_buffer[0].length != 0:\n                C.gss_release_buffer(minor_status, output_token_buffer)", "response": "This method deactivates the security context and returns an interprocess token which is used to create a new interprocess token for the current security context."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the lifetime of the context.", "response": "def lifetime(self):\n        \"\"\"\n        The lifetime of the context in seconds (only valid after :meth:`step` has been called). If\n        the context does not have a time limit on its validity, this will be\n        :const:`gssapi.C_INDEFINITE`\n        \"\"\"\n\n        minor_status = ffi.new('OM_uint32[1]')\n        lifetime_rec = ffi.new('OM_uint32[1]')\n\n        retval = C.gss_inquire_context(\n            minor_status,\n            self._ctx[0],\n            ffi.NULL,  # src_name\n            ffi.NULL,  # target_name\n            lifetime_rec,\n            ffi.NULL,  # mech_type\n            ffi.NULL,  # ctx_flags\n            ffi.NULL,  # locally_initiated\n            ffi.NULL   # established\n        )\n        if GSS_ERROR(retval):\n            if minor_status[0] and self.mech_type:\n                raise _exception_for_status(retval, minor_status[0], self.mech_type)\n            else:\n                raise _exception_for_status(retval, minor_status[0])\n        return lifetime_rec[0]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndeleting a security context. This method will delete the local data structures associated with the specified security context, and may return an output token, which when passed to :meth:`process_context_token` on the peer may instruct it to also delete its context. RFC 2744 recommends that GSSAPI mechanisms do not emit any output token when they're deleted, so this behaviour could be considered deprecated. After this method is called, this security context will become invalid and should not be used in any way. :returns: An output token if one was emitted by the GSSAPI mechanism, otherwise an empty bytestring. :rtype: bytes", "response": "def delete(self):\n        \"\"\"\n        Delete a security context. This method will delete the local data structures associated\n        with the specified security context, and may return an output token, which when passed to\n        :meth:`process_context_token` on the peer may instruct it to also delete its context.\n\n        RFC 2744 recommends that GSSAPI mechanisms do not emit any output token when they're\n        deleted, so this behaviour could be considered deprecated.\n\n        After this method is called, this security context will become invalid and should not be\n        used in any way.\n\n        :returns: An output token if one was emitted by the GSSAPI mechanism, otherwise an empty\n            bytestring.\n        :rtype: bytes\n        \"\"\"\n\n        if not self._ctx[0]:\n            raise GSSException(\"Can't delete invalid context\")\n        output_token_buffer = ffi.new('gss_buffer_desc[1]')\n        minor_status = ffi.new('OM_uint32[1]')\n        retval = C.gss_delete_sec_context(\n            minor_status,\n            self._ctx,\n            output_token_buffer\n        )\n        self._ctx = ffi.new('gss_ctx_id_t[1]')\n        self._reset_flags()\n        try:\n            if GSS_ERROR(retval):\n                if minor_status[0] and self.mech_type:\n                    raise _exception_for_status(retval, minor_status[0], self.mech_type)\n                else:\n                    raise _exception_for_status(retval, minor_status[0])\n\n            return _buf_to_str(output_token_buffer[0])\n        finally:\n            if output_token_buffer[0].length != 0:\n                C.gss_release_buffer(minor_status, output_token_buffer)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef step(self, input_token=None):\n\n        minor_status = ffi.new('OM_uint32[1]')\n\n        if input_token:\n            input_token_buffer = ffi.new('gss_buffer_desc[1]')\n            input_token_buffer[0].length = len(input_token)\n            c_str_input_token = ffi.new('char[]', input_token)\n            input_token_buffer[0].value = c_str_input_token\n        else:\n            input_token_buffer = ffi.cast('gss_buffer_t', C.GSS_C_NO_BUFFER)\n\n        if isinstance(self._desired_mech, OID):\n            desired_mech = ffi.addressof(self._desired_mech._oid)\n        else:\n            desired_mech = ffi.cast('gss_OID', C.GSS_C_NO_OID)\n\n        actual_mech = ffi.new('gss_OID[1]')\n        output_token_buffer = ffi.new('gss_buffer_desc[1]')\n        actual_flags = ffi.new('OM_uint32[1]')\n        actual_time = ffi.new('OM_uint32[1]')\n\n        if self._cred_object is not None:\n            cred = self._cred_object._cred[0]\n        else:\n            cred = ffi.cast('gss_cred_id_t', C.GSS_C_NO_CREDENTIAL)\n\n        retval = C.gss_init_sec_context(\n            minor_status,\n            cred,\n            self._ctx,\n            self.peer_name._name[0],\n            desired_mech,\n            self._req_flags,\n            self._time_req,\n            self._channel_bindings,\n            input_token_buffer,\n            actual_mech,\n            output_token_buffer,\n            actual_flags,\n            actual_time\n        )\n        try:\n            if output_token_buffer[0].length != 0:\n                out_token = _buf_to_str(output_token_buffer[0])\n            else:\n                out_token = None\n\n            if GSS_ERROR(retval):\n                if minor_status[0] and actual_mech[0]:\n                    raise _exception_for_status(retval, minor_status[0], actual_mech[0], out_token)\n                else:\n                    raise _exception_for_status(retval, minor_status[0], None, out_token)\n\n            self.established = not (retval & C.GSS_S_CONTINUE_NEEDED)\n            self.flags = actual_flags[0]\n\n            if actual_mech[0]:\n                self.mech_type = OID(actual_mech[0][0])\n\n            return out_token\n        except:\n            if self._ctx[0]:\n                C.gss_delete_sec_context(\n                    minor_status,\n                    self._ctx,\n                    ffi.cast('gss_buffer_t', C.GSS_C_NO_BUFFER)\n                )\n                self._reset_flags()\n            raise\n        finally:\n            if output_token_buffer[0].length != 0:\n                C.gss_release_buffer(minor_status, output_token_buffer)", "response": "Performs a step to establish the context as an initiator."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nperforming a step to establish the context as an acceptor.", "response": "def step(self, input_token):\n        \"\"\"Performs a step to establish the context as an acceptor.\n\n        This method should be called in a loop and fed input tokens from the initiator, and its\n        output tokens should be sent to the initiator, until this context's :attr:`established`\n        attribute is True.\n\n        :param input_token: The input token from the initiator (required).\n        :type input_token: bytes\n        :returns: either a byte string with the next token to send to the initiator,\n            or None if there is no further token to send to the initiator.\n        :raises: :exc:`~gssapi.error.GSSException` if there is an error establishing the context.\n        \"\"\"\n        minor_status = ffi.new('OM_uint32[1]')\n        input_token_buffer = ffi.new('gss_buffer_desc[1]')\n        input_token_buffer[0].length = len(input_token)\n        c_str_import_token = ffi.new('char[]', input_token)\n        input_token_buffer[0].value = c_str_import_token\n\n        mech_type = ffi.new('gss_OID[1]')\n        output_token_buffer = ffi.new('gss_buffer_desc[1]')\n        src_name_handle = ffi.new('gss_name_t[1]')\n        actual_flags = ffi.new('OM_uint32[1]')\n        time_rec = ffi.new('OM_uint32[1]')\n        delegated_cred_handle = ffi.new('gss_cred_id_t[1]')\n\n        if self._cred_object is not None:\n            cred = self._cred_object._cred[0]\n        else:\n            cred = ffi.cast('gss_cred_id_t', C.GSS_C_NO_CREDENTIAL)\n\n        retval = C.gss_accept_sec_context(\n            minor_status,\n            self._ctx,\n            cred,\n            input_token_buffer,\n            self._channel_bindings,\n            src_name_handle,\n            mech_type,\n            output_token_buffer,\n            actual_flags,\n            time_rec,\n            delegated_cred_handle\n        )\n        if src_name_handle[0]:\n            src_name = MechName(src_name_handle, mech_type[0])  # make sure src_name is GC'd\n        try:\n            if output_token_buffer[0].length != 0:\n                out_token = _buf_to_str(output_token_buffer[0])\n            else:\n                out_token = None\n\n            if GSS_ERROR(retval):\n                if minor_status[0] and mech_type[0]:\n                    raise _exception_for_status(retval, minor_status[0], mech_type[0], out_token)\n                else:\n                    raise _exception_for_status(retval, minor_status[0], None, out_token)\n\n            self.established = not (retval & C.GSS_S_CONTINUE_NEEDED)\n            self.flags = actual_flags[0]\n\n            if (self.flags & C.GSS_C_DELEG_FLAG):\n                self.delegated_cred = Credential(delegated_cred_handle)\n\n            if mech_type[0]:\n                self.mech_type = OID(mech_type[0][0])\n\n                if src_name_handle[0]:\n                    src_name._mech_type = self.mech_type\n                    self.peer_name = src_name\n\n            return out_token\n        except:\n            if self._ctx:\n                C.gss_delete_sec_context(\n                    minor_status,\n                    self._ctx,\n                    ffi.cast('gss_buffer_t', C.GSS_C_NO_BUFFER)\n                )\n                self._reset_flags()\n            raise\n        finally:\n            if output_token_buffer[0].length != 0:\n                C.gss_release_buffer(minor_status, output_token_buffer)\n            # if self.delegated_cred is present, it will handle gss_release_cred:\n            if delegated_cred_handle[0] and not self.delegated_cred:\n                C.gss_release_cred(minor_status, delegated_cred_handle)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef mechs(self):\n        if not self._mechs:\n            self._mechs = self._inquire(False, False, False, True)[3]\n        return self._mechs", "response": "Returns a set of mechanisms supported by the credential."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nexports this credential into a byte string which can be passed to imprt in order to serialize it into a byte string.", "response": "def export(self):\n        \"\"\"\n        Serializes this credential into a byte string, which can be passed to :meth:`imprt` in\n        another process in order to deserialize the byte string back into a credential. Exporting\n        a credential does not destroy it.\n\n        :returns: The serialized token representation of this credential.\n        :rtype: bytes\n        :raises: :exc:`~gssapi.error.GSSException` if there is a problem with exporting the\n            credential.\n\n            :exc:`NotImplementedError` if the underlying GSSAPI implementation does not\n            support the ``gss_export_cred`` C function.\n        \"\"\"\n        if not hasattr(C, 'gss_export_cred'):\n            raise NotImplementedError(\"The GSSAPI implementation does not support gss_export_cred\")\n\n        minor_status = ffi.new('OM_uint32[1]')\n        output_buffer = ffi.new('gss_buffer_desc[1]')\n        retval = C.gss_export_cred(minor_status, self._cred[0], output_buffer)\n        try:\n            if GSS_ERROR(retval):\n                raise _exception_for_status(retval, minor_status[0])\n\n            return _buf_to_str(output_buffer[0])\n        finally:\n            if output_buffer[0].length != 0:\n                C.gss_release_buffer(minor_status, output_buffer)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef imprt(cls, token):\n        if not hasattr(C, 'gss_import_cred'):\n            raise NotImplementedError(\"The GSSAPI implementation does not support gss_import_cred\")\n\n        minor_status = ffi.new('OM_uint32[1]')\n\n        token_buffer = ffi.new('gss_buffer_desc[1]')\n        token_buffer[0].length = len(token)\n        c_str_token = ffi.new('char[]', token)\n        token_buffer[0].value = c_str_token\n\n        imported_cred = ffi.new('gss_cred_id_t[1]')\n\n        retval = C.gss_import_cred(minor_status, token_buffer, imported_cred)\n        try:\n            if GSS_ERROR(retval):\n                raise _exception_for_status(retval, minor_status[0])\n\n            return cls(imported_cred)\n        except:\n            _release_gss_cred_id_t(imported_cred)\n            raise", "response": "Deserializes a byte string token into a : class:`Credential object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef store(self, usage=None, mech=None, overwrite=False, default=False, cred_store=None):\n        if usage is None:\n            usage = self.usage\n        if isinstance(mech, OID):\n            oid_ptr = ffi.addressof(mech._oid)\n        else:\n            oid_ptr = ffi.cast('gss_OID', C.GSS_C_NO_OID)\n\n        minor_status = ffi.new('OM_uint32[1]')\n        elements_stored = ffi.new('gss_OID_set[1]')\n        usage_stored = ffi.new('gss_cred_usage_t[1]')\n\n        if cred_store is None:\n            if not hasattr(C, 'gss_store_cred'):\n                raise NotImplementedError(\"The GSSAPI implementation does not support \"\n                                          \"gss_store_cred\")\n\n            retval = C.gss_store_cred(\n                minor_status,\n                self._cred[0],\n                ffi.cast('gss_cred_usage_t', usage),\n                oid_ptr,\n                ffi.cast('OM_uint32', overwrite),\n                ffi.cast('OM_uint32', default),\n                elements_stored,\n                usage_stored\n            )\n        else:\n            if not hasattr(C, 'gss_store_cred_into'):\n                raise NotImplementedError(\"The GSSAPI implementation does not support \"\n                                          \"gss_store_cred_into\")\n\n            c_strings, elements, cred_store_kv_set = _make_kv_set(cred_store)\n\n            retval = C.gss_store_cred_into(\n                minor_status,\n                self._cred[0],\n                ffi.cast('gss_cred_usage_t', usage),\n                oid_ptr,\n                ffi.cast('OM_uint32', overwrite),\n                ffi.cast('OM_uint32', default),\n                cred_store_kv_set,\n                elements_stored,\n                usage_stored\n            )\n        try:\n            if GSS_ERROR(retval):\n                if oid_ptr:\n                    raise _exception_for_status(retval, minor_status[0], oid_ptr)\n                else:\n                    raise _exception_for_status(retval, minor_status[0])\n        except:\n            if elements_stored[0]:\n                C.gss_release_oid_set(minor_status, elements_stored)\n            raise\n\n        return (OIDSet(elements_stored), usage_stored[0])", "response": "Stores this credential into a credential store."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_all_mechs():\n    minor_status = ffi.new('OM_uint32[1]')\n    mech_set = ffi.new('gss_OID_set[1]')\n    try:\n        retval = C.gss_indicate_mechs(minor_status, mech_set)\n        if GSS_ERROR(retval):\n            raise _exception_for_status(retval, minor_status[0])\n    except:\n        _release_OID_set(mech_set)\n        raise\n    return OIDSet(oid_set=mech_set)", "response": "Return an OIDSet of all the mechanisms supported by the underlying GSSAPI\n    implementation."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntake a string form of a mechanism OID and returns an OID object representing the mechanism.", "response": "def mech_from_string(input_string):\n        \"\"\"\n        Takes a string form of a mechanism OID, in dot-separated: \"1.2.840.113554.1.2.2\" or numeric\n        ASN.1: \"{1 2 840 113554 1 2 2}\" notation, and returns an :class:`OID` object representing\n        the mechanism, which can be passed to other GSSAPI methods.\n\n        :param input_string: a string representing the desired mechanism OID.\n        :returns: the mechanism OID.\n        :rtype: :class:`OID`\n        :raises: ValueError if the the input string is ill-formatted.\n        :raises: KeyError if the mechanism identified by the string is not supported by the\n            underlying GSSAPI implementation.\n        \"\"\"\n        if not re.match(r'^\\d+(\\.\\d+)*$', input_string):\n            if re.match(r'^\\{\\d+( \\d+)*\\}$', input_string):\n                input_string = \".\".join(input_string[1:-1].split())\n            else:\n                raise ValueError(input_string)\n        for mech in get_all_mechs():\n            if input_string == str(mech):\n                return mech\n        raise KeyError(\"Unknown mechanism: {0}\".format(input_string))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a new set with the OID passed in as the only member of the set.", "response": "def singleton_set(cls, single_oid):\n        \"\"\"\n        Factory function to create a new :class:`OIDSet` with a single member.\n\n        :param single_oid: the OID to use as a member of the new set\n        :type single_oid: :class:`OID`\n        :returns: an OID set with the OID passed in as the only member\n        :rtype: :class:`OIDSet`\n        \"\"\"\n        new_set = cls()\n        oid_ptr = None\n        if isinstance(single_oid, OID):\n            oid_ptr = ffi.addressof(single_oid._oid)\n        elif isinstance(single_oid, ffi.CData):\n            if ffi.typeof(single_oid) == ffi.typeof('gss_OID_desc'):\n                oid_ptr = ffi.addressof(single_oid)\n            elif ffi.typeof(single_oid) == ffi.typeof('gss_OID'):\n                oid_ptr = single_oid\n        if oid_ptr is None:\n            raise TypeError(\"Expected a gssapi.oids.OID, got \" + str(type(single_oid)))\n\n        minor_status = ffi.new('OM_uint32[1]')\n        retval = C.gss_add_oid_set_member(minor_status, oid_ptr, new_set._oid_set)\n        if GSS_ERROR(retval):\n            raise _exception_for_status(retval, minor_status[0])\n        return new_set"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a new entry to the set.", "response": "def add(self, new_oid):\n        \"\"\"\n        Adds another :class:`OID` to this set.\n\n        :param new_oid: the OID to add.\n        :type new_oid: :class:`OID`\n        \"\"\"\n        if self._oid_set[0]:\n            oid_ptr = None\n            if isinstance(new_oid, OID):\n                oid_ptr = ffi.addressof(new_oid._oid)\n            elif isinstance(new_oid, ffi.CData):\n                if ffi.typeof(new_oid) == ffi.typeof('gss_OID_desc'):\n                    oid_ptr = ffi.addressof(new_oid)\n                elif ffi.typeof(new_oid) == ffi.typeof('gss_OID'):\n                    oid_ptr = new_oid\n            if oid_ptr is None:\n                raise TypeError(\"Expected a gssapi.oids.OID, got \" + str(type(new_oid)))\n\n            minor_status = ffi.new('OM_uint32[1]')\n            retval = C.gss_add_oid_set_member(minor_status, oid_ptr, self._oid_set)\n            if GSS_ERROR(retval):\n                raise _exception_for_status(retval, minor_status[0])\n        else:\n            raise GSSException(\"Cannot add a member to this OIDSet, its gss_OID_set is NULL!\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef main(properties=properties, options=options, **custom_options):\n    return init(**dict(options, **custom_options))(**properties)", "response": "Imports and runs setup function with given properties."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nimporting and returns a setup function.", "response": "def init(\n    dist='dist',\n    minver=None,\n    maxver=None,\n    use_markdown_readme=True,\n    use_stdeb=False,\n    use_distribute=False,\n    ):\n    \"\"\"Imports and returns a setup function.\n\n    If use_markdown_readme is set,\n    then README.md is added to setuptools READMES list.\n\n    If use_stdeb is set on a Debian based system,\n    then module stdeb is imported.\n    Stdeb supports building deb packages on Debian based systems.\n    The package should only be installed on the same system version\n    it was built on, though. See http://github.com/astraw/stdeb.\n\n    If use_distribute is set, then distribute_setup.py is imported.\n    \"\"\"\n    if not minver == maxver == None:\n        import sys\n        if not minver <= sys.version < (maxver or 'Any'):\n            sys.stderr.write(\n                '%s: requires python version in <%s, %s), not %s\\n' % (\n                sys.argv[0], minver or 'any', maxver or 'any', sys.version.split()[0]))\n            sys.exit(1)\n\n    if use_distribute:\n        from distribute_setup import use_setuptools\n        use_setuptools(to_dir=dist)\n        from setuptools import setup\n    else:\n        try:\n            from setuptools import setup\n        except ImportError:\n            from distutils.core import setup\n\n    if use_markdown_readme:\n        try:\n            import setuptools.command.sdist\n            setuptools.command.sdist.READMES = tuple(list(getattr(setuptools.command.sdist, 'READMES', ()))\n                + ['README.md'])\n        except ImportError:\n            pass\n\n    if use_stdeb:\n        import platform\n        if 'debian' in platform.dist():\n            try:\n                import stdeb\n            except ImportError:\n                pass\n\n    return setup"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef main(context=None, *args, **kwargs):\n\n    # Get configuration\n    args = _get_command_line_args()\n    # Get settings filepath\n    settings_filepath = args.get('settings_path')\n    # Get settings using the settings filepath\n    settings = _get_settings(settings_filepath)\n    settings = settings.get('microphone', {})\n    # TODO: verify that this doesn't break things in new and interesting ways\n    settings.update(kwargs)\n\n    plugin_manager = pluginmanager.PluginInterface()\n    plugin_manager.set_entry_points('microphone.audioengines')\n    plugins = plugin_manager.collect_entry_point_plugins(return_dict=True)\n\n    # find the audio driver or stick to the default of `pyaudio`\n    audio_driver = settings.get('audio_driver', 'pyaudio')\n\n    try:\n        # NOTE: `AudioDriver` is a class\n        AudioDriver = plugins[audio_driver]\n    # Fail early if we can't find the plugin we're looking for\n    except KeyError:\n        logging.error('Audio driver set in microphone settings of {} not foun'\n                      'd. Please install or fix your settings file.')\n\n        logging.error('Plugins available: {}'.format(list(plugins.keys())))\n        sys.exit(1)\n\n    # TODO: Assume that a computer will only use one audio driver?\n\n    # Also assume that microphones may be physcially displaced from each other\n    # which means that they might record simultaneously\n\n    # FIXME: these are not good default addresses\n    command_publish_address = settings.get('publish_address',\n                                           'tcp://127.0.0.1:6910')\n\n    command_subscribe_address = settings.get('subscribe_address',\n                                             'tcp://127.0.0.1:6823')\n\n    audio_publish_address = settings.get('audio_publish_address',\n                                         'tcp://127.0.0.1:5012')\n\n    messaging = Messaging(command_publish_address,\n                          command_subscribe_address,\n                          audio_publish_address)\n\n    audio_driver = AudioDriver(messaging, settings)\n\n    audio_driver.run()", "response": "Main function for the microphone command line tool."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a file handle which is used to record audio", "response": "def _create_file():\n    \"\"\"\n    Returns a file handle which is used to record audio\n    \"\"\"\n    f = wave.open('audio.wav', mode='wb')\n    f.setnchannels(2)\n    p = pyaudio.PyAudio()\n    f.setsampwidth(p.get_sample_size(pyaudio.paInt16))\n    f.setframerate(p.get_default_input_device_info()['defaultSampleRate'])\n    try:\n        yield f\n    finally:\n        f.close()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget all PyAudio devices.", "response": "def get_devices(self, device_type='all'):\n        num_devices = self._pyaudio.get_device_count()\n        self._logger.debug('Found %d PyAudio devices', num_devices)\n        for i in range(num_devices):\n            info = self._pyaudio.get_device_info_by_index(i)\n            name = info['name']\n            if name in self.devices:\n                continue\n            else:\n                self.devices[name] = PyAudioDevice(self, info)\n\n        return self.devices\n        \"\"\"\n        if device_type == plugin.audioengine.DEVICE_TYPE_ALL:\n            return devs\n        else:\n            return [device for device in devs if device_type in device.types]\n        \"\"\""}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef open_stream(self,\n                    bits,\n                    channels,\n                    rate=None,\n                    chunksize=1024,\n                    output=True):\n\n        if rate is None:\n            rate = int(self.info['defaultSampleRate'])\n        # Check if format is supported\n        is_supported_fmt = self.supports_format(bits, channels, rate,\n                                                output=output)\n        if not is_supported_fmt:\n            msg_fmt = (\"PyAudioDevice {index} ({name}) doesn't support \" +\n                       \"%s format (Int{bits}, {channels}-channel at\" +\n                       \" {rate} Hz)\") % ('output' if output else 'input')\n            msg = msg_fmt.format(index=self.index,\n                                 name=self.name,\n                                 bits=bits,\n                                 channels=channels,\n                                 rate=rate)\n            self._logger.critical(msg)\n            raise plugin.audioengine.UnsupportedFormat(msg)\n        # Everything looks fine, open the stream\n        direction = ('output' if output else 'input')\n        stream_kwargs = {\n            'format': bits_to_samplefmt(bits),\n            'channels': channels,\n            'rate': rate,\n            'output': output,\n            'input': not output,\n            ('%s_device_index' % direction): self._index,\n            'frames_per_buffer': chunksize if output else chunksize*8  # Hacky\n        }\n\n        stream = self._engine._pyaudio.open(**stream_kwargs)\n        \"\"\"\n        self._logger.debug(\"%s stream opened on device '%s' (%d Hz, %d \" +\n                           \"channel, %d bit)\", \"output\" if output else \"input\",\n                           self.slug, rate, channels, bits)\n        \"\"\"\n        try:\n            yield stream\n        finally:\n            stream.close()\n            \"\"\"\n            self._logger.debug(\"%s stream closed on device '%s'\",\n                               \"output\" if output else \"input\", self.slug)\n            \"\"\"", "response": "Open a stream of the next available state."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef djfrontend_h5bp_css(version=None):\n    if version is None:\n        version = getattr(settings, 'DJFRONTEND_H5BP_CSS', DJFRONTEND_H5BP_CSS_DEFAULT)\n\n    return format_html(\n        '<link rel=\"stylesheet\" href=\"{0}djfrontend/css/h5bp/{1}/h5bp.css\">',\n        _static_url, version)", "response": "Returns the HTML5 Boilerplate CSS file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef djfrontend_normalize(version=None):\n    if version is None:\n        version = getattr(settings, 'DJFRONTEND_NORMALIZE', DJFRONTEND_NORMALIZE_DEFAULT)\n\n    return format_html(\n        '<link rel=\"stylesheet\" href=\"{0}djfrontend/css/normalize/{1}/normalize.css\">',\n        _static_url, version)", "response": "Returns a normalized HTML file."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the font - awesome stylesheet.", "response": "def djfrontend_fontawesome(version=None):\n    \"\"\"\n    Returns Font Awesome CSS file.\n    TEMPLATE_DEBUG returns full file, otherwise returns minified file.\n    \"\"\"\n    if version is None:\n        version = getattr(settings, 'DJFRONTEND_FONTAWESOME', DJFRONTEND_FONTAWESOME_DEFAULT)\n\n    return format_html(\n        '<link rel=\"stylesheet\" href=\"{0}djfrontend/css/fontawesome/{1}/font-awesome{2}.css\">',\n        _static_url, version, _min)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn Modernizr JavaScript file according to version number.", "response": "def djfrontend_modernizr(version=None):\n    \"\"\"\n    Returns Modernizr JavaScript file according to version number.\n    TEMPLATE_DEBUG returns full file, otherwise returns minified file.\n    Included in HTML5 Boilerplate.\n    \"\"\"\n    if version is None:\n        version = getattr(settings, 'DJFRONTEND_MODERNIZR', DJFRONTEND_MODERNIZR_DEFAULT)\n\n    if getattr(settings, 'TEMPLATE_DEBUG', False):\n        template = '<script src=\"{static}djfrontend/js/modernizr/{v}/modernizr.js\"></script>'\n    else:\n        template = (\n            '<script src=\"//cdnjs.cloudflare.com/ajax/libs/modernizr/{v}/modernizr.min.js\"></script>\\n'\n            '<script>window.Modernizr || document.write(\\'<script src=\"{static}djfrontend/js/modernizr/{v}/modernizr.min.js\"><\\/script>\\')</script>')\n    return format_html(template, static=_static_url, v=version)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef djfrontend_jquery(version=None):\n    if version is None:\n        version = getattr(settings, 'DJFRONTEND_JQUERY', DJFRONTEND_JQUERY_DEFAULT)\n\n    if getattr(settings, 'TEMPLATE_DEBUG', False):\n        template = '<script src=\"{static}djfrontend/js/jquery/{v}/jquery.js\"></script>'\n    else:\n        template = (\n            '<script src=\"//ajax.googleapis.com/ajax/libs/jquery/{v}/jquery.min.js\"></script>'\n            '<script>window.jQuery || document.write(\\'<script src=\"{static}djfrontend/js/jquery/{v}/jquery.min.js\"><\\/script>\\')</script>')\n    return format_html(template, static=_static_url, v=version)", "response": "Returns jQuery JavaScript file according to version number."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the jQuery UI plugin file according to version number.", "response": "def djfrontend_jqueryui(version=None):\n    \"\"\"\n    Returns the jQuery UI plugin file according to version number.\n    TEMPLATE_DEBUG returns full file, otherwise returns minified file from Google CDN with local fallback.\n    \"\"\"\n    if version is None:\n        version = getattr(settings, 'DJFRONTEND_JQUERYUI', DJFRONTEND_JQUERYUI_DEFAULT)\n\n    if getattr(settings, 'TEMPLATE_DEBUG', False):\n        return format_html(\n            '<script src=\"{0}djfrontend/js/jquery/jqueryui/{1}/jquery-ui.js\"></script>',\n            settings.STATIC_URL, version)\n    else:\n        return format_html(\n            '<script src=\"//ajax.googleapis.com/ajax/libs/jqueryui/{v}/jquery-ui.min.js\"></script>'\n            '<script>window.jQuery.ui || document.write(\\'<script src=\"{static}djfrontend/js/jquery/jqueryui/{v}/jquery-ui.min.js\"><\\/script>\\')</script>',\n            static=_static_url, v=version)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef djfrontend_jquery_datatables(version=None):\n    if version is None:\n        if not getattr(settings, 'DJFRONTEND_JQUERY_DATATABLES', False):\n            version = getattr(settings, 'DJFRONTEND_JQUERY_DATATABLES_VERSION', DJFRONTEND_JQUERY_DATATABLES_VERSION_DEFAULT)\n        else:\n            version = getattr(settings, 'DJFRONTEND_JQUERY_DATATABLES', DJFRONTEND_JQUERY_DATATABLES_VERSION_DEFAULT)\n\n    if getattr(settings, 'TEMPLATE_DEBUG', False):\n        template = '<script src=\"{static}djfrontend/js/jquery/jquery.dataTables/{v}/jquery.dataTables.js\"></script>'\n    else:\n        template = (\n            '<script src=\"//cdnjs.cloudflare.com/ajax/libs/datatables/{v}/jquery.dataTables.min.js\"></script>'\n            '<script>window.jQuery.fn.DataTable || document.write(\\'<script src=\"{static}djfrontend/js/jquery/jquery.dataTables/{v}/jquery.dataTables.min.js\"><\\/script>\\')</script>')\n    return format_html(template, static=_static_url, v=version)", "response": "Returns the jQuery DataTables plugin file according to version number."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef djfrontend_jquery_datatables_css(version=None):\n    if version is None:\n        if not getattr(settings, 'DJFRONTEND_JQUERY_DATATABLES_CSS', False):\n            version = getattr(settings, 'DJFRONTEND_JQUERY_DATATABLES_VERSION', DJFRONTEND_JQUERY_DATATABLES_VERSION_DEFAULT)\n        else:\n            version = getattr(settings, 'DJFRONTEND_JQUERY_DATATABLES_CSS', DJFRONTEND_JQUERY_DATATABLES_VERSION_DEFAULT)\n\n\n    return format_html(\n        '<link rel=\"stylesheet\" href=\"{static}djfrontend/css/jquery/jquery.dataTables/{v}/jquery.dataTables{min}.css\">',\n        static=_static_url, v=version, min=_min)", "response": "Returns the jQuery DataTables CSS file according to version number."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef djfrontend_jquery_datatables_themeroller(version=None):\n    if version is None:\n        if not getattr(settings, 'DJFRONTEND_JQUERY_DATATABLES_THEMEROLLER', False):\n            version = getattr(settings, 'DJFRONTEND_JQUERY_DATATABLES_VERSION', DJFRONTEND_JQUERY_DATATABLES_VERSION_DEFAULT)\n        else:\n            version = getattr(settings, 'DJFRONTEND_JQUERY_DATATABLES_THEMEROLLER', DJFRONTEND_JQUERY_DATATABLES_VERSION_DEFAULT)\n\n    return format_html(\n        '<link rel=\"stylesheet\" href=\"href=\"{static}djfrontend/css/jquery/jquery.dataTables/{v}/jquery.dataTables_themeroller.min.css\">',\n        static=_static_url, v=version)", "response": "Returns the jQuery DataTables ThemeRoller CSS file according to version number."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the jQuery Dynamic Formset plugin file according to version number.", "response": "def djfrontend_jquery_formset(version=None):\n    \"\"\"\n    Returns the jQuery Dynamic Formset plugin file according to version number.\n    TEMPLATE_DEBUG returns full file, otherwise returns minified file.\n    \"\"\"\n    if version is None:\n        version = getattr(settings, 'DJFRONTEND_JQUERY_FORMSET', DJFRONTEND_JQUERY_FORMSET_DEFAULT)\n\n    if getattr(settings, 'TEMPLATE_DEBUG', False):\n        template = '<script src=\"{static}djfrontend/js/jquery/jquery.formset/{v}/jquery.formset.js\"></script>'\n    else:\n        template = (\n            '<script src=\"//cdnjs.cloudflare.com/ajax/libs/jquery.formset/{v}/jquery.formset.min.js\"></script>\\n'\n            '<script>window.jQuery.fn.formset || document.write(\\'<script src=\"{static}djfrontend/js/jquery/jquery.formset/{v}/jquery.formset.min.js\"><\\/script>\\')</script>')\n    return format_html(template, static=_static_url, v=version)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef djfrontend_jquery_scrollto(version=None):\n    if version is None:\n        version = getattr(settings, 'DJFRONTEND_JQUERY_SCROLLTO', DJFRONTEND_JQUERY_SCROLLTO_DEFAULT)\n\n    if getattr(settings, 'TEMPLATE_DEBUG', False):\n        template = '<script src=\"{static}djfrontend/js/jquery/jquery.scrollTo/{v}/jquery.scrollTo.js\"></script>'\n    else:\n        template = (\n            '<script src=\"//cdnjs.cloudflare.com/ajax/libs/jquery-scrollTo/{v}/jquery.scrollTo.min.js\"></script>'\n            '<script>window.jQuery.fn.scrollTo || document.write(\\'<script src=\"{static}djfrontend/js/jquery/jquery.scrollTo/{v}/jquery.scrollTo.min.js\"><\\/script>\\')</script>')\n    return format_html(template, static=_static_url, v=version)", "response": "Returns the jQuery ScrollTo plugin file according to version number."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef djfrontend_jquery_smoothscroll(version=None):\n    if version is None:\n        version = getattr(settings, 'DJFRONTEND_JQUERY_SMOOTHSCROLL', DJFRONTEND_JQUERY_SMOOTHSCROLL_DEFAULT)\n\n    if getattr(settings, 'TEMPLATE_DEBUG', False):\n        template = '<script src=\"{static}djfrontend/js/jquery/jquery.smooth-scroll/{v}/jquery.smooth-scroll.js\"></script>'\n    else:\n        template = (\n            '<script src=\"//cdnjs.cloudflare.com/ajax/libs/jquery-smooth-scroll/{v}/jquery.smooth-scroll.min.js\"></script>'\n            '<script>window.jQuery.fn.smoothScroll || document.write(\\'<script src=\"{static}djfrontend/js/jquery/jquery.smooth-scroll/{v}/jquery.smooth-scroll.min.js\"><\\/script>\\')</script>')\n    return format_html(template, static=_static_url, v=version)", "response": "Returns the jQuery Smooth Scroll plugin file according to version number."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef djfrontend_twbs_css(version=None):\n    if version is None:\n        if not getattr(settings, 'DJFRONTEND_TWBS_CSS', False):\n            version = getattr(settings, 'DJFRONTEND_TWBS_VERSION', DJFRONTEND_TWBS_VERSION_DEFAULT)\n        else:\n             version = getattr(settings, 'DJFRONTEND_TWBS_CSS', DJFRONTEND_TWBS_VERSION_DEFAULT)\n\n    return format_html(\n        '<link rel=\"stylesheet\" href=\"{static}djfrontend/css/twbs/{v}/bootstrap{min}.css\">',\n        static=_static_url, v=version, min=_min)", "response": "Returns the Twitter Bootstrap CSS file."}
