{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_usage(self, program_name=None):\n        program_name = os.path.relpath(program_name or sys.argv[0] or 'Dummy',\n                                       self.base_dir)\n        commands = OrderedDict(self.gather_commands())\n        options = gather_command_line_options()\n        long_usage = format_usage(program_name, self.doc, commands, options)\n        # internal usage is a workaround because docopt cannot handle spaces\n        # in program names. So for parsing we use 'dummy' as the program name.\n        # for printing help etc. we want to use the actual program name.\n        internal_usage = format_usage('dummy', self.doc, commands, options)\n        short_usage = printable_usage(long_usage)\n        return short_usage, long_usage, internal_usage", "response": "Get the commandline usage string for this experiment."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrun the main function of the experiment or a given command.", "response": "def run(self, command_name=None, config_updates=None, named_configs=(),\n            meta_info=None, options=None):\n        \"\"\"\n        Run the main function of the experiment or a given command.\n\n        Parameters\n        ----------\n        command_name : str, optional\n            Name of the command to be run. Defaults to main function.\n\n        config_updates : dict, optional\n            Changes to the configuration as a nested dictionary\n\n        named_configs : list[str], optional\n            list of names of named_configs to use\n\n        meta_info : dict, optional\n            Additional meta information for this run.\n\n        options : dict, optional\n            Dictionary of options to use\n\n        Returns\n        -------\n        sacred.run.Run\n            the Run object corresponding to the finished run\n\n        \"\"\"\n        run = self._create_run(command_name, config_updates, named_configs,\n                               meta_info, options)\n        run()\n        return run"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrun the command with the given name.", "response": "def run_command(self, command_name, config_updates=None,\n                    named_configs=(), args=(), meta_info=None):\n        \"\"\"Run the command with the given name.\n\n        .. note:: Deprecated in Sacred 0.7\n            run_command() will be removed in Sacred 1.0.\n            It is replaced by run() which can now also handle command_names.\n        \"\"\"\n        import warnings\n        warnings.warn(\"run_command is deprecated. Use run instead\",\n                      DeprecationWarning)\n        return self.run(command_name, config_updates, named_configs, meta_info,\n                        args)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run_commandline(self, argv=None):\n        argv = ensure_wellformed_argv(argv)\n        short_usage, usage, internal_usage = self.get_usage()\n        args = docopt(internal_usage, [str(a) for a in argv[1:]], help=False)\n\n        cmd_name = args.get('COMMAND') or self.default_command\n        config_updates, named_configs = get_config_updates(args['UPDATE'])\n\n        err = self._check_command(cmd_name)\n        if not args['help'] and err:\n            print(short_usage)\n            print(err)\n            exit(1)\n\n        if self._handle_help(args, usage):\n            exit()\n\n        try:\n            return self.run(cmd_name, config_updates, named_configs, {}, args)\n        except Exception as e:\n            if self.current_run:\n                debug = self.current_run.debug\n            else:\n                # The usual command line options are applied after the run\n                # object is built completely. Some exceptions (e.g.\n                # ConfigAddedError) are raised before this. In these cases,\n                # the debug flag must be checked manually.\n                debug = args.get('--debug', False)\n\n            if debug:\n                # Debug: Don't change behaviour, just re-raise exception\n                raise\n            elif self.current_run and self.current_run.pdb:\n                # Print exception and attach pdb debugger\n                import traceback\n                import pdb\n                traceback.print_exception(*sys.exc_info())\n                pdb.post_mortem()\n            else:\n                # Handle pretty printing of exceptions. This includes\n                # filtering the stacktrace and printing the usage, as\n                # specified by the exceptions attributes\n                if isinstance(e, SacredError):\n                    print(format_sacred_error(e, short_usage), file=sys.stderr)\n                else:\n                    print_filtered_stacktrace()\n                exit(1)", "response": "Runs the command - line interface of this experiment."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef open_resource(self, filename, mode='r'):\n        assert self.current_run is not None, \"Can only be called during a run.\"\n        return self.current_run.open_resource(filename, mode)", "response": "Open a file and save it as a resource."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_artifact(\n            self,\n            filename,\n            name=None,\n            metadata=None,\n            content_type=None,\n    ):\n        \"\"\"Add a file as an artifact.\n\n        In Sacred terminology an artifact is a file produced by the experiment\n        run. In case of a MongoObserver that means storing the file in the\n        database.\n\n        This function can only be called during a run, and just calls the\n        :py:meth:`sacred.run.Run.add_artifact` method.\n\n        Parameters\n        ----------\n        filename : str\n            name of the file to be stored as artifact\n        name : str, optional\n            optionally set the name of the artifact.\n            Defaults to the relative file-path.\n        metadata: dict, optional\n            optionally attach metadata to the artifact.\n            This only has an effect when using the MongoObserver.\n        content_type: str, optional\n            optionally attach a content-type to the artifact.\n            This only has an effect when using the MongoObserver.\n        \"\"\"\n        assert self.current_run is not None, \"Can only be called during a run.\"\n        self.current_run.add_artifact(filename, name, metadata, content_type)", "response": "Adds an artifact to the current run."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef log_scalar(self, name, value, step=None):\n        # Method added in change https://github.com/chovanecm/sacred/issues/4\n        # The same as Run.log_scalar\n        return self.current_run.log_scalar(name, value, step)", "response": "Log a scalar value to the current run."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _gather(self, func):\n        for ingredient, _ in self.traverse_ingredients():\n            for name, item in func(ingredient):\n                if ingredient == self:\n                    name = name[len(self.path) + 1:]\n                yield name, item", "response": "Yields the names of the items in the gatheredCOOKIES."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_default_options(self):\n        _, _, internal_usage = self.get_usage()\n        args = docopt(internal_usage, [])\n        return {k: v for k, v in args.items() if k.startswith('--')}", "response": "Get a dictionary of default options as used with run."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconstructing args list and kwargs dictionary for this signature.", "response": "def construct_arguments(self, args, kwargs, options, bound=False):\n        \"\"\"\n        Construct args list and kwargs dictionary for this signature.\n\n        They are created such that:\n          - the original explicit call arguments (args, kwargs) are preserved\n          - missing arguments are filled in by name using options (if possible)\n          - default arguments are overridden by options\n          - TypeError is thrown if:\n            * kwargs contains one or more unexpected keyword arguments\n            * conflicting values for a parameter in both args and kwargs\n            * there is an unfilled parameter at the end of this process\n        \"\"\"\n        expected_args = self._get_expected_args(bound)\n        self._assert_no_unexpected_args(expected_args, args)\n        self._assert_no_unexpected_kwargs(expected_args, kwargs)\n        self._assert_no_duplicate_args(expected_args, args, kwargs)\n\n        args, kwargs = self._fill_in_options(args, kwargs, options, bound)\n\n        self._assert_no_missing_args(args, kwargs, bound)\n        return args, kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef flush():\n    try:\n        sys.stdout.flush()\n        sys.stderr.flush()\n    except (AttributeError, ValueError, IOError):\n        pass  # unsupported\n    try:\n        libc.fflush(None)\n    except (AttributeError, ValueError, IOError):\n        pass", "response": "Try to flush all stdio buffers both from python and from C."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef tee_output_python():\n    buffer = StringIO()\n    out = CapturedStdout(buffer)\n    orig_stdout, orig_stderr = sys.stdout, sys.stderr\n    flush()\n    sys.stdout = TeeingStreamProxy(sys.stdout, buffer)\n    sys.stderr = TeeingStreamProxy(sys.stderr, buffer)\n    try:\n        yield out\n    finally:\n        flush()\n        out.finalize()\n        sys.stdout, sys.stderr = orig_stdout, orig_stderr", "response": "Context manager that teees sys. stdout and sys. stderr to new StringIO."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef tee_output_fd():\n    with NamedTemporaryFile(mode='w+') as target:\n        original_stdout_fd = 1\n        original_stderr_fd = 2\n        target_fd = target.fileno()\n\n        # Save a copy of the original stdout and stderr file descriptors\n        saved_stdout_fd = os.dup(original_stdout_fd)\n        saved_stderr_fd = os.dup(original_stderr_fd)\n\n        try:\n            # we call os.setsid to move process to a new process group\n            # this is done to avoid receiving KeyboardInterrupts (see #149)\n            # in Python 3 we could just pass start_new_session=True\n            tee_stdout = subprocess.Popen(\n                ['tee', '-a', target.name], preexec_fn=os.setsid,\n                stdin=subprocess.PIPE, stdout=1)\n            tee_stderr = subprocess.Popen(\n                ['tee', '-a', target.name], preexec_fn=os.setsid,\n                stdin=subprocess.PIPE, stdout=2)\n        except (FileNotFoundError, OSError, AttributeError):\n            # No tee found in this operating system. Trying to use a python\n            # implementation of tee. However this is slow and error-prone.\n            tee_stdout = subprocess.Popen(\n                [sys.executable, \"-m\", \"sacred.pytee\"],\n                stdin=subprocess.PIPE, stderr=target_fd)\n            tee_stderr = subprocess.Popen(\n                [sys.executable, \"-m\", \"sacred.pytee\"],\n                stdin=subprocess.PIPE, stdout=target_fd)\n\n        flush()\n        os.dup2(tee_stdout.stdin.fileno(), original_stdout_fd)\n        os.dup2(tee_stderr.stdin.fileno(), original_stderr_fd)\n        out = CapturedStdout(target)\n\n        try:\n            yield out  # let the caller do their printing\n        finally:\n            flush()\n\n            # then redirect stdout back to the saved fd\n            tee_stdout.stdin.close()\n            tee_stderr.stdin.close()\n\n            # restore original fds\n            os.dup2(saved_stdout_fd, original_stdout_fd)\n            os.dup2(saved_stderr_fd, original_stderr_fd)\n\n            # wait for completion of the tee processes with timeout\n            # implemented using a timer because timeout support is py3 only\n            def kill_tees():\n                tee_stdout.kill()\n                tee_stderr.kill()\n\n            tee_timer = Timer(1, kill_tees)\n            try:\n                tee_timer.start()\n                tee_stdout.wait()\n                tee_stderr.wait()\n            finally:\n                tee_timer.cancel()\n\n            os.close(saved_stdout_fd)\n            os.close(saved_stderr_fd)\n            out.finalize()", "response": "Yields a file on the file descriptor level."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses the UPDATES given on the commandline and return a dict of config updates and named configs.", "response": "def get_config_updates(updates):\n    \"\"\"\n    Parse the UPDATES given on the commandline.\n\n    Parameters\n    ----------\n        updates (list[str]):\n            list of update-strings of the form NAME=LITERAL or just NAME.\n\n    Returns\n    -------\n        (dict, list):\n            Config updates and named configs to use\n\n    \"\"\"\n    config_updates = {}\n    named_configs = []\n    if not updates:\n        return config_updates, named_configs\n    for upd in updates:\n        if upd == '':\n            continue\n        path, sep, value = upd.partition('=')\n        if sep == '=':\n            path = path.strip()    # get rid of surrounding whitespace\n            value = value.strip()  # get rid of surrounding whitespace\n            set_by_dotted_path(config_updates, path, _convert_value(value))\n        else:\n            named_configs.append(path)\n    return config_updates, named_configs"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nformatting the Options - part of the usage text.", "response": "def _format_options_usage(options):\n    \"\"\"\n    Format the Options-part of the usage text.\n\n    Parameters\n    ----------\n        options : list[sacred.commandline_options.CommandLineOption]\n            A list of all supported commandline options.\n\n    Returns\n    -------\n        str\n            Text formatted as a description for the commandline options\n\n    \"\"\"\n    options_usage = \"\"\n    for op in options:\n        short, long = op.get_flags()\n        if op.arg:\n            flag = \"{short} {arg} {long}={arg}\".format(\n                short=short, long=long, arg=op.arg)\n        else:\n            flag = \"{short} {long}\".format(short=short, long=long)\n\n        wrapped_description = textwrap.wrap(inspect.cleandoc(op.__doc__),\n                                            width=79,\n                                            initial_indent=' ' * 32,\n                                            subsequent_indent=' ' * 32)\n        wrapped_description = \"\\n\".join(wrapped_description).strip()\n\n        options_usage += \"  {0:28}  {1}\\n\".format(flag, wrapped_description)\n    return options_usage"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nformatting the Arguments - part of the usage text.", "response": "def _format_arguments_usage(options):\n    \"\"\"\n    Construct the Arguments-part of the usage text.\n\n    Parameters\n    ----------\n        options : list[sacred.commandline_options.CommandLineOption]\n            A list of all supported commandline options.\n\n    Returns\n    -------\n        str\n            Text formatted as a description of the arguments supported by the\n            commandline options.\n\n    \"\"\"\n    argument_usage = \"\"\n    for op in options:\n        if op.arg and op.arg_description:\n            wrapped_description = textwrap.wrap(op.arg_description,\n                                                width=79,\n                                                initial_indent=' ' * 12,\n                                                subsequent_indent=' ' * 12)\n            wrapped_description = \"\\n\".join(wrapped_description).strip()\n            argument_usage += \"  {0:8}  {1}\\n\".format(op.arg,\n                                                      wrapped_description)\n    return argument_usage"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _format_command_usage(commands):\n    if not commands:\n        return \"\"\n    command_usage = \"\\nCommands:\\n\"\n    cmd_len = max([len(c) for c in commands] + [8])\n    command_doc = OrderedDict(\n        [(cmd_name, _get_first_line_of_docstring(cmd_doc))\n         for cmd_name, cmd_doc in commands.items()])\n    for cmd_name, cmd_doc in command_doc.items():\n        command_usage += (\"  {:%d}  {}\\n\" % cmd_len).format(cmd_name, cmd_doc)\n    return command_usage", "response": "Formats the commands dictionary into a string."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nformat the usage text for this experiment.", "response": "def format_usage(program_name, description, commands=None, options=()):\n    \"\"\"\n    Construct the usage text.\n\n    Parameters\n    ----------\n        program_name : str\n            Usually the name of the python file that contains the experiment.\n        description : str\n            description of this experiment (usually the docstring).\n        commands : dict[str, func]\n            Dictionary of supported commands.\n            Each entry should be a tuple of (name, function).\n        options : list[sacred.commandline_options.CommandLineOption]\n            A list of all supported commandline options.\n\n    Returns\n    -------\n        str\n            The complete formatted usage text for this experiment.\n            It adheres to the structure required by ``docopt``.\n\n    \"\"\"\n    usage = USAGE_TEMPLATE.format(\n        program_name=cmd_quote(program_name),\n        description=description.strip() if description else '',\n        options=_format_options_usage(options),\n        arguments=_format_arguments_usage(options),\n        commands=_format_command_usage(commands)\n    )\n    return usage"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing string as python literal if possible and fallback to string.", "response": "def _convert_value(value):\n    \"\"\"Parse string as python literal if possible and fallback to string.\"\"\"\n    try:\n        return restore(ast.literal_eval(value))\n    except (ValueError, SyntaxError):\n        if SETTINGS.COMMAND_LINE.STRICT_PARSING:\n            raise\n        # use as string if nothing else worked\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\niterate over the items of a dictionary in a special order.", "response": "def iterate_flattened_separately(dictionary, manually_sorted_keys=None):\n    \"\"\"\n    Recursively iterate over the items of a dictionary in a special order.\n\n    First iterate over manually sorted keys and then over all items that are\n    non-dictionary values (sorted by keys), then over the rest\n    (sorted by keys), providing full dotted paths for every leaf.\n    \"\"\"\n    if manually_sorted_keys is None:\n        manually_sorted_keys = []\n    for key in manually_sorted_keys:\n        if key in dictionary:\n            yield key, dictionary[key]\n\n    single_line_keys = [key for key in dictionary.keys() if\n                        key not in manually_sorted_keys and\n                        (not dictionary[key] or\n                         not isinstance(dictionary[key], dict))]\n    for key in sorted(single_line_keys):\n        yield key, dictionary[key]\n\n    multi_line_keys = [key for key in dictionary.keys() if\n                       key not in manually_sorted_keys and\n                       (dictionary[key] and\n                        isinstance(dictionary[key], dict))]\n    for key in sorted(multi_line_keys):\n        yield key, PATHCHANGE\n        for k, val in iterate_flattened_separately(dictionary[key],\n                                                   manually_sorted_keys):\n            yield join_paths(key, k), val"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_by_dotted_path(d, path, value):\n    split_path = path.split('.')\n    current_option = d\n    for p in split_path[:-1]:\n        if p not in current_option:\n            current_option[p] = dict()\n        current_option = current_option[p]\n    current_option[split_path[-1]] = value", "response": "Set an entry in a nested dict using a dotted path."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_by_dotted_path(d, path, default=None):\n    if not path:\n        return d\n    split_path = path.split('.')\n    current_option = d\n    for p in split_path:\n        if p not in current_option:\n            return default\n        current_option = current_option[p]\n    return current_option", "response": "Get an entry from nested dictionaries using a dotted path."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef iter_path_splits(path):\n    split_path = path.split('.')\n    for i in range(len(split_path)):\n        p1 = join_paths(*split_path[:i])\n        p2 = join_paths(*split_path[i:])\n        yield p1, p2", "response": "Iterate over possible splits of a dotted path."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\niterate through all prefixes of a dotted path.", "response": "def iter_prefixes(path):\n    \"\"\"\n    Iterate through all (non-empty) prefixes of a dotted path.\n\n    Example:\n    >>> list(iter_prefixes('foo.bar.baz'))\n    ['foo', 'foo.bar', 'foo.bar.baz']\n    \"\"\"\n    split_path = path.split('.')\n    for i in range(1, len(split_path) + 1):\n        yield join_paths(*split_path[:i])"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_prefix(pre_path, path):\n    pre_path = pre_path.strip('.')\n    path = path.strip('.')\n    return not pre_path or path.startswith(pre_path + '.')", "response": "Return True if pre_path is a path - prefix of path."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef rel_path(base, path):\n    if base == path:\n        return ''\n    assert is_prefix(base, path), \"{} not a prefix of {}\".format(base, path)\n    return path[len(base):].strip('.')", "response": "Return path relative to base."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef convert_to_nested_dict(dotted_dict):\n    nested_dict = {}\n    for k, v in iterate_flattened(dotted_dict):\n        set_by_dotted_path(nested_dict, k, v)\n    return nested_dict", "response": "Convert a dict with dotted path keys to corresponding nested dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef format_filtered_stacktrace(filter_traceback='default'):\n    exc_type, exc_value, exc_traceback = sys.exc_info()\n    # determine if last exception is from sacred\n    current_tb = exc_traceback\n    while current_tb.tb_next is not None:\n        current_tb = current_tb.tb_next\n\n    if filter_traceback == 'default' \\\n            and _is_sacred_frame(current_tb.tb_frame):\n        # just print sacred internal trace\n        header = [\"Exception originated from within Sacred.\\n\"\n                  \"Traceback (most recent calls):\\n\"]\n        texts = tb.format_exception(exc_type, exc_value, current_tb)\n        return ''.join(header + texts[1:]).strip()\n    elif filter_traceback in ('default', 'always'):\n        # print filtered stacktrace\n        if sys.version_info >= (3, 5):\n            tb_exception = \\\n                tb.TracebackException(exc_type, exc_value, exc_traceback,\n                                      limit=None)\n            return ''.join(filtered_traceback_format(tb_exception))\n        else:\n            s = \"Traceback (most recent calls WITHOUT Sacred internals):\"\n            current_tb = exc_traceback\n            while current_tb is not None:\n                if not _is_sacred_frame(current_tb.tb_frame):\n                    tb.print_tb(current_tb, 1)\n                current_tb = current_tb.tb_next\n            s += \"\\n\".join(tb.format_exception_only(exc_type,\n                                                    exc_value)).strip()\n            return s\n    elif filter_traceback == 'never':\n        # print full stacktrace\n        return '\\n'.join(\n            tb.format_exception(exc_type, exc_value, exc_traceback))\n    else:\n        raise ValueError('Unknown value for filter_traceback: ' +\n                         filter_traceback)", "response": "Returns the traceback as string."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting a set of all classes that inherit from the given class.", "response": "def get_inheritors(cls):\n    \"\"\"Get a set of all classes that inherit from the given class.\"\"\"\n    subclasses = set()\n    work = [cls]\n    while work:\n        parent = work.pop()\n        for child in parent.__subclasses__():\n            if child not in subclasses:\n                subclasses.add(child)\n                work.append(child)\n    return subclasses"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef convert_camel_case_to_snake_case(name):\n    s1 = re.sub('(.)([A-Z][a-z]+)', r'\\1_\\2', name)\n    return re.sub('([a-z0-9])([A-Z])', r'\\1_\\2', s1).lower()", "response": "Convert CamelCase to snake_case."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef apply_backspaces_and_linefeeds(text):\n    orig_lines = text.split('\\n')\n    orig_lines_len = len(orig_lines)\n    new_lines = []\n    for orig_line_idx, orig_line in enumerate(orig_lines):\n        chars, cursor = [], 0\n        orig_line_len = len(orig_line)\n        for orig_char_idx, orig_char in enumerate(orig_line):\n            if orig_char == '\\r' and (orig_char_idx != orig_line_len - 1 or\n                                      orig_line_idx != orig_lines_len - 1):\n                cursor = 0\n            elif orig_char == '\\b':\n                cursor = max(0, cursor - 1)\n            else:\n                if (orig_char == '\\r' and\n                        orig_char_idx == orig_line_len - 1 and\n                        orig_line_idx == orig_lines_len - 1):\n                    cursor = len(chars)\n                if cursor == len(chars):\n                    chars.append(orig_char)\n                else:\n                    chars[cursor] = orig_char\n                cursor += 1\n        new_lines.append(''.join(chars))\n    return '\\n'.join(new_lines)", "response": "Interpret text like a terminal by removing backspaces and linefeeds and applying them line by line."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef module_is_imported(modname, scope=None):\n    # return early if modname is not even cached\n    if not module_is_in_cache(modname):\n        return False\n\n    if scope is None:  # use globals() of the caller by default\n        scope = inspect.stack()[1][0].f_globals\n\n    for m in scope.values():\n        if isinstance(m, type(sys)) and m.__name__ == modname:\n            return True\n\n    return False", "response": "Checks if a module is imported within the current namespace."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a TelegramObserver from a given configuration file.", "response": "def from_config(cls, filename):\n        \"\"\"\n        Create a TelegramObserver from a given configuration file.\n\n        The file can be in any format supported by Sacred\n        (.json, .pickle, [.yaml]).\n        It has to specify a ``token`` and a ``chat_id`` and can optionally set\n        ``silent_completion``,``completed_text``, ``interrupted_text``, and\n        ``failed_text``.\n        \"\"\"\n        import telegram\n        d = load_config_file(filename)\n        request = cls.get_proxy_request(d) if 'proxy_url' in d else None\n\n        if 'token' in d and 'chat_id' in d:\n            bot = telegram.Bot(d['token'], request=request)\n            obs = cls(bot, **d)\n        else:\n            raise ValueError(\"Telegram configuration file must contain \"\n                             \"entries for 'token' and 'chat_id'!\")\n        for k in ['completed_text', 'interrupted_text', 'failed_text']:\n            if k in d:\n                setattr(obs, k, d[k])\n        return obs"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstores new measurements into the metrics collection.", "response": "def log_metrics(self, metrics_by_name, info):\n        \"\"\"Store new measurements to the database.\n\n        Take measurements and store them into\n        the metrics collection in the database.\n        Additionally, reference the metrics\n        in the info[\"metrics\"] dictionary.\n        \"\"\"\n        if self.metrics is None:\n            # If, for whatever reason, the metrics collection has not been set\n            # do not try to save anything there.\n            return\n        for key in metrics_by_name:\n            query = {\"run_id\": self.run_entry['_id'],\n                     \"name\": key}\n            push = {\"steps\": {\"$each\": metrics_by_name[key][\"steps\"]},\n                    \"values\": {\"$each\": metrics_by_name[key][\"values\"]},\n                    \"timestamps\": {\"$each\": metrics_by_name[key][\"timestamps\"]}\n                    }\n            update = {\"$push\": push}\n            result = self.metrics.update_one(query, update, upsert=True)\n            if result.upserted_id is not None:\n                # This is the first time we are storing this metric\n                info.setdefault(\"metrics\", []) \\\n                    .append({\"name\": key, \"id\": str(result.upserted_id)})"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntrying to retrieve a X. py file for a given X. py [ c file.", "response": "def get_py_file_if_possible(pyc_name):\n    \"\"\"Try to retrieve a X.py file for a given X.py[c] file.\"\"\"\n    if pyc_name.endswith(('.py', '.so', '.pyd')):\n        return pyc_name\n    assert pyc_name.endswith('.pyc')\n    non_compiled_file = pyc_name[:-1]\n    if os.path.exists(non_compiled_file):\n        return non_compiled_file\n    return pyc_name"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_digest(filename):\n    h = hashlib.md5()\n    with open(filename, 'rb') as f:\n        data = f.read(1 * MB)\n        while data:\n            h.update(data)\n            data = f.read(1 * MB)\n        return h.hexdigest()", "response": "Compute the MD5 hash for a given file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntrying to retrieve the commit hash of a given file.", "response": "def get_commit_if_possible(filename):\n    \"\"\"Try to retrieve VCS information for a given file.\n\n    Currently only supports git using the gitpython package.\n\n    Parameters\n    ----------\n    filename : str\n\n    Returns\n    -------\n        path: str\n            The base path of the repository\n        commit: str\n            The commit hash\n        is_dirty: bool\n            True if there are uncommitted changes in the repository\n    \"\"\"\n    # git\n    if opt.has_gitpython:\n        from git import Repo, InvalidGitRepositoryError\n        try:\n            directory = os.path.dirname(filename)\n            repo = Repo(directory, search_parent_directories=True)\n            try:\n                path = repo.remote().url\n            except ValueError:\n                path = 'git:/' + repo.working_dir\n            is_dirty = repo.is_dirty()\n            commit = repo.head.commit.hexsha\n            return path, commit, is_dirty\n        except (InvalidGitRepositoryError, ValueError):\n            pass\n    return None, None, None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef splitall(path):\n    allparts = []\n    while True:\n        parts = os.path.split(path)\n        if parts[0] == path:  # sentinel for absolute paths\n            allparts.insert(0, parts[0])\n            break\n        elif parts[1] == path:  # sentinel for relative paths\n            allparts.insert(0, parts[1])\n            break\n        else:\n            path = parts[0]\n            allparts.insert(0, parts[1])\n    return allparts", "response": "Splits a path into a list of directory names and optionally a filename."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef convert_path_to_module_parts(path):\n    module_parts = splitall(path)\n    if module_parts[-1] in ['__init__.py', '__init__.pyc']:\n        # remove trailing __init__.py\n        module_parts = module_parts[:-1]\n    else:\n        # remove file extension\n        module_parts[-1], _ = os.path.splitext(module_parts[-1])\n    return module_parts", "response": "Convert a path to a python file into a list of module names."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_local_source(filename, modname, experiment_path):\n    if not is_subdir(filename, experiment_path):\n        return False\n    rel_path = os.path.relpath(filename, experiment_path)\n    path_parts = convert_path_to_module_parts(rel_path)\n\n    mod_parts = modname.split('.')\n    if path_parts == mod_parts:\n        return True\n    if len(path_parts) > len(mod_parts):\n        return False\n    abs_path_parts = convert_path_to_module_parts(os.path.abspath(filename))\n    return all([p == m for p, m in zip(reversed(abs_path_parts),\n                                       reversed(mod_parts))])", "response": "Checks if a module is local source file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef gather_sources_and_dependencies(globs, base_dir=None):\n\n    experiment_path, main = get_main_file(globs)\n\n    base_dir = base_dir or experiment_path\n\n    gather_sources = source_discovery_strategies[SETTINGS['DISCOVER_SOURCES']]\n    sources = gather_sources(globs, base_dir)\n    if main is not None:\n        sources.add(main)\n\n    gather_dependencies = dependency_discovery_strategies[\n        SETTINGS['DISCOVER_DEPENDENCIES']]\n    dependencies = gather_dependencies(globs, base_dir)\n\n    if opt.has_numpy:\n        # Add numpy as a dependency because it might be used for randomness\n        dependencies.add(PackageDependency.create(opt.np))\n\n    return main, sources, dependencies", "response": "Scan the given globals for modules and return them as sources and dependencies."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef assert_is_valid_key(key):\n    if SETTINGS.CONFIG.ENFORCE_KEYS_MONGO_COMPATIBLE and (\n            isinstance(key, basestring) and ('.' in key or key[0] == '$')):\n        raise KeyError('Invalid key \"{}\". Config-keys cannot '\n                       'contain \".\" or start with \"$\"'.format(key))\n\n    if SETTINGS.CONFIG.ENFORCE_KEYS_JSONPICKLE_COMPATIBLE and \\\n            isinstance(key, basestring) and (\n            key in jsonpickle.tags.RESERVED or key.startswith('json://')):\n        raise KeyError('Invalid key \"{}\". Config-keys cannot be one of the'\n                       'reserved jsonpickle tags: {}'\n                       .format(key, jsonpickle.tags.RESERVED))\n\n    if SETTINGS.CONFIG.ENFORCE_STRING_KEYS and (\n            not isinstance(key, basestring)):\n        raise KeyError('Invalid key \"{}\". Config-keys have to be strings, '\n                       'but was {}'.format(key, type(key)))\n\n    if SETTINGS.CONFIG.ENFORCE_VALID_PYTHON_IDENTIFIER_KEYS and (\n            isinstance(key, basestring) and not PYTHON_IDENTIFIER.match(key)):\n        raise KeyError('Key \"{}\" is not a valid python identifier'\n                       .format(key))\n\n    if SETTINGS.CONFIG.ENFORCE_KEYS_NO_EQUALS and (\n            isinstance(key, basestring) and '=' in key):\n        raise KeyError('Invalid key \"{}\". Config keys may not contain an'\n                       'equals sign (\"=\").'.format('='))", "response": "Checks if a given config key is valid."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef from_config(cls, filename):\n        d = load_config_file(filename)\n        obs = None\n        if 'webhook_url' in d:\n            obs = cls(d['webhook_url'])\n        else:\n            raise ValueError(\"Slack configuration file must contain \"\n                             \"an entry for 'webhook_url'!\")\n        for k in ['completed_text', 'interrupted_text', 'failed_text',\n                  'bot_name', 'icon']:\n            if k in d:\n                setattr(obs, k, d[k])\n        return obs", "response": "Create a SlackObserver from a given configuration file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_host_info():\n    host_info = {}\n    for k, v in host_info_gatherers.items():\n        try:\n            host_info[k] = v()\n        except IgnoreHostInfo:\n            pass\n    return host_info", "response": "Collect some information about the machine this experiment runs on."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef host_info_getter(func, name=None):\n    name = name or func.__name__\n    host_info_gatherers[name] = func\n    return func", "response": "Decorator to add a function to the global dict of functions that can be used to collect the host info."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef linearize_metrics(logged_metrics):\n    metrics_by_name = {}\n    for metric_entry in logged_metrics:\n        if metric_entry.name not in metrics_by_name:\n            metrics_by_name[metric_entry.name] = {\n                \"steps\": [],\n                \"values\": [],\n                \"timestamps\": [],\n                \"name\": metric_entry.name\n            }\n        metrics_by_name[metric_entry.name][\"steps\"] \\\n            .append(metric_entry.step)\n        metrics_by_name[metric_entry.name][\"values\"] \\\n            .append(metric_entry.value)\n        metrics_by_name[metric_entry.name][\"timestamps\"] \\\n            .append(metric_entry.timestamp)\n    return metrics_by_name", "response": "Takes a list of individual measurements possibly belonging\n    to different metrics and groups them by name."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nlogging a scalar metric.", "response": "def log_scalar_metric(self, metric_name, value, step=None):\n        \"\"\"\n        Add a new measurement.\n\n        The measurement will be processed by the MongoDB observer\n        during a heartbeat event.\n        Other observers are not yet supported.\n\n        :param metric_name: The name of the metric, e.g. training.loss.\n        :param value: The measured value.\n        :param step: The step number (integer), e.g. the iteration number\n                    If not specified, an internal counter for each metric\n                    is used, incremented by one.\n        \"\"\"\n        if opt.has_numpy:\n            np = opt.np\n            if isinstance(value, np.generic):\n                value = np.asscalar(value)\n            if isinstance(step, np.generic):\n                step = np.asscalar(step)\n        if step is None:\n            step = self._metric_step_counter.get(metric_name, -1) + 1\n        self._logged_metrics.put(\n            ScalarMetricLogEntry(metric_name, step,\n                                 datetime.datetime.utcnow(),\n                                 value))\n        self._metric_step_counter[metric_name] = step"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_last_metrics(self):\n        read_up_to = self._logged_metrics.qsize()\n        messages = []\n        for i in range(read_up_to):\n            try:\n                messages.append(self._logged_metrics.get_nowait())\n            except Empty:\n                pass\n        return messages", "response": "Read all measurement events since last call of the method."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef with_metaclass(meta, *bases):\n    # This requires a bit of explanation: the basic idea is to make a dummy\n    # metaclass for one level of class instantiation that replaces itself with\n    # the actual metaclass.\n    class Metaclass(meta):\n        def __new__(cls, name, this_bases, d):\n            return meta(name, bases, d)\n    return type.__new__(Metaclass, str('temporary_class'), (), {})", "response": "Create a base class with a metaclass."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a sorted list of all CommandLineOption subclasses.", "response": "def gather_command_line_options(filter_disabled=None):\n    \"\"\"Get a sorted list of all CommandLineOption subclasses.\"\"\"\n    if filter_disabled is None:\n        filter_disabled = not SETTINGS.COMMAND_LINE.SHOW_DISABLED_OPTIONS\n    options = [opt for opt in get_inheritors(CommandLineOption)\n               if not filter_disabled or opt._enabled]\n    return sorted(options, key=lambda opt: opt.__name__)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef apply(cls, args, run):\n        # TODO: sacred.initialize.create_run already takes care of this\n\n        try:\n            lvl = int(args)\n        except ValueError:\n            lvl = args\n        run.root_logger.setLevel(lvl)", "response": "Adjust the loglevel of the root - logger of this run."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds priority info for this run.", "response": "def apply(cls, args, run):\n        \"\"\"Add priority info for this run.\"\"\"\n        try:\n            priority = float(args)\n        except ValueError:\n            raise ValueError(\"The PRIORITY argument must be a number! \"\n                             \"(but was '{}')\".format(args))\n        run.meta_info['priority'] = priority"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a generator that yields items from an ingredient instance.", "response": "def gather_from_ingredients(wrapped, instance=None, args=None, kwargs=None):\n    \"\"\"\n    Decorator that calls `_gather` on the instance the wrapped function is\n    bound to (should be an `Ingredient`) and yields from the returned\n    generator.\n\n    This function is necessary, because `Ingredient._gather` cannot directly be\n    used as a decorator inside of `Ingredient`.\n    \"\"\"\n    for item in instance._gather(wrapped):\n        yield item"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pre_run_hook(self, func, prefix=None):\n        cf = self.capture(func, prefix=prefix)\n        self.pre_run_hooks.append(cf)\n        return cf", "response": "Decorator to add a pre - run hook to this ingredient."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef command(self, function=None, prefix=None, unobserved=False):\n        captured_f = self.capture(function, prefix=prefix)\n        captured_f.unobserved = unobserved\n        self.commands[function.__name__] = captured_f\n        return captured_f", "response": "Decorator to define a new command for this Ingredient or Experiment."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef named_config(self, func):\n        config_scope = ConfigScope(func)\n        self._add_named_config(func.__name__, config_scope)\n        return config_scope", "response": "Decorator to turn a function into a named configuration."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef config_hook(self, func):\n        argspec = inspect.getargspec(func)\n        args = ['config', 'command_name', 'logger']\n        if not (argspec.args == args and argspec.varargs is None and\n                argspec.keywords is None and argspec.defaults is None):\n            raise ValueError('Wrong signature for config_hook. Expected: '\n                             '(config, command_name, logger)')\n        self.config_hooks.append(func)\n        return self.config_hooks[-1]", "response": "Decorator to add a config hook to this Ingredient."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_config(self, cfg_or_file=None, **kw_conf):\n        self.configurations.append(self._create_config_dict(cfg_or_file,\n                                                            kw_conf))", "response": "Adds a configuration entry to this ingredient."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a named configuration entry to this ingredient.", "response": "def add_named_config(self, name, cfg_or_file=None, **kw_conf):\n        \"\"\"\n        Add a **named** configuration entry to this ingredient/experiment.\n\n        Can be called with a filename, a dictionary xor with keyword arguments.\n        Supported formats for the config-file so far are: ``json``, ``pickle``\n        and ``yaml``.\n\n        The resulting dictionary will be converted into a\n         :class:`~sacred.config_scope.ConfigDict`.\n\n        See :ref:`named_configurations`\n\n        :param name: name of the configuration\n        :type name: str\n        :param cfg_or_file: Configuration dictionary of filename of config file\n                            to add to this ingredient/experiment.\n        :type cfg_or_file: dict or str\n        :param kw_conf: Configuration entries to be added to this\n                        ingredient/experiment.\n        \"\"\"\n        self._add_named_config(name, self._create_config_dict(cfg_or_file,\n                                                              kw_conf))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a package to the list of dependencies.", "response": "def add_package_dependency(self, package_name, version):\n        \"\"\"\n        Add a package to the list of dependencies.\n\n        :param package_name: The name of the package dependency\n        :type package_name: str\n        :param version: The (minimum) version of the package\n        :type version: str\n        \"\"\"\n        if not PEP440_VERSION_PATTERN.match(version):\n            raise ValueError('Invalid Version: \"{}\"'.format(version))\n        self.dependencies.add(PackageDependency(package_name, version))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfunctioning needed and used by gathering functions through the decorator `gather_from_ingredients` in `Ingredient`. Don't use this function by itself outside of the decorator! By overwriting this function you can filter what is visible when gathering something (e.g. commands). See `Experiment._gather` for an example.", "response": "def _gather(self, func):\n        \"\"\"\n        Function needed and used by gathering functions through the decorator\n        `gather_from_ingredients` in `Ingredient`. Don't use this function by\n        itself outside of the decorator!\n\n        By overwriting this function you can filter what is visible when\n        gathering something (e.g. commands). See `Experiment._gather` for an\n        example.\n        \"\"\"\n        for ingredient, _ in self.traverse_ingredients():\n            for item in func(ingredient):\n                yield item"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef gather_commands(self, ingredient):\n        for command_name, command in ingredient.commands.items():\n            yield join_paths(ingredient.path, command_name), command", "response": "Yield all commands from this ingredient and its sub - ingredients."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nyielding all named configs from this ingredient and its sub - ingredients.", "response": "def gather_named_configs(self, ingredient):\n        \"\"\"Collect all named configs from this ingredient and its\n        sub-ingredients.\n\n        Yields\n        ------\n        config_name: str\n            The full (dotted) name of the named config.\n        config: ConfigScope or ConfigDict or basestring\n            The corresponding named config.\n        \"\"\"\n        for config_name, config in ingredient.named_configs.items():\n            yield join_paths(ingredient.path, config_name), config"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_experiment_info(self):\n        dependencies = set()\n        sources = set()\n        for ing, _ in self.traverse_ingredients():\n            dependencies |= ing.dependencies\n            sources |= ing.sources\n\n        for dep in dependencies:\n            dep.fill_missing_version()\n\n        mainfile = (self.mainfile.to_json(self.base_dir)[0]\n                    if self.mainfile else None)\n\n        def name_lower(d):\n            return d.name.lower()\n\n        return dict(\n            name=self.path,\n            base_dir=self.base_dir,\n            sources=[s.to_json(self.base_dir) for s in sorted(sources)],\n            dependencies=[d.to_json()\n                          for d in sorted(dependencies, key=name_lower)],\n            repositories=collect_repositories(sources),\n            mainfile=mainfile\n        )", "response": "Get a dictionary with information about this experiment."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef traverse_ingredients(self):\n        if self._is_traversing:\n            raise CircularDependencyError(ingredients=[self])\n        else:\n            self._is_traversing = True\n        yield self, 0\n        with CircularDependencyError.track(self):\n            for ingredient in self.ingredients:\n                for ingred, depth in ingredient.traverse_ingredients():\n                    yield ingred, depth + 1\n        self._is_traversing = False", "response": "Recursively traverse this ingredient and its sub - ingredients."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fail_if_publish_binary_not_installed(binary, publish_target, install_link):\n    if not shutil.which(binary):\n        click.secho(\n            \"Publishing to {publish_target} requires {binary} to be installed and configured\".format(\n                publish_target=publish_target, binary=binary\n            ),\n            bg=\"red\",\n            fg=\"white\",\n            bold=True,\n            err=True,\n        )\n        click.echo(\n            \"Follow the instructions at {install_link}\".format(\n                install_link=install_link\n            ),\n            err=True,\n        )\n        sys.exit(1)", "response": "Exit with error message if binary is not installed"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef path_from_row_pks(row, pks, use_rowid, quote=True):\n    if use_rowid:\n        bits = [row['rowid']]\n    else:\n        bits = [\n            row[pk][\"value\"] if isinstance(row[pk], dict) else row[pk]\n            for pk in pks\n        ]\n    if quote:\n        bits = [urllib.parse.quote_plus(str(bit)) for bit in bits]\n    else:\n        bits = [str(bit) for bit in bits]\n\n    return ','.join(bits)", "response": "Generate an optionally URL - quoted unique identifier\n            for a row from its primary keys."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef detect_primary_keys(conn, table):\n    \" Figure out primary keys for a table. \"\n    table_info_rows = [\n        row\n        for row in conn.execute(\n            'PRAGMA table_info(\"{}\")'.format(table)\n        ).fetchall()\n        if row[-1]\n    ]\n    table_info_rows.sort(key=lambda row: row[-1])\n    return [str(r[1]) for r in table_info_rows]", "response": "Figure out primary keys for a table."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef detect_fts(conn, table):\n    \"Detect if table has a corresponding FTS virtual table and return it\"\n    rows = conn.execute(detect_fts_sql(table)).fetchall()\n    if len(rows) == 0:\n        return None\n    else:\n        return rows[0][0]", "response": "Detect if table has a corresponding FTS virtual table and return it"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_url(value):\n    \"Must start with http:// or https:// and contain JUST a URL\"\n    if not isinstance(value, str):\n        return False\n    if not value.startswith('http://') and not value.startswith('https://'):\n        return False\n    # Any whitespace at all is invalid\n    if whitespace_re.search(value):\n        return False\n    return True", "response": "Must start with http:// or https:// and contain JUST a URL"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_css_class(s):\n    if css_class_re.match(s):\n        return s\n    md5_suffix = hashlib.md5(s.encode('utf8')).hexdigest()[:6]\n    # Strip leading _, -\n    s = s.lstrip('_').lstrip('-')\n    # Replace any whitespace with hyphens\n    s = '-'.join(s.split())\n    # Remove any remaining invalid characters\n    s = css_invalid_chars_re.sub('', s)\n    # Attach the md5 suffix\n    bits = [b for b in (s, md5_suffix) if b]\n    return '-'.join(bits)", "response": "Converts a string to a valid unique CSS class."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef metadata(self, key=None, database=None, table=None, fallback=True):\n        assert not (database is None and table is not None), \\\n            \"Cannot call metadata() with table= specified but not database=\"\n        databases = self._metadata.get(\"databases\") or {}\n        search_list = []\n        if database is not None:\n            search_list.append(databases.get(database) or {})\n        if table is not None:\n            table_metadata = (\n                (databases.get(database) or {}).get(\"tables\") or {}\n            ).get(table) or {}\n            search_list.insert(0, table_metadata)\n        search_list.append(self._metadata)\n        if not fallback:\n            # No fallback allowed, so just use the first one in the list\n            search_list = search_list[:1]\n        if key is not None:\n            for item in search_list:\n                if key in item:\n                    return item[key]\n            return None\n        else:\n            # Return the merged list\n            m = {}\n            for item in search_list:\n                m.update(item)\n            return m", "response": "Returns the metadata value for the specified key in the specified database or table."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn config for plugin falling back from specified database / table", "response": "def plugin_config(\n        self, plugin_name, database=None, table=None, fallback=True\n    ):\n        \"Return config for plugin, falling back from specified database/table\"\n        plugins = self.metadata(\n            \"plugins\", database=database, table=table, fallback=fallback\n        )\n        if plugins is None:\n            return None\n        return plugins.get(plugin_name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning dict mapping ( column value ) -> label", "response": "async def expand_foreign_keys(self, database, table, column, values):\n        \"Returns dict mapping (column, value) -> label\"\n        labeled_fks = {}\n        foreign_keys = await self.foreign_keys_for_table(database, table)\n        # Find the foreign_key for this column\n        try:\n            fk = [\n                foreign_key for foreign_key in foreign_keys\n                if foreign_key[\"column\"] == column\n            ][0]\n        except IndexError:\n            return {}\n        label_column = await self.label_column_for_table(database, fk[\"other_table\"])\n        if not label_column:\n            return {\n                (fk[\"column\"], value): str(value)\n                for value in values\n            }\n        labeled_fks = {}\n        sql = '''\n            select {other_column}, {label_column}\n            from {other_table}\n            where {other_column} in ({placeholders})\n        '''.format(\n            other_column=escape_sqlite(fk[\"other_column\"]),\n            label_column=escape_sqlite(label_column),\n            other_table=escape_sqlite(fk[\"other_table\"]),\n            placeholders=\", \".join([\"?\"] * len(set(values))),\n        )\n        try:\n            results = await self.execute(\n                database, sql, list(set(values))\n            )\n        except InterruptedError:\n            pass\n        else:\n            for id, value in results:\n                labeled_fks[(fk[\"column\"], id)] = value\n        return labeled_fks"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninspecting the database and return a dictionary of table metadata", "response": "def inspect(self):\n        \" Inspect the database and return a dictionary of table metadata \"\n        if self._inspect:\n            return self._inspect\n\n        self._inspect = {}\n        for filename in self.files:\n            if filename is MEMORY:\n                self._inspect[\":memory:\"] = {\n                    \"hash\": \"000\",\n                    \"file\": \":memory:\",\n                    \"size\": 0,\n                    \"views\": {},\n                    \"tables\": {},\n                }\n            else:\n                path = Path(filename)\n                name = path.stem\n                if name in self._inspect:\n                    raise Exception(\"Multiple files with same stem %s\" % name)\n                try:\n                    with sqlite3.connect(\n                        \"file:{}?mode=ro\".format(path), uri=True\n                    ) as conn:\n                        self.prepare_connection(conn)\n                        self._inspect[name] = {\n                            \"hash\": inspect_hash(path),\n                            \"file\": str(path),\n                            \"size\": path.stat().st_size,\n                            \"views\": inspect_views(conn),\n                            \"tables\": inspect_tables(conn, (self.metadata(\"databases\") or {}).get(name, {}))\n                        }\n                except sqlite3.OperationalError as e:\n                    if (e.args[0] == 'no such module: VirtualSpatialIndex'):\n                        raise click.UsageError(\n                            \"It looks like you're trying to load a SpatiaLite\"\n                            \" database without first loading the SpatiaLite module.\"\n                            \"\\n\\nRead more: https://datasette.readthedocs.io/en/latest/spatialite.html\"\n                        )\n                    else:\n                        raise\n        return self._inspect"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfetches table - specific metadata.", "response": "def table_metadata(self, database, table):\n        \"Fetch table-specific metadata.\"\n        return (self.metadata(\"databases\") or {}).get(database, {}).get(\n            \"tables\", {}\n        ).get(\n            table, {}\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nexecutes a SQL query against a database and returns a list of results.", "response": "async def execute(\n        self,\n        db_name,\n        sql,\n        params=None,\n        truncate=False,\n        custom_time_limit=None,\n        page_size=None,\n    ):\n        \"\"\"Executes sql against db_name in a thread\"\"\"\n        page_size = page_size or self.page_size\n\n        def sql_operation_in_thread(conn):\n            time_limit_ms = self.sql_time_limit_ms\n            if custom_time_limit and custom_time_limit < time_limit_ms:\n                time_limit_ms = custom_time_limit\n\n            with sqlite_timelimit(conn, time_limit_ms):\n                try:\n                    cursor = conn.cursor()\n                    cursor.execute(sql, params or {})\n                    max_returned_rows = self.max_returned_rows\n                    if max_returned_rows == page_size:\n                        max_returned_rows += 1\n                    if max_returned_rows and truncate:\n                        rows = cursor.fetchmany(max_returned_rows + 1)\n                        truncated = len(rows) > max_returned_rows\n                        rows = rows[:max_returned_rows]\n                    else:\n                        rows = cursor.fetchall()\n                        truncated = False\n                except sqlite3.OperationalError as e:\n                    if e.args == ('interrupted',):\n                        raise InterruptedError(e)\n                    print(\n                        \"ERROR: conn={}, sql = {}, params = {}: {}\".format(\n                            conn, repr(sql), params, e\n                        )\n                    )\n                    raise\n\n            if truncate:\n                return Results(rows, truncated, cursor.description)\n\n            else:\n                return Results(rows, False, cursor.description)\n\n        with trace(\"sql\", (db_name, sql.strip(), params)):\n            results = await self.execute_against_connection_in_thread(\n                db_name, sql_operation_in_thread\n            )\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns columns rows for specified table - including fancy foreign key treatment", "response": "async def display_columns_and_rows(\n        self,\n        database,\n        table,\n        description,\n        rows,\n        link_column=False,\n        truncate_cells=0,\n    ):\n        \"Returns columns, rows for specified table - including fancy foreign key treatment\"\n        table_metadata = self.ds.table_metadata(database, table)\n        sortable_columns = await self.sortable_columns_for_table(database, table, True)\n        columns = [\n            {\"name\": r[0], \"sortable\": r[0] in sortable_columns} for r in description\n        ]\n        pks = await self.ds.execute_against_connection_in_thread(\n            database, lambda conn: detect_primary_keys(conn, table)\n        )\n        column_to_foreign_key_table = {\n            fk[\"column\"]: fk[\"other_table\"]\n            for fk in await self.ds.foreign_keys_for_table(database, table)\n        }\n\n        cell_rows = []\n        for row in rows:\n            cells = []\n            # Unless we are a view, the first column is a link - either to the rowid\n            # or to the simple or compound primary key\n            if link_column:\n                cells.append(\n                    {\n                        \"column\": pks[0] if len(pks) == 1 else \"Link\",\n                        \"value\": jinja2.Markup(\n                            '<a href=\"/{database}/{table}/{flat_pks_quoted}\">{flat_pks}</a>'.format(\n                                database=database,\n                                table=urllib.parse.quote_plus(table),\n                                flat_pks=str(\n                                    jinja2.escape(\n                                        path_from_row_pks(row, pks, not pks, False)\n                                    )\n                                ),\n                                flat_pks_quoted=path_from_row_pks(row, pks, not pks),\n                            )\n                        ),\n                    }\n                )\n\n            for value, column_dict in zip(row, columns):\n                column = column_dict[\"name\"]\n                if link_column and len(pks) == 1 and column == pks[0]:\n                    # If there's a simple primary key, don't repeat the value as it's\n                    # already shown in the link column.\n                    continue\n\n                # First let the plugins have a go\n                # pylint: disable=no-member\n                plugin_display_value = pm.hook.render_cell(\n                    value=value,\n                    column=column,\n                    table=table,\n                    database=database,\n                    datasette=self.ds,\n                )\n                if plugin_display_value is not None:\n                    display_value = plugin_display_value\n                elif isinstance(value, dict):\n                    # It's an expanded foreign key - display link to other row\n                    label = value[\"label\"]\n                    value = value[\"value\"]\n                    # The table we link to depends on the column\n                    other_table = column_to_foreign_key_table[column]\n                    link_template = (\n                        LINK_WITH_LABEL if (label != value) else LINK_WITH_VALUE\n                    )\n                    display_value = jinja2.Markup(link_template.format(\n                        database=database,\n                        table=urllib.parse.quote_plus(other_table),\n                        link_id=urllib.parse.quote_plus(str(value)),\n                        id=str(jinja2.escape(value)),\n                        label=str(jinja2.escape(label)),\n                    ))\n                elif value in (\"\", None):\n                    display_value = jinja2.Markup(\"&nbsp;\")\n                elif is_url(str(value).strip()):\n                    display_value = jinja2.Markup(\n                        '<a href=\"{url}\">{url}</a>'.format(\n                            url=jinja2.escape(value.strip())\n                        )\n                    )\n                elif column in table_metadata.get(\"units\", {}) and value != \"\":\n                    # Interpret units using pint\n                    value = value * ureg(table_metadata[\"units\"][column])\n                    # Pint uses floating point which sometimes introduces errors in the compact\n                    # representation, which we have to round off to avoid ugliness. In the vast\n                    # majority of cases this rounding will be inconsequential. I hope.\n                    value = round(value.to_compact(), 6)\n                    display_value = jinja2.Markup(\n                        \"{:~P}\".format(value).replace(\" \", \"&nbsp;\")\n                    )\n                else:\n                    display_value = str(value)\n                    if truncate_cells and len(display_value) > truncate_cells:\n                        display_value = display_value[:truncate_cells] + u\"\\u2026\"\n\n                cells.append({\"column\": column, \"value\": display_value})\n            cell_rows.append(cells)\n\n        if link_column:\n            # Add the link column header.\n            # If it's a simple primary key, we have to remove and re-add that column name at\n            # the beginning of the header row.\n            if len(pks) == 1:\n                columns = [col for col in columns if col[\"name\"] != pks[0]]\n\n            columns = [\n                {\"name\": pks[0] if len(pks) == 1 else \"Link\", \"sortable\": len(pks) == 1}\n            ] + columns\n        return columns, cell_rows"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef inspect_hash(path):\n    \" Calculate the hash of a database, efficiently. \"\n    m = hashlib.sha256()\n    with path.open(\"rb\") as fp:\n        while True:\n            data = fp.read(HASH_BLOCK_SIZE)\n            if not data:\n                break\n            m.update(data)\n\n    return m.hexdigest()", "response": "Calculate the hash of a database efficiently."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef inspect_tables(conn, database_metadata):\n    \" List tables and their row counts, excluding uninteresting tables. \"\n    tables = {}\n    table_names = [\n        r[\"name\"]\n        for r in conn.execute(\n            'select * from sqlite_master where type=\"table\"'\n        )\n    ]\n\n    for table in table_names:\n        table_metadata = database_metadata.get(\"tables\", {}).get(\n            table, {}\n        )\n\n        try:\n            count = conn.execute(\n                \"select count(*) from {}\".format(escape_sqlite(table))\n            ).fetchone()[0]\n        except sqlite3.OperationalError:\n            # This can happen when running against a FTS virtual table\n            # e.g. \"select count(*) from some_fts;\"\n            count = 0\n\n        column_names = table_columns(conn, table)\n\n        tables[table] = {\n            \"name\": table,\n            \"columns\": column_names,\n            \"primary_keys\": detect_primary_keys(conn, table),\n            \"count\": count,\n            \"hidden\": table_metadata.get(\"hidden\") or False,\n            \"fts_table\": detect_fts(conn, table),\n        }\n\n    foreign_keys = get_all_foreign_keys(conn)\n    for table, info in foreign_keys.items():\n        tables[table][\"foreign_keys\"] = info\n\n    # Mark tables 'hidden' if they relate to FTS virtual tables\n    hidden_tables = [\n        r[\"name\"]\n        for r in conn.execute(\n            \"\"\"\n                select name from sqlite_master\n                where rootpage = 0\n                and sql like '%VIRTUAL TABLE%USING FTS%'\n            \"\"\"\n        )\n    ]\n\n    if detect_spatialite(conn):\n        # Also hide Spatialite internal tables\n        hidden_tables += [\n            \"ElementaryGeometries\",\n            \"SpatialIndex\",\n            \"geometry_columns\",\n            \"spatial_ref_sys\",\n            \"spatialite_history\",\n            \"sql_statements_log\",\n            \"sqlite_sequence\",\n            \"views_geometry_columns\",\n            \"virts_geometry_columns\",\n        ] + [\n            r[\"name\"]\n            for r in conn.execute(\n                \"\"\"\n                    select name from sqlite_master\n                    where name like \"idx_%\"\n                    and type = \"table\"\n                \"\"\"\n            )\n        ]\n\n    for t in tables.keys():\n        for hidden_table in hidden_tables:\n            if t == hidden_table or t.startswith(hidden_table):\n                tables[t][\"hidden\"] = True\n                continue\n\n    return tables", "response": "List tables and their row counts excluding uninteresting tables."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef lookups(self):\n        \"Yields (lookup, display, no_argument) pairs\"\n        for filter in self._filters:\n            yield filter.key, filter.display, filter.no_argument", "response": "Yields ( lookup display no_argument pairs"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef selections(self):\n        \"Yields (column, lookup, value) tuples\"\n        for key, value in self.pairs:\n            if '__' in key:\n                column, lookup = key.rsplit('__', 1)\n            else:\n                column = key\n                lookup = 'exact'\n            yield column, lookup, value", "response": "Yields ( column lookup value ) tuples"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef convert_unit(self, column, value):\n        \"If the user has provided a unit in the query, convert it into the column unit, if present.\"\n        if column not in self.units:\n            return value\n\n        # Try to interpret the value as a unit\n        value = self.ureg(value)\n        if isinstance(value, numbers.Number):\n            # It's just a bare number, assume it's the column unit\n            return value\n\n        column_unit = self.ureg(self.units[column])\n        return value.to(column_unit).magnitude", "response": "If the user has provided a unit in the query convert it into the column unit if present."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef skeleton(files, metadata, sqlite_extensions):\n    \"Generate a skeleton metadata.json file for specified SQLite databases\"\n    if os.path.exists(metadata):\n        click.secho(\n            \"File {} already exists, will not over-write\".format(metadata),\n            bg=\"red\",\n            fg=\"white\",\n            bold=True,\n            err=True,\n        )\n        sys.exit(1)\n    app = Datasette(files, sqlite_extensions=sqlite_extensions)\n    databases = {}\n    for database_name, info in app.inspect().items():\n        databases[database_name] = {\n            \"title\": None,\n            \"description\": None,\n            \"description_html\": None,\n            \"license\": None,\n            \"license_url\": None,\n            \"source\": None,\n            \"source_url\": None,\n            \"queries\": {},\n            \"tables\": {\n                table_name: {\n                    \"title\": None,\n                    \"description\": None,\n                    \"description_html\": None,\n                    \"license\": None,\n                    \"license_url\": None,\n                    \"source\": None,\n                    \"source_url\": None,\n                    \"units\": {},\n                }\n                for table_name in (info.get(\"tables\") or {})\n            },\n        }\n    open(metadata, \"w\").write(\n        json.dumps(\n            {\n                \"title\": None,\n                \"description\": None,\n                \"description_html\": None,\n                \"license\": None,\n                \"license_url\": None,\n                \"source\": None,\n                \"source_url\": None,\n                \"databases\": databases,\n            },\n            indent=4,\n        )\n    )\n    click.echo(\"Wrote skeleton to {}\".format(metadata))", "response": "Generate a skeleton metadata. json file for specified SQLite databases"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlists currently available plugins", "response": "def plugins(all, plugins_dir):\n    \"List currently available plugins\"\n    app = Datasette([], plugins_dir=plugins_dir)\n    click.echo(json.dumps(app.plugins(all), indent=4))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\npackage specified SQLite files into a new datasette Docker container", "response": "def package(\n    files,\n    tag,\n    metadata,\n    extra_options,\n    branch,\n    template_dir,\n    plugins_dir,\n    static,\n    install,\n    spatialite,\n    version_note,\n    **extra_metadata\n):\n    \"Package specified SQLite files into a new datasette Docker container\"\n    if not shutil.which(\"docker\"):\n        click.secho(\n            ' The package command requires \"docker\" to be installed and configured ',\n            bg=\"red\",\n            fg=\"white\",\n            bold=True,\n            err=True,\n        )\n        sys.exit(1)\n    with temporary_docker_directory(\n        files,\n        \"datasette\",\n        metadata,\n        extra_options,\n        branch,\n        template_dir,\n        plugins_dir,\n        static,\n        install,\n        spatialite,\n        version_note,\n        extra_metadata,\n    ):\n        args = [\"docker\", \"build\"]\n        if tag:\n            args.append(\"-t\")\n            args.append(tag)\n        args.append(\".\")\n        call(args)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nserving up specified SQLite database files with a web UI", "response": "def serve(\n    files,\n    immutable,\n    host,\n    port,\n    debug,\n    reload,\n    cors,\n    sqlite_extensions,\n    inspect_file,\n    metadata,\n    template_dir,\n    plugins_dir,\n    static,\n    memory,\n    config,\n    version_note,\n    help_config,\n):\n    \"\"\"Serve up specified SQLite database files with a web UI\"\"\"\n    if help_config:\n        formatter = formatting.HelpFormatter()\n        with formatter.section(\"Config options\"):\n            formatter.write_dl([\n                (option.name, '{} (default={})'.format(\n                    option.help, option.default\n                ))\n                for option in CONFIG_OPTIONS\n            ])\n        click.echo(formatter.getvalue())\n        sys.exit(0)\n    if reload:\n        import hupper\n\n        reloader = hupper.start_reloader(\"datasette.cli.serve\")\n        reloader.watch_files(files)\n        if metadata:\n            reloader.watch_files([metadata.name])\n\n    inspect_data = None\n    if inspect_file:\n        inspect_data = json.load(open(inspect_file))\n\n    metadata_data = None\n    if metadata:\n        metadata_data = json.loads(metadata.read())\n\n    click.echo(\"Serve! files={} (immutables={}) on port {}\".format(files, immutable, port))\n    ds = Datasette(\n        files,\n        immutables=immutable,\n        cache_headers=not debug and not reload,\n        cors=cors,\n        inspect_data=inspect_data,\n        metadata=metadata_data,\n        sqlite_extensions=sqlite_extensions,\n        template_dir=template_dir,\n        plugins_dir=plugins_dir,\n        static_mounts=static,\n        config=dict(config),\n        memory=memory,\n        version_note=version_note,\n    )\n    # Force initial hashing/table counting\n    ds.inspect()\n    ds.app().run(host=host, port=port, debug=debug)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef matrix(df,\n           filter=None, n=0, p=0, sort=None,\n           figsize=(25, 10), width_ratios=(15, 1), color=(0.25, 0.25, 0.25),\n           fontsize=16, labels=None, sparkline=True, inline=False,\n           freq=None):\n    \"\"\"\n    A matrix visualization of the nullity of the given DataFrame.\n\n    For optimal performance, please stay within 250 rows and 50 columns.\n\n    :param df: The `DataFrame` being mapped.\n    :param filter: The filter to apply to the heatmap. Should be one of \"top\", \"bottom\", or None (default).\n    :param n: The max number of columns to include in the filtered DataFrame.\n    :param p: The max percentage fill of the columns in the filtered DataFrame.\n    :param sort: The sort to apply to the heatmap. Should be one of \"ascending\", \"descending\", or None (default).\n    :param figsize: The size of the figure to display.\n    :param fontsize: The figure's font size. Default to 16.\n    :param labels: Whether or not to display the column names. Defaults to the underlying data labels when there are\n    50 columns or less, and no labels when there are more than 50 columns.\n    :param sparkline: Whether or not to display the sparkline. Defaults to True.\n    :param width_ratios: The ratio of the width of the matrix to the width of the sparkline. Defaults to `(15, 1)`.\n    Does nothing if `sparkline=False`.\n    :param color: The color of the filled columns. Default is `(0.25, 0.25, 0.25)`.\n    :return: If `inline` is False, the underlying `matplotlib.figure` object. Else, nothing.\n    \"\"\"\n    df = nullity_filter(df, filter=filter, n=n, p=p)\n    df = nullity_sort(df, sort=sort)\n\n    height = df.shape[0]\n    width = df.shape[1]\n\n    # z is the color-mask array, g is a NxNx3 matrix. Apply the z color-mask to set the RGB of each pixel.\n    z = df.notnull().values\n    g = np.zeros((height, width, 3))\n\n    g[z < 0.5] = [1, 1, 1]\n    g[z > 0.5] = color\n\n    # Set up the matplotlib grid layout. A unary subplot if no sparkline, a left-right splot if yes sparkline.\n    plt.figure(figsize=figsize)\n    if sparkline:\n        gs = gridspec.GridSpec(1, 2, width_ratios=width_ratios)\n        gs.update(wspace=0.08)\n        ax1 = plt.subplot(gs[1])\n    else:\n        gs = gridspec.GridSpec(1, 1)\n    ax0 = plt.subplot(gs[0])\n\n    # Create the nullity plot.\n    ax0.imshow(g, interpolation='none')\n\n    # Remove extraneous default visual elements.\n    ax0.set_aspect('auto')\n    ax0.grid(b=False)\n    ax0.xaxis.tick_top()\n    ax0.xaxis.set_ticks_position('none')\n    ax0.yaxis.set_ticks_position('none')\n    ax0.spines['top'].set_visible(False)\n    ax0.spines['right'].set_visible(False)\n    ax0.spines['bottom'].set_visible(False)\n    ax0.spines['left'].set_visible(False)\n\n    # Set up and rotate the column ticks. The labels argument is set to None by default. If the user specifies it in\n    # the argument, respect that specification. Otherwise display for <= 50 columns and do not display for > 50.\n    if labels or (labels is None and len(df.columns) <= 50):\n        ha = 'left'\n        ax0.set_xticks(list(range(0, width)))\n        ax0.set_xticklabels(list(df.columns), rotation=45, ha=ha, fontsize=fontsize)\n    else:\n        ax0.set_xticks([])\n\n    # Adds Timestamps ticks if freq is not None, else set up the two top-bottom row ticks.\n    if freq:\n        ts_list = []\n\n        if type(df.index) == pd.PeriodIndex:\n            ts_array = pd.date_range(df.index.to_timestamp().date[0],\n                                     df.index.to_timestamp().date[-1],\n                                     freq=freq).values\n\n            ts_ticks = pd.date_range(df.index.to_timestamp().date[0],\n                                     df.index.to_timestamp().date[-1],\n                                     freq=freq).map(lambda t:\n                                                    t.strftime('%Y-%m-%d'))\n\n        elif type(df.index) == pd.DatetimeIndex:\n            ts_array = pd.date_range(df.index.date[0], df.index.date[-1],\n                                     freq=freq).values\n\n            ts_ticks = pd.date_range(df.index.date[0], df.index.date[-1],\n                                     freq=freq).map(lambda t:\n                                                    t.strftime('%Y-%m-%d'))\n        else:\n            raise KeyError('Dataframe index must be PeriodIndex or DatetimeIndex.')\n        try:\n            for value in ts_array:\n                ts_list.append(df.index.get_loc(value))\n        except KeyError:\n            raise KeyError('Could not divide time index into desired frequency.')\n\n        ax0.set_yticks(ts_list)\n        ax0.set_yticklabels(ts_ticks, fontsize=int(fontsize / 16 * 20), rotation=0)\n    else:\n        ax0.set_yticks([0, df.shape[0] - 1])\n        ax0.set_yticklabels([1, df.shape[0]], fontsize=int(fontsize / 16 * 20), rotation=0)\n\n    # Create the inter-column vertical grid.\n    in_between_point = [x + 0.5 for x in range(0, width - 1)]\n    for in_between_point in in_between_point:\n        ax0.axvline(in_between_point, linestyle='-', color='white')\n\n    if sparkline:\n        # Calculate row-wise completeness for the sparkline.\n        completeness_srs = df.notnull().astype(bool).sum(axis=1)\n        x_domain = list(range(0, height))\n        y_range = list(reversed(completeness_srs.values))\n        min_completeness = min(y_range)\n        max_completeness = max(y_range)\n        min_completeness_index = y_range.index(min_completeness)\n        max_completeness_index = y_range.index(max_completeness)\n\n        # Set up the sparkline, remove the border element.\n        ax1.grid(b=False)\n        ax1.set_aspect('auto')\n        # GH 25\n        if int(mpl.__version__[0]) <= 1:\n            ax1.set_axis_bgcolor((1, 1, 1))\n        else:\n            ax1.set_facecolor((1, 1, 1))\n        ax1.spines['top'].set_visible(False)\n        ax1.spines['right'].set_visible(False)\n        ax1.spines['bottom'].set_visible(False)\n        ax1.spines['left'].set_visible(False)\n        ax1.set_ymargin(0)\n\n        # Plot sparkline---plot is sideways so the x and y axis are reversed.\n        ax1.plot(y_range, x_domain, color=color)\n\n        if labels:\n            # Figure out what case to display the label in: mixed, upper, lower.\n            label = 'Data Completeness'\n            if str(df.columns[0]).islower():\n                label = label.lower()\n            if str(df.columns[0]).isupper():\n                label = label.upper()\n\n            # Set up and rotate the sparkline label.\n            ha = 'left'\n            ax1.set_xticks([min_completeness + (max_completeness - min_completeness) / 2])\n            ax1.set_xticklabels([label], rotation=45, ha=ha, fontsize=fontsize)\n            ax1.xaxis.tick_top()\n            ax1.set_yticks([])\n        else:\n            ax1.set_xticks([])\n            ax1.set_yticks([])\n\n        # Add maximum and minimum labels, circles.\n        ax1.annotate(max_completeness,\n                     xy=(max_completeness, max_completeness_index),\n                     xytext=(max_completeness + 2, max_completeness_index),\n                     fontsize=int(fontsize / 16 * 14),\n                     va='center',\n                     ha='left')\n        ax1.annotate(min_completeness,\n                     xy=(min_completeness, min_completeness_index),\n                     xytext=(min_completeness - 2, min_completeness_index),\n                     fontsize=int(fontsize / 16 * 14),\n                     va='center',\n                     ha='right')\n\n        ax1.set_xlim([min_completeness - 2, max_completeness + 2])  # Otherwise the circles are cut off.\n        ax1.plot([min_completeness], [min_completeness_index], '.', color=color, markersize=10.0)\n        ax1.plot([max_completeness], [max_completeness_index], '.', color=color, markersize=10.0)\n\n        # Remove tick mark (only works after plotting).\n        ax1.xaxis.set_ticks_position('none')\n\n    if inline:\n        plt.show()\n    else:\n        return ax0", "response": "A basic nullity visualization of the given DataFrame."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef bar(df, figsize=(24, 10), fontsize=16, labels=None, log=False, color='dimgray', inline=False,\n        filter=None, n=0, p=0, sort=None):\n    \"\"\"\n    A bar chart visualization of the nullity of the given DataFrame.\n\n    :param df: The input DataFrame.\n    :param log: Whether or not to display a logorithmic plot. Defaults to False (linear).\n    :param filter: The filter to apply to the heatmap. Should be one of \"top\", \"bottom\", or None (default).\n    :param n: The cap on the number of columns to include in the filtered DataFrame.\n    :param p: The cap on the percentage fill of the columns in the filtered DataFrame.\n    :param sort: The sort to apply to the heatmap. Should be one of \"ascending\", \"descending\", or None (default).\n    :param figsize: The size of the figure to display.\n    :param fontsize: The figure's font size. This default to 16.\n    :param labels: Whether or not to display the column names. Would need to be turned off on particularly large\n    displays. Defaults to True.\n    :param color: The color of the filled columns. Default to the RGB multiple `(0.25, 0.25, 0.25)`.\n    :return: If `inline` is False, the underlying `matplotlib.figure` object. Else, nothing.\n    \"\"\"\n    nullity_counts = len(df) - df.isnull().sum()\n    df = nullity_filter(df, filter=filter, n=n, p=p)\n    df = nullity_sort(df, sort=sort)\n\n    plt.figure(figsize=figsize)\n    (nullity_counts / len(df)).plot(kind='bar', figsize=figsize, fontsize=fontsize, log=log, color=color)\n    ax1 = plt.gca()\n\n    axes = [ax1]\n\n    # Start appending elements, starting with a modified bottom x axis.\n    if labels or (labels is None and len(df.columns) <= 50):\n        ax1.set_xticklabels(ax1.get_xticklabels(), rotation=45, ha='right', fontsize=fontsize)\n\n        # Create the numerical ticks.\n        ax2 = ax1.twinx()\n        axes.append(ax2)\n        if not log:\n            ax1.set_ylim([0, 1])\n            ax2.set_yticks(ax1.get_yticks())\n            ax2.set_yticklabels([int(n*len(df)) for n in ax1.get_yticks()], fontsize=fontsize)\n        else:\n            # For some reason when a logarithmic plot is specified `ax1` always contains two more ticks than actually\n            # appears in the plot. The fix is to ignore the first and last entries. Also note that when a log scale\n            # is used, we have to make it match the `ax1` layout ourselves.\n            ax2.set_yscale('log')\n            ax2.set_ylim(ax1.get_ylim())\n            ax2.set_yticklabels([int(n*len(df)) for n in ax1.get_yticks()], fontsize=fontsize)\n    else:\n        ax1.set_xticks([])\n\n    # Create the third axis, which displays columnar totals above the rest of the plot.\n    ax3 = ax1.twiny()\n    axes.append(ax3)\n    ax3.set_xticks(ax1.get_xticks())\n    ax3.set_xlim(ax1.get_xlim())\n    ax3.set_xticklabels(nullity_counts.values, fontsize=fontsize, rotation=45, ha='left')\n    ax3.grid(False)\n\n    for ax in axes:\n        ax.spines['top'].set_visible(False)\n        ax.spines['right'].set_visible(False)\n        ax.spines['bottom'].set_visible(False)\n        ax.spines['left'].set_visible(False)\n        ax.xaxis.set_ticks_position('none')\n        ax.yaxis.set_ticks_position('none')\n\n    if inline:\n        plt.show()\n    else:\n        return ax1", "response": "A bar chart visualization of the nullity of the given DataFrame."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npresenting a seaborn heatmap visualization of nullity correlation in a DataFrame.", "response": "def heatmap(df, inline=False,\n            filter=None, n=0, p=0, sort=None,\n            figsize=(20, 12), fontsize=16, labels=True, \n            cmap='RdBu', vmin=-1, vmax=1, cbar=True\n            ):\n    \"\"\"\n    Presents a `seaborn` heatmap visualization of nullity correlation in the given DataFrame.\n    \n    Note that this visualization has no special support for large datasets. For those, try the dendrogram instead.\n\n    :param df: The DataFrame whose completeness is being heatmapped.\n    :param filter: The filter to apply to the heatmap. Should be one of \"top\", \"bottom\", or None (default). See\n    `nullity_filter()` for more information.\n    :param n: The cap on the number of columns to include in the filtered DataFrame. See  `nullity_filter()` for\n    more information.\n    :param p: The cap on the percentage fill of the columns in the filtered DataFrame. See  `nullity_filter()` for\n    more information.\n    :param sort: The sort to apply to the heatmap. Should be one of \"ascending\", \"descending\", or None. See\n    `nullity_sort()` for more information.\n    :param figsize: The size of the figure to display. This is a `matplotlib` parameter which defaults to (20, 12).\n    :param fontsize: The figure's font size.\n    :param labels: Whether or not to label each matrix entry with its correlation (default is True).\n    :param cmap: What `matplotlib` colormap to use. Defaults to `RdBu`.\n    :param vmin: The normalized colormap threshold. Defaults to -1, e.g. the bottom of the color scale.\n    :param vmax: The normalized colormap threshold. Defaults to 1, e.g. the bottom of the color scale.\n    :param inline: Whether or not the figure is inline. If it's not then instead of getting plotted, this method will\n    return its figure.\n    :return: If `inline` is False, the underlying `matplotlib.figure` object. Else, nothing.\n    \"\"\"\n    # Apply filters and sorts, set up the figure.\n    df = nullity_filter(df, filter=filter, n=n, p=p)\n    df = nullity_sort(df, sort=sort)\n\n    plt.figure(figsize=figsize)\n    gs = gridspec.GridSpec(1, 1)\n    ax0 = plt.subplot(gs[0])\n\n    # Remove completely filled or completely empty variables.\n    df = df.iloc[:,[i for i, n in enumerate(np.var(df.isnull(), axis='rows')) if n > 0]]\n\n    # Create and mask the correlation matrix. Construct the base heatmap.\n    corr_mat = df.isnull().corr()\n    mask = np.zeros_like(corr_mat)\n    mask[np.triu_indices_from(mask)] = True\n\n    if labels:\n        sns.heatmap(corr_mat, mask=mask, cmap=cmap, ax=ax0, cbar=cbar,\n                    annot=True, annot_kws={'size': fontsize - 2},\n                    vmin=vmin, vmax=vmax)\n    else:\n        sns.heatmap(corr_mat, mask=mask, cmap=cmap, ax=ax0, cbar=cbar,\n                    vmin=vmin, vmax=vmax)\n\n    # Apply visual corrections and modifications.\n    ax0.xaxis.tick_bottom()\n    ax0.set_xticklabels(ax0.xaxis.get_majorticklabels(), rotation=45, ha='right', fontsize=fontsize)\n    ax0.set_yticklabels(ax0.yaxis.get_majorticklabels(), fontsize=fontsize, rotation=0)\n    ax0.set_yticklabels(ax0.yaxis.get_majorticklabels(), rotation=0, fontsize=fontsize)\n    ax0.xaxis.set_ticks_position('none')\n    ax0.yaxis.set_ticks_position('none')\n    ax0.patch.set_visible(False)\n\n    for text in ax0.texts:\n        t = float(text.get_text())\n        if 0.95 <= t < 1:\n            text.set_text('<1')\n        elif -1 < t <= -0.95:\n            text.set_text('>-1')\n        elif t == 1:\n            text.set_text('1')\n        elif t == -1:\n            text.set_text('-1')\n        elif -0.05 < t < 0.05:\n            text.set_text('')\n        else:\n            text.set_text(round(t, 1))\n\n    if inline:\n        plt.show()\n    else:\n        return ax0"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dendrogram(df, method='average',\n               filter=None, n=0, p=0, sort=None,\n               orientation=None, figsize=None,\n               fontsize=16, inline=False\n               ):\n    \"\"\"\n    Fits a `scipy` hierarchical clustering algorithm to the given DataFrame's variables and visualizes the results as\n    a `scipy` dendrogram.\n    \n    The default vertical display will fit up to 50 columns. If more than 50 columns are specified and orientation is\n    left unspecified the dendrogram will automatically swap to a horizontal display to fit the additional variables.\n\n    :param df: The DataFrame whose completeness is being dendrogrammed.\n    :param method: The distance measure being used for clustering. This is a parameter that is passed to \n    `scipy.hierarchy`.\n    :param filter: The filter to apply to the heatmap. Should be one of \"top\", \"bottom\", or None (default).\n    :param n: The cap on the number of columns to include in the filtered DataFrame.\n    :param p: The cap on the percentage fill of the columns in the filtered DataFrame.\n    :param sort: The sort to apply to the heatmap. Should be one of \"ascending\", \"descending\", or None.\n    :param figsize: The size of the figure to display. This is a `matplotlib` parameter which defaults to `(25, 10)`.\n    :param fontsize: The figure's font size.\n    :param orientation: The way the dendrogram is oriented. Defaults to top-down if there are less than or equal to 50\n    columns and left-right if there are more.\n    :param inline: Whether or not the figure is inline. If it's not then instead of getting plotted, this method will\n    return its figure.\n    :return: If `inline` is False, the underlying `matplotlib.figure` object. Else, nothing.\n    \"\"\"\n    if not figsize:\n        if len(df.columns) <= 50 or orientation == 'top' or orientation == 'bottom':\n            figsize = (25, 10)\n        else:\n            figsize = (25, (25 + len(df.columns) - 50)*0.5)\n    \n    plt.figure(figsize=figsize)\n    gs = gridspec.GridSpec(1, 1)\n    ax0 = plt.subplot(gs[0])\n\n    df = nullity_filter(df, filter=filter, n=n, p=p)\n    df = nullity_sort(df, sort=sort)\n\n    # Link the hierarchical output matrix, figure out orientation, construct base dendrogram.\n    x = np.transpose(df.isnull().astype(int).values)\n    z = hierarchy.linkage(x, method)\n\n    if not orientation:\n        if len(df.columns) > 50:\n            orientation = 'left'\n        else:\n            orientation = 'bottom'\n\n    hierarchy.dendrogram(z,\n                         orientation=orientation,\n                         labels=df.columns.tolist(),\n                         distance_sort='descending',\n                         link_color_func=lambda c: 'black',\n                         leaf_font_size=fontsize,\n                         ax=ax0\n                        )\n\n    # Remove extraneous default visual elements.\n    ax0.set_aspect('auto')\n    ax0.grid(b=False)\n    if orientation == 'bottom':\n        ax0.xaxis.tick_top()\n    ax0.xaxis.set_ticks_position('none')\n    ax0.yaxis.set_ticks_position('none')\n    ax0.spines['top'].set_visible(False)\n    ax0.spines['right'].set_visible(False)\n    ax0.spines['bottom'].set_visible(False)\n    ax0.spines['left'].set_visible(False)\n    ax0.patch.set_visible(False)\n\n    # Set up the categorical axis labels and draw.\n    if orientation == 'bottom':\n        ax0.set_xticklabels(ax0.xaxis.get_majorticklabels(), rotation=45, ha='left')\n    elif orientation == 'top':\n        ax0.set_xticklabels(ax0.xaxis.get_majorticklabels(), rotation=45, ha='right')\n    if orientation == 'bottom' or orientation == 'top':\n        ax0.tick_params(axis='y', labelsize=int(fontsize / 16 * 20))\n    else:\n        ax0.tick_params(axis='x', labelsize=int(fontsize / 16 * 20))\n\n    if inline:\n        plt.show()\n    else:\n        return ax0", "response": "A function that returns a matplotlib figure object that visualizes the results of a hierarchical clustering algorithm."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef geoplot(df,\n            filter=None, n=0, p=0, sort=None,\n            x=None, y=None, figsize=(25, 10), inline=False,\n            by=None, cmap='YlGn', **kwargs):\n    \"\"\"\n    Generates a geographical data nullity heatmap, which shows the distribution of missing data across geographic\n    regions. The precise output depends on the inputs provided. If no geographical context is provided, a quadtree\n    is computed and nullities are rendered as abstract geographic squares. If geographical context is provided in the\n    form of a column of geographies (region, borough. ZIP code, etc.) in the `DataFrame`, convex hulls are computed\n    for each of the point groups and the heatmap is generated within them.\n\n    :param df: The DataFrame whose completeness is being geoplotted.\n    :param filter: The filter to apply to the heatmap. Should be one of \"top\", \"bottom\", or None (default).\n    :param sort: The sort to apply to the heatmap. Should be one of \"ascending\", \"descending\", or None.\n    :param n: The cap on the number of columns to include in the filtered DataFrame.\n    :param p: The cap on the percentage fill of the columns in the filtered DataFrame.\n    :param figsize: The size of the figure to display. This is a `matplotlib` parameter which defaults to `(25, 10)`.\n    :param x: The variable in the dataset containing the x-coordinates of the dataset.\n    :param y: The variable in the dataset containing the y-coordinates of the dataset.\n    :param by: If specified, plot in convex hull mode, using the given column to cluster points in the same area. If\n    not specified, plot in quadtree mode.\n    :param cmap: The colormap to display the data with. Defaults to `YlGn`.\n    :param inline: Whether or not the figure is inline. If it's not then instead of getting plotted, this method will\n    return its figure.\n    :param kwargs: Additional keyword arguments are passed to the underlying `geoplot` function.\n    :return: If `inline` is False, the underlying `matplotlib.figure` object. Else, nothing.\n    \"\"\"\n    import geoplot as gplt\n    import geopandas as gpd\n    from shapely.geometry import Point\n\n    df = nullity_filter(df, filter=filter, n=n, p=p)\n    df = nullity_sort(df, sort=sort)\n\n    nullity = df.notnull().sum(axis='columns') / df.shape[1]\n    if x and y:\n        gdf = gpd.GeoDataFrame(nullity, columns=['nullity'],\n                               geometry=df.apply(lambda srs: Point(srs[x], srs[y]), axis='columns'))\n    else:\n        raise ValueError(\"The 'x' and 'y' parameters must be specified.\")\n\n    if by:\n        if df[by].isnull().any():\n            warnings.warn('The \"{0}\" column included null values. The offending records were dropped'.format(by))\n            df = df.dropna(subset=[by])\n            gdf = gdf.loc[df.index]\n\n        vc = df[by].value_counts()\n        if (vc < 3).any():\n            warnings.warn('Grouping by \"{0}\" included clusters with fewer than three points, which cannot be made '\n                          'polygonal. The offending records were dropped.'.format(by))\n            where = df[by].isin((df[by].value_counts() > 2).where(lambda b: b).dropna().index.values)\n            gdf = gdf.loc[where]\n        gdf[by] = df[by]\n\n    gplt.aggplot(gdf, figsize=figsize, hue='nullity', agg=np.average, cmap=cmap, by=by, edgecolor='None', **kwargs)\n    ax = plt.gca()\n\n    if inline:\n        plt.show()\n    else:\n        return ax", "response": "Returns a geographical data nullity heatmap."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef nullity_sort(df, sort=None):\n    if sort == 'ascending':\n        return df.iloc[np.argsort(df.count(axis='columns').values), :]\n    elif sort == 'descending':\n        return df.iloc[np.flipud(np.argsort(df.count(axis='columns').values)), :]\n    else:\n        return df", "response": "Sorts a DataFrame according to its nullity in either ascending or descending order."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef nullity_filter(df, filter=None, p=0, n=0):\n    if filter == 'top':\n        if p:\n            df = df.iloc[:, [c >= p for c in df.count(axis='rows').values / len(df)]]\n        if n:\n            df = df.iloc[:, np.sort(np.argsort(df.count(axis='rows').values)[-n:])]\n    elif filter == 'bottom':\n        if p:\n            df = df.iloc[:, [c <= p for c in df.count(axis='rows').values / len(df)]]\n        if n:\n            df = df.iloc[:, np.sort(np.argsort(df.count(axis='rows').values)[:n])]\n    return df", "response": "Filters a DataFrame according to its nullity."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_service_account_file(cls, filename, *args, **kwargs):\n        credentials = service_account.Credentials.from_service_account_file(\n            filename)\n        kwargs['credentials'] = credentials\n        return cls(*args, **kwargs)", "response": "Creates an instance of this class using the provided credentials\n                file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a fully - qualified session string.", "response": "def session_path(cls, project, session):\n        \"\"\"Return a fully-qualified session string.\"\"\"\n        return google.api_core.path_template.expand(\n            'projects/{project}/agent/sessions/{session}',\n            project=project,\n            session=session,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef session_entity_type_path(cls, project, session, entity_type):\n        return google.api_core.path_template.expand(\n            'projects/{project}/agent/sessions/{session}/entityTypes/{entity_type}',\n            project=project,\n            session=session,\n            entity_type=entity_type,\n        )", "response": "Return a fully - qualified session_entity_type string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_session_entity_type(\n            self,\n            parent,\n            session_entity_type,\n            retry=google.api_core.gapic_v1.method.DEFAULT,\n            timeout=google.api_core.gapic_v1.method.DEFAULT,\n            metadata=None):\n        \"\"\"\n        Creates a session entity type.\n\n        Example:\n            >>> import dialogflow_v2\n            >>>\n            >>> client = dialogflow_v2.SessionEntityTypesClient()\n            >>>\n            >>> parent = client.session_path('[PROJECT]', '[SESSION]')\n            >>>\n            >>> # TODO: Initialize ``session_entity_type``:\n            >>> session_entity_type = {}\n            >>>\n            >>> response = client.create_session_entity_type(parent, session_entity_type)\n\n        Args:\n            parent (str): Required. The session to create a session entity type for.\n                Format: ``projects/<Project ID>/agent/sessions/<Session ID>``.\n            session_entity_type (Union[dict, ~google.cloud.dialogflow_v2.types.SessionEntityType]): Required. The session entity type to create.\n                If a dict is provided, it must be of the same form as the protobuf\n                message :class:`~google.cloud.dialogflow_v2.types.SessionEntityType`\n            retry (Optional[google.api_core.retry.Retry]):  A retry object used\n                to retry requests. If ``None`` is specified, requests will not\n                be retried.\n            timeout (Optional[float]): The amount of time, in seconds, to wait\n                for the request to complete. Note that if ``retry`` is\n                specified, the timeout applies to each individual attempt.\n            metadata (Optional[Sequence[Tuple[str, str]]]): Additional metadata\n                that is provided to the method.\n\n        Returns:\n            A :class:`~google.cloud.dialogflow_v2.types.SessionEntityType` instance.\n\n        Raises:\n            google.api_core.exceptions.GoogleAPICallError: If the request\n                    failed for any reason.\n            google.api_core.exceptions.RetryError: If the request failed due\n                    to a retryable error and retry attempts failed.\n            ValueError: If the parameters are invalid.\n        \"\"\"\n        # Wrap the transport method to add retry and timeout logic.\n        if 'create_session_entity_type' not in self._inner_api_calls:\n            self._inner_api_calls[\n                'create_session_entity_type'] = google.api_core.gapic_v1.method.wrap_method(\n                    self.transport.create_session_entity_type,\n                    default_retry=self._method_configs[\n                        'CreateSessionEntityType'].retry,\n                    default_timeout=self._method_configs[\n                        'CreateSessionEntityType'].timeout,\n                    client_info=self._client_info,\n                )\n\n        request = session_entity_type_pb2.CreateSessionEntityTypeRequest(\n            parent=parent,\n            session_entity_type=session_entity_type,\n        )\n        return self._inner_api_calls['create_session_entity_type'](\n            request, retry=retry, timeout=timeout, metadata=metadata)", "response": "Creates a session entity type for the specified session."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update_session_entity_type(\n            self,\n            session_entity_type,\n            update_mask=None,\n            retry=google.api_core.gapic_v1.method.DEFAULT,\n            timeout=google.api_core.gapic_v1.method.DEFAULT,\n            metadata=None):\n        \"\"\"\n        Updates the specified session entity type.\n\n        Example:\n            >>> import dialogflow_v2\n            >>>\n            >>> client = dialogflow_v2.SessionEntityTypesClient()\n            >>>\n            >>> # TODO: Initialize ``session_entity_type``:\n            >>> session_entity_type = {}\n            >>>\n            >>> response = client.update_session_entity_type(session_entity_type)\n\n        Args:\n            session_entity_type (Union[dict, ~google.cloud.dialogflow_v2.types.SessionEntityType]): Required. The entity type to update. Format:\n                ``projects/<Project ID>/agent/sessions/<Session ID>/entityTypes/<Entity Type\n                Display Name>``.\n                If a dict is provided, it must be of the same form as the protobuf\n                message :class:`~google.cloud.dialogflow_v2.types.SessionEntityType`\n            update_mask (Union[dict, ~google.cloud.dialogflow_v2.types.FieldMask]): Optional. The mask to control which fields get updated.\n                If a dict is provided, it must be of the same form as the protobuf\n                message :class:`~google.cloud.dialogflow_v2.types.FieldMask`\n            retry (Optional[google.api_core.retry.Retry]):  A retry object used\n                to retry requests. If ``None`` is specified, requests will not\n                be retried.\n            timeout (Optional[float]): The amount of time, in seconds, to wait\n                for the request to complete. Note that if ``retry`` is\n                specified, the timeout applies to each individual attempt.\n            metadata (Optional[Sequence[Tuple[str, str]]]): Additional metadata\n                that is provided to the method.\n\n        Returns:\n            A :class:`~google.cloud.dialogflow_v2.types.SessionEntityType` instance.\n\n        Raises:\n            google.api_core.exceptions.GoogleAPICallError: If the request\n                    failed for any reason.\n            google.api_core.exceptions.RetryError: If the request failed due\n                    to a retryable error and retry attempts failed.\n            ValueError: If the parameters are invalid.\n        \"\"\"\n        # Wrap the transport method to add retry and timeout logic.\n        if 'update_session_entity_type' not in self._inner_api_calls:\n            self._inner_api_calls[\n                'update_session_entity_type'] = google.api_core.gapic_v1.method.wrap_method(\n                    self.transport.update_session_entity_type,\n                    default_retry=self._method_configs[\n                        'UpdateSessionEntityType'].retry,\n                    default_timeout=self._method_configs[\n                        'UpdateSessionEntityType'].timeout,\n                    client_info=self._client_info,\n                )\n\n        request = session_entity_type_pb2.UpdateSessionEntityTypeRequest(\n            session_entity_type=session_entity_type,\n            update_mask=update_mask,\n        )\n        return self._inner_api_calls['update_session_entity_type'](\n            request, retry=retry, timeout=timeout, metadata=metadata)", "response": "Updates the specified session entity type."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef delete_session_entity_type(\n            self,\n            name,\n            retry=google.api_core.gapic_v1.method.DEFAULT,\n            timeout=google.api_core.gapic_v1.method.DEFAULT,\n            metadata=None):\n        \"\"\"\n        Deletes the specified session entity type.\n\n        Example:\n            >>> import dialogflow_v2\n            >>>\n            >>> client = dialogflow_v2.SessionEntityTypesClient()\n            >>>\n            >>> name = client.session_entity_type_path('[PROJECT]', '[SESSION]', '[ENTITY_TYPE]')\n            >>>\n            >>> client.delete_session_entity_type(name)\n\n        Args:\n            name (str): Required. The name of the entity type to delete. Format:\n                ``projects/<Project ID>/agent/sessions/<Session ID>/entityTypes/<Entity Type\n                Display Name>``.\n            retry (Optional[google.api_core.retry.Retry]):  A retry object used\n                to retry requests. If ``None`` is specified, requests will not\n                be retried.\n            timeout (Optional[float]): The amount of time, in seconds, to wait\n                for the request to complete. Note that if ``retry`` is\n                specified, the timeout applies to each individual attempt.\n            metadata (Optional[Sequence[Tuple[str, str]]]): Additional metadata\n                that is provided to the method.\n\n        Raises:\n            google.api_core.exceptions.GoogleAPICallError: If the request\n                    failed for any reason.\n            google.api_core.exceptions.RetryError: If the request failed due\n                    to a retryable error and retry attempts failed.\n            ValueError: If the parameters are invalid.\n        \"\"\"\n        # Wrap the transport method to add retry and timeout logic.\n        if 'delete_session_entity_type' not in self._inner_api_calls:\n            self._inner_api_calls[\n                'delete_session_entity_type'] = google.api_core.gapic_v1.method.wrap_method(\n                    self.transport.delete_session_entity_type,\n                    default_retry=self._method_configs[\n                        'DeleteSessionEntityType'].retry,\n                    default_timeout=self._method_configs[\n                        'DeleteSessionEntityType'].timeout,\n                    client_info=self._client_info,\n                )\n\n        request = session_entity_type_pb2.DeleteSessionEntityTypeRequest(\n            name=name, )\n        self._inner_api_calls['delete_session_entity_type'](\n            request, retry=retry, timeout=timeout, metadata=metadata)", "response": "Delete the specified session entity type."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef list_knowledge_bases(project_id):\n    import dialogflow_v2beta1 as dialogflow\n    client = dialogflow.KnowledgeBasesClient()\n    project_path = client.project_path(project_id)\n\n    print('Knowledge Bases for: {}'.format(project_id))\n    for knowledge_base in client.list_knowledge_bases(project_path):\n        print(' - Display Name: {}'.format(knowledge_base.display_name))\n        print(' - Knowledge ID: {}\\n'.format(knowledge_base.name))", "response": "Lists the Knowledge bases belonging to a project."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a Knowledge base.", "response": "def create_knowledge_base(project_id, display_name):\n    \"\"\"Creates a Knowledge base.\n\n    Args:\n        project_id: The GCP project linked with the agent.\n        display_name: The display name of the Knowledge base.\"\"\"\n    import dialogflow_v2beta1 as dialogflow\n    client = dialogflow.KnowledgeBasesClient()\n    project_path = client.project_path(project_id)\n\n    knowledge_base = dialogflow.types.KnowledgeBase(\n        display_name=display_name)\n\n    response = client.create_knowledge_base(project_path, knowledge_base)\n\n    print('Knowledge Base created:\\n')\n    print('Display Name: {}\\n'.format(response.display_name))\n    print('Knowledge ID: {}\\n'.format(response.name))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting a specific Knowledge base.", "response": "def get_knowledge_base(project_id, knowledge_base_id):\n    \"\"\"Gets a specific Knowledge base.\n\n    Args:\n        project_id: The GCP project linked with the agent.\n        knowledge_base_id: Id of the Knowledge base.\"\"\"\n    import dialogflow_v2beta1 as dialogflow\n    client = dialogflow.KnowledgeBasesClient()\n    knowledge_base_path = client.knowledge_base_path(\n        project_id, knowledge_base_id)\n\n    response = client.get_knowledge_base(knowledge_base_path)\n\n    print('Got Knowledge Base:')\n    print(' - Display Name: {}'.format(response.display_name))\n    print(' - Knowledge ID: {}'.format(response.name))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndelete a specific Knowledge base.", "response": "def delete_knowledge_base(project_id, knowledge_base_id):\n    \"\"\"Deletes a specific Knowledge base.\n\n    Args:\n        project_id: The GCP project linked with the agent.\n        knowledge_base_id: Id of the Knowledge base.\"\"\"\n    import dialogflow_v2beta1 as dialogflow\n    client = dialogflow.KnowledgeBasesClient()\n    knowledge_base_path = client.knowledge_base_path(\n        project_id, knowledge_base_id)\n\n    response = client.delete_knowledge_base(knowledge_base_path)\n\n    print('Knowledge Base deleted.'.format(response))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the result of detect intent with texts as inputs and includes the response in an audio format.", "response": "def detect_intent_with_texttospeech_response(project_id, session_id, texts,\n                                             language_code):\n    \"\"\"Returns the result of detect intent with texts as inputs and includes\n    the response in an audio format.\n\n    Using the same `session_id` between requests allows continuation\n    of the conversaion.\"\"\"\n    import dialogflow_v2beta1 as dialogflow\n    session_client = dialogflow.SessionsClient()\n\n    session_path = session_client.session_path(project_id, session_id)\n    print('Session path: {}\\n'.format(session_path))\n\n    for text in texts:\n        text_input = dialogflow.types.TextInput(\n            text=text, language_code=language_code)\n\n        query_input = dialogflow.types.QueryInput(text=text_input)\n\n        # Set the query parameters with sentiment analysis\n        output_audio_config = dialogflow.types.OutputAudioConfig(\n            audio_encoding=dialogflow.enums.OutputAudioEncoding\n            .OUTPUT_AUDIO_ENCODING_LINEAR_16)\n\n        response = session_client.detect_intent(\n            session=session_path, query_input=query_input,\n            output_audio_config=output_audio_config)\n\n        print('=' * 20)\n        print('Query text: {}'.format(response.query_result.query_text))\n        print('Detected intent: {} (confidence: {})\\n'.format(\n            response.query_result.intent.display_name,\n            response.query_result.intent_detection_confidence))\n        print('Fulfillment text: {}\\n'.format(\n            response.query_result.fulfillment_text))\n        # The response's audio_content is binary.\n        with open('output.wav', 'wb') as out:\n            out.write(response.output_audio)\n            print('Audio content written to file \"output.wav\"')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef detect_intent_with_model_selection(project_id, session_id, audio_file_path,\n                                       language_code):\n    \"\"\"Returns the result of detect intent with model selection on an audio file\n    as input\n\n    Using the same `session_id` between requests allows continuation\n    of the conversaion.\"\"\"\n    import dialogflow_v2beta1 as dialogflow\n    session_client = dialogflow.SessionsClient()\n\n    # Note: hard coding audio_encoding and sample_rate_hertz for simplicity.\n    audio_encoding = dialogflow.enums.AudioEncoding.AUDIO_ENCODING_LINEAR_16\n    sample_rate_hertz = 16000\n\n    session_path = session_client.session_path(project_id, session_id)\n    print('Session path: {}\\n'.format(session_path))\n\n    with open(audio_file_path, 'rb') as audio_file:\n        input_audio = audio_file.read()\n\n    # Which Speech model to select for the given request.\n    # Possible models: video, phone_call, command_and_search, default\n    model = 'phone_call'\n\n    audio_config = dialogflow.types.InputAudioConfig(\n        audio_encoding=audio_encoding, language_code=language_code,\n        sample_rate_hertz=sample_rate_hertz,\n        model=model)\n    query_input = dialogflow.types.QueryInput(audio_config=audio_config)\n\n    response = session_client.detect_intent(\n        session=session_path, query_input=query_input,\n        input_audio=input_audio)\n\n    print('=' * 20)\n    print('Query text: {}'.format(response.query_result.query_text))\n    print('Detected intent: {} (confidence: {})\\n'.format(\n        response.query_result.intent.display_name,\n        response.query_result.intent_detection_confidence))\n    print('Fulfillment text: {}\\n'.format(\n        response.query_result.fulfillment_text))", "response": "Returns the result of detect intent with model selection on an audio file\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a fully - qualified knowledge_base string.", "response": "def knowledge_base_path(cls, project, knowledge_base):\n        \"\"\"Return a fully-qualified knowledge_base string.\"\"\"\n        return google.api_core.path_template.expand(\n            'projects/{project}/knowledgeBases/{knowledge_base}',\n            project=project,\n            knowledge_base=knowledge_base,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nretrieves a specific knowledge base from the specified resource.", "response": "def get_knowledge_base(self,\n                           name,\n                           retry=google.api_core.gapic_v1.method.DEFAULT,\n                           timeout=google.api_core.gapic_v1.method.DEFAULT,\n                           metadata=None):\n        \"\"\"\n        Retrieves the specified knowledge base.\n\n        Example:\n            >>> import dialogflow_v2beta1\n            >>>\n            >>> client = dialogflow_v2beta1.KnowledgeBasesClient()\n            >>>\n            >>> name = client.knowledge_base_path('[PROJECT]', '[KNOWLEDGE_BASE]')\n            >>>\n            >>> response = client.get_knowledge_base(name)\n\n        Args:\n            name (str): Required. The name of the knowledge base to retrieve.\n                Format ``projects/<Project ID>/knowledgeBases/<Knowledge Base ID>``.\n            retry (Optional[google.api_core.retry.Retry]):  A retry object used\n                to retry requests. If ``None`` is specified, requests will not\n                be retried.\n            timeout (Optional[float]): The amount of time, in seconds, to wait\n                for the request to complete. Note that if ``retry`` is\n                specified, the timeout applies to each individual attempt.\n            metadata (Optional[Sequence[Tuple[str, str]]]): Additional metadata\n                that is provided to the method.\n\n        Returns:\n            A :class:`~google.cloud.dialogflow_v2beta1.types.KnowledgeBase` instance.\n\n        Raises:\n            google.api_core.exceptions.GoogleAPICallError: If the request\n                    failed for any reason.\n            google.api_core.exceptions.RetryError: If the request failed due\n                    to a retryable error and retry attempts failed.\n            ValueError: If the parameters are invalid.\n        \"\"\"\n        # Wrap the transport method to add retry and timeout logic.\n        if 'get_knowledge_base' not in self._inner_api_calls:\n            self._inner_api_calls[\n                'get_knowledge_base'] = google.api_core.gapic_v1.method.wrap_method(\n                    self.transport.get_knowledge_base,\n                    default_retry=self._method_configs[\n                        'GetKnowledgeBase'].retry,\n                    default_timeout=self._method_configs['GetKnowledgeBase']\n                    .timeout,\n                    client_info=self._client_info,\n                )\n\n        request = knowledge_base_pb2.GetKnowledgeBaseRequest(name=name, )\n        return self._inner_api_calls['get_knowledge_base'](\n            request, retry=retry, timeout=timeout, metadata=metadata)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new knowledge base for the specified agent.", "response": "def create_knowledge_base(self,\n                              parent,\n                              knowledge_base,\n                              retry=google.api_core.gapic_v1.method.DEFAULT,\n                              timeout=google.api_core.gapic_v1.method.DEFAULT,\n                              metadata=None):\n        \"\"\"\n        Creates a knowledge base.\n\n        Example:\n            >>> import dialogflow_v2beta1\n            >>>\n            >>> client = dialogflow_v2beta1.KnowledgeBasesClient()\n            >>>\n            >>> parent = client.project_path('[PROJECT]')\n            >>>\n            >>> # TODO: Initialize ``knowledge_base``:\n            >>> knowledge_base = {}\n            >>>\n            >>> response = client.create_knowledge_base(parent, knowledge_base)\n\n        Args:\n            parent (str): Required. The agent to create a knowledge base for.\n                Format: ``projects/<Project ID>/agent``.\n            knowledge_base (Union[dict, ~google.cloud.dialogflow_v2beta1.types.KnowledgeBase]): Required. The knowledge base to create.\n                If a dict is provided, it must be of the same form as the protobuf\n                message :class:`~google.cloud.dialogflow_v2beta1.types.KnowledgeBase`\n            retry (Optional[google.api_core.retry.Retry]):  A retry object used\n                to retry requests. If ``None`` is specified, requests will not\n                be retried.\n            timeout (Optional[float]): The amount of time, in seconds, to wait\n                for the request to complete. Note that if ``retry`` is\n                specified, the timeout applies to each individual attempt.\n            metadata (Optional[Sequence[Tuple[str, str]]]): Additional metadata\n                that is provided to the method.\n\n        Returns:\n            A :class:`~google.cloud.dialogflow_v2beta1.types.KnowledgeBase` instance.\n\n        Raises:\n            google.api_core.exceptions.GoogleAPICallError: If the request\n                    failed for any reason.\n            google.api_core.exceptions.RetryError: If the request failed due\n                    to a retryable error and retry attempts failed.\n            ValueError: If the parameters are invalid.\n        \"\"\"\n        # Wrap the transport method to add retry and timeout logic.\n        if 'create_knowledge_base' not in self._inner_api_calls:\n            self._inner_api_calls[\n                'create_knowledge_base'] = google.api_core.gapic_v1.method.wrap_method(\n                    self.transport.create_knowledge_base,\n                    default_retry=self._method_configs[\n                        'CreateKnowledgeBase'].retry,\n                    default_timeout=self._method_configs['CreateKnowledgeBase']\n                    .timeout,\n                    client_info=self._client_info,\n                )\n\n        request = knowledge_base_pb2.CreateKnowledgeBaseRequest(\n            parent=parent,\n            knowledge_base=knowledge_base,\n        )\n        return self._inner_api_calls['create_knowledge_base'](\n            request, retry=retry, timeout=timeout, metadata=metadata)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef environment_session_path(cls, project, environment, user, session):\n        return google.api_core.path_template.expand(\n            'projects/{project}/agent/environments/{environment}/users/{user}/sessions/{session}',\n            project=project,\n            environment=environment,\n            user=user,\n            session=session,\n        )", "response": "Return a fully - qualified environment_session string."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef environment_session_entity_type_path(cls, project, environment, user,\n                                             session, entity_type):\n        \"\"\"Return a fully-qualified environment_session_entity_type string.\"\"\"\n        return google.api_core.path_template.expand(\n            'projects/{project}/agent/environments/{environment}/users/{user}/sessions/{session}/entityTypes/{entity_type}',\n            project=project,\n            environment=environment,\n            user=user,\n            session=session,\n            entity_type=entity_type,\n        )", "response": "Return a fully - qualified environment_session_entity_type string."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a fully - qualified document string.", "response": "def document_path(cls, project, knowledge_base, document):\n        \"\"\"Return a fully-qualified document string.\"\"\"\n        return google.api_core.path_template.expand(\n            'projects/{project}/knowledgeBases/{knowledge_base}/documents/{document}',\n            project=project,\n            knowledge_base=knowledge_base,\n            document=document,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef list_documents(self,\n                       parent,\n                       page_size=None,\n                       retry=google.api_core.gapic_v1.method.DEFAULT,\n                       timeout=google.api_core.gapic_v1.method.DEFAULT,\n                       metadata=None):\n        \"\"\"\n        Returns the list of all documents of the knowledge base.\n\n        Example:\n            >>> import dialogflow_v2beta1\n            >>>\n            >>> client = dialogflow_v2beta1.DocumentsClient()\n            >>>\n            >>> parent = client.knowledge_base_path('[PROJECT]', '[KNOWLEDGE_BASE]')\n            >>>\n            >>> # Iterate over all results\n            >>> for element in client.list_documents(parent):\n            ...     # process element\n            ...     pass\n            >>>\n            >>>\n            >>> # Alternatively:\n            >>>\n            >>> # Iterate over results one page at a time\n            >>> for page in client.list_documents(parent, options=CallOptions(page_token=INITIAL_PAGE)):\n            ...     for element in page:\n            ...         # process element\n            ...         pass\n\n        Args:\n            parent (str): Required. The knowledge base to list all documents for.\n                Format: ``projects/<Project ID>/knowledgeBases/<Knowledge Base ID>``.\n            page_size (int): The maximum number of resources contained in the\n                underlying API response. If page streaming is performed per-\n                resource, this parameter does not affect the return value. If page\n                streaming is performed per-page, this determines the maximum number\n                of resources in a page.\n            retry (Optional[google.api_core.retry.Retry]):  A retry object used\n                to retry requests. If ``None`` is specified, requests will not\n                be retried.\n            timeout (Optional[float]): The amount of time, in seconds, to wait\n                for the request to complete. Note that if ``retry`` is\n                specified, the timeout applies to each individual attempt.\n            metadata (Optional[Sequence[Tuple[str, str]]]): Additional metadata\n                that is provided to the method.\n\n        Returns:\n            A :class:`~google.gax.PageIterator` instance. By default, this\n            is an iterable of :class:`~google.cloud.dialogflow_v2beta1.types.Document` instances.\n            This object can also be configured to iterate over the pages\n            of the response through the `options` parameter.\n\n        Raises:\n            google.api_core.exceptions.GoogleAPICallError: If the request\n                    failed for any reason.\n            google.api_core.exceptions.RetryError: If the request failed due\n                    to a retryable error and retry attempts failed.\n            ValueError: If the parameters are invalid.\n        \"\"\"\n        # Wrap the transport method to add retry and timeout logic.\n        if 'list_documents' not in self._inner_api_calls:\n            self._inner_api_calls[\n                'list_documents'] = google.api_core.gapic_v1.method.wrap_method(\n                    self.transport.list_documents,\n                    default_retry=self._method_configs['ListDocuments'].retry,\n                    default_timeout=self._method_configs['ListDocuments']\n                    .timeout,\n                    client_info=self._client_info,\n                )\n\n        request = document_pb2.ListDocumentsRequest(\n            parent=parent,\n            page_size=page_size,\n        )\n        iterator = google.api_core.page_iterator.GRPCIterator(\n            client=None,\n            method=functools.partial(\n                self._inner_api_calls['list_documents'],\n                retry=retry,\n                timeout=timeout,\n                metadata=metadata),\n            request=request,\n            items_field='documents',\n            request_token_field='page_token',\n            response_token_field='next_page_token',\n        )\n        return iterator", "response": "Returns the list of all documents of the specified knowledge base."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_document(self,\n                     name,\n                     retry=google.api_core.gapic_v1.method.DEFAULT,\n                     timeout=google.api_core.gapic_v1.method.DEFAULT,\n                     metadata=None):\n        \"\"\"\n        Retrieves the specified document.\n\n        Example:\n            >>> import dialogflow_v2beta1\n            >>>\n            >>> client = dialogflow_v2beta1.DocumentsClient()\n            >>>\n            >>> name = client.document_path('[PROJECT]', '[KNOWLEDGE_BASE]', '[DOCUMENT]')\n            >>>\n            >>> response = client.get_document(name)\n\n        Args:\n            name (str): Required. The name of the document to retrieve.\n                Format ``projects/<Project ID>/knowledgeBases/<Knowledge Base\n                ID>/documents/<Document ID>``.\n            retry (Optional[google.api_core.retry.Retry]):  A retry object used\n                to retry requests. If ``None`` is specified, requests will not\n                be retried.\n            timeout (Optional[float]): The amount of time, in seconds, to wait\n                for the request to complete. Note that if ``retry`` is\n                specified, the timeout applies to each individual attempt.\n            metadata (Optional[Sequence[Tuple[str, str]]]): Additional metadata\n                that is provided to the method.\n\n        Returns:\n            A :class:`~google.cloud.dialogflow_v2beta1.types.Document` instance.\n\n        Raises:\n            google.api_core.exceptions.GoogleAPICallError: If the request\n                    failed for any reason.\n            google.api_core.exceptions.RetryError: If the request failed due\n                    to a retryable error and retry attempts failed.\n            ValueError: If the parameters are invalid.\n        \"\"\"\n        # Wrap the transport method to add retry and timeout logic.\n        if 'get_document' not in self._inner_api_calls:\n            self._inner_api_calls[\n                'get_document'] = google.api_core.gapic_v1.method.wrap_method(\n                    self.transport.get_document,\n                    default_retry=self._method_configs['GetDocument'].retry,\n                    default_timeout=self._method_configs['GetDocument']\n                    .timeout,\n                    client_info=self._client_info,\n                )\n\n        request = document_pb2.GetDocumentRequest(name=name, )\n        return self._inner_api_calls['get_document'](\n            request, retry=retry, timeout=timeout, metadata=metadata)", "response": "Retrieves a specific document from the specified base."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_document(self,\n                        parent,\n                        document,\n                        retry=google.api_core.gapic_v1.method.DEFAULT,\n                        timeout=google.api_core.gapic_v1.method.DEFAULT,\n                        metadata=None):\n        \"\"\"\n        Creates a new document.\n\n        Operation <response: ``Document``,\n        metadata: [KnowledgeOperationMetadata][google.cloud.dialogflow.v2beta1.KnowledgeOperationMetadata]>\n\n        Example:\n            >>> import dialogflow_v2beta1\n            >>>\n            >>> client = dialogflow_v2beta1.DocumentsClient()\n            >>>\n            >>> parent = client.knowledge_base_path('[PROJECT]', '[KNOWLEDGE_BASE]')\n            >>>\n            >>> # TODO: Initialize ``document``:\n            >>> document = {}\n            >>>\n            >>> response = client.create_document(parent, document)\n            >>>\n            >>> def callback(operation_future):\n            ...     # Handle result.\n            ...     result = operation_future.result()\n            >>>\n            >>> response.add_done_callback(callback)\n            >>>\n            >>> # Handle metadata.\n            >>> metadata = response.metadata()\n\n        Args:\n            parent (str): Required. The knoweldge base to create a document for.\n                Format: ``projects/<Project ID>/knowledgeBases/<Knowledge Base ID>``.\n            document (Union[dict, ~google.cloud.dialogflow_v2beta1.types.Document]): Required. The document to create.\n                If a dict is provided, it must be of the same form as the protobuf\n                message :class:`~google.cloud.dialogflow_v2beta1.types.Document`\n            retry (Optional[google.api_core.retry.Retry]):  A retry object used\n                to retry requests. If ``None`` is specified, requests will not\n                be retried.\n            timeout (Optional[float]): The amount of time, in seconds, to wait\n                for the request to complete. Note that if ``retry`` is\n                specified, the timeout applies to each individual attempt.\n            metadata (Optional[Sequence[Tuple[str, str]]]): Additional metadata\n                that is provided to the method.\n\n        Returns:\n            A :class:`~google.cloud.dialogflow_v2beta1.types._OperationFuture` instance.\n\n        Raises:\n            google.api_core.exceptions.GoogleAPICallError: If the request\n                    failed for any reason.\n            google.api_core.exceptions.RetryError: If the request failed due\n                    to a retryable error and retry attempts failed.\n            ValueError: If the parameters are invalid.\n        \"\"\"\n        # Wrap the transport method to add retry and timeout logic.\n        if 'create_document' not in self._inner_api_calls:\n            self._inner_api_calls[\n                'create_document'] = google.api_core.gapic_v1.method.wrap_method(\n                    self.transport.create_document,\n                    default_retry=self._method_configs['CreateDocument'].retry,\n                    default_timeout=self._method_configs['CreateDocument']\n                    .timeout,\n                    client_info=self._client_info,\n                )\n\n        request = document_pb2.CreateDocumentRequest(\n            parent=parent,\n            document=document,\n        )\n        operation = self._inner_api_calls['create_document'](\n            request, retry=retry, timeout=timeout, metadata=metadata)\n        return google.api_core.operation.from_gapic(\n            operation,\n            self.transport._operations_client,\n            document_pb2.Document,\n            metadata_type=document_pb2.KnowledgeOperationMetadata,\n        )", "response": "Creates a new document for the specified parent and document."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete_document(self,\n                        name,\n                        retry=google.api_core.gapic_v1.method.DEFAULT,\n                        timeout=google.api_core.gapic_v1.method.DEFAULT,\n                        metadata=None):\n        \"\"\"\n        Deletes the specified document.\n\n        Operation <response: ``google.protobuf.Empty``,\n        metadata: [KnowledgeOperationMetadata][google.cloud.dialogflow.v2beta1.KnowledgeOperationMetadata]>\n\n        Example:\n            >>> import dialogflow_v2beta1\n            >>>\n            >>> client = dialogflow_v2beta1.DocumentsClient()\n            >>>\n            >>> name = client.document_path('[PROJECT]', '[KNOWLEDGE_BASE]', '[DOCUMENT]')\n            >>>\n            >>> response = client.delete_document(name)\n            >>>\n            >>> def callback(operation_future):\n            ...     # Handle result.\n            ...     result = operation_future.result()\n            >>>\n            >>> response.add_done_callback(callback)\n            >>>\n            >>> # Handle metadata.\n            >>> metadata = response.metadata()\n\n        Args:\n            name (str): The name of the document to delete.\n                Format: ``projects/<Project ID>/knowledgeBases/<Knowledge Base\n                ID>/documents/<Document ID>``.\n            retry (Optional[google.api_core.retry.Retry]):  A retry object used\n                to retry requests. If ``None`` is specified, requests will not\n                be retried.\n            timeout (Optional[float]): The amount of time, in seconds, to wait\n                for the request to complete. Note that if ``retry`` is\n                specified, the timeout applies to each individual attempt.\n            metadata (Optional[Sequence[Tuple[str, str]]]): Additional metadata\n                that is provided to the method.\n\n        Returns:\n            A :class:`~google.cloud.dialogflow_v2beta1.types._OperationFuture` instance.\n\n        Raises:\n            google.api_core.exceptions.GoogleAPICallError: If the request\n                    failed for any reason.\n            google.api_core.exceptions.RetryError: If the request failed due\n                    to a retryable error and retry attempts failed.\n            ValueError: If the parameters are invalid.\n        \"\"\"\n        # Wrap the transport method to add retry and timeout logic.\n        if 'delete_document' not in self._inner_api_calls:\n            self._inner_api_calls[\n                'delete_document'] = google.api_core.gapic_v1.method.wrap_method(\n                    self.transport.delete_document,\n                    default_retry=self._method_configs['DeleteDocument'].retry,\n                    default_timeout=self._method_configs['DeleteDocument']\n                    .timeout,\n                    client_info=self._client_info,\n                )\n\n        request = document_pb2.DeleteDocumentRequest(name=name, )\n        operation = self._inner_api_calls['delete_document'](\n            request, retry=retry, timeout=timeout, metadata=metadata)\n        return google.api_core.operation.from_gapic(\n            operation,\n            self.transport._operations_client,\n            empty_pb2.Empty,\n            metadata_type=document_pb2.KnowledgeOperationMetadata,\n        )", "response": "Deletes the specified document."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a fully - qualified context string.", "response": "def context_path(cls, project, session, context):\n        \"\"\"Return a fully-qualified context string.\"\"\"\n        return google.api_core.path_template.expand(\n            'projects/{project}/agent/sessions/{session}/contexts/{context}',\n            project=project,\n            session=session,\n            context=context,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_context(self,\n                    name,\n                    retry=google.api_core.gapic_v1.method.DEFAULT,\n                    timeout=google.api_core.gapic_v1.method.DEFAULT,\n                    metadata=None):\n        \"\"\"\n        Retrieves the specified context.\n\n        Example:\n            >>> import dialogflow_v2\n            >>>\n            >>> client = dialogflow_v2.ContextsClient()\n            >>>\n            >>> name = client.context_path('[PROJECT]', '[SESSION]', '[CONTEXT]')\n            >>>\n            >>> response = client.get_context(name)\n\n        Args:\n            name (str): Required. The name of the context. Format:\n                ``projects/<Project ID>/agent/sessions/<Session ID>/contexts/<Context ID>``.\n            retry (Optional[google.api_core.retry.Retry]):  A retry object used\n                to retry requests. If ``None`` is specified, requests will not\n                be retried.\n            timeout (Optional[float]): The amount of time, in seconds, to wait\n                for the request to complete. Note that if ``retry`` is\n                specified, the timeout applies to each individual attempt.\n            metadata (Optional[Sequence[Tuple[str, str]]]): Additional metadata\n                that is provided to the method.\n\n        Returns:\n            A :class:`~google.cloud.dialogflow_v2.types.Context` instance.\n\n        Raises:\n            google.api_core.exceptions.GoogleAPICallError: If the request\n                    failed for any reason.\n            google.api_core.exceptions.RetryError: If the request failed due\n                    to a retryable error and retry attempts failed.\n            ValueError: If the parameters are invalid.\n        \"\"\"\n        # Wrap the transport method to add retry and timeout logic.\n        if 'get_context' not in self._inner_api_calls:\n            self._inner_api_calls[\n                'get_context'] = google.api_core.gapic_v1.method.wrap_method(\n                    self.transport.get_context,\n                    default_retry=self._method_configs['GetContext'].retry,\n                    default_timeout=self._method_configs['GetContext'].timeout,\n                    client_info=self._client_info,\n                )\n\n        request = context_pb2.GetContextRequest(name=name, )\n        return self._inner_api_calls['get_context'](\n            request, retry=retry, timeout=timeout, metadata=metadata)", "response": "Retrieves the specified context."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_context(self,\n                       parent,\n                       context,\n                       retry=google.api_core.gapic_v1.method.DEFAULT,\n                       timeout=google.api_core.gapic_v1.method.DEFAULT,\n                       metadata=None):\n        \"\"\"\n        Creates a context.\n\n        Example:\n            >>> import dialogflow_v2\n            >>>\n            >>> client = dialogflow_v2.ContextsClient()\n            >>>\n            >>> parent = client.session_path('[PROJECT]', '[SESSION]')\n            >>>\n            >>> # TODO: Initialize ``context``:\n            >>> context = {}\n            >>>\n            >>> response = client.create_context(parent, context)\n\n        Args:\n            parent (str): Required. The session to create a context for.\n                Format: ``projects/<Project ID>/agent/sessions/<Session ID>``.\n            context (Union[dict, ~google.cloud.dialogflow_v2.types.Context]): Required. The context to create.\n                If a dict is provided, it must be of the same form as the protobuf\n                message :class:`~google.cloud.dialogflow_v2.types.Context`\n            retry (Optional[google.api_core.retry.Retry]):  A retry object used\n                to retry requests. If ``None`` is specified, requests will not\n                be retried.\n            timeout (Optional[float]): The amount of time, in seconds, to wait\n                for the request to complete. Note that if ``retry`` is\n                specified, the timeout applies to each individual attempt.\n            metadata (Optional[Sequence[Tuple[str, str]]]): Additional metadata\n                that is provided to the method.\n\n        Returns:\n            A :class:`~google.cloud.dialogflow_v2.types.Context` instance.\n\n        Raises:\n            google.api_core.exceptions.GoogleAPICallError: If the request\n                    failed for any reason.\n            google.api_core.exceptions.RetryError: If the request failed due\n                    to a retryable error and retry attempts failed.\n            ValueError: If the parameters are invalid.\n        \"\"\"\n        # Wrap the transport method to add retry and timeout logic.\n        if 'create_context' not in self._inner_api_calls:\n            self._inner_api_calls[\n                'create_context'] = google.api_core.gapic_v1.method.wrap_method(\n                    self.transport.create_context,\n                    default_retry=self._method_configs['CreateContext'].retry,\n                    default_timeout=self._method_configs['CreateContext']\n                    .timeout,\n                    client_info=self._client_info,\n                )\n\n        request = context_pb2.CreateContextRequest(\n            parent=parent,\n            context=context,\n        )\n        return self._inner_api_calls['create_context'](\n            request, retry=retry, timeout=timeout, metadata=metadata)", "response": "Creates a new context for the specified session."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nupdating the specified context.", "response": "def update_context(self,\n                       context,\n                       update_mask=None,\n                       retry=google.api_core.gapic_v1.method.DEFAULT,\n                       timeout=google.api_core.gapic_v1.method.DEFAULT,\n                       metadata=None):\n        \"\"\"\n        Updates the specified context.\n\n        Example:\n            >>> import dialogflow_v2\n            >>>\n            >>> client = dialogflow_v2.ContextsClient()\n            >>>\n            >>> # TODO: Initialize ``context``:\n            >>> context = {}\n            >>>\n            >>> response = client.update_context(context)\n\n        Args:\n            context (Union[dict, ~google.cloud.dialogflow_v2.types.Context]): Required. The context to update.\n                If a dict is provided, it must be of the same form as the protobuf\n                message :class:`~google.cloud.dialogflow_v2.types.Context`\n            update_mask (Union[dict, ~google.cloud.dialogflow_v2.types.FieldMask]): Optional. The mask to control which fields get updated.\n                If a dict is provided, it must be of the same form as the protobuf\n                message :class:`~google.cloud.dialogflow_v2.types.FieldMask`\n            retry (Optional[google.api_core.retry.Retry]):  A retry object used\n                to retry requests. If ``None`` is specified, requests will not\n                be retried.\n            timeout (Optional[float]): The amount of time, in seconds, to wait\n                for the request to complete. Note that if ``retry`` is\n                specified, the timeout applies to each individual attempt.\n            metadata (Optional[Sequence[Tuple[str, str]]]): Additional metadata\n                that is provided to the method.\n\n        Returns:\n            A :class:`~google.cloud.dialogflow_v2.types.Context` instance.\n\n        Raises:\n            google.api_core.exceptions.GoogleAPICallError: If the request\n                    failed for any reason.\n            google.api_core.exceptions.RetryError: If the request failed due\n                    to a retryable error and retry attempts failed.\n            ValueError: If the parameters are invalid.\n        \"\"\"\n        # Wrap the transport method to add retry and timeout logic.\n        if 'update_context' not in self._inner_api_calls:\n            self._inner_api_calls[\n                'update_context'] = google.api_core.gapic_v1.method.wrap_method(\n                    self.transport.update_context,\n                    default_retry=self._method_configs['UpdateContext'].retry,\n                    default_timeout=self._method_configs['UpdateContext']\n                    .timeout,\n                    client_info=self._client_info,\n                )\n\n        request = context_pb2.UpdateContextRequest(\n            context=context,\n            update_mask=update_mask,\n        )\n        return self._inner_api_calls['update_context'](\n            request, retry=retry, timeout=timeout, metadata=metadata)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_session_entity_type(project_id, session_id, entity_values,\n                               entity_type_display_name, entity_override_mode):\n    \"\"\"Create a session entity type with the given display name.\"\"\"\n    import dialogflow_v2 as dialogflow\n    session_entity_types_client = dialogflow.SessionEntityTypesClient()\n\n    session_path = session_entity_types_client.session_path(\n        project_id, session_id)\n    session_entity_type_name = (\n        session_entity_types_client.session_entity_type_path(\n            project_id, session_id, entity_type_display_name))\n\n    # Here we use the entity value as the only synonym.\n    entities = [\n        dialogflow.types.EntityType.Entity(value=value, synonyms=[value])\n        for value in entity_values]\n    session_entity_type = dialogflow.types.SessionEntityType(\n        name=session_entity_type_name,\n        entity_override_mode=entity_override_mode,\n        entities=entities)\n\n    response = session_entity_types_client.create_session_entity_type(\n        session_path, session_entity_type)\n\n    print('SessionEntityType created: \\n\\n{}'.format(response))", "response": "Create a session entity type with the given display name."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delete_session_entity_type(project_id, session_id,\n                               entity_type_display_name):\n    \"\"\"Delete session entity type with the given entity type display name.\"\"\"\n    import dialogflow_v2 as dialogflow\n    session_entity_types_client = dialogflow.SessionEntityTypesClient()\n\n    session_entity_type_name = (\n        session_entity_types_client.session_entity_type_path(\n            project_id, session_id, entity_type_display_name))\n\n    session_entity_types_client.delete_session_entity_type(\n        session_entity_type_name)", "response": "Delete the given session entity type with the given entity type display name."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_entity_type(project_id, display_name, kind):\n    import dialogflow_v2 as dialogflow\n    entity_types_client = dialogflow.EntityTypesClient()\n\n    parent = entity_types_client.project_agent_path(project_id)\n    entity_type = dialogflow.types.EntityType(\n        display_name=display_name, kind=kind)\n\n    response = entity_types_client.create_entity_type(parent, entity_type)\n\n    print('Entity type created: \\n{}'.format(response))", "response": "Create an entity type with the given display name."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndeletes the given entity type with the given entity type name.", "response": "def delete_entity_type(project_id, entity_type_id):\n    \"\"\"Delete entity type with the given entity type name.\"\"\"\n    import dialogflow_v2 as dialogflow\n    entity_types_client = dialogflow.EntityTypesClient()\n\n    entity_type_path = entity_types_client.entity_type_path(\n        project_id, entity_type_id)\n\n    entity_types_client.delete_entity_type(entity_type_path)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the result of detect intent with texts as inputs.", "response": "def detect_intent_texts(project_id, session_id, texts, language_code):\n    \"\"\"Returns the result of detect intent with texts as inputs.\n\n    Using the same `session_id` between requests allows continuation\n    of the conversation.\"\"\"\n\n    import dialogflow_v2 as dialogflow\n    session_client = dialogflow.SessionsClient()\n\n    session = session_client.session_path(project_id, session_id)\n    print('Session path: {}\\n'.format(session))\n\n    for text in texts:\n        text_input = dialogflow.types.TextInput(\n            text=text, language_code=language_code)\n\n        query_input = dialogflow.types.QueryInput(text=text_input)\n\n        response = session_client.detect_intent(\n            session=session, query_input=query_input)\n\n        print('=' * 20)\n        print('Query text: {}'.format(response.query_result.query_text))\n        print('Detected intent: {} (confidence: {})\\n'.format(\n            response.query_result.intent.display_name,\n            response.query_result.intent_detection_confidence))\n        print('Fulfillment text: {}\\n'.format(\n            response.query_result.fulfillment_text))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a fully - qualified entity_type string.", "response": "def entity_type_path(cls, project, entity_type):\n        \"\"\"Return a fully-qualified entity_type string.\"\"\"\n        return google.api_core.path_template.expand(\n            'projects/{project}/agent/entityTypes/{entity_type}',\n            project=project,\n            entity_type=entity_type,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_entity_type(self,\n                        name,\n                        language_code=None,\n                        retry=google.api_core.gapic_v1.method.DEFAULT,\n                        timeout=google.api_core.gapic_v1.method.DEFAULT,\n                        metadata=None):\n        \"\"\"\n        Retrieves the specified entity type.\n\n        Example:\n            >>> import dialogflow_v2\n            >>>\n            >>> client = dialogflow_v2.EntityTypesClient()\n            >>>\n            >>> name = client.entity_type_path('[PROJECT]', '[ENTITY_TYPE]')\n            >>>\n            >>> response = client.get_entity_type(name)\n\n        Args:\n            name (str): Required. The name of the entity type.\n                Format: ``projects/<Project ID>/agent/entityTypes/<EntityType ID>``.\n            language_code (str): Optional. The language to retrieve entity synonyms for. If not specified,\n                the agent's default language is used.\n                [More than a dozen\n                languages](https://dialogflow.com/docs/reference/language) are supported.\n                Note: languages must be enabled in the agent, before they can be used.\n            retry (Optional[google.api_core.retry.Retry]):  A retry object used\n                to retry requests. If ``None`` is specified, requests will not\n                be retried.\n            timeout (Optional[float]): The amount of time, in seconds, to wait\n                for the request to complete. Note that if ``retry`` is\n                specified, the timeout applies to each individual attempt.\n            metadata (Optional[Sequence[Tuple[str, str]]]): Additional metadata\n                that is provided to the method.\n\n        Returns:\n            A :class:`~google.cloud.dialogflow_v2.types.EntityType` instance.\n\n        Raises:\n            google.api_core.exceptions.GoogleAPICallError: If the request\n                    failed for any reason.\n            google.api_core.exceptions.RetryError: If the request failed due\n                    to a retryable error and retry attempts failed.\n            ValueError: If the parameters are invalid.\n        \"\"\"\n        # Wrap the transport method to add retry and timeout logic.\n        if 'get_entity_type' not in self._inner_api_calls:\n            self._inner_api_calls[\n                'get_entity_type'] = google.api_core.gapic_v1.method.wrap_method(\n                    self.transport.get_entity_type,\n                    default_retry=self._method_configs['GetEntityType'].retry,\n                    default_timeout=self._method_configs['GetEntityType']\n                    .timeout,\n                    client_info=self._client_info,\n                )\n\n        request = entity_type_pb2.GetEntityTypeRequest(\n            name=name,\n            language_code=language_code,\n        )\n        return self._inner_api_calls['get_entity_type'](\n            request, retry=retry, timeout=timeout, metadata=metadata)", "response": "Retrieves the specified entity type from the entity type service."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_entity_type(self,\n                           parent,\n                           entity_type,\n                           language_code=None,\n                           retry=google.api_core.gapic_v1.method.DEFAULT,\n                           timeout=google.api_core.gapic_v1.method.DEFAULT,\n                           metadata=None):\n        \"\"\"\n        Creates an entity type in the specified agent.\n\n        Example:\n            >>> import dialogflow_v2\n            >>>\n            >>> client = dialogflow_v2.EntityTypesClient()\n            >>>\n            >>> parent = client.project_agent_path('[PROJECT]')\n            >>>\n            >>> # TODO: Initialize ``entity_type``:\n            >>> entity_type = {}\n            >>>\n            >>> response = client.create_entity_type(parent, entity_type)\n\n        Args:\n            parent (str): Required. The agent to create a entity type for.\n                Format: ``projects/<Project ID>/agent``.\n            entity_type (Union[dict, ~google.cloud.dialogflow_v2.types.EntityType]): Required. The entity type to create.\n                If a dict is provided, it must be of the same form as the protobuf\n                message :class:`~google.cloud.dialogflow_v2.types.EntityType`\n            language_code (str): Optional. The language of entity synonyms defined in ``entity_type``. If not\n                specified, the agent's default language is used.\n                [More than a dozen\n                languages](https://dialogflow.com/docs/reference/language) are supported.\n                Note: languages must be enabled in the agent, before they can be used.\n            retry (Optional[google.api_core.retry.Retry]):  A retry object used\n                to retry requests. If ``None`` is specified, requests will not\n                be retried.\n            timeout (Optional[float]): The amount of time, in seconds, to wait\n                for the request to complete. Note that if ``retry`` is\n                specified, the timeout applies to each individual attempt.\n            metadata (Optional[Sequence[Tuple[str, str]]]): Additional metadata\n                that is provided to the method.\n\n        Returns:\n            A :class:`~google.cloud.dialogflow_v2.types.EntityType` instance.\n\n        Raises:\n            google.api_core.exceptions.GoogleAPICallError: If the request\n                    failed for any reason.\n            google.api_core.exceptions.RetryError: If the request failed due\n                    to a retryable error and retry attempts failed.\n            ValueError: If the parameters are invalid.\n        \"\"\"\n        # Wrap the transport method to add retry and timeout logic.\n        if 'create_entity_type' not in self._inner_api_calls:\n            self._inner_api_calls[\n                'create_entity_type'] = google.api_core.gapic_v1.method.wrap_method(\n                    self.transport.create_entity_type,\n                    default_retry=self._method_configs[\n                        'CreateEntityType'].retry,\n                    default_timeout=self._method_configs['CreateEntityType']\n                    .timeout,\n                    client_info=self._client_info,\n                )\n\n        request = entity_type_pb2.CreateEntityTypeRequest(\n            parent=parent,\n            entity_type=entity_type,\n            language_code=language_code,\n        )\n        return self._inner_api_calls['create_entity_type'](\n            request, retry=retry, timeout=timeout, metadata=metadata)", "response": "Creates an entity type in the specified agent."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates the specified entity type.", "response": "def update_entity_type(self,\n                           entity_type,\n                           language_code=None,\n                           update_mask=None,\n                           retry=google.api_core.gapic_v1.method.DEFAULT,\n                           timeout=google.api_core.gapic_v1.method.DEFAULT,\n                           metadata=None):\n        \"\"\"\n        Updates the specified entity type.\n\n        Example:\n            >>> import dialogflow_v2\n            >>>\n            >>> client = dialogflow_v2.EntityTypesClient()\n            >>>\n            >>> # TODO: Initialize ``entity_type``:\n            >>> entity_type = {}\n            >>>\n            >>> response = client.update_entity_type(entity_type)\n\n        Args:\n            entity_type (Union[dict, ~google.cloud.dialogflow_v2.types.EntityType]): Required. The entity type to update.\n                Format: ``projects/<Project ID>/agent/entityTypes/<EntityType ID>``.\n                If a dict is provided, it must be of the same form as the protobuf\n                message :class:`~google.cloud.dialogflow_v2.types.EntityType`\n            language_code (str): Optional. The language of entity synonyms defined in ``entity_type``. If not\n                specified, the agent's default language is used.\n                [More than a dozen\n                languages](https://dialogflow.com/docs/reference/language) are supported.\n                Note: languages must be enabled in the agent, before they can be used.\n            update_mask (Union[dict, ~google.cloud.dialogflow_v2.types.FieldMask]): Optional. The mask to control which fields get updated.\n                If a dict is provided, it must be of the same form as the protobuf\n                message :class:`~google.cloud.dialogflow_v2.types.FieldMask`\n            retry (Optional[google.api_core.retry.Retry]):  A retry object used\n                to retry requests. If ``None`` is specified, requests will not\n                be retried.\n            timeout (Optional[float]): The amount of time, in seconds, to wait\n                for the request to complete. Note that if ``retry`` is\n                specified, the timeout applies to each individual attempt.\n            metadata (Optional[Sequence[Tuple[str, str]]]): Additional metadata\n                that is provided to the method.\n\n        Returns:\n            A :class:`~google.cloud.dialogflow_v2.types.EntityType` instance.\n\n        Raises:\n            google.api_core.exceptions.GoogleAPICallError: If the request\n                    failed for any reason.\n            google.api_core.exceptions.RetryError: If the request failed due\n                    to a retryable error and retry attempts failed.\n            ValueError: If the parameters are invalid.\n        \"\"\"\n        # Wrap the transport method to add retry and timeout logic.\n        if 'update_entity_type' not in self._inner_api_calls:\n            self._inner_api_calls[\n                'update_entity_type'] = google.api_core.gapic_v1.method.wrap_method(\n                    self.transport.update_entity_type,\n                    default_retry=self._method_configs[\n                        'UpdateEntityType'].retry,\n                    default_timeout=self._method_configs['UpdateEntityType']\n                    .timeout,\n                    client_info=self._client_info,\n                )\n\n        request = entity_type_pb2.UpdateEntityTypeRequest(\n            entity_type=entity_type,\n            language_code=language_code,\n            update_mask=update_mask,\n        )\n        return self._inner_api_calls['update_entity_type'](\n            request, retry=retry, timeout=timeout, metadata=metadata)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef batch_update_entity_types(\n            self,\n            parent,\n            entity_type_batch_uri=None,\n            entity_type_batch_inline=None,\n            language_code=None,\n            update_mask=None,\n            retry=google.api_core.gapic_v1.method.DEFAULT,\n            timeout=google.api_core.gapic_v1.method.DEFAULT,\n            metadata=None):\n        \"\"\"\n        Updates/Creates multiple entity types in the specified agent.\n\n        Operation <response: ``BatchUpdateEntityTypesResponse``,\n        metadata: [google.protobuf.Struct][google.protobuf.Struct]>\n\n        Example:\n            >>> import dialogflow_v2\n            >>>\n            >>> client = dialogflow_v2.EntityTypesClient()\n            >>>\n            >>> parent = client.project_agent_path('[PROJECT]')\n            >>>\n            >>> response = client.batch_update_entity_types(parent)\n            >>>\n            >>> def callback(operation_future):\n            ...     # Handle result.\n            ...     result = operation_future.result()\n            >>>\n            >>> response.add_done_callback(callback)\n            >>>\n            >>> # Handle metadata.\n            >>> metadata = response.metadata()\n\n        Args:\n            parent (str): Required. The name of the agent to update or create entity types in.\n                Format: ``projects/<Project ID>/agent``.\n            entity_type_batch_uri (str): The URI to a Google Cloud Storage file containing entity types to update\n                or create. The file format can either be a serialized proto (of\n                EntityBatch type) or a JSON object. Note: The URI must start with\n                \\\"gs://\\\".\n            entity_type_batch_inline (Union[dict, ~google.cloud.dialogflow_v2.types.EntityTypeBatch]): The collection of entity type to update or create.\n                If a dict is provided, it must be of the same form as the protobuf\n                message :class:`~google.cloud.dialogflow_v2.types.EntityTypeBatch`\n            language_code (str): Optional. The language of entity synonyms defined in ``entity_types``. If not\n                specified, the agent's default language is used.\n                [More than a dozen\n                languages](https://dialogflow.com/docs/reference/language) are supported.\n                Note: languages must be enabled in the agent, before they can be used.\n            update_mask (Union[dict, ~google.cloud.dialogflow_v2.types.FieldMask]): Optional. The mask to control which fields get updated.\n                If a dict is provided, it must be of the same form as the protobuf\n                message :class:`~google.cloud.dialogflow_v2.types.FieldMask`\n            retry (Optional[google.api_core.retry.Retry]):  A retry object used\n                to retry requests. If ``None`` is specified, requests will not\n                be retried.\n            timeout (Optional[float]): The amount of time, in seconds, to wait\n                for the request to complete. Note that if ``retry`` is\n                specified, the timeout applies to each individual attempt.\n            metadata (Optional[Sequence[Tuple[str, str]]]): Additional metadata\n                that is provided to the method.\n\n        Returns:\n            A :class:`~google.cloud.dialogflow_v2.types._OperationFuture` instance.\n\n        Raises:\n            google.api_core.exceptions.GoogleAPICallError: If the request\n                    failed for any reason.\n            google.api_core.exceptions.RetryError: If the request failed due\n                    to a retryable error and retry attempts failed.\n            ValueError: If the parameters are invalid.\n        \"\"\"\n        # Wrap the transport method to add retry and timeout logic.\n        if 'batch_update_entity_types' not in self._inner_api_calls:\n            self._inner_api_calls[\n                'batch_update_entity_types'] = google.api_core.gapic_v1.method.wrap_method(\n                    self.transport.batch_update_entity_types,\n                    default_retry=self._method_configs[\n                        'BatchUpdateEntityTypes'].retry,\n                    default_timeout=self._method_configs[\n                        'BatchUpdateEntityTypes'].timeout,\n                    client_info=self._client_info,\n                )\n\n        # Sanity check: We have some fields which are mutually exclusive;\n        # raise ValueError if more than one is sent.\n        google.api_core.protobuf_helpers.check_oneof(\n            entity_type_batch_uri=entity_type_batch_uri,\n            entity_type_batch_inline=entity_type_batch_inline,\n        )\n\n        request = entity_type_pb2.BatchUpdateEntityTypesRequest(\n            parent=parent,\n            entity_type_batch_uri=entity_type_batch_uri,\n            entity_type_batch_inline=entity_type_batch_inline,\n            language_code=language_code,\n            update_mask=update_mask,\n        )\n        operation = self._inner_api_calls['batch_update_entity_types'](\n            request, retry=retry, timeout=timeout, metadata=metadata)\n        return google.api_core.operation.from_gapic(\n            operation,\n            self.transport._operations_client,\n            entity_type_pb2.BatchUpdateEntityTypesResponse,\n            metadata_type=struct_pb2.Struct,\n        )", "response": "Batch update entity types in a specific agent."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndelete entities in the specified entity type. Operation <response: ``google.protobuf.Empty``, metadata: [google.protobuf.Struct][google.protobuf.Struct]> Example: >>> import dialogflow_v2 >>> >>> client = dialogflow_v2.EntityTypesClient() >>> >>> parent = client.entity_type_path('[PROJECT]', '[ENTITY_TYPE]') >>> >>> # TODO: Initialize ``entity_values``: >>> entity_values = [] >>> >>> response = client.batch_delete_entities(parent, entity_values) >>> >>> def callback(operation_future): ... # Handle result. ... result = operation_future.result() >>> >>> response.add_done_callback(callback) >>> >>> # Handle metadata. >>> metadata = response.metadata() Args: parent (str): Required. The name of the entity type to delete entries for. Format: ``projects/<Project ID>/agent/entityTypes/<Entity Type ID>``. entity_values (list[str]): Required. The canonical ``values`` of the entities to delete. Note that these are not fully-qualified names, i.e. they don't start with ``projects/<Project ID>``. language_code (str): Optional. The language of entity synonyms defined in ``entities``. If not specified, the agent's default language is used. [More than a dozen languages](https://dialogflow.com/docs/reference/language) are supported. Note: languages must be enabled in the agent, before they can be used. retry (Optional[google.api_core.retry.Retry]): A retry object used to retry requests. If ``None`` is specified, requests will not be retried. timeout (Optional[float]): The amount of time, in seconds, to wait for the request to complete. Note that if ``retry`` is specified, the timeout applies to each individual attempt. metadata (Optional[Sequence[Tuple[str, str]]]): Additional metadata that is provided to the method. Returns: A :class:`~google.cloud.dialogflow_v2.types._OperationFuture` instance. Raises: google.api_core.exceptions.GoogleAPICallError: If the request failed for any reason. google.api_core.exceptions.RetryError: If the request failed due to a retryable error and retry attempts failed. ValueError: If the parameters are invalid.", "response": "def batch_delete_entities(self,\n                              parent,\n                              entity_values,\n                              language_code=None,\n                              retry=google.api_core.gapic_v1.method.DEFAULT,\n                              timeout=google.api_core.gapic_v1.method.DEFAULT,\n                              metadata=None):\n        \"\"\"\n        Deletes entities in the specified entity type.\n\n        Operation <response: ``google.protobuf.Empty``,\n        metadata: [google.protobuf.Struct][google.protobuf.Struct]>\n\n        Example:\n            >>> import dialogflow_v2\n            >>>\n            >>> client = dialogflow_v2.EntityTypesClient()\n            >>>\n            >>> parent = client.entity_type_path('[PROJECT]', '[ENTITY_TYPE]')\n            >>>\n            >>> # TODO: Initialize ``entity_values``:\n            >>> entity_values = []\n            >>>\n            >>> response = client.batch_delete_entities(parent, entity_values)\n            >>>\n            >>> def callback(operation_future):\n            ...     # Handle result.\n            ...     result = operation_future.result()\n            >>>\n            >>> response.add_done_callback(callback)\n            >>>\n            >>> # Handle metadata.\n            >>> metadata = response.metadata()\n\n        Args:\n            parent (str): Required. The name of the entity type to delete entries for. Format:\n                ``projects/<Project ID>/agent/entityTypes/<Entity Type ID>``.\n            entity_values (list[str]): Required. The canonical ``values`` of the entities to delete. Note that\n                these are not fully-qualified names, i.e. they don't start with\n                ``projects/<Project ID>``.\n            language_code (str): Optional. The language of entity synonyms defined in ``entities``. If not\n                specified, the agent's default language is used.\n                [More than a dozen\n                languages](https://dialogflow.com/docs/reference/language) are supported.\n                Note: languages must be enabled in the agent, before they can be used.\n            retry (Optional[google.api_core.retry.Retry]):  A retry object used\n                to retry requests. If ``None`` is specified, requests will not\n                be retried.\n            timeout (Optional[float]): The amount of time, in seconds, to wait\n                for the request to complete. Note that if ``retry`` is\n                specified, the timeout applies to each individual attempt.\n            metadata (Optional[Sequence[Tuple[str, str]]]): Additional metadata\n                that is provided to the method.\n\n        Returns:\n            A :class:`~google.cloud.dialogflow_v2.types._OperationFuture` instance.\n\n        Raises:\n            google.api_core.exceptions.GoogleAPICallError: If the request\n                    failed for any reason.\n            google.api_core.exceptions.RetryError: If the request failed due\n                    to a retryable error and retry attempts failed.\n            ValueError: If the parameters are invalid.\n        \"\"\"\n        # Wrap the transport method to add retry and timeout logic.\n        if 'batch_delete_entities' not in self._inner_api_calls:\n            self._inner_api_calls[\n                'batch_delete_entities'] = google.api_core.gapic_v1.method.wrap_method(\n                    self.transport.batch_delete_entities,\n                    default_retry=self._method_configs[\n                        'BatchDeleteEntities'].retry,\n                    default_timeout=self._method_configs['BatchDeleteEntities']\n                    .timeout,\n                    client_info=self._client_info,\n                )\n\n        request = entity_type_pb2.BatchDeleteEntitiesRequest(\n            parent=parent,\n            entity_values=entity_values,\n            language_code=language_code,\n        )\n        operation = self._inner_api_calls['batch_delete_entities'](\n            request, retry=retry, timeout=timeout, metadata=metadata)\n        return google.api_core.operation.from_gapic(\n            operation,\n            self.transport._operations_client,\n            empty_pb2.Empty,\n            metadata_type=struct_pb2.Struct,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the result of detect intent with querying Knowledge Connector.", "response": "def detect_intent_knowledge(project_id, session_id, language_code,\n                            knowledge_base_id, texts):\n    \"\"\"Returns the result of detect intent with querying Knowledge Connector.\n\n    Args:\n    project_id: The GCP project linked with the agent you are going to query.\n    session_id: Id of the session, using the same `session_id` between requests\n              allows continuation of the conversation.\n    language_code: Language of the queries.\n    knowledge_base_id: The Knowledge base's id to query against.\n    texts: A list of text queries to send.\n    \"\"\"\n    import dialogflow_v2beta1 as dialogflow\n    session_client = dialogflow.SessionsClient()\n\n    session_path = session_client.session_path(project_id, session_id)\n    print('Session path: {}\\n'.format(session_path))\n\n    for text in texts:\n        text_input = dialogflow.types.TextInput(\n            text=text, language_code=language_code)\n\n        query_input = dialogflow.types.QueryInput(text=text_input)\n\n        knowledge_base_path = dialogflow.knowledge_bases_client \\\n            .KnowledgeBasesClient \\\n            .knowledge_base_path(project_id, knowledge_base_id)\n\n        query_params = dialogflow.types.QueryParameters(\n            knowledge_base_names=[knowledge_base_path])\n\n        response = session_client.detect_intent(\n            session=session_path, query_input=query_input,\n            query_params=query_params)\n\n        print('=' * 20)\n        print('Query text: {}'.format(response.query_result.query_text))\n        print('Detected intent: {} (confidence: {})\\n'.format(\n            response.query_result.intent.display_name,\n            response.query_result.intent_detection_confidence))\n        print('Fulfillment text: {}\\n'.format(\n            response.query_result.fulfillment_text))\n        print('Knowledge results:')\n        knowledge_answers = response.query_result.knowledge_answers\n        for answers in knowledge_answers.answers:\n            print(' - Answer: {}'.format(answers.answer))\n            print(' - Confidence: {}'.format(\n                answers.match_confidence))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a fully - qualified intent string.", "response": "def intent_path(cls, project, intent):\n        \"\"\"Return a fully-qualified intent string.\"\"\"\n        return google.api_core.path_template.expand(\n            'projects/{project}/agent/intents/{intent}',\n            project=project,\n            intent=intent,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef agent_path(cls, project, agent):\n        return google.api_core.path_template.expand(\n            'projects/{project}/agents/{agent}',\n            project=project,\n            agent=agent,\n        )", "response": "Return a fully - qualified agent string."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_intent(self,\n                   name,\n                   language_code=None,\n                   intent_view=None,\n                   retry=google.api_core.gapic_v1.method.DEFAULT,\n                   timeout=google.api_core.gapic_v1.method.DEFAULT,\n                   metadata=None):\n        \"\"\"\n        Retrieves the specified intent.\n\n        Example:\n            >>> import dialogflow_v2\n            >>>\n            >>> client = dialogflow_v2.IntentsClient()\n            >>>\n            >>> name = client.intent_path('[PROJECT]', '[INTENT]')\n            >>>\n            >>> response = client.get_intent(name)\n\n        Args:\n            name (str): Required. The name of the intent.\n                Format: ``projects/<Project ID>/agent/intents/<Intent ID>``.\n            language_code (str): Optional. The language to retrieve training phrases, parameters and rich\n                messages for. If not specified, the agent's default language is used.\n                [More than a dozen\n                languages](https://dialogflow.com/docs/reference/language) are supported.\n                Note: languages must be enabled in the agent, before they can be used.\n            intent_view (~google.cloud.dialogflow_v2.types.IntentView): Optional. The resource view to apply to the returned intent.\n            retry (Optional[google.api_core.retry.Retry]):  A retry object used\n                to retry requests. If ``None`` is specified, requests will not\n                be retried.\n            timeout (Optional[float]): The amount of time, in seconds, to wait\n                for the request to complete. Note that if ``retry`` is\n                specified, the timeout applies to each individual attempt.\n            metadata (Optional[Sequence[Tuple[str, str]]]): Additional metadata\n                that is provided to the method.\n\n        Returns:\n            A :class:`~google.cloud.dialogflow_v2.types.Intent` instance.\n\n        Raises:\n            google.api_core.exceptions.GoogleAPICallError: If the request\n                    failed for any reason.\n            google.api_core.exceptions.RetryError: If the request failed due\n                    to a retryable error and retry attempts failed.\n            ValueError: If the parameters are invalid.\n        \"\"\"\n        # Wrap the transport method to add retry and timeout logic.\n        if 'get_intent' not in self._inner_api_calls:\n            self._inner_api_calls[\n                'get_intent'] = google.api_core.gapic_v1.method.wrap_method(\n                    self.transport.get_intent,\n                    default_retry=self._method_configs['GetIntent'].retry,\n                    default_timeout=self._method_configs['GetIntent'].timeout,\n                    client_info=self._client_info,\n                )\n\n        request = intent_pb2.GetIntentRequest(\n            name=name,\n            language_code=language_code,\n            intent_view=intent_view,\n        )\n        return self._inner_api_calls['get_intent'](\n            request, retry=retry, timeout=timeout, metadata=metadata)", "response": "Retrieves the specified intent from the specified project."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates an intent in the specified agent.", "response": "def create_intent(self,\n                      parent,\n                      intent,\n                      language_code=None,\n                      intent_view=None,\n                      retry=google.api_core.gapic_v1.method.DEFAULT,\n                      timeout=google.api_core.gapic_v1.method.DEFAULT,\n                      metadata=None):\n        \"\"\"\n        Creates an intent in the specified agent.\n\n        Example:\n            >>> import dialogflow_v2\n            >>>\n            >>> client = dialogflow_v2.IntentsClient()\n            >>>\n            >>> parent = client.project_agent_path('[PROJECT]')\n            >>>\n            >>> # TODO: Initialize ``intent``:\n            >>> intent = {}\n            >>>\n            >>> response = client.create_intent(parent, intent)\n\n        Args:\n            parent (str): Required. The agent to create a intent for.\n                Format: ``projects/<Project ID>/agent``.\n            intent (Union[dict, ~google.cloud.dialogflow_v2.types.Intent]): Required. The intent to create.\n                If a dict is provided, it must be of the same form as the protobuf\n                message :class:`~google.cloud.dialogflow_v2.types.Intent`\n            language_code (str): Optional. The language of training phrases, parameters and rich messages\n                defined in ``intent``. If not specified, the agent's default language is\n                used. [More than a dozen\n                languages](https://dialogflow.com/docs/reference/language) are supported.\n                Note: languages must be enabled in the agent, before they can be used.\n            intent_view (~google.cloud.dialogflow_v2.types.IntentView): Optional. The resource view to apply to the returned intent.\n            retry (Optional[google.api_core.retry.Retry]):  A retry object used\n                to retry requests. If ``None`` is specified, requests will not\n                be retried.\n            timeout (Optional[float]): The amount of time, in seconds, to wait\n                for the request to complete. Note that if ``retry`` is\n                specified, the timeout applies to each individual attempt.\n            metadata (Optional[Sequence[Tuple[str, str]]]): Additional metadata\n                that is provided to the method.\n\n        Returns:\n            A :class:`~google.cloud.dialogflow_v2.types.Intent` instance.\n\n        Raises:\n            google.api_core.exceptions.GoogleAPICallError: If the request\n                    failed for any reason.\n            google.api_core.exceptions.RetryError: If the request failed due\n                    to a retryable error and retry attempts failed.\n            ValueError: If the parameters are invalid.\n        \"\"\"\n        # Wrap the transport method to add retry and timeout logic.\n        if 'create_intent' not in self._inner_api_calls:\n            self._inner_api_calls[\n                'create_intent'] = google.api_core.gapic_v1.method.wrap_method(\n                    self.transport.create_intent,\n                    default_retry=self._method_configs['CreateIntent'].retry,\n                    default_timeout=self._method_configs['CreateIntent']\n                    .timeout,\n                    client_info=self._client_info,\n                )\n\n        request = intent_pb2.CreateIntentRequest(\n            parent=parent,\n            intent=intent,\n            language_code=language_code,\n            intent_view=intent_view,\n        )\n        return self._inner_api_calls['create_intent'](\n            request, retry=retry, timeout=timeout, metadata=metadata)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate the specified intent in the specified language.", "response": "def update_intent(self,\n                      intent,\n                      language_code,\n                      update_mask=None,\n                      intent_view=None,\n                      retry=google.api_core.gapic_v1.method.DEFAULT,\n                      timeout=google.api_core.gapic_v1.method.DEFAULT,\n                      metadata=None):\n        \"\"\"\n        Updates the specified intent.\n\n        Example:\n            >>> import dialogflow_v2\n            >>>\n            >>> client = dialogflow_v2.IntentsClient()\n            >>>\n            >>> # TODO: Initialize ``intent``:\n            >>> intent = {}\n            >>>\n            >>> # TODO: Initialize ``language_code``:\n            >>> language_code = ''\n            >>>\n            >>> response = client.update_intent(intent, language_code)\n\n        Args:\n            intent (Union[dict, ~google.cloud.dialogflow_v2.types.Intent]): Required. The intent to update.\n                Format: ``projects/<Project ID>/agent/intents/<Intent ID>``.\n                If a dict is provided, it must be of the same form as the protobuf\n                message :class:`~google.cloud.dialogflow_v2.types.Intent`\n            language_code (str): Optional. The language of training phrases, parameters and rich messages\n                defined in ``intent``. If not specified, the agent's default language is\n                used. [More than a dozen\n                languages](https://dialogflow.com/docs/reference/language) are supported.\n                Note: languages must be enabled in the agent, before they can be used.\n            update_mask (Union[dict, ~google.cloud.dialogflow_v2.types.FieldMask]): Optional. The mask to control which fields get updated.\n                If a dict is provided, it must be of the same form as the protobuf\n                message :class:`~google.cloud.dialogflow_v2.types.FieldMask`\n            intent_view (~google.cloud.dialogflow_v2.types.IntentView): Optional. The resource view to apply to the returned intent.\n            retry (Optional[google.api_core.retry.Retry]):  A retry object used\n                to retry requests. If ``None`` is specified, requests will not\n                be retried.\n            timeout (Optional[float]): The amount of time, in seconds, to wait\n                for the request to complete. Note that if ``retry`` is\n                specified, the timeout applies to each individual attempt.\n            metadata (Optional[Sequence[Tuple[str, str]]]): Additional metadata\n                that is provided to the method.\n\n        Returns:\n            A :class:`~google.cloud.dialogflow_v2.types.Intent` instance.\n\n        Raises:\n            google.api_core.exceptions.GoogleAPICallError: If the request\n                    failed for any reason.\n            google.api_core.exceptions.RetryError: If the request failed due\n                    to a retryable error and retry attempts failed.\n            ValueError: If the parameters are invalid.\n        \"\"\"\n        # Wrap the transport method to add retry and timeout logic.\n        if 'update_intent' not in self._inner_api_calls:\n            self._inner_api_calls[\n                'update_intent'] = google.api_core.gapic_v1.method.wrap_method(\n                    self.transport.update_intent,\n                    default_retry=self._method_configs['UpdateIntent'].retry,\n                    default_timeout=self._method_configs['UpdateIntent']\n                    .timeout,\n                    client_info=self._client_info,\n                )\n\n        request = intent_pb2.UpdateIntentRequest(\n            intent=intent,\n            language_code=language_code,\n            update_mask=update_mask,\n            intent_view=intent_view,\n        )\n        return self._inner_api_calls['update_intent'](\n            request, retry=retry, timeout=timeout, metadata=metadata)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndelete an intent from the specified resource.", "response": "def delete_intent(self,\n                      name,\n                      retry=google.api_core.gapic_v1.method.DEFAULT,\n                      timeout=google.api_core.gapic_v1.method.DEFAULT,\n                      metadata=None):\n        \"\"\"\n        Deletes the specified intent.\n\n        Example:\n            >>> import dialogflow_v2\n            >>>\n            >>> client = dialogflow_v2.IntentsClient()\n            >>>\n            >>> name = client.intent_path('[PROJECT]', '[INTENT]')\n            >>>\n            >>> client.delete_intent(name)\n\n        Args:\n            name (str): Required. The name of the intent to delete.\n                Format: ``projects/<Project ID>/agent/intents/<Intent ID>``.\n            retry (Optional[google.api_core.retry.Retry]):  A retry object used\n                to retry requests. If ``None`` is specified, requests will not\n                be retried.\n            timeout (Optional[float]): The amount of time, in seconds, to wait\n                for the request to complete. Note that if ``retry`` is\n                specified, the timeout applies to each individual attempt.\n            metadata (Optional[Sequence[Tuple[str, str]]]): Additional metadata\n                that is provided to the method.\n\n        Raises:\n            google.api_core.exceptions.GoogleAPICallError: If the request\n                    failed for any reason.\n            google.api_core.exceptions.RetryError: If the request failed due\n                    to a retryable error and retry attempts failed.\n            ValueError: If the parameters are invalid.\n        \"\"\"\n        # Wrap the transport method to add retry and timeout logic.\n        if 'delete_intent' not in self._inner_api_calls:\n            self._inner_api_calls[\n                'delete_intent'] = google.api_core.gapic_v1.method.wrap_method(\n                    self.transport.delete_intent,\n                    default_retry=self._method_configs['DeleteIntent'].retry,\n                    default_timeout=self._method_configs['DeleteIntent']\n                    .timeout,\n                    client_info=self._client_info,\n                )\n\n        request = intent_pb2.DeleteIntentRequest(name=name, )\n        self._inner_api_calls['delete_intent'](\n            request, retry=retry, timeout=timeout, metadata=metadata)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nbatch update intents in a specific agent.", "response": "def batch_update_intents(self,\n                             parent,\n                             language_code,\n                             intent_batch_uri=None,\n                             intent_batch_inline=None,\n                             update_mask=None,\n                             intent_view=None,\n                             retry=google.api_core.gapic_v1.method.DEFAULT,\n                             timeout=google.api_core.gapic_v1.method.DEFAULT,\n                             metadata=None):\n        \"\"\"\n        Updates/Creates multiple intents in the specified agent.\n\n        Operation <response: ``BatchUpdateIntentsResponse``>\n\n        Example:\n            >>> import dialogflow_v2\n            >>>\n            >>> client = dialogflow_v2.IntentsClient()\n            >>>\n            >>> parent = client.project_agent_path('[PROJECT]')\n            >>>\n            >>> # TODO: Initialize ``language_code``:\n            >>> language_code = ''\n            >>>\n            >>> response = client.batch_update_intents(parent, language_code)\n            >>>\n            >>> def callback(operation_future):\n            ...     # Handle result.\n            ...     result = operation_future.result()\n            >>>\n            >>> response.add_done_callback(callback)\n            >>>\n            >>> # Handle metadata.\n            >>> metadata = response.metadata()\n\n        Args:\n            parent (str): Required. The name of the agent to update or create intents in.\n                Format: ``projects/<Project ID>/agent``.\n            language_code (str): Optional. The language of training phrases, parameters and rich messages\n                defined in ``intents``. If not specified, the agent's default language is\n                used. [More than a dozen\n                languages](https://dialogflow.com/docs/reference/language) are supported.\n                Note: languages must be enabled in the agent, before they can be used.\n            intent_batch_uri (str): The URI to a Google Cloud Storage file containing intents to update or\n                create. The file format can either be a serialized proto (of IntentBatch\n                type) or JSON object. Note: The URI must start with \\\"gs://\\\".\n            intent_batch_inline (Union[dict, ~google.cloud.dialogflow_v2.types.IntentBatch]): The collection of intents to update or create.\n                If a dict is provided, it must be of the same form as the protobuf\n                message :class:`~google.cloud.dialogflow_v2.types.IntentBatch`\n            update_mask (Union[dict, ~google.cloud.dialogflow_v2.types.FieldMask]): Optional. The mask to control which fields get updated.\n                If a dict is provided, it must be of the same form as the protobuf\n                message :class:`~google.cloud.dialogflow_v2.types.FieldMask`\n            intent_view (~google.cloud.dialogflow_v2.types.IntentView): Optional. The resource view to apply to the returned intent.\n            retry (Optional[google.api_core.retry.Retry]):  A retry object used\n                to retry requests. If ``None`` is specified, requests will not\n                be retried.\n            timeout (Optional[float]): The amount of time, in seconds, to wait\n                for the request to complete. Note that if ``retry`` is\n                specified, the timeout applies to each individual attempt.\n            metadata (Optional[Sequence[Tuple[str, str]]]): Additional metadata\n                that is provided to the method.\n\n        Returns:\n            A :class:`~google.cloud.dialogflow_v2.types._OperationFuture` instance.\n\n        Raises:\n            google.api_core.exceptions.GoogleAPICallError: If the request\n                    failed for any reason.\n            google.api_core.exceptions.RetryError: If the request failed due\n                    to a retryable error and retry attempts failed.\n            ValueError: If the parameters are invalid.\n        \"\"\"\n        # Wrap the transport method to add retry and timeout logic.\n        if 'batch_update_intents' not in self._inner_api_calls:\n            self._inner_api_calls[\n                'batch_update_intents'] = google.api_core.gapic_v1.method.wrap_method(\n                    self.transport.batch_update_intents,\n                    default_retry=self._method_configs[\n                        'BatchUpdateIntents'].retry,\n                    default_timeout=self._method_configs['BatchUpdateIntents']\n                    .timeout,\n                    client_info=self._client_info,\n                )\n\n        # Sanity check: We have some fields which are mutually exclusive;\n        # raise ValueError if more than one is sent.\n        google.api_core.protobuf_helpers.check_oneof(\n            intent_batch_uri=intent_batch_uri,\n            intent_batch_inline=intent_batch_inline,\n        )\n\n        request = intent_pb2.BatchUpdateIntentsRequest(\n            parent=parent,\n            language_code=language_code,\n            intent_batch_uri=intent_batch_uri,\n            intent_batch_inline=intent_batch_inline,\n            update_mask=update_mask,\n            intent_view=intent_view,\n        )\n        operation = self._inner_api_calls['batch_update_intents'](\n            request, retry=retry, timeout=timeout, metadata=metadata)\n        return google.api_core.operation.from_gapic(\n            operation,\n            self.transport._operations_client,\n            intent_pb2.BatchUpdateIntentsResponse,\n            metadata_type=struct_pb2.Struct,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndeleting intents in the specified agent. Operation <response: ``google.protobuf.Empty``> Example: >>> import dialogflow_v2 >>> >>> client = dialogflow_v2.IntentsClient() >>> >>> parent = client.project_agent_path('[PROJECT]') >>> >>> # TODO: Initialize ``intents``: >>> intents = [] >>> >>> response = client.batch_delete_intents(parent, intents) >>> >>> def callback(operation_future): ... # Handle result. ... result = operation_future.result() >>> >>> response.add_done_callback(callback) >>> >>> # Handle metadata. >>> metadata = response.metadata() Args: parent (str): Required. The name of the agent to delete all entities types for. Format: ``projects/<Project ID>/agent``. intents (list[Union[dict, ~google.cloud.dialogflow_v2.types.Intent]]): Required. The collection of intents to delete. Only intent ``name`` must be filled in. If a dict is provided, it must be of the same form as the protobuf message :class:`~google.cloud.dialogflow_v2.types.Intent` retry (Optional[google.api_core.retry.Retry]): A retry object used to retry requests. If ``None`` is specified, requests will not be retried. timeout (Optional[float]): The amount of time, in seconds, to wait for the request to complete. Note that if ``retry`` is specified, the timeout applies to each individual attempt. metadata (Optional[Sequence[Tuple[str, str]]]): Additional metadata that is provided to the method. Returns: A :class:`~google.cloud.dialogflow_v2.types._OperationFuture` instance. Raises: google.api_core.exceptions.GoogleAPICallError: If the request failed for any reason. google.api_core.exceptions.RetryError: If the request failed due to a retryable error and retry attempts failed. ValueError: If the parameters are invalid.", "response": "def batch_delete_intents(self,\n                             parent,\n                             intents,\n                             retry=google.api_core.gapic_v1.method.DEFAULT,\n                             timeout=google.api_core.gapic_v1.method.DEFAULT,\n                             metadata=None):\n        \"\"\"\n        Deletes intents in the specified agent.\n\n        Operation <response: ``google.protobuf.Empty``>\n\n        Example:\n            >>> import dialogflow_v2\n            >>>\n            >>> client = dialogflow_v2.IntentsClient()\n            >>>\n            >>> parent = client.project_agent_path('[PROJECT]')\n            >>>\n            >>> # TODO: Initialize ``intents``:\n            >>> intents = []\n            >>>\n            >>> response = client.batch_delete_intents(parent, intents)\n            >>>\n            >>> def callback(operation_future):\n            ...     # Handle result.\n            ...     result = operation_future.result()\n            >>>\n            >>> response.add_done_callback(callback)\n            >>>\n            >>> # Handle metadata.\n            >>> metadata = response.metadata()\n\n        Args:\n            parent (str): Required. The name of the agent to delete all entities types for. Format:\n                ``projects/<Project ID>/agent``.\n            intents (list[Union[dict, ~google.cloud.dialogflow_v2.types.Intent]]): Required. The collection of intents to delete. Only intent ``name`` must be\n                filled in.\n                If a dict is provided, it must be of the same form as the protobuf\n                message :class:`~google.cloud.dialogflow_v2.types.Intent`\n            retry (Optional[google.api_core.retry.Retry]):  A retry object used\n                to retry requests. If ``None`` is specified, requests will not\n                be retried.\n            timeout (Optional[float]): The amount of time, in seconds, to wait\n                for the request to complete. Note that if ``retry`` is\n                specified, the timeout applies to each individual attempt.\n            metadata (Optional[Sequence[Tuple[str, str]]]): Additional metadata\n                that is provided to the method.\n\n        Returns:\n            A :class:`~google.cloud.dialogflow_v2.types._OperationFuture` instance.\n\n        Raises:\n            google.api_core.exceptions.GoogleAPICallError: If the request\n                    failed for any reason.\n            google.api_core.exceptions.RetryError: If the request failed due\n                    to a retryable error and retry attempts failed.\n            ValueError: If the parameters are invalid.\n        \"\"\"\n        # Wrap the transport method to add retry and timeout logic.\n        if 'batch_delete_intents' not in self._inner_api_calls:\n            self._inner_api_calls[\n                'batch_delete_intents'] = google.api_core.gapic_v1.method.wrap_method(\n                    self.transport.batch_delete_intents,\n                    default_retry=self._method_configs[\n                        'BatchDeleteIntents'].retry,\n                    default_timeout=self._method_configs['BatchDeleteIntents']\n                    .timeout,\n                    client_info=self._client_info,\n                )\n\n        request = intent_pb2.BatchDeleteIntentsRequest(\n            parent=parent,\n            intents=intents,\n        )\n        operation = self._inner_api_calls['batch_delete_intents'](\n            request, retry=retry, timeout=timeout, metadata=metadata)\n        return google.api_core.operation.from_gapic(\n            operation,\n            self.transport._operations_client,\n            empty_pb2.Empty,\n            metadata_type=struct_pb2.Struct,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef environment_context_path(cls, project, environment, user, session,\n                                 context):\n        \"\"\"Return a fully-qualified environment_context string.\"\"\"\n        return google.api_core.path_template.expand(\n            'projects/{project}/agent/environments/{environment}/users/{user}/sessions/{session}/contexts/{context}',\n            project=project,\n            environment=environment,\n            user=user,\n            session=session,\n            context=context,\n        )", "response": "Return a fully - qualified environment_context string."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef detect_intent_with_sentiment_analysis(project_id, session_id, texts,\n                                          language_code):\n    \"\"\"Returns the result of detect intent with texts as inputs and analyzes the\n    sentiment of the query text.\n\n    Using the same `session_id` between requests allows continuation\n    of the conversaion.\"\"\"\n    import dialogflow_v2beta1 as dialogflow\n    session_client = dialogflow.SessionsClient()\n\n    session_path = session_client.session_path(project_id, session_id)\n    print('Session path: {}\\n'.format(session_path))\n\n    for text in texts:\n        text_input = dialogflow.types.TextInput(\n            text=text, language_code=language_code)\n\n        query_input = dialogflow.types.QueryInput(text=text_input)\n\n        # Enable sentiment analysis\n        sentiment_config = dialogflow.types.SentimentAnalysisRequestConfig(\n            analyze_query_text_sentiment=True)\n\n        # Set the query parameters with sentiment analysis\n        query_params = dialogflow.types.QueryParameters(\n            sentiment_analysis_request_config=sentiment_config)\n\n        response = session_client.detect_intent(\n            session=session_path, query_input=query_input,\n            query_params=query_params)\n\n        print('=' * 20)\n        print('Query text: {}'.format(response.query_result.query_text))\n        print('Detected intent: {} (confidence: {})\\n'.format(\n            response.query_result.intent.display_name,\n            response.query_result.intent_detection_confidence))\n        print('Fulfillment text: {}\\n'.format(\n            response.query_result.fulfillment_text))\n        # Score between -1.0 (negative sentiment) and 1.0 (positive sentiment).\n        print('Query Text Sentiment Score: {}\\n'.format(\n            response.query_result.sentiment_analysis_result\n            .query_text_sentiment.score))\n        print('Query Text Sentiment Magnitude: {}\\n'.format(\n            response.query_result.sentiment_analysis_result\n            .query_text_sentiment.magnitude))", "response": "Returns the result of detect intent with texts as inputs and analyzes the\n    Sentiment analysis is performed on the texts."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef detect_intent(self,\n                      session,\n                      query_input,\n                      query_params=None,\n                      output_audio_config=None,\n                      input_audio=None,\n                      retry=google.api_core.gapic_v1.method.DEFAULT,\n                      timeout=google.api_core.gapic_v1.method.DEFAULT,\n                      metadata=None):\n        \"\"\"\n        Processes a natural language query and returns structured, actionable data\n        as a result. This method is not idempotent, because it may cause contexts\n        and session entity types to be updated, which in turn might affect\n        results of future queries.\n\n        Example:\n            >>> import dialogflow_v2beta1\n            >>>\n            >>> client = dialogflow_v2beta1.SessionsClient()\n            >>>\n            >>> session = client.session_path('[PROJECT]', '[SESSION]')\n            >>>\n            >>> # TODO: Initialize ``query_input``:\n            >>> query_input = {}\n            >>>\n            >>> response = client.detect_intent(session, query_input)\n\n        Args:\n            session (str): Required. The name of the session this query is sent to. Format:\n                ``projects/<Project ID>/agent/sessions/<Session ID>``, or\n                ``projects/<Project ID>/agent/environments/<Environment ID>/users/<User\n                ID>/sessions/<Session ID>``. If ``Environment ID`` is not specified, we assume\n                default 'draft' environment. If ``User ID`` is not specified, we are using\n                \\\"-\\\". It\u2019s up to the API caller to choose an appropriate ``Session ID`` and\n                ``User Id``. They can be a random numbers or some type of user and session\n                identifiers (preferably hashed). The length of the ``Session ID`` and\n                ``User ID`` must not exceed 36 characters.\n            query_input (Union[dict, ~google.cloud.dialogflow_v2beta1.types.QueryInput]): Required. The input specification. It can be set to:\n\n                1.  an audio config\n                ::\n\n                    which instructs the speech recognizer how to process the speech audio,\n\n                2.  a conversational query in the form of text, or\n\n                3.  an event that specifies which intent to trigger.\n                If a dict is provided, it must be of the same form as the protobuf\n                message :class:`~google.cloud.dialogflow_v2beta1.types.QueryInput`\n            query_params (Union[dict, ~google.cloud.dialogflow_v2beta1.types.QueryParameters]): Optional. The parameters of this query.\n                If a dict is provided, it must be of the same form as the protobuf\n                message :class:`~google.cloud.dialogflow_v2beta1.types.QueryParameters`\n            output_audio_config (Union[dict, ~google.cloud.dialogflow_v2beta1.types.OutputAudioConfig]): Optional. Instructs the speech synthesizer how to generate the output\n                audio. If this field is not set and agent-level speech synthesizer is not\n                configured, no output audio is generated.\n                If a dict is provided, it must be of the same form as the protobuf\n                message :class:`~google.cloud.dialogflow_v2beta1.types.OutputAudioConfig`\n            input_audio (bytes): Optional. The natural language speech audio to be processed. This field\n                should be populated iff ``query_input`` is set to an input audio config.\n                A single request can contain up to 1 minute of speech audio data.\n            retry (Optional[google.api_core.retry.Retry]):  A retry object used\n                to retry requests. If ``None`` is specified, requests will not\n                be retried.\n            timeout (Optional[float]): The amount of time, in seconds, to wait\n                for the request to complete. Note that if ``retry`` is\n                specified, the timeout applies to each individual attempt.\n            metadata (Optional[Sequence[Tuple[str, str]]]): Additional metadata\n                that is provided to the method.\n\n        Returns:\n            A :class:`~google.cloud.dialogflow_v2beta1.types.DetectIntentResponse` instance.\n\n        Raises:\n            google.api_core.exceptions.GoogleAPICallError: If the request\n                    failed for any reason.\n            google.api_core.exceptions.RetryError: If the request failed due\n                    to a retryable error and retry attempts failed.\n            ValueError: If the parameters are invalid.\n        \"\"\"\n        # Wrap the transport method to add retry and timeout logic.\n        if 'detect_intent' not in self._inner_api_calls:\n            self._inner_api_calls[\n                'detect_intent'] = google.api_core.gapic_v1.method.wrap_method(\n                    self.transport.detect_intent,\n                    default_retry=self._method_configs['DetectIntent'].retry,\n                    default_timeout=self._method_configs['DetectIntent']\n                    .timeout,\n                    client_info=self._client_info,\n                )\n\n        request = session_pb2.DetectIntentRequest(\n            session=session,\n            query_input=query_input,\n            query_params=query_params,\n            output_audio_config=output_audio_config,\n            input_audio=input_audio,\n        )\n        return self._inner_api_calls['detect_intent'](\n            request, retry=retry, timeout=timeout, metadata=metadata)", "response": "This method handles a natural language query and returns structured actionable data structure for the specified language entity type."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the result of detect intent with streaming audio as input.", "response": "def detect_intent_stream(project_id, session_id, audio_file_path,\n                         language_code):\n    \"\"\"Returns the result of detect intent with streaming audio as input.\n\n    Using the same `session_id` between requests allows continuation\n    of the conversaion.\"\"\"\n    import dialogflow_v2 as dialogflow\n    session_client = dialogflow.SessionsClient()\n\n    # Note: hard coding audio_encoding and sample_rate_hertz for simplicity.\n    audio_encoding = dialogflow.enums.AudioEncoding.AUDIO_ENCODING_LINEAR_16\n    sample_rate_hertz = 16000\n\n    session_path = session_client.session_path(project_id, session_id)\n    print('Session path: {}\\n'.format(session_path))\n\n    def request_generator(audio_config, audio_file_path):\n        query_input = dialogflow.types.QueryInput(audio_config=audio_config)\n\n        # The first request contains the configuration.\n        yield dialogflow.types.StreamingDetectIntentRequest(\n            session=session_path, query_input=query_input)\n\n        # Here we are reading small chunks of audio data from a local\n        # audio file.  In practice these chunks should come from\n        # an audio input device.\n        with open(audio_file_path, 'rb') as audio_file:\n            while True:\n                chunk = audio_file.read(4096)\n                if not chunk:\n                    break\n                # The later requests contains audio data.\n                yield dialogflow.types.StreamingDetectIntentRequest(\n                    input_audio=chunk)\n\n    audio_config = dialogflow.types.InputAudioConfig(\n        audio_encoding=audio_encoding, language_code=language_code,\n        sample_rate_hertz=sample_rate_hertz)\n\n    requests = request_generator(audio_config, audio_file_path)\n    responses = session_client.streaming_detect_intent(requests)\n\n    print('=' * 20)\n    for response in responses:\n        print('Intermediate transcript: \"{}\".'.format(\n                response.recognition_result.transcript))\n\n    # Note: The result from the last response is the final transcript along\n    # with the detected content.\n    query_result = response.query_result\n\n    print('=' * 20)\n    print('Query text: {}'.format(query_result.query_text))\n    print('Detected intent: {} (confidence: {})\\n'.format(\n        query_result.intent.display_name,\n        query_result.intent_detection_confidence))\n    print('Fulfillment text: {}\\n'.format(\n        query_result.fulfillment_text))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_intent(project_id, display_name, training_phrases_parts,\n                  message_texts):\n    \"\"\"Create an intent of the given intent type.\"\"\"\n    import dialogflow_v2 as dialogflow\n    intents_client = dialogflow.IntentsClient()\n\n    parent = intents_client.project_agent_path(project_id)\n    training_phrases = []\n    for training_phrases_part in training_phrases_parts:\n        part = dialogflow.types.Intent.TrainingPhrase.Part(\n            text=training_phrases_part)\n        # Here we create a new training phrase for each provided part.\n        training_phrase = dialogflow.types.Intent.TrainingPhrase(parts=[part])\n        training_phrases.append(training_phrase)\n\n    text = dialogflow.types.Intent.Message.Text(text=message_texts)\n    message = dialogflow.types.Intent.Message(text=text)\n\n    intent = dialogflow.types.Intent(\n        display_name=display_name,\n        training_phrases=training_phrases,\n        messages=[message])\n\n    response = intents_client.create_intent(parent, intent)\n\n    print('Intent created: {}'.format(response))", "response": "Create an intent of the given intent type."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete_intent(project_id, intent_id):\n    import dialogflow_v2 as dialogflow\n    intents_client = dialogflow.IntentsClient()\n\n    intent_path = intents_client.intent_path(project_id, intent_id)\n\n    intents_client.delete_intent(intent_path)", "response": "Delete intent with the given intent type and intent value."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_agent(self,\n                  parent,\n                  retry=google.api_core.gapic_v1.method.DEFAULT,\n                  timeout=google.api_core.gapic_v1.method.DEFAULT,\n                  metadata=None):\n        \"\"\"\n        Retrieves the specified agent.\n\n        Example:\n            >>> import dialogflow_v2\n            >>>\n            >>> client = dialogflow_v2.AgentsClient()\n            >>>\n            >>> parent = client.project_path('[PROJECT]')\n            >>>\n            >>> response = client.get_agent(parent)\n\n        Args:\n            parent (str): Required. The project that the agent to fetch is associated with.\n                Format: ``projects/<Project ID>``.\n            retry (Optional[google.api_core.retry.Retry]):  A retry object used\n                to retry requests. If ``None`` is specified, requests will not\n                be retried.\n            timeout (Optional[float]): The amount of time, in seconds, to wait\n                for the request to complete. Note that if ``retry`` is\n                specified, the timeout applies to each individual attempt.\n            metadata (Optional[Sequence[Tuple[str, str]]]): Additional metadata\n                that is provided to the method.\n\n        Returns:\n            A :class:`~google.cloud.dialogflow_v2.types.Agent` instance.\n\n        Raises:\n            google.api_core.exceptions.GoogleAPICallError: If the request\n                    failed for any reason.\n            google.api_core.exceptions.RetryError: If the request failed due\n                    to a retryable error and retry attempts failed.\n            ValueError: If the parameters are invalid.\n        \"\"\"\n        # Wrap the transport method to add retry and timeout logic.\n        if 'get_agent' not in self._inner_api_calls:\n            self._inner_api_calls[\n                'get_agent'] = google.api_core.gapic_v1.method.wrap_method(\n                    self.transport.get_agent,\n                    default_retry=self._method_configs['GetAgent'].retry,\n                    default_timeout=self._method_configs['GetAgent'].timeout,\n                    client_info=self._client_info,\n                )\n\n        request = agent_pb2.GetAgentRequest(parent=parent, )\n        return self._inner_api_calls['get_agent'](\n            request, retry=retry, timeout=timeout, metadata=metadata)", "response": "Retrieves the specified agent."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntrain the specified agent.", "response": "def train_agent(self,\n                    parent,\n                    retry=google.api_core.gapic_v1.method.DEFAULT,\n                    timeout=google.api_core.gapic_v1.method.DEFAULT,\n                    metadata=None):\n        \"\"\"\n        Trains the specified agent.\n\n        Operation <response: ``google.protobuf.Empty``,\n        metadata: [google.protobuf.Struct][google.protobuf.Struct]>\n\n        Example:\n            >>> import dialogflow_v2\n            >>>\n            >>> client = dialogflow_v2.AgentsClient()\n            >>>\n            >>> parent = client.project_path('[PROJECT]')\n            >>>\n            >>> response = client.train_agent(parent)\n            >>>\n            >>> def callback(operation_future):\n            ...     # Handle result.\n            ...     result = operation_future.result()\n            >>>\n            >>> response.add_done_callback(callback)\n            >>>\n            >>> # Handle metadata.\n            >>> metadata = response.metadata()\n\n        Args:\n            parent (str): Required. The project that the agent to train is associated with.\n                Format: ``projects/<Project ID>``.\n            retry (Optional[google.api_core.retry.Retry]):  A retry object used\n                to retry requests. If ``None`` is specified, requests will not\n                be retried.\n            timeout (Optional[float]): The amount of time, in seconds, to wait\n                for the request to complete. Note that if ``retry`` is\n                specified, the timeout applies to each individual attempt.\n            metadata (Optional[Sequence[Tuple[str, str]]]): Additional metadata\n                that is provided to the method.\n\n        Returns:\n            A :class:`~google.cloud.dialogflow_v2.types._OperationFuture` instance.\n\n        Raises:\n            google.api_core.exceptions.GoogleAPICallError: If the request\n                    failed for any reason.\n            google.api_core.exceptions.RetryError: If the request failed due\n                    to a retryable error and retry attempts failed.\n            ValueError: If the parameters are invalid.\n        \"\"\"\n        # Wrap the transport method to add retry and timeout logic.\n        if 'train_agent' not in self._inner_api_calls:\n            self._inner_api_calls[\n                'train_agent'] = google.api_core.gapic_v1.method.wrap_method(\n                    self.transport.train_agent,\n                    default_retry=self._method_configs['TrainAgent'].retry,\n                    default_timeout=self._method_configs['TrainAgent'].timeout,\n                    client_info=self._client_info,\n                )\n\n        request = agent_pb2.TrainAgentRequest(parent=parent, )\n        operation = self._inner_api_calls['train_agent'](\n            request, retry=retry, timeout=timeout, metadata=metadata)\n        return google.api_core.operation.from_gapic(\n            operation,\n            self.transport._operations_client,\n            empty_pb2.Empty,\n            metadata_type=struct_pb2.Struct,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef export_agent(self,\n                     parent,\n                     agent_uri=None,\n                     retry=google.api_core.gapic_v1.method.DEFAULT,\n                     timeout=google.api_core.gapic_v1.method.DEFAULT,\n                     metadata=None):\n        \"\"\"\n        Exports the specified agent to a ZIP file.\n\n        Operation <response: ``ExportAgentResponse``,\n        metadata: [google.protobuf.Struct][google.protobuf.Struct]>\n\n        Example:\n            >>> import dialogflow_v2\n            >>>\n            >>> client = dialogflow_v2.AgentsClient()\n            >>>\n            >>> parent = client.project_path('[PROJECT]')\n            >>>\n            >>> response = client.export_agent(parent)\n            >>>\n            >>> def callback(operation_future):\n            ...     # Handle result.\n            ...     result = operation_future.result()\n            >>>\n            >>> response.add_done_callback(callback)\n            >>>\n            >>> # Handle metadata.\n            >>> metadata = response.metadata()\n\n        Args:\n            parent (str): Required. The project that the agent to export is associated with.\n                Format: ``projects/<Project ID>``.\n            agent_uri (str): Optional. The Google Cloud Storage URI to export the agent to.\n                Note: The URI must start with\n                \\\"gs://\\\". If left unspecified, the serialized agent is returned inline.\n            retry (Optional[google.api_core.retry.Retry]):  A retry object used\n                to retry requests. If ``None`` is specified, requests will not\n                be retried.\n            timeout (Optional[float]): The amount of time, in seconds, to wait\n                for the request to complete. Note that if ``retry`` is\n                specified, the timeout applies to each individual attempt.\n            metadata (Optional[Sequence[Tuple[str, str]]]): Additional metadata\n                that is provided to the method.\n\n        Returns:\n            A :class:`~google.cloud.dialogflow_v2.types._OperationFuture` instance.\n\n        Raises:\n            google.api_core.exceptions.GoogleAPICallError: If the request\n                    failed for any reason.\n            google.api_core.exceptions.RetryError: If the request failed due\n                    to a retryable error and retry attempts failed.\n            ValueError: If the parameters are invalid.\n        \"\"\"\n        # Wrap the transport method to add retry and timeout logic.\n        if 'export_agent' not in self._inner_api_calls:\n            self._inner_api_calls[\n                'export_agent'] = google.api_core.gapic_v1.method.wrap_method(\n                    self.transport.export_agent,\n                    default_retry=self._method_configs['ExportAgent'].retry,\n                    default_timeout=self._method_configs['ExportAgent']\n                    .timeout,\n                    client_info=self._client_info,\n                )\n\n        request = agent_pb2.ExportAgentRequest(\n            parent=parent,\n            agent_uri=agent_uri,\n        )\n        operation = self._inner_api_calls['export_agent'](\n            request, retry=retry, timeout=timeout, metadata=metadata)\n        return google.api_core.operation.from_gapic(\n            operation,\n            self.transport._operations_client,\n            agent_pb2.ExportAgentResponse,\n            metadata_type=struct_pb2.Struct,\n        )", "response": "Exports the specified agent to a ZIP file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef import_agent(self,\n                     parent,\n                     agent_uri=None,\n                     agent_content=None,\n                     retry=google.api_core.gapic_v1.method.DEFAULT,\n                     timeout=google.api_core.gapic_v1.method.DEFAULT,\n                     metadata=None):\n        \"\"\"\n        Imports the specified agent from a ZIP file.\n\n        Uploads new intents and entity types without deleting the existing ones.\n        Intents and entity types with the same name are replaced with the new\n        versions from ImportAgentRequest.\n\n        Operation <response: ``google.protobuf.Empty``,\n        metadata: [google.protobuf.Struct][google.protobuf.Struct]>\n\n        Example:\n            >>> import dialogflow_v2\n            >>>\n            >>> client = dialogflow_v2.AgentsClient()\n            >>>\n            >>> parent = client.project_path('[PROJECT]')\n            >>>\n            >>> response = client.import_agent(parent)\n            >>>\n            >>> def callback(operation_future):\n            ...     # Handle result.\n            ...     result = operation_future.result()\n            >>>\n            >>> response.add_done_callback(callback)\n            >>>\n            >>> # Handle metadata.\n            >>> metadata = response.metadata()\n\n        Args:\n            parent (str): Required. The project that the agent to import is associated with.\n                Format: ``projects/<Project ID>``.\n            agent_uri (str): The URI to a Google Cloud Storage file containing the agent to import.\n                Note: The URI must start with \\\"gs://\\\".\n            agent_content (bytes): The agent to import.\n\n                Example for how to import an agent via the command line:\n\n                curl \\\n                  'https://dialogflow.googleapis.com/v2/projects/<project_name>/agent:import\\\n                   -X POST \\\n                   -H 'Authorization: Bearer '$(gcloud auth print-access-token) \\\n                   -H 'Accept: application/json' \\\n                   -H 'Content-Type: application/json' \\\n                   --compressed \\\n                   --data-binary \\\"{\n                ::\n\n                      'agentContent': '$(cat <agent zip file> | base64 -w 0)'\n                   }\\\"\n            retry (Optional[google.api_core.retry.Retry]):  A retry object used\n                to retry requests. If ``None`` is specified, requests will not\n                be retried.\n            timeout (Optional[float]): The amount of time, in seconds, to wait\n                for the request to complete. Note that if ``retry`` is\n                specified, the timeout applies to each individual attempt.\n            metadata (Optional[Sequence[Tuple[str, str]]]): Additional metadata\n                that is provided to the method.\n\n        Returns:\n            A :class:`~google.cloud.dialogflow_v2.types._OperationFuture` instance.\n\n        Raises:\n            google.api_core.exceptions.GoogleAPICallError: If the request\n                    failed for any reason.\n            google.api_core.exceptions.RetryError: If the request failed due\n                    to a retryable error and retry attempts failed.\n            ValueError: If the parameters are invalid.\n        \"\"\"\n        # Wrap the transport method to add retry and timeout logic.\n        if 'import_agent' not in self._inner_api_calls:\n            self._inner_api_calls[\n                'import_agent'] = google.api_core.gapic_v1.method.wrap_method(\n                    self.transport.import_agent,\n                    default_retry=self._method_configs['ImportAgent'].retry,\n                    default_timeout=self._method_configs['ImportAgent']\n                    .timeout,\n                    client_info=self._client_info,\n                )\n\n        # Sanity check: We have some fields which are mutually exclusive;\n        # raise ValueError if more than one is sent.\n        google.api_core.protobuf_helpers.check_oneof(\n            agent_uri=agent_uri,\n            agent_content=agent_content,\n        )\n\n        request = agent_pb2.ImportAgentRequest(\n            parent=parent,\n            agent_uri=agent_uri,\n            agent_content=agent_content,\n        )\n        operation = self._inner_api_calls['import_agent'](\n            request, retry=retry, timeout=timeout, metadata=metadata)\n        return google.api_core.operation.from_gapic(\n            operation,\n            self.transport._operations_client,\n            empty_pb2.Empty,\n            metadata_type=struct_pb2.Struct,\n        )", "response": "Imports the specified agent from a ZIP file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef list_documents(project_id, knowledge_base_id):\n    import dialogflow_v2beta1 as dialogflow\n    client = dialogflow.DocumentsClient()\n    knowledge_base_path = client.knowledge_base_path(project_id,\n                                                     knowledge_base_id)\n\n    print('Documents for Knowledge Id: {}'.format(knowledge_base_id))\n    for document in client.list_documents(knowledge_base_path):\n        print(' - Display Name: {}'.format(document.display_name))\n        print(' - Knowledge ID: {}'.format(document.name))\n        print(' - MIME Type: {}'.format(document.mime_type))\n        print(' - Knowledge Types:')\n        for knowledge_type in document.knowledge_types:\n            print('    - {}'.format(KNOWLEDGE_TYPES[knowledge_type]))\n        print(' - Source: {}\\n'.format(document.content_uri))", "response": "Lists the Documents belonging to a Knowledge base."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new Knowledge base Document.", "response": "def create_document(project_id, knowledge_base_id, display_name, mime_type,\n                    knowledge_type, content_uri):\n    \"\"\"Creates a Document.\n\n    Args:\n        project_id: The GCP project linked with the agent.\n        knowledge_base_id: Id of the Knowledge base.\n        display_name: The display name of the Document.\n        mime_type: The mime_type of the Document. e.g. text/csv, text/html,\n            text/plain, text/pdf etc.\n        knowledge_type: The Knowledge type of the Document. e.g. FAQ,\n            EXTRACTIVE_QA.\n        content_uri: Uri of the document, e.g. gs://path/mydoc.csv,\n            http://mypage.com/faq.html.\"\"\"\n    import dialogflow_v2beta1 as dialogflow\n    client = dialogflow.DocumentsClient()\n    knowledge_base_path = client.knowledge_base_path(project_id,\n                                                     knowledge_base_id)\n\n    document = dialogflow.types.Document(\n        display_name=display_name, mime_type=mime_type,\n        content_uri=content_uri)\n\n    document.knowledge_types.append(\n        dialogflow.types.Document.KnowledgeType.Value(knowledge_type))\n\n    response = client.create_document(knowledge_base_path, document)\n    print('Waiting for results...')\n    document = response.result(timeout=90)\n    print('Created Document:')\n    print(' - Display Name: {}'.format(document.display_name))\n    print(' - Knowledge ID: {}'.format(document.name))\n    print(' - MIME Type: {}'.format(document.mime_type))\n    print(' - Knowledge Types:')\n    for knowledge_type in document.knowledge_types:\n        print('    - {}'.format(KNOWLEDGE_TYPES[knowledge_type]))\n    print(' - Source: {}\\n'.format(document.content_uri))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget a Document. Args: project_id: The GCP project linked with the agent. knowledge_base_id: Id of the Knowledge base. document_id: Id of the Document.", "response": "def get_document(project_id, knowledge_base_id, document_id):\n    \"\"\"Gets a Document.\n\n    Args:\n        project_id: The GCP project linked with the agent.\n        knowledge_base_id: Id of the Knowledge base.\n        document_id: Id of the Document.\"\"\"\n    import dialogflow_v2beta1 as dialogflow\n    client = dialogflow.DocumentsClient()\n    document_path = client.document_path(project_id, knowledge_base_id,\n                                         document_id)\n\n    response = client.get_document(document_path)\n    print('Got Document:')\n    print(' - Display Name: {}'.format(response.display_name))\n    print(' - Knowledge ID: {}'.format(response.name))\n    print(' - MIME Type: {}'.format(response.mime_type))\n    print(' - Knowledge Types:')\n    for knowledge_type in response.knowledge_types:\n        print('    - {}'.format(KNOWLEDGE_TYPES[knowledge_type]))\n    print(' - Source: {}\\n'.format(response.content_uri))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delete_document(project_id, knowledge_base_id, document_id):\n    import dialogflow_v2beta1 as dialogflow\n    client = dialogflow.DocumentsClient()\n    document_path = client.document_path(project_id, knowledge_base_id,\n                                         document_id)\n\n    response = client.delete_document(document_path)\n    print('operation running:\\n {}'.format(response.operation))\n    print('Waiting for results...')\n    print('Done.\\n {}'.format(response.result()))", "response": "Deletes a Document.\n\n    Args:\n        project_id: The GCP project linked with the agent.\n        knowledge_base_id: Id of the Knowledge base.\n        document_id: Id of the Document."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates an entity of the given entity type.", "response": "def create_entity(project_id, entity_type_id, entity_value, synonyms):\n    \"\"\"Create an entity of the given entity type.\"\"\"\n    import dialogflow_v2 as dialogflow\n    entity_types_client = dialogflow.EntityTypesClient()\n\n    # Note: synonyms must be exactly [entity_value] if the\n    # entity_type's kind is KIND_LIST\n    synonyms = synonyms or [entity_value]\n\n    entity_type_path = entity_types_client.entity_type_path(\n        project_id, entity_type_id)\n\n    entity = dialogflow.types.EntityType.Entity()\n    entity.value = entity_value\n    entity.synonyms.extend(synonyms)\n\n    response = entity_types_client.batch_create_entities(\n        entity_type_path, [entity])\n\n    print('Entity created: {}'.format(response))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndeletes entity with the given entity type and entity value.", "response": "def delete_entity(project_id, entity_type_id, entity_value):\n    \"\"\"Delete entity with the given entity type and entity value.\"\"\"\n    import dialogflow_v2 as dialogflow\n    entity_types_client = dialogflow.EntityTypesClient()\n\n    entity_type_path = entity_types_client.entity_type_path(\n        project_id, entity_type_id)\n\n    entity_types_client.batch_delete_entities(\n        entity_type_path, [entity_value])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef choose(self, n):\n        args = self._argchoose(n, absolute=True)\n        columns = (self.content[args.content[c]] for c in args.columns)\n        out = self.JaggedArray.fromoffsets(args.offsets, self.Table.named(\"tuple\", *columns).flattentuple())\n        return out", "response": "Return all unique combinations of n elements from the jagged dimension."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning all unique combinations of two elements taken without replacement from the indices of the jagged dimension.", "response": "def argdistincts(self, nested=False):\n        \"\"\"\n        Return all unique combinations (up to permutation) of two elements,\n        taken without replacement from the indices of the jagged dimension.\n        Combinations are ordered lexicographically.\n        nested: Return a doubly-jagged array where the first jagged dimension\n        matches the shape of this array\n        \"\"\"\n        out = self._argdistincts(absolute=False)\n\n        if nested:\n            out = self.JaggedArray.fromcounts(self.numpy.maximum(0, self.counts - 1), self.JaggedArray.fromcounts(self.index[:, :0:-1].flatten(), out._content))\n\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning all unique combinations of two elements taken without replacement from the contents of the jagged dimension.", "response": "def distincts(self, nested=False):\n        \"\"\"\n        Return all unique combinations (up to permutation) of two elements,\n        taken without replacement from the contents of the jagged dimension.\n        Combinations are ordered lexicographically.\n        nested: Return a doubly-jagged array where the first jagged dimension\n        matches the shape of this array\n        \"\"\"\n        argpairs = self._argdistincts(absolute=True)\n        left = argpairs._content[\"0\"]\n        right = argpairs._content[\"1\"]\n\n        out = self.JaggedArray.fromoffsets(argpairs.offsets, self.Table.named(\"tuple\", self._content[left], self._content[right]).flattentuple())\n        out._parents = argpairs._parents\n\n        if nested:\n            out = self.JaggedArray.fromcounts(self.numpy.maximum(0, self.counts - 1), self.JaggedArray.fromcounts(self.index[:, :0:-1].flatten(), out._content))\n\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef unary_from_labels(labels, n_labels, gt_prob, zero_unsure=True):\n    assert 0 < gt_prob < 1, \"`gt_prob must be in (0,1).\"\n\n    labels = labels.flatten()\n\n    n_energy = -np.log((1.0 - gt_prob) / (n_labels - 1))\n    p_energy = -np.log(gt_prob)\n\n    # Note that the order of the following operations is important.\n    # That's because the later ones overwrite part of the former ones, and only\n    # after all of them is `U` correct!\n    U = np.full((n_labels, len(labels)), n_energy, dtype='float32')\n    U[labels - 1 if zero_unsure else labels, np.arange(U.shape[1])] = p_energy\n\n    # Overwrite 0-labels using uniform probability, i.e. \"unsure\".\n    if zero_unsure:\n        U[:, labels == 0] = -np.log(1.0 / n_labels)\n\n    return U", "response": "Simple classifier that is 50% certain that the annotation is correct."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef unary_from_softmax(sm, scale=None, clip=1e-5):\n    num_cls = sm.shape[0]\n    if scale is not None:\n        assert 0 < scale <= 1, \"`scale` needs to be in (0,1]\"\n        uniform = np.ones(sm.shape) / num_cls\n        sm = scale * sm + (1 - scale) * uniform\n    if clip is not None:\n        sm = np.clip(sm, clip, 1.0)\n    return -np.log(sm).reshape([num_cls, -1]).astype(np.float32)", "response": "Converts a softmax class - probabilities to unary potentials."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndeprecate use unary_from_softmax instead.", "response": "def softmax_to_unary(sm, GT_PROB=1):\n    \"\"\"Deprecated, use `unary_from_softmax` instead.\"\"\"\n    warning(\"pydensecrf.softmax_to_unary is deprecated, use unary_from_softmax instead.\")\n    scale = None if GT_PROB == 1 else GT_PROB\n    return unary_from_softmax(sm, scale, clip=None)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a 2D array of the same shape as the input.", "response": "def _create_pairwise_gaussian_2d(sx, sy, shape):\n    \"\"\"\n    A simple reference implementation for the 2D case. The ND implementation\n    is faster.\n    \"\"\"\n    feat_size = 2\n    feats = np.zeros((feat_size, shape[0], shape[1]), dtype=np.float32)\n    for i in range(shape[0]):\n        for j in range(shape[1]):\n            feats[0, i, j] = i / sx\n            feats[1, i, j] = j / sy\n    return feats.reshape([feat_size, -1])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a 2D feature array for pairwise bilateral.", "response": "def _create_pairwise_bilateral_2d(sx, sy, sr, sg, sb, img):\n    \"\"\"\n    A simple reference implementation for the 2D case. The ND implementation\n    is faster.\n    \"\"\"\n    feat_size = 5\n    feats = np.zeros((feat_size, img.shape[0], img.shape[1]), dtype=np.float32)\n    for i in range(img.shape[0]):\n        for j in range(img.shape[1]):\n            feats[0, i, j] = i / sx\n            feats[1, i, j] = j / sy\n            feats[2, i, j] = img[i, j, 0] / sr\n            feats[3, i, j] = img[i, j, 1] / sg\n            feats[4, i, j] = img[i, j, 2] / sb\n    return feats.reshape([feat_size, -1])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef to_string(self):\n        buff = u\"\"\n        for child in self.content.iter():\n            if child.tag in [self.qn('text:p'), self.qn('text:h')]:\n                buff += self.text_to_string(child) + \"\\n\"\n        # remove last newline char\n        if buff:\n            buff = buff[:-1]\n        return buff", "response": "Converts the document to a string."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef qn(self, namespace):\n        nsmap = {\n            'text': 'urn:oasis:names:tc:opendocument:xmlns:text:1.0',\n        }\n        spl = namespace.split(':')\n        return '{{{}}}{}'.format(nsmap[spl[0]], spl[1])", "response": "Connect tag prefix to longer namespace"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_parser():\n\n    # initialize the parser\n    parser = argparse.ArgumentParser(\n        description=(\n            'Command line tool for extracting text from any document. '\n        ) % locals(),\n    )\n\n    # define the command line options here\n    parser.add_argument(\n        'filename', help='Filename to extract text.',\n    ).completer = argcomplete.completers.FilesCompleter\n    parser.add_argument(\n        '-e', '--encoding', type=str, default=DEFAULT_ENCODING,\n        choices=_get_available_encodings(),\n        help='Specify the encoding of the output.',\n    )\n    parser.add_argument(\n        '--extension', type=str, default=None,\n        choices=_get_available_extensions(),\n        help='Specify the extension of the file.',\n    )\n    parser.add_argument(\n        '-m', '--method', default='',\n        help='Specify a method of extraction for formats that support it',\n    )\n    parser.add_argument(\n        '-o', '--output', type=FileType('wb'), default='-',\n        help='Output raw text in this file',\n    )\n    parser.add_argument(\n        '-O', '--option', type=str, action=AddToNamespaceAction,\n        help=(\n            'Add arbitrary options to various parsers of the form '\n            'KEYWORD=VALUE. A full list of available KEYWORD options is '\n            'available at http://bit.ly/textract-options'\n        ),\n    )\n    parser.add_argument(\n        '-v', '--version', action='version', version='%(prog)s '+VERSION,\n    )\n\n    # enable autocompletion with argcomplete\n    argcomplete.autocomplete(parser)\n\n    return parser", "response": "Initialize the parser for the command line interface and bind the automatic autocompletion functionality functionality"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_available_encodings():\n    available_encodings = set(encodings.aliases.aliases.values())\n    paths = [os.path.dirname(encodings.__file__)]\n    for importer, modname, ispkg in pkgutil.walk_packages(path=paths):\n        available_encodings.add(modname)\n    available_encodings = list(available_encodings)\n    available_encodings.sort()\n    return available_encodings", "response": "Get a list of the available encodings to make it easy to\n    tab - complete the command line interface."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_text(self, deserialized_json):\n        if isinstance(deserialized_json, dict):\n            result = ''\n            for key in sorted(deserialized_json):\n                result += self.get_text(deserialized_json[key]) + ' '\n            return result\n\n        if isinstance(deserialized_json, list):\n            result = ''\n            for item in deserialized_json:\n                result += self.get_text(item) + ' '\n            return result\n\n        if isinstance(deserialized_json, six.string_types):\n            return deserialized_json\n        else:\n            return ''", "response": "Recursively get text from a deserialized json."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef extract_pdftotext(self, filename, **kwargs):\n        if 'layout' in kwargs:\n            args = ['pdftotext', '-layout', filename, '-']\n        else:\n            args = ['pdftotext', filename, '-']\n        stdout, _ = self.run(args)\n        return stdout", "response": "Extract text from pdfs using the pdftotext command line utility."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nextract text from pdfs using pdfminer.", "response": "def extract_pdfminer(self, filename, **kwargs):\n        \"\"\"Extract text from pdfs using pdfminer.\"\"\"\n        stdout, _ = self.run(['pdf2txt.py', filename])\n        return stdout"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef extract_tesseract(self, filename, **kwargs):\n        temp_dir = mkdtemp()\n        base = os.path.join(temp_dir, 'conv')\n        contents = []\n        try:\n            stdout, _ = self.run(['pdftoppm', filename, base])\n\n            for page in sorted(os.listdir(temp_dir)):\n                page_path = os.path.join(temp_dir, page)\n                page_content = TesseractParser().extract(page_path, **kwargs)\n                contents.append(page_content)\n            return six.b('').join(contents)\n        finally:\n            shutil.rmtree(temp_dir)", "response": "Extract text from pdfs using tesseract."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts audio file to. wav", "response": "def convert_to_wav(self, filename):\n        \"\"\"\n        Uses sox cmdline tool, to convert audio file to .wav\n\n        Note: for testing, use -\n        http://www.text2speech.org/,\n        with American Male 2 for best results\n        \"\"\"\n        temp_filename = '{0}.wav'.format(self.temp_filename())\n        self.run(['sox', '-G', '-c', '1', filename, temp_filename])\n        return temp_filename"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning True if the element is visible.", "response": "def _visible(self, element):\n        \"\"\"Used to filter text elements that have invisible text on the page.\n        \"\"\"\n        if element.name in self._disallowed_names:\n            return False\n        elif re.match(u'<!--.*-->', six.text_type(element.extract())):\n            return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nlooking for any possible text within given tag.", "response": "def _find_any_text(self, tag):\n        \"\"\"Looks for any possible text within given tag.\n        \"\"\"\n        text = ''\n        if tag is not None:\n            text = six.text_type(tag)\n            text = re.sub(r'(<[^>]+>)', '', text)\n            text = re.sub(r'\\s', ' ', text)\n            text = text.strip()\n        return text"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse the ASCII tables in the page and returns a list of dicts.", "response": "def _parse_tables(self, soup):\n        \"\"\"Returns array containing basic informations about tables for ASCII\n        replacement (look: _replace_tables()).\n        \"\"\"\n        tables = []\n        for t in soup.find_all('table'):\n            t_dict = {'width': 0, 'table': t, 'trs': [], 'col_width': {}}\n            trs = t.find_all('tr')\n            if len(trs) > 0:\n                for tr in trs:\n                    tr_dict = []\n                    tds = tr.find_all('th') + tr.find_all('td')\n                    if len(tds) > 0:\n                        for i, td in enumerate(tds):\n                            td_text = self._find_any_text(td)\n                            length = len(td_text)\n                            if i in t_dict['col_width']:\n                                t_dict['col_width'][i] = max(\n                                    length,\n                                    t_dict['col_width'][i]\n                                )\n                            else:\n                                t_dict['col_width'][i] = length\n                            tr_dict.append({\n                                'text': td_text,\n                                'colspan': int(td.get('colspan', 1)),\n                            })\n                        t_dict['trs'].append(tr_dict)\n                for col in t_dict['col_width']:\n                    t_dict['width'] += t_dict['col_width'][col]\n                tables.append(t_dict)\n        return tables"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreplace all tables in the given soup with their ASCII equivalent.", "response": "def _replace_tables(self, soup, v_separator=' | ', h_separator='-'):\n        \"\"\"Replaces <table> elements with its ASCII equivalent.\n        \"\"\"\n        tables = self._parse_tables(soup)\n        v_sep_len = len(v_separator)\n        v_left_sep = v_separator.lstrip()\n        for t in tables:\n            html = ''\n            trs = t['trs']\n            h_length = 1 + (v_sep_len * len(t['col_width'])) + t['width']\n            head_foot = (h_separator * h_length) + \"\\n\"\n            html += head_foot\n            for tr in trs:\n                html += v_left_sep\n                for i, td in enumerate(tr):\n                    text = td['text']\n                    col_width = t['col_width'][i] + v_sep_len\n                    if td['colspan'] > 1:\n                        for j in range(td['colspan']-1):\n                            j = j + 1\n                            if (i+j) < len(t['col_width']):\n                                col_width += t['col_width'][i+j] + v_sep_len\n                    html += ('%' + str(col_width) + 's') % (text + v_separator)\n                html += \"\\n\"\n            html += head_foot\n            new_table = soup.new_tag('div')\n            new_table.string = html\n            t['table'].replace_with(new_table)\n        return soup"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nunwrap inline elements defined in self. _inline_tags.", "response": "def _join_inlines(self, soup):\n        \"\"\"Unwraps inline elements defined in self._inline_tags.\n        \"\"\"\n        elements = soup.find_all(True)\n        for elem in elements:\n            if self._inline(elem):\n                elem.unwrap()\n        return soup"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef process(self, filename, encoding, **kwargs):\n        # make a \"unicode sandwich\" to handle dealing with unknown\n        # input byte strings and converting them to a predictable\n        # output encoding\n        # http://nedbatchelder.com/text/unipain/unipain.html#35\n        byte_string = self.extract(filename, **kwargs)\n        unicode_string = self.decode(byte_string)\n        return self.encode(unicode_string, encoding)", "response": "Process filename and encode byte - string with encoding."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef decode(self, text):\n        # only decode byte strings into unicode if it hasn't already\n        # been done by a subclass\n        if isinstance(text, six.text_type):\n            return text\n\n        # empty text? nothing to decode\n        if not text:\n            return u''\n\n        # use chardet to automatically detect the encoding text\n        result = chardet.detect(text)\n        return text.decode(result['encoding'])", "response": "Decode the given text using the Chardet encoding."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run(self, args):\n\n        # run a subprocess and put the stdout and stderr on the pipe object\n        try:\n            pipe = subprocess.Popen(\n                args,\n                stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n            )\n        except OSError as e:\n            if e.errno == errno.ENOENT:\n                # File not found.\n                # This is equivalent to getting exitcode 127 from sh\n                raise exceptions.ShellError(\n                    ' '.join(args), 127, '', '',\n                )\n\n        # pipe.wait() ends up hanging on large files. using\n        # pipe.communicate appears to avoid this issue\n        stdout, stderr = pipe.communicate()\n\n        # if pipe is busted, raise an error (unlike Fabric)\n        if pipe.returncode != 0:\n            raise exceptions.ShellError(\n                ' '.join(args), pipe.returncode, stdout, stderr,\n            )\n\n        return stdout, stderr", "response": "Run command and return the subsequent stdout and stderr as a tuple."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef temp_filename(self):\n        # TODO: it would be nice to get this to behave more like a\n        # context so we can make sure these temporary files are\n        # removed, regardless of whether an error occurs or the\n        # program is terminated.\n        handle, filename = tempfile.mkstemp()\n        os.close(handle)\n        return filename", "response": "Return a unique tempfile name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef process(filename, encoding=DEFAULT_ENCODING, extension=None, **kwargs):\n\n    # make sure the filename exists\n    if not os.path.exists(filename):\n        raise exceptions.MissingFileError(filename)\n\n    # get the filename extension, which is something like .docx for\n    # example, and import the module dynamically using importlib. This\n    # is a relative import so the name of the package is necessary\n    # normally, file extension will be extracted from the file name\n    # if the file name has no extension, then the user can pass the\n    # extension as an argument\n    if extension:\n        ext = extension\n        # check if the extension has the leading .\n        if not ext.startswith('.'):\n            ext = '.' + ext\n        ext = ext.lower()\n    else:\n        _, ext = os.path.splitext(filename)\n        ext = ext.lower()\n\n    # check the EXTENSION_SYNONYMS dictionary\n    ext = EXTENSION_SYNONYMS.get(ext, ext)\n\n    # to avoid conflicts with packages that are installed globally\n    # (e.g. python's json module), all extension parser modules have\n    # the _parser extension\n    rel_module = ext + _FILENAME_SUFFIX\n\n    # If we can't import the module, the file extension isn't currently\n    # supported\n    try:\n        filetype_module = importlib.import_module(\n            rel_module, 'textract.parsers'\n        )\n    except ImportError:\n        raise exceptions.ExtensionNotSupported(ext)\n\n    # do the extraction\n\n    parser = filetype_module.Parser()\n    return parser.process(filename, encoding, **kwargs)", "response": "This function is used to extract text from a file. It uses the file extension to determine the parser module and the file name of the file and returns the extracted text as a byte - string encoded with encoding."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_available_extensions():\n    extensions = []\n\n    # from filenames\n    parsers_dir = os.path.join(os.path.dirname(__file__))\n    glob_filename = os.path.join(parsers_dir, \"*\" + _FILENAME_SUFFIX + \".py\")\n    ext_re = re.compile(glob_filename.replace('*', \"(?P<ext>\\w+)\"))\n    for filename in glob.glob(glob_filename):\n        ext_match = ext_re.match(filename)\n        ext = ext_match.groups()[0]\n        extensions.append(ext)\n        extensions.append('.' + ext)\n\n    # from relevant synonyms (don't use the '' synonym)\n    for ext in EXTENSION_SYNONYMS.keys():\n        if ext:\n            extensions.append(ext)\n            extensions.append(ext.replace('.', '', 1))\n    extensions.sort()\n    return extensions", "response": "Get a list of available file extensions to make it easy for\n    tab - completion and exception handling."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread in the dependencies from the requirements files", "response": "def parse_requirements(requirements_filename):\n    \"\"\"read in the dependencies from the requirements files\n    \"\"\"\n    dependencies, dependency_links = [], []\n    requirements_dir = os.path.dirname(requirements_filename)\n    with open(requirements_filename, 'r') as stream:\n        for line in stream:\n            line = line.strip()\n            if line.startswith(\"-r\"):\n                filename = os.path.join(requirements_dir, line[2:].strip())\n                _dependencies, _dependency_links = parse_requirements(filename)\n                dependencies.extend(_dependencies)\n                dependency_links.extend(_dependency_links)\n            elif line.startswith(\"http\"):\n                dependency_links.append(line)\n            else:\n                package = line.split('#')[0]\n                if package:\n                    dependencies.append(package)\n    return dependencies, dependency_links"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fit(self, users, items, user_features=None, item_features=None):\n\n        self._user_id_mapping = {}\n        self._item_id_mapping = {}\n        self._user_feature_mapping = {}\n        self._item_feature_mapping = {}\n\n        return self.fit_partial(users, items, user_features, item_features)", "response": "Fit the user id and feature name mappings."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fit_partial(\n        self, users=None, items=None, user_features=None, item_features=None\n    ):\n        \"\"\"\n        Fit the user/item id and feature name mappings.\n\n        Calling fit the second time will add new entries to existing mappings.\n\n        Parameters\n        ----------\n\n        users: iterable of user ids, optional\n        items: iterable of item ids, optional\n        user_features: iterable of user features, optional\n        item_features: iterable of item features, optional\n        \"\"\"\n\n        if users is not None:\n            for user_id in users:\n                self._user_id_mapping.setdefault(user_id, len(self._user_id_mapping))\n\n                if self._user_identity_features:\n                    self._user_feature_mapping.setdefault(\n                        user_id, len(self._user_feature_mapping)\n                    )\n\n        if items is not None:\n            for item_id in items:\n                self._item_id_mapping.setdefault(item_id, len(self._item_id_mapping))\n\n                if self._item_identity_features:\n                    self._item_feature_mapping.setdefault(\n                        item_id, len(self._item_feature_mapping)\n                    )\n\n        if user_features is not None:\n            for user_feature in user_features:\n                self._user_feature_mapping.setdefault(\n                    user_feature, len(self._user_feature_mapping)\n                )\n\n        if item_features is not None:\n            for item_feature in item_features:\n                self._item_feature_mapping.setdefault(\n                    item_feature, len(self._item_feature_mapping)\n                )", "response": "Fit the user id and feature name mappings."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef build_interactions(self, data):\n\n        interactions = _IncrementalCOOMatrix(self.interactions_shape(), np.int32)\n        weights = _IncrementalCOOMatrix(self.interactions_shape(), np.float32)\n\n        for datum in data:\n            user_idx, item_idx, weight = self._unpack_datum(datum)\n\n            interactions.append(user_idx, item_idx, 1)\n            weights.append(user_idx, item_idx, weight)\n\n        return (interactions.tocoo(), weights.tocoo())", "response": "Builds an interaction matrix."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nbuilds a CSR matrix of user features from an iterable of user ids or feature names.", "response": "def build_user_features(self, data, normalize=True):\n        \"\"\"\n        Build a user features matrix out of an iterable of the form\n        (user id, [list of feature names]) or (user id, {feature name: feature weight}).\n\n        Parameters\n        ----------\n\n        data: iterable of the form\n            (user id, [list of feature names]) or (user id,\n            {feature name: feature weight}).\n            User and feature ids will be translated to internal indices\n            constructed during the fit call.\n        normalize: bool, optional\n            If true, will ensure that feature weights sum to 1 in every row.\n\n        Returns\n        -------\n\n        feature matrix: CSR matrix (num users, num features)\n            Matrix of user features.\n        \"\"\"\n\n        builder = _FeatureBuilder(\n            self._user_id_mapping,\n            self._user_feature_mapping,\n            self._user_identity_features,\n            normalize,\n            \"user\",\n        )\n\n        return builder.build(data)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef build_item_features(self, data, normalize=True):\n\n        builder = _FeatureBuilder(\n            self._item_id_mapping,\n            self._item_feature_mapping,\n            self._item_identity_features,\n            normalize,\n            \"item\",\n        )\n\n        return builder.build(data)", "response": "Builds a CSR matrix of item features."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef mapping(self):\n\n        return (\n            self._user_id_mapping,\n            self._user_feature_mapping,\n            self._item_id_mapping,\n            self._item_feature_mapping,\n        )", "response": "Returns the constructed mappings."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fetch_stackexchange(\n    dataset,\n    test_set_fraction=0.2,\n    min_training_interactions=1,\n    data_home=None,\n    indicator_features=True,\n    tag_features=False,\n    download_if_missing=True,\n):\n    \"\"\"\n    Fetch a dataset from the `StackExchange network <http://stackexchange.com/>`_.\n\n    The datasets contain users answering questions: an interaction is defined as a user\n    answering a given question.\n\n    The following datasets from the StackExchange network are available:\n\n    - CrossValidated: From stats.stackexchange.com. Approximately 9000 users, 72000 questions,\n      and 70000 answers.\n    - StackOverflow: From stackoverflow.stackexchange.com. Approximately 1.3M users, 11M questions,\n      and 18M answers.\n\n    Parameters\n    ----------\n\n    dataset: string, one of ('crossvalidated', 'stackoverflow')\n        The part of the StackExchange network for which to fetch the dataset.\n    test_set_fraction: float, optional\n        The fraction of the dataset used for testing. Splitting into the train and test set is done\n        in a time-based fashion: all interactions before a certain time are in the train set and\n        all interactions after that time are in the test set.\n    min_training_interactions: int, optional\n        Only include users with this amount of interactions in the training set.\n    data_home: path, optional\n        Path to the directory in which the downloaded data should be placed.\n        Defaults to ``~/lightfm_data/``.\n    indicator_features: bool, optional\n        Use an [n_users, n_users] identity matrix for item features. When True with genre_features,\n        indicator and genre features are concatenated into a single feature matrix of shape\n        [n_users, n_users + n_genres].\n    download_if_missing: bool, optional\n        Download the data if not present. Raises an IOError if False and data is missing.\n\n    Notes\n    -----\n\n    The return value is a dictionary containing the following keys:\n\n    Returns\n    -------\n\n    train: sp.coo_matrix of shape [n_users, n_items]\n         Contains training set interactions.\n    test: sp.coo_matrix of shape [n_users, n_items]\n         Contains testing set interactions.\n    item_features: sp.csr_matrix of shape [n_items, n_item_features]\n         Contains item features.\n    item_feature_labels: np.array of strings of shape [n_item_features,]\n         Labels of item features.\n    \"\"\"\n\n    if not (indicator_features or tag_features):\n        raise ValueError(\n            \"At least one of item_indicator_features \" \"or tag_features must be True\"\n        )\n\n    if dataset not in (\"crossvalidated\", \"stackoverflow\"):\n        raise ValueError(\"Unknown dataset\")\n\n    if not (0.0 < test_set_fraction < 1.0):\n        raise ValueError(\"Test set fraction must be between 0 and 1\")\n\n    urls = {\n        \"crossvalidated\": (\n            \"https://github.com/maciejkula/lightfm_datasets/releases/\"\n            \"download/v0.1.0/stackexchange_crossvalidated.npz\"\n        ),\n        \"stackoverflow\": (\n            \"https://github.com/maciejkula/lightfm_datasets/releases/\"\n            \"download/v0.1.0/stackexchange_stackoverflow.npz\"\n        ),\n    }\n\n    path = _common.get_data(\n        data_home,\n        urls[dataset],\n        os.path.join(\"stackexchange\", dataset),\n        \"data.npz\",\n        download_if_missing,\n    )\n\n    data = np.load(path)\n\n    interactions = sp.coo_matrix(\n        (\n            data[\"interactions_data\"],\n            (data[\"interactions_row\"], data[\"interactions_col\"]),\n        ),\n        shape=data[\"interactions_shape\"].flatten(),\n    )\n    interactions.sum_duplicates()\n\n    tag_features_mat = sp.coo_matrix(\n        (data[\"features_data\"], (data[\"features_row\"], data[\"features_col\"])),\n        shape=data[\"features_shape\"].flatten(),\n    )\n    tag_labels = data[\"labels\"]\n\n    test_cutoff_index = int(len(interactions.data) * (1.0 - test_set_fraction))\n    test_cutoff_timestamp = np.sort(interactions.data)[test_cutoff_index]\n    in_train = interactions.data < test_cutoff_timestamp\n    in_test = np.logical_not(in_train)\n\n    train = sp.coo_matrix(\n        (\n            np.ones(in_train.sum(), dtype=np.float32),\n            (interactions.row[in_train], interactions.col[in_train]),\n        ),\n        shape=interactions.shape,\n    )\n    test = sp.coo_matrix(\n        (\n            np.ones(in_test.sum(), dtype=np.float32),\n            (interactions.row[in_test], interactions.col[in_test]),\n        ),\n        shape=interactions.shape,\n    )\n\n    if min_training_interactions > 0:\n        include = np.squeeze(np.array(train.getnnz(axis=1))) > min_training_interactions\n\n        train = train.tocsr()[include].tocoo()\n        test = test.tocsr()[include].tocoo()\n\n    if indicator_features and not tag_features:\n        features = sp.identity(train.shape[1], format=\"csr\", dtype=np.float32)\n        labels = np.array([\"question_id:{}\".format(x) for x in range(train.shape[1])])\n    elif not indicator_features and tag_features:\n        features = tag_features_mat.tocsr()\n        labels = tag_labels\n    else:\n        id_features = sp.identity(train.shape[1], format=\"csr\", dtype=np.float32)\n        features = sp.hstack([id_features, tag_features_mat]).tocsr()\n        labels = np.concatenate(\n            [\n                np.array([\"question_id:{}\".format(x) for x in range(train.shape[1])]),\n                tag_labels,\n            ]\n        )\n\n    return {\n        \"train\": train,\n        \"test\": test,\n        \"item_features\": features,\n        \"item_feature_labels\": labels,\n    }", "response": "Fetch a StackExchange dataset from StackExchange network."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget path to the movielens dataset file.", "response": "def _get_movielens_path():\n    \"\"\"\n    Get path to the movielens dataset file.\n    \"\"\"\n\n    return os.path.join(os.path.dirname(os.path.abspath(__file__)),\n                        'movielens.zip')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the raw lines of the train and test files.", "response": "def _get_raw_movielens_data():\n    \"\"\"\n    Return the raw lines of the train and test files.\n    \"\"\"\n\n    path = _get_movielens_path()\n\n    if not os.path.isfile(path):\n        _download_movielens(path)\n\n    with zipfile.ZipFile(path) as datafile:\n        return (datafile.read('ml-100k/ua.base').decode().split('\\n'),\n                datafile.read('ml-100k/ua.test').decode().split('\\n'))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting raw lines of the genre file.", "response": "def _get_movie_raw_metadata():\n    \"\"\"\n    Get raw lines of the genre file.\n    \"\"\"\n\n    path = _get_movielens_path()\n\n    if not os.path.isfile(path):\n        _download_movielens(path)\n\n    with zipfile.ZipFile(path) as datafile:\n        return datafile.read('ml-100k/u.item').decode(errors='ignore').split('\\n')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a matrix of item - specific features and genres.", "response": "def get_movielens_item_metadata(use_item_ids):\n    \"\"\"\n    Build a matrix of genre features (no_items, no_features).\n\n    If use_item_ids is True, per-item features will also be used.\n    \"\"\"\n\n    features = {}\n    genre_set = set()\n\n    for line in _get_movie_raw_metadata():\n\n        if not line:\n            continue\n\n        splt = line.split('|')\n        item_id = int(splt[0])\n\n        genres = [idx for idx, val in\n                  zip(range(len(splt[5:])), splt[5:])\n                  if int(val) > 0]\n\n        if use_item_ids:\n            # Add item-specific features too\n            genres.append(item_id)\n\n        for genre_id in genres:\n            genre_set.add(genre_id)\n\n        features[item_id] = genres\n\n    mat = sp.lil_matrix((len(features) + 1,\n                         len(genre_set)),\n                        dtype=np.int32)\n\n    for item_id, genre_ids in features.items():\n        for genre_id in genre_ids:\n            mat[item_id, genre_id] = 1\n\n    return mat"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_movielens_data():\n\n    train_data, test_data = _get_raw_movielens_data()\n\n    uids = set()\n    iids = set()\n\n    for uid, iid, rating, timestamp in itertools.chain(_parse(train_data),\n                                                       _parse(test_data)):\n        uids.add(uid)\n        iids.add(iid)\n\n    rows = max(uids) + 1\n    cols = max(iids) + 1\n\n    return (_build_interaction_matrix(rows, cols, _parse(train_data)),\n            _build_interaction_matrix(rows, cols, _parse(test_data)))", "response": "Get the train and test data for a single node."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads the raw lines of the train and test files.", "response": "def _read_raw_data(path):\n    \"\"\"\n    Return the raw lines of the train and test files.\n    \"\"\"\n\n    with zipfile.ZipFile(path) as datafile:\n        return (\n            datafile.read(\"ml-100k/ua.base\").decode().split(\"\\n\"),\n            datafile.read(\"ml-100k/ua.test\").decode().split(\"\\n\"),\n            datafile.read(\"ml-100k/u.item\").decode(errors=\"ignore\").split(\"\\n\"),\n            datafile.read(\"ml-100k/u.genre\").decode(errors=\"ignore\").split(\"\\n\"),\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfetch the Movielens dataset.", "response": "def fetch_movielens(\n    data_home=None,\n    indicator_features=True,\n    genre_features=False,\n    min_rating=0.0,\n    download_if_missing=True,\n):\n    \"\"\"\n    Fetch the `Movielens 100k dataset <http://grouplens.org/datasets/movielens/100k/>`_.\n\n    The dataset contains 100,000 interactions from 1000 users on 1700 movies,\n    and is exhaustively described in its\n    `README <http://files.grouplens.org/datasets/movielens/ml-100k-README.txt>`_.\n\n    Parameters\n    ----------\n\n    data_home: path, optional\n        Path to the directory in which the downloaded data should be placed.\n        Defaults to ``~/lightfm_data/``.\n    indicator_features: bool, optional\n        Use an [n_items, n_items] identity matrix for item features. When True with genre_features,\n        indicator and genre features are concatenated into a single feature matrix of shape\n        [n_items, n_items + n_genres].\n    genre_features: bool, optional\n        Use a [n_items, n_genres] matrix for item features. When True with item_indicator_features,\n        indicator and genre features are concatenated into a single feature matrix of shape\n        [n_items, n_items + n_genres].\n    min_rating: float, optional\n        Minimum rating to include in the interaction matrix.\n    download_if_missing: bool, optional\n        Download the data if not present. Raises an IOError if False and data is missing.\n\n    Notes\n    -----\n\n    The return value is a dictionary containing the following keys:\n\n    Returns\n    -------\n\n    train: sp.coo_matrix of shape [n_users, n_items]\n         Contains training set interactions.\n    test: sp.coo_matrix of shape [n_users, n_items]\n         Contains testing set interactions.\n    item_features: sp.csr_matrix of shape [n_items, n_item_features]\n         Contains item features.\n    item_feature_labels: np.array of strings of shape [n_item_features,]\n         Labels of item features.\n    item_labels: np.array of strings of shape [n_items,]\n         Items' titles.\n    \"\"\"\n\n    if not (indicator_features or genre_features):\n        raise ValueError(\n            \"At least one of item_indicator_features \" \"or genre_features must be True\"\n        )\n\n    zip_path = _common.get_data(\n        data_home,\n        (\n            \"https://github.com/maciejkula/\"\n            \"lightfm_datasets/releases/\"\n            \"download/v0.1.0/movielens.zip\"\n        ),\n        \"movielens100k\",\n        \"movielens.zip\",\n        download_if_missing,\n    )\n\n    # Load raw data\n    try:\n        (train_raw, test_raw, item_metadata_raw, genres_raw) = _read_raw_data(zip_path)\n    except zipfile.BadZipFile:\n        # Download was corrupted, get rid of the partially\n        # downloaded file so that we re-download on the\n        # next try.\n        os.unlink(zip_path)\n        raise ValueError(\n            \"Corrupted Movielens download. Check your \"\n            \"internet connection and try again.\"\n        )\n\n    # Figure out the dimensions\n    num_users, num_items = _get_dimensions(_parse(train_raw), _parse(test_raw))\n\n    # Load train interactions\n    train = _build_interaction_matrix(\n        num_users, num_items, _parse(train_raw), min_rating\n    )\n    # Load test interactions\n    test = _build_interaction_matrix(num_users, num_items, _parse(test_raw), min_rating)\n\n    assert train.shape == test.shape\n\n    # Load metadata features\n    (\n        id_features,\n        id_feature_labels,\n        genre_features_matrix,\n        genre_feature_labels,\n    ) = _parse_item_metadata(num_items, item_metadata_raw, genres_raw)\n\n    assert id_features.shape == (num_items, len(id_feature_labels))\n    assert genre_features_matrix.shape == (num_items, len(genre_feature_labels))\n\n    if indicator_features and not genre_features:\n        features = id_features\n        feature_labels = id_feature_labels\n    elif genre_features and not indicator_features:\n        features = genre_features_matrix\n        feature_labels = genre_feature_labels\n    else:\n        features = sp.hstack([id_features, genre_features_matrix]).tocsr()\n        feature_labels = np.concatenate((id_feature_labels, genre_feature_labels))\n\n    data = {\n        \"train\": train,\n        \"test\": test,\n        \"item_features\": features,\n        \"item_feature_labels\": feature_labels,\n        \"item_labels\": id_feature_labels,\n    }\n\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a LightFM instance that is a precision at k metric.", "response": "def precision_at_k(\n    model,\n    test_interactions,\n    train_interactions=None,\n    k=10,\n    user_features=None,\n    item_features=None,\n    preserve_rows=False,\n    num_threads=1,\n    check_intersections=True,\n):\n    \"\"\"\n    Measure the precision at k metric for a model: the fraction of known\n    positives in the first k positions of the ranked list of results.\n    A perfect score is 1.0.\n\n    Parameters\n    ----------\n\n    model: LightFM instance\n         the fitted model to be evaluated\n    test_interactions: np.float32 csr_matrix of shape [n_users, n_items]\n         Non-zero entries representing known positives in the evaluation set.\n    train_interactions: np.float32 csr_matrix of shape [n_users, n_items], optional\n         Non-zero entries representing known positives in the train set. These\n         will be omitted from the score calculations to avoid re-recommending\n         known positives.\n    k: integer, optional\n         The k parameter.\n    user_features: np.float32 csr_matrix of shape [n_users, n_user_features], optional\n         Each row contains that user's weights over features.\n    item_features: np.float32 csr_matrix of shape [n_items, n_item_features], optional\n         Each row contains that item's weights over features.\n    preserve_rows: boolean, optional\n         When False (default), the number of rows in the output will be equal\n         to the number of users with interactions in the evaluation set.\n         When True, the number of rows in the output will be equal to the\n         number of users.\n    num_threads: int, optional\n         Number of parallel computation threads to use. Should\n         not be higher than the number of physical cores.\n    check_intersections: bool, optional, True by default,\n        Only relevant when train_interactions are supplied.\n        A flag that signals whether the test and train matrices should be checked\n        for intersections to prevent optimistic ranks / wrong evaluation / bad data split.\n\n    Returns\n    -------\n\n    np.array of shape [n_users with interactions or n_users,]\n         Numpy array containing precision@k scores for each user. If there are\n         no interactions for a given user the returned precision will be 0.\n    \"\"\"\n\n    if num_threads < 1:\n        raise ValueError(\"Number of threads must be 1 or larger.\")\n\n    ranks = model.predict_rank(\n        test_interactions,\n        train_interactions=train_interactions,\n        user_features=user_features,\n        item_features=item_features,\n        num_threads=num_threads,\n        check_intersections=check_intersections,\n    )\n\n    ranks.data = np.less(ranks.data, k, ranks.data)\n\n    precision = np.squeeze(np.array(ranks.sum(axis=1))) / k\n\n    if not preserve_rows:\n        precision = precision[test_interactions.getnnz(axis=1) > 0]\n\n    return precision"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the recall at k metric for a light fM model.", "response": "def recall_at_k(\n    model,\n    test_interactions,\n    train_interactions=None,\n    k=10,\n    user_features=None,\n    item_features=None,\n    preserve_rows=False,\n    num_threads=1,\n    check_intersections=True,\n):\n    \"\"\"\n    Measure the recall at k metric for a model: the number of positive items in\n    the first k positions of the ranked list of results divided by the number\n    of positive items in the test period. A perfect score is 1.0.\n\n    Parameters\n    ----------\n\n    model: LightFM instance\n         the fitted model to be evaluated\n    test_interactions: np.float32 csr_matrix of shape [n_users, n_items]\n         Non-zero entries representing known positives in the evaluation set.\n    train_interactions: np.float32 csr_matrix of shape [n_users, n_items], optional\n         Non-zero entries representing known positives in the train set. These\n         will be omitted from the score calculations to avoid re-recommending\n         known positives.\n    k: integer, optional\n         The k parameter.\n    user_features: np.float32 csr_matrix of shape [n_users, n_user_features], optional\n         Each row contains that user's weights over features.\n    item_features: np.float32 csr_matrix of shape [n_items, n_item_features], optional\n         Each row contains that item's weights over features.\n    preserve_rows: boolean, optional\n         When False (default), the number of rows in the output will be equal\n         to the number of users with interactions in the evaluation set.\n         When True, the number of rows in the output will be equal to the\n         number of users.\n    num_threads: int, optional\n         Number of parallel computation threads to use. Should\n         not be higher than the number of physical cores.\n    check_intersections: bool, optional, True by default,\n        Only relevant when train_interactions are supplied.\n        A flag that signals whether the test and train matrices should be checked\n        for intersections to prevent optimistic ranks / wrong evaluation / bad data split.\n\n    Returns\n    -------\n\n    np.array of shape [n_users with interactions or n_users,]\n         Numpy array containing recall@k scores for each user. If there are no\n         interactions for a given user having items in the test period, the\n         returned recall will be 0.\n    \"\"\"\n\n    if num_threads < 1:\n        raise ValueError(\"Number of threads must be 1 or larger.\")\n\n    ranks = model.predict_rank(\n        test_interactions,\n        train_interactions=train_interactions,\n        user_features=user_features,\n        item_features=item_features,\n        num_threads=num_threads,\n        check_intersections=check_intersections,\n    )\n\n    ranks.data = np.less(ranks.data, k, ranks.data)\n\n    retrieved = np.squeeze(test_interactions.getnnz(axis=1))\n    hit = np.squeeze(np.array(ranks.sum(axis=1)))\n\n    if not preserve_rows:\n        hit = hit[test_interactions.getnnz(axis=1) > 0]\n        retrieved = retrieved[test_interactions.getnnz(axis=1) > 0]\n\n    return hit / retrieved"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmeasure the ROC AUC metric for a model: the probability that a randomly chosen positive example has a higher score than a randomly chosen negative example. A perfect score is 1.0. Parameters ---------- model: LightFM instance the fitted model to be evaluated test_interactions: np.float32 csr_matrix of shape [n_users, n_items] Non-zero entries representing known positives in the evaluation set. train_interactions: np.float32 csr_matrix of shape [n_users, n_items], optional Non-zero entries representing known positives in the train set. These will be omitted from the score calculations to avoid re-recommending known positives. user_features: np.float32 csr_matrix of shape [n_users, n_user_features], optional Each row contains that user's weights over features. item_features: np.float32 csr_matrix of shape [n_items, n_item_features], optional Each row contains that item's weights over features. preserve_rows: boolean, optional When False (default), the number of rows in the output will be equal to the number of users with interactions in the evaluation set. When True, the number of rows in the output will be equal to the number of users. num_threads: int, optional Number of parallel computation threads to use. Should not be higher than the number of physical cores. check_intersections: bool, optional, True by default, Only relevant when train_interactions are supplied. A flag that signals whether the test and train matrices should be checked for intersections to prevent optimistic ranks / wrong evaluation / bad data split. Returns ------- np.array of shape [n_users with interactions or n_users,] Numpy array containing AUC scores for each user. If there are no interactions for a given user the returned AUC will be 0.5.", "response": "def auc_score(\n    model,\n    test_interactions,\n    train_interactions=None,\n    user_features=None,\n    item_features=None,\n    preserve_rows=False,\n    num_threads=1,\n    check_intersections=True,\n):\n    \"\"\"\n    Measure the ROC AUC metric for a model: the probability that a randomly\n    chosen positive example has a higher score than a randomly chosen negative\n    example.\n    A perfect score is 1.0.\n\n    Parameters\n    ----------\n\n    model: LightFM instance\n         the fitted model to be evaluated\n    test_interactions: np.float32 csr_matrix of shape [n_users, n_items]\n         Non-zero entries representing known positives in the evaluation set.\n    train_interactions: np.float32 csr_matrix of shape [n_users, n_items], optional\n         Non-zero entries representing known positives in the train set. These\n         will be omitted from the score calculations to avoid re-recommending\n         known positives.\n    user_features: np.float32 csr_matrix of shape [n_users, n_user_features], optional\n         Each row contains that user's weights over features.\n    item_features: np.float32 csr_matrix of shape [n_items, n_item_features], optional\n         Each row contains that item's weights over features.\n    preserve_rows: boolean, optional\n         When False (default), the number of rows in the output will be equal\n         to the number of users with interactions in the evaluation set.\n         When True, the number of rows in the output will be equal to the\n         number of users.\n    num_threads: int, optional\n         Number of parallel computation threads to use. Should\n         not be higher than the number of physical cores.\n    check_intersections: bool, optional, True by default,\n        Only relevant when train_interactions are supplied.\n        A flag that signals whether the test and train matrices should be checked\n        for intersections to prevent optimistic ranks / wrong evaluation / bad data split.\n\n    Returns\n    -------\n\n    np.array of shape [n_users with interactions or n_users,]\n         Numpy array containing AUC scores for each user. If there are no\n         interactions for a given user the returned AUC will be 0.5.\n    \"\"\"\n\n    if num_threads < 1:\n        raise ValueError(\"Number of threads must be 1 or larger.\")\n\n    ranks = model.predict_rank(\n        test_interactions,\n        train_interactions=train_interactions,\n        user_features=user_features,\n        item_features=item_features,\n        num_threads=num_threads,\n        check_intersections=check_intersections,\n    )\n\n    assert np.all(ranks.data >= 0)\n\n    auc = np.zeros(ranks.shape[0], dtype=np.float32)\n\n    if train_interactions is not None:\n        num_train_positives = np.squeeze(\n            np.array(train_interactions.getnnz(axis=1)).astype(np.int32)\n        )\n    else:\n        num_train_positives = np.zeros(test_interactions.shape[0], dtype=np.int32)\n\n    # The second argument is modified in-place, but\n    # here we don't care about the inconsistency\n    # introduced into the ranks matrix.\n    calculate_auc_from_rank(\n        CSRMatrix(ranks), num_train_positives, ranks.data, auc, num_threads\n    )\n\n    if not preserve_rows:\n        auc = auc[test_interactions.getnnz(axis=1) > 0]\n\n    return auc"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef reciprocal_rank(\n    model,\n    test_interactions,\n    train_interactions=None,\n    user_features=None,\n    item_features=None,\n    preserve_rows=False,\n    num_threads=1,\n    check_intersections=True,\n):\n    \"\"\"\n    Measure the reciprocal rank metric for a model: 1 / the rank of the highest\n    ranked positive example. A perfect score is 1.0.\n\n    Parameters\n    ----------\n\n    model: LightFM instance\n         the fitted model to be evaluated\n    test_interactions: np.float32 csr_matrix of shape [n_users, n_items]\n         Non-zero entries representing known positives in the evaluation set.\n    train_interactions: np.float32 csr_matrix of shape [n_users, n_items], optional\n         Non-zero entries representing known positives in the train set. These\n         will be omitted from the score calculations to avoid re-recommending\n         known positives.\n    user_features: np.float32 csr_matrix of shape [n_users, n_user_features], optional\n         Each row contains that user's weights over features.\n    item_features: np.float32 csr_matrix of shape [n_items, n_item_features], optional\n         Each row contains that item's weights over features.\n    preserve_rows: boolean, optional\n         When False (default), the number of rows in the output will be equal\n         to the number of users with interactions in the evaluation set.\n         When True, the number of rows in the output will be equal to the\n         number of users.\n    num_threads: int, optional\n         Number of parallel computation threads to use. Should\n         not be higher than the number of physical cores.\n    check_intersections: bool, optional, True by default,\n        Only relevant when train_interactions are supplied.\n        A flag that signals whether the test and train matrices should be checked\n        for intersections to prevent optimistic ranks / wrong evaluation / bad data split.\n\n    Returns\n    -------\n\n    np.array of shape [n_users with interactions or n_users,]\n         Numpy array containing reciprocal rank scores for each user.\n         If there are no interactions for a given user the returned value will\n         be 0.0.\n    \"\"\"\n\n    if num_threads < 1:\n        raise ValueError(\"Number of threads must be 1 or larger.\")\n\n    ranks = model.predict_rank(\n        test_interactions,\n        train_interactions=train_interactions,\n        user_features=user_features,\n        item_features=item_features,\n        num_threads=num_threads,\n        check_intersections=check_intersections,\n    )\n\n    ranks.data = 1.0 / (ranks.data + 1.0)\n\n    ranks = np.squeeze(np.array(ranks.max(axis=1).todense()))\n\n    if not preserve_rows:\n        ranks = ranks[test_interactions.getnnz(axis=1) > 0]\n\n    return ranks", "response": "Returns a new node with the reciprocal rank of the given model."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _initialize(self, no_components, no_item_features, no_user_features):\n\n        # Initialise item features.\n        self.item_embeddings = (\n            (self.random_state.rand(no_item_features, no_components) - 0.5)\n            / no_components\n        ).astype(np.float32)\n        self.item_embedding_gradients = np.zeros_like(self.item_embeddings)\n        self.item_embedding_momentum = np.zeros_like(self.item_embeddings)\n        self.item_biases = np.zeros(no_item_features, dtype=np.float32)\n        self.item_bias_gradients = np.zeros_like(self.item_biases)\n        self.item_bias_momentum = np.zeros_like(self.item_biases)\n\n        # Initialise user features.\n        self.user_embeddings = (\n            (self.random_state.rand(no_user_features, no_components) - 0.5)\n            / no_components\n        ).astype(np.float32)\n        self.user_embedding_gradients = np.zeros_like(self.user_embeddings)\n        self.user_embedding_momentum = np.zeros_like(self.user_embeddings)\n        self.user_biases = np.zeros(no_user_features, dtype=np.float32)\n        self.user_bias_gradients = np.zeros_like(self.user_biases)\n        self.user_bias_momentum = np.zeros_like(self.user_biases)\n\n        if self.learning_schedule == \"adagrad\":\n            self.item_embedding_gradients += 1\n            self.item_bias_gradients += 1\n            self.user_embedding_gradients += 1\n            self.user_bias_gradients += 1", "response": "Initializes the internal latent representations."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfit the model to a set of user - item and sample - weight matrices.", "response": "def fit(\n        self,\n        interactions,\n        user_features=None,\n        item_features=None,\n        sample_weight=None,\n        epochs=1,\n        num_threads=1,\n        verbose=False,\n    ):\n        \"\"\"\n        Fit the model.\n\n        For details on how to use feature matrices, see the documentation\n        on the :class:`lightfm.LightFM` class.\n\n        Arguments\n        ---------\n\n        interactions: np.float32 coo_matrix of shape [n_users, n_items]\n             the matrix containing\n             user-item interactions. Will be converted to\n             numpy.float32 dtype if it is not of that type.\n        user_features: np.float32 csr_matrix of shape [n_users, n_user_features], optional\n             Each row contains that user's weights over features.\n        item_features: np.float32 csr_matrix of shape [n_items, n_item_features], optional\n             Each row contains that item's weights over features.\n        sample_weight: np.float32 coo_matrix of shape [n_users, n_items], optional\n             matrix with entries expressing weights of individual\n             interactions from the interactions matrix.\n             Its row and col arrays must be the same as\n             those of the interactions matrix. For memory\n             efficiency its possible to use the same arrays\n             for both weights and interaction matrices.\n             Defaults to weight 1.0 for all interactions.\n             Not implemented for the k-OS loss.\n        epochs: int, optional\n             number of epochs to run\n        num_threads: int, optional\n             Number of parallel computation threads to use. Should\n             not be higher than the number of physical cores.\n        verbose: bool, optional\n             whether to print progress messages.\n             If `tqdm` is installed, a progress bar will be displayed instead.\n\n        Returns\n        -------\n\n        LightFM instance\n            the fitted model\n\n        \"\"\"\n\n        # Discard old results, if any\n        self._reset_state()\n\n        return self.fit_partial(\n            interactions,\n            user_features=user_features,\n            item_features=item_features,\n            sample_weight=sample_weight,\n            epochs=epochs,\n            num_threads=num_threads,\n            verbose=verbose,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfitting the model to a set of user - item models.", "response": "def fit_partial(\n        self,\n        interactions,\n        user_features=None,\n        item_features=None,\n        sample_weight=None,\n        epochs=1,\n        num_threads=1,\n        verbose=False,\n    ):\n        \"\"\"\n        Fit the model.\n\n        Fit the model. Unlike fit, repeated calls to this method will\n        cause training to resume from the current model state.\n\n        For details on how to use feature matrices, see the documentation\n        on the :class:`lightfm.LightFM` class.\n\n        Arguments\n        ---------\n\n        interactions: np.float32 coo_matrix of shape [n_users, n_items]\n             the matrix containing\n             user-item interactions. Will be converted to\n             numpy.float32 dtype if it is not of that type.\n        user_features: np.float32 csr_matrix of shape [n_users, n_user_features], optional\n             Each row contains that user's weights over features.\n        item_features: np.float32 csr_matrix of shape [n_items, n_item_features], optional\n             Each row contains that item's weights over features.\n        sample_weight: np.float32 coo_matrix of shape [n_users, n_items], optional\n             matrix with entries expressing weights of individual\n             interactions from the interactions matrix.\n             Its row and col arrays must be the same as\n             those of the interactions matrix. For memory\n             efficiency its possible to use the same arrays\n             for both weights and interaction matrices.\n             Defaults to weight 1.0 for all interactions.\n             Not implemented for the k-OS loss.\n        epochs: int, optional\n             number of epochs to run\n        num_threads: int, optional\n             Number of parallel computation threads to use. Should\n             not be higher than the number of physical cores.\n        verbose: bool, optional\n             whether to print progress messages.\n             If `tqdm` is installed, a progress bar will be displayed instead.\n\n        Returns\n        -------\n\n        LightFM instance\n            the fitted model\n        \"\"\"\n\n        # We need this in the COO format.\n        # If that's already true, this is a no-op.\n        interactions = interactions.tocoo()\n\n        if interactions.dtype != CYTHON_DTYPE:\n            interactions.data = interactions.data.astype(CYTHON_DTYPE)\n\n        sample_weight_data = self._process_sample_weight(interactions, sample_weight)\n\n        n_users, n_items = interactions.shape\n        (user_features, item_features) = self._construct_feature_matrices(\n            n_users, n_items, user_features, item_features\n        )\n\n        for input_data in (\n            user_features.data,\n            item_features.data,\n            interactions.data,\n            sample_weight_data,\n        ):\n            self._check_input_finite(input_data)\n        if self.item_embeddings is None:\n            # Initialise latent factors only if this is the first call\n            # to fit_partial.\n            self._initialize(\n                self.no_components, item_features.shape[1], user_features.shape[1]\n            )\n\n        # Check that the dimensionality of the feature matrices has\n        # not changed between runs.\n        if not item_features.shape[1] == self.item_embeddings.shape[0]:\n            raise ValueError(\"Incorrect number of features in item_features\")\n\n        if not user_features.shape[1] == self.user_embeddings.shape[0]:\n            raise ValueError(\"Incorrect number of features in user_features\")\n\n        if num_threads < 1:\n            raise ValueError(\"Number of threads must be 1 or larger.\")\n\n        for _ in self._progress(epochs, verbose=verbose):\n            self._run_epoch(\n                item_features,\n                user_features,\n                interactions,\n                sample_weight_data,\n                num_threads,\n                self.loss,\n            )\n\n            self._check_finite()\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _run_epoch(\n        self,\n        item_features,\n        user_features,\n        interactions,\n        sample_weight,\n        num_threads,\n        loss,\n    ):\n        \"\"\"\n        Run an individual epoch.\n        \"\"\"\n\n        if loss in (\"warp\", \"bpr\", \"warp-kos\"):\n            # The CSR conversion needs to happen before shuffle indices are created.\n            # Calling .tocsr may result in a change in the data arrays of the COO matrix,\n            positives_lookup = CSRMatrix(\n                self._get_positives_lookup_matrix(interactions)\n            )\n\n        # Create shuffle indexes.\n        shuffle_indices = np.arange(len(interactions.data), dtype=np.int32)\n        self.random_state.shuffle(shuffle_indices)\n\n        lightfm_data = self._get_lightfm_data()\n\n        # Call the estimation routines.\n        if loss == \"warp\":\n            fit_warp(\n                CSRMatrix(item_features),\n                CSRMatrix(user_features),\n                positives_lookup,\n                interactions.row,\n                interactions.col,\n                interactions.data,\n                sample_weight,\n                shuffle_indices,\n                lightfm_data,\n                self.learning_rate,\n                self.item_alpha,\n                self.user_alpha,\n                num_threads,\n                self.random_state,\n            )\n        elif loss == \"bpr\":\n            fit_bpr(\n                CSRMatrix(item_features),\n                CSRMatrix(user_features),\n                positives_lookup,\n                interactions.row,\n                interactions.col,\n                interactions.data,\n                sample_weight,\n                shuffle_indices,\n                lightfm_data,\n                self.learning_rate,\n                self.item_alpha,\n                self.user_alpha,\n                num_threads,\n                self.random_state,\n            )\n        elif loss == \"warp-kos\":\n            fit_warp_kos(\n                CSRMatrix(item_features),\n                CSRMatrix(user_features),\n                positives_lookup,\n                interactions.row,\n                shuffle_indices,\n                lightfm_data,\n                self.learning_rate,\n                self.item_alpha,\n                self.user_alpha,\n                self.k,\n                self.n,\n                num_threads,\n                self.random_state,\n            )\n        else:\n            fit_logistic(\n                CSRMatrix(item_features),\n                CSRMatrix(user_features),\n                interactions.row,\n                interactions.col,\n                interactions.data,\n                sample_weight,\n                shuffle_indices,\n                lightfm_data,\n                self.learning_rate,\n                self.item_alpha,\n                self.user_alpha,\n                num_threads,\n            )", "response": "Runs an individual epoch."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef predict(\n        self, user_ids, item_ids, item_features=None, user_features=None, num_threads=1\n    ):\n        \"\"\"\n        Compute the recommendation score for user-item pairs.\n\n        For details on how to use feature matrices, see the documentation\n        on the :class:`lightfm.LightFM` class.\n\n        Arguments\n        ---------\n\n        user_ids: integer or np.int32 array of shape [n_pairs,]\n             single user id or an array containing the user ids for the\n             user-item pairs for which a prediction is to be computed. Note\n             that these are LightFM's internal id's, i.e. the index of the\n             user in the interaction matrix used for fitting the model.\n        item_ids: np.int32 array of shape [n_pairs,]\n             an array containing the item ids for the user-item pairs for which\n             a prediction is to be computed. Note that these are LightFM's\n             internal id's, i.e. the index of the item in the interaction\n             matrix used for fitting the model.\n        user_features: np.float32 csr_matrix of shape [n_users, n_user_features], optional\n             Each row contains that user's weights over features.\n        item_features: np.float32 csr_matrix of shape [n_items, n_item_features], optional\n             Each row contains that item's weights over features.\n        num_threads: int, optional\n             Number of parallel computation threads to use. Should\n             not be higher than the number of physical cores.\n\n        Returns\n        -------\n\n        np.float32 array of shape [n_pairs,]\n            Numpy array containing the recommendation scores for pairs defined\n            by the inputs.\n        \"\"\"\n\n        self._check_initialized()\n\n        if not isinstance(user_ids, np.ndarray):\n            user_ids = np.repeat(np.int32(user_ids), len(item_ids))\n\n        if isinstance(item_ids, (list, tuple)):\n            item_ids = np.array(item_ids, dtype=np.int32)\n\n        assert len(user_ids) == len(item_ids)\n\n        if user_ids.dtype != np.int32:\n            user_ids = user_ids.astype(np.int32)\n        if item_ids.dtype != np.int32:\n            item_ids = item_ids.astype(np.int32)\n\n        if num_threads < 1:\n            raise ValueError(\"Number of threads must be 1 or larger.\")\n\n        if user_ids.min() < 0 or item_ids.min() < 0:\n            raise ValueError(\n                \"User or item ids cannot be negative. \"\n                \"Check your inputs for negative numbers \"\n                \"or very large numbers that can overflow.\"\n            )\n\n        n_users = user_ids.max() + 1\n        n_items = item_ids.max() + 1\n\n        (user_features, item_features) = self._construct_feature_matrices(\n            n_users, n_items, user_features, item_features\n        )\n\n        lightfm_data = self._get_lightfm_data()\n\n        predictions = np.empty(len(user_ids), dtype=np.float64)\n\n        predict_lightfm(\n            CSRMatrix(item_features),\n            CSRMatrix(user_features),\n            user_ids,\n            item_ids,\n            predictions,\n            lightfm_data,\n            num_threads,\n        )\n\n        return predictions", "response": "Compute the recommendation score for a set of user - item pairs."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\npredicts the rank of selected items for each user in the list.", "response": "def predict_rank(\n        self,\n        test_interactions,\n        train_interactions=None,\n        item_features=None,\n        user_features=None,\n        num_threads=1,\n        check_intersections=True,\n    ):\n        \"\"\"\n        Predict the rank of selected interactions. Computes recommendation\n        rankings across all items for every user in interactions and calculates\n        the rank of all non-zero entries in the recommendation ranking, with 0\n        meaning the top of the list (most recommended) and n_items - 1 being\n        the end of the list (least recommended).\n\n        Performs best when only a handful of interactions need to be evaluated\n        per user. If you need to compute predictions for many items for every\n        user, use the predict method instead.\n\n        For details on how to use feature matrices, see the documentation\n        on the :class:`lightfm.LightFM` class.\n\n        Arguments\n        ---------\n\n        test_interactions: np.float32 csr_matrix of shape [n_users, n_items]\n             Non-zero entries denote the user-item pairs\n             whose rank will be computed.\n        train_interactions: np.float32 csr_matrix of shape [n_users, n_items], optional\n             Non-zero entries denote the user-item pairs which will be excluded\n             from rank computation. Use to exclude training set interactions\n             from being scored and ranked for evaluation.\n        user_features: np.float32 csr_matrix of shape [n_users, n_user_features], optional\n             Each row contains that user's weights over features.\n        item_features: np.float32 csr_matrix of shape [n_items, n_item_features], optional\n             Each row contains that item's weights over features.\n        num_threads: int, optional\n             Number of parallel computation threads to use.\n             Should not be higher than the number of physical cores.\n        check_intersections: bool, optional, True by default,\n            Only relevant when train_interactions are supplied.\n            A flag that signals whether the test and train matrices should be checked\n            for intersections to prevent optimistic ranks / wrong evaluation / bad data split.\n\n        Returns\n        -------\n\n        np.float32 csr_matrix of shape [n_users, n_items]\n            the [i, j]-th entry of the matrix will contain the rank of the j-th\n            item in the sorted recommendations list for the i-th user.\n            The degree of sparsity of this matrix will be equal to that of the\n            input interactions matrix.\n        \"\"\"\n\n        self._check_initialized()\n\n        if num_threads < 1:\n            raise ValueError(\"Number of threads must be 1 or larger.\")\n\n        if check_intersections:\n            self._check_test_train_intersections(test_interactions, train_interactions)\n\n        n_users, n_items = test_interactions.shape\n\n        (user_features, item_features) = self._construct_feature_matrices(\n            n_users, n_items, user_features, item_features\n        )\n\n        if not item_features.shape[1] == self.item_embeddings.shape[0]:\n            raise ValueError(\"Incorrect number of features in item_features\")\n\n        if not user_features.shape[1] == self.user_embeddings.shape[0]:\n            raise ValueError(\"Incorrect number of features in user_features\")\n\n        test_interactions = test_interactions.tocsr()\n        test_interactions = self._to_cython_dtype(test_interactions)\n\n        if train_interactions is None:\n            train_interactions = sp.csr_matrix((n_users, n_items), dtype=CYTHON_DTYPE)\n        else:\n            train_interactions = train_interactions.tocsr()\n            train_interactions = self._to_cython_dtype(train_interactions)\n\n        ranks = sp.csr_matrix(\n            (\n                np.zeros_like(test_interactions.data),\n                test_interactions.indices,\n                test_interactions.indptr,\n            ),\n            shape=test_interactions.shape,\n        )\n\n        lightfm_data = self._get_lightfm_data()\n\n        predict_ranks(\n            CSRMatrix(item_features),\n            CSRMatrix(user_features),\n            CSRMatrix(test_interactions),\n            CSRMatrix(train_interactions),\n            ranks.data,\n            lightfm_data,\n            num_threads,\n        )\n\n        return ranks"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_item_representations(self, features=None):\n\n        self._check_initialized()\n\n        if features is None:\n            return self.item_biases, self.item_embeddings\n\n        features = sp.csr_matrix(features, dtype=CYTHON_DTYPE)\n\n        return features * self.item_biases, features * self.item_embeddings", "response": "Returns the latent representations for items given model and features."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_user_representations(self, features=None):\n\n        self._check_initialized()\n\n        if features is None:\n            return self.user_biases, self.user_embeddings\n\n        features = sp.csr_matrix(features, dtype=CYTHON_DTYPE)\n\n        return features * self.user_biases, features * self.user_embeddings", "response": "Returns the latent representations for users given model and features."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the parameters for this estimator.", "response": "def get_params(self, deep=True):\n        \"\"\"\n        Get parameters for this estimator.\n\n        Arguments\n        ---------\n\n        deep: boolean, optional\n            If True, will return the parameters for this estimator and\n            contained subobjects that are estimators.\n\n        Returns\n        -------\n\n        params : mapping of string to any\n            Parameter names mapped to their values.\n        \"\"\"\n\n        params = {\n            \"loss\": self.loss,\n            \"learning_schedule\": self.learning_schedule,\n            \"no_components\": self.no_components,\n            \"learning_rate\": self.learning_rate,\n            \"k\": self.k,\n            \"n\": self.n,\n            \"rho\": self.rho,\n            \"epsilon\": self.epsilon,\n            \"max_sampled\": self.max_sampled,\n            \"item_alpha\": self.item_alpha,\n            \"user_alpha\": self.user_alpha,\n            \"random_state\": self.random_state,\n        }\n\n        return params"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the parameters of this estimator.", "response": "def set_params(self, **params):\n        \"\"\"\n        Set the parameters of this estimator.\n\n        Returns\n        -------\n\n        self\n        \"\"\"\n\n        valid_params = self.get_params()\n\n        for key, value in params.items():\n            if key not in valid_params:\n                raise ValueError(\n                    \"Invalid parameter %s for estimator %s. \"\n                    \"Check the list of available parameters \"\n                    \"with `estimator.get_params().keys()`.\"\n                    % (key, self.__class__.__name__)\n                )\n\n            setattr(self, key, value)\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _adjust_returns(returns, adjustment_factor):\n    if isinstance(adjustment_factor, (float, int)) and adjustment_factor == 0:\n        return returns\n    return returns - adjustment_factor", "response": "Adjusts the returns series by adjustment_factor."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the annualization factor from the specified period.", "response": "def annualization_factor(period, annualization):\n    \"\"\"\n    Return annualization factor from period entered or if a custom\n    value is passed in.\n\n    Parameters\n    ----------\n    period : str, optional\n        Defines the periodicity of the 'returns' data for purposes of\n        annualizing. Value ignored if `annualization` parameter is specified.\n        Defaults are::\n\n            'monthly':12\n            'weekly': 52\n            'daily': 252\n\n    annualization : int, optional\n        Used to suppress default values available in `period` to convert\n        returns into annual returns. Value should be the annual frequency of\n        `returns`.\n\n    Returns\n    -------\n    annualization_factor : float\n    \"\"\"\n    if annualization is None:\n        try:\n            factor = ANNUALIZATION_FACTORS[period]\n        except KeyError:\n            raise ValueError(\n                \"Period cannot be '{}'. \"\n                \"Can be '{}'.\".format(\n                    period, \"', '\".join(ANNUALIZATION_FACTORS.keys())\n                )\n            )\n    else:\n        factor = annualization\n    return factor"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncomputing simple returns from a timeseries of prices.", "response": "def simple_returns(prices):\n    \"\"\"\n    Compute simple returns from a timeseries of prices.\n\n    Parameters\n    ----------\n    prices : pd.Series, pd.DataFrame or np.ndarray\n        Prices of assets in wide-format, with assets as columns,\n        and indexed by datetimes.\n\n    Returns\n    -------\n    returns : array-like\n        Returns of assets in wide-format, with assets as columns,\n        and index coerced to be tz-aware.\n    \"\"\"\n    if isinstance(prices, (pd.DataFrame, pd.Series)):\n        out = prices.pct_change().iloc[1:]\n    else:\n        # Assume np.ndarray\n        out = np.diff(prices, axis=0)\n        np.divide(out, prices[:-1], out=out)\n\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncomputing cumulative returns of a simple returns.", "response": "def cum_returns(returns, starting_value=0, out=None):\n    \"\"\"\n    Compute cumulative returns from simple returns.\n\n    Parameters\n    ----------\n    returns : pd.Series, np.ndarray, or pd.DataFrame\n        Returns of the strategy as a percentage, noncumulative.\n         - Time series with decimal returns.\n         - Example::\n\n            2015-07-16   -0.012143\n            2015-07-17    0.045350\n            2015-07-20    0.030957\n            2015-07-21    0.004902\n\n         - Also accepts two dimensional data. In this case, each column is\n           cumulated.\n\n    starting_value : float, optional\n       The starting returns.\n    out : array-like, optional\n        Array to use as output buffer.\n        If not passed, a new array will be created.\n\n    Returns\n    -------\n    cumulative_returns : array-like\n        Series of cumulative returns.\n    \"\"\"\n    if len(returns) < 1:\n        return returns.copy()\n\n    nanmask = np.isnan(returns)\n    if np.any(nanmask):\n        returns = returns.copy()\n        returns[nanmask] = 0\n\n    allocated_output = out is None\n    if allocated_output:\n        out = np.empty_like(returns)\n\n    np.add(returns, 1, out=out)\n    out.cumprod(axis=0, out=out)\n\n    if starting_value == 0:\n        np.subtract(out, 1, out=out)\n    else:\n        np.multiply(out, starting_value, out=out)\n\n    if allocated_output:\n        if returns.ndim == 1 and isinstance(returns, pd.Series):\n            out = pd.Series(out, index=returns.index)\n        elif isinstance(returns, pd.DataFrame):\n            out = pd.DataFrame(\n                out, index=returns.index, columns=returns.columns,\n            )\n\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncomputing cumulative returns for a single time series or a single time series.", "response": "def cum_returns_final(returns, starting_value=0):\n    \"\"\"\n    Compute total returns from simple returns.\n\n    Parameters\n    ----------\n    returns : pd.DataFrame, pd.Series, or np.ndarray\n       Noncumulative simple returns of one or more timeseries.\n    starting_value : float, optional\n       The starting returns.\n\n    Returns\n    -------\n    total_returns : pd.Series, np.ndarray, or float\n        If input is 1-dimensional (a Series or 1D numpy array), the result is a\n        scalar.\n\n        If input is 2-dimensional (a DataFrame or 2D numpy array), the result\n        is a 1D array containing cumulative returns for each column of input.\n    \"\"\"\n    if len(returns) == 0:\n        return np.nan\n\n    if isinstance(returns, pd.DataFrame):\n        result = (returns + 1).prod()\n    else:\n        result = np.nanprod(returns + 1, axis=0)\n\n    if starting_value == 0:\n        result -= 1\n    else:\n        result *= starting_value\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef aggregate_returns(returns, convert_to):\n\n    def cumulate_returns(x):\n        return cum_returns(x).iloc[-1]\n\n    if convert_to == WEEKLY:\n        grouping = [lambda x: x.year, lambda x: x.isocalendar()[1]]\n    elif convert_to == MONTHLY:\n        grouping = [lambda x: x.year, lambda x: x.month]\n    elif convert_to == YEARLY:\n        grouping = [lambda x: x.year]\n    else:\n        raise ValueError(\n            'convert_to must be {}, {} or {}'.format(WEEKLY, MONTHLY, YEARLY)\n        )\n\n    return returns.groupby(grouping).apply(cumulate_returns)", "response": "Aggregates returns by week month or year."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndetermine the maximum drawdown of a specific language.", "response": "def max_drawdown(returns, out=None):\n    \"\"\"\n    Determines the maximum drawdown of a strategy.\n\n    Parameters\n    ----------\n    returns : pd.Series or np.ndarray\n        Daily returns of the strategy, noncumulative.\n        - See full explanation in :func:`~empyrical.stats.cum_returns`.\n    out : array-like, optional\n        Array to use as output buffer.\n        If not passed, a new array will be created.\n\n    Returns\n    -------\n    max_drawdown : float\n\n    Note\n    -----\n    See https://en.wikipedia.org/wiki/Drawdown_(economics) for more details.\n    \"\"\"\n    allocated_output = out is None\n    if allocated_output:\n        out = np.empty(returns.shape[1:])\n\n    returns_1d = returns.ndim == 1\n\n    if len(returns) < 1:\n        out[()] = np.nan\n        if returns_1d:\n            out = out.item()\n        return out\n\n    returns_array = np.asanyarray(returns)\n\n    cumulative = np.empty(\n        (returns.shape[0] + 1,) + returns.shape[1:],\n        dtype='float64',\n    )\n    cumulative[0] = start = 100\n    cum_returns(returns_array, starting_value=start, out=cumulative[1:])\n\n    max_return = np.fmax.accumulate(cumulative, axis=0)\n\n    nanmin((cumulative - max_return) / max_return, axis=0, out=out)\n    if returns_1d:\n        out = out.item()\n    elif allocated_output and isinstance(returns, pd.DataFrame):\n        out = pd.Series(out)\n\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the mean annual growth rate of returns.", "response": "def annual_return(returns, period=DAILY, annualization=None):\n    \"\"\"\n    Determines the mean annual growth rate of returns. This is equivilent\n    to the compound annual growth rate.\n\n    Parameters\n    ----------\n    returns : pd.Series or np.ndarray\n        Periodic returns of the strategy, noncumulative.\n        - See full explanation in :func:`~empyrical.stats.cum_returns`.\n    period : str, optional\n        Defines the periodicity of the 'returns' data for purposes of\n        annualizing. Value ignored if `annualization` parameter is specified.\n        Defaults are::\n\n            'monthly':12\n            'weekly': 52\n            'daily': 252\n\n    annualization : int, optional\n        Used to suppress default values available in `period` to convert\n        returns into annual returns. Value should be the annual frequency of\n        `returns`.\n\n    Returns\n    -------\n    annual_return : float\n        Annual Return as CAGR (Compounded Annual Growth Rate).\n\n    \"\"\"\n\n    if len(returns) < 1:\n        return np.nan\n\n    ann_factor = annualization_factor(period, annualization)\n    num_years = len(returns) / ann_factor\n    # Pass array to ensure index -1 looks up successfully.\n    ending_value = cum_returns_final(returns, starting_value=1)\n\n    return ending_value ** (1 / num_years) - 1"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef annual_volatility(returns,\n                      period=DAILY,\n                      alpha=2.0,\n                      annualization=None,\n                      out=None):\n    \"\"\"\n    Determines the annual volatility of a strategy.\n\n    Parameters\n    ----------\n    returns : pd.Series or np.ndarray\n        Periodic returns of the strategy, noncumulative.\n        - See full explanation in :func:`~empyrical.stats.cum_returns`.\n    period : str, optional\n        Defines the periodicity of the 'returns' data for purposes of\n        annualizing. Value ignored if `annualization` parameter is specified.\n        Defaults are::\n\n            'monthly':12\n            'weekly': 52\n            'daily': 252\n\n    alpha : float, optional\n        Scaling relation (Levy stability exponent).\n    annualization : int, optional\n        Used to suppress default values available in `period` to convert\n        returns into annual returns. Value should be the annual frequency of\n        `returns`.\n    out : array-like, optional\n        Array to use as output buffer.\n        If not passed, a new array will be created.\n\n    Returns\n    -------\n    annual_volatility : float\n    \"\"\"\n    allocated_output = out is None\n    if allocated_output:\n        out = np.empty(returns.shape[1:])\n\n    returns_1d = returns.ndim == 1\n\n    if len(returns) < 2:\n        out[()] = np.nan\n        if returns_1d:\n            out = out.item()\n        return out\n\n    ann_factor = annualization_factor(period, annualization)\n    nanstd(returns, ddof=1, axis=0, out=out)\n    out = np.multiply(out, ann_factor ** (1.0 / alpha), out=out)\n    if returns_1d:\n        out = out.item()\n    return out", "response": "Returns an annual volatility of a specific strategy."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndetermine the Calmar ratio or drawdown ratio of a given returns.", "response": "def calmar_ratio(returns, period=DAILY, annualization=None):\n    \"\"\"\n    Determines the Calmar ratio, or drawdown ratio, of a strategy.\n\n    Parameters\n    ----------\n    returns : pd.Series or np.ndarray\n        Daily returns of the strategy, noncumulative.\n        - See full explanation in :func:`~empyrical.stats.cum_returns`.\n    period : str, optional\n        Defines the periodicity of the 'returns' data for purposes of\n        annualizing. Value ignored if `annualization` parameter is specified.\n        Defaults are::\n\n            'monthly':12\n            'weekly': 52\n            'daily': 252\n\n    annualization : int, optional\n        Used to suppress default values available in `period` to convert\n        returns into annual returns. Value should be the annual frequency of\n        `returns`.\n\n\n    Returns\n    -------\n    calmar_ratio : float\n        Calmar ratio (drawdown ratio) as float. Returns np.nan if there is no\n        calmar ratio.\n\n    Note\n    -----\n    See https://en.wikipedia.org/wiki/Calmar_ratio for more details.\n    \"\"\"\n\n    max_dd = max_drawdown(returns=returns)\n    if max_dd < 0:\n        temp = annual_return(\n            returns=returns,\n            period=period,\n            annualization=annualization\n        ) / abs(max_dd)\n    else:\n        return np.nan\n\n    if np.isinf(temp):\n        return np.nan\n\n    return temp"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef omega_ratio(returns, risk_free=0.0, required_return=0.0,\n                annualization=APPROX_BDAYS_PER_YEAR):\n    \"\"\"Determines the Omega ratio of a strategy.\n\n    Parameters\n    ----------\n    returns : pd.Series or np.ndarray\n        Daily returns of the strategy, noncumulative.\n        - See full explanation in :func:`~empyrical.stats.cum_returns`.\n    risk_free : int, float\n        Constant risk-free return throughout the period\n    required_return : float, optional\n        Minimum acceptance return of the investor. Threshold over which to\n        consider positive vs negative returns. It will be converted to a\n        value appropriate for the period of the returns. E.g. An annual minimum\n        acceptable return of 100 will translate to a minimum acceptable\n        return of 0.018.\n    annualization : int, optional\n        Factor used to convert the required_return into a daily\n        value. Enter 1 if no time period conversion is necessary.\n\n    Returns\n    -------\n    omega_ratio : float\n\n    Note\n    -----\n    See https://en.wikipedia.org/wiki/Omega_ratio for more details.\n\n    \"\"\"\n\n    if len(returns) < 2:\n        return np.nan\n\n    if annualization == 1:\n        return_threshold = required_return\n    elif required_return <= -1:\n        return np.nan\n    else:\n        return_threshold = (1 + required_return) ** \\\n            (1. / annualization) - 1\n\n    returns_less_thresh = returns - risk_free - return_threshold\n\n    numer = sum(returns_less_thresh[returns_less_thresh > 0.0])\n    denom = -1.0 * sum(returns_less_thresh[returns_less_thresh < 0.0])\n\n    if denom > 0.0:\n        return numer / denom\n    else:\n        return np.nan", "response": "Determines the Omega ratio of a strategy."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sharpe_ratio(returns,\n                 risk_free=0,\n                 period=DAILY,\n                 annualization=None,\n                 out=None):\n    \"\"\"\n    Determines the Sharpe ratio of a strategy.\n\n    Parameters\n    ----------\n    returns : pd.Series or np.ndarray\n        Daily returns of the strategy, noncumulative.\n        - See full explanation in :func:`~empyrical.stats.cum_returns`.\n    risk_free : int, float\n        Constant risk-free return throughout the period.\n    period : str, optional\n        Defines the periodicity of the 'returns' data for purposes of\n        annualizing. Value ignored if `annualization` parameter is specified.\n        Defaults are::\n\n            'monthly':12\n            'weekly': 52\n            'daily': 252\n\n    annualization : int, optional\n        Used to suppress default values available in `period` to convert\n        returns into annual returns. Value should be the annual frequency of\n        `returns`.\n    out : array-like, optional\n        Array to use as output buffer.\n        If not passed, a new array will be created.\n\n    Returns\n    -------\n    sharpe_ratio : float\n        nan if insufficient length of returns or if if adjusted returns are 0.\n\n    Note\n    -----\n    See https://en.wikipedia.org/wiki/Sharpe_ratio for more details.\n\n    \"\"\"\n    allocated_output = out is None\n    if allocated_output:\n        out = np.empty(returns.shape[1:])\n\n    return_1d = returns.ndim == 1\n\n    if len(returns) < 2:\n        out[()] = np.nan\n        if return_1d:\n            out = out.item()\n        return out\n\n    returns_risk_adj = np.asanyarray(_adjust_returns(returns, risk_free))\n    ann_factor = annualization_factor(period, annualization)\n\n    np.multiply(\n        np.divide(\n            nanmean(returns_risk_adj, axis=0),\n            nanstd(returns_risk_adj, ddof=1, axis=0),\n            out=out,\n        ),\n        np.sqrt(ann_factor),\n        out=out,\n    )\n    if return_1d:\n        out = out.item()\n\n    return out", "response": "Returns the Sharpe ratio of a strategy."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sortino_ratio(returns,\n                  required_return=0,\n                  period=DAILY,\n                  annualization=None,\n                  out=None,\n                  _downside_risk=None):\n    \"\"\"\n    Determines the Sortino ratio of a strategy.\n\n    Parameters\n    ----------\n    returns : pd.Series or np.ndarray or pd.DataFrame\n        Daily returns of the strategy, noncumulative.\n        - See full explanation in :func:`~empyrical.stats.cum_returns`.\n    required_return: float / series\n        minimum acceptable return\n    period : str, optional\n        Defines the periodicity of the 'returns' data for purposes of\n        annualizing. Value ignored if `annualization` parameter is specified.\n        Defaults are::\n\n            'monthly':12\n            'weekly': 52\n            'daily': 252\n\n    annualization : int, optional\n        Used to suppress default values available in `period` to convert\n        returns into annual returns. Value should be the annual frequency of\n        `returns`.\n    _downside_risk : float, optional\n        The downside risk of the given inputs, if known. Will be calculated if\n        not provided.\n    out : array-like, optional\n        Array to use as output buffer.\n        If not passed, a new array will be created.\n\n    Returns\n    -------\n    sortino_ratio : float or pd.Series\n\n        depends on input type\n        series ==> float\n        DataFrame ==> pd.Series\n\n    Note\n    -----\n    See `<https://www.sunrisecapital.com/wp-content/uploads/2014/06/Futures_\n    Mag_Sortino_0213.pdf>`__ for more details.\n\n    \"\"\"\n    allocated_output = out is None\n    if allocated_output:\n        out = np.empty(returns.shape[1:])\n\n    return_1d = returns.ndim == 1\n\n    if len(returns) < 2:\n        out[()] = np.nan\n        if return_1d:\n            out = out.item()\n        return out\n\n    adj_returns = np.asanyarray(_adjust_returns(returns, required_return))\n\n    ann_factor = annualization_factor(period, annualization)\n\n    average_annual_return = nanmean(adj_returns, axis=0) * ann_factor\n    annualized_downside_risk = (\n        _downside_risk\n        if _downside_risk is not None else\n        downside_risk(returns, required_return, period, annualization)\n    )\n    np.divide(average_annual_return, annualized_downside_risk, out=out)\n    if return_1d:\n        out = out.item()\n    elif isinstance(returns, pd.DataFrame):\n        out = pd.Series(out)\n\n    return out", "response": "Determines the Sortino ratio of a strategy."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef downside_risk(returns,\n                  required_return=0,\n                  period=DAILY,\n                  annualization=None,\n                  out=None):\n    \"\"\"\n    Determines the downside deviation below a threshold\n\n    Parameters\n    ----------\n    returns : pd.Series or np.ndarray or pd.DataFrame\n        Daily returns of the strategy, noncumulative.\n        - See full explanation in :func:`~empyrical.stats.cum_returns`.\n    required_return: float / series\n        minimum acceptable return\n    period : str, optional\n        Defines the periodicity of the 'returns' data for purposes of\n        annualizing. Value ignored if `annualization` parameter is specified.\n        Defaults are::\n\n            'monthly':12\n            'weekly': 52\n            'daily': 252\n\n    annualization : int, optional\n        Used to suppress default values available in `period` to convert\n        returns into annual returns. Value should be the annual frequency of\n        `returns`.\n    out : array-like, optional\n        Array to use as output buffer.\n        If not passed, a new array will be created.\n\n    Returns\n    -------\n    downside_deviation : float or pd.Series\n        depends on input type\n        series ==> float\n        DataFrame ==> pd.Series\n\n    Note\n    -----\n    See `<https://www.sunrisecapital.com/wp-content/uploads/2014/06/Futures_\n    Mag_Sortino_0213.pdf>`__ for more details, specifically why using the\n    standard deviation of the negative returns is not correct.\n    \"\"\"\n    allocated_output = out is None\n    if allocated_output:\n        out = np.empty(returns.shape[1:])\n\n    returns_1d = returns.ndim == 1\n\n    if len(returns) < 1:\n        out[()] = np.nan\n        if returns_1d:\n            out = out.item()\n        return out\n\n    ann_factor = annualization_factor(period, annualization)\n\n    downside_diff = np.clip(\n        _adjust_returns(\n            np.asanyarray(returns),\n            np.asanyarray(required_return),\n        ),\n        np.NINF,\n        0,\n    )\n\n    np.square(downside_diff, out=downside_diff)\n    nanmean(downside_diff, axis=0, out=out)\n    np.sqrt(out, out=out)\n    np.multiply(out, np.sqrt(ann_factor), out=out)\n\n    if returns_1d:\n        out = out.item()\n    elif isinstance(returns, pd.DataFrame):\n        out = pd.Series(out, index=returns.columns)\n    return out", "response": "Returns a base - level downside - risk of a given set of returns."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndetermining the Excess Sharpe of a strategy.", "response": "def excess_sharpe(returns, factor_returns, out=None):\n    \"\"\"\n    Determines the Excess Sharpe of a strategy.\n\n    Parameters\n    ----------\n    returns : pd.Series or np.ndarray\n        Daily returns of the strategy, noncumulative.\n        - See full explanation in :func:`~empyrical.stats.cum_returns`.\n    factor_returns: float / series\n        Benchmark return to compare returns against.\n    out : array-like, optional\n        Array to use as output buffer.\n        If not passed, a new array will be created.\n\n    Returns\n    -------\n    excess_sharpe : float\n\n    Note\n    -----\n    The excess Sharpe is a simplified Information Ratio that uses\n    tracking error rather than \"active risk\" as the denominator.\n    \"\"\"\n    allocated_output = out is None\n    if allocated_output:\n        out = np.empty(returns.shape[1:])\n\n    returns_1d = returns.ndim == 1\n\n    if len(returns) < 2:\n        out[()] = np.nan\n        if returns_1d:\n            out = out.item()\n        return out\n\n    active_return = _adjust_returns(returns, factor_returns)\n    tracking_error = np.nan_to_num(nanstd(active_return, ddof=1, axis=0))\n\n    out = np.divide(\n        nanmean(active_return, axis=0, out=out),\n        tracking_error,\n        out=out,\n    )\n    if returns_1d:\n        out = out.item()\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _to_pandas(ob):\n    if isinstance(ob, (pd.Series, pd.DataFrame)):\n        return ob\n\n    if ob.ndim == 1:\n        return pd.Series(ob)\n    elif ob.ndim == 2:\n        return pd.DataFrame(ob)\n    else:\n        raise ValueError(\n            'cannot convert array of dim > 2 to a pandas structure',\n        )", "response": "Convert an array - like object to a pandas object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a new list of series containing the data in the input series but with their indices aligned.", "response": "def _aligned_series(*many_series):\n    \"\"\"\n    Return a new list of series containing the data in the input series, but\n    with their indices aligned. NaNs will be filled in for missing values.\n\n    Parameters\n    ----------\n    *many_series\n        The series to align.\n\n    Returns\n    -------\n    aligned_series : iterable[array-like]\n        A new list of series containing the data in the input series, but\n        with their indices aligned. NaNs will be filled in for missing values.\n\n    \"\"\"\n    head = many_series[0]\n    tail = many_series[1:]\n    n = len(head)\n    if (isinstance(head, np.ndarray) and\n            all(len(s) == n and isinstance(s, np.ndarray) for s in tail)):\n        # optimization: ndarrays of the same length are already aligned\n        return many_series\n\n    # dataframe has no ``itervalues``\n    return (\n        v\n        for _, v in iteritems(pd.concat(map(_to_pandas, many_series), axis=1))\n    )"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalculates annualized alpha and beta of a single entry in a single tree.", "response": "def alpha_beta(returns,\n               factor_returns,\n               risk_free=0.0,\n               period=DAILY,\n               annualization=None,\n               out=None):\n    \"\"\"Calculates annualized alpha and beta.\n\n    Parameters\n    ----------\n    returns : pd.Series\n        Daily returns of the strategy, noncumulative.\n        - See full explanation in :func:`~empyrical.stats.cum_returns`.\n    factor_returns : pd.Series\n         Daily noncumulative returns of the factor to which beta is\n         computed. Usually a benchmark such as the market.\n         - This is in the same style as returns.\n    risk_free : int, float, optional\n        Constant risk-free return throughout the period. For example, the\n        interest rate on a three month us treasury bill.\n    period : str, optional\n        Defines the periodicity of the 'returns' data for purposes of\n        annualizing. Value ignored if `annualization` parameter is specified.\n        Defaults are::\n\n            'monthly':12\n            'weekly': 52\n            'daily': 252\n\n    annualization : int, optional\n        Used to suppress default values available in `period` to convert\n        returns into annual returns. Value should be the annual frequency of\n        `returns`.\n    out : array-like, optional\n        Array to use as output buffer.\n        If not passed, a new array will be created.\n\n    Returns\n    -------\n    alpha : float\n    beta : float\n    \"\"\"\n    returns, factor_returns = _aligned_series(returns, factor_returns)\n\n    return alpha_beta_aligned(\n        returns,\n        factor_returns,\n        risk_free=risk_free,\n        period=period,\n        annualization=annualization,\n        out=out,\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalculates alpha and beta over a rolling window.", "response": "def roll_alpha_beta(returns, factor_returns, window=10, **kwargs):\n    \"\"\"\n    Computes alpha and beta over a rolling window.\n\n    Parameters\n    ----------\n    lhs : array-like\n        The first array to pass to the rolling alpha-beta.\n    rhs : array-like\n        The second array to pass to the rolling alpha-beta.\n    window : int\n        Size of the rolling window in terms of the periodicity of the data.\n    out : array-like, optional\n        Array to use as output buffer.\n        If not passed, a new array will be created.\n    **kwargs\n        Forwarded to :func:`~empyrical.alpha_beta`.\n    \"\"\"\n    returns, factor_returns = _aligned_series(returns, factor_returns)\n\n    return roll_alpha_beta_aligned(\n        returns,\n        factor_returns,\n        window=window,\n        **kwargs\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef alpha_beta_aligned(returns,\n                       factor_returns,\n                       risk_free=0.0,\n                       period=DAILY,\n                       annualization=None,\n                       out=None):\n    \"\"\"Calculates annualized alpha and beta.\n\n    If they are pd.Series, expects returns and factor_returns have already\n    been aligned on their labels.  If np.ndarray, these arguments should have\n    the same shape.\n\n    Parameters\n    ----------\n    returns : pd.Series or np.ndarray\n        Daily returns of the strategy, noncumulative.\n        - See full explanation in :func:`~empyrical.stats.cum_returns`.\n    factor_returns : pd.Series or np.ndarray\n         Daily noncumulative returns of the factor to which beta is\n         computed. Usually a benchmark such as the market.\n         - This is in the same style as returns.\n    risk_free : int, float, optional\n        Constant risk-free return throughout the period. For example, the\n        interest rate on a three month us treasury bill.\n    period : str, optional\n        Defines the periodicity of the 'returns' data for purposes of\n        annualizing. Value ignored if `annualization` parameter is specified.\n        Defaults are::\n\n            'monthly':12\n            'weekly': 52\n            'daily': 252\n\n    annualization : int, optional\n        Used to suppress default values available in `period` to convert\n        returns into annual returns. Value should be the annual frequency of\n        `returns`.\n    out : array-like, optional\n        Array to use as output buffer.\n        If not passed, a new array will be created.\n\n    Returns\n    -------\n    alpha : float\n    beta : float\n    \"\"\"\n    if out is None:\n        out = np.empty(returns.shape[1:] + (2,), dtype='float64')\n\n    b = beta_aligned(returns, factor_returns, risk_free, out=out[..., 1])\n    alpha_aligned(\n        returns,\n        factor_returns,\n        risk_free,\n        period,\n        annualization,\n        out=out[..., 0],\n        _beta=b,\n    )\n\n    return out", "response": "Calculates annualized alpha and beta of a single entry in a tree."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncalculate annualized alpha for a set of returns and factor returns.", "response": "def alpha(returns,\n          factor_returns,\n          risk_free=0.0,\n          period=DAILY,\n          annualization=None,\n          out=None,\n          _beta=None):\n    \"\"\"Calculates annualized alpha.\n\n    Parameters\n    ----------\n    returns : pd.Series\n        Daily returns of the strategy, noncumulative.\n        - See full explanation in :func:`~empyrical.stats.cum_returns`.\n    factor_returns : pd.Series\n        Daily noncumulative returns of the factor to which beta is\n        computed. Usually a benchmark such as the market.\n        - This is in the same style as returns.\n    risk_free : int, float, optional\n        Constant risk-free return throughout the period. For example, the\n        interest rate on a three month us treasury bill.\n    period : str, optional\n        Defines the periodicity of the 'returns' data for purposes of\n        annualizing. Value ignored if `annualization` parameter is specified.\n        Defaults are::\n\n            'monthly':12\n            'weekly': 52\n            'daily': 252\n\n    annualization : int, optional\n        Used to suppress default values available in `period` to convert\n        returns into annual returns. Value should be the annual frequency of\n        `returns`.\n        - See full explanation in :func:`~empyrical.stats.annual_return`.\n    _beta : float, optional\n        The beta for the given inputs, if already known. Will be calculated\n        internally if not provided.\n    out : array-like, optional\n        Array to use as output buffer.\n        If not passed, a new array will be created.\n\n    Returns\n    -------\n    float\n        Alpha.\n    \"\"\"\n    if not (isinstance(returns, np.ndarray) and\n            isinstance(factor_returns, np.ndarray)):\n        returns, factor_returns = _aligned_series(returns, factor_returns)\n\n    return alpha_aligned(\n        returns,\n        factor_returns,\n        risk_free=risk_free,\n        period=period,\n        annualization=annualization,\n        out=out,\n        _beta=_beta\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef alpha_aligned(returns,\n                  factor_returns,\n                  risk_free=0.0,\n                  period=DAILY,\n                  annualization=None,\n                  out=None,\n                  _beta=None):\n    \"\"\"Calculates annualized alpha.\n\n    If they are pd.Series, expects returns and factor_returns have already\n    been aligned on their labels.  If np.ndarray, these arguments should have\n    the same shape.\n\n    Parameters\n    ----------\n    returns : pd.Series or np.ndarray\n        Daily returns of the strategy, noncumulative.\n        - See full explanation in :func:`~empyrical.stats.cum_returns`.\n    factor_returns : pd.Series or np.ndarray\n        Daily noncumulative returns of the factor to which beta is\n        computed. Usually a benchmark such as the market.\n        - This is in the same style as returns.\n    risk_free : int, float, optional\n        Constant risk-free return throughout the period. For example, the\n        interest rate on a three month us treasury bill.\n    period : str, optional\n        Defines the periodicity of the 'returns' data for purposes of\n        annualizing. Value ignored if `annualization` parameter is specified.\n        Defaults are::\n\n            'monthly':12\n            'weekly': 52\n            'daily': 252\n\n    annualization : int, optional\n        Used to suppress default values available in `period` to convert\n        returns into annual returns. Value should be the annual frequency of\n        `returns`.\n        - See full explanation in :func:`~empyrical.stats.annual_return`.\n    _beta : float, optional\n        The beta for the given inputs, if already known. Will be calculated\n        internally if not provided.\n    out : array-like, optional\n        Array to use as output buffer.\n        If not passed, a new array will be created.\n\n    Returns\n    -------\n    alpha : float\n    \"\"\"\n    allocated_output = out is None\n    if allocated_output:\n        out = np.empty(returns.shape[1:], dtype='float64')\n\n    if len(returns) < 2:\n        out[()] = np.nan\n        if returns.ndim == 1:\n            out = out.item()\n        return out\n\n    ann_factor = annualization_factor(period, annualization)\n\n    if _beta is None:\n        _beta = beta_aligned(returns, factor_returns, risk_free)\n\n    adj_returns = _adjust_returns(returns, risk_free)\n    adj_factor_returns = _adjust_returns(factor_returns, risk_free)\n    alpha_series = adj_returns - (_beta * adj_factor_returns)\n\n    out = np.multiply(\n        nanmean(alpha_series, axis=0, out=out),\n        ann_factor,\n        out=out,\n    )\n\n    if allocated_output and isinstance(returns, pd.DataFrame):\n        out = pd.Series(out)\n\n    if returns.ndim == 1:\n        out = out.item()\n\n    return out", "response": "Calculates annualized alpha for a given set of returns and factor_returns."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef beta(returns, factor_returns, risk_free=0.0, out=None):\n    if not (isinstance(returns, np.ndarray) and\n            isinstance(factor_returns, np.ndarray)):\n        returns, factor_returns = _aligned_series(returns, factor_returns)\n\n    return beta_aligned(\n        returns,\n        factor_returns,\n        risk_free=risk_free,\n        out=out,\n    )", "response": "Calculates beta of a single entry in a node."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef beta_aligned(returns, factor_returns, risk_free=0.0, out=None):\n    # Cache these as locals since we're going to call them multiple times.\n    nan = np.nan\n    isnan = np.isnan\n\n    returns_1d = returns.ndim == 1\n    if returns_1d:\n        returns = returns[:, np.newaxis]\n\n    if factor_returns.ndim == 1:\n        factor_returns = factor_returns[:, np.newaxis]\n\n    N, M = returns.shape\n\n    if out is None:\n        out = np.full(M, nan)\n    elif out.ndim == 0:\n        out = out[np.newaxis]\n\n    if len(returns) < 1 or len(factor_returns) < 2:\n        out[()] = nan\n        if returns_1d:\n            out = out.item()\n        return out\n\n    # Copy N times as a column vector and fill with nans to have the same\n    # missing value pattern as the dependent variable.\n    #\n    # PERF_TODO: We could probably avoid the space blowup by doing this in\n    # Cython.\n\n    # shape: (N, M)\n    independent = np.where(\n        isnan(returns),\n        nan,\n        factor_returns,\n    )\n\n    # Calculate beta as Cov(X, Y) / Cov(X, X).\n    # https://en.wikipedia.org/wiki/Simple_linear_regression#Fitting_the_regression_line  # noqa\n    #\n    # NOTE: The usual formula for covariance is::\n    #\n    #    mean((X - mean(X)) * (Y - mean(Y)))\n    #\n    # However, we don't actually need to take the mean of both sides of the\n    # product, because of the folllowing equivalence::\n    #\n    # Let X_res = (X - mean(X)).\n    # We have:\n    #\n    #     mean(X_res * (Y - mean(Y))) = mean(X_res * (Y - mean(Y)))\n    #                             (1) = mean((X_res * Y) - (X_res * mean(Y)))\n    #                             (2) = mean(X_res * Y) - mean(X_res * mean(Y))\n    #                             (3) = mean(X_res * Y) - mean(X_res) * mean(Y)\n    #                             (4) = mean(X_res * Y) - 0 * mean(Y)\n    #                             (5) = mean(X_res * Y)\n    #\n    #\n    # The tricky step in the above derivation is step (4). We know that\n    # mean(X_res) is zero because, for any X:\n    #\n    #     mean(X - mean(X)) = mean(X) - mean(X) = 0.\n    #\n    # The upshot of this is that we only have to center one of `independent`\n    # and `dependent` when calculating covariances. Since we need the centered\n    # `independent` to calculate its variance in the next step, we choose to\n    # center `independent`.\n\n    ind_residual = independent - nanmean(independent, axis=0)\n\n    covariances = nanmean(ind_residual * returns, axis=0)\n\n    # We end up with different variances in each column here because each\n    # column may have a different subset of the data dropped due to missing\n    # data in the corresponding dependent column.\n    # shape: (M,)\n    np.square(ind_residual, out=ind_residual)\n    independent_variances = nanmean(ind_residual, axis=0)\n    independent_variances[independent_variances < 1.0e-30] = np.nan\n\n    np.divide(covariances, independent_variances, out=out)\n\n    if returns_1d:\n        out = out.item()\n\n    return out", "response": "Calculates beta of a single item."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef stability_of_timeseries(returns):\n    if len(returns) < 2:\n        return np.nan\n\n    returns = np.asanyarray(returns)\n    returns = returns[~np.isnan(returns)]\n\n    cum_log_returns = np.log1p(returns).cumsum()\n    rhat = stats.linregress(np.arange(len(cum_log_returns)),\n                            cum_log_returns)[2]\n\n    return rhat ** 2", "response": "Determines the R - squared of a linear fit to the cumulative\n    log returns."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef tail_ratio(returns):\n\n    if len(returns) < 1:\n        return np.nan\n\n    returns = np.asanyarray(returns)\n    # Be tolerant of nan's\n    returns = returns[~np.isnan(returns)]\n    if len(returns) < 1:\n        return np.nan\n\n    return np.abs(np.percentile(returns, 95)) / \\\n        np.abs(np.percentile(returns, 5))", "response": "Determines the ratio between the right and left tail."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef capture(returns, factor_returns, period=DAILY):\n    return (annual_return(returns, period=period) /\n            annual_return(factor_returns, period=period))", "response": "Compute the capture ratio of a given returns and factor."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef up_capture(returns, factor_returns, **kwargs):\n    return up(returns, factor_returns, function=capture, **kwargs)", "response": "Compute the capture ratio for periods when the benchmark return is positive\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef down_capture(returns, factor_returns, **kwargs):\n    return down(returns, factor_returns, function=capture, **kwargs)", "response": "Compute the capture ratio for periods when the benchmark return is negative."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncomputes the ratio of up_capture to down_capture.", "response": "def up_down_capture(returns, factor_returns, **kwargs):\n    \"\"\"\n    Computes the ratio of up_capture to down_capture.\n\n    Parameters\n    ----------\n    returns : pd.Series or np.ndarray\n        Returns of the strategy, noncumulative.\n        - See full explanation in :func:`~empyrical.stats.cum_returns`.\n    factor_returns : pd.Series or np.ndarray\n        Noncumulative returns of the factor to which beta is\n        computed. Usually a benchmark such as the market.\n        - This is in the same style as returns.\n    period : str, optional\n        Defines the periodicity of the 'returns' data for purposes of\n        annualizing. Value ignored if `annualization` parameter is specified.\n        Defaults are::\n\n            'monthly':12\n            'weekly': 52\n            'daily': 252\n\n    Returns\n    -------\n    up_down_capture : float\n        the updown capture ratio\n    \"\"\"\n    return (up_capture(returns, factor_returns, **kwargs) /\n            down_capture(returns, factor_returns, **kwargs))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a sequence of alpha and beta periods for periods when the benchmark return is positive.", "response": "def up_alpha_beta(returns, factor_returns, **kwargs):\n    \"\"\"\n    Computes alpha and beta for periods when the benchmark return is positive.\n\n    Parameters\n    ----------\n    see documentation for `alpha_beta`.\n\n    Returns\n    -------\n    float\n        Alpha.\n    float\n        Beta.\n    \"\"\"\n    return up(returns, factor_returns, function=alpha_beta_aligned, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncomputes alpha and beta for periods when the benchmark return is negative.", "response": "def down_alpha_beta(returns, factor_returns, **kwargs):\n    \"\"\"\n    Computes alpha and beta for periods when the benchmark return is negative.\n\n    Parameters\n    ----------\n    see documentation for `alpha_beta`.\n\n    Returns\n    -------\n    alpha : float\n    beta : float\n    \"\"\"\n    return down(returns, factor_returns, function=alpha_beta_aligned, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncomputes the up capture measure over a rolling window.", "response": "def roll_up_capture(returns, factor_returns, window=10, **kwargs):\n    \"\"\"\n    Computes the up capture measure over a rolling window.\n    see documentation for :func:`~empyrical.stats.up_capture`.\n    (pass all args, kwargs required)\n\n    Parameters\n    ----------\n    returns : pd.Series or np.ndarray\n        Daily returns of the strategy, noncumulative.\n        - See full explanation in :func:`~empyrical.stats.cum_returns`.\n\n    factor_returns : pd.Series or np.ndarray\n        Noncumulative returns of the factor to which beta is\n        computed. Usually a benchmark such as the market.\n        - This is in the same style as returns.\n\n    window : int, required\n        Size of the rolling window in terms of the periodicity of the data.\n        - eg window = 60, periodicity=DAILY, represents a rolling 60 day window\n    \"\"\"\n    return roll(returns, factor_returns, window=window, function=up_capture,\n                **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalculating the down capture measure over a rolling window.", "response": "def roll_down_capture(returns, factor_returns, window=10, **kwargs):\n    \"\"\"\n    Computes the down capture measure over a rolling window.\n    see documentation for :func:`~empyrical.stats.down_capture`.\n    (pass all args, kwargs required)\n\n    Parameters\n    ----------\n    returns : pd.Series or np.ndarray\n        Daily returns of the strategy, noncumulative.\n        - See full explanation in :func:`~empyrical.stats.cum_returns`.\n\n    factor_returns : pd.Series or np.ndarray\n        Noncumulative returns of the factor to which beta is\n        computed. Usually a benchmark such as the market.\n        - This is in the same style as returns.\n\n    window : int, required\n        Size of the rolling window in terms of the periodicity of the data.\n        - eg window = 60, periodicity=DAILY, represents a rolling 60 day window\n    \"\"\"\n    return roll(returns, factor_returns, window=window, function=down_capture,\n                **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncomputing the up - down capture measure over a rolling window.", "response": "def roll_up_down_capture(returns, factor_returns, window=10, **kwargs):\n    \"\"\"\n    Computes the up/down capture measure over a rolling window.\n    see documentation for :func:`~empyrical.stats.up_down_capture`.\n    (pass all args, kwargs required)\n\n    Parameters\n    ----------\n    returns : pd.Series or np.ndarray\n        Daily returns of the strategy, noncumulative.\n        - See full explanation in :func:`~empyrical.stats.cum_returns`.\n\n    factor_returns : pd.Series or np.ndarray\n        Noncumulative returns of the factor to which beta is\n        computed. Usually a benchmark such as the market.\n        - This is in the same style as returns.\n\n    window : int, required\n        Size of the rolling window in terms of the periodicity of the data.\n        - eg window = 60, periodicity=DAILY, represents a rolling 60 day window\n    \"\"\"\n    return roll(returns, factor_returns, window=window,\n                function=up_down_capture, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate the conditional value at risk CVaR of a returns stream.", "response": "def conditional_value_at_risk(returns, cutoff=0.05):\n    \"\"\"\n    Conditional value at risk (CVaR) of a returns stream.\n\n    CVaR measures the expected single-day returns of an asset on that asset's\n    worst performing days, where \"worst-performing\" is defined as falling below\n    ``cutoff`` as a percentile of all daily returns.\n\n    Parameters\n    ----------\n    returns : pandas.Series or 1-D numpy.array\n        Non-cumulative daily returns.\n    cutoff : float, optional\n        Decimal representing the percentage cutoff for the bottom percentile of\n        returns. Defaults to 0.05.\n\n    Returns\n    -------\n    CVaR : float\n        The CVaR value.\n    \"\"\"\n    # PERF: Instead of using the 'value_at_risk' function to find the cutoff\n    # value, which requires a call to numpy.percentile, determine the cutoff\n    # index manually and partition out the lowest returns values. The value at\n    # the cutoff index should be included in the partition.\n    cutoff_index = int((len(returns) - 1) * cutoff)\n    return np.mean(np.partition(returns, cutoff_index)[:cutoff_index + 1])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef roll(*args, **kwargs):\n    func = kwargs.pop('function')\n    window = kwargs.pop('window')\n    if len(args) > 2:\n        raise ValueError(\"Cannot pass more than 2 return sets\")\n\n    if len(args) == 2:\n        if not isinstance(args[0], type(args[1])):\n            raise ValueError(\"The two returns arguments are not the same.\")\n\n    if isinstance(args[0], np.ndarray):\n        return _roll_ndarray(func, window, *args, **kwargs)\n    return _roll_pandas(func, window, *args, **kwargs)", "response": "Calculates a given statistic across a rolling time period."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncalculate a given statistic filtering only positive factor return periods.", "response": "def up(returns, factor_returns, **kwargs):\n    \"\"\"\n    Calculates a given statistic filtering only positive factor return periods.\n\n    Parameters\n    ----------\n    returns : pd.Series or np.ndarray\n        Daily returns of the strategy, noncumulative.\n        - See full explanation in :func:`~empyrical.stats.cum_returns`.\n    factor_returns (optional): float / series\n        Benchmark return to compare returns against.\n    function:\n        the function to run for each rolling window.\n    (other keywords): other keywords that are required to be passed to the\n        function in the 'function' argument may also be passed in.\n\n    Returns\n    -------\n    Same as the return of the function\n    \"\"\"\n    func = kwargs.pop('function')\n    returns = returns[factor_returns > 0]\n    factor_returns = factor_returns[factor_returns > 0]\n    return func(returns, factor_returns, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating a given statistic filtering only negative factor return periods.", "response": "def down(returns, factor_returns, **kwargs):\n    \"\"\"\n    Calculates a given statistic filtering only negative factor return periods.\n\n    Parameters\n    ----------\n    returns : pd.Series or np.ndarray\n        Daily returns of the strategy, noncumulative.\n        - See full explanation in :func:`~empyrical.stats.cum_returns`.\n    factor_returns (optional): float / series\n        Benchmark return to compare returns against.\n    function:\n        the function to run for each rolling window.\n    (other keywords): other keywords that are required to be passed to the\n        function in the 'function' argument may also be passed in.\n\n    Returns\n    -------\n    Same as the return of the 'function'\n    \"\"\"\n    func = kwargs.pop('function')\n    returns = returns[factor_returns < 0]\n    factor_returns = factor_returns[factor_returns < 0]\n    return func(returns, factor_returns, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the Timestamp or DatetimeIndex of the input date in UTC.", "response": "def get_utc_timestamp(dt):\n    \"\"\"\n    Returns the Timestamp/DatetimeIndex\n    with either localized or converted to UTC.\n\n    Parameters\n    ----------\n    dt : Timestamp/DatetimeIndex\n        the date(s) to be converted\n\n    Returns\n    -------\n    same type as input\n        date(s) converted to UTC\n    \"\"\"\n\n    dt = pd.to_datetime(dt)\n    try:\n        dt = dt.tz_localize('UTC')\n    except TypeError:\n        dt = dt.tz_convert('UTC')\n    return dt"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nretrieving Fama - French factors via pandas - datareader Returns ------- pandas. DataFrame", "response": "def get_fama_french():\n    \"\"\"\n    Retrieve Fama-French factors via pandas-datareader\n    Returns\n    -------\n    pandas.DataFrame\n        Percent change of Fama-French factors\n    \"\"\"\n\n    start = '1/1/1970'\n    research_factors = web.DataReader('F-F_Research_Data_Factors_daily',\n                                      'famafrench', start=start)[0]\n    momentum_factor = web.DataReader('F-F_Momentum_Factor_daily',\n                                     'famafrench', start=start)[0]\n    five_factors = research_factors.join(momentum_factor).dropna()\n    five_factors /= 100.\n    five_factors.index = five_factors.index.tz_localize('utc')\n\n    five_factors.columns = five_factors.columns.str.strip()\n\n    return five_factors"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget returns from a cached csv file if the cache is recent enough update the cache file if it is up - to - date.", "response": "def get_returns_cached(filepath, update_func, latest_dt, **kwargs):\n    \"\"\"\n    Get returns from a cached file if the cache is recent enough,\n    otherwise, try to retrieve via a provided update function and\n    update the cache file.\n    Parameters\n    ----------\n    filepath : str\n        Path to cached csv file\n    update_func : function\n        Function to call in case cache is not up-to-date.\n    latest_dt : pd.Timestamp (tz=UTC)\n        Latest datetime required in csv file.\n    **kwargs : Keyword arguments\n        Optional keyword arguments will be passed to update_func()\n    Returns\n    -------\n    pandas.DataFrame\n        DataFrame containing returns\n    \"\"\"\n\n    update_cache = False\n\n    try:\n        mtime = getmtime(filepath)\n    except OSError as e:\n        if e.errno != errno.ENOENT:\n            raise\n        update_cache = True\n    else:\n\n        file_dt = pd.Timestamp(mtime, unit='s')\n\n        if latest_dt.tzinfo:\n            file_dt = file_dt.tz_localize('utc')\n\n        if file_dt < latest_dt:\n            update_cache = True\n        else:\n            returns = pd.read_csv(filepath, index_col=0, parse_dates=True)\n            returns.index = returns.index.tz_localize(\"UTC\")\n\n    if update_cache:\n        returns = update_func(**kwargs)\n        try:\n            ensure_directory(cache_dir())\n        except OSError as e:\n            warnings.warn(\n                'could not update cache: {}. {}: {}'.format(\n                    filepath, type(e).__name__, e,\n                ),\n                UserWarning,\n            )\n\n        try:\n            returns.to_csv(filepath)\n        except OSError as e:\n            warnings.warn(\n                'could not update cache {}. {}: {}'.format(\n                    filepath, type(e).__name__, e,\n                ),\n                UserWarning,\n            )\n\n    return returns"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload risk factors from a file.", "response": "def load_portfolio_risk_factors(filepath_prefix=None, start=None, end=None):\n    \"\"\"\n    Load risk factors Mkt-Rf, SMB, HML, Rf, and UMD.\n    Data is stored in HDF5 file. If the data is more than 2\n    days old, redownload from Dartmouth.\n    Returns\n    -------\n    five_factors : pd.DataFrame\n        Risk factors timeseries.\n    \"\"\"\n\n    if start is None:\n        start = '1/1/1970'\n    if end is None:\n        end = _1_bday_ago()\n\n    start = get_utc_timestamp(start)\n    end = get_utc_timestamp(end)\n\n    if filepath_prefix is None:\n        filepath = data_path('factors.csv')\n    else:\n        filepath = filepath_prefix\n\n    five_factors = get_returns_cached(filepath, get_fama_french, end)\n\n    return five_factors.loc[start:end]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload the treasury yields from FRED.", "response": "def get_treasury_yield(start=None, end=None, period='3MO'):\n    \"\"\"\n    Load treasury yields from FRED.\n\n    Parameters\n    ----------\n    start : date, optional\n        Earliest date to fetch data for.\n        Defaults to earliest date available.\n    end : date, optional\n        Latest date to fetch data for.\n        Defaults to latest date available.\n    period : {'1MO', '3MO', '6MO', 1', '5', '10'}, optional\n        Which maturity to use.\n    Returns\n    -------\n    pd.Series\n        Annual treasury yield for every day.\n    \"\"\"\n\n    if start is None:\n        start = '1/1/1970'\n    if end is None:\n        end = _1_bday_ago()\n\n    treasury = web.DataReader(\"DGS3{}\".format(period), \"fred\",\n                              start, end)\n\n    treasury = treasury.ffill()\n\n    return treasury"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwraps for pandas. io. data. get_data_yahoo. This function returns the returns of a given symbol in the requested period.", "response": "def get_symbol_returns_from_yahoo(symbol, start=None, end=None):\n    \"\"\"\n    Wrapper for pandas.io.data.get_data_yahoo().\n    Retrieves prices for symbol from yahoo and computes returns\n    based on adjusted closing prices.\n\n    Parameters\n    ----------\n    symbol : str\n        Symbol name to load, e.g. 'SPY'\n    start : pandas.Timestamp compatible, optional\n        Start date of time period to retrieve\n    end : pandas.Timestamp compatible, optional\n        End date of time period to retrieve\n\n    Returns\n    -------\n    pandas.DataFrame\n        Returns of symbol in requested period.\n    \"\"\"\n\n    try:\n        px = web.get_data_yahoo(symbol, start=start, end=end)\n        px['date'] = pd.to_datetime(px['date'])\n        px.set_index('date', drop=False, inplace=True)\n        rets = px[['adjclose']].pct_change().dropna()\n    except Exception as e:\n        warnings.warn(\n            'Yahoo Finance read failed: {}, falling back to Google'.format(e),\n            UserWarning)\n        px = web.get_data_google(symbol, start=start, end=end)\n        rets = px[['Close']].pct_change().dropna()\n\n    rets.index = rets.index.tz_localize(\"UTC\")\n    rets.columns = [symbol]\n    return rets"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndefaulting returns function for the given symbol.", "response": "def default_returns_func(symbol, start=None, end=None):\n    \"\"\"\n    Gets returns for a symbol.\n    Queries Yahoo Finance. Attempts to cache SPY.\n\n    Parameters\n    ----------\n    symbol : str\n        Ticker symbol, e.g. APPL.\n    start : date, optional\n        Earliest date to fetch data for.\n        Defaults to earliest date available.\n    end : date, optional\n        Latest date to fetch data for.\n        Defaults to latest date available.\n\n    Returns\n    -------\n    pd.Series\n        Daily returns for the symbol.\n         - See full explanation in tears.create_full_tear_sheet (returns).\n    \"\"\"\n\n    if start is None:\n        start = '1/1/1970'\n    if end is None:\n        end = _1_bday_ago()\n\n    start = get_utc_timestamp(start)\n    end = get_utc_timestamp(end)\n\n    if symbol == 'SPY':\n        filepath = data_path('spy.csv')\n        rets = get_returns_cached(filepath,\n                                  get_symbol_returns_from_yahoo,\n                                  end,\n                                  symbol='SPY',\n                                  start='1/1/1970',\n                                  end=datetime.now())\n        rets = rets[start:end]\n    else:\n        rets = get_symbol_returns_from_yahoo(symbol, start=start, end=end)\n\n    return rets[symbol]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef rolling_window(array, length, mutable=False):\n    if not length:\n        raise ValueError(\"Can't have 0-length window\")\n\n    orig_shape = array.shape\n    if not orig_shape:\n        raise IndexError(\"Can't restride a scalar.\")\n    elif orig_shape[0] < length:\n        raise IndexError(\n            \"Can't restride array of shape {shape} with\"\n            \" a window length of {len}\".format(\n                shape=orig_shape,\n                len=length,\n            )\n        )\n\n    num_windows = (orig_shape[0] - length + 1)\n    new_shape = (num_windows, length) + orig_shape[1:]\n\n    new_strides = (array.strides[0],) + array.strides\n\n    out = as_strided(array, new_shape, new_strides)\n    out.setflags(write=mutable)\n    return out", "response": "This function takes an array of length words and returns a new array of size length with the new ones."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef perf_attrib(returns,\n                positions,\n                factor_returns,\n                factor_loadings):\n    \"\"\"\n    Attributes the performance of a returns stream to a set of risk factors.\n\n    Performance attribution determines how much each risk factor, e.g.,\n    momentum, the technology sector, etc., contributed to total returns, as\n    well as the daily exposure to each of the risk factors. The returns that\n    can be attributed to one of the given risk factors are the\n    `common_returns`, and the returns that _cannot_ be attributed to a risk\n    factor are the `specific_returns`. The `common_returns` and\n    `specific_returns` summed together will always equal the total returns.\n\n    Parameters\n    ----------\n    returns : pd.Series\n        Returns for each day in the date range.\n        - Example:\n            2017-01-01   -0.017098\n            2017-01-02    0.002683\n            2017-01-03   -0.008669\n\n    positions: pd.Series\n        Daily holdings in percentages, indexed by date.\n        - Examples:\n            dt          ticker\n            2017-01-01  AAPL      0.417582\n                        TLT       0.010989\n                        XOM       0.571429\n            2017-01-02  AAPL      0.202381\n                        TLT       0.535714\n                        XOM       0.261905\n\n    factor_returns : pd.DataFrame\n        Returns by factor, with date as index and factors as columns\n        - Example:\n                        momentum  reversal\n            2017-01-01  0.002779 -0.005453\n            2017-01-02  0.001096  0.010290\n\n    factor_loadings : pd.DataFrame\n        Factor loadings for all days in the date range, with date and ticker as\n        index, and factors as columns.\n        - Example:\n                               momentum  reversal\n            dt         ticker\n            2017-01-01 AAPL   -1.592914  0.852830\n                       TLT     0.184864  0.895534\n                       XOM     0.993160  1.149353\n            2017-01-02 AAPL   -0.140009 -0.524952\n                       TLT    -1.066978  0.185435\n                       XOM    -1.798401  0.761549\n\n    Returns\n    -------\n    tuple of (risk_exposures_portfolio, perf_attribution)\n\n    risk_exposures_portfolio : pd.DataFrame\n        df indexed by datetime, with factors as columns\n        - Example:\n                        momentum  reversal\n            dt\n            2017-01-01 -0.238655  0.077123\n            2017-01-02  0.821872  1.520515\n\n    perf_attribution : pd.DataFrame\n        df with factors, common returns, and specific returns as columns,\n        and datetimes as index\n        - Example:\n                        momentum  reversal  common_returns  specific_returns\n            dt\n            2017-01-01  0.249087  0.935925        1.185012          1.185012\n            2017-01-02 -0.003194 -0.400786       -0.403980         -0.403980\n\n    Note\n    ----\n    See https://en.wikipedia.org/wiki/Performance_attribution for more details.\n    \"\"\"\n    risk_exposures_portfolio = compute_exposures(positions,\n                                                 factor_loadings)\n\n    perf_attrib_by_factor = risk_exposures_portfolio.multiply(factor_returns)\n\n    common_returns = perf_attrib_by_factor.sum(axis='columns')\n    specific_returns = returns - common_returns\n\n    returns_df = pd.DataFrame({'total_returns': returns,\n                               'common_returns': common_returns,\n                               'specific_returns': specific_returns})\n\n    return (risk_exposures_portfolio,\n            pd.concat([perf_attrib_by_factor, returns_df], axis='columns'))", "response": "This function is used to add the attributes to the performance of a single return stream to a set of risk factors."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompute daily risk factor exposures for a single record.", "response": "def compute_exposures(positions, factor_loadings):\n    \"\"\"\n    Compute daily risk factor exposures.\n\n    Parameters\n    ----------\n    positions: pd.Series\n        A series of holdings as percentages indexed by date and ticker.\n        - Examples:\n            dt          ticker\n            2017-01-01  AAPL      0.417582\n                        TLT       0.010989\n                        XOM       0.571429\n            2017-01-02  AAPL      0.202381\n                        TLT       0.535714\n                        XOM       0.261905\n\n    factor_loadings : pd.DataFrame\n        Factor loadings for all days in the date range, with date and ticker as\n        index, and factors as columns.\n        - Example:\n                               momentum  reversal\n            dt         ticker\n            2017-01-01 AAPL   -1.592914  0.852830\n                       TLT     0.184864  0.895534\n                       XOM     0.993160  1.149353\n            2017-01-02 AAPL   -0.140009 -0.524952\n                       TLT    -1.066978  0.185435\n                       XOM    -1.798401  0.761549\n\n    Returns\n    -------\n    risk_exposures_portfolio : pd.DataFrame\n        df indexed by datetime, with factors as columns\n        - Example:\n                        momentum  reversal\n            dt\n            2017-01-01 -0.238655  0.077123\n            2017-01-02  0.821872  1.520515\n    \"\"\"\n    risk_exposures = factor_loadings.multiply(positions, axis='rows')\n    return risk_exposures.groupby(level='dt').sum()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn True if there are pending test items.", "response": "def has_pending(self):\n        \"\"\"Return True if there are pending test items.\n\n        This indicates that collection has finished and nodes are still\n        processing test items, so this can be thought of as\n        \"the scheduler is active\".\n        \"\"\"\n        if self.workqueue:\n            return True\n\n        for assigned_unit in self.assigned_work.values():\n            if self._pending_of(assigned_unit) > 0:\n                return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_node(self, node):\n        assert node not in self.assigned_work\n        self.assigned_work[node] = OrderedDict()", "response": "Add a new node to the scheduler."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving a node from the scheduler.", "response": "def remove_node(self, node):\n        \"\"\"Remove a node from the scheduler.\n\n        This should be called either when the node crashed or at shutdown time.\n        In the former case any pending items assigned to the node will be\n        re-scheduled.\n\n        Called by the hooks:\n\n        - ``DSession.worker_workerfinished``.\n        - ``DSession.worker_errordown``.\n\n        Return the item being executed while the node crashed or None if the\n        node has no more pending items.\n        \"\"\"\n        workload = self.assigned_work.pop(node)\n        if not self._pending_of(workload):\n            return None\n\n        # The node crashed, identify test that crashed\n        for work_unit in workload.values():\n            for nodeid, completed in work_unit.items():\n                if not completed:\n                    crashitem = nodeid\n                    break\n            else:\n                continue\n            break\n        else:\n            raise RuntimeError(\n                \"Unable to identify crashitem on a workload with pending items\"\n            )\n\n        # Made uncompleted work unit available again\n        self.workqueue.update(workload)\n\n        for node in self.assigned_work:\n            self._reschedule(node)\n\n        return crashitem"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_node_collection(self, node, collection):\n\n        # Check that add_node() was called on the node before\n        assert node in self.assigned_work\n\n        # A new node has been added later, perhaps an original one died.\n        if self.collection_is_completed:\n\n            # Assert that .schedule() should have been called by now\n            assert self.collection\n\n            # Check that the new collection matches the official collection\n            if collection != self.collection:\n\n                other_node = next(iter(self.registered_collections.keys()))\n\n                msg = report_collection_diff(\n                    self.collection, collection, other_node.gateway.id, node.gateway.id\n                )\n                self.log(msg)\n                return\n\n        self.registered_collections[node] = list(collection)", "response": "Add the collected test items from a node."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _assign_work_unit(self, node):\n        assert self.workqueue\n\n        # Grab a unit of work\n        scope, work_unit = self.workqueue.popitem(last=False)\n\n        # Keep track of the assigned work\n        assigned_to_node = self.assigned_work.setdefault(node, default=OrderedDict())\n        assigned_to_node[scope] = work_unit\n\n        # Ask the node to execute the workload\n        worker_collection = self.registered_collections[node]\n        nodeids_indexes = [\n            worker_collection.index(nodeid)\n            for nodeid, completed in work_unit.items()\n            if not completed\n        ]\n\n        node.send_runtest_some(nodeids_indexes)", "response": "Assign a work unit to a node."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _pending_of(self, workload):\n        pending = sum(list(scope.values()).count(False) for scope in workload.values())\n        return pending", "response": "Return the number of pending tests in a workload."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if there are any pending work units left and if so add more work to the node.", "response": "def _reschedule(self, node):\n        \"\"\"Maybe schedule new items on the node.\n\n        If there are any globally pending work units left then this will check\n        if the given node should be given any more tests.\n        \"\"\"\n\n        # Do not add more work to a node shutting down\n        if node.shutting_down:\n            return\n\n        # Check that more work is available\n        if not self.workqueue:\n            node.shutdown()\n            return\n\n        self.log(\"Number of units waiting for node:\", len(self.workqueue))\n\n        # Check that the node is almost depleted of work\n        # 2: Heuristic of minimum tests to enqueue more work\n        if self._pending_of(self.assigned_work[node]) > 2:\n            return\n\n        # Pop one unit of work and assign it\n        self._assign_work_unit(node)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef schedule(self):\n        assert self.collection_is_completed\n\n        # Initial distribution already happened, reschedule on all nodes\n        if self.collection is not None:\n            for node in self.nodes:\n                self._reschedule(node)\n            return\n\n        # Check that all nodes collected the same tests\n        if not self._check_nodes_have_same_collection():\n            self.log(\"**Different tests collected, aborting run**\")\n            return\n\n        # Collections are identical, create the final list of items\n        self.collection = list(next(iter(self.registered_collections.values())))\n        if not self.collection:\n            return\n\n        # Determine chunks of work (scopes)\n        for nodeid in self.collection:\n            scope = self._split_scope(nodeid)\n            work_unit = self.workqueue.setdefault(scope, default=OrderedDict())\n            work_unit[nodeid] = False\n\n        # Avoid having more workers than work\n        extra_nodes = len(self.nodes) - len(self.workqueue)\n\n        if extra_nodes > 0:\n            self.log(\"Shuting down {0} nodes\".format(extra_nodes))\n\n            for _ in range(extra_nodes):\n                unused_node, assigned = self.assigned_work.popitem(last=True)\n\n                self.log(\"Shuting down unused node {0}\".format(unused_node))\n                unused_node.shutdown()\n\n        # Assign initial workload\n        for node in self.nodes:\n            self._assign_work_unit(node)\n\n        # Ensure nodes start with at least two work units if possible (#277)\n        for node in self.nodes:\n            self._reschedule(node)\n\n        # Initial distribution sent all tests, start node shutdown\n        if not self.workqueue:\n            for node in self.nodes:\n                node.shutdown()", "response": "Initiate the distribution of the items across the nodes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_node_collection(self, node, collection):\n        assert node in self.node2pending\n        if not self.collection_is_completed:\n            self.node2collection[node] = list(collection)\n            self.node2pending[node] = []\n            if len(self.node2collection) >= self.numnodes:\n                self.collection_is_completed = True\n        elif self._removed2pending:\n            for deadnode in self._removed2pending:\n                if deadnode.gateway.spec == node.gateway.spec:\n                    dead_collection = self.node2collection[deadnode]\n                    if collection != dead_collection:\n                        msg = report_collection_diff(\n                            dead_collection,\n                            collection,\n                            deadnode.gateway.id,\n                            node.gateway.id,\n                        )\n                        self.log(msg)\n                        return\n                    pending = self._removed2pending.pop(deadnode)\n                    self.node2pending[node] = pending\n                    break", "response": "Add the collected test items from a node to a node s pending list."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nschedule the test items on the nodes which have been completed.", "response": "def schedule(self):\n        \"\"\"Schedule the test items on the nodes\n\n        If the node's pending list is empty it is a new node which\n        needs to run all the tests.  If the pending list is already\n        populated (by ``.add_node_collection()``) then it replaces a\n        dead node and we only need to run those tests.\n        \"\"\"\n        assert self.collection_is_completed\n        for node, pending in self.node2pending.items():\n            if node in self._started:\n                continue\n            if not pending:\n                pending[:] = range(len(self.node2collection[node]))\n                node.send_runtest_all()\n                node.shutdown()\n            else:\n                node.send_runtest_some(pending)\n            self._started.append(node)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef has_pending(self):\n        if self.pending:\n            return True\n        for pending in self.node2pending.values():\n            if pending:\n                return True\n        return False", "response": "Return True if there are pending test items and nodes are pending."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_node_collection(self, node, collection):\n        assert node in self.node2pending\n        if self.collection_is_completed:\n            # A new node has been added later, perhaps an original one died.\n            # .schedule() should have\n            # been called by now\n            assert self.collection\n            if collection != self.collection:\n                other_node = next(iter(self.node2collection.keys()))\n                msg = report_collection_diff(\n                    self.collection, collection, other_node.gateway.id, node.gateway.id\n                )\n                self.log(msg)\n                return\n        self.node2collection[node] = list(collection)", "response": "Add the collected test items from a node to the node2collection map."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if the given node should be given any more tests.", "response": "def check_schedule(self, node, duration=0):\n        \"\"\"Maybe schedule new items on the node\n\n        If there are any globally pending nodes left then this will\n        check if the given node should be given any more tests.  The\n        ``duration`` of the last test is optionally used as a\n        heuristic to influence how many tests the node is assigned.\n        \"\"\"\n        if node.shutting_down:\n            return\n\n        if self.pending:\n            # how many nodes do we have?\n            num_nodes = len(self.node2pending)\n            # if our node goes below a heuristic minimum, fill it out to\n            # heuristic maximum\n            items_per_node_min = max(2, len(self.pending) // num_nodes // 4)\n            items_per_node_max = max(2, len(self.pending) // num_nodes // 2)\n            node_pending = self.node2pending[node]\n            if len(node_pending) < items_per_node_min:\n                if duration >= 0.1 and len(node_pending) >= 2:\n                    # seems the node is doing long-running tests\n                    # and has enough items to continue\n                    # so let's rather wait with sending new items\n                    return\n                num_send = items_per_node_max - len(node_pending)\n                self._send_tests(node, num_send)\n        else:\n            node.shutdown()\n\n        self.log(\"num items waiting for node:\", len(self.pending))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving a node from the scheduler.", "response": "def remove_node(self, node):\n        \"\"\"Remove a node from the scheduler\n\n        This should be called either when the node crashed or at\n        shutdown time.  In the former case any pending items assigned\n        to the node will be re-scheduled.  Called by the\n        ``DSession.worker_workerfinished`` and\n        ``DSession.worker_errordown`` hooks.\n\n        Return the item which was being executing while the node\n        crashed or None if the node has no more pending items.\n\n        \"\"\"\n        pending = self.node2pending.pop(node)\n        if not pending:\n            return\n\n        # The node crashed, reassing pending items\n        crashitem = self.collection[pending.pop(0)]\n        self.pending.extend(pending)\n        for node in self.node2pending:\n            self.check_schedule(node)\n        return crashitem"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef schedule(self):\n        assert self.collection_is_completed\n\n        # Initial distribution already happened, reschedule on all nodes\n        if self.collection is not None:\n            for node in self.nodes:\n                self.check_schedule(node)\n            return\n\n        # XXX allow nodes to have different collections\n        if not self._check_nodes_have_same_collection():\n            self.log(\"**Different tests collected, aborting run**\")\n            return\n\n        # Collections are identical, create the index of pending items.\n        self.collection = list(self.node2collection.values())[0]\n        self.pending[:] = range(len(self.collection))\n        if not self.collection:\n            return\n\n        # Send a batch of tests to run. If we don't have at least two\n        # tests per node, we have to send them all so that we can send\n        # shutdown signals and get all nodes working.\n        initial_batch = max(len(self.pending) // 4, 2 * len(self.nodes))\n\n        # distribute tests round-robin up to the batch size\n        # (or until we run out)\n        nodes = cycle(self.nodes)\n        for i in range(initial_batch):\n            self._send_tests(next(nodes), 1)\n\n        if not self.pending:\n            # initial distribution sent all tests, start node shutdown\n            for node in self.nodes:\n                node.shutdown()", "response": "Initiate the test collection of the items across the nodes."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn True if all nodes have collected the same items.", "response": "def _check_nodes_have_same_collection(self):\n        \"\"\"Return True if all nodes have collected the same items.\n\n        If collections differ, this method returns False while logging\n        the collection differences and posting collection errors to\n        pytest_collectreport hook.\n        \"\"\"\n        node_collection_items = list(self.node2collection.items())\n        first_node, col = node_collection_items[0]\n        same_collection = True\n        for node, collection in node_collection_items[1:]:\n            msg = report_collection_diff(\n                col, collection, first_node.gateway.id, node.gateway.id\n            )\n            if msg:\n                same_collection = False\n                self.log(msg)\n                if self.config is not None:\n                    rep = CollectReport(\n                        node.gateway.id, \"failed\", longrepr=msg, result=[]\n                    )\n                    self.config.hook.pytest_collectreport(report=rep)\n\n        return same_collection"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nloop one callback from one of the workers.", "response": "def loop_once(self):\n        \"\"\"Process one callback from one of the workers.\"\"\"\n        while 1:\n            if not self._active_nodes:\n                # If everything has died stop looping\n                self.triggershutdown()\n                raise RuntimeError(\"Unexpectedly no active workers available\")\n            try:\n                eventcall = self.queue.get(timeout=2.0)\n                break\n            except Empty:\n                continue\n        callname, kwargs = eventcall\n        assert callname, kwargs\n        method = \"worker_\" + callname\n        call = getattr(self, method)\n        self.log(\"calling method\", method, kwargs)\n        call(**kwargs)\n        if self.sched.tests_finished:\n            self.triggershutdown()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef worker_workerready(self, node, workerinfo):\n        node.workerinfo = workerinfo\n        node.workerinfo[\"id\"] = node.gateway.id\n        node.workerinfo[\"spec\"] = node.gateway.spec\n\n        # TODO: (#234 task) needs this for pytest. Remove when refactor in pytest repo\n        node.slaveinfo = node.workerinfo\n\n        self.config.hook.pytest_testnodeready(node=node)\n        if self.shuttingdown:\n            node.shutdown()\n        else:\n            self.sched.add_node(node)", "response": "Emitted when a node starts up."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nemitting when node executes its pytest_sessionfinish hook. Removes the node from the scheduler.", "response": "def worker_workerfinished(self, node):\n        \"\"\"Emitted when node executes its pytest_sessionfinish hook.\n\n        Removes the node from the scheduler.\n\n        The node might not be in the scheduler if it had not emitted\n        workerready before shutdown was triggered.\n        \"\"\"\n        self.config.hook.pytest_testnodedown(node=node, error=None)\n        if node.workeroutput[\"exitstatus\"] == 2:  # keyboard-interrupt\n            self.shouldstop = \"%s received keyboard-interrupt\" % (node,)\n            self.worker_errordown(node, \"keyboard-interrupt\")\n            return\n        if node in self.sched.nodes:\n            crashitem = self.sched.remove_node(node)\n            assert not crashitem, (crashitem, node)\n        self._active_nodes.remove(node)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nemit by the WorkerController when a node dies.", "response": "def worker_errordown(self, node, error):\n        \"\"\"Emitted by the WorkerController when a node dies.\"\"\"\n        self.config.hook.pytest_testnodedown(node=node, error=error)\n        try:\n            crashitem = self.sched.remove_node(node)\n        except KeyError:\n            pass\n        else:\n            if crashitem:\n                self.handle_crashitem(crashitem, node)\n\n        self._failed_nodes_count += 1\n        maximum_reached = (\n            self._max_worker_restart is not None\n            and self._failed_nodes_count > self._max_worker_restart\n        )\n        if maximum_reached:\n            if self._max_worker_restart == 0:\n                msg = \"Worker restarting disabled\"\n            else:\n                msg = \"Maximum crashed workers reached: %d\" % self._max_worker_restart\n            self.report_line(msg)\n        else:\n            self.report_line(\"Replacing crashed worker %s\" % node.gateway.id)\n            self._clone_node(node)\n        self._active_nodes.remove(node)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nemitting when a node calls the pytest_runtest_logstart hook.", "response": "def worker_logstart(self, node, nodeid, location):\n        \"\"\"Emitted when a node calls the pytest_runtest_logstart hook.\"\"\"\n        self.config.hook.pytest_runtest_logstart(nodeid=nodeid, location=location)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nemit when a node calls the pytest_runtest_logfinish hook.", "response": "def worker_logfinish(self, node, nodeid, location):\n        \"\"\"Emitted when a node calls the pytest_runtest_logfinish hook.\"\"\"\n        self.config.hook.pytest_runtest_logfinish(nodeid=nodeid, location=location)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nemit when a node calls the pytest_collectreport hook. This is called when a node calls the pytest_collectreport hook.", "response": "def worker_collectreport(self, node, rep):\n        \"\"\"Emitted when a node calls the pytest_collectreport hook.\n\n        Because we only need the report when there's a failure/skip, as optimization\n        we only expect to receive failed/skipped reports from workers (#330).\n        \"\"\"\n        assert not rep.passed\n        self._failed_worker_collectreport(node, rep)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef worker_logwarning(self, message, code, nodeid, fslocation):\n        kwargs = dict(message=message, code=code, nodeid=nodeid, fslocation=fslocation)\n        self.config.hook.pytest_logwarning.call_historic(kwargs=kwargs)", "response": "Emitted when a node calls the pytest_logwarning hook."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nemitting when a node calls the pytest_logwarning hook.", "response": "def worker_warning_captured(self, warning_message, when, item):\n        \"\"\"Emitted when a node calls the pytest_logwarning hook.\"\"\"\n        kwargs = dict(warning_message=warning_message, when=when, item=item)\n        self.config.hook.pytest_warning_captured.call_historic(kwargs=kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a new node based on an existing node.", "response": "def _clone_node(self, node):\n        \"\"\"Return new node based on an existing one.\n\n        This is normally for when a node dies, this will copy the spec\n        of the existing node and create a new one with a new id.  The\n        new node will have been setup so it will start calling the\n        \"worker_*\" hooks and do work soon.\n        \"\"\"\n        spec = node.gateway.spec\n        spec.id = None\n        self.nodemanager.group.allocate_id(spec)\n        node = self.nodemanager.setup_node(spec, self.queue.put)\n        self._active_nodes.add(node)\n        return node"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef rsync_roots(self, gateway):\n        if self.roots:\n            for root in self.roots:\n                self.rsync(gateway, root, **self.rsyncoptions)", "response": "Rsync the set of roots to the node s gateway cwd."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget options to be passed for rsync.", "response": "def _getrsyncoptions(self):\n        \"\"\"Get options to be passed for rsync.\"\"\"\n        ignores = list(self.DEFAULT_IGNORES)\n        ignores += self.config.option.rsyncignore\n        ignores += self.config.getini(\"rsyncignore\")\n\n        return {\"ignores\": ignores, \"verbose\": self.config.option.verbose}"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nperforming rsync to remote hosts for node.", "response": "def rsync(self, gateway, source, notify=None, verbose=False, ignores=None):\n        \"\"\"Perform rsync to remote hosts for node.\"\"\"\n        # XXX This changes the calling behaviour of\n        #     pytest_xdist_rsyncstart and pytest_xdist_rsyncfinish to\n        #     be called once per rsync target.\n        rsync = HostRSync(source, verbose=verbose, ignores=ignores)\n        spec = gateway.spec\n        if spec.popen and not spec.chdir:\n            # XXX This assumes that sources are python-packages\n            #     and that adding the basedir does not hurt.\n            gateway.remote_exec(\n                \"\"\"\n                import sys ; sys.path.insert(0, %r)\n            \"\"\"\n                % os.path.dirname(str(source))\n            ).waitclose()\n            return\n        if (spec, source) in self._rsynced_specs:\n            return\n\n        def finished():\n            if notify:\n                notify(\"rsyncrootready\", spec, source)\n\n        rsync.add_target_host(gateway, finished=finished)\n        self._rsynced_specs.add((spec, source))\n        self.config.hook.pytest_xdist_rsyncstart(source=source, gateways=[gateway])\n        rsync.send()\n        self.config.hook.pytest_xdist_rsyncfinish(source=source, gateways=[gateway])"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsends a named parametrized command to the other side", "response": "def sendcommand(self, name, **kwargs):\n        \"\"\" send a named parametrized command to the other side. \"\"\"\n        self.log(\"sending command %s(**%s)\" % (name, kwargs))\n        self.channel.send((name, kwargs))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef report_collection_diff(from_collection, to_collection, from_id, to_id):\n    if from_collection == to_collection:\n        return None\n\n    diff = unified_diff(from_collection, to_collection, fromfile=from_id, tofile=to_id)\n    error_message = (\n        u\"Different tests were collected between {from_id} and {to_id}. \"\n        u\"The difference is:\\n\"\n        u\"{diff}\"\n    ).format(from_id=from_id, to_id=to_id, diff=\"\\n\".join(diff))\n    msg = \"\\n\".join([x.rstrip() for x in error_message.split(\"\\n\")])\n    return msg", "response": "Report the collected test difference between two nodes."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\napplies search written in DjangoQL mini - language to given queryset", "response": "def apply_search(queryset, search, schema=None):\n    \"\"\"\n    Applies search written in DjangoQL mini-language to given queryset\n    \"\"\"\n    ast = DjangoQLParser().parse(search)\n    schema = schema or DjangoQLSchema\n    schema_instance = schema(queryset.model)\n    schema_instance.validate(ast)\n    return queryset.filter(build_filter(ast, schema_instance))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of options for this object.", "response": "def get_options(self):\n        \"\"\"\n        Override this method to provide custom suggestion options\n        \"\"\"\n        choices = self._field_choices()\n        if choices:\n            return [c[1] for c in choices]\n        else:\n            return self.model.objects.\\\n                order_by(self.name).\\\n                values_list(self.name, flat=True)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting the value to the lookup value", "response": "def get_lookup_value(self, value):\n        \"\"\"\n        Override this method to convert displayed values to lookup values\n        \"\"\"\n        choices = self._field_choices()\n        if choices:\n            if isinstance(value, list):\n                return [c[0] for c in choices if c[1] in value]\n            else:\n                for c in choices:\n                    if c[1] == value:\n                        return c[0]\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a comparison suffix for the current locale.", "response": "def get_operator(self, operator):\n        \"\"\"\n        Get a comparison suffix to be used in Django ORM & inversion flag for it\n\n        :param operator: string, DjangoQL comparison operator\n        :return: (suffix, invert) - a tuple with 2 values:\n            suffix - suffix to be used in ORM query, for example '__gt' for '>'\n            invert - boolean, True if this comparison needs to be inverted\n        \"\"\"\n        op = {\n            '=': '',\n            '>': '__gt',\n            '>=': '__gte',\n            '<': '__lt',\n            '<=': '__lte',\n            '~': '__icontains',\n            'in': '__in',\n        }.get(operator)\n        if op is not None:\n            return op, False\n        op = {\n            '!=': '',\n            '!~': '__icontains',\n            'not in': '__in',\n        }[operator]\n        return op, True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a dict with all model labels and their fields found.", "response": "def introspect(self, model, exclude=()):\n        \"\"\"\n        Start with given model and recursively walk through its relationships.\n\n        Returns a dict with all model labels and their fields found.\n        \"\"\"\n        result = {}\n        open_set = deque([model])\n        closed_set = list(exclude)\n\n        while open_set:\n            model = open_set.popleft()\n            model_label = self.model_label(model)\n\n            if model_label in closed_set:\n                continue\n\n            model_fields = OrderedDict()\n            for field in self.get_fields(model):\n                if not isinstance(field, DjangoQLField):\n                    field = self.get_field_instance(model, field)\n                if not field:\n                    continue\n                if isinstance(field, RelationField):\n                    if field.relation not in closed_set:\n                        model_fields[field.name] = field\n                        open_set.append(field.related_model)\n                else:\n                    model_fields[field.name] = field\n\n            result[model_label] = model_fields\n            closed_set.append(model_label)\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_fields(self, model):\n        return sorted(\n            [f.name for f in model._meta.get_fields() if f.name != 'password']\n        )", "response": "Returns a list of all the fields of a given model."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nvalidate DjangoQL AST tree vs. current schema", "response": "def validate(self, node):\n        \"\"\"\n        Validate DjangoQL AST tree vs. current schema\n        \"\"\"\n        assert isinstance(node, Node)\n        if isinstance(node.operator, Logical):\n            self.validate(node.left)\n            self.validate(node.right)\n            return\n        assert isinstance(node.left, Name)\n        assert isinstance(node.operator, Comparison)\n        assert isinstance(node.right, (Const, List))\n\n        # Check that field and value types are compatible\n        field = self.resolve_name(node.left)\n        value = node.right.value\n        if field is None:\n            if value is not None:\n                raise DjangoQLSchemaError(\n                    'Related model %s can be compared to None only, but not to '\n                    '%s' % (node.left.value, type(value).__name__)\n                )\n        else:\n            values = value if isinstance(node.right, List) else [value]\n            for v in values:\n                field.validate(v)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find_column(self, t):\n        cr = max(self.text.rfind(l, 0, t.lexpos) for l in self.line_terminators)\n        if cr == -1:\n            return t.lexpos + 1\n        return t.lexpos - cr", "response": "Returns the column in the current text that contains the given token."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef p_expression_logical(self, p):\n        p[0] = Expression(left=p[1], operator=p[2], right=p[3])", "response": "parse an expression logical expression"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing the expression comparison section.", "response": "def p_expression_comparison(self, p):\n        \"\"\"\n        expression : name comparison_number number\n                   | name comparison_string string\n                   | name comparison_equality boolean_value\n                   | name comparison_equality none\n                   | name comparison_in_list const_list_value\n        \"\"\"\n        p[0] = Expression(left=p[1], operator=p[2], right=p[3])"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nexecutes filter with given args.", "response": "async def execute_filter(filter_: FilterObj, args):\n    \"\"\"\n    Helper for executing filter\n\n    :param filter_:\n    :param args:\n    :return:\n    \"\"\"\n    if filter_.is_async:\n        return await filter_.filter(*args, **filter_.kwargs)\n    else:\n        return filter_.filter(*args, **filter_.kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def check_filters(filters: typing.Iterable[FilterObj], args):\n    data = {}\n    if filters is not None:\n        for filter_ in filters:\n            f = await execute_filter(filter_, args)\n            if not f:\n                raise FilterNotPassed()\n            elif isinstance(f, dict):\n                data.update(f)\n    return data", "response": "Check list of filters and return dict of filters"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nvalidate and parse config.", "response": "def validate(cls, full_config: typing.Dict[str, typing.Any]) -> typing.Optional[typing.Dict[str, typing.Any]]:\n        \"\"\"\n        Validate and parse config.\n\n        This method will be called by the filters factory when you bind this filter.\n        Must be overridden.\n\n        :param full_config: dict with arguments passed to handler registrar\n        :return: Current filter config\n        \"\"\"\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef validate(cls, full_config: typing.Dict[str, typing.Any]) -> typing.Dict[str, typing.Any]:\n        if cls.key is not None:\n            if cls.key in full_config:\n                return {cls.key: full_config[cls.key]}\n            elif cls.required:\n                return {cls.key: cls.default}", "response": "Validate that the class is in the full_config."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if all filters return a positive result AttributeNames", "response": "async def check(self, *args):\n        \"\"\"\n        All filters must return a positive result\n\n        :param args:\n        :return:\n        \"\"\"\n        data = {}\n        for target in self.targets:\n            result = await target(*args)\n            if not result:\n                return False\n            if isinstance(result, dict):\n                data.update(result)\n        if not data:\n            return True\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def send_message(user_id: int, text: str, disable_notification: bool = False) -> bool:\n    try:\n        await bot.send_message(user_id, text, disable_notification=disable_notification)\n    except exceptions.BotBlocked:\n        log.error(f\"Target [ID:{user_id}]: blocked by user\")\n    except exceptions.ChatNotFound:\n        log.error(f\"Target [ID:{user_id}]: invalid user ID\")\n    except exceptions.RetryAfter as e:\n        log.error(f\"Target [ID:{user_id}]: Flood limit is exceeded. Sleep {e.timeout} seconds.\")\n        await asyncio.sleep(e.timeout)\n        return await send_message(user_id, text)  # Recursive call\n    except exceptions.UserDeactivated:\n        log.error(f\"Target [ID:{user_id}]: user is deactivated\")\n    except exceptions.TelegramAPIError:\n        log.exception(f\"Target [ID:{user_id}]: failed\")\n    else:\n        log.info(f\"Target [ID:{user_id}]: success\")\n        return True\n    return False", "response": "Send a message to the specified user."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def broadcaster() -> int:\n    count = 0\n    try:\n        for user_id in get_users():\n            if await send_message(user_id, '<b>Hello!</b>'):\n                count += 1\n            await asyncio.sleep(.05)  # 20 messages per second (Limit: 30 messages per second)\n    finally:\n        log.info(f\"{count} messages successful sent.\")\n\n    return count", "response": "Simple broadcaster for getting all users from the database."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_full_command(self):\n        if self.is_command():\n            command, _, args = self.text.partition(' ')\n            return command, args", "response": "Split command and args tuple"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget command from message", "response": "def get_command(self, pure=False):\n        \"\"\"\n        Get command from message\n\n        :return:\n        \"\"\"\n        command = self.get_full_command()\n        if command:\n            command = command[0]\n            if pure:\n                command, _, _ = command[1:].partition('@')\n            return command"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_entities(self, as_html=True):\n\n        text = self.text or self.caption\n        if text is None:\n            raise TypeError(\"This message doesn't have any text.\")\n\n        quote_fn = md.quote_html if as_html else md.escape_md\n\n        entities = self.entities or self.caption_entities\n        if not entities:\n            return quote_fn(text)\n\n        if not sys.maxunicode == 0xffff:\n            text = text.encode('utf-16-le')\n\n        result = ''\n        offset = 0\n\n        for entity in sorted(entities, key=lambda item: item.offset):\n            entity_text = entity.parse(text, as_html=as_html)\n\n            if sys.maxunicode == 0xffff:\n                part = text[offset:entity.offset]\n                result += quote_fn(part) + entity_text\n            else:\n                part = text[offset * 2:entity.offset * 2]\n                result += quote_fn(part.decode('utf-16-le')) + entity_text\n\n            offset = entity.offset + entity.length\n\n        if sys.maxunicode == 0xffff:\n            part = text[offset:]\n            result += quote_fn(part)\n        else:\n            part = text[offset * 2:]\n            result += quote_fn(part.decode('utf-16-le'))\n\n        return result", "response": "Parses the text or caption of the message and returns a string with the text."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting URL for the message.", "response": "def url(self) -> str:\n        \"\"\"\n        Get URL for the message\n\n        :return: str\n        \"\"\"\n        if self.chat.type not in [ChatType.SUPER_GROUP, ChatType.CHANNEL]:\n            raise TypeError('Invalid chat type!')\n        elif not self.chat.username:\n            raise TypeError('This chat does not have @username')\n\n        return f\"https://t.me/{self.chat.username}/{self.message_id}\""}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate URL for using in text messages with HTML or MD parse mode.", "response": "def link(self, text, as_html=True) -> str:\n        \"\"\"\n        Generate URL for using in text messages with HTML or MD parse mode\n\n        :param text: link label\n        :param as_html: generate as HTML\n        :return: str\n        \"\"\"\n        try:\n            url = self.url\n        except TypeError:  # URL is not accessible\n            if as_html:\n                return md.quote_html(text)\n            return md.escape_md(text)\n\n        if as_html:\n            return md.hlink(text, url)\n        return md.link(text, url)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsend a message to the chat.", "response": "async def answer(self, text, parse_mode=None, disable_web_page_preview=None,\n                     disable_notification=None, reply_markup=None, reply=False) -> Message:\n        \"\"\"\n        Answer to this message\n\n        :param text: str\n        :param parse_mode: str\n        :param disable_web_page_preview: bool\n        :param disable_notification: bool\n        :param reply_markup:\n        :param reply: fill 'reply_to_message_id'\n        :return: :class:`aiogram.types.Message`\n        \"\"\"\n        return await self.bot.send_message(chat_id=self.chat.id, text=text,\n                                           parse_mode=parse_mode,\n                                           disable_web_page_preview=disable_web_page_preview,\n                                           disable_notification=disable_notification,\n                                           reply_to_message_id=self.message_id if reply else None,\n                                           reply_markup=reply_markup)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def answer_photo(self, photo: typing.Union[base.InputFile, base.String],\n                           caption: typing.Union[base.String, None] = None,\n                           disable_notification: typing.Union[base.Boolean, None] = None,\n                           reply_markup=None, reply=False) -> Message:\n        \"\"\"\n        Use this method to send photos.\n\n        Source: https://core.telegram.org/bots/api#sendphoto\n\n        :param photo: Photo to send.\n        :type photo: :obj:`typing.Union[base.InputFile, base.String]`\n        :param caption: Photo caption (may also be used when resending photos by file_id), 0-200 characters\n        :type caption: :obj:`typing.Union[base.String, None]`\n        :param disable_notification: Sends the message silently. Users will receive a notification with no sound.\n        :type disable_notification: :obj:`typing.Union[base.Boolean, None]`\n        :param reply_markup: Additional interface options.\n        :type reply_markup: :obj:`typing.Union[types.InlineKeyboardMarkup,\n            types.ReplyKeyboardMarkup, types.ReplyKeyboardRemove, types.ForceReply, None]`\n        :param reply: fill 'reply_to_message_id'\n        :return: On success, the sent Message is returned.\n        :rtype: :obj:`types.Message`\n        \"\"\"\n        return await self.bot.send_photo(chat_id=self.chat.id, photo=photo, caption=caption,\n                                         disable_notification=disable_notification,\n                                         reply_to_message_id=self.message_id if reply else None,\n                                         reply_markup=reply_markup)", "response": "Send a photo to the chat."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def answer_audio(self, audio: typing.Union[base.InputFile, base.String],\n                           caption: typing.Union[base.String, None] = None,\n                           duration: typing.Union[base.Integer, None] = None,\n                           performer: typing.Union[base.String, None] = None,\n                           title: typing.Union[base.String, None] = None,\n                           disable_notification: typing.Union[base.Boolean, None] = None,\n                           reply_markup=None,\n                           reply=False) -> Message:\n        \"\"\"\n        Use this method to send audio files, if you want Telegram clients to display them in the music player.\n        Your audio must be in the .mp3 format.\n\n        For sending voice messages, use the sendVoice method instead.\n\n        Source: https://core.telegram.org/bots/api#sendaudio\n\n        :param audio: Audio file to send.\n        :type audio: :obj:`typing.Union[base.InputFile, base.String]`\n        :param caption: Audio caption, 0-200 characters\n        :type caption: :obj:`typing.Union[base.String, None]`\n        :param duration: Duration of the audio in seconds\n        :type duration: :obj:`typing.Union[base.Integer, None]`\n        :param performer: Performer\n        :type performer: :obj:`typing.Union[base.String, None]`\n        :param title: Track name\n        :type title: :obj:`typing.Union[base.String, None]`\n        :param disable_notification: Sends the message silently. Users will receive a notification with no sound.\n        :type disable_notification: :obj:`typing.Union[base.Boolean, None]`\n        :param reply_markup: Additional interface options.\n        :type reply_markup: :obj:`typing.Union[types.InlineKeyboardMarkup,\n            types.ReplyKeyboardMarkup, types.ReplyKeyboardRemove, types.ForceReply, None]`\n        :param reply: fill 'reply_to_message_id'\n        :return: On success, the sent Message is returned.\n        :rtype: :obj:`types.Message`\n        \"\"\"\n        return await self.bot.send_audio(chat_id=self.chat.id,\n                                         audio=audio,\n                                         caption=caption,\n                                         duration=duration,\n                                         performer=performer,\n                                         title=title,\n                                         disable_notification=disable_notification,\n                                         reply_to_message_id=self.message_id if reply else None,\n                                         reply_markup=reply_markup)", "response": "Send audio to Telegram."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsending a media group.", "response": "async def answer_media_group(self, media: typing.Union[MediaGroup, typing.List],\n                                 disable_notification: typing.Union[base.Boolean, None] = None,\n                                 reply=False) -> typing.List[Message]:\n        \"\"\"\n        Use this method to send a group of photos or videos as an album.\n\n        Source: https://core.telegram.org/bots/api#sendmediagroup\n\n        :param media: A JSON-serialized array describing photos and videos to be sent\n        :type media: :obj:`typing.Union[types.MediaGroup, typing.List]`\n        :param disable_notification: Sends the message silently. Users will receive a notification with no sound.\n        :type disable_notification: :obj:`typing.Union[base.Boolean, None]`\n        :param reply: fill 'reply_to_message_id'\n        :return: On success, an array of the sent Messages is returned.\n        :rtype: typing.List[types.Message]\n        \"\"\"\n        return await self.bot.send_media_group(self.chat.id,\n                                               media=media,\n                                               disable_notification=disable_notification,\n                                               reply_to_message_id=self.message_id if reply else None)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def answer_location(self, latitude: base.Float,\n                              longitude: base.Float, live_period: typing.Union[base.Integer, None] = None,\n                              disable_notification: typing.Union[base.Boolean, None] = None,\n                              reply_markup=None,\n                              reply=False) -> Message:\n        \"\"\"\n        Use this method to send point on the map.\n\n        Source: https://core.telegram.org/bots/api#sendlocation\n\n        :param latitude: Latitude of the location\n        :type latitude: :obj:`base.Float`\n        :param longitude: Longitude of the location\n        :type longitude: :obj:`base.Float`\n        :param live_period: Period in seconds for which the location will be updated\n        :type live_period: :obj:`typing.Union[base.Integer, None]`\n        :param disable_notification: Sends the message silently. Users will receive a notification with no sound.\n        :type disable_notification: :obj:`typing.Union[base.Boolean, None]`\n        :param reply_markup: Additional interface options.\n        :type reply_markup: :obj:`typing.Union[types.InlineKeyboardMarkup,\n            types.ReplyKeyboardMarkup, types.ReplyKeyboardRemove, types.ForceReply, None]`\n        :param reply: fill 'reply_to_message_id'\n        :return: On success, the sent Message is returned.\n        :rtype: :obj:`types.Message`\n        \"\"\"\n        return await self.bot.send_location(chat_id=self.chat.id,\n                                            latitude=latitude,\n                                            longitude=longitude,\n                                            live_period=live_period,\n                                            disable_notification=disable_notification,\n                                            reply_to_message_id=self.message_id if reply else None,\n                                            reply_markup=reply_markup)", "response": "Send a location to the map."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsending an animation to Telegram servers.", "response": "async def send_animation(self,\n                             animation: typing.Union[base.InputFile, base.String],\n                             duration: typing.Union[base.Integer, None] = None,\n                             width: typing.Union[base.Integer, None] = None,\n                             height: typing.Union[base.Integer, None] = None,\n                             thumb: typing.Union[typing.Union[base.InputFile, base.String], None] = None,\n                             caption: typing.Union[base.String, None] = None,\n                             parse_mode: typing.Union[base.String, None] = None,\n                             disable_notification: typing.Union[base.Boolean, None] = None,\n                             reply_markup=None,\n                             reply=True) -> Message:\n        \"\"\"\n        Use this method to send animation files (GIF or H.264/MPEG-4 AVC video without sound).\n\n        On success, the sent Message is returned.\n        Bots can currently send animation files of up to 50 MB in size, this limit may be changed in the future.\n\n        Source https://core.telegram.org/bots/api#sendanimation\n\n        :param animation: Animation to send. Pass a file_id as String to send an animation that exists\n            on the Telegram servers (recommended), pass an HTTP URL as a String for Telegram to get an animation\n            from the Internet, or upload a new animation using multipart/form-data\n        :type animation: :obj:`typing.Union[base.InputFile, base.String]`\n        :param duration: Duration of sent animation in seconds\n        :type duration: :obj:`typing.Union[base.Integer, None]`\n        :param width: Animation width\n        :type width: :obj:`typing.Union[base.Integer, None]`\n        :param height: Animation height\n        :type height: :obj:`typing.Union[base.Integer, None]`\n        :param thumb: Thumbnail of the file sent. The thumbnail should be in JPEG format and less than 200 kB in size.\n            A thumbnail\u2018s width and height should not exceed 90.\n        :type thumb: :obj:`typing.Union[typing.Union[base.InputFile, base.String], None]`\n        :param caption: Animation caption (may also be used when resending animation by file_id), 0-1024 characters\n        :type caption: :obj:`typing.Union[base.String, None]`\n        :param parse_mode: Send Markdown or HTML, if you want Telegram apps to show bold, italic,\n            fixed-width text or inline URLs in the media caption\n        :type parse_mode: :obj:`typing.Union[base.String, None]`\n        :param disable_notification: Sends the message silently. Users will receive a notification with no sound\n        :type disable_notification: :obj:`typing.Union[base.Boolean, None]`\n        :param reply_markup: Additional interface options. A JSON-serialized object for an inline keyboard,\n            custom reply keyboard, instructions to remove reply keyboard or to force a reply from the user\n        :type reply_markup: :obj:`typing.Union[typing.Union[types.InlineKeyboardMarkup, types.ReplyKeyboardMarkup,\n            types.ReplyKeyboardRemove, types.ForceReply], None]`\n        :param reply: fill 'reply_to_message_id'\n        :return: On success, the sent Message is returned\n        :rtype: :obj:`types.Message`\n        \"\"\"\n        warn_deprecated('\"Message.send_animation\" method will be removed in 2.2 version.\\n'\n                        'Use \"Message.reply_animation\" instead.',\n                        stacklevel=8)\n\n        return await self.bot.send_animation(self.chat.id, animation=animation,\n                                             duration=duration,\n                                             width=width,\n                                             height=height,\n                                             thumb=thumb,\n                                             caption=caption,\n                                             parse_mode=parse_mode,\n                                             disable_notification=disable_notification,\n                                             reply_to_message_id=self.message_id if reply else None,\n                                             reply_markup=reply_markup\n                                             )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def reply_document(self, document: typing.Union[base.InputFile, base.String],\n                             caption: typing.Union[base.String, None] = None,\n                             disable_notification: typing.Union[base.Boolean, None] = None,\n                             reply_markup=None,\n                             reply=True) -> Message:\n        \"\"\"\n        Use this method to send general files.\n\n        Bots can currently send files of any type of up to 50 MB in size, this limit may be changed in the future.\n\n        Source: https://core.telegram.org/bots/api#senddocument\n\n        :param document: File to send.\n        :type document: :obj:`typing.Union[base.InputFile, base.String]`\n        :param caption: Document caption (may also be used when resending documents by file_id), 0-200 characters\n        :type caption: :obj:`typing.Union[base.String, None]`\n        :param disable_notification: Sends the message silently. Users will receive a notification with no sound.\n        :type disable_notification: :obj:`typing.Union[base.Boolean, None]`\n        :param reply_markup: Additional interface options.\n        :type reply_markup: :obj:`typing.Union[types.InlineKeyboardMarkup,\n            types.ReplyKeyboardMarkup, types.ReplyKeyboardRemove, types.ForceReply], None]`\n        :param reply: fill 'reply_to_message_id'\n        :return: On success, the sent Message is returned.\n        :rtype: :obj:`types.Message`\n        \"\"\"\n        return await self.bot.send_document(chat_id=self.chat.id,\n                                            document=document,\n                                            caption=caption,\n                                            disable_notification=disable_notification,\n                                            reply_to_message_id=self.message_id if reply else None,\n                                            reply_markup=reply_markup)", "response": "Send a single file or file to the bot."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsending a video to the Telegram server.", "response": "async def reply_video(self, video: typing.Union[base.InputFile, base.String],\n                          duration: typing.Union[base.Integer, None] = None,\n                          width: typing.Union[base.Integer, None] = None,\n                          height: typing.Union[base.Integer, None] = None,\n                          caption: typing.Union[base.String, None] = None,\n                          disable_notification: typing.Union[base.Boolean, None] = None,\n                          reply_markup=None,\n                          reply=True) -> Message:\n        \"\"\"\n        Use this method to send video files, Telegram clients support mp4 videos\n        (other formats may be sent as Document).\n\n        Source: https://core.telegram.org/bots/api#sendvideo\n\n        :param video: Video to send.\n        :type video: :obj:`typing.Union[base.InputFile, base.String]`\n        :param duration: Duration of sent video in seconds\n        :type duration: :obj:`typing.Union[base.Integer, None]`\n        :param width: Video width\n        :type width: :obj:`typing.Union[base.Integer, None]`\n        :param height: Video height\n        :type height: :obj:`typing.Union[base.Integer, None]`\n        :param caption: Video caption (may also be used when resending videos by file_id), 0-200 characters\n        :type caption: :obj:`typing.Union[base.String, None]`\n        :param disable_notification: Sends the message silently. Users will receive a notification with no sound.\n        :type disable_notification: :obj:`typing.Union[base.Boolean, None]`\n        :param reply_markup: Additional interface options.\n        :type reply_markup: :obj:`typing.Union[types.InlineKeyboardMarkup,\n            types.ReplyKeyboardMarkup, types.ReplyKeyboardRemove, types.ForceReply, None]`\n        :param reply: fill 'reply_to_message_id'\n        :return: On success, the sent Message is returned.\n        :rtype: :obj:`types.Message`\n        \"\"\"\n        return await self.bot.send_video(chat_id=self.chat.id,\n                                         video=video,\n                                         duration=duration,\n                                         width=width,\n                                         height=height,\n                                         caption=caption,\n                                         disable_notification=disable_notification,\n                                         reply_to_message_id=self.message_id if reply else None,\n                                         reply_markup=reply_markup)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def reply_voice(self, voice: typing.Union[base.InputFile, base.String],\n                          caption: typing.Union[base.String, None] = None,\n                          duration: typing.Union[base.Integer, None] = None,\n                          disable_notification: typing.Union[base.Boolean, None] = None,\n                          reply_markup=None,\n                          reply=True) -> Message:\n        \"\"\"\n        Use this method to send audio files, if you want Telegram clients to display the file\n        as a playable voice message.\n\n        For this to work, your audio must be in an .ogg file encoded with OPUS\n        (other formats may be sent as Audio or Document).\n\n        Source: https://core.telegram.org/bots/api#sendvoice\n\n        :param voice: Audio file to send.\n        :type voice: :obj:`typing.Union[base.InputFile, base.String]`\n        :param caption: Voice message caption, 0-200 characters\n        :type caption: :obj:`typing.Union[base.String, None]`\n        :param duration: Duration of the voice message in seconds\n        :type duration: :obj:`typing.Union[base.Integer, None]`\n        :param disable_notification: Sends the message silently. Users will receive a notification with no sound.\n        :type disable_notification: :obj:`typing.Union[base.Boolean, None]`\n        :param reply_markup: Additional interface options.\n        :type reply_markup: :obj:`typing.Union[types.InlineKeyboardMarkup,\n            types.ReplyKeyboardMarkup, types.ReplyKeyboardRemove, types.ForceReply, None]`\n        :param reply: fill 'reply_to_message_id'\n        :return: On success, the sent Message is returned.\n        :rtype: :obj:`types.Message`\n        \"\"\"\n        return await self.bot.send_voice(chat_id=self.chat.id,\n                                         voice=voice,\n                                         caption=caption,\n                                         duration=duration,\n                                         disable_notification=disable_notification,\n                                         reply_to_message_id=self.message_id if reply else None,\n                                         reply_markup=reply_markup)", "response": "Send a voice message."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsends a video note to the chat.", "response": "async def reply_video_note(self, video_note: typing.Union[base.InputFile, base.String],\n                               duration: typing.Union[base.Integer, None] = None,\n                               length: typing.Union[base.Integer, None] = None,\n                               disable_notification: typing.Union[base.Boolean, None] = None,\n                               reply_markup=None,\n                               reply=True) -> Message:\n        \"\"\"\n        As of v.4.0, Telegram clients support rounded square mp4 videos of up to 1 minute long.\n        Use this method to send video messages.\n\n        Source: https://core.telegram.org/bots/api#sendvideonote\n\n        :param video_note: Video note to send.\n        :type video_note: :obj:`typing.Union[base.InputFile, base.String]`\n        :param duration: Duration of sent video in seconds\n        :type duration: :obj:`typing.Union[base.Integer, None]`\n        :param length: Video width and height\n        :type length: :obj:`typing.Union[base.Integer, None]`\n        :param disable_notification: Sends the message silently. Users will receive a notification with no sound.\n        :type disable_notification: :obj:`typing.Union[base.Boolean, None]`\n        :param reply_markup: Additional interface options.\n        :type reply_markup: :obj:`typing.Union[types.InlineKeyboardMarkup,\n            types.ReplyKeyboardMarkup, types.ReplyKeyboardRemove, types.ForceReply, None]`\n        :param reply: fill 'reply_to_message_id'\n        :return: On success, the sent Message is returned.\n        :rtype: :obj:`types.Message`\n        \"\"\"\n        return await self.bot.send_video_note(chat_id=self.chat.id,\n                                              video_note=video_note,\n                                              duration=duration,\n                                              length=length,\n                                              disable_notification=disable_notification,\n                                              reply_to_message_id=self.message_id if reply else None,\n                                              reply_markup=reply_markup)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def send_venue(self, latitude: base.Float, longitude: base.Float, title: base.String, address: base.String,\n                         foursquare_id: typing.Union[base.String, None] = None,\n                         disable_notification: typing.Union[base.Boolean, None] = None,\n                         reply_markup=None,\n                         reply=True) -> Message:\n        \"\"\"\n        Use this method to send information about a venue.\n\n        Source: https://core.telegram.org/bots/api#sendvenue\n\n        :param latitude: Latitude of the venue\n        :type latitude: :obj:`base.Float`\n        :param longitude: Longitude of the venue\n        :type longitude: :obj:`base.Float`\n        :param title: Name of the venue\n        :type title: :obj:`base.String`\n        :param address: Address of the venue\n        :type address: :obj:`base.String`\n        :param foursquare_id: Foursquare identifier of the venue\n        :type foursquare_id: :obj:`typing.Union[base.String, None]`\n        :param disable_notification: Sends the message silently. Users will receive a notification with no sound.\n        :type disable_notification: :obj:`typing.Union[base.Boolean, None]`\n        :param reply_markup: Additional interface options.\n        :type reply_markup: :obj:`typing.Union[types.InlineKeyboardMarkup,\n            types.ReplyKeyboardMarkup, types.ReplyKeyboardRemove, types.ForceReply, None]`\n        :param reply: fill 'reply_to_message_id'\n        :return: On success, the sent Message is returned.\n        :rtype: :obj:`types.Message`\n        \"\"\"\n        warn_deprecated('\"Message.send_venue\" method will be removed in 2.2 version.\\n'\n                        'Use \"Message.reply_venue\" instead.',\n                        stacklevel=8)\n\n        return await self.bot.send_venue(chat_id=self.chat.id,\n                                         latitude=latitude,\n                                         longitude=longitude,\n                                         title=title,\n                                         address=address,\n                                         foursquare_id=foursquare_id,\n                                         disable_notification=disable_notification,\n                                         reply_to_message_id=self.message_id if reply else None,\n                                         reply_markup=reply_markup)", "response": "Use this method to send information about a venue.\n\n        Source: https://core.telegram.org/bots/api#sendvenue\n\n        :param latitude: Latitude of the venue\n        :type latitude: :obj:`base.Float`\n        :param longitude: Longitude of the venue\n        :type longitude: :obj:`base.Float`\n        :param title: Name of the venue\n        :type title: :obj:`base.String`\n        :param address: Address of the venue\n        :type address: :obj:`base.String`\n        :param foursquare_id: Foursquare identifier of the venue\n        :type foursquare_id: :obj:`typing.Union[base.String, None]`\n        :param disable_notification: Sends the message silently. Users will receive a notification with no sound.\n        :type disable_notification: :obj:`typing.Union[base.Boolean, None]`\n        :param reply_markup: Additional interface options.\n        :type reply_markup: :obj:`typing.Union[types.InlineKeyboardMarkup,\n            types.ReplyKeyboardMarkup, types.ReplyKeyboardRemove, types.ForceReply, None]`\n        :param reply: fill 'reply_to_message_id'\n        :return: On success, the sent Message is returned.\n        :rtype: :obj:`types.Message`"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def send_contact(self, phone_number: base.String,\n                           first_name: base.String, last_name: typing.Union[base.String, None] = None,\n                           disable_notification: typing.Union[base.Boolean, None] = None,\n                           reply_markup=None,\n                           reply=True) -> Message:\n        \"\"\"\n        Use this method to send phone contacts.\n\n        Source: https://core.telegram.org/bots/api#sendcontact\n\n        :param phone_number: Contact's phone number\n        :type phone_number: :obj:`base.String`\n        :param first_name: Contact's first name\n        :type first_name: :obj:`base.String`\n        :param last_name: Contact's last name\n        :type last_name: :obj:`typing.Union[base.String, None]`\n        :param disable_notification: Sends the message silently. Users will receive a notification with no sound.\n        :type disable_notification: :obj:`typing.Union[base.Boolean, None]`\n        :param reply_markup: Additional interface options.\n        :type reply_markup: :obj:`typing.Union[types.InlineKeyboardMarkup,\n            types.ReplyKeyboardMarkup, types.ReplyKeyboardRemove, types.ForceReply, None]`\n        :param reply: fill 'reply_to_message_id'\n        :return: On success, the sent Message is returned.\n        :rtype: :obj:`types.Message`\n        \"\"\"\n        warn_deprecated('\"Message.send_contact\" method will be removed in 2.2 version.\\n'\n                        'Use \"Message.reply_contact\" instead.',\n                        stacklevel=8)\n\n        return await self.bot.send_contact(chat_id=self.chat.id,\n                                           phone_number=phone_number,\n                                           first_name=first_name, last_name=last_name,\n                                           disable_notification=disable_notification,\n                                           reply_to_message_id=self.message_id if reply else None,\n                                           reply_markup=reply_markup)", "response": "Use this method to send phone contacts.\n\n        Source: https://core.telegram.org/bots/api#sendcontact\n\n        :param phone_number: Contact's phone number\n        :type phone_number: :obj:`base.String`\n        :param first_name: Contact's first name\n        :type first_name: :obj:`base.String`\n        :param last_name: Contact's last name\n        :type last_name: :obj:`typing.Union[base.String, None]`\n        :param disable_notification: Sends the message silently. Users will receive a notification with no sound.\n        :type disable_notification: :obj:`typing.Union[base.Boolean, None]`\n        :param reply_markup: Additional interface options.\n        :type reply_markup: :obj:`typing.Union[types.InlineKeyboardMarkup,\n            types.ReplyKeyboardMarkup, types.ReplyKeyboardRemove, types.ForceReply, None]`\n        :param reply: fill 'reply_to_message_id'\n        :return: On success, the sent Message is returned.\n        :rtype: :obj:`types.Message`"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def reply_sticker(self, sticker: typing.Union[base.InputFile, base.String],\n                            disable_notification: typing.Union[base.Boolean, None] = None,\n                            reply_markup=None, reply=True) -> Message:\n        \"\"\"\n        Use this method to send .webp stickers.\n\n        Source: https://core.telegram.org/bots/api#sendsticker\n\n        :param sticker: Sticker to send.\n        :type sticker: :obj:`typing.Union[base.InputFile, base.String]`\n        :param disable_notification: Sends the message silently. Users will receive a notification with no sound.\n        :type disable_notification: :obj:`typing.Union[base.Boolean, None]`\n        :param reply_markup: Additional interface options.\n        :type reply_markup: :obj:`typing.Union[types.InlineKeyboardMarkup,\n            types.ReplyKeyboardMarkup, types.ReplyKeyboardRemove, types.ForceReply, None]`\n        :param reply: fill 'reply_to_message_id'\n        :return: On success, the sent Message is returned.\n        :rtype: :obj:`types.Message`\n        \"\"\"\n        return await self.bot.send_sticker(chat_id=self.chat.id, sticker=sticker,\n                                           disable_notification=disable_notification,\n                                           reply_to_message_id=self.message_id if reply else None,\n                                           reply_markup=reply_markup)", "response": "Send a sticker to the chat."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def forward(self, chat_id, disable_notification=None) -> Message:\n        return await self.bot.forward_message(chat_id, self.chat.id, self.message_id, disable_notification)", "response": "Use this method to forward the message to another chat."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def edit_text(self, text: base.String,\n                        parse_mode: typing.Union[base.String, None] = None,\n                        disable_web_page_preview: typing.Union[base.Boolean, None] = None,\n                        reply_markup=None):\n        \"\"\"\n        Use this method to edit text and game messages sent by the bot or via the bot (for inline bots).\n\n        Source: https://core.telegram.org/bots/api#editmessagetext\n\n        :param text: New text of the message\n        :type text: :obj:`base.String`\n        :param parse_mode: Send Markdown or HTML, if you want Telegram apps to show bold, italic,\n            fixed-width text or inline URLs in your bot's message.\n        :type parse_mode: :obj:`typing.Union[base.String, None]`\n        :param disable_web_page_preview: Disables link previews for links in this message\n        :type disable_web_page_preview: :obj:`typing.Union[base.Boolean, None]`\n        :param reply_markup: A JSON-serialized object for an inline keyboard.\n        :type reply_markup: :obj:`typing.Union[types.InlineKeyboardMarkup, None]`\n        :return: On success, if edited message is sent by the bot,\n            the edited Message is returned, otherwise True is returned.\n        :rtype: :obj:`typing.Union[types.Message, base.Boolean]`\n        \"\"\"\n        return await self.bot.edit_message_text(text=text,\n                                                chat_id=self.chat.id, message_id=self.message_id,\n                                                parse_mode=parse_mode,\n                                                disable_web_page_preview=disable_web_page_preview,\n                                                reply_markup=reply_markup)", "response": "Edit the text of a message."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nedit the caption of the message.", "response": "async def edit_caption(self, caption: base.String,\n                           parse_mode: typing.Union[base.String, None] = None,\n                           reply_markup=None):\n        \"\"\"\n        Use this method to edit captions of messages sent by the bot or via the bot (for inline bots).\n\n        Source: https://core.telegram.org/bots/api#editmessagecaption\n\n        :param caption: New caption of the message\n        :type caption: :obj:`typing.Union[base.String, None]`\n        :param parse_mode: Send Markdown or HTML, if you want Telegram apps to show bold, italic,\n            fixed-width text or inline URLs in your bot's message.\n        :type parse_mode: :obj:`typing.Union[base.String, None]`\n        :param reply_markup: A JSON-serialized object for an inline keyboard\n        :type reply_markup: :obj:`typing.Union[types.InlineKeyboardMarkup, None]`\n        :return: On success, if edited message is sent by the bot, the edited Message is returned,\n            otherwise True is returned.\n        :rtype: :obj:`typing.Union[types.Message, base.Boolean]`\n        \"\"\"\n        return await self.bot.edit_message_caption(chat_id=self.chat.id, message_id=self.message_id, caption=caption,\n                                                   parse_mode=parse_mode, reply_markup=reply_markup)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nediting a message s media content.", "response": "async def edit_media(self, media: InputMedia, reply_markup=None):\n        \"\"\"\n        Use this method to edit audio, document, photo, or video messages.\n        If a message is a part of a message album, then it can be edited only to a photo or a video.\n        Otherwise, message type can be changed arbitrarily.\n        When inline message is edited, new file can't be uploaded.\n        Use previously uploaded file via its file_id or specify a URL.\n\n        On success, if the edited message was sent by the bot,\n        the edited Message is returned, otherwise True is returned.\n\n        Source https://core.telegram.org/bots/api#editmessagemedia\n\n        :param media: A JSON-serialized object for a new media content of the message\n        :type media: :obj:`types.InputMedia`\n        :param reply_markup: A JSON-serialized object for a new inline keyboard\n        :type reply_markup: :obj:`typing.Union[types.InlineKeyboardMarkup, None]`\n        :return: On success, if the edited message was sent by the bot, the edited Message is returned,\n            otherwise True is returned\n        :rtype: :obj:`typing.Union[types.Message, base.Boolean]`\n        \"\"\"\n        return await self.bot.edit_message_media(media=media, chat_id=self.chat.id, message_id=self.message_id,\n                                                 reply_markup=reply_markup)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nedit the reply markup of the message.", "response": "async def edit_reply_markup(self, reply_markup=None):\n        \"\"\"\n        Use this method to edit only the reply markup of messages sent by the bot or via the bot (for inline bots).\n\n        Source: https://core.telegram.org/bots/api#editmessagereplymarkup\n\n        :param reply_markup: A JSON-serialized object for an inline keyboard\n        :type reply_markup: :obj:`typing.Union[types.InlineKeyboardMarkup, None]`\n        :return: On success, if edited message is sent by the bot, the edited Message is returned,\n            otherwise True is returned.\n        :rtype: :obj:`typing.Union[types.Message, base.Boolean]`\n        \"\"\"\n        return await self.bot.edit_message_reply_markup(chat_id=self.chat.id, message_id=self.message_id,\n                                                        reply_markup=reply_markup)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndeleting the reply markup of the message.", "response": "async def delete_reply_markup(self):\n        \"\"\"\n        Use this method to delete reply markup of messages sent by the bot or via the bot (for inline bots).\n\n        :return: On success, if edited message is sent by the bot, the edited Message is returned,\n            otherwise True is returned.\n        :rtype: :obj:`typing.Union[types.Message, base.Boolean]`\n        \"\"\"\n        return await self.bot.edit_message_reply_markup(chat_id=self.chat.id, message_id=self.message_id)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def edit_live_location(self, latitude: base.Float, longitude: base.Float,\n                                 reply_markup=None) -> typing.Union[Message, base.Boolean]:\n        \"\"\"\n        Use this method to edit live location messages sent by the bot or via the bot (for inline bots).\n        A location can be edited until its live_period expires or editing is explicitly disabled by a call\n        to stopMessageLiveLocation.\n\n        Source: https://core.telegram.org/bots/api#editmessagelivelocation\n\n        :param latitude: Latitude of new location\n        :type latitude: :obj:`base.Float`\n        :param longitude: Longitude of new location\n        :type longitude: :obj:`base.Float`\n        :param reply_markup: A JSON-serialized object for a new inline keyboard.\n        :type reply_markup: :obj:`typing.Union[types.InlineKeyboardMarkup, None]`\n        :return: On success, if the edited message was sent by the bot, the edited Message is returned,\n            otherwise True is returned.\n        :rtype: :obj:`typing.Union[types.Message, base.Boolean]`\n        \"\"\"\n        return await self.bot.edit_message_live_location(latitude=latitude, longitude=longitude,\n                                                         chat_id=self.chat.id, message_id=self.message_id,\n                                                         reply_markup=reply_markup)", "response": "Edit the live location of a message."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nstops updating a live location message.", "response": "async def stop_live_location(self, reply_markup=None) -> typing.Union[Message, base.Boolean]:\n        \"\"\"\n        Use this method to stop updating a live location message sent by the bot or via the bot\n        (for inline bots) before live_period expires.\n\n        Source: https://core.telegram.org/bots/api#stopmessagelivelocation\n\n        :param reply_markup: A JSON-serialized object for a new inline keyboard.\n        :type reply_markup: :obj:`typing.Union[types.InlineKeyboardMarkup, None]`\n        :return: On success, if the message was sent by the bot, the sent Message is returned,\n            otherwise True is returned.\n        :rtype: :obj:`typing.Union[types.Message, base.Boolean]`\n        \"\"\"\n        return await self.bot.stop_message_live_location(chat_id=self.chat.id, message_id=self.message_id,\n                                                         reply_markup=reply_markup)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndeletes this message :return: bool", "response": "async def delete(self):\n        \"\"\"\n        Delete this message\n\n        :return: bool\n        \"\"\"\n        return await self.bot.delete_message(self.chat.id, self.message_id)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def pin(self, disable_notification: bool = False):\n        return await self.chat.pin_message(self.message_id, disable_notification)", "response": "Pin the message to the chat."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating callback data for new entry.", "response": "def new(self, *args, **kwargs) -> str:\n        \"\"\"\n        Generate callback data\n\n        :param args:\n        :param kwargs:\n        :return:\n        \"\"\"\n        args = list(args)\n\n        data = [self.prefix]\n\n        for part in self._part_names:\n            value = kwargs.pop(part, None)\n            if value is None:\n                if args:\n                    value = args.pop(0)\n                else:\n                    raise ValueError(f\"Value for '{part}' is not passed!\")\n\n            if value is not None and not isinstance(value, str):\n                value = str(value)\n\n            if not value:\n                raise ValueError(f\"Value for part {part} can't be empty!'\")\n            elif self.sep in value:\n                raise ValueError(f\"Symbol defined as separator can't be used in values of parts\")\n\n            data.append(value)\n\n        if args or kwargs:\n            raise TypeError('Too many arguments is passed!')\n\n        callback_data = self.sep.join(data)\n        if len(callback_data) > 64:\n            raise ValueError('Resulted callback data is too long!')\n\n        return callback_data"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse(self, callback_data: str) -> typing.Dict[str, str]:\n        prefix, *parts = callback_data.split(self.sep)\n        if prefix != self.prefix:\n            raise ValueError(\"Passed callback data can't be parsed with that prefix.\")\n        elif len(parts) != len(self._part_names):\n            raise ValueError('Invalid parts count!')\n\n        result = {'@': prefix}\n        result.update(zip(self._part_names, parts))\n        return result", "response": "Parse the data from the callback data."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef filter(self, **config) -> CallbackDataFilter:\n        for key in config.keys():\n            if key not in self._part_names:\n                raise ValueError(f\"Invalid field name '{key}'\")\n        return CallbackDataFilter(self, config)", "response": "Generate filter for the set of items in the archive."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def cmd_id(message: types.Message):\n    if message.reply_to_message:\n        target = message.reply_to_message.from_user\n        chat = message.chat\n    elif message.forward_from and message.chat.type == ChatType.PRIVATE:\n        target = message.forward_from\n        chat = message.forward_from or message.chat\n    else:\n        target = message.from_user\n        chat = message.chat\n\n    result_msg = [hbold('Info about user:'),\n                  f\"First name: {target.first_name}\"]\n    if target.last_name:\n        result_msg.append(f\"Last name: {target.last_name}\")\n    if target.username:\n        result_msg.append(f\"Username: {target.mention}\")\n    result_msg.append(f\"User ID: {target.id}\")\n\n    result_msg.extend([hbold('Chat:'),\n                       f\"Type: {chat.type}\",\n                       f\"Chat ID: {chat.id}\"])\n    if chat.type != ChatType.PRIVATE:\n        result_msg.append(f\"Title: {chat.title}\")\n    else:\n        result_msg.append(f\"Title: {chat.full_name}\")\n    return SendMessage(message.chat.id, '\\n'.join(result_msg), reply_to_message_id=message.message_id,\n                       parse_mode=ParseMode.HTML)", "response": "Return info about user."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndownloads file from URL.", "response": "def from_url(cls, url, filename=None, chunk_size=CHUNK_SIZE):\n        \"\"\"\n        Download file from URL\n\n        Manually is not required action. You can send urls instead!\n\n        :param url: target URL\n        :param filename: optional. set custom file name\n        :param chunk_size:\n\n        :return: InputFile\n        \"\"\"\n        pipe = _WebPipe(url, chunk_size=chunk_size)\n        if filename is None:\n            filename = pipe.name\n\n        return cls(pipe, filename, chunk_size)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef save(self, filename, chunk_size=CHUNK_SIZE):\n        with open(filename, 'wb') as fp:\n            while True:\n                # Chunk writer\n                data = self.file.read(chunk_size)\n                if not data:\n                    break\n                fp.write(data)\n            # Flush all data\n            fp.flush()\n\n        # Go to start of file.\n        if self.file.seekable():\n            self.file.seek(0)", "response": "Writes the file to disk and flushes all data until EOF."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create(cls, selective: typing.Optional[base.Boolean] = None):\n        return cls(selective=selective)", "response": "Create new force reply"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef insert(self, button):\n        if self.keyboard and len(self.keyboard[-1]) < self.row_width:\n            self.keyboard[-1].append(button)\n        else:\n            self.add(button)\n        return self", "response": "Insert button to last row of reply keyboard markup."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncancels the current state and remove keyboard.", "response": "async def cancel_handler(message: types.Message, state: FSMContext, raw_state: Optional[str] = None):\n    \"\"\"\n    Allow user to cancel any action\n    \"\"\"\n    if raw_state is None:\n        return\n\n    # Cancel state and inform user about it\n    await state.finish()\n    # And remove keyboard (just in case)\n    await message.reply('Canceled.', reply_markup=types.ReplyKeyboardRemove())"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nnotifies user only on first exceed and notify about unlocking only on last exceed", "response": "async def message_throttled(self, message: types.Message, throttled: Throttled):\n        \"\"\"\n        Notify user only on first exceed and notify about unlocking only on last exceed\n\n        :param message:\n        :param throttled:\n        \"\"\"\n        handler = current_handler.get()\n        dispatcher = Dispatcher.get_current()\n        if handler:\n            key = getattr(handler, 'throttling_key', f\"{self.prefix}_{handler.__name__}\")\n        else:\n            key = f\"{self.prefix}_message\"\n\n        # Calculate how many time is left till the block ends\n        delta = throttled.rate - throttled.delta\n\n        # Prevent flooding\n        if throttled.exceeded_count <= 2:\n            await message.reply('Too many requests! ')\n\n        # Sleep.\n        await asyncio.sleep(delta)\n\n        # Check lock status\n        thr = await dispatcher.check_key(key)\n\n        # If current message is not last with current key - do not send message\n        if thr.exceeded_count == throttled.exceeded_count:\n            await message.reply('Unlocked.')"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nuses this method to send answers to an inline query. No more than 50 results per query are allowed. Source: https://core.telegram.org/bots/api#answerinlinequery :param results: A JSON-serialized array of results for the inline query :type results: :obj:`typing.List[types.InlineQueryResult]` :param cache_time: The maximum amount of time in seconds that the result of the inline query may be cached on the server. Defaults to 300. :type cache_time: :obj:`typing.Union[base.Integer, None]` :param is_personal: Pass True, if results may be cached on the server side only for the user that sent the query. By default, results may be returned to any user who sends the same query :type is_personal: :obj:`typing.Union[base.Boolean, None]` :param next_offset: Pass the offset that a client should send in the next query with the same text to receive more results. Pass an empty string if there are no more results or if you don\u2018t support pagination. Offset length can\u2019t exceed 64 bytes. :type next_offset: :obj:`typing.Union[base.String, None]` :param switch_pm_text: If passed, clients will display a button with specified text that switches the user to a private chat with the bot and sends the bot a start message with the parameter switch_pm_parameter :type switch_pm_text: :obj:`typing.Union[base.String, None]` :param switch_pm_parameter: Deep-linking parameter for the /start message sent to the bot when user presses the switch button. 1-64 characters, only A-Z, a-z, 0-9, _ and - are allowed. :type switch_pm_parameter: :obj:`typing.Union[base.String, None]` :return: On success, True is returned :rtype: :obj:`base.Boolean`", "response": "async def answer(self,\n                     results: typing.List[InlineQueryResult],\n                     cache_time: typing.Union[base.Integer, None] = None,\n                     is_personal: typing.Union[base.Boolean, None] = None,\n                     next_offset: typing.Union[base.String, None] = None,\n                     switch_pm_text: typing.Union[base.String, None] = None,\n                     switch_pm_parameter: typing.Union[base.String, None] = None):\n        \"\"\"\n        Use this method to send answers to an inline query.\n        No more than 50 results per query are allowed.\n\n        Source: https://core.telegram.org/bots/api#answerinlinequery\n\n        :param results: A JSON-serialized array of results for the inline query\n        :type results: :obj:`typing.List[types.InlineQueryResult]`\n        :param cache_time: The maximum amount of time in seconds that the result of the\n            inline query may be cached on the server. Defaults to 300.\n        :type cache_time: :obj:`typing.Union[base.Integer, None]`\n        :param is_personal: Pass True, if results may be cached on the server side only\n            for the user that sent the query. By default, results may be returned to any user who sends the same query\n        :type is_personal: :obj:`typing.Union[base.Boolean, None]`\n        :param next_offset: Pass the offset that a client should send in the\n            next query with the same text to receive more results.\n            Pass an empty string if there are no more results or if you don\u2018t support pagination.\n            Offset length can\u2019t exceed 64 bytes.\n        :type next_offset: :obj:`typing.Union[base.String, None]`\n        :param switch_pm_text: If passed, clients will display a button with specified text that\n            switches the user to a private chat with the bot and sends the bot a start message\n            with the parameter switch_pm_parameter\n        :type switch_pm_text: :obj:`typing.Union[base.String, None]`\n        :param switch_pm_parameter: Deep-linking parameter for the /start message sent to the bot when\n            user presses the switch button. 1-64 characters, only A-Z, a-z, 0-9, _ and - are allowed.\n        :type switch_pm_parameter: :obj:`typing.Union[base.String, None]`\n        :return: On success, True is returned\n        :rtype: :obj:`base.Boolean`\n        \"\"\"\n        return await self.bot.answer_inline_query(self.id,\n                                                  results=results,\n                                                  cache_time=cache_time,\n                                                  is_personal=is_personal,\n                                                  next_offset=next_offset,\n                                                  switch_pm_text=switch_pm_text,\n                                                  switch_pm_parameter=switch_pm_parameter)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating secret hash :param data: :param token: :return:", "response": "def generate_hash(data: dict, token: str) -> str:\n    \"\"\"\n    Generate secret hash\n\n    :param data:\n    :param token:\n    :return:\n    \"\"\"\n    secret = hashlib.sha256()\n    secret.update(token.encode('utf-8'))\n    sorted_params = collections.OrderedDict(sorted(data.items()))\n    msg = '\\n'.join(\"{}={}\".format(k, v) for k, v in sorted_params.items() if k != 'hash')\n    return hmac.new(secret.digest(), msg.encode('utf-8'), digestmod=hashlib.sha256).hexdigest()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nvalidating auth token :param data: :param token: :return:", "response": "def check_token(data: dict, token: str) -> bool:\n    \"\"\"\n    Validate auth token\n\n    :param data:\n    :param token:\n    :return:\n    \"\"\"\n    param_hash = data.get('hash', '') or ''\n    return param_hash == generate_hash(data, token)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbinds a callback to the filter manager.", "response": "def bind(self, callback: typing.Union[typing.Callable, AbstractFilter],\n             validator: typing.Optional[typing.Callable] = None,\n             event_handlers: typing.Optional[typing.List[Handler]] = None,\n             exclude_event_handlers: typing.Optional[typing.Iterable[Handler]] = None):\n        \"\"\"\n        Register filter\n\n        :param callback: callable or subclass of :obj:`AbstractFilter`\n        :param validator: custom validator.\n        :param event_handlers: list of instances of :obj:`Handler`\n        :param exclude_event_handlers: list of excluded event handlers (:obj:`Handler`)\n        \"\"\"\n        record = FilterRecord(callback, validator, event_handlers, exclude_event_handlers)\n        self._registered.append(record)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef unbind(self, callback: typing.Union[typing.Callable, AbstractFilter]):\n        for record in self._registered:\n            if record.callback == callback:\n                self._registered.remove(record)", "response": "Unregisters a callback from the set of active items."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef resolve(self, event_handler, *custom_filters, **full_config\n                ) -> typing.List[typing.Union[typing.Callable, AbstractFilter]]:\n        \"\"\"\n        Resolve filters to filters-set\n\n        :param event_handler:\n        :param custom_filters:\n        :param full_config:\n        :return:\n        \"\"\"\n        filters_set = []\n        filters_set.extend(self._resolve_registered(event_handler,\n                                                    {k: v for k, v in full_config.items() if v is not None}))\n        if custom_filters:\n            filters_set.extend(custom_filters)\n\n        return filters_set", "response": "Resolve filters to filters - set\n       "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _resolve_registered(self, event_handler, full_config) -> typing.Generator:\n        for record in self._registered:\n            filter_ = record.resolve(self._dispatcher, event_handler, full_config)\n            if filter_:\n                yield filter_\n\n        if full_config:\n            raise NameError('Invalid filter name(s): \\'' + '\\', '.join(full_config.keys()) + '\\'')", "response": "Resolve registered filters\n\n        :param event_handler:\n        :param full_config:\n        :return:"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses Telegram auth widget data.", "response": "def parse(cls, request: web.Request) -> AuthWidgetData:\n        \"\"\"\n        Parse request as Telegram auth widget data.\n\n        :param request:\n        :return: :obj:`AuthWidgetData`\n        :raise: :obj:`aiohttp.web.HTTPBadRequest`\n        \"\"\"\n        try:\n            query = dict(request.query)\n            query['id'] = int(query['id'])\n            query['auth_date'] = int(query['auth_date'])\n            widget = AuthWidgetData(**query)\n        except (ValueError, KeyError):\n            raise web.HTTPBadRequest(text='Invalid auth data')\n        else:\n            return widget"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _check_ip(ip: str) -> bool:\n    address = ipaddress.IPv4Address(ip)\n    return address in allowed_ips", "response": "Check if IP is in range"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nallows the given IP address.", "response": "def allow_ip(*ips: typing.Union[str, ipaddress.IPv4Network, ipaddress.IPv4Address]):\n    \"\"\"\n    Allow ip address.\n\n    :param ips:\n    :return:\n    \"\"\"\n    for ip in ips:\n        if isinstance(ip, ipaddress.IPv4Address):\n            allowed_ips.add(ip)\n        elif isinstance(ip, str):\n            allowed_ips.add(ipaddress.IPv4Address(ip))\n        elif isinstance(ip, ipaddress.IPv4Network):\n            allowed_ips.update(ip.hosts())\n        else:\n            raise ValueError(f\"Bad type of ipaddress: {type(ip)} ('{ip}')\")"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconfigure the web. Application for working with webhook handler.", "response": "def configure_app(dispatcher, app: web.Application, path=DEFAULT_WEB_PATH, route_name=DEFAULT_ROUTE_NAME):\n    \"\"\"\n    You can prepare web.Application for working with webhook handler.\n\n    :param dispatcher: Dispatcher instance\n    :param app: :class:`aiohttp.web.Application`\n    :param path: Path to your webhook.\n    :param route_name: Name of webhook handler route\n    :return:\n    \"\"\"\n    app.router.add_route('*', path, WebhookRequestHandler, name=route_name)\n    app[BOT_DISPATCHER_KEY] = dispatcher"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_new_configured_app(dispatcher, path=DEFAULT_WEB_PATH):\n    app = web.Application()\n    configure_app(dispatcher, app, path)\n    return app", "response": "Create a new web. Application and configure it."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_dispatcher(self):\n        dp = self.request.app[BOT_DISPATCHER_KEY]\n        try:\n            from aiogram import Bot, Dispatcher\n            Dispatcher.set_current(dp)\n            Bot.set_current(dp.bot)\n        except RuntimeError:\n            pass\n        return dp", "response": "Get Dispatcher instance from environment"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads update from stream and deserialize it.", "response": "async def parse_update(self, bot):\n        \"\"\"\n        Read update from stream and deserialize it.\n\n        :param bot: bot instance. You an get it from Dispatcher\n        :return: :class:`aiogram.types.Update`\n        \"\"\"\n        data = await self.request.json()\n        update = types.Update(**data)\n        return update"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def post(self):\n        self.validate_ip()\n\n        # context.update_state({'CALLER': WEBHOOK,\n        #                       WEBHOOK_CONNECTION: True,\n        #                       WEBHOOK_REQUEST: self.request})\n\n        dispatcher = self.get_dispatcher()\n        update = await self.parse_update(dispatcher.bot)\n\n        results = await self.process_update(update)\n        response = self.get_response(results)\n\n        if response:\n            web_response = response.get_web_response()\n        else:\n            web_response = web.Response(text='ok')\n\n        if self.request.app.get('RETRY_AFTER', None):\n            web_response.headers['Retry-After'] = self.request.app['RETRY_AFTER']\n\n        return web_response", "response": "Process POST request\n\n        if one of handler returns instance of :class:`aiogram.dispatcher.webhook.BaseResponse` return it to webhook.\n        Otherwise do nothing (return 'ok')\n\n        :return: :class:`aiohttp.web.Response`"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprocessing an update and return the result.", "response": "async def process_update(self, update):\n        \"\"\"\n        Need respond in less than 60 seconds in to webhook.\n\n        So... If you respond greater than 55 seconds webhook automatically respond 'ok'\n        and execute callback response via simple HTTP request.\n\n        :param update:\n        :return:\n        \"\"\"\n        dispatcher = self.get_dispatcher()\n        loop = dispatcher.loop\n\n        # Analog of `asyncio.wait_for` but without cancelling task\n        waiter = loop.create_future()\n        timeout_handle = loop.call_later(RESPONSE_TIMEOUT, asyncio.tasks._release_waiter, waiter)\n        cb = functools.partial(asyncio.tasks._release_waiter, waiter)\n\n        fut = asyncio.ensure_future(dispatcher.updates_handler.notify(update), loop=loop)\n        fut.add_done_callback(cb)\n\n        try:\n            try:\n                await waiter\n            except asyncio.futures.CancelledError:\n                fut.remove_done_callback(cb)\n                fut.cancel()\n                raise\n\n            if fut.done():\n                return fut.result()\n            else:\n                # context.set_value(WEBHOOK_CONNECTION, False)\n                fut.remove_done_callback(cb)\n                fut.add_done_callback(self.respond_via_request)\n        finally:\n            timeout_handle.cancel()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nhandles response via request.", "response": "def respond_via_request(self, task):\n        \"\"\"\n        Handle response after 55 second.\n\n        :param task:\n        :return:\n        \"\"\"\n        warn(f\"Detected slow response into webhook. \"\n             f\"(Greater than {RESPONSE_TIMEOUT} seconds)\\n\"\n             f\"Recommended to use 'async_task' decorator from Dispatcher for handler with long timeouts.\",\n             TimeoutWarning)\n\n        dispatcher = self.get_dispatcher()\n        loop = dispatcher.loop\n\n        try:\n            results = task.result()\n        except Exception as e:\n            loop.create_task(\n                dispatcher.errors_handlers.notify(dispatcher, types.Update.get_current(), e))\n        else:\n            response = self.get_response(results)\n            if response is not None:\n                asyncio.ensure_future(response.execute_response(dispatcher.bot), loop=loop)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget response object from results.", "response": "def get_response(self, results):\n        \"\"\"\n        Get response object from results.\n\n        :param results: list\n        :return:\n        \"\"\"\n        if results is None:\n            return None\n        for result in itertools.chain.from_iterable(results):\n            if isinstance(result, BaseResponse):\n                return result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking client IP. Accept requests only from telegram servers. :return:", "response": "def check_ip(self):\n        \"\"\"\n        Check client IP. Accept requests only from telegram servers.\n\n        :return:\n        \"\"\"\n        # For reverse proxy (nginx)\n        forwarded_for = self.request.headers.get('X-Forwarded-For', None)\n        if forwarded_for:\n            return forwarded_for, _check_ip(forwarded_for)\n\n        # For default method\n        peer_name = self.request.transport.get_extra_info('peername')\n        if peer_name is not None:\n            host, _ = peer_name\n            return host, _check_ip(host)\n\n        # Not allowed and can't get client IP\n        return None, False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef validate_ip(self):\n        if self.request.app.get('_check_ip', False):\n            ip_address, accept = self.check_ip()\n            if not accept:\n                raise web.HTTPUnauthorized()", "response": "Check if the user is allowed to access the resource. Raise web. HTTPUnauthorized if not allowed hosts."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def execute_response(self, bot):\n        method_name = helper.HelperMode.apply(self.method, helper.HelperMode.snake_case)\n        method = getattr(bot, method_name, None)\n        if method:\n            return await method(**self.cleanup())\n        return await bot.request(self.method, self.cleanup())", "response": "Execute the response from the server."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreplies to message or message_id", "response": "def reply(self, message: typing.Union[int, types.Message]):\n        \"\"\"\n        Reply to message\n\n        :param message: :obj:`int` or  :obj:`types.Message`\n        :return: self\n        \"\"\"\n        setattr(self, 'reply_to_message_id', message.message_id if isinstance(message, types.Message) else message)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef to(self, target: typing.Union[types.Message, types.Chat, types.base.Integer, types.base.String]):\n        if isinstance(target, types.Message):\n            chat_id = target.chat.id\n        elif isinstance(target, types.Chat):\n            chat_id = target.id\n        elif isinstance(target, (int, str)):\n            chat_id = target\n        else:\n            raise TypeError(f\"Bad type of target. ({type(target)})\")\n\n        setattr(self, 'chat_id', chat_id)\n        return self", "response": "Send to chat\n\n        :param target: message or chat or id\n        :return:"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef write(self, *text, sep=' '):\n        self.text += markdown.text(*text, sep)\n        return self", "response": "Write text to response\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write_ln(self, *text, sep=' '):\n        if self.text and self.text[-1] != '\\n':\n            self.text += '\\n'\n        self.text += markdown.text(*text, sep) + '\\n'\n        return self", "response": "Write line in the log file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef message(self, message: types.Message):\n        setattr(self, 'from_chat_id', message.chat.id)\n        setattr(self, 'message_id', message.message_id)\n        return self", "response": "Select target message\n\n        :param message:\n        :return:"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nattaching photo to the entry.", "response": "def attach_photo(self, photo: String, caption: String = None):\n        \"\"\"\n        Attach photo\n\n        :param photo:\n        :param caption:\n        :return: self\n        \"\"\"\n        self.media.attach_photo(photo, caption)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nattach video to the current object", "response": "def attach_video(self, video: String, caption: String = None, width: Integer = None,\n                     height: Integer = None, duration: Integer = None):\n        \"\"\"\n        Attach video\n\n        :param video:\n        :param caption:\n        :param width:\n        :param height:\n        :param duration:\n        :return: self\n        \"\"\"\n        self.media.attach_video(video, caption, width=width, height=height, duration=duration)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check_address(cls, *,\n                      chat: typing.Union[str, int, None] = None,\n                      user: typing.Union[str, int, None] = None) -> (typing.Union[str, int], typing.Union[str, int]):\n        \"\"\"\n        In all storage's methods chat or user is always required.\n        If one of them is not provided, you have to set missing value based on the provided one.\n\n        This method performs the check described above.\n\n        :param chat:\n        :param user:\n        :return:\n        \"\"\"\n        if chat is None and user is None:\n            raise ValueError('`user` or `chat` parameter is required but no one is provided!')\n\n        if user is None and chat is not None:\n            user = chat\n        elif user is not None and chat is None:\n            chat = user\n        return chat, user", "response": "This method checks the address of a chat or user."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget state - data for user in chat.", "response": "async def get_data(self, *,\n                       chat: typing.Union[str, int, None] = None,\n                       user: typing.Union[str, int, None] = None,\n                       default: typing.Optional[typing.Dict] = None) -> typing.Dict:\n        \"\"\"\n        Get state-data for user in chat. Return `default` if no data is provided in storage.\n\n        Chat or user is always required. If one of them is not provided,\n        you have to set missing value based on the provided one.\n\n        :param chat:\n        :param user:\n        :param default:\n        :return:\n        \"\"\"\n        raise NotImplementedError"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate data for user in chat", "response": "async def update_data(self, *,\n                          chat: typing.Union[str, int, None] = None,\n                          user: typing.Union[str, int, None] = None,\n                          data: typing.Dict = None,\n                          **kwargs):\n        \"\"\"\n        Update data for user in chat\n\n        You can use data parameter or|and kwargs.\n\n        Chat or user is always required. If one of them is not provided,\n        you have to set missing value based on the provided one.\n\n        :param data:\n        :param chat:\n        :param user:\n        :param kwargs:\n        :return:\n        \"\"\"\n        raise NotImplementedError"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nresetting state for user in chat.", "response": "async def reset_state(self, *,\n                          chat: typing.Union[str, int, None] = None,\n                          user: typing.Union[str, int, None] = None,\n                          with_data: typing.Optional[bool] = True):\n        \"\"\"\n        Reset state for user in chat.\n        You may desire to use this method when finishing conversations.\n\n        Chat or user is always required. If one of this is not presented,\n        you have to set missing value based on the provided one.\n\n        :param chat:\n        :param user:\n        :param with_data:\n        :return:\n        \"\"\"\n        chat, user = self.check_address(chat=chat, user=user)\n        await self.set_state(chat=chat, user=user, state=None)\n        if with_data:\n            await self.set_data(chat=chat, user=user, data={})"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def finish(self, *,\n                     chat: typing.Union[str, int, None] = None,\n                     user: typing.Union[str, int, None] = None):\n        \"\"\"\n        Finish conversation for user in chat.\n\n        Chat or user is always required. If one of them is not provided,\n        you have to set missing value based on the provided one.\n\n        :param chat:\n        :param user:\n        :return:\n        \"\"\"\n        await self.reset_state(chat=chat, user=user, with_data=True)", "response": "Finish conversation for user in chat."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget user s data bucket for chat.", "response": "async def get_bucket(self, *,\n                         chat: typing.Union[str, int, None] = None,\n                         user: typing.Union[str, int, None] = None,\n                         default: typing.Optional[dict] = None) -> typing.Dict:\n        \"\"\"\n        Get bucket for user in chat. Return `default` if no data is provided in storage.\n\n        Chat or user is always required. If one of them is not provided,\n        you have to set missing value based on the provided one.\n\n        :param chat:\n        :param user:\n        :param default:\n        :return:\n        \"\"\"\n        raise NotImplementedError"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def set_bucket(self, *,\n                         chat: typing.Union[str, int, None] = None,\n                         user: typing.Union[str, int, None] = None,\n                         bucket: typing.Dict = None):\n        \"\"\"\n        Set bucket for user in chat\n\n        Chat or user is always required. If one of them is not provided,\n        you have to set missing value based on the provided one.\n\n        :param chat:\n        :param user:\n        :param bucket:\n        \"\"\"\n        raise NotImplementedError", "response": "Set the user s bucket for chat or user in chat."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating the user s bucket for chat.", "response": "async def update_bucket(self, *,\n                            chat: typing.Union[str, int, None] = None,\n                            user: typing.Union[str, int, None] = None,\n                            bucket: typing.Dict = None,\n                            **kwargs):\n        \"\"\"\n        Update bucket for user in chat\n\n        You can use bucket parameter or|and kwargs.\n\n        Chat or user is always required. If one of them is not provided,\n        you have to set missing value based on the provided one.\n\n        :param bucket:\n        :param chat:\n        :param user:\n        :param kwargs:\n        :return:\n        \"\"\"\n        raise NotImplementedError"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def reset_bucket(self, *,\n                           chat: typing.Union[str, int, None] = None,\n                           user: typing.Union[str, int, None] = None):\n        \"\"\"\n        Reset bucket dor user in chat.\n\n        Chat or user is always required. If one of them is not provided,\n        you have to set missing value based on the provided one.\n\n        :param chat:\n        :param user:\n        :return:\n        \"\"\"\n        await self.set_data(chat=chat, user=user, data={})", "response": "Reset the user s bucket in chat."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def create(cls, fsm_context: FSMContext):\n        proxy = cls(fsm_context)\n        await proxy.load()\n        return proxy", "response": "Create a new object and load it."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def connect(self) -> Connection:\n        if self._conn is None:\n            self._conn = await r.connect(host=self._host,\n                                         port=self._port,\n                                         db=self._db,\n                                         auth_key=self._auth_key,\n                                         user=self._user,\n                                         password=self._password,\n                                         timeout=self._timeout,\n                                         ssl=self._ssl,\n                                         io_loop=self._loop)\n        return self._conn", "response": "Connect to the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def get_states_list(self) -> typing.List[typing.Tuple[int, int]]:\n        async with self.connection() as conn:\n            result = []\n\n            items = (await r.table(self._table).run(conn)).items\n\n            for item in items:\n                chat = int(item.pop('id'))\n                for key in item.keys():\n                    user = int(key)\n                    result.append((chat, user))\n\n        return result", "response": "Get list of all stored chat s and user s state"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nresetting all states in DB", "response": "async def reset_all(self):\n        \"\"\"\n        Reset states in DB\n        \"\"\"\n        async with self.connection() as conn:\n            await r.table(self._table).delete().run(conn)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef attach_many(self, *medias: typing.Union[InputMedia, typing.Dict]):\n        for media in medias:\n            self.attach(media)", "response": "Attaches a list of input media to the current object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef attach(self, media: typing.Union[InputMedia, typing.Dict]):\n        if isinstance(media, dict):\n            if 'type' not in media:\n                raise ValueError(f\"Invalid media!\")\n\n            media_type = media['type']\n            if media_type == 'photo':\n                media = InputMediaPhoto(**media)\n            elif media_type == 'video':\n                media = InputMediaVideo(**media)\n            # elif media_type == 'document':\n            #     media = InputMediaDocument(**media)\n            # elif media_type == 'audio':\n            #     media = InputMediaAudio(**media)\n            # elif media_type == 'animation':\n            #     media = InputMediaAnimation(**media)\n            else:\n                raise TypeError(f\"Invalid media type '{media_type}'!\")\n\n        elif not isinstance(media, InputMedia):\n            raise TypeError(f\"Media must be an instance of InputMedia or dict, not {type(media).__name__}\")\n\n        elif media.type in ['document', 'audio', 'animation']:\n            raise ValueError(f\"This type of media is not supported by media groups!\")\n\n        self.media.append(media)", "response": "Adds a new media to the list of active media."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nattaching photo to the object.", "response": "def attach_photo(self, photo: typing.Union[InputMediaPhoto, base.InputFile],\n                     caption: base.String = None):\n        \"\"\"\n        Attach photo\n\n        :param photo:\n        :param caption:\n        \"\"\"\n        if not isinstance(photo, InputMedia):\n            photo = InputMediaPhoto(media=photo, caption=caption)\n        self.attach(photo)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef attach_video(self, video: typing.Union[InputMediaVideo, base.InputFile],\n                     thumb: typing.Union[base.InputFile, base.String] = None,\n                     caption: base.String = None,\n                     width: base.Integer = None, height: base.Integer = None, duration: base.Integer = None):\n        \"\"\"\n        Attach video\n\n        :param video:\n        :param caption:\n        :param width:\n        :param height:\n        :param duration:\n        \"\"\"\n        if not isinstance(video, InputMedia):\n            video = InputMediaVideo(media=video, thumb=thumb, caption=caption,\n                                    width=width, height=height, duration=duration)\n        self.attach(video)", "response": "Attaches a video to the object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting object as JSON serializable", "response": "def to_python(self) -> typing.List:\n        \"\"\"\n        Get object as JSON serializable\n\n        :return:\n        \"\"\"\n        self.clean()\n        result = []\n        for obj in self.media:\n            if isinstance(obj, base.TelegramObject):\n                obj = obj.to_python()\n            result.append(obj)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def answer(self, text: typing.Union[base.String, None] = None,\n                     show_alert: typing.Union[base.Boolean, None] = None,\n                     url: typing.Union[base.String, None] = None,\n                     cache_time: typing.Union[base.Integer, None] = None):\n        \"\"\"\n        Use this method to send answers to callback queries sent from inline keyboards.\n        The answer will be displayed to the user as a notification at the top of the chat screen or as an alert.\n\n        Alternatively, the user can be redirected to the specified Game URL.\n        For this option to work, you must first create a game for your bot via @Botfather and accept the terms.\n        Otherwise, you may use links like t.me/your_bot?start=XXXX that open your bot with a parameter.\n\n        Source: https://core.telegram.org/bots/api#answercallbackquery\n\n        :param text: Text of the notification. If not specified, nothing will be shown to the user, 0-200 characters\n        :type text: :obj:`typing.Union[base.String, None]`\n        :param show_alert: If true, an alert will be shown by the client instead of a notification\n            at the top of the chat screen. Defaults to false.\n        :type show_alert: :obj:`typing.Union[base.Boolean, None]`\n        :param url: URL that will be opened by the user's client.\n        :type url: :obj:`typing.Union[base.String, None]`\n        :param cache_time: The maximum amount of time in seconds that the\n            result of the callback query may be cached client-side.\n        :type cache_time: :obj:`typing.Union[base.Integer, None]`\n        :return: On success, True is returned.\n        :rtype: :obj:`base.Boolean`\"\"\"\n        await self.bot.answer_callback_query(callback_query_id=self.id, text=text,\n                                             show_alert=show_alert, url=url, cache_time=cache_time)", "response": "Send an answer to the callback query."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def check(self, message: types.Message):\n        check = await super(CommandStart, self).check(message)\n\n        if check and self.deep_link is not None:\n            if not isinstance(self.deep_link, re.Pattern):\n                return message.get_args() == self.deep_link\n\n            match = self.deep_link.match(message.get_args())\n            if match:\n                return {'deep_link': match}\n            return False\n\n        return check", "response": "Check if the message is a valid deep - linking command."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsplit long text into a list of parts.", "response": "def split_text(text: str, length: int = MAX_MESSAGE_LENGTH) -> typing.List[str]:\n    \"\"\"\n    Split long text\n\n    :param text:\n    :param length:\n    :return: list of parts\n    :rtype: :obj:`typing.List[str]`\n    \"\"\"\n    return [text[i:i + length] for i in range(0, len(text), length)]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef safe_split_text(text: str, length: int = MAX_MESSAGE_LENGTH) -> typing.List[str]:\n    # TODO: More informative description\n\n    temp_text = text\n    parts = []\n    while temp_text:\n        if len(temp_text) > length:\n            try:\n                split_pos = temp_text[:length].rindex(' ')\n            except ValueError:\n                split_pos = length\n            if split_pos < length // 4 * 3:\n                split_pos = length\n            parts.append(temp_text[:split_pos])\n            temp_text = temp_text[split_pos:].lstrip()\n        else:\n            parts.append(temp_text)\n            break\n    return parts", "response": "Split long text into list of strings."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef paginate(data: typing.Iterable, page: int = 0, limit: int = 10) -> typing.Iterable:\n    return data[page * limit:page * limit + limit]", "response": "Slice data over pages\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def me(self) -> types.User:\n        if not hasattr(self, '_me'):\n            setattr(self, '_me', await self.get_me())\n        return getattr(self, '_me')", "response": "Return the current user."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def download_file_by_id(self, file_id: base.String, destination=None,\n                                  timeout: base.Integer = 30, chunk_size: base.Integer = 65536,\n                                  seek: base.Boolean = True):\n        \"\"\"\n        Download file by file_id to destination\n\n        if You want to automatically create destination (:class:`io.BytesIO`) use default\n        value of destination and handle result of this method.\n\n        :param file_id: str\n        :param destination: filename or instance of :class:`io.IOBase`. For e. g. :class:`io.BytesIO`\n        :param timeout: int\n        :param chunk_size: int\n        :param seek: bool - go to start of file when downloading is finished\n        :return: destination\n        \"\"\"\n        file = await self.get_file(file_id)\n        return await self.download_file(file_path=file.file_path, destination=destination,\n                                        timeout=timeout, chunk_size=chunk_size, seek=seek)", "response": "Download file by file_id to destination"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def get_updates(self, offset: typing.Union[base.Integer, None] = None,\n                          limit: typing.Union[base.Integer, None] = None,\n                          timeout: typing.Union[base.Integer, None] = None,\n                          allowed_updates:\n                          typing.Union[typing.List[base.String], None] = None) -> typing.List[types.Update]:\n        \"\"\"\n        Use this method to receive incoming updates using long polling (wiki).\n\n        Notes\n        1. This method will not work if an outgoing webhook is set up.\n        2. In order to avoid getting duplicate updates, recalculate offset after each server response.\n\n        Source: https://core.telegram.org/bots/api#getupdates\n\n        :param offset: Identifier of the first update to be returned\n        :type offset: :obj:`typing.Union[base.Integer, None]`\n        :param limit: Limits the number of updates to be retrieved\n        :type limit: :obj:`typing.Union[base.Integer, None]`\n        :param timeout: Timeout in seconds for long polling\n        :type timeout: :obj:`typing.Union[base.Integer, None]`\n        :param allowed_updates: List the types of updates you want your bot to receive\n        :type allowed_updates: :obj:`typing.Union[typing.List[base.String], None]`\n        :return: An Array of Update objects is returned\n        :rtype: :obj:`typing.List[types.Update]`\n        \"\"\"\n        allowed_updates = prepare_arg(allowed_updates)\n        payload = generate_payload(**locals())\n\n        result = await self.request(api.Methods.GET_UPDATES, payload)\n        return [types.Update(**update) for update in result]", "response": "Get updates from the server."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def set_webhook(self, url: base.String,\n                          certificate: typing.Union[base.InputFile, None] = None,\n                          max_connections: typing.Union[base.Integer, None] = None,\n                          allowed_updates: typing.Union[typing.List[base.String], None] = None) -> base.Boolean:\n        \"\"\"\n        Use this method to specify a url and receive incoming updates via an outgoing webhook.\n        Whenever there is an update for the bot, we will send an HTTPS POST request to the specified url,\n        containing a JSON-serialized Update. In case of an unsuccessful request,\n        we will give up after a reasonable amount of attempts.\n\n        Source: https://core.telegram.org/bots/api#setwebhook\n\n        :param url: HTTPS url to send updates to. Use an empty string to remove webhook integration\n        :type url: :obj:`base.String`\n        :param certificate: Upload your public key certificate so that the root certificate in use can be checked\n        :type certificate: :obj:`typing.Union[base.InputFile, None]`\n        :param max_connections: Maximum allowed number of simultaneous HTTPS connections to the webhook\n            for update delivery, 1-100.\n        :type max_connections: :obj:`typing.Union[base.Integer, None]`\n        :param allowed_updates: List the types of updates you want your bot to receive\n        :type allowed_updates: :obj:`typing.Union[typing.List[base.String], None]`\n        :return: Returns true\n        :rtype: :obj:`base.Boolean`\n        \"\"\"\n        allowed_updates = prepare_arg(allowed_updates)\n        payload = generate_payload(**locals(), exclude=['certificate'])\n\n        files = {}\n        prepare_file(payload, files, 'certificate', certificate)\n\n        result = await self.request(api.Methods.SET_WEBHOOK, payload, files)\n        return result", "response": "Send an outgoing webhook to the specified url."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndeletes the current webhook.", "response": "async def delete_webhook(self) -> base.Boolean:\n        \"\"\"\n        Use this method to remove webhook integration if you decide to switch back to getUpdates.\n        Returns True on success. Requires no parameters.\n\n        Source: https://core.telegram.org/bots/api#deletewebhook\n\n        :return: Returns True on success\n        :rtype: :obj:`base.Boolean`\n        \"\"\"\n        payload = generate_payload(**locals())\n\n        result = await self.request(api.Methods.DELETE_WEBHOOK, payload)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def get_webhook_info(self) -> types.WebhookInfo:\n        payload = generate_payload(**locals())\n\n        result = await self.request(api.Methods.GET_WEBHOOK_INFO, payload)\n        return types.WebhookInfo(**result)", "response": "Use this method to get current webhook status. Requires no parameters."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def send_message(self, chat_id: typing.Union[base.Integer, base.String], text: base.String,\n                           parse_mode: typing.Union[base.String, None] = None,\n                           disable_web_page_preview: typing.Union[base.Boolean, None] = None,\n                           disable_notification: typing.Union[base.Boolean, None] = None,\n                           reply_to_message_id: typing.Union[base.Integer, None] = None,\n                           reply_markup: typing.Union[types.InlineKeyboardMarkup,\n                                                      types.ReplyKeyboardMarkup,\n                                                      types.ReplyKeyboardRemove,\n                                                      types.ForceReply, None] = None) -> types.Message:\n        \"\"\"\n        Use this method to send text messages.\n\n        Source: https://core.telegram.org/bots/api#sendmessage\n\n        :param chat_id: Unique identifier for the target chat or username of the target channel\n        :type chat_id: :obj:`typing.Union[base.Integer, base.String]`\n        :param text: Text of the message to be sent\n        :type text: :obj:`base.String`\n        :param parse_mode: Send Markdown or HTML, if you want Telegram apps to show bold, italic,\n            fixed-width text or inline URLs in your bot's message.\n        :type parse_mode: :obj:`typing.Union[base.String, None]`\n        :param disable_web_page_preview: Disables link previews for links in this message\n        :type disable_web_page_preview: :obj:`typing.Union[base.Boolean, None]`\n        :param disable_notification: Sends the message silently. Users will receive a notification with no sound\n        :type disable_notification: :obj:`typing.Union[base.Boolean, None]`\n        :param reply_to_message_id: If the message is a reply, ID of the original message\n        :type reply_to_message_id: :obj:`typing.Union[base.Integer, None]`\n        :param reply_markup: Additional interface options\n        :type reply_markup: :obj:`typing.Union[types.InlineKeyboardMarkup,\n            types.ReplyKeyboardMarkup, types.ReplyKeyboardRemove, types.ForceReply, None]`\n        :return: On success, the sent Message is returned\n        :rtype: :obj:`types.Message`\n        \"\"\"\n        reply_markup = prepare_arg(reply_markup)\n        payload = generate_payload(**locals())\n        if self.parse_mode:\n            payload.setdefault('parse_mode', self.parse_mode)\n\n        result = await self.request(api.Methods.SEND_MESSAGE, payload)\n        return types.Message(**result)", "response": "Use this method to send a message in a chat."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nuse this method to forward a message from one chat to another.", "response": "async def forward_message(self, chat_id: typing.Union[base.Integer, base.String],\n                              from_chat_id: typing.Union[base.Integer, base.String], message_id: base.Integer,\n                              disable_notification: typing.Union[base.Boolean, None] = None) -> types.Message:\n        \"\"\"\n        Use this method to forward messages of any kind.\n\n        Source: https://core.telegram.org/bots/api#forwardmessage\n\n        :param chat_id: Unique identifier for the target chat or username of the target channel\n        :type chat_id: :obj:`typing.Union[base.Integer, base.String]`\n        :param from_chat_id: Unique identifier for the chat where the original message was sent\n        :type from_chat_id: :obj:`typing.Union[base.Integer, base.String]`\n        :param disable_notification: Sends the message silently. Users will receive a notification with no sound\n        :type disable_notification: :obj:`typing.Union[base.Boolean, None]`\n        :param message_id: Message identifier in the chat specified in from_chat_id\n        :type message_id: :obj:`base.Integer`\n        :return: On success, the sent Message is returned\n        :rtype: :obj:`types.Message`\n        \"\"\"\n        payload = generate_payload(**locals())\n\n        result = await self.request(api.Methods.FORWARD_MESSAGE, payload)\n        return types.Message(**result)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def send_audio(self, chat_id: typing.Union[base.Integer, base.String],\n                         audio: typing.Union[base.InputFile, base.String],\n                         caption: typing.Union[base.String, None] = None,\n                         parse_mode: typing.Union[base.String, None] = None,\n                         duration: typing.Union[base.Integer, None] = None,\n                         performer: typing.Union[base.String, None] = None,\n                         title: typing.Union[base.String, None] = None,\n                         thumb: typing.Union[base.InputFile, base.String, None] = None,\n                         disable_notification: typing.Union[base.Boolean, None] = None,\n                         reply_to_message_id: typing.Union[base.Integer, None] = None,\n                         reply_markup: typing.Union[types.InlineKeyboardMarkup,\n                                                    types.ReplyKeyboardMarkup,\n                                                    types.ReplyKeyboardRemove,\n                                                    types.ForceReply, None] = None) -> types.Message:\n        \"\"\"\n        Use this method to send audio files, if you want Telegram clients to display them in the music player.\n        Your audio must be in the .mp3 format.\n\n        For sending voice messages, use the sendVoice method instead.\n\n        Source: https://core.telegram.org/bots/api#sendaudio\n\n        :param chat_id: Unique identifier for the target chat or username of the target channel\n        :type chat_id: :obj:`typing.Union[base.Integer, base.String]`\n        :param audio: Audio file to send\n        :type audio: :obj:`typing.Union[base.InputFile, base.String]`\n        :param caption: Audio caption, 0-1024 characters\n        :type caption: :obj:`typing.Union[base.String, None]`\n        :param parse_mode: Send Markdown or HTML, if you want Telegram apps to show bold, italic,\n            fixed-width text or inline URLs in your bot's message.\n        :type parse_mode: :obj:`typing.Union[base.String, None]`\n        :param duration: Duration of the audio in seconds\n        :type duration: :obj:`typing.Union[base.Integer, None]`\n        :param performer: Performer\n        :type performer: :obj:`typing.Union[base.String, None]`\n        :param title: Track name\n        :type title: :obj:`typing.Union[base.String, None]`\n        :param thumb: Thumbnail of the file sent\n        :type thumb: :obj:`typing.Union[base.InputFile, base.String, None]`\n        :param disable_notification: Sends the message silently. Users will receive a notification with no sound\n        :type disable_notification: :obj:`typing.Union[base.Boolean, None]`\n        :param reply_to_message_id: If the message is a reply, ID of the original message\n        :type reply_to_message_id: :obj:`typing.Union[base.Integer, None]`\n        :param reply_markup: Additional interface options\n        :type reply_markup: :obj:`typing.Union[types.InlineKeyboardMarkup, types.ReplyKeyboardMarkup,\n            types.ReplyKeyboardRemove, types.ForceReply, None]`\n        :return: On success, the sent Message is returned\n        :rtype: :obj:`types.Message`\n        \"\"\"\n        reply_markup = prepare_arg(reply_markup)\n        payload = generate_payload(**locals(), exclude=['audio'])\n        if self.parse_mode:\n            payload.setdefault('parse_mode', self.parse_mode)\n\n        files = {}\n        prepare_file(payload, files, 'audio', audio)\n\n        result = await self.request(api.Methods.SEND_AUDIO, payload, files)\n        return types.Message(**result)", "response": "Use this method to send audio files. You must be an administrator in the chat for this to work and must have the appropriate admin rights."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def send_animation(self,\n                             chat_id: typing.Union[base.Integer, base.String],\n                             animation: typing.Union[base.InputFile, base.String],\n                             duration: typing.Union[base.Integer, None] = None,\n                             width: typing.Union[base.Integer, None] = None,\n                             height: typing.Union[base.Integer, None] = None,\n                             thumb: typing.Union[typing.Union[base.InputFile, base.String], None] = None,\n                             caption: typing.Union[base.String, None] = None,\n                             parse_mode: typing.Union[base.String, None] = None,\n                             disable_notification: typing.Union[base.Boolean, None] = None,\n                             reply_to_message_id: typing.Union[base.Integer, None] = None,\n                             reply_markup: typing.Union[typing.Union[types.InlineKeyboardMarkup,\n                                                                     types.ReplyKeyboardMarkup,\n                                                                     types.ReplyKeyboardRemove,\n                                                                     types.ForceReply], None] = None\n                             ) -> types.Message:\n        \"\"\"\n        Use this method to send animation files (GIF or H.264/MPEG-4 AVC video without sound).\n\n        On success, the sent Message is returned.\n        Bots can currently send animation files of up to 50 MB in size, this limit may be changed in the future.\n\n        Source https://core.telegram.org/bots/api#sendanimation\n\n        :param chat_id: Unique identifier for the target chat or username of the target channel\n            (in the format @channelusername)\n        :type chat_id: :obj:`typing.Union[base.Integer, base.String]`\n        :param animation: Animation to send. Pass a file_id as String to send an animation that exists\n            on the Telegram servers (recommended), pass an HTTP URL as a String for Telegram to get an animation\n            from the Internet, or upload a new animation using multipart/form-data\n        :type animation: :obj:`typing.Union[base.InputFile, base.String]`\n        :param duration: Duration of sent animation in seconds\n        :type duration: :obj:`typing.Union[base.Integer, None]`\n        :param width: Animation width\n        :type width: :obj:`typing.Union[base.Integer, None]`\n        :param height: Animation height\n        :type height: :obj:`typing.Union[base.Integer, None]`\n        :param thumb: Thumbnail of the file sent. The thumbnail should be in JPEG format and less than 200 kB in size.\n            A thumbnail\u2018s width and height should not exceed 90.\n        :type thumb: :obj:`typing.Union[typing.Union[base.InputFile, base.String], None]`\n        :param caption: Animation caption (may also be used when resending animation by file_id), 0-1024 characters\n        :type caption: :obj:`typing.Union[base.String, None]`\n        :param parse_mode: Send Markdown or HTML, if you want Telegram apps to show bold, italic,\n            fixed-width text or inline URLs in the media caption\n        :type parse_mode: :obj:`typing.Union[base.String, None]`\n        :param disable_notification: Sends the message silently. Users will receive a notification with no sound\n        :type disable_notification: :obj:`typing.Union[base.Boolean, None]`\n        :param reply_to_message_id: If the message is a reply, ID of the original message\n        :type reply_to_message_id: :obj:`typing.Union[base.Integer, None]`\n        :param reply_markup: Additional interface options. A JSON-serialized object for an inline keyboard,\n            custom reply keyboard, instructions to remove reply keyboard or to force a reply from the user\n        :type reply_markup: :obj:`typing.Union[typing.Union[types.InlineKeyboardMarkup, types.ReplyKeyboardMarkup,\n            types.ReplyKeyboardRemove, types.ForceReply], None]`\n        :return: On success, the sent Message is returned\n        :rtype: :obj:`types.Message`\n        \"\"\"\n        reply_markup = prepare_arg(reply_markup)\n        payload = generate_payload(**locals(), exclude=[\"animation\", \"thumb\"])\n\n        files = {}\n        prepare_file(payload, files, 'animation', animation)\n        prepare_attachment(payload, files, 'thumb', thumb)\n\n        result = await self.request(api.Methods.SEND_ANIMATION, payload, files)\n        return types.Message(**result)", "response": "Use this method to send an animation file to Telegram servers."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nusing this method to send a voice message.", "response": "async def send_voice(self, chat_id: typing.Union[base.Integer, base.String],\n                         voice: typing.Union[base.InputFile, base.String],\n                         caption: typing.Union[base.String, None] = None,\n                         parse_mode: typing.Union[base.String, None] = None,\n                         duration: typing.Union[base.Integer, None] = None,\n                         disable_notification: typing.Union[base.Boolean, None] = None,\n                         reply_to_message_id: typing.Union[base.Integer, None] = None,\n                         reply_markup: typing.Union[types.InlineKeyboardMarkup,\n                                                    types.ReplyKeyboardMarkup,\n                                                    types.ReplyKeyboardRemove,\n                                                    types.ForceReply, None] = None) -> types.Message:\n        \"\"\"\n        Use this method to send audio files, if you want Telegram clients to display the file\n        as a playable voice message.\n\n        For this to work, your audio must be in an .ogg file encoded with OPUS\n        (other formats may be sent as Audio or Document).\n\n        Source: https://core.telegram.org/bots/api#sendvoice\n\n        :param chat_id: Unique identifier for the target chat or username of the target channel\n        :type chat_id: :obj:`typing.Union[base.Integer, base.String]`\n        :param voice: Audio file to send\n        :type voice: :obj:`typing.Union[base.InputFile, base.String]`\n        :param caption: Voice message caption, 0-1024 characters\n        :type caption: :obj:`typing.Union[base.String, None]`\n        :param parse_mode: Send Markdown or HTML, if you want Telegram apps to show bold, italic,\n            fixed-width text or inline URLs in your bot's message.\n        :type parse_mode: :obj:`typing.Union[base.String, None]`\n        :param duration: Duration of the voice message in seconds\n        :type duration: :obj:`typing.Union[base.Integer, None]`\n        :param disable_notification: Sends the message silently. Users will receive a notification with no sound\n        :type disable_notification: :obj:`typing.Union[base.Boolean, None]`\n        :param reply_to_message_id: If the message is a reply, ID of the original message\n        :type reply_to_message_id: :obj:`typing.Union[base.Integer, None]`\n        :param reply_markup: Additional interface options\n        :type reply_markup: :obj:`typing.Union[types.InlineKeyboardMarkup,\n            types.ReplyKeyboardMarkup, types.ReplyKeyboardRemove, types.ForceReply, None]`\n        :return: On success, the sent Message is returned\n        :rtype: :obj:`types.Message`\n        \"\"\"\n        reply_markup = prepare_arg(reply_markup)\n        payload = generate_payload(**locals(), exclude=['voice'])\n        if self.parse_mode:\n            payload.setdefault('parse_mode', self.parse_mode)\n\n        files = {}\n        prepare_file(payload, files, 'voice', voice)\n\n        result = await self.request(api.Methods.SEND_VOICE, payload, files)\n        return types.Message(**result)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nuse this method to send a video note. You must be an administrator in the chat for this to work and must have the appropriate admin rights.", "response": "async def send_video_note(self, chat_id: typing.Union[base.Integer, base.String],\n                              video_note: typing.Union[base.InputFile, base.String],\n                              duration: typing.Union[base.Integer, None] = None,\n                              length: typing.Union[base.Integer, None] = None,\n                              thumb: typing.Union[base.InputFile, base.String, None] = None,\n                              disable_notification: typing.Union[base.Boolean, None] = None,\n                              reply_to_message_id: typing.Union[base.Integer, None] = None,\n                              reply_markup: typing.Union[types.InlineKeyboardMarkup,\n                                                         types.ReplyKeyboardMarkup,\n                                                         types.ReplyKeyboardRemove,\n                                                         types.ForceReply, None] = None) -> types.Message:\n        \"\"\"\n        As of v.4.0, Telegram clients support rounded square mp4 videos of up to 1 minute long.\n        Use this method to send video messages.\n\n        Source: https://core.telegram.org/bots/api#sendvideonote\n\n        :param chat_id: Unique identifier for the target chat or username of the target channel\n        :type chat_id: :obj:`typing.Union[base.Integer, base.String]`\n        :param video_note: Video note to send\n        :type video_note: :obj:`typing.Union[base.InputFile, base.String]`\n        :param duration: Duration of sent video in seconds\n        :type duration: :obj:`typing.Union[base.Integer, None]`\n        :param length: Video width and height\n        :type length: :obj:`typing.Union[base.Integer, None]`\n        :param thumb: Thumbnail of the file sent\n        :type thumb: :obj:`typing.Union[base.InputFile, base.String, None]`\n        :param disable_notification: Sends the message silently. Users will receive a notification with no sound\n        :type disable_notification: :obj:`typing.Union[base.Boolean, None]`\n        :param reply_to_message_id: If the message is a reply, ID of the original message\n        :type reply_to_message_id: :obj:`typing.Union[base.Integer, None]`\n        :param reply_markup: Additional interface options\n        :type reply_markup: :obj:`typing.Union[types.InlineKeyboardMarkup, types.ReplyKeyboardMarkup,\n            types.ReplyKeyboardRemove, types.ForceReply, None]`\n        :return: On success, the sent Message is returned\n        :rtype: :obj:`types.Message`\n        \"\"\"\n        reply_markup = prepare_arg(reply_markup)\n        payload = generate_payload(**locals(), exclude=['video_note'])\n\n        files = {}\n        prepare_file(payload, files, 'video_note', video_note)\n\n        result = await self.request(api.Methods.SEND_VIDEO_NOTE, payload, files)\n        return types.Message(**result)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def send_media_group(self, chat_id: typing.Union[base.Integer, base.String],\n                               media: typing.Union[types.MediaGroup, typing.List],\n                               disable_notification: typing.Union[base.Boolean, None] = None,\n                               reply_to_message_id: typing.Union[base.Integer,\n                                                                 None] = None) -> typing.List[types.Message]:\n        \"\"\"\n        Use this method to send a group of photos or videos as an album.\n\n        Source: https://core.telegram.org/bots/api#sendmediagroup\n\n        :param chat_id: Unique identifier for the target chat or username of the target channel\n        :type chat_id: :obj:`typing.Union[base.Integer, base.String]`\n        :param media: A JSON-serialized array describing photos and videos to be sent\n        :type media: :obj:`typing.Union[types.MediaGroup, typing.List]`\n        :param disable_notification: Sends the message silently. Users will receive a notification with no sound\n        :type disable_notification: :obj:`typing.Union[base.Boolean, None]`\n        :param reply_to_message_id: If the message is a reply, ID of the original message\n        :type reply_to_message_id: :obj:`typing.Union[base.Integer, None]`\n        :return: On success, an array of the sent Messages is returned\n        :rtype: typing.List[types.Message]\n        \"\"\"\n        # Convert list to MediaGroup\n        if isinstance(media, list):\n            media = types.MediaGroup(media)\n\n        files = dict(media.get_files())\n\n        media = prepare_arg(media)\n        payload = generate_payload(**locals(), exclude=['files'])\n\n        result = await self.request(api.Methods.SEND_MEDIA_GROUP, payload, files)\n        return [types.Message(**message) for message in result]", "response": "Use this method to send a group of photos or videos to a chat. You must be an administrator in the chat for this to work and must have the appropriate admin rights. You must have the appropriate admin rights."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def send_location(self, chat_id: typing.Union[base.Integer, base.String],\n                            latitude: base.Float, longitude: base.Float,\n                            live_period: typing.Union[base.Integer, None] = None,\n                            disable_notification: typing.Union[base.Boolean, None] = None,\n                            reply_to_message_id: typing.Union[base.Integer, None] = None,\n                            reply_markup: typing.Union[types.InlineKeyboardMarkup,\n                                                       types.ReplyKeyboardMarkup,\n                                                       types.ReplyKeyboardRemove,\n                                                       types.ForceReply, None] = None) -> types.Message:\n        \"\"\"\n        Use this method to send point on the map.\n\n        Source: https://core.telegram.org/bots/api#sendlocation\n\n        :param chat_id: Unique identifier for the target chat or username of the target channel\n        :type chat_id: :obj:`typing.Union[base.Integer, base.String]`\n        :param latitude: Latitude of the location\n        :type latitude: :obj:`base.Float`\n        :param longitude: Longitude of the location\n        :type longitude: :obj:`base.Float`\n        :param live_period: Period in seconds for which the location will be updated\n        :type live_period: :obj:`typing.Union[base.Integer, None]`\n        :param disable_notification: Sends the message silently. Users will receive a notification with no sound\n        :type disable_notification: :obj:`typing.Union[base.Boolean, None]`\n        :param reply_to_message_id: If the message is a reply, ID of the original message\n        :type reply_to_message_id: :obj:`typing.Union[base.Integer, None]`\n        :param reply_markup: Additional interface options\n        :type reply_markup: :obj:`typing.Union[types.InlineKeyboardMarkup,\n            types.ReplyKeyboardMarkup, types.ReplyKeyboardRemove, types.ForceReply, None]`\n        :return: On success, the sent Message is returned\n        :rtype: :obj:`types.Message`\n        \"\"\"\n        reply_markup = prepare_arg(reply_markup)\n        payload = generate_payload(**locals())\n\n        result = await self.request(api.Methods.SEND_LOCATION, payload)\n        return types.Message(**result)", "response": "Use this method to send a location to the map. You must be an administrator in the chat for this to work and must have the appropriate admin rights. You must have the appropriate admin rights."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nuses this method to edit a live location message.", "response": "async def edit_message_live_location(self, latitude: base.Float, longitude: base.Float,\n                                         chat_id: typing.Union[base.Integer, base.String, None] = None,\n                                         message_id: typing.Union[base.Integer, None] = None,\n                                         inline_message_id: typing.Union[base.String, None] = None,\n                                         reply_markup: typing.Union[types.InlineKeyboardMarkup,\n                                                                    None] = None) -> types.Message or base.Boolean:\n        \"\"\"\n        Use this method to edit live location messages sent by the bot or via the bot (for inline bots).\n        A location can be edited until its live_period expires or editing is explicitly disabled by a call\n        to stopMessageLiveLocation.\n\n        Source: https://core.telegram.org/bots/api#editmessagelivelocation\n\n        :param chat_id: Required if inline_message_id is not specified\n        :type chat_id: :obj:`typing.Union[base.Integer, base.String, None]`\n        :param message_id: Required if inline_message_id is not specified. Identifier of the sent message\n        :type message_id: :obj:`typing.Union[base.Integer, None]`\n        :param inline_message_id: Required if chat_id and message_id are not specified. Identifier of the inline message\n        :type inline_message_id: :obj:`typing.Union[base.String, None]`\n        :param latitude: Latitude of new location\n        :type latitude: :obj:`base.Float`\n        :param longitude: Longitude of new location\n        :type longitude: :obj:`base.Float`\n        :param reply_markup: A JSON-serialized object for a new inline keyboard\n        :type reply_markup: :obj:`typing.Union[types.InlineKeyboardMarkup, None]`\n        :return: On success, if the edited message was sent by the bot, the edited Message is returned,\n            otherwise True is returned.\n        :rtype: :obj:`typing.Union[types.Message, base.Boolean]`\n        \"\"\"\n        reply_markup = prepare_arg(reply_markup)\n        payload = generate_payload(**locals())\n\n        result = await self.request(api.Methods.EDIT_MESSAGE_LIVE_LOCATION, payload)\n        if isinstance(result, bool):\n            return result\n        return types.Message(**result)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nuses this method to send a venue. You must be an administrator in the chat for this to work and must have the appropriate admin rights. You must have the appropriate admin rights.", "response": "async def send_venue(self, chat_id: typing.Union[base.Integer, base.String],\n                         latitude: base.Float, longitude: base.Float,\n                         title: base.String, address: base.String,\n                         foursquare_id: typing.Union[base.String, None] = None,\n                         foursquare_type: typing.Union[base.String, None] = None,\n                         disable_notification: typing.Union[base.Boolean, None] = None,\n                         reply_to_message_id: typing.Union[base.Integer, None] = None,\n                         reply_markup: typing.Union[types.InlineKeyboardMarkup,\n                                                    types.ReplyKeyboardMarkup,\n                                                    types.ReplyKeyboardRemove,\n                                                    types.ForceReply, None] = None) -> types.Message:\n        \"\"\"\n        Use this method to send information about a venue.\n\n        Source: https://core.telegram.org/bots/api#sendvenue\n\n        :param chat_id: Unique identifier for the target chat or username of the target channel\n        :type chat_id: :obj:`typing.Union[base.Integer, base.String]`\n        :param latitude: Latitude of the venue\n        :type latitude: :obj:`base.Float`\n        :param longitude: Longitude of the venue\n        :type longitude: :obj:`base.Float`\n        :param title: Name of the venue\n        :type title: :obj:`base.String`\n        :param address: Address of the venue\n        :type address: :obj:`base.String`\n        :param foursquare_id: Foursquare identifier of the venue\n        :type foursquare_id: :obj:`typing.Union[base.String, None]`\n        :param foursquare_type: Foursquare type of the venue, if known\n        :type foursquare_type: :obj:`typing.Union[base.String, None]`\n        :param disable_notification: Sends the message silently. Users will receive a notification with no sound\n        :type disable_notification: :obj:`typing.Union[base.Boolean, None]`\n        :param reply_to_message_id: If the message is a reply, ID of the original message\n        :type reply_to_message_id: :obj:`typing.Union[base.Integer, None]`\n        :param reply_markup: Additional interface options\n        :type reply_markup: :obj:`typing.Union[types.InlineKeyboardMarkup,\n            types.ReplyKeyboardMarkup, types.ReplyKeyboardRemove, types.ForceReply, None]`\n        :return: On success, the sent Message is returned\n        :rtype: :obj:`types.Message`\n        \"\"\"\n        reply_markup = prepare_arg(reply_markup)\n        payload = generate_payload(**locals())\n\n        result = await self.request(api.Methods.SEND_VENUE, payload)\n        return types.Message(**result)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nuse this method to send phone contacts. You must be an administrator in the chat for this to work and must have the appropriate admin rights. You must have the appropriate admin rights.", "response": "async def send_contact(self, chat_id: typing.Union[base.Integer, base.String],\n                           phone_number: base.String, first_name: base.String,\n                           last_name: typing.Union[base.String, None] = None,\n                           vcard: typing.Union[base.String, None] = None,\n                           disable_notification: typing.Union[base.Boolean, None] = None,\n                           reply_to_message_id: typing.Union[base.Integer, None] = None,\n                           reply_markup: typing.Union[types.InlineKeyboardMarkup,\n                                                      types.ReplyKeyboardMarkup,\n                                                      types.ReplyKeyboardRemove,\n                                                      types.ForceReply, None] = None) -> types.Message:\n        \"\"\"\n        Use this method to send phone contacts.\n\n        Source: https://core.telegram.org/bots/api#sendcontact\n\n        :param chat_id: Unique identifier for the target chat or username of the target channel\n        :type chat_id: :obj:`typing.Union[base.Integer, base.String]`\n        :param phone_number: Contact's phone number\n        :type phone_number: :obj:`base.String`\n        :param first_name: Contact's first name\n        :type first_name: :obj:`base.String`\n        :param last_name: Contact's last name\n        :type last_name: :obj:`typing.Union[base.String, None]`\n        :param vcard: vcard\n        :type vcard: :obj:`typing.Union[base.String, None]`\n        :param disable_notification: Sends the message silently. Users will receive a notification with no sound\n        :type disable_notification: :obj:`typing.Union[base.Boolean, None]`\n        :param reply_to_message_id: If the message is a reply, ID of the original message\n        :type reply_to_message_id: :obj:`typing.Union[base.Integer, None]`\n        :param reply_markup: Additional interface options\n        :type reply_markup: :obj:`typing.Union[types.InlineKeyboardMarkup,\n            types.ReplyKeyboardMarkup, types.ReplyKeyboardRemove, types.ForceReply, None]`\n        :return: On success, the sent Message is returned\n        :rtype: :obj:`types.Message`\n        \"\"\"\n        reply_markup = prepare_arg(reply_markup)\n        payload = generate_payload(**locals())\n\n        result = await self.request(api.Methods.SEND_CONTACT, payload)\n        return types.Message(**result)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nuses this method to send a native poll.", "response": "async def send_poll(self, chat_id: typing.Union[base.Integer, base.String],\n                        question: base.String,\n                        options: typing.List[base.String],\n                        disable_notification: typing.Optional[base.Boolean],\n                        reply_to_message_id: typing.Union[base.Integer, None],\n                        reply_markup: typing.Union[types.InlineKeyboardMarkup,\n                                                   types.ReplyKeyboardMarkup,\n                                                   types.ReplyKeyboardRemove,\n                                                   types.ForceReply, None] = None) -> types.Message:\n        \"\"\"\n        Use this method to send a native poll. A native poll can't be sent to a private chat.\n        On success, the sent Message is returned.\n\n        :param chat_id: Unique identifier for the target chat\n            or username of the target channel (in the format @channelusername).\n            A native poll can't be sent to a private chat.\n        :type chat_id: :obj:`typing.Union[base.Integer, base.String]`\n        :param question: Poll question, 1-255 characters\n        :type question: :obj:`base.String`\n        :param options: List of answer options, 2-10 strings 1-100 characters each\n        :param options: :obj:`typing.List[base.String]`\n        :param disable_notification: Sends the message silently. Users will receive a notification with no sound.\n        :type disable_notification: :obj:`typing.Optional[Boolean]`\n        :param reply_to_message_id: If the message is a reply, ID of the original message\n        :type reply_to_message_id: :obj:`typing.Optional[Integer]`\n        :param reply_markup: Additional interface options\n        :type reply_markup: :obj:`typing.Union[types.InlineKeyboardMarkup,\n            types.ReplyKeyboardMarkup, types.ReplyKeyboardRemove, types.ForceReply, None]`\n        :return: On success, the sent Message is returned\n        :rtype: :obj:`types.Message`\n        \"\"\"\n        options = prepare_arg(options)\n        payload = generate_payload(**locals())\n\n        result = await self.request(api.Methods.SEND_POLL, payload)\n        return types.Message(**result)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def send_chat_action(self, chat_id: typing.Union[base.Integer, base.String],\n                               action: base.String) -> base.Boolean:\n        \"\"\"\n        Use this method when you need to tell the user that something is happening on the bot's side.\n        The status is set for 5 seconds or less\n        (when a message arrives from your bot, Telegram clients clear its typing status).\n\n        We only recommend using this method when a response from the bot will take\n        a noticeable amount of time to arrive.\n\n        Source: https://core.telegram.org/bots/api#sendchataction\n\n        :param chat_id: Unique identifier for the target chat or username of the target channel\n        :type chat_id: :obj:`typing.Union[base.Integer, base.String]`\n        :param action: Type of action to broadcast\n        :type action: :obj:`base.String`\n        :return: Returns True on success\n        :rtype: :obj:`base.Boolean`\n        \"\"\"\n        payload = generate_payload(**locals())\n\n        result = await self.request(api.Methods.SEND_CHAT_ACTION, payload)\n        return result", "response": "Use this method to send a specific action to a specific chat."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget a list of profile pictures for a user.", "response": "async def get_user_profile_photos(self, user_id: base.Integer, offset: typing.Union[base.Integer, None] = None,\n                                      limit: typing.Union[base.Integer, None] = None) -> types.UserProfilePhotos:\n        \"\"\"\n        Use this method to get a list of profile pictures for a user. Returns a UserProfilePhotos object.\n\n        Source: https://core.telegram.org/bots/api#getuserprofilephotos\n\n        :param user_id: Unique identifier of the target user\n        :type user_id: :obj:`base.Integer`\n        :param offset: Sequential number of the first photo to be returned. By default, all photos are returned\n        :type offset: :obj:`typing.Union[base.Integer, None]`\n        :param limit: Limits the number of photos to be retrieved. Values between 1\u2014100 are accepted. Defaults to 100\n        :type limit: :obj:`typing.Union[base.Integer, None]`\n        :return: Returns a UserProfilePhotos object\n        :rtype: :obj:`types.UserProfilePhotos`\n        \"\"\"\n        payload = generate_payload(**locals())\n\n        result = await self.request(api.Methods.GET_USER_PROFILE_PHOTOS, payload)\n        return types.UserProfilePhotos(**result)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget basic info about a file and prepare it for downloading.", "response": "async def get_file(self, file_id: base.String) -> types.File:\n        \"\"\"\n        Use this method to get basic info about a file and prepare it for downloading.\n        For the moment, bots can download files of up to 20MB in size.\n\n        Note: This function may not preserve the original file name and MIME type.\n        You should save the file's MIME type and name (if available) when the File object is received.\n\n        Source: https://core.telegram.org/bots/api#getfile\n\n        :param file_id: File identifier to get info about\n        :type file_id: :obj:`base.String`\n        :return: On success, a File object is returned\n        :rtype: :obj:`types.File`\n        \"\"\"\n        payload = generate_payload(**locals())\n\n        result = await self.request(api.Methods.GET_FILE, payload)\n        return types.File(**result)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def kick_chat_member(self, chat_id: typing.Union[base.Integer, base.String], user_id: base.Integer,\n                               until_date: typing.Union[base.Integer, None] = None) -> base.Boolean:\n        \"\"\"\n        Use this method to kick a user from a group, a supergroup or a channel.\n        In the case of supergroups and channels, the user will not be able to return to the group\n        on their own using invite links, etc., unless unbanned first.\n\n        The bot must be an administrator in the chat for this to work and must have the appropriate admin rights.\n\n        Note: In regular groups (non-supergroups), this method will only work if the \u2018All Members Are Admins\u2019 setting\n        is off in the target group.\n        Otherwise members may only be removed by the group's creator or by the member that added them.\n\n        Source: https://core.telegram.org/bots/api#kickchatmember\n\n        :param chat_id: Unique identifier for the target group or username of the target supergroup or channel\n        :type chat_id: :obj:`typing.Union[base.Integer, base.String]`\n        :param user_id: Unique identifier of the target user\n        :type user_id: :obj:`base.Integer`\n        :param until_date: Date when the user will be unbanned, unix time\n        :type until_date: :obj:`typing.Union[base.Integer, None]`\n        :return: Returns True on success\n        :rtype: :obj:`base.Boolean`\n        \"\"\"\n        until_date = prepare_arg(until_date)\n        payload = generate_payload(**locals())\n\n        result = await self.request(api.Methods.KICK_CHAT_MEMBER, payload)\n        return result", "response": "Use this method to kick a user from a chat."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nuse this method to unban a previously kicked user in a supergroup or channel.", "response": "async def unban_chat_member(self, chat_id: typing.Union[base.Integer, base.String],\n                                user_id: base.Integer) -> base.Boolean:\n        \"\"\"\n        Use this method to unban a previously kicked user in a supergroup or channel. `\n        The user will not return to the group or channel automatically, but will be able to join via link, etc.\n\n        The bot must be an administrator for this to work.\n\n        Source: https://core.telegram.org/bots/api#unbanchatmember\n\n        :param chat_id: Unique identifier for the target group or username of the target supergroup or channel\n        :type chat_id: :obj:`typing.Union[base.Integer, base.String]`\n        :param user_id: Unique identifier of the target user\n        :type user_id: :obj:`base.Integer`\n        :return: Returns True on success\n        :rtype: :obj:`base.Boolean`\n        \"\"\"\n        payload = generate_payload(**locals())\n\n        result = await self.request(api.Methods.UNBAN_CHAT_MEMBER, payload)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def restrict_chat_member(self, chat_id: typing.Union[base.Integer, base.String],\n                                   user_id: base.Integer,\n                                   until_date: typing.Union[base.Integer, None] = None,\n                                   can_send_messages: typing.Union[base.Boolean, None] = None,\n                                   can_send_media_messages: typing.Union[base.Boolean, None] = None,\n                                   can_send_other_messages: typing.Union[base.Boolean, None] = None,\n                                   can_add_web_page_previews: typing.Union[base.Boolean, None] = None) -> base.Boolean:\n        \"\"\"\n        Use this method to restrict a user in a supergroup.\n        The bot must be an administrator in the supergroup for this to work and must have the appropriate admin rights.\n        Pass True for all boolean parameters to lift restrictions from a user.\n\n        Source: https://core.telegram.org/bots/api#restrictchatmember\n\n        :param chat_id: Unique identifier for the target chat or username of the target supergroup\n        :type chat_id: :obj:`typing.Union[base.Integer, base.String]`\n        :param user_id: Unique identifier of the target user\n        :type user_id: :obj:`base.Integer`\n        :param until_date: Date when restrictions will be lifted for the user, unix time\n        :type until_date: :obj:`typing.Union[base.Integer, None]`\n        :param can_send_messages: Pass True, if the user can send text messages, contacts, locations and venues\n        :type can_send_messages: :obj:`typing.Union[base.Boolean, None]`\n        :param can_send_media_messages: Pass True, if the user can send audios, documents, photos, videos,\n            video notes and voice notes, implies can_send_messages\n        :type can_send_media_messages: :obj:`typing.Union[base.Boolean, None]`\n        :param can_send_other_messages: Pass True, if the user can send animations, games, stickers and\n            use inline bots, implies can_send_media_messages\n        :type can_send_other_messages: :obj:`typing.Union[base.Boolean, None]`\n        :param can_add_web_page_previews: Pass True, if the user may add web page previews to their messages,\n            implies can_send_media_messages\n        :type can_add_web_page_previews: :obj:`typing.Union[base.Boolean, None]`\n        :return: Returns True on success\n        :rtype: :obj:`base.Boolean`\n        \"\"\"\n        until_date = prepare_arg(until_date)\n        payload = generate_payload(**locals())\n\n        result = await self.request(api.Methods.RESTRICT_CHAT_MEMBER, payload)\n        return result", "response": "Use this method to restrict a user in a supergroup. The bot must be an administrator in the chat for this to work and must have the appropriate admin rights."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def promote_chat_member(self, chat_id: typing.Union[base.Integer, base.String],\n                                  user_id: base.Integer,\n                                  can_change_info: typing.Union[base.Boolean, None] = None,\n                                  can_post_messages: typing.Union[base.Boolean, None] = None,\n                                  can_edit_messages: typing.Union[base.Boolean, None] = None,\n                                  can_delete_messages: typing.Union[base.Boolean, None] = None,\n                                  can_invite_users: typing.Union[base.Boolean, None] = None,\n                                  can_restrict_members: typing.Union[base.Boolean, None] = None,\n                                  can_pin_messages: typing.Union[base.Boolean, None] = None,\n                                  can_promote_members: typing.Union[base.Boolean, None] = None) -> base.Boolean:\n        \"\"\"\n        Use this method to promote or demote a user in a supergroup or a channel.\n        The bot must be an administrator in the chat for this to work and must have the appropriate admin rights.\n        Pass False for all boolean parameters to demote a user.\n\n        Source: https://core.telegram.org/bots/api#promotechatmember\n\n        :param chat_id: Unique identifier for the target chat or username of the target channel\n        :type chat_id: :obj:`typing.Union[base.Integer, base.String]`\n        :param user_id: Unique identifier of the target user\n        :type user_id: :obj:`base.Integer`\n        :param can_change_info: Pass True, if the administrator can change chat title, photo and other settings\n        :type can_change_info: :obj:`typing.Union[base.Boolean, None]`\n        :param can_post_messages: Pass True, if the administrator can create channel posts, channels only\n        :type can_post_messages: :obj:`typing.Union[base.Boolean, None]`\n        :param can_edit_messages: Pass True, if the administrator can edit messages of other users, channels only\n        :type can_edit_messages: :obj:`typing.Union[base.Boolean, None]`\n        :param can_delete_messages: Pass True, if the administrator can delete messages of other users\n        :type can_delete_messages: :obj:`typing.Union[base.Boolean, None]`\n        :param can_invite_users: Pass True, if the administrator can invite new users to the chat\n        :type can_invite_users: :obj:`typing.Union[base.Boolean, None]`\n        :param can_restrict_members: Pass True, if the administrator can restrict, ban or unban chat members\n        :type can_restrict_members: :obj:`typing.Union[base.Boolean, None]`\n        :param can_pin_messages: Pass True, if the administrator can pin messages, supergroups only\n        :type can_pin_messages: :obj:`typing.Union[base.Boolean, None]`\n        :param can_promote_members: Pass True, if the administrator can add new administrators\n            with a subset of his own privileges or demote administrators that he has promoted,\n            directly or indirectly (promoted by administrators that were appointed by him)\n        :type can_promote_members: :obj:`typing.Union[base.Boolean, None]`\n        :return: Returns True on success\n        :rtype: :obj:`base.Boolean`\n        \"\"\"\n        payload = generate_payload(**locals())\n\n        result = await self.request(api.Methods.PROMOTE_CHAT_MEMBER, payload)\n        return result", "response": "Promote a user in a supergroup or channel."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def export_chat_invite_link(self, chat_id: typing.Union[base.Integer, base.String]) -> base.String:\n        payload = generate_payload(**locals())\n\n        result = await self.request(api.Methods.EXPORT_CHAT_INVITE_LINK, payload)\n        return result", "response": "Use this method to generate a new invite link for a chat. You must be an administrator in the chat for this to work and must have the appropriate admin rights. You must have the appropriate admin rights."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nusing this method to set a new profile photo for a chat. Photos can t be changed for private chats. Photos can t be changed for private chats.", "response": "async def set_chat_photo(self, chat_id: typing.Union[base.Integer, base.String],\n                             photo: base.InputFile) -> base.Boolean:\n        \"\"\"\n        Use this method to set a new profile photo for the chat. Photos can't be changed for private chats.\n        The bot must be an administrator in the chat for this to work and must have the appropriate admin rights.\n\n        Note: In regular groups (non-supergroups), this method will only work if the \u2018All Members Are Admins\u2019\n        setting is off in the target group.\n\n        Source: https://core.telegram.org/bots/api#setchatphoto\n\n        :param chat_id: Unique identifier for the target chat or username of the target channel\n        :type chat_id: :obj:`typing.Union[base.Integer, base.String]`\n        :param photo: New chat photo, uploaded using multipart/form-data\n        :type photo: :obj:`base.InputFile`\n        :return: Returns True on success\n        :rtype: :obj:`base.Boolean`\n        \"\"\"\n        payload = generate_payload(**locals(), exclude=['photo'])\n\n        files = {}\n        prepare_file(payload, files, 'photo', photo)\n\n        result = await self.request(api.Methods.SET_CHAT_PHOTO, payload, files)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nuses this method to delete a chat photo. Photos can t be changed for private chats.", "response": "async def delete_chat_photo(self, chat_id: typing.Union[base.Integer, base.String]) -> base.Boolean:\n        \"\"\"\n        Use this method to delete a chat photo. Photos can't be changed for private chats.\n        The bot must be an administrator in the chat for this to work and must have the appropriate admin rights.\n\n        Note: In regular groups (non-supergroups), this method will only work if the \u2018All Members Are Admins\u2019\n        setting is off in the target group.\n\n        Source: https://core.telegram.org/bots/api#deletechatphoto\n\n        :param chat_id: Unique identifier for the target chat or username of the target channel\n        :type chat_id: :obj:`typing.Union[base.Integer, base.String]`\n        :return: Returns True on success\n        :rtype: :obj:`base.Boolean`\n        \"\"\"\n        payload = generate_payload(**locals())\n\n        result = await self.request(api.Methods.DELETE_CHAT_PHOTO, payload)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def set_chat_title(self, chat_id: typing.Union[base.Integer, base.String],\n                             title: base.String) -> base.Boolean:\n        \"\"\"\n        Use this method to change the title of a chat. Titles can't be changed for private chats.\n        The bot must be an administrator in the chat for this to work and must have the appropriate admin rights.\n\n        Note: In regular groups (non-supergroups), this method will only work if the \u2018All Members Are Admins\u2019\n        setting is off in the target group.\n\n        Source: https://core.telegram.org/bots/api#setchattitle\n\n        :param chat_id: Unique identifier for the target chat or username of the target channel\n        :type chat_id: :obj:`typing.Union[base.Integer, base.String]`\n        :param title: New chat title, 1-255 characters\n        :type title: :obj:`base.String`\n        :return: Returns True on success\n        :rtype: :obj:`base.Boolean`\n        \"\"\"\n        payload = generate_payload(**locals())\n\n        result = await self.request(api.Methods.SET_CHAT_TITLE, payload)\n        return result", "response": "Use this method to change the title of a private chat."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def set_chat_description(self, chat_id: typing.Union[base.Integer, base.String],\n                                   description: typing.Union[base.String, None] = None) -> base.Boolean:\n        \"\"\"\n        Use this method to change the description of a supergroup or a channel.\n        The bot must be an administrator in the chat for this to work and must have the appropriate admin rights.\n\n        Source: https://core.telegram.org/bots/api#setchatdescription\n\n        :param chat_id: Unique identifier for the target chat or username of the target channel\n        :type chat_id: :obj:`typing.Union[base.Integer, base.String]`\n        :param description: New chat description, 0-255 characters\n        :type description: :obj:`typing.Union[base.String, None]`\n        :return: Returns True on success\n        :rtype: :obj:`base.Boolean`\n        \"\"\"\n        payload = generate_payload(**locals())\n\n        result = await self.request(api.Methods.SET_CHAT_DESCRIPTION, payload)\n        return result", "response": "Use this method to change the description of a supergroup or channel. You must be an administrator in the chat for this to work and must have the appropriate admin rights. You must have the appropriate admin rights."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def pin_chat_message(self, chat_id: typing.Union[base.Integer, base.String], message_id: base.Integer,\n                               disable_notification: typing.Union[base.Boolean, None] = None) -> base.Boolean:\n        \"\"\"\n        Use this method to pin a message in a supergroup.\n        The bot must be an administrator in the chat for this to work and must have the appropriate admin rights.\n\n        Source: https://core.telegram.org/bots/api#pinchatmessage\n\n        :param chat_id: Unique identifier for the target chat or username of the target supergroup\n        :type chat_id: :obj:`typing.Union[base.Integer, base.String]`\n        :param message_id: Identifier of a message to pin\n        :type message_id: :obj:`base.Integer`\n        :param disable_notification: Pass True, if it is not necessary to send a notification to\n            all group members about the new pinned message\n        :type disable_notification: :obj:`typing.Union[base.Boolean, None]`\n        :return: Returns True on success\n        :rtype: :obj:`base.Boolean`\n        \"\"\"\n        payload = generate_payload(**locals())\n\n        result = await self.request(api.Methods.PIN_CHAT_MESSAGE, payload)\n        return result", "response": "Use this method to pin a message in a supergroup."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nuses this method to unpin a message in a supergroup chat. The bot must be an administrator in the chat for this to work and must have the appropriate admin rights.", "response": "async def unpin_chat_message(self, chat_id: typing.Union[base.Integer, base.String]) -> base.Boolean:\n        \"\"\"\n        Use this method to unpin a message in a supergroup chat.\n        The bot must be an administrator in the chat for this to work and must have the appropriate admin rights.\n\n        Source: https://core.telegram.org/bots/api#unpinchatmessage\n\n        :param chat_id: Unique identifier for the target chat or username of the target supergroup\n        :type chat_id: :obj:`typing.Union[base.Integer, base.String]`\n        :return: Returns True on success\n        :rtype: :obj:`base.Boolean`\n        \"\"\"\n        payload = generate_payload(**locals())\n\n        result = await self.request(api.Methods.UNPIN_CHAT_MESSAGE, payload)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def leave_chat(self, chat_id: typing.Union[base.Integer, base.String]) -> base.Boolean:\n        payload = generate_payload(**locals())\n\n        result = await self.request(api.Methods.LEAVE_CHAT, payload)\n        return result", "response": "Use this method to leave a chat s unique identifier."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nuse this method to get up to date information about the chat.", "response": "async def get_chat(self, chat_id: typing.Union[base.Integer, base.String]) -> types.Chat:\n        \"\"\"\n        Use this method to get up to date information about the chat\n        (current name of the user for one-on-one conversations, current username of a user, group or channel, etc.).\n\n        Source: https://core.telegram.org/bots/api#getchat\n\n        :param chat_id: Unique identifier for the target chat or username of the target supergroup or channel\n        :type chat_id: :obj:`typing.Union[base.Integer, base.String]`\n        :return: Returns a Chat object on success\n        :rtype: :obj:`types.Chat`\n        \"\"\"\n        payload = generate_payload(**locals())\n\n        result = await self.request(api.Methods.GET_CHAT, payload)\n        return types.Chat(**result)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def get_chat_administrators(self, chat_id: typing.Union[base.Integer, base.String]\n                                      ) -> typing.List[types.ChatMember]:\n        \"\"\"\n        Use this method to get a list of administrators in a chat.\n\n        Source: https://core.telegram.org/bots/api#getchatadministrators\n\n        :param chat_id: Unique identifier for the target chat or username of the target supergroup or channel\n        :type chat_id: :obj:`typing.Union[base.Integer, base.String]`\n        :return: On success, returns an Array of ChatMember objects that contains information about all\n            chat administrators except other bots.\n            If the chat is a group or a supergroup and no administrators were appointed,\n            only the creator will be returned.\n        :rtype: :obj:`typing.List[types.ChatMember]`\n        \"\"\"\n        payload = generate_payload(**locals())\n\n        result = await self.request(api.Methods.GET_CHAT_ADMINISTRATORS, payload)\n        return [types.ChatMember(**chatmember) for chatmember in result]", "response": "Use this method to get a list of administrators in a chat."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nusing this method to get the number of members in a chat.", "response": "async def get_chat_members_count(self, chat_id: typing.Union[base.Integer, base.String]) -> base.Integer:\n        \"\"\"\n        Use this method to get the number of members in a chat.\n\n        Source: https://core.telegram.org/bots/api#getchatmemberscount\n\n        :param chat_id: Unique identifier for the target chat or username of the target supergroup or channel\n        :type chat_id: :obj:`typing.Union[base.Integer, base.String]`\n        :return: Returns Int on success\n        :rtype: :obj:`base.Integer`\n        \"\"\"\n        payload = generate_payload(**locals())\n\n        result = await self.request(api.Methods.GET_CHAT_MEMBERS_COUNT, payload)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nuse this method to get information about a member of a chat.", "response": "async def get_chat_member(self, chat_id: typing.Union[base.Integer, base.String],\n                              user_id: base.Integer) -> types.ChatMember:\n        \"\"\"\n        Use this method to get information about a member of a chat.\n\n        Source: https://core.telegram.org/bots/api#getchatmember\n\n        :param chat_id: Unique identifier for the target chat or username of the target supergroup or channel\n        :type chat_id: :obj:`typing.Union[base.Integer, base.String]`\n        :param user_id: Unique identifier of the target user\n        :type user_id: :obj:`base.Integer`\n        :return: Returns a ChatMember object on success\n        :rtype: :obj:`types.ChatMember`\n        \"\"\"\n        payload = generate_payload(**locals())\n\n        result = await self.request(api.Methods.GET_CHAT_MEMBER, payload)\n        return types.ChatMember(**result)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nuse this method to set a new group sticker set for a supergroup. The bot must be an administrator in the chat for this to work and must have the appropriate admin rights.", "response": "async def set_chat_sticker_set(self, chat_id: typing.Union[base.Integer, base.String],\n                                   sticker_set_name: base.String) -> base.Boolean:\n        \"\"\"\n        Use this method to set a new group sticker set for a supergroup.\n        The bot must be an administrator in the chat for this to work and must have the appropriate admin rights.\n\n        Use the field can_set_sticker_set optionally returned in getChat requests to check\n        if the bot can use this method.\n\n        Source: https://core.telegram.org/bots/api#setchatstickerset\n\n        :param chat_id: Unique identifier for the target chat or username of the target supergroup\n        :type chat_id: :obj:`typing.Union[base.Integer, base.String]`\n        :param sticker_set_name: Name of the sticker set to be set as the group sticker set\n        :type sticker_set_name: :obj:`base.String`\n        :return: Returns True on success\n        :rtype: :obj:`base.Boolean`\n        \"\"\"\n        payload = generate_payload(**locals())\n\n        result = await self.request(api.Methods.SET_CHAT_STICKER_SET, payload)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nuse this method to delete a group sticker set from a supergroup. The bot must be an administrator in the chat for this to work and must have the appropriate admin rights. The bot must have the appropriate admin rights. Returns True on success.", "response": "async def delete_chat_sticker_set(self, chat_id: typing.Union[base.Integer, base.String]) -> base.Boolean:\n        \"\"\"\n        Use this method to delete a group sticker set from a supergroup.\n        The bot must be an administrator in the chat for this to work and must have the appropriate admin rights.\n\n        Use the field can_set_sticker_set optionally returned in getChat requests\n        to check if the bot can use this method.\n\n        Source: https://core.telegram.org/bots/api#deletechatstickerset\n\n        :param chat_id: Unique identifier for the target chat or username of the target supergroup\n        :type chat_id: :obj:`typing.Union[base.Integer, base.String]`\n        :return: Returns True on success\n        :rtype: :obj:`base.Boolean`\n        \"\"\"\n        payload = generate_payload(**locals())\n\n        result = await self.request(api.Methods.DELETE_CHAT_STICKER_SET, payload)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsend an answer to a callback query.", "response": "async def answer_callback_query(self, callback_query_id: base.String,\n                                    text: typing.Union[base.String, None] = None,\n                                    show_alert: typing.Union[base.Boolean, None] = None,\n                                    url: typing.Union[base.String, None] = None,\n                                    cache_time: typing.Union[base.Integer, None] = None) -> base.Boolean:\n        \"\"\"\n        Use this method to send answers to callback queries sent from inline keyboards.\n        The answer will be displayed to the user as a notification at the top of the chat screen or as an alert.\n\n        Alternatively, the user can be redirected to the specified Game URL.\n        For this option to work, you must first create a game for your bot via @Botfather and accept the terms.\n        Otherwise, you may use links like t.me/your_bot?start=XXXX that open your bot with a parameter.\n\n        Source: https://core.telegram.org/bots/api#answercallbackquery\n\n        :param callback_query_id: Unique identifier for the query to be answered\n        :type callback_query_id: :obj:`base.String`\n        :param text: Text of the notification. If not specified, nothing will be shown to the user, 0-1024 characters\n        :type text: :obj:`typing.Union[base.String, None]`\n        :param show_alert: If true, an alert will be shown by the client instead of a notification\n            at the top of the chat screen. Defaults to false.\n        :type show_alert: :obj:`typing.Union[base.Boolean, None]`\n        :param url: URL that will be opened by the user's client\n        :type url: :obj:`typing.Union[base.String, None]`\n        :param cache_time: The maximum amount of time in seconds that the\n            result of the callback query may be cached client-side.\n        :type cache_time: :obj:`typing.Union[base.Integer, None]`\n        :return: On success, True is returned\n        :rtype: :obj:`base.Boolean`\n        \"\"\"\n        payload = generate_payload(**locals())\n\n        result = await self.request(api.Methods.ANSWER_CALLBACK_QUERY, payload)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nusing this method to edit text and game messages sent by the bot.", "response": "async def edit_message_text(self, text: base.String,\n                                chat_id: typing.Union[base.Integer, base.String, None] = None,\n                                message_id: typing.Union[base.Integer, None] = None,\n                                inline_message_id: typing.Union[base.String, None] = None,\n                                parse_mode: typing.Union[base.String, None] = None,\n                                disable_web_page_preview: typing.Union[base.Boolean, None] = None,\n                                reply_markup: typing.Union[types.InlineKeyboardMarkup,\n                                                           None] = None) -> types.Message or base.Boolean:\n        \"\"\"\n        Use this method to edit text and game messages sent by the bot or via the bot (for inline bots).\n\n        Source: https://core.telegram.org/bots/api#editmessagetext\n\n        :param chat_id: Required if inline_message_id is not specified\n            Unique identifier for the target chat or username of the target channel\n        :type chat_id: :obj:`typing.Union[base.Integer, base.String, None]`\n        :param message_id: Required if inline_message_id is not specified. Identifier of the sent message\n        :type message_id: :obj:`typing.Union[base.Integer, None]`\n        :param inline_message_id: Required if chat_id and message_id are not specified. Identifier of the inline message\n        :type inline_message_id: :obj:`typing.Union[base.String, None]`\n        :param text: New text of the message\n        :type text: :obj:`base.String`\n        :param parse_mode: Send Markdown or HTML, if you want Telegram apps to show bold, italic,\n            fixed-width text or inline URLs in your bot's message.\n        :type parse_mode: :obj:`typing.Union[base.String, None]`\n        :param disable_web_page_preview: Disables link previews for links in this message\n        :type disable_web_page_preview: :obj:`typing.Union[base.Boolean, None]`\n        :param reply_markup: A JSON-serialized object for an inline keyboard\n        :type reply_markup: :obj:`typing.Union[types.InlineKeyboardMarkup, None]`\n        :return: On success, if edited message is sent by the bot,\n            the edited Message is returned, otherwise True is returned.\n        :rtype: :obj:`typing.Union[types.Message, base.Boolean]`\n        \"\"\"\n        reply_markup = prepare_arg(reply_markup)\n        payload = generate_payload(**locals())\n        if self.parse_mode:\n            payload.setdefault('parse_mode', self.parse_mode)\n\n        result = await self.request(api.Methods.EDIT_MESSAGE_TEXT, payload)\n        if isinstance(result, bool):\n            return result\n        return types.Message(**result)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def edit_message_caption(self, chat_id: typing.Union[base.Integer, base.String, None] = None,\n                                   message_id: typing.Union[base.Integer, None] = None,\n                                   inline_message_id: typing.Union[base.String, None] = None,\n                                   caption: typing.Union[base.String, None] = None,\n                                   parse_mode: typing.Union[base.String, None] = None,\n                                   reply_markup: typing.Union[types.InlineKeyboardMarkup,\n                                                              None] = None) -> types.Message or base.Boolean:\n        \"\"\"\n        Use this method to edit captions of messages sent by the bot or via the bot (for inline bots).\n\n        Source: https://core.telegram.org/bots/api#editmessagecaption\n\n        :param chat_id: Required if inline_message_id is not specified\n            Unique identifier for the target chat or username of the target channel\n        :type chat_id: :obj:`typing.Union[base.Integer, base.String, None]`\n        :param message_id: Required if inline_message_id is not specified. Identifier of the sent message\n        :type message_id: :obj:`typing.Union[base.Integer, None]`\n        :param inline_message_id: Required if chat_id and message_id are not specified. Identifier of the inline message\n        :type inline_message_id: :obj:`typing.Union[base.String, None]`\n        :param caption: New caption of the message\n        :type caption: :obj:`typing.Union[base.String, None]`\n        :param parse_mode: Send Markdown or HTML, if you want Telegram apps to show bold, italic,\n            fixed-width text or inline URLs in your bot's message.\n        :type parse_mode: :obj:`typing.Union[base.String, None]`\n        :param reply_markup: A JSON-serialized object for an inline keyboard\n        :type reply_markup: :obj:`typing.Union[types.InlineKeyboardMarkup, None]`\n        :return: On success, if edited message is sent by the bot, the edited Message is returned,\n            otherwise True is returned.\n        :rtype: :obj:`typing.Union[types.Message, base.Boolean]`\n        \"\"\"\n        reply_markup = prepare_arg(reply_markup)\n        payload = generate_payload(**locals())\n        if self.parse_mode:\n            payload.setdefault('parse_mode', self.parse_mode)\n\n        result = await self.request(api.Methods.EDIT_MESSAGE_CAPTION, payload)\n        if isinstance(result, bool):\n            return result\n        return types.Message(**result)", "response": "Use this method to edit a message s caption."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def edit_message_media(self,\n                                 media: types.InputMedia,\n                                 chat_id: typing.Union[typing.Union[base.Integer, base.String], None] = None,\n                                 message_id: typing.Union[base.Integer, None] = None,\n                                 inline_message_id: typing.Union[base.String, None] = None,\n                                 reply_markup: typing.Union[types.InlineKeyboardMarkup, None] = None,\n                                 ) -> typing.Union[types.Message, base.Boolean]:\n        \"\"\"\n        Use this method to edit audio, document, photo, or video messages.\n        If a message is a part of a message album, then it can be edited only to a photo or a video.\n        Otherwise, message type can be changed arbitrarily.\n        When inline message is edited, new file can't be uploaded.\n        Use previously uploaded file via its file_id or specify a URL.\n\n        On success, if the edited message was sent by the bot,\n        the edited Message is returned, otherwise True is returned.\n\n        Source https://core.telegram.org/bots/api#editmessagemedia\n\n        :param chat_id: Required if inline_message_id is not specified\n        :type chat_id: :obj:`typing.Union[typing.Union[base.Integer, base.String], None]`\n        :param message_id: Required if inline_message_id is not specified. Identifier of the sent message\n        :type message_id: :obj:`typing.Union[base.Integer, None]`\n        :param inline_message_id: Required if chat_id and message_id are not specified. Identifier of the inline message\n        :type inline_message_id: :obj:`typing.Union[base.String, None]`\n        :param media: A JSON-serialized object for a new media content of the message\n        :type media: :obj:`types.InputMedia`\n        :param reply_markup: A JSON-serialized object for a new inline keyboard\n        :type reply_markup: :obj:`typing.Union[types.InlineKeyboardMarkup, None]`\n        :return: On success, if the edited message was sent by the bot, the edited Message is returned,\n            otherwise True is returned\n        :rtype: :obj:`typing.Union[types.Message, base.Boolean]`\n        \"\"\"\n        reply_markup = prepare_arg(reply_markup)\n        payload = generate_payload(**locals())\n\n        if isinstance(media, types.InputMedia):\n            files = dict(media.get_files())\n        else:\n            files = None\n\n        result = await self.request(api.Methods.EDIT_MESSAGE_MEDIA, payload, files)\n        if isinstance(result, bool):\n            return result\n        return types.Message(**result)", "response": "Use this method to edit a message s media content."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nusing this method to edit the inline keyboard reply markup of a message.", "response": "async def edit_message_reply_markup(self,\n                                        chat_id: typing.Union[base.Integer, base.String, None] = None,\n                                        message_id: typing.Union[base.Integer, None] = None,\n                                        inline_message_id: typing.Union[base.String, None] = None,\n                                        reply_markup: typing.Union[types.InlineKeyboardMarkup,\n                                                                   None] = None) -> types.Message or base.Boolean:\n        \"\"\"\n        Use this method to edit only the reply markup of messages sent by the bot or via the bot (for inline bots).\n\n        Source: https://core.telegram.org/bots/api#editmessagereplymarkup\n\n        :param chat_id: Required if inline_message_id is not specified\n            Unique identifier for the target chat or username of the target channel\n        :type chat_id: :obj:`typing.Union[base.Integer, base.String, None]`\n        :param message_id: Required if inline_message_id is not specified. Identifier of the sent message\n        :type message_id: :obj:`typing.Union[base.Integer, None]`\n        :param inline_message_id: Required if chat_id and message_id are not specified. Identifier of the inline message\n        :type inline_message_id: :obj:`typing.Union[base.String, None]`\n        :param reply_markup: A JSON-serialized object for an inline keyboard\n        :type reply_markup: :obj:`typing.Union[types.InlineKeyboardMarkup, None]`\n        :return: On success, if edited message is sent by the bot, the edited Message is returned,\n            otherwise True is returned.\n        :rtype: :obj:`typing.Union[types.Message, base.Boolean]`\n        \"\"\"\n        reply_markup = prepare_arg(reply_markup)\n        payload = generate_payload(**locals())\n\n        result = await self.request(api.Methods.EDIT_MESSAGE_REPLY_MARKUP, payload)\n        if isinstance(result, bool):\n            return result\n        return types.Message(**result)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def stop_poll(self, chat_id: typing.Union[base.String, base.Integer],\n                        message_id: base.Integer,\n                        reply_markup: typing.Union[types.InlineKeyboardMarkup, None] = None) -> types.Poll:\n        \"\"\"\n        Use this method to stop a poll which was sent by the bot.\n        On success, the stopped Poll with the final results is returned.\n\n        :param chat_id: Unique identifier for the target chat or username of the target channel\n        :type chat_id: :obj:`typing.Union[base.String, base.Integer]`\n        :param message_id: Identifier of the original message with the poll\n        :type message_id: :obj:`base.Integer`\n        :param reply_markup: A JSON-serialized object for a new message inline keyboard.\n        :type reply_markup: :obj:`typing.Union[types.InlineKeyboardMarkup, None]`\n        :return: On success, the stopped Poll with the final results is returned.\n        :rtype: :obj:`types.Poll`\n        \"\"\"\n        payload = generate_payload(**locals())\n\n        result = await self.request(api.Methods.STOP_POLL, payload)\n        return types.Poll(**result)", "response": "Use this method to stop a poll."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nuse this method to delete a specific message in a chat.", "response": "async def delete_message(self, chat_id: typing.Union[base.Integer, base.String],\n                             message_id: base.Integer) -> base.Boolean:\n        \"\"\"\n        Use this method to delete a message, including service messages, with the following limitations:\n        - A message can only be deleted if it was sent less than 48 hours ago.\n        - Bots can delete outgoing messages in private chats, groups, and supergroups.\n        - Bots can delete incoming messages in private chats.\n        - Bots granted can_post_messages permissions can delete outgoing messages in channels.\n        - If the bot is an administrator of a group, it can delete any message there.\n        - If the bot has can_delete_messages permission in a supergroup or a channel, it can delete any message there.\n\n        Source: https://core.telegram.org/bots/api#deletemessage\n\n        :param chat_id: Unique identifier for the target chat or username of the target channel\n        :type chat_id: :obj:`typing.Union[base.Integer, base.String]`\n        :param message_id: Identifier of the message to delete\n        :type message_id: :obj:`base.Integer`\n        :return: Returns True on success\n        :rtype: :obj:`base.Boolean`\n        \"\"\"\n        payload = generate_payload(**locals())\n\n        result = await self.request(api.Methods.DELETE_MESSAGE, payload)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nuse this method to send a new sticker to the chat. You must be an administrator in the chat for this to work and must have the appropriate admin rights.", "response": "async def send_sticker(self, chat_id: typing.Union[base.Integer, base.String],\n                           sticker: typing.Union[base.InputFile, base.String],\n                           disable_notification: typing.Union[base.Boolean, None] = None,\n                           reply_to_message_id: typing.Union[base.Integer, None] = None,\n                           reply_markup: typing.Union[types.InlineKeyboardMarkup,\n                                                      types.ReplyKeyboardMarkup,\n                                                      types.ReplyKeyboardRemove,\n                                                      types.ForceReply, None] = None) -> types.Message:\n        \"\"\"\n        Use this method to send .webp stickers.\n\n        Source: https://core.telegram.org/bots/api#sendsticker\n\n        :param chat_id: Unique identifier for the target chat or username of the target channel\n        :type chat_id: :obj:`typing.Union[base.Integer, base.String]`\n        :param sticker: Sticker to send\n        :type sticker: :obj:`typing.Union[base.InputFile, base.String]`\n        :param disable_notification: Sends the message silently. Users will receive a notification with no sound\n        :type disable_notification: :obj:`typing.Union[base.Boolean, None]`\n        :param reply_to_message_id: If the message is a reply, ID of the original message\n        :type reply_to_message_id: :obj:`typing.Union[base.Integer, None]`\n        :param reply_markup: Additional interface options\n        :type reply_markup: :obj:`typing.Union[types.InlineKeyboardMarkup,\n            types.ReplyKeyboardMarkup, types.ReplyKeyboardRemove, types.ForceReply, None]`\n        :return: On success, the sent Message is returned\n        :rtype: :obj:`types.Message`\n        \"\"\"\n        reply_markup = prepare_arg(reply_markup)\n        payload = generate_payload(**locals(), exclude=['sticker'])\n\n        files = {}\n        prepare_file(payload, files, 'sticker', sticker)\n\n        result = await self.request(api.Methods.SEND_STICKER, payload, files)\n        return types.Message(**result)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nuses this method to get a sticker set.", "response": "async def get_sticker_set(self, name: base.String) -> types.StickerSet:\n        \"\"\"\n        Use this method to get a sticker set.\n\n        Source: https://core.telegram.org/bots/api#getstickerset\n\n        :param name: Name of the sticker set\n        :type name: :obj:`base.String`\n        :return: On success, a StickerSet object is returned\n        :rtype: :obj:`types.StickerSet`\n        \"\"\"\n        payload = generate_payload(**locals())\n\n        result = await self.request(api.Methods.GET_STICKER_SET, payload)\n        return types.StickerSet(**result)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def upload_sticker_file(self, user_id: base.Integer, png_sticker: base.InputFile) -> types.File:\n        payload = generate_payload(**locals(), exclude=['png_sticker'])\n\n        files = {}\n        prepare_file(payload, files, 'png_sticker', png_sticker)\n\n        result = await self.request(api.Methods.UPLOAD_STICKER_FILE, payload, files)\n        return types.File(**result)", "response": "Upload a. png file with a sticker to the user with a new sticker set."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a new sticker set owned by a user.", "response": "async def create_new_sticker_set(self, user_id: base.Integer, name: base.String, title: base.String,\n                                     png_sticker: typing.Union[base.InputFile, base.String], emojis: base.String,\n                                     contains_masks: typing.Union[base.Boolean, None] = None,\n                                     mask_position: typing.Union[types.MaskPosition, None] = None) -> base.Boolean:\n        \"\"\"\n        Use this method to create new sticker set owned by a user. The bot will be able to edit the created sticker set.\n\n        Source: https://core.telegram.org/bots/api#createnewstickerset\n\n        :param user_id: User identifier of created sticker set owner\n        :type user_id: :obj:`base.Integer`\n        :param name: Short name of sticker set, to be used in t.me/addstickers/ URLs (e.g., animals)\n        :type name: :obj:`base.String`\n        :param title: Sticker set title, 1-64 characters\n        :type title: :obj:`base.String`\n        :param png_sticker: Png image with the sticker, must be up to 512 kilobytes in size,\n            dimensions must not exceed 512px, and either width or height must be exactly 512px.\n        :type png_sticker: :obj:`typing.Union[base.InputFile, base.String]`\n        :param emojis: One or more emoji corresponding to the sticker\n        :type emojis: :obj:`base.String`\n        :param contains_masks: Pass True, if a set of mask stickers should be created\n        :type contains_masks: :obj:`typing.Union[base.Boolean, None]`\n        :param mask_position: A JSON-serialized object for position where the mask should be placed on faces\n        :type mask_position: :obj:`typing.Union[types.MaskPosition, None]`\n        :return: Returns True on success\n        :rtype: :obj:`base.Boolean`\n        \"\"\"\n        mask_position = prepare_arg(mask_position)\n        payload = generate_payload(**locals(), exclude=['png_sticker'])\n\n        files = {}\n        prepare_file(payload, files, 'png_sticker', png_sticker)\n\n        result = await self.request(api.Methods.CREATE_NEW_STICKER_SET, payload, files)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nuses this method to move a sticker in a set to a specific position.", "response": "async def set_sticker_position_in_set(self, sticker: base.String, position: base.Integer) -> base.Boolean:\n        \"\"\"\n        Use this method to move a sticker in a set created by the bot to a specific position.\n\n        Source: https://core.telegram.org/bots/api#setstickerpositioninset\n\n        :param sticker: File identifier of the sticker\n        :type sticker: :obj:`base.String`\n        :param position: New sticker position in the set, zero-based\n        :type position: :obj:`base.Integer`\n        :return: Returns True on success\n        :rtype: :obj:`base.Boolean`\n        \"\"\"\n        payload = generate_payload(**locals())\n        result = await self.request(api.Methods.SET_STICKER_POSITION_IN_SET, payload)\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nuses this method to delete a sticker from a set created by the bot. The following methods and objects allow your bot to work in inline mode. Source: https://core.telegram.org/bots/api#deletestickerfromset :param sticker: File identifier of the sticker :type sticker: :obj:`base.String` :return: Returns True on success :rtype: :obj:`base.Boolean`", "response": "async def delete_sticker_from_set(self, sticker: base.String) -> base.Boolean:\n        \"\"\"\n        Use this method to delete a sticker from a set created by the bot.\n\n        The following methods and objects allow your bot to work in inline mode.\n\n        Source: https://core.telegram.org/bots/api#deletestickerfromset\n\n        :param sticker: File identifier of the sticker\n        :type sticker: :obj:`base.String`\n        :return: Returns True on success\n        :rtype: :obj:`base.Boolean`\n        \"\"\"\n        payload = generate_payload(**locals())\n\n        result = await self.request(api.Methods.DELETE_STICKER_FROM_SET, payload)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nuse this method to send answers to an inline query.", "response": "async def answer_inline_query(self, inline_query_id: base.String,\n                                  results: typing.List[types.InlineQueryResult],\n                                  cache_time: typing.Union[base.Integer, None] = None,\n                                  is_personal: typing.Union[base.Boolean, None] = None,\n                                  next_offset: typing.Union[base.String, None] = None,\n                                  switch_pm_text: typing.Union[base.String, None] = None,\n                                  switch_pm_parameter: typing.Union[base.String, None] = None) -> base.Boolean:\n        \"\"\"\n        Use this method to send answers to an inline query.\n        No more than 50 results per query are allowed.\n\n        Source: https://core.telegram.org/bots/api#answerinlinequery\n\n        :param inline_query_id: Unique identifier for the answered query\n        :type inline_query_id: :obj:`base.String`\n        :param results: A JSON-serialized array of results for the inline query\n        :type results: :obj:`typing.List[types.InlineQueryResult]`\n        :param cache_time: The maximum amount of time in seconds that the result of the\n            inline query may be cached on the server. Defaults to 300.\n        :type cache_time: :obj:`typing.Union[base.Integer, None]`\n        :param is_personal: Pass True, if results may be cached on the server side only\n            for the user that sent the query. By default, results may be returned to any user who sends the same query\n        :type is_personal: :obj:`typing.Union[base.Boolean, None]`\n        :param next_offset: Pass the offset that a client should send in the\n            next query with the same text to receive more results.\n            Pass an empty string if there are no more results or if you don\u2018t support pagination.\n            Offset length can\u2019t exceed 64 bytes.\n        :type next_offset: :obj:`typing.Union[base.String, None]`\n        :param switch_pm_text: If passed, clients will display a button with specified text that\n            switches the user to a private chat with the bot and sends the bot a start message\n            with the parameter switch_pm_parameter\n        :type switch_pm_text: :obj:`typing.Union[base.String, None]`\n        :param switch_pm_parameter: Deep-linking parameter for the /start message sent to the bot when\n            user presses the switch button. 1-64 characters, only A-Z, a-z, 0-9, _ and - are allowed.\n        :type switch_pm_parameter: :obj:`typing.Union[base.String, None]`\n        :return: On success, True is returned\n        :rtype: :obj:`base.Boolean`\n        \"\"\"\n        results = prepare_arg(results)\n        payload = generate_payload(**locals())\n\n        result = await self.request(api.Methods.ANSWER_INLINE_QUERY, payload)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def send_invoice(self, chat_id: base.Integer, title: base.String,\n                           description: base.String, payload: base.String,\n                           provider_token: base.String, start_parameter: base.String,\n                           currency: base.String, prices: typing.List[types.LabeledPrice],\n                           provider_data: typing.Union[typing.Dict, None] = None,\n                           photo_url: typing.Union[base.String, None] = None,\n                           photo_size: typing.Union[base.Integer, None] = None,\n                           photo_width: typing.Union[base.Integer, None] = None,\n                           photo_height: typing.Union[base.Integer, None] = None,\n                           need_name: typing.Union[base.Boolean, None] = None,\n                           need_phone_number: typing.Union[base.Boolean, None] = None,\n                           need_email: typing.Union[base.Boolean, None] = None,\n                           need_shipping_address: typing.Union[base.Boolean, None] = None,\n                           is_flexible: typing.Union[base.Boolean, None] = None,\n                           disable_notification: typing.Union[base.Boolean, None] = None,\n                           reply_to_message_id: typing.Union[base.Integer, None] = None,\n                           reply_markup: typing.Union[types.InlineKeyboardMarkup, None] = None) -> types.Message:\n        \"\"\"\n        Use this method to send invoices.\n\n        Source: https://core.telegram.org/bots/api#sendinvoice\n\n        :param chat_id: Unique identifier for the target private chat\n        :type chat_id: :obj:`base.Integer`\n        :param title: Product name, 1-32 characters\n        :type title: :obj:`base.String`\n        :param description: Product description, 1-255 characters\n        :type description: :obj:`base.String`\n        :param payload: Bot-defined invoice payload, 1-128 bytes\n            This will not be displayed to the user, use for your internal processes.\n        :type payload: :obj:`base.String`\n        :param provider_token: Payments provider token, obtained via Botfather\n        :type provider_token: :obj:`base.String`\n        :param start_parameter: Unique deep-linking parameter that can be used to generate this\n            invoice when used as a start parameter\n        :type start_parameter: :obj:`base.String`\n        :param currency: Three-letter ISO 4217 currency code, see more on currencies\n        :type currency: :obj:`base.String`\n        :param prices: Price breakdown, a list of components\n            (e.g. product price, tax, discount, delivery cost, delivery tax, bonus, etc.)\n        :type prices: :obj:`typing.List[types.LabeledPrice]`\n        :param provider_data: JSON-encoded data about the invoice, which will be shared with the payment provider\n        :type provider_data: :obj:`typing.Union[typing.Dict, None]`\n        :param photo_url: URL of the product photo for the invoice\n        :type photo_url: :obj:`typing.Union[base.String, None]`\n        :param photo_size: Photo size\n        :type photo_size: :obj:`typing.Union[base.Integer, None]`\n        :param photo_width: Photo width\n        :type photo_width: :obj:`typing.Union[base.Integer, None]`\n        :param photo_height: Photo height\n        :type photo_height: :obj:`typing.Union[base.Integer, None]`\n        :param need_name: Pass True, if you require the user's full name to complete the order\n        :type need_name: :obj:`typing.Union[base.Boolean, None]`\n        :param need_phone_number: Pass True, if you require the user's phone number to complete the order\n        :type need_phone_number: :obj:`typing.Union[base.Boolean, None]`\n        :param need_email: Pass True, if you require the user's email to complete the order\n        :type need_email: :obj:`typing.Union[base.Boolean, None]`\n        :param need_shipping_address: Pass True, if you require the user's shipping address to complete the order\n        :type need_shipping_address: :obj:`typing.Union[base.Boolean, None]`\n        :param is_flexible: Pass True, if the final price depends on the shipping method\n        :type is_flexible: :obj:`typing.Union[base.Boolean, None]`\n        :param disable_notification: Sends the message silently. Users will receive a notification with no sound\n        :type disable_notification: :obj:`typing.Union[base.Boolean, None]`\n        :param reply_to_message_id: If the message is a reply, ID of the original message\n        :type reply_to_message_id: :obj:`typing.Union[base.Integer, None]`\n        :param reply_markup: A JSON-serialized object for an inline keyboard\n            If empty, one 'Pay total price' button will be shown. If not empty, the first button must be a Pay button.\n        :type reply_markup: :obj:`typing.Union[types.InlineKeyboardMarkup, None]`\n        :return: On success, the sent Message is returned\n        :rtype: :obj:`types.Message`\n        \"\"\"\n        prices = prepare_arg([price.to_python() if hasattr(price, 'to_python') else price for price in prices])\n        reply_markup = prepare_arg(reply_markup)\n        payload_ = generate_payload(**locals())\n\n        result = await self.request(api.Methods.SEND_INVOICE, payload_)\n        return types.Message(**result)", "response": "Use this method to send invoice. You must be an administrator in the chat for this to work and must have the appropriate admin rights."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsends an Answer Shipping Query to the Telegram API.", "response": "async def answer_shipping_query(self, shipping_query_id: base.String, ok: base.Boolean,\n                                    shipping_options: typing.Union[typing.List[types.ShippingOption], None] = None,\n                                    error_message: typing.Union[base.String, None] = None) -> base.Boolean:\n        \"\"\"\n        If you sent an invoice requesting a shipping address and the parameter is_flexible was specified,\n        the Bot API will send an Update with a shipping_query field to the bot.\n\n        Source: https://core.telegram.org/bots/api#answershippingquery\n\n        :param shipping_query_id: Unique identifier for the query to be answered\n        :type shipping_query_id: :obj:`base.String`\n        :param ok: Specify True if delivery to the specified address is possible and False if there are any problems\n            (for example, if delivery to the specified address is not possible)\n        :type ok: :obj:`base.Boolean`\n        :param shipping_options: Required if ok is True. A JSON-serialized array of available shipping options\n        :type shipping_options: :obj:`typing.Union[typing.List[types.ShippingOption], None]`\n        :param error_message: Required if ok is False\n            Error message in human readable form that explains why it is impossible to complete the order\n            (e.g. \"Sorry, delivery to your desired address is unavailable').\n            Telegram will display this message to the user.\n        :type error_message: :obj:`typing.Union[base.String, None]`\n        :return: On success, True is returned\n        :rtype: :obj:`base.Boolean`\n        \"\"\"\n        if shipping_options:\n            shipping_options = prepare_arg([shipping_option.to_python()\n                                            if hasattr(shipping_option, 'to_python')\n                                            else shipping_option\n                                            for shipping_option in shipping_options])\n        payload = generate_payload(**locals())\n\n        result = await self.request(api.Methods.ANSWER_SHIPPING_QUERY, payload)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def answer_pre_checkout_query(self, pre_checkout_query_id: base.String, ok: base.Boolean,\n                                        error_message: typing.Union[base.String, None] = None) -> base.Boolean:\n        \"\"\"\n        Once the user has confirmed their payment and shipping details,\n        the Bot API sends the final confirmation in the form of an Update with the field pre_checkout_query.\n        Use this method to respond to such pre-checkout queries.\n\n        Source: https://core.telegram.org/bots/api#answerprecheckoutquery\n\n        :param pre_checkout_query_id: Unique identifier for the query to be answered\n        :type pre_checkout_query_id: :obj:`base.String`\n        :param ok: Specify True if everything is alright (goods are available, etc.) and the\n            bot is ready to proceed with the order. Use False if there are any problems.\n        :type ok: :obj:`base.Boolean`\n        :param error_message: Required if ok is False\n            Error message in human readable form that explains the reason for failure to proceed with the checkout\n            (e.g. \"Sorry, somebody just bought the last of our amazing black T-shirts while you were busy filling\n            out your payment details. Please choose a different color or garment!\").\n            Telegram will display this message to the user.\n        :type error_message: :obj:`typing.Union[base.String, None]`\n        :return: On success, True is returned\n        :rtype: :obj:`base.Boolean`\n        \"\"\"\n        payload = generate_payload(**locals())\n\n        result = await self.request(api.Methods.ANSWER_PRE_CHECKOUT_QUERY, payload)\n        return result", "response": "This method is used to answer a pre - checkout query."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the errors of a user s Passport.", "response": "async def set_passport_data_errors(self,\n                                       user_id: base.Integer,\n                                       errors: typing.List[types.PassportElementError]) -> base.Boolean:\n        \"\"\"\n        Informs a user that some of the Telegram Passport elements they provided contains errors.\n        The user will not be able to re-submit their Passport to you until the errors are fixed\n        (the contents of the field for which you returned the error must change).\n        Returns True on success.\n\n        Use this if the data submitted by the user doesn't satisfy the standards your service\n        requires for any reason. For example, if a birthday date seems invalid, a submitted document\n        is blurry, a scan shows evidence of tampering, etc. Supply some details in the error message\n        to make sure the user knows how to correct the issues.\n\n        Source https://core.telegram.org/bots/api#setpassportdataerrors\n\n        :param user_id: User identifier\n        :type user_id: :obj:`base.Integer`\n        :param errors: A JSON-serialized array describing the errors\n        :type errors: :obj:`typing.List[types.PassportElementError]`\n        :return: Returns True on success\n        :rtype: :obj:`base.Boolean`\n        \"\"\"\n        errors = prepare_arg(errors)\n        payload = generate_payload(**locals())\n\n        result = await self.request(api.Methods.SET_PASSPORT_DATA_ERRORS, payload)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nusing this method to send a game.", "response": "async def send_game(self, chat_id: base.Integer, game_short_name: base.String,\n                        disable_notification: typing.Union[base.Boolean, None] = None,\n                        reply_to_message_id: typing.Union[base.Integer, None] = None,\n                        reply_markup: typing.Union[types.InlineKeyboardMarkup, None] = None) -> types.Message:\n        \"\"\"\n        Use this method to send a game.\n\n        Source: https://core.telegram.org/bots/api#sendgame\n\n        :param chat_id: Unique identifier for the target chat\n        :type chat_id: :obj:`base.Integer`\n        :param game_short_name: Short name of the game, serves as the unique identifier for the game. \\\n            Set up your games via Botfather.\n        :type game_short_name: :obj:`base.String`\n        :param disable_notification: Sends the message silently. Users will receive a notification with no sound\n        :type disable_notification: :obj:`typing.Union[base.Boolean, None]`\n        :param reply_to_message_id: If the message is a reply, ID of the original message\n        :type reply_to_message_id: :obj:`typing.Union[base.Integer, None]`\n        :param reply_markup: A JSON-serialized object for an inline keyboard\n            If empty, one \u2018Play game_title\u2019 button will be shown. If not empty, the first button must launch the game.\n        :type reply_markup: :obj:`typing.Union[types.InlineKeyboardMarkup, None]`\n        :return: On success, the sent Message is returned\n        :rtype: :obj:`types.Message`\n        \"\"\"\n        reply_markup = prepare_arg(reply_markup)\n        payload = generate_payload(**locals())\n\n        result = await self.request(api.Methods.SEND_GAME, payload)\n        return types.Message(**result)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def set_game_score(self, user_id: base.Integer, score: base.Integer,\n                             force: typing.Union[base.Boolean, None] = None,\n                             disable_edit_message: typing.Union[base.Boolean, None] = None,\n                             chat_id: typing.Union[base.Integer, None] = None,\n                             message_id: typing.Union[base.Integer, None] = None,\n                             inline_message_id: typing.Union[base.String,\n                                                             None] = None) -> types.Message or base.Boolean:\n        \"\"\"\n        Use this method to set the score of the specified user in a game.\n\n        Source: https://core.telegram.org/bots/api#setgamescore\n\n        :param user_id: User identifier\n        :type user_id: :obj:`base.Integer`\n        :param score: New score, must be non-negative\n        :type score: :obj:`base.Integer`\n        :param force: Pass True, if the high score is allowed to decrease\n            This can be useful when fixing mistakes or banning cheaters\n        :type force: :obj:`typing.Union[base.Boolean, None]`\n        :param disable_edit_message: Pass True, if the game message should not be automatically\n            edited to include the current scoreboard\n        :type disable_edit_message: :obj:`typing.Union[base.Boolean, None]`\n        :param chat_id: Required if inline_message_id is not specified. Unique identifier for the target chat\n        :type chat_id: :obj:`typing.Union[base.Integer, None]`\n        :param message_id: Required if inline_message_id is not specified. Identifier of the sent message\n        :type message_id: :obj:`typing.Union[base.Integer, None]`\n        :param inline_message_id: Required if chat_id and message_id are not specified. Identifier of the inline message\n        :type inline_message_id: :obj:`typing.Union[base.String, None]`\n        :return: On success, if the message was sent by the bot, returns the edited Message, otherwise returns True\n            Returns an error, if the new score is not greater than the user's\n            current score in the chat and force is False.\n        :rtype: :obj:`typing.Union[types.Message, base.Boolean]`\n        \"\"\"\n        payload = generate_payload(**locals())\n\n        result = await self.request(api.Methods.SET_GAME_SCORE, payload)\n        if isinstance(result, bool):\n            return result\n        return types.Message(**result)", "response": "Use this method to set the score of a user in a game."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def get_game_high_scores(self, user_id: base.Integer,\n                                   chat_id: typing.Union[base.Integer, None] = None,\n                                   message_id: typing.Union[base.Integer, None] = None,\n                                   inline_message_id: typing.Union[base.String,\n                                                                   None] = None) -> typing.List[types.GameHighScore]:\n        \"\"\"\n        Use this method to get data for high score tables.\n\n        This method will currently return scores for the target user, plus two of his closest neighbors on each side.\n        Will also return the top three users if the user and his neighbors are not among them.\n        Please note that this behavior is subject to change.\n\n        Source: https://core.telegram.org/bots/api#getgamehighscores\n\n        :param user_id: Target user id\n        :type user_id: :obj:`base.Integer`\n        :param chat_id: Required if inline_message_id is not specified. Unique identifier for the target chat\n        :type chat_id: :obj:`typing.Union[base.Integer, None]`\n        :param message_id: Required if inline_message_id is not specified. Identifier of the sent message\n        :type message_id: :obj:`typing.Union[base.Integer, None]`\n        :param inline_message_id: Required if chat_id and message_id are not specified. Identifier of the inline message\n        :type inline_message_id: :obj:`typing.Union[base.String, None]`\n        :return: Will return the score of the specified user and several of his neighbors in a game\n            On success, returns an Array of GameHighScore objects.\n            This method will currently return scores for the target user,\n            plus two of his closest neighbors on each side. Will also return the top three users if the\n            user and his neighbors are not among them.\n        :rtype: :obj:`typing.List[types.GameHighScore]`\n        \"\"\"\n        payload = generate_payload(**locals())\n        result = await self.request(api.Methods.GET_GAME_HIGH_SCORES, payload)\n\n        return [types.GameHighScore(**gamehighscore) for gamehighscore in result]", "response": "Use this method to get the high scores for a user in a chat."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates keyboard with list of posts", "response": "def get_keyboard() -> types.InlineKeyboardMarkup:\n    \"\"\"\n    Generate keyboard with list of posts\n    \"\"\"\n    markup = types.InlineKeyboardMarkup()\n    for post_id, post in POSTS.items():\n        markup.add(\n            types.InlineKeyboardButton(\n                post['title'],\n                callback_data=posts_cb.new(id=post_id, action='view'))\n        )\n    return markup"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload all compiled locales from path", "response": "def find_locales(self) -> Dict[str, gettext.GNUTranslations]:\n        \"\"\"\n        Load all compiled locales from path\n\n        :return: dict with locales\n        \"\"\"\n        translations = {}\n\n        for name in os.listdir(self.path):\n            if not os.path.isdir(os.path.join(self.path, name)):\n                continue\n            mo_path = os.path.join(self.path, name, 'LC_MESSAGES', self.domain + '.mo')\n\n            if os.path.exists(mo_path):\n                with open(mo_path, 'rb') as fp:\n                    translations[name] = gettext.GNUTranslations(fp)\n            elif os.path.exists(mo_path[:-2] + 'po'):\n                raise RuntimeError(f\"Found locale '{name} but this language is not compiled!\")\n\n        return translations"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef gettext(self, singular, plural=None, n=1, locale=None) -> str:\n        if locale is None:\n            locale = self.ctx_locale.get()\n\n        if locale not in self.locales:\n            if n is 1:\n                return singular\n            else:\n                return plural\n\n        translator = self.locales[locale]\n\n        if plural is None:\n            return translator.gettext(singular)\n        else:\n            return translator.ngettext(singular, plural, n)", "response": "Get text from the context."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef lazy_gettext(self, singular, plural=None, n=1, locale=None) -> LazyProxy:\n        return LazyProxy(self.gettext, singular, plural, n, locale)", "response": "Lazy get text\n\n        :param singular:\n        :param plural:\n        :param n:\n        :param locale:\n        :return:"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def get_user_locale(self, action: str, args: Tuple[Any]) -> str:\n        user: types.User = types.User.get_current()\n        locale: Locale = user.locale\n\n        if locale:\n            *_, data = args\n            language = data['locale'] = locale.language\n            return language", "response": "User locale getter\n        You can override the method if you want to use different way of getting user language.\n\n        :param action: event name\n        :param args: event arguments\n        :return: locale name"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def trigger(self, action, args):\n        if 'update' not in action \\\n                and 'error' not in action \\\n                and action.startswith('pre_process'):\n            locale = await self.get_user_locale(action, args)\n            self.ctx_locale.set(locale)\n            return True", "response": "Event trigger\n\n        :param action: event name\n        :param args: event arguments\n        :return:"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nstarting bot in long - polling mode.", "response": "def start_polling(dispatcher, *, loop=None, skip_updates=False, reset_webhook=True,\n                  on_startup=None, on_shutdown=None, timeout=20, fast=True):\n    \"\"\"\n    Start bot in long-polling mode\n\n    :param dispatcher:\n    :param loop:\n    :param skip_updates:\n    :param reset_webhook:\n    :param on_startup:\n    :param on_shutdown:\n    :param timeout:\n    \"\"\"\n    executor = Executor(dispatcher, skip_updates=skip_updates, loop=loop)\n    _setup_callbacks(executor, on_startup, on_shutdown)\n\n    executor.start_polling(reset_webhook=reset_webhook, timeout=timeout, fast=fast)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_webhook(dispatcher: Dispatcher, webhook_path: str, *, loop: Optional[asyncio.AbstractEventLoop] = None,\n                skip_updates: bool = None, on_startup: Optional[Callable] = None,\n                on_shutdown: Optional[Callable] = None, check_ip: bool = False,\n                retry_after: Optional[Union[str, int]] = None, route_name: str = DEFAULT_ROUTE_NAME,\n                web_app: Optional[Application] = None):\n    \"\"\"\n    Set webhook for bot\n\n    :param dispatcher: Dispatcher\n    :param webhook_path: str\n    :param loop: Optional[asyncio.AbstractEventLoop] (default: None)\n    :param skip_updates: bool (default: None)\n    :param on_startup: Optional[Callable] (default: None)\n    :param on_shutdown: Optional[Callable] (default: None)\n    :param check_ip: bool (default: False)\n    :param retry_after: Optional[Union[str, int]] See https://tools.ietf.org/html/rfc7231#section-7.1.3 (default: None)\n    :param route_name: str (default: 'webhook_handler')\n    :param web_app: Optional[Application] (default: None)\n    :return:\n    \"\"\"\n    executor = Executor(dispatcher, skip_updates=skip_updates, check_ip=check_ip, retry_after=retry_after,\n                        loop=loop)\n    _setup_callbacks(executor, on_startup, on_shutdown)\n\n    executor.set_webhook(webhook_path, route_name=route_name, web_app=web_app)\n    return executor", "response": "Sets the webhook for bot\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef start_webhook(dispatcher, webhook_path, *, loop=None, skip_updates=None,\n                  on_startup=None, on_shutdown=None, check_ip=False, retry_after=None, route_name=DEFAULT_ROUTE_NAME,\n                  **kwargs):\n    \"\"\"\n    Start bot in webhook mode\n\n    :param dispatcher:\n    :param webhook_path:\n    :param loop:\n    :param skip_updates:\n    :param on_startup:\n    :param on_shutdown:\n    :param check_ip:\n    :param route_name:\n    :param kwargs:\n    :return:\n    \"\"\"\n    executor = set_webhook(dispatcher=dispatcher,\n                           webhook_path=webhook_path,\n                           loop=loop,\n                           skip_updates=skip_updates,\n                           on_startup=on_startup,\n                           on_shutdown=on_shutdown,\n                           check_ip=check_ip,\n                           retry_after=retry_after,\n                           route_name=route_name)\n    executor.run_app(**kwargs)", "response": "Start bot in webhook mode"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nexecuting Future. :param dispatcher: instance of Dispatcher :param future: future :param loop: instance of AbstractEventLoop :param skip_updates: :param on_startup: :param on_shutdown: :return:", "response": "def start(dispatcher, future, *, loop=None, skip_updates=None,\n          on_startup=None, on_shutdown=None):\n    \"\"\"\n    Execute Future.\n\n    :param dispatcher: instance of Dispatcher\n    :param future: future\n    :param loop: instance of AbstractEventLoop\n    :param skip_updates:\n    :param on_startup:\n    :param on_shutdown:\n    :return:\n    \"\"\"\n    executor = Executor(dispatcher, skip_updates=skip_updates, loop=loop)\n    _setup_callbacks(executor, on_startup, on_shutdown)\n\n    return executor.start(future)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef on_startup(self, callback: callable, polling=True, webhook=True):\n        self._check_frozen()\n        if not webhook and not polling:\n            warn('This action has no effect!', UserWarning)\n            return\n\n        if isinstance(callback, (list, tuple, set)):\n            for cb in callback:\n                self.on_startup(cb, polling, webhook)\n            return\n\n        if polling:\n            self._on_startup_polling.append(callback)\n        if webhook:\n            self._on_startup_webhook.append(callback)", "response": "Register a callback for the startup process"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef on_shutdown(self, callback: callable, polling=True, webhook=True):\n        self._check_frozen()\n        if not webhook and not polling:\n            warn('This action has no effect!', UserWarning)\n            return\n\n        if isinstance(callback, (list, tuple, set)):\n            for cb in callback:\n                self.on_shutdown(cb, polling, webhook)\n            return\n\n        if polling:\n            self._on_shutdown_polling.append(callback)\n        if webhook:\n            self._on_shutdown_webhook.append(callback)", "response": "Register a callback for the shutdown process"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets webhook for bot", "response": "def set_webhook(self, webhook_path: Optional[str] = None, request_handler: Any = WebhookRequestHandler,\n                    route_name: str = DEFAULT_ROUTE_NAME, web_app: Optional[Application] = None):\n        \"\"\"\n        Set webhook for bot\n\n        :param webhook_path: Optional[str] (default: None)\n        :param request_handler: Any (default: WebhookRequestHandler)\n        :param route_name: str Name of webhook handler route (default: 'webhook_handler')\n        :param web_app: Optional[Application] (default: None)\n        :return:\n        \"\"\"\n        self._prepare_webhook(webhook_path, request_handler, route_name, web_app)\n        self.loop.run_until_complete(self._startup_webhook())"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef start_webhook(self, webhook_path=None, request_handler=WebhookRequestHandler, route_name=DEFAULT_ROUTE_NAME,\n                      **kwargs):\n        \"\"\"\n        Start bot in webhook mode\n\n        :param webhook_path:\n        :param request_handler:\n        :param route_name: Name of webhook handler route\n        :param kwargs:\n        :return:\n        \"\"\"\n        self.set_webhook(webhook_path=webhook_path, request_handler=request_handler, route_name=route_name)\n        self.run_app(**kwargs)", "response": "Start bot in webhook mode"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nstarts polling for the current locale.", "response": "def start_polling(self, reset_webhook=None, timeout=20, fast=True):\n        \"\"\"\n        Start bot in long-polling mode\n\n        :param reset_webhook:\n        :param timeout:\n        \"\"\"\n        self._prepare_polling()\n        loop: asyncio.AbstractEventLoop = self.loop\n\n        try:\n            loop.run_until_complete(self._startup_polling())\n            loop.create_task(self.dispatcher.start_polling(reset_webhook=reset_webhook, timeout=timeout, fast=fast))\n            loop.run_forever()\n        except (KeyboardInterrupt, SystemExit):\n            # loop.stop()\n            pass\n        finally:\n            loop.run_until_complete(self._shutdown_polling())\n            log.warning(\"Goodbye!\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef start(self, future):\n        self._check_frozen()\n        self._freeze = True\n        loop: asyncio.AbstractEventLoop = self.loop\n\n        try:\n            loop.run_until_complete(self._startup_polling())\n            result = loop.run_until_complete(future)\n        except (KeyboardInterrupt, SystemExit):\n            result = None\n            loop.stop()\n        finally:\n            loop.run_until_complete(self._shutdown_polling())\n            log.warning(\"Goodbye!\")\n        return result", "response": "Execute the given Future.\n        Execute the Future.\n        Return the result or raise its exception."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add(self, *args):\n        row = []\n        for index, button in enumerate(args, start=1):\n            row.append(button)\n            if index % self.row_width == 0:\n                self.inline_keyboard.append(row)\n                row = []\n        if len(row) > 0:\n            self.inline_keyboard.append(row)\n        return self", "response": "Adds buttons to the inline keyboard markup."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef row(self, *args):\n        btn_array = []\n        for button in args:\n            btn_array.append(button)\n        self.inline_keyboard.append(btn_array)\n        return self", "response": "Adds a row to the inline keyboard markup."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninsert button to last row of inline keyboard.", "response": "def insert(self, button):\n        \"\"\"\n        Insert button to last row\n\n        :param button:\n        :return: self\n        :rtype: :obj:`types.InlineKeyboardMarkup`\n        \"\"\"\n        if self.inline_keyboard and len(self.inline_keyboard[-1]) < self.row_width:\n            self.inline_keyboard[-1].append(button)\n        else:\n            self.add(button)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads version of the node.", "response": "def get_version():\n    \"\"\"\n    Read version\n\n    :return: str\n    \"\"\"\n    txt = (WORK_DIR / 'aiogram' / '__init__.py').read_text('utf-8')\n    try:\n        return re.findall(r\"^__version__ = '([^']+)'\\r?$\", txt, re.M)[0]\n    except IndexError:\n        raise RuntimeError('Unable to determine version.')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_requirements(filename=None):\n    if filename is None:\n        filename = 'requirements.txt'\n\n    file = WORK_DIR / filename\n\n    install_reqs = parse_requirements(str(file), session='hack')\n    return [str(ir.req) for ir in install_reqs]", "response": "Read requirements from requirements. txt"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef request_timeout(self, timeout):\n        timeout = self._prepare_timeout(timeout)\n        token = self._ctx_timeout.set(timeout)\n        try:\n            yield\n        finally:\n            self._ctx_timeout.reset(token)", "response": "Context manager implements opportunity to change request timeout in current context."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def request(self, method: base.String,\n                      data: Optional[Dict] = None,\n                      files: Optional[Dict] = None, **kwargs) -> Union[List, Dict, base.Boolean]:\n        \"\"\"\n        Make an request to Telegram Bot API\n\n        https://core.telegram.org/bots/api#making-requests\n\n        :param method: API method\n        :type method: :obj:`str`\n        :param data: request parameters\n        :type data: :obj:`dict`\n        :param files: files\n        :type files: :obj:`dict`\n        :return: result\n        :rtype: Union[List, Dict]\n        :raise: :obj:`aiogram.exceptions.TelegramApiError`\n        \"\"\"\n        return await api.make_request(self.session, self.__token, method, data, files,\n                                      proxy=self.proxy, proxy_auth=self.proxy_auth, timeout=self.timeout, **kwargs)", "response": "Make a request to Telegram Bot API."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def download_file(self, file_path: base.String,\n                            destination: Optional[base.InputFile] = None,\n                            timeout: Optional[base.Integer] = sentinel,\n                            chunk_size: Optional[base.Integer] = 65536,\n                            seek: Optional[base.Boolean] = True) -> Union[io.BytesIO, io.FileIO]:\n        \"\"\"\n        Download file by file_path to destination\n\n        if You want to automatically create destination (:class:`io.BytesIO`) use default\n        value of destination and handle result of this method.\n\n        :param file_path: file path on telegram server (You can get it from :obj:`aiogram.types.File`)\n        :type file_path: :obj:`str`\n        :param destination: filename or instance of :class:`io.IOBase`. For e. g. :class:`io.BytesIO`\n        :param timeout: Integer\n        :param chunk_size: Integer\n        :param seek: Boolean - go to start of file when downloading is finished.\n        :return: destination\n        \"\"\"\n        if destination is None:\n            destination = io.BytesIO()\n\n        url = api.Methods.file_url(token=self.__token, path=file_path)\n\n        dest = destination if isinstance(destination, io.IOBase) else open(destination, 'wb')\n        async with self.session.get(url, timeout=timeout, proxy=self.proxy, proxy_auth=self.proxy_auth) as response:\n            while True:\n                chunk = await response.content.read(chunk_size)\n                if not chunk:\n                    break\n                dest.write(chunk)\n                dest.flush()\n        if seek:\n            dest.seek(0)\n        return dest", "response": "Download file by file_path to destination."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsends file to the API.", "response": "async def send_file(self, file_type, method, file, payload) -> Union[Dict, base.Boolean]:\n        \"\"\"\n        Send file\n\n        https://core.telegram.org/bots/api#inputfile\n\n        :param file_type: field name\n        :param method: API method\n        :param file: String or io.IOBase\n        :param payload: request payload\n        :return: response\n        \"\"\"\n        if file is None:\n            files = {}\n        elif isinstance(file, str):\n            # You can use file ID or URL in the most of requests\n            payload[file_type] = file\n            files = None\n        else:\n            files = {file_type: file}\n\n        return await self.request(method, payload, files)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the value for the current object instance.", "response": "def get_value(self, instance):\n        \"\"\"\n        Get value for the current object instance\n\n        :param instance:\n        :return:\n        \"\"\"\n        return instance.values.get(self.alias, self.default)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_value(self, instance, value, parent=None):\n        self.resolve_base(instance)\n        value = self.deserialize(value, parent)\n        instance.values[self.alias] = value\n        self._trigger_changed(instance, value)", "response": "Set the value of the key in the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef values(self):\n        if not hasattr(self, VALUES_ATTR_NAME):\n            setattr(self, VALUES_ATTR_NAME, {})\n        return getattr(self, VALUES_ATTR_NAME)", "response": "Get the values of the values attribute."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets object as JSON serializable", "response": "def to_python(self) -> typing.Dict:\n        \"\"\"\n        Get object as JSON serializable\n\n        :return:\n        \"\"\"\n        self.clean()\n        result = {}\n        for name, value in self.values.items():\n            if name in self.props:\n                value = self.props[name].export(self)\n            if isinstance(value, TelegramObject):\n                value = value.to_python()\n            if isinstance(value, LazyProxy):\n                value = str(value)\n            result[self.props_aliases.get(name, name)] = value\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef clean(self):\n        for key, value in self.values.copy().items():\n            if value is None:\n                del self.values[key]", "response": "Remove empty values from the dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the mention of the Chat.", "response": "def mention(self):\n        \"\"\"\n        Get mention if a Chat has a username, or get full name if this is a Private Chat, otherwise None is returned\n        \"\"\"\n        if self.username:\n            return '@' + self.username\n        if self.type == ChatType.PRIVATE:\n            return self.full_name\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def get_url(self):\n        if self.type == ChatType.PRIVATE:\n            return f\"tg://user?id={self.id}\"\n\n        if self.username:\n            return f'https://t.me/{self.username}'\n\n        if self.invite_link:\n            return self.invite_link\n\n        await self.update_chat()\n        return self.invite_link", "response": "Get url of user or invite link."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def update_chat(self):\n        other = await self.bot.get_chat(self.id)\n\n        for key, value in other:\n            self[key] = value", "response": "User this method to update Chat data"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def kick(self, user_id: base.Integer,\n                   until_date: typing.Union[base.Integer, None] = None):\n        \"\"\"\n        Use this method to kick a user from a group, a supergroup or a channel.\n        In the case of supergroups and channels, the user will not be able to return to the group\n        on their own using invite links, etc., unless unbanned first.\n\n        The bot must be an administrator in the chat for this to work and must have the appropriate admin rights.\n\n        Note: In regular groups (non-supergroups), this method will only work if the \u2018All Members Are Admins\u2019 setting\n        is off in the target group.\n        Otherwise members may only be removed by the group's creator or by the member that added them.\n\n        Source: https://core.telegram.org/bots/api#kickchatmember\n\n        :param user_id: Unique identifier of the target user\n        :type user_id: :obj:`base.Integer`\n        :param until_date: Date when the user will be unbanned, unix time.\n        :type until_date: :obj:`typing.Union[base.Integer, None]`\n        :return: Returns True on success.\n        :rtype: :obj:`base.Boolean`\n        \"\"\"\n        return await self.bot.kick_chat_member(self.id, user_id=user_id, until_date=until_date)", "response": "Kick a user from a group supergroup or channel."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def unban(self, user_id: base.Integer):\n        return await self.bot.unban_chat_member(self.id, user_id=user_id)", "response": "Unban a previously kicked user in a group or channel."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def restrict(self, user_id: base.Integer,\n                       until_date: typing.Union[base.Integer, None] = None,\n                       can_send_messages: typing.Union[base.Boolean, None] = None,\n                       can_send_media_messages: typing.Union[base.Boolean, None] = None,\n                       can_send_other_messages: typing.Union[base.Boolean, None] = None,\n                       can_add_web_page_previews: typing.Union[base.Boolean, None] = None) -> base.Boolean:\n        \"\"\"\n        Use this method to restrict a user in a supergroup.\n        The bot must be an administrator in the supergroup for this to work and must have the appropriate admin rights.\n        Pass True for all boolean parameters to lift restrictions from a user.\n\n        Source: https://core.telegram.org/bots/api#restrictchatmember\n\n        :param user_id: Unique identifier of the target user\n        :type user_id: :obj:`base.Integer`\n        :param until_date: Date when restrictions will be lifted for the user, unix time.\n        :type until_date: :obj:`typing.Union[base.Integer, None]`\n        :param can_send_messages: Pass True, if the user can send text messages, contacts, locations and venues\n        :type can_send_messages: :obj:`typing.Union[base.Boolean, None]`\n        :param can_send_media_messages: Pass True, if the user can send audios, documents, photos, videos,\n            video notes and voice notes, implies can_send_messages\n        :type can_send_media_messages: :obj:`typing.Union[base.Boolean, None]`\n        :param can_send_other_messages: Pass True, if the user can send animations, games, stickers and\n            use inline bots, implies can_send_media_messages\n        :type can_send_other_messages: :obj:`typing.Union[base.Boolean, None]`\n        :param can_add_web_page_previews: Pass True, if the user may add web page previews to their messages,\n            implies can_send_media_messages\n        :type can_add_web_page_previews: :obj:`typing.Union[base.Boolean, None]`\n        :return: Returns True on success.\n        :rtype: :obj:`base.Boolean`\n        \"\"\"\n        return await self.bot.restrict_chat_member(self.id, user_id=user_id, until_date=until_date,\n                                                   can_send_messages=can_send_messages,\n                                                   can_send_media_messages=can_send_media_messages,\n                                                   can_send_other_messages=can_send_other_messages,\n                                                   can_add_web_page_previews=can_add_web_page_previews)", "response": "Restrict a user s permissions to a supergroup."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\npromotes a user to a supergroup or channel.", "response": "async def promote(self, user_id: base.Integer,\n                      can_change_info: typing.Union[base.Boolean, None] = None,\n                      can_post_messages: typing.Union[base.Boolean, None] = None,\n                      can_edit_messages: typing.Union[base.Boolean, None] = None,\n                      can_delete_messages: typing.Union[base.Boolean, None] = None,\n                      can_invite_users: typing.Union[base.Boolean, None] = None,\n                      can_restrict_members: typing.Union[base.Boolean, None] = None,\n                      can_pin_messages: typing.Union[base.Boolean, None] = None,\n                      can_promote_members: typing.Union[base.Boolean, None] = None) -> base.Boolean:\n        \"\"\"\n        Use this method to promote or demote a user in a supergroup or a channel.\n        The bot must be an administrator in the chat for this to work and must have the appropriate admin rights.\n        Pass False for all boolean parameters to demote a user.\n\n        Source: https://core.telegram.org/bots/api#promotechatmember\n\n        :param user_id: Unique identifier of the target user\n        :type user_id: :obj:`base.Integer`\n        :param can_change_info: Pass True, if the administrator can change chat title, photo and other settings\n        :type can_change_info: :obj:`typing.Union[base.Boolean, None]`\n        :param can_post_messages: Pass True, if the administrator can create channel posts, channels only\n        :type can_post_messages: :obj:`typing.Union[base.Boolean, None]`\n        :param can_edit_messages: Pass True, if the administrator can edit messages of other users, channels only\n        :type can_edit_messages: :obj:`typing.Union[base.Boolean, None]`\n        :param can_delete_messages: Pass True, if the administrator can delete messages of other users\n        :type can_delete_messages: :obj:`typing.Union[base.Boolean, None]`\n        :param can_invite_users: Pass True, if the administrator can invite new users to the chat\n        :type can_invite_users: :obj:`typing.Union[base.Boolean, None]`\n        :param can_restrict_members: Pass True, if the administrator can restrict, ban or unban chat members\n        :type can_restrict_members: :obj:`typing.Union[base.Boolean, None]`\n        :param can_pin_messages: Pass True, if the administrator can pin messages, supergroups only\n        :type can_pin_messages: :obj:`typing.Union[base.Boolean, None]`\n        :param can_promote_members: Pass True, if the administrator can add new administrators\n            with a subset of his own privileges or demote administrators that he has promoted,\n            directly or indirectly (promoted by administrators that were appointed by him)\n        :type can_promote_members: :obj:`typing.Union[base.Boolean, None]`\n        :return: Returns True on success.\n        :rtype: :obj:`base.Boolean`\n        \"\"\"\n        return await self.bot.promote_chat_member(self.id,\n                                                  user_id=user_id,\n                                                  can_change_info=can_change_info,\n                                                  can_post_messages=can_post_messages,\n                                                  can_edit_messages=can_edit_messages,\n                                                  can_delete_messages=can_delete_messages,\n                                                  can_invite_users=can_invite_users,\n                                                  can_restrict_members=can_restrict_members,\n                                                  can_pin_messages=can_pin_messages,\n                                                  can_promote_members=can_promote_members)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\npinning a message in a supergroup.", "response": "async def pin_message(self, message_id: int, disable_notification: bool = False):\n        \"\"\"\n        Use this method to pin a message in a supergroup.\n        The bot must be an administrator in the chat for this to work and must have the appropriate admin rights.\n\n        Source: https://core.telegram.org/bots/api#pinchatmessage\n\n        :param message_id: Identifier of a message to pin\n        :type message_id: :obj:`base.Integer`\n        :param disable_notification: Pass True, if it is not necessary to send a notification to\n            all group members about the new pinned message\n        :type disable_notification: :obj:`typing.Union[base.Boolean, None]`\n        :return: Returns True on success.\n        :rtype: :obj:`base.Boolean`\n        \"\"\"\n        return await self.bot.pin_chat_message(self.id, message_id, disable_notification)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def export_invite_link(self):\n        if not self.invite_link:\n            self.invite_link = await self.bot.export_chat_invite_link(self.id)\n\n        return self.invite_link", "response": "Export the invite link for this chat."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks chat is group or super - group", "response": "def is_group_or_super_group(cls, obj) -> bool:\n        \"\"\"\n        Check chat is group or super-group\n\n        :param obj:\n        :return:\n        \"\"\"\n        return cls._check(obj, [cls.GROUP, cls.SUPER_GROUP])"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndoes typing :param sleep: sleep timeout :return:", "response": "async def typing(cls, sleep=None):\n        \"\"\"\n        Do typing\n\n        :param sleep: sleep timeout\n        :return:\n        \"\"\"\n        if isinstance(sleep, str):\n            sleep = cls.calc_timeout(sleep)\n        await cls._do(cls.TYPING, sleep)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting value of entity AttributeNames", "response": "def get_text(self, text):\n        \"\"\"\n        Get value of entity\n\n        :param text: full text\n        :return: part of text\n        \"\"\"\n        if sys.maxunicode == 0xffff:\n            return text[self.offset:self.offset + self.length]\n\n        if not isinstance(text, bytes):\n            entity_text = text.encode('utf-16-le')\n        else:\n            entity_text = text\n\n        entity_text = entity_text[self.offset * 2:(self.offset + self.length) * 2]\n        return entity_text.decode('utf-16-le')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing the text with markup and returns the entity value with markup.", "response": "def parse(self, text, as_html=True):\n        \"\"\"\n        Get entity value with markup\n\n        :param text: original text\n        :param as_html: as html?\n        :return: entity text with markup\n        \"\"\"\n        if not text:\n            return text\n        entity_text = self.get_text(text)\n\n        if self.type == MessageEntityType.BOLD:\n            if as_html:\n                return markdown.hbold(entity_text)\n            return markdown.bold(entity_text)\n        elif self.type == MessageEntityType.ITALIC:\n            if as_html:\n                return markdown.hitalic(entity_text)\n            return markdown.italic(entity_text)\n        elif self.type == MessageEntityType.PRE:\n            if as_html:\n                return markdown.hpre(entity_text)\n            return markdown.pre(entity_text)\n        elif self.type == MessageEntityType.CODE:\n            if as_html:\n                return markdown.hcode(entity_text)\n            return markdown.code(entity_text)\n        elif self.type == MessageEntityType.URL:\n            if as_html:\n                return markdown.hlink(entity_text, entity_text)\n            return markdown.link(entity_text, entity_text)\n        elif self.type == MessageEntityType.TEXT_LINK:\n            if as_html:\n                return markdown.hlink(entity_text, self.url)\n            return markdown.link(entity_text, self.url)\n        elif self.type == MessageEntityType.TEXT_MENTION and self.user:\n            return self.user.get_mention(entity_text)\n        return entity_text"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate payload for a node in the nova tree.", "response": "def generate_payload(exclude=None, **kwargs):\n    \"\"\"\n    Generate payload\n\n    Usage: payload = generate_payload(**locals(), exclude=['foo'])\n\n    :param exclude:\n    :param kwargs:\n    :return: dict\n    \"\"\"\n    if exclude is None:\n        exclude = []\n    return {key: value for key, value in kwargs.items() if\n            key not in exclude + DEFAULT_FILTER\n            and value is not None\n            and not key.startswith('_')}"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _normalize(obj):\n    if isinstance(obj, list):\n        return [_normalize(item) for item in obj]\n    elif isinstance(obj, dict):\n        return {k: _normalize(v) for k, v in obj.items() if v is not None}\n    elif hasattr(obj, 'to_python'):\n        return obj.to_python()\n    return obj", "response": "Normalize dicts and lists of navigable objects and return a normalized object"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef prepare_arg(value):\n    if value is None:\n        return value\n    elif isinstance(value, (list, dict)) or hasattr(value, 'to_python'):\n        return json.dumps(_normalize(value))\n    elif isinstance(value, datetime.timedelta):\n        now = datetime.datetime.now()\n        return int((now + value).timestamp())\n    elif isinstance(value, datetime.datetime):\n        return round(value.timestamp())\n    elif isinstance(value, LazyProxy):\n        return str(value)\n    return value", "response": "Prepare the argument for the\n    function."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef all(cls):\n        result = []\n        for name in dir(cls):\n            if not name.isupper():\n                continue\n            value = getattr(cls, name)\n            if isinstance(value, ItemsList):\n                result.append(value[0])\n            else:\n                result.append(value)\n        return result", "response": "Get all consts\n        :return: list"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _screaming_snake_case(cls, text):\n        if text.isupper():\n            return text\n        result = ''\n        for pos, symbol in enumerate(text):\n            if symbol.isupper() and pos > 0:\n                result += '_' + symbol\n            else:\n                result += symbol.upper()\n        return result", "response": "Transform text to SCREAMING_SNAKE_CASE"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _snake_case(cls, text):\n        if text.islower():\n            return text\n        return cls._screaming_snake_case(text).lower()", "response": "Transform text to snake case"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntransforms text to camelCase or CamelCase", "response": "def _camel_case(cls, text, first_upper=False):\n        \"\"\"\n        Transform text to camelCase or CamelCase\n\n        :param text:\n        :param first_upper: first symbol must be upper?\n        :return:\n        \"\"\"\n        result = ''\n        need_upper = False\n        for pos, symbol in enumerate(text):\n            if symbol == '_' and pos > 0:\n                need_upper = True\n            else:\n                if need_upper:\n                    result += symbol.upper()\n                else:\n                    result += symbol.lower()\n                need_upper = False\n        if first_upper:\n            result = result[0].upper() + result[1:]\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef apply(cls, text, mode):\n        if mode == cls.SCREAMING_SNAKE_CASE:\n            return cls._screaming_snake_case(text)\n        elif mode == cls.snake_case:\n            return cls._snake_case(text)\n        elif mode == cls.lowercase:\n            return cls._snake_case(text).replace('_', '')\n        elif mode == cls.lowerCamelCase:\n            return cls._camel_case(text)\n        elif mode == cls.CamelCase:\n            return cls._camel_case(text, True)\n        elif callable(mode):\n            return mode(text)\n        return text", "response": "Apply mode for text\n       "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef filter(self, record: logging.LogRecord):\n        update = types.Update.get_current(True)\n        if update:\n            for key, value in self.make_prefix(self.prefix, self.process_update(update)):\n                setattr(record, key, value)\n\n        return True", "response": "Filter a log record by data from Telegram Update object."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses an update object and yield the update s attributes.", "response": "def process_update(self, update: types.Update):\n        \"\"\"\n        Parse Update object\n\n        :param update:\n        :return:\n        \"\"\"\n        yield 'update_id', update.update_id\n\n        if update.message:\n            yield 'update_type', 'message'\n            yield from self.process_message(update.message)\n        if update.edited_message:\n            yield 'update_type', 'edited_message'\n            yield from self.process_message(update.edited_message)\n        if update.channel_post:\n            yield 'update_type', 'channel_post'\n            yield from self.process_message(update.channel_post)\n        if update.edited_channel_post:\n            yield 'update_type', 'edited_channel_post'\n            yield from self.process_message(update.edited_channel_post)\n        if update.inline_query:\n            yield 'update_type', 'inline_query'\n            yield from self.process_inline_query(update.inline_query)\n        if update.chosen_inline_result:\n            yield 'update_type', 'chosen_inline_result'\n            yield from self.process_chosen_inline_result(update.chosen_inline_result)\n        if update.callback_query:\n            yield 'update_type', 'callback_query'\n            yield from self.process_callback_query(update.callback_query)\n        if update.shipping_query:\n            yield 'update_type', 'shipping_query'\n            yield from self.process_shipping_query(update.shipping_query)\n        if update.pre_checkout_query:\n            yield 'update_type', 'pre_checkout_query'\n            yield from self.process_pre_checkout_query(update.pre_checkout_query)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef make_prefix(self, prefix, iterable):\n        if not prefix:\n            yield from iterable\n\n        for key, value in iterable:\n            yield f\"{prefix}_{key}\", value", "response": "Add prefix to the label\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef process_user(self, user: types.User):\n        if not user:\n            return\n\n        yield 'user_id', user.id\n        if self.include_content:\n            yield 'user_full_name', user.full_name\n            if user.username:\n                yield 'user_name', f\"@{user.username}\"", "response": "Generate user data\n\n        :param user:\n        :return:"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating chat data :param chat: :return:", "response": "def process_chat(self, chat: types.Chat):\n        \"\"\"\n        Generate chat data\n\n        :param chat:\n        :return:\n        \"\"\"\n        if not chat:\n            return\n\n        yield 'chat_id', chat.id\n        yield 'chat_type', chat.type\n        if self.include_content:\n            yield 'chat_title', chat.full_name\n            if chat.username:\n                yield 'chat_name', f\"@{chat.username}\""}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def process_updates(self, updates, fast: typing.Optional[bool] = True):\n        if fast:\n            tasks = []\n            for update in updates:\n                tasks.append(self.updates_handler.notify(update))\n            return await asyncio.gather(*tasks)\n\n        results = []\n        for update in updates:\n            results.append(await self.updates_handler.notify(update))\n        return results", "response": "Process list of updates."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def process_update(self, update: types.Update):\n        types.Update.set_current(update)\n\n        try:\n            if update.message:\n                types.User.set_current(update.message.from_user)\n                types.Chat.set_current(update.message.chat)\n                return await self.message_handlers.notify(update.message)\n            if update.edited_message:\n                types.User.set_current(update.edited_message.from_user)\n                types.Chat.set_current(update.edited_message.chat)\n                return await self.edited_message_handlers.notify(update.edited_message)\n            if update.channel_post:\n                types.Chat.set_current(update.channel_post.chat)\n                return await self.channel_post_handlers.notify(update.channel_post)\n            if update.edited_channel_post:\n                types.Chat.set_current(update.edited_channel_post.chat)\n                return await self.edited_channel_post_handlers.notify(update.edited_channel_post)\n            if update.inline_query:\n                types.User.set_current(update.inline_query.from_user)\n                return await self.inline_query_handlers.notify(update.inline_query)\n            if update.chosen_inline_result:\n                types.User.set_current(update.chosen_inline_result.from_user)\n                return await self.chosen_inline_result_handlers.notify(update.chosen_inline_result)\n            if update.callback_query:\n                if update.callback_query.message:\n                    types.Chat.set_current(update.callback_query.message.chat)\n                types.User.set_current(update.callback_query.from_user)\n                return await self.callback_query_handlers.notify(update.callback_query)\n            if update.shipping_query:\n                types.User.set_current(update.shipping_query.from_user)\n                return await self.shipping_query_handlers.notify(update.shipping_query)\n            if update.pre_checkout_query:\n                types.User.set_current(update.pre_checkout_query.from_user)\n                return await self.pre_checkout_query_handlers.notify(update.pre_checkout_query)\n            if update.poll:\n                return await self.poll_handlers.notify(update.poll)\n        except Exception as e:\n            err = await self.errors_handlers.notify(update, e)\n            if err:\n                return err\n            raise", "response": "Process single update object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nresetting webhook to the default URL.", "response": "async def reset_webhook(self, check=True) -> bool:\n        \"\"\"\n        Reset webhook\n\n        :param check: check before deleting\n        :return:\n        \"\"\"\n        if check:\n            wh = await self.bot.get_webhook_info()\n            if not wh.url:\n                return False\n\n        return await self.bot.delete_webhook()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def start_polling(self,\n                            timeout=20,\n                            relax=0.1,\n                            limit=None,\n                            reset_webhook=None,\n                            fast: typing.Optional[bool] = True,\n                            error_sleep: int = 5):\n        \"\"\"\n        Start long-polling\n\n        :param timeout:\n        :param relax:\n        :param limit:\n        :param reset_webhook:\n        :param fast:\n        :return:\n        \"\"\"\n        if self._polling:\n            raise RuntimeError('Polling already started')\n\n        log.info('Start polling.')\n\n        # context.set_value(MODE, LONG_POLLING)\n        Dispatcher.set_current(self)\n        Bot.set_current(self.bot)\n\n        if reset_webhook is None:\n            await self.reset_webhook(check=False)\n        if reset_webhook:\n            await self.reset_webhook(check=True)\n\n        self._polling = True\n        offset = None\n        try:\n            current_request_timeout = self.bot.timeout\n            if current_request_timeout is not sentinel and timeout is not None:\n                request_timeout = aiohttp.ClientTimeout(total=current_request_timeout.total + timeout or 1)\n            else:\n                request_timeout = None\n\n            while self._polling:\n                try:\n                    with self.bot.request_timeout(request_timeout):\n                        updates = await self.bot.get_updates(limit=limit, offset=offset, timeout=timeout)\n                except:\n                    log.exception('Cause exception while getting updates.')\n                    await asyncio.sleep(error_sleep)\n                    continue\n\n                if updates:\n                    log.debug(f\"Received {len(updates)} updates.\")\n                    offset = updates[-1].update_id + 1\n\n                    self.loop.create_task(self._process_polling_updates(updates, fast))\n\n                if relax:\n                    await asyncio.sleep(relax)\n\n        finally:\n            self._close_waiter._set_result(None)\n            log.warning('Polling is stopped.')", "response": "Start long - polling."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def _process_polling_updates(self, updates, fast: typing.Optional[bool] = True):\n        need_to_call = []\n        for responses in itertools.chain.from_iterable(await self.process_updates(updates, fast)):\n            for response in responses:\n                if not isinstance(response, BaseResponse):\n                    continue\n                need_to_call.append(response.execute_response(self.bot))\n        if need_to_call:\n            try:\n                asyncio.gather(*need_to_call)\n            except TelegramAPIError:\n                log.exception('Cause exception while processing updates.')", "response": "Process long - polling updates received from long - polling API."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef stop_polling(self):\n        if hasattr(self, '_polling') and self._polling:\n            log.info('Stop polling...')\n            self._polling = False", "response": "Stop long - polling process."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef register_message_handler(self, callback, *custom_filters, commands=None, regexp=None, content_types=None,\n                                 state=None, run_task=None, **kwargs):\n        \"\"\"\n        Register handler for message\n\n        .. code-block:: python3\n\n            # This handler works only if state is None (by default).\n            dp.register_message_handler(cmd_start, commands=['start', 'about'])\n            dp.register_message_handler(entry_point, commands=['setup'])\n\n            # This handler works only if current state is \"first_step\"\n            dp.register_message_handler(step_handler_1, state=\"first_step\")\n\n            # If you want to handle all states by one handler, use `state=\"*\"`.\n            dp.register_message_handler(cancel_handler, commands=['cancel'], state=\"*\")\n            dp.register_message_handler(cancel_handler, lambda msg: msg.text.lower() == 'cancel', state=\"*\")\n\n        :param callback:\n        :param commands: list of commands\n        :param regexp: REGEXP\n        :param content_types: List of content types.\n        :param custom_filters: list of custom filters\n        :param kwargs:\n        :param state:\n        :return: decorated function\n        \"\"\"\n        filters_set = self.filters_factory.resolve(self.message_handlers,\n                                                   *custom_filters,\n                                                   commands=commands,\n                                                   regexp=regexp,\n                                                   content_types=content_types,\n                                                   state=state,\n                                                   **kwargs)\n        self.message_handlers.register(self._wrap_async_task(callback, run_task), filters_set)", "response": "Register handler for message related to a specific locale."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef message_handler(self, *custom_filters, commands=None, regexp=None, content_types=None, state=None,\n                        run_task=None, **kwargs):\n        \"\"\"\n        Decorator for message handler\n\n        Examples:\n\n        Simple commands handler:\n\n        .. code-block:: python3\n\n            @dp.message_handler(commands=['start', 'welcome', 'about'])\n            async def cmd_handler(message: types.Message):\n\n        Filter messages by regular expression:\n\n        .. code-block:: python3\n\n            @dp.message_handler(rexexp='^[a-z]+-[0-9]+')\n            async def msg_handler(message: types.Message):\n\n        Filter messages by command regular expression:\n\n        .. code-block:: python3\n\n            @dp.message_handler(filters.RegexpCommandsFilter(regexp_commands=['item_([0-9]*)']))\n            async def send_welcome(message: types.Message):\n\n        Filter by content type:\n\n        .. code-block:: python3\n\n            @dp.message_handler(content_types=ContentType.PHOTO | ContentType.DOCUMENT)\n            async def audio_handler(message: types.Message):\n\n        Filter by custom function:\n\n        .. code-block:: python3\n\n            @dp.message_handler(lambda message: message.text and 'hello' in message.text.lower())\n            async def text_handler(message: types.Message):\n\n        Use multiple filters:\n\n        .. code-block:: python3\n\n            @dp.message_handler(commands=['command'], content_types=ContentType.TEXT)\n            async def text_handler(message: types.Message):\n\n        Register multiple filters set for one handler:\n\n        .. code-block:: python3\n\n            @dp.message_handler(commands=['command'])\n            @dp.message_handler(lambda message: demojize(message.text) == ':new_moon_with_face:')\n            async def text_handler(message: types.Message):\n\n        This handler will be called if the message starts with '/command' OR is some emoji\n\n        By default content_type is :class:`ContentType.TEXT`\n\n        :param commands: list of commands\n        :param regexp: REGEXP\n        :param content_types: List of content types.\n        :param custom_filters: list of custom filters\n        :param kwargs:\n        :param state:\n        :param run_task: run callback in task (no wait results)\n        :return: decorated function\n        \"\"\"\n\n        def decorator(callback):\n            self.register_message_handler(callback, *custom_filters,\n                                          commands=commands, regexp=regexp, content_types=content_types,\n                                          state=state, run_task=run_task, **kwargs)\n            return callback\n\n        return decorator", "response": "This is the main message handler for all the messages in the queue."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef edited_message_handler(self, *custom_filters, commands=None, regexp=None, content_types=None,\n                               state=None, run_task=None, **kwargs):\n        \"\"\"\n        Decorator for edited message handler\n\n        You can use combination of different handlers\n\n        .. code-block:: python3\n\n            @dp.message_handler()\n            @dp.edited_message_handler()\n            async def msg_handler(message: types.Message):\n\n        :param commands: list of commands\n        :param regexp: REGEXP\n        :param content_types: List of content types.\n        :param state:\n        :param custom_filters: list of custom filters\n        :param run_task: run callback in task (no wait results)\n        :param kwargs:\n        :return: decorated function\n        \"\"\"\n\n        def decorator(callback):\n            self.register_edited_message_handler(callback, *custom_filters, commands=commands, regexp=regexp,\n                                                 content_types=content_types, state=state, run_task=run_task, **kwargs)\n            return callback\n\n        return decorator", "response": "Decorator for edited message handler"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nregistering handler for channel post", "response": "def register_channel_post_handler(self, callback, *custom_filters, commands=None, regexp=None, content_types=None,\n                                      state=None, run_task=None, **kwargs):\n        \"\"\"\n        Register handler for channel post\n\n        :param callback:\n        :param commands: list of commands\n        :param regexp: REGEXP\n        :param content_types: List of content types.\n        :param state:\n        :param custom_filters: list of custom filters\n        :param run_task: run callback in task (no wait results)\n        :param kwargs:\n        :return: decorated function\n        \"\"\"\n        filters_set = self.filters_factory.resolve(self.channel_post_handlers,\n                                                   *custom_filters,\n                                                   commands=commands,\n                                                   regexp=regexp,\n                                                   content_types=content_types,\n                                                   state=state,\n                                                   **kwargs)\n        self.channel_post_handlers.register(self._wrap_async_task(callback, run_task), filters_set)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef channel_post_handler(self, *custom_filters, commands=None, regexp=None, content_types=None,\n                             state=None, run_task=None, **kwargs):\n        \"\"\"\n        Decorator for channel post handler\n\n        :param commands: list of commands\n        :param regexp: REGEXP\n        :param content_types: List of content types.\n        :param state:\n        :param custom_filters: list of custom filters\n        :param run_task: run callback in task (no wait results)\n        :param kwargs:\n        :return: decorated function\n        \"\"\"\n\n        def decorator(callback):\n            self.register_channel_post_handler(callback, *custom_filters, commands=commands, regexp=regexp,\n                                               content_types=content_types, state=state, run_task=run_task, **kwargs)\n            return callback\n\n        return decorator", "response": "Decorator for channel post handler"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef register_edited_channel_post_handler(self, callback, *custom_filters, commands=None, regexp=None,\n                                             content_types=None, state=None, run_task=None, **kwargs):\n        \"\"\"\n        Register handler for edited channel post\n\n        :param callback:\n        :param commands: list of commands\n        :param regexp: REGEXP\n        :param content_types: List of content types.\n        :param state:\n        :param custom_filters: list of custom filters\n        :param run_task: run callback in task (no wait results)\n        :param kwargs:\n        :return: decorated function\n        \"\"\"\n        filters_set = self.filters_factory.resolve(self.edited_message_handlers,\n                                                   *custom_filters,\n                                                   commands=commands,\n                                                   regexp=regexp,\n                                                   content_types=content_types,\n                                                   state=state,\n                                                   **kwargs)\n        self.edited_channel_post_handlers.register(self._wrap_async_task(callback, run_task), filters_set)", "response": "Register handler for edited channel post"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nregisters handler for inline query", "response": "def register_inline_handler(self, callback, *custom_filters, state=None, run_task=None, **kwargs):\n        \"\"\"\n        Register handler for inline query\n\n        Example:\n\n        .. code-block:: python3\n\n            dp.register_inline_handler(some_inline_handler, lambda inline_query: True)\n\n        :param callback:\n        :param custom_filters: list of custom filters\n        :param state:\n        :param run_task: run callback in task (no wait results)\n        :param kwargs:\n        :return: decorated function\n        \"\"\"\n        if custom_filters is None:\n            custom_filters = []\n        filters_set = self.filters_factory.resolve(self.inline_query_handlers,\n                                                   *custom_filters,\n                                                   state=state,\n                                                   **kwargs)\n        self.inline_query_handlers.register(self._wrap_async_task(callback, run_task), filters_set)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef inline_handler(self, *custom_filters, state=None, run_task=None, **kwargs):\n\n        def decorator(callback):\n            self.register_inline_handler(callback, *custom_filters, state=state, run_task=run_task, **kwargs)\n            return callback\n\n        return decorator", "response": "Decorator for inline query handler"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nregistering handler for chosen inline query", "response": "def register_chosen_inline_handler(self, callback, *custom_filters, state=None, run_task=None, **kwargs):\n        \"\"\"\n        Register handler for chosen inline query\n\n        Example:\n\n        .. code-block:: python3\n\n            dp.register_chosen_inline_handler(some_chosen_inline_handler, lambda chosen_inline_query: True)\n\n        :param callback:\n        :param state:\n        :param custom_filters:\n        :param run_task: run callback in task (no wait results)\n        :param kwargs:\n        :return:\n        \"\"\"\n        if custom_filters is None:\n            custom_filters = []\n        filters_set = self.filters_factory.resolve(self.chosen_inline_result_handlers,\n                                                   *custom_filters,\n                                                   state=state,\n                                                   **kwargs)\n        self.chosen_inline_result_handlers.register(self._wrap_async_task(callback, run_task), filters_set)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef chosen_inline_handler(self, *custom_filters, state=None, run_task=None, **kwargs):\n\n        def decorator(callback):\n            self.register_chosen_inline_handler(callback, *custom_filters, state=state, run_task=run_task, **kwargs)\n            return callback\n\n        return decorator", "response": "Decorator for chosen inline query handler"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nregistering handler for callback query", "response": "def register_callback_query_handler(self, callback, *custom_filters, state=None, run_task=None, **kwargs):\n        \"\"\"\n        Register handler for callback query\n\n        Example:\n\n        .. code-block:: python3\n\n            dp.register_callback_query_handler(some_callback_handler, lambda callback_query: True)\n\n        :param callback:\n        :param state:\n        :param custom_filters:\n        :param run_task: run callback in task (no wait results)\n        :param kwargs:\n        \"\"\"\n        filters_set = self.filters_factory.resolve(self.callback_query_handlers,\n                                                   *custom_filters,\n                                                   state=state,\n                                                   **kwargs)\n        self.callback_query_handlers.register(self._wrap_async_task(callback, run_task), filters_set)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef callback_query_handler(self, *custom_filters, state=None, run_task=None, **kwargs):\n\n        def decorator(callback):\n            self.register_callback_query_handler(callback, *custom_filters, state=state, run_task=run_task, **kwargs)\n            return callback\n\n        return decorator", "response": "Decorator for callback query handler"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef register_shipping_query_handler(self, callback, *custom_filters, state=None, run_task=None,\n                                        **kwargs):\n        \"\"\"\n        Register handler for shipping query\n\n        Example:\n\n        .. code-block:: python3\n\n            dp.register_shipping_query_handler(some_shipping_query_handler, lambda shipping_query: True)\n\n        :param callback:\n        :param state:\n        :param custom_filters:\n        :param run_task: run callback in task (no wait results)\n        :param kwargs:\n        \"\"\"\n        filters_set = self.filters_factory.resolve(self.shipping_query_handlers,\n                                                   *custom_filters,\n                                                   state=state,\n                                                   **kwargs)\n        self.shipping_query_handlers.register(self._wrap_async_task(callback, run_task), filters_set)", "response": "Register handler for shipping query"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nregistering handler for pre - checkout query", "response": "def register_pre_checkout_query_handler(self, callback, *custom_filters, state=None, run_task=None, **kwargs):\n        \"\"\"\n        Register handler for pre-checkout query\n\n        Example:\n\n        .. code-block:: python3\n\n            dp.register_pre_checkout_query_handler(some_pre_checkout_query_handler, lambda shipping_query: True)\n\n        :param callback:\n        :param state:\n        :param custom_filters:\n        :param run_task: run callback in task (no wait results)\n        :param kwargs:\n        \"\"\"\n        filters_set = self.filters_factory.resolve(self.pre_checkout_query_handlers,\n                                                   *custom_filters,\n                                                   state=state,\n                                                   **kwargs)\n        self.pre_checkout_query_handlers.register(self._wrap_async_task(callback, run_task), filters_set)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nregisters handler for errors type", "response": "def register_errors_handler(self, callback, *custom_filters, exception=None, run_task=None, **kwargs):\n        \"\"\"\n        Register handler for errors\n\n        :param callback:\n        :param exception: you can make handler for specific errors type\n        :param run_task: run callback in task (no wait results)\n        \"\"\"\n        filters_set = self.filters_factory.resolve(self.errors_handlers,\n                                                   *custom_filters,\n                                                   exception=exception,\n                                                   **kwargs)\n        self.errors_handlers.register(self._wrap_async_task(callback, run_task), filters_set)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef current_state(self, *,\n                      chat: typing.Union[str, int, None] = None,\n                      user: typing.Union[str, int, None] = None) -> FSMContext:\n        \"\"\"\n        Get current state for user in chat as context\n\n        .. code-block:: python3\n\n            with dp.current_state(chat=message.chat.id, user=message.user.id) as state:\n                pass\n\n            state = dp.current_state()\n            state.set_state('my_state')\n\n        :param chat:\n        :param user:\n        :return:\n        \"\"\"\n        if chat is None:\n            chat_obj = types.Chat.get_current()\n            chat = chat_obj.id if chat_obj else None\n        if user is None:\n            user_obj = types.User.get_current()\n            user = user_obj.id if user_obj else None\n\n        return FSMContext(storage=self.storage, chat=chat, user=user)", "response": "Get current state for user in chat as context"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nexecuting throttling manager. Returns True if limit has not exceeded otherwise raises ThrottleError or returns False :param key: key in storage :param rate: limit (by default is equal to default rate limit) :param user: user id :param chat: chat id :param no_error: return boolean value instead of raising error :return: bool", "response": "async def throttle(self, key, *, rate=None, user=None, chat=None, no_error=None) -> bool:\n        \"\"\"\n        Execute throttling manager.\n        Returns True if limit has not exceeded otherwise raises ThrottleError or returns False\n\n        :param key: key in storage\n        :param rate: limit (by default is equal to default rate limit)\n        :param user: user id\n        :param chat: chat id\n        :param no_error: return boolean value instead of raising error\n        :return: bool\n        \"\"\"\n        if not self.storage.has_bucket():\n            raise RuntimeError('This storage does not provide Leaky Bucket')\n\n        if no_error is None:\n            no_error = self.no_throttle_error\n        if rate is None:\n            rate = self.throttling_rate_limit\n        if user is None and chat is None:\n            user = types.User.get_current()\n            chat = types.Chat.get_current()\n\n        # Detect current time\n        now = time.time()\n\n        bucket = await self.storage.get_bucket(chat=chat, user=user)\n\n        # Fix bucket\n        if bucket is None:\n            bucket = {key: {}}\n        if key not in bucket:\n            bucket[key] = {}\n        data = bucket[key]\n\n        # Calculate\n        called = data.get(LAST_CALL, now)\n        delta = now - called\n        result = delta >= rate or delta <= 0\n\n        # Save results\n        data[RESULT] = result\n        data[RATE_LIMIT] = rate\n        data[LAST_CALL] = now\n        data[DELTA] = delta\n        if not result:\n            data[EXCEEDED_COUNT] += 1\n        else:\n            data[EXCEEDED_COUNT] = 1\n        bucket[key].update(data)\n        await self.storage.set_bucket(chat=chat, user=user, bucket=bucket)\n\n        if not result and not no_error:\n            # Raise if it is allowed\n            raise Throttled(key=key, chat=chat, user=user, **data)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if a key is in the bucket", "response": "async def check_key(self, key, chat=None, user=None):\n        \"\"\"\n        Get information about key in bucket\n\n        :param key:\n        :param chat:\n        :param user:\n        :return:\n        \"\"\"\n        if not self.storage.has_bucket():\n            raise RuntimeError('This storage does not provide Leaky Bucket')\n\n        if user is None and chat is None:\n            user = types.User.get_current()\n            chat = types.Chat.get_current()\n\n        bucket = await self.storage.get_bucket(chat=chat, user=user)\n        data = bucket.get(key, {})\n        return Throttled(key=key, chat=chat, user=user, **data)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrelease a blocked key from the storage.", "response": "async def release_key(self, key, chat=None, user=None):\n        \"\"\"\n        Release blocked key\n\n        :param key:\n        :param chat:\n        :param user:\n        :return:\n        \"\"\"\n        if not self.storage.has_bucket():\n            raise RuntimeError('This storage does not provide Leaky Bucket')\n\n        if user is None and chat is None:\n            user = types.User.get_current()\n            chat = types.Chat.get_current()\n\n        bucket = await self.storage.get_bucket(chat=chat, user=user)\n        if bucket and key in bucket:\n            del bucket['key']\n            await self.storage.set_bucket(chat=chat, user=user, bucket=bucket)\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nexecute handler as task and return None.", "response": "def async_task(self, func):\n        \"\"\"\n        Execute handler as task and return None.\n        Use this decorator for slow handlers (with timeouts)\n\n        .. code-block:: python3\n\n            @dp.message_handler(commands=['command'])\n            @dp.async_task\n            async def cmd_with_timeout(message: types.Message):\n                await asyncio.sleep(120)\n                return SendMessage(message.chat.id, 'KABOOM').reply(message)\n\n        :param func:\n        :return:\n        \"\"\"\n\n        def process_response(task):\n            try:\n                response = task.result()\n            except Exception as e:\n                self.loop.create_task(\n                    self.errors_handlers.notify(types.Update.get_current(), e))\n            else:\n                if isinstance(response, BaseResponse):\n                    self.loop.create_task(response.execute_response(self.bot))\n\n        @functools.wraps(func)\n        async def wrapper(*args, **kwargs):\n            task = self.loop.create_task(func(*args, **kwargs))\n            task.add_done_callback(process_response)\n\n        return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef check_token(token: str) -> bool:\n    if any(x.isspace() for x in token):\n        raise exceptions.ValidationError('Token is invalid!')\n\n    left, sep, right = token.partition(':')\n    if (not sep) or (not left.isdigit()) or (len(left) < 3):\n        raise exceptions.ValidationError('Token is invalid!')\n\n    return True", "response": "Validate BOT token\n\n    :param token:\n    :return:"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def check_result(method_name: str, content_type: str, status_code: int, body: str):\n    log.debug('Response for %s: [%d] \"%r\"', method_name, status_code, body)\n\n    if content_type != 'application/json':\n        raise exceptions.NetworkError(f\"Invalid response with content type {content_type}: \\\"{body}\\\"\")\n\n    try:\n        result_json = json.loads(body)\n    except ValueError:\n        result_json = {}\n\n    description = result_json.get('description') or body\n    parameters = types.ResponseParameters(**result_json.get('parameters', {}) or {})\n\n    if HTTPStatus.OK <= status_code <= HTTPStatus.IM_USED:\n        return result_json.get('result')\n    elif parameters.retry_after:\n        raise exceptions.RetryAfter(parameters.retry_after)\n    elif parameters.migrate_to_chat_id:\n        raise exceptions.MigrateToChat(parameters.migrate_to_chat_id)\n    elif status_code == HTTPStatus.BAD_REQUEST:\n        exceptions.BadRequest.detect(description)\n    elif status_code == HTTPStatus.NOT_FOUND:\n        exceptions.NotFound.detect(description)\n    elif status_code == HTTPStatus.CONFLICT:\n        exceptions.ConflictError.detect(description)\n    elif status_code in [HTTPStatus.UNAUTHORIZED, HTTPStatus.FORBIDDEN]:\n        exceptions.Unauthorized.detect(description)\n    elif status_code == HTTPStatus.REQUEST_ENTITY_TOO_LARGE:\n        raise exceptions.NetworkError('File too large for uploading. '\n                                      'Check telegram api limits https://core.telegram.org/bots/api#senddocument')\n    elif status_code >= HTTPStatus.INTERNAL_SERVER_ERROR:\n        if 'restart' in description:\n            raise exceptions.RestartingTelegram()\n        raise exceptions.TelegramAPIError(description)\n    raise exceptions.TelegramAPIError(f\"{description} [{status_code}]\")", "response": "Checks whether the result is a valid API response."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncomposes a request data for a node.", "response": "def compose_data(params=None, files=None):\n    \"\"\"\n    Prepare request data\n\n    :param params:\n    :param files:\n    :return:\n    \"\"\"\n    data = aiohttp.formdata.FormData(quote_fields=False)\n\n    if params:\n        for key, value in params.items():\n            data.add_field(key, str(value))\n\n    if files:\n        for key, f in files.items():\n            if isinstance(f, tuple):\n                if len(f) == 2:\n                    filename, fileobj = f\n                else:\n                    raise ValueError('Tuple must have exactly 2 elements: filename, fileobj')\n            elif isinstance(f, types.InputFile):\n                filename, fileobj = f.filename, f.file\n            else:\n                filename, fileobj = guess_filename(f) or key, f\n\n            data.add_field(key, fileobj, filename=filename)\n\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef full_name(self):\n        full_name = self.first_name\n        if self.last_name:\n            full_name += ' ' + self.last_name\n        return full_name", "response": "Get full name of the user."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef locale(self) -> babel.core.Locale or None:\n        if not self.language_code:\n            return None\n        if not hasattr(self, '_locale'):\n            setattr(self, '_locale', babel.core.Locale.parse(self.language_code, sep='-'))\n        return getattr(self, '_locale')", "response": "Get user s locale."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndownloading the file and store it in the destination.", "response": "async def download(self, destination=None, timeout=30, chunk_size=65536, seek=True, make_dirs=True):\n        \"\"\"\n        Download file\n\n        :param destination: filename or instance of :class:`io.IOBase`. For e. g. :class:`io.BytesIO`\n        :param timeout: Integer\n        :param chunk_size: Integer\n        :param seek: Boolean - go to start of file when downloading is finished.\n        :param make_dirs: Make dirs if not exist\n        :return: destination\n        \"\"\"\n        file = await self.get_file()\n\n        is_path = True\n        if destination is None:\n            destination = file.file_path\n        elif isinstance(destination, (str, pathlib.Path)) and os.path.isdir(destination):\n            os.path.join(destination, file.file_path)\n        else:\n            is_path = False\n\n        if is_path and make_dirs:\n            os.makedirs(os.path.dirname(destination), exist_ok=True)\n\n        return await self.bot.download_file(file_path=file.file_path, destination=destination, timeout=timeout,\n                                            chunk_size=chunk_size, seek=seek)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def get_file(self):\n        if hasattr(self, 'file_path'):\n            return self\n        else:\n            return await self.bot.get_file(self.file_id)", "response": "Get file information\n\n        :return: :obj:`aiogram.types.File`"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nregistering callback with the handler.", "response": "def register(self, handler, filters=None, index=None):\n        from .filters import get_filters_spec\n        \"\"\"\n        Register callback\n\n        Filters can be awaitable or not.\n\n        :param handler: coroutine\n        :param filters: list of filters\n        :param index: you can reorder handlers\n        \"\"\"\n        spec, handler = _get_spec(handler)\n\n        if filters and not isinstance(filters, (list, tuple, set)):\n            filters = [filters]\n        filters = get_filters_spec(self.dispatcher, filters)\n\n        record = Handler.HandlerObj(handler=handler, spec=spec, filters=filters)\n        if index is None:\n            self.handlers.append(record)\n        else:\n            self.handlers.insert(index, record)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving handler :param handler: callback :return:", "response": "def unregister(self, handler):\n        \"\"\"\n        Remove handler\n\n        :param handler: callback\n        :return:\n        \"\"\"\n        for handler_obj in self.handlers:\n            registered = handler_obj.handler\n            if handler is registered:\n                self.handlers.remove(handler_obj)\n                return True\n        raise ValueError('This handler is not registered!')"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nnotifies handlers of a new event.", "response": "async def notify(self, *args):\n        \"\"\"\n        Notify handlers\n\n        :param args:\n        :return:\n        \"\"\"\n        from .filters import check_filters, FilterNotPassed\n\n        results = []\n\n        data = {}\n        ctx_data.set(data)\n\n        if self.middleware_key:\n            try:\n                await self.dispatcher.middleware.trigger(f\"pre_process_{self.middleware_key}\", args + (data,))\n            except CancelHandler:  # Allow to cancel current event\n                return results\n\n        try:\n            for handler_obj in self.handlers:\n                try:\n                    data.update(await check_filters(handler_obj.filters, args))\n                except FilterNotPassed:\n                    continue\n                else:\n                    ctx_token = current_handler.set(handler_obj.handler)\n                    try:\n                        if self.middleware_key:\n                            await self.dispatcher.middleware.trigger(f\"process_{self.middleware_key}\", args + (data,))\n                        partial_data = _check_spec(handler_obj.spec, data)\n                        response = await handler_obj.handler(*args, **partial_data)\n                        if response is not None:\n                            results.append(response)\n                        if self.once:\n                            break\n                    except SkipHandler:\n                        continue\n                    except CancelHandler:\n                        break\n                    finally:\n                        current_handler.reset(ctx_token)\n        finally:\n            if self.middleware_key:\n                await self.dispatcher.middleware.trigger(f\"post_process_{self.middleware_key}\",\n                                                         args + (results, data,))\n\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef setup(self, middleware):\n        if not isinstance(middleware, BaseMiddleware):\n            raise TypeError(f\"`middleware` must be an instance of BaseMiddleware, not {type(middleware)}\")\n        if middleware.is_configured():\n            raise ValueError('That middleware is already used!')\n\n        self.applications.append(middleware)\n        middleware.setup(self)\n        log.debug(f\"Loaded middleware '{middleware.__class__.__name__}'\")\n        return middleware", "response": "Setup a new application."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def trigger(self, action: str, args: typing.Iterable):\n        for app in self.applications:\n            await app.trigger(action, args)", "response": "Call action to middlewares with args lilt.\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def trigger(self, action, args):\n        handler_name = f\"on_{action}\"\n        handler = getattr(self, handler_name, None)\n        if not handler:\n            return None\n        await handler(*args)", "response": "Trigger action.\n\n        :param action:\n        :param args:\n        :return:"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef quote_html(content):\n    new_content = ''\n    for symbol in content:\n        new_content += HTML_QUOTES_MAP[symbol] if symbol in _HQS else symbol\n    return new_content", "response": "Quote HTML symbols in the given content."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmaking a block of text bold.", "response": "def bold(*content, sep=' '):\n    \"\"\"\n    Make bold text (Markdown)\n\n    :param content:\n    :param sep:\n    :return:\n    \"\"\"\n    return _md(_join(*content, sep=sep), symbols=MD_SYMBOLS[0])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef hbold(*content, sep=' '):\n    return _md(quote_html(_join(*content, sep=sep)), symbols=MD_SYMBOLS[4])", "response": "Make bold text (HTML)\n\n    :param content:\n    :param sep:\n    :return:"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef italic(*content, sep=' '):\n    return _md(_join(*content, sep=sep), symbols=MD_SYMBOLS[1])", "response": "Make italic text (Markdown)\n\n    :param content:\n    :param sep:\n    :return:"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmakes italic text (HTML) :param content: :param sep: :return:", "response": "def hitalic(*content, sep=' '):\n    \"\"\"\n    Make italic text (HTML)\n\n    :param content:\n    :param sep:\n    :return:\n    \"\"\"\n    return _md(quote_html(_join(*content, sep=sep)), symbols=MD_SYMBOLS[5])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef code(*content, sep=' '):\n    return _md(_join(*content, sep=sep), symbols=MD_SYMBOLS[2])", "response": "Make mono - width text"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef hcode(*content, sep=' '):\n    return _md(quote_html(_join(*content, sep=sep)), symbols=MD_SYMBOLS[6])", "response": "Make mono - width text HTML"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmakes mono - width text block.", "response": "def pre(*content, sep='\\n'):\n    \"\"\"\n    Make mono-width text block (Markdown)\n\n    :param content:\n    :param sep:\n    :return:\n    \"\"\"\n    return _md(_join(*content, sep=sep), symbols=MD_SYMBOLS[3])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmaking mono - width text block.", "response": "def hpre(*content, sep='\\n'):\n    \"\"\"\n    Make mono-width text block (HTML)\n\n    :param content:\n    :param sep:\n    :return:\n    \"\"\"\n    return _md(quote_html(_join(*content, sep=sep)), symbols=MD_SYMBOLS[7])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def redis(self) -> aioredis.RedisConnection:\n        # Use thread-safe asyncio Lock because this method without that is not safe\n        async with self._connection_lock:\n            if self._redis is None:\n                self._redis = await aioredis.create_connection((self._host, self._port),\n                                                               db=self._db, password=self._password, ssl=self._ssl,\n                                                               loop=self._loop,\n                                                               **self._kwargs)\n        return self._redis", "response": "Get Redis connection\n\n        This property is awaitable."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the record from storage.", "response": "async def get_record(self, *,\n                         chat: typing.Union[str, int, None] = None,\n                         user: typing.Union[str, int, None] = None) -> typing.Dict:\n        \"\"\"\n        Get record from storage\n\n        :param chat:\n        :param user:\n        :return:\n        \"\"\"\n        chat, user = self.check_address(chat=chat, user=user)\n        addr = f\"fsm:{chat}:{user}\"\n\n        conn = await self.redis()\n        data = await conn.execute('GET', addr)\n        if data is None:\n            return {'state': None, 'data': {}}\n        return json.loads(data)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def set_record(self, *, chat: typing.Union[str, int, None] = None, user: typing.Union[str, int, None] = None,\n                         state=None, data=None, bucket=None):\n        \"\"\"\n        Write record to storage\n\n        :param bucket:\n        :param chat:\n        :param user:\n        :param state:\n        :param data:\n        :return:\n        \"\"\"\n        if data is None:\n            data = {}\n        if bucket is None:\n            bucket = {}\n\n        chat, user = self.check_address(chat=chat, user=user)\n        addr = f\"fsm:{chat}:{user}\"\n\n        record = {'state': state, 'data': data, 'bucket': bucket}\n\n        conn = await self.redis()\n        await conn.execute('SET', addr, json.dumps(record))", "response": "Write a record to storage."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def get_states_list(self) -> typing.List[typing.Tuple[int]]:\n        conn = await self.redis()\n        result = []\n\n        keys = await conn.execute('KEYS', 'fsm:*')\n        for item in keys:\n            *_, chat, user = item.decode('utf-8').split(':')\n            result.append((chat, user))\n\n        return result", "response": "Get list of all stored chat s and user s state"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nresets all states in DB", "response": "async def reset_all(self, full=True):\n        \"\"\"\n        Reset states in DB\n\n        :param full: clean DB or clean only states\n        :return:\n        \"\"\"\n        conn = await self.redis()\n\n        if full:\n            await conn.execute('FLUSHDB')\n        else:\n            keys = await conn.execute('KEYS', 'fsm:*')\n            await conn.execute('DEL', *keys)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets Redis connection This property is awaitable.", "response": "async def redis(self) -> aioredis.Redis:\n        \"\"\"\n        Get Redis connection\n\n        This property is awaitable.\n        \"\"\"\n        # Use thread-safe asyncio Lock because this method without that is not safe\n        async with self._connection_lock:\n            if self._redis is None:\n                self._redis = await aioredis.create_redis_pool((self._host, self._port),\n                                                               db=self._db, password=self._password, ssl=self._ssl,\n                                                               minsize=1, maxsize=self._pool_size,\n                                                               loop=self._loop, **self._kwargs)\n        return self._redis"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreset all states in DB", "response": "async def reset_all(self, full=True):\n        \"\"\"\n        Reset states in DB\n\n        :param full: clean DB or clean only states\n        :return:\n        \"\"\"\n        conn = await self.redis()\n\n        if full:\n            await conn.flushdb()\n        else:\n            keys = await conn.keys(self.generate_key('*'))\n            await conn.delete(*keys)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def get_states_list(self) -> typing.List[typing.Tuple[int]]:\n        conn = await self.redis()\n        result = []\n\n        keys = await conn.keys(self.generate_key('*', '*', STATE_KEY), encoding='utf8')\n        for item in keys:\n            *_, chat, user, _ = item.split(':')\n            result.append((chat, user))\n\n        return result", "response": "Get list of all stored chat s and user s state"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef open_tablebase(directory: PathLike, *, load_wdl: bool = True, load_dtz: bool = True, max_fds: Optional[int] = 128, VariantBoard: Type[chess.Board] = chess.Board) -> Tablebase:\n    tables = Tablebase(max_fds=max_fds, VariantBoard=VariantBoard)\n    tables.add_directory(directory, load_wdl=load_wdl, load_dtz=load_dtz)\n    return tables", "response": "Opens a collection of tables for probing."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_directory(self, directory: PathLike, *, load_wdl: bool = True, load_dtz: bool = True) -> int:\n        num = 0\n        directory = os.path.abspath(directory)\n\n        for filename in os.listdir(directory):\n            path = os.path.join(directory, filename)\n            tablename, ext = os.path.splitext(filename)\n\n            if is_table_name(tablename) and os.path.isfile(path):\n                if load_wdl:\n                    if ext == self.variant.tbw_suffix:\n                        num += self._open_table(self.wdl, WdlTable, path)\n                    elif \"P\" not in tablename and ext == self.variant.pawnless_tbw_suffix:\n                        num += self._open_table(self.wdl, WdlTable, path)\n\n                if load_dtz:\n                    if ext == self.variant.tbz_suffix:\n                        num += self._open_table(self.dtz, DtzTable, path)\n                    elif \"P\" not in tablename and ext == self.variant.pawnless_tbz_suffix:\n                        num += self._open_table(self.dtz, DtzTable, path)\n\n        return num", "response": "Adds tables from a directory."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprobes WDL tables for win - draw - loss - information.", "response": "def probe_wdl(self, board: chess.Board) -> int:\n        \"\"\"\n        Probes WDL tables for win/draw/loss-information.\n\n        Probing is thread-safe when done with different *board* objects and\n        if *board* objects are not modified during probing.\n\n        Returns ``2`` if the side to move is winning, ``0`` if the position is\n        a draw and ``-2`` if the side to move is losing.\n\n        Returns ``1`` in case of a cursed win and ``-1`` in case of a blessed\n        loss. Mate can be forced but the position can be drawn due to the\n        fifty-move rule.\n\n        >>> import chess\n        >>> import chess.syzygy\n        >>>\n        >>> with chess.syzygy.open_tablebase(\"data/syzygy/regular\") as tablebase:\n        ...     board = chess.Board(\"8/2K5/4B3/3N4/8/8/4k3/8 b - - 0 1\")\n        ...     print(tablebase.probe_wdl(board))\n        ...\n        -2\n\n        :raises: :exc:`KeyError` (or specifically\n            :exc:`chess.syzygy.MissingTableError`) if the position could not\n            be found in the tablebase. Use\n            :func:`~chess.syzygy.Tablebase.get_wdl()` if you prefer to get\n            ``None`` instead of an exception.\n\n            Note that probing corrupted table files is undefined behavior.\n        \"\"\"\n        # Positions with castling rights are not in the tablebase.\n        if board.castling_rights:\n            raise KeyError(\"syzygy tables do not contain positions with castling rights: {}\".format(board.fen()))\n\n        # Validate piece count.\n        if chess.popcount(board.occupied) > 7:\n            raise KeyError(\"syzygy tables support up to 6 (and experimentally 7) pieces, not {}: {}\".format(chess.popcount(board.occupied), board.fen()))\n\n        # Probe.\n        v, _ = self.probe_ab(board, -2, 2)\n\n        # If en passant is not possible, we are done.\n        if not board.ep_square or self.variant.captures_compulsory:\n            return v\n\n        # Now handle en passant.\n        v1 = -3\n\n        # Look at all legal en passant captures.\n        for move in board.generate_legal_ep():\n            board.push(move)\n            try:\n                v0_plus, _ = self.probe_ab(board, -2, 2)\n                v0 = -v0_plus\n            finally:\n                board.pop()\n\n            if v0 > v1:\n                v1 = v0\n\n        if v1 > -3:\n            if v1 >= v:\n                v = v1\n            elif v == 0:\n                # If there is not at least one legal non-en-passant move we are\n                # forced to play the losing en passant cature.\n                if all(board.is_en_passant(move) for move in board.generate_legal_moves()):\n                    v = v1\n\n        return v"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprobes DTZ tables for distance to zero information.", "response": "def probe_dtz(self, board: chess.Board) -> int:\n        \"\"\"\n        Probes DTZ tables for distance to zero information.\n\n        Both DTZ and WDL tables are required in order to probe for DTZ.\n\n        Returns a positive value if the side to move is winning, ``0`` if the\n        position is a draw and a negative value if the side to move is losing.\n        More precisely:\n\n        +-----+------------------+--------------------------------------------+\n        | WDL | DTZ              |                                            |\n        +=====+==================+============================================+\n        |  -2 | -100 <= n <= -1  | Unconditional loss (assuming 50-move       |\n        |     |                  | counter is zero), where a zeroing move can |\n        |     |                  | be forced in -n plies.                     |\n        +-----+------------------+--------------------------------------------+\n        |  -1 |         n < -100 | Loss, but draw under the 50-move rule.     |\n        |     |                  | A zeroing move can be forced in -n plies   |\n        |     |                  | or -n - 100 plies (if a later phase is     |\n        |     |                  | responsible for the blessed loss).         |\n        +-----+------------------+--------------------------------------------+\n        |   0 |         0        | Draw.                                      |\n        +-----+------------------+--------------------------------------------+\n        |   1 |   100 < n        | Win, but draw under the 50-move rule.      |\n        |     |                  | A zeroing move can be forced in n plies or |\n        |     |                  | n - 100 plies (if a later phase is         |\n        |     |                  | responsible for the cursed win).           |\n        +-----+------------------+--------------------------------------------+\n        |   2 |    1 <= n <= 100 | Unconditional win (assuming 50-move        |\n        |     |                  | counter is zero), where a zeroing move can |\n        |     |                  | be forced in n plies.                      |\n        +-----+------------------+--------------------------------------------+\n\n        The return value can be off by one: a return value -n can mean a\n        losing zeroing move in in n + 1 plies and a return value +n can mean a\n        winning zeroing move in n + 1 plies.\n        This is guaranteed not to happen for positions exactly on the edge of\n        the 50-move rule, so that (with some care) this never impacts the\n        result of practical play.\n\n        Minmaxing the DTZ values guarantees winning a won position (and drawing\n        a drawn position), because it makes progress keeping the win in hand.\n        However the lines are not always the most straightforward ways to win.\n        Engines like Stockfish calculate themselves, checking with DTZ, but\n        only play according to DTZ if they can not manage on their own.\n\n        >>> import chess\n        >>> import chess.syzygy\n        >>>\n        >>> with chess.syzygy.open_tablebase(\"data/syzygy/regular\") as tablebase:\n        ...     board = chess.Board(\"8/2K5/4B3/3N4/8/8/4k3/8 b - - 0 1\")\n        ...     print(tablebase.probe_dtz(board))\n        ...\n        -53\n\n        Probing is thread-safe when done with different *board* objects and\n        if *board* objects are not modified during probing.\n\n        :raises: :exc:`KeyError` (or specifically\n            :exc:`chess.syzygy.MissingTableError`) if the position could not\n            be found in the tablebase. Use\n            :func:`~chess.syzygy.Tablebase.get_dtz()` if you prefer to get\n            ``None`` instead of an exception.\n\n            Note that probing corrupted table files is undefined behavior.\n        \"\"\"\n        v = self.probe_dtz_no_ep(board)\n\n        if not board.ep_square or self.variant.captures_compulsory:\n            return v\n\n        v1 = -3\n\n        # Generate all en-passant moves.\n        for move in board.generate_legal_ep():\n            board.push(move)\n            try:\n                v0_plus, _ = self.probe_ab(board, -2, 2)\n                v0 = -v0_plus\n            finally:\n                board.pop()\n\n            if v0 > v1:\n                v1 = v0\n\n        if v1 > -3:\n            v1 = WDL_TO_DTZ[v1 + 2]\n            if v < -100:\n                if v1 >= 0:\n                    v = v1\n            elif v < 0:\n                if v1 >= 0 or v1 < -100:\n                    v = v1\n            elif v > 100:\n                if v1 > 0:\n                    v = v1\n            elif v > 0:\n                if v1 == 1:\n                    v = v1\n            elif v1 >= 0:\n                v = v1\n            else:\n                if all(board.is_en_passant(move) for move in board.generate_legal_moves()):\n                    v = v1\n\n        return v"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef close(self) -> None:\n        while self.wdl:\n            _, wdl = self.wdl.popitem()\n            wdl.close()\n\n        while self.dtz:\n            _, dtz = self.dtz.popitem()\n            dtz.close()\n\n        self.lru.clear()", "response": "Closes all loaded tables."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading a game from a file opened in text mode.", "response": "def read_game(handle: TextIO, *, Visitor: Callable[[], BaseVisitor[ResultT]] = GameBuilder) -> Optional[ResultT]:\n    \"\"\"\n    Reads a game from a file opened in text mode.\n\n    >>> import chess.pgn\n    >>>\n    >>> pgn = open(\"data/pgn/kasparov-deep-blue-1997.pgn\")\n    >>>\n    >>> first_game = chess.pgn.read_game(pgn)\n    >>> second_game = chess.pgn.read_game(pgn)\n    >>>\n    >>> first_game.headers[\"Event\"]\n    'IBM Man-Machine, New York USA'\n    >>>\n    >>> # Iterate through all moves and play them on a board.\n    >>> board = first_game.board()\n    >>> for move in first_game.mainline_moves():\n    ...     board.push(move)\n    ...\n    >>> board\n    Board('4r3/6P1/2p2P1k/1p6/pP2p1R1/P1B5/2P2K2/3r4 b - - 0 45')\n\n    By using text mode, the parser does not need to handle encodings. It is the\n    caller's responsibility to open the file with the correct encoding.\n    PGN files are usually ASCII or UTF-8 encoded. So, the following should\n    cover most relevant cases (ASCII, UTF-8, UTF-8 with BOM).\n\n    >>> pgn = open(\"data/pgn/kasparov-deep-blue-1997.pgn\", encoding=\"utf-8-sig\")\n\n    Use :class:`~io.StringIO` to parse games from a string.\n\n    >>> import io\n    >>>\n    >>> pgn = io.StringIO(\"1. e4 e5 2. Nf3 *\")\n    >>> game = chess.pgn.read_game(pgn)\n\n    The end of a game is determined by a completely blank line or the end of\n    the file. (Of course, blank lines in comments are possible).\n\n    According to the PGN standard, at least the usual 7 header tags are\n    required for a valid game. This parser also handles games without any\n    headers just fine.\n\n    The parser is relatively forgiving when it comes to errors. It skips over\n    tokens it can not parse. Any exceptions are logged and collected in\n    :data:`Game.errors <chess.pgn.Game.errors>`. This behavior can be\n    :func:`overriden <chess.pgn.GameBuilder.handle_error>`.\n\n    Returns the parsed game or ``None`` if the end of file is reached.\n    \"\"\"\n    visitor = Visitor()\n\n    found_game = False\n    skipping_game = False\n    headers = None\n    managed_headers = None\n\n    # Ignore leading empty lines and comments.\n    line = handle.readline().lstrip(\"\\ufeff\")\n    while line.isspace() or line.startswith(\"%\") or line.startswith(\";\"):\n        line = handle.readline()\n\n    # Parse game headers.\n    while line:\n        # Ignore comments.\n        if line.startswith(\"%\") or line.startswith(\";\"):\n            line = handle.readline()\n            continue\n\n        # First token of the game.\n        if not found_game:\n            found_game = True\n            skipping_game = visitor.begin_game() is SKIP\n            if not skipping_game:\n                managed_headers = visitor.begin_headers()\n                if not isinstance(managed_headers, Headers):\n                    managed_headers = None\n                    headers = Headers({})\n\n        if not line.startswith(\"[\"):\n            break\n\n        if not skipping_game:\n            tag_match = TAG_REGEX.match(line)\n            if tag_match:\n                visitor.visit_header(tag_match.group(1), tag_match.group(2))\n                if headers is not None:\n                    headers[tag_match.group(1)] = tag_match.group(2)\n            else:\n                break\n\n        line = handle.readline()\n\n    if not found_game:\n        return None\n\n    if not skipping_game:\n        skipping_game = visitor.end_headers() is SKIP\n\n    # Ignore single empty line after headers.\n    if line.isspace():\n        line = handle.readline()\n\n    if not skipping_game:\n        # Chess variant.\n        headers = managed_headers if headers is None else headers\n        try:\n            VariantBoard = headers.variant()\n        except ValueError as error:\n            visitor.handle_error(error)\n            VariantBoard = chess.Board\n\n        # Initial position.\n        fen = headers.get(\"FEN\", VariantBoard.starting_fen)\n        try:\n            board_stack = [VariantBoard(fen, chess960=headers.is_chess960())]\n        except ValueError as error:\n            visitor.handle_error(error)\n            skipping_game = True\n        else:\n            visitor.visit_board(board_stack[0])\n\n    # Fast path: Skip entire game.\n    if skipping_game:\n        in_comment = False\n\n        while line:\n            if not in_comment:\n                if line.isspace():\n                    break\n                elif line.startswith(\"%\"):\n                    line = handle.readline()\n                    continue\n\n            for match in SKIP_MOVETEXT_REGEX.finditer(line):\n                token = match.group(0)\n                if token == \"{\":\n                    in_comment = True\n                elif not in_comment and token == \";\":\n                    break\n                elif token == \"}\":\n                    in_comment = False\n\n            line = handle.readline()\n\n        visitor.end_game()\n        return visitor.result()\n\n    # Parse movetext.\n    skip_variation_depth = 0\n    while line:\n        read_next_line = True\n\n        # Ignore comments.\n        if line.startswith(\"%\") or line.startswith(\";\"):\n            line = handle.readline()\n            continue\n\n        # An empty line means the end of a game.\n        if line.isspace():\n            visitor.end_game()\n            return visitor.result()\n\n        for match in MOVETEXT_REGEX.finditer(line):\n            token = match.group(0)\n\n            if token.startswith(\"{\"):\n                # Consume until the end of the comment.\n                line = token[1:]\n                comment_lines = []\n                while line and \"}\" not in line:\n                    comment_lines.append(line.rstrip())\n                    line = handle.readline()\n                end_index = line.find(\"}\")\n                comment_lines.append(line[:end_index])\n                if \"}\" in line:\n                    line = line[end_index:]\n                else:\n                    line = \"\"\n\n                if not skip_variation_depth:\n                    visitor.visit_comment(\"\\n\".join(comment_lines).strip())\n\n                # Continue with the current or the next line.\n                if line:\n                    read_next_line = False\n                break\n            elif token == \"(\":\n                if skip_variation_depth:\n                    skip_variation_depth += 1\n                elif board_stack[-1].move_stack:\n                    if visitor.begin_variation() is SKIP:\n                        skip_variation_depth = 1\n                    else:\n                        board = board_stack[-1].copy()\n                        board.pop()\n                        board_stack.append(board)\n            elif token == \")\":\n                if skip_variation_depth:\n                    skip_variation_depth -= 1\n                if len(board_stack) > 1:\n                    visitor.end_variation()\n                    board_stack.pop()\n            elif skip_variation_depth:\n                continue\n            elif token.startswith(\";\"):\n                break\n            elif token.startswith(\"$\"):\n                # Found a NAG.\n                visitor.visit_nag(int(token[1:]))\n            elif token == \"?\":\n                visitor.visit_nag(NAG_MISTAKE)\n            elif token == \"??\":\n                visitor.visit_nag(NAG_BLUNDER)\n            elif token == \"!\":\n                visitor.visit_nag(NAG_GOOD_MOVE)\n            elif token == \"!!\":\n                visitor.visit_nag(NAG_BRILLIANT_MOVE)\n            elif token == \"!?\":\n                visitor.visit_nag(NAG_SPECULATIVE_MOVE)\n            elif token == \"?!\":\n                visitor.visit_nag(NAG_DUBIOUS_MOVE)\n            elif token in [\"1-0\", \"0-1\", \"1/2-1/2\", \"*\"] and len(board_stack) == 1:\n                visitor.visit_result(token)\n            else:\n                # Parse SAN tokens.\n                try:\n                    move = visitor.parse_san(board_stack[-1], token)\n                except ValueError as error:\n                    visitor.handle_error(error)\n                    skip_variation_depth = 1\n                else:\n                    visitor.visit_move(board_stack[-1], move)\n                    board_stack[-1].push(move)\n                visitor.visit_board(board_stack[-1])\n\n        if read_next_line:\n            line = handle.readline()\n\n    visitor.end_game()\n    return visitor.result()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets a board with the position of the node.", "response": "def board(self, *, _cache: bool = True) -> chess.Board:\n        \"\"\"\n        Gets a board with the position of the node.\n\n        It's a copy, so modifying the board will not alter the game.\n        \"\"\"\n        if self.board_cached is not None:\n            board = self.board_cached()\n            if board is not None:\n                return board.copy()\n\n        board = self.parent.board(_cache=False)\n        board.push(self.move)\n\n        if _cache:\n            self.board_cached = weakref.ref(board)\n            return board.copy()\n        else:\n            return board"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the UCI notation of the move leading to this node.", "response": "def uci(self, *, chess960: Optional[bool] = None) -> str:\n        \"\"\"\n        Gets the UCI notation of the move leading to this node.\n        See :func:`chess.Board.uci()`.\n\n        Do not call this on the root node.\n        \"\"\"\n        return self.parent.board().uci(self.move, chess960=chess960)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef root(self) -> \"GameNode\":\n        node = self\n\n        while node.parent:\n            node = node.parent\n\n        return node", "response": "Gets the root node i. e. the game."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef end(self) -> \"GameNode\":\n        node = self\n\n        while node.variations:\n            node = node.variations[0]\n\n        return node", "response": "Follows the main variation to the end and returns the last node."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking if this node starts a variation.", "response": "def starts_variation(self) -> bool:\n        \"\"\"\n        Checks if this node starts a variation (and can thus have a starting\n        comment). The root node does not start a variation and can have no\n        starting comment.\n\n        For example, in ``1. e4 e5 (1... c5 2. Nf3) 2. Nf3``, the node holding\n        1... c5 starts a variation.\n        \"\"\"\n        if not self.parent or not self.parent.variations:\n            return False\n\n        return self.parent.variations[0] != self"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if the node is in the mainline of the game.", "response": "def is_mainline(self) -> bool:\n        \"\"\"Checks if the node is in the mainline of the game.\"\"\"\n        node = self\n\n        while node.parent:\n            parent = node.parent\n\n            if not parent.variations or parent.variations[0] != node:\n                return False\n\n            node = parent\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if this node is the first variation from the point of view of its parent.", "response": "def is_main_variation(self) -> bool:\n        \"\"\"\n        Checks if this node is the first variation from the point of view of its\n        parent. The root node is also in the main variation.\n        \"\"\"\n        if not self.parent:\n            return True\n\n        return not self.parent.variations or self.parent.variations[0] == self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef has_variation(self, move: chess.Move) -> bool:\n        return move in (variation.move for variation in self.variations)", "response": "Checks if the given move appears as a variation."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\npromote the given move to the main variation.", "response": "def promote_to_main(self, move: chess.Move) -> None:\n        \"\"\"Promotes the given *move* to the main variation.\"\"\"\n        variation = self[move]\n        self.variations.remove(variation)\n        self.variations.insert(0, variation)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmoving a variation one up in the list of variations.", "response": "def promote(self, move: chess.Move) -> None:\n        \"\"\"Moves a variation one up in the list of variations.\"\"\"\n        variation = self[move]\n        i = self.variations.index(variation)\n        if i > 0:\n            self.variations[i - 1], self.variations[i] = self.variations[i], self.variations[i - 1]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmove a variation one down in the list of variations.", "response": "def demote(self, move: chess.Move) -> None:\n        \"\"\"Moves a variation one down in the list of variations.\"\"\"\n        variation = self[move]\n        i = self.variations.index(variation)\n        if i < len(self.variations) - 1:\n            self.variations[i + 1], self.variations[i] = self.variations[i], self.variations[i + 1]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef remove_variation(self, move: chess.Move) -> None:\n        self.variations.remove(self.variation(move))", "response": "Removes a variation from the set."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a child node with the given attributes.", "response": "def add_variation(self, move: chess.Move, *, comment: str = \"\", starting_comment: str = \"\", nags: Iterable[int] = ()) -> \"GameNode\":\n        \"\"\"Creates a child node with the given attributes.\"\"\"\n        node = type(self).dangling_node()\n        node.move = move\n        node.nags = set(nags)\n        node.comment = comment\n        node.starting_comment = starting_comment\n\n        node.parent = self\n        self.variations.append(node)\n        return node"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a new main variation to the game node.", "response": "def add_main_variation(self, move: chess.Move, *, comment: str = \"\") -> \"GameNode\":\n        \"\"\"\n        Creates a child node with the given attributes and promotes it to the\n        main variation.\n        \"\"\"\n        node = self.add_variation(move, comment=comment)\n        self.variations.remove(node)\n        self.variations.insert(0, node)\n        return node"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a line to the last node of the game.", "response": "def add_line(self, moves: Iterable[chess.Move], *, comment: str = \"\", starting_comment: str = \"\", nags: Iterable[int] = ()) -> \"GameNode\":\n        \"\"\"\n        Creates a sequence of child nodes for the given list of moves.\n        Adds *comment* and *nags* to the last node of the line and returns it.\n        \"\"\"\n        node = self\n\n        # Add line.\n        for move in moves:\n            node = node.add_variation(move, starting_comment=starting_comment)\n            starting_comment = \"\"\n\n        # Merge comment and NAGs.\n        if node.comment:\n            node.comment += \" \" + comment\n        else:\n            node.comment = comment\n\n        node.nags.update(nags)\n\n        return node"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef accept(self, visitor: \"BaseVisitor[ResultT]\", *, _parent_board: Optional[chess.Board] = None) -> ResultT:\n        board = self.parent.board() if _parent_board is None else _parent_board\n\n        # First, visit the move that leads to this node.\n        self._accept_node(board, visitor)\n\n        # Then visit sidelines.\n        if _parent_board is not None and self == self.parent.variations[0]:\n            for variation in itertools.islice(self.parent.variations, 1, None):\n                if visitor.begin_variation() is not SKIP:\n                    variation.accept(visitor, _parent_board=board)\n                visitor.end_variation()\n\n        # The mainline is continued last.\n        if self.variations:\n            board.push(self.move)\n            self.variations[0].accept(visitor, _parent_board=board)\n            board.pop()\n\n        # Get the result if not called recursively.\n        return visitor.result() if _parent_board is None else None", "response": "Visit the game node and all its variations."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef accept_subgame(self, visitor: \"BaseVisitor[ResultT]\") -> ResultT:\n        if visitor.begin_game() is not SKIP:\n            game = self.root()\n            board = self.board()\n\n            dummy_game = Game.without_tag_roster()\n            dummy_game.setup(board)\n\n            visitor.begin_headers()\n\n            for tagname, tagvalue in game.headers.items():\n                if tagname not in dummy_game.headers:\n                    visitor.visit_header(tagname, tagvalue)\n            for tagname, tagvalue in dummy_game.headers.items():\n                visitor.visit_header(tagname, tagvalue)\n\n            if visitor.end_headers() is not SKIP:\n                visitor.visit_board(board)\n\n                if self.variations:\n                    self.variations[0].accept(visitor, _parent_board=board)\n\n                visitor.visit_result(game.headers.get(\"Result\", \"*\"))\n\n        visitor.end_game()\n        return visitor.result()", "response": "Traverses the game and all other game nodes in PGN order as if the game was starting after this node. Returns the visitor * result."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the board for this game.", "response": "def board(self, *, _cache: bool = False) -> chess.Board:\n        \"\"\"\n        Gets the starting position of the game.\n\n        Unless the ``FEN`` header tag is set, this is the default starting\n        position (for the ``Variant``).\n        \"\"\"\n        return self.headers.board()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting up a specific starting position. This sets the Chess960 header tags.", "response": "def setup(self, board: Union[chess.Board, str]) -> None:\n        \"\"\"\n        Sets up a specific starting position. This sets (or resets) the\n        ``FEN``, ``SetUp``, and ``Variant`` header tags.\n        \"\"\"\n        try:\n            fen = board.fen()\n        except AttributeError:\n            board = chess.Board(board)\n            board.chess960 = board.has_chess960_castling_rights()\n            fen = board.fen()\n\n        if fen == type(board).starting_fen:\n            self.headers.pop(\"SetUp\", None)\n            self.headers.pop(\"FEN\", None)\n        else:\n            self.headers[\"SetUp\"] = \"1\"\n            self.headers[\"FEN\"] = fen\n\n        if type(board).aliases[0] == \"Standard\" and board.chess960:\n            self.headers[\"Variant\"] = \"Chess960\"\n        elif type(board).aliases[0] != \"Standard\":\n            self.headers[\"Variant\"] = type(board).aliases[0]\n            self.headers[\"FEN\"] = board.fen()\n        else:\n            self.headers.pop(\"Variant\", None)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntraverse the game in PGN order using the given visitor. Returns the result.", "response": "def accept(self, visitor: \"BaseVisitor[ResultT]\") -> ResultT:\n        \"\"\"\n        Traverses the game in PGN order using the given *visitor*. Returns\n        the *visitor* result.\n        \"\"\"\n        if visitor.begin_game() is not SKIP:\n            for tagname, tagvalue in self.headers.items():\n                visitor.visit_header(tagname, tagvalue)\n            if visitor.end_headers() is not SKIP:\n                board = self.board()\n                visitor.visit_board(board)\n\n                if self.comment:\n                    visitor.visit_comment(self.comment)\n\n                if self.variations:\n                    self.variations[0].accept(visitor, _parent_board=board)\n\n                visitor.visit_result(self.headers.get(\"Result\", \"*\"))\n\n        visitor.end_game()\n        return visitor.result()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_board(cls: Type[GameT], board: chess.Board) -> GameT:\n        # Setup the initial position.\n        game = cls()\n        game.setup(board.root())\n        node = game  # type: GameNode\n\n        # Replay all moves.\n        for move in board.move_stack:\n            node = node.add_variation(move)\n\n        game.headers[\"Result\"] = board.result()\n        return game", "response": "Creates a game from the move stack of a chess. Board."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing a move from standard algebraic notation.", "response": "def parse_san(self, board: chess.Board, san: str) -> chess.Move:\n        \"\"\"\n        When the visitor is used by a parser, this is called to parse a move\n        in standard algebraic notation.\n\n        You can override the default implementation to work around specific\n        quirks of your input format.\n        \"\"\"\n        # Replace zeros with correct castling notation.\n        if san == \"0-0\":\n            san = \"O-O\"\n        elif san == \"0-0-0\":\n            san = \"O-O-O\"\n\n        return board.parse_san(san)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef handle_error(self, error: Exception) -> None:\n        LOGGER.exception(\"error during pgn parsing\")\n        self.game.errors.append(error)", "response": "Adds an error to the game s errors list."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads the description from README. rst and replaces mentions of the latest version with a concrete version number.", "response": "def read_description():\n    \"\"\"\n    Reads the description from README.rst and substitutes mentions of the\n    latest version with a concrete version number.\n    \"\"\"\n    with open(os.path.join(os.path.dirname(__file__), \"README.rst\"), encoding=\"utf-8\") as f:\n        description = f.read()\n\n    # Link to the documentation of the specific version.\n    description = description.replace(\n        \"//python-chess.readthedocs.io/en/latest/\",\n        \"//python-chess.readthedocs.io/en/v{}/\".format(chess.__version__))\n\n    # Use documentation badge for the specific version.\n    description = description.replace(\n        \"//readthedocs.org/projects/python-chess/badge/?version=latest\",\n        \"//readthedocs.org/projects/python-chess/badge/?version=v{}\".format(chess.__version__))\n\n    # Show Travis CI build status of the concrete version.\n    description = description.replace(\n        \"//travis-ci.org/niklasf/python-chess.svg?branch=master\",\n        \"//travis-ci.org/niklasf/python-chess.svg?branch=v{}\".format(chess.__version__))\n\n    # Show Appveyor build status of the concrete version.\n    description = description.replace(\n        \"/y9k3hdbm0f0nbum9/branch/master\",\n        \"/y9k3hdbm0f0nbum9/branch/v{}\".format(chess.__version__))\n\n    # Remove doctest comments.\n    description = re.sub(r\"\\s*# doctest:.*\", \"\", description)\n\n    return description"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrun a coroutine in a background thread.", "response": "def run_in_background(coroutine: \"Callable[[concurrent.futures.Future[T], Coroutine[Any, Any, None]]\", *, debug: bool = False, _policy_lock: threading.Lock = threading.Lock()) -> T:\n    \"\"\"\n    Runs ``coroutine(future)`` in a new event loop on a background thread.\n\n    Blocks and returns the *future* result as soon as it is resolved.\n    The coroutine and all remaining tasks continue running in the background\n    until it is complete.\n\n    Note: This installs a :class:`chess.engine.EventLoopPolicy` for the entire\n    process.\n    \"\"\"\n    assert asyncio.iscoroutinefunction(coroutine)\n\n    with _policy_lock:\n        if not isinstance(asyncio.get_event_loop_policy(), EventLoopPolicy):\n            asyncio.set_event_loop_policy(EventLoopPolicy())\n\n    future = concurrent.futures.Future()  # type: concurrent.futures.Future[T]\n\n    def background() -> None:\n        loop = asyncio.new_event_loop()\n        asyncio.set_event_loop(loop)\n        loop.set_debug(debug)\n\n        try:\n            loop.run_until_complete(coroutine(future))\n            future.cancel()\n        except Exception as exc:\n            future.set_exception(exc)\n            return\n        finally:\n            try:\n                # Finish all remaining tasks.\n                pending = _all_tasks(loop)\n                loop.run_until_complete(asyncio.gather(*pending, loop=loop, return_exceptions=True))\n\n                # Shutdown async generators.\n                try:\n                    loop.run_until_complete(loop.shutdown_asyncgens())\n                except AttributeError:\n                    # Before Python 3.6.\n                    pass\n            finally:\n                loop.close()\n\n    threading.Thread(target=background).start()\n    return future.result()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nspawn and initializes an UCI engine.", "response": "async def popen_uci(command: Union[str, List[str]], *, setpgrp: bool = False, loop=None, **popen_args: Any) -> Tuple[asyncio.SubprocessTransport, UciProtocol]:\n    \"\"\"\n    Spawns and initializes an UCI engine.\n\n    :param command: Path of the engine executable, or a list including the\n        path and arguments.\n    :param setpgrp: Open the engine process in a new process group. This will\n        stop signals (such as keyboard interrupts) from propagating from the\n        parent process. Defaults to ``False``.\n    :param popen_args: Additional arguments for\n        `popen <https://docs.python.org/3/library/subprocess.html#popen-constructor>`_.\n        Do not set ``stdin``, ``stdout``, ``bufsize`` or\n        ``universal_newlines``.\n\n    Returns a subprocess transport and engine protocol pair.\n    \"\"\"\n    transport, protocol = await UciProtocol.popen(command, setpgrp=setpgrp, loop=loop, **popen_args)\n    try:\n        await protocol.initialize()\n    except:\n        transport.close()\n        raise\n    return transport, protocol"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def popen_xboard(command: Union[str, List[str]], *, setpgrp: bool = False, **popen_args: Any) -> Tuple[asyncio.SubprocessTransport, XBoardProtocol]:\n    transport, protocol = await XBoardProtocol.popen(command, setpgrp=setpgrp, **popen_args)\n    try:\n        await protocol.initialize()\n    except:\n        transport.close()\n        raise\n    return transport, protocol", "response": "Spawns and initializes an XBoard engine."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the score from the point of view of the given color.", "response": "def pov(self, color: chess.Color) -> \"Score\":\n        \"\"\"Get the score from the point of view of the given *color*.\"\"\"\n        return self.relative if self.turn == color else -self.relative"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def play(self, board: chess.Board, limit: Limit, *, game: object = None, info: Info = INFO_NONE, ponder: bool = False, root_moves: Optional[Iterable[chess.Move]] = None, options: ConfigMapping = {}) -> PlayResult:", "response": "Play a position.\n\n        :param board: The position. The entire move stack will be sent to the\n            engine.\n        :param limit: An instance of :class:`chess.engine.Limit` that\n            determines when to stop thinking.\n        :param game: Optional. An arbitrary object that identifies the game.\n            Will automatically inform the engine if the object is not equal\n            to the previous game (e.g. ``ucinewgame``, ``new``).\n        :param info: Selects which additional information to retrieve from the\n            engine. ``INFO_NONE``, ``INFO_BASE`` (basic information that is\n            trivial to obtain), ``INFO_SCORE``, ``INFO_PV``,\n            ``INFO_REFUTATION``, ``INFO_CURRLINE``, ``INFO_ALL`` or any\n            bitwise combination. Some overhead is associated with parsing\n            extra information.\n        :param ponder: Whether the engine should keep analysing in the\n            background even after the result has been returned.\n        :param root_moves: Optional. Consider only root moves from this list.\n        :param options: Optional. A dictionary of engine options for the\n            analysis. The previous configuration will be restored after the\n            analysis is complete. You can permanently apply a configuration\n            with :func:`~chess.engine.EngineProtocol.configure()`."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nanalyse a position and returns a dictionary of info.", "response": "async def analyse(self, board: chess.Board, limit: Limit, *, multipv: Optional[int] = None, game: object = None, info: Info = INFO_ALL, root_moves: Optional[Iterable[chess.Move]] = None, options: ConfigMapping = {}) -> Union[List[InfoDict], InfoDict]:\n        \"\"\"\n        Analyses a position and returns a dictionary of\n        `information <#chess.engine.PlayResult.info>`_.\n\n        :param board: The position to analyse. The entire move stack will be\n            sent to the engine.\n        :param limit: An instance of :class:`chess.engine.Limit` that\n            determines when to stop the analysis.\n        :param multipv: Optional. Analyse multiple root moves. Will return a list of\n            at most *multipv* dictionaries rather than just a single\n            info dictionary.\n        :param game: Optional. An arbitrary object that identifies the game.\n            Will automatically inform the engine if the object is not equal\n            to the previous game (e.g. ``ucinewgame``, ``new``).\n        :param info: Selects which information to retrieve from the\n            engine. ``INFO_NONE``, ``INFO_BASE`` (basic information that is\n            trivial to obtain), ``INFO_SCORE``, ``INFO_PV``,\n            ``INFO_REFUTATION``, ``INFO_CURRLINE``, ``INFO_ALL`` or any\n            bitwise combination. Some overhead is associated with parsing\n            extra information.\n        :param root_moves: Optional. Limit analysis to a list of root moves.\n        :param options: Optional. A dictionary of engine options for the\n            analysis. The previous configuration will be restored after the\n            analysis is complete. You can permanently apply a configuration\n            with :func:`~chess.engine.EngineProtocol.configure()`.\n        \"\"\"\n        analysis = await self.analysis(board, limit, multipv=multipv, game=game, info=info, root_moves=root_moves, options=options)\n\n        with analysis:\n            await analysis.wait()\n\n        return analysis.info if multipv is None else analysis.multipv"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nstart analysing a position. :param board: The position to analyse. The entire move stack will be sent to the engine. :param limit: Optional. An instance of :class:`chess.engine.Limit` that determines when to stop the analysis. Analysis is infinite by default. :param multipv: Optional. Analyse multiple root moves. :param game: Optional. An arbitrary object that identifies the game. Will automatically inform the engine if the object is not equal to the previous game (e.g. ``ucinewgame``, ``new``). :param info: Selects which information to retrieve from the engine. ``INFO_NONE``, ``INFO_BASE`` (basic information that is trivial to obtain), ``INFO_SCORE``, ``INFO_PV``, ``INFO_REFUTATION``, ``INFO_CURRLINE``, ``INFO_ALL`` or any bitwise combination. Some overhead is associated with parsing extra information. :param root_moves: Optional. Limit analysis to a list of root moves. :param options: Optional. A dictionary of engine options for the analysis. The previous configuration will be restored after the analysis is complete. You can permanently apply a configuration with :func:`~chess.engine.EngineProtocol.configure()`. Returns :class:`~chess.engine.AnalysisResult`, a handle that allows asynchronously iterating over the information sent by the engine and stopping the the analysis at any time.", "response": "async def analysis(self, board: chess.Board, limit: Optional[Limit] = None, *, multipv: Optional[int] = None, game: object = None, info: Info = INFO_ALL, root_moves: Optional[Iterable[chess.Move]] = None, options: ConfigMapping = {}) -> \"AnalysisResult\":\n        \"\"\"\n        Starts analysing a position.\n\n        :param board: The position to analyse. The entire move stack will be\n            sent to the engine.\n        :param limit: Optional. An instance of :class:`chess.engine.Limit`\n            that determines when to stop the analysis. Analysis is infinite\n            by default.\n        :param multipv: Optional. Analyse multiple root moves.\n        :param game: Optional. An arbitrary object that identifies the game.\n            Will automatically inform the engine if the object is not equal\n            to the previous game (e.g. ``ucinewgame``, ``new``).\n        :param info: Selects which information to retrieve from the\n            engine. ``INFO_NONE``, ``INFO_BASE`` (basic information that is\n            trivial to obtain), ``INFO_SCORE``, ``INFO_PV``,\n            ``INFO_REFUTATION``, ``INFO_CURRLINE``, ``INFO_ALL`` or any\n            bitwise combination. Some overhead is associated with parsing\n            extra information.\n        :param root_moves: Optional. Limit analysis to a list of root moves.\n        :param options: Optional. A dictionary of engine options for the\n            analysis. The previous configuration will be restored after the\n            analysis is complete. You can permanently apply a configuration\n            with :func:`~chess.engine.EngineProtocol.configure()`.\n\n        Returns :class:`~chess.engine.AnalysisResult`, a handle that allows\n        asynchronously iterating over the information sent by the engine\n        and stopping the the analysis at any time.\n        \"\"\""}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nswitching debug mode of the engine on or off.", "response": "def debug(self, on: bool = True) -> None:\n        \"\"\"\n        Switches debug mode of the engine on or off. This does not interrupt\n        other ongoing operations.\n        \"\"\"\n        if on:\n            self.send_line(\"debug on\")\n        else:\n            self.send_line(\"debug off\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nstop the analysis as soon as possible.", "response": "def stop(self) -> None:\n        \"\"\"Stops the analysis as soon as possible.\"\"\"\n        if self._stop and not self._posted_kork:\n            self._stop()\n            self._stop = None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the next dictionary of information from the engine and raises an exception if none is available.", "response": "async def get(self) -> InfoDict:\n        \"\"\"\n        Waits for the next dictionary of information from the engine and\n        returns it.\n\n        It might be more convenient to use ``async for info in analysis: ...``.\n\n        :raises: :exc:`chess.engine.AnalysisComplete` if the analysis is\n            complete (or has been stopped) and all information has been\n            consumed. Use :func:`~chess.engine.AnalysisResult.next()` if you\n            prefer to get ``None`` instead of an exception.\n        \"\"\"\n        if self._seen_kork:\n            raise AnalysisComplete()\n\n        info = await self._queue.get()\n        if not info:\n            # Empty dictionary marks end.\n            self._seen_kork = True\n            await self._finished\n            raise AnalysisComplete()\n\n        return info"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if the queue is empty.", "response": "def empty(self) -> bool:\n        \"\"\"\n        Checks if all information has been consumed.\n\n        If the queue is empty, but the analysis is still ongoing, then further\n        information can become available in the future.\n\n        If the queue is not empty, then the next call to\n        :func:`~chess.engine.AnalysisResult.get()` will return instantly.\n        \"\"\"\n        return self._seen_kork or self._queue.qsize() <= self._posted_kork"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef close(self) -> None:\n        def _shutdown() -> None:\n            self.transport.close()\n            self.shutdown_event.set()\n\n        with self._shutdown_lock:\n            if not self._shutdown:\n                self._shutdown = True\n                self.protocol.loop.call_soon_threadsafe(_shutdown)", "response": "Closes the transport and the background event loop as soon as possible."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nspawns and initializes an UCI engine.", "response": "def popen_uci(cls, command: Union[str, List[str]], *, timeout: Optional[float] = 10.0, debug: bool = False, setpgrp: bool = False, **popen_args: Any) -> \"SimpleEngine\":\n        \"\"\"\n        Spawns and initializes an UCI engine.\n        Returns a :class:`~chess.engine.SimpleEngine` instance.\n        \"\"\"\n        return cls.popen(UciProtocol, command, timeout=timeout, debug=debug, setpgrp=setpgrp, **popen_args)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nspawn and initializes an XBoard engine.", "response": "def popen_xboard(cls, command: Union[str, List[str]], *, timeout: Optional[float] = 10.0, debug: bool = False, setpgrp: bool = False, **popen_args: Any) -> \"SimpleEngine\":\n        \"\"\"\n        Spawns and initializes an XBoard engine.\n        Returns a :class:`~chess.engine.SimpleEngine` instance.\n        \"\"\"\n        return cls.popen(XBoardProtocol, command, timeout=timeout, debug=debug, setpgrp=setpgrp, **popen_args)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the given piece as an SVG image.", "response": "def piece(piece: chess.Piece, size: Optional[int] = None) -> str:\n    \"\"\"\n    Renders the given :class:`chess.Piece` as an SVG image.\n\n    >>> import chess\n    >>> import chess.svg\n    >>>\n    >>> chess.svg.piece(chess.Piece.from_symbol(\"R\"))  # doctest: +SKIP\n\n    .. image:: ../docs/wR.svg\n    \"\"\"\n    svg = _svg(SQUARE_SIZE, size)\n    svg.append(ET.fromstring(PIECES[piece.symbol()]))\n    return SvgWrapper(ET.tostring(svg).decode(\"utf-8\"))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef board(board: Optional[chess.BaseBoard] = None, *,\n          squares: Optional[chess.IntoSquareSet] = None,\n          flipped: bool = False,\n          coordinates: bool = True,\n          lastmove: Optional[chess.Move] = None,\n          check: Optional[chess.Square] = None,\n          arrows: Iterable[Union[Arrow, Tuple[chess.Square, chess.Square]]] = (),\n          size: Optional[int] = None,\n          style: Optional[str] = None) -> str:\n    \"\"\"\n    Renders a board with pieces and/or selected squares as an SVG image.\n\n    :param board: A :class:`chess.BaseBoard` for a chessboard with pieces or\n        ``None`` (the default) for a chessboard without pieces.\n    :param squares: A :class:`chess.SquareSet` with selected squares.\n    :param flipped: Pass ``True`` to flip the board.\n    :param coordinates: Pass ``False`` to disable coordinates in the margin.\n    :param lastmove: A :class:`chess.Move` to be highlighted.\n    :param check: A square to be marked as check.\n    :param arrows: A list of :class:`~chess.svg.Arrow` objects like\n        ``[chess.svg.Arrow(chess.E2, chess.E4)]`` or a list of tuples like\n        ``[(chess.E2, chess.E4)]``. An arrow from a square pointing to the same\n        square is drawn as a circle, like ``[(chess.E2, chess.E2)]``.\n    :param size: The size of the image in pixels (e.g., ``400`` for a 400 by\n        400 board) or ``None`` (the default) for no size limit.\n    :param style: A CSS stylesheet to include in the SVG image.\n\n    >>> import chess\n    >>> import chess.svg\n    >>>\n    >>> board = chess.Board(\"8/8/8/8/4N3/8/8/8 w - - 0 1\")\n    >>> squares = board.attacks(chess.E4)\n    >>> chess.svg.board(board=board, squares=squares)  # doctest: +SKIP\n\n    .. image:: ../docs/Ne4.svg\n    \"\"\"\n    margin = MARGIN if coordinates else 0\n    svg = _svg(8 * SQUARE_SIZE + 2 * margin, size)\n\n    if style:\n        ET.SubElement(svg, \"style\").text = style\n\n    defs = ET.SubElement(svg, \"defs\")\n    if board:\n        for piece_color in chess.COLORS:\n            for piece_type in chess.PIECE_TYPES:\n                if board.pieces_mask(piece_type, piece_color):\n                    defs.append(ET.fromstring(PIECES[chess.Piece(piece_type, piece_color).symbol()]))\n\n    squares = chess.SquareSet(squares) if squares else chess.SquareSet()\n    if squares:\n        defs.append(ET.fromstring(XX))\n\n    if check is not None:\n        defs.append(ET.fromstring(CHECK_GRADIENT))\n\n    for square, bb in enumerate(chess.BB_SQUARES):\n        file_index = chess.square_file(square)\n        rank_index = chess.square_rank(square)\n\n        x = (file_index if not flipped else 7 - file_index) * SQUARE_SIZE + margin\n        y = (7 - rank_index if not flipped else rank_index) * SQUARE_SIZE + margin\n\n        cls = [\"square\", \"light\" if chess.BB_LIGHT_SQUARES & bb else \"dark\"]\n        if lastmove and square in [lastmove.from_square, lastmove.to_square]:\n            cls.append(\"lastmove\")\n        fill_color = DEFAULT_COLORS[\" \".join(cls)]\n\n        cls.append(chess.SQUARE_NAMES[square])\n\n        ET.SubElement(svg, \"rect\", {\n            \"x\": str(x),\n            \"y\": str(y),\n            \"width\": str(SQUARE_SIZE),\n            \"height\": str(SQUARE_SIZE),\n            \"class\": \" \".join(cls),\n            \"stroke\": \"none\",\n            \"fill\": fill_color,\n        })\n\n        if square == check:\n            ET.SubElement(svg, \"rect\", {\n                \"x\": str(x),\n                \"y\": str(y),\n                \"width\": str(SQUARE_SIZE),\n                \"height\": str(SQUARE_SIZE),\n                \"class\": \"check\",\n                \"fill\": \"url(#check_gradient)\",\n            })\n\n        # Render pieces.\n        if board is not None:\n            piece = board.piece_at(square)\n            if piece:\n                ET.SubElement(svg, \"use\", {\n                    \"xlink:href\": \"#{}-{}\".format(chess.COLOR_NAMES[piece.color], chess.PIECE_NAMES[piece.piece_type]),\n                    \"transform\": \"translate({:d}, {:d})\".format(x, y),\n                })\n\n        # Render selected squares.\n        if squares is not None and square in squares:\n            ET.SubElement(svg, \"use\", {\n                \"xlink:href\": \"#xx\",\n                \"x\": str(x),\n                \"y\": str(y),\n            })\n\n    if coordinates:\n        for file_index, file_name in enumerate(chess.FILE_NAMES):\n            x = (file_index if not flipped else 7 - file_index) * SQUARE_SIZE + margin\n            svg.append(_text(file_name, x, 0, SQUARE_SIZE, margin))\n            svg.append(_text(file_name, x, margin + 8 * SQUARE_SIZE, SQUARE_SIZE, margin))\n        for rank_index, rank_name in enumerate(chess.RANK_NAMES):\n            y = (7 - rank_index if not flipped else rank_index) * SQUARE_SIZE + margin\n            svg.append(_text(rank_name, 0, y, margin, SQUARE_SIZE))\n            svg.append(_text(rank_name, margin + 8 * SQUARE_SIZE, y, margin, SQUARE_SIZE))\n\n    for arrow in arrows:\n        try:\n            tail, head, color = arrow.tail, arrow.head, arrow.color  # type: ignore\n        except AttributeError:\n            tail, head = arrow  # type: ignore\n            color = \"#888\"\n\n        tail_file = chess.square_file(tail)\n        tail_rank = chess.square_rank(tail)\n        head_file = chess.square_file(head)\n        head_rank = chess.square_rank(head)\n\n        xtail = margin + (tail_file + 0.5 if not flipped else 7.5 - tail_file) * SQUARE_SIZE\n        ytail = margin + (7.5 - tail_rank if not flipped else tail_rank + 0.5) * SQUARE_SIZE\n        xhead = margin + (head_file + 0.5 if not flipped else 7.5 - head_file) * SQUARE_SIZE\n        yhead = margin + (7.5 - head_rank if not flipped else head_rank + 0.5) * SQUARE_SIZE\n\n        if (head_file, head_rank) == (tail_file, tail_rank):\n            ET.SubElement(svg, \"circle\", {\n                \"cx\": str(xhead),\n                \"cy\": str(yhead),\n                \"r\": str(SQUARE_SIZE * 0.9 / 2),\n                \"stroke-width\": str(SQUARE_SIZE * 0.1),\n                \"stroke\": color,\n                \"fill\": \"none\",\n                \"opacity\": \"0.5\",\n            })\n        else:\n            marker_size = 0.75 * SQUARE_SIZE\n            marker_margin = 0.1 * SQUARE_SIZE\n\n            dx, dy = xhead - xtail, yhead - ytail\n            hypot = math.hypot(dx, dy)\n\n            shaft_x = xhead - dx * (marker_size + marker_margin) / hypot\n            shaft_y = yhead - dy * (marker_size + marker_margin) / hypot\n\n            xtip = xhead - dx * marker_margin / hypot\n            ytip = yhead - dy * marker_margin / hypot\n\n            ET.SubElement(svg, \"line\", {\n                \"x1\": str(xtail),\n                \"y1\": str(ytail),\n                \"x2\": str(shaft_x),\n                \"y2\": str(shaft_y),\n                \"stroke\": color,\n                \"stroke-width\": str(SQUARE_SIZE * 0.2),\n                \"opacity\": \"0.5\",\n                \"stroke-linecap\": \"butt\",\n                \"class\": \"arrow\",\n            })\n\n            marker = [(xtip, ytip),\n                      (shaft_x + dy * 0.5 * marker_size / hypot,\n                       shaft_y - dx * 0.5 * marker_size / hypot),\n                      (shaft_x - dy * 0.5 * marker_size / hypot,\n                       shaft_y + dx * 0.5 * marker_size / hypot)]\n\n            ET.SubElement(svg, \"polygon\", {\n                \"points\": \" \".join(str(x) + \",\" + str(y) for x, y in marker),\n                \"fill\": color,\n                \"opacity\": \"0.5\",\n                \"class\": \"arrow\",\n            })\n\n    return SvgWrapper(ET.tostring(svg).decode(\"utf-8\"))", "response": "Returns a chess. BaseBoard with pieces and selected squares and selected arrows drawn as SVG images."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef open_tablebase_native(directory: PathLike, *, libgtb: Any = None, LibraryLoader: Any = ctypes.cdll) -> NativeTablebase:\n    libgtb = libgtb or ctypes.util.find_library(\"gtb\") or \"libgtb.so.1.0.1\"\n    tables = NativeTablebase(LibraryLoader.LoadLibrary(libgtb))\n    tables.add_directory(directory)\n    return tables", "response": "Opens a collection of tables for probing using libgtb."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nopens a collection of tables for probing.", "response": "def open_tablebase(directory: PathLike, *, libgtb: Any = None, LibraryLoader: Any = ctypes.cdll) -> Union[NativeTablebase, PythonTablebase]:\n    \"\"\"\n    Opens a collection of tables for probing.\n\n    First native access via the shared library libgtb is tried. You can\n    optionally provide a specific library name or a library loader.\n    The shared library has global state and caches, so only one instance can\n    be open at a time.\n\n    Second, pure Python probing code is tried.\n    \"\"\"\n    try:\n        if LibraryLoader:\n            return open_tablebase_native(directory, libgtb=libgtb, LibraryLoader=LibraryLoader)\n    except (OSError, RuntimeError) as err:\n        LOGGER.info(\"Falling back to pure Python tablebase: %r\", err)\n\n    tables = PythonTablebase()\n    tables.add_directory(directory)\n    return tables"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_directory(self, directory: PathLike) -> None:\n        directory = os.path.abspath(directory)\n        if not os.path.isdir(directory):\n            raise IOError(\"not a directory: {!r}\".format(directory))\n\n        for tbfile in fnmatch.filter(os.listdir(directory), \"*.gtb.cp4\"):\n            self.available_tables[os.path.basename(tbfile).replace(\".gtb.cp4\", \"\")] = os.path.join(directory, tbfile)", "response": "Adds all. gtb. cp4 files from a directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef probe_dtm(self, board: chess.Board) -> int:\n        # Can not probe positions with castling rights.\n        if board.castling_rights:\n            raise KeyError(\"gaviota tables do not contain positions with castling rights: {}\".format(board.fen()))\n\n        # Supports only up to 5 pieces.\n        if chess.popcount(board.occupied) > 5:\n            raise KeyError(\"gaviota tables support up to 5 pieces, not {}: {}\".format(chess.popcount(board.occupied), board.fen()))\n\n        # KvK is a draw.\n        if board.occupied == board.kings:\n            return 0\n\n        # Prepare the tablebase request.\n        white_squares = list(chess.SquareSet(board.occupied_co[chess.WHITE]))\n        white_types = [typing.cast(chess.PieceType, board.piece_type_at(sq)) for sq in white_squares]\n        black_squares = list(chess.SquareSet(board.occupied_co[chess.BLACK]))\n        black_types = [typing.cast(chess.PieceType, board.piece_type_at(sq)) for sq in black_squares]\n        side = 0 if (board.turn == chess.WHITE) else 1\n        epsq = board.ep_square if board.ep_square else NOSQUARE\n        req = Request(white_squares, white_types, black_squares, black_types, side, epsq)\n\n        # Probe.\n        dtm = self.egtb_get_dtm(req)\n        ply, res = unpackdist(dtm)\n\n        if res == iWMATE:\n            # White mates in the stored position.\n            if req.realside == 1:\n                if req.is_reversed:\n                    return ply\n                else:\n                    return -ply\n            else:\n                if req.is_reversed:\n                    return -ply\n                else:\n                    return ply\n        elif res == iBMATE:\n            # Black mates in the stored position.\n            if req.realside == 0:\n                if req.is_reversed:\n                    return ply\n                else:\n                    return -ply\n            else:\n                if req.is_reversed:\n                    return -ply\n                else:\n                    return ply\n        else:\n            # Draw.\n            return 0", "response": "Probes for depth to mate information."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nprobing for win - draw loss - information.", "response": "def probe_wdl(self, board: chess.Board) -> int:\n        \"\"\"\n        Probes for win/draw/loss-information.\n\n        Returns ``1`` if the side to move is winning, ``0`` if it is a draw,\n        and ``-1`` if the side to move is losing.\n\n        >>> import chess\n        >>> import chess.gaviota\n        >>>\n        >>> with chess.gaviota.open_tablebase(\"data/gaviota\") as tablebase:\n        ...     board = chess.Board(\"8/4k3/8/B7/8/8/8/4K3 w - - 0 1\")\n        ...     print(tablebase.probe_wdl(board))\n        ...\n        0\n\n        :raises: :exc:`KeyError` (or specifically\n            :exc:`chess.gaviota.MissingTableError`) if the probe fails. Use\n            :func:`~chess.gaviota.PythonTablebase.get_wdl()` if you prefer\n            to get ``None`` instead of an exception.\n\n            Note that probing a corrupted table file is undefined behavior.\n        \"\"\"\n        dtm = self.probe_dtm(board)\n\n        if dtm == 0:\n            if board.is_checkmate():\n                return -1\n            else:\n                return 0\n        elif dtm > 0:\n            return 1\n        else:\n            return -1"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef close(self) -> None:\n        self.available_tables.clear()\n\n        self.zipinfo.clear()\n\n        self.block_age = 0\n        self.block_cache.clear()\n\n        while self.streams:\n            _, stream = self.streams.popitem()\n            stream.close()", "response": "Closes all loaded tables."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef square_distance(a: Square, b: Square) -> int:\n    return max(abs(square_file(a) - square_file(b)), abs(square_rank(a) - square_rank(b)))", "response": "Gets the distance between two kingsheets."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the symbol for white and black pieces.", "response": "def symbol(self) -> str:\n        \"\"\"\n        Gets the symbol ``P``, ``N``, ``B``, ``R``, ``Q`` or ``K`` for white\n        pieces or the lower-case variants for the black pieces.\n        \"\"\"\n        symbol = piece_symbol(self.piece_type)\n        return symbol.upper() if self.color else symbol"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef unicode_symbol(self, *, invert_color: bool = False) -> str:\n        symbol = self.symbol().swapcase() if invert_color else self.symbol()\n        return UNICODE_PIECE_SYMBOLS[symbol]", "response": "Gets the Unicode character for the piece."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_symbol(cls, symbol: str) -> \"Piece\":\n        return cls(PIECE_SYMBOLS.index(symbol.lower()), symbol.isupper())", "response": "Creates a piece instance from a piece symbol."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef uci(self) -> str:\n        if self.drop:\n            return piece_symbol(self.drop).upper() + \"@\" + SQUARE_NAMES[self.to_square]\n        elif self.promotion:\n            return SQUARE_NAMES[self.from_square] + SQUARE_NAMES[self.to_square] + piece_symbol(self.promotion)\n        elif self:\n            return SQUARE_NAMES[self.from_square] + SQUARE_NAMES[self.to_square]\n        else:\n            return \"0000\"", "response": "Gets an UCI string for the current move."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse an UCI string and returns a Move object.", "response": "def from_uci(cls, uci: str) -> \"Move\":\n        \"\"\"\n        Parses an UCI string.\n\n        :raises: :exc:`ValueError` if the UCI string is invalid.\n        \"\"\"\n        if uci == \"0000\":\n            return cls.null()\n        elif len(uci) == 4 and \"@\" == uci[1]:\n            drop = PIECE_SYMBOLS.index(uci[0].lower())\n            square = SQUARE_NAMES.index(uci[2:])\n            return cls(square, square, drop=drop)\n        elif len(uci) == 4:\n            return cls(SQUARE_NAMES.index(uci[0:2]), SQUARE_NAMES.index(uci[2:4]))\n        elif len(uci) == 5:\n            promotion = PIECE_SYMBOLS.index(uci[4])\n            return cls(SQUARE_NAMES.index(uci[0:2]), SQUARE_NAMES.index(uci[2:4]), promotion=promotion)\n        else:\n            raise ValueError(\"expected uci string to be of length 4 or 5: {!r}\".format(uci))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a set of squares of the given type and color.", "response": "def pieces(self, piece_type: PieceType, color: Color) -> \"SquareSet\":\n        \"\"\"\n        Gets pieces of the given type and color.\n\n        Returns a :class:`set of squares <chess.SquareSet>`.\n        \"\"\"\n        return SquareSet(self.pieces_mask(piece_type, color))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the piece at the given square.", "response": "def piece_at(self, square: Square) -> Optional[Piece]:\n        \"\"\"Gets the :class:`piece <chess.Piece>` at the given square.\"\"\"\n        piece_type = self.piece_type_at(square)\n        if piece_type:\n            mask = BB_SQUARES[square]\n            color = bool(self.occupied_co[WHITE] & mask)\n            return Piece(piece_type, color)\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef piece_type_at(self, square: Square) -> Optional[PieceType]:\n        mask = BB_SQUARES[square]\n\n        if not self.occupied & mask:\n            return None  # Early return\n        elif self.pawns & mask:\n            return PAWN\n        elif self.knights & mask:\n            return KNIGHT\n        elif self.bishops & mask:\n            return BISHOP\n        elif self.rooks & mask:\n            return ROOK\n        elif self.queens & mask:\n            return QUEEN\n        else:\n            return KING", "response": "Gets the piece type at the given square."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfind the king square of the given color. Returns None if there is no king of that color.", "response": "def king(self, color: Color) -> Optional[Square]:\n        \"\"\"\n        Finds the king square of the given side. Returns ``None`` if there\n        is no king of that color.\n\n        In variants with king promotions, only non-promoted kings are\n        considered.\n        \"\"\"\n        king_mask = self.occupied_co[color] & self.kings & ~self.promoted\n        return msb(king_mask) if king_mask else None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_attacked_by(self, color: Color, square: Square) -> bool:\n        return bool(self.attackers_mask(color, square))", "response": "Checks if the given side attacks the given square."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef attackers(self, color: Color, square: Square) -> \"SquareSet\":\n        return SquareSet(self.attackers_mask(color, square))", "response": "Gets a set of attackers of the given color for the given square."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pin(self, color: Color, square: Square) -> \"SquareSet\":\n        return SquareSet(self.pin_mask(color, square))", "response": "Returns a set of squares that are pinned to the given color."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndetermining if the given square is pinned to the king of the given color.", "response": "def is_pinned(self, color: Color, square: Square) -> bool:\n        \"\"\"\n        Detects if the given square is pinned to the king of the given color.\n        \"\"\"\n        return self.pin_mask(color, square) != BB_ALL"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef remove_piece_at(self, square: Square) -> Optional[Piece]:\n        color = bool(self.occupied_co[WHITE] & BB_SQUARES[square])\n        piece_type = self._remove_piece_at(square)\n        return Piece(piece_type, color) if piece_type else None", "response": "Removes the piece from the given square. Returns None if the piece is not present."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting a piece at the given square.", "response": "def set_piece_at(self, square: Square, piece: Optional[Piece], promoted: bool = False) -> None:\n        \"\"\"\n        Sets a piece at the given square.\n\n        An existing piece is replaced. Setting *piece* to ``None`` is\n        equivalent to :func:`~chess.Board.remove_piece_at()`.\n        \"\"\"\n        if piece is None:\n            self._remove_piece_at(square)\n        else:\n            self._set_piece_at(square, piece.piece_type, piece.color, promoted)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef board_fen(self, *, promoted: Optional[bool] = False) -> str:\n        builder = []\n        empty = 0\n\n        for square in SQUARES_180:\n            piece = self.piece_at(square)\n\n            if not piece:\n                empty += 1\n            else:\n                if empty:\n                    builder.append(str(empty))\n                    empty = 0\n                builder.append(piece.symbol())\n                if promoted and BB_SQUARES[square] & self.promoted:\n                    builder.append(\"~\")\n\n            if BB_SQUARES[square] & BB_FILE_H:\n                if empty:\n                    builder.append(str(empty))\n                    empty = 0\n\n                if square != H1:\n                    builder.append(\"/\")\n\n        return \"\".join(builder)", "response": "Gets the board FEN."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef piece_map(self) -> Dict[Square, Piece]:\n        result = {}\n        for square in scan_reversed(self.occupied):\n            result[square] = typing.cast(Piece, self.piece_at(square))\n        return result", "response": "Gets a dictionary of pieces by square index."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef chess960_pos(self) -> Optional[int]:\n        if self.occupied_co[WHITE] != BB_RANK_1 | BB_RANK_2:\n            return None\n        if self.occupied_co[BLACK] != BB_RANK_7 | BB_RANK_8:\n            return None\n        if self.pawns != BB_RANK_2 | BB_RANK_7:\n            return None\n        if self.promoted:\n            return None\n\n        # Piece counts.\n        brnqk = [self.bishops, self.rooks, self.knights, self.queens, self.kings]\n        if [popcount(pieces) for pieces in brnqk] != [4, 4, 4, 2, 2]:\n            return None\n\n        # Symmetry.\n        if any((BB_RANK_1 & pieces) << 56 != BB_RANK_8 & pieces for pieces in brnqk):\n            return None\n\n        # Algorithm from ChessX, src/database/bitboard.cpp, r2254.\n        x = self.bishops & (2 + 8 + 32 + 128)\n        if not x:\n            return None\n        bs1 = (lsb(x) - 1) // 2\n        cc_pos = bs1\n        x = self.bishops & (1 + 4 + 16 + 64)\n        if not x:\n            return None\n        bs2 = lsb(x) * 2\n        cc_pos += bs2\n\n        q = 0\n        qf = False\n        n0 = 0\n        n1 = 0\n        n0f = False\n        n1f = False\n        rf = 0\n        n0s = [0, 4, 7, 9]\n        for square in range(A1, H1 + 1):\n            bb = BB_SQUARES[square]\n            if bb & self.queens:\n                qf = True\n            elif bb & self.rooks or bb & self.kings:\n                if bb & self.kings:\n                    if rf != 1:\n                        return None\n                else:\n                    rf += 1\n\n                if not qf:\n                    q += 1\n\n                if not n0f:\n                    n0 += 1\n                elif not n1f:\n                    n1 += 1\n            elif bb & self.knights:\n                if not qf:\n                    q += 1\n\n                if not n0f:\n                    n0f = True\n                elif not n1f:\n                    n1f = True\n\n        if n0 < 4 and n1f and qf:\n            cc_pos += q * 16\n            krn = n0s[n0] + n1\n            cc_pos += krn * 96\n            return cc_pos\n        else:\n            return None", "response": "Gets the Chess960 starting position index between 0 and 959."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef unicode(self, *, invert_color: bool = False, borders: bool = False) -> str:\n        builder = []\n        for rank_index in range(7, -1, -1):\n            if borders:\n                builder.append(\"  \")\n                builder.append(\"-\" * 17)\n                builder.append(\"\\n\")\n\n                builder.append(RANK_NAMES[rank_index])\n                builder.append(\" \")\n\n            for file_index in range(8):\n                square_index = square(file_index, rank_index)\n\n                if borders:\n                    builder.append(\"|\")\n                elif file_index > 0:\n                    builder.append(\" \")\n\n                piece = self.piece_at(square_index)\n\n                if piece:\n                    builder.append(piece.unicode_symbol(invert_color=invert_color))\n                else:\n                    builder.append(u\"\u00b7\")\n\n            if borders:\n                builder.append(\"|\")\n\n            if borders or rank_index > 0:\n                builder.append(\"\\n\")\n\n        if borders:\n            builder.append(\"  \")\n            builder.append(\"-\" * 17)\n            builder.append(\"\\n\")\n            builder.append(\"   a b c d e f g h\")\n\n        return \"\".join(builder)", "response": "Returns a string representation of the board with Unicode pieces."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a mirrored copy of the board.", "response": "def mirror(self: BaseBoardT) -> BaseBoardT:\n        \"\"\"\n        Returns a mirrored copy of the board.\n\n        The board is mirrored vertically and piece colors are swapped, so that\n        the position is equivalent modulo color.\n        \"\"\"\n        board = self.transform(flip_vertical)\n        board.occupied_co[WHITE], board.occupied_co[BLACK] = board.occupied_co[BLACK], board.occupied_co[WHITE]\n        return board"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a copy of the board.", "response": "def copy(self: BaseBoardT) -> BaseBoardT:\n        \"\"\"Creates a copy of the board.\"\"\"\n        board = type(self)(None)\n\n        board.pawns = self.pawns\n        board.knights = self.knights\n        board.bishops = self.bishops\n        board.rooks = self.rooks\n        board.queens = self.queens\n        board.kings = self.kings\n\n        board.occupied_co[WHITE] = self.occupied_co[WHITE]\n        board.occupied_co[BLACK] = self.occupied_co[BLACK]\n        board.occupied = self.occupied\n        board.promoted = self.promoted\n\n        return board"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new board initialized with a Chess960 starting position.", "response": "def from_chess960_pos(cls: Type[BaseBoardT], sharnagl: int) -> BaseBoardT:\n        \"\"\"\n        Creates a new board, initialized with a Chess960 starting position.\n\n        >>> import chess\n        >>> import random\n        >>>\n        >>> board = chess.Board.from_chess960_pos(random.randint(0, 959))\n        \"\"\"\n        board = cls.empty()\n        board.set_chess960_pos(sharnagl)\n        return board"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrestoring the starting position.", "response": "def reset(self) -> None:\n        \"\"\"Restores the starting position.\"\"\"\n        self.turn = WHITE\n        self.castling_rights = BB_CORNERS\n        self.ep_square = None\n        self.halfmove_clock = 0\n        self.fullmove_number = 1\n\n        self.reset_board()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nclears the board. Resets move stack and move counters. The side to move is white. There are no rooks or kings, so castling rights are removed. In order to be in a valid :func:`~chess.Board.status()` at least kings need to be put on the board.", "response": "def clear(self) -> None:\n        \"\"\"\n        Clears the board.\n\n        Resets move stack and move counters. The side to move is white. There\n        are no rooks or kings, so castling rights are removed.\n\n        In order to be in a valid :func:`~chess.Board.status()` at least kings\n        need to be put on the board.\n        \"\"\"\n        self.turn = WHITE\n        self.castling_rights = BB_EMPTY\n        self.ep_square = None\n        self.halfmove_clock = 0\n        self.fullmove_number = 1\n\n        self.clear_board()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a copy of the root position.", "response": "def root(self: BoardT) -> BoardT:\n        \"\"\"Returns a copy of the root position.\"\"\"\n        if self._stack:\n            board = type(self)(None, chess960=self.chess960)\n            self._stack[0].restore(board)\n            return board\n        else:\n            return self.copy(stack=False)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns if the current side to move is in check.", "response": "def is_check(self) -> bool:\n        \"\"\"Returns if the current side to move is in check.\"\"\"\n        king = self.king(self.turn)\n        return king is not None and self.is_attacked_by(not self.turn, king)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_into_check(self, move: Move) -> bool:\n        king = self.king(self.turn)\n        if king is None:\n            return False\n\n        checkers = self.attackers_mask(not self.turn, king)\n        if checkers:\n            # If already in check, look if it is an evasion.\n            if move not in self._generate_evasions(king, checkers, BB_SQUARES[move.from_square], BB_SQUARES[move.to_square]):\n                return True\n\n        return not self._is_safe(king, self._slider_blockers(king), move)", "response": "Checks if the given move would leave the king in check or put it into check."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if the king of the other side is attacked.", "response": "def was_into_check(self) -> bool:\n        \"\"\"\n        Checks if the king of the other side is attacked. Such a position is not\n        valid and could only be reached by an illegal move.\n        \"\"\"\n        king = self.king(not self.turn)\n        return king is not None and self.is_attacked_by(self.turn, king)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the game result.", "response": "def result(self, *, claim_draw: bool = False) -> str:\n        \"\"\"\n        Gets the game result.\n\n        ``1-0``, ``0-1`` or ``1/2-1/2`` if the\n        :func:`game is over <chess.Board.is_game_over()>`. Otherwise, the\n        result is undetermined: ``*``.\n        \"\"\"\n        # Chess variant support.\n        if self.is_variant_loss():\n            return \"0-1\" if self.turn == WHITE else \"1-0\"\n        elif self.is_variant_win():\n            return \"1-0\" if self.turn == WHITE else \"0-1\"\n        elif self.is_variant_draw():\n            return \"1/2-1/2\"\n\n        # Checkmate.\n        if self.is_checkmate():\n            return \"0-1\" if self.turn == WHITE else \"1-0\"\n\n        # Draw claimed.\n        if claim_draw and self.can_claim_draw():\n            return \"1/2-1/2\"\n\n        # Seventyfive-move rule or fivefold repetition.\n        if self.is_seventyfive_moves() or self.is_fivefold_repetition():\n            return \"1/2-1/2\"\n\n        # Insufficient material.\n        if self.is_insufficient_material():\n            return \"1/2-1/2\"\n\n        # Stalemate.\n        if not any(self.generate_legal_moves()):\n            return \"1/2-1/2\"\n\n        # Undetermined.\n        return \"*\""}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_stalemate(self) -> bool:\n        if self.is_check():\n            return False\n\n        if self.is_variant_end():\n            return False\n\n        return not any(self.generate_legal_moves())", "response": "Checks if the current position is a stalemate."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef has_insufficient_material(self, color: Color) -> bool:\n        if self.occupied_co[color] & (self.pawns | self.rooks | self.queens):\n            return False\n\n        # Knights are only insufficient material if:\n        # (1) We do not have any other pieces, including more than one knight.\n        # (2) The opponent does not have pawns, knights, bishops or rooks.\n        #     These would allow self mate.\n        if self.occupied_co[color] & self.knights:\n            return (popcount(self.occupied_co[color]) <= 2 and\n                    not (self.occupied_co[not color] & ~self.kings & ~self.queens))\n\n        # Bishops are only insufficient material if:\n        # (1) We no dot have any other pieces, including bishops of the\n        #     opposite color.\n        # (2) The opponent does not have bishops of the opposite color,\n        #     pawns or knights. These would allow self mate.\n        if self.occupied_co[color] & self.bishops:\n            same_color = (not self.bishops & BB_DARK_SQUARES) or (not self.bishops & BB_LIGHT_SQUARES)\n            return same_color and not (self.occupied_co[not color] & ~self.kings & ~self.rooks & ~self.queens)\n\n        return True", "response": "Checks if the current game has insufficient winning material."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_seventyfive_moves(self) -> bool:\n        if self.halfmove_clock >= 150:\n            if any(self.generate_legal_moves()):\n                return True\n\n        return False", "response": "Returns True if there are seventyfive moves."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn True if there are 5 repetitions of the current game.", "response": "def is_fivefold_repetition(self) -> bool:\n        \"\"\"\n        Since the 1st of July 2014 a game is automatically drawn (without\n        a claim by one of the players) if a position occurs for the fifth time.\n        Originally this had to occur on consecutive alternating moves, but\n        this has since been revised.\n        \"\"\"\n        transposition_key = self._transposition_key()\n        repetitions = 1\n        switchyard = []\n\n        while self.move_stack and repetitions < 5:\n            move = self.pop()\n            switchyard.append(move)\n\n            if self.is_irreversible(move):\n                break\n\n            if self._transposition_key() == transposition_key:\n                repetitions += 1\n\n        while switchyard:\n            self.push(switchyard.pop())\n\n        return repetitions >= 5"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef can_claim_fifty_moves(self) -> bool:\n        # Fifty-move rule.\n        if self.halfmove_clock >= 100:\n            if any(self.generate_legal_moves()):\n                return True\n\n        return False", "response": "Return True if the fifty - move rule can be claimed."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning True if the game can claim a threefold repetition.", "response": "def can_claim_threefold_repetition(self) -> bool:\n        \"\"\"\n        Draw by threefold repetition can be claimed if the position on the\n        board occured for the third time or if such a repetition is reached\n        with one of the possible legal moves.\n\n        Note that checking this can be slow: In the worst case\n        scenario every legal move has to be tested and the entire game has to\n        be replayed because there is no incremental transposition table.\n        \"\"\"\n        transposition_key = self._transposition_key()\n        transpositions = collections.Counter()  # type: typing.Counter[Hashable]\n        transpositions.update((transposition_key, ))\n\n        # Count positions.\n        switchyard = []\n        while self.move_stack:\n            move = self.pop()\n            switchyard.append(move)\n\n            if self.is_irreversible(move):\n                break\n\n            transpositions.update((self._transposition_key(), ))\n\n        while switchyard:\n            self.push(switchyard.pop())\n\n        # Threefold repetition occured.\n        if transpositions[transposition_key] >= 3:\n            return True\n\n        # The next legal move is a threefold repetition.\n        for move in self.generate_legal_moves():\n            self.push(move)\n            try:\n                if transpositions[self._transposition_key()] >= 2:\n                    return True\n            finally:\n                self.pop()\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if the current position has repeated 3 times.", "response": "def is_repetition(self, count: int = 3) -> bool:\n        \"\"\"\n        Checks if the current position has repeated 3 (or a given number of)\n        times.\n\n        Unlike :func:`~chess.Board.can_claim_threefold_repetition()`,\n        this does not consider a repetition that can be played on the next\n        move.\n\n        Note that checking this can be slow: In the worst case the entire\n        game has to be replayed because there is no incremental transposition\n        table.\n        \"\"\"\n        transposition_key = self._transposition_key()\n        switchyard = []\n\n        try:\n            while True:\n                if count <= 1:\n                    return True\n\n                if not self.move_stack:\n                    break\n\n                move = self.pop()\n                switchyard.append(move)\n\n                if self.is_irreversible(move):\n                    break\n\n                if self._transposition_key() == transposition_key:\n                    count -= 1\n        finally:\n            while switchyard:\n                self.push(switchyard.pop())\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\npushes a move onto the board and returns the new entry in the board.", "response": "def push(self: BoardT, move: Move) -> None:\n        \"\"\"\n        Updates the position with the given move and puts it onto the\n        move stack.\n\n        >>> import chess\n        >>>\n        >>> board = chess.Board()\n        >>>\n        >>> Nf3 = chess.Move.from_uci(\"g1f3\")\n        >>> board.push(Nf3)  # Make the move\n\n        >>> board.pop()  # Unmake the last move\n        Move.from_uci('g1f3')\n\n        Null moves just increment the move counters, switch turns and forfeit\n        en passant capturing.\n\n        :warning: Moves are not checked for legality.\n        \"\"\"\n        # Push move and remember board state.\n        move = self._to_chess960(move)\n        self.move_stack.append(self._from_chess960(self.chess960, move.from_square, move.to_square, move.promotion, move.drop))\n        self._stack.append(self._board_state())\n\n        # Reset en passant square.\n        ep_square = self.ep_square\n        self.ep_square = None\n\n        # Increment move counters.\n        self.halfmove_clock += 1\n        if self.turn == BLACK:\n            self.fullmove_number += 1\n\n        # On a null move, simply swap turns and reset the en passant square.\n        if not move:\n            self.turn = not self.turn\n            return\n\n        # Drops.\n        if move.drop:\n            self._set_piece_at(move.to_square, move.drop, self.turn)\n            self.turn = not self.turn\n            return\n\n        # Zero the half-move clock.\n        if self.is_zeroing(move):\n            self.halfmove_clock = 0\n\n        from_bb = BB_SQUARES[move.from_square]\n        to_bb = BB_SQUARES[move.to_square]\n\n        promoted = bool(self.promoted & from_bb)\n        piece_type = self._remove_piece_at(move.from_square)\n        assert piece_type is not None, \"push() expects move to be pseudo-legal, but got {} in {}\".format(move, self.fen())\n        capture_square = move.to_square\n        captured_piece_type = self.piece_type_at(capture_square)\n\n        # Update castling rights.\n        self.castling_rights = self.clean_castling_rights() & ~to_bb & ~from_bb\n        if piece_type == KING and not promoted:\n            if self.turn == WHITE:\n                self.castling_rights &= ~BB_RANK_1\n            else:\n                self.castling_rights &= ~BB_RANK_8\n        elif captured_piece_type == KING and not self.promoted & to_bb:\n            if self.turn == WHITE and square_rank(move.to_square) == 7:\n                self.castling_rights &= ~BB_RANK_8\n            elif self.turn == BLACK and square_rank(move.to_square) == 0:\n                self.castling_rights &= ~BB_RANK_1\n\n        # Handle special pawn moves.\n        if piece_type == PAWN:\n            diff = move.to_square - move.from_square\n\n            if diff == 16 and square_rank(move.from_square) == 1:\n                self.ep_square = move.from_square + 8\n            elif diff == -16 and square_rank(move.from_square) == 6:\n                self.ep_square = move.from_square - 8\n            elif move.to_square == ep_square and abs(diff) in [7, 9] and not captured_piece_type:\n                # Remove pawns captured en passant.\n                down = -8 if self.turn == WHITE else 8\n                capture_square = ep_square + down\n                captured_piece_type = self._remove_piece_at(capture_square)\n\n        # Promotion.\n        if move.promotion:\n            promoted = True\n            piece_type = move.promotion\n\n        # Castling.\n        castling = piece_type == KING and self.occupied_co[self.turn] & to_bb\n        if castling:\n            a_side = square_file(move.to_square) < square_file(move.from_square)\n\n            self._remove_piece_at(move.from_square)\n            self._remove_piece_at(move.to_square)\n\n            if a_side:\n                self._set_piece_at(C1 if self.turn == WHITE else C8, KING, self.turn)\n                self._set_piece_at(D1 if self.turn == WHITE else D8, ROOK, self.turn)\n            else:\n                self._set_piece_at(G1 if self.turn == WHITE else G8, KING, self.turn)\n                self._set_piece_at(F1 if self.turn == WHITE else F8, ROOK, self.turn)\n\n        # Put the piece on the target square.\n        if not castling:\n            was_promoted = bool(self.promoted & to_bb)\n            self._set_piece_at(move.to_square, piece_type, self.turn, promoted)\n\n            if captured_piece_type:\n                self._push_capture(move, capture_square, captured_piece_type, was_promoted)\n\n        # Swap turn.\n        self.turn = not self.turn"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pop(self: BoardT) -> Move:\n        move = self.move_stack.pop()\n        self._stack.pop().restore(self)\n        return move", "response": "Restores the previous position and returns the last move from the stack."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a FEN representation of the current position.", "response": "def fen(self, *, shredder: bool = False, en_passant: str = \"legal\", promoted: Optional[bool] = None) -> str:\n        \"\"\"\n        Gets a FEN representation of the position.\n\n        A FEN string (e.g.,\n        ``rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1``) consists\n        of the position part :func:`~chess.Board.board_fen()`, the\n        :data:`~chess.Board.turn`, the castling part\n        (:data:`~chess.Board.castling_rights`),\n        the en passant square (:data:`~chess.Board.ep_square`),\n        the :data:`~chess.Board.halfmove_clock`\n        and the :data:`~chess.Board.fullmove_number`.\n\n        :param shredder: Use :func:`~chess.Board.castling_shredder_fen()`\n            and encode castling rights by the file of the rook\n            (like ``HAha``) instead of the default\n            :func:`~chess.Board.castling_xfen()` (like ``KQkq``).\n        :param en_passant: By default, only fully legal en passant squares\n            are included (:func:`~chess.Board.has_legal_en_passant()`).\n            Pass ``fen`` to strictly follow the FEN specification\n            (always include the en passant square after a two-step pawn move)\n            or ``xfen`` to follow the X-FEN specification\n            (:func:`~chess.Board.has_pseudo_legal_en_passant()`).\n        :param promoted: Mark promoted pieces like ``Q~``. By default, this is\n            only enabled in chess variants where this is relevant.\n        \"\"\"\n        return \" \".join([\n            self.epd(shredder=shredder, en_passant=en_passant, promoted=promoted),\n            str(self.halfmove_clock),\n            str(self.fullmove_number)\n        ])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse a FEN string and sets the position of the current entry in the object.", "response": "def set_fen(self, fen: str) -> None:\n        \"\"\"\n        Parses a FEN and sets the position from it.\n\n        :raises: :exc:`ValueError` if the FEN string is invalid.\n        \"\"\"\n        parts = fen.split()\n\n        # Board part.\n        try:\n            board_part = parts.pop(0)\n        except IndexError:\n            raise ValueError(\"empty fen\")\n\n        # Turn.\n        try:\n            turn_part = parts.pop(0)\n        except IndexError:\n            turn = WHITE\n        else:\n            if turn_part == \"w\":\n                turn = WHITE\n            elif turn_part == \"b\":\n                turn = BLACK\n            else:\n                raise ValueError(\"expected 'w' or 'b' for turn part of fen: {!r}\".format(fen))\n\n        # Validate castling part.\n        try:\n            castling_part = parts.pop(0)\n        except IndexError:\n            castling_part = \"-\"\n        else:\n            if not FEN_CASTLING_REGEX.match(castling_part):\n                raise ValueError(\"invalid castling part in fen: {!r}\".format(fen))\n\n        # En passant square.\n        try:\n            ep_part = parts.pop(0)\n        except IndexError:\n            ep_square = None\n        else:\n            try:\n                ep_square = None if ep_part == \"-\" else SQUARE_NAMES.index(ep_part)\n            except ValueError:\n                raise ValueError(\"invalid en passant part in fen: {!r}\".format(fen))\n\n        # Check that the half-move part is valid.\n        try:\n            halfmove_part = parts.pop(0)\n        except IndexError:\n            halfmove_clock = 0\n        else:\n            try:\n                halfmove_clock = int(halfmove_part)\n            except ValueError:\n                raise ValueError(\"invalid half-move clock in fen: {!r}\".format(fen))\n\n            if halfmove_clock < 0:\n                raise ValueError(\"half-move clock cannot be negative: {!r}\".format(fen))\n\n        # Check that the full-move number part is valid.\n        # 0 is allowed for compability, but later replaced with 1.\n        try:\n            fullmove_part = parts.pop(0)\n        except IndexError:\n            fullmove_number = 1\n        else:\n            try:\n                fullmove_number = int(fullmove_part)\n            except ValueError:\n                raise ValueError(\"invalid fullmove number in fen: {!r}\".format(fen))\n\n            if fullmove_number < 0:\n                raise ValueError(\"fullmove number cannot be negative: {!r}\".format(fen))\n\n            fullmove_number = max(fullmove_number, 1)\n\n        # All parts should be consumed now.\n        if parts:\n            raise ValueError(\"fen string has more parts than expected: {!r}\".format(fen))\n\n        # Validate the board part and set it.\n        self._set_board_fen(board_part)\n\n        # Apply.\n        self.turn = turn\n        self._set_castling_fen(castling_part)\n        self.ep_square = ep_square\n        self.halfmove_clock = halfmove_clock\n        self.fullmove_number = fullmove_number\n        self.clear_stack()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef chess960_pos(self, *, ignore_turn: bool = False, ignore_castling: bool = False, ignore_counters: bool = True) -> Optional[int]:\n        if self.ep_square:\n            return None\n\n        if not ignore_turn:\n            if self.turn != WHITE:\n                return None\n\n        if not ignore_castling:\n            if self.clean_castling_rights() != self.rooks:\n                return None\n\n        if not ignore_counters:\n            if self.fullmove_number != 1 or self.halfmove_clock != 0:\n                return None\n\n        return super().chess960_pos()", "response": "Gets the Chess960 starting position index between 0 and 956."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef epd(self, *, shredder: bool = False, en_passant: str = \"legal\", promoted: Optional[bool] = None, **operations: Union[None, str, int, float, Move, Iterable[Move]]) -> str:\n        if en_passant == \"fen\":\n            ep_square = self.ep_square\n        elif en_passant == \"xfen\":\n            ep_square = self.ep_square if self.has_pseudo_legal_en_passant() else None\n        else:\n            ep_square = self.ep_square if self.has_legal_en_passant() else None\n\n        epd = [self.board_fen(promoted=promoted),\n               \"w\" if self.turn == WHITE else \"b\",\n               self.castling_shredder_fen() if shredder else self.castling_xfen(),\n               SQUARE_NAMES[ep_square] if ep_square is not None else \"-\"]\n\n        if operations:\n            epd.append(self._epd_operations(operations))\n\n        return \" \".join(epd)", "response": "Returns an EPD representation of the current position."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef lan(self, move: Move) -> str:\n        return self._algebraic(move, long=True)", "response": "Gets the long algebraic notation of the given move."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngive a sequence of moves returns a string representing the sequence in standard algebraic notation.", "response": "def variation_san(self, variation: Iterable[Move]) -> str:\n        \"\"\"\n        Given a sequence of moves, returns a string representing the sequence\n        in standard algebraic notation (e.g., ``1. e4 e5 2. Nf3 Nc6`` or\n        ``37...Bg6 38. fxg6``).\n\n        The board will not be modified as a result of calling this.\n\n        :raises: :exc:`ValueError` if any moves in the sequence are illegal.\n        \"\"\"\n        board = self.copy(stack=False)\n        san = []\n\n        for move in variation:\n            if not board.is_legal(move):\n                raise ValueError(\"illegal move {} in position {}\".format(move, board.fen()))\n\n            if board.turn == WHITE:\n                san.append(\"{}. {}\".format(board.fullmove_number, board.san(move)))\n            elif not san:\n                san.append(\"{}...{}\".format(board.fullmove_number, board.san(move)))\n            else:\n                san.append(board.san(move))\n\n            board.push(move)\n\n        return \" \".join(san)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_san(self, san: str) -> Move:\n        # Castling.\n        try:\n            if san in [\"O-O\", \"O-O+\", \"O-O#\"]:\n                return next(move for move in self.generate_castling_moves() if self.is_kingside_castling(move))\n            elif san in [\"O-O-O\", \"O-O-O+\", \"O-O-O#\"]:\n                return next(move for move in self.generate_castling_moves() if self.is_queenside_castling(move))\n        except StopIteration:\n            raise ValueError(\"illegal san: {!r} in {}\".format(san, self.fen()))\n\n        # Match normal moves.\n        match = SAN_REGEX.match(san)\n        if not match:\n            # Null moves.\n            if san in [\"--\", \"Z0\"]:\n                return Move.null()\n\n            raise ValueError(\"invalid san: {!r}\".format(san))\n\n        # Get target square.\n        to_square = SQUARE_NAMES.index(match.group(4))\n        to_mask = BB_SQUARES[to_square] & ~self.occupied_co[self.turn]\n\n        # Get the promotion type.\n        p = match.group(5)\n        promotion = p and PIECE_SYMBOLS.index(p[-1].lower())\n\n        # Filter by piece type.\n        if match.group(1):\n            piece_type = PIECE_SYMBOLS.index(match.group(1).lower())\n            from_mask = self.pieces_mask(piece_type, self.turn)\n        else:\n            from_mask = self.pawns\n\n        # Filter by source file.\n        if match.group(2):\n            from_mask &= BB_FILES[FILE_NAMES.index(match.group(2))]\n\n        # Filter by source rank.\n        if match.group(3):\n            from_mask &= BB_RANKS[int(match.group(3)) - 1]\n\n        # Match legal moves.\n        matched_move = None\n        for move in self.generate_legal_moves(from_mask, to_mask):\n            if move.promotion != promotion:\n                continue\n\n            if matched_move:\n                raise ValueError(\"ambiguous san: {!r} in {}\".format(san, self.fen()))\n\n            matched_move = move\n\n        if not matched_move:\n            raise ValueError(\"illegal san: {!r} in {}\".format(san, self.fen()))\n\n        return matched_move", "response": "Parses a single san string and returns a Move object."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses a move in standard algebraic notation makes the move and puts it on the stack.", "response": "def push_san(self, san: str) -> Move:\n        \"\"\"\n        Parses a move in standard algebraic notation, makes the move and puts\n        it on the the move stack.\n\n        Returns the move.\n\n        :raises: :exc:`ValueError` if neither legal nor a null move.\n        \"\"\"\n        move = self.parse_san(san)\n        self.push(move)\n        return move"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the UCI notation of the given move.", "response": "def uci(self, move: Move, *, chess960: Optional[bool] = None) -> str:\n        \"\"\"\n        Gets the UCI notation of the move.\n\n        *chess960* defaults to the mode of the board. Pass ``True`` to force\n        Chess960 mode.\n        \"\"\"\n        if chess960 is None:\n            chess960 = self.chess960\n\n        move = self._to_chess960(move)\n        move = self._from_chess960(chess960, move.from_square, move.to_square, move.promotion, move.drop)\n        return move.uci()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing the given UCI notation and returns a new Move object.", "response": "def parse_uci(self, uci: str) -> Move:\n        \"\"\"\n        Parses the given move in UCI notation.\n\n        Supports both Chess960 and standard UCI notation.\n\n        The returned move is guaranteed to be either legal or a null move.\n\n        :raises: :exc:`ValueError` if the move is invalid or illegal in the\n            current position (but not a null move).\n        \"\"\"\n        move = Move.from_uci(uci)\n\n        if not move:\n            return move\n\n        move = self._to_chess960(move)\n        move = self._from_chess960(self.chess960, move.from_square, move.to_square, move.promotion, move.drop)\n\n        if not self.is_legal(move):\n            raise ValueError(\"illegal uci: {!r} in {}\".format(uci, self.fen()))\n\n        return move"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef push_uci(self, uci: str) -> Move:\n        move = self.parse_uci(uci)\n        self.push(move)\n        return move", "response": "Pushes a move in UCI notation and returns the move."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_en_passant(self, move: Move) -> bool:\n        return (self.ep_square == move.to_square and\n                bool(self.pawns & BB_SQUARES[move.from_square]) and\n                abs(move.to_square - move.from_square) in [7, 9] and\n                not self.occupied & BB_SQUARES[move.to_square])", "response": "Checks if the given pseudo - legal move is an en passant capture."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking if the given pseudo - legal move is a capture.", "response": "def is_capture(self, move: Move) -> bool:\n        \"\"\"Checks if the given pseudo-legal move is a capture.\"\"\"\n        return bool(BB_SQUARES[move.to_square] & self.occupied_co[not self.turn]) or self.is_en_passant(move)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_zeroing(self, move: Move) -> bool:\n        return bool(BB_SQUARES[move.from_square] & self.pawns or BB_SQUARES[move.to_square] & self.occupied_co[not self.turn])", "response": "Checks if the given pseudo - legal move is a capture or pawn move."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if the given pseudo - legal move is irreversible.", "response": "def is_irreversible(self, move: Move) -> bool:\n        \"\"\"\n        Checks if the given pseudo-legal move is irreversible.\n\n        In standard chess, pawn moves, captures and moves that destroy castling\n        rights are irreversible.\n        \"\"\"\n        backrank = BB_RANK_1 if self.turn == WHITE else BB_RANK_8\n        cr = self.clean_castling_rights() & backrank\n        return bool(self.is_zeroing(move) or\n                    cr and BB_SQUARES[move.from_square] & self.kings & ~self.promoted or\n                    cr & BB_SQUARES[move.from_square] or\n                    cr & BB_SQUARES[move.to_square])"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks if the given pseudo - legal move is a castling move.", "response": "def is_castling(self, move: Move) -> bool:\n        \"\"\"Checks if the given pseudo-legal move is a castling move.\"\"\"\n        if self.kings & BB_SQUARES[move.from_square]:\n            diff = square_file(move.from_square) - square_file(move.to_square)\n            return abs(diff) > 1 or bool(self.rooks & self.occupied_co[self.turn] & BB_SQUARES[move.to_square])\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_kingside_castling(self, move: Move) -> bool:\n        return self.is_castling(move) and square_file(move.to_square) > square_file(move.from_square)", "response": "Checks if the given pseudo - legal move is a kingside castling move."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef clean_castling_rights(self) -> Bitboard:\n        if self._stack:\n            # Castling rights do not change in a game, so we can assume them to\n            # be filtered already.\n            return self.castling_rights\n\n        castling = self.castling_rights & self.rooks\n        white_castling = castling & BB_RANK_1 & self.occupied_co[WHITE]\n        black_castling = castling & BB_RANK_8 & self.occupied_co[BLACK]\n\n        if not self.chess960:\n            # The rooks must be on a1, h1, a8 or h8.\n            white_castling &= (BB_A1 | BB_H1)\n            black_castling &= (BB_A8 | BB_H8)\n\n            # The kings must be on e1 or e8.\n            if not self.occupied_co[WHITE] & self.kings & ~self.promoted & BB_E1:\n                white_castling = 0\n            if not self.occupied_co[BLACK] & self.kings & ~self.promoted & BB_E8:\n                black_castling = 0\n\n            return white_castling | black_castling\n        else:\n            # The kings must be on the back rank.\n            white_king_mask = self.occupied_co[WHITE] & self.kings & BB_RANK_1 & ~self.promoted\n            black_king_mask = self.occupied_co[BLACK] & self.kings & BB_RANK_8 & ~self.promoted\n            if not white_king_mask:\n                white_castling = 0\n            if not black_king_mask:\n                black_castling = 0\n\n            # There are only two ways of castling, a-side and h-side, and the\n            # king must be between the rooks.\n            white_a_side = white_castling & -white_castling\n            white_h_side = BB_SQUARES[msb(white_castling)] if white_castling else 0\n\n            if white_a_side and msb(white_a_side) > msb(white_king_mask):\n                white_a_side = 0\n            if white_h_side and msb(white_h_side) < msb(white_king_mask):\n                white_h_side = 0\n\n            black_a_side = (black_castling & -black_castling)\n            black_h_side = BB_SQUARES[msb(black_castling)] if black_castling else BB_EMPTY\n\n            if black_a_side and msb(black_a_side) > msb(black_king_mask):\n                black_a_side = 0\n            if black_h_side and msb(black_h_side) < msb(black_king_mask):\n                black_h_side = 0\n\n            # Done.\n            return black_a_side | black_h_side | white_a_side | white_h_side", "response": "Returns valid castling rights filtered from the current bitboard."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef has_castling_rights(self, color: Color) -> bool:\n        backrank = BB_RANK_1 if color == WHITE else BB_RANK_8\n        return bool(self.clean_castling_rights() & backrank)", "response": "Checks if the given side has castling rights."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if the given side has castling rights.", "response": "def has_kingside_castling_rights(self, color: Color) -> bool:\n        \"\"\"\n        Checks if the given side has kingside (that is h-side in Chess960)\n        castling rights.\n        \"\"\"\n        backrank = BB_RANK_1 if color == WHITE else BB_RANK_8\n        king_mask = self.kings & self.occupied_co[color] & backrank & ~self.promoted\n        if not king_mask:\n            return False\n\n        castling_rights = self.clean_castling_rights() & backrank\n        while castling_rights:\n            rook = castling_rights & -castling_rights\n\n            if rook > king_mask:\n                return True\n\n            castling_rights = castling_rights & (castling_rights - 1)\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if there are castling rights that are only possible in Chess960.", "response": "def has_chess960_castling_rights(self) -> bool:\n        \"\"\"\n        Checks if there are castling rights that are only possible in Chess960.\n        \"\"\"\n        # Get valid Chess960 castling rights.\n        chess960 = self.chess960\n        self.chess960 = True\n        castling_rights = self.clean_castling_rights()\n        self.chess960 = chess960\n\n        # Standard chess castling rights can only be on the standard\n        # starting rook squares.\n        if castling_rights & ~BB_CORNERS:\n            return True\n\n        # If there are any castling rights in standard chess, the king must be\n        # on e1 or e8.\n        if castling_rights & BB_RANK_1 and not self.occupied_co[WHITE] & self.kings & BB_E1:\n            return True\n        if castling_rights & BB_RANK_8 and not self.occupied_co[BLACK] & self.kings & BB_E8:\n            return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef status(self) -> Status:\n        errors = STATUS_VALID\n\n        # There must be at least one piece.\n        if not self.occupied:\n            errors |= STATUS_EMPTY\n\n        # There must be exactly one king of each color.\n        if not self.occupied_co[WHITE] & self.kings:\n            errors |= STATUS_NO_WHITE_KING\n        if not self.occupied_co[BLACK] & self.kings:\n            errors |= STATUS_NO_BLACK_KING\n        if popcount(self.occupied & self.kings) > 2:\n            errors |= STATUS_TOO_MANY_KINGS\n\n        # There can not be more than 16 pieces of any color.\n        if popcount(self.occupied_co[WHITE]) > 16:\n            errors |= STATUS_TOO_MANY_WHITE_PIECES\n        if popcount(self.occupied_co[BLACK]) > 16:\n            errors |= STATUS_TOO_MANY_BLACK_PIECES\n\n        # There can not be more than 8 pawns of any color.\n        if popcount(self.occupied_co[WHITE] & self.pawns) > 8:\n            errors |= STATUS_TOO_MANY_WHITE_PAWNS\n        if popcount(self.occupied_co[BLACK] & self.pawns) > 8:\n            errors |= STATUS_TOO_MANY_BLACK_PAWNS\n\n        # Pawns can not be on the back rank.\n        if self.pawns & BB_BACKRANKS:\n            errors |= STATUS_PAWNS_ON_BACKRANK\n\n        # Castling rights.\n        if self.castling_rights != self.clean_castling_rights():\n            errors |= STATUS_BAD_CASTLING_RIGHTS\n\n        # En passant.\n        if self.ep_square != self._valid_ep_square():\n            errors |= STATUS_INVALID_EP_SQUARE\n\n        # Side to move giving check.\n        if self.was_into_check():\n            errors |= STATUS_OPPOSITE_CHECK\n\n        return errors", "response": "Return the status of the current entry."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a copy of the board.", "response": "def copy(self: BoardT, *, stack: Union[bool, int] = True) -> BoardT:\n        \"\"\"\n        Creates a copy of the board.\n\n        Defaults to copying the entire move stack. Alternatively, *stack* can\n        be ``False``, or an integer to copy a limited number of moves.\n        \"\"\"\n        board = super().copy()\n\n        board.chess960 = self.chess960\n\n        board.ep_square = self.ep_square\n        board.castling_rights = self.castling_rights\n        board.turn = self.turn\n        board.fullmove_number = self.fullmove_number\n        board.halfmove_clock = self.halfmove_clock\n\n        if stack:\n            stack = len(self.move_stack) if stack is True else stack\n            board.move_stack = [copy.copy(move) for move in self.move_stack[-stack:]]\n            board._stack = self._stack[-stack:]\n\n        return board"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new empty board.", "response": "def empty(cls: Type[BoardT], *, chess960: bool = False) -> BoardT:\n        \"\"\"Creates a new empty board. Also see :func:`~chess.Board.clear()`.\"\"\"\n        return cls(None, chess960=chess960)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_epd(cls: Type[BoardT], epd: str, *, chess960: bool = False) -> Tuple[BoardT, Dict[str, Union[None, str, int, float, Move, List[Move]]]]:\n        board = cls.empty(chess960=chess960)\n        return board, board.set_epd(epd)", "response": "Creates a new board from an EPD string."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove a square from the set.", "response": "def remove(self, square: Square) -> None:\n        \"\"\"\n        Removes a square from the set.\n\n        :raises: :exc:`KeyError` if the given square was not in the set.\n        \"\"\"\n        mask = BB_SQUARES[square]\n        if self.mask & mask:\n            self.mask ^= mask\n        else:\n            raise KeyError(square)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pop(self) -> Square:\n        if not self.mask:\n            raise KeyError(\"pop from empty SquareSet\")\n\n        square = lsb(self.mask)\n        self.mask &= (self.mask - 1)\n        return square", "response": "Removes a square from the set and returns it."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef tolist(self) -> List[bool]:\n        result = [False] * 64\n        for square in self:\n            result[square] = True\n        return result", "response": "Convert the set to a list of 64 bools."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find_variant(name: str) -> Type[chess.Board]:\n    for variant in VARIANTS:\n        if any(alias.lower() == name.lower() for alias in variant.aliases):\n            return variant\n    raise ValueError(\"unsupported variant: {}\".format(name))", "response": "Looks for a variant board class by variant name."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef zobrist_hash(board: chess.Board, *, _hasher: Callable[[chess.Board], int] = ZobristHasher(POLYGLOT_RANDOM_ARRAY)) -> int:\n    return _hasher(board)", "response": "Calculates the Polyglot Zobrist hash of the position."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef find_all(self, board: Union[chess.Board, int], *, minimum_weight: int = 1, exclude_moves: Container[chess.Move] = ()) -> Iterator[Entry]:\n        try:\n            key = int(board)  # type: ignore\n            context = None  # type: Optional[chess.Board]\n        except (TypeError, ValueError):\n            context = typing.cast(chess.Board, board)\n            key = zobrist_hash(context)\n\n        i = self.bisect_key_left(key)\n        size = len(self)\n\n        while i < size:\n            entry = self[i]\n            i += 1\n\n            if entry.key != key:\n                break\n\n            if entry.weight < minimum_weight:\n                continue\n\n            if context:\n                move = context._from_chess960(context.chess960, entry.move.from_square, entry.move.to_square, entry.move.promotion, entry.move.drop)\n                entry = Entry(entry.key, entry.raw_move, entry.weight, entry.learn, move)\n\n            if exclude_moves and entry.move in exclude_moves:\n                continue\n\n            if context and not context.is_legal(entry.move):\n                continue\n\n            yield entry", "response": "Iterates over the entries in the list that are at a specific position and yields corresponding entries."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfinds the main entry for the given position or Zobrist hash.", "response": "def find(self, board: Union[chess.Board, int], *, minimum_weight: int = 1, exclude_moves: Container[chess.Move] = ()) -> Entry:\n        \"\"\"\n        Finds the main entry for the given position or Zobrist hash.\n\n        The main entry is the (first) entry with the highest weight.\n\n        By default, entries with weight ``0`` are excluded. This is a common\n        way to delete entries from an opening book without compacting it. Pass\n        *minimum_weight* ``0`` to select all entries.\n\n        :raises: :exc:`IndexError` if no entries are found. Use\n            :func:`~chess.polyglot.MemoryMappedReader.get()` if you prefer to\n            get ``None`` instead of an exception.\n        \"\"\"\n        try:\n            return max(self.find_all(board, minimum_weight=minimum_weight, exclude_moves=exclude_moves), key=lambda entry: entry.weight)\n        except ValueError:\n            raise IndexError()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef choice(self, board: Union[chess.Board, int], *, minimum_weight: int = 1, exclude_moves: Container[chess.Move] = (), random=random) -> Entry:\n        chosen_entry = None\n\n        for i, entry in enumerate(self.find_all(board, minimum_weight=minimum_weight, exclude_moves=exclude_moves)):\n            if chosen_entry is None or random.randint(0, i) == i:\n                chosen_entry = entry\n\n        if chosen_entry is None:\n            raise IndexError()\n\n        return chosen_entry", "response": "Uniformly selects a random entry for the given position."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nselects a random entry for the given position distributed by the weights of the entries.", "response": "def weighted_choice(self, board: Union[chess.Board, int], *, exclude_moves: Container[chess.Move] = (), random=random) -> Entry:\n        \"\"\"\n        Selects a random entry for the given position, distributed by the\n        weights of the entries.\n\n        :raises: :exc:`IndexError` if no entries are found.\n        \"\"\"\n        total_weights = sum(entry.weight for entry in self.find_all(board, exclude_moves=exclude_moves))\n        if not total_weights:\n            raise IndexError()\n\n        choice = random.randint(0, total_weights - 1)\n\n        current_sum = 0\n        for entry in self.find_all(board, exclude_moves=exclude_moves):\n            current_sum += entry.weight\n            if current_sum > choice:\n                return entry\n\n        assert False"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _geom_points(geom):\n    if geom['type'] == 'Point':\n        yield tuple(geom['coordinates'])\n    elif geom['type'] in ('MultiPoint', 'LineString'):\n        for position in geom['coordinates']:\n            yield tuple(position)\n    else:\n        raise InvalidFeatureError(\n            \"Unsupported geometry type:{0}\".format(geom['type']))", "response": "Converts a GeoJSON geometry to a sequence of point tuples"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read_points(features):\n    for feature in features:\n\n        if isinstance(feature, (tuple, list)) and len(feature) == 2:\n            yield feature\n\n        elif hasattr(feature, '__geo_interface__'):\n            # An object implementing the geo_interface\n            try:\n                # Could be a Feature...\n                geom = feature.__geo_interface__['geometry']\n                for pt in _geom_points(geom):\n                    yield pt\n            except KeyError:\n                # ... or a geometry directly\n                for pt in _geom_points(feature.__geo_interface__):\n                    yield pt\n\n        elif 'type' in feature and feature['type'] == 'Feature':\n            # A GeoJSON-like mapping\n            geom = feature['geometry']\n            for pt in _geom_points(geom):\n                yield pt\n\n        elif 'coordinates' in feature:\n            geom = feature\n            for pt in _geom_points(geom):\n                yield pt\n\n        else:\n            raise InvalidFeatureError(\n                \"Unknown object: Not a GeoJSON Point feature or \"\n                \"an object with __geo_interface__:\\n{0}\".format(feature))", "response": "Iterate over a list of features to a sequence of point tuples where each tuple is a GeoJSON point or a GeoJSON geometry."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef encode_waypoints(features, min_limit=None, max_limit=None, precision=6):\n    coords = ['{lon},{lat}'.format(\n                  lon=float(round(lon, precision)),\n                  lat=float(round(lat, precision)))\n              for lon, lat in read_points(features)]\n\n    if min_limit is not None and len(coords) < min_limit:\n        raise InvalidFeatureError(\n            \"Not enough features to encode coordinates, \"\n            \"need at least {0}\".format(min_limit))\n    if max_limit is not None and len(coords) > max_limit:\n        raise InvalidFeatureError(\n            \"Too many features to encode coordinates, \"\n            \"need at most {0}\".format(max_limit))\n\n    return ';'.join(coords)", "response": "Given an iterable of features return a string encoded in waypoint - style used by certain mapbox APIs\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nencodes and iterable of features as a polyline", "response": "def encode_polyline(features):\n    \"\"\"Encode and iterable of features as a polyline\n    \"\"\"\n    points = list(read_points(features))\n    latlon_points = [(x[1], x[0]) for x in points]\n    return polyline.encode(latlon_points)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntake a geojson - like mapping representing geometry Feature or FeatureCollection or a sequence of such objects and returns a FeatureCollection - like dict containing only the objects that are not in the sequence.", "response": "def normalize_geojson_featurecollection(obj):\n    \"\"\"Takes a geojson-like mapping representing\n    geometry, Feature or FeatureCollection (or a sequence of such objects)\n    and returns a FeatureCollection-like dict\n    \"\"\"\n    if not isinstance(obj, Sequence):\n        obj = [obj]\n\n    features = []\n    for x in obj:\n        if not isinstance(x, Mapping) or 'type' not in x:\n            raise ValueError(\n                \"Expecting a geojson-like mapping or sequence of them\")\n\n        if 'features' in x:\n            features.extend(x['features'])\n        elif 'geometry' in x:\n            features.append(x)\n        elif 'coordinates' in x:\n            feat = {'type': 'Feature',\n                    'properties': {},\n                    'geometry': x}\n            features.append(feat)\n        else:\n            raise ValueError(\n                \"Expecting a geojson-like mapping or sequence of them\")\n\n    return {'type': 'FeatureCollection', 'features': features}"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef directions(self, features, profile='mapbox/driving',\n                   alternatives=None, geometries=None, overview=None, steps=None,\n                   continue_straight=None, waypoint_snapping=None, annotations=None,\n                   language=None, **kwargs):\n        \"\"\"Request directions for waypoints encoded as GeoJSON features.\n\n        Parameters\n        ----------\n        features : iterable\n            An collection of GeoJSON features\n        profile : str\n            Name of a Mapbox profile such as 'mapbox.driving'\n        alternatives : bool\n            Whether to try to return alternative routes, default: False\n        geometries : string\n            Type of geometry returned (geojson, polyline, polyline6)\n        overview : string or False\n            Type of returned overview geometry: 'full', 'simplified',\n            or False\n        steps : bool\n            Whether to return steps and turn-by-turn instructions,\n            default: False\n        continue_straight : bool\n            Direction of travel when departing intermediate waypoints\n        radiuses : iterable of numbers or 'unlimited'\n            Must be same length as features\n        waypoint_snapping : list\n            Controls snapping of waypoints\n\n            The list is zipped with the features collection and must\n            have the same length. Elements of the list must be one of:\n\n            - A number (interpretted as a snapping radius)\n            - The string 'unlimited' (unlimited snapping radius)\n            - A 3-element tuple consisting of (radius, angle, range)\n            - None (no snapping parameters specified for that waypoint)\n        annotations : str\n            Whether or not to return additional metadata along the route\n\n            Possible values are: 'duration', 'distance', 'speed', and\n            'congestion'. Several annotations can be used by joining\n            them with ','.\n        language : str\n            Language of returned turn-by-turn text instructions,\n            default: 'en'\n\n        Returns\n        -------\n        requests.Response\n            The response object has a geojson() method for access to\n            the route(s) as a GeoJSON-like FeatureCollection\n            dictionary.\n        \"\"\"\n        # backwards compatible, deprecated\n        if 'geometry' in kwargs and geometries is None:\n            geometries = kwargs['geometry']\n            warnings.warn('Use `geometries` instead of `geometry`',\n                          errors.MapboxDeprecationWarning)\n\n        annotations = self._validate_annotations(annotations)\n        coordinates = encode_coordinates(\n            features, precision=6, min_limit=2, max_limit=25)\n        geometries = self._validate_geom_encoding(geometries)\n        overview = self._validate_geom_overview(overview)\n        profile = self._validate_profile(profile)\n\n        bearings, radii = self._validate_snapping(waypoint_snapping, features)\n\n        params = {}\n        if alternatives is not None:\n            params.update(\n                {'alternatives': 'true' if alternatives is True else 'false'})\n        if geometries is not None:\n            params.update({'geometries': geometries})\n        if overview is not None:\n            params.update(\n                {'overview': 'false' if overview is False else overview})\n        if steps is not None:\n            params.update(\n                {'steps': 'true' if steps is True else 'false'})\n        if continue_straight is not None:\n            params.update(\n                {'continue_straight': 'true' if steps is True else 'false'})\n        if annotations is not None:\n            params.update({'annotations': ','.join(annotations)})\n        if language is not None:\n            params.update({'language': language})\n        if radii is not None:\n            params.update(\n                {'radiuses': ';'.join(str(r) for r in radii)})\n        if bearings is not None:\n            params.update(\n                {'bearings': ';'.join(self._encode_bearing(b) for b in bearings)})\n\n        profile_ns, profile_name = profile.split('/')\n\n        uri = URITemplate(\n            self.baseuri + '/{profile_ns}/{profile_name}/{coordinates}.json').expand(\n                profile_ns=profile_ns, profile_name=profile_name, coordinates=coordinates)\n\n        resp = self.session.get(uri, params=params)\n        self.handle_http_error(resp)\n\n        def geojson():\n            return self._geojson(resp.json(), geom_format=geometries)\n        resp.geojson = geojson\n        return resp", "response": "Request directions for waypoints encoded as GeoJSON features."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef analytics(self, resource_type, username, id=None, start=None, end=None):\n        \n        resource_type = self._validate_resource_type(resource_type)\n        username = self._validate_username(username)\n        start, end = self._validate_period(start, end)\n        id = self._validate_id(resource_type, id)\n\n        params = {}\n        if id is not None:\n            params.update({'id': id})\n\n        if start is not None and end is not None:\n            params.update({'period': start + ',' + end})\n\n        uri = URITemplate(self.baseuri + '/{resourceType}/{username}').expand(\n            resourceType=resource_type, username=username)\n\n        resp = self.session.get(uri, params=params)\n        resp.geojson = resp.json()\n        self.handle_http_error(resp)\n\n        return resp", "response": "Returns the request counts per day for a given resource and period."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef matrix(self, coordinates, profile='mapbox/driving', \n               sources=None, destinations=None, annotations=None):\n        \"\"\"Request a directions matrix for trips between coordinates\n\n        In the default case, the matrix returns a symmetric matrix,\n        using all input coordinates as sources and destinations. You may\n        also generate an asymmetric matrix, with only some coordinates\n        as sources or destinations:\n\n        Parameters\n        ----------\n        coordinates : sequence\n            A sequence of coordinates, which may be represented as\n            GeoJSON features, GeoJSON geometries, or (longitude,\n            latitude) pairs.\n        profile : str\n            The trip travel mode. Valid modes are listed in the class's\n            valid_profiles attribute.\n        annotations : list\n            Used to specify the resulting matrices. Possible values are\n            listed in the class's valid_annotations attribute.\n        sources : list\n            Indices of source coordinates to include in the matrix.\n            Default is all coordinates.\n        destinations : list\n            Indices of destination coordinates to include in the\n            matrix. Default is all coordinates.\n\n        Returns\n        -------\n        requests.Response\n\n        Note: the directions matrix itself is obtained by calling the\n        response's json() method. The resulting mapping has a code,\n        the destinations and the sources, and depending of the\n        annotations specified, it can also contain a durations matrix,\n        a distances matrix or both of them (by default, only the\n        durations matrix is provided).\n\n        code : str\n            Status of the response\n        sources : list\n            Results of snapping selected coordinates to the nearest\n            addresses.\n        destinations : list\n            Results of snapping selected coordinates to the nearest\n            addresses.\n        durations : list\n            An array of arrays representing the matrix in row-major\n            order.  durations[i][j] gives the travel time from the i-th\n            source to the j-th destination. All values are in seconds.\n            The duration between the same coordinate is always 0. If\n            a duration can not be found, the result is null.\n        distances : list\n            An array of arrays representing the matrix in row-major\n            order.  distances[i][j] gives the distance from the i-th\n            source to the j-th destination. All values are in meters.\n            The distance between the same coordinate is always 0. If\n            a distance can not be found, the result is null.\n\n        \"\"\"\n        annotations = self._validate_annotations(annotations)\n        profile = self._validate_profile(profile)\n        coords = encode_waypoints(coordinates)\n\n        params = self._make_query(sources, destinations)\n\n        if annotations is not None:\n            params.update({'annotations': ','.join(annotations)})\n\n        uri = '{0}/{1}/{2}'.format(self.baseuri, profile, coords)\n        res = self.session.get(uri, params=params)\n        self.handle_http_error(res)\n        return res", "response": "Request a directions matrix for trips between coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _attribs(self, name=None, description=None):\n        a = {}\n        if name:\n            a['name'] = name\n        if description:\n            a['description'] = description\n        return a", "response": "Form an attributes dictionary from keyword args."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a new empty dataset.", "response": "def create(self, name=None, description=None):\n        \"\"\"Creates a new, empty dataset.\n\n        Parameters\n        ----------\n        name : str, optional\n            The name of the dataset.\n\n        description : str, optional\n            The description of the dataset.\n\n        Returns\n        -------\n        request.Response\n            The response contains the properties of a new dataset as a JSON object.\n        \"\"\"\n        \n        uri = URITemplate(self.baseuri + '/{owner}').expand(\n            owner=self.username)\n        return self.session.post(uri, json=self._attribs(name, description))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlists all datasets for a particular account.", "response": "def list(self):\n        \"\"\"Lists all datasets for a particular account.\n\n        Returns\n        -------\n        request.Response\n            The response contains a list of JSON objects describing datasets.\n        \"\"\"\n        \n        uri = URITemplate(self.baseuri + '/{owner}').expand(\n            owner=self.username)\n        return self.session.get(uri)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read_dataset(self, dataset):\n        \n        uri = URITemplate(self.baseuri + '/{owner}/{id}').expand(\n            owner=self.username, id=dataset)\n        return self.session.get(uri)", "response": "Retrieves a single dataset."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates a single dataset.", "response": "def update_dataset(self, dataset, name=None, description=None):\n        \"\"\"Updates a single dataset.\n\n        Parameters\n        ----------\n        dataset : str\n            The dataset id.\n\n        name : str, optional\n            The name of the dataset.\n\n        description : str, optional\n            The description of the dataset.\n\n        Returns\n        -------\n        request.Response\n            The response contains the properties of the updated dataset as a JSON object.\n        \"\"\"\n        \n        uri = URITemplate(self.baseuri + '/{owner}/{id}').expand(\n            owner=self.username, id=dataset)\n        return self.session.patch(uri, json=self._attribs(name, description))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete_dataset(self, dataset):\n        \n        uri = URITemplate(self.baseuri + '/{owner}/{id}').expand(\n            owner=self.username, id=dataset)\n        return self.session.delete(uri)", "response": "Deletes a single dataset including all of the features that it contains."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of features in a dataset.", "response": "def list_features(self, dataset, reverse=False, start=None, limit=None):\n        \"\"\"Lists features in a dataset.\n\n        Parameters\n        ----------\n        dataset : str             \n            The dataset id.\n\n        reverse : str, optional\n            List features in reverse order.\n\n            Possible value is \"true\".\n\n        start : str, optional\n            The id of the feature after which to start the list (pagination).\n\n        limit : str, optional\n            The maximum number of features to list (pagination).\n\n        Returns\n        -------\n        request.Response\n            The response contains the features of a dataset as a GeoJSON FeatureCollection.\n        \"\"\"\n        \n        uri = URITemplate(self.baseuri + '/{owner}/{id}/features').expand(\n            owner=self.username, id=dataset)\n\n        params = {}\n        if reverse:\n            params['reverse'] = 'true'\n        if start:\n            params['start'] = start\n        if limit:\n            params['limit'] = int(limit)\n        return self.session.get(uri, params=params)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read_feature(self, dataset, fid):\n        \n        uri = URITemplate(\n            self.baseuri + '/{owner}/{did}/features/{fid}').expand(\n                owner=self.username, did=dataset, fid=fid)\n        return self.session.get(uri)", "response": "Retrieves a feature in a dataset."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update_feature(self, dataset, fid, feature):\n        \n        uri = URITemplate(\n            self.baseuri + '/{owner}/{did}/features/{fid}').expand(\n                owner=self.username, did=dataset, fid=fid)\n        return self.session.put(uri, json=feature)", "response": "Inserts or updates a feature in a dataset."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove a feature from a dataset.", "response": "def delete_feature(self, dataset, fid):\n        \"\"\"Removes a feature from a dataset.\n\n        Parameters\n        ----------\n        dataset : str\n            The dataset id.\n\n        fid : str\n            The feature id.\n\n        Returns\n        -------\n        HTTP status code.\n        \"\"\"\n        \n        uri = URITemplate(\n            self.baseuri + '/{owner}/{did}/features/{fid}').expand(\n                owner=self.username, did=dataset, fid=fid)\n        return self.session.delete(uri)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget temporary S3 credentials to stage user - uploaded files", "response": "def _get_credentials(self):\n        \"\"\"Gets temporary S3 credentials to stage user-uploaded files\n        \"\"\"\n        uri = URITemplate(self.baseuri + '/{username}/credentials').expand(\n            username=self.username)\n\n        resp = self.session.post(uri)\n\n        self.handle_http_error(\n            resp,\n            custom_messages={\n                401: \"Token is not authorized\",\n                404: \"Token does not have upload scope\",\n                429: \"Too many requests\"})\n        return resp"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _validate_tileset(self, tileset):\n        if '.' not in tileset:\n            tileset = \"{0}.{1}\".format(self.username, tileset)\n\n        pattern = '^[a-z0-9-_]{1,32}\\.[a-z0-9-_]{1,32}$'\n        if not re.match(pattern, tileset, flags=re.IGNORECASE):\n            raise ValidationError(\n                'tileset {0} is invalid, must match r\"{1}\"'.format(\n                    tileset, pattern))\n\n        return tileset", "response": "Validate the tileset name and return the name of the new tileset"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nresolving username and handle deprecation of account kwarg", "response": "def _resolve_username(self, account, username):\n        \"\"\"Resolve username and handle deprecation of account kwarg\"\"\"\n        if account is not None:\n            warnings.warn(\n                \"Use keyword argument 'username' instead of 'account'\",\n                DeprecationWarning)\n        return username or account or self.username"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nstage data in a Mapbox - owned S3 bucket.", "response": "def stage(self, fileobj, creds=None, callback=None):\n        \"\"\"Stages data in a Mapbox-owned S3 bucket\n\n        If creds are not provided, temporary credentials will be\n        generated using the Mapbox API.\n\n        Parameters\n        ----------\n        fileobj: file object or filename\n            A Python file object opened in binary mode or a filename.\n        creds: dict\n            AWS credentials allowing uploads to the destination bucket.\n        callback: func\n            A function that takes a number of bytes processed as its\n            sole argument.\n\n        Returns\n        -------\n        str\n            The URL of the staged data\n        \"\"\"\n\n        if not hasattr(fileobj, 'read'):\n            fileobj = open(fileobj, 'rb')\n\n        if not creds:\n            res = self._get_credentials()\n            creds = res.json()\n\n        session = boto3_session(\n            aws_access_key_id=creds['accessKeyId'],\n            aws_secret_access_key=creds['secretAccessKey'],\n            aws_session_token=creds['sessionToken'],\n            region_name='us-east-1')\n\n        s3 = session.resource('s3')\n        bucket = s3.Bucket(creds['bucket'])\n        key = creds['key']\n        bucket.upload_fileobj(fileobj, key, Callback=callback)\n\n        return creds['url']"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a new Mapbox tile set.", "response": "def create(self, stage_url, tileset, name=None, patch=False, bypass=False):\n        \"\"\"Create a tileset\n\n        Note: this step is refered to as \"upload\" in the API docs;\n        This class's upload() method is a high-level function\n        which acts like the Studio upload form.\n\n        Returns a response object where the json() contents are\n        an upload dict. Completion of the tileset may take several\n        seconds or minutes depending on size of the data. The status()\n        method of this class may be used to poll the API endpoint for\n        tileset creation status.\n\n        Parameters\n        ----------\n        stage_url: str\n            URL to resource on S3, typically provided in the response\n            of this class's stage() method.\n        tileset: str\n            The id of the tileset set to be created. Username will be\n            prefixed if not present. For example, 'my-tileset' becomes\n            '{username}.my-tileset'.\n        name: str\n            A short name for the tileset that will appear in Mapbox\n            studio.\n        patch: bool\n            Optional patch mode which requires a flag on the owner's\n            account.\n        bypass: bool\n            Optional bypass validation mode for MBTiles which requires\n            a flag on the owner's account.\n\n        Returns\n        -------\n        requests.Response\n        \"\"\"\n        tileset = self._validate_tileset(tileset)\n        username, _name = tileset.split(\".\")\n\n        msg = {'tileset': tileset,\n               'url': stage_url}\n\n        if patch:\n            msg['patch'] = patch\n\n        if bypass:\n            msg['bypass_mbtiles_validation'] = bypass\n\n        msg['name'] = name if name else _name\n\n        uri = URITemplate(self.baseuri + '/{username}').expand(\n            username=username)\n\n        resp = self.session.post(uri, json=msg)\n        self.handle_http_error(resp)\n\n        return resp"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of all uploads with the given username.", "response": "def list(self, account=None, username=None):\n        \"\"\"List of all uploads\n\n        Returns a Response object, the json() method of which returns\n        a list of uploads\n\n        Parameters\n        ----------\n        username : str\n            Account username, defaults to the service's username.\n        account : str, **deprecated**\n            Alias for username. Will be removed in version 1.0.\n\n        Returns\n        -------\n        requests.Response\n        \"\"\"\n        username = self._resolve_username(account, username)\n        uri = URITemplate(self.baseuri + '/{username}').expand(\n            username=username)\n        resp = self.session.get(uri)\n        self.handle_http_error(resp)\n        return resp"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck status of a specific object.", "response": "def status(self, upload, account=None, username=None):\n        \"\"\"Check status of upload\n\n        Parameters\n        ----------\n        upload: str\n            The id of the upload or a dict with key 'id'.\n        username : str\n            Account username, defaults to the service's username.\n        account : str, **deprecated**\n            Alias for username. Will be removed in version 1.0.\n\n        Returns\n        -------\n        requests.Response\n        \"\"\"\n        username = self._resolve_username(account, username)\n        if isinstance(upload, dict):\n            upload_id = upload['id']\n        else:\n            upload_id = upload\n        uri = URITemplate(self.baseuri + '/{username}/{upload_id}').expand(\n            username=username, upload_id=upload_id)\n        resp = self.session.get(uri)\n        self.handle_http_error(resp)\n        return resp"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nuploading data and create a Mapbox tileset.", "response": "def upload(self, fileobj, tileset, name=None, patch=False, callback=None, bypass=False):\n        \"\"\"Upload data and create a Mapbox tileset\n\n        Effectively replicates the Studio upload feature. Returns a\n        Response object, the json() of which returns a dict with upload\n        metadata.\n\n        Parameters\n        ----------\n        fileobj: file object or str\n            A filename or a Python file object opened in binary mode.\n        tileset: str\n            A tileset identifier such as '{owner}.my-tileset'.\n        name: str\n            A short name for the tileset that will appear in Mapbox\n            studio.\n        patch: bool\n            Optional patch mode which requires a flag on the owner's\n            account.\n        bypass: bool\n            Optional bypass validation mode for MBTiles which requires\n            a flag on the owner's account.\n        callback: func\n            A function that takes a number of bytes processed as its\n            sole argument. May be used with a progress bar.\n\n        Returns\n        -------\n        requests.Response\n        \"\"\"\n        tileset = self._validate_tileset(tileset)\n        url = self.stage(fileobj, callback=callback)\n        return self.create(url, tileset, name=name, patch=patch, bypass=bypass)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _validate_country_codes(self, ccs):\n        for cc in ccs:\n            if cc not in self.country_codes:\n                raise InvalidCountryCodeError(cc)\n        return {'country': \",\".join(ccs)}", "response": "Validate country codes for use in requests."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nvalidates place types and return a mapping for use in requests.", "response": "def _validate_place_types(self, types):\n        \"\"\"Validate place types and return a mapping for use in requests.\"\"\"\n        for pt in types:\n            if pt not in self.place_types:\n                raise InvalidPlaceTypeError(pt)\n        return {'types': \",\".join(types)}"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a Requests response object that contains a GeoJSON representation of the given longitude and latitude.", "response": "def reverse(self, lon, lat, types=None, limit=None):\n        \"\"\"Returns a Requests response object that contains a GeoJSON\n        collection of places near the given longitude and latitude.\n\n        `response.geojson()` returns the geocoding result as GeoJSON.\n        `response.status_code` returns the HTTP API status code.\n\n        See: https://www.mapbox.com/api-documentation/search/#reverse-geocoding.\"\"\"\n        uri = URITemplate(self.baseuri + '/{dataset}/{lon},{lat}.json').expand(\n            dataset=self.name,\n            lon=str(round(float(lon), self.precision.get('reverse', 5))),\n            lat=str(round(float(lat), self.precision.get('reverse', 5))))\n        params = {}\n\n        if types:\n            types = list(types)\n            params.update(self._validate_place_types(types))\n\n        if limit is not None:\n            if not types or len(types) != 1:\n                raise InvalidPlaceTypeError(\n                    'Specify a single type when using limit with reverse geocoding')\n            params.update(limit='{0}'.format(limit))\n\n        resp = self.session.get(uri, params=params)\n        self.handle_http_error(resp)\n\n        # for consistency with other services\n        def geojson():\n            return resp.json()\n        resp.geojson = geojson\n\n        return resp"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef Session(access_token=None, env=None):\n    if env is None:\n        env = os.environ.copy()\n    access_token = (\n        access_token or\n        env.get('MapboxAccessToken') or\n        env.get('MAPBOX_ACCESS_TOKEN'))\n    session = requests.Session()\n    session.params.update(access_token=access_token)\n    session.headers.update({\n        'User-Agent': 'mapbox-sdk-py/{0} {1}'.format(\n            __version__, requests.utils.default_user_agent())})\n    return session", "response": "Create an HTTP session."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef username(self):\n        token = self.session.params.get('access_token')\n        if not token:\n            raise errors.TokenError(\n                \"session does not have a valid access_token param\")\n        data = token.split('.')[1]\n        # replace url chars and add padding\n        # (https://gist.github.com/perrygeo/ee7c65bb1541ff6ac770)\n        data = data.replace('-', '+').replace('_', '/') + \"===\"\n        try:\n            return json.loads(base64.b64decode(data).decode('utf-8'))['u']\n        except (ValueError, KeyError):\n            raise errors.TokenError(\n                \"access_token does not contain username\")", "response": "The username in the service s access token Returns ------- str"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef handle_http_error(self, response, custom_messages=None,\n                          raise_for_status=False):\n        \"\"\"Converts service errors to Python exceptions\n\n        Parameters\n        ----------\n        response : requests.Response\n            A service response.\n        custom_messages : dict, optional\n            A mapping of custom exception messages to HTTP status codes.\n        raise_for_status : bool, optional\n            If True, the requests library provides Python exceptions.\n\n        Returns\n        -------\n        None\n        \"\"\"\n        if not custom_messages:\n            custom_messages = {}\n        if response.status_code in custom_messages.keys():\n            raise errors.HTTPError(custom_messages[response.status_code])\n        if raise_for_status:\n            response.raise_for_status()", "response": "Converts HTTP errors to Python exceptions."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef match(self, feature, gps_precision=None, profile='mapbox.driving'):\n        profile = self._validate_profile(profile)\n\n        feature = self._validate_feature(feature)\n        geojson_line_feature = json.dumps(feature)\n\n        uri = URITemplate(self.baseuri + '/{profile}.json').expand(\n            profile=profile)\n\n        params = None\n        if gps_precision:\n            params = {'gps_precision': gps_precision}\n\n        res = self.session.post(uri, data=geojson_line_feature, params=params,\n                                headers={'Content-Type': 'application/json'})\n        self.handle_http_error(res)\n\n        def geojson():\n            return res.json()\n\n        res.geojson = geojson\n        return res", "response": "Match features to OpenStreetMap data."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _validate_geometry(self, geometry):\n\n        if geometry is not None and geometry not in self.valid_geometries:\n            raise InvalidParameterError(\"{} is not a valid geometry\".format(geometry))\n\n        return geometry", "response": "Validates geometry raising error if invalid."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef tilequery(\n        self,\n        map_id,\n        lon=None,\n        lat=None,\n        radius=None,\n        limit=None,\n        dedupe=None,\n        geometry=None,\n        layers=None,\n    ):\n\n        \"\"\"Returns data about specific features\n        from a vector tileset.\n\n        Parameters\n        ----------\n        map_id : str or list\n            The tileset's unique identifier in the\n            format username.id.\n\n            map_id may be either a str with one value\n            or a list with multiple values.\n\n        lon : float\n            The longitude to query, where -180\n            is the minimum value and 180 is the\n            maximum value.\n\n        lat : float\n            The latitude to query, where -85.0511\n            is the minimum value and 85.0511 is the\n            maximum value.\n\n        radius : int, optional\n            The approximate distance in meters to\n            query, where 0 is the minimum value.\n            (There is no maximum value.)\n\n            If None, the default value is 0.\n\n        limit : int, optional\n            The number of features to return, where\n            1 is the minimum value and 50 is the\n            maximum value.\n\n            If None, the default value is 5.\n\n        dedupe : bool, optional\n            Whether to remove duplicate results.\n\n            If None, the default value is True.\n\n        geometry : str, optional\n            The geometry type to query.\n\n        layers : list, optional\n            The list of layers to query.\n\n            If a specified layer does not exist,\n            then the Tilequery API will skip it.\n            If no layers exist, then the API will\n            return an empty GeoJSON FeatureCollection.\n\n        Returns\n        -------\n        request.Response\n            The response object with a GeoJSON\n            FeatureCollection of features at or near\n            the specified longitude and latitude.\n        \"\"\"\n\n        # If map_id is a list, then convert it to a str\n        # of comma-separated values.\n\n        if isinstance(map_id, list):\n            map_id = \",\".join(map_id)\n\n        # Validate lon and lat.\n\n        lon = self._validate_lon(lon)\n        lat = self._validate_lat(lat)\n\n        # Create dict to assist in building URI resource path.\n\n        path_values = dict(\n            api_name=self.api_name, lon=lon, lat=lat\n        )\n\n        # Build URI resource path.\n\n        path_part = \"/\" + map_id + \"/{api_name}/{lon},{lat}.json\"\n        uri = URITemplate(self.base_uri + path_part).expand(**path_values)\n\n        # Build URI query_parameters.\n\n        query_parameters = dict()\n\n        if radius is not None:\n            radius = self._validate_radius(radius)\n            query_parameters[\"radius\"] = radius\n\n        if limit is not None:\n            limit = self._validate_limit(limit)\n            query_parameters[\"limit\"] = limit\n\n        if dedupe is not None:\n            query_parameters[\"dedupe\"] = \"true\" if True else \"false\"\n\n        if geometry is not None:\n            geometry = self._validate_geometry(geometry)\n            query_parameters[\"geometry\"] = geometry\n\n        if layers is not None:\n            query_parameters[\"layers\"] = \",\".join(layers)\n\n        # Send HTTP GET request.\n\n        response = self.session.get(uri, params=query_parameters)\n        self.handle_http_error(response)\n\n        # To be consistent with other services,\n        # add geojson method to response object.\n\n        def geojson():\n            return response.json()\n\n        response.geojson = geojson\n\n        return response", "response": "Returns data about specific features from a vector tileset."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget a tile from the server.", "response": "def tile(self, username, style_id, z, x, y, tile_size=512, retina=False):\n        \"/styles/v1/{username}/{style_id}/tiles/{tileSize}/{z}/{x}/{y}{@2x}\"\n        if tile_size not in (256, 512):\n            raise errors.ImageSizeError('tile_size must be 256 or 512 pixels')\n\n        pth = '/{username}/{style_id}/tiles/{tile_size}/{z}/{x}/{y}'\n\n        values = dict(username=username, style_id=style_id,\n                      tile_size=tile_size, z=z, x=x, y=y)\n\n        uri = URITemplate(self.baseuri + pth).expand(**values)\n        if retina:\n            uri += '@2x'\n        res = self.session.get(uri)\n        self.handle_http_error(res)\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _validate_x(self, x, z):\n\n        if (x < 0) or (x > ((2**z) - 1)):\n            raise InvalidColumnError(\n                \"{} is not a valid value for x (column)\".format(x)\n            )\n\n        return x", "response": "Validates x ( column ) raising error if invalid."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nvalidates y ( row raise error if invalid.", "response": "def _validate_y(self, y, z):\n        \"\"\"Validates y (row), raising error if invalid.\"\"\"\n\n        if (y < 0) or (y > ((2**z) - 1)):\n            raise InvalidRowError(\n                \"{} is not a valid value for y (row)\".format(y)\n            )\n\n        return y"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nvalidate file format raising error if invalid.", "response": "def _validate_file_format(self, file_format):\n        \"\"\"Validates file format, raising error if invalid.\"\"\"\n\n        if file_format not in self.valid_file_formats:\n            raise InvalidFileFormatError(\n                \"{} is not a valid file format\".format(file_format)\n            )\n\n        return file_format"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _validate_feature_format(self, feature_format):\n\n        if feature_format not in self.valid_feature_formats:\n            raise InvalidFeatureFormatError(\n                \"{} is not a valid feature format\".format(feature_format)\n            )\n\n        return feature_format", "response": "Validates feature format raising error if invalid."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nvalidating marker name raising error if invalid.", "response": "def _validate_marker_name(self, marker_name):\n        \"\"\"Validates marker name, raising error if invalid.\"\"\"\n\n        if marker_name not in self.valid_marker_names:\n            raise InvalidMarkerNameError(\n                \"{} is not a valid marker name\".format(marker_name)\n            )\n\n        return marker_name"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _validate_label(self, label):\n\n        letter_pattern = compile(\"^[a-z]{1}$\")\n        number_pattern = compile(\"^[0]{1}$|^[1-9]{1,2}$\")\n        icon_pattern = compile(\"^[a-zA-Z ]{1,}$\")\n\n        if not match(letter_pattern, label)\\\n            and not match(number_pattern, label)\\\n                and not match(icon_pattern, label):\n                    raise InvalidLabelError(\n                        \"{} is not a valid label\".format(label)\n                    )\n\n        return label", "response": "Validates label raising error if invalid."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _validate_color(self, color):\n\n        three_digit_pattern = compile(\"^[a-f0-9]{3}$\")\n        six_digit_pattern = compile(\"^[a-f0-9]{6}$\")\n\n        if not match(three_digit_pattern, color)\\\n            and not match(six_digit_pattern, color):\n                raise InvalidColorError(\n                    \"{} is not a valid color\".format(color)\n                )\n\n        return color", "response": "Validates color raising error if invalid."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning an image tile vector tile or UTFGrid tile.", "response": "def tile(self, map_id, x, y, z, retina=False, \n             file_format=\"png\", style_id=None, timestamp=None):\n\n        \"\"\"Returns an image tile, vector tile, or UTFGrid\n        in the specified file format.\n\n        Parameters\n        ----------\n        map_id : str\n            The tile's unique identifier in the format username.id.\n\n        x : int\n            The tile's column, where 0 is the minimum value\n            and ((2**z) - 1) is the maximum value.\n\n        y : int\n            The tile's row, where 0 is the minimum value\n            and ((2**z) - 1) is the maximum value.\n\n        z : int\n            The tile's zoom level, where 0 is the minimum value\n            and 20 is the maximum value.\n\n        retina : bool, optional\n            The tile's scale, where True indicates Retina scale\n            (double scale) and False indicates regular scale.  \n\n            The default value is false.\n       \n        file_format : str, optional\n            The tile's file format.  \n\n            The default value is png.\n\n        style_id : str, optional\n            The tile's style id.  \n\n            style_id must be used together with timestamp.\n\n        timestamp : str, optional\n            The style id's ISO-formatted timestamp, found by \n            accessing the \"modified\" property of a style object.\n\n            timestamp must be used together with style_id.\n\n        Returns\n        -------\n        request.Response\n            The response object with a tile in the specified format.\n        \"\"\"\n\n        # Check x, y, and z.\n\n        if x is None or y is None or z is None:\n            raise ValidationError(\n                \"x, y, and z must be not be None\"\n            )\n\n        # Validate x, y, z, retina, and file_format.\n\n        x = self._validate_x(x, z)\n        y = self._validate_y(y, z)\n        z = self._validate_z(z)\n        retina = self._validate_retina(retina)\n        file_format = self._validate_file_format(file_format)\n\n        # Create dict to assist in building URI resource path.\n\n        path_values = dict(\n            map_id=map_id,\n            x=str(x),\n            y=str(y),\n            z=str(z)\n        )\n\n        # Start building URI resource path.\n\n        path_part = \"/{map_id}/{z}/{x}/{y}\"\n        uri = URITemplate(self.base_uri + path_part).expand(**path_values)\n\n        # Finish building URI resource path.\n        # As in static.py, this two-part process avoids \n        # undesired escaping of \"@\" in \"@2x.\"\n\n        path_part = \"{}.{}\".format(retina, file_format)\n        uri += path_part\n\n        # Validate timestamp and build URI query parameters.\n \n        query_parameters = dict()\n\n        if style_id is not None and timestamp is not None:\n            timestamp = self._validate_timestamp(timestamp)\n            style = \"{}@{}\".format(style_id, timestamp)\n            query_parameters[\"style\"] = style\n\n        # Send HTTP GET request.\n\n        response = self.session.get(uri, params=query_parameters)\n        self.handle_http_error(response)\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn vector features from Mapbox Editor projects as GeoJSON or KML.", "response": "def features(self, map_id, feature_format=\"json\"):\n        \"\"\"Returns vector features from Mapbox Editor projects\n        as GeoJSON or KML.\n\n        Parameters\n        ----------\n        map_id : str\n            The map's unique identifier in the format username.id.\n\n        feature_format : str, optional\n            The vector's feature format.\n\n            The default value is json.\n\n        Returns\n        -------\n        request.Response\n            The response object with vector features.\n        \"\"\"\n\n        # Validate feature_format.\n\n        feature_format = self._validate_feature_format(feature_format)\n   \n        # Create dict to assist in building URI resource path.\n\n        path_values = dict(\n            map_id=map_id,\n            feature_format=feature_format\n        )\n\n        # Build URI resource path.\n\n        path_part = \"/{map_id}/features.{feature_format}\"\n        uri = URITemplate(self.base_uri + path_part).expand(**path_values)\n\n        # Send HTTP GET request.\n\n        response = self.session.get(uri)\n        self.handle_http_error(response)\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef metadata(self, map_id, secure=False):\n\n        # Create dict to assist in building URI resource path.\n\n        path_values = dict(\n            map_id=map_id\n        )\n\n        # Build URI resource path.\n\n        path_part = \"/{map_id}.json\"\n        uri = URITemplate(self.base_uri + path_part).expand(**path_values)\n\n        # Build URI query parameters.\n\n        query_parameters = dict()\n\n        if secure:\n            query_parameters[\"secure\"] = \"\"\n\n        # Send HTTP GET request.\n\n        response = self.session.get(uri, params=query_parameters)\n        self.handle_http_error(response)\n\n        return response", "response": "Returns TileJSON metadata for a specified tileset."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a single marker image without any background map.", "response": "def marker(self, marker_name=None, label=None, \n               color=None, retina=False):\n        \"\"\"Returns a single marker image without any\n           background map.\n\n        Parameters\n        ----------\n        marker_name : str\n            The marker's shape and size.\n\n        label : str, optional\n            The marker's alphanumeric label.\n\n            Options are a through z, 0 through 99, or the\n            name of a valid Maki icon.\n\n        color : str, optional\n            The marker's color.\n\n            Options are three- or six-digit hexadecimal\n            color codes.\n\n        retina : bool, optional\n            The marker's scale, where True indicates Retina scale\n            (double scale) and False indicates regular scale.  \n\n            The default value is false.\n \n        Returns\n        -------\n        request.Response\n            The response object with the specified marker.\n        \"\"\"\n\n        # Check for marker_name.\n\n        if marker_name is None:\n            raise ValidationError(\n                \"marker_name is a required argument\"\n            )\n\n        # Validate marker_name and retina.\n\n        marker_name = self._validate_marker_name(marker_name)\n        retina = self._validate_retina(retina)\n\n        # Create dict and start building URI resource path.\n\n        path_values = dict(\n            marker_name=marker_name\n        )\n\n        path_part = \"/marker/{marker_name}\"\n\n        # Validate label, update dict,\n        # and continue building URI resource path.\n\n        if label is not None:\n            label = self._validate_label(label)\n            path_values[\"label\"] = label\n            path_part += \"-{label}\"\n\n        # Validate color, update dict,\n        # and continue building URI resource path.\n\n        if color is not None:\n            color = self._validate_color(color)\n            path_values[\"color\"] = color\n            path_part += \"+{color}\"\n\n        uri = URITemplate(self.base_uri + path_part).expand(**path_values)\n\n        # Finish building URI resource path.\n\n        path_part = \"{}.png\".format(retina)\n        uri += path_part\n\n        # Send HTTP GET request.\n\n        response = self.session.get(uri)\n        self.handle_http_error(response)\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntries to set color to the werkzeug log.", "response": "def set_werkzeug_log_color():\n    \"\"\"Try to set color to the werkzeug log.\"\"\"\n    from django.core.management.color import color_style\n    from werkzeug.serving import WSGIRequestHandler\n    from werkzeug._internal import _log\n\n    _style = color_style()\n    _orig_log = WSGIRequestHandler.log\n\n    def werk_log(self, type, message, *args):\n        try:\n            msg = '%s - - [%s] %s' % (\n                self.address_string(),\n                self.log_date_time_string(),\n                message % args,\n            )\n            http_code = str(args[1])\n        except Exception:\n            return _orig_log(type, message, *args)\n\n        # Utilize terminal colors, if available\n        if http_code[0] == '2':\n            # Put 2XX first, since it should be the common case\n            msg = _style.HTTP_SUCCESS(msg)\n        elif http_code[0] == '1':\n            msg = _style.HTTP_INFO(msg)\n        elif http_code == '304':\n            msg = _style.HTTP_NOT_MODIFIED(msg)\n        elif http_code[0] == '3':\n            msg = _style.HTTP_REDIRECT(msg)\n        elif http_code == '404':\n            msg = _style.HTTP_NOT_FOUND(msg)\n        elif http_code[0] == '4':\n            msg = _style.HTTP_BAD_REQUEST(msg)\n        else:\n            # Any 5XX, or any other response\n            msg = _style.HTTP_SERVER_ERROR(msg)\n\n        _log(type, msg)\n\n    WSGIRequestHandler.log = werk_log"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncleans up a slug by removing separator characters that occur at the beginning or end of a slug.", "response": "def _slug_strip(self, value):\n        \"\"\"\n        Clean up a slug by removing slug separator characters that occur at\n        the beginning or end of a slug.\n\n        If an alternate separator is used, it will also replace any instances\n        of the default '-' separator with the new separator.\n        \"\"\"\n        re_sep = '(?:-|%s)' % re.escape(self.separator)\n        value = re.sub('%s+' % re_sep, self.separator, value)\n        return re.sub(r'^%s+|%s+$' % (re_sep, re_sep), '', value)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting our string value to JSON after we load it from the DB", "response": "def to_python(self, value):\n        \"\"\"Convert our string value to JSON after we load it from the DB\"\"\"\n        if value is None or value == '':\n            return {}\n\n        if isinstance(value, six.string_types):\n            res = loads(value)\n        else:\n            res = value\n\n        if isinstance(res, dict):\n            return JSONDict(**res)\n        elif isinstance(res, list):\n            return JSONList(res)\n\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_db_prep_save(self, value, connection, **kwargs):\n        if value is None and self.null:\n            return None\n        # default values come in as strings; only non-strings should be\n        # run through `dumps`\n        if not isinstance(value, six.string_types):\n            value = dumps(value)\n\n        return value", "response": "Convert our JSON object to a string before we save"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _make_writeable(filename):\n    import stat\n    if sys.platform.startswith('java'):\n        # On Jython there is no os.access()\n        return\n    if not os.access(filename, os.W_OK):\n        st = os.stat(filename)\n        new_permissions = stat.S_IMODE(st.st_mode) | stat.S_IWUSR\n        os.chmod(filename, new_permissions)", "response": "Make sure that the file is writeable. Useful for our source is\n    read - only."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset up a logger (if no handlers exist) for console output, and file 'tee' output if desired.", "response": "def setup_logger(logger, stream, filename=None, fmt=None):\n    \"\"\"\n    Set up a logger (if no handlers exist) for console output,\n    and file 'tee' output if desired.\n    \"\"\"\n    if len(logger.handlers) < 1:\n        console = logging.StreamHandler(stream)\n        console.setLevel(logging.DEBUG)\n        console.setFormatter(logging.Formatter(fmt))\n        logger.addHandler(console)\n        logger.setLevel(logging.DEBUG)\n        logger.propagate = False\n\n        if filename:\n            outfile = logging.FileHandler(filename)\n            outfile.setLevel(logging.INFO)\n            outfile.setFormatter(logging.Formatter(\"%(asctime)s \" + (fmt if fmt else '%(message)s')))\n            logger.addHandler(outfile)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns full name or username.", "response": "def full_name(first_name, last_name, username, **extra):\n    \"\"\"Return full name or username.\"\"\"\n    name = \" \".join(n for n in [first_name, last_name] if n)\n    if not name:\n        return username\n    return name"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprinting the full name of the user in the format of a list of entries per line.", "response": "def address(self, qs):\n        \"\"\"\n        Single entry per line in the format of:\n            \"full name\" <my@address.com>;\n        \"\"\"\n        self.stdout.write(\"\\n\".join('\"%s\" <%s>;' % (full_name(**ent), ent['email']) for ent in qs))\n        self.stdout.write(\"\\n\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef emails(self, qs):\n        self.stdout.write(\",\\n\".join(ent['email'] for ent in qs))\n        self.stdout.write(\"\\n\")", "response": "Print the emails of the entries in the list qs."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef outlook(self, qs):\n        csvf = writer(sys.stdout)\n        columns = ['Name', 'E-mail Address', 'Notes', 'E-mail 2 Address', 'E-mail 3 Address',\n                   'Mobile Phone', 'Pager', 'Company', 'Job Title', 'Home Phone', 'Home Phone 2',\n                   'Home Fax', 'Home Address', 'Business Phone', 'Business Phone 2',\n                   'Business Fax', 'Business Address', 'Other Phone', 'Other Fax', 'Other Address']\n        csvf.writerow(columns)\n        empty = [''] * (len(columns) - 2)\n        for ent in qs:\n            csvf.writerow([full_name(**ent), ent['email']] + empty)", "response": "CSV format suitable for importing into outlook"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts a list of vCard objects into a vcard format.", "response": "def vcard(self, qs):\n        \"\"\"VCARD format.\"\"\"\n        try:\n            import vobject\n        except ImportError:\n            print(self.style.ERROR(\"Please install vobject to use the vcard export format.\"))\n            sys.exit(1)\n\n        out = sys.stdout\n        for ent in qs:\n            card = vobject.vCard()\n            card.add('fn').value = full_name(**ent)\n            if not ent['last_name'] and not ent['first_name']:\n                # fallback to fullname, if both first and lastname are not declared\n                card.add('n').value = vobject.vcard.Name(full_name(**ent))\n            else:\n                card.add('n').value = vobject.vcard.Name(ent['last_name'], ent['first_name'])\n            emailpart = card.add('email')\n            emailpart.value = ent['email']\n            emailpart.type_param = 'INTERNET'\n\n            out.write(card.serialize())"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nhighlights the source code of a single language.", "response": "def highlight(parser, token):\n    \"\"\"\n    Tag to put a highlighted source code <pre> block in your code.\n    This takes two arguments, the language and a little explaination message\n    that will be generated before the code.  The second argument is optional.\n\n    Your code will be fed through pygments so you can use any language it\n    supports.\n\n    Usage::\n\n      {% load highlighting %}\n      {% highlight 'python' 'Excerpt: blah.py' %}\n      def need_food(self):\n          print(\"Love is colder than death\")\n      {% endhighlight %}\n\n    \"\"\"\n    if not HAS_PYGMENTS:  # pragma: no cover\n        raise ImportError(\"Please install 'pygments' library to use highlighting.\")\n    nodelist = parser.parse(('endhighlight',))\n    parser.delete_first_token()\n    bits = token.split_contents()[1:]\n    if len(bits) < 1:\n        raise TemplateSyntaxError(\"'highlight' statement requires an argument\")\n    return CodeNode(bits[0], nodelist, *bits[1:])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_mysql_cnf(dbinfo):\n    read_default_file = dbinfo.get('OPTIONS', {}).get('read_default_file')\n    if read_default_file:\n        config = configparser.RawConfigParser({\n            'user': '',\n            'password': '',\n            'database': '',\n            'host': '',\n            'port': '',\n            'socket': '',\n        })\n        import os\n        config.read(os.path.expanduser(read_default_file))\n        try:\n            user = config.get('client', 'user')\n            password = config.get('client', 'password')\n            database_name = config.get('client', 'database')\n            database_host = config.get('client', 'host')\n            database_port = config.get('client', 'port')\n            socket = config.get('client', 'socket')\n\n            if database_host == 'localhost' and socket:\n                # mysql actually uses a socket if host is localhost\n                database_host = socket\n\n            return user, password, database_name, database_host, database_port\n\n        except configparser.NoSectionError:\n            pass\n\n    return '', '', '', '', ''", "response": "Parse mysql database config file for connection settings."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a dictionary mapping of job names together with their respective application class.", "response": "def get_jobs(when=None, only_scheduled=False):\n    \"\"\"\n    Return a dictionary mapping of job names together with their respective\n    application class.\n    \"\"\"\n    # FIXME: HACK: make sure the project dir is on the path when executed as ./manage.py\n    try:\n        cpath = os.path.dirname(os.path.realpath(sys.argv[0]))\n        ppath = os.path.dirname(cpath)\n        if ppath not in sys.path:\n            sys.path.append(ppath)\n    except Exception:\n        pass\n    _jobs = {}\n\n    for app_name in [app.name for app in apps.get_app_configs()]:\n        scandirs = (None, 'minutely', 'quarter_hourly', 'hourly', 'daily', 'weekly', 'monthly', 'yearly')\n        if when:\n            scandirs = None, when\n        for subdir in scandirs:\n            try:\n                path = find_job_module(app_name, subdir)\n                for name in find_jobs(path):\n                    if (app_name, name) in _jobs:\n                        raise JobError(\"Duplicate job %s\" % name)\n                    job = import_job(app_name, name, subdir)\n                    if only_scheduled and job.when is None:\n                        # only include jobs which are scheduled\n                        continue\n                    if when and job.when != when:\n                        # generic job not in same schedule\n                        continue\n                    _jobs[(app_name, name)] = job\n            except ImportError:\n                # No job module -- continue scanning\n                pass\n\n    return _jobs"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nformats a block of text into a single line of code.", "response": "def format_block(block, nlspaces=0):\n    \"\"\"\n    Format the given block of text, trimming leading/trailing\n    empty lines and any leading whitespace that is common to all lines.\n    The purpose is to let us list a code block as a multiline,\n    triple-quoted Python string, taking care of\n    indentation concerns.\n    http://code.activestate.com/recipes/145672/\n    \"\"\"\n    # separate block into lines\n    lines = smart_text(block).split('\\n')\n\n    # remove leading/trailing empty lines\n    while lines and not lines[0]:\n        del lines[0]\n    while lines and not lines[-1]:\n        del lines[-1]\n\n    # look at first line to see how much indentation to trim\n    ws = re.match(r'\\s*', lines[0]).group(0)\n    if ws:\n        lines = map(lambda x: x.replace(ws, '', 1), lines)\n\n    # remove leading/trailing blank lines (after leading ws removal)\n    # we do this again in case there were pure-whitespace lines\n    while lines and not lines[0]:\n        del lines[0]\n    while lines and not lines[-1]:\n        del lines[-1]\n\n    # account for user-specified leading spaces\n    flines = ['%s%s' % (' ' * nlspaces, line) for line in lines]\n\n    return '\\n'.join(flines) + '\\n'"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef widont(value, count=1):\n    def replace(matchobj):\n        return force_text('&nbsp;%s' % matchobj.group(1))\n    for i in range(count):\n        value = re_widont.sub(replace, force_text(value))\n    return value", "response": "Add an HTML non - breaking space between the final two words of the string to avoid widowed words."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd an HTML non-breaking space between the final two words at the end of (and in sentences just outside of) block level tags to avoid \"widowed\" words. Examples: >>> print(widont_html('<h2>Here is a simple example </h2> <p>Single</p>')) <h2>Here is a simple&nbsp;example </h2> <p>Single</p> >>> print(widont_html('<p>test me<br /> out</p><h2>Ok?</h2>Not in a p<p title=\"test me\">and this</p>')) <p>test&nbsp;me<br /> out</p><h2>Ok?</h2>Not in a&nbsp;p<p title=\"test me\">and&nbsp;this</p> >>> print(widont_html('leading text <p>test me out</p> trailing text')) leading&nbsp;text <p>test me&nbsp;out</p> trailing&nbsp;text", "response": "def widont_html(value):\n    \"\"\"\n    Add an HTML non-breaking space between the final two words at the end of\n    (and in sentences just outside of) block level tags to avoid \"widowed\"\n    words.\n\n    Examples:\n\n    >>> print(widont_html('<h2>Here is a simple  example  </h2> <p>Single</p>'))\n    <h2>Here is a simple&nbsp;example  </h2> <p>Single</p>\n\n    >>> print(widont_html('<p>test me<br /> out</p><h2>Ok?</h2>Not in a p<p title=\"test me\">and this</p>'))\n    <p>test&nbsp;me<br /> out</p><h2>Ok?</h2>Not in a&nbsp;p<p title=\"test me\">and&nbsp;this</p>\n\n    >>> print(widont_html('leading text  <p>test me out</p>  trailing text'))\n    leading&nbsp;text  <p>test me&nbsp;out</p>  trailing&nbsp;text\n    \"\"\"\n    def replace(matchobj):\n        return force_text('%s&nbsp;%s%s' % matchobj.groups())\n    return re_widont_html.sub(replace, force_text(value))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncopy the specified template directory to the copy_to location", "response": "def copy_template(template_name, copy_to, **options):\n    \"\"\"Copy the specified template directory to the copy_to location\"\"\"\n    import django_extensions\n\n    style = color_style()\n    ERROR = getattr(style, 'ERROR', lambda x: x)\n    SUCCESS = getattr(style, 'SUCCESS', lambda x: x)\n\n    template_dir = os.path.join(django_extensions.__path__[0], 'conf', template_name)\n    verbosity = options[\"verbosity\"]\n\n    # walks the template structure and copies it\n    for d, subdirs, files in os.walk(template_dir):\n        relative_dir = d[len(template_dir) + 1:]\n        if relative_dir and not os.path.exists(os.path.join(copy_to, relative_dir)):\n            os.mkdir(os.path.join(copy_to, relative_dir))\n        for i, subdir in enumerate(subdirs):\n            if subdir.startswith('.'):\n                del subdirs[i]\n        for f in files:\n            if f.endswith('.pyc') or f.startswith('.DS_Store'):\n                continue\n            path_old = os.path.join(d, f)\n            path_new = os.path.join(copy_to, relative_dir, f).rstrip(\".tmpl\")\n            if os.path.exists(path_new):\n                if verbosity > 1:\n                    print(ERROR(\"%s already exists\" % path_new))\n                continue\n            if verbosity > 1:\n                print(SUCCESS(\"%s\" % path_new))\n\n            with open(path_old, 'r') as fp_orig:\n                with open(path_new, 'w') as fp_new:\n                    fp_new.write(fp_orig.read())\n\n            try:\n                shutil.copymode(path_old, path_new)\n                _make_writeable(path_new)\n            except OSError:\n                sys.stderr.write(\"Notice: Couldn't set permission bits on %s. You're probably using an uncommon filesystem setup. No problem.\\n\" % path_new)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrun jobs from the signals", "response": "def runjobs_by_signals(self, when, options):\n        \"\"\" Run jobs from the signals \"\"\"\n        # Thanks for Ian Holsman for the idea and code\n        from django_extensions.management import signals\n        from django.conf import settings\n\n        verbosity = options[\"verbosity\"]\n        for app_name in settings.INSTALLED_APPS:\n            try:\n                __import__(app_name + '.management', '', '', [''])\n            except ImportError:\n                pass\n\n        for app in (app.models_module for app in apps.get_app_configs() if app.models_module):\n            if verbosity > 1:\n                app_name = '.'.join(app.__name__.rsplit('.')[:-1])\n                print(\"Sending %s job signal for: %s\" % (when, app_name))\n            if when == 'minutely':\n                signals.run_minutely_jobs.send(sender=app, app=app)\n            elif when == 'quarter_hourly':\n                signals.run_quarter_hourly_jobs.send(sender=app, app=app)\n            elif when == 'hourly':\n                signals.run_hourly_jobs.send(sender=app, app=app)\n            elif when == 'daily':\n                signals.run_daily_jobs.send(sender=app, app=app)\n            elif when == 'weekly':\n                signals.run_weekly_jobs.send(sender=app, app=app)\n            elif when == 'monthly':\n                signals.run_monthly_jobs.send(sender=app, app=app)\n            elif when == 'yearly':\n                signals.run_yearly_jobs.send(sender=app, app=app)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_version(version):\n    if len(version) > 2 and version[2] is not None:\n        if isinstance(version[2], int):\n            str_version = \"%s.%s.%s\" % version[:3]\n        else:\n            str_version = \"%s.%s_%s\" % version[:3]\n    else:\n        str_version = \"%s.%s\" % version[:2]\n\n    return str_version", "response": "Dynamically calculate the version based on VERSION tuple."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef indentby(parser, token):\n    args = token.split_contents()\n    largs = len(args)\n    if largs not in (2, 4):\n        raise template.TemplateSyntaxError(\"indentby tag requires 1 or 3 arguments\")\n    indent_level = args[1]\n    if_statement = None\n    if largs == 4:\n        if_statement = args[3]\n    nodelist = parser.parse(('endindentby', ))\n    parser.delete_first_token()\n    return IndentByNode(nodelist, indent_level, if_statement)", "response": "Adds indentation to text between the tags by the given indentation level."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting our string value to JSON after we load it from the DB", "response": "def to_python(self, value):\n        \"\"\" Convert our string value to JSON after we load it from the DB \"\"\"\n        if not value:\n            return {}\n        elif isinstance(value, six.string_types):\n            res = loads(value)\n            assert isinstance(res, dict)\n            return JSONDict(**res)\n        else:\n            return value"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_db_prep_save(self, value):\n        if not value:\n            return super(JSONField, self).get_db_prep_save(\"\")\n        else:\n            return super(JSONField, self).get_db_prep_save(dumps(value))", "response": "Convert our JSON object to a string before we save"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _urlopen_as_json(self, url, headers=None):\n        req = Request(url, headers=headers)\n        return json.loads(urlopen(req).read())", "response": "Shorcut for return contents as json"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if the requirement is frozen to pypi.", "response": "def check_pypi(self):\n        \"\"\"If the requirement is frozen to pypi, check for a new version.\"\"\"\n        for dist in get_installed_distributions():\n            name = dist.project_name\n            if name in self.reqs.keys():\n                self.reqs[name][\"dist\"] = dist\n\n        pypi = ServerProxy(\"https://pypi.python.org/pypi\")\n        for name, req in list(self.reqs.items()):\n            if req[\"url\"]:\n                continue  # skipping github packages.\n            elif \"dist\" in req:\n                dist = req[\"dist\"]\n                dist_version = LooseVersion(dist.version)\n                available = pypi.package_releases(req[\"pip_req\"].name, True) or pypi.package_releases(req[\"pip_req\"].name.replace('-', '_'), True)\n                available_version = self._available_version(dist_version, available)\n\n                if not available_version:\n                    msg = self.style.WARN(\"release is not on pypi (check capitalization and/or --extra-index-url)\")\n                elif self.options['show_newer'] and dist_version > available_version:\n                    msg = self.style.INFO(\"{0} available (newer installed)\".format(available_version))\n                elif available_version > dist_version:\n                    msg = self.style.INFO(\"{0} available\".format(available_version))\n                else:\n                    msg = \"up to date\"\n                    del self.reqs[name]\n                    continue\n                pkg_info = self.style.BOLD(\"{dist.project_name} {dist.version}\".format(dist=dist))\n            else:\n                msg = \"not installed\"\n                pkg_info = name\n            self.stdout.write(\"{pkg_info:40} {msg}\".format(pkg_info=pkg_info, msg=msg))\n            del self.reqs[name]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check_github(self):\n        for name, req in list(self.reqs.items()):\n            req_url = req[\"url\"]\n            if not req_url:\n                continue\n            req_url = str(req_url)\n            if req_url.startswith(\"git\") and \"github.com/\" not in req_url:\n                continue\n            if req_url.endswith((\".tar.gz\", \".tar.bz2\", \".zip\")):\n                continue\n\n            headers = {\n                \"content-type\": \"application/json\",\n            }\n            if self.github_api_token:\n                headers[\"Authorization\"] = \"token {0}\".format(self.github_api_token)\n            try:\n                path_parts = urlparse(req_url).path.split(\"#\", 1)[0].strip(\"/\").rstrip(\"/\").split(\"/\")\n\n                if len(path_parts) == 2:\n                    user, repo = path_parts\n\n                elif 'archive' in path_parts:\n                    # Supports URL of format:\n                    # https://github.com/django/django/archive/master.tar.gz#egg=Django\n                    # https://github.com/django/django/archive/master.zip#egg=Django\n                    user, repo = path_parts[:2]\n                    repo += '@' + path_parts[-1].replace('.tar.gz', '').replace('.zip', '')\n\n                else:\n                    self.style.ERROR(\"\\nFailed to parse %r\\n\" % (req_url, ))\n                    continue\n            except (ValueError, IndexError) as e:\n                self.stdout.write(self.style.ERROR(\"\\nFailed to parse %r: %s\\n\" % (req_url, e)))\n                continue\n\n            try:\n                test_auth = requests.get(\"https://api.github.com/django/\", headers=headers).json()\n            except HTTPError as e:\n                self.stdout.write(\"\\n%s\\n\" % str(e))\n                return\n\n            if \"message\" in test_auth and test_auth[\"message\"] == \"Bad credentials\":\n                self.stdout.write(self.style.ERROR(\"\\nGithub API: Bad credentials. Aborting!\\n\"))\n                return\n            elif \"message\" in test_auth and test_auth[\"message\"].startswith(\"API Rate Limit Exceeded\"):\n                self.stdout.write(self.style.ERROR(\"\\nGithub API: Rate Limit Exceeded. Aborting!\\n\"))\n                return\n\n            frozen_commit_sha = None\n            if \".git\" in repo:\n                repo_name, frozen_commit_full = repo.split(\".git\")\n                if frozen_commit_full.startswith(\"@\"):\n                    frozen_commit_sha = frozen_commit_full[1:]\n            elif \"@\" in repo:\n                repo_name, frozen_commit_sha = repo.split(\"@\")\n\n            if frozen_commit_sha is None:\n                msg = self.style.ERROR(\"repo is not frozen\")\n\n            if frozen_commit_sha:\n                branch_url = \"https://api.github.com/repos/{0}/{1}/branches\".format(user, repo_name)\n                branch_data = requests.get(branch_url, headers=headers).json()\n\n                frozen_commit_url = \"https://api.github.com/repos/{0}/{1}/commits/{2}\".format(\n                    user, repo_name, frozen_commit_sha\n                )\n                frozen_commit_data = requests.get(frozen_commit_url, headers=headers).json()\n\n                if \"message\" in frozen_commit_data and frozen_commit_data[\"message\"] == \"Not Found\":\n                    msg = self.style.ERROR(\"{0} not found in {1}. Repo may be private.\".format(frozen_commit_sha[:10], name))\n                elif frozen_commit_data[\"sha\"] in [branch[\"commit\"][\"sha\"] for branch in branch_data]:\n                    msg = self.style.BOLD(\"up to date\")\n                else:\n                    msg = self.style.INFO(\"{0} is not the head of any branch\".format(frozen_commit_data[\"sha\"][:10]))\n\n            if \"dist\" in req:\n                pkg_info = \"{dist.project_name} {dist.version}\".format(dist=req[\"dist\"])\n            elif frozen_commit_sha is None:\n                pkg_info = name\n            else:\n                pkg_info = \"{0} {1}\".format(name, frozen_commit_sha[:10])\n            self.stdout.write(\"{pkg_info:40} {msg}\".format(pkg_info=pkg_info, msg=msg))\n            del self.reqs[name]", "response": "Checks if the current version of the current branch is in github."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef check_other(self):\n        if self.reqs:\n            self.stdout.write(self.style.ERROR(\"\\nOnly pypi and github based requirements are supported:\"))\n            for name, req in self.reqs.items():\n                if \"dist\" in req:\n                    pkg_info = \"{dist.project_name} {dist.version}\".format(dist=req[\"dist\"])\n                elif \"url\" in req:\n                    pkg_info = \"{url}\".format(url=req[\"url\"])\n                else:\n                    pkg_info = \"unknown package\"\n                self.stdout.write(self.style.BOLD(\"{pkg_info:40} is not a pypi or github requirement\".format(pkg_info=pkg_info)))", "response": "Check if the other package is frozen somewhere other than pypi or github."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef copy_template(template_name, copy_to, tag_library_name):\n    import django_extensions\n    import shutil\n\n    template_dir = os.path.join(django_extensions.__path__[0], 'conf', template_name)\n\n    # walk the template structure and copies it\n    for d, subdirs, files in os.walk(template_dir):\n        relative_dir = d[len(template_dir) + 1:]\n        if relative_dir and not os.path.exists(os.path.join(copy_to, relative_dir)):\n            os.mkdir(os.path.join(copy_to, relative_dir))\n        for i, subdir in enumerate(subdirs):\n            if subdir.startswith('.'):\n                del subdirs[i]\n        for f in files:\n            if f.endswith('.pyc') or f.startswith('.DS_Store'):\n                continue\n            path_old = os.path.join(d, f)\n            path_new = os.path.join(copy_to, relative_dir, f.replace('sample', tag_library_name))\n            if os.path.exists(path_new):\n                path_new = os.path.join(copy_to, relative_dir, f)\n                if os.path.exists(path_new):\n                    continue\n            path_new = path_new.rstrip(\".tmpl\")\n            fp_old = open(path_old, 'r')\n            fp_new = open(path_new, 'w')\n            fp_new.write(fp_old.read())\n            fp_old.close()\n            fp_new.close()\n            try:\n                shutil.copymode(path_old, path_new)\n                _make_writeable(path_new)\n            except OSError:\n                sys.stderr.write(\"Notice: Couldn't set permission bits on %s. You're probably using an uncommon filesystem setup. No problem.\\n\" % path_new)", "response": "Copy the specified template directory to the copy_to location"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the Keyczar class to use.", "response": "def get_crypt_class(self):\n        \"\"\"\n        Get the Keyczar class to use.\n\n        The class can be customized with the ENCRYPTED_FIELD_MODE setting. By default,\n        this setting is DECRYPT_AND_ENCRYPT. Set this to ENCRYPT to disable decryption.\n        This is necessary if you are only providing public keys to Keyczar.\n\n        Returns:\n            keyczar.Encrypter if ENCRYPTED_FIELD_MODE is ENCRYPT.\n            keyczar.Crypter if ENCRYPTED_FIELD_MODE is DECRYPT_AND_ENCRYPT.\n\n        Override this method to customize the type of Keyczar class returned.\n        \"\"\"\n        crypt_type = getattr(settings, 'ENCRYPTED_FIELD_MODE', 'DECRYPT_AND_ENCRYPT')\n        if crypt_type == 'ENCRYPT':\n            crypt_class_name = 'Encrypter'\n        elif crypt_type == 'DECRYPT_AND_ENCRYPT':\n            crypt_class_name = 'Crypter'\n        else:\n            raise ImproperlyConfigured(\n                'ENCRYPTED_FIELD_MODE must be either DECRYPT_AND_ENCRYPT '\n                'or ENCRYPT, not %s.' % crypt_type)\n        return getattr(keyczar, crypt_class_name)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nresetting the database for this project.", "response": "def handle(self, *args, **options):\n        \"\"\"\n        Reset the database for this project.\n\n        Note: Transaction wrappers are in reverse as a work around for\n        autocommit, anybody know how to do this the right way?\n        \"\"\"\n        router = options['router']\n        dbinfo = settings.DATABASES.get(router)\n        if dbinfo is None:\n            raise CommandError(\"Unknown database router %s\" % router)\n\n        engine = dbinfo.get('ENGINE')\n\n        user = password = database_name = database_host = database_port = ''\n        if engine == 'mysql':\n            (user, password, database_name, database_host, database_port) = parse_mysql_cnf(dbinfo)\n\n        user = options['user'] or dbinfo.get('USER') or user\n        password = options['password'] or dbinfo.get('PASSWORD') or password\n        owner = options['owner'] or user\n\n        database_name = options['dbname'] or dbinfo.get('NAME') or database_name\n        if database_name == '':\n            raise CommandError(\"You need to specify DATABASE_NAME in your Django settings file.\")\n\n        database_host = dbinfo.get('HOST') or database_host\n        database_port = dbinfo.get('PORT') or database_port\n\n        verbosity = options[\"verbosity\"]\n        if options['interactive']:\n            confirm = input(\"\"\"\nYou have requested a database reset.\nThis will IRREVERSIBLY DESTROY\nALL data in the database \"%s\".\nAre you sure you want to do this?\n\nType 'yes' to continue, or 'no' to cancel: \"\"\" % (database_name,))\n        else:\n            confirm = 'yes'\n\n        if confirm != 'yes':\n            print(\"Reset cancelled.\")\n            return\n\n        SQLITE_ENGINES = getattr(settings, 'DJANGO_EXTENSIONS_RESET_DB_SQLITE_ENGINES', (\n            'django.db.backends.sqlite3',\n            'django.db.backends.spatialite',\n        ))\n        MYSQL_ENGINES = getattr(settings, 'DJANGO_EXTENSIONS_RESET_DB_MYSQL_ENGINES', (\n            'django.db.backends.mysql',\n        ))\n        POSTGRESQL_ENGINES = getattr(settings, 'DJANGO_EXTENSIONS_RESET_DB_POSTGRESQL_ENGINES', (\n            'django.db.backends.postgresql',\n            'django.db.backends.postgresql_psycopg2',\n            'django.db.backends.postgis',\n            'psqlextra.backend',\n        ))\n\n        if engine in SQLITE_ENGINES:\n            try:\n                logging.info(\"Unlinking %s database\", engine)\n                os.unlink(database_name)\n            except OSError:\n                pass\n\n        elif engine in MYSQL_ENGINES:\n            import MySQLdb as Database\n            kwargs = {\n                'user': user,\n                'passwd': password,\n            }\n            if database_host.startswith('/'):\n                kwargs['unix_socket'] = database_host\n            else:\n                kwargs['host'] = database_host\n\n            if database_port:\n                kwargs['port'] = int(database_port)\n\n            connection = Database.connect(**kwargs)\n            drop_query = 'DROP DATABASE IF EXISTS `%s`' % database_name\n            utf8_support = '' if options['no_utf8_support'] else 'CHARACTER SET utf8'\n            create_query = 'CREATE DATABASE `%s` %s' % (database_name, utf8_support)\n            logging.info('Executing... \"%s\"', drop_query)\n            connection.query(drop_query)\n            logging.info('Executing... \"%s\"', create_query)\n            connection.query(create_query.strip())\n\n        elif engine in POSTGRESQL_ENGINES:\n            import psycopg2 as Database  # NOQA\n\n            conn_params = {'database': 'template1'}\n            if user:\n                conn_params['user'] = user\n            if password:\n                conn_params['password'] = password\n            if database_host:\n                conn_params['host'] = database_host\n            if database_port:\n                conn_params['port'] = database_port\n\n            connection = Database.connect(**conn_params)\n            connection.set_isolation_level(0)  # autocommit false\n            cursor = connection.cursor()\n\n            if options['close_sessions']:\n                close_sessions_query = \"\"\"\n                    SELECT pg_terminate_backend(pg_stat_activity.pid)\n                    FROM pg_stat_activity\n                    WHERE pg_stat_activity.datname = '%s';\n                \"\"\" % database_name\n                logging.info('Executing... \"%s\"', close_sessions_query.strip())\n                try:\n                    cursor.execute(close_sessions_query)\n                except Database.ProgrammingError as e:\n                    logging.exception(\"Error: %s\", str(e))\n\n            drop_query = \"DROP DATABASE \\\"%s\\\";\" % database_name\n            logging.info('Executing... \"%s\"', drop_query)\n            try:\n                cursor.execute(drop_query)\n            except Database.ProgrammingError as e:\n                logging.exception(\"Error: %s\", str(e))\n\n            create_query = \"CREATE DATABASE \\\"%s\\\"\" % database_name\n            if owner:\n                create_query += \" WITH OWNER = \\\"%s\\\" \" % owner\n            create_query += \" ENCODING = 'UTF8'\"\n\n            if settings.DEFAULT_TABLESPACE:\n                create_query += ' TABLESPACE = %s;' % settings.DEFAULT_TABLESPACE\n            else:\n                create_query += ';'\n\n            logging.info('Executing... \"%s\"', create_query)\n            cursor.execute(create_query)\n\n        else:\n            raise CommandError(\"Unknown database engine %s\" % engine)\n\n        if verbosity >= 2 or options['interactive']:\n            print(\"Reset successful.\")"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _postgresql(self, dbhost, dbport, dbname, dbuser, dbpass, dsn_style=None):  # noqa\n        dsn = []\n\n        if dsn_style is None or dsn_style == 'all' or dsn_style == 'keyvalue':\n            dsnstr = \"host='{0}' dbname='{2}' user='{3}' password='{4}'\"\n\n            if dbport is not None:\n                dsnstr += \" port='{1}'\"\n\n            dsn.append(dsnstr.format(dbhost,\n                                     dbport,\n                                     dbname,\n                                     dbuser,\n                                     dbpass,))\n\n        if dsn_style == 'all' or dsn_style == 'kwargs':\n            dsnstr = \"host='{0}', database='{2}', user='{3}', password='{4}'\"\n            if dbport is not None:\n                dsnstr += \", port='{1}'\"\n\n            dsn.append(dsnstr.format(dbhost,\n                                     dbport,\n                                     dbname,\n                                     dbuser,\n                                     dbpass))\n\n        if dsn_style == 'all' or dsn_style == 'uri':\n            dsnstr = \"postgresql://{user}:{password}@{host}/{name}\"\n\n            dsn.append(dsnstr.format(\n                host=\"{host}:{port}\".format(host=dbhost, port=dbport) if dbport else dbhost,  # noqa\n                name=dbname, user=dbuser, password=dbpass))\n\n        if dsn_style == 'all' or dsn_style == 'pgpass':\n            dsn.append(':'.join(map(str, filter(\n                None, [dbhost, dbport, dbname, dbuser, dbpass]))))\n\n        return dsn", "response": "Returns a string that can be used to connect to PostgreSQL."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef orm_item_locator(orm_obj):\n\n    the_class = orm_obj._meta.object_name\n    original_class = the_class\n    pk_name = orm_obj._meta.pk.name\n    original_pk_name = pk_name\n    pk_value = getattr(orm_obj, pk_name)\n\n    while hasattr(pk_value, \"_meta\") and hasattr(pk_value._meta, \"pk\") and hasattr(pk_value._meta.pk, \"name\"):\n        the_class = pk_value._meta.object_name\n        pk_name = pk_value._meta.pk.name\n        pk_value = getattr(pk_value, pk_name)\n\n    clean_dict = make_clean_dict(orm_obj.__dict__)\n\n    for key in clean_dict:\n        v = clean_dict[key]\n        if v is not None and not isinstance(v, (six.string_types, six.integer_types, float, datetime.datetime)):\n            clean_dict[key] = six.u(\"%s\" % v)\n\n    output = \"\"\" importer.locate_object(%s, \"%s\", %s, \"%s\", %s, %s ) \"\"\" % (\n        original_class, original_pk_name,\n        the_class, pk_name, pk_value, clean_dict\n    )\n    return output", "response": "This function is used to locate an object that will not be exported is required."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_models(app_labels):\n\n    # These models are not to be output, e.g. because they can be generated automatically\n    # TODO: This should be \"appname.modelname\" string\n    EXCLUDED_MODELS = (ContentType, )\n\n    models = []\n\n    # If no app labels are given, return all\n    if not app_labels:\n        for app in apps.get_app_configs():\n            models += [m for m in apps.get_app_config(app.label).get_models()\n                       if m not in EXCLUDED_MODELS]\n        return models\n\n    # Get all relevant apps\n    for app_label in app_labels:\n        # If a specific model is mentioned, get only that model\n        if \".\" in app_label:\n            app_label, model_name = app_label.split(\".\", 1)\n            models.append(apps.get_model(app_label, model_name))\n        # Get all models for a given app\n        else:\n            models += [m for m in apps.get_app_config(app_label).get_models()\n                       if m not in EXCLUDED_MODELS]\n\n    return models", "response": "Get a list of models for the given app labels."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef flatten_blocks(lines, num_indents=-1):\n    # The standard indent is four spaces\n    INDENTATION = \" \" * 4\n\n    if not lines:\n        return \"\"\n\n    # If this is a string, add the indentation and finish here\n    if isinstance(lines, six.string_types):\n        return INDENTATION * num_indents + lines\n\n    # If this is not a string, join the lines and recurse\n    return \"\\n\".join([flatten_blocks(line, num_indents + 1) for line in lines])", "response": "Flatten a list of lines into a string containing a list of indentation and a list of lines."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_attribute_value(item, field, context, force=False, skip_autofield=True):\n    # Find the value of the field, catching any database issues\n    try:\n        value = getattr(item, field.name)\n    except ObjectDoesNotExist:\n        raise SkipValue('Could not find object for %s.%s, ignoring.\\n' % (item.__class__.__name__, field.name))\n\n    # AutoField: We don't include the auto fields, they'll be automatically recreated\n    if skip_autofield and isinstance(field, AutoField):\n        raise SkipValue()\n\n    # Some databases (eg MySQL) might store boolean values as 0/1, this needs to be cast as a bool\n    elif isinstance(field, BooleanField) and value is not None:\n        return repr(bool(value))\n\n    # Post file-storage-refactor, repr() on File/ImageFields no longer returns the path\n    elif isinstance(field, FileField):\n        return repr(force_text(value))\n\n    # ForeignKey fields, link directly using our stored python variable name\n    elif isinstance(field, ForeignKey) and value is not None:\n\n        # Special case for contenttype foreign keys: no need to output any\n        # content types in this script, as they can be generated again\n        # automatically.\n        # NB: Not sure if \"is\" will always work\n        if field.remote_field.model is ContentType:\n            return 'ContentType.objects.get(app_label=\"%s\", model=\"%s\")' % (value.app_label, value.model)\n\n        # Generate an identifier (key) for this foreign object\n        pk_name = value._meta.pk.name\n        key = '%s_%s' % (value.__class__.__name__, getattr(value, pk_name))\n\n        if key in context:\n            variable_name = context[key]\n            # If the context value is set to None, this should be skipped.\n            # This identifies models that have been skipped (inheritance)\n            if variable_name is None:\n                raise SkipValue()\n            # Return the variable name listed in the context\n            return \"%s\" % variable_name\n        elif value.__class__ not in context[\"__avaliable_models\"] or force:\n            context[\"__extra_imports\"][value._meta.object_name] = value.__module__\n            item_locator = orm_item_locator(value)\n            return item_locator\n        else:\n            raise DoLater('(FK) %s.%s\\n' % (item.__class__.__name__, field.name))\n\n    elif isinstance(field, (DateField, DateTimeField)) and value is not None:\n        return \"dateutil.parser.parse(\\\"%s\\\")\" % value.isoformat()\n\n    # A normal field (e.g. a python built-in)\n    else:\n        return repr(value)", "response": "Get the value of the given attribute from the given item."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck that all the depenedencies for this model are already in the queue.", "response": "def check_dependencies(model, model_queue, avaliable_models):\n    \"\"\" Check that all the depenedencies for this model are already in the queue. \"\"\"\n    # A list of allowed links: existing fields, itself and the special case ContentType\n    allowed_links = [m.model.__name__ for m in model_queue] + [model.__name__, 'ContentType']\n\n    # For each ForeignKey or ManyToMany field, check that a link is possible\n\n    for field in model._meta.fields:\n        if not field.remote_field:\n            continue\n        if field.remote_field.model.__name__ not in allowed_links:\n            if field.remote_field.model not in avaliable_models:\n                continue\n            return False\n\n    for field in model._meta.many_to_many:\n        if not field.remote_field:\n            continue\n        if field.remote_field.model.__name__ not in allowed_links:\n            return False\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntake the stored imports and converts them to lines", "response": "def get_import_lines(self):\n        \"\"\" Take the stored imports and converts them to lines \"\"\"\n        if self.imports:\n            return [\"from %s import %s\" % (value, key) for key, value in self.imports.items()]\n        else:\n            return []"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of lists or strings representing the code body.", "response": "def get_lines(self):\n        \"\"\"\n        Return a list of lists or strings, representing the code body.\n        Each list is a block, each string is a statement.\n        \"\"\"\n        code = []\n\n        for counter, item in enumerate(self.model._default_manager.all()):\n            instance = InstanceCode(instance=item, id=counter + 1, context=self.context, stdout=self.stdout, stderr=self.stderr, options=self.options)\n            self.instances.append(instance)\n            if instance.waiting_list:\n                code += instance.lines\n\n        # After each instance has been processed, try again.\n        # This allows self referencing fields to work.\n        for instance in self.instances:\n            if instance.waiting_list:\n                code += instance.lines\n\n        return code"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of lists or strings representing the code body.", "response": "def get_lines(self, force=False):\n        \"\"\"\n        Return a list of lists or strings, representing the code body.\n        Each list is a block, each string is a statement.\n\n        force (True or False): if an attribute object cannot be included,\n        it is usually skipped to be processed later. With 'force' set, there\n        will be no waiting: a get_or_create() call is written instead.\n        \"\"\"\n        code_lines = []\n\n        # Don't return anything if this is an instance that should be skipped\n        if self.skip():\n            return []\n\n        # Initialise our new object\n        # e.g. model_name_35 = Model()\n        code_lines += self.instantiate()\n\n        # Add each field\n        # e.g. model_name_35.field_one = 1034.91\n        #      model_name_35.field_two = \"text\"\n        code_lines += self.get_waiting_list()\n\n        if force:\n            # TODO: Check that M2M are not affected\n            code_lines += self.get_waiting_list(force=force)\n\n        # Print the save command for our new object\n        # e.g. model_name_35.save()\n        if code_lines:\n            code_lines.append(\"%s = importer.save_or_locate(%s)\\n\" % (self.variable_name, self.variable_name))\n\n        code_lines += self.get_many_to_many_lines(force=force)\n\n        return code_lines"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef skip(self):\n        if self.skip_me is not None:\n            return self.skip_me\n\n        cls = self.instance.__class__\n        using = router.db_for_write(cls, instance=self.instance)\n        collector = Collector(using=using)\n        collector.collect([self.instance], collect_related=False)\n        sub_objects = sum([list(i) for i in collector.data.values()], [])\n        sub_objects_parents = [so._meta.parents for so in sub_objects]\n        if [self.model in p for p in sub_objects_parents].count(True) == 1:\n            # since this instance isn't explicitly created, it's variable name\n            # can't be referenced in the script, so record None in context dict\n            pk_name = self.instance._meta.pk.name\n            key = '%s_%s' % (self.model.__name__, getattr(self.instance, pk_name))\n            self.context[key] = None\n            self.skip_me = True\n        else:\n            self.skip_me = False\n\n        return self.skip_me", "response": "Determine whether or not this object should be skipped."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef instantiate(self):\n        # e.g. model_name_35 = Model()\n        code_lines = []\n\n        if not self.instantiated:\n            code_lines.append(\"%s = %s()\" % (self.variable_name, self.model.__name__))\n            self.instantiated = True\n\n            # Store our variable name for future foreign key references\n            pk_name = self.instance._meta.pk.name\n            key = '%s_%s' % (self.model.__name__, getattr(self.instance, pk_name))\n            self.context[key] = self.variable_name\n\n        return code_lines", "response": "Write lines for instantiation of the object."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of code lines for any waiting fields that can be completed now.", "response": "def get_waiting_list(self, force=False):\n        \"\"\" Add lines for any waiting fields that can be completed now. \"\"\"\n\n        code_lines = []\n        skip_autofield = self.options['skip_autofield']\n\n        # Process normal fields\n        for field in list(self.waiting_list):\n            try:\n                # Find the value, add the line, remove from waiting list and move on\n                value = get_attribute_value(self.instance, field, self.context, force=force, skip_autofield=skip_autofield)\n                code_lines.append('%s.%s = %s' % (self.variable_name, field.name, value))\n                self.waiting_list.remove(field)\n            except SkipValue:\n                # Remove from the waiting list and move on\n                self.waiting_list.remove(field)\n                continue\n            except DoLater:\n                # Move on, maybe next time\n                continue\n\n        return code_lines"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_many_to_many_lines(self, force=False):\n\n        lines = []\n\n        for field, rel_items in self.many_to_many_waiting_list.items():\n            for rel_item in list(rel_items):\n                try:\n                    pk_name = rel_item._meta.pk.name\n                    key = '%s_%s' % (rel_item.__class__.__name__, getattr(rel_item, pk_name))\n                    value = \"%s\" % self.context[key]\n                    lines.append('%s.%s.add(%s)' % (self.variable_name, field.name, value))\n                    self.many_to_many_waiting_list[field].remove(rel_item)\n                except KeyError:\n                    if force:\n                        item_locator = orm_item_locator(rel_item)\n                        self.context[\"__extra_imports\"][rel_item._meta.object_name] = rel_item.__module__\n                        lines.append('%s.%s.add( %s )' % (self.variable_name, field.name, item_locator))\n                        self.many_to_many_waiting_list[field].remove(rel_item)\n\n        if lines:\n            lines.append(\"\")\n\n        return lines", "response": "Generate lines that define many to many relations for this instance."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _queue_models(self, models, context):\n        model_queue = []\n        number_remaining_models = len(models)\n        # Max number of cycles allowed before we call it an infinite loop.\n        MAX_CYCLES = number_remaining_models\n        allowed_cycles = MAX_CYCLES\n\n        while number_remaining_models > 0:\n            previous_number_remaining_models = number_remaining_models\n\n            model = models.pop(0)\n\n            # If the model is ready to be processed, add it to the list\n            if check_dependencies(model, model_queue, context[\"__avaliable_models\"]):\n                model_class = ModelCode(model=model, context=context, stdout=self.stdout, stderr=self.stderr, options=self.options)\n                model_queue.append(model_class)\n\n            # Otherwise put the model back at the end of the list\n            else:\n                models.append(model)\n\n            # Check for infinite loops.\n            # This means there is a cyclic foreign key structure\n            # That cannot be resolved by re-ordering\n            number_remaining_models = len(models)\n            if number_remaining_models == previous_number_remaining_models:\n                allowed_cycles -= 1\n                if allowed_cycles <= 0:\n                    # Add the remaining models, but do not remove them from the model list\n                    missing_models = [ModelCode(model=m, context=context, stdout=self.stdout, stderr=self.stderr, options=self.options) for m in models]\n                    model_queue += missing_models\n                    # Replace the models with the model class objects\n                    # (sure, this is a little bit of hackery)\n                    models[:] = missing_models\n                    break\n            else:\n                allowed_cycles = MAX_CYCLES\n\n        return model_queue", "response": "Queue the models for the foreign key structure."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sql_to_dict(self, query, param):\n        cursor = connection.cursor()\n        cursor.execute(query, param)\n        fieldnames = [name[0] for name in cursor.description]\n        result = []\n        for row in cursor.fetchall():\n            rowset = []\n            for field in zip(fieldnames, row):\n                rowset.append(field)\n            result.append(dict(rowset))\n        return result", "response": "Execute a query and return a list of dicts where each element is a list of dicts each element is a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprints differences to stdout", "response": "def print_diff(self, style=no_style()):\n        \"\"\" Print differences to stdout \"\"\"\n        if self.options['sql']:\n            self.print_diff_sql(style)\n        else:\n            self.print_diff_text(style)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pygments_required(func):\n    def wrapper(*args, **kwargs):\n        if not HAS_PYGMENTS:  # pragma: no cover\n            raise ImportError(\n                \"Please install 'pygments' library to use syntax_color.\")\n        rv = func(*args, **kwargs)\n        return rv\n    return wrapper", "response": "Decorator that ensures that pygments is installed. Raise ImportError if pygments is not installed."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the index of the class with the given id on fks", "response": "def index(fks, id):\n    \"\"\"\n    Look for the id on fks, fks is an array of arrays, each array has on [1]\n    the id of the class in a dia diagram.  When not present returns None, else\n    it returns the position of the class with id on fks\n    \"\"\"\n    for i, j in fks.items():\n        if fks[i][1] == id:\n            return i\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef addparentstofks(rels, fks):\n    for j in rels:\n        son = index(fks, j[1])\n        parent = index(fks, j[0])\n        fks[son][2] = fks[son][2].replace(\"models.Model\", parent)\n        if parent not in fks[son][0]:\n            fks[son][0].append(parent)", "response": "Add parent class to the list of relations between parents and sons and a dict of dicts of base class names."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a string describing a form based on the model.", "response": "def describe_form(label, fields):\n    \"\"\" Return a string describing a form based on the model \"\"\"\n    try:\n        app_name, model_name = label.split('.')[-2:]\n    except (IndexError, ValueError):\n        raise CommandError(\"Need application and model name in the form: appname.model\")\n    model = apps.get_model(app_name, model_name)\n\n    opts = model._meta\n    field_list = []\n    for f in opts.fields + opts.many_to_many:\n        if not f.editable:\n            continue\n        if fields and f.name not in fields:\n            continue\n        formfield = f.formfield()\n        if '__dict__' not in dir(formfield):\n            continue\n        attrs = {}\n        valid_fields = ['required', 'initial', 'max_length', 'min_length', 'max_value', 'min_value', 'max_digits', 'decimal_places', 'choices', 'help_text', 'label']\n        for k, v in formfield.__dict__.items():\n            if k in valid_fields and v is not None:\n                # ignore defaults, to minimize verbosity\n                if k == 'required' and v:\n                    continue\n                if k == 'help_text' and not v:\n                    continue\n                if k == 'widget':\n                    attrs[k] = v.__class__\n                elif k in ['help_text', 'label']:\n                    attrs[k] = str(force_text(v).strip())\n                else:\n                    attrs[k] = v\n\n        params = ', '.join(['%s=%r' % (k, v) for k, v in sorted(attrs.items())])\n        field_list.append('    %(field_name)s = forms.%(field_type)s(%(params)s)' % {\n            'field_name': f.name,\n            'field_type': formfield.__class__.__name__,\n            'params': params\n        })\n    return '''\nfrom django import forms\nfrom %(app_name)s.models import %(object_name)s\n\nclass %(object_name)sForm(forms.Form):\n%(field_list)s\n''' % {'app_name': app_name, 'object_name': opts.object_name, 'field_list': '\\n'.join(field_list)}"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_app_name(mod_name):\n    rparts = list(reversed(mod_name.split('.')))\n    try:\n        try:\n            return rparts[rparts.index(MODELS_MODULE_NAME) + 1]\n        except ValueError:\n            # MODELS_MODULE_NAME ('models' string) is not found\n            return rparts[1]\n    except IndexError:\n        # Some weird model naming scheme like in Sentry.\n        return mod_name", "response": "Retrieve application name from models. py module path"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nimport the items in import_directives and returns a list of the imported items", "response": "def import_items(import_directives, style, quiet_load=False):\n    \"\"\"\n    Import the items in import_directives and return a list of the imported items\n\n    Each item in import_directives should be one of the following forms\n        * a tuple like ('module.submodule', ('classname1', 'classname2')), which indicates a 'from module.submodule import classname1, classname2'\n        * a tuple like ('module.submodule', 'classname1'), which indicates a 'from module.submodule import classname1'\n        * a tuple like ('module.submodule', '*'), which indicates a 'from module.submodule import *'\n        * a simple 'module.submodule' which indicates 'import module.submodule'.\n\n    Returns a dict mapping the names to the imported items\n    \"\"\"\n    imported_objects = {}\n    for directive in import_directives:\n        try:\n            # First try a straight import\n            if isinstance(directive, six.string_types):\n                imported_object = __import__(directive)\n                imported_objects[directive.split('.')[0]] = imported_object\n                if not quiet_load:\n                    print(style.SQL_COLTYPE(\"import %s\" % directive))\n                continue\n            elif isinstance(directive, (list, tuple)) and len(directive) == 2:\n                if not isinstance(directive[0], six.string_types):\n                    if not quiet_load:\n                        print(style.ERROR(\"Unable to import %r: module name must be of type string\" % directive[0]))\n                    continue\n                if isinstance(directive[1], (list, tuple)) and all(isinstance(e, six.string_types) for e in directive[1]):\n                    # Try the ('module.submodule', ('classname1', 'classname2')) form\n                    imported_object = __import__(directive[0], {}, {}, directive[1])\n                    imported_names = []\n                    for name in directive[1]:\n                        try:\n                            imported_objects[name] = getattr(imported_object, name)\n                        except AttributeError:\n                            if not quiet_load:\n                                print(style.ERROR(\"Unable to import %r from %r: %r does not exist\" % (name, directive[0], name)))\n                        else:\n                            imported_names.append(name)\n                    if not quiet_load:\n                        print(style.SQL_COLTYPE(\"from %s import %s\" % (directive[0], ', '.join(imported_names))))\n                elif isinstance(directive[1], six.string_types):\n                    # If it is a tuple, but the second item isn't a list, so we have something like ('module.submodule', 'classname1')\n                    # Check for the special '*' to import all\n                    if directive[1] == '*':\n                        imported_object = __import__(directive[0], {}, {}, directive[1])\n                        for k in dir(imported_object):\n                            imported_objects[k] = getattr(imported_object, k)\n                        if not quiet_load:\n                            print(style.SQL_COLTYPE(\"from %s import *\" % directive[0]))\n                    else:\n                        imported_object = getattr(__import__(directive[0], {}, {}, [directive[1]]), directive[1])\n                        imported_objects[directive[1]] = imported_object\n                        if not quiet_load:\n                            print(style.SQL_COLTYPE(\"from %s import %s\" % (directive[0], directive[1])))\n                else:\n                    if not quiet_load:\n                        print(style.ERROR(\"Unable to import %r from %r: names must be of type string\" % (directive[1], directive[0])))\n            else:\n                if not quiet_load:\n                    print(style.ERROR(\"Unable to import %r: names must be of type string\" % directive))\n        except ImportError:\n            try:\n                if not quiet_load:\n                    print(style.ERROR(\"Unable to import %r\" % directive))\n            except TypeError:\n                if not quiet_load:\n                    print(style.ERROR(\"Unable to import %r from %r\" % directive))\n\n    return imported_objects"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef truncateletters(value, arg):\n    warnings.warn(\n        \"`django_extensions.templatetags.truncate_letters` is deprecated. \"\n        \"You should use `django.template.defaultfilters.truncatechars` instead\",  # noqa\n        RemovedInNextVersionWarning,\n        stacklevel=2,\n    )\n    return truncatechars(value, arg)", "response": "Truncates a string after a certain number of letters"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_generic_fields():\n    generic_fields = []\n    for model in apps.get_models():\n        for field_name, field in model.__dict__.items():\n            if isinstance(field, GenericForeignKey):\n                generic_fields.append(field)\n    return generic_fields", "response": "Return a list of all GenericForeignKeys in all models."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmerge several model instances into one.", "response": "def merge_model_instances(self, primary_object, alias_objects):\n        \"\"\"\n        Merge several model instances into one, the `primary_object`.\n        Use this function to merge model objects and migrate all of the related\n        fields from the alias objects the primary object.\n        \"\"\"\n        generic_fields = get_generic_fields()\n\n        # get related fields\n        related_fields = list(filter(\n            lambda x: x.is_relation is True,\n            primary_object._meta.get_fields()))\n\n        many_to_many_fields = list(filter(\n            lambda x: x.many_to_many is True, related_fields))\n\n        related_fields = list(filter(\n            lambda x: x.many_to_many is False, related_fields))\n\n        # Loop through all alias objects and migrate their references to the\n        # primary object\n        deleted_objects = []\n        deleted_objects_count = 0\n        for alias_object in alias_objects:\n            # Migrate all foreign key references from alias object to primary\n            # object.\n            for many_to_many_field in many_to_many_fields:\n                alias_varname = many_to_many_field.name\n                related_objects = getattr(alias_object, alias_varname)\n                for obj in related_objects.all():\n                    try:\n                        # Handle regular M2M relationships.\n                        getattr(alias_object, alias_varname).remove(obj)\n                        getattr(primary_object, alias_varname).add(obj)\n                    except AttributeError:\n                        # Handle M2M relationships with a 'through' model.\n                        # This does not delete the 'through model.\n                        # TODO: Allow the user to delete a duplicate 'through' model.\n                        through_model = getattr(alias_object, alias_varname).through\n                        kwargs = {\n                            many_to_many_field.m2m_reverse_field_name(): obj,\n                            many_to_many_field.m2m_field_name(): alias_object,\n                        }\n                        through_model_instances = through_model.objects.filter(**kwargs)\n                        for instance in through_model_instances:\n                            # Re-attach the through model to the primary_object\n                            setattr(\n                                instance,\n                                many_to_many_field.m2m_field_name(),\n                                primary_object)\n                            instance.save()\n                            # TODO: Here, try to delete duplicate instances that are\n                            # disallowed by a unique_together constraint\n\n            for related_field in related_fields:\n                if related_field.one_to_many:\n                    alias_varname = related_field.get_accessor_name()\n                    related_objects = getattr(alias_object, alias_varname)\n                    for obj in related_objects.all():\n                        field_name = related_field.field.name\n                        setattr(obj, field_name, primary_object)\n                        obj.save()\n                elif related_field.one_to_one or related_field.many_to_one:\n                    alias_varname = related_field.name\n                    related_object = getattr(alias_object, alias_varname)\n                    primary_related_object = getattr(primary_object, alias_varname)\n                    if primary_related_object is None:\n                        setattr(primary_object, alias_varname, related_object)\n                        primary_object.save()\n                    elif related_field.one_to_one:\n                        self.stdout.write(\"Deleted {} with id {}\\n\".format(\n                            related_object, related_object.id))\n                        related_object.delete()\n\n            for field in generic_fields:\n                filter_kwargs = {}\n                filter_kwargs[field.fk_field] = alias_object._get_pk_val()\n                filter_kwargs[field.ct_field] = field.get_content_type(alias_object)\n                related_objects = field.model.objects.filter(**filter_kwargs)\n                for generic_related_object in related_objects:\n                    setattr(generic_related_object, field.name, primary_object)\n                    generic_related_object.save()\n\n            if alias_object.id:\n                deleted_objects += [alias_object]\n                self.stdout.write(\"Deleted {} with id {}\\n\".format(\n                    alias_object, alias_object.id))\n                alias_object.delete()\n                deleted_objects_count += 1\n\n        return primary_object, deleted_objects, deleted_objects_count"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_arguments(self, parser):\n        parser.add_argument('app_label', nargs='*')\n        for argument in self.arguments:\n            parser.add_argument(*argument.split(' '), **self.arguments[argument])", "response": "Unpack self. arguments for parser. add_arguments."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef print_output(self, dotdata, output_file=None):\n        if six.PY3 and isinstance(dotdata, six.binary_type):\n            dotdata = dotdata.decode()\n\n        if output_file:\n            with open(output_file, 'wt') as dot_output_f:\n                dot_output_f.write(dotdata)\n        else:\n            self.stdout.write(dotdata)", "response": "Write model data to file or stdout in DOT ( text format."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef render_output_json(self, graph_data, output_file=None):\n        if output_file:\n            with open(output_file, 'wt') as json_output_f:\n                json.dump(graph_data, json_output_f)\n        else:\n            self.stdout.write(json.dumps(graph_data))", "response": "Write model data to file or stdout in JSON format."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrender model data as image using pygraphviz", "response": "def render_output_pygraphviz(self, dotdata, **kwargs):\n        \"\"\"Render model data as image using pygraphviz\"\"\"\n        if not HAS_PYGRAPHVIZ:\n            raise CommandError(\"You need to install pygraphviz python module\")\n\n        version = pygraphviz.__version__.rstrip(\"-svn\")\n        try:\n            if tuple(int(v) for v in version.split('.')) < (0, 36):\n                # HACK around old/broken AGraph before version 0.36 (ubuntu ships with this old version)\n                tmpfile = tempfile.NamedTemporaryFile()\n                tmpfile.write(dotdata)\n                tmpfile.seek(0)\n                dotdata = tmpfile.name\n        except ValueError:\n            pass\n\n        graph = pygraphviz.AGraph(dotdata)\n        graph.layout(prog=kwargs['layout'])\n        graph.draw(kwargs['outputfile'])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrender model data as image using pydot", "response": "def render_output_pydot(self, dotdata, **kwargs):\n        \"\"\"Render model data as image using pydot\"\"\"\n        if not HAS_PYDOT:\n            raise CommandError(\"You need to install pydot python module\")\n\n        graph = pydot.graph_from_dot_data(dotdata)\n        if not graph:\n            raise CommandError(\"pydot returned an error\")\n        if isinstance(graph, (list, tuple)):\n            if len(graph) > 1:\n                sys.stderr.write(\"Found more then one graph, rendering only the first one.\\n\")\n            graph = graph[0]\n\n        output_file = kwargs['outputfile']\n        formats = [\n            'bmp', 'canon', 'cmap', 'cmapx', 'cmapx_np', 'dot', 'dia', 'emf',\n            'em', 'fplus', 'eps', 'fig', 'gd', 'gd2', 'gif', 'gv', 'imap',\n            'imap_np', 'ismap', 'jpe', 'jpeg', 'jpg', 'metafile', 'pdf',\n            'pic', 'plain', 'plain-ext', 'png', 'pov', 'ps', 'ps2', 'svg',\n            'svgz', 'tif', 'tiff', 'tk', 'vml', 'vmlz', 'vrml', 'wbmp', 'xdot',\n        ]\n        ext = output_file[output_file.rfind('.') + 1:]\n        format_ = ext if ext in formats else 'raw'\n        graph.write(output_file, format=format_)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nextract a list of views from a list of urlpatterns.", "response": "def extract_views_from_urlpatterns(self, urlpatterns, base='', namespace=None):\n        \"\"\"\n        Return a list of views from a list of urlpatterns.\n\n        Each object in the returned list is a three-tuple: (view_func, regex, name)\n        \"\"\"\n        views = []\n        for p in urlpatterns:\n            if isinstance(p, (URLPattern, RegexURLPattern)):\n                try:\n                    if not p.name:\n                        name = p.name\n                    elif namespace:\n                        name = '{0}:{1}'.format(namespace, p.name)\n                    else:\n                        name = p.name\n                    pattern = describe_pattern(p)\n                    views.append((p.callback, base + pattern, name))\n                except ViewDoesNotExist:\n                    continue\n            elif isinstance(p, (URLResolver, RegexURLResolver)):\n                try:\n                    patterns = p.url_patterns\n                except ImportError:\n                    continue\n                if namespace and p.namespace:\n                    _namespace = '{0}:{1}'.format(namespace, p.namespace)\n                else:\n                    _namespace = (p.namespace or namespace)\n                pattern = describe_pattern(p)\n                if isinstance(p, LocaleRegexURLResolver):\n                    for language in self.LANGUAGES:\n                        with translation.override(language[0]):\n                            views.extend(self.extract_views_from_urlpatterns(patterns, base + pattern, namespace=_namespace))\n                else:\n                    views.extend(self.extract_views_from_urlpatterns(patterns, base + pattern, namespace=_namespace))\n            elif hasattr(p, '_get_callback'):\n                try:\n                    views.append((p._get_callback(), base + describe_pattern(p), p.name))\n                except ViewDoesNotExist:\n                    continue\n            elif hasattr(p, 'url_patterns') or hasattr(p, '_get_url_patterns'):\n                try:\n                    patterns = p.url_patterns\n                except ImportError:\n                    continue\n                views.extend(self.extract_views_from_urlpatterns(patterns, base + describe_pattern(p), namespace=namespace))\n            else:\n                raise TypeError(\"%s does not appear to be a urlpattern object\" % p)\n        return views"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef foreignkey_autocomplete(self, request):\n        query = request.GET.get('q', None)\n        app_label = request.GET.get('app_label', None)\n        model_name = request.GET.get('model_name', None)\n        search_fields = request.GET.get('search_fields', None)\n        object_pk = request.GET.get('object_pk', None)\n\n        try:\n            to_string_function = self.related_string_functions[model_name]\n        except KeyError:\n            if six.PY3:\n                to_string_function = lambda x: x.__str__()\n            else:\n                to_string_function = lambda x: x.__unicode__()\n\n        if search_fields and app_label and model_name and (query or object_pk):\n            def construct_search(field_name):\n                # use different lookup methods depending on the notation\n                if field_name.startswith('^'):\n                    return \"%s__istartswith\" % field_name[1:]\n                elif field_name.startswith('='):\n                    return \"%s__iexact\" % field_name[1:]\n                elif field_name.startswith('@'):\n                    return \"%s__search\" % field_name[1:]\n                else:\n                    return \"%s__icontains\" % field_name\n\n            model = apps.get_model(app_label, model_name)\n\n            queryset = model._default_manager.all()\n            data = ''\n            if query:\n                for bit in query.split():\n                    or_queries = [models.Q(**{construct_search(smart_str(field_name)): smart_str(bit)}) for field_name in search_fields.split(',')]\n                    other_qs = QuerySet(model)\n                    other_qs.query.select_related = queryset.query.select_related\n                    other_qs = other_qs.filter(reduce(operator.or_, or_queries))\n                    queryset = queryset & other_qs\n\n                additional_filter = self.get_related_filter(model, request)\n                if additional_filter:\n                    queryset = queryset.filter(additional_filter)\n\n                if self.autocomplete_limit:\n                    queryset = queryset[:self.autocomplete_limit]\n\n                data = ''.join([six.u('%s|%s\\n') % (to_string_function(f), f.pk) for f in queryset])\n            elif object_pk:\n                try:\n                    obj = queryset.get(pk=object_pk)\n                except Exception:  # FIXME: use stricter exception checking\n                    pass\n                else:\n                    data = to_string_function(obj)\n            return HttpResponse(data, content_type='text/plain')\n        return HttpResponseNotFound()", "response": "Returns the string that can be used by the jQuery Autocomplete plugin."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\noverriding the default widget for Foreignkey fields if they are specified in the related_search_fields class attribute.", "response": "def formfield_for_dbfield(self, db_field, **kwargs):\n        \"\"\"\n        Override the default widget for Foreignkey fields if they are\n        specified in the related_search_fields class attribute.\n        \"\"\"\n        if isinstance(db_field, models.ForeignKey) and db_field.name in self.related_search_fields:\n            help_text = self.get_help_text(db_field.name, db_field.remote_field.model._meta.object_name)\n            if kwargs.get('help_text'):\n                help_text = six.u('%s %s' % (kwargs['help_text'], help_text))\n            kwargs['widget'] = ForeignKeySearchInput(db_field.remote_field, self.related_search_fields[db_field.name])\n            kwargs['help_text'] = help_text\n        return super(ForeignKeyAutocompleteAdminMixin, self).formfield_for_dbfield(db_field, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef null_technical_500_response(request, exc_type, exc_value, tb, status_code=500):\n    try:\n        # Store the most recent tb for WSGI requests. The class can be found in the second frame of the tb\n        if isinstance(tb.tb_next.tb_frame.f_locals.get('self'), WSGIHandler):\n            tld.wsgi_tb = tb\n        elif tld.wsgi_tb:\n            tb = tld.wsgi_tb\n    except AttributeError:\n        pass\n\n    six.reraise(exc_type, exc_value, tb)", "response": "A wrapper for the technical 500 response."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsplits the invalidation request in groups of 1000 objects", "response": "def invalidate_objects_cf(self):\n        \"\"\"Split the invalidation request in groups of 1000 objects\"\"\"\n        if not self.AWS_CLOUDFRONT_DISTRIBUTION:\n            raise CommandError(\n                'An object invalidation was requested but the variable '\n                'AWS_CLOUDFRONT_DISTRIBUTION is not present in your settings.')\n\n        # We can't send more than 1000 objects in the same invalidation\n        # request.\n        chunk = 1000\n\n        # Connecting to CloudFront\n        conn = self.open_cf()\n\n        # Splitting the object list\n        objs = self.uploaded_files\n        chunks = [objs[i:i + chunk] for i in range(0, len(objs), chunk)]\n\n        # Invalidation requests\n        for paths in chunks:\n            conn.create_invalidation_request(\n                self.AWS_CLOUDFRONT_DISTRIBUTION, paths)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sync_s3(self):\n        bucket, key = self.open_s3()\n        for directory in self.DIRECTORIES:\n            for root, dirs, files in os.walk(directory):\n                self.upload_s3((bucket, key, self.AWS_BUCKET_NAME, directory), root, files, dirs)", "response": "Walk the media directory and syncs files to S3"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nopens connection to S3 returning bucket and key", "response": "def open_s3(self):\n        \"\"\"Open connection to S3 returning bucket and key\"\"\"\n        conn = boto.connect_s3(\n            self.AWS_ACCESS_KEY_ID,\n            self.AWS_SECRET_ACCESS_KEY,\n            **self.get_s3connection_kwargs())\n        try:\n            bucket = conn.get_bucket(self.AWS_BUCKET_NAME)\n        except boto.exception.S3ResponseError:\n            bucket = conn.create_bucket(self.AWS_BUCKET_NAME)\n        return bucket, boto.s3.key.Key(bucket)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the application_name on PostgreSQL connection", "response": "def set_application_name(self, options):\n        \"\"\"\n        Set the application_name on PostgreSQL connection\n\n        Use the fallback_application_name to let the user override\n        it with PGAPPNAME env variable\n\n        http://www.postgresql.org/docs/9.4/static/libpq-connect.html#LIBPQ-PARAMKEYWORDS  # noqa\n        \"\"\"\n        supported_backends = ['django.db.backends.postgresql',\n                              'django.db.backends.postgresql_psycopg2']\n        opt_name = 'fallback_application_name'\n        default_app_name = 'django_shell'\n        app_name = default_app_name\n        dbs = getattr(settings, 'DATABASES', [])\n\n        # lookup over all the databases entry\n        for db in dbs.keys():\n            if dbs[db]['ENGINE'] in supported_backends:\n                try:\n                    options = dbs[db]['OPTIONS']\n                except KeyError:\n                    options = {}\n\n                # dot not override a defined value\n                if opt_name in options.keys():\n                    app_name = dbs[db]['OPTIONS'][opt_name]\n                else:\n                    dbs[db].setdefault('OPTIONS', {}).update({opt_name: default_app_name})\n                    app_name = default_app_name\n\n        return app_name"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncollects all subclasses of user - defined base classes from project.", "response": "def collect_subclasses(self):  # type: () -> Dict[str, List[Tuple[str, str]]]\n        \"\"\"\n        Collect all subclasses of user-defined base classes from project.\n        :return: Dictionary from module name to list of tuples.\n        First element of tuple is model name and second is alias.\n        Currently we set alias equal to model name,\n        but in future functionality of aliasing subclasses can be added.\n        \"\"\"\n        result = {}  # type: Dict[str, List[Tuple[str, str]]]\n        for loader, module_name, is_pkg in walk_packages(path=[settings.BASE_DIR]):\n            subclasses_from_module = self._collect_classes_from_module(module_name)\n            if subclasses_from_module:\n                result[module_name] = subclasses_from_module\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprocess a single message from the module logger at INFO level.", "response": "def process_message(self, peer, mailfrom, rcpttos, data, **kwargs):\n        \"\"\"Output will be sent to the module logger at INFO level.\"\"\"\n        inheaders = 1\n        lines = data.split('\\n')\n        logger.info('---------- MESSAGE FOLLOWS ----------')\n        for line in lines:\n            # headers first\n            if inheaders and not line:\n                logger.info('X-Peer: %s' % peer[0])\n                inheaders = 0\n            logger.info(line)\n        logger.info('------------ END MESSAGE ------------')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndeleting all the objects that are not in objects_to_keep.", "response": "def remove_objects_not_in(self, objects_to_keep, verbosity):\n        \"\"\"\n        Delete all the objects in the database that are not in objects_to_keep.\n        - objects_to_keep: A map where the keys are classes, and the values are a\n         set of the objects of that class we should keep.\n        \"\"\"\n        for class_ in objects_to_keep.keys():\n            current = class_.objects.all()\n            current_ids = set([x.pk for x in current])\n            keep_ids = set([x.pk for x in objects_to_keep[class_]])\n\n            remove_these_ones = current_ids.difference(keep_ids)\n            if remove_these_ones:\n                for obj in current:\n                    if obj.pk in remove_these_ones:\n                        obj.delete()\n                        if verbosity >= 2:\n                            print(\"Deleted object: %s\" % six.u(obj))\n\n            if verbosity > 0 and remove_these_ones:\n                num_deleted = len(remove_these_ones)\n                if num_deleted > 1:\n                    type_deleted = six.u(class_._meta.verbose_name_plural)\n                else:\n                    type_deleted = six.u(class_._meta.verbose_name)\n\n                print(\"Deleted %s %s\" % (str(num_deleted), type_deleted))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef execute(self, *args, **options):\n        try:\n            super(EmailNotificationCommand, self).execute(*args, **options)\n        except Exception:\n            if options['email_exception'] or getattr(self, 'email_exception', False):\n                self.send_email_notification(include_traceback=True)\n            raise", "response": "Override in order to send emails on unhandled exceptions."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsending an email notification to the user.", "response": "def send_email_notification(self, notification_id=None, include_traceback=False, verbosity=1):\n        \"\"\"\n        Send email notifications.\n\n        Reads settings from settings.EMAIL_NOTIFICATIONS dict, if available,\n        using ``notification_id`` as a key or else provides reasonable\n        defaults.\n        \"\"\"\n        # Load email notification settings if available\n        if notification_id is not None:\n            try:\n                email_settings = settings.EMAIL_NOTIFICATIONS.get(notification_id, {})\n            except AttributeError:\n                email_settings = {}\n        else:\n            email_settings = {}\n\n        # Exit if no traceback found and not in 'notify always' mode\n        if not include_traceback and not email_settings.get('notification_level', 0):\n            print(self.style.ERROR(\"Exiting, not in 'notify always' mode.\"))\n            return\n\n        # Set email fields.\n        subject = email_settings.get('subject', \"Django extensions email notification.\")\n\n        command_name = self.__module__.split('.')[-1]\n\n        body = email_settings.get(\n            'body',\n            \"Reporting execution of command: '%s'\" % command_name\n        )\n\n        # Include traceback\n        if include_traceback and not email_settings.get('no_traceback', False):\n            try:\n                exc_type, exc_value, exc_traceback = sys.exc_info()\n                trb = ''.join(traceback.format_tb(exc_traceback))\n                body += \"\\n\\nTraceback:\\n\\n%s\\n\" % trb\n            finally:\n                del exc_traceback\n\n        # Set from address\n        from_email = email_settings.get('from_email', settings.DEFAULT_FROM_EMAIL)\n\n        # Calculate recipients\n        recipients = list(email_settings.get('recipients', []))\n\n        if not email_settings.get('no_admins', False):\n            recipients.extend(settings.ADMINS)\n\n        if not recipients:\n            if verbosity > 0:\n                print(self.style.ERROR(\"No email recipients available.\"))\n            return\n\n        # Send email...\n        send_mail(subject, body, from_email, recipients,\n                  fail_silently=email_settings.get('fail_silently', True))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load_tag_library(libname):\n    from django.template.backends.django import get_installed_libraries\n    from django.template.library import InvalidTemplateLibrary\n    try:\n        lib = get_installed_libraries()[libname]\n        lib = importlib.import_module(lib).register\n        return lib\n    except (InvalidTemplateLibrary, KeyError):\n        return None", "response": "Load a templatetag library on multiple Django versions. Returns None if the library isn t loaded."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndecide whether to use a model based on the model name and the lists of include and exclude models to include and exclude.", "response": "def use_model(self, model_name):\n        \"\"\"\n        Decide whether to use a model, based on the model name and the lists of\n        models to exclude and include.\n        \"\"\"\n        # Check against exclude list.\n        if self.exclude_models:\n            for model_pattern in self.exclude_models:\n                model_pattern = '^%s$' % model_pattern.replace('*', '.*')\n                if re.search(model_pattern, model_name):\n                    return False\n        # Check against exclude list.\n        elif self.include_models:\n            for model_pattern in self.include_models:\n                model_pattern = '^%s$' % model_pattern.replace('*', '.*')\n                if re.search(model_pattern, model_name):\n                    return True\n        # Return `True` if `include_models` is falsey, otherwise return `False`.\n        return not self.include_models"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef GetClosestPoint(x, a, b):\n  assert(x.IsUnitLength())\n  assert(a.IsUnitLength())\n  assert(b.IsUnitLength())\n\n  a_cross_b = a.RobustCrossProd(b)\n  # project to the great circle going through a and b\n  p = x.Minus(\n      a_cross_b.Times(\n      x.DotProd(a_cross_b) / a_cross_b.Norm2()))\n\n  # if p lies between a and b, return it\n  if SimpleCCW(a_cross_b, a, p) and SimpleCCW(p, b, a_cross_b):\n    return p.Normalize()\n\n  # otherwise return the closer of a or b\n  if x.Minus(a).Norm2() <= x.Minus(b).Norm2():\n    return a\n  else:\n    return b", "response": "Get the point on the great circle segment ab closest to x."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the L_2 norm of self.", "response": "def Norm2(self):\n    \"\"\"\n    Returns the L_2 (Euclidean) norm of self.\n    \"\"\"\n    sum = self.x * self.x + self.y * self.y + self.z * self.z\n    return math.sqrt(float(sum))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a new point which is the pointwise sum of self and other.", "response": "def Plus(self, other):\n    \"\"\"\n    Returns a new point which is the pointwise sum of self and other.\n    \"\"\"\n    return Point(self.x + other.x,\n                 self.y + other.y,\n                 self.z + other.z)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a new point which is the pointwise subtraction of self and other.", "response": "def Minus(self, other):\n    \"\"\"\n    Returns a new point which is the pointwise subtraction of other from\n    self.\n    \"\"\"\n    return Point(self.x - other.x,\n                 self.y - other.y,\n                 self.z - other.z)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the ( scalar ) dot product of self with other.", "response": "def DotProd(self, other):\n    \"\"\"\n    Returns the (scalar) dot product of self with other.\n    \"\"\"\n    return self.x * other.x + self.y * other.y + self.z * other.z"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef Times(self, val):\n    return Point(self.x * val, self.y * val, self.z * val)", "response": "Returns a new point which is pointwise multiplied by val."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the index of the largest component in the tree.", "response": "def LargestComponent(self):\n    \"\"\"\n    Returns (i, val) where i is the component index (0 - 2)\n    which has largest absolute value and val is the value\n    of the component.\n    \"\"\"\n    if abs(self.x) > abs(self.y):\n      if abs(self.x) > abs(self.z):\n        return (0, self.x)\n      else:\n        return (2, self.z)\n    else:\n      if abs(self.y) > abs(self.z):\n        return (1, self.y)\n      else:\n        return (2, self.z)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef Ortho(self):\n    (index, val) = self.LargestComponent()\n    index = index - 1\n    if index < 0:\n      index = 2\n    temp = Point(0.012, 0.053, 0.00457)\n    if index == 0:\n      temp.x = 1\n    elif index == 1:\n      temp.y = 1\n    elif index == 2:\n      temp.z = 1\n    return self.CrossProd(temp).Normalize()", "response": "Returns a unit - length point orthogonal to this point"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef CrossProd(self, other):\n    return Point(\n        self.y * other.z - self.z * other.y,\n        self.z * other.x - self.x * other.z,\n        self.x * other.y - self.y * other.x)", "response": "Returns the cross product of self and other."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning true if self and other are approximately equal.", "response": "def Equals(self, other):\n    \"\"\"\n    Returns true of self and other are approximately equal.\n    \"\"\"\n    return (self._approxEq(self.x, other.x)\n            and self._approxEq(self.y, other.y)\n            and self._approxEq(self.z, other.z))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the angle in radians between self and other.", "response": "def Angle(self, other):\n    \"\"\"\n    Returns the angle in radians between self and other.\n    \"\"\"\n    return math.atan2(self.CrossProd(other).Norm2(),\n                      self.DotProd(other))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert this point to a latitude and longitude.", "response": "def ToLatLng(self):\n    \"\"\"\n    Returns that latitude and longitude that this point represents\n    under a spherical Earth model.\n    \"\"\"\n    rad_lat = math.atan2(self.z, math.sqrt(self.x * self.x + self.y * self.y))\n    rad_lng = math.atan2(self.y, self.x)\n    return (rad_lat * 180.0 / math.pi, rad_lng * 180.0 / math.pi)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a new point representing this latitude and longitude under the spherical Earth model.", "response": "def FromLatLng(lat, lng):\n    \"\"\"\n    Returns a new point representing this latitude and longitude under\n    a spherical Earth model.\n    \"\"\"\n    phi = lat * (math.pi / 180.0)\n    theta = lng * (math.pi / 180.0)\n    cosphi = math.cos(phi)\n    return Point(math.cos(theta) * cosphi,\n                 math.sin(theta) * cosphi,\n                 math.sin(phi))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the closest point to a point on the piecewise linear curve represented by the polyline.", "response": "def GetClosestPoint(self, p):\n    \"\"\"\n    Returns (closest_p, closest_i), where closest_p is the closest point\n    to p on the piecewise linear curve represented by the polyline,\n    and closest_i is the index of the point on the polyline just before\n    the polyline segment that contains closest_p.\n    \"\"\"\n    assert(len(self._points) > 0)\n    closest_point = self._points[0]\n    closest_i = 0\n\n    for i in range(0, len(self._points) - 1):\n      (a, b) = (self._points[i], self._points[i+1])\n      cur_closest_point = GetClosestPoint(p, a, b)\n      if p.Angle(cur_closest_point) < p.Angle(closest_point):\n        closest_point = cur_closest_point.Normalize()\n        closest_i = i\n\n    return (closest_point, closest_i)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef LengthMeters(self):\n    assert(len(self._points) > 0)\n    length = 0\n    for i in range(0, len(self._points) - 1):\n      length += self._points[i].GetDistanceMeters(self._points[i+1])\n    return length", "response": "Return length of this polyline in meters."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef CutAtClosestPoint(self, p):\n    (closest, i) = self.GetClosestPoint(p)\n\n    tmp = [closest]\n    tmp.extend(self._points[i+1:])\n    return (Poly(self._points[0:i+1]),\n            Poly(tmp))", "response": "Given a point on the polyline closest to p returns two new polylines one representing the polyline from the beginning up to x and one representing the polyline from the end up to x."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef GreedyPolyMatchDist(self, shape):\n    tmp_shape = Poly(shape.GetPoints())\n    max_radius = 0\n    for (i, point) in enumerate(self._points):\n      tmp_shape = tmp_shape.CutAtClosestPoint(point)[1]\n      dist = tmp_shape.GetPoint(0).GetDistanceMeters(point)\n      max_radius = max(max_radius, dist)\n    return max_radius", "response": "Returns the maximum distance in meters of any point in self to the\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef MergePolys(polys, merge_point_threshold=10):\n    name = \";\".join((p.GetName(), '')[p.GetName() is None] for p in polys)\n    merged = Poly([], name)\n    if polys:\n      first_poly = polys[0]\n      for p in first_poly.GetPoints():\n        merged.AddPoint(p)\n      last_point = merged._GetPointSafe(-1)\n      for poly in polys[1:]:\n        first_point = poly._GetPointSafe(0)\n        if (last_point and first_point and\n            last_point.GetDistanceMeters(first_point) <= merge_point_threshold):\n          points = poly.GetPoints()[1:]\n        else:\n          points = poly.GetPoints()\n        for p in points:\n          merged.AddPoint(p)\n        last_point = merged._GetPointSafe(-1)\n    return merged", "response": "Merge multiple polylines into one."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd a new polyline to the collection.", "response": "def AddPoly(self, poly, smart_duplicate_handling=True):\n    \"\"\"\n    Adds a new polyline to the collection.\n    \"\"\"\n    inserted_name = poly.GetName()\n    if poly.GetName() in self._name_to_shape:\n      if not smart_duplicate_handling:\n        raise ShapeError(\"Duplicate shape found: \" + poly.GetName())\n\n      print (\"Warning: duplicate shape id being added to collection: \" +\n             poly.GetName())\n      if poly.GreedyPolyMatchDist(self._name_to_shape[poly.GetName()]) < 10:\n        print(\"  (Skipping as it apears to be an exact duplicate)\")\n      else:\n        print(\"  (Adding new shape variant with uniquified name)\")\n        inserted_name = \"%s-%d\" % (inserted_name, len(self._name_to_shape))\n    self._name_to_shape[inserted_name] = poly"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of polylines that have endpoints within max_radius of the given start and end points.", "response": "def FindMatchingPolys(self, start_point, end_point, max_radius=150):\n    \"\"\"\n    Returns a list of polylines in the collection that have endpoints\n    within max_radius of the given start and end points.\n    \"\"\"\n    matches = []\n    for shape in self._name_to_shape.itervalues():\n      if start_point.GetDistanceMeters(shape.GetPoint(0)) < max_radius and \\\n        end_point.GetDistanceMeters(shape.GetPoint(-1)) < max_radius:\n        matches.append(shape)\n    return matches"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _ReconstructPath(self, came_from, current_node):\n    if current_node in came_from:\n      (previous_node, previous_edge) = came_from[current_node]\n      if previous_edge.GetPoint(0) == current_node:\n        previous_edge = previous_edge.Reversed()\n      p = self._ReconstructPath(came_from, previous_node)\n      return Poly.MergePolys([p, previous_edge], merge_point_threshold=0)\n    else:\n      return Poly([], '')", "response": "Reconstructs the path from the given came_from dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef AddTableColumn(self, table, column):\n    if column not in self._table_columns[table]:\n      self._table_columns[table].append(column)", "response": "Adds a column to a table."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds columns to table if they are not already there.", "response": "def AddTableColumns(self, table, columns):\n    \"\"\"Add columns to table if they are not already there.\n\n    Args:\n      table: table name as a string\n      columns: an iterable of column names\"\"\"\n    table_columns = self._table_columns.setdefault(table, [])\n    for attr in columns:\n      if attr not in table_columns:\n        table_columns.append(attr)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd an agency to this schedule.", "response": "def AddAgency(self, name, url, timezone, agency_id=None):\n    \"\"\"Adds an agency to this schedule.\"\"\"\n    agency = self._gtfs_factory.Agency(name, url, timezone, agency_id)\n    self.AddAgencyObject(agency)\n    return agency"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef GetDefaultAgency(self):\n    if not self._default_agency:\n      if len(self._agencies) == 0:\n        self.NewDefaultAgency()\n      elif len(self._agencies) == 1:\n        self._default_agency = self._agencies.values()[0]\n    return self._default_agency", "response": "Returns the default Agency. If no default Agency has been set create a new one and return None."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new Agency object and make it the default agency for this Schedule", "response": "def NewDefaultAgency(self, **kwargs):\n    \"\"\"Create a new Agency object and make it the default agency for this Schedule\"\"\"\n    agency = self._gtfs_factory.Agency(**kwargs)\n    if not agency.agency_id:\n      agency.agency_id = util.FindUniqueId(self._agencies)\n    self._default_agency = agency\n    self.SetDefaultAgency(agency, validate=False)  # Blank agency won't validate\n    return agency"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the default agency for this schedule.", "response": "def SetDefaultAgency(self, agency, validate=True):\n    \"\"\"Make agency the default and add it to the schedule if not already added\"\"\"\n    assert isinstance(agency, self._gtfs_factory.Agency)\n    self._default_agency = agency\n    if agency.agency_id not in self._agencies:\n      self.AddAgencyObject(agency, validate=validate)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the default ServicePeriod. If no default ServicePeriod has been set create a new one if there is more than one ServicePeriod.", "response": "def GetDefaultServicePeriod(self):\n    \"\"\"Return the default ServicePeriod. If no default ServicePeriod has been\n    set select the default depending on how many ServicePeriod objects are in\n    the Schedule. If there are 0 make a new ServicePeriod the default, if there\n    is 1 it becomes the default, if there is more than 1 then return None.\n    \"\"\"\n    if not self._default_service_period:\n      if len(self.service_periods) == 0:\n        self.NewDefaultServicePeriod()\n      elif len(self.service_periods) == 1:\n        self._default_service_period = self.service_periods.values()[0]\n    return self._default_service_period"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef NewDefaultServicePeriod(self):\n    service_period = self._gtfs_factory.ServicePeriod()\n    service_period.service_id = util.FindUniqueId(self.service_periods)\n    # blank service won't validate in AddServicePeriodObject\n    self.SetDefaultServicePeriod(service_period, validate=False)\n    return service_period", "response": "Create a new ServicePeriod object make it the default service period and\n    return it."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a tuple of earliest and latest dates on which the service periods are defined in YYYYMMDD form.", "response": "def GetDateRange(self):\n    \"\"\"Returns a tuple of (earliest, latest) dates on which the service periods\n    in the schedule define service, in YYYYMMDD form.\n    \"\"\"\n    (minvalue, maxvalue, minorigin, maxorigin) = self.GetDateRangeWithOrigins()\n    return (minvalue, maxvalue)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef GetDateRangeWithOrigins(self):\n    period_list = self.GetServicePeriodList()\n    ranges = [period.GetDateRange() for period in period_list]\n    starts = filter(lambda x: x, [item[0] for item in ranges])\n    ends = filter(lambda x: x, [item[1] for item in ranges])\n\n    if not starts or not ends:\n      return (None, None, None, None)\n\n    minvalue, minindex = min(itertools.izip(starts, itertools.count()))\n    maxvalue, maxindex = max(itertools.izip(ends, itertools.count()))\n\n    minreason = (period_list[minindex].HasDateExceptionOn(minvalue) and\n                 \"earliest service exception date in calendar_dates.txt\" or\n                 \"earliest service date in calendar.txt\")\n\n    maxreason = (period_list[maxindex].HasDateExceptionOn(maxvalue) and\n                 \"last service exception date in calendar_dates.txt\" or\n                 \"last service date in calendar.txt\")\n\n    # Override with feed_info.txt feed_start_date and feed_end_date values, if\n    # defined\n    if self.feed_info and self.feed_info.feed_start_date:\n      minvalue = self.feed_info.feed_start_date\n      minreason = \"feed_start_date in feed_info.txt\"\n    if self.feed_info and self.feed_info.feed_end_date:\n      maxvalue = self.feed_info.feed_end_date\n      maxreason = \"feed_end_date in feed_info.txt\"\n\n    return (minvalue, maxvalue, minreason, maxreason)", "response": "Returns a tuple of earliest latest and earliest_origin dates for the current service period."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of tuples containing a date object and a list of zero or more ServicePeriods. Each tuple contains a date object and a list of zero or more ServicePeriods.", "response": "def GetServicePeriodsActiveEachDate(self, date_start, date_end):\n    \"\"\"Return a list of tuples (date, [period1, period2, ...]).\n\n    For each date in the range [date_start, date_end) make list of each\n    ServicePeriod object which is active.\n\n    Args:\n      date_start: The first date in the list, a date object\n      date_end: The first date after the list, a date object\n\n    Returns:\n      A list of tuples. Each tuple contains a date object and a list of zero or\n      more ServicePeriod objects.\n    \"\"\"\n    date_it = date_start\n    one_day = datetime.timedelta(days=1)\n    date_service_period_list = []\n    while date_it < date_end:\n      periods_today = []\n      date_it_string = date_it.strftime(\"%Y%m%d\")\n      for service in self.GetServicePeriodList():\n        if service.IsActiveOn(date_it_string, date_it):\n          periods_today.append(service)\n      date_service_period_list.append((date_it, periods_today))\n      date_it += one_day\n    return date_service_period_list"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef AddStop(self, lat, lng, name, stop_id=None):\n    if stop_id is None:\n      stop_id = util.FindUniqueId(self.stops)\n    stop = self._gtfs_factory.Stop(stop_id=stop_id, lat=lat, lng=lng, name=name)\n    self.AddStopObject(stop)\n    return stop", "response": "Adds a stop to this schedule."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef AddStopObject(self, stop, problem_reporter=None):\n    assert stop._schedule is None\n    if not problem_reporter:\n      problem_reporter = self.problem_reporter\n\n    if not stop.stop_id:\n      return\n\n    if stop.stop_id in self.stops:\n      problem_reporter.DuplicateID('stop_id', stop.stop_id)\n      return\n\n    stop._schedule = weakref.proxy(self)\n    self.AddTableColumns('stops', stop._ColumnNames())\n    self.stops[stop.stop_id] = stop\n    if hasattr(stop, 'zone_id') and stop.zone_id:\n      self.fare_zones[stop.zone_id] = True", "response": "Adds a Stop object to this schedule."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a route to this schedule.", "response": "def AddRoute(self, short_name, long_name, route_type, route_id=None):\n    \"\"\"Add a route to this schedule.\n\n    Args:\n      short_name: Short name of the route, such as \"71L\"\n      long_name: Full name of the route, such as \"NW 21st Ave/St Helens Rd\"\n      route_type: A type such as \"Tram\", \"Subway\" or \"Bus\"\n      route_id: id of the route or None, in which case a unique id is picked\n    Returns:\n      A new Route object\n    \"\"\"\n    if route_id is None:\n      route_id = util.FindUniqueId(self.routes)\n    route = self._gtfs_factory.Route(short_name=short_name, long_name=long_name,\n                        route_type=route_type, route_id=route_id)\n    route.agency_id = self.GetDefaultAgency().agency_id\n    self.AddRouteObject(route)\n    return route"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef AddFareObject(self, fare, problem_reporter=None):\n    warnings.warn(\"No longer supported. The Fare class was renamed to \"\n                  \"FareAttribute, and all related functions were renamed \"\n                  \"accordingly.\", DeprecationWarning)\n    self.AddFareAttributeObject(fare, problem_reporter)", "response": "Deprecated. Please use AddFareAttributeObject."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the n nearest stops to lat lon", "response": "def GetNearestStops(self, lat, lon, n=1):\n    \"\"\"Return the n nearest stops to lat,lon\"\"\"\n    dist_stop_list = []\n    for s in self.stops.values():\n      # TODO: Use util.ApproximateDistanceBetweenStops?\n      dist = (s.stop_lat - lat)**2 + (s.stop_lon - lon)**2\n      if len(dist_stop_list) < n:\n        bisect.insort(dist_stop_list, (dist, s))\n      elif dist < dist_stop_list[-1][0]:\n        bisect.insort(dist_stop_list, (dist, s))\n        dist_stop_list.pop()  # Remove stop with greatest distance\n    return [stop for dist, stop in dist_stop_list]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a sample of up to n stops in a bounding box.", "response": "def GetStopsInBoundingBox(self, north, east, south, west, n):\n    \"\"\"Return a sample of up to n stops in a bounding box\"\"\"\n    stop_list = []\n    for s in self.stops.values():\n      if (s.stop_lat <= north and s.stop_lat >= south and\n          s.stop_lon <= east and s.stop_lon >= west):\n        stop_list.append(s)\n        if len(stop_list) == n:\n          break\n    return stop_list"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwrites the schedule as a Google Transit Feed in file_name.", "response": "def WriteGoogleTransitFeed(self, file):\n    \"\"\"Output this schedule as a Google Transit Feed in file_name.\n\n    Args:\n      file: path of new feed file (a string) or a file-like object\n\n    Returns:\n      None\n    \"\"\"\n    # Compression type given when adding each file\n    archive = zipfile.ZipFile(file, 'w')\n\n    if 'agency' in self._table_columns:\n      agency_string = StringIO.StringIO()\n      writer = util.CsvUnicodeWriter(agency_string)\n      columns = self.GetTableColumns('agency')\n      writer.writerow(columns)\n      for a in self._agencies.values():\n        writer.writerow([util.EncodeUnicode(a[c]) for c in columns])\n      self._WriteArchiveString(archive, 'agency.txt', agency_string)\n\n\n    if 'feed_info' in self._table_columns:\n      feed_info_string = StringIO.StringIO()\n      writer = util.CsvUnicodeWriter(feed_info_string)\n      columns = self.GetTableColumns('feed_info')\n      writer.writerow(columns)\n      writer.writerow([util.EncodeUnicode(self.feed_info[c]) for c in columns])\n      self._WriteArchiveString(archive, 'feed_info.txt', feed_info_string)\n\n    calendar_dates_string = StringIO.StringIO()\n    writer = util.CsvUnicodeWriter(calendar_dates_string)\n    writer.writerow(\n        self._gtfs_factory.ServicePeriod._FIELD_NAMES_CALENDAR_DATES)\n    has_data = False\n    for period in self.service_periods.values():\n      for row in period.GenerateCalendarDatesFieldValuesTuples():\n        has_data = True\n        writer.writerow(row)\n    wrote_calendar_dates = False\n    if has_data:\n      wrote_calendar_dates = True\n      self._WriteArchiveString(archive, 'calendar_dates.txt',\n                               calendar_dates_string)\n\n    calendar_string = StringIO.StringIO()\n    writer = util.CsvUnicodeWriter(calendar_string)\n    writer.writerow(self._gtfs_factory.ServicePeriod._FIELD_NAMES)\n    has_data = False\n    for s in self.service_periods.values():\n      row = s.GetCalendarFieldValuesTuple()\n      if row:\n        has_data = True\n        writer.writerow(row)\n    if has_data or not wrote_calendar_dates:\n      self._WriteArchiveString(archive, 'calendar.txt', calendar_string)\n\n    if 'stops' in self._table_columns:\n      stop_string = StringIO.StringIO()\n      writer = util.CsvUnicodeWriter(stop_string)\n      columns = self.GetTableColumns('stops')\n      writer.writerow(columns)\n      for s in self.stops.values():\n        writer.writerow([util.EncodeUnicode(s[c]) for c in columns])\n      self._WriteArchiveString(archive, 'stops.txt', stop_string)\n\n    if 'routes' in self._table_columns:\n      route_string = StringIO.StringIO()\n      writer = util.CsvUnicodeWriter(route_string)\n      columns = self.GetTableColumns('routes')\n      writer.writerow(columns)\n      for r in self.routes.values():\n        writer.writerow([util.EncodeUnicode(r[c]) for c in columns])\n      self._WriteArchiveString(archive, 'routes.txt', route_string)\n\n    if 'trips' in self._table_columns:\n      trips_string = StringIO.StringIO()\n      writer = util.CsvUnicodeWriter(trips_string)\n      columns = self.GetTableColumns('trips')\n      writer.writerow(columns)\n      for t in self.trips.values():\n        writer.writerow([util.EncodeUnicode(t[c]) for c in columns])\n      self._WriteArchiveString(archive, 'trips.txt', trips_string)\n\n    # write frequencies.txt (if applicable)\n    headway_rows = []\n    for trip in self.GetTripList():\n      headway_rows += trip.GetFrequencyOutputTuples()\n    if headway_rows:\n      headway_string = StringIO.StringIO()\n      writer = util.CsvUnicodeWriter(headway_string)\n      writer.writerow(self._gtfs_factory.Frequency._FIELD_NAMES)\n      writer.writerows(headway_rows)\n      self._WriteArchiveString(archive, 'frequencies.txt', headway_string)\n\n    # write fares (if applicable)\n    if self.GetFareAttributeList():\n      fare_string = StringIO.StringIO()\n      writer = util.CsvUnicodeWriter(fare_string)\n      writer.writerow(self._gtfs_factory.FareAttribute._FIELD_NAMES)\n      writer.writerows(\n          f.GetFieldValuesTuple() for f in self.GetFareAttributeList())\n      self._WriteArchiveString(archive, 'fare_attributes.txt', fare_string)\n\n    # write fare rules (if applicable)\n    rule_rows = []\n    for fare in self.GetFareAttributeList():\n      for rule in fare.GetFareRuleList():\n        rule_rows.append(rule.GetFieldValuesTuple())\n    if rule_rows:\n      rule_string = StringIO.StringIO()\n      writer = util.CsvUnicodeWriter(rule_string)\n      writer.writerow(self._gtfs_factory.FareRule._FIELD_NAMES)\n      writer.writerows(rule_rows)\n      self._WriteArchiveString(archive, 'fare_rules.txt', rule_string)\n    stop_times_string = StringIO.StringIO()\n    writer = util.CsvUnicodeWriter(stop_times_string)\n    writer.writerow(self._gtfs_factory.StopTime._FIELD_NAMES)\n    for t in self.trips.values():\n      writer.writerows(t._GenerateStopTimesTuples())\n    self._WriteArchiveString(archive, 'stop_times.txt', stop_times_string)\n\n    # write shapes (if applicable)\n    shape_rows = []\n    for shape in self.GetShapeList():\n      seq = 1\n      for (lat, lon, dist) in shape.points:\n        shape_rows.append((shape.shape_id, lat, lon, seq, dist))\n        seq += 1\n    if shape_rows:\n      shape_string = StringIO.StringIO()\n      writer = util.CsvUnicodeWriter(shape_string)\n      writer.writerow(self._gtfs_factory.Shape._FIELD_NAMES)\n      writer.writerows(shape_rows)\n      self._WriteArchiveString(archive, 'shapes.txt', shape_string)\n\n    if 'transfers' in self._table_columns:\n      transfer_string = StringIO.StringIO()\n      writer = util.CsvUnicodeWriter(transfer_string)\n      columns = self.GetTableColumns('transfers')\n      writer.writerow(columns)\n      for t in self.GetTransferIter():\n        writer.writerow([util.EncodeUnicode(t[c]) for c in columns])\n      self._WriteArchiveString(archive, 'transfers.txt', transfer_string)\n\n    archive.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef GenerateDateTripsDeparturesList(self, date_start, date_end):\n\n    service_id_to_trips = defaultdict(lambda: 0)\n    service_id_to_departures = defaultdict(lambda: 0)\n    for trip in self.GetTripList():\n      headway_start_times = trip.GetFrequencyStartTimes()\n      if headway_start_times:\n        trip_runs = len(headway_start_times)\n      else:\n        trip_runs = 1\n\n      service_id_to_trips[trip.service_id] += trip_runs\n      service_id_to_departures[trip.service_id] += (\n          (trip.GetCountStopTimes() - 1) * trip_runs)\n\n    date_services = self.GetServicePeriodsActiveEachDate(date_start, date_end)\n    date_trips = []\n\n    for date, services in date_services:\n      day_trips = sum(service_id_to_trips[s.service_id] for s in services)\n      day_departures = sum(\n          service_id_to_departures[s.service_id] for s in services)\n      date_trips.append((date, day_trips, day_departures))\n    return date_trips", "response": "Generates a list of trips and departures for a given date range."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nvalidates the start and expiration dates of the feed.", "response": "def ValidateFeedStartAndExpirationDates(self, problems, first_date, last_date,\n                                          first_date_origin, last_date_origin,\n                                          today):\n    \"\"\"Validate the start and expiration dates of the feed.\n       Issue a warning if it only starts in the future, or if\n       it expires within 60 days.\n\n    Args:\n      problems: The problem reporter object\n      first_date: A date object representing the first day the feed is active\n      last_date: A date object representing the last day the feed is active\n      today: A date object representing the date the validation is being run on\n\n    Returns:\n      None\n    \"\"\"\n    warning_cutoff = today + datetime.timedelta(days=60)\n    if last_date < warning_cutoff:\n        problems.ExpirationDate(time.mktime(last_date.timetuple()),\n                                last_date_origin)\n\n    if first_date > today:\n      problems.FutureService(time.mktime(first_date.timetuple()),\n                             first_date_origin)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ValidateServiceGaps(self,\n                          problems,\n                          validation_start_date,\n                          validation_end_date,\n                          service_gap_interval):\n    \"\"\"Validate consecutive dates without service in the feed.\n       Issue a warning if it finds service gaps of at least\n       \"service_gap_interval\" consecutive days in the date range\n       [validation_start_date, last_service_date)\n\n    Args:\n      problems: The problem reporter object\n      validation_start_date: A date object representing the date from which the\n                             validation should take place\n      validation_end_date: A date object representing the first day the feed is\n                        active\n      service_gap_interval: An integer indicating how many consecutive days the\n                            service gaps need to have for a warning to be issued\n\n    Returns:\n      None\n    \"\"\"\n    if service_gap_interval is None:\n      return\n\n    departures = self.GenerateDateTripsDeparturesList(validation_start_date,\n                                                      validation_end_date)\n\n    # The first day without service of the _current_ gap\n    first_day_without_service = validation_start_date\n    # The last day without service of the _current_ gap\n    last_day_without_service = validation_start_date\n\n    consecutive_days_without_service = 0\n\n    for day_date, day_trips, _ in departures:\n      if day_trips == 0:\n        if consecutive_days_without_service == 0:\n            first_day_without_service = day_date\n        consecutive_days_without_service += 1\n        last_day_without_service = day_date\n      else:\n        if consecutive_days_without_service >= service_gap_interval:\n            problems.TooManyDaysWithoutService(first_day_without_service,\n                                               last_day_without_service,\n                                               consecutive_days_without_service)\n\n        consecutive_days_without_service = 0\n\n    # We have to check if there is a gap at the end of the specified date range\n    if consecutive_days_without_service >= service_gap_interval:\n      problems.TooManyDaysWithoutService(first_day_without_service,\n                                         last_day_without_service,\n                                         consecutive_days_without_service)", "response": "Validate consecutive dates without service in the feed."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck for the stop times of a trip.", "response": "def ValidateStopTimesForTrip(self, problems, trip, stop_times):\n    \"\"\"Checks for the stop times of a trip.\n\n    Ensure that a trip does not have too many consecutive stop times with the\n    same departure/arrival time.\"\"\"\n    prev_departure_secs = -1\n    consecutive_stop_times_with_potentially_same_time = 0\n    consecutive_stop_times_with_fully_specified_same_time = 0\n\n    def CheckSameTimeCount():\n      # More than five consecutive stop times with the same time?  Seems not\n      # very likely (a stop every 10 seconds?).  In practice, this warning\n      # affects about 0.5% of current GTFS trips.\n      if (prev_departure_secs != -1 and\n          consecutive_stop_times_with_fully_specified_same_time > 5):\n        problems.TooManyConsecutiveStopTimesWithSameTime(trip.trip_id,\n            consecutive_stop_times_with_fully_specified_same_time,\n            prev_departure_secs)\n    for index, st in enumerate(stop_times):\n      if st.arrival_secs is None or st.departure_secs is None:\n        consecutive_stop_times_with_potentially_same_time += 1\n        continue\n      if (prev_departure_secs == st.arrival_secs and\n        st.arrival_secs == st.departure_secs):\n        consecutive_stop_times_with_potentially_same_time += 1\n        consecutive_stop_times_with_fully_specified_same_time = (\n            consecutive_stop_times_with_potentially_same_time)\n      else:\n        CheckSameTimeCount()\n        consecutive_stop_times_with_potentially_same_time = 1\n        consecutive_stop_times_with_fully_specified_same_time = 1\n      prev_departure_secs = st.departure_secs\n\n    # Make sure to check one last time at the end\n    CheckSameTimeCount()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nvalidate various holistic aspects of the schedule.", "response": "def Validate(self,\n               problems=None,\n               validate_children=True,\n               today=None,\n               service_gap_interval=None):\n    \"\"\"Validates various holistic aspects of the schedule\n       (mostly interrelationships between the various data sets).\"\"\"\n\n    if not problems:\n      problems = self.problem_reporter\n\n    self.ValidateAgenciesHaveSameAgencyTimezone(problems)\n    self.ValidateFeedInfoLangMatchesAgencyLang(problems)\n    self.ValidateServiceRangeAndExceptions(problems, today,\n                                           service_gap_interval)\n    # TODO: Check Trip fields against valid values\n    self.ValidateStops(problems, validate_children)\n    #TODO: check that every station is used.\n    # Then uncomment testStationWithoutReference.\n    self.ValidateNearbyStops(problems)\n    self.ValidateRouteNames(problems, validate_children)\n    self.ValidateTrips(problems)\n    self.ValidateRouteAgencyId(problems)\n    self.ValidateTripStopTimes(problems)\n    self.ValidateUnusedShapes(problems)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef Draw(self, stoplist=None, triplist=None, height=520):\n    output = str()\n    if not triplist:\n      triplist = []\n    if not stoplist:\n      stoplist = []\n\n    if not self._cache or triplist or stoplist:\n      self._gheight = height\n      self._tlist=triplist\n      self._slist=stoplist\n      self._decorators = []\n      self._stations = self._BuildStations(stoplist)\n      self._cache = \"%s %s %s %s\" % (self._DrawBox(),\n                                      self._DrawHours(),\n                                      self._DrawStations(),\n                                      self._DrawTrips(triplist))\n\n\n\n    output = \"%s %s %s %s\" % (self._DrawHeader(),\n                              self._cache,\n                              self._DrawDecorators(),\n                              self._DrawFooter())\n    return output", "response": "This method creates a marey graph."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndispatch the best algorithm for calculating stations line positions.", "response": "def _BuildStations(self, stoplist):\n    \"\"\"Dispatches the best algorithm for calculating station line position.\n\n    Args:\n      # Class Stop is defined in transitfeed.py\n      stoplist: [Stop, Stop, ...]\n      # Class Trip is defined in transitfeed.py\n      triplist: [Trip, Trip, ...]\n\n    Returns:\n      # One integer y-coordinate for each station normalized between\n      # 0 and X, where X is the height of the graph in pixels\n      [0, 33, 140, ... , X]\n    \"\"\"\n    stations = []\n    dists = self._EuclidianDistances(stoplist)\n    stations = self._CalculateYLines(dists)\n    return stations"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _EuclidianDistances(self,slist):\n    e_dists2 = [transitfeed.ApproximateDistanceBetweenStops(stop, tail) for\n                (stop,tail) in itertools.izip(slist, slist[1:])]\n\n    return e_dists2", "response": "Calculate the euclidian distances between stations."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalculates the horizontal lines in the graph.", "response": "def _CalculateYLines(self, dists):\n    \"\"\"Builds a list with y-coordinates for the horizontal lines in the graph.\n\n    Args:\n      # One integer for each pair of stations\n      # indicating the approximate distance\n      dists: [0,33,140, ... ,X]\n\n    Returns:\n      # One integer y-coordinate for each station normalized between\n      # 0 and X, where X is the height of the graph in pixels\n      [0, 33, 140, ... , X]\n    \"\"\"\n    tot_dist = sum(dists)\n    if tot_dist > 0:\n      pixel_dist = [float(d * (self._gheight-20))/tot_dist for d in dists]\n      pixel_grid = [0]+[int(pd + sum(pixel_dist[0:i])) for i,pd in\n                        enumerate(pixel_dist)]\n    else:\n      pixel_grid = []\n\n    return pixel_grid"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalculates distances and plot stops.", "response": "def _TravelTimes(self,triplist,index=0):\n    \"\"\" Calculate distances and plot stops.\n\n    Uses a timetable to approximate distances\n    between stations\n\n    Args:\n    # Class Trip is defined in transitfeed.py\n    triplist: [Trip, Trip, ...]\n    # (Optional) Index of Triplist prefered for timetable Calculation\n    index: 3\n\n    Returns:\n    # One integer for each pair of stations\n    # indicating the approximate distance\n    [0,33,140, ... ,X]\n    \"\"\"\n\n    def DistanceInTravelTime(dep_secs, arr_secs):\n      t_dist = arr_secs-dep_secs\n      if t_dist<0:\n        t_dist = self._DUMMY_SEPARATOR # min separation\n      return t_dist\n\n    if not triplist:\n      return []\n\n    if 0 < index < len(triplist):\n      trip = triplist[index]\n    else:\n      trip = triplist[0]\n\n    t_dists2 = [DistanceInTravelTime(stop[3],tail[2]) for (stop,tail)\n                 in itertools.izip(trip.GetTimeStops(),trip.GetTimeStops()[1:])]\n    return t_dists2"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating svg polylines for each trip in triplist.", "response": "def _DrawTrips(self,triplist,colpar=\"\"):\n    \"\"\"Generates svg polylines for each transit trip.\n\n    Args:\n      # Class Trip is defined in transitfeed.py\n      [Trip, Trip, ...]\n\n    Returns:\n      # A string containing a polyline tag for each trip\n      ' <polyline class=\"T\" stroke=\"#336633\" points=\"433,0 ...'\n    \"\"\"\n\n    stations = []\n    if not self._stations and triplist:\n      self._stations = self._CalculateYLines(self._TravelTimes(triplist))\n      if not self._stations:\n        self._AddWarning(\"Failed to use traveltimes for graph\")\n        self._stations = self._CalculateYLines(self._Uniform(triplist))\n        if not self._stations:\n          self._AddWarning(\"Failed to calculate station distances\")\n          return\n\n    stations = self._stations\n    tmpstrs = []\n    servlist = []\n    for t in triplist:\n      if not colpar:\n        if t.service_id not in servlist:\n          servlist.append(t.service_id)\n        shade = int(servlist.index(t.service_id) * (200/len(servlist))+55)\n        color = \"#00%s00\" %  hex(shade)[2:4]\n      else:\n        color=colpar\n\n      start_offsets = [0]\n      first_stop = t.GetTimeStops()[0]\n\n      for j,freq_offset in enumerate(start_offsets):\n        if j>0 and not colpar:\n          color=\"purple\"\n        scriptcall = 'onmouseover=\"LineClick(\\'%s\\',\\'Trip %s starting %s\\')\"' % (t.trip_id,\n            t.trip_id, transitfeed.FormatSecondsSinceMidnight(t.GetStartTime()))\n        tmpstrhead = '<polyline class=\"T\" id=\"%s\" stroke=\"%s\" %s points=\"' % \\\n          (str(t.trip_id),color, scriptcall)\n        tmpstrs.append(tmpstrhead)\n\n        for i, s in enumerate(t.GetTimeStops()):\n          arr_t = s[0]\n          dep_t = s[1]\n          if arr_t is None or dep_t is None:\n            continue\n          arr_x = int(arr_t/3600.0 * self._hour_grid) - self._hour_grid * self._offset\n          dep_x = int(dep_t/3600.0 * self._hour_grid) - self._hour_grid * self._offset\n          tmpstrs.append(\"%s,%s \" % (int(arr_x+20), int(stations[i]+20)))\n          tmpstrs.append(\"%s,%s \" % (int(dep_x+20), int(stations[i]+20)))\n        tmpstrs.append('\" />')\n    return \"\".join(tmpstrs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _Uniform(self, triplist):\n    # This should not be neseccary, but we are in fallback mode\n    longest = max([len(t.GetTimeStops()) for t in triplist])\n    return [100] * longest", "response": "Fallback to assuming uniform distance between stations"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate svg with a horizontal line for each station and stop.", "response": "def _DrawStations(self, color=\"#aaa\"):\n    \"\"\"Generates svg with a horizontal line for each station/stop.\n\n    Args:\n      # Class Stop is defined in transitfeed.py\n      stations: [Stop, Stop, ...]\n\n    Returns:\n      # A string containing a polyline tag for each stop\n      \" <polyline class=\"Station\" stroke=\"#336633\" points=\"20,0 ...\"\n    \"\"\"\n    stations=self._stations\n    tmpstrs = []\n    for y in stations:\n      tmpstrs.append('  <polyline class=\"Station\" stroke=\"%s\" \\\n      points=\"%s,%s, %s,%s\" />' %(color,20,20+y+.5,self._gwidth+20,20+y+.5))\n    return \"\".join(tmpstrs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngenerate svg to show a vertical hour and sub - hour grid.", "response": "def _DrawHours(self):\n    \"\"\"Generates svg to show a vertical hour and sub-hour grid\n\n    Returns:\n      # A string containing a polyline tag for each grid line\n      \" <polyline class=\"FullHour\" points=\"20,0 ...\"\n    \"\"\"\n    tmpstrs = []\n    for i in range(0, self._gwidth, self._min_grid):\n      if i % self._hour_grid == 0:\n        tmpstrs.append('<polyline class=\"FullHour\" points=\"%d,%d, %d,%d\" />' \\\n                       % (i + .5 + 20, 20, i + .5 + 20, self._gheight))\n        tmpstrs.append('<text class=\"Label\" x=\"%d\" y=\"%d\">%d</text>'\n                       % (i + 20, 20,\n                         (i / self._hour_grid + self._offset) % 24))\n      else:\n        tmpstrs.append('<polyline class=\"SubHour\" points=\"%d,%d,%d,%d\" />' \\\n                       % (i + .5 + 20, 20, i + .5 + 20, self._gheight))\n    return \"\".join(tmpstrs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef AddStationDecoration(self, index, color=\"#f00\"):\n    tmpstr = str()\n    num_stations = len(self._stations)\n    ind = int(index)\n    if self._stations:\n      if 0<ind<num_stations:\n        y = self._stations[ind]\n        tmpstr = '<polyline class=\"Dec\" stroke=\"%s\" points=\"%s,%s,%s,%s\" />' \\\n          % (color, 20, 20+y+.5, self._gwidth+20, 20+y+.5)\n    self._decorators.append(tmpstr)", "response": "Adds a new station - line to the decorations list."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef AddTripDecoration(self, triplist, color=\"#f00\"):\n    tmpstr = self._DrawTrips(triplist,color)\n    self._decorators.append(tmpstr)", "response": "Adds a new decoration to the current decoration list."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nchange the zoom factor of the graph manually.", "response": "def ChangeScaleFactor(self, newfactor):\n    \"\"\"Changes the zoom of the graph manually.\n\n    1.0 is the original canvas size.\n\n    Args:\n      # float value between 0.0 and 5.0\n      newfactor: 0.7\n    \"\"\"\n    if float(newfactor) > 0 and float(newfactor) < self._MAX_ZOOM:\n      self._zoomfactor = newfactor"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nincreases the zoom of the graph one step ( 0. 1 units.", "response": "def ScaleLarger(self):\n    \"\"\"Increases the zoom of the graph one step (0.1 units).\"\"\"\n    newfactor = self._zoomfactor + 0.1\n    if float(newfactor) > 0 and float(newfactor) < self._MAX_ZOOM:\n      self._zoomfactor = newfactor"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndecrease the zoom of the graph one step ( 0. 1 units.", "response": "def ScaleSmaller(self):\n    \"\"\"Decreases the zoom of the graph one step(0.1 units).\"\"\"\n    newfactor = self._zoomfactor - 0.1\n    if float(newfactor) > 0 and float(newfactor) < self._MAX_ZOOM:\n      self._zoomfactor = newfactor"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a KML Folder element.", "response": "def _CreateFolder(self, parent, name, visible=True, description=None):\n    \"\"\"Create a KML Folder element.\n\n    Args:\n      parent: The parent ElementTree.Element instance.\n      name: The folder name as a string.\n      visible: Whether the folder is initially visible or not.\n      description: A description string or None.\n\n    Returns:\n      The folder ElementTree.Element instance.\n    \"\"\"\n    folder = ET.SubElement(parent, 'Folder')\n    name_tag = ET.SubElement(folder, 'name')\n    name_tag.text = name\n    if description is not None:\n      desc_tag = ET.SubElement(folder, 'description')\n      desc_tag.text = description\n    if not visible:\n      visibility = ET.SubElement(folder, 'visibility')\n      visibility.text = '0'\n    return folder"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _CreateStyleForRoute(self, doc, route):\n    style_id = 'route_%s' % route.route_id\n    style = ET.SubElement(doc, 'Style', {'id': style_id})\n    linestyle = ET.SubElement(style, 'LineStyle')\n    width = ET.SubElement(linestyle, 'width')\n    type_to_width = {0: '3',  # Tram\n                     1: '3',  # Subway\n                     2: '5',  # Rail\n                     3: '1'}  # Bus\n    width.text = type_to_width.get(route.route_type, '1')\n    if route.route_color:\n      color = ET.SubElement(linestyle, 'color')\n      red = route.route_color[0:2].lower()\n      green = route.route_color[2:4].lower()\n      blue = route.route_color[4:6].lower()\n      color.text = 'ff%s%s%s' % (blue, green, red)\n    return style_id", "response": "Create a KML style element for the route."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _CreatePlacemark(self, parent, name, style_id=None, visible=True,\n                       description=None):\n    \"\"\"Create a KML Placemark element.\n\n    Args:\n      parent: The parent ElementTree.Element instance.\n      name: The placemark name as a string.\n      style_id: If not None, the id of a style to use for the placemark.\n      visible: Whether the placemark is initially visible or not.\n      description: A description string or None.\n\n    Returns:\n      The placemark ElementTree.Element instance.\n    \"\"\"\n    placemark = ET.SubElement(parent, 'Placemark')\n    placemark_name = ET.SubElement(placemark, 'name')\n    placemark_name.text = name\n    if description is not None:\n      desc_tag = ET.SubElement(placemark, 'description')\n      desc_tag.text = description\n    if style_id is not None:\n      styleurl = ET.SubElement(placemark, 'styleUrl')\n      styleurl.text = '#%s' % style_id\n    if not visible:\n      visibility = ET.SubElement(placemark, 'visibility')\n      visibility.text = '0'\n    return placemark", "response": "Create a KML Placemark element."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _CreateLineString(self, parent, coordinate_list):\n    if not coordinate_list:\n      return None\n    linestring = ET.SubElement(parent, 'LineString')\n    tessellate = ET.SubElement(linestring, 'tessellate')\n    tessellate.text = '1'\n    if len(coordinate_list[0]) == 3:\n      altitude_mode = ET.SubElement(linestring, 'altitudeMode')\n      altitude_mode.text = 'absolute'\n    coordinates = ET.SubElement(linestring, 'coordinates')\n    if len(coordinate_list[0]) == 3:\n      coordinate_str_list = ['%f,%f,%f' % t for t in coordinate_list]\n    else:\n      coordinate_str_list = ['%f,%f' % t for t in coordinate_list]\n    coordinates.text = ' '.join(coordinate_str_list)\n    return linestring", "response": "Create a KML LineString element."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _CreateLineStringForShape(self, parent, shape):\n    coordinate_list = [(longitude, latitude) for\n                       (latitude, longitude, distance) in shape.points]\n    return self._CreateLineString(parent, coordinate_list)", "response": "Create a KML LineString using coordinates from a shape."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _CreateStopsFolder(self, schedule, doc):\n    if not schedule.GetStopList():\n      return None\n    stop_folder = self._CreateFolder(doc, 'Stops')\n    stop_folder_selection = self._StopFolderSelectionMethod(stop_folder)\n    stop_style_selection = self._StopStyleSelectionMethod(doc)\n    stops = list(schedule.GetStopList())\n    stops.sort(key=lambda x: x.stop_name)\n    for stop in stops:\n      (folder, pathway_folder) = stop_folder_selection(stop)\n      (style_id, pathway_style_id) = stop_style_selection(stop)\n      self._CreateStopPlacemark(folder, stop, style_id)\n      if (self.show_stop_hierarchy and\n          stop.location_type != transitfeed.Stop.LOCATION_TYPE_STATION and\n          stop.parent_station and stop.parent_station in schedule.stops):\n        placemark = self._CreatePlacemark(\n            pathway_folder, stop.stop_name, pathway_style_id)\n        parent_station = schedule.stops[stop.parent_station]\n        coordinates = [(stop.stop_lon, stop.stop_lat),\n                       (parent_station.stop_lon, parent_station.stop_lat)]\n        self._CreateLineString(placemark, coordinates)\n    return stop_folder", "response": "Creates a KML Folder containing placemarks for each stop in the schedule."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a method to determine which KML folder a stop should go in.", "response": "def _StopFolderSelectionMethod(self, stop_folder):\n    \"\"\"Create a method to determine which KML folder a stop should go in.\n\n    Args:\n      stop_folder: the parent folder element for all stops.\n\n    Returns:\n      A function that should accept a Stop argument and return a tuple of\n      (stop KML folder, pathways KML folder).\n\n    Given a Stop, we need to determine which folder the stop should go in.  In\n    the most basic case, that's the root Stops folder.  However, if\n    show_stop_hierarchy is enabled, we put a stop in a separate sub-folder\n    depending on if the stop is a station, a platform, an entrance, or just a\n    plain-old stand-alone stop.  This method returns a function that is used\n    to pick which folder a stop stop should go in.  It also optionally returns\n    a folder where any line-string connections associated with a stop (eg. to\n    show the pathway between an entrance and a station) should be added.\n    \"\"\"\n    if not self.show_stop_hierarchy:\n      return lambda stop: (stop_folder, None)\n\n    # Create the various sub-folders for showing the stop hierarchy\n    station_folder = self._CreateFolder(stop_folder, 'Stations')\n    platform_folder = self._CreateFolder(stop_folder, 'Platforms')\n    platform_connections = self._CreateFolder(platform_folder, 'Connections')\n    entrance_folder = self._CreateFolder(stop_folder, 'Entrances')\n    entrance_connections = self._CreateFolder(entrance_folder, 'Connections')\n    standalone_folder = self._CreateFolder(stop_folder, 'Stand-Alone')\n\n    def FolderSelectionMethod(stop):\n      if stop.location_type == transitfeed.Stop.LOCATION_TYPE_STATION:\n        return (station_folder, None)\n      elif stop.location_type == googletransit.Stop.LOCATION_TYPE_ENTRANCE:\n        return (entrance_folder, entrance_connections)\n      elif stop.parent_station:\n        return (platform_folder, platform_connections)\n      return (standalone_folder, None)\n\n    return FolderSelectionMethod"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _StopStyleSelectionMethod(self, doc):\n    if not self.show_stop_hierarchy:\n      return lambda stop: (None, None)\n\n    # Create the various styles for showing the stop hierarchy\n    self._CreateStyle(\n        doc, 'stop_entrance', {'IconStyle': {'color': 'ff0000ff'}})\n    self._CreateStyle(\n        doc,\n        'entrance_connection',\n        {'LineStyle': {'color': 'ff0000ff', 'width': '2'}})\n    self._CreateStyle(\n        doc, 'stop_platform', {'IconStyle': {'color': 'ffff0000'}})\n    self._CreateStyle(\n        doc,\n        'platform_connection',\n        {'LineStyle': {'color': 'ffff0000', 'width': '2'}})\n    self._CreateStyle(\n        doc, 'stop_standalone', {'IconStyle': {'color': 'ff00ff00'}})\n\n    def StyleSelectionMethod(stop):\n      if stop.location_type == transitfeed.Stop.LOCATION_TYPE_STATION:\n        return ('stop_station', None)\n      elif stop.location_type == googletransit.Stop.LOCATION_TYPE_ENTRANCE:\n        return ('stop_entrance', 'entrance_connection')\n      elif stop.parent_station:\n        return ('stop_platform', 'platform_connection')\n      return ('stop_standalone', None)\n\n    return StyleSelectionMethod", "response": "Create a method that returns a tuple of the style id and pathway style id."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new stop <Placemark > element.", "response": "def _CreateStopPlacemark(self, stop_folder, stop, style_id):\n    \"\"\"Creates a new stop <Placemark/> element.\n\n    Args:\n      stop_folder: the KML folder the placemark will be added to.\n      stop: the actual Stop to create a placemark for.\n      style_id: optional argument indicating a style id to add to the placemark.\n    \"\"\"\n    desc_items = []\n    desc_items.append(\"Stop id: %s\" % stop.stop_id)\n    if stop.stop_desc:\n      desc_items.append(stop.stop_desc)\n    if stop.stop_url:\n      desc_items.append('Stop info page: <a href=\"%s\">%s</a>' % (\n          stop.stop_url, stop.stop_url))\n    description = '<br/>'.join(desc_items) or None\n    placemark = self._CreatePlacemark(stop_folder, stop.stop_name,\n                                        description=description,\n                                        style_id=style_id)\n    point = ET.SubElement(placemark, 'Point')\n    coordinates = ET.SubElement(point, 'coordinates')\n    coordinates.text = '%.6f,%.6f' % (stop.stop_lon, stop.stop_lat)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a KML Folder containing placemarks for each pattern in the route.", "response": "def _CreateRoutePatternsFolder(self, parent, route,\n                                   style_id=None, visible=True):\n    \"\"\"Create a KML Folder containing placemarks for each pattern in the route.\n\n    A pattern is a sequence of stops used by one of the trips in the route.\n\n    If there are not patterns for the route then no folder is created and None\n    is returned.\n\n    Args:\n      parent: The parent ElementTree.Element instance.\n      route: The transitfeed.Route instance.\n      style_id: The id of a style to use if not None.\n      visible: Whether the folder is initially visible or not.\n\n    Returns:\n      The Folder ElementTree.Element instance or None if there are no patterns.\n    \"\"\"\n    pattern_id_to_trips = route.GetPatternIdTripDict()\n    if not pattern_id_to_trips:\n      return None\n\n    # sort by number of trips using the pattern\n    pattern_trips = pattern_id_to_trips.values()\n    pattern_trips.sort(lambda a, b: cmp(len(b), len(a)))\n\n    folder = self._CreateFolder(parent, 'Patterns', visible)\n    for n, trips in enumerate(pattern_trips):\n      trip_ids = [trip.trip_id for trip in trips]\n      name = 'Pattern %d (trips: %d)' % (n+1, len(trips))\n      description = 'Trips using this pattern (%d in total): %s' % (\n          len(trips), ', '.join(trip_ids))\n      placemark = self._CreatePlacemark(folder, name, style_id, visible,\n                                        description)\n      coordinates = [(stop.stop_lon, stop.stop_lat)\n                     for stop in trips[0].GetPattern()]\n      self._CreateLineString(placemark, coordinates)\n    return folder"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a KML Folder for the shapes of a route.", "response": "def _CreateRouteShapesFolder(self, schedule, parent, route,\n                               style_id=None, visible=True):\n    \"\"\"Create a KML Folder for the shapes of a route.\n\n    The folder contains a placemark for each shape referenced by a trip in the\n    route. If there are no such shapes, no folder is created and None is\n    returned.\n\n    Args:\n      schedule: The transitfeed.Schedule instance.\n      parent: The parent ElementTree.Element instance.\n      route: The transitfeed.Route instance.\n      style_id: The id of a style to use if not None.\n      visible: Whether the placemark is initially visible or not.\n\n    Returns:\n      The Folder ElementTree.Element instance or None.\n    \"\"\"\n    shape_id_to_trips = {}\n    for trip in route.trips:\n      if trip.shape_id:\n        shape_id_to_trips.setdefault(trip.shape_id, []).append(trip)\n    if not shape_id_to_trips:\n      return None\n\n    # sort by the number of trips using the shape\n    shape_id_to_trips_items = shape_id_to_trips.items()\n    shape_id_to_trips_items.sort(lambda a, b: cmp(len(b[1]), len(a[1])))\n\n    folder = self._CreateFolder(parent, 'Shapes', visible)\n    for shape_id, trips in shape_id_to_trips_items:\n      trip_ids = [trip.trip_id for trip in trips]\n      name = '%s (trips: %d)' % (shape_id, len(trips))\n      description = 'Trips using this shape (%d in total): %s' % (\n          len(trips), ', '.join(trip_ids))\n      placemark = self._CreatePlacemark(folder, name, style_id, visible,\n                                        description)\n      self._CreateLineStringForShape(placemark, schedule.GetShape(shape_id))\n    return folder"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _CreateRouteTripsFolder(self, parent, route, style_id=None, schedule=None):\n    if not route.trips:\n      return None\n    trips = list(route.trips)\n    trips.sort(key=lambda x: x.trip_id)\n    trips_folder = self._CreateFolder(parent, 'Trips', visible=False)\n    for trip in trips:\n      if (self.date_filter and\n          not trip.service_period.IsActiveOn(self.date_filter)):\n        continue\n\n      if trip.trip_headsign:\n        description = 'Headsign: %s' % trip.trip_headsign\n      else:\n        description = None\n\n      coordinate_list = []\n      for secs, stoptime, tp in trip.GetTimeInterpolatedStops():\n        if self.altitude_per_sec > 0:\n          coordinate_list.append((stoptime.stop.stop_lon, stoptime.stop.stop_lat,\n                                  (secs - 3600 * 4) * self.altitude_per_sec))\n        else:\n          coordinate_list.append((stoptime.stop.stop_lon,\n                                  stoptime.stop.stop_lat))\n      placemark = self._CreatePlacemark(trips_folder,\n                                        trip.trip_id,\n                                        style_id=style_id,\n                                        visible=False,\n                                        description=description)\n      self._CreateLineString(placemark, coordinate_list)\n    return trips_folder", "response": "Creates a KML Folder containing all the trips in the route."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a KML Folder containing routes in a schedule.", "response": "def _CreateRoutesFolder(self, schedule, doc, route_type=None):\n    \"\"\"Create a KML Folder containing routes in a schedule.\n\n    The folder contains a subfolder for each route in the schedule of type\n    route_type. If route_type is None, then all routes are selected. Each\n    subfolder contains a flattened graph placemark, a route shapes placemark\n    and, if show_trips is True, a subfolder containing placemarks for each of\n    the trips in the route.\n\n    If there are no routes in the schedule then no folder is created and None\n    is returned.\n\n    Args:\n      schedule: The transitfeed.Schedule instance.\n      doc: The KML Document ElementTree.Element instance.\n      route_type: The route type integer or None.\n\n    Returns:\n      The Folder ElementTree.Element instance or None.\n    \"\"\"\n\n    def GetRouteName(route):\n      \"\"\"Return a placemark name for the route.\n\n      Args:\n        route: The transitfeed.Route instance.\n\n      Returns:\n        The name as a string.\n      \"\"\"\n      name_parts = []\n      if route.route_short_name:\n        name_parts.append('<b>%s</b>' % route.route_short_name)\n      if route.route_long_name:\n        name_parts.append(route.route_long_name)\n      return ' - '.join(name_parts) or route.route_id\n\n    def GetRouteDescription(route):\n      \"\"\"Return a placemark description for the route.\n\n      Args:\n        route: The transitfeed.Route instance.\n\n      Returns:\n        The description as a string.\n      \"\"\"\n      desc_items = []\n      if route.route_desc:\n        desc_items.append(route.route_desc)\n      if route.route_url:\n        desc_items.append('Route info page: <a href=\"%s\">%s</a>' % (\n            route.route_url, route.route_url))\n      description = '<br/>'.join(desc_items)\n      return description or None\n\n    routes = [route for route in schedule.GetRouteList()\n              if route_type is None or route.route_type == route_type]\n    if not routes:\n      return None\n    routes.sort(key=lambda x: GetRouteName(x))\n\n    if route_type is not None:\n      route_type_names = {0: 'Tram, Streetcar or Light rail',\n                          1: 'Subway or Metro',\n                          2: 'Rail',\n                          3: 'Bus',\n                          4: 'Ferry',\n                          5: 'Cable car',\n                          6: 'Gondola or suspended cable car',\n                          7: 'Funicular'}\n      type_name = route_type_names.get(route_type, str(route_type))\n      folder_name = 'Routes - %s' % type_name\n    else:\n      folder_name = 'Routes'\n    routes_folder = self._CreateFolder(doc, folder_name, visible=False)\n\n    for route in routes:\n      style_id = self._CreateStyleForRoute(doc, route)\n      route_folder = self._CreateFolder(routes_folder,\n                                        GetRouteName(route),\n                                        description=GetRouteDescription(route))\n      self._CreateRouteShapesFolder(schedule, route_folder, route,\n                                    style_id, False)\n      self._CreateRoutePatternsFolder(route_folder, route, style_id, False)\n      if self.show_trips:\n        self._CreateRouteTripsFolder(route_folder, route, style_id, schedule)\n    return routes_folder"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a KML Folder containing all the shapes in a schedule.", "response": "def _CreateShapesFolder(self, schedule, doc):\n    \"\"\"Create a KML Folder containing all the shapes in a schedule.\n\n    The folder contains a placemark for each shape. If there are no shapes in\n    the schedule then the folder is not created and None is returned.\n\n    Args:\n      schedule: The transitfeed.Schedule instance.\n      doc: The KML Document ElementTree.Element instance.\n\n    Returns:\n      The Folder ElementTree.Element instance or None.\n    \"\"\"\n    if not schedule.GetShapeList():\n      return None\n    shapes_folder = self._CreateFolder(doc, 'Shapes')\n    shapes = list(schedule.GetShapeList())\n    shapes.sort(key=lambda x: x.shape_id)\n    for shape in shapes:\n      placemark = self._CreatePlacemark(shapes_folder, shape.shape_id)\n      self._CreateLineStringForShape(placemark, shape)\n      if self.shape_points:\n        self._CreateShapePointFolder(shapes_folder, shape)\n    return shapes_folder"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a KML Folder containing all the shape points in a shape.", "response": "def _CreateShapePointFolder(self, shapes_folder, shape):\n    \"\"\"Create a KML Folder containing all the shape points in a shape.\n\n    The folder contains placemarks for each shapepoint.\n\n    Args:\n      shapes_folder: A KML Shape Folder ElementTree.Element instance\n      shape: The shape to plot.\n\n    Returns:\n      The Folder ElementTree.Element instance or None.\n    \"\"\"\n\n    folder_name = shape.shape_id + ' Shape Points'\n    folder = self._CreateFolder(shapes_folder, folder_name, visible=False)\n    for (index, (lat, lon, dist)) in enumerate(shape.points):\n      placemark = self._CreatePlacemark(folder, str(index+1))\n      point = ET.SubElement(placemark, 'Point')\n      coordinates = ET.SubElement(point, 'coordinates')\n      coordinates.text = '%.6f,%.6f' % (lon, lat)\n    return folder"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwrites out a KML feed as a KML file.", "response": "def Write(self, schedule, output_file):\n    \"\"\"Writes out a feed as KML.\n\n    Args:\n      schedule: A transitfeed.Schedule object containing the feed to write.\n      output_file: The name of the output KML file, or file object to use.\n    \"\"\"\n    # Generate the DOM to write\n    root = ET.Element('kml')\n    root.attrib['xmlns'] = 'http://earth.google.com/kml/2.1'\n    doc = ET.SubElement(root, 'Document')\n    open_tag = ET.SubElement(doc, 'open')\n    open_tag.text = '1'\n    self._CreateStopsFolder(schedule, doc)\n    if self.split_routes:\n      route_types = set()\n      for route in schedule.GetRouteList():\n        route_types.add(route.route_type)\n      route_types = list(route_types)\n      route_types.sort()\n      for route_type in route_types:\n        self._CreateRoutesFolder(schedule, doc, route_type)\n    else:\n      self._CreateRoutesFolder(schedule, doc)\n    self._CreateShapesFolder(schedule, doc)\n\n    # Make sure we pretty-print\n    self._SetIndentation(root)\n\n    # Now write the output\n    if isinstance(output_file, file):\n      output = output_file\n    else:\n      output = open(output_file, 'w')\n    output.write(\"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n\"\"\")\n    ET.ElementTree(root).write(output, 'utf-8')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of tuples for all trips visiting this stop.", "response": "def _GetTripSequence(self, schedule=None):\n    \"\"\"Return a list of (trip, stop_sequence) for all trips visiting this stop.\n\n    A trip may be in the list multiple times with different index.\n    stop_sequence is an integer.\n\n    Args:\n      schedule: Deprecated, do not use.\n    \"\"\"\n    if schedule is None:\n      schedule = getattr(self, \"_schedule\", None)\n    if schedule is None:\n      warnings.warn(\"No longer supported. _schedule attribute is  used to get \"\n                    \"stop_times table\", DeprecationWarning)\n    cursor = schedule._connection.cursor()\n    cursor.execute(\"SELECT trip_id,stop_sequence FROM stop_times \"\n                   \"WHERE stop_id=?\",\n                   (self.stop_id, ))\n    return [(schedule.GetTrip(row[0]), row[1]) for row in cursor]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of ( trip index ).", "response": "def _GetTripIndex(self, schedule=None):\n    \"\"\"Return a list of (trip, index).\n\n    trip: a Trip object\n    index: an offset in trip.GetStopTimes()\n    \"\"\"\n    trip_index = []\n    for trip, sequence in self._GetTripSequence(schedule):\n      for index, st in enumerate(trip.GetStopTimes()):\n        if st.stop_sequence == sequence:\n          trip_index.append((trip, index))\n          break\n      else:\n        raise RuntimeError(\"stop_sequence %d not found in trip_id %s\" %\n                           sequence, trip.trip_id)\n    return trip_index"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef GetStopTimeTrips(self, schedule=None):\n    time_trips = []\n    for trip, index in self._GetTripIndex(schedule):\n      secs, stoptime, is_timepoint = trip.GetTimeInterpolatedStops()[index]\n      time_trips.append((secs, (trip, index), is_timepoint))\n    return time_trips", "response": "Returns a list of tuples of time trip index and is_timepoint."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef RunValidationOutputFromOptions(feed, options):\n  if options.output.upper() == \"CONSOLE\":\n    return RunValidationOutputToConsole(feed, options)\n  else:\n    return RunValidationOutputToFilename(feed, options, options.output)", "response": "Validate feed output results per options and return an exit code."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef RunValidationOutputToFilename(feed, options, output_filename):\n  try:\n    output_file = open(output_filename, 'w')\n    exit_code = RunValidationOutputToFile(feed, options, output_file)\n    output_file.close()\n  except IOError as e:\n    print('Error while writing %s: %s' % (output_filename, e))\n    output_filename = None\n    exit_code = 2\n\n  if options.manual_entry and output_filename:\n    webbrowser.open('file://%s' % os.path.abspath(output_filename))\n\n  return exit_code", "response": "Validate feed save HTML at output_filename and return an exit code."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef RunValidationOutputToFile(feed, options, output_file):\n  accumulator = HTMLCountingProblemAccumulator(options.limit_per_type,\n                                               options.error_types_ignore_list)\n  problems = transitfeed.ProblemReporter(accumulator)\n  schedule, exit_code = RunValidation(feed, options, problems)\n  if isinstance(feed, basestring):\n    feed_location = feed\n  else:\n    feed_location = getattr(feed, 'name', repr(feed))\n  accumulator.WriteOutput(feed_location, output_file, schedule, options.extension)\n  return exit_code", "response": "Validate feed write HTML to output_file and return an exit code."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nvalidating feed print reports and return an exit code.", "response": "def RunValidationOutputToConsole(feed, options):\n  \"\"\"Validate feed, print reports and return an exit code.\"\"\"\n  accumulator = CountingConsoleProblemAccumulator(\n      options.error_types_ignore_list)\n  problems = transitfeed.ProblemReporter(accumulator)\n  _, exit_code = RunValidation(feed, options, problems)\n  return exit_code"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nvalidates a feed and return the loaded Schedule and exit code.", "response": "def RunValidation(feed, options, problems):\n  \"\"\"Validate feed, returning the loaded Schedule and exit code.\n\n  Args:\n    feed: GTFS file, either path of the file as a string or a file object\n    options: options object returned by optparse\n    problems: transitfeed.ProblemReporter instance\n\n  Returns:\n    a transitfeed.Schedule object, exit code and plain text string of other\n    problems\n    Exit code is 2 if an extension is provided but can't be loaded, 1 if\n    problems are found and 0 if the Schedule is problem free.\n    plain text string is '' if no other problems are found.\n  \"\"\"\n  util.CheckVersion(problems, options.latest_version)\n\n  # TODO: Add tests for this flag in testfeedvalidator.py\n  if options.extension:\n    try:\n      __import__(options.extension)\n      extension_module = sys.modules[options.extension]\n    except ImportError:\n      # TODO: Document extensions in a wiki page, place link here\n      print(\"Could not import extension %s! Please ensure it is a proper \"\n            \"Python module.\" % options.extension)\n      exit(2)\n  else:\n    extension_module = transitfeed\n\n  gtfs_factory = extension_module.GetGtfsFactory()\n\n  print('validating %s' % feed)\n  print('FeedValidator extension used: %s' % options.extension)\n  loader = gtfs_factory.Loader(feed, problems=problems, extra_validation=False,\n                               memory_db=options.memory_db,\n                               check_duplicate_trips=\\\n                               options.check_duplicate_trips,\n                               gtfs_factory=gtfs_factory)\n  schedule = loader.Load()\n  # Start validation: children are already validated by the loader.\n  schedule.Validate(service_gap_interval=options.service_gap_interval,\n                    validate_children=False)\n\n  if feed == 'IWantMyvalidation-crash.txt':\n    # See tests/testfeedvalidator.py\n    raise Exception('For testing the feed validator crash handler.')\n\n  accumulator = problems.GetAccumulator()\n  if accumulator.HasIssues():\n    print('ERROR: %s found' % accumulator.FormatCount())\n    return schedule, 1\n  else:\n    print('feed validated successfully')\n    return schedule, 0"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef RunValidationFromOptions(feed, options):\n  if options.performance:\n    return ProfileRunValidationOutputFromOptions(feed, options)\n  else:\n    return RunValidationOutputFromOptions(feed, options)", "response": "Validate feed run in profiler if in options and return an exit code."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ProfileRunValidationOutputFromOptions(feed, options):\n  import cProfile\n  import pstats\n  # runctx will modify a dict, but not locals(). We need a way to get rv back.\n  locals_for_exec = locals()\n  cProfile.runctx('rv = RunValidationOutputFromOptions(feed, options)',\n                  globals(), locals_for_exec, 'validate-stats')\n\n  # Only available on Unix, http://docs.python.org/lib/module-resource.html\n  import resource\n  print(\"Time: %d seconds\" % (\n      resource.getrusage(resource.RUSAGE_SELF).ru_utime +\n      resource.getrusage(resource.RUSAGE_SELF).ru_stime))\n\n  # http://aspn.activestate.com/ASPN/Cookbook/Python/Recipe/286222\n  # http://aspn.activestate.com/ASPN/Cookbook/ \"The recipes are freely\n  # available for review and use.\"\n  def _VmB(VmKey):\n    \"\"\"Return size from proc status in bytes.\"\"\"\n    _proc_status = '/proc/%d/status' % os.getpid()\n    _scale = {'kB': 1024.0, 'mB': 1024.0*1024.0,\n              'KB': 1024.0, 'MB': 1024.0*1024.0}\n\n     # get pseudo file  /proc/<pid>/status\n    try:\n        t = open(_proc_status)\n        v = t.read()\n        t.close()\n    except:\n        raise Exception(\"no proc file %s\" % _proc_status)\n        return 0  # non-Linux?\n     # get VmKey line e.g. 'VmRSS:  9999  kB\\n ...'\n    try:\n        i = v.index(VmKey)\n        v = v[i:].split(None, 3)  # whitespace\n    except:\n        return 0 # v is empty\n\n    if len(v) < 3:\n        raise Exception(\"%s\" % v)\n        return 0  # invalid format?\n     # convert Vm value to bytes\n    return int(float(v[1]) * _scale[v[2]])\n\n  # I ran this on over a hundred GTFS files, comparing VmSize to VmRSS\n  # (resident set size). The difference was always under 2% or 3MB.\n  print(\"Virtual Memory Size: %d bytes\" % _VmB('VmSize:'))\n\n  # Output report of where CPU time was spent.\n  p = pstats.Stats('validate-stats')\n  p.strip_dirs()\n  p.sort_stats('cumulative').print_stats(30)\n  p.sort_stats('cumulative').print_callers(30)\n  return locals_for_exec['rv']", "response": "Run RunValidationOutputFromOptions print profile and return exit code."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nformatting all problems of one type.", "response": "def FormatType(self, level_name, class_problist):\n    \"\"\"Write the HTML dumping all problems of one type.\n\n    Args:\n      level_name: string such as \"Error\" or \"Warning\"\n      class_problist: sequence of tuples (class name,\n          BoundedProblemList object)\n\n    Returns:\n      HTML in a string\n    \"\"\"\n    class_problist.sort()\n    output = []\n    for classname, problist in class_problist:\n      output.append('<h4 class=\"issueHeader\"><a name=\"%s%s\">%s</a></h4><ul>\\n' %\n                    (level_name, classname, UnCamelCase(classname)))\n      for e in problist.problems:\n        self.FormatException(e, output)\n      if problist.dropped_count:\n        output.append('<li>and %d more of this type.' %\n                      (problist.dropped_count))\n      output.append('</ul>\\n')\n    return ''.join(output)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef FormatTypeSummaryTable(self, level_name, name_to_problist):\n    output = []\n    output.append('<table>')\n    for classname in sorted(name_to_problist.keys()):\n      problist = name_to_problist[classname]\n      human_name = MaybePluralizeWord(problist.count, UnCamelCase(classname))\n      output.append('<tr><td>%d</td><td><a href=\"#%s%s\">%s</a></td></tr>\\n' %\n                    (problist.count, level_name, classname, human_name))\n    output.append('</table>\\n')\n    return ''.join(output)", "response": "Formats the type summary table."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nformat an exception into a list of HTML output.", "response": "def FormatException(self, e, output):\n    \"\"\"Append HTML version of e to list output.\"\"\"\n    d = e.GetDictToFormat()\n    for k in ('file_name', 'feedname', 'column_name'):\n      if k in d.keys():\n        d[k] = '<code>%s</code>' % d[k]\n    if 'url' in d.keys():\n      d['url'] = '<a href=\"%(url)s\">%(url)s</a>' % d\n\n    problem_text = e.FormatProblem(d).replace('\\n', '<br>')\n    problem_class = 'problem'\n    if e.IsNotice():\n      problem_class += ' notice'\n    output.append('<li>')\n    output.append('<div class=\"%s\">%s</div>' %\n                  (problem_class, transitfeed.EncodeUnicode(problem_text)))\n    try:\n      if hasattr(e, 'row_num'):\n        line_str = 'line %d of ' % e.row_num\n      else:\n        line_str = ''\n      output.append('in %s<code>%s</code><br>\\n' %\n                    (line_str, transitfeed.EncodeUnicode(e.file_name)))\n      row = e.row\n      headers = e.headers\n      column_name = e.column_name\n      table_header = ''  # HTML\n      table_data = ''  # HTML\n      for header, value in zip(headers, row):\n        attributes = ''\n        if header == column_name:\n          attributes = ' class=\"problem\"'\n        table_header += '<th%s>%s</th>' % (attributes, header)\n        table_data += '<td%s>%s</td>' % (attributes, value)\n      # Make sure output is encoded into UTF-8\n      output.append('<table class=\"dump\"><tr>%s</tr>\\n' %\n                    transitfeed.EncodeUnicode(table_header))\n      output.append('<tr>%s</tr></table>\\n' %\n                    transitfeed.EncodeUnicode(table_data))\n    except AttributeError as e:\n      pass  # Hope this was getting an attribute from e ;-)\n    output.append('<br></li>\\n')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite the html output to f.", "response": "def WriteOutput(self, feed_location, f, schedule, extension):\n    \"\"\"Write the html output to f.\"\"\"\n    if self.HasIssues():\n      if self.ErrorCount() + self.WarningCount() == 1:\n        summary = ('<span class=\"fail\">Found this problem:</span>\\n%s' %\n                   self.CountTable())\n      else:\n        summary = ('<span class=\"fail\">Found these problems:</span>\\n%s' %\n                   self.CountTable())\n    else:\n      summary = '<span class=\"pass\">feed validated successfully</span>'\n\n    if self.HasNotices():\n      summary = ('<h3 class=\"issueHeader\">Notices:</h3>' + \n          self.FormatType(\"Notice\", self.ProblemListMap(TYPE_NOTICE).items()) +\n          summary)\n\n    basename = os.path.basename(feed_location)\n    feed_path = (feed_location[:feed_location.rfind(basename)], basename)\n\n    agencies = ', '.join(['<a href=\"%s\">%s</a>' % (a.agency_url, a.agency_name)\n                          for a in schedule.GetAgencyList()])\n    if not agencies:\n      agencies = '?'\n\n    dates = \"No valid service dates found\"\n    (start, end) = schedule.GetDateRange()\n    if start and end:\n      def FormatDate(yyyymmdd):\n        src_format = \"%Y%m%d\"\n        dst_format = \"%B %d, %Y\"\n        try:\n          return time.strftime(dst_format,\n                               time.strptime(yyyymmdd, src_format))\n        except ValueError:\n          return yyyymmdd\n\n      formatted_start = FormatDate(start)\n      formatted_end = FormatDate(end)\n      dates = \"%s to %s\" % (formatted_start, formatted_end)\n\n    calendar_summary = CalendarSummary(schedule)\n    if calendar_summary:\n      calendar_summary_html = \"\"\"<br>\nDuring the upcoming service dates %(date_summary_range)s:\n<table>\n<tr><th class=\"header\">Average trips per date:</th><td class=\"header\">%(mean_trips)s</td></tr>\n<tr><th class=\"header\">Most trips on a date:</th><td class=\"header\">%(max_trips)s, on %(max_trips_dates)s</td></tr>\n<tr><th class=\"header\">Least trips on a date:</th><td class=\"header\">%(min_trips)s, on %(min_trips_dates)s</td></tr>\n</table>\"\"\" % calendar_summary\n    else:\n      calendar_summary_html = \"\"\n\n    output_prefix = \"\"\"\n<html>\n<head>\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\">\n<title>FeedValidator: %(feed_file)s</title>\n<style>\nbody {font-family: Georgia, serif; background-color: white}\n.path {color: gray}\ndiv.problem {max-width: 500px}\ntable.dump td,th {background-color: khaki; padding: 2px; font-family:monospace}\ntable.dump td.problem,th.problem {background-color: dc143c; color: white; padding: 2px; font-family:monospace}\ntable.count_outside td {vertical-align: top}\ntable.count_outside {border-spacing: 0px; }\ntable {border-spacing: 5px 0px; margin-top: 3px}\nh3.issueHeader {padding-left: 0.5em}\nh4.issueHeader {padding-left: 1em}\n.pass {background-color: lightgreen}\n.fail {background-color: yellow}\n.notice {background-color: yellow}\n.pass, .fail {font-size: 16pt}\n.header {background-color: white; font-family: Georgia, serif; padding: 0px}\nth.header {text-align: right; font-weight: normal; color: gray}\n.footer {font-size: 10pt}\n</style>\n</head>\n<body>\nGTFS validation results for feed:<br>\n<code><span class=\"path\">%(feed_dir)s</span><b>%(feed_file)s</b></code><br>\nFeedValidator extension used: %(extension)s\n<br><br>\n<table>\n<tr><th class=\"header\">Agencies:</th><td class=\"header\">%(agencies)s</td></tr>\n<tr><th class=\"header\">Routes:</th><td class=\"header\">%(routes)s</td></tr>\n<tr><th class=\"header\">Stops:</th><td class=\"header\">%(stops)s</td></tr>\n<tr><th class=\"header\">Trips:</th><td class=\"header\">%(trips)s</td></tr>\n<tr><th class=\"header\">Shapes:</th><td class=\"header\">%(shapes)s</td></tr>\n<tr><th class=\"header\">Effective:</th><td class=\"header\">%(dates)s</td></tr>\n</table>\n%(calendar_summary)s\n<br>\n%(problem_summary)s\n<br><br>\n\"\"\" % { \"feed_file\": feed_path[1],\n        \"feed_dir\": feed_path[0],\n        \"agencies\": agencies,\n        \"routes\": len(schedule.GetRouteList()),\n        \"stops\": len(schedule.GetStopList()),\n        \"trips\": len(schedule.GetTripList()),\n        \"shapes\": len(schedule.GetShapeList()),\n        \"dates\": dates,\n        \"problem_summary\": summary,\n        \"calendar_summary\": calendar_summary_html,\n        \"extension\": extension}\n\n# In output_suffix string\n# time.strftime() returns a regular local time string (not a Unicode one) with\n# default system encoding. And decode() will then convert this time string back\n# into a Unicode string. We use decode() here because we don't want the operating\n# system to do any system encoding (which may cause some problem if the string\n# contains some non-English characters) for the string. Therefore we decode it\n# back to its original Unicode code print.\n\n    time_unicode = (time.strftime('%B %d, %Y at %I:%M %p %Z').\n                    decode(sys.getfilesystemencoding()))\n    output_suffix = \"\"\"\n<div class=\"footer\">\nGenerated by <a href=\"https://github.com/google/transitfeed/wiki/FeedValidator\">\nFeedValidator</a> version %s on %s.\n</div>\n</body>\n</html>\"\"\" % (transitfeed.__version__, time_unicode)\n\n    f.write(transitfeed.EncodeUnicode(output_prefix))\n    if self.ProblemListMap(TYPE_ERROR):\n      f.write('<h3 class=\"issueHeader\">Errors:</h3>')\n      f.write(self.FormatType(\"Error\", self.ProblemListMap(TYPE_ERROR).items()))\n    if self.ProblemListMap(TYPE_WARNING):\n      f.write('<h3 class=\"issueHeader\">Warnings:</h3>')\n      f.write(self.FormatType(\"Warning\", self.ProblemListMap(TYPE_WARNING).items()))\n    f.write(transitfeed.EncodeUnicode(output_suffix))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the date range over which this ServicePeriod is valid.", "response": "def GetDateRange(self):\n    \"\"\"Return the range over which this ServicePeriod is valid.\n\n    The range includes exception dates that add service outside of\n    (start_date, end_date), but doesn't shrink the range if exception\n    dates take away service at the edges of the range.\n\n    Returns:\n      A tuple of \"YYYYMMDD\" strings, (start date, end date) or (None, None) if\n      no dates have been given.\n    \"\"\"\n    start = self.start_date\n    end = self.end_date\n\n    for date, (exception_type, _) in self.date_exceptions.items():\n      if exception_type == self._EXCEPTION_TYPE_REMOVE:\n        continue\n      if not start or (date < start):\n        start = date\n      if not end or (date > end):\n        end = date\n    if start is None:\n      start = end\n    elif end is None:\n      end = start\n    # If start and end are None we did a little harmless shuffling\n    return (start, end)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef GetCalendarFieldValuesTuple(self):\n    if self.start_date and self.end_date:\n      return [getattr(self, fn) for fn in self._FIELD_NAMES]", "response": "Returns the tuple of calendar. txt values for this ServicePeriod."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef GenerateCalendarDatesFieldValuesTuples(self):\n    for date, (exception_type, _) in self.date_exceptions.items():\n      yield (self.service_id, date, unicode(exception_type))", "response": "Generates tuples of calendar_dates. txt values."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef GetCalendarDatesFieldValuesTuples(self):\n    result = []\n    for date_tuple in self.GenerateCalendarDatesFieldValuesTuples():\n      result.append(date_tuple)\n    result.sort()  # helps with __eq__\n    return result", "response": "Return a list of date execeptions"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef SetDayOfWeekHasService(self, dow, has_service=True):\n    assert(dow >= 0 and dow < 7)\n    self.day_of_week[dow] = has_service", "response": "Sets the service as running on a day of the week. By default the service is not running on any day."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets whether or not the weekday is running on all of Monday through Friday.", "response": "def SetWeekdayService(self, has_service=True):\n    \"\"\"Set service as running (or not) on all of Monday through Friday.\"\"\"\n    for i in range(0, 5):\n      self.SetDayOfWeekHasService(i, has_service)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef SetWeekendService(self, has_service=True):\n    self.SetDayOfWeekHasService(5, has_service)\n    self.SetDayOfWeekHasService(6, has_service)", "response": "Sets the weekend service to running or not on Saturday and Sunday."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntests if this service period has a date exception at a given date.", "response": "def HasDateExceptionOn(self, date, exception_type=_EXCEPTION_TYPE_ADD):\n    \"\"\"Test if this service period has a date exception of the given type.\n\n    Args:\n      date: a string of form \"YYYYMMDD\"\n      exception_type: the exception type the date should have. Defaults to\n                      _EXCEPTION_TYPE_ADD\n\n    Returns:\n      True iff this service has service exception of specified type at date.\n    \"\"\"\n    if date in self.date_exceptions:\n      return exception_type == self.date_exceptions[date][0]\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef IsActiveOn(self, date, date_object=None):\n    if date in self.date_exceptions:\n      exception_type, _ = self.date_exceptions[date]\n      if exception_type == self._EXCEPTION_TYPE_ADD:\n        return True\n      else:\n        return False\n    if (self.start_date and self.end_date and self.start_date <= date and\n        date <= self.end_date):\n      if date_object is None:\n        date_object = util.DateStringToDateObject(date)\n      return self.day_of_week[date_object.weekday()]\n    return False", "response": "Tests if this service period is active on a date."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ActiveDates(self):\n    (earliest, latest) = self.GetDateRange()\n    if earliest is None:\n      return []\n    dates = []\n    date_it = util.DateStringToDateObject(earliest)\n    date_end = util.DateStringToDateObject(latest)\n    delta = datetime.timedelta(days=1)\n    while date_it <= date_end:\n      date_it_string = date_it.strftime(\"%Y%m%d\")\n      if self.IsActiveOn(date_it_string, date_it):\n        dates.append(date_it_string)\n      date_it = date_it + delta\n    return dates", "response": "Return the dates this service period is active as a list of YYYYMMDDs."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef Validate(self, problems=default_problem_reporter):\n    found_problem = False\n    found_problem = ((not util.ValidateRequiredFieldsAreNotEmpty(\n                          self, self._REQUIRED_FIELD_NAMES, problems))\n                          or found_problem)\n    found_problem = self.ValidateAgencyUrl(problems) or found_problem\n    found_problem = self.ValidateAgencyLang(problems) or found_problem\n    found_problem = self.ValidateAgencyTimezone(problems) or found_problem\n    found_problem = self.ValidateAgencyFareUrl(problems) or found_problem\n    found_problem = self.ValidateAgencyEmail(problems) or found_problem\n\n    return not found_problem", "response": "Validate the attribute values and this object s internal consistency."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ConvertCH1903(x, y):\n  \"Converts coordinates from the 1903 Swiss national grid system to WGS-84.\"\n  yb = (x - 600000.0) / 1e6;\n  xb = (y - 200000.0) / 1e6;\n  lam = 2.6779094 \\\n     + 4.728982 * yb \\\n     + 0.791484 * yb * xb \\\n     + 0.1306 * yb * xb * xb \\\n     - 0.0436 * yb * yb * yb\n  phi = 16.9023892 \\\n     + 3.238372 * xb \\\n     - 0.270978 * yb * yb \\\n     - 0.002582 * xb * xb \\\n     - 0.0447 * yb * yb * xb \\\n     - 0.0140 * xb * xb * xb\n  return (phi * 100.0 / 36.0, lam * 100.0 / 36.0)", "response": "Converts coordinates from the 1903 Swiss national grid system to WGS - 84."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nencode one value for CSV.", "response": "def EncodeForCSV(x):\n  \"Encodes one value for CSV.\"\n  k = x.encode('utf-8')\n  if ',' in k or '\"' in k:\n    return '\"%s\"' % k.replace('\"', '\"\"')\n  else:\n    return k"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwriting one row of comma - separated values to stream.", "response": "def WriteRow(stream, values):\n  \"Writes one row of comma-separated values to stream.\"\n  stream.write(','.join([EncodeForCSV(val) for val in values]))\n  stream.write('\\n')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef DemangleName(self, name):\n    \"Applies some simple heuristics to split names into (city, name).\"\n\n    # Handle special cases where our heuristcs doesn't work.\n    # Example:\"Triemli\" --> (\"Triemli\", \"Zurich\").\n    if name in SPECIAL_NAMES:\n      return SPECIAL_NAMES[name]\n\n    # Expand abbreviations.\n    for abbrev, expanded in [('str.', 'strasse'),\n                             ('Schiffst.', 'Schiffstation')]:\n      suffix_pos = name.rfind(abbrev)\n      if suffix_pos > 0:\n        name = name[:suffix_pos] + expanded\n    #end for\n\n    names = name.split(\", \", 1)\n    if len(names) == 2:\n      if names[1] in POI_TERMS:\n        nam = u'%s %s' % (names[0], names[1])\n      else:\n        nam = names[1]\n      city = names[0]\n    else:\n      # \"Zurich Enge\": First word of station name designates the city\n      nam = names[0]\n      city = nam.split(' ')[0]\n    return (nam, SPECIAL_CITIES.get(city, city))", "response": "Applies some simple heuristics to split names into ( city name."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nimports the rec_ort. mdv file.", "response": "def ImportStations(self, station_file, adv_file):\n    \"Imports the rec_ort.mdv file.\"\n    for id, name, x, y, uic_code in  \\\n    ReadCSV(station_file, ['ORT_NR', 'ORT_NAME',\n                'ORT_POS_X', 'ORT_POS_Y', 'ORT_NR_NATIONAL']):\n      station = Station()\n      station.id = id\n      station.position = self.coord_converter(float(x), float(y))\n      station.uic_code = ''\n      if uic_code and len(uic_code) == 7 and uic_code[:2] == '85':\n        station.uic_code = uic_code\n      station.name, station.city = self.DemangleName(name)\n      station.country = 'CH'\n      station.url = 'http://fahrplan.zvv.ch/?to.0=' + \\\n                    urllib.quote(name.encode('iso-8859-1'))\n      station.advertised_lines = set()\n      self.stations[id] = station\n    for station_id, line_id in ReadCSV(adv_file, ['ORT_NR', 'LI_NR']):\n      if station_id in self.stations:\n        # Line ids in this file have leading zeroes, remove.\n        self.stations[station_id].advertised_lines.add(line_id.lstrip(\"0\"))\n      else:\n        print(\"Warning, advertised lines file references \" \\\n              \"unknown station, id \" + station_id)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nimport the rec_lin_ber. mdv file.", "response": "def ImportRoutes(self, s):\n    \"Imports the rec_lin_ber.mdv file.\"\n    # the line id is really qualified with an area_id (BEREICH_NR), but the\n    # table of advertised lines does not include area. Fortunately, it seems\n    # that line ids are unique across all areas, so we can just throw it away.\n    for line_id, name in \\\n    ReadCSV(s, ['LI_NR', 'LINIEN_BEZ_DRUCK']):\n      route = Route()\n      route.id = line_id\n      route.name = name\n      route.color = \"FFFFFF\"\n      route.color_text = \"000000\"\n      if name in TRAM_LINES:\n        route.type = TYPE_TRAM\n        route.color = TRAM_LINES[name][0]\n        route.color_text = TRAM_LINES[name][1]\n      else:\n        route.type = TYPE_BUS\n        if route.name[0:1]==\"N\":\n          route.color = \"000000\"\n          route.color_text = \"FFFF00\"\n      self.routes[route.id] = route"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ImportPatterns(self, s):\n    \"Imports the lid_verlauf.mdv file.\"\n    for line, strli, direction, seq, station_id in  \\\n    ReadCSV(s, ['LI_NR', 'STR_LI_VAR', 'LI_RI_NR', 'LI_LFD_NR', 'ORT_NR']):\n      pattern_id = u'Pat.%s.%s.%s' % (line, strli, direction)\n      pattern = self.patterns.get(pattern_id, None)\n      if not pattern:\n        pattern = Pattern()\n        pattern.id = pattern_id\n        pattern.stops = []\n        pattern.stoptimes = {}\n        self.patterns[pattern_id] = pattern\n      seq = int(seq) - 1\n      if len(pattern.stops) <= seq:\n        pattern.stops.extend([None] * (seq - len(pattern.stops)  + 1))\n      pattern.stops[seq] = station_id", "response": "Imports the lid_verlauf. mdv file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading the bedverb. mdv file.", "response": "def ImportBoarding(self, drop_off_file):\n    \"Reads the bedverb.mdv file.\"\n    for trip_id, seq, code in \\\n    ReadCSV(drop_off_file, ['FRT_FID', 'LI_LFD_NR', 'BEDVERB_CODE']):\n      key = (trip_id, int(seq) - 1)\n      if code == 'A':\n        self.pickup_type[key] = '1'  # '1' = no pick-up\n      elif code == 'E':\n        self.drop_off_type[key] = '1'  # '1' = no drop-off\n      elif code == 'B' :\n        # 'B' just means that rider needs to push a button to have the driver\n        # stop. We don't encode this for now.\n        pass\n      else:\n        raise ValueError('Unexpected code in bedverb.mdv; '\n                         'FRT_FID=%s BEDVERB_CODE=%s' % (trip_id, code))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ImportTrafficRestrictions(self, restrictions_file):\n    \"Reads the vb_regio.mdv file.\"\n    ParseDate = lambda x: datetime.date(int(x[:4]), int(x[4:6]), int(x[6:8]))\n    MonthNr = lambda x: int(x[:4]) * 12 + int(x[4:6])\n    for schedule, id, bitmask, start_date, end_date in  \\\n    ReadCSV(restrictions_file,\n            ['FPL_KUERZEL', 'VB', 'VB_DATUM', 'DATUM_VON', 'DATUM_BIS']):\n      id = u\"VB%s.%s\" % (schedule, id)\n      bitmask = bitmask.strip()\n      dates = {}\n\n      # This is ugly as hell, I know. I briefly explain what I do:\n      # 8 characters in the bitmask equal a month ( 8 * 4bits = 32, no month has\n      # more than 31 days, so it's ok).\n      # Then I check if the current day of the month is in the bitmask (by\n      # shifting the bit by x days and comparing it to the bitmask).\n      # If so I calculate back what year month and actual day I am in\n      # (very disgusting) and mark that date...\n      for i in range(MonthNr(end_date) - MonthNr(start_date)+1):\n        mask=int(bitmask[i*8:i*8+8], 16)\n        for d in range(32):\n          if 1 << d & mask:\n            year=int(start_date[0:4])+ ((int(start_date[4:6]) + i -1 )) / 12\n            month=((int(start_date[4:6]) + i-1 ) % 12) +1\n            day=d+1\n            cur_date = str(year)+(\"0\"+str(month))[-2:]+(\"0\"+str(day))[-2:]\n            dates[int(cur_date)] = 1\n      self.services[id] = dates.keys()\n      self.services[id].sort()", "response": "Reads the vb_regio. mdv file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nimporting the lid_fahrzeitart. mdv file.", "response": "def ImportStopTimes(self, stoptimes_file):\n    \"Imports the lid_fahrzeitart.mdv file.\"\n    for line, strli, direction, seq, stoptime_id, drive_secs, wait_secs in \\\n    ReadCSV(stoptimes_file,\n            ['LI_NR', 'STR_LI_VAR', 'LI_RI_NR', 'LI_LFD_NR',\n             'FGR_NR', 'FZT_REL', 'HZEIT']):\n      pattern = self.patterns[u'Pat.%s.%s.%s' % (line, strli, direction)]\n      stoptimes = pattern.stoptimes.setdefault(stoptime_id, [])\n      seq = int(seq) - 1\n      drive_secs = int(drive_secs)\n      wait_secs = int(wait_secs)\n      assert len(stoptimes) == seq  # fails if seq not in order\n      stoptimes.append((drive_secs, wait_secs))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ImportTrips(self, trips_file):\n    \"Imports the rec_frt.mdv file.\"\n    for trip_id, trip_starttime, line, strli, direction,  \\\n        stoptime_id, schedule_id, daytype_id, restriction_id,  \\\n        dest_station_id, dest_stop_id, trip_type in  \\\n        ReadCSV(trips_file,\n            ['FRT_FID', 'FRT_START', 'LI_NR', 'STR_LI_VAR', 'LI_RI_NR',\n             'FGR_NR', 'FPL_KUERZEL', 'TAGESMERKMAL_NR', 'VB',\n             'FRT_HP_AUS', 'HALTEPUNKT_NR_ZIEL', 'FAHRTART_NR']):\n      if trip_type != '1':\n        print(\"skipping Trip \", trip_id, line, direction, \\\n              dest_station_id, trip_type)\n        continue  # 1=normal, 2=empty, 3=from depot, 4=to depot, 5=other\n      trip = Trip()\n      #The trip_id (FRT_FID) field is not unique in the vbz data, as of Dec 2009\n      # to prevent overwritingimported trips when we key them by trip.id\n      # we should make trip.id unique, by combining trip_id and line\n      trip.id = (\"%s_%s\") % (trip_id, line)\n      trip.starttime = int(trip_starttime)\n      trip.route = self.routes[line]\n      dest_station = self.stations[dest_station_id]\n      pattern_id = u'Pat.%s.%s.%s' % (line, strli, direction)\n      trip.pattern = self.patterns[pattern_id]\n      trip.stoptimes = trip.pattern.stoptimes[stoptime_id]\n      if restriction_id:\n        service_id = u'VB%s.%s' % (schedule_id, restriction_id)\n      else:\n        service_id = u'C%s.%s' % (schedule_id, daytype_id)\n      trip.service_id = service_id\n      assert len(self.services[service_id]) > 0\n      assert not trip.id in self.trips\n      self.trips[trip.id] = trip", "response": "Imports the rec_frt. mdv file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef Write(self, outpath):\n    \"Writes a .zip file in Google Transit format.\"\n    out = zipfile.ZipFile(outpath, mode=\"w\", compression=zipfile.ZIP_DEFLATED)\n    for filename, func in [('agency.txt', self.WriteAgency),\n                           ('calendar.txt', self.WriteCalendar),\n                           ('calendar_dates.txt', self.WriteCalendarDates),\n                           ('routes.txt', self.WriteRoutes),\n                           ('trips.txt', self.WriteTrips),\n                           ('stops.txt', self.WriteStations),\n                           ('stop_times.txt', self.WriteStopTimes)]:\n      s = cStringIO.StringIO()\n      func(s)\n      out.writestr(filename, s.getvalue())\n    out.close()", "response": "Writes a. zip file in Google Transit format."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef TransposeTable(table):\n  transposed = []\n  rows = len(table)\n  cols = max(len(row) for row in table)\n  for x in range(cols):\n    transposed.append([])\n    for y in range(rows):\n      if x < len(table[y]):\n        transposed[x].append(table[y][x])\n      else:\n        transposed[x].append(None)\n  return transposed", "response": "Transpose a list of lists using None to extend all input lists to the\n same length."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef CheckVersion(problems, latest_version=None):\n  if not latest_version:\n    timeout = 20\n    socket.setdefaulttimeout(timeout)\n    request = urllib2.Request(LATEST_RELEASE_VERSION_URL)\n\n    try:\n      response = urllib2.urlopen(request)\n      content = response.read()\n      m = re.search(r'version=(\\d+\\.\\d+\\.\\d+)', content)\n      if m:\n        latest_version = m.group(1)\n\n    except urllib2.HTTPError as e:\n      description = ('During the new-version check, we failed to reach '\n                     'transitfeed server: Reason: %s [%s].' %\n                     (e.reason, e.code))\n      problems.OtherProblem(\n        description=description, type=errors.TYPE_NOTICE)\n      return\n    except urllib2.URLError as e:\n      description = ('During the new-version check, we failed to reach '\n                     'transitfeed server. Reason: %s.' % e.reason)\n      problems.OtherProblem(\n        description=description, type=errors.TYPE_NOTICE)\n      return\n\n  if not latest_version:\n    description = ('During the new-version check, we had trouble parsing the '\n                   'contents of %s.' % LATEST_RELEASE_VERSION_URL)\n    problems.OtherProblem(\n      description=description, type=errors.TYPE_NOTICE)\n    return\n\n  newest_version = _MaxVersion([latest_version, __version__])\n  if __version__ != newest_version:\n    problems.NewVersionAvailable(newest_version)", "response": "Checks if there is a newer version of transitfeed available."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef EncodeUnicode(text):\n  if type(text) == type(u''):\n    return text.encode(OUTPUT_ENCODING)\n  else:\n    return text", "response": "Encode text if it is unicode."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ValidateURL(url, column_name=None, problems=None):\n  if IsEmpty(url) or IsValidURL(url):\n    return True\n  else:\n    if problems:\n      problems.InvalidValue(column_name, url)\n    return False", "response": "Validates a non - required URL value."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks the basic validity of email: - an empty email is considered valid and no error or warning is issued. - should start with any string not including @ - then should match a single @ - then matches any string not including @ - then contains a single dot - then again matches any string after dot.", "response": "def ValidateEmail(email, column_name=None, problems=None):\n  \"\"\"\n  checks the basic validity of email:\n    - an empty email is considered valid and no error or warning is issued.\n    - should start with any string not including @\n    - then should match a single @\n    - then matches any string not including @\n    - then contains a single dot\n    - then again matches any string after dot.\n  \"\"\"\n  if IsEmpty(email) or re.match(r'[^@]+@[^@]+\\.[^@]+', email):\n    return True\n  else:\n    if problems:\n      problems.InvalidValue(column_name, email)\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nvalidate a non - required language code value.", "response": "def ValidateLanguageCode(lang, column_name=None, problems=None):\n  \"\"\"\n  Validates a non-required language code value using IsValidLanguageCode():\n    - if invalid adds InvalidValue error (if problems accumulator is provided)\n    - an empty language code is regarded as valid! Otherwise we might end up\n      with many duplicate errors because of the required field checks.\n  \"\"\"\n  if IsEmpty(lang) or IsValidLanguageCode(lang):\n    return True\n  else:\n    if problems:\n      problems.InvalidValue(column_name, lang)\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nvalidates a non - required timezone string value using IsValidTimezone.", "response": "def ValidateTimezone(timezone, column_name=None, problems=None):\n  \"\"\"\n  Validates a non-required timezone string value using IsValidTimezone():\n    - if invalid adds InvalidValue error (if problems accumulator is provided)\n    - an empty timezone string is regarded as valid! Otherwise we might end up\n      with many duplicate errors because of the required field checks.\n  \"\"\"\n  if IsEmpty(timezone) or IsValidTimezone(timezone):\n    return True\n  else:\n    if problems:\n      # if we get here pytz has already been imported successfully in\n      # IsValidTimezone(). So a try-except block is not needed here.\n      import pytz\n      problems.InvalidValue(\n          column_name, timezone,\n          '\"%s\" is not a common timezone name according to pytz version %s' %\n          (timezone, pytz.VERSION))\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nvalidating a non - required date string value.", "response": "def ValidateDate(date, column_name=None, problems=None):\n  \"\"\"\n  Validates a non-required date string value using IsValidDate():\n    - if invalid adds InvalidValue error (if problems accumulator is provided)\n    - an empty date string is regarded as valid! Otherwise we might end up\n      with many duplicate errors because of the required field checks.\n  \"\"\"\n  if IsEmpty(date) or IsValidDate(date):\n    return True\n  else:\n    if problems:\n      problems.InvalidValue(column_name, date)\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nvalidating that all required fields of a GTFS object are empty.", "response": "def ValidateRequiredFieldsAreNotEmpty(gtfs_object, required_field_names,\n                                      problems=None):\n  \"\"\"\n  Validates whether all required fields of an object have a value:\n    - if value empty adds MissingValue errors (if problems accumulator is\n      provided)\n  \"\"\"\n  no_missing_value = True\n  for name in required_field_names:\n    if IsEmpty(getattr(gtfs_object, name, None)):\n      if problems:\n        problems.MissingValue(name)\n      no_missing_value = False\n  return no_missing_value"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ValidateAndReturnIntValue(value, allowed_values, default, allow_empty,\n                              column_name=None, problems=None):\n  \"\"\"\n  Validates a value to be a valid integer in the list of allowed values:\n    - if no integer value adds InvalidValue error and returns the default value\n    - if integer but not in allowed_values addes InvalidValue warning\n    - returns the default value if empty and allow_empty = True\n\n  Args:\n    value: a string or integer value\n    allowed_values: a list of allowed integer values\n    default: a default value for invalid string vlaues\n    allow_empty: a bool indicating whether an empty value is allowed and\n                 defaults to the default value\n    column_name: the column name the value comes from\n    problems: the problems accumulator\n\n  Returns:\n    An integer value.\n  \"\"\"\n  if allow_empty and IsEmpty(value):\n    return default\n  try:\n    int_value = int(value)\n  except (ValueError, TypeError):\n    if problems and column_name:\n      problems.InvalidValue(column_name, value)\n    return default\n  else:\n    if int_value not in allowed_values:\n      if problems and column_name:\n        problems.InvalidValue(column_name, value,\n                              type=errors.TYPE_WARNING)\n    return int_value", "response": "Validates a value to be an integer in the list of allowed values and returns the integer value."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ColorLuminance(color):\n  r = int(color[0:2], 16)\n  g = int(color[2:4], 16)\n  b = int(color[4:6], 16)\n  return (299*r + 587*g + 114*b) / 1000.0", "response": "Compute the brightness of an sRGB color using the formula from\n http://www. w3. org / TR / 2000_WD - AERT - 20000426#color - contrast."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ValidateYesNoUnknown(value, column_name=None, problems=None):\n  if IsEmpty(value) or IsValidYesNoUnknown(value):\n    return True\n  else:\n    if problems:\n      problems.InvalidValue(column_name, value)\n    return False", "response": "Validates a value 0 1 2 for yes and 3 for no."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef FindUniqueId(dic):\n  name = str(len(dic))\n  while name in dic:\n    # Use bigger numbers so it is obvious when an id is picked randomly.\n    name = str(random.randint(1000000, 999999999))\n  return name", "response": "Return a string not used as a key in the dictionary dic"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef TimeToSecondsSinceMidnight(time_string):\n  m = re.match(r'(\\d{1,3}):([0-5]\\d):([0-5]\\d)$', time_string)\n  # ignored: matching for leap seconds\n  if not m:\n    raise errors.Error('Bad HH:MM:SS \"%s\"' % time_string)\n  return int(m.group(1)) * 3600 + int(m.group(2)) * 60 + int(m.group(3))", "response": "Convert a time string into seconds since midnight."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a date object for a string YYYYMMDD.", "response": "def DateStringToDateObject(date_string):\n  \"\"\"Return a date object for a string \"YYYYMMDD\".\"\"\"\n  # If this becomes a bottleneck date objects could be cached\n  if re.match('^\\d{8}$', date_string) == None:\n    return None\n  try:\n    return datetime.date(int(date_string[0:4]), int(date_string[4:6]),\n                         int(date_string[6:8]))\n  except ValueError:\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef FloatStringToFloat(float_string, problems=None):\n  # Will raise TypeError unless a string\n  match = re.match(r\"^[+-]?\\d+(\\.\\d+)?$\", float_string)\n  # Will raise TypeError if the string can't be parsed\n  parsed_value = float(float_string)\n\n  if \"x\" in float_string:\n    # This is needed because Python 2.4 does not complain about float(\"0x20\").\n    # But it does complain about float(\"0b10\"), so this should be enough.\n    raise ValueError()\n\n  if not match and problems is not None:\n    # Does not match the regex, but it's a float according to Python\n    problems.InvalidFloatValue(float_string)\n  return parsed_value", "response": "Convert a float as a string to a float or raise an exception"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef NonNegIntStringToInt(int_string, problems=None):\n  # Will raise TypeError unless a string\n  match = re.match(r\"^(?:0|[1-9]\\d*)$\", int_string)\n  # Will raise ValueError if the string can't be parsed\n  parsed_value = int(int_string)\n\n  if parsed_value < 0:\n    raise ValueError()\n  elif not match and problems is not None:\n    # Does not match the regex, but it's an int according to Python\n    problems.InvalidNonNegativeIntegerValue(int_string)\n\n  return parsed_value", "response": "Convert an non - negative integer string to an int or raise an exception."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ApproximateDistance(degree_lat1, degree_lng1, degree_lat2, degree_lng2):\n  # TODO: change to ellipsoid approximation, such as\n  # http://www.codeguru.com/Cpp/Cpp/algorithms/article.php/c5115/\n  lat1 = math.radians(degree_lat1)\n  lng1 = math.radians(degree_lng1)\n  lat2 = math.radians(degree_lat2)\n  lng2 = math.radians(degree_lng2)\n  dlat = math.sin(0.5 * (lat2 - lat1))\n  dlng = math.sin(0.5 * (lng2 - lng1))\n  x = dlat * dlat + dlng * dlng * math.cos(lat1) * math.cos(lat2)\n  return EARTH_RADIUS * (2 * math.atan2(math.sqrt(x),\n      math.sqrt(max(0.0, 1.0 - x))))", "response": "Compute approximate distance between two points in meters."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ApproximateDistanceBetweenStops(stop1, stop2):\n  if (stop1.stop_lat is None or stop1.stop_lon is None or\n      stop2.stop_lat is None or stop2.stop_lon is None):\n    return None\n  return ApproximateDistance(stop1.stop_lat, stop1.stop_lon,\n                             stop2.stop_lat, stop2.stop_lon)", "response": "Compute approximate distance between two stops in meters."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef writerow(self, row):\n    encoded_row = []\n    for s in row:\n      if isinstance(s, unicode):\n        encoded_row.append(s.encode(\"utf-8\"))\n      else:\n        encoded_row.append(s)\n    try:\n      self.writer.writerow(encoded_row)\n    except Exception as e:\n      print('error writing %s as %s' % (row, encoded_row))\n      raise e", "response": "Write row to the csv file. Any unicode strings in row are encoded as\n    utf - 8."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning next line without end of line marker or raise StopIteration.", "response": "def next(self):\n    \"\"\"Return next line without end of line marker or raise StopIteration.\"\"\"\n    try:\n      next_line = next(self._f)\n    except StopIteration:\n      self._FinalCheck()\n      raise\n\n    self._line_number += 1\n    m_eol = re.search(r\"[\\x0a\\x0d]*$\", next_line)\n    if m_eol.group() == \"\\x0d\\x0a\":\n      self._crlf += 1\n      if self._crlf <= 5:\n        self._crlf_examples.append(self._line_number)\n    elif m_eol.group() == \"\\x0a\":\n      self._lf += 1\n      if self._lf <= 5:\n        self._lf_examples.append(self._line_number)\n    elif m_eol.group() == \"\":\n      # Should only happen at the end of the file\n      try:\n        next(self._f)\n        raise RuntimeError(\"Unexpected row without new line sequence\")\n      except StopIteration:\n        # Will be raised again when EndOfLineChecker.next() is next called\n        pass\n    else:\n      self._problems.InvalidLineEnd(\n        codecs.getencoder('string_escape')(m_eol.group())[0],\n        (self._name, self._line_number))\n    next_line_contents = next_line[0:m_eol.start()]\n    for seq, name in INVALID_LINE_SEPARATOR_UTF8.items():\n      if next_line_contents.find(seq) != -1:\n        self._problems.OtherProblem(\n          \"Line contains %s\" % name,\n          context=(self._name, self._line_number))\n    return next_line_contents"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef read_first_available_value(filename, field_name):\n    if not os.path.exists(filename):\n        return None\n    with open(filename, 'rb') as csvfile:\n        reader = csv.DictReader(csvfile)\n        for row in reader:\n            value = row.get(field_name)\n            if value:\n                return value\n    return None", "response": "Reads the first available value of the given field in the CSV table."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _find_feed_language(self):\n        self.feed_language = (\n            read_first_available_value(\n                os.path.join(self.src_dir, 'feed_info.txt'), 'feed_lang') or\n            read_first_available_value(\n                os.path.join(self.src_dir, 'agency.txt'), 'agency_lang'))\n        if not self.feed_language:\n            raise Exception(\n                'Cannot find feed language in feed_info.txt and agency.txt')\n        print('\\tfeed language: %s' % self.feed_language)", "response": "Find feed language based specified feed_info. txt or agency. txt."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _read_translations(self):\n        print('Reading original translations')\n        self.translations_map = {}\n        n_translations = 0\n        with open(os.path.join(self.src_dir, 'translations.txt'),\n                  'rb') as csvfile:\n            reader = csv.DictReader(csvfile)\n            for row in reader:\n                self.translations_map.setdefault(\n                    row['trans_id'], {})[row['lang']] = row['translation']\n                n_translations += 1\n        print('\\ttotal original translations: %s' % n_translations)", "response": "Read from the old translations. txt."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfinds texts whose translation depends on context.", "response": "def _find_context_dependent_names(self):\n        \"\"\"Finds texts whose translation depends on context.\n\n        Example.\n          Here the word \"Palacio\" is translated from Spanish to English in\n          multiple ways. Feed language is es (Spanish).\n\n          trans_id,lang,translation\n          stop-name-1,es,Palacio\n          stop-name-1,en,Palace\n          headsign-1,es,Palacio\n          headsign-1,en,To Palace\n        \"\"\"\n        n_occurences_of_original = {}\n        for trans_id, translations in self.translations_map.items():\n            try:\n                original_name = translations[self.feed_language]\n            except KeyError:\n                raise Exception(\n                    'No translation in feed language for %s, available: %s' %\n                    (trans_id, translations))\n            n_occurences_of_original[original_name] = (\n                n_occurences_of_original.get(original_name, 0) +\n                1)\n\n        self.context_dependent_names = set(\n            name\n            for name, occur in n_occurences_of_original.items()\n            if occur > 1)\n        print('Total context-dependent translations: %d' %\n              len(self.context_dependent_names))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert all translations from the source directory to the new format and stores at dest_dir.", "response": "def convert_translations(self, dest_dir):\n        \"\"\"\n        Converts translations to the new format and stores at dest_dir.\n        \"\"\"\n        if not os.path.isdir(dest_dir):\n            os.makedirs(dest_dir)\n        total_translation_rows = 0\n        with open(os.path.join(dest_dir, 'translations.txt'),\n                  'w+b') as out_file:\n            writer = csv.DictWriter(\n                out_file, fieldnames=NEW_TRANSLATIONS_FIELDS)\n            writer.writeheader()\n            for filename in sorted(os.listdir(self.src_dir)):\n                if not (filename.endswith('.txt') and\n                        os.path.isfile(os.path.join(self.src_dir, filename))):\n                    print('Skipping %s' % filename)\n                    continue\n                table_name = filename[:-len('.txt')]\n                if table_name == 'translations':\n                    continue\n                total_translation_rows += self._translate_table(\n                    dest_dir, table_name, writer)\n        print('Total translation rows: %s' % total_translation_rows)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _translate_table(self, dest_dir, table_name, translations_writer):\n        in_filename = os.path.join(self.src_dir, '%s.txt' % table_name)\n        if not os.path.exists(in_filename):\n            raise Exception('No %s' % table_name)\n\n        out_filename = os.path.join(dest_dir, '%s.txt' % table_name)\n        with open(in_filename, 'rb') as in_file:\n            reader = csv.DictReader(in_file)\n            if not reader.fieldnames or not any_translatable_field(\n                    reader.fieldnames):\n                print('Copying %s with no translatable columns' % table_name)\n                shutil.copy(in_filename, out_filename)\n                return 0\n            table_translator = TableTranslator(\n                table_name, reader.fieldnames, self.old_translations,\n                translations_writer)\n            with open(out_filename, 'w+b') as out_file:\n                writer = csv.DictWriter(out_file, fieldnames=reader.fieldnames)\n                writer.writeheader()\n                for row in reader:\n                    writer.writerow(table_translator.translate_row(row))\n\n            table_translator.write_for_field_values()\n            print('\\ttranslation rows: %s' %\n                  table_translator.total_translation_rows)\n            return table_translator.total_translation_rows", "response": "Translate a single table to a new format."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _DetermineFormat(self):\n    if self._zip:\n      # If zip was passed to __init__ then path isn't used\n      assert not self._path\n      return True\n\n    if not isinstance(self._path, basestring) and hasattr(self._path, 'read'):\n      # A file-like object, used for testing with a StringIO file\n      self._zip = zipfile.ZipFile(self._path, mode='r')\n      return True\n\n    if not os.path.exists(self._path):\n      self._problems.FeedNotFound(self._path)\n      return False\n\n    if self._path.endswith('.zip'):\n      try:\n        self._zip = zipfile.ZipFile(self._path, mode='r')\n      except IOError:  # self._path is a directory\n        pass\n      except zipfile.BadZipfile:\n        self._problems.UnknownFormat(self._path)\n        return False\n\n    if not self._zip and not os.path.isdir(self._path):\n      self._problems.UnknownFormat(self._path)\n      return False\n\n    return True", "response": "Determines if the feed is in a form that we understand and\n       if so returns True."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of file names in the feed.", "response": "def _GetFileNames(self):\n    \"\"\"Returns a list of file names in the feed.\"\"\"\n    if self._zip:\n      return self._zip.namelist()\n    else:\n      return os.listdir(self._path)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the contents of a file in a UTF - 8 format.", "response": "def _GetUtf8Contents(self, file_name):\n    \"\"\"Check for errors in file_name and return a string for csv reader.\"\"\"\n    contents = self._FileContents(file_name)\n    if not contents:  # Missing file\n      return\n\n    # Check for errors that will prevent csv.reader from working\n    if len(contents) >= 2 and contents[0:2] in (codecs.BOM_UTF16_BE,\n        codecs.BOM_UTF16_LE):\n      self._problems.FileFormat(\"appears to be encoded in utf-16\", (file_name, ))\n      # Convert and continue, so we can find more errors\n      contents = codecs.getdecoder('utf-16')(contents)[0].encode('utf-8')\n\n    null_index = contents.find('\\0')\n    if null_index != -1:\n      # It is easier to get some surrounding text than calculate the exact\n      # row_num\n      m = re.search(r'.{,20}\\0.{,20}', contents, re.DOTALL)\n      self._problems.FileFormat(\n          \"contains a null in text \\\"%s\\\" at byte %d\" %\n          (codecs.getencoder('string_escape')(m.group()), null_index + 1),\n          (file_name, ))\n      return\n\n    # strip out any UTF-8 Byte Order Marker (otherwise it'll be\n    # treated as part of the first column name, causing a mis-parse)\n    contents = contents.lstrip(codecs.BOM_UTF8)\n    return contents"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _ReadCsvDict(self, file_name, cols, required, deprecated):\n    assert file_name.endswith(\".txt\")\n    table_name = file_name[0:-4]\n    contents = self._GetUtf8Contents(file_name)\n    if not contents:\n      return\n\n    eol_checker = util.EndOfLineChecker(StringIO.StringIO(contents),\n                                   file_name, self._problems)\n    # The csv module doesn't provide a way to skip trailing space, but when I\n    # checked 15/675 feeds had trailing space in a header row and 120 had spaces\n    # after fields. Space after header fields can cause a serious parsing\n    # problem, so warn. Space after body fields can cause a problem time,\n    # integer and id fields; they will be validated at higher levels.\n    reader = csv.reader(eol_checker, skipinitialspace=True)\n\n    raw_header = next(reader)\n    header_occurrences = util.defaultdict(lambda: 0)\n    header = []\n    valid_columns = []  # Index into raw_header and raw_row\n    for i, h in enumerate(raw_header):\n      h_stripped = h.strip()\n      if not h_stripped:\n        self._problems.CsvSyntax(\n            description=\"The header row should not contain any blank values. \"\n                        \"The corresponding column will be skipped for the \"\n                        \"entire file.\",\n            context=(file_name, 1, [''] * len(raw_header), raw_header),\n            type=problems.TYPE_ERROR)\n        continue\n      elif h != h_stripped:\n        self._problems.CsvSyntax(\n            description=\"The header row should not contain any \"\n                        \"space characters.\",\n            context=(file_name, 1, [''] * len(raw_header), raw_header),\n            type=problems.TYPE_WARNING)\n      header.append(h_stripped)\n      valid_columns.append(i)\n      header_occurrences[h_stripped] += 1\n\n    for name, count in header_occurrences.items():\n      if count > 1:\n        self._problems.DuplicateColumn(\n            header=name,\n            file_name=file_name,\n            count=count)\n\n    self._schedule._table_columns[table_name] = header\n\n    # check for unrecognized columns, which are often misspellings\n    header_context = (file_name, 1, [''] * len(header), header)\n    valid_cols = cols + [deprecated_name for (deprecated_name, _) in deprecated]\n    unknown_cols = set(header) - set(valid_cols)\n    if len(unknown_cols) == len(header):\n      self._problems.CsvSyntax(\n            description=\"The header row did not contain any known column \"\n                        \"names. The file is most likely missing the header row \"\n                        \"or not in the expected CSV format.\",\n            context=(file_name, 1, [''] * len(raw_header), raw_header),\n            type=problems.TYPE_ERROR)\n    else:\n      for col in unknown_cols:\n        # this is provided in order to create a nice colored list of\n        # columns in the validator output\n        self._problems.UnrecognizedColumn(file_name, col, header_context)\n\n    # check for missing required columns\n    missing_cols = set(required) - set(header)\n    for col in missing_cols:\n      # this is provided in order to create a nice colored list of\n      # columns in the validator output\n      self._problems.MissingColumn(file_name, col, header_context)\n\n    # check for deprecated columns\n    for (deprecated_name, new_name) in deprecated:\n      if deprecated_name in header:\n        self._problems.DeprecatedColumn(file_name, deprecated_name, new_name,\n                                        header_context)\n\n    line_num = 1  # First line read by reader.next() above\n    for raw_row in reader:\n      line_num += 1\n      if len(raw_row) == 0:  # skip extra empty lines in file\n        continue\n\n      if len(raw_row) > len(raw_header):\n        self._problems.OtherProblem('Found too many cells (commas) in line '\n                                    '%d of file \"%s\".  Every row in the file '\n                                    'should have the same number of cells as '\n                                    'the header (first line) does.' %\n                                    (line_num, file_name),\n                                    (file_name, line_num),\n                                    type=problems.TYPE_WARNING)\n\n      if len(raw_row) < len(raw_header):\n        self._problems.OtherProblem('Found missing cells (commas) in line '\n                                    '%d of file \"%s\".  Every row in the file '\n                                    'should have the same number of cells as '\n                                    'the header (first line) does.' %\n                                    (line_num, file_name),\n                                    (file_name, line_num),\n                                    type=problems.TYPE_WARNING)\n\n      # raw_row is a list of raw bytes which should be valid utf-8. Convert each\n      # valid_columns of raw_row into Unicode.\n      valid_values = []\n      unicode_error_columns = []  # index of valid_values elements with an error\n      for i in valid_columns:\n        try:\n          valid_values.append(raw_row[i].decode('utf-8'))\n        except UnicodeDecodeError:\n          # Replace all invalid characters with REPLACEMENT CHARACTER (U+FFFD)\n          valid_values.append(codecs.getdecoder(\"utf8\")\n                              (raw_row[i], errors=\"replace\")[0])\n          unicode_error_columns.append(len(valid_values) - 1)\n        except IndexError:\n          break\n\n      # The error report may contain a dump of all values in valid_values so\n      # problems can not be reported until after converting all of raw_row to\n      # Unicode.\n      for i in unicode_error_columns:\n        self._problems.InvalidValue(header[i], valid_values[i],\n                                    'Unicode error',\n                                    (file_name, line_num,\n                                     valid_values, header))\n\n      # We strip ALL whitespace from around values.  This matches the behavior\n      # of both the Google and OneBusAway GTFS parser.\n      valid_values = [value.strip() for value in valid_values]\n\n      d = dict(zip(header, valid_values))\n      yield (d, line_num, header, valid_values)", "response": "Reads lines from file_name yielding a dict of unicode values."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread lines from file_name yielding a list of unicode values corresponding to the column names in cols.", "response": "def _ReadCSV(self, file_name, cols, required, deprecated):\n    \"\"\"Reads lines from file_name, yielding a list of unicode values\n    corresponding to the column names in cols.\"\"\"\n    contents = self._GetUtf8Contents(file_name)\n    if not contents:\n      return\n\n    eol_checker = util.EndOfLineChecker(StringIO.StringIO(contents),\n                                   file_name, self._problems)\n    reader = csv.reader(eol_checker)  # Use excel dialect\n\n    header = next(reader)\n    header = map(lambda x: x.strip(), header)  # trim any whitespace\n    header_occurrences = util.defaultdict(lambda: 0)\n    for column_header in header:\n      header_occurrences[column_header] += 1\n\n    for name, count in header_occurrences.items():\n      if count > 1:\n        self._problems.DuplicateColumn(\n            header=name,\n            file_name=file_name,\n            count=count)\n\n    # check for unrecognized columns, which are often misspellings\n    header_context = (file_name, 1, [''] * len(header), header)\n    valid_cols = cols + [deprecated_name for (deprecated_name, _) in deprecated]\n    unknown_cols = set(header).difference(set(valid_cols))\n    for col in unknown_cols:\n      # this is provided in order to create a nice colored list of\n      # columns in the validator output\n      self._problems.UnrecognizedColumn(file_name, col, header_context)\n\n    # check for missing required columns\n    col_index = [-1] * len(cols)\n    for i in range(len(cols)):\n      if cols[i] in header:\n        col_index[i] = header.index(cols[i])\n      elif cols[i] in required:\n        self._problems.MissingColumn(file_name, cols[i], header_context)\n\n    # check for deprecated columns\n    for (deprecated_name, new_name) in deprecated:\n      if deprecated_name in header:\n        self._problems.DeprecatedColumn(file_name, deprecated_name, new_name,\n                                        header_context)\n\n    row_num = 1\n    for row in reader:\n      row_num += 1\n      if len(row) == 0:  # skip extra empty lines in file\n        continue\n\n      if len(row) > len(header):\n        self._problems.OtherProblem('Found too many cells (commas) in line '\n                                    '%d of file \"%s\".  Every row in the file '\n                                    'should have the same number of cells as '\n                                    'the header (first line) does.' %\n                                    (row_num, file_name), (file_name, row_num),\n                                    type=problems.TYPE_WARNING)\n\n      if len(row) < len(header):\n        self._problems.OtherProblem('Found missing cells (commas) in line '\n                                    '%d of file \"%s\".  Every row in the file '\n                                    'should have the same number of cells as '\n                                    'the header (first line) does.' %\n                                    (row_num, file_name), (file_name, row_num),\n                                    type=problems.TYPE_WARNING)\n\n      result = [None] * len(cols)\n      unicode_error_columns = []  # A list of column numbers with an error\n      for i in range(len(cols)):\n        ci = col_index[i]\n        if ci >= 0:\n          if len(row) <= ci:  # handle short CSV rows\n            result[i] = u''\n          else:\n            try:\n              result[i] = row[ci].decode('utf-8').strip()\n            except UnicodeDecodeError:\n              # Replace all invalid characters with\n              # REPLACEMENT CHARACTER (U+FFFD)\n              result[i] = codecs.getdecoder(\"utf8\")(row[ci],\n                                                    errors=\"replace\")[0].strip()\n              unicode_error_columns.append(i)\n\n      for i in unicode_error_columns:\n        self._problems.InvalidValue(cols[i], result[i],\n                                    'Unicode error',\n                                    (file_name, row_num, result, cols))\n      yield (result, row_num, cols)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns True if there s a file with the given file_name in the current feed with the given file_name in the current feed.", "response": "def _HasFile(self, file_name):\n    \"\"\"Returns True if there's a file in the current feed with the\n       given file_name in the current feed.\"\"\"\n    if self._zip:\n      return file_name in self._zip.namelist()\n    else:\n      file_path = os.path.join(self._path, file_name)\n      return os.path.exists(file_path) and os.path.isfile(file_path)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef AddTrip(self, schedule=None, headsign=None, service_period=None,\n              trip_id=None):\n    \"\"\"Add a trip to this route.\n\n    Args:\n      schedule: a Schedule object which will hold the new trip or None to use\n        the schedule of this route.\n      headsign: headsign of the trip as a string\n      service_period: a ServicePeriod object or None to use\n        schedule.GetDefaultServicePeriod()\n      trip_id: optional trip_id for the new trip\n\n    Returns:\n      a new Trip object\n    \"\"\"\n    if schedule is None:\n      assert self._schedule is not None\n      schedule = self._schedule\n    if trip_id is None:\n      trip_id = util.FindUniqueId(schedule.trips)\n    if service_period is None:\n      service_period = schedule.GetDefaultServicePeriod()\n    trip_class = self.GetGtfsFactory().Trip\n    trip_obj = trip_class(route=self, headsign=headsign,\n                service_period=service_period, trip_id=trip_id)\n    schedule.AddTripObject(trip_obj)\n    return trip_obj", "response": "Adds a trip to this route."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a dictionary that maps pattern_id to a list of Trip objects.", "response": "def GetPatternIdTripDict(self):\n    \"\"\"Return a dictionary that maps pattern_id to a list of Trip objects.\"\"\"\n    d = {}\n    for t in self._trips:\n      d.setdefault(t.pattern_id, []).append(t)\n    return d"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef GetGtfsClassByFileName(self, filename):\n    if filename not in self._file_mapping:\n      return None\n    mapping = self._file_mapping[filename]\n    class_list = mapping['classes']\n    if len(class_list) > 1:\n      raise problems.NonStandardMapping(filename)\n    else:\n      return self._class_mapping[class_list[0]]", "response": "Returns the transitfeed class corresponding to a GTFS file."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list of filenames sorted by loading order.", "response": "def GetLoadingOrder(self):\n    \"\"\"Returns a list of filenames sorted by loading order.\n    Only includes files that Loader's standardized loading knows how to load\"\"\"\n    result = {}\n    for filename, mapping in self._file_mapping.iteritems():\n      loading_order = mapping['loading_order']\n      if loading_order is not None:\n        result[loading_order] = filename\n    return list(result[key] for key in sorted(result))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning true if a file is required by GTFS.", "response": "def IsFileRequired(self, filename):\n    \"\"\"Returns true if a file is required by GTFS, false otherwise.\n    Unknown files are, by definition, not required\"\"\"\n    if filename not in self._file_mapping:\n      return False\n    mapping = self._file_mapping[filename]\n    return mapping['required']"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef AddMapping(self, filename, new_mapping):\n    for field in self._REQUIRED_MAPPING_FIELDS:\n      if field not in new_mapping:\n        raise problems.InvalidMapping(field)\n    if filename in self.GetKnownFilenames():\n      raise problems.DuplicateMapping(filename)\n    self._file_mapping[filename] = new_mapping", "response": "Adds an entry to the list of known filenames."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupdate an entry in the list of known filenames.", "response": "def UpdateMapping(self, filename, mapping_update):\n    \"\"\"Updates an entry in the list of known filenames.\n       An entry is identified by its filename.\n\n    Args:\n        filename: The filename whose mapping is to be updated\n        mapping_update: A dictionary containing the fields to update and their\n            new values.\n    Raises:\n        InexistentMapping if the filename does not exist in the mapping\n    \"\"\"\n    if filename not in self._file_mapping:\n      raise problems.NonexistentMapping(filename)\n    mapping = self._file_mapping[filename]\n    mapping.update(mapping_update)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef AddClass(self, class_name, gtfs_class):\n    if class_name in self._class_mapping:\n      raise problems.DuplicateMapping(class_name)\n    self._class_mapping[class_name] = gtfs_class", "response": "Adds an entry to the list of known classes."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates an entry in the list of known classes.", "response": "def UpdateClass(self, class_name, gtfs_class):\n    \"\"\"Updates an entry in the list of known classes.\n\n    Args:\n        class_name: A string with the class name that is to be updated.\n        gtfs_class: The new class\n    Raises:\n        NonexistentMapping if there is no class with the specified class_name.\n    \"\"\"\n    if class_name not in self._class_mapping:\n      raise problems.NonexistentMapping(class_name)\n    self._class_mapping[class_name] = gtfs_class"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef RemoveClass(self, class_name):\n    if class_name not in self._class_mapping:\n      raise problems.NonexistentMapping(class_name)\n    del self._class_mapping[class_name]", "response": "Removes an entry from the list of known classes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading the kml file and parses it into a Google transit feed object.", "response": "def Parse(self, filename, feed):\n    \"\"\"\n    Reads the kml file, parses it and updated the Google transit feed\n    object with the extracted information.\n\n    Args:\n      filename - kml file name\n      feed - an instance of Schedule class to be updated\n    \"\"\"\n    dom = minidom.parse(filename)\n    self.ParseDom(dom, feed)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses the given kml dom tree and updates the Google transit feed object.", "response": "def ParseDom(self, dom, feed):\n    \"\"\"\n    Parses the given kml dom tree and updates the Google transit feed object.\n\n    Args:\n      dom - kml dom tree\n      feed - an instance of Schedule class to be updated\n    \"\"\"\n    shape_num = 0\n    for node in dom.getElementsByTagName('Placemark'):\n      p = self.ParsePlacemark(node)\n      if p.IsPoint():\n        (lon, lat) = p.coordinates[0]\n        m = self.stopNameRe.search(p.name)\n        feed.AddStop(lat, lon, m.group(1))\n      elif p.IsLine():\n        self.ConvertPlacemarkToShape(p, feed)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncomputes the geodesic distance between two points on the Earth.", "response": "def Distance(lat0, lng0, lat1, lng1):\n  \"\"\"\n  Compute the geodesic distance in meters between two points on the\n  surface of the Earth.  The latitude and longitude angles are in\n  degrees.\n\n  Approximate geodesic distance function (Haversine Formula) assuming\n  a perfect sphere of radius 6367 km (see \"What are some algorithms\n  for calculating the distance between 2 points?\" in the GIS Faq at\n  http://www.census.gov/geo/www/faq-index.html).  The approximate\n  radius is adequate for our needs here, but a more sophisticated\n  geodesic function should be used if greater accuracy is required\n  (see \"When is it NOT okay to assume the Earth is a sphere?\" in the\n  same faq).\n  \"\"\"\n  deg2rad = math.pi / 180.0\n  lat0 = lat0 * deg2rad\n  lng0 = lng0 * deg2rad\n  lat1 = lat1 * deg2rad\n  lng1 = lng1 * deg2rad\n  dlng = lng1 - lng0\n  dlat = lat1 - lat0\n  a = math.sin(dlat*0.5)\n  b = math.sin(dlng*0.5)\n  a = a * a + math.cos(lat0) * math.cos(lat1) * b * b\n  c = 2.0 * math.atan2(math.sqrt(a), math.sqrt(1.0 - a))\n  return 6367000.0 * c"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding up to 500m of error to each coordinate of lat lng.", "response": "def AddNoiseToLatLng(lat, lng):\n  \"\"\"Add up to 500m of error to each coordinate of lat, lng.\"\"\"\n  m_per_tenth_lat = Distance(lat, lng, lat + 0.1, lng)\n  m_per_tenth_lng = Distance(lat, lng, lat, lng + 0.1)\n  lat_per_100m = 1 / m_per_tenth_lat * 10\n  lng_per_100m = 1 / m_per_tenth_lng * 10\n  return (lat + (lat_per_100m * 5 * (random.random() * 2 - 1)),\n          lng + (lng_per_100m * 5 * (random.random() * 2 - 1)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef GetRandomLocationsNearStops(schedule):\n  locations = []\n  for s in schedule.GetStopList():\n    locations.append(AddNoiseToLatLng(s.stop_lat, s.stop_lon))\n  return locations", "response": "Return a list of ( lat lng ) tuples that are nearstops."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef GetRandomDatetime():\n  seconds_offset = random.randint(0, 60 * 60 * 24 * 7)\n  dt = datetime.today() + timedelta(seconds=seconds_offset)\n  return dt.replace(second=0, microsecond=0)", "response": "Return a random datetime in the next week."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a URL for routing between two lat lon.", "response": "def LatLngsToGoogleUrl(source, destination, dt):\n  \"\"\"Return a URL for routing between two (lat, lng) at a datetime.\"\"\"\n  params = {\"saddr\": FormatLatLng(source),\n            \"daddr\": FormatLatLng(destination),\n            \"time\": dt.strftime(\"%I:%M%p\"),\n            \"date\": dt.strftime(\"%Y-%m-%d\"),\n            \"dirflg\": \"r\",\n            \"ie\": \"UTF8\",\n            \"oe\": \"UTF8\"}\n  url = urlparse.urlunsplit((\"http\", \"maps.google.com\", \"/maps\",\n                             urllib.urlencode(params), \"\"))\n  return url"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef LatLngsToGoogleLink(source, destination):\n  dt = GetRandomDatetime()\n  return \"<a href='%s'>from:%s to:%s on %s</a>\" % (\n      LatLngsToGoogleUrl(source, destination, dt),\n      FormatLatLng(source), FormatLatLng(destination),\n      dt.ctime())", "response": "Return a string \"<a... for a trip at a random time."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef WriteOutput(title, locations, limit, f):\n  output_prefix = \"\"\"\n<html>\n<head>\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\">\n<title>%(title)s</title>\n</head>\n<body>\nRandom queries for %(title)s<p>\nThis list of random queries should speed up important manual testing. Here are\nsome things to check when looking at the results of a query.\n<ul>\n  <li> Check the agency attribution under the trip results:\n  <ul>\n    <li> has correct name and spelling of the agency\n    <li> opens a page with general information about the service\n  </ul>\n  <li> For each alternate trip check that each of these is reasonable:\n  <ul>\n    <li> the total time of the trip\n    <li> the time for each leg. Bad data frequently results in a leg going a long\n    way in a few minutes.\n    <li> the icons and mode names (Tram, Bus, etc) are correct for each leg\n    <li> the route names and headsigns are correctly formatted and not\n    redundant.\n    For a good example see <a\n    href=\"https://developers.google.com/transit/gtfs/examples/display-to-users\">\n    the screenshots in the Google Transit Feed Specification</a>.\n    <li> the shape line on the map looks correct. Make sure the polyline does\n    not zig-zag, loop, skip stops or jump far away unless the trip does the\n    same thing.\n    <li> the route is active on the day the trip planner returns\n  </ul>\n</ul>\nIf you find a problem be sure to save the URL. This file is generated randomly.\n<ol>\n\"\"\" % locals()\n\n  output_suffix = \"\"\"\n</ol>\n</body>\n</html>\n\"\"\" % locals()\n\n  f.write(transitfeed.EncodeUnicode(output_prefix))\n  for source, destination in zip(locations[0:limit], locations[1:limit + 1]):\n    f.write(transitfeed.EncodeUnicode(\"<li>%s\\n\" %\n                                      LatLngsToGoogleLink(source, destination)))\n  f.write(transitfeed.EncodeUnicode(output_suffix))", "response": "Writes the output of a random query to a file."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngives a path return only the parent name and file name as a string.", "response": "def ParentAndBaseName(path):\n  \"\"\"Given a path return only the parent name and file name as a string.\"\"\"\n  dirname, basename = os.path.split(path)\n  dirname = dirname.rstrip(os.path.sep)\n  if os.path.altsep:\n    dirname = dirname.rstrip(os.path.altsep)\n  _, parentname = os.path.split(dirname)\n  return os.path.join(parentname, basename)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef LoadFile(f, table_name, conn):\n  reader = csv.reader(f)\n  header = next(reader)\n\n  columns = []\n  for n in header:\n    n = n.replace(' ', '')\n    n = n.replace('-', '_')\n    columns.append(n)\n\n  create_columns = []\n  column_types = {}\n  for n in columns:\n    if n in column_types:\n      create_columns.append(\"%s %s\" % (n, column_types[n]))\n    else:\n      create_columns.append(\"%s INTEGER\" % (n))\n\n  c = conn.cursor()\n  try:\n    c.execute(\"CREATE TABLE %s (%s)\" % (table_name, \",\".join(create_columns)))\n  except sqlite.OperationalError:\n    # Likely table exists\n    print(\"table %s already exists?\" % (table_name))\n    for create_column in create_columns:\n      try:\n        c.execute(\"ALTER TABLE %s ADD COLUMN %s\" % (table_name, create_column))\n      except sqlite.OperationalError:\n        # Likely it already exists\n        print(\"column %s already exists in %s?\" % (create_column, table_name))\n\n  placeholders = \",\".join([\"?\"] * len(columns))\n  insert_values = \"INSERT INTO %s (%s) VALUES (%s)\" % (table_name, \",\".join(columns), placeholders)\n\n  #c.execute(\"BEGIN TRANSACTION;\")\n  for row in reader:\n    if row:\n      if len(row) < len(columns):\n        row.extend([None] * (len(columns) - len(row)))\n      c.execute(insert_values, row)\n  #c.execute(\"END TRANSACTION;\")\n  conn.commit()", "response": "Import lines from f as new table in db with cursor c."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef PrintColumns(shapefile):\n  ds = ogr.Open(shapefile)\n  layer = ds.GetLayer(0)\n  if len(layer) == 0:\n    raise ShapeImporterError(\"Layer 0 has no elements!\")\n\n  feature = layer.GetFeature(0)\n  print(\"%d features\" % feature.GetFieldCount())\n  for j in range(0, feature.GetFieldCount()):\n    print('--' + feature.GetFieldDefnRef(j).GetName() + \\\n          ': ' + feature.GetFieldAsString(j))", "response": "Print the columns of the shapefile to the screen."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef AddShapefile(shapefile, graph, key_cols):\n  ds = ogr.Open(shapefile)\n  layer = ds.GetLayer(0)\n\n  for i in range(0, len(layer)):\n    feature = layer.GetFeature(i)\n\n    geometry = feature.GetGeometryRef()\n\n    if key_cols:\n      key_list = []\n      for col in key_cols:\n        key_list.append(str(feature.GetField(col)))\n      shape_id = '-'.join(key_list)\n    else:\n      shape_id = '%s-%d' % (shapefile, i)\n\n    poly = shapelib.Poly(name=shape_id)\n    for j in range(0, geometry.GetPointCount()):\n      (lat, lng) = (round(geometry.GetY(j), 15), round(geometry.GetX(j), 15))\n      poly.AddPoint(shapelib.Point.FromLatLng(lat, lng))\n    graph.AddPoly(poly)\n\n  return graph", "response": "Adds shapes found in the given shape filename to the given polyline\n graph object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntrying to find a matching shape for a given pattern Poly object and trip.", "response": "def GetMatchingShape(pattern_poly, trip, matches, max_distance, verbosity=0):\n  \"\"\"\n  Tries to find a matching shape for the given pattern Poly object,\n  trip, and set of possibly matching Polys from which to choose a match.\n  \"\"\"\n  if len(matches) == 0:\n    print ('No matching shape found within max-distance %d for trip %s '\n           % (max_distance, trip.trip_id))\n    return None\n\n  if verbosity >= 1:\n    for match in matches:\n      print(\"match: size %d\" % match.GetNumPoints())\n  scores = [(pattern_poly.GreedyPolyMatchDist(match), match)\n            for match in matches]\n\n  scores.sort()\n\n  if scores[0][0] > max_distance:\n    print ('No matching shape found within max-distance %d for trip %s '\n           '(min score was %f)'\n           % (max_distance, trip.trip_id, scores[0][0]))\n    return None\n\n  return scores[0][1]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef AddExtraShapes(extra_shapes_txt, graph):\n\n  print(\"Adding extra shapes from %s\" % extra_shapes_txt)\n  try:\n    tmpdir = tempfile.mkdtemp()\n    shutil.copy(extra_shapes_txt, os.path.join(tmpdir, 'shapes.txt'))\n    loader = transitfeed.ShapeLoader(tmpdir)\n    schedule = loader.Load()\n    for shape in schedule.GetShapeList():\n      print(\"Adding extra shape: %s\" % shape.shape_id)\n      graph.AddPoly(ShapeToPoly(shape))\n  finally:\n    if tmpdir:\n      shutil.rmtree(tmpdir)", "response": "Adds extra shapes into a graph."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ApproximateDistanceBetweenPoints(pa, pb):\n  alat, alon = pa\n  blat, blon = pb\n  sa = transitfeed.Stop(lat=alat, lng=alon)\n  sb = transitfeed.Stop(lat=blat, lng=blon)\n  return transitfeed.ApproximateDistanceBetweenStops(sa, sb)", "response": "Finds the approximate distance between two points on the Earth s surface."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef LoadWithoutErrors(path, memory_db):\n  accumulator = transitfeed.ExceptionProblemAccumulator()\n  loading_problem_handler = MergeProblemReporter(accumulator)\n  try:\n    schedule = transitfeed.Loader(path,\n                                  memory_db=memory_db,\n                                  problems=loading_problem_handler,\n                                  extra_validation=True).Load()\n  except transitfeed.ExceptionWithContext as e:\n    print((\n        \"\\n\\nFeeds to merge must load without any errors.\\n\"\n        \"While loading %s the following error was found:\\n%s\\n%s\\n\" %\n        (path, e.FormatContext(), transitfeed.EncodeUnicode(e.FormatProblem()))), file=sys.stderr)\n    sys.exit(1)\n  return schedule", "response": "Return a Schedule object loaded from path ; sys. exit for any error."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef main():\n  usage = \\\n\"\"\"%prog [options] <input GTFS a.zip> <input GTFS b.zip> <output GTFS.zip>\n\nMerges <input GTFS a.zip> and <input GTFS b.zip> into a new GTFS file\n<output GTFS.zip>.\n\nFor more information see\nhttps://github.com/google/transitfeed/wiki/Merge\n\"\"\"\n\n  parser = util.OptionParserLongError(\n      usage=usage, version='%prog '+transitfeed.__version__)\n  parser.add_option('--cutoff_date',\n                    dest='cutoff_date',\n                    default=None,\n                    help='a transition date from the old feed to the new '\n                    'feed in the format YYYYMMDD')\n  parser.add_option('--largest_stop_distance',\n                    dest='largest_stop_distance',\n                    default=StopMerger.largest_stop_distance,\n                    help='the furthest distance two stops can be apart and '\n                    'still be merged, in metres')\n  parser.add_option('--largest_shape_distance',\n                    dest='largest_shape_distance',\n                    default=ShapeMerger.largest_shape_distance,\n                    help='the furthest distance the endpoints of two shapes '\n                    'can be apart and the shape still be merged, in metres')\n  parser.add_option('--html_output_path',\n                    dest='html_output_path',\n                    default='merge-results.html',\n                    help='write the html output to this file')\n  parser.add_option('--no_browser',\n                    dest='no_browser',\n                    action='store_true',\n                    help='prevents the merge results from being opened in a '\n                    'browser')\n  parser.add_option('--latest_version', dest='latest_version',\n                    action='store',\n                    help='a version number such as 1.2.1 or None to get the '\n                    'latest version from the project page. Output a warning if '\n                    'merge.py is older than this version.')\n  parser.add_option('-m', '--memory_db', dest='memory_db',  action='store_true',\n                    help='Use in-memory sqlite db instead of a temporary file. '\n                         'It is faster but uses more RAM.')\n  parser.set_defaults(memory_db=False)\n  (options, args) = parser.parse_args()\n\n  if len(args) != 3:\n    parser.error('You did not provide all required command line arguments.')\n\n  old_feed_path = os.path.abspath(args[0])\n  new_feed_path = os.path.abspath(args[1])\n  merged_feed_path = os.path.abspath(args[2])\n\n  if old_feed_path.find(\"IWantMyCrash\") != -1:\n    # See tests/testmerge.py\n    raise Exception('For testing the merge crash handler.')\n\n  a_schedule = LoadWithoutErrors(old_feed_path, options.memory_db)\n  b_schedule = LoadWithoutErrors(new_feed_path, options.memory_db)\n  merged_schedule = transitfeed.Schedule(memory_db=options.memory_db)\n  accumulator = HTMLProblemAccumulator()\n  problem_reporter = MergeProblemReporter(accumulator)\n\n  util.CheckVersion(problem_reporter, options.latest_version)\n\n  feed_merger = FeedMerger(a_schedule, b_schedule, merged_schedule,\n                           problem_reporter)\n  feed_merger.AddDefaultMergers()\n\n  feed_merger.GetMerger(StopMerger).SetLargestStopDistance(float(\n      options.largest_stop_distance))\n  feed_merger.GetMerger(ShapeMerger).SetLargestShapeDistance(float(\n      options.largest_shape_distance))\n\n  if options.cutoff_date is not None:\n    service_period_merger = feed_merger.GetMerger(ServicePeriodMerger)\n    service_period_merger.DisjoinCalendars(options.cutoff_date)\n\n  if feed_merger.MergeSchedules():\n    feed_merger.GetMergedSchedule().WriteGoogleTransitFeed(merged_feed_path)\n  else:\n    merged_feed_path = None\n\n  output_file = file(options.html_output_path, 'w')\n  accumulator.WriteOutput(output_file, feed_merger,\n                          old_feed_path, new_feed_path, merged_feed_path)\n  output_file.close()\n\n  if not options.no_browser:\n    webbrowser.open('file://%s' % os.path.abspath(options.html_output_path))", "response": "Run the merge driver."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate an HTML table of merge statistics.", "response": "def _GenerateStatsTable(self, feed_merger):\n    \"\"\"Generate an HTML table of merge statistics.\n\n    Args:\n      feed_merger: The FeedMerger instance.\n\n    Returns:\n      The generated HTML as a string.\n    \"\"\"\n    rows = []\n    rows.append('<tr><th class=\"header\"/><th class=\"header\">Merged</th>'\n                '<th class=\"header\">Copied from old feed</th>'\n                '<th class=\"header\">Copied from new feed</th></tr>')\n    for merger in feed_merger.GetMergerList():\n      stats = merger.GetMergeStats()\n      if stats is None:\n        continue\n      merged, not_merged_a, not_merged_b = stats\n      rows.append('<tr><th class=\"header\">%s</th>'\n                  '<td class=\"header\">%d</td>'\n                  '<td class=\"header\">%d</td>'\n                  '<td class=\"header\">%d</td></tr>' %\n                  (merger.DATASET_NAME, merged, not_merged_a, not_merged_b))\n    return '<table>%s</table>' % '\\n'.join(rows)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _GenerateSection(self, problem_type):\n    if problem_type == transitfeed.TYPE_WARNING:\n      dataset_problems = self._dataset_warnings\n      heading = 'Warnings'\n    else:\n      dataset_problems = self._dataset_errors\n      heading = 'Errors'\n\n    if not dataset_problems:\n      return ''\n\n    prefix = '<h2 class=\"issueHeader\">%s:</h2>' % heading\n    dataset_sections = []\n    for dataset_merger, problems in dataset_problems.items():\n      dataset_sections.append('<h3>%s</h3><ol>%s</ol>' % (\n          dataset_merger.FILE_NAME, '\\n'.join(problems)))\n    body = '\\n'.join(dataset_sections)\n    return prefix + body", "response": "Generates an HTML section of the given type of problems."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating a summary of the warnings and errors.", "response": "def _GenerateSummary(self):\n    \"\"\"Generate a summary of the warnings and errors.\n\n    Returns:\n      The generated HTML as a string.\n    \"\"\"\n    items = []\n    if self._notices:\n      items.append('notices: %d' % self._notice_count)\n    if self._dataset_errors:\n      items.append('errors: %d' % self._error_count)\n    if self._dataset_warnings:\n      items.append('warnings: %d' % self._warning_count)\n\n    if items:\n      return '<p><span class=\"fail\">%s</span></p>' % '<br>'.join(items)\n    else:\n      return '<p><span class=\"pass\">feeds merged successfully</span></p>'"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _GenerateNotices(self):\n    items = []\n    for e in self._notices:\n      d = e.GetDictToFormat()\n      if 'url' in d.keys():\n        d['url'] = '<a href=\"%(url)s\">%(url)s</a>' % d\n      items.append('<li class=\"notice\">%s</li>' %\n                   e.FormatProblem(d).replace('\\n', '<br>'))\n    if items:\n      return '<h2>Notices:</h2>\\n<ul>%s</ul>\\n' % '\\n'.join(items)\n    else:\n      return ''", "response": "Generate a summary of any notices."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrite the feed merged output to a file.", "response": "def WriteOutput(self, output_file, feed_merger,\n                  old_feed_path, new_feed_path, merged_feed_path):\n    \"\"\"Write the HTML output to a file.\n\n    Args:\n      output_file: The file object that the HTML output will be written to.\n      feed_merger: The FeedMerger instance.\n      old_feed_path: The path to the old feed file as a string.\n      new_feed_path: The path to the new feed file as a string\n      merged_feed_path: The path to the merged feed file as a string. This\n                        may be None if no merged feed was written.\n    \"\"\"\n    if merged_feed_path is None:\n      html_merged_feed_path = ''\n    else:\n      html_merged_feed_path = '<p>Merged feed created: <code>%s</code></p>' % (\n          merged_feed_path)\n\n    html_header = \"\"\"<html>\n<head>\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\"/>\n<title>Feed Merger Results</title>\n<style>\n  body {font-family: Georgia, serif; background-color: white}\n  .path {color: gray}\n  div.problem {max-width: 500px}\n  td,th {background-color: khaki; padding: 2px; font-family:monospace}\n  td.problem,th.problem {background-color: dc143c; color: white; padding: 2px;\n                         font-family:monospace}\n  table {border-spacing: 5px 0px; margin-top: 3px}\n  h3.issueHeader {padding-left: 1em}\n  .notice {background-color: yellow}\n  span.pass {background-color: lightgreen}\n  span.fail {background-color: yellow}\n  .pass, .fail {font-size: 16pt; padding: 3px}\n  ol,.unused {padding-left: 40pt}\n  .header {background-color: white; font-family: Georgia, serif; padding: 0px}\n  th.header {text-align: right; font-weight: normal; color: gray}\n  .footer {font-size: 10pt}\n</style>\n</head>\n<body>\n<h1>Feed merger results</h1>\n<p>Old feed: <code>%(old_feed_path)s</code></p>\n<p>New feed: <code>%(new_feed_path)s</code></p>\n%(html_merged_feed_path)s\"\"\" % locals()\n\n    html_stats = self._GenerateStatsTable(feed_merger)\n    html_summary = self._GenerateSummary()\n    html_notices = self._GenerateNotices()\n    html_errors = self._GenerateSection(transitfeed.TYPE_ERROR)\n    html_warnings = self._GenerateSection(transitfeed.TYPE_WARNING)\n\n    html_footer = \"\"\"\n<div class=\"footer\">\nGenerated using transitfeed version %s on %s.\n</div>\n</body>\n</html>\"\"\" % (transitfeed.__version__,\n              time.strftime('%B %d, %Y at %I:%M %p %Z'))\n\n    output_file.write(transitfeed.EncodeUnicode(html_header))\n    output_file.write(transitfeed.EncodeUnicode(html_stats))\n    output_file.write(transitfeed.EncodeUnicode(html_summary))\n    output_file.write(transitfeed.EncodeUnicode(html_notices))\n    output_file.write(transitfeed.EncodeUnicode(html_errors))\n    output_file.write(transitfeed.EncodeUnicode(html_warnings))\n    output_file.write(transitfeed.EncodeUnicode(html_footer))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntrying to merge two values.", "response": "def _MergeIdentical(self, a, b):\n    \"\"\"Tries to merge two values. The values are required to be identical.\n\n    Args:\n      a: The first value.\n      b: The second value.\n\n    Returns:\n      The trivially merged value.\n\n    Raises:\n      MergeError: The values were not identical.\n    \"\"\"\n    if a != b:\n      raise MergeError(\"values must be identical ('%s' vs '%s')\" %\n                       (transitfeed.EncodeUnicode(a),\n                        transitfeed.EncodeUnicode(b)))\n    return b"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _MergeIdenticalCaseInsensitive(self, a, b):\n    if a.lower() != b.lower():\n      raise MergeError(\"values must be the same (case insensitive) \"\n                       \"('%s' vs '%s')\" % (transitfeed.EncodeUnicode(a),\n                                           transitfeed.EncodeUnicode(b)))\n    return b", "response": "Tries to merge two strings."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _MergeOptional(self, a, b):\n    if a and b:\n      if a != b:\n        raise MergeError(\"values must be identical if both specified \"\n                         \"('%s' vs '%s')\" % (transitfeed.EncodeUnicode(a),\n                                             transitfeed.EncodeUnicode(b)))\n    return a or b", "response": "Tries to merge two values which may be None."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmerge the agency ids to the corresponding agency id in the merged agency.", "response": "def _MergeSameAgency(self, a_agency_id, b_agency_id):\n    \"\"\"Merge agency ids to the corresponding agency id in the merged schedule.\n\n    Args:\n      a_agency_id: an agency id from the old schedule\n      b_agency_id: an agency id from the new schedule\n\n    Returns:\n      The agency id of the corresponding merged agency.\n\n    Raises:\n      MergeError: If a_agency_id and b_agency_id do not correspond to the same\n                  merged agency.\n      KeyError: Either aaid or baid is not a valid agency id.\n    \"\"\"\n    a_agency_id = (a_agency_id or\n                   self.feed_merger.a_schedule.GetDefaultAgency().agency_id)\n    b_agency_id = (b_agency_id or\n                   self.feed_merger.b_schedule.GetDefaultAgency().agency_id)\n    a_agency = self.feed_merger.a_schedule.GetAgency(\n        a_agency_id)._migrated_entity\n    b_agency = self.feed_merger.b_schedule.GetAgency(\n        b_agency_id)._migrated_entity\n    if a_agency != b_agency:\n      raise MergeError('agency must be the same')\n    return a_agency.agency_id"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _SchemedMerge(self, scheme, a, b):\n    migrated = self._Migrate(b, self.feed_merger.b_schedule, False)\n    for attr, merger in scheme.items():\n      a_attr = getattr(a, attr, None)\n      b_attr = getattr(b, attr, None)\n      try:\n        merged_attr = merger(a_attr, b_attr)\n      except MergeError as merge_error:\n        raise MergeError(\"Attribute '%s' could not be merged: %s.\" % (\n            attr, merge_error))\n      setattr(migrated, attr, merged_attr)\n    return migrated", "response": "Tries to merge two entities according to a merge scheme."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntry to merge entities based on their ids.", "response": "def _MergeSameId(self):\n    \"\"\"Tries to merge entities based on their ids.\n\n    This tries to merge only the entities from the old and new schedules which\n    have the same id. These are added into the merged schedule. Entities which\n    do not merge or do not have the same id as another entity in the other\n    schedule are simply migrated into the merged schedule.\n\n    This method is less flexible than _MergeDifferentId since it only tries\n    to merge entities which have the same id while _MergeDifferentId tries to\n    merge everything. However, it is faster and so should be used whenever\n    possible.\n\n    This method makes use of various methods like _Merge and _Migrate which\n    are not implemented in the abstract DataSetMerger class. These method\n    should be overwritten in a subclass to allow _MergeSameId to work with\n    different entity types.\n\n    Returns:\n      The number of merged entities.\n    \"\"\"\n    a_not_merged = []\n    b_not_merged = []\n\n    for a in self._GetIter(self.feed_merger.a_schedule):\n      try:\n        b = self._GetById(self.feed_merger.b_schedule, self._GetId(a))\n      except KeyError:\n        # there was no entity in B with the same id as a\n        a_not_merged.append(a)\n        continue\n      try:\n        self._Add(a, b, self._MergeEntities(a, b))\n        self._num_merged += 1\n      except MergeError as merge_error:\n        a_not_merged.append(a)\n        b_not_merged.append(b)\n        self._ReportSameIdButNotMerged(self._GetId(a), merge_error)\n\n    for b in self._GetIter(self.feed_merger.b_schedule):\n      try:\n        a = self._GetById(self.feed_merger.a_schedule, self._GetId(b))\n      except KeyError:\n        # there was no entity in A with the same id as b\n        b_not_merged.append(b)\n\n    # migrate the remaining entities\n    for a in a_not_merged:\n      newid = self._HasId(self.feed_merger.b_schedule, self._GetId(a))\n      self._Add(a, None, self._Migrate(a, self.feed_merger.a_schedule, newid))\n    for b in b_not_merged:\n      newid = self._HasId(self.feed_merger.a_schedule, self._GetId(b))\n      self._Add(None, b, self._Migrate(b, self.feed_merger.b_schedule, newid))\n\n    self._num_not_merged_a = len(a_not_merged)\n    self._num_not_merged_b = len(b_not_merged)\n    return self._num_merged"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _MergeByIdKeepNew(self):\n    # Maps from migrated ID to tuple(original object, migrated object)\n    a_orig_migrated = {}\n    b_orig_migrated = {}\n\n    for orig in self._GetIter(self.feed_merger.a_schedule):\n      migrated = self._Migrate(orig, self.feed_merger.a_schedule)\n      a_orig_migrated[self._GetId(migrated)] = (orig, migrated)\n\n    for orig in self._GetIter(self.feed_merger.b_schedule):\n      migrated = self._Migrate(orig, self.feed_merger.b_schedule)\n      b_orig_migrated[self._GetId(migrated)] = (orig, migrated)\n\n    for migrated_id, (orig, migrated) in b_orig_migrated.items():\n      self._Add(None, orig, migrated)\n      self._num_not_merged_b += 1\n\n    for migrated_id, (orig, migrated) in a_orig_migrated.items():\n      if migrated_id not in b_orig_migrated:\n        self._Add(orig, None, migrated)\n        self._num_not_merged_a += 1\n    return self._num_merged", "response": "Migrate all entities discarding duplicates from the old schedule and the new schedule."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _MergeDifferentId(self):\n    # TODO: The same entity from A could merge with multiple from B.\n    # This should either generate an error or should be prevented from\n    # happening.\n    for a in self._GetIter(self.feed_merger.a_schedule):\n      for b in self._GetIter(self.feed_merger.b_schedule):\n        try:\n          self._Add(a, b, self._MergeEntities(a, b))\n          self._num_merged += 1\n        except MergeError:\n          continue\n\n    for a in self._GetIter(self.feed_merger.a_schedule):\n      if a not in self.feed_merger.a_merge_map:\n        self._num_not_merged_a += 1\n        newid = self._HasId(self.feed_merger.b_schedule, self._GetId(a))\n        self._Add(a, None,\n                  self._Migrate(a, self.feed_merger.a_schedule, newid))\n    for b in self._GetIter(self.feed_merger.b_schedule):\n      if b not in self.feed_merger.b_merge_map:\n        self._num_not_merged_b += 1\n        newid = self._HasId(self.feed_merger.a_schedule, self._GetId(b))\n        self._Add(None, b,\n                  self._Migrate(b, self.feed_merger.b_schedule, newid))\n\n    return self._num_merged", "response": "Tries to merge all possible combinations of entities with the same id."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreporting that two entities have the same id but could not be merged.", "response": "def _ReportSameIdButNotMerged(self, entity_id, reason):\n    \"\"\"Report that two entities have the same id but could not be merged.\n\n    Args:\n      entity_id: The id of the entities.\n      reason: A string giving a reason why they could not be merged.\n    \"\"\"\n    self.feed_merger.problem_reporter.SameIdButNotMerged(self,\n                                                         entity_id,\n                                                         reason)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks if the schedule has an entity with the given id.", "response": "def _HasId(self, schedule, entity_id):\n    \"\"\"Check if the schedule has an entity with the given id.\n\n    Args:\n      schedule: The transitfeed.Schedule instance to look in.\n      entity_id: The id of the entity.\n\n    Returns:\n      True if the schedule has an entity with the id or False if not.\n    \"\"\"\n    try:\n      self._GetById(schedule, entity_id)\n      has = True\n    except KeyError:\n      has = False\n    return has"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmerge two agencies. To be merged, they are required to have the same id, name, url and timezone. The remaining language attribute is taken from the new agency. Args: a: The first agency. b: The second agency. Returns: The merged agency. Raises: MergeError: The agencies could not be merged.", "response": "def _MergeEntities(self, a, b):\n    \"\"\"Merges two agencies.\n\n    To be merged, they are required to have the same id, name, url and\n    timezone. The remaining language attribute is taken from the new agency.\n\n    Args:\n      a: The first agency.\n      b: The second agency.\n\n    Returns:\n      The merged agency.\n\n    Raises:\n      MergeError: The agencies could not be merged.\n    \"\"\"\n\n    def _MergeAgencyId(a_agency_id, b_agency_id):\n      \"\"\"Merge two agency ids.\n\n      The only difference between this and _MergeIdentical() is that the values\n      None and '' are regarded as being the same.\n\n      Args:\n        a_agency_id: The first agency id.\n        b_agency_id: The second agency id.\n\n      Returns:\n        The merged agency id.\n\n      Raises:\n        MergeError: The agency ids could not be merged.\n      \"\"\"\n      a_agency_id = a_agency_id or None\n      b_agency_id = b_agency_id or None\n      return self._MergeIdentical(a_agency_id, b_agency_id)\n\n    scheme = {'agency_id': _MergeAgencyId,\n              'agency_name': self._MergeIdentical,\n              'agency_url': self._MergeIdentical,\n              'agency_timezone': self._MergeIdentical}\n    return self._SchemedMerge(scheme, a, b)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmerging two stops. For the stops to be merged, they must have: - the same stop_id - the same stop_name (case insensitive) - the same zone_id - locations less than largest_stop_distance apart The other attributes can have arbitary changes. The merged attributes are taken from the new stop. Args: a: The first stop. b: The second stop. Returns: The merged stop. Raises: MergeError: The stops could not be merged.", "response": "def _MergeEntities(self, a, b):\n    \"\"\"Merges two stops.\n\n    For the stops to be merged, they must have:\n      - the same stop_id\n      - the same stop_name (case insensitive)\n      - the same zone_id\n      - locations less than largest_stop_distance apart\n    The other attributes can have arbitary changes. The merged attributes are\n    taken from the new stop.\n\n    Args:\n      a: The first stop.\n      b: The second stop.\n\n    Returns:\n      The merged stop.\n\n    Raises:\n      MergeError: The stops could not be merged.\n    \"\"\"\n    distance = transitfeed.ApproximateDistanceBetweenStops(a, b)\n    if distance > self.largest_stop_distance:\n      raise MergeError(\"Stops are too far apart: %.1fm \"\n                       \"(largest_stop_distance is %.1fm).\" %\n                       (distance, self.largest_stop_distance))\n    scheme = {'stop_id': self._MergeIdentical,\n              'stop_name': self._MergeIdenticalCaseInsensitive,\n              'zone_id': self._MergeIdentical,\n              'location_type': self._MergeIdentical}\n    return self._SchemedMerge(scheme, a, b)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates the merged_schedule with the unmerged stops.", "response": "def _UpdateAndMigrateUnmerged(self, not_merged_stops, zone_map, merge_map,\n                                schedule):\n    \"\"\"Correct references in migrated unmerged stops and add to merged_schedule.\n\n    For stops migrated from one of the input feeds to the output feed update the\n    parent_station and zone_id references to point to objects in the output\n    feed. Then add the migrated stop to the new schedule.\n\n    Args:\n      not_merged_stops: list of stops from one input feed that have not been\n        merged\n      zone_map: map from zone_id in the input feed to zone_id in the output feed\n      merge_map: map from Stop objects in the input feed to Stop objects in\n        the output feed\n      schedule: the input Schedule object\n    \"\"\"\n    # for the unmerged stops, we use an already mapped zone_id if possible\n    # if not, we generate a new one and add it to the map\n    for stop, migrated_stop in not_merged_stops:\n      if stop.zone_id in zone_map:\n        migrated_stop.zone_id = zone_map[stop.zone_id]\n      else:\n        migrated_stop.zone_id = self.feed_merger.GenerateId(stop.zone_id)\n        zone_map[stop.zone_id] = migrated_stop.zone_id\n      if stop.parent_station:\n        parent_original = schedule.GetStop(stop.parent_station)\n        migrated_stop.parent_station = merge_map[parent_original].stop_id\n      self.feed_merger.merged_schedule.AddStopObject(migrated_stop)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef DisjoinCalendars(self, cutoff):\n\n    def TruncatePeriod(service_period, start, end):\n      \"\"\"Truncate the service period to into the range [start, end].\n\n      Args:\n        service_period: The service period to truncate.\n        start: The start date as a string in YYYYMMDD format.\n        end: The end date as a string in YYYYMMDD format.\n      \"\"\"\n      service_period.start_date = max(service_period.start_date, start)\n      service_period.end_date = min(service_period.end_date, end)\n      dates_to_delete = []\n      for k in service_period.date_exceptions:\n        if (k < start) or (k > end):\n          dates_to_delete.append(k)\n      for k in dates_to_delete:\n        del service_period.date_exceptions[k]\n\n    # find the date one day before cutoff\n    year = int(cutoff[:4])\n    month = int(cutoff[4:6])\n    day = int(cutoff[6:8])\n    cutoff_date = datetime.date(year, month, day)\n    one_day_delta = datetime.timedelta(days=1)\n    before = (cutoff_date - one_day_delta).strftime('%Y%m%d')\n\n    for a in self.feed_merger.a_schedule.GetServicePeriodList():\n      TruncatePeriod(a, 0, before)\n    for b in self.feed_merger.b_schedule.GetServicePeriodList():\n      TruncatePeriod(b, cutoff, '9'*8)", "response": "Disjoins old and new calendars to a given cutoff date."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking whether any old service periods intersect with any new ones.", "response": "def CheckDisjointCalendars(self):\n    \"\"\"Check whether any old service periods intersect with any new ones.\n\n    This is a rather coarse check based on\n    transitfeed.SevicePeriod.GetDateRange.\n\n    Returns:\n      True if the calendars are disjoint or False if not.\n    \"\"\"\n    # TODO: Do an exact check here.\n\n    a_service_periods = self.feed_merger.a_schedule.GetServicePeriodList()\n    b_service_periods = self.feed_merger.b_schedule.GetServicePeriodList()\n\n    for a_service_period in a_service_periods:\n      a_start, a_end = a_service_period.GetDateRange()\n      for b_service_period in b_service_periods:\n        b_start, b_end = b_service_period.GetDateRange()\n        overlap_start = max(a_start, b_start)\n        overlap_end = min(a_end, b_end)\n        if overlap_end >= overlap_start:\n          return False\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmerging the fares if all the attributes are the same.", "response": "def _MergeEntities(self, a, b):\n    \"\"\"Merges the fares if all the attributes are the same.\"\"\"\n    scheme = {'price': self._MergeIdentical,\n              'currency_type': self._MergeIdentical,\n              'payment_method': self._MergeIdentical,\n              'transfers': self._MergeIdentical,\n              'transfer_duration': self._MergeIdentical}\n    return self._SchemedMerge(scheme, a, b)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _MergeEntities(self, a, b):\n    if a.shape_id != b.shape_id:\n      raise MergeError('shape_id must be the same')\n\n    distance = max(ApproximateDistanceBetweenPoints(a.points[0][:2],\n                                                    b.points[0][:2]),\n                   ApproximateDistanceBetweenPoints(a.points[-1][:2],\n                                                    b.points[-1][:2]))\n    if distance > self.largest_shape_distance:\n      raise MergeError('The shape endpoints are too far away: %.1fm '\n                       '(largest_shape_distance is %.1fm)' %\n                       (distance, self.largest_shape_distance))\n\n    return self._Migrate(b, self.feed_merger.b_schedule, False)", "response": "Merges two shapes by taking the new shape."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmerging the fare rule datasets into one fare rule dataset.", "response": "def MergeDataSets(self):\n    \"\"\"Merge the fare rule datasets.\n\n    The fare rules are first migrated. Merging is done by removing any\n    duplicate rules.\n\n    Returns:\n      True since fare rules can always be merged.\n    \"\"\"\n    rules = set()\n    for (schedule, merge_map, zone_map) in ([self.feed_merger.a_schedule,\n                                             self.feed_merger.a_merge_map,\n                                             self.feed_merger.a_zone_map],\n                                            [self.feed_merger.b_schedule,\n                                             self.feed_merger.b_merge_map,\n                                             self.feed_merger.b_zone_map]):\n      for fare in schedule.GetFareAttributeList():\n        for fare_rule in fare.GetFareRuleList():\n          fare_id = merge_map[\n              schedule.GetFareAttribute(fare_rule.fare_id)].fare_id\n          route_id = (fare_rule.route_id and\n                      merge_map[schedule.GetRoute(fare_rule.route_id)].route_id)\n          origin_id = (fare_rule.origin_id and\n                       zone_map[fare_rule.origin_id])\n          destination_id = (fare_rule.destination_id and\n                            zone_map[fare_rule.destination_id])\n          contains_id = (fare_rule.contains_id and\n                         zone_map[fare_rule.contains_id])\n          rules.add((fare_id, route_id, origin_id, destination_id,\n                     contains_id))\n    for fare_rule_tuple in rules:\n      migrated_fare_rule = transitfeed.FareRule(*fare_rule_tuple)\n      self.feed_merger.merged_schedule.AddFareRuleObject(migrated_fare_rule)\n\n    if rules:\n      self.feed_merger.problem_reporter.FareRulesBroken(self)\n    print('Fare Rules: union has %d fare rules' % len(rules))\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _FindLargestIdPostfixNumber(self, schedule):\n    postfix_number_re = re.compile('(\\d+)$')\n\n    def ExtractPostfixNumber(entity_id):\n      \"\"\"Try to extract an integer from the end of entity_id.\n\n      If entity_id is None or if there is no integer ending the id, zero is\n      returned.\n\n      Args:\n        entity_id: An id string or None.\n\n      Returns:\n        An integer ending the entity_id or zero.\n      \"\"\"\n      if entity_id is None:\n        return 0\n      match = postfix_number_re.search(entity_id)\n      if match is not None:\n        return int(match.group(1))\n      else:\n        return 0\n\n    id_data_sets = {'agency_id': schedule.GetAgencyList(),\n                    'stop_id': schedule.GetStopList(),\n                    'route_id': schedule.GetRouteList(),\n                    'trip_id': schedule.GetTripList(),\n                    'service_id': schedule.GetServicePeriodList(),\n                    'fare_id': schedule.GetFareAttributeList(),\n                    'shape_id': schedule.GetShapeList()}\n\n    max_postfix_number = 0\n    for id_name, entity_list in id_data_sets.items():\n      for entity in entity_list:\n        entity_id = getattr(entity, id_name)\n        postfix_number = ExtractPostfixNumber(entity_id)\n        max_postfix_number = max(max_postfix_number, postfix_number)\n    return max_postfix_number", "response": "Finds the largest integer used as an ending of an id in the schedule."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates a unique id based on the given id.", "response": "def GenerateId(self, entity_id=None):\n    \"\"\"Generate a unique id based on the given id.\n\n    This is done by appending a counter which is then incremented. The\n    counter is initialised at the maximum number used as an ending for\n    any id in the old and new schedules.\n\n    Args:\n      entity_id: The base id string. This is allowed to be None.\n\n    Returns:\n      The generated id.\n    \"\"\"\n    self._idnum += 1\n    if entity_id:\n      return '%s_merged_%d' % (entity_id, self._idnum)\n    else:\n      return 'merged_%d' % self._idnum"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef Register(self, a, b, migrated_entity):\n    # There are a few places where code needs to find the corresponding\n    # migrated entity of an object without knowing in which original schedule\n    # the entity started. With a_merge_map and b_merge_map both have to be\n    # checked. Use of the _migrated_entity attribute allows the migrated entity\n    # to be directly found without the schedule.  The merge maps also require\n    # that all objects be hashable. GenericGTFSObject is at the moment, but\n    # this is a bug. See comment in transitfeed.GenericGTFSObject.\n    if a is not None:\n      self.a_merge_map[a] = migrated_entity\n      a._migrated_entity = migrated_entity\n    if b is not None:\n      self.b_merge_map[b] = migrated_entity\n      b._migrated_entity = migrated_entity", "response": "Registers a merge mapping."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef AddDefaultMergers(self):\n    self.AddMerger(AgencyMerger(self))\n    self.AddMerger(StopMerger(self))\n    self.AddMerger(RouteMerger(self))\n    self.AddMerger(ServicePeriodMerger(self))\n    self.AddMerger(FareMerger(self))\n    self.AddMerger(ShapeMerger(self))\n    self.AddMerger(TripMerger(self))\n    self.AddMerger(FareRuleMerger(self))", "response": "Adds the default DataSetMergers defined in this module."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlook for an added DataSetMerger derived from the given class.", "response": "def GetMerger(self, cls):\n    \"\"\"Looks for an added DataSetMerger derived from the given class.\n\n    Args:\n      cls: A class derived from DataSetMerger.\n\n    Returns:\n      The matching DataSetMerger instance.\n\n    Raises:\n      LookupError: No matching DataSetMerger has been added.\n    \"\"\"\n    for merger in self._mergers:\n      if isinstance(merger, cls):\n        return merger\n    raise LookupError('No matching DataSetMerger found')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef filter_line(self, route):\n    if self._route_type is not None and self._route_type != route.route_type:\n      self.info('Skipping route %s due to different route_type value (%s)' %\n                (route['route_id'], route['route_type']))\n      return\n    self.info('Filtering infrequent trips for route %s.' % route.route_id)\n    trip_count = len(route.trips)\n    for pattern_id, pattern in route.GetPatternIdTripDict().items():\n      ratio = float(1.0 * len(pattern) / trip_count)\n      if not self._force:\n        if (ratio < self._threshold):\n          self.info(\"\\t%d trips on route %s with headsign '%s' recognized \"\n                    \"as unusual (ratio %f)\" %\n                    (len(pattern),\n                    route['route_short_name'],\n                    pattern[0]['trip_headsign'],\n                    ratio))\n          for trip in pattern:\n            trip.trip_type = 1 # special\n            self.info(\"\\t\\tsetting trip_type of trip %s as special\" %\n                      trip.trip_id)\n      else:\n        self.info(\"\\t%d trips on route %s with headsign '%s' recognized \"\n                  \"as %s (ratio %f)\" %\n                  (len(pattern),\n                   route['route_short_name'],\n                   pattern[0]['trip_headsign'],\n                   ('regular', 'unusual')[ratio < self._threshold],\n                   ratio))\n        for trip in pattern:\n          trip.trip_type = ('0','1')[ratio < self._threshold]\n          self.info(\"\\t\\tsetting trip_type of trip %s as %s\" %\n                    (trip.trip_id,\n                     ('regular', 'unusual')[ratio < self._threshold]))", "response": "Filter out trips that are not unusual."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmarks unusual trips for all the routes in the dataset.", "response": "def filter(self, dataset):\n    \"\"\"Mark unusual trips for all the routes in the dataset.\"\"\"\n    self.info('Going to filter infrequent routes in the dataset')\n    for route in dataset.routes.values():\n      self.filter_line(route)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef StopToTuple(stop):\n  return (stop.stop_id, stop.stop_name, float(stop.stop_lat),\n          float(stop.stop_lon), stop.location_type)", "response": "Return tuple as expected by javascript function addStopMarkerFromList"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef FindDefaultFileDir():\n  base = FindPy2ExeBase()\n  if base:\n    return os.path.join(base, 'schedule_viewer_files')\n  else:\n    # For all other distributions 'files' is in the gtfsscheduleviewer\n    # directory.\n    base = os.path.dirname(gtfsscheduleviewer.__file__)  # Strip __init__.py\n    return os.path.join(base, 'files')", "response": "Return the path of the directory containing the static files. By default\n is called files. By default\n is called files. By default\n is called schedule_viewer_files."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef OpenFile(self, filename):\n    (mime_type, encoding) = mimetypes.guess_type(filename)\n    assert mime_type\n    # A crude guess of when we should use binary mode. Without it non-unix\n    # platforms may corrupt binary files.\n    if mime_type.startswith('text/'):\n      mode = 'r'\n    else:\n      mode = 'rb'\n    return open(os.path.join(self.server.file_dir, filename), mode), mime_type", "response": "Try to open filename in the static files directory of this server."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngive a route_id generate a list of patterns of the route. For each pattern include some basic information and a few sample trips.", "response": "def handle_json_GET_routepatterns(self, params):\n    \"\"\"Given a route_id generate a list of patterns of the route. For each\n    pattern include some basic information and a few sample trips.\"\"\"\n    schedule = self.server.schedule\n    route = schedule.GetRoute(params.get('route', None))\n    if not route:\n      self.send_error(404)\n      return\n    time = int(params.get('time', 0))\n    date = params.get('date', \"\")\n    sample_size = 3  # For each pattern return the start time for this many trips\n\n    pattern_id_trip_dict = route.GetPatternIdTripDict()\n    patterns = []\n\n    for pattern_id, trips in pattern_id_trip_dict.items():\n      time_stops = trips[0].GetTimeStops()\n      if not time_stops:\n        continue\n      has_non_zero_trip_type = False;\n\n      # Iterating over a copy so we can remove from trips inside the loop\n      trips_with_service = []\n      for trip in trips:\n        service_id = trip.service_id\n        service_period = schedule.GetServicePeriod(service_id)\n\n        if date and not service_period.IsActiveOn(date):\n          continue\n        trips_with_service.append(trip)\n\n        if trip['trip_type'] and trip['trip_type'] != '0':\n          has_non_zero_trip_type = True\n\n      # We're only interested in the trips that do run on the specified date\n      trips = trips_with_service\n\n      name = u'%s to %s, %d stops' % (time_stops[0][2].stop_name, time_stops[-1][2].stop_name, len(time_stops))\n      transitfeed.SortListOfTripByTime(trips)\n\n      num_trips = len(trips)\n      if num_trips <= sample_size:\n        start_sample_index = 0\n        num_after_sample = 0\n      else:\n        # Will return sample_size trips that start after the 'time' param.\n\n        # Linear search because I couldn't find a built-in way to do a binary\n        # search with a custom key.\n        start_sample_index = len(trips)\n        for i, trip in enumerate(trips):\n          if trip.GetStartTime() >= time:\n            start_sample_index = i\n            break\n\n        num_after_sample = num_trips - (start_sample_index + sample_size)\n        if num_after_sample < 0:\n          # Less than sample_size trips start after 'time' so return all the\n          # last sample_size trips.\n          num_after_sample = 0\n          start_sample_index = num_trips - sample_size\n\n      sample = []\n      for t in trips[start_sample_index:start_sample_index + sample_size]:\n        sample.append( (t.GetStartTime(), t.trip_id) )\n\n      patterns.append((name, pattern_id, start_sample_index, sample,\n                       num_after_sample, (0,1)[has_non_zero_trip_type]))\n\n    patterns.sort()\n    return patterns"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalls handler and output the return value in JSON.", "response": "def handle_json_wrapper_GET(self, handler, parsed_params):\n    \"\"\"Call handler and output the return value in JSON.\"\"\"\n    schedule = self.server.schedule\n    result = handler(parsed_params)\n    content = ResultEncoder().encode(result)\n    self.send_response(200)\n    self.send_header('Content-Type', 'text/plain')\n    self.send_header('Content-Length', str(len(content)))\n    self.end_headers()\n    self.wfile.write(content)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef handle_json_GET_routes(self, params):\n    schedule = self.server.schedule\n    result = []\n    for r in schedule.GetRouteList():\n      result.append( (r.route_id, r.route_short_name, r.route_long_name) )\n    result.sort(key = lambda x: x[1:3])\n    return result", "response": "Return a list of all routes."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef handle_json_GET_triprows(self, params):\n    schedule = self.server.schedule\n    try:\n      trip = schedule.GetTrip(params.get('trip', None))\n    except KeyError:\n      # if a non-existent trip is searched for, the return nothing\n      return\n    route = schedule.GetRoute(trip.route_id)\n    trip_row = dict(trip.iteritems())\n    route_row = dict(route.iteritems())\n    return [['trips.txt', trip_row], ['routes.txt', route_row]]", "response": "Return a list of rows from the feed file that are related to this\n    trip."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of the nearest limit stops to lat lon", "response": "def handle_json_GET_neareststops(self, params):\n    \"\"\"Return a list of the nearest 'limit' stops to 'lat', 'lon'\"\"\"\n    schedule = self.server.schedule\n    lat = float(params.get('lat'))\n    lon = float(params.get('lon'))\n    limit = int(params.get('limit'))\n    stops = schedule.GetNearestStops(lat=lat, lon=lon, n=limit)\n    return [StopToTuple(s) for s in stops]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of up to limit stops within bounding box with n e s w in the NE and SW corners. Does not handle boxes crossing longitude line 180.", "response": "def handle_json_GET_boundboxstops(self, params):\n    \"\"\"Return a list of up to 'limit' stops within bounding box with 'n','e'\n    and 's','w' in the NE and SW corners. Does not handle boxes crossing\n    longitude line 180.\"\"\"\n    schedule = self.server.schedule\n    n = float(params.get('n'))\n    e = float(params.get('e'))\n    s = float(params.get('s'))\n    w = float(params.get('w'))\n    limit = int(params.get('limit'))\n    stops = schedule.GetStopsInBoundingBox(north=n, east=e, south=s, west=w, n=limit)\n    return [StopToTuple(s) for s in stops]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngive a stop_id and time in seconds since midnight return the next 2 departure trips to visit the stop.", "response": "def handle_json_GET_stoptrips(self, params):\n    \"\"\"Given a stop_id and time in seconds since midnight return the next\n    trips to visit the stop.\"\"\"\n    schedule = self.server.schedule\n    stop = schedule.GetStop(params.get('stop', None))\n    time = int(params.get('time', 0))\n    date = params.get('date', \"\")\n\n    time_trips = stop.GetStopTimeTrips(schedule)\n    time_trips.sort()  # OPT: use bisect.insort to make this O(N*ln(N)) -> O(N)\n    # Keep the first 5 after param 'time'.\n    # Need make a tuple to find correct bisect point\n    time_trips = time_trips[bisect.bisect_left(time_trips, (time, 0)):]\n    time_trips = time_trips[:5]\n    # TODO: combine times for a route to show next 2 departure times\n    result = []\n    for time, (trip, index), tp in time_trips:\n      service_id = trip.service_id\n      service_period = schedule.GetServicePeriod(service_id)\n      if date and not service_period.IsActiveOn(date):\n        continue\n      headsign = None\n      # Find the most recent headsign from the StopTime objects\n      for stoptime in trip.GetStopTimes()[index::-1]:\n        if stoptime.stop_headsign:\n          headsign = stoptime.stop_headsign\n          break\n      # If stop_headsign isn't found, look for a trip_headsign\n      if not headsign:\n        headsign = trip.trip_headsign\n      route = schedule.GetRoute(trip.route_id)\n      trip_name = ''\n      if route.route_short_name:\n        trip_name += route.route_short_name\n      if route.route_long_name:\n        if len(trip_name):\n          trip_name += \" - \"\n        trip_name += route.route_long_name\n      if headsign:\n        trip_name += \" (Direction: %s)\" % headsign\n\n      result.append((time, (trip.trip_id, trip_name, trip.service_id), tp))\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef handle_GET_ttablegraph(self,params):\n    schedule = self.server.schedule\n    marey = MareyGraph()\n    trip = schedule.GetTrip(params.get('trip', None))\n    route = schedule.GetRoute(trip.route_id)\n    height = int(params.get('height', 300))\n\n    if not route:\n      print('no such route')\n      self.send_error(404)\n      return\n\n    pattern_id_trip_dict = route.GetPatternIdTripDict()\n    pattern_id = trip.pattern_id\n    if pattern_id not in pattern_id_trip_dict:\n      print('no pattern %s found in %s' % (pattern_id, pattern_id_trip_dict.keys()))\n      self.send_error(404)\n      return\n    triplist = pattern_id_trip_dict[pattern_id]\n\n    pattern_start_time = min((t.GetStartTime() for t in triplist))\n    pattern_end_time = max((t.GetEndTime() for t in triplist))\n\n    marey.SetSpan(pattern_start_time,pattern_end_time)\n    marey.Draw(triplist[0].GetPattern(), triplist, height)\n\n    content = marey.Draw()\n\n    self.send_response(200)\n    self.send_header('Content-Type', 'image/svg+xml')\n    self.send_header('Content-Length', str(len(content)))\n    self.end_headers()\n    self.wfile.write(content)", "response": "Handles GET request for a table graph"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef IsValidLanguageCode(lang):\n  bcp47_obj = parser.ParseLanguage(str(lang.lower()))\n  return bcp47_obj.IsWellformed() and bcp47_obj.IsValid()", "response": "Checks the validity of a language code value"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nvalidates a non - required language code value.", "response": "def ValidateLanguageCode(lang, column_name=None, problems=None):\n  \"\"\"\n  Validates a non-required language code value using the pybcp47 module:\n    - if invalid adds InvalidValue error (if problems accumulator is provided)\n    - distinguishes between 'not well-formed' and 'not valid' and adds error\n      reasons accordingly\n    - an empty language code is regarded as valid! Otherwise we might end up\n      with many duplicate errors because of the required field checks.\n    - returns true if the language is valid, false if not well-formed or\n      invalid.\n  \"\"\"\n  if util.IsEmpty(lang):\n    return True\n  bcp47_obj = parser.ParseLanguage(str(lang.lower()))\n  if not bcp47_obj.wellformed:\n    if problems:\n      problems.InvalidValue(column_name, lang,\n                            'language code \"%s\" is not well-formed' %\n                            lang, type=problems_class.TYPE_ERROR)\n    return False\n  if not bcp47_obj.valid:\n    if problems:\n      problems.InvalidValue(column_name, lang,\n                            'language code \"%s\" is not valid, parses as: %s' %\n                            (lang, bcp47_obj), type=problems_class.TYPE_WARNING)\n    return False\n  return True"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef MakeExpandedTrace(frame_records):\n  dump = []\n  for (frame_obj, filename, line_num, fun_name, context_lines,\n       context_index) in frame_records:\n    dump.append('File \"%s\", line %d, in %s\\n' % (filename, line_num,\n                                                 fun_name))\n    if context_lines:\n      for (i, line) in enumerate(context_lines):\n        if i == context_index:\n          dump.append(' --> %s' % line)\n        else:\n          dump.append('     %s' % line)\n    for local_name, local_val in frame_obj.f_locals.items():\n      try:\n        local_type_name = type(local_val).__name__\n      except Exception as e:\n        local_type_name = '    Exception in type({}).__name__: {}'.format(local_name, e)\n      try:\n        truncated_val = repr(local_val)[0:500]\n      except Exception as e:\n        dump.append('    Exception in repr({}): {}\\n'.format(local_name, e))\n      else:\n        if len(truncated_val) >= 500:\n          truncated_val = '%s...' % truncated_val[0:499]\n        dump.append('    {} = {} ({})\\n'.format(local_name, truncated_val, local_type_name))\n    dump.append('\\n')\n  return dump", "response": "Return a list of text lines for the given list of frame records."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ParseAttributes(self, problems):\n    if util.IsEmpty(self.shape_id):\n      problems.MissingValue('shape_id')\n      return\n\n    try:\n      if not isinstance(self.shape_pt_sequence, int):\n        self.shape_pt_sequence = \\\n                util.NonNegIntStringToInt(self.shape_pt_sequence, problems)\n      elif self.shape_pt_sequence < 0:\n        problems.InvalidValue('shape_pt_sequence', self.shape_pt_sequence,\n                              'Value should be a number (0 or higher)')\n    except (TypeError, ValueError):\n      problems.InvalidValue('shape_pt_sequence', self.shape_pt_sequence,\n                            'Value should be a number (0 or higher)')\n      return\n\n    try:\n      if not isinstance(self.shape_pt_lat, (int, float)):\n        self.shape_pt_lat = util.FloatStringToFloat(self.shape_pt_lat, problems)\n      if abs(self.shape_pt_lat) > 90.0:\n        problems.InvalidValue('shape_pt_lat', self.shape_pt_lat)\n        return\n    except (TypeError, ValueError):\n      problems.InvalidValue('shape_pt_lat', self.shape_pt_lat)\n      return\n\n    try:\n      if not isinstance(self.shape_pt_lon, (int, float)):\n        self.shape_pt_lon = util.FloatStringToFloat(self.shape_pt_lon, problems)\n      if abs(self.shape_pt_lon) > 180.0:\n        problems.InvalidValue('shape_pt_lon', self.shape_pt_lon)\n        return\n    except (TypeError, ValueError):\n      problems.InvalidValue('shape_pt_lon', self.shape_pt_lon)\n      return\n\n    if abs(self.shape_pt_lat) < 1.0 and abs(self.shape_pt_lon) < 1.0:\n      problems.InvalidValue('shape_pt_lat', self.shape_pt_lat,\n                            'Point location too close to 0, 0, which means '\n                            'that it\\'s probably an incorrect location.',\n                            type=problems_module.TYPE_WARNING)\n      return\n\n    if self.shape_dist_traveled == '':\n      self.shape_dist_traveled = None\n\n    if (self.shape_dist_traveled is not None and\n        not isinstance(self.shape_dist_traveled, (int, float))):\n      try:\n        self.shape_dist_traveled = \\\n                util.FloatStringToFloat(self.shape_dist_traveled, problems)\n      except (TypeError, ValueError):\n        problems.InvalidValue('shape_dist_traveled', self.shape_dist_traveled,\n                              'This value should be a positive number.')\n        return\n\n    if self.shape_dist_traveled is not None and self.shape_dist_traveled < 0:\n      problems.InvalidValue('shape_dist_traveled', self.shape_dist_traveled,\n                            'This value should be a positive number.')\n      return\n\n    return True", "response": "Parses all attributes of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef SetFileContext(self, file_name, row_num, row, headers):\n    self._context = (file_name, row_num, row, headers)", "response": "Save the current context for the current file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef InvalidLineEnd(self, bad_line_end, context=None, type=TYPE_WARNING):\n    e = InvalidLineEnd(bad_line_end=bad_line_end, context=context,\n                       context2=self._context, type=type)\n    self.AddToAccumulator(e)", "response": "bad_line_end is a human readable string."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _LineWrap(text, width):\n    return reduce(lambda line, word, width=width: '%s%s%s' %\n                  (line,\n                   ' \\n'[(len(line) - line.rfind('\\n') - 1 +\n                         len(word.split('\\n', 1)[0]) >= width)],\n                   word),\n                  text.split(' ')\n                 )", "response": "Returns a word - wrap function that preserves existing line breaks\n    and most spaces in the text."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ContextTupleToDict(context):\n    d = {}\n    if not context:\n      return d\n    for k, v in zip(ExceptionWithContext.CONTEXT_PARTS, context):\n      if v != '' and v != None:  # Don't ignore int(0), a valid row_num\n        d[k] = v\n    return d", "response": "Convert a tuple representing a context into a dict of key - value pairs\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a copy of self as a dict suitable for passing to FormatProblem", "response": "def GetDictToFormat(self):\n    \"\"\"Return a copy of self as a dict, suitable for passing to FormatProblem\"\"\"\n    d = {}\n    for k, v in self.__dict__.items():\n      # TODO: Better handling of unicode/utf-8 within Schedule objects.\n      # Concatinating a unicode and utf-8 str object causes an exception such\n      # as \"UnicodeDecodeError: 'ascii' codec can't decode byte ...\" as python\n      # tries to convert the str to a unicode. To avoid that happening within\n      # the problem reporter convert all unicode attributes to utf-8.\n      # Currently valid utf-8 fields are converted to unicode in _ReadCsvDict.\n      # Perhaps all fields should be left as utf-8.\n      d[k] = util.EncodeUnicode(v)\n    return d"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef FormatProblem(self, d=None):\n    if not d:\n      d = self.GetDictToFormat()\n\n    output_error_text = self.__class__.ERROR_TEXT % d\n    if ('reason' in d) and d['reason']:\n      return '%s\\n%s' % (output_error_text, d['reason'])\n    else:\n      return output_error_text", "response": "Returns a text string describing the problem."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a text string describing the context of the current object", "response": "def FormatContext(self):\n    \"\"\"Return a text string describing the context\"\"\"\n    text = ''\n    if hasattr(self, 'feed_name'):\n      text += \"In feed '%s': \" % self.feed_name\n    if hasattr(self, 'file_name'):\n      text += self.file_name\n    if hasattr(self, 'row_num'):\n      text += \":%i\" % self.row_num\n    if hasattr(self, 'column_name'):\n      text += \" column %s\" % self.column_name\n    return text"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a tuple that can be used to sort problems into a consistent order.", "response": "def GetOrderKey(self):\n    \"\"\"Return a tuple that can be used to sort problems into a consistent order.\n\n    Returns:\n      A list of values.\n    \"\"\"\n    context_attributes = ['_type']\n    context_attributes.extend(ExceptionWithContext.CONTEXT_PARTS)\n    context_attributes.extend(self._GetExtraOrderAttributes())\n\n    tokens = []\n    for context_attribute in context_attributes:\n      tokens.append(getattr(self, context_attribute, None))\n    return tokens"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nselecting a set of location ids for a pathway graph.", "response": "def choose_location_ids(gtfs, stop_ids=None):\n    \"\"\"Chooses a set of location ids (stations and their children) for\n    rendering a pathway graph.\n\n    If stop_ids is None, then all stations that have pathways are chosen.\n\n    If stop_ids is not None, then the station with this stop_id (or\n    with a child with this stop_id) is chosen.\n\n    \"\"\"\n\n    if not stop_ids:\n        # Select locations that are involved in pathway graph.\n        return [location.gtfs_id\n                for location in gtfs.locations\n                if location.station().self_or_children_have_pathways()]\n\n    station_ids = set()\n    try:\n        for stop_id in stop_ids.split(','):\n            station = gtfs.get_location(stop_id).station()\n            station_ids.add(station.gtfs_id)\n            print('Visualizing station %s' % station.gtfs_id)\n    except KeyError:\n        raise Exception('Cannot find location with stop_id=%s' % stop_id)\n\n    location_ids = station_ids.copy()\n    for station_id in station_ids:\n        for child_id in gtfs.get_location(station_id).children:\n            # Child is a platform, entrance or generic node.\n            location_ids.add(child_id)\n            # Add boarding areas if they are present for this child platform.\n            for boarding_area_id in gtfs.get_location(child_id).children:\n                location_ids.add(gtfs.get_location(boarding_area_id).gtfs_id)\n\n    return location_ids"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef gtfs_to_graphviz(gtfs, stop_ids=None):\n    graph = GraphViz()\n    location_ids = choose_location_ids(gtfs, stop_ids)\n    locations = [gtfs.get_location(i) for i in location_ids]\n\n    for location in locations:\n        if not location.parent_id:\n            graph.add_cluster(GraphCluster(\n                location.gtfs_id,\n                location_label(location, max_length=-1),\n                location_color(location.location_type)))\n\n    for location in locations:\n        if location.parent_id and requires_platform_cluster(location):\n            graph.get_cluster(location.parent_id).add_cluster(GraphCluster(\n                location.gtfs_id,\n                location_label(location),\n                location_color(location.location_type)))\n\n    for location in locations:\n        if not location.parent_id or requires_platform_cluster(location):\n            continue\n        node = GraphNode(\n            location.gtfs_id,\n            location_label(location, max_length=25),\n            location_color(location.location_type),\n            location_shape(location.location_type))\n        cluster = graph.get_cluster(location.station().gtfs_id)\n        if location.location_type == LocationType.boarding_area:\n            cluster = cluster.get_cluster(location.parent_id)\n        cluster.nodes.append(node)\n\n    for pathway in gtfs.pathways:\n        if pathway.from_id in location_ids and pathway.to_id in location_ids:\n            graph.edges.append(GraphEdge(\n                pathway.from_id, pathway.to_id,\n                'both' if pathway.is_bidirectional else 'forward',\n                pathway_label(pathway)))\n\n    return graph", "response": "Reads GTFS data and returns GraphViz DOT file content as string."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef GetGtfsFactory(self):\n\n    if self._gtfs_factory is None:\n      #TODO(anog): We really need to create a dependency graph and clean things\n      #            up, as the comment in __init__.py says.\n      #            Not having GenericGTFSObject as a leaf (with no other\n      #            imports) creates all sorts of circular import problems.\n      #            This is why the import is here and not at the top level.\n      #            When this runs, gtfsfactory should have already been loaded\n      #            by other modules, avoiding the circular imports.\n      from . import gtfsfactory\n      self._gtfs_factory = gtfsfactory.GetGtfsFactory()\n    return self._gtfs_factory", "response": "Returns the object s GTFS Factory."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef iteritems(self):\n    for name, value in self.__dict__.iteritems():\n      if (not name) or name[0] == \"_\":\n        continue\n      yield name, value", "response": "Return an iterable for ( name value ) pairs of public attributes."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn iterable of column names used by this object.", "response": "def keys(self):\n    \"\"\"Return iterable of columns used by this object.\"\"\"\n    columns = set()\n    for name in vars(self):\n      if (not name) or name[0] == \"_\":\n        continue\n      columns.add(name)\n    return columns"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef AddShapePointObjectUnsorted(self, shapepoint, problems):\n    if (len(self.sequence) == 0 or\n        shapepoint.shape_pt_sequence >= self.sequence[-1]):\n      index = len(self.sequence)\n    elif shapepoint.shape_pt_sequence <= self.sequence[0]:\n      index = 0\n    else:\n      index = bisect.bisect(self.sequence, shapepoint.shape_pt_sequence)\n\n    if shapepoint.shape_pt_sequence in self.sequence:\n      problems.InvalidValue('shape_pt_sequence', shapepoint.shape_pt_sequence,\n                            'The sequence number %d occurs more than once in '\n                            'shape %s.' %\n                            (shapepoint.shape_pt_sequence, self.shape_id))\n\n    if shapepoint.shape_dist_traveled is not None and len(self.sequence) > 0:\n      if (index != len(self.sequence) and\n          shapepoint.shape_dist_traveled > self.distance[index]):\n        problems.InvalidValue('shape_dist_traveled',\n                              shapepoint.shape_dist_traveled,\n                              'Each subsequent point in a shape should have '\n                              'a distance value that shouldn\\'t be larger '\n                              'than the next ones. In this case, the next '\n                              'distance was %f.' % self.distance[index])\n\n      if (index > 0 and\n          shapepoint.shape_dist_traveled < self.distance[index - 1]):\n        problems.InvalidValue('shape_dist_traveled',\n                              shapepoint.shape_dist_traveled,\n                              'Each subsequent point in a shape should have '\n                              'a distance value that\\'s at least as large as '\n                              'the previous ones. In this case, the previous '\n                              'distance was %f.' % self.distance[index - 1])\n\n    if shapepoint.shape_dist_traveled > self.max_distance:\n      self.max_distance = shapepoint.shape_dist_traveled\n\n    self.sequence.insert(index, shapepoint.shape_pt_sequence)\n    self.distance.insert(index, shapepoint.shape_dist_traveled)\n    self.points.insert(index, (shapepoint.shape_pt_lat,\n                               shapepoint.shape_pt_lon,\n                               shapepoint.shape_dist_traveled))", "response": "Adds a shapepoint into a correct position by sequence."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a point on the shape polyline with the input shape_dist_traveled.", "response": "def GetPointWithDistanceTraveled(self, shape_dist_traveled):\n    \"\"\"Returns a point on the shape polyline with the input shape_dist_traveled.\n\n    Args:\n      shape_dist_traveled: The input shape_dist_traveled.\n\n    Returns:\n      The shape point as a tuple (lat, lng, shape_dist_traveled), where lat and\n      lng is the location of the shape point, and shape_dist_traveled is an\n      increasing metric representing the distance traveled along the shape.\n      Returns None if there is data error in shape.\n    \"\"\"\n    if not self.distance:\n      return None\n    if shape_dist_traveled <= self.distance[0]:\n      return self.points[0]\n    if shape_dist_traveled >= self.distance[-1]:\n      return self.points[-1]\n\n    index = bisect.bisect(self.distance, shape_dist_traveled)\n    (lat0, lng0, dist0) = self.points[index - 1]\n    (lat1, lng1, dist1) = self.points[index]\n\n    # Interpolate if shape_dist_traveled does not equal to any of the point\n    # in shape segment.\n    # (lat0, lng0)          (lat, lng)           (lat1, lng1)\n    # -----|--------------------|---------------------|------\n    #    dist0          shape_dist_traveled         dist1\n    #      \\------- ca --------/ \\-------- bc -------/\n    #       \\----------------- ba ------------------/\n    ca = shape_dist_traveled - dist0\n    bc = dist1 - shape_dist_traveled\n    ba = bc + ca\n    if ba == 0:\n      # This only happens when there's data error in shapes and should have been\n      # catched before. Check to avoid crash.\n      return None\n    # This won't work crossing longitude 180 and is only an approximation which\n    # works well for short distance.\n    lat = (lat1 * ca + lat0 * bc) / ba\n    lng = (lng1 * ca + lng0 * bc) / ba\n    return (lat, lng, shape_dist_traveled)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a stop to this trip.", "response": "def AddStopTime(self, stop, problems=None, schedule=None, **kwargs):\n    \"\"\"Add a stop to this trip. Stops must be added in the order visited.\n\n    Args:\n      stop: A Stop object\n      kwargs: remaining keyword args passed to StopTime.__init__\n\n    Returns:\n      None\n    \"\"\"\n    if problems is None:\n      # TODO: delete this branch when StopTime.__init__ doesn't need a\n      # ProblemReporter\n      problems = problems_module.default_problem_reporter\n    stoptime = self.GetGtfsFactory().StopTime(\n        problems=problems, stop=stop, **kwargs)\n    self.AddStopTimeObject(stoptime, schedule)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a StopTime object to this trip.", "response": "def _AddStopTimeObjectUnordered(self, stoptime, schedule):\n    \"\"\"Add StopTime object to this trip.\n\n    The trip isn't checked for duplicate sequence numbers so it must be\n    validated later.\"\"\"\n    stop_time_class = self.GetGtfsFactory().StopTime\n    cursor = schedule._connection.cursor()\n    insert_query = \"INSERT INTO stop_times (%s) VALUES (%s);\" % (\n       ','.join(stop_time_class._SQL_FIELD_NAMES),\n       ','.join(['?'] * len(stop_time_class._SQL_FIELD_NAMES)))\n    cursor = schedule._connection.cursor()\n    cursor.execute(\n        insert_query, stoptime.GetSqlValuesTuple(self.trip_id))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ReplaceStopTimeObject(self, stoptime, schedule=None):\n\n    if schedule is None:\n      schedule = self._schedule\n\n    new_secs = stoptime.GetTimeSecs()\n    cursor = schedule._connection.cursor()\n    cursor.execute(\"DELETE FROM stop_times WHERE trip_id=? and \"\n                   \"stop_sequence=? and stop_id=?\",\n                   (self.trip_id, stoptime.stop_sequence, stoptime.stop_id))\n    if cursor.rowcount == 0:\n      raise problems_module.Error('Attempted replacement of StopTime object which does not exist')\n    self._AddStopTimeObjectUnordered(stoptime, schedule)", "response": "Replaces a StopTime object from this trip with the given one."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a StopTime object to the end of this trip.", "response": "def AddStopTimeObject(self, stoptime, schedule=None, problems=None):\n    \"\"\"Add a StopTime object to the end of this trip.\n\n    Args:\n      stoptime: A StopTime object. Should not be reused in multiple trips.\n      schedule: Schedule object containing this trip which must be\n      passed to Trip.__init__ or here\n      problems: ProblemReporter object for validating the StopTime in its new\n      home\n\n    Returns:\n      None\n    \"\"\"\n    if schedule is None:\n      schedule = self._schedule\n    if schedule is None:\n      warnings.warn(\"No longer supported. _schedule attribute is used to get \"\n                    \"stop_times table\", DeprecationWarning)\n    if problems is None:\n      problems = schedule.problem_reporter\n\n    new_secs = stoptime.GetTimeSecs()\n    cursor = schedule._connection.cursor()\n    cursor.execute(\"SELECT max(stop_sequence), max(arrival_secs), \"\n                   \"max(departure_secs) FROM stop_times WHERE trip_id=?\",\n                   (self.trip_id,))\n    row = cursor.fetchone()\n    if row[0] is None:\n      # This is the first stop_time of the trip\n      stoptime.stop_sequence = 1\n      if new_secs == None:\n        problems.OtherProblem(\n            'No time for first StopTime of trip_id \"%s\"' % (self.trip_id,))\n    else:\n      stoptime.stop_sequence = row[0] + 1\n      prev_secs = max(row[1], row[2])\n      if new_secs != None and new_secs < prev_secs:\n        problems.OtherProblem(\n            'out of order stop time for stop_id=%s trip_id=%s %s < %s' %\n            (util.EncodeUnicode(stoptime.stop_id),\n             util.EncodeUnicode(self.trip_id),\n             util.FormatSecondsSinceMidnight(new_secs),\n             util.FormatSecondsSinceMidnight(prev_secs)))\n    self._AddStopTimeObjectUnordered(stoptime, schedule)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef GetTimeStops(self):\n    return [(st.arrival_secs, st.departure_secs, st.stop) for st in\n            self.GetStopTimes()]", "response": "Return a list of tuples."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the number of stop times made by this trip.", "response": "def GetCountStopTimes(self):\n    \"\"\"Return the number of stops made by this trip.\"\"\"\n    cursor = self._schedule._connection.cursor()\n    cursor.execute(\n        'SELECT count(*) FROM stop_times WHERE trip_id=?', (self.trip_id,))\n    return cursor.fetchone()[0]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef GetTimeInterpolatedStops(self):\n    rv = []\n\n    stoptimes = self.GetStopTimes()\n    # If there are no stoptimes [] is the correct return value but if the start\n    # or end are missing times there is no correct return value.\n    if not stoptimes:\n      return []\n    if (stoptimes[0].GetTimeSecs() is None or\n        stoptimes[-1].GetTimeSecs() is None):\n      raise ValueError(\"%s must have time at first and last stop\" % (self))\n\n    cur_timepoint = None\n    next_timepoint = None\n    distance_between_timepoints = 0\n    distance_traveled_between_timepoints = 0\n\n    for i, st in enumerate(stoptimes):\n      if st.GetTimeSecs() != None:\n        cur_timepoint = st\n        distance_between_timepoints = 0\n        distance_traveled_between_timepoints = 0\n        if i + 1 < len(stoptimes):\n          k = i + 1\n          distance_between_timepoints += util.ApproximateDistanceBetweenStops(stoptimes[k-1].stop, stoptimes[k].stop)\n          while stoptimes[k].GetTimeSecs() == None:\n            k += 1\n            distance_between_timepoints += util.ApproximateDistanceBetweenStops(stoptimes[k-1].stop, stoptimes[k].stop)\n          next_timepoint = stoptimes[k]\n        rv.append( (st.GetTimeSecs(), st, True) )\n      else:\n        distance_traveled_between_timepoints += util.ApproximateDistanceBetweenStops(stoptimes[i-1].stop, st.stop)\n        distance_percent = distance_traveled_between_timepoints / distance_between_timepoints\n        total_time = next_timepoint.GetTimeSecs() - cur_timepoint.GetTimeSecs()\n        time_estimate = distance_percent * total_time + cur_timepoint.GetTimeSecs()\n        rv.append( (int(round(time_estimate)), st, False) )\n\n    return rv", "response": "Returns a list of tuples that are the times needed to interpolate this trip."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nclear all stop times associated with this trip.", "response": "def ClearStopTimes(self):\n    \"\"\"Remove all stop times from this trip.\n\n    StopTime objects previously returned by GetStopTimes are unchanged but are\n    no longer associated with this trip.\n    \"\"\"\n    cursor = self._schedule._connection.cursor()\n    cursor.execute('DELETE FROM stop_times WHERE trip_id=?', (self.trip_id,))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a sorted list of StopTime objects for this trip.", "response": "def GetStopTimes(self, problems=None):\n    \"\"\"Return a sorted list of StopTime objects for this trip.\"\"\"\n    # In theory problems=None should be safe because data from database has been\n    # validated. See comment in _LoadStopTimes for why this isn't always true.\n    cursor = self._schedule._connection.cursor()\n    cursor.execute(\n        'SELECT arrival_secs,departure_secs,stop_headsign,pickup_type,'\n        'drop_off_type,shape_dist_traveled,stop_id,stop_sequence,timepoint '\n        'FROM stop_times '\n        'WHERE trip_id=? '\n        'ORDER BY stop_sequence', (self.trip_id,))\n    stop_times = []\n    stoptime_class = self.GetGtfsFactory().StopTime\n    if problems is None:\n      # TODO: delete this branch when StopTime.__init__ doesn't need a\n      # ProblemReporter\n      problems = problems_module.default_problem_reporter\n    for row in cursor.fetchall():\n      stop = self._schedule.GetStop(row[6])\n      stop_times.append(stoptime_class(problems=problems,\n                                       stop=stop,\n                                       arrival_secs=row[0],\n                                       departure_secs=row[1],\n                                       stop_headsign=row[2],\n                                       pickup_type=row[3],\n                                       drop_off_type=row[4],\n                                       shape_dist_traveled=row[5],\n                                       stop_sequence=row[7],\n                                       timepoint=row[8]))\n    return stop_times"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef GetFrequencyStopTimes(self, problems=None):\n    stoptimes_list = [] # list of stoptime lists to be returned\n    stoptime_pattern = self.GetStopTimes()\n    first_secs = stoptime_pattern[0].arrival_secs # first time of the trip\n    stoptime_class = self.GetGtfsFactory().StopTime\n    # for each start time of a headway run\n    for run_secs in self.GetFrequencyStartTimes():\n      # stop time list for a headway run\n      stoptimes = []\n      # go through the pattern and generate stoptimes\n      for st in stoptime_pattern:\n        arrival_secs, departure_secs = None, None # default value if the stoptime is not timepoint\n        if st.arrival_secs != None:\n          arrival_secs = st.arrival_secs - first_secs + run_secs\n        if st.departure_secs != None:\n          departure_secs = st.departure_secs - first_secs + run_secs\n        # append stoptime\n        stoptimes.append(stoptime_class(problems=problems, stop=st.stop,\n                                        arrival_secs=arrival_secs,\n                                        departure_secs=departure_secs,\n                                        stop_headsign=st.stop_headsign,\n                                        pickup_type=st.pickup_type,\n                                        drop_off_type=st.drop_off_type,\n                                        shape_dist_traveled= \\\n                                            st.shape_dist_traveled,\n                                        stop_sequence=st.stop_sequence,\n                                        timepoint=st.timepoint))\n      # add stoptimes to the stoptimes_list\n      stoptimes_list.append ( stoptimes )\n    return stoptimes_list", "response": "Returns a list of StopTime objects for each headway - based run."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the first time of the trip.", "response": "def GetStartTime(self, problems=problems_module.default_problem_reporter):\n    \"\"\"Return the first time of the trip. TODO: For trips defined by frequency\n    return the first time of the first trip.\"\"\"\n    cursor = self._schedule._connection.cursor()\n    cursor.execute(\n        'SELECT arrival_secs,departure_secs FROM stop_times WHERE '\n        'trip_id=? ORDER BY stop_sequence LIMIT 1', (self.trip_id,))\n    (arrival_secs, departure_secs) = cursor.fetchone()\n    if arrival_secs != None:\n      return arrival_secs\n    elif departure_secs != None:\n      return departure_secs\n    else:\n      problems.InvalidValue('departure_time', '',\n                            'The first stop_time in trip %s is missing '\n                            'times.' % self.trip_id)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of start time for each headway - based run.", "response": "def GetFrequencyStartTimes(self):\n    \"\"\"Return a list of start time for each headway-based run.\n\n    Returns:\n      a sorted list of seconds since midnight, the start time of each run. If\n      this trip doesn't have headways returns an empty list.\"\"\"\n    start_times = []\n    # for each headway period of the trip\n    for freq_tuple in self.GetFrequencyTuples():\n      (start_secs, end_secs, headway_secs) = freq_tuple[0:3]\n      # reset run secs to the start of the timeframe\n      run_secs = start_secs\n      while run_secs < end_secs:\n        start_times.append(run_secs)\n        # increment current run secs by headway secs\n        run_secs += headway_secs\n    return start_times"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _GenerateStopTimesTuples(self):\n    stoptimes = self.GetStopTimes()\n    for i, st in enumerate(stoptimes):\n      yield st.GetFieldValuesTuple(self.trip_id)", "response": "Generator for rows of the stop_times file"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef GetPattern(self):\n    stoptimes = self.GetStopTimes()\n    return tuple(st.stop for st in stoptimes)", "response": "Return a tuple of Stop objects in the order visited"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef AddHeadwayPeriodObject(self, headway_period, problem_reporter):\n    warnings.warn(\"No longer supported. The HeadwayPeriod class was renamed to \"\n                  \"Frequency, and all related functions were renamed \"\n                  \"accordingly.\", DeprecationWarning)\n    self.AddFrequencyObject(frequency, problem_reporter)", "response": "Deprecated. Please use AddFrequencyObject."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a Frequency object to this trip s list of Frequencies.", "response": "def AddFrequencyObject(self, frequency, problem_reporter):\n    \"\"\"Add a Frequency object to this trip's list of Frequencies.\"\"\"\n    if frequency is not None:\n      self.AddFrequency(frequency.StartTime(),\n                        frequency.EndTime(),\n                        frequency.HeadwaySecs(),\n                        frequency.ExactTimes(),\n                        problem_reporter)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd a frequency to this vehicle.", "response": "def AddFrequency(self, start_time, end_time, headway_secs, exact_times=0,\n      problem_reporter=problems_module.default_problem_reporter):\n    \"\"\"Adds a period to this trip during which the vehicle travels\n    at regular intervals (rather than specifying exact times for each stop).\n\n    Args:\n      start_time: The time at which this headway period starts, either in\n          numerical seconds since midnight or as \"HH:MM:SS\" since midnight.\n      end_time: The time at which this headway period ends, either in\n          numerical seconds since midnight or as \"HH:MM:SS\" since midnight.\n          This value should be larger than start_time.\n      headway_secs: The amount of time, in seconds, between occurences of\n          this trip.\n      exact_times: If 1, indicates that frequency trips should be scheduled\n          exactly as determined by their start time and headway.  Default is 0.\n      problem_reporter: Optional parameter that can be used to select\n          how any errors in the other input parameters will be reported.\n    Returns:\n      None\n    \"\"\"\n    if start_time == None or start_time == '':  # 0 is OK\n      problem_reporter.MissingValue('start_time')\n      return\n    if isinstance(start_time, basestring):\n      try:\n        start_time = util.TimeToSecondsSinceMidnight(start_time)\n      except problems_module.Error:\n        problem_reporter.InvalidValue('start_time', start_time)\n        return\n    elif start_time < 0:\n      problem_reporter.InvalidValue('start_time', start_time)\n\n    if end_time == None or end_time == '':\n      problem_reporter.MissingValue('end_time')\n      return\n    if isinstance(end_time, basestring):\n      try:\n        end_time = util.TimeToSecondsSinceMidnight(end_time)\n      except problems_module.Error:\n        problem_reporter.InvalidValue('end_time', end_time)\n        return\n    elif end_time < 0:\n      problem_reporter.InvalidValue('end_time', end_time)\n      return\n\n    if not headway_secs:\n      problem_reporter.MissingValue('headway_secs')\n      return\n    try:\n      headway_secs = int(headway_secs)\n    except ValueError:\n      problem_reporter.InvalidValue('headway_secs', headway_secs)\n      return\n\n    if headway_secs <= 0:\n      problem_reporter.InvalidValue('headway_secs', headway_secs)\n      return\n\n    if end_time <= start_time:\n      problem_reporter.InvalidValue('end_time', end_time,\n                                    'should be greater than start_time')\n\n    if not exact_times:\n      exact_times = 0      \n    if exact_times not in (0, 1):\n      problem_reporter.InvalidValue('exact_times', exact_times,\n          'Should be 0 (no fixed schedule) or 1 (fixed and regular schedule)')\n\n    self._headways.append((start_time, end_time, headway_secs, exact_times))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nvalidating the attributes of this object.", "response": "def Validate(self, problems, validate_children=True):\n    \"\"\"Validate attributes of this object.\n\n    Check that this object has all required values set to a valid value without\n    reference to the rest of the schedule. If the _schedule attribute is set\n    then check that references such as route_id and service_id are correct.\n\n    Args:\n      problems: A ProblemReporter object\n      validate_children: if True and the _schedule attribute is set than call\n                         ValidateChildren\n    \"\"\"\n    self.ValidateRouteId(problems)\n    self.ValidateServicePeriod(problems)\n    self.ValidateDirectionId(problems)\n    self.ValidateTripId(problems)\n    self.ValidateShapeIdsExistInShapeList(problems)\n    self.ValidateRouteIdExistsInRouteList(problems)\n    self.ValidateServiceIdExistsInServiceList(problems)\n    self.ValidateBikesAllowed(problems)\n    self.ValidateWheelchairAccessible(problems)\n    if self._schedule and validate_children:\n      self.ValidateChildren(problems)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ValidateChildren(self, problems):\n    assert self._schedule, \"Trip must be in a schedule to ValidateChildren\"\n    # TODO: validate distance values in stop times (if applicable)\n\n    self.ValidateNoDuplicateStopSequences(problems)\n    stoptimes = self.GetStopTimes(problems)\n    stoptimes.sort(key=lambda x: x.stop_sequence)\n    self.ValidateTripStartAndEndTimes(problems, stoptimes)\n    self.ValidateStopTimesSequenceHasIncreasingTimeAndDistance(problems,\n                                                               stoptimes)\n    self.ValidateShapeDistTraveledSmallerThanMaxShapeDistance(problems,\n                                                              stoptimes)\n    self.ValidateDistanceFromStopToShape(problems, stoptimes)\n    self.ValidateFrequencies(problems)", "response": "Validate StopTimes and headways of this trip."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a tuple that outputs a row of _FIELD_NAMES to be written to GTFS file.", "response": "def GetFieldValuesTuple(self, trip_id):\n    \"\"\"Return a tuple that outputs a row of _FIELD_NAMES to be written to a\n       GTFS file.\n\n    Arguments:\n        trip_id: The trip_id of the trip to which this StopTime corresponds.\n                 It must be provided, as it is not stored in StopTime.\n    \"\"\"\n    result = []\n    for fn in self._FIELD_NAMES:\n      if fn == 'trip_id':\n        result.append(trip_id)\n      else:\n        # Since we'll be writting to an output file, we want empty values to be\n        # outputted as an empty string\n        result.append(getattr(self, fn) or '' )\n    return tuple(result)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a tuple that outputs a row of _FIELD_NAMES to be written to SQLite database.", "response": "def GetSqlValuesTuple(self, trip_id):\n    \"\"\"Return a tuple that outputs a row of _FIELD_NAMES to be written to a\n       SQLite database.\n\n    Arguments:\n        trip_id: The trip_id of the trip to which this StopTime corresponds.\n                 It must be provided, as it is not stored in StopTime.\n    \"\"\"\n\n    result = []\n    for fn in self._SQL_FIELD_NAMES:\n      if fn == 'trip_id':\n        result.append(trip_id)\n      else:\n        # Since we'll be writting to SQLite, we want empty values to be\n        # outputted as NULL string (contrary to what happens in\n        # GetFieldValuesTuple)\n        result.append(getattr(self, fn))\n    return tuple(result)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the first time_secs that is not None.", "response": "def GetTimeSecs(self):\n    \"\"\"Return the first of arrival_secs and departure_secs that is not None.\n    If both are None return None.\"\"\"\n    if self.arrival_secs != None:\n      return self.arrival_secs\n    elif self.departure_secs != None:\n      return self.departure_secs\n    else:\n      return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new segy file with the geometry and properties given by spec.", "response": "def create(filename, spec):\n    \"\"\"Create a new segy file.\n\n    Create a new segy file with the geometry and properties given by `spec`.\n    This enables creating SEGY files from your data. The created file supports\n    all segyio modes, but has an emphasis on writing. The spec must be\n    complete, otherwise an exception will be raised. A default, empty spec can\n    be created with ``segyio.spec()``.\n\n    Very little data is written to the file, so just calling create is not\n    sufficient to re-read the file with segyio. Rather, every trace header and\n    trace must be written to the file to be considered complete.\n\n    Create should be used together with python's ``with`` statement. This ensure\n    the data is written. Please refer to the examples.\n\n    The ``segyio.spec()`` function will default sorting, offsets and everything\n    in the mandatory group, except format and samples, and requires the caller\n    to fill in *all* the fields in either of the exclusive groups.\n\n    If any field is missing from the first exclusive group, and the tracecount\n    is set, the resulting file will be considered unstructured. If the\n    tracecount is set, and all fields of the first exclusive group are\n    specified, the file is considered structured and the tracecount is inferred\n    from the xlines/ilines/offsets. The offsets are defaulted to ``[1]`` by\n    ``segyio.spec()``.\n\n    Parameters\n    ----------\n    filename : str\n        Path to file to create\n    spec : segyio.spec\n        Structure of the segy file\n\n    Returns\n    -------\n    file : segyio.SegyFile\n        An open segyio file handle, similar to that returned by `segyio.open`\n\n    See also\n    --------\n    segyio.spec : template for the `spec` argument\n\n\n    Notes\n    -----\n\n    .. versionadded:: 1.1\n\n    .. versionchanged:: 1.4\n       Support for creating unstructured files\n\n    .. versionchanged:: 1.8\n       Support for creating lsb files\n\n    The ``spec`` is any object that has the following attributes\n\n    Mandatory::\n\n        iline   : int or segyio.BinField\n        xline   : int or segyio.BinField\n        samples : array of int\n        format  : { 1, 5 }\n            1 = IBM float, 5 = IEEE float\n\n    Exclusive::\n\n        ilines  : array_like of int\n        xlines  : array_like of int\n        offsets : array_like of int\n        sorting : int or segyio.TraceSortingFormat\n\n        OR\n\n        tracecount : int\n\n    Optional::\n\n        ext_headers : int\n        endian : str { 'big', 'msb', 'little', 'lsb' }\n            defaults to 'big'\n\n\n    Examples\n    --------\n\n    Create a file:\n\n    >>> spec = segyio.spec()\n    >>> spec.ilines  = [1, 2, 3, 4]\n    >>> spec.xlines  = [11, 12, 13]\n    >>> spec.samples = list(range(50))\n    >>> spec.sorting = 2\n    >>> spec.format  = 1\n    >>> with segyio.create(path, spec) as f:\n    ...     ## fill the file with data\n    ...     pass\n    ...\n\n    Copy a file, but shorten all traces by 50 samples:\n\n    >>> with segyio.open(srcpath) as src:\n    ...     spec = segyio.spec()\n    ...     spec.sorting = src.sorting\n    ...     spec.format = src.format\n    ...     spec.samples = src.samples[:len(src.samples) - 50]\n    ...     spec.ilines = src.ilines\n    ...     spec.xline = src.xlines\n    ...     with segyio.create(dstpath, spec) as dst:\n    ...         dst.text[0] = src.text[0]\n    ...         dst.bin = src.bin\n    ...         dst.header = src.header\n    ...         dst.trace = src.trace\n\n     Copy a file, but shift samples time by 50:\n\n    >>> with segyio.open(srcpath) as src:\n    ...     delrt = 50\n    ...     spec = segyio.spec()\n    ...     spec.samples = src.samples + delrt\n    ...     spec.ilines = src.ilines\n    ...     spec.xline = src.xlines\n    ...     with segyio.create(dstpath, spec) as dst:\n    ...         dst.text[0] = src.text[0]\n    ...         dst.bin = src.bin\n    ...         dst.header = src.header\n    ...         dst.header = { TraceField.DelayRecordingTime: delrt }\n    ...         dst.trace = src.trace\n\n    Copy a file, but shorten all traces by 50 samples (since v1.4):\n\n    >>> with segyio.open(srcpath) as src:\n    ...     spec = segyio.tools.metadata(src)\n    ...     spec.samples = spec.samples[:len(spec.samples) - 50]\n    ...     with segyio.create(dstpath, spec) as dst:\n    ...         dst.text[0] = src.text[0]\n    ...         dst.bin = src.bin\n    ...         dst.header = src.header\n    ...         dst.trace = src.trace\n    \"\"\"\n\n    from . import _segyio\n\n    if not structured(spec):\n        tracecount = spec.tracecount\n    else:\n        tracecount = len(spec.ilines) * len(spec.xlines) * len(spec.offsets)\n\n    ext_headers = spec.ext_headers if hasattr(spec, 'ext_headers') else 0\n    samples = numpy.asarray(spec.samples)\n\n    endians = {\n        'lsb': 256, # (1 << 8)\n        'little': 256,\n        'msb': 0,\n        'big': 0,\n    }\n    endian = spec.endian if hasattr(spec, 'endian') else 'big'\n    if endian is None:\n        endian = 'big'\n\n    if endian not in endians:\n        problem = 'unknown endianness {}, expected one of: '\n        opts = ' '.join(endians.keys())\n        raise ValueError(problem.format(endian) + opts)\n\n    fd = _segyio.segyiofd(str(filename), 'w+', endians[endian])\n    fd.segymake(\n        samples = len(samples),\n        tracecount = tracecount,\n        format = int(spec.format),\n        ext_headers = int(ext_headers),\n    )\n\n    f = segyio.SegyFile(fd,\n            filename = str(filename),\n            mode = 'w+',\n            iline = int(spec.iline),\n            xline = int(spec.xline),\n            endian = endian,\n    )\n\n    f._samples       = samples\n\n    if structured(spec):\n        sorting = spec.sorting if hasattr(spec, 'sorting') else None\n        if sorting is None:\n            sorting = TraceSortingFormat.INLINE_SORTING\n        f.interpret(spec.ilines, spec.xlines, spec.offsets, sorting)\n\n    f.text[0] = default_text_header(f._il, f._xl, segyio.TraceField.offset)\n\n    if len(samples) == 1:\n        interval = int(samples[0] * 1000)\n    else:\n        interval = int((samples[1] - samples[0]) * 1000)\n\n    f.bin.update(\n        ntrpr    = tracecount,\n        nart     = tracecount,\n        hdt      = interval,\n        dto      = interval,\n        hns      = len(samples),\n        nso      = len(samples),\n        format   = int(spec.format),\n        exth     = ext_headers,\n    )\n\n    return f"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nopen a seismic unix file.", "response": "def open(filename, mode = 'r', iline = 189,\n                               xline = 193,\n                               strict = True,\n                               ignore_geometry = False,\n                               endian = 'big' ):\n    \"\"\"Open a seismic unix file.\n\n    Behaves identically to open(), except it expects the seismic unix format,\n    not SEG-Y.\n\n    Parameters\n    ----------\n    filename : str\n        Path to file to open\n\n    mode : {'r', 'r+'}\n        File access mode, read-only ('r', default) or read-write ('r+')\n\n    iline : int or segyio.TraceField\n        Inline number field in the trace headers. Defaults to 189 as per the\n        SEG-Y rev1 specification\n\n    xline : int or segyio.TraceField\n        Crossline number field in the trace headers. Defaults to 193 as per the\n        SEG-Y rev1 specification\n\n    strict : bool, optional\n        Abort if a geometry cannot be inferred. Defaults to True.\n\n    ignore_geometry : bool, optional\n        Opt out on building geometry information, useful for e.g. shot\n        organised files. Defaults to False.\n\n    endian : {'big', 'msb', 'little', 'lsb'}\n        File endianness, big/msb (default) or little/lsb\n\n    Returns\n    -------\n    file : segyio.su.file\n        An open seismic unix file handle\n\n    Raises\n    ------\n    ValueError\n        If the mode string contains 'w', as it would truncate the file\n\n    See also\n    --------\n    segyio.open : SEG-Y open\n\n    Notes\n    -----\n    .. versionadded:: 1.8\n    \"\"\"\n\n    if 'w' in mode:\n        problem = 'w in mode would truncate the file'\n        solution = 'use r+ to open in read-write'\n        raise ValueError(', '.join((problem, solution)))\n\n    endians = {\n        'little': 256, # (1 << 8)\n        'lsb': 256,\n        'big': 0,\n        'msb': 0,\n    }\n\n    if endian not in endians:\n        problem = 'unknown endianness, must be one of: '\n        candidates = ' '.join(endians.keys())\n        raise ValueError(problem + candidates)\n\n    from .. import _segyio\n    fd = _segyio.segyiofd(str(filename), mode, endians[endian])\n    fd.suopen()\n    metrics = fd.metrics()\n\n    f = sufile(\n        fd,\n        filename = str(filename),\n        mode = mode,\n        iline = iline,\n        xline = xline,\n    )\n\n    h0 = f.header[0]\n\n    dt = h0[words.dt] / 1000.0\n    t0 = h0[words.delrt]\n    samples = metrics['samplecount']\n    f._samples = (numpy.arange(samples) * dt) + t0\n\n    if ignore_geometry:\n        return f\n\n    return infer_geometry(f, metrics, iline, xline, strict)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of values representing the samples in a trace at depth or time.", "response": "def sample_indexes(segyfile, t0=0.0, dt_override=None):\n    \"\"\"\n    Creates a list of values representing the samples in a trace at depth or time.\n    The list starts at *t0* and is incremented with am*dt* for the number of samples.\n    If a *dt_override* is not provided it will try to find a *dt* in the file.\n\n\n    Parameters\n    ----------\n    segyfile :  segyio.SegyFile\n    t0 : float\n        initial sample, or delay-recording-time\n    dt_override : float or None\n\n    Returns\n    -------\n    samples : array_like of float\n\n    Notes\n    -----\n\n    .. versionadded:: 1.1\n\n    \"\"\"\n    if dt_override is None:\n        dt_override = dt(segyfile)\n\n    return [t0 + t * dt_override for t in range(len(segyfile.samples))]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nformatting textual header for the segment - y file.", "response": "def create_text_header(lines):\n    \"\"\"Format textual header\n\n    Create a \"correct\" SEG-Y textual header.  Every line will be prefixed with\n    C## and there are 40 lines. The input must be a dictionary with the line\n    number[1-40] as a key. The value for each key should be up to 76 character\n    long string.\n\n    Parameters\n    ----------\n\n    lines : dict\n        `lines` dictionary with fields:\n\n        - ``no`` : line number (`int`)\n        - ``line`` : line (`str`)\n\n    Returns\n    -------\n\n    text : str\n\n    \"\"\"\n\n    rows = []\n    for line_no in range(1, 41):\n        line = \"\"\n        if line_no in lines:\n            line = lines[line_no]\n        row = \"C{0:>2} {1:76}\".format(line_no, line)\n        rows.append(row)\n\n    rows = ''.join(rows)\n    return rows"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the input string with newlines wrapped to the user specified width for each line.", "response": "def wrap(s, width=80):\n    \"\"\"\n    Formats the text input with newlines given the user specified width for\n    each line.\n\n    Parameters\n    ----------\n\n    s : str\n    width : int\n\n    Returns\n    -------\n\n    text : str\n\n    Notes\n    -----\n\n    .. versionadded:: 1.1\n\n    \"\"\"\n    return '\\n'.join(textwrap.wrap(str(s), width=width))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef native(data,\n           format = segyio.SegySampleFormat.IBM_FLOAT_4_BYTE,\n           copy = True):\n    \"\"\"Convert numpy array to native float\n\n    Converts a numpy array from raw segy trace data to native floats. Works for numpy ndarrays.\n\n    Parameters\n    ----------\n\n    data : numpy.ndarray\n    format : int or segyio.SegySampleFormat\n    copy : bool\n        If True, convert on a copy, and leave the input array unmodified\n\n    Returns\n    -------\n\n    data : numpy.ndarray\n\n    Notes\n    -----\n\n    .. versionadded:: 1.1\n\n    Examples\n    --------\n\n    Convert mmap'd trace to native float:\n\n    >>> d = np.memmap('file.sgy', offset = 3600, dtype = np.uintc)\n    >>> samples = 1500\n    >>> trace = segyio.tools.native(d[240:240+samples])\n\n    \"\"\"\n\n    data = data.view( dtype = np.single )\n    if copy:\n        data = np.copy( data )\n\n    format = int(segyio.SegySampleFormat(format))\n    return segyio._segyio.native(data, format)", "response": "Convert numpy array to native float. Works for numpy arrays."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cube(f):\n\n    if not isinstance(f, segyio.SegyFile):\n        with segyio.open(f) as fl:\n            return cube(fl)\n\n    ilsort = f.sorting == segyio.TraceSortingFormat.INLINE_SORTING\n    fast = f.ilines if ilsort else f.xlines\n    slow = f.xlines if ilsort else f.ilines\n    fast, slow, offs = len(fast), len(slow), len(f.offsets)\n    smps = len(f.samples)\n    dims = (fast, slow, smps) if offs == 1 else (fast, slow, offs, smps)\n    return f.trace.raw[:].reshape(dims)", "response": "Read a full cube from a segy file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfind the clock - wise rotation of the survey and the origin of the line.", "response": "def rotation(f, line = 'fast'):\n    \"\"\" Find rotation of the survey\n\n    Find the clock-wise rotation and origin of `line` as ``(rot, cdpx, cdpy)``\n\n    The clock-wise rotation is defined as the angle in radians between line\n    given by the first and last trace of the first line and the axis that gives\n    increasing CDP-Y, in the direction that gives increasing CDP-X.\n\n    By default, the first line is the 'fast' direction, which is inlines if the\n    file is inline sorted, and crossline if it's crossline sorted.\n\n\n    Parameters\n    ----------\n\n    f : SegyFile\n    line : { 'fast', 'slow', 'iline', 'xline' }\n\n    Returns\n    -------\n\n    rotation : float\n    cdpx : int\n    cdpy : int\n\n\n    Notes\n    -----\n\n    .. versionadded:: 1.2\n\n    \"\"\"\n\n    if f.unstructured:\n        raise ValueError(\"Rotation requires a structured file\")\n\n    lines = { 'fast': f.fast,\n              'slow': f.slow,\n              'iline': f.iline,\n              'xline': f.xline,\n            }\n\n    if line not in lines:\n        error = \"Unknown line {}\".format(line)\n        solution = \"Must be any of: {}\".format(' '.join(lines.keys()))\n        raise ValueError('{} {}'.format(error, solution))\n\n    l = lines[line]\n    origin = f.header[0][segyio.su.cdpx, segyio.su.cdpy]\n    cdpx, cdpy = origin[segyio.su.cdpx], origin[segyio.su.cdpy]\n\n    rot = f.xfd.rotation( len(l),\n                          l.stride,\n                          len(f.offsets),\n                          np.fromiter(l.keys(), dtype = np.intc) )\n    return rot, cdpx, cdpy"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef resample(f, rate = None, delay = None, micro = False,\n                                           trace = True,\n                                           binary = True):\n    \"\"\"Resample a file\n\n    Resample all data traces, and update the file handle to reflect the new\n    sample rate. No actual samples (data traces) are modified, only the header\n    fields and interpretation.\n\n    By default, the rate and the delay are in millseconds - if you need higher\n    resolution, passing micro=True interprets rate as microseconds (as it is\n    represented in the file). Delay is always milliseconds.\n\n    By default, both the global binary header and the trace headers are updated\n    to reflect this. If preserving either the trace header interval field or\n    the binary header interval field is important, pass trace=False and\n    binary=False respectively, to not have that field updated. This only apply\n    to sample rates - the recording delay is only found in trace headers and\n    will be written unconditionally, if delay is not None.\n\n    .. warning::\n        This function requires an open file handle and is **DESTRUCTIVE**. It\n        will modify the file, and if an exception is raised then partial writes\n        might have happened and the file might be corrupted.\n\n    This function assumes all traces have uniform delays and frequencies.\n\n    Parameters\n    ----------\n\n    f : SegyFile\n    rate : int\n    delay : int\n    micro : bool\n        if True, interpret rate as microseconds\n    trace : bool\n        Update the trace header if True\n    binary : bool\n        Update the binary header if True\n\n    Notes\n    -----\n\n    .. versionadded:: 1.4\n\n    \"\"\"\n\n    if rate is not None:\n        if not micro: rate *= 1000\n\n        if binary: f.bin[segyio.su.hdt] = rate\n        if trace: f.header = { segyio.su.dt: rate}\n\n    if delay is not None:\n        f.header = { segyio.su.delrt: delay }\n\n    t0 = delay if delay is not None else f.samples[0]\n    rate = rate / 1000 if rate is not None else f.samples[1] - f.samples[0]\n\n    f._samples = (np.arange(len(f.samples)) * rate) + t0\n\n    return f", "response": "Resample a file and update the header and binary header fields of the new file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_array(filename, data, iline=189,\n                               xline=193,\n                               format=SegySampleFormat.IBM_FLOAT_4_BYTE,\n                               dt=4000,\n                               delrt=0):\n    \"\"\" Create a new SEGY file from an n-dimentional array. Create a structured\n    SEGY file with defaulted headers from a 2-, 3- or 4-dimensional array.\n    ilines, xlines, offsets and samples are inferred from the size of the\n    array. Please refer to the documentation for functions from_array2D,\n    from_array3D and from_array4D to see how the arrays are interpreted.\n\n    Structure-defining fields in the binary header and in the traceheaders are\n    set accordingly. Such fields include, but are not limited to iline, xline\n    and offset. The file also contains a defaulted textual header.\n\n    Parameters\n    ----------\n    filename : string-like\n        Path to new file\n    data : 2-,3- or 4-dimensional array-like\n    iline : int or segyio.TraceField\n        Inline number field in the trace headers. Defaults to 189 as per the\n        SEG-Y rev1 specification\n    xline : int or segyio.TraceField\n        Crossline number field in the trace headers. Defaults to 193 as per the\n        SEG-Y rev1 specification\n    format : int or segyio.SegySampleFormat\n        Sample format field in the trace header. Defaults to IBM float 4 byte\n    dt : int-like\n        sample interval\n    delrt : int-like\n\n    Notes\n    -----\n    .. versionadded:: 1.8\n\n    Examples\n    --------\n    Create a file from a 3D array, open it and read an iline:\n\n    >>> segyio.tools.from_array(path, array3d)\n    >>> segyio.open(path, mode) as f:\n    ...     iline = f.iline[0]\n    ...\n    \"\"\"\n\n    dt = int(dt)\n    delrt = int(delrt)\n\n    data = np.asarray(data)\n    dimensions = len(data.shape)\n\n    if dimensions not in range(2, 5):\n        problem = \"Expected 2, 3, or 4 dimensions, {} was given\".format(dimensions)\n        raise ValueError(problem)\n\n    spec = segyio.spec()\n    spec.iline   = iline\n    spec.xline   = xline\n    spec.format  = format\n    spec.sorting = TraceSortingFormat.INLINE_SORTING\n\n    if dimensions == 2:\n        spec.ilines  = [1]\n        spec.xlines  = list(range(1, np.size(data,0) + 1))\n        spec.samples = list(range(np.size(data,1)))\n        spec.tracecount = np.size(data, 1)\n\n    if dimensions == 3:\n        spec.ilines  = list(range(1, np.size(data, 0) + 1))\n        spec.xlines  = list(range(1, np.size(data, 1) + 1))\n        spec.samples = list(range(np.size(data, 2)))\n\n    if dimensions == 4:\n        spec.ilines  = list(range(1, np.size(data, 0) + 1))\n        spec.xlines  = list(range(1, np.size(data, 1) + 1))\n        spec.offsets = list(range(1, np.size(data, 2)+ 1))\n        spec.samples = list(range(np.size(data,3)))\n\n    samplecount = len(spec.samples)\n\n    with segyio.create(filename, spec) as f:\n        tr = 0\n        for ilno, il in enumerate(spec.ilines):\n            for xlno, xl in enumerate(spec.xlines):\n                for offno, off in enumerate(spec.offsets):\n                    f.header[tr] = {\n                        segyio.su.tracf  : tr,\n                        segyio.su.cdpt   : tr,\n                        segyio.su.offset : off,\n                        segyio.su.ns     : samplecount,\n                        segyio.su.dt     : dt,\n                        segyio.su.delrt  : delrt,\n                        segyio.su.iline  : il,\n                        segyio.su.xline  : xl\n                    }\n                    if dimensions == 2: f.trace[tr] = data[tr, :]\n                    if dimensions == 3: f.trace[tr] = data[ilno, xlno, :]\n                    if dimensions == 4: f.trace[tr] = data[ilno, xlno, offno, :]\n                    tr += 1\n\n        f.bin.update(\n            tsort=TraceSortingFormat.INLINE_SORTING,\n            hdt=dt,\n            dto=dt\n        )", "response": "Create a new SEGY file from an n - dimensional array."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_array3D(filename, data, iline=189,\n                                 xline=193,\n                                 format=SegySampleFormat.IBM_FLOAT_4_BYTE,\n                                 dt=4000,\n                                 delrt=0):\n    \"\"\" Create a new SEGY file from a 3D array\n    Create an structured SEGY file with defaulted headers from a 3-dimensional\n    array. The file is inline-sorted. ilines, xlines and samples are inferred\n    from the array. Structure-defining fields in the binary header and\n    in the traceheaders are set accordingly. Such fields include, but are not\n    limited to iline, xline and offset. The file also contains a defaulted\n    textual header.\n\n    The 3-dimensional array is interpreted as::\n\n             xl0   xl1   xl2\n            -----------------\n         / | tr0 | tr1 | tr2 | il0\n           -----------------\n       | / | tr3 | tr4 | tr5 | il1\n            -----------------\n       | / | tr6 | tr7 | tr8 | il2\n            -----------------\n       | /      /     /     / n-samples\n         ------------------\n\n    ilines =  [1, len(axis(0) + 1]\n    xlines =  [1, len(axis(1) + 1]\n    samples = [0, len(axis(2)]\n\n    Parameters\n    ----------\n    filename : string-like\n        Path to new file\n    data : 3-dimensional array-like\n    iline : int or segyio.TraceField\n        Inline number field in the trace headers. Defaults to 189 as per the\n        SEG-Y rev1 specification\n    xline : int or segyio.TraceField\n        Crossline number field in the trace headers. Defaults to 193 as per the\n        SEG-Y rev1 specification\n    format : int or segyio.SegySampleFormat\n        Sample format field in the trace header. Defaults to IBM float 4 byte\n    dt : int-like\n        sample interval\n    delrt : int-like\n\n    Notes\n    -----\n    .. versionadded:: 1.8\n\n    Examples\n    --------\n    Create a file from a 3D array, open it and read an iline:\n\n    >>> segyio.tools.from_array3D(path, array3d)\n    >>> segyio.open(path, mode) as f:\n    ...     iline = f.iline[0]\n    ...\n    \"\"\"\n\n    data = np.asarray(data)\n    dimensions = len(data.shape)\n\n    if dimensions != 3:\n        problem = \"Expected 3 dimensions, {} was given\".format(dimensions)\n        raise ValueError(problem)\n\n    from_array(filename, data, iline=iline, xline=xline, format=format,\n                                                         dt=dt,\n                                                         delrt=delrt)", "response": "Create a new SEGY file from a 3D array."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef open(filename, mode=\"r\", iline = 189,\n                             xline = 193,\n                             strict = True,\n                             ignore_geometry = False,\n                             endian = 'big'):\n    \"\"\"Open a segy file.\n\n    Opens a segy file and tries to figure out its sorting, inline numbers,\n    crossline numbers, and offsets, and enables reading and writing to this\n    file in a simple manner.\n\n    For reading, the access mode `r` is preferred. All write operations will\n    raise an exception. For writing, the mode `r+` is preferred (as `rw` would\n    truncate the file). Any mode with `w` will raise an error. The modes used\n    are standard C file modes; please refer to that documentation for a\n    complete reference.\n\n    Open should be used together with python's ``with`` statement. Please refer\n    to the examples. When the ``with`` statement is used the file will\n    automatically be closed when the routine completes or an exception is\n    raised.\n\n    By default, segyio tries to open in ``strict`` mode. This means the file will\n    be assumed to represent a geometry with consistent inline, crosslines and\n    offsets. If strict is False, segyio will still try to establish a geometry,\n    but it won't abort if it fails. When in non-strict mode is opened,\n    geometry-dependent modes such as iline will raise an error.\n\n    If ``ignore_geometry=True``, segyio will *not* try to build iline/xline or\n    other geometry related structures, which leads to faster opens. This is\n    essentially the same as using ``strict=False`` on a file that has no\n    geometry.\n\n    Parameters\n    ----------\n\n    filename : str\n        Path to file to open\n\n    mode : {'r', 'r+'}\n        File access mode, read-only ('r', default) or read-write ('r+')\n\n    iline : int or segyio.TraceField\n        Inline number field in the trace headers. Defaults to 189 as per the\n        SEG-Y rev1 specification\n\n    xline : int or segyio.TraceField\n        Crossline number field in the trace headers. Defaults to 193 as per the\n        SEG-Y rev1 specification\n\n    strict : bool, optional\n        Abort if a geometry cannot be inferred. Defaults to True.\n\n    ignore_geometry : bool, optional\n        Opt out on building geometry information, useful for e.g. shot\n        organised files. Defaults to False.\n\n    endian : {'big', 'msb', 'little', 'lsb'}\n        File endianness, big/msb (default) or little/lsb\n\n    Returns\n    -------\n\n    file : segyio.SegyFile\n        An open segyio file handle\n\n    Raises\n    ------\n\n    ValueError\n        If the mode string contains 'w', as it would truncate the file\n\n    Notes\n    -----\n\n    .. versionadded:: 1.1\n\n    .. versionchanged:: 1.8\n        endian argument\n\n    When a file is opened non-strict, only raw traces access is allowed, and\n    using modes such as ``iline`` raise an error.\n\n\n    Examples\n    --------\n\n    Open a file in read-only mode:\n\n    >>> with segyio.open(path, \"r\") as f:\n    ...     print(f.ilines)\n    ...\n    [1, 2, 3, 4, 5]\n\n    Open a file in read-write mode:\n\n    >>> with segyio.open(path, \"r+\") as f:\n    ...     f.trace = np.arange(100)\n\n    Open two files at once:\n\n    >>> with segyio.open(path) as src, segyio.open(path, \"r+\") as dst:\n    ...     dst.trace = src.trace # copy all traces from src to dst\n\n    Open a file little-endian file:\n\n    >>> with segyio.open(path, endian = 'little') as f:\n    ...     f.trace[0]\n\n    \"\"\"\n\n    if 'w' in mode:\n        problem = 'w in mode would truncate the file'\n        solution = 'use r+ to open in read-write'\n        raise ValueError(', '.join((problem, solution)))\n\n    endians = {\n        'little': 256, # (1 << 8)\n        'lsb': 256,\n        'big': 0,\n        'msb': 0,\n    }\n\n    if endian not in endians:\n        problem = 'unknown endianness {}, expected one of: '\n        opts = ' '.join(endians.keys())\n        raise ValueError(problem.format(endian) + opts)\n\n    from . import _segyio\n    fd = _segyio.segyiofd(str(filename), mode, endians[endian])\n    fd.segyopen()\n    metrics = fd.metrics()\n\n    f = segyio.SegyFile(fd,\n            filename = str(filename),\n            mode = mode,\n            iline = iline,\n            xline = xline,\n            endian = endian,\n    )\n\n    try:\n        dt = segyio.tools.dt(f, fallback_dt = 4000.0) / 1000.0\n        t0 = f.header[0][segyio.TraceField.DelayRecordingTime]\n        samples = metrics['samplecount']\n        f._samples = (numpy.arange(samples) * dt) + t0\n\n    except:\n        f.close()\n        raise\n\n    if ignore_geometry:\n        return f\n\n    return infer_geometry(f, metrics, iline, xline, strict)", "response": "Open a segy file and return a new object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfetch the contents of the trace header from disk.", "response": "def fetch(self, buf = None, traceno = None):\n        \"\"\"Fetch the header from disk\n\n        This object will read header when it is constructed, which means it\n        might be out-of-date if the file is updated through some other handle.\n        This method is largely meant for internal use - if you need to reload\n        disk contents, use ``reload``.\n\n        Fetch does not update any internal state (unless `buf` is ``None`` on a\n        trace header, and the read succeeds), but returns the fetched header\n        contents.\n\n        This method can be used to reposition the trace header, which is useful\n        for constructing generators.\n\n        If this is called on a writable, new file, and this header has not yet\n        been written to, it will successfully return an empty buffer that, when\n        written to, will be reflected on disk.\n\n        Parameters\n        ----------\n        buf     : bytearray\n            buffer to read into instead of ``self.buf``\n        traceno : int\n\n        Returns\n        -------\n        buf : bytearray\n\n        Notes\n        -----\n        .. versionadded:: 1.6\n\n        This method is not intended as user-oriented functionality, but might\n        be useful in high-performance code.\n        \"\"\"\n\n        if buf is None:\n            buf = self.buf\n\n        if traceno is None:\n            traceno = self.traceno\n\n        try:\n            if self.kind == TraceField:\n                if traceno is None: return buf\n                return self.filehandle.getth(traceno, buf)\n            else:\n                return self.filehandle.getbin()\n        except IOError:\n            if not self.readonly:\n                # the file was probably newly created and the trace header\n                # hasn't been written yet, and we set the buffer to zero. if\n                # this is the case we want to try and write it later, and if\n                # the file was broken, permissions were wrong etc writing will\n                # fail too\n                #\n                # if the file is opened read-only and this happens, there's no\n                # way to actually write and the error is an actual error\n                return bytearray(len(self.buf))\n            else: raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreloads the internal cache of the internal cache of the current segment.", "response": "def reload(self):\n        \"\"\"\n        This object will read header when it is constructed, which means it\n        might be out-of-date if the file is updated through some other handle.\n\n        It's rarely required to call this method, and it's a symptom of fragile\n        code. However, if you have multiple handles to the same header, it\n        might be necessary. Consider the following example::\n\n            >>> x = f.header[10]\n            >>> y = f.header[10]\n            >>> x[1, 5]\n            { 1: 5, 5: 10 }\n            >>> y[1, 5]\n            { 1: 5, 5: 10 }\n            >>> x[1] = 6\n            >>> x[1], y[1] # write to x[1] is invisible to y\n            6, 5\n            >>> y.reload()\n            >>> x[1], y[1]\n            6, 6\n            >>> x[1] = 5\n            >>> x[1], y[1]\n            5, 6\n            >>> y[5] = 1\n            >>> x.reload()\n            >>> x[1], y[1, 5] # the write to x[1] is lost\n            6, { 1: 6; 5: 1 }\n\n        In segyio, headers writes are atomic, and the write to disk writes the\n        full cache. If this cache is out of date, some writes might get lost,\n        even though the updates are compatible.\n\n        The fix to this issue is either to use ``reload`` and maintain buffer\n        consistency, or simply don't let header handles alias and overlap in\n        lifetime.\n\n        Notes\n        -----\n        .. versionadded:: 1.6\n        \"\"\"\n\n        self.buf = self.fetch(buf = self.buf)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef flush(self):\n\n        if self.kind == TraceField:\n            self.filehandle.putth(self.traceno, self.buf)\n\n        elif self.kind == BinField:\n            self.filehandle.putbin(self.buf)\n\n        else:\n            msg = 'Object corrupted: kind {} not valid'\n            raise RuntimeError(msg.format(self.kind))", "response": "Commit backing storage to disk."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update(self, *args, **kwargs):\n\n        if len(args) > 1:\n            msg = 'update expected at most 1 non-keyword argument, got {}'\n            raise TypeError(msg.format(len(args)))\n\n        buf = bytearray(self.buf)\n\n        # Implementation largely borrowed from collections.mapping\n        # If E present and has a .keys() method: for k in E: D[k] = E[k]\n        # If E present and lacks .keys() method: for (k, v) in E: D[k] = v\n        # In either case, this is followed by: for k, v in F.items(): D[k] = v\n        if len(args) == 1:\n            other = args[0]\n            if isinstance(other, collections.Mapping):\n                for key in other:\n                    self.putfield(buf, int(key), other[key])\n            elif hasattr(other, \"keys\"):\n                for key in other.keys():\n                    self.putfield(buf, int(key), other[key])\n            else:\n                for key, value in other:\n                    self.putfield(buf, int(key), value)\n\n        for key, value in kwargs.items():\n            self.putfield(buf, int(self._kwargs[key]), value)\n\n        self.buf = buf\n        self.flush()", "response": "Update the dictionary d with the values from E and F."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef raw(self):\n        return RawTrace(self.filehandle,\n                        self.dtype,\n                        len(self),\n                        self.shape,\n                        self.readonly,\n                       )", "response": "Returns a copy of the current Trace object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ref(self):\n\n        x = RefTrace(self.filehandle,\n                     self.dtype,\n                     len(self),\n                     self.shape,\n                     self.readonly,\n                    )\n        yield x\n        x.flush()", "response": "A write - back version of Trace\n           ."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncommits cached writes to the file handle.", "response": "def flush(self):\n        \"\"\"\n        Commit cached writes to the file handle. Does not flush libc buffers or\n        notifies the kernel, so these changes may not immediately be visible to\n        other processes.\n\n        Updates the fingerprints whena writes happen, so successive ``flush()``\n        invocations are no-ops.\n\n        It is not necessary to call this method in user code.\n\n        Notes\n        -----\n        .. versionadded:: 1.6\n\n        This method is not intended as user-oriented functionality, but might\n        be useful in certain contexts to provide stronger guarantees.\n        \"\"\"\n        garbage = []\n        for i, (x, signature) in self.refs.items():\n            if sys.getrefcount(x) == 3:\n                garbage.append(i)\n\n            if fingerprint(x) == signature: continue\n\n            self.filehandle.puttr(i, x)\n            signature = fingerprint(x)\n\n\n        # to avoid too many resource leaks, when this dict is the only one\n        # holding references to already-produced traces, clear them\n        for i in garbage:\n            del self.refs[i]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwriting iterables to lines", "response": "def iline(self, value):\n        \"\"\"Write iterables to lines\n\n        Examples:\n            Supports writing to *all* crosslines via assignment, regardless of\n            data source and format. Will respect the sample size and structure\n            of the file being assigned to, so if the argument traces are longer\n            than that of the file being written to the surplus data will be\n            ignored. Uses same rules for writing as `f.iline[i] = x`.\n        \"\"\"\n        for i, src in zip(self.segy.ilines, value):\n            self.iline[i] = src"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef xline(self, value):\n\n        for i, src in zip(self.segy.xlines, value):\n            self.xline[i] = src", "response": "Write iterables to lines\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the iline object for the current segment in inline mode.", "response": "def iline(self):\n        \"\"\"\n        Interact with segy in inline mode\n\n        Returns\n        -------\n        iline : Line or None\n\n        Raises\n        ------\n        ValueError\n            If the file is unstructured\n\n        Notes\n        -----\n        .. versionadded:: 1.1\n        \"\"\"\n\n        if self.unstructured:\n            raise ValueError(self._unstructured_errmsg)\n\n        if self._iline is not None:\n            return self._iline\n\n        self._iline = Line(self,\n                           self.ilines,\n                           self._iline_length,\n                           self._iline_stride,\n                           self.offsets,\n                           'inline',\n                          )\n        return self._iline"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef xline(self):\n        if self.unstructured:\n            raise ValueError(self._unstructured_errmsg)\n\n        if self._xline is not None:\n            return self._xline\n\n        self._xline = Line(self,\n                           self.xlines,\n                           self._xline_length,\n                           self._xline_stride,\n                           self.offsets,\n                           'crossline',\n                          )\n        return self._xline", "response": "Return the xline of the file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\naccess the fast dimension of the log entry.", "response": "def fast(self):\n        \"\"\"Access the 'fast' dimension\n\n        This mode yields iline or xline mode, depending on which one is laid\n        out `faster`, i.e. the line with linear disk layout. Use this mode if\n        the inline/crossline distinction isn't as interesting as traversing in\n        a fast manner (typically when you want to apply a function to the whole\n        file, line-by-line).\n\n        Returns\n        -------\n        fast : Line\n            line addressing mode\n\n        Notes\n        -----\n        .. versionadded:: 1.1\n        \"\"\"\n        if self.sorting == TraceSortingFormat.INLINE_SORTING:\n            return self.iline\n        elif self.sorting == TraceSortingFormat.CROSSLINE_SORTING:\n            return self.xline\n        else:\n            raise RuntimeError(\"Unknown sorting.\")"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef depth_slice(self):\n\n        if self.depth is not None:\n            return self.depth\n\n        from .depth import Depth\n        self.depth = Depth(self)\n        return self.depth", "response": "Interact with segy in depth slice mode"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef gather(self):\n        if self.unstructured:\n            raise ValueError(self._unstructured_errmsg)\n\n        if self._gather is not None:\n            return self._gather\n\n        self._gather = Gather(self.trace, self.iline, self.xline, self.offsets)\n        return self._gather", "response": "Returns a Gather object for the current segment."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef interpret(self, ilines, xlines, offsets=None, sorting=TraceSortingFormat.INLINE_SORTING):\n\n        \"\"\" (Re-)interpret structure on top of a file\n\n        (Re-)interpret the structure of the file given the new sorting, ilines,\n        xlines and offset indices. Note that file itself is not changed in any\n        way, it is only segyio's interpretation of the file that changes. It's\n        a way of telling segyio that a file is laid out in a particular way,\n        even though the header fields say otherwise.\n\n        `interpret` expect that the ilines-, xlines- and offsets-indices are\n        unique. It also expect the dimensions of ilines, xlines and offset to\n        match the tracecount.\n\n        Parameters\n        ----------\n        f : SegyFile\n        ilines : array_like\n            ilines indices in new structure\n        xlines : array_like\n            xlines indices in new structure\n        offsets : array_like\n            offset indices in new structure\n        sorting : int, string or TraceSortingFormat\n            Sorting in new structure\n\n        Notes\n        -----\n\n        .. versionadded:: 1.8\n\n        Examples\n        --------\n        (Re)interpret the structure of the file:\n\n        >>> ilines = [10, 11, 12, 13]\n        >>> xlines = [20, 21, 22, 23, 24]\n        >>> with segyio.open(file, ignore_geometry=True) as f:\n        ... f.interpret(ilines, xlines)\n        \"\"\"\n\n        valid_sortings = {\n            1           : TraceSortingFormat.CROSSLINE_SORTING,\n            2           : TraceSortingFormat.INLINE_SORTING,\n            'iline'     : TraceSortingFormat.INLINE_SORTING,\n            'inline'    : TraceSortingFormat.INLINE_SORTING,\n            'xl'        : TraceSortingFormat.CROSSLINE_SORTING,\n            'crossline' : TraceSortingFormat.CROSSLINE_SORTING,\n            TraceSortingFormat.INLINE_SORTING    : TraceSortingFormat.INLINE_SORTING,\n            TraceSortingFormat.CROSSLINE_SORTING : TraceSortingFormat.CROSSLINE_SORTING,\n        }\n\n        if sorting not in valid_sortings:\n            error = \"Invalid sorting\"\n            solution = \"valid sorting options are: {}\".format(valid_sortings.keys())\n            raise ValueError('{}, {}'.format(error, solution))\n\n        if offsets is None:\n            offsets = np.arange(1)\n\n        ilines  = np.copy(np.asarray(ilines,  dtype=np.intc))\n        xlines  = np.copy(np.asarray(xlines,  dtype=np.intc))\n        offsets = np.copy(np.asarray(offsets, dtype=np.intc))\n\n        if np.unique(ilines).size != ilines.size:\n            error = \"Inlines inconsistent\"\n            solution = \"expect all inlines to be unique\"\n            raise ValueError(\"{}, {}\".format(error, solution))\n\n        if np.unique(xlines).size != xlines.size:\n            error = \"Crosslines inconsistent\"\n            solution = \"expect all crosslines to be unique\"\n            raise ValueError(\"{}, {}\".format(error, solution))\n\n        if np.unique(offsets).size != offsets.size:\n            error = \"Offsets inconsistent\"\n            solution = \"expect all offsets to be unique\"\n            raise ValueError(\"{}, {}\".format(error, solution))\n\n        if ilines.size * xlines.size * offsets.size != self.tracecount:\n            error = (\"Invalid dimensions, ilines ({}) * xlines ({}) * offsets \"\n                     \"({}) should match the number of traces ({})\").format(ilines.size,\n                                                                           xlines.size,\n                                                                           offsets.size,\n                                                                           self.tracecount)\n            raise ValueError(error)\n\n        from . import _segyio\n\n        line_metrics = _segyio.line_metrics(sorting,\n                                            self.tracecount,\n                                            ilines.size,\n                                            xlines.size,\n                                            offsets.size)\n\n        self._iline_length = line_metrics['iline_length']\n        self._iline_stride = line_metrics['iline_stride']\n\n        self._xline_length = line_metrics['xline_length']\n        self._xline_stride = line_metrics['xline_stride']\n\n        self._sorting = sorting\n        self._offsets = offsets\n        self._ilines = ilines\n        self._xlines = xlines\n\n        return self", "response": "Interpret the contents of a file and return a new set of tracecount entries."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef moral_graph(model, format='raw', prog='dot', path=None, name=None):\n    if not pydot_imported:\n        raise ImportError(\n            'PyDot must be installed to use the moral_graph function.\\n PyDot is available from http://dkbza.org/pydot.html')\n\n    model.moral_dot_object = pydot.Dot()\n\n    # Data are filled ellipses\n    for datum in model.observed_stochastics:\n        model.moral_dot_object.add_node(\n            pydot.Node(name=datum.__name__,\n                       style='filled'))\n\n    # Stochastics are open ellipses\n    for s in model.stochastics:\n        model.moral_dot_object.add_node(pydot.Node(name=s.__name__))\n\n    gone_already = set()\n    for s in model.stochastics | model.observed_stochastics:\n        gone_already.add(s)\n        for other_s in s.moral_neighbors:\n            if not other_s in gone_already:\n                model.moral_dot_object.add_edge(\n                    pydot.Edge(src=other_s.__name__,\n                               dst=s.__name__,\n                               arrowhead='none'))\n\n    # Draw the graph\n    ext = format\n    if format == 'raw':\n        ext = 'dot'\n    if name is None:\n        name = model.__name__\n    name = name + '.' + ext\n    if not path is None:\n        model.moral_dot_object.write(\n            path=os.path.join(path,\n                              name),\n            format=format,\n            prog=prog)\n    else:\n        model.moral_dot_object.write(\n            path='./' +\n            name,\n            format=format,\n            prog=prog)\n\n    return model.moral_dot_object", "response": "Returns the graph of the model and writes it to path with filename name."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef graph(\n    model, format='raw', prog='dot', path=None, name=None, consts=False, legend=False,\n        collapse_deterministics=False, collapse_potentials=False, label_edges=True):\n    \"\"\"\n    graph(  model,\n            format='raw',\n            prog='dot',\n            path=None,\n            name=None,\n            consts=False,\n            legend=True,\n            collapse_deterministics = False,\n            collapse_potentials = False)\n\n    Draws the graph for this model and writes it to path with filename name.\n    Returns the pydot 'dot' object for further user manipulation.\n\n    GraphViz and PyDot must be installed to use this function.\n\n    :Parameters:\n      model : PyMC Model instance\n      format : string\n        'ps', 'ps2', 'hpgl', 'pcl', 'mif', 'pic', 'gd', 'gd2', 'gif', 'jpg',\n        'jpeg', 'png', 'wbmp', 'ismap', 'imap', 'cmap', 'cmapx', 'vrml', 'vtx', 'mp',\n        'fig', 'svg', 'svgz', 'dia', 'dot', 'canon', 'plain', 'plain-ext', 'xdot'\n      prog : string\n        'dot', 'neato'\n      path : string\n        If model.__name__ is defined and path is None, the output file is\n        ./'name'.'format'.\n      consts : boolean\n        If True, constant parents are included in the graph.\n      legend : boolean\n        If True, a graph legend is created.\n      collapse_deterministics : boolean\n        If True, all deterministic dependencies are collapsed.\n      collapse_potentials : boolean\n        If True, all potentials are converted to undirected edges.\n    \"\"\"\n\n    if not pydot_imported:\n        raise ImportError(\n            'PyDot must be installed to use the graph function.\\n PyDot is available from http://dkbza.org/pydot.html')\n    pydot_nodes = {}\n    pydot_subgraphs = {}\n    obj_substitute_names = {}\n    shown_objects = set([])\n    model.dot_object = pydot.Dot()\n\n    def get_obj_names(obj, key):\n\n        if isinstance(obj, Stochastic):\n            if obj in obj_substitute_names:\n                return obj_substitute_names[obj]\n            if obj.observed:\n                datum = obj\n                # Data are filled ellipses\n                pydot_nodes[\n                    datum] = pydot.Node(\n                        name=datum.__name__,\n                        style='filled')\n                model.dot_object.add_node(pydot_nodes[datum])\n                shown_objects.add(datum)\n                obj_substitute_names[datum] = [datum.__name__]\n            else:\n                s = obj\n                # Stochastics are open ellipses\n                pydot_nodes[s] = pydot.Node(name=s.__name__)\n                model.dot_object.add_node(pydot_nodes[s])\n                shown_objects.add(s)\n                obj_substitute_names[s] = [s.__name__]\n\n        elif isinstance(obj, Deterministic):\n            if obj in obj_substitute_names:\n                return obj_substitute_names[obj]\n            d = obj\n            # Deterministics are downward-pointing triangles\n            if not collapse_deterministics:\n                pydot_nodes[\n                    d] = pydot.Node(\n                        name=d.__name__,\n                        shape='invtriangle')\n                model.dot_object.add_node(pydot_nodes[d])\n                shown_objects.add(d)\n                obj_substitute_names[d] = [d.__name__]\n            else:\n                obj_substitute_names[d] = []\n\n        elif isinstance(obj, Potential):\n            if obj in obj_substitute_names:\n                return obj_substitute_names[obj]\n            potential = obj\n            # Potentials are squares\n            if not collapse_potentials:\n                pydot_nodes[\n                    potential] = pydot.Node(\n                        name=potential.__name__,\n                        shape='box')\n                model.dot_object.add_node(pydot_nodes[potential])\n                shown_objects.add(potential)\n                obj_substitute_names[potential] = [potential.__name__]\n            else:\n                obj_substitute_names[potential] = []\n\n        elif consts:\n            if key in obj_substitute_names:\n                return\n            else:\n                obj_substitute_names[key] = [key]\n                model.dot_object.add_node(pydot.Node(name=key, style='filled'))\n                return\n\n        else:\n            return\n\n        return obj_substitute_names[obj]\n\n    connected = []\n\n    def maybe_connect_parent(src, dst, label):\n        if (src, dst, label) in connected:\n            return False\n        else:\n            connected.append((src, dst, label))\n            model.dot_object.add_edge(\n                pydot.Edge(src=src,\n                           dst=dst,\n                           label=label))\n            return True\n\n    def connect_parents(node):\n\n        if collapse_deterministics:\n            parent_tups = [(s.__name__, s) for s in node.extended_parents]\n            if consts:\n                parent_tups += filter(\n                    lambda x: not isinstance(x[1],\n                                             Variable),\n                    node.parents.items())\n            parent_dict = dict(parent_tups)\n        else:\n            parent_dict = node.parents\n\n        for key in parent_dict:\n            key_val = parent_dict[key]\n            label = label_edges * key or ''\n\n            if hasattr(key_val, '__name__'):\n                const_node_name = key_val.__name__\n            elif len(key_val.__str__()) <= 10:\n                const_node_name = key_val.__str__()\n            else:\n                const_node_name = key_val.__class__.__name__\n\n            if isinstance(key_val, Variable):\n                if any([maybe_connect_parent(name, node.__name__, label)\n                        for name in get_obj_names(key_val, None)]):\n                    connect_parents(key_val)\n\n            elif isinstance(key_val, ContainerBase):\n                for var in key_val.variables:\n                    if any([maybe_connect_parent(name, node.__name__, label)\n                            for name in get_obj_names(var, None)]):\n                        connect_parents(var)\n\n            elif consts:\n                get_obj_names(key_val, const_node_name)\n                maybe_connect_parent(const_node_name, node.__name__, label)\n\n    # Create edges from parent-child relationships between nodes.\n    if collapse_potentials:\n        shownodes = model.variables\n    else:\n        shownodes = model.nodes\n\n    for node in shownodes:\n        get_obj_names(node, None)\n        if node in shown_objects:\n            connect_parents(node)\n\n    if collapse_potentials:\n        for potential in model.potentials:\n            if collapse_deterministics:\n                potential_parents = set()\n                for p in potential.extended_parents:\n                    potential_parents.update(get_obj_names(p, None))\n            else:\n                potential_parents = set()\n                for parent in potential.parents.values():\n                    if isinstance(parent, Variable):\n                        potential_parents |= set(get_obj_names(parent, None))\n                    elif isinstance(parent, ContainerBase):\n                        for ult_parent in parent.variables:\n                            potential_parents |= set(\n                                get_obj_names(parent,\n                                              None))\n            remaining_parents = copy(potential_parents)\n            for p1 in potential_parents:\n                remaining_parents.discard(p1)\n                for p2 in remaining_parents:\n                    new_edge = pydot.Edge(\n                        src=p2,\n                        dst=p1,\n                        label=potential.__name__,\n                        arrowhead='none')\n                    model.dot_object.add_edge(new_edge)\n\n    # Add legend if requested\n    if legend:\n        legend = pydot.Cluster(graph_name='Legend', label='Legend')\n        legend.add_node(pydot.Node(name='data', style='filled'))\n        legend.add_node(pydot.Node(name='stochastics'))\n        legend.add_node(pydot.Node(name='deterministics', shape='invtriangle'))\n        legend.add_node(pydot.Node(name='potentials', shape='box'))\n        if consts:\n            legend.add_node(pydot.Node(name='constants', style='filled'))\n        model.dot_object.add_subgraph(legend)\n\n    # Draw the graph\n    ext = format\n    if format == 'raw':\n        ext = 'dot'\n    if name is None:\n        name = model.__name__\n    name = name + '.' + ext\n    if not path is None:\n        model.dot_object.write(\n            path=os.path.join(path,\n                              name),\n            format=format,\n            prog=prog)\n    else:\n        model.dot_object.write(path='./' + name, format=format, prog=prog)\n\n    return model.dot_object", "response": "Returns a graph representation of the given model."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pick_best_methods(stochastic):\n\n    # Keep track of most competent methohd\n    max_competence = 0\n    # Empty set of appropriate StepMethods\n    best_candidates = set([])\n\n    # Loop over StepMethodRegistry\n    for method in StepMethodRegistry:\n\n        # Parse method and its associated competence\n        try:\n            competence = method.competence(stochastic)\n        except:\n            competence = 0\n\n        # If better than current best method, promote it\n        if competence > max_competence:\n            best_candidates = set([method])\n            max_competence = competence\n\n        # If same competence, add it to the set of best methods\n        elif competence == max_competence:\n            best_candidates.add(method)\n\n    if max_competence <= 0:\n        raise ValueError(\n            'Maximum competence reported for stochastic %s is <= 0... you may need to write a custom step method class.' %\n            stochastic.__name__)\n\n    # print_(s.__name__ + ': ', best_candidates, ' ', max_competence)\n    return best_candidates", "response": "Picks the StepMethods best suited to handle\n    a stochastic variable."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nassign a step method to a random a variable.", "response": "def assign_method(stochastic, scale=None, verbose=-1):\n    \"\"\"\n    Returns a step method instance to handle a\n    variable. If several methods have the same competence,\n    it picks one arbitrarily (using set.pop()).\n    \"\"\"\n\n    # Retrieve set of best candidates\n    best_candidates = pick_best_methods(stochastic)\n\n    # Randomly grab and appropriate method\n    method = best_candidates.pop()\n\n    failure_header = \"\"\"Failed attempting to automatically assign step method class %s\nto stochastic variable %s. Try setting %s's competence method to return 0\nand manually assigning it when appropriate. See the user guide.\n\nError message: \"\"\" % (method.__name__, stochastic.__name__, method.__name__)\n\n    try:\n        if scale:\n            out = method(stochastic, scale=scale, verbose=verbose)\n        else:\n            out = method(stochastic, verbose=verbose)\n    except:\n        a, b, c = sys.exc_info()\n        try:\n            args = list(b.args)\n        except AttributeError:\n            args = []\n        args.append(failure_header)\n        b.args = args\n        six.reraise(a, b, c)\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the summed log - probability of all stochastic variables that depend on self. stochastics removed.", "response": "def loglike(self):\n        '''\n        The summed log-probability of all stochastic variables that depend on\n        self.stochastics, with self.stochastics removed.\n        '''\n        sum = logp_of_set(self.children)\n        if self.verbose > 2:\n            print_('\\t' + self._id + ' Current log-likelihood ', sum)\n        return sum"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef logp_plus_loglike(self):\n        '''\n        The summed log-probability of all stochastic variables that depend on\n        self.stochastics, and self.stochastics.\n        '''\n        sum = logp_of_set(self.markov_blanket)\n        if self.verbose > 2:\n            print_('\\t' + self._id +\n                   ' Current log-likelihood plus current log-probability', sum)\n        return sum", "response": "Returns the summed log - probability of all stochastic variables that depend on self. markov_blanket and self. stochastics."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a dictionary with the current value of the variables defining the state of the step method.", "response": "def current_state(self):\n        \"\"\"Return a dictionary with the current value of the variables defining\n        the state of the step method.\"\"\"\n        state = {}\n        for s in self._state:\n            state[s] = getattr(self, s)\n        return state"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ratio():\n\n        def fget(self):\n            return self.accepted / (self.accepted + self.rejected)\n        return locals()", "response": "Returns the acceptance ratio of the current user."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef propose(self):\n    \n        prop_dist = self.proposal_distribution.lower()\n        if  prop_dist == \"normal\":\n            self.stochastic.value = rnormal(\n                self.stochastic.value,\n                self.adaptive_scale_factor *\n                self.proposal_sd,\n                size=self.stochastic.value.shape)\n        elif prop_dist == \"prior\":\n            self.stochastic.random()", "response": "This method is called by step to generate proposed values for a new item in the archive."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef tune(self, divergence_threshold=1e10, verbose=0):\n\n        if self.verbose > -1:\n            verbose = self.verbose\n\n        # Verbose feedback\n        if verbose > 0:\n            print_('\\t%s tuning:' % self._id)\n\n        # Flag for tuning state\n        tuning = True\n\n        # Calculate recent acceptance rate\n        if not (self.accepted + self.rejected):\n            return tuning\n        acc_rate = self.accepted / (self.accepted + self.rejected)\n        \n        current_factor = self.adaptive_scale_factor\n\n        # Switch statement\n        if acc_rate < 0.001:\n            # reduce by 90 percent\n            self.adaptive_scale_factor *= 0.1\n        elif acc_rate < 0.05:\n            # reduce by 50 percent\n            self.adaptive_scale_factor *= 0.5\n        elif acc_rate < 0.2:\n            # reduce by ten percent\n            self.adaptive_scale_factor *= 0.9\n        elif acc_rate > 0.95:\n            # increase by factor of ten\n            self.adaptive_scale_factor *= 10.0\n        elif acc_rate > 0.75:\n            # increase by double\n            self.adaptive_scale_factor *= 2.0\n        elif acc_rate > 0.5:\n            # increase by ten percent\n            self.adaptive_scale_factor *= 1.1\n        else:\n            tuning = False\n\n        # Re-initialize rejection count\n        self.rejected = 0.\n        self.accepted = 0.\n        \n        # Prevent from tuning to zero\n        if not self.adaptive_scale_factor:\n            self.adaptive_scale_factor = current_factor\n            return False\n\n        # More verbose feedback, if requested\n        if verbose > 0:\n            if hasattr(self, 'stochastic'):\n                print_('\\t\\tvalue:', self.stochastic.value)\n            print_('\\t\\tacceptance rate:', acc_rate)\n            print_('\\t\\tadaptive scale factor:', self.adaptive_scale_factor)\n            print_()\n\n        return tuning", "response": "Tune the scaling parameter for the proposal distribution of the current entry."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef competence(s):\n        # MatrixMetropolis handles the Wishart family, which are valued as\n        # _symmetric_ matrices.\n        if any([isinstance(s, cls)\n                for cls in [distributions.Wishart, distributions.WishartCov]]):\n            return 2\n        else:\n            return 0", "response": "The competence function for MatrixMetropolis."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef propose(self):\n\n        # Locally store size of matrix\n        dims = self.stochastic.value.shape\n\n        # Add normal deviate to value and symmetrize\n        dev = rnormal(\n            0,\n            self.adaptive_scale_factor *\n            self.proposal_sd,\n            size=dims)\n        symmetrize(dev)\n\n        # Replace\n        self.stochastic.value = dev + self.stochastic.value", "response": "Proposals for positive definite matrix using random walk deviations on Cholesky - specific factor."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef competence(stochastic):\n        if stochastic.dtype in bool_dtypes:\n            return 2\n\n        elif isinstance(stochastic, distributions.Bernoulli):\n            return 2\n            \n        elif (isinstance(stochastic, distributions.Categorical) and \n            (len(stochastic.parents['p'])==2)):\n            return 2\n\n        else:\n            return 0", "response": "The competence function for Binary One - At - A - Time Metropolis\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cov_from_value(self, scaling):\n        rv = []\n        for s in self.stochastics:\n            rv.extend(np.ravel(s.value).copy())\n\n        # Remove 0 values since this would lead to quite small jumps...\n        arv = np.array(rv)\n        arv[arv == 0] = 1.\n\n        # Create a diagonal covariance matrix using the scaling factor.\n        return np.eye(self.dim) * np.abs(arv) / scaling", "response": "Return a covariance matrix for the jump distribution using the actual value of the stochastic as a guess of their variance divided by the scaling argument."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a covariance matrix built from a dictionary of scales.", "response": "def cov_from_scales(self, scales):\n        \"\"\"Return a covariance matrix built from a dictionary of scales.\n\n        `scales` is a dictionary keyed by stochastic instances, and the\n        values refer are the variance of the jump distribution for each\n        stochastic. If a stochastic is a sequence, the variance must\n        have the same length.\n        \"\"\"\n\n        # Get array of scales\n        ord_sc = []\n        for stochastic in self.stochastics:\n            ord_sc.append(np.ravel(scales[stochastic]))\n        ord_sc = np.concatenate(ord_sc)\n\n        if np.squeeze(ord_sc).shape[0] != self.dim:\n            raise ValueError(\"Improper initial scales, dimension don't match\",\n                             (np.squeeze(ord_sc), self.dim))\n\n        # Scale identity matrix\n        return np.eye(self.dim) * ord_sc"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cov_from_trace(self, trace=slice(None)):\n        n = []\n        for s in self.stochastics:\n            n.append(s.trace.length())\n        n = set(n)\n        if len(n) > 1:\n            raise ValueError('Traces do not have the same length.')\n        elif n == 0:\n            raise AttributeError(\n                'Stochastic has no trace to compute covariance.')\n        else:\n            n = n.pop()\n\n        if not isinstance(trace, slice):\n            trace = slice(trace, n)\n\n        a = self.trace2array(trace)\n\n        return np.cov(a, rowvar=0)", "response": "Define the jump distribution covariance matrix from the object s stored trace."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef check_type(self):\n        self.isdiscrete = {}\n        for stochastic in self.stochastics:\n            if stochastic.dtype in integer_dtypes:\n                self.isdiscrete[stochastic] = True\n            elif stochastic.dtype in bool_dtypes:\n                raise ValueError(\n                    'Binary stochastics not supported by AdaptativeMetropolis.')\n            else:\n                self.isdiscrete[stochastic] = False", "response": "Make sure each stochastic has a correct type and identify discrete stochastics."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncomputes the dimension of the sampling space and identify the slices that are belonging to each stochastic.", "response": "def dimension(self):\n        \"\"\"Compute the dimension of the sampling space and identify the slices\n        belonging to each stochastic.\n        \"\"\"\n        self.dim = 0\n        self._slices = {}\n        for stochastic in self.stochastics:\n            if isinstance(stochastic.value, np.matrix):\n                p_len = len(stochastic.value.A.ravel())\n            elif isinstance(stochastic.value, np.ndarray):\n                p_len = len(stochastic.value.ravel())\n            else:\n                p_len = 1\n            self._slices[stochastic] = slice(self.dim, self.dim + p_len)\n            self.dim += p_len"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nperforming a Metropolis step.", "response": "def step(self):\n        \"\"\"\n        Perform a Metropolis step.\n\n        Stochastic parameters are block-updated using a multivariate normal\n        distribution whose covariance is updated every self.interval once\n        self.delay steps have been performed.\n\n        The AM instance keeps a local copy of the stochastic parameter's trace.\n        This trace is used to computed the empirical covariance, and is\n        completely independent from the Database backend.\n\n        If self.greedy is True and the number of iterations is smaller than\n        self.delay, only accepted jumps are stored in the internal\n        trace to avoid computing singular covariance matrices.\n        \"\"\"\n\n        # Probability and likelihood for stochastic's current value:\n        logp = self.logp_plus_loglike\n        if self.verbose > 1:\n            print_('Current value: ', self.stoch2array())\n            print_('Current likelihood: ', logp)\n\n        # Sample a candidate value\n        self.propose()\n\n        # Metropolis acception/rejection test\n        accept = False\n        try:\n            # Probability and likelihood for stochastic's proposed value:\n            logp_p = self.logp_plus_loglike\n            if self.verbose > 2:\n                print_('Current value: ', self.stoch2array())\n                print_('Current likelihood: ', logp_p)\n\n            if np.log(random()) < logp_p - logp:\n                accept = True\n                self.accepted += 1\n                if self.verbose > 2:\n                    print_('Accepted')\n            else:\n                self.rejected += 1\n                if self.verbose > 2:\n                    print_('Rejected')\n        except ZeroProbability:\n            self.rejected += 1\n            logp_p = None\n            if self.verbose > 2:\n                print_('Rejected with ZeroProbability Error.')\n\n        if (not self._current_iter % self.interval) and self.verbose > 1:\n            print_(\"Step \", self._current_iter)\n            print_(\"\\tLogprobability (current, proposed): \", logp, logp_p)\n            for stochastic in self.stochastics:\n                print_(\n                    \"\\t\",\n                    stochastic.__name__,\n                    stochastic.last_value,\n                    stochastic.value)\n            if accept:\n                print_(\"\\tAccepted\\t*******\\n\")\n            else:\n                print_(\"\\tRejected\\n\")\n            print_(\n                \"\\tAcceptance ratio: \",\n                self.accepted / (\n                    self.accepted + self.rejected))\n\n        if self._current_iter == self.delay:\n            self.greedy = False\n\n        if not accept:\n            self.reject()\n\n        if accept or not self.greedy:\n            self.internal_tally()\n\n        if self._current_iter > self.delay and self._current_iter % self.interval == 0:\n            self.update_cov()\n\n        self._current_iter += 1"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef internal_tally(self):\n        chain = []\n        for stochastic in self.stochastics:\n            chain.append(np.ravel(stochastic.value))\n        self._trace.append(np.concatenate(chain))", "response": "Store the trace of the stochastics for the computation of the covariance."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef trace2array(self, sl):\n        chain = []\n        for stochastic in self.stochastics:\n            tr = stochastic.trace.gettrace(slicing=sl)\n            if tr is None:\n                raise AttributeError\n            chain.append(tr)\n        return np.hstack(chain)", "response": "Return an array with the trace of all stochastics sliced by sl."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef stoch2array(self):\n        a = np.empty(self.dim)\n        for stochastic in self.stochastics:\n            a[self._slices[stochastic]] = stochastic.value\n        return a", "response": "Return the stochastic objects as an array."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntraverses the proposal kernel", "response": "def traverse(self):\n        \"\"\"Traverse proposal kernel\"\"\"\n\n        if self.verbose > 1:\n            print_('\\t' + self._id + ' Running Traverse proposal kernel')\n\n        # Mask for values to move\n        phi = self.phi\n\n        theta = self.traverse_theta\n\n        # Calculate beta\n        if (random() < (theta - 1) / (2 * theta)):\n            beta = exp(1 / (theta + 1) * log(random()))\n        else:\n            beta = exp(1 / (1 - theta) * log(random()))\n\n        if self._prime:\n            xp, x = self.values\n        else:\n            x, xp = self.values\n\n        if self.verbose > 1:\n            print_('\\t' + 'Current value = ' + str(x))\n\n        x = (xp + beta * (xp - x)) * phi + x * (phi == False)\n\n        if self.verbose > 1:\n            print_('\\t' + 'Proposed value = ' + str(x))\n\n        self.stochastic.value = x\n\n        # Set proposal adjustment factor\n        self.hastings_factor = (sum(phi) - 2) * log(beta)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrevert the current s value to the last accepted value", "response": "def reject(self):\n        \"\"\"Sets current s value to the last accepted value\"\"\"\n        self.stochastic.revert()\n\n        # Increment rejected count\n        self.rejected[self.current_kernel] += 1\n\n        if self.verbose > 1:\n            print_(\n                self._id,\n                \"rejected, reverting to value =\",\n                self.stochastic.value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsingle iteration of t - walk algorithm.", "response": "def step(self):\n        \"\"\"Single iteration of t-walk algorithm\"\"\"\n\n        valid_proposal = False\n\n        # Use x or xprime as pivot\n        self._prime = (random() < 0.5)\n\n        if self.verbose > 1:\n            print_(\"\\n\\nUsing x%s as pivot\" % (\" prime\" * self._prime or \"\"))\n\n        if self._prime:\n            # Set the value of the stochastic to the auxiliary\n            self.stochastic.value = self.values[1]\n\n            if self.verbose > 1:\n                print_(\n                    self._id,\n                    \"setting value to auxiliary\",\n                    self.stochastic.value)\n\n        # Current log-probability\n        logp = self.logp_plus_loglike\n        if self.verbose > 1:\n            print_(\"Current logp\", logp)\n\n        try:\n            # Propose new value\n            while not valid_proposal:\n                self.propose()\n                # Check that proposed value lies in support\n                valid_proposal = self._support(self.stochastic.value)\n\n            if not sum(self.phi):\n                raise ZeroProbability\n\n            # Proposed log-probability\n            logp_p = self.logp_plus_loglike\n            if self.verbose > 1:\n                print_(\"Proposed logp\", logp_p)\n\n        except ZeroProbability:\n\n            # Reject proposal\n            if self.verbose > 1:\n                print_(self._id + ' rejecting due to ZeroProbability.')\n            self.reject()\n\n            if self._prime:\n                # Update value list\n                self.values[1] = self.stochastic.value\n                # Revert to stochastic's value for next iteration\n                self.stochastic.value = self.values[0]\n\n                if self.verbose > 1:\n                    print_(\n                        self._id,\n                        \"reverting stochastic to primary value\",\n                        self.stochastic.value)\n            else:\n                # Update value list\n                self.values[0] = self.stochastic.value\n\n            if self.verbose > 1:\n                print_(self._id + ' returning.')\n            return\n\n        if self.verbose > 1:\n            print_('logp_p - logp: ', logp_p - logp)\n\n        # Evaluate acceptance ratio\n        if log(random()) > (logp_p - logp + self.hastings_factor):\n\n            # Revert s if fail\n            self.reject()\n\n        else:\n            # Increment accepted count\n            self.accepted[self.current_kernel] += 1\n            if self.verbose > 1:\n                print_(self._id + ' accepting')\n\n        if self._prime:\n            # Update value list\n            self.values[1] = self.stochastic.value\n            # Revert to stochastic's value for next iteration\n            self.stochastic.value = self.values[0]\n\n            if self.verbose > 1:\n                print_(\n                    self._id,\n                    \"reverting stochastic to primary value\",\n                    self.stochastic.value)\n\n        else:\n            # Update value list\n            self.values[0] = self.stochastic.value"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nslices step method from Neal 2003", "response": "def step(self):\n        \"\"\"\n        Slice step method\n\n        From Neal 2003 (doi:10.1214/aos/1056562461)\n        \"\"\"\n        logy = self.loglike - rexponential(1)\n\n        L = self.stochastic.value - runiform(0, self.w)\n        R = L + self.w\n\n        if self.doubling:\n            # Doubling procedure\n            K = self.m\n            while (K and (logy < self.fll(L) or logy < self.fll(R))):\n                if random() < 0.5:\n                    L -= R - L\n                else:\n                    R += R - L\n                K -= 1\n        else:\n            # Stepping out procedure\n            J = np.floor(runiform(0, self.m))\n            K = (self.m - 1) - J\n            while(J > 0 and logy < self.fll(L)):\n                L -= self.w\n                J -= 1\n            while(K > 0 and logy < self.fll(R)):\n                R += self.w\n                K -= 1\n\n        # Shrinkage procedure\n        self.stochastic.value = runiform(L, R)\n        try:\n            logy_new = self.loglike\n        except ZeroProbability:\n            logy_new = -np.infty\n        while(logy_new < logy):\n            if (self.stochastic.value < self.stochastic.last_value):\n                L = float(self.stochastic.value)\n            else:\n                R = float(self.stochastic.value)\n            self.stochastic.revert()\n            self.stochastic.value = runiform(L, R)\n            try:\n                logy_new = self.loglike\n            except ZeroProbability:\n                logy_new = -np.infty"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fll(self, value):\n        self.stochastic.value = value\n        try:\n            ll = self.loglike\n        except ZeroProbability:\n            ll = -np.infty\n        self.stochastic.revert()\n        return ll", "response": "Returns loglike of value"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef tune(self, verbose=None):\n        if not self._tune:\n            return False\n        else:\n            self.w_tune.append(\n                abs(self.stochastic.last_value - self.stochastic.value))\n            self.w = 2 * (sum(self.w_tune) / len(self.w_tune))\n            return True", "response": "Tune the slice width parameter"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef stochastic_from_scipy_dist(scipy_dist):\n\n    name = scipy_dist.__class__.__name__.replace('_gen', '').capitalize()\n\n    (args, defaults) = get_signature(scipy_dist._cdf)\n    shape_args = args[2:]\n    if isinstance(scipy_dist, rv_continuous):\n        dtype = float\n\n        def logp(value, **kwds):\n            args, kwds = separate_shape_args(kwds, shape_args)\n            return np.sum(scipy_dist.logpdf(value, *args, **kwds))\n\n        parent_names = shape_args + ['loc', 'scale']\n        defaults = [None] * (len(parent_names) - 2) + [0., 1.]\n\n    elif isinstance(scipy_dist, rv_discrete):\n        dtype = int\n\n        def logp(value, **kwds):\n            args, kwds = separate_shape_args(kwds, shape_args)\n            return np.sum(scipy_dist.logpmf(value, *args, **kwds))\n\n        parent_names = shape_args + ['loc']\n        defaults = [None] * (len(parent_names) - 1) + [0]\n    else:\n        return None\n\n    parents_default = dict(zip(parent_names, defaults))\n\n    def random(shape=None, **kwds):\n        args, kwds = separate_shape_args(kwds, shape_args)\n\n        if shape is None:\n            return scipy_dist.rvs(*args, **kwds)\n        else:\n            return np.reshape(scipy_dist.rvs(*args, **kwds), shape)\n\n    # Build docstring from distribution\n    docstr = name[0] + ' = ' + name + '(name, ' + ', '.join(\n        parent_names) + ', value=None, shape=None, trace=True, rseed=True, doc=None)\\n\\n'\n    docstr += 'Stochastic variable with ' + name + \\\n        ' distribution.\\nParents are: ' + ', '.join(parent_names) + '.\\n\\n'\n    docstr += \"\"\"\nMethods:\n\n    random()\n        - draws random value\n          sets value to return value\n\n    ppf(q)\n        - percent point function (inverse of cdf --- percentiles)\n          sets value to return value\n\n    isf(q)\n        - inverse survival function (inverse of sf)\n          sets value to return value\n\n    stats(moments='mv')\n        - mean('m',axis=0), variance('v'), skew('s'), and/or kurtosis('k')\n\n\nAttributes:\n\n    logp\n        - sum(log(pdf())) or sum(log(pmf()))\n\n    cdf\n        - cumulative distribution function\n\n    sf\n        - survival function (1-cdf --- sometimes more accurate)\n\n    entropy\n        - (differential) entropy of the RV.\n\n\nNOTE: If you encounter difficulties with this object, please try the analogous\ncomputation using the rv objects in scipy.stats.distributions directly before\nreporting the bug.\n    \"\"\"\n\n    new_class = new_dist_class(\n        dtype,\n        name,\n        parent_names,\n        parents_default,\n        docstr,\n        logp,\n        random,\n        True,\n        None)\n\n    class newer_class(new_class):\n        __doc__ = docstr\n        rv = scipy_dist\n\n        def __init__(self, *args, **kwds):\n            new_class.__init__(self, *args, **kwds)\n            self.args, self.kwds = separate_shape_args(\n                self.parents, shape_args)\n            self.frozen_rv = self.rv(self.args, self.kwds)\n\n        def _pymc_dists_to_value(self, args):\n            \"\"\"Replace arguments that are a pymc.Node with their value.\"\"\"\n            # This is needed because the scipy rv function transforms\n            # every input argument which causes new pymc lambda\n            # functions to be generated. Thus, when calling this many\n            # many times, excessive amounts of RAM are used.\n            new_args = []\n            for arg in args:\n                if isinstance(arg, pm.Node):\n                    new_args.append(arg.value)\n                else:\n                    new_args.append(arg)\n            return new_args\n\n        def _cdf(self):\n            \"\"\"\n            The cumulative distribution function of self conditional on parents\n            evaluated at self's current value\n            \"\"\"\n            return self.rv.cdf(\n                self.value, *self._pymc_dists_to_value(self.args), **self.kwds)\n        cdf = property(_cdf, doc=_cdf.__doc__)\n\n        def _sf(self):\n            \"\"\"\n            The survival function of self conditional on parents\n            evaluated at self's current value\n            \"\"\"\n            return self.rv.sf(\n                self.value, *self._pymc_dists_to_value(self.args), **self.kwds)\n        sf = property(_sf, doc=_sf.__doc__)\n\n        def ppf(self, q):\n            \"\"\"\n            The percentile point function (inverse cdf) of self conditional on parents.\n            Self's value will be set to the return value.\n            \"\"\"\n            self.value = self.rv.ppf(\n                q,\n                *\n                self._pymc_dists_to_value(\n                    self.args),\n                **self.kwds)\n            return self.value\n\n        def isf(self, q):\n            \"\"\"\n            The inverse survival function of self conditional on parents.\n            Self's value will be set to the return value.\n            \"\"\"\n            self.value = self.rv.isf(\n                q,\n                *self._pymc_dists_to_value(\n                    self.args),\n                **self.kwds)\n            return self.value\n\n        def stats(self, moments='mv'):\n            \"\"\"The first few moments of self's distribution conditional on parents\"\"\"\n            return self.rv.stats(\n                moments=moments, *self._pymc_dists_to_value(self.args), **self.kwds)\n\n        def _entropy(self):\n            \"\"\"The entropy of self's distribution conditional on its parents\"\"\"\n            return self.rv.entropy(\n                *self._pymc_dists_to_value(self.args), **self.kwds)\n        entropy = property(_entropy, doc=_entropy.__doc__)\n\n    newer_class.__name__ = new_class.__name__\n    return newer_class", "response": "Return a Stochastic subclass made from a particular SciPy distribution."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates an array of zeros with shape length where obj is the internal PyMC Stochastic or Deterministic.", "response": "def _initialize(self, chain, length):\n        \"\"\"Create an array of zeros with shape (length, shape(obj)), where\n        obj is the internal PyMC Stochastic or Deterministic.\n        \"\"\"\n        # If this db was loaded from the disk, it may not have its\n        # tallied step methods' getfuncs yet.\n        if self._getfunc is None:\n            self._getfunc = self.db.model._funs_to_tally[self.name]\n\n        # First, see if the object has an explicit dtype.\n        value = np.array(self._getfunc())\n\n        if value.dtype is object:\n            self._trace[chain] = zeros(length, dtype=object)\n\n        elif value.dtype is not None:\n            self._trace[chain] = zeros((length,) + shape(value), value.dtype)\n\n        # Otherwise, if it's an array, read off its value's dtype.\n        elif isinstance(value, ndarray):\n            self._trace[chain] = zeros((length,) + shape(value), value.dtype)\n\n        # Otherwise, let numpy type its value. If the value is a scalar, the trace will be of the\n        # corresponding type. Otherwise it'll be an object array.\n        else:\n            self._trace[chain] = zeros(\n                (length,\n                 ) + shape(value),\n                dtype=value.__class__)\n\n        self._index[chain] = 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstores the object s current value to a chain.", "response": "def tally(self, chain):\n        \"\"\"Store the object's current value to a chain.\n\n        :Parameters:\n        chain : integer\n          Chain index.\n        \"\"\"\n\n        value = self._getfunc()\n\n        try:\n            self._trace[chain][self._index[chain]] = value.copy()\n        except AttributeError:\n            self._trace[chain][self._index[chain]] = value\n        self._index[chain] += 1"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntruncate the trace array to some index.", "response": "def truncate(self, index, chain):\n        \"\"\"\n        Truncate the trace array to some index.\n\n        :Parameters:\n        index : int\n          The index within the chain after which all values will be removed.\n        chain : int\n          The chain index (>=0).\n        \"\"\"\n        self._trace[chain] = self._trace[chain][:index]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef gettrace(self, burn=0, thin=1, chain=-1, slicing=None):\n        if slicing is None:\n            slicing = slice(burn, None, thin)\n        if chain is not None:\n            if chain < 0:\n                chain = range(self.db.chains)[chain]\n            return self._trace[chain][slicing]\n        else:\n            return concatenate(list(self._trace.values()))[slicing]", "response": "Return the trace.\n\n        :Stochastics:\n          - burn (int): The number of transient steps to skip.\n          - thin (int): Keep one in thin.\n          - chain (int): The index of the chain to fetch. If None, return all chains.\n          - slicing: A slice, overriding burn and thin assignement."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef length(self, chain=-1):\n        if chain is not None:\n            if chain < 0:\n                chain = range(self.db.chains)[chain]\n            return self._trace[chain].shape[0]\n        else:\n            return sum([t.shape[0] for t in self._trace.values()])", "response": "Returns the length of the trace."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load(dbname, dbmode='a'):\n    if dbmode == 'w':\n        raise AttributeError(\"dbmode='w' not allowed for load.\")\n    db = Database(dbname, dbmode=dbmode)\n\n    return db", "response": "Load an existing hdf5 database."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd current value to trace.", "response": "def tally(self, chain):\n        \"\"\"Adds current value to trace.\"\"\"\n\n        arr = np.asarray(self._getfunc())\n        arr = arr.reshape((1,) + arr.shape)\n        self.db._arrays[chain, self.name].append(arr)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef gettrace(self, burn=0, thin=1, chain=-1, slicing=None):\n\n        # XXX: handle chain == None case properly\n\n        if chain is None:\n            chain = -1\n        chain = self.db.chains[chain]\n\n        arr = self.db._arrays[chain, self.name]\n\n        if slicing is not None:\n            burn, stop, thin = slicing.start, slicing.stop, slicing.step\n\n        if slicing is None or stop is None:\n            stop = arr.nrows\n            return np.asarray(arr.read(start=burn, stop=stop, step=thin))", "response": "Return the trace of the transient state."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _initialize(self, funs_to_tally, length):\n\n        chain = self.nchains\n        self._chains[chain] = self._h5file.create_group(\n            '/', 'chain%d' % chain, 'chain #%d' % chain)\n\n        for name, fun in six.iteritems(funs_to_tally):\n\n            arr = np.asarray(fun())\n\n            assert arr.dtype != np.dtype('object')\n\n            array = self._h5file.createEArray(\n                self._chains[chain], name,\n                tables.Atom.from_dtype(arr.dtype), (0,) + arr.shape,\n                filters=self.filter)\n\n            self._arrays[chain, name] = array\n            self._traces[name] = Trace(name, getfunc=fun, db=self)\n            self._traces[name]._initialize(self.chains, length)\n\n        self.trace_names.append(list(funs_to_tally.keys()))", "response": "Create a group named chain# to store all data for this chain."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a Database instance from the data stored in the directory.", "response": "def load(dirname):\n    \"\"\"Create a Database instance from the data stored in the directory.\"\"\"\n    if not os.path.exists(dirname):\n        raise AttributeError('No txt database named %s' % dirname)\n\n    db = Database(dirname, dbmode='a')\n    chain_folders = [os.path.join(dirname, c) for c in db.get_chains()]\n    db.chains = len(chain_folders)\n\n    data = {}\n    for chain, folder in enumerate(chain_folders):\n        files = os.listdir(folder)\n        funnames = funname(files)\n        db.trace_names.append(funnames)\n        for file in files:\n            name = funname(file)\n            if name not in data:\n                data[\n                    name] = {\n                }  # This could be simplified using \"collections.defaultdict(dict)\". New in Python 2.5\n            # Read the shape information\n            with open(os.path.join(folder, file)) as f:\n                f.readline()\n                shape = eval(f.readline()[16:])\n                data[\n                    name][\n                        chain] = np.loadtxt(\n                            os.path.join(\n                                folder,\n                                file),\n                            delimiter=',').reshape(\n                                shape)\n                f.close()\n\n    # Create the Traces.\n    for name, values in six.iteritems(data):\n        db._traces[name] = Trace(name=name, value=values, db=db)\n        setattr(db, name, db._traces[name])\n\n    # Load the state.\n    statefile = os.path.join(dirname, 'state.txt')\n    if os.path.exists(statefile):\n        with open(statefile, 'r') as f:\n            db._state_ = eval(f.read())\n    else:\n        db._state_ = {}\n\n    return db"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef funname(file):\n    if isinstance(file, str):\n        files = [file]\n    else:\n        files = file\n    bases = [os.path.basename(f) for f in files]\n    names = [os.path.splitext(b)[0] for b in bases]\n    if isinstance(file, str):\n        return names[0]\n    else:\n        return names", "response": "Return variable names from file names."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _finalize(self, chain):\n        path = os.path.join(\n            self.db._directory,\n            self.db.get_chains()[chain],\n            self.name + '.txt')\n        arr = self.gettrace(chain=chain)\n\n        # Following numpy's example.\n        if six.PY3:\n            mode = 'wb'\n        else:\n            mode = 'w'\n        with open(path, mode) as f:\n            f.write(six.b('# Variable: %s\\n' % self.name))\n            f.write(six.b('# Sample shape: %s\\n' % str(arr.shape)))\n            f.write(six.b('# Date: %s\\n' % datetime.datetime.now()))\n            np.savetxt(f, arr.reshape((-1, arr[0].size)), delimiter=',')", "response": "Write the trace to an ASCII file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_chains(self):\n        chains = []\n        try:\n            content = os.listdir(self._directory)\n            for c in content:\n                if os.path.isdir(os.path.join(self._directory, c)) and c.startswith(\n                        CHAIN_NAME[:-2]):\n                    chains.append(c)\n        except:\n            pass\n        chains.sort()\n        return chains", "response": "Return an ordered list of the Chain_# directories in the db\n        directory."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _initialize(self, funs_to_tally, length):\n\n        dir = os.path.join(self._directory, CHAIN_NAME % self.chains)\n        os.mkdir(dir)\n\n        base.Database._initialize(self, funs_to_tally, length)", "response": "Create folder to store simulation results."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsave the sampler s state in a state. txt file.", "response": "def savestate(self, state):\n        \"\"\"Save the sampler's state in a state.txt file.\"\"\"\n        oldstate = np.get_printoptions()\n        np.set_printoptions(threshold=1e6)\n        try:\n            with open(os.path.join(self._directory, 'state.txt'), 'w') as f:\n                print_(state, file=f)\n        finally:\n            np.set_printoptions(**oldstate)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nevaluating the basis functions on x and return the result as a matrix.", "response": "def eval_basis(self, x, regularize=True):\n        \"\"\"\n        basis_mat = C.eval_basis(x)\n\n        Evaluates self's basis functions on x and returns them stacked\n        in a matrix. basis_mat[i,j] gives basis function i evaluated at\n        x[j,:].\n        \"\"\"\n        if regularize:\n            x = regularize_array(x)\n\n        out = zeros((self.n, x.shape[0]), dtype=float, order='F')\n\n        for i in xrange(self.n):\n            out[i] = self.basis[i](x, **self.params)\n\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef eval_basis(self, x, regularize=True):\n        # Make object of same shape as self.basis, fill in with evals of each individual basis factor.\n        # Make object of same shape as diag(coef_cov), fill in with products of those evals.\n        # Reshape and return.\n        if regularize:\n            x = regularize_array(x)\n\n        out = zeros(self.shape + (x.shape[0],), dtype=float, order='F')\n\n        # Evaluate the basis factors\n        basis_factors = []\n        for i in xrange(self.ndim):\n            basis_factors.append([])\n            for j in xrange(self.n_per_dim[i]):\n                basis_factors[i].append(self.basis[i][j](x, **self.params))\n\n        out = ones((self.n, x.shape[0]), dtype=float)\n        out_reshaped = out.reshape(self.shape + (x.shape[0],))\n\n        for ind in ndindex(self.shape):\n            for dim in xrange(self.ndim):\n                out_reshaped[ind] *= basis_factors[dim][ind[dim]]\n\n        return out", "response": "Evaluate the basis functions on x and return the result as a matrix."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nallocates appropriate mean to time series", "response": "def rate(s=switch, e=early_mean, l=late_mean):\n    \"\"\"Allocate appropriate mean to time series\"\"\"\n    out = np.empty(len(disasters_array))\n    # Early mean prior to switchpoint\n    out[:s] = e\n    # Late mean following switchpoint\n    out[s:] = l\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfast copy of a Fortran - contiguous matrix.", "response": "def fast_matrix_copy(f, t=None, n_threads=1):\n    \"\"\"\n    Not any faster than a serial copy so far.\n    \"\"\"\n    if not f.flags['F_CONTIGUOUS']:\n        raise RuntimeError(\n            'This will not be fast unless input array f is Fortran-contiguous.')\n\n    if t is None:\n        t = asmatrix(empty(f.shape, order='F'))\n    elif not t.flags['F_CONTIGUOUS']:\n        raise RuntimeError(\n            'This will not be fast unless input array t is Fortran-contiguous.')\n\n    # Figure out how to divide job up between threads.\n    dcopy_wrap(ravel(asarray(f.T)), ravel(asarray(t.T)))\n    return t"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef caching_call(f, x, x_sofar, f_sofar):\n    lenx = x.shape[0]\n\n    nr, rf, rt, nu, xu, ui = remove_duplicates(x)\n\n    unique_indices = ui[:nu]\n    x_unique = xu[:nu]\n    repeat_from = rf[:nr]\n    repeat_to = rt[:nr]\n\n    # Check which observations have already been made.\n    if x_sofar is not None:\n\n        f_unique, new_indices, N_new_indices = check_repeats(\n            x_unique, x_sofar, f_sofar)\n\n        # If there are any new input points, draw values over them.\n        if N_new_indices > 0:\n\n            x_new = x_unique[new_indices[:N_new_indices]]\n            f_new = f(x_new)\n\n            f_unique[new_indices[:N_new_indices]] = f_new\n\n            # Record the new values\n            x_sofar = vstack((x_sofar, x_new))\n            f_sofar = hstack((f_sofar, f_new))\n        else:\n            f = f_unique\n\n    # If no observations have been made, don't check.\n    else:\n        f_unique = f(x_unique)\n        x_sofar = x_unique\n        f_sofar = f_unique\n\n    f = empty(lenx)\n    f[unique_indices] = f_unique\n    f[repeat_to] = f[repeat_from]\n\n    return f, x_sofar, f_sofar", "response": "Computes f and f_sofar given that f = x_sofar."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef square_and_sum(a, s):\n    cmin, cmax = thread_partition_array(a)\n    map_noreturn(asqs, [(a, s, cmin[i], cmax[i]) for i in xrange(len(cmax))])\n    return a", "response": "Writes np. sum ( a ** 2 s into s\n    Writes np. sum ( a ** 2 s into s\n    Writes np. sum ( a ** 2 s into s\n    Writes np. sum ( a ** 2 s into s\n    Writes np. sum ( a ** 2 s into s\n    Writes np. sum ( a ** 2 s into s\n    Writes np. sum ( a ** 2 s into s\n    Writes np. sum ( a ** 2"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef vecs_to_datmesh(x, y):\n    x, y = meshgrid(x, y)\n    out = zeros(x.shape + (2,), dtype=float)\n    out[:, :, 0] = x\n    out[:, :, 1] = y\n    return out", "response": "Converts input arguments x and y to a 2d meshgrid suitable for calling Means Covariances and Realizations."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef trimult(U, x, uplo='U', transa='N', alpha=1., inplace=False):\n    if inplace:\n        b = x\n    else:\n        b = x.copy('F')\n    dtrmm_wrap(a=U, b=b, uplo=uplo, transa=transa, alpha=alpha)\n    return b", "response": "Returns a new object with the same attributes as the given object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsolving a triangular system with a given upper triangular system and a given lower triangular system.", "response": "def trisolve(U, b, uplo='U', transa='N', alpha=1., inplace=False):\n    \"\"\"\n    x = trisolve(U,b, uplo='U')\n\n\n    Solves U x = b, where U is upper triangular if uplo='U'\n    or lower triangular if uplo = 'L'.\n\n\n    If a degenerate column is found, an error is raised.\n    \"\"\"\n    if inplace:\n        x = b\n    else:\n        x = b.copy('F')\n    if U.shape[0] == 0:\n        raise ValueError('Attempted to solve zero-rank triangular system')\n    dtrsm_wrap(a=U, b=x, side='L', uplo=uplo, transa=transa, alpha=alpha)\n    return x"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nplot the pointwise mean + / - sd envelope defined by M and C along their base mesh.", "response": "def plot_envelope(M, C, mesh):\n    \"\"\"\n    plot_envelope(M,C,mesh)\n\n\n    plots the pointwise mean +/- sd envelope defined by M and C\n    along their base mesh.\n\n\n    :Arguments:\n\n        -   `M`: A Gaussian process mean.\n\n        -   `C`: A Gaussian process covariance\n\n        -   `mesh`: The mesh on which to evaluate the mean and cov.\n    \"\"\"\n\n    try:\n        from pylab import fill, plot, clf, axis\n        x = concatenate((mesh, mesh[::-1]))\n        mean, var = point_eval(M, C, mesh)\n        sig = sqrt(var)\n        mean = M(mesh)\n        y = concatenate((mean - sig, (mean + sig)[::-1]))\n        # clf()\n        fill(x, y, facecolor='.8', edgecolor='1.')\n        plot(mesh, mean, 'k-.')\n    except ImportError:\n        print_(\"Matplotlib is not installed; plotting is disabled.\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nobserve the value of obs_vals on M and C.", "response": "def observe(M, C, obs_mesh, obs_vals, obs_V=0, lintrans=None,\n            cross_validate=True):\n    \"\"\"\n    (M, C, obs_mesh, obs_vals[, obs_V = 0, lintrans = None, cross_validate = True])\n\n\n    Imposes observation of the value of obs_vals on M and C, where\n\n    obs_vals ~ N(lintrans * f(obs_mesh), V)\n    f ~ GP(M,C)\n\n\n    :Arguments:\n\n        -   `M`: The mean function\n\n        -   `C`: The covariance function\n\n        -   `obs_mesh`: The places where f has been evaluated.\n\n        -   `obs_vals`: The values of f that were observed there.\n\n        -   `obs_V`: The observation variance. If None, assumed to be infinite\n            (observations made with no error).\n\n        -   `lintrans`: A linear transformation. If None, assumed to be the\n            identity transformation (pretend it doesn't exist).\n\n        -   `cross_validate`: A flag indicating whether a check should be done to\n            see if the data could have arisen from M and C with positive probability.\n\n    \"\"\"\n    obs_mesh = regularize_array(obs_mesh)\n    # print_(obs_mesh)\n    obs_V = resize(obs_V, obs_mesh.shape[0])\n    obs_vals = resize(obs_vals, obs_mesh.shape[0])\n\n    # First observe C.\n    relevant_slice, obs_mesh_new = C.observe(obs_mesh, obs_V, output_type='o')\n\n    # Then observe M from C.\n    M.observe(C, obs_mesh_new, obs_vals.ravel()[relevant_slice])\n\n    # Cross-validate if not asked not to.\n    if obs_mesh_new.shape[0] < obs_mesh.shape[0]:\n        if cross_validate:\n            if not predictive_check(\n                    obs_vals, obs_mesh, M, C.obs_piv, sqrt(C.relative_precision)):\n                raise ValueError(\n                    \"These data seem extremely improbable given your GP prior. \\n Suggestions: decrease observation precision, or adjust the covariance to \\n allow the function to be less smooth.\")"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking the internal covariance of the observations.", "response": "def predictive_check(obs_vals, obs_mesh, M, posdef_indices, tolerance):\n    \"\"\"\n    OK = predictive_check(obs_vals, obs_mesh, M, posdef_indices, tolerance)\n\n\n    If an internal covariance is low-rank, make sure the observations\n    are consistent. Returns True if good, False if bad.\n\n\n    :Arguments:\n\n        -   `obs_vals`: The observed values.\n\n        -   `obs_mesh`: The mesh on which the observed values were observed.\n\n        -   `M`: The mean function, observed at obs_vals[posdef_indices].\n\n        -   `tolerance`: The maximum allowable deviation at M(obs_mesh[non_posdef_indices]).\n    \"\"\"\n\n    non_posdef_indices = array(\n        list(set(range(len(obs_vals))) - set(posdef_indices)), dtype=int)\n    if len(non_posdef_indices) > 0:\n        M_under = M(obs_mesh[non_posdef_indices, :]).ravel()\n        dev = abs((M_under - obs_vals[non_posdef_indices]))\n        if dev.max() > tolerance:\n            return False\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef point_predict(f, x, size=1, nugget=None):\n    orig_shape = x.shape\n    x = regularize_array(x)\n\n    mu = f.M_internal(x, regularize=False)\n    V = f.C_internal(x, regularize=False)\n    if nugget is not None:\n        V += nugget\n    out = random.normal(size=(size, x.shape[0])) * sqrt(V) + mu\n    return out.reshape((size,) + orig_shape[:-1]).squeeze()", "response": "point_predict(f, x[, size, nugget])\n\n    Makes 'size' simulations for f(x) + N(0,nugget).\n    Simulated values of f(x_i) are uncorrelated for different i.\n    Useful for geostatistical predictions."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nevaluates M and C at x.", "response": "def point_eval(M, C, x):\n    \"\"\"\n    Evaluates M(x) and C(x).\n\n    Minimizes computation; evaluating M(x) and C(x) separately would\n    evaluate the off-diagonal covariance term twice, but callling\n    point_eval(M,C,x) would only evaluate it once.\n\n    Also chunks the evaluations if the off-diagonal term.\n    \"\"\"\n\n    x_ = regularize_array(x)\n\n    M_out = empty(x_.shape[0])\n    V_out = empty(x_.shape[0])\n\n    if isinstance(C, pymc.gp.BasisCovariance):\n        y_size = len(C.basis)\n    elif C.obs_mesh is not None:\n        y_size = C.obs_mesh.shape[0]\n    else:\n        y_size = 1\n\n    n_chunks = ceil(y_size * x_.shape[0] / float(chunksize))\n    bounds = array(linspace(0, x_.shape[0], n_chunks + 1), dtype='int')\n    cmin = bounds[:-1]\n    cmax = bounds[1:]\n    for (cmin, cmax) in zip(bounds[:-1], bounds[1:]):\n        x__ = x_[cmin:cmax]\n        V_out[cmin:cmax], Uo_Cxo = C(x__, regularize=False, return_Uo_Cxo=True)\n        M_out[cmin:cmax] = M(x__, regularize=False, Uo_Cxo=Uo_Cxo)\n\n    if len(x.shape) > 1:\n        targ_shape = x.shape[:-1]\n    else:\n        targ_shape = x.shape\n    return M_out.reshape(targ_shape), V_out.reshape(targ_shape)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef batchsd(trace, batches=5):\n\n    if len(np.shape(trace)) > 1:\n\n        dims = np.shape(trace)\n        # ttrace = np.transpose(np.reshape(trace, (dims[0], sum(dims[1:]))))\n        ttrace = np.transpose([t.ravel() for t in trace])\n\n        return np.reshape([batchsd(t, batches) for t in ttrace], dims[1:])\n\n    else:\n        if batches == 1:\n            return np.std(trace) / np.sqrt(len(trace))\n\n        try:\n            batched_traces = np.resize(trace, (batches, int(len(trace) / batches)))\n        except ValueError:\n            # If batches do not divide evenly, trim excess samples\n            resid = len(trace) % batches\n            batched_traces = np.resize(trace[:-resid], \n                (batches, len(trace[:-resid]) / batches))\n\n        means = np.mean(batched_traces, 1)\n\n        return np.std(means) / np.sqrt(batches)", "response": "Calculates the simulation standard error accounting for non - independent\nSSHA samples."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _initialize(self, chain, length):\n        # If this db was loaded from the disk, it may not have its\n        # tallied step methods' getfuncs yet.\n        if self._getfunc is None:\n            self._getfunc = self.db.model._funs_to_tally[self.name]", "response": "Prepare for tallying. Create a new chain."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef stats(self, alpha=0.05, start=0, batches=100,\n              chain=None, quantiles=(2.5, 25, 50, 75, 97.5)):\n        \"\"\"\n        Generate posterior statistics for node.\n\n        :Parameters:\n        name : string\n          The name of the tallyable object.\n\n        alpha : float\n          The alpha level for generating posterior intervals. Defaults to\n          0.05.\n\n        start : int\n          The starting index from which to summarize (each) chain. Defaults\n          to zero.\n\n        batches : int\n          Batch size for calculating standard deviation for non-independent\n          samples. Defaults to 100.\n\n        chain : int\n          The index for which chain to summarize. Defaults to None (all\n          chains).\n\n        quantiles : tuple or list\n          The desired quantiles to be calculated. Defaults to (2.5, 25, 50, 75, 97.5).\n        \"\"\"\n\n        try:\n            trace = np.squeeze(\n                np.array(\n                    self.db.trace(\n                        self.name)(\n                            chain=chain),\n                    float))[\n                        start:]\n\n            n = len(trace)\n            if not n:\n                print_(\n                    'Cannot generate statistics for zero-length trace in',\n                    self.__name__)\n                return\n\n            return {\n                'n': n,\n                'standard deviation': trace.std(0),\n                'mean': trace.mean(0),\n                '%s%s HPD interval' % (int(100 * (1 - alpha)), '%'): utils.hpd(trace, alpha),\n                'mc error': batchsd(trace, min(n, batches)),\n                'quantiles': utils.quantiles(trace, qlist=quantiles)\n            }\n        except:\n            print_('Could not generate output statistics for', self.name)\n            return", "response": "Generate posterior statistics for the tallyable object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _initialize(self, funs_to_tally, length=None):\n\n        for name, fun in six.iteritems(funs_to_tally):\n            if name not in self._traces:\n                self._traces[\n                    name] = self.__Trace__(\n                        name=name,\n                        getfunc=fun,\n                        db=self)\n\n            self._traces[name]._initialize(self.chains, length)\n\n        self.trace_names.append(list(funs_to_tally.keys()))\n\n        self.chains += 1", "response": "Initializes the tallyable objects."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nlinking the Database to the given model.", "response": "def connect_model(self, model):\n        \"\"\"Link the Database to the Model instance.\n\n        In case a new database is created from scratch, ``connect_model``\n        creates Trace objects for all tallyable pymc objects defined in\n        `model`.\n\n        If the database is being loaded from an existing file, ``connect_model``\n        restore the objects trace to their stored value.\n\n        :Parameters:\n        model : pymc.Model instance\n          An instance holding the pymc objects defining a statistical\n          model (stochastics, deterministics, data, ...)\n        \"\"\"\n        # Changed this to allow non-Model models. -AP\n        # We could also remove it altogether. -DH\n        if isinstance(model, pymc.Model):\n            self.model = model\n        else:\n            raise AttributeError('Not a Model instance.')\n\n        # Restore the state of the Model from an existing Database.\n        # The `load` method will have already created the Trace objects.\n        if hasattr(self, '_state_'):\n            names = set()\n            for morenames in self.trace_names:\n                names.update(morenames)\n            for name, fun in six.iteritems(model._funs_to_tally):\n                if name in self._traces:\n                    self._traces[name]._getfunc = fun\n                    names.discard(name)\n            # if len(names) > 0:\n            # print_(\"Some objects from the database have not been assigned a\n            # getfunc\", names)\n\n        # Create a fresh new state.\n        # We will be able to remove this when we deprecate traces on objects.\n        else:\n            for name, fun in six.iteritems(model._funs_to_tally):\n                if name not in self._traces:\n                    self._traces[\n                        name] = self.__Trace__(\n                            name=name,\n                            getfunc=fun,\n                            db=self)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _finalize(self, chain=-1):\n        chain = range(self.chains)[chain]\n        for name in self.trace_names[chain]:\n            self._traces[name]._finalize(chain)\n        self.commit()", "response": "Finalize the chain for all tallyable objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef truncate(self, index, chain=-1):\n        chain = range(self.chains)[chain]\n        for name in self.trace_names[chain]:\n            self._traces[name].truncate(index, chain)", "response": "Tell the traces to truncate themselves at the given index."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the trace of a tallyable object stored in the database.", "response": "def trace(self, name, chain=-1):\n        \"\"\"Return the trace of a tallyable object stored in the database.\n\n        :Parameters:\n        name : string\n          The name of the tallyable object.\n        chain : int\n          The trace index. Setting `chain=i` will return the trace created by\n          the ith call to `sample`.\n        \"\"\"\n        trace = copy.copy(self._traces[name])\n        trace._chain = chain\n        return trace"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsynchronizing self s observation status with C s.", "response": "def observe(self, C, obs_mesh_new, obs_vals_new, mean_under=None):\n        \"\"\"\n        Synchronizes self's observation status with C's.\n        Values of observation are given by obs_vals.\n\n        obs_mesh_new and obs_vals_new should already have\n        been sliced, as Covariance.observe(..., output_type='o') does.\n        \"\"\"\n\n        self.C = C\n        self.obs_mesh = C.obs_mesh\n        self.obs_len = C.obs_len\n\n        self.Uo = C.Uo\n\n        # Evaluate the underlying mean function on the new observation mesh.\n        if mean_under is None:\n            mean_under_new = C._mean_under_new(self, obs_mesh_new)\n        else:\n            mean_under_new = mean_under\n\n        # If self hasn't been observed yet:\n        if not self.observed:\n\n            self.dev = (obs_vals_new - mean_under_new)\n\n            self.reg_mat = C._unobs_reg(self)\n\n        # If self has been observed already:\n        elif len(obs_vals_new) > 0:\n\n            # Rank of old observations.\n            m_old = len(self.dev)\n\n            # Deviation of new observation from mean without regard to old\n            # observations.\n            dev_new = (obs_vals_new - mean_under_new)\n\n            # Again, basis covariances get special treatment.\n            self.reg_mat = C._obs_reg(self, dev_new, m_old)\n\n            # Stack deviations of old and new observations from unobserved\n            # mean.\n            self.dev = hstack((self.dev, dev_new))\n        self.observed = True"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _extract(__func__, kwds, keys, classname, probe=True):\n\n    # Add docs and name\n    kwds['doc'] = __func__.__doc__\n    if not 'name' in kwds:\n        kwds['name'] = __func__.__name__\n    # kwds.update({'doc':__func__.__doc__, 'name':__func__.__name__})\n\n    # Instanitate dictionary of parents\n    parents = {}\n\n    # This gets used by stochastic to check for long-format logp and random:\n    if probe:\n        cur_status = check_special_methods()\n        disable_special_methods()\n        # Define global tracing function (I assume this is for debugging??)\n        # No, it's to get out the logp and random functions, if they're in\n        # there.\n\n        def probeFunc(frame, event, arg):\n            if event == 'return':\n                locals = frame.f_locals\n                kwds.update(dict((k, locals.get(k)) for k in keys))\n                sys.settrace(None)\n            return probeFunc\n\n        sys.settrace(probeFunc)\n\n        # Get the functions logp and random (complete interface).\n        # Disable special methods to prevent the formation of a hurricane of\n        # Deterministics\n        try:\n            __func__()\n        except:\n            if 'logp' in keys:\n                kwds['logp'] = __func__\n            else:\n                kwds['eval'] = __func__\n        # Reenable special methods.\n        if cur_status:\n            enable_special_methods()\n\n    for key in keys:\n        if not key in kwds:\n            kwds[key] = None\n\n    for key in ['logp', 'eval']:\n        if key in keys:\n            if kwds[key] is None:\n                kwds[key] = __func__\n\n    # Build parents dictionary by parsing the __func__tion's arguments.\n    (args, defaults) = get_signature(__func__)\n\n    if defaults is None:\n        defaults = ()\n\n    # Make sure all parents were defined\n    arg_deficit = (len(args) - ('value' in args)) - len(defaults)\n    if arg_deficit > 0:\n        err_str =  classname + ' ' + __func__.__name__ + \\\n            ': no parent provided for the following labels:'\n        for i in range(arg_deficit):\n            err_str += \" \" + args[i + ('value' in args)]\n            if i < arg_deficit - 1:\n                err_str += ','\n        raise ValueError(err_str)\n\n    # Fill in parent dictionary\n    try:\n        parents.update(dict(zip(args[-len(defaults):], defaults)))\n    except TypeError:\n        pass\n\n    value = parents.pop('value', None)\n\n    return (value, parents)", "response": "Extract the class name and their arguments from the given function."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef deterministic(__func__=None, **kwds):\n    def instantiate_n(__func__):\n        junk, parents = _extract(\n            __func__, kwds, keys, 'Deterministic', probe=False)\n        return Deterministic(parents=parents, **kwds)\n\n    keys = ['eval']\n\n    instantiate_n.kwds = kwds\n\n    if __func__:\n        return instantiate_n(__func__)\n\n    return instantiate_n", "response": "Decorator function instantiating deterministic variables. Usage :\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef plot(self):\n        figure()\n        plot_envelope(self.M, self.C, self.xplot)\n        for i in range(3):\n            f = Realization(self.M, self.C)\n            plot(self.xplot,f(self.xplot))\n\n        plot(self.abundance, self.frye, 'k.', markersize=4)\n        xlabel('Female abundance')\n        ylabel('Frye density')\n        title(self.name)\n        axis('tight')", "response": "Plot posterior from simple nonstochetric regression."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef params_of_mean(value=array([-.005, 1.]), tau=.1, rate=4.):\n\n    def logp(value, tau, rate):\n        if value[1] > 0 and value[1] + value[0] * 110 > 0:\n            return normal_like(value[0], 0., tau) + \\\n                exponential_like(value[1], rate)\n        else:\n            return -Inf\n\n    def random(tau, rate):\n        val = zeros(2)\n        val[0] = rnormal(0., tau)\n        val[1] = rexponential(rate)\n        while val[1] < 0 or val[1] + val[0] * 110 <= 0:\n            val[0] = rnormal(0., tau)\n            val[1] = rexponential(rate)\n        return val", "response": "Returns the parameters of the next log - likelihood and random - likelihood of the next poisson distribution."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef disasters(value=disasters_array, params_of_mean=params_of_mean):\n    val = params_of_mean[1] + params_of_mean[0] * arange(111)\n    return poisson_like(value, val)", "response": "Annual occurences of coal mining disasters."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload a pickled database. Return a Database instance.", "response": "def load(filename):\n    \"\"\"Load a pickled database.\n\n    Return a Database instance.\n    \"\"\"\n    file = open(filename, 'rb')\n    container = std_pickle.load(file)\n    file.close()\n    db = Database(file.name)\n    chains = 0\n    funs = set()\n    for k, v in six.iteritems(container):\n        if k == '_state_':\n            db._state_ = v\n        else:\n            db._traces[k] = Trace(name=k, value=v, db=db)\n            setattr(db, k, db._traces[k])\n            chains = max(chains, len(v))\n            funs.add(k)\n\n    db.chains = chains\n    db.trace_names = chains * [list(funs)]\n\n    return db"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndumping traces using cPickle.", "response": "def _finalize(self):\n        \"\"\"Dump traces using cPickle.\"\"\"\n        container = {}\n        try:\n            for name in self._traces:\n                container[name] = self._traces[name]._trace\n            container['_state_'] = self._state_\n\n            file = open(self.filename, 'w+b')\n            std_pickle.dump(container, file)\n            file.close()\n        except AttributeError:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef open01(x, limit=1.e-6):\n    try:\n        return np.array([min(max(y, limit), 1. - limit) for y in x])\n    except TypeError:\n        return min(max(x, limit), 1. - limit)", "response": "Constrain numbers to 1 interval"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef validate(sampler, replicates=20, iterations=10000, burn=5000,\n             thin=1, deterministic=False, db='ram', plot=True, verbose=0):\n    \"\"\"\n    Model validation method, following Cook et al. (Journal of Computational and\n    Graphical Statistics, 2006, DOI: 10.1198/106186006X136976).\n\n    Generates posterior samples based on 'true' parameter values and data simulated\n    from the priors. The quantiles of the parameter values are calculated, based on\n    the samples. If the model is valid, the quantiles should be uniformly distributed\n    over [0,1].\n\n    Since this relies on the generation of simulated data, all data stochastics\n    must have a valid random() method for validation to proceed.\n\n    Parameters\n    ----------\n    sampler : Sampler\n      An MCMC sampler object.\n    replicates (optional) : int\n      The number of validation replicates (i.e. number of quantiles to be simulated).\n      Defaults to 100.\n    iterations (optional) : int\n      The number of MCMC iterations to be run per replicate. Defaults to 2000.\n    burn (optional) : int\n      The number of burn-in iterations to be run per replicate. Defaults to 1000.\n    thin (optional) : int\n      The thinning factor to be applied to posterior sample. Defaults to 1 (no thinning)\n    deterministic (optional) : bool\n      Flag for inclusion of deterministic nodes in validation procedure. Defaults\n      to False.\n    db (optional) : string\n      The database backend to use for the validation runs. Defaults to 'ram'.\n    plot (optional) : bool\n      Flag for validation plots. Defaults to True.\n\n    Returns\n    -------\n    stats : dict\n      Return a dictionary containing tuples with the chi-square statistic and\n      associated p-value for each data stochastic.\n\n    Notes\n    -----\n    This function requires SciPy.\n    \"\"\"\n    import scipy as sp\n    # Set verbosity for models to zero\n    sampler.verbose = 0\n\n    # Specify parameters to be evaluated\n    parameters = sampler.stochastics\n    if deterministic:\n        # Add deterministics to the mix, if requested\n        parameters = parameters | sampler.deterministics\n\n    # Assign database backend\n    original_backend = sampler.db.__name__\n    sampler._assign_database_backend(db)\n\n    # Empty lists for quantiles\n    quantiles = {}\n\n    if verbose:\n        print_(\"\\nExecuting Cook et al. (2006) validation procedure ...\\n\")\n\n    # Loop over replicates\n    for i in range(replicates):\n\n        # Sample from priors\n        for p in sampler.stochastics:\n            if not p.extended_parents:\n                p.random()\n\n        # Sample \"true\" data values\n        for o in sampler.observed_stochastics:\n            # Generate simuated data for data stochastic\n            o.set_value(o.random(), force=True)\n            if verbose:\n                print_(\"Data for %s is %s\" % (o.__name__, o.value))\n\n        param_values = {}\n        # Record data-generating parameter values\n        for s in parameters:\n            param_values[s] = s.value\n\n        try:\n            # Fit models given parameter values\n            sampler.sample(iterations, burn=burn, thin=thin)\n\n            for s in param_values:\n\n                if not i:\n                    # Initialize dict\n                    quantiles[s.__name__] = []\n                trace = s.trace()\n                q = sum(trace < param_values[s], 0) / float(len(trace))\n                quantiles[s.__name__].append(open01(q))\n\n            # Replace data values\n            for o in sampler.observed_stochastics:\n                o.revert()\n\n        finally:\n            # Replace data values\n            for o in sampler.observed_stochastics:\n                o.revert()\n\n            # Replace backend\n            sampler._assign_database_backend(original_backend)\n\n        if not i % 10 and i and verbose:\n            print_(\"\\tCompleted validation replicate\", i)\n\n    # Replace backend\n    sampler._assign_database_backend(original_backend)\n\n    stats = {}\n    # Calculate chi-square statistics\n    for param in quantiles:\n        q = quantiles[param]\n        # Calculate chi-square statistics\n        X2 = sum(sp.special.ndtri(q) ** 2)\n        # Calculate p-value\n        p = sp.special.chdtrc(replicates, X2)\n\n        stats[param] = (X2, p)\n\n    if plot:\n        # Convert p-values to z-scores\n        p = copy(stats)\n        for i in p:\n            p[i] = p[i][1]\n        Matplot.zplot(p, verbose=verbose)\n\n    return stats", "response": "This function validates the MCMC model."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef geweke(x, first=.1, last=.5, intervals=20, maxlag=20):\n    \n    if not has_sm:\n        print(\"statsmodels not available. Geweke diagnostic cannot be calculated.\")\n        return\n\n    if np.ndim(x) > 1:\n        return [geweke(y, first, last, intervals) for y in np.transpose(x)]\n\n    # Filter out invalid intervals\n    if first + last >= 1:\n        raise ValueError(\n            \"Invalid intervals for Geweke convergence analysis\",\n            (first, last))\n\n    # Initialize list of z-scores\n    zscores = [None] * intervals\n\n    # Starting points for calculations\n    starts = np.linspace(0, int(len(x)*(1.-last)), intervals).astype(int)\n\n    # Loop over start indices\n    for i,s in enumerate(starts):\n\n        # Size of remaining array\n        x_trunc = x[s:]\n        n = len(x_trunc)\n\n        # Calculate slices\n        first_slice = x_trunc[:int(first * n)]\n        last_slice = x_trunc[int(last * n):]\n\n        z = (first_slice.mean() - last_slice.mean())\n        z /= np.sqrt(spec(first_slice)/len(first_slice) +\n                     spec(last_slice)/len(last_slice))\n        zscores[i] = len(x) - n, z\n\n    return zscores", "response": "Calculates the z - scores for convergence diagnostics."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef batch_means(x, f=lambda y: y, theta=.5, q=.95, burn=0):\n\n    try:\n        import scipy\n        from scipy import stats\n    except ImportError:\n        raise ImportError('SciPy must be installed to use batch_means.')\n\n    x = x[burn:]\n\n    n = len(x)\n\n    b = np.int(n ** theta)\n    a = n / b\n\n    t_quant = stats.t.isf(1 - q, a - 1)\n\n    Y = np.array([np.mean(f(x[i * b:(i + 1) * b])) for i in xrange(a)])\n    sig = b / (a - 1.) * sum((Y - np.mean(f(x))) ** 2)\n\n    return t_quant * sig / np.sqrt(n)", "response": "This function calculates the half - width of the frequentist confidence interval of the Monte Carlo estimate of E [ f ]."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef discrepancy(observed, simulated, expected):\n    try:\n        simulated = simulated.astype(float)\n    except AttributeError:\n        simulated = simulated.trace().astype(float)\n    try:\n        expected = expected.astype(float)\n    except AttributeError:\n        expected = expected.trace().astype(float)\n    # Ensure expected values are rxn\n    expected = np.resize(expected, simulated.shape)\n\n    D_obs = np.sum([(np.sqrt(observed) - np.sqrt(\n        e)) ** 2 for e in expected], 1)\n    D_sim = np.sum(\n        [(np.sqrt(s) - np.sqrt(e)) ** 2 for s,\n         e in zip(simulated,\n                  expected)],\n        1)\n\n    # Print p-value\n    count = sum(s > o for o, s in zip(D_obs, D_sim))\n    print_('Bayesian p-value: p=%.3f' % (1. * count / len(D_obs)))\n\n    return D_obs, D_sim", "response": "Calculates the discrepancy between observed simulated and expected data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncalculate the effective sample size of a set of traces.", "response": "def effective_n(x):\n    \"\"\" Returns estimate of the effective sample size of a set of traces.\n\n    Parameters\n    ----------\n    x : array-like\n      An array containing the 2 or more traces of a stochastic parameter. That is, an array of dimension m x n x k, where m is the number of traces, n the number of samples, and k the dimension of the stochastic.\n    \n    Returns\n    -------\n    n_eff : float\n      Return the effective sample size, :math:`\\hat{n}_{eff}`\n\n    Notes\n    -----\n\n    The diagnostic is computed by:\n\n      .. math:: \\hat{n}_{eff} = \\frac{mn}}{1 + 2 \\sum_{t=1}^T \\hat{\\rho}_t}\n\n    where :math:`\\hat{\\rho}_t` is the estimated autocorrelation at lag t, and T\n    is the first odd positive integer for which the sum :math:`\\hat{\\rho}_{T+1} + \\hat{\\rho}_{T+1}` \n    is negative.\n\n    References\n    ----------\n    Gelman et al. (2014)\"\"\"\n    \n    if np.shape(x) < (2,):\n        raise ValueError(\n            'Calculation of effective sample size requires multiple chains of the same length.')\n\n    try:\n        m, n = np.shape(x)\n    except ValueError:\n        return [effective_n(np.transpose(y)) for y in np.transpose(x)]\n        \n    s2 = gelman_rubin(x, return_var=True)\n    \n    negative_autocorr = False\n    t = 1\n    \n    variogram = lambda t: (sum(sum((x[j][i] - x[j][i-t])**2 for i in range(t,n)) for j in range(m)) \n                                / (m*(n - t)))\n    rho = np.ones(n)\n    # Iterate until the sum of consecutive estimates of autocorrelation is negative\n    while not negative_autocorr and (t < n):\n        \n        rho[t] = 1. - variogram(t)/(2.*s2)\n        \n        if not t % 2:\n            negative_autocorr = sum(rho[t-1:t+1]) < 0\n        \n        t += 1\n        \n    return int(m*n / (1 + 2*rho[1:t].sum()))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalculates the Gelman - Rubin diagnostic factor for a set of traces.", "response": "def gelman_rubin(x, return_var=False):\n    \"\"\" Returns estimate of R for a set of traces.\n\n    The Gelman-Rubin diagnostic tests for lack of convergence by comparing\n    the variance between multiple chains to the variance within each chain.\n    If convergence has been achieved, the between-chain and within-chain\n    variances should be identical. To be most effective in detecting evidence\n    for nonconvergence, each chain should have been initialized to starting\n    values that are dispersed relative to the target distribution.\n\n    Parameters\n    ----------\n    x : array-like\n      An array containing the 2 or more traces of a stochastic parameter. That is, an array of dimension m x n x k, where m is the number of traces, n the number of samples, and k the dimension of the stochastic.\n      \n    return_var : bool\n      Flag for returning the marginal posterior variance instead of R-hat (defaults of False).\n\n    Returns\n    -------\n    Rhat : float\n      Return the potential scale reduction factor, :math:`\\hat{R}`\n\n    Notes\n    -----\n\n    The diagnostic is computed by:\n\n      .. math:: \\hat{R} = \\sqrt{\\frac{\\hat{V}}{W}}\n\n    where :math:`W` is the within-chain variance and :math:`\\hat{V}` is\n    the posterior variance estimate for the pooled traces. This is the\n    potential scale reduction factor, which converges to unity when each\n    of the traces is a sample from the target posterior. Values greater\n    than one indicate that one or more chains have not yet converged.\n\n    References\n    ----------\n    Brooks and Gelman (1998)\n    Gelman and Rubin (1992)\"\"\"\n\n    if np.shape(x) < (2,):\n        raise ValueError(\n            'Gelman-Rubin diagnostic requires multiple chains of the same length.')\n\n    try:\n        m, n = np.shape(x)\n    except ValueError:\n        return [gelman_rubin(np.transpose(y)) for y in np.transpose(x)]\n\n    # Calculate between-chain variance\n    B_over_n = np.sum((np.mean(x, 1) - np.mean(x)) ** 2) / (m - 1)\n\n    # Calculate within-chain variances\n    W = np.sum(\n        [(x[i] - xbar) ** 2 for i,\n         xbar in enumerate(np.mean(x,\n                                   1))]) / (m * (n - 1))\n\n    # (over) estimate of variance\n    s2 = W * (n - 1) / n + B_over_n\n    \n    if return_var:\n        return s2\n\n    # Pooled posterior variance estimate\n    V = s2 + B_over_n / m\n\n    # Calculate PSRF\n    R = V / W\n\n    return np.sqrt(R)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _cut_time(gammas):\n\n    for i in range(len(gammas) - 1):\n\n        if not ((gammas[i + 1] > 0.0) & (gammas[i + 1] < gammas[i])):\n            return i\n\n    return i", "response": "Support function for iat. cut_time"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalculating the integrated autocorrelation time ( IAT ) given the trace from a Stochastic.", "response": "def iat(x, maxlag=None):\n    \"\"\"Calculate the integrated autocorrelation time (IAT), given the trace from a Stochastic.\"\"\"\n\n    if not maxlag:\n        # Calculate maximum lag to which autocorrelation is calculated\n        maxlag = _find_max_lag(x)\n\n    acr = [autocorr(x, lag) for lag in range(1, maxlag + 1)]\n\n    # Calculate gamma values\n    gammas = [(acr[2 * i] + acr[2 * i + 1]) for i in range(maxlag // 2)]\n\n    cut = _cut_time(gammas)\n\n    if cut + 1 == len(gammas):\n        print_(\"Not enough lag to calculate IAT\")\n\n    return np.sum(2 * gammas[:cut + 1]) - 1.0"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef check_valid_object_name(sequence):\n    names = []\n    for o in sequence:\n        if o.__name__ in names:\n            raise ValueError(\n                'A tallyable PyMC object called %s already exists. This will cause problems for some database backends.' %\n                o.__name__)\n        else:\n            names.append(o.__name__)", "response": "Check that the names of the objects are all different."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nseed the initial values for the current instance of the class.", "response": "def seed(self):\n        \"\"\"\n        Seed new initial values for the stochastics.\n        \"\"\"\n\n        for generation in self.generations:\n            for s in generation:\n                try:\n                    if s.rseed is not None:\n                        value = s.random(**s.parents.value)\n                except:\n                    pass"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nretrieving node with passed name", "response": "def get_node(self, node_name):\n        \"\"\"Retrieve node with passed name\"\"\"\n        for node in self.nodes:\n            if node.__name__ == node_name:\n                return node"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sample(self, iter, length=None, verbose=0):\n        self._cur_trace_index = 0\n        self.max_trace_length = iter\n        self._iter = iter\n        self.verbose = verbose or 0\n        self.seed()\n\n        # Assign Trace instances to tallyable objects.\n        self.db.connect_model(self)\n\n        # Initialize database -> initialize traces.\n        if length is None:\n            length = iter\n        self.db._initialize(self._funs_to_tally, length)\n\n        # Put traces on objects\n        for v in self._variables_to_tally:\n            v.trace = self.db._traces[v.__name__]\n\n        # Loop\n        self._current_iter = 0\n        self._loop()\n        self._finalize()", "response": "Draw samples from the posterior."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _finalize(self):\n        if self.status in ['running', 'halt']:\n            if self.verbose > 0:\n                print_('\\nSampling finished normally.')\n            self.status = 'ready'\n\n        self.save_state()\n        self.db._finalize()", "response": "Reset the status and tell the database to finalize the traces."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef stats(self, variables=None, alpha=0.05, start=0,\n              batches=100, chain=None, quantiles=(2.5, 25, 50, 75, 97.5)):\n        \"\"\"\n        Statistical output for variables.\n\n        :Parameters:\n        variables : iterable\n          List or array of variables for which statistics are to be\n          generated. If it is not specified, all the tallied variables\n          are summarized.\n\n        alpha : float\n          The alpha level for generating posterior intervals. Defaults to\n          0.05.\n\n        start : int\n          The starting index from which to summarize (each) chain. Defaults\n          to zero.\n\n        batches : int\n          Batch size for calculating standard deviation for non-independent\n          samples. Defaults to 100.\n\n        chain : int\n          The index for which chain to summarize. Defaults to None (all\n          chains).\n        \"\"\"\n\n        # If no names provided, run them all\n        if variables is None:\n            variables = self._variables_to_tally\n        else:\n            variables = [v for v in self.variables if v.__name__ in variables]\n\n        stat_dict = {}\n\n        # Loop over nodes\n        for variable in variables:\n            # Plot object\n            stat_dict[variable.__name__] = self.trace(\n                variable.__name__).stats(alpha=alpha, start=start,\n                                         batches=batches, chain=chain, quantiles=quantiles)\n\n        return stat_dict", "response": "Returns a dictionary of statistics for the given set of variables."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef write_csv(\n        self, filename, variables=None, alpha=0.05, start=0, batches=100,\n            chain=None, quantiles=(2.5, 25, 50, 75, 97.5)):\n        \"\"\"\n        Save summary statistics to a csv table.\n\n        :Parameters:\n\n        filename : string\n          Filename to save output.\n\n        variables : iterable\n          List or array of variables for which statistics are to be\n          generated. If it is not specified, all the tallied variables\n          are summarized.\n\n        alpha : float\n          The alpha level for generating posterior intervals. Defaults to\n          0.05.\n\n        start : int\n          The starting index from which to summarize (each) chain. Defaults\n          to zero.\n\n        batches : int\n          Batch size for calculating standard deviation for non-independent\n          samples. Defaults to 100.\n\n        chain : int\n          The index for which chain to summarize. Defaults to None (all\n          chains).\n        \"\"\"\n\n        # Append 'csv' suffix if there is no suffix on the filename\n        if filename.find('.') == -1:\n            filename += '.csv'\n\n        outfile = open(filename, 'w')\n\n        # Write header to file\n        header = 'Parameter, Mean, SD, MC Error, Lower 95% HPD, Upper 95% HPD, '\n        header += ', '.join(['q%s' % i for i in quantiles])\n        outfile.write(header + '\\n')\n\n        stats = self.stats(\n            variables=variables,\n            alpha=alpha,\n            start=start,\n            batches=batches,\n            chain=chain,\n            quantiles=quantiles)\n\n        if variables is None:\n            variables = sorted(stats.keys())\n\n        buffer = str()\n        for param in variables:\n\n            values = stats[param]\n\n            try:\n                # Multivariate node\n                shape = values['mean'].shape\n                indices = list(itertools.product(*[range(i) for i in shape]))\n\n                for i in indices:\n                    buffer += self._csv_str(param, values, quantiles, i)\n\n            except AttributeError:\n                # Scalar node\n                buffer += self._csv_str(param, values, quantiles)\n\n        outfile.write(buffer)\n\n        outfile.close()", "response": "Writes summary statistics to a CSV file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _csv_str(self, param, stats, quantiles, index=None):\n\n        buffer = param\n        if not index:\n            buffer += ', '\n        else:\n            buffer += '_' + '_'.join([str(i) for i in index]) + ', '\n\n        for stat in ('mean', 'standard deviation', 'mc error'):\n            buffer += str(stats[stat][index]) + ', '\n\n        # Index to interval label\n        iindex = [key.split()[-1] for key in stats.keys()].index('interval')\n        interval = list(stats.keys())[iindex]\n        buffer += ', '.join(stats[interval].T[index].astype(str))\n\n        # Process quantiles\n        qvalues = stats['quantiles']\n        for q in quantiles:\n            buffer += ', ' + str(qvalues[q][index])\n\n        return buffer + '\\n'", "response": "Support function for write_csv"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates a pretty - printed summary of the model s variables.", "response": "def summary(self, variables=None, alpha=0.05, start=0, batches=100,\n                chain=None, roundto=3):\n        \"\"\"\n        Generate a pretty-printed summary of the model's variables.\n\n        :Parameters:\n        alpha : float\n          The alpha level for generating posterior intervals. Defaults to\n          0.05.\n\n        start : int\n          The starting index from which to summarize (each) chain. Defaults\n          to zero.\n\n        batches : int\n          Batch size for calculating standard deviation for non-independent\n          samples. Defaults to 100.\n\n        chain : int\n          The index for which chain to summarize. Defaults to None (all\n          chains).\n\n        roundto : int\n          The number of digits to round posterior statistics.\n\n        quantiles : tuple or list\n          The desired quantiles to be calculated. Defaults to (2.5, 25, 50, 75, 97.5).\n        \"\"\"\n\n        # If no names provided, run them all\n        if variables is None:\n            variables = self._variables_to_tally\n        else:\n            variables = [\n                self.__dict__[\n                    i] for i in variables if self.__dict__[\n                        i] in self._variables_to_tally]\n\n        # Loop over nodes\n        for variable in variables:\n            variable.summary(\n                alpha=alpha, start=start, batches=batches, chain=chain,\n                roundto=roundto)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nassigns Trace instance to stochastics and deterministics and Database instance to self.", "response": "def _assign_database_backend(self, db):\n        \"\"\"Assign Trace instance to stochastics and deterministics and Database instance\n        to self.\n\n        :Parameters:\n          - `db` : string, Database instance\n            The name of the database module (see below), or a Database instance.\n\n        Available databases:\n          - `no_trace` : Traces are not stored at all.\n          - `ram` : Traces stored in memory.\n          - `txt` : Traces stored in memory and saved in txt files at end of\n                sampling.\n          - `sqlite` : Traces stored in sqlite database.\n          - `hdf5` : Traces stored in an HDF5 file.\n        \"\"\"\n        # Objects that are not to be tallied are assigned a no_trace.Trace\n        # Tallyable objects are listed in the _nodes_to_tally set.\n\n        no_trace = getattr(database, 'no_trace')\n        self._variables_to_tally = set()\n        for object in self.stochastics | self.deterministics:\n\n            if object.keep_trace:\n                self._variables_to_tally.add(object)\n                try:\n                    if object.mask is None:\n                        # Standard stochastic\n                        self._funs_to_tally[object.__name__] = object.get_value\n                    else:\n                        # Has missing values, so only fetch stochastic elements\n                        # using mask\n                        self._funs_to_tally[\n                            object.__name__] = object.get_stoch_value\n                except AttributeError:\n                    # Not a stochastic object, so no mask\n                    self._funs_to_tally[object.__name__] = object.get_value\n            else:\n                object.trace = no_trace.Trace(object.__name__)\n\n        check_valid_object_name(self._variables_to_tally)\n\n        # If not already done, load the trace backend from the database\n        # module, and assign a database instance to Model.\n        if isinstance(db, str):\n            if db in dir(database):\n                module = getattr(database, db)\n\n                # Assign a default name for the database output file.\n                if self._db_args.get('dbname') is None:\n                    self._db_args['dbname'] = self.__name__ + '.' + db\n\n                self.db = module.Database(**self._db_args)\n            elif db in database.__modules__:\n                raise ImportError(\n                    'Database backend `%s` is not properly installed. Please see the documentation for instructions.' % db)\n            else:\n                raise AttributeError(\n                    'Database backend `%s` is not defined in pymc.database.' % db)\n        elif isinstance(db, database.base.Database):\n            self.db = db\n            self.restore_sampler_state()\n        else:   # What is this for? DH.\n            self.db = db.Database(**self._db_args)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pause(self):\n        self.status = 'paused'\n        # The _loop method will react to 'paused' status and stop looping.\n        if hasattr(\n                self, '_sampling_thread') and self._sampling_thread.isAlive():\n            print_('Waiting for current iteration to finish...')\n            while self._sampling_thread.isAlive():\n                sleep(.1)", "response": "Pause the sampler. Sampling can be resumed by calling `icontinue`."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef halt(self):\n        self.status = 'halt'\n        # The _halt method is called by _loop.\n        if hasattr(\n                self, '_sampling_thread') and self._sampling_thread.isAlive():\n            print_('Waiting for current iteration to finish...')\n            while self._sampling_thread.isAlive():\n                sleep(.1)", "response": "Halt a sampling running in another thread."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef tally(self):\n        if self.verbose > 2:\n            print_(self.__name__ + ' tallying.')\n        if self._cur_trace_index < self.max_trace_length:\n            self.db.tally()\n\n        self._cur_trace_index += 1\n        if self.verbose > 2:\n            print_(self.__name__ + ' done tallying.')", "response": "Records the value of all tracing variables."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef isample(self, *args, **kwds):\n        self._exc_info = None\n        out = kwds.pop('out', sys.stdout)\n        kwds['progress_bar'] = False\n\n        def samp_targ(*args, **kwds):\n            try:\n                self.sample(*args, **kwds)\n            except:\n                self._exc_info = sys.exc_info()\n\n        self._sampling_thread = Thread(\n            target=samp_targ,\n            args=args,\n            kwargs=kwds)\n        self.status = 'running'\n        self._sampling_thread.start()\n        self.iprompt(out=out)", "response": "Sample the log file for the current locale."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef icontinue(self):\n        if self.status != 'paused':\n            print_(\n                \"No sampling to continue. Please initiate sampling with isample.\")\n            return\n\n        def sample_and_finalize():\n            self._loop()\n            self._finalize()\n\n        self._sampling_thread = Thread(target=sample_and_finalize)\n        self.status = 'running'\n        self._sampling_thread.start()\n        self.iprompt()", "response": "Restarts thread in interactive mode"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nstart a prompt listening to user input.", "response": "def iprompt(self, out=sys.stdout):\n        \"\"\"Start a prompt listening to user input.\"\"\"\n\n        cmds = \"\"\"\n        Commands:\n          i -- index: print current iteration index\n          p -- pause: interrupt sampling and return to the main console.\n                      Sampling can be resumed later with icontinue().\n          h -- halt:  stop sampling and truncate trace. Sampling cannot be\n                      resumed for this chain.\n          b -- bg:    return to the main console. The sampling will still\n                      run in a background thread. There is a possibility of\n                      malfunction if you interfere with the Sampler's\n                      state or the database during sampling. Use this at your\n                      own risk.\n        \"\"\"\n\n        print_(\"\"\"==============\n PyMC console\n==============\n\n        PyMC is now sampling. Use the following commands to query or pause the sampler.\n        \"\"\", file=out)\n        print_(cmds, file=out)\n\n        prompt = True\n        try:\n            while self.status in ['running', 'paused']:\n                    # sys.stdout.write('pymc> ')\n                if prompt:\n                    out.write('pymc > ')\n                    out.flush()\n\n                if self._exc_info is not None:\n                    a, b, c = self._exc_info\n                    reraise(a, b, c)\n\n                cmd = utils.getInput().strip()\n                if cmd == 'i':\n                    print_(\n                        'Current iteration: %i of %i' %\n                        (self._current_iter, self._iter), file=out)\n                    prompt = True\n                elif cmd == 'p':\n                    self.status = 'paused'\n                    break\n                elif cmd == 'h':\n                    self.status = 'halt'\n                    self._halt()\n                    break\n                elif cmd == 'b':\n                    return\n                elif cmd == '\\n':\n                    prompt = True\n                    pass\n                elif cmd == '':\n                    prompt = False\n                else:\n                    print_('Unknown command: ', cmd, file=out)\n                    print_(cmds, file=out)\n                    prompt = True\n\n        except KeyboardInterrupt:\n            if not self.status == 'ready':\n                self.status = 'halt'\n                self._halt()\n\n        if self.status == 'ready':\n            print_(\"Sampling terminated successfully.\", file=out)\n        else:\n            print_('Waiting for current iteration to finish...', file=out)\n            while self._sampling_thread.isAlive():\n                sleep(.1)\n            print_('Exiting interactive prompt...', file=out)\n            if self.status == 'paused':\n                print_(\n                    'Call icontinue method to continue, or call halt method to truncate traces and stop.',\n                    file=out)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_state(self):\n        state = dict(sampler={}, stochastics={})\n        # The state of the sampler itself.\n        for s in self._state:\n            state['sampler'][s] = getattr(self, s)\n\n        # The state of each stochastic parameter\n        for s in self.stochastics:\n            state['stochastics'][s.__name__] = s.value\n        return state", "response": "Return the sampler s current state in order to\n        restart sampling at a later time."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef save_state(self):\n        try:\n            self.db.savestate(self.get_state())\n        except:\n            print_('Warning, unable to save state.')\n            print_('Error message:')\n            traceback.print_exc()", "response": "Save the current state of the sampler."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrestoring the state of the sampler and to", "response": "def restore_sampler_state(self):\n        \"\"\"\n        Restore the state of the sampler and to\n        the state stored in the database.\n        \"\"\"\n\n        state = self.db.getstate() or {}\n\n        # Restore sampler's state\n        sampler_state = state.get('sampler', {})\n        self.__dict__.update(sampler_state)\n\n        # Restore stochastic parameters state\n        stoch_state = state.get('stochastics', {})\n        for sm in self.stochastics:\n            try:\n                sm.value = stoch_state[sm.__name__]\n            except:\n                warnings.warn(\n                    'Failed to restore state of stochastic %s from %s backend' %\n                    (sm.__name__, self.db.__name__))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef remember(self, chain=-1, trace_index=None):\n        if trace_index is None:\n            trace_index = randint(self._cur_trace_index)\n\n        for variable in self._variables_to_tally:\n            if isinstance(variable, Stochastic):\n                try:\n                    variable.value = self.trace(\n                        variable.__name__,\n                        chain=chain)[trace_index]\n                except:\n                    cls, inst, tb = sys.exc_info()\n                    warnings.warn(\n                        'Unable to remember value of variable %s. Original error: \\n\\n%s: %s' %\n                        (variable, cls.__name__, inst.message))", "response": "Rememberes the value of all tracing variables in the specified chain."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef trace(self, name, chain=-1):\n        if isinstance(name, str):\n            return self.db.trace(name, chain)\n        elif isinstance(name, Variable):\n            return self.db.trace(name.__name__, chain)\n        else:\n            raise ValueError(\n                'Name argument must be string or Variable, got %s.' %\n                name)", "response": "Returns the trace of a tallyable object stored in the database."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nround an array and recasts it to int. Also works on scalars.", "response": "def round_array(array_in):\n    \"\"\"\n    arr_out = round_array(array_in)\n\n    Rounds an array and recasts it to int. Also works on scalars.\n    \"\"\"\n    if isinstance(array_in, ndarray):\n        return np.round(array_in).astype(int)\n    else:\n        return int(np.round(array_in))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the histogram of a set of samples.", "response": "def histogram(a, bins=10, range=None, normed=False,\n              weights=None, axis=None, strategy=None):\n    \"\"\"histogram(a, bins=10, range=None, normed=False, weights=None, axis=None)\n                                                                   -> H, dict\n\n    Return the distribution of sample.\n\n    :Stochastics:\n      `a` : Array sample.\n      `bins` : Number of bins, or an array of bin edges, in which case the\n              range is not used. If 'Scott' or 'Freeman' is passed, then\n              the named method is used to find the optimal number of bins.\n      `range` : Lower and upper bin edges, default: [min, max].\n      `normed` :Boolean, if False, return the number of samples in each bin,\n              if True, return the density.\n      `weights` : Sample weights. The weights are normed only if normed is\n              True. Should weights.sum() not equal len(a), the total bin count\n              will not be equal to the number of samples.\n      `axis` : Specifies the dimension along which the histogram is computed.\n              Defaults to None, which aggregates the entire sample array.\n      `strategy` : Histogramming method (binsize, searchsorted or digitize).\n\n    :Return:\n      `H` : The number of samples in each bin.\n        If normed is True, H is a frequency distribution.\n      dict{ 'edges':      The bin edges, including the rightmost edge.\n        'upper':      Upper outliers.\n        'lower':      Lower outliers.\n        'bincenters': Center of bins.\n        'strategy': the histogramming method employed.}\n\n    :Examples:\n      >>> x = random.rand(100,10)\n      >>> H, D = histogram(x, bins=10, range=[0,1], normed=True)\n      >>> H2, D = histogram(x, bins=10, range=[0,1], normed=True, axis=0)\n\n    :SeeAlso: histogramnd\n    \"\"\"\n    weighted = weights is not None\n\n    a = asarray(a)\n    if axis is None:\n        a = atleast_1d(a.ravel())\n        if weighted:\n            weights = atleast_1d(weights.ravel())\n        axis = 0\n\n    # Define the range\n    if range is None:\n        mn, mx = a.min(), a.max()\n        if mn == mx:\n            mn = mn - .5\n            mx = mx + .5\n        range = [mn, mx]\n\n    # Find the optimal number of bins.\n    if bins is None or isinstance(bins, str):\n        bins = _optimize_binning(a, range, bins)\n\n    # Compute the bin edges if they are not given explicitely.\n    # For the rightmost bin, we want values equal to the right\n    # edge to be counted in the last bin, and not as an outlier.\n    # Hence, we shift the last bin by a tiny amount.\n    if not iterable(bins):\n        dr = diff(range) / bins * 1e-10\n        edges = linspace(range[0], range[1] + dr, bins + 1, endpoint=True)\n    else:\n        edges = asarray(bins, float)\n\n    dedges = diff(edges)\n    bincenters = edges[:-1] + dedges / 2.\n\n    # Number of bins\n    nbin = len(edges) - 1\n\n    # Measure of bin precision.\n    decimal = int(-log10(dedges.min()) + 10)\n\n    # Choose the fastest histogramming method\n    even = (len(set(around(dedges, decimal))) == 1)\n    if strategy is None:\n        if even:\n            strategy = 'binsize'\n        else:\n            if nbin > 30:  # approximative threshold\n                strategy = 'searchsort'\n            else:\n                strategy = 'digitize'\n    else:\n        if strategy not in ['binsize', 'digitize', 'searchsort']:\n            raise ValueError('Unknown histogramming strategy.', strategy)\n        if strategy == 'binsize' and not even:\n            raise ValueError(\n                'This binsize strategy cannot be used for uneven bins.')\n\n    # Stochastics for the fixed_binsize functions.\n    start = float(edges[0])\n    binwidth = float(dedges[0])\n\n    # Looping to reduce memory usage\n    block = 66600\n    slices = [slice(None)] * a.ndim\n    for i in arange(0, len(a), block):\n        slices[axis] = slice(i, i + block)\n        at = a[slices]\n        if weighted:\n            at = concatenate((at, weights[slices]), axis)\n            if strategy == 'binsize':\n                count = apply_along_axis(_splitinmiddle, axis, at,\n                                         flib.weighted_fixed_binsize, start, binwidth, nbin)\n            elif strategy == 'searchsort':\n                count = apply_along_axis(_splitinmiddle, axis, at,\n                                         _histogram_searchsort_weighted, edges)\n            elif strategy == 'digitize':\n                count = apply_along_axis(_splitinmiddle, axis, at,\n                                         _histogram_digitize, edges, normed)\n        else:\n            if strategy == 'binsize':\n                count = apply_along_axis(\n                    flib.fixed_binsize,\n                    axis,\n                    at,\n                    start,\n                    binwidth,\n                    nbin)\n            elif strategy == 'searchsort':\n                count = apply_along_axis(\n                    _histogram_searchsort,\n                    axis,\n                    at,\n                    edges)\n            elif strategy == 'digitize':\n                count = apply_along_axis(\n                    _histogram_digitize, axis, at, None, edges,\n                    normed)\n\n        if i == 0:\n            total = count\n        else:\n            total += count\n\n    # Outlier count\n    upper = total.take(array([-1]), axis)\n    lower = total.take(array([0]), axis)\n\n    # Non-outlier count\n    core = a.ndim * [slice(None)]\n    core[axis] = slice(1, -1)\n    hist = total[core]\n\n    if normed:\n        normalize = lambda x: atleast_1d(x / (x * dedges).sum())\n        hist = apply_along_axis(normalize, axis, hist)\n\n    return hist, {'edges': edges, 'lower': lower, 'upper': upper,\n                  'bincenters': bincenters, 'strategy': strategy}"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _histogram_fixed_binsize(a, start, width, n):\n\n    return flib.fixed_binsize(a, start, width, n)", "response": "Returns a histogram of evenly spaced n - bin edges."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _histogram_binsize_weighted(a, w, start, width, n):\n    return flib.weighted_fixed_binsize(a, w, start, width, n)", "response": "Returns a weighted version of the given array of samples with bin sizes w."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _optimize_binning(x, range, method='Freedman'):\n    N = x.shape[0]\n    if method.lower() == 'freedman':\n        s = sort(x)\n        IQR = s[int(N * .75)] - s[int(\n            N * .25)]  # Interquantile range (75% -25%)\n        width = 2 * IQR * N ** (-1. / 3)\n\n    elif method.lower() == 'scott':\n        width = 3.49 * x.std() * N ** (-1. / 3)\n    else:\n        raise ValueError('Method must be Scott or Freedman', method)\n    return int(diff(range) / width)", "response": "Find the optimal number of bins."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef normcdf(x, log=False):\n    y = np.atleast_1d(x).copy()\n    flib.normcdf(y)\n    if log:\n        if (y>0).all():\n            return np.log(y)\n        return -np.inf\n    return y", "response": "Normal cumulative density function."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlog - normal cumulative density function", "response": "def lognormcdf(x, mu, tau):\n    \"\"\"Log-normal cumulative density function\"\"\"\n    x = np.atleast_1d(x)\n    return np.array(\n        [0.5 * (1 - flib.derf(-(np.sqrt(tau / 2)) * (np.log(y) - mu))) for y in x])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninversing of normal cumulative density function.", "response": "def invcdf(x):\n    \"\"\"Inverse of normal cumulative density function.\"\"\"\n    x_flat = np.ravel(x)\n    x_trans = np.array([flib.ppnd16(y, 1) for y in x_flat])\n    return np.reshape(x_trans, np.shape(x))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ar1_gen(rho, mu, sigma, size=1):\n    mu = np.asarray(mu, float)\n    mu = np.resize(mu, size)\n    r = mu.copy()\n    r += np.random.randn(size) * sigma\n    r[0] = np.random.randn(1) * sigma / np.sqrt(1 - rho ** 2)\n    i = 0\n    while True:\n        yield r[i]\n        i += 1\n        if i == size:\n            break\n        r[i] += rho * (r[i - 1] - mu[i - 1])", "response": "Generate an autoregressive series of order one AR."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns an autoregressive series of order one AR.", "response": "def ar1(rho, mu, sigma, size=1):\n    \"\"\"Return an autoregressive series of order one AR(1).\n\n    .. math::\n        X_t = \\mu_t + \\rho (X_{t-1}-\\mu_{t-1} + \\epsilon_t\n\n    If mu is a sequence and size > len(mu), the algorithm loops through\n    mu.\n\n    :Stochastics:\n        rho : scalar in [0,1]\n        mu : scalar or sequence\n        sigma : scalar > 0\n        size : integer\n    \"\"\"\n    return np.array([x for x in ar1_gen(rho, mu, sigma, size)])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef autocorr(x, lag=1):\n\n    if not lag:\n        return 1\n    if lag < 0:\n        return\n    # x = np.squeeze(asarray(x))\n    #     mu = x.mean()\n    #     v = x.var()\n    #     return ((x[:-lag]-mu)*(x[lag:]-mu)).sum()/v/(len(x) - lag)\n    S = autocov(x, lag)\n    return S[0, 1] / sqrt(prod(diag(S)))", "response": "Sample autocorrelation at specified lag."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsamples autocovariance at specified lag.", "response": "def autocov(x, lag=1):\n    \"\"\"\n    Sample autocovariance at specified lag.\n    The autocovariance is a 2x2 matrix with the variances of\n    x[:-lag] and x[lag:] in the diagonal and the autocovariance\n    on the off-diagonal.\n    \"\"\"\n\n    if not lag:\n        return 1\n    if lag < 0:\n        return\n    return cov(x[:-lag], x[lag:], bias=1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a generator returning values from the object s trace.", "response": "def trace_generator(trace, start=0, stop=None, step=1):\n    \"\"\"Return a generator returning values from the object's trace.\n\n    Ex:\n    T = trace_generator(theta.trace)\n    T.next()\n    for t in T:...\n    \"\"\"\n    i = start\n    stop = stop or np.inf\n    size = min(trace.length(), stop)\n    while i < size:\n        index = slice(i, i + 1)\n        yield trace.gettrace(slicing=index)[0]\n        i += step"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndraw random variates from obj. random method.", "response": "def draw_random(obj, **kwds):\n    \"\"\"Draw random variates from obj.random method.\n\n    If the object has parents whose value must be updated, use\n    parent_name=trace_generator_function.\n\n    Ex:\n    R = draw_random(theta, beta=pymc.utils.trace_generator(beta.trace))\n    R.next()\n    \"\"\"\n    while True:\n        for k, v in six.iteritems(kwds):\n            obj.parents[k] = v.next()\n        yield obj.random()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef rec_setattr(obj, attr, value):\n    attrs = attr.split('.')\n    setattr(reduce(getattr, attrs[:-1], obj), attrs[-1], value)", "response": "Set object s attribute. May use dot notation."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef hpd(x, alpha):\n\n    # Make a copy of trace\n    x = x.copy()\n\n    # For multivariate node\n    if x.ndim > 1:\n\n        # Transpose first, then sort\n        tx = tr(x, list(range(x.ndim)[1:]) + [0])\n        dims = shape(tx)\n\n        # Container list for intervals\n        intervals = np.resize(0.0, (2,) + dims[:-1])\n\n        for index in make_indices(dims[:-1]):\n\n            try:\n                index = tuple(index)\n            except TypeError:\n                pass\n\n            # Sort trace\n            sx = sort(tx[index])\n\n            # Append to list\n            intervals[0][index], intervals[1][index] = calc_min_interval(sx, alpha)\n        \n        # Transpose back before returning\n        return array(intervals)\n\n    else:\n        # Sort univariate node\n        sx = sort(x)\n\n        return array(calc_min_interval(sx, alpha))", "response": "Calculate highest posterior density of array for given alpha."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a dictionary of requested quantiles from array x", "response": "def quantiles(x, qlist=(2.5, 25, 50, 75, 97.5)):\n    \"\"\"Returns a dictionary of requested quantiles from array\n\n    :Arguments:\n      x : Numpy array\n          An array containing MCMC samples\n      qlist : tuple or list\n          A list of desired quantiles (defaults to (2.5, 25, 50, 75, 97.5))\n\n    \"\"\"\n\n    # Make a copy of trace\n    x = x.copy()\n\n    # For multivariate node\n    if x.ndim > 1:\n        # Transpose first, then sort, then transpose back\n        sx = sort(x.T).T\n    else:\n        # Sort univariate node\n        sx = sort(x)\n\n    try:\n        # Generate specified quantiles\n        quants = [sx[int(len(sx) * q / 100.0)] for q in qlist]\n\n        return dict(zip(qlist, quants))\n\n    except IndexError:\n        print_(\"Too few elements for quantile calculation\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates output files that are compatible with CODA.", "response": "def coda_output(pymc_object, name=None, chain=-1):\n    \"\"\"Generate output files that are compatible with CODA\n\n    :Arguments:\n      pymc_object : Model or Node\n          A PyMC object containing MCMC output.\n\n    \"\"\"\n\n    print_()\n    print_(\"Generating CODA output\")\n    print_('=' * 50)\n\n    if name is None:\n        name = pymc_object.__name__\n\n    # Open trace file\n    trace_file = open(name + '_coda.out', 'w')\n\n    # Open index file\n    index_file = open(name + '_coda.ind', 'w')\n\n    variables = [pymc_object]\n    if hasattr(pymc_object, 'stochastics'):\n        variables = pymc_object.stochastics\n\n    # Initialize index\n    index = 1\n\n    # Loop over all parameters\n    for v in variables:\n\n        vname = v.__name__\n        print_(\"Processing\", vname)\n        try:\n            index = _process_trace(\n                trace_file,\n                index_file,\n                v.trace(chain=chain),\n                vname,\n                index)\n        except TypeError:\n            pass\n\n    # Close files\n    trace_file.close()\n    index_file.close()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _process_trace(trace_file, index_file, trace, name, index):\n\n    if ndim(trace) > 1:\n        trace = swapaxes(trace, 0, 1)\n        for i, seq in enumerate(trace):\n            _name = '%s_%s' % (name, i)\n            index = _process_trace(trace_file, index_file, seq, _name, index)\n    else:\n        index_buffer = '%s\\t%s\\t' % (name, index)\n        for i, val in enumerate(trace):\n            trace_file.write('%s\\t%s\\r\\n' % (i + 1, val))\n            index += 1\n        index_file.write('%s%s\\r\\n' % (index_buffer, index - 1))\n\n    return index", "response": "Support function for coda_output(); writes output to files"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning log - difference of two log - vectors.", "response": "def log_difference(lx, ly):\n    \"\"\"Returns log(exp(lx) - exp(ly)) without leaving log space.\"\"\"\n\n    # Negative log of double-precision infinity\n    li = -709.78271289338397\n    diff = ly - lx\n    # Make sure log-difference can succeed\n    if np.any(diff >= 0):\n        raise ValueError(\n            'Cannot compute log(x-y), because y>=x for some elements.')\n    # Otherwise evaluate log-difference\n    return lx + np.log(1. - np.exp(diff))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getInput():\n    input = ''\n\n    if sys.platform == 'win32':\n        import msvcrt\n        if msvcrt.kbhit():  # Check for a keyboard hit.\n            input += msvcrt.getch()\n            print_(input)\n        else:\n            time.sleep(.1)\n\n    else:  # Other platforms\n        # Posix will work with sys.stdin or sys.stdin.fileno()\n        # Mac needs the file descriptor.\n        # This solution does not work for windows since select\n        # expects a socket, and I have no idea how to create a\n        # socket from standard input.\n        sock = sys.stdin.fileno()\n\n        # select(rlist, wlist, xlist, timeout)\n        while len(select.select([sock], [], [], 0.1)[0]) > 0:\n            input += decode(os.read(sock, 4096))\n\n    return input", "response": "Read the input buffer without blocking the system."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncrawl out from v to find the biggest dataless submodel containing v.", "response": "def crawl_dataless(sofar, gens):\n    \"\"\"\n    Crawls out from v to find the biggest dataless submodel containing v.\n    TODO: Let MCMC start the crawl from its last generation. It doesn't\n    matter that there won't be one contiguous group.\n    \"\"\"\n    new_gen = set([])\n    all_ext_parents = set()\n    for s in gens[-1]:\n        all_ext_parents.update(s.extended_parents)\n\n    for p in all_ext_parents:\n        if p._random is not None and not p.observed:\n            if len(p.extended_children - sofar) == 0:\n                new_gen.add(p)\n    if len(new_gen) == 0:\n        return sofar, gens\n    else:\n        sofar |= new_gen\n        gens.append(new_gen)\n        return crawl_dataless(sofar, gens)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfinding all the generations that are in the current generation.", "response": "def find_generations(container, with_data=False):\n    \"\"\"\n    A generation is the set of stochastic variables that only has parents in\n    previous generations.\n    \"\"\"\n\n    generations = []\n\n    # Find root generation\n    generations.append(set())\n    all_children = set()\n    if with_data:\n        stochastics_to_iterate = container.stochastics | container.observed_stochastics\n    else:\n        stochastics_to_iterate = container.stochastics\n    for s in stochastics_to_iterate:\n        all_children.update(s.extended_children & stochastics_to_iterate)\n    generations[0] = stochastics_to_iterate - all_children\n\n    # Find subsequent _generations\n    children_remaining = True\n    gen_num = 0\n    while children_remaining:\n        gen_num += 1\n\n        # Find children of last generation\n        generations.append(set())\n        for s in generations[gen_num - 1]:\n            generations[gen_num].update(\n                s.extended_children & stochastics_to_iterate)\n\n        # Take away stochastics that have parents in the current generation.\n        thisgen_children = set()\n        for s in generations[gen_num]:\n            thisgen_children.update(\n                s.extended_children & stochastics_to_iterate)\n        generations[gen_num] -= thisgen_children\n\n        # Stop when no subsequent _generations remain\n        if len(thisgen_children) == 0:\n            children_remaining = False\n    return generations"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nappend a node to the list.", "response": "def append(nodelist, node, label=None, sep='_'):\n    \"\"\"\n    Append function to automate the naming of list elements in Containers.\n\n    :Arguments:\n        - `nodelist` : List containing nodes for Container.\n        - `node` : Node to be added to list.\n        - `label` : Label to be appended to list (If not passed,\n        defaults to element number).\n        - `sep` : Separator character for label (defaults to underscore).\n\n    :Return:\n        - `nodelist` : Passed list with node added.\n\n    \"\"\"\n\n    nname = node.__name__\n\n    # Determine label\n    label = label or len(nodelist)\n\n    # Look for separator at the end of name\n    ind = nname.rfind(sep)\n\n    # If there is no separator, we will remove last character and\n    # replace with label.\n    node.__name__ = nname[:ind] + sep + str(label)\n\n    nodelist.append(node)\n\n    return nodelist"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nextending the set of children by conditionally stochastic descendants.", "response": "def extend_children(children):\n    \"\"\"\n    extend_children(children)\n\n    Returns a set containing\n    nearest conditionally stochastic (Stochastic, not Deterministic) descendants.\n    \"\"\"\n    new_children = copy(children)\n    need_recursion = False\n    dtrm_children = set()\n\n    for child in children:\n        if isinstance(child, Deterministic):\n            new_children |= child.children\n            dtrm_children.add(child)\n            need_recursion = True\n\n    new_children -= dtrm_children\n\n    if need_recursion:\n        new_children = extend_children(new_children)\n\n    return new_children"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nextends parents of a tree with parents.", "response": "def extend_parents(parents):\n    \"\"\"\n    extend_parents(parents)\n\n    Returns a set containing\n    nearest conditionally stochastic (Stochastic, not Deterministic) ancestors.\n    \"\"\"\n    new_parents = set()\n\n    for parent in parents:\n\n        new_parents.add(parent)\n\n        if isinstance(parent, DeterministicBase):\n            new_parents.remove(parent)\n            new_parents |= parent.extended_parents\n\n        elif isinstance(parent, ContainerBase):\n            for contained_parent in parent.stochastics:\n                new_parents.add(contained_parent)\n            for contained_parent in parent.deterministics:\n                new_parents |= contained_parent.extended_parents\n\n    return new_parents"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the gradient of this logp with respect to variable.", "response": "def logp_partial_gradient(self, variable, calculation_set=None):\n        \"\"\"\n        gets the logp gradient of this deterministic with respect to variable\n        \"\"\"\n        if self.verbose > 0:\n            print_('\\t' + self.__name__ + ': logp_partial_gradient accessed.')\n\n        if not (datatypes.is_continuous(variable)\n                and datatypes.is_continuous(self)):\n            return zeros(shape(variable.value))\n\n        # loop through all the parameters and add up all the gradients of log p\n        # with respect to the approrpiate variable\n        gradient = builtins.sum(\n            [child.logp_partial_gradient(self,\n                                         calculation_set) for child in self.children])\n\n        totalGradient = 0\n        for parameter, value in six.iteritems(self.parents):\n            if value is variable:\n\n                totalGradient += self.apply_jacobian(\n                    parameter, variable, gradient)\n\n        return np.reshape(totalGradient, shape(variable.value))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef gen_lazy_function(self):\n\n        # If value argument to __init__ was None, draw value from random\n        # method.\n        if self._value is None:\n\n            # Use random function if provided\n            if self._random is not None:\n                self.value = self._random(**self._parents.value)\n\n            # Otherwise leave initial value at None and warn.\n            else:\n                raise ValueError(\n                    'Stochastic ' +\n                    self.__name__ +\n                    \"'s value initialized to None; no initial value or random method provided.\")\n\n        arguments = {}\n        arguments.update(self.parents)\n        arguments['value'] = self\n        arguments = DictContainer(arguments)\n\n        self._logp = LazyFunction(fun=self._logp_fun,\n                                  arguments=arguments,\n                                  ultimate_args=self.extended_parents | set(\n                                      [self]),\n                                  cache_depth=self._cache_depth)\n        self._logp.force_compute()\n\n        self._logp_partial_gradients = {}\n\n        for parameter, function in six.iteritems(self._logp_partial_gradient_functions):\n            lazy_logp_partial_gradient = LazyFunction(fun=function,\n                                                      arguments=arguments,\n                                                      ultimate_args=self.extended_parents | set(\n                                                          [self]),\n                                                      cache_depth=self._cache_depth)\n            # lazy_logp_partial_gradient.force_compute()\n            self._logp_partial_gradients[parameter] = lazy_logp_partial_gradient", "response": "Generates a lazy function that can be used to generate the value of the object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef logp_gradient_contribution(self, calculation_set=None):\n        # NEED some sort of check to see if the log p calculation has recently\n        # failed, in which case not to continue\n\n        return self.logp_partial_gradient(self, calculation_set) + builtins.sum(\n            [child.logp_partial_gradient(self, calculation_set) for child in self.children])", "response": "Calculates the gradient of the joint log posterior with respect to self. logp_partial_gradient"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef logp_partial_gradient(self, variable, calculation_set=None):\n        if (calculation_set is None) or (self in calculation_set):\n\n            if not datatypes.is_continuous(variable):\n                return zeros(shape(variable.value))\n\n            if variable is self:\n                try:\n                    gradient_func = self._logp_partial_gradients['value']\n\n                except KeyError:\n                    raise NotImplementedError(\n                        repr(\n                            self) +\n                        \" has no gradient function for 'value'\")\n\n                gradient = np.reshape(\n                    gradient_func.get(\n                    ),\n                    np.shape(\n                        variable.value))\n            else:\n                gradient = builtins.sum(\n                    [self._pgradient(variable,\n                                     parameter,\n                                     value) for parameter,\n                     value in six.iteritems(self.parents)])\n\n            return gradient\n        else:\n            return 0", "response": "Calculates the partial gradient of the posterior of self with respect to variable."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndrawing a new value for a Stochastic condition on its parents and returns it.", "response": "def random(self):\n        \"\"\"\n        Draws a new value for a stoch conditional on its parents\n        and returns it.\n\n        Raises an error if no 'random' argument was passed to __init__.\n        \"\"\"\n\n        if self._random:\n            # Get current values of parents for use as arguments for _random()\n            r = self._random(**self.parents.value)\n        else:\n            raise AttributeError(\n                'Stochastic ' +\n                self.__name__ +\n                ' does not know how to draw its value, see documentation')\n\n        if self.shape:\n            r = np.reshape(r, self.shape)\n\n        # Set Stochastic's value to drawn value\n        if not self.observed:\n            self.value = r\n\n        return r"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef save_sampler(sampler):\n    db = sampler.db\n    fnode = tables.filenode.newnode(db._h5file, where='/', name='__sampler__')\n    import pickle\n    pickle.dump(sampler, fnode)", "response": "Dumps a sampler into its hdf5 database."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef restore_sampler(fname):\n    hf = tables.open_file(fname)\n    fnode = hf.root.__sampler__\n    import pickle\n    sampler = pickle.load(fnode)\n    return sampler", "response": "Creates a new sampler from an hdf5 database."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef gettrace(self, burn=0, thin=1, chain=-1, slicing=None):\n\n        if chain is not None:\n            vlarrays = [self._vlarrays[chain]]\n        else:\n            vlarrays = self._vlarrays\n\n        for i, vlarray in enumerate(vlarrays):\n            if slicing is not None:\n                burn, stop, thin = slicing.start, slicing.stop, slicing.step\n            if slicing is None or stop is None:\n                stop = len(vlarray)\n            col = vlarray[burn:stop:thin]\n            if i == 0:\n                data = np.asarray(col)\n            else:\n                data = hstack((data, col))\n\n        return data", "response": "Return the trace of the transient steps in the chain."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef length(self, chain=-1):\n        if chain is not None:\n            return len(self._vlarrays[chain])\n        else:\n            return sum(map(len, self._vlarrays))", "response": "Returns the length of the trace."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef tally(self, chain):\n        self.db._rows[chain][self.name] = self._getfunc()", "response": "Adds current value to trace"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the trace of the transient state.", "response": "def gettrace(self, burn=0, thin=1, chain=-1, slicing=None):\n        \"\"\"Return the trace (last by default).\n\n        :Parameters:\n        burn : integer\n          The number of transient steps to skip.\n        thin : integer\n          Keep one in thin.\n        chain : integer\n          The index of the chain to fetch. If None, return all chains. The\n          default is to return the last chain.\n        slicing : slice object\n          A slice overriding burn and thin assignement.\n        \"\"\"\n\n        if chain is not None:\n            tables = [self.db._gettables()[chain], ]\n        else:\n            tables = self.db._gettables()\n\n        for i, table in enumerate(tables):\n            if slicing is not None:\n                burn, stop, thin = slicing.start, slicing.stop, slicing.step\n            if slicing is None or stop is None:\n                stop = table.nrows\n            col = table.read(start=burn, stop=stop, step=thin, field=self.name)\n            if i == 0:\n                data = np.asarray(col)\n            else:\n                data = np.append(data, col, axis=0)\n\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef hdf5_col(self, chain=-1):\n        return self.db._tables[chain].colinstances[self.name]", "response": "Return a pytables column object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the length of the trace.", "response": "def length(self, chain=-1):\n        \"\"\"Return the length of the trace.\n\n        :Parameters:\n        chain : int or None\n          The chain index. If None, returns the combined length of all chains.\n        \"\"\"\n        if chain is not None:\n            tables = [self.db._gettables()[chain], ]\n        else:\n            tables = self.db._gettables()\n\n        n = asarray([table.nrows for table in tables])\n        return n.sum()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef connect_model(self, model):\n\n        # Changed this to allow non-Model models. -AP\n        if isinstance(model, pymc.Model):\n            self.model = model\n        else:\n            raise AttributeError('Not a Model instance.')\n\n        # Restore the state of the Model from an existing Database.\n        # The `load` method will have already created the Trace objects.\n        if hasattr(self, '_state_'):\n            names = set()\n            for morenames in self.trace_names:\n                names.update(morenames)\n            for name, fun in six.iteritems(model._funs_to_tally):\n                if name in self._traces:\n                    self._traces[name]._getfunc = fun\n                    names.remove(name)\n            if len(names) > 0:\n                raise RuntimeError(\n                    \"Some objects from the database have not been assigned a getfunc: %s\" %\n                    ', '.join(names))\n\n        # Create a fresh new state. This is now taken care of in initialize.\n        else:\n            for name, fun in six.iteritems(model._funs_to_tally):\n                if np.array(fun()).dtype is np.dtype('object'):\n                    self._traces[\n                        name] = TraceObject(\n                            name,\n                            getfunc=fun,\n                            db=self)\n                else:\n                    self._traces[name] = Trace(name, getfunc=fun, db=self)", "response": "Link the Database to the given model."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _initialize(self, funs_to_tally, length):\n        i = self.chains\n        self._chains.append(\n            self._h5file.create_group(\n                \"/\",\n                'chain%d' %\n                i,\n                'Chain #%d' %\n                i))\n        current_object_group = self._h5file.create_group(\n            self._chains[-1],\n            'group0',\n            'Group storing objects.')\n        group_counter = 0\n        object_counter = 0\n\n        # Create the Table in the chain# group, and ObjectAtoms in\n        # chain#/group#.\n        table_descr = {}\n        for name, fun in six.iteritems(funs_to_tally):\n\n            arr = asarray(fun())\n\n            if arr.dtype is np.dtype('object'):\n\n                self._traces[name]._vlarrays.append(self._h5file.create_vlarray(\n                    current_object_group,\n                    name,\n                    tables.ObjectAtom(),\n                    title=name + ' samples.',\n                    filters=self.filter))\n\n                object_counter += 1\n                if object_counter % 4096 == 0:\n                    group_counter += 1\n                    current_object_group = self._h5file.create_group(\n                        self._chains[-1],\n                        'group%d' % group_counter, 'Group storing objects.')\n\n            else:\n                table_descr[name] = tables.Col.from_dtype(\n                    dtype((arr.dtype, arr.shape)))\n\n        table = self._h5file.create_table(self._chains[-1],\n                                         'PyMCsamples',\n                                         table_descr,\n                                         title='PyMC samples',\n                                         filters=self.filter,\n                                         expectedrows=length)\n\n        self._tables.append(table)\n        self._rows.append(self._tables[-1].row)\n\n        # Store data objects\n        for object in self.model.observed_stochastics:\n            if object.keep_trace is True:\n                setattr(table.attrs, object.__name__, object.value)\n\n       # Make sure the variables have a corresponding Trace instance.\n        for name, fun in six.iteritems(funs_to_tally):\n            if name not in self._traces:\n                if np.array(fun()).dtype is np.dtype('object'):\n                    self._traces[\n                        name] = TraceObject(\n                            name,\n                            getfunc=fun,\n                            db=self)\n                else:\n                    self._traces[name] = Trace(name, getfunc=fun, db=self)\n\n            self._traces[name]._initialize(self.chains, length)\n\n        self.trace_names.append(list(funs_to_tally.keys()))\n        self.chains += 1", "response": "Initialize the internal state of the object atom tables."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nstoring a dictionnary containing the state of the Model and its StepMethods.", "response": "def savestate(self, state, chain=-1):\n        \"\"\"Store a dictionnary containing the state of the Model and its\n        StepMethods.\"\"\"\n        cur_chain = self._chains[chain]\n        if hasattr(cur_chain, '_state_'):\n            cur_chain._state_[0] = state\n        else:\n            s = self._h5file.create_vlarray(\n                cur_chain,\n                '_state_',\n                tables.ObjectAtom(),\n                title='The saved state of the sampler',\n                filters=self.filter)\n            s.append(state)\n        self._h5file.flush()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _model_trace_description(self):\n        D = {}\n        for name, fun in six.iteritems(self.model._funs_to_tally):\n            arr = asarray(fun())\n            D[name] = tables.Col.from_dtype(dtype((arr.dtype, arr.shape)))\n        return D, {}", "response": "Return a dict containing the table description and the ObjectAtoms to be created."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmaking sure the next objects to be tallied are compatible with the stored trace.", "response": "def _check_compatibility(self):\n        \"\"\"Make sure the next objects to be tallied are compatible with the\n        stored trace.\"\"\"\n        stored_descr = self._file_trace_description()\n        try:\n            for k, v in self._model_trace_description():\n                assert(stored_descr[k][0] == v[0])\n        except:\n            raise ValueError(\n                \"The objects to tally are incompatible with the objects stored in the file.\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _gettables(self):\n\n        groups = self._h5file.list_nodes(\"/\")\n        if len(groups) == 0:\n            return []\n        else:\n            return [\n                gr.PyMCsamples for gr in groups if gr._v_name[:5] == 'chain']", "response": "Return a list of hdf5 tables name PyMCsamples."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_attr(self, name, object, description='', chain=-1, array=False):\n\n        if not np.isscalar(chain):\n            raise TypeError(\"chain must be a scalar integer.\")\n\n        table = self._tables[chain]\n\n        if array is False:\n            table.set_attr(name, object)\n            obj = getattr(table.attrs, name)\n        else:\n            # Create an array in the group\n            if description == '':\n                description = name\n            group = table._g_getparent()\n            self._h5file.create_array(group, name, object, description)\n            obj = getattr(group, name)\n\n        setattr(self, name, obj)", "response": "Add an attribute to the chain."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef regularize_array(A):\n    if not isinstance(A,np.ndarray):\n        A = np.array(A, dtype=float)\n    else:\n        A = np.asarray(A, dtype=float)\n\n    if len(A.shape) <= 1:\n        return A.reshape(-1,1)\n\n    elif A.shape[-1]>1:\n        return A.reshape(-1, A.shape[-1])\n\n    else:\n        return A", "response": "Takes an np. ndarray as an input and returns a new array with the same shape as A."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef import_item(name):\n    package = '.'.join(name.split('.')[0:-1])\n    obj = name.split('.')[-1]\n\n    if package:\n        module = __import__(package,fromlist=[obj])\n        return module.__dict__[obj]\n    else:\n        return __import__(obj)", "response": "Imports a nested module."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_distance_metric(self, distance_fun_name, distance_fun_module, with_x):\n\n        if self.ampsq_is_diag:\n            kls = covariance_wrapper_with_diag\n        else:\n            kls = covariance_wrapper\n        new_fun = kls(self.cov_fun_name, self.cov_fun_module, self.extra_cov_params, distance_fun_name, distance_fun_module, with_x=with_x)\n        self.wrappers.append(new_fun)\n        # try:\n        setattr(self, distance_fun_name, new_fun)\n        # except:\n        #     pass\n        return new_fun", "response": "Adds a distance metric to the current object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fit(self, method='fmin_powell', iterlim=1000, tol=.0001, verbose=0,\n            no_callback=False, **kwargs):\n        \"\"\"\n        N.fit(method='fmin_powell', iterlim=1000, tol=.001):\n\n        Causes the normal approximation object to fit itself.\n\n        method: May be one of the following, from the scipy.optimize package:\n            -fmin_l_bfgs_b\n            -fmin_ncg\n            -fmin_cg\n            -fmin_powell\n            -fmin\n\n        no_callback: Boolean indicating whether or not to use a callback\n        function. If True and a callback keyword is provided in kwargs, then\n        the user-supplied callback will be used. Otherwise, if False,\n        and verbose > 0, a default callback will print iteration progress.\n\n        The kwargs are passed to the scipy.optimize functions. See there\n        for more information.\n        \"\"\"\n        self.tol = tol\n        self.method = method\n        self.verbose = verbose\n\n        p = zeros(self.len, dtype=float)\n        for stochastic in self.stochastics:\n            p[self._slices[stochastic]] = ravel(stochastic.value)\n\n        if not self.method == 'newton':\n            if not scipy_imported:\n                raise ImportError('Scipy is required to use EM and NormApprox')\n\n        default_callback = (verbose > 0 and not no_callback)\n        if default_callback and 'callback' in kwargs:\n            raise ValueError(\"For user-provided callback and verbose output\"\n                             \" set use_callback to True\")\n\n        if default_callback:\n            def callback(p):\n                try:\n                    print_('Current log-probability : %f' % self.logp)\n                except ZeroProbability:\n                    print_('Current log-probability : %f' % -Inf)\n        elif 'callback' in kwargs:\n            callback = kwargs.pop('callback')\n        else:\n            def callback(p):\n                pass\n\n        if self.method == 'fmin_ncg':\n            p = fmin_ncg(f=self.func,\n                         x0=p,\n                         fprime=self.gradfunc,\n                         fhess=self.hessfunc,\n                         epsilon=self.eps,\n                         maxiter=iterlim,\n                         callback=callback,\n                         avextol=tol,\n                         disp=verbose,\n                         **kwargs)\n\n        elif self.method == 'fmin':\n\n            p = fmin(func=self.func,\n                     x0=p,\n                     callback=callback,\n                     maxiter=iterlim,\n                     ftol=tol,\n                     disp=verbose, **kwargs)\n\n        elif self.method == 'fmin_powell':\n            p = fmin_powell(func=self.func,\n                            x0=p,\n                            callback=callback,\n                            maxiter=iterlim,\n                            ftol=tol,\n                            disp=verbose, **kwargs)\n\n        elif self.method == 'fmin_cg':\n            p = fmin_cg(f=self.func, x0=p,\n                        fprime=self.gradfunc,\n                        epsilon=self.eps,\n                        callback=callback,\n                        maxiter=iterlim,\n                        gtol=tol,\n                        disp=verbose, **kwargs)\n\n        elif self.method == 'fmin_l_bfgs_b':\n            from scipy import __version__ as sp_version\n            from distutils.version import LooseVersion\n            if LooseVersion(sp_version) >= LooseVersion('0.12.0'):\n                p = fmin_l_bfgs_b(func=self.func,\n                                  x0=p,\n                                  fprime=self.gradfunc,\n                                  epsilon=self.eps,\n                                  callback=callback,\n                                  pgtol=tol,\n                                  iprint=verbose - 1,\n                                  **kwargs)[0]\n            else:\n                if verbose > 0:\n                    from warnings import warn\n                    warn(\"Callbacks are not available for fmin_l_bfgs_b in \"\n                         \"SciPy < 0.12.0. Optimization progress will not be\"\n                         \"displayed.\", UserWarning)\n                p = fmin_l_bfgs_b(func=self.func,\n                                  x0=p,\n                                  fprime=self.gradfunc,\n                                  epsilon=self.eps,\n                                  pgtol=tol,\n                                  iprint=verbose - 1,\n                                  **kwargs)[0]\n        else:\n            raise ValueError('Method unknown.')\n\n        self._set_stochastics(p)\n        self._mu = p\n\n        try:\n            self.logp_at_max = self.logp\n        except:\n            raise RuntimeError(\n                'Posterior probability optimization converged to value with zero probability.')\n\n        lnL = sum([x.logp for x in self.observed_stochastics]\n                  )  # log-likelihood of observed stochastics\n        self.lnL = lnL\n        try:\n            self.AIC = 2. * (self.len - lnL)  # 2k - 2 ln(L)\n            self.AICc = self.AIC + ((2 * self.len * (self.len + 1)) / float(self.data_len - self.len - 1))\n        except Exception as e:\n            print('Cannot calculate AIC:', e)\n            self.AICc = self.AIC = -Inf\n        try:\n            self.BIC = self.len * log(\n                self.data_len) - 2. * lnL  # k ln(n) - 2 ln(L)\n        except FloatingPointError as e:\n            print('Cannot calculate BIC:', e)\n            self.BIC = -Inf\n\n        self.fitted = True", "response": "Fits the normal approximation object to obtain a new object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the function that gets passed to the optimizers.", "response": "def func(self, p):\n        \"\"\"\n        The function that gets passed to the optimizers.\n        \"\"\"\n        self._set_stochastics(p)\n        try:\n            return -1. * self.logp\n        except ZeroProbability:\n            return Inf"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the gradient - computing function that gets passed to the optimizers.", "response": "def gradfunc(self, p):\n        \"\"\"\n        The gradient-computing function that gets passed to the optimizers,\n        if needed.\n        \"\"\"\n        self._set_stochastics(p)\n        for i in xrange(self.len):\n            self.grad[i] = self.diff(i)\n\n        return -1 * self.grad"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef i_logp(self, index):\n        all_relevant_stochastics = set()\n        p, i = self.stochastic_indices[index]\n        try:\n            return p.logp + logp_of_set(p.extended_children)\n        except ZeroProbability:\n            return -Inf", "response": "Evaluates the log - probability of the Markov blanket of a particular index."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef diff2(self, i, j):\n\n        old_val = copy(self[j])\n\n        if not self.stochastic_indices[i][\n                0] in self.stochastic_indices[j][0].moral_neighbors:\n            return 0.\n\n        def diff_for_diff(val):\n            self[j] = val\n            return self.diff(i)\n\n        d = derivative(\n            func=diff_for_diff,\n            x0=old_val,\n            dx=self.eps[j],\n            n=1,\n            order=self.diff_order)\n\n        self[j] = old_val\n        return d", "response": "Mixed second derivative. Differentiates wrt both indices."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompute the gradient and hessian of the current object. Used for optimization.", "response": "def grad_and_hess(self):\n        \"\"\"\n        Computes self's gradient and Hessian. Used if the\n        optimization method for a NormApprox doesn't\n        use gradients and hessians, for instance fmin.\n        \"\"\"\n        for i in xrange(self.len):\n\n            di = self.diff(i)\n            self.grad[i] = di\n            self.hess[i, i] = self.diff(i, 2)\n\n            if i < self.len - 1:\n\n                for j in xrange(i + 1, self.len):\n                    dij = self.diff2(i, j)\n\n                    self.hess[i, j] = dij\n                    self.hess[j, i] = dij"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreverts all the current set of stochastics to the maximum value.", "response": "def revert_to_max(self):\n        \"\"\"\n        N.revert_to_max()\n\n        Sets all N's stochastics to their MAP values.\n        \"\"\"\n        try:\n            self._set_stochastics([self.mu[s] for s in self.stochastics])\n        except KeyError:\n            self._set_stochastics(self.mu[self.stochastics])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndraw all the stochastics from the posterior and set the current N s stochastics to random values drawn from the posterior.", "response": "def draw(self):\n        \"\"\"\n        N.draw()\n\n        Sets all N's stochastics to random values drawn from\n        the normal approximation to the posterior.\n        \"\"\"\n        devs = normal(size=self._sig.shape[1])\n        p = inner(self._sig, devs) + self._mu\n        self._set_stochastics(p)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate several work requests for the same callable with different arguments.", "response": "def makeRequests(callable_, args_list, callback=None,\n                 exc_callback=_handle_thread_exception):\n    \"\"\"Create several work requests for same callable with different arguments.\n\n    Convenience function for creating several work requests for the same\n    callable where each invocation of the callable receives different values\n    for its arguments.\n\n    ``args_list`` contains the parameters for each invocation of callable.\n    Each item in ``args_list`` should be either a 2-item tuple of the list of\n    positional arguments and a dictionary of keyword arguments or a single,\n    non-tuple argument.\n\n    See docstring for ``WorkRequest`` for info on ``callback`` and\n    ``exc_callback``.\n\n    \"\"\"\n    requests = []\n    for item in args_list:\n        if isinstance(item, tuple):\n            requests.append(\n                WorkRequest(callable_, item[0], item[1], callback=callback,\n                            exc_callback=exc_callback)\n            )\n        else:\n            requests.append(\n                WorkRequest(callable_, [item], None, callback=callback,\n                            exc_callback=exc_callback)\n            )\n    return requests"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\npartitions work arrays for multithreaded addition and multiplication", "response": "def thread_partition_array(x):\n    \"Partition work arrays for multithreaded addition and multiplication\"\n    n_threads = get_threadpool_size()\n    if len(x.shape) > 1:\n        maxind = x.shape[1]\n    else:\n        maxind = x.shape[0]\n    bounds = np.array(np.linspace(0, maxind, n_threads + 1), dtype='int')\n    cmin = bounds[:-1]\n    cmax = bounds[1:]\n    return cmin, cmax"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run(self):\n        while True:\n            if self._dismissed.isSet():\n                # we are dismissed, break out of loop\n                break\n\n            # get next work request.\n            request = self._requests_queue.get()\n            # print 'Worker thread %s running request %s' %(self, request)\n\n            if self._dismissed.isSet():\n                # we are dismissed, put back request in queue and exit loop\n                self._requests_queue.put(request)\n                break\n            try:\n                result = request.callable(*request.args, **request.kwds)\n                if request.callback:\n                    request.callback(request, result)\n                del result\n                self._requests_queue.task_done()\n            except:\n                request.exception = True\n                if request.exc_callback:\n                    request.exc_callback(request)\n                self._requests_queue.task_done()\n            finally:\n                request.self_destruct()", "response": "Repeatedly process the job queue until told to exit."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef createWorkers(self, num_workers):\n        for i in range(num_workers):\n            self.workers.append(WorkerThread(self._requests_queue))", "response": "Add num_workers worker threads to the pool."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef dismissWorkers(self, num_workers):\n        for i in range(min(num_workers, len(self.workers))):\n            worker = self.workers.pop()\n            worker.dismiss()", "response": "Tell num_workers worker threads to quit after their current task."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef setNumWorkers(self, num_workers):\n        cur_num = len(self.workers)\n        if cur_num > num_workers:\n            self.dismissWorkers(cur_num - num_workers)\n        else:\n            self.createWorkers(num_workers - cur_num)", "response": "Set number of worker threads to num_workers"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nput a work request into the work queue and save its id for later.", "response": "def putRequest(self, request, block=True, timeout=0):\n        \"\"\"Put work request into work queue and save its id for later.\"\"\"\n        # don't reuse old work requests\n        # print '\\tthread pool putting work request %s'%request\n        self._requests_queue.put(request, block, timeout)\n        self.workRequests[request.requestID] = request"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef zip(value=data, mu=mu, psi=psi):\n\n    # Initialize likeihood\n    like = 0.0\n\n    # Loop over data\n    for x in value:\n\n        if not x:\n            # Zero values\n            like += np.log((1. - psi) + psi * np.exp(-mu))\n\n        else:\n            # Non-zero values\n            like += np.log(psi) + poisson_like(x, mu)\n\n    return like", "response": "Calculates Zero - inflated Poisson likelihood of a sequence of values."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nobserves self on obs_mesh with observation variance obs_V. Output_type controls the information returned: 'r' : returns information needed by Realization objects. 'o' : returns information needed by function observe. 's' : returns information needed by the Gaussian process submodel.", "response": "def observe(self, obs_mesh, obs_V, output_type='r'):\n        \"\"\"\n        Observes self on obs_mesh with observation variance obs_V.\n        Output_type controls the information returned:\n\n        'r' : returns information needed by Realization objects.\n        'o' : returns information needed by function observe.\n        's' : returns information needed by the Gaussian process\n              submodel.\n        \"\"\"\n\n        # print 'C.observe called'\n\n        # Number of spatial dimensions.\n        ndim = obs_mesh.shape[1]\n\n        if self.ndim is not None:\n            if not ndim == self.ndim:\n                raise ValueError(\n                    \"Dimension of observation mesh is not equal to dimension of base mesh.\")\n        else:\n            self.ndim = ndim\n\n        # print ndim\n\n        # =====================================\n        # = If self hasn't been observed yet: =\n        # =====================================\n        if not self.observed:\n\n            # If self has not been observed, get the Cholesky factor of self(obs_mesh, obs_mesh)\n            # and the side information and store it.\n\n            # Rank so far is 0.\n            m_old = 0\n\n            # Number of observation points so far is 0.\n            N_old = 0\n\n            if output_type != 's':\n                obs_dict = self.cholesky(\n                    obs_mesh,\n                    apply_pivot=False,\n                    nugget=obs_V,\n                    regularize=False,\n                    rank_limit=self.rank_limit)\n            else:\n                C_eval = self.__call__(obs_mesh, obs_mesh, regularize=False)\n                U = C_eval.copy('F')\n                for i in xrange(U.shape[0]):\n                    U[i, i] += obs_V[i]\n                info = dpotrf_wrap(U)\n                if info > 0:\n                    raise LinAlgError(\n                        \"Matrix does not appear to be positive definite by row %i. Could not observe with assume_full_rank=True.\" %\n                        info)\n                obs_dict = {\n                    'U': U,\n                    'pivots': arange(\n                        U.shape[0]),\n                    'U_new': U,\n                    'C_eval': C_eval}\n            obs_dict_new = obs_dict\n\n            # Rank of self(obs_mesh, obs_mesh)\n            m_new = obs_dict['U'].shape[0]\n\n            # Upper-triangular Cholesky factor of self(obs_mesh, obs_mesh)\n            self.full_Uo = obs_dict['U']\n            # print (self.full_Uo[:,argsort(obs_dict['pivots'])].T*self.full_Uo[:,argsort(obs_dict['pivots'])] - self(obs_mesh,obs_mesh)).max()\n\n            # Upper-triangular square Cholesky factor of self(obs_mesh_*,\n            # obs_mesh_*). See documentation.\n            self.Uo = obs_dict['U'][:, :m_new]\n\n            # Pivots.\n            piv_new = obs_dict['pivots']\n            self.full_piv = piv_new\n            self.obs_piv = piv_new[:m_new]\n\n            # Remember full observation mesh.\n            self.full_obs_mesh = obs_mesh\n\n            # relevant slice is the positive-definite indices, which get into\n            # obs_mesh_*. See documentation.\n            relevant_slice = self.obs_piv\n\n            # obs_mesh_new is obs_mesh_* from documentation.\n            obs_mesh_new = obs_mesh[relevant_slice, :]\n\n            self.obs_mesh = obs_mesh_new\n            self.obs_V = obs_V[piv_new]\n            self.obs_len = m_new\n\n        # =======================================\n        # = If self has been observed already:  =\n        # =======================================\n        else:\n\n            # If self has been observed, get the Cholesky factor of the _full_ observation mesh (new\n            # and old observations) using continue_cholesky, along with side\n            # information, and store it.\n\n            # Extract information from self's existing attributes related to\n            # the observation mesh..\n            obs_old, piv_old = self.Uo, self.obs_piv\n\n            # Rank of self's evaluation on the observation mesh so far.\n            m_old = len(self.obs_piv)\n\n            # Number of observations so far.\n            N_old = self.full_obs_mesh.shape[0]\n\n            # Number of new observations.\n            N_new = obs_mesh.shape[0]\n\n            # Call to self.continue_cholesky.\n            obs_dict_new = self.continue_cholesky(x=obs_mesh,\n                                                  x_old=self.full_obs_mesh,\n                                                  chol_dict_old={\n                                                      'U': self.full_Uo,\n                                                      'pivots': self.full_piv},\n                                                  apply_pivot=False,\n                                                  observed=False,\n                                                  regularize=False,\n                                                  nugget=obs_V,\n                                                  assume_full_rank=output_type == 's',\n                                                  rank_limit=self.rank_limit)\n\n            if output_type == 's':\n                C_eval = obs_dict_new['C_eval']\n\n            # Full Cholesky factor of self(obs_mesh, obs_mesh), where obs_mesh\n            # is the combined observation mesh.\n            self.full_Uo = obs_dict_new['U']\n\n            # Rank of self(obs_mesh, obs_mesh)\n            m_new = self.full_Uo.shape[0]\n\n            # Square upper-triangular Cholesky factor of self(obs_mesh_*,\n            # obs_mesh_*). See documentation.\n            self.Uo = self.full_Uo[:, :m_new]\n\n            # Pivots.\n            piv_new = obs_dict_new['pivots']\n            self.obs_piv = piv_new[:m_new]\n            self.full_piv = piv_new\n\n            # Concatenate old and new observation meshes.\n            self.full_obs_mesh = vstack((self.full_obs_mesh, obs_mesh))\n            relevant_slice = piv_new[m_old:m_new] - N_old\n            obs_mesh_new = obs_mesh[relevant_slice, :]\n\n            # Remember obs_mesh_* and corresponding observation variances.\n            self.obs_mesh = vstack((self.obs_mesh, obs_mesh[relevant_slice, :]))\n            self.obs_V = hstack((self.obs_V, obs_V[relevant_slice]))\n\n            # Length of obs_mesh_*.\n            self.obs_len = m_new\n\n        self.observed = True\n        # Output expected by Realization\n        if output_type == 'r':\n            return relevant_slice, obs_mesh_new, self.full_Uo[\n                m_old:, argsort(piv_new)[N_old:]], self.full_Uo[:m_old, argsort(piv_new)[N_old:]]\n\n        # Ouptut expected by observe\n        if output_type == 'o':\n            return relevant_slice, obs_mesh_new\n\n        # Output expected by the GP submodel\n        if output_type == 's':\n            return obs_dict_new['U_new'], obs_dict_new[\n                'C_eval'], self.full_Uo[:m_old, argsort(piv_new)[N_old:]]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_numpy_status():\n    numpy_status = {}\n    try:\n        import numpy\n        numpy_version = numpy.__version__\n        numpy_status['up_to_date'] = parse_version(\n            numpy_version) >= parse_version(numpy_min_version)\n        numpy_status['version'] = numpy_version\n    except ImportError:\n        numpy_status['up_to_date'] = False\n        numpy_status['version'] = \"\"\n    return numpy_status", "response": "Returns a dictionary containing a boolean specifying whether NumPy is up - to - date along with the version string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_index_list(shape, j):\n\n    r = range(len(shape))\n    index_list = (r)\n\n    for i in r:\n        if i < len(shape):\n            prodshape = prod(shape[i + 1:])\n        else:\n            prodshape = 0\n        index_list[i] = int(floor(j / prodshape))\n        if index_list[i] > shape[i]:\n            raise IndexError('Requested index too large')\n        j %= prodshape\n\n    return index_list", "response": "Returns the index list of the entry with the specified shape and j."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef func_quantiles(node, qlist=(.025, .25, .5, .75, .975)):\n\n    # For very large objects, this will be rather long.\n    # Too get the length of the table, use obj.trace.length()\n\n    if isinstance(node, Variable):\n        func_stacks = node.trace()\n    else:\n        func_stacks = node\n\n    if any(qlist < 0.) or any(qlist > 1.):\n        raise TypeError('The elements of qlist must be between 0 and 1')\n\n    func_stacks = func_stacks.copy()\n\n    N_samp = shape(func_stacks)[0]\n    func_len = tuple(shape(func_stacks)[1:])\n\n    func_stacks.sort(axis=0)\n\n    quants = zeros((len(qlist), func_len), dtype=float)\n    alphas = 1. - abs(array(qlist) - .5) / .5\n\n    for i in range(len(qlist)):\n        quants[i, ] = func_stacks[int(qlist[i] * N_samp), ]\n\n    return quants, alphas", "response": "Returns an array of the quantiles of the node."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef func_envelopes(node, CI=(.25, .5, .95)):\n\n    if isinstance(node, Variable):\n        func_stacks = asarray(node.trace())\n    else:\n        func_stacks = node\n\n    func_stacks = func_stacks.copy()\n    func_stacks.sort(axis=0)\n\n    envelopes = []\n    qsort = sort(CI)\n\n    for i in range(len(qsort)):\n        envelopes.append(\n            centered_envelope(func_stacks,\n                              qsort[len(qsort) - i - 1]))\n    envelopes.append(centered_envelope(func_stacks, 0.))\n\n    return envelopes", "response": "Function envelopes for a node."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef plotwrapper(f):\n\n    def wrapper(pymc_obj, *args, **kwargs):\n        start = 0\n        if 'start' in kwargs:\n            start = kwargs.pop('start')\n\n        # Figure out what type of object it is\n        try:\n            # First try Model type\n            for variable in pymc_obj._variables_to_tally:\n                # Plot object\n                if variable._plot is not False:\n                    data = pymc_obj.trace(variable.__name__)[start:]\n                    if size(data[-1]) >= 10 and variable._plot != True:\n                        continue\n                    elif variable.dtype is dtype('object'):\n                        continue\n                    name = variable.__name__\n                    if args:\n                        name = '%s_%s' % (args[0], variable.__name__)\n                    f(data, name, *args, **kwargs)\n            return\n        except AttributeError:\n            pass\n\n        try:\n            # Then try Trace type\n            data = pymc_obj()[:]\n            name = pymc_obj.name\n            f(data, name, *args, **kwargs)\n            return\n        except (AttributeError, TypeError):\n            pass\n\n        try:\n            # Then try Node type\n            if pymc_obj._plot is not False:\n                data = pymc_obj.trace()[start:]  # This is deprecated. DH\n                name = pymc_obj.__name__\n                f(data, name, *args, **kwargs)\n            return\n        except AttributeError:\n            pass\n\n        if isinstance(pymc_obj, dict):\n            # Then try dictionary\n            for i in pymc_obj:\n                data = pymc_obj[i][start:]\n                if args:\n                    i = '%s_%s' % (args[0], i)\n                elif 'name' in kwargs:\n                    i = '%s_%s' % (kwargs.pop('name'), i)\n                f(data, i, *args, **kwargs)\n            return\n\n        # If others fail, assume that raw data is passed\n        f(pymc_obj, *args, **kwargs)\n\n    wrapper.__doc__ = f.__doc__\n    wrapper.__name__ = f.__name__\n    return wrapper", "response": "A function decorator that returns a function that will plot the object and its children."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef plot(\n    data, name, format='png', suffix='', path='./', common_scale=True, datarange=(None, None), fontmap=None, verbose=1,\n        new=True, last=True, rows=1, num=1):\n    \"\"\"\n    Generates summary plots for nodes of a given PyMC object.\n\n    :Arguments:\n        data: PyMC object, trace or array\n            A trace from an MCMC sample or a PyMC object with one or more traces.\n\n        name: string\n            The name of the object.\n\n        format (optional): string\n            Graphic output format (defaults to png).\n\n        suffix (optional): string\n            Filename suffix.\n\n        path (optional): string\n            Specifies location for saving plots (defaults to local directory).\n\n        common_scale (optional): bool\n            Specifies whether plots of multivariate nodes should be on the same scale\n            (defaults to True).\n            \n        datarange (optional): tuple or list\n            Range of data to plot (defaults to empirical range of data)\n            \n        fontmap (optional): dict\n            Dictionary containing the font map for the labels of the graphic.\n\n        verbose (optional): int\n            Verbosity level for output (defaults to 1).\n\n    \"\"\"\n    if fontmap is None:\n        fontmap = {1: 10, 2: 8, 3: 6, 4: 5, 5: 4}\n\n    # If there is only one data array, go ahead and plot it ...\n    if ndim(data) == 1:\n\n        if verbose > 0:\n            print_('Plotting', name)\n\n        # If new plot, generate new frame\n        if new:\n            figure(figsize=(10, 6))\n\n        # Call trace\n        trace(data, name, datarange=datarange, rows=rows * 2, columns=2,  \n                 num=num + 3 * (num - 1), last=last, fontmap=fontmap)\n        # Call autocorrelation\n        autocorrelation(data, name, rows=rows * 2, columns=2, \n                    num=num+3*(num-1)+2, last=last, fontmap=fontmap)\n        # Call histogram\n        histogram(data, name, datarange=datarange, rows=rows, columns=2,\n                 num=num*2, last=last, fontmap=fontmap)\n\n        if last:\n            if not os.path.exists(path):\n                os.mkdir(path)\n            if not path.endswith('/'):\n                path += '/'\n            savefig(\"%s%s%s.%s\" % (path, name, suffix, format))\n\n    else:\n        # ... otherwise plot recursively\n        tdata = swapaxes(data, 0, 1)\n\n        datarange = (None, None)\n        # Determine common range for plots\n        if common_scale:\n            datarange = (nmin(tdata), nmax(tdata))\n\n        # How many rows?\n        _rows = min(4, len(tdata))\n\n        for i in range(len(tdata)):\n\n            # New plot or adding to existing?\n            _new = not i % _rows\n            # Current subplot number\n            _num = i % _rows + 1\n            # Final subplot of current figure?\n            _last = (_num == _rows) or (i == len(tdata) - 1)\n\n            plot(tdata[i], name + '_' + str(i), format=format, path=path,\n                common_scale=common_scale, datarange=datarange,\n                suffix=suffix, new=_new, last=_last, rows=_rows, \n                num=_num, fontmap=fontmap, verbose=verbose)", "response": "Plots the MCMC object with the given data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef histogram(\n    data, name, bins='sturges', datarange=(None, None), format='png', suffix='', path='./', rows=1,\n        columns=1, num=1, last=True, fontmap = None, verbose=1):\n    \"\"\"\n    Generates histogram from an array of data.\n\n    :Arguments:\n        data: array or list\n            Usually a trace from an MCMC sample.\n\n        name: string\n            The name of the histogram.\n\n        bins: int or string\n            The number of bins, or a preferred binning method. Available methods include\n            'doanes', 'sturges' and 'sqrt' (defaults to 'doanes').\n\n        datarange: tuple or list\n            Preferred range of histogram (defaults to (None,None)).\n\n        format (optional): string\n            Graphic output format (defaults to png).\n\n        suffix (optional): string\n            Filename suffix.\n\n        path (optional): string\n            Specifies location for saving plots (defaults to local directory).\n\n        fontmap (optional): dict\n            Font map for plot.\n    \"\"\"\n\n    # Internal histogram specification for handling nested arrays\n    try:\n\n        if fontmap is None:\n            fontmap = {1: 10, 2: 8, 3: 6, 4: 5, 5: 4}\n\n        # Stand-alone plot or subplot?\n        standalone = rows == 1 and columns == 1 and num == 1\n        if standalone:\n            if verbose > 0:\n                print_('Generating histogram of', name)\n            figure()\n\n        subplot(rows, columns, num)\n\n        # Specify number of bins\n        uniquevals = len(unique(data))\n        if isinstance(bins, int):\n            pass\n        if bins == 'sturges':\n            bins = uniquevals * (uniquevals <= 25) or _sturges(len(data))\n        elif bins == 'doanes':\n            bins = uniquevals * (uniquevals <= 25) or _doanes(data, len(data))\n        elif bins == 'sqrt':\n            bins = uniquevals * (uniquevals <= 25) or _sqrt_choice(len(data))\n        elif isinstance(bins, int):\n            bins = bins\n        else:\n            raise ValueError('Invalid bins argument in histogram')\n\n        if isnan(bins):\n            bins = uniquevals * (uniquevals <= 25) or int(\n                4 + 1.5 * log(len(data)))\n            print_(\n                'Bins could not be calculated using selected method. Setting bins to %i.' %\n                bins)\n\n        # Generate histogram\n        hist(data.tolist(), bins, histtype='stepfilled')\n\n        xlim(datarange)\n\n        # Plot options\n        title('\\n\\n   %s hist' % name, x=0., y=1., ha='left', va='top',\n             fontsize='medium')\n\n        ylabel(\"Frequency\", fontsize='x-small')\n\n        # Plot vertical lines for median and 95% HPD interval\n        quant = calc_quantiles(data)\n        axvline(x=quant[50], linewidth=2, color='black')\n        for q in calc_hpd(data, 0.05):\n            axvline(x=q, linewidth=2, color='grey', linestyle='dotted')\n\n        # Smaller tick labels\n        tlabels = gca().get_xticklabels()\n        setp(tlabels, 'fontsize', fontmap[rows])\n        tlabels = gca().get_yticklabels()\n        setp(tlabels, 'fontsize', fontmap[rows])\n\n        if standalone:\n            if not os.path.exists(path):\n                os.mkdir(path)\n            if not path.endswith('/'):\n                path += '/'\n            # Save to file\n            savefig(\"%s%s%s.%s\" % (path, name, suffix, format))\n            # close()\n\n    except OverflowError:\n        print_('... cannot generate histogram')", "response": "Generates a histogram of the specified number of unique values."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef trace(\n    data, name, format='png', datarange=(None, None), suffix='', path='./', rows=1, columns=1,\n        num=1, last=True, fontmap = None, verbose=1):\n    \"\"\"\n    Generates trace plot from an array of data.\n\n    :Arguments:\n        data: array or list\n            Usually a trace from an MCMC sample.\n\n        name: string\n            The name of the trace.\n\n        datarange: tuple or list\n            Preferred y-range of trace (defaults to (None,None)).\n\n        format (optional): string\n            Graphic output format (defaults to png).\n\n        suffix (optional): string\n            Filename suffix.\n\n        path (optional): string\n            Specifies location for saving plots (defaults to local directory).\n\n        fontmap (optional): dict\n            Font map for plot.\n\n    \"\"\"\n\n    if fontmap is None:\n        fontmap = {1: 10, 2: 8, 3: 6, 4: 5, 5: 4}\n\n    # Stand-alone plot or subplot?\n    standalone = rows == 1 and columns == 1 and num == 1\n\n    if standalone:\n        if verbose > 0:\n            print_('Plotting', name)\n        figure()\n\n    subplot(rows, columns, num)\n    pyplot(data.tolist())\n    ylim(datarange)\n\n    # Plot options\n    title('\\n\\n %s trace' % name, x=0., y=1., ha='left', va='top',\n         fontsize='small')\n\n    # Smaller tick labels\n    tlabels = gca().get_xticklabels()\n    setp(tlabels, 'fontsize', fontmap[max(rows / 2, 1)])\n\n    tlabels = gca().get_yticklabels()\n    setp(tlabels, 'fontsize', fontmap[max(rows / 2, 1)])\n\n    if standalone:\n        if not os.path.exists(path):\n            os.mkdir(path)\n        if not path.endswith('/'):\n            path += '/'\n        # Save to file\n        savefig(\"%s%s%s.%s\" % (path, name, suffix, format))", "response": "Generates a trace plot from an array of data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef geweke_plot(\n    data, name, format='png', suffix='-diagnostic', path='./', fontmap=None):\n    '''\n    Generate Geweke (1992) diagnostic plots.\n    \n    :Arguments:\n        data: list\n            List (or list of lists for vector-valued variables) of Geweke diagnostics, output\n            from the `pymc.diagnostics.geweke` function .\n\n        name: string\n            The name of the plot.\n\n        format (optional): string\n            Graphic output format (defaults to png).\n\n        suffix (optional): string\n            Filename suffix (defaults to \"-diagnostic\").\n\n        path (optional): string\n            Specifies location for saving plots (defaults to local directory).\n\n        fontmap (optional): dict\n            Font map for plot.\n    \n    '''\n\n    if fontmap is None:\n        fontmap = {1: 10, 2: 8, 3: 6, 4: 5, 5: 4}\n\n    # Generate new scatter plot\n    figure()\n    x, y = transpose(data)\n    scatter(x.tolist(), y.tolist())\n\n    # Plot options\n    xlabel('First iteration', fontsize='x-small')\n    ylabel('Z-score for %s' % name, fontsize='x-small')\n\n    # Plot lines at +/- 2 sd from zero\n    pyplot((nmin(x), nmax(x)), (2, 2), '--')\n    pyplot((nmin(x), nmax(x)), (-2, -2), '--')\n\n    # Set plot bound\n    ylim(min(-2.5, nmin(y)), max(2.5, nmax(y)))\n    xlim(0, nmax(x))\n\n    # Save to file\n    if not os.path.exists(path):\n        os.mkdir(path)\n    if not path.endswith('/'):\n        path += '/'\n    savefig(\"%s%s%s.%s\" % (path, name, suffix, format))", "response": "Generate Geweke diagnostic plots."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef discrepancy_plot(\n    data, name='discrepancy', report_p=True, format='png', suffix='-gof',\n    path='./', fontmap=None, verbose=1):\n    '''\n    Generate goodness-of-fit deviate scatter plot.\n    \n    :Arguments:\n        data: list\n            List (or list of lists for vector-valued variables) of discrepancy values, output\n            from the `pymc.diagnostics.discrepancy` function .\n\n        name: string\n            The name of the plot.\n            \n        report_p: bool\n            Flag for annotating the p-value to the plot.\n\n        format (optional): string\n            Graphic output format (defaults to png).\n\n        suffix (optional): string\n            Filename suffix (defaults to \"-gof\").\n\n        path (optional): string\n            Specifies location for saving plots (defaults to local directory).\n\n        fontmap (optional): dict\n            Font map for plot.\n    \n    '''\n\n    if verbose > 0:\n        print_('Plotting', name + suffix)\n\n    if fontmap is None:\n        fontmap = {1: 10, 2: 8, 3: 6, 4: 5, 5: 4}\n\n    # Generate new scatter plot\n    figure()\n    try:\n        x, y = transpose(data)\n    except ValueError:\n        x, y = data\n    scatter(x, y)\n\n    # Plot x=y line\n    lo = nmin(ravel(data))\n    hi = nmax(ravel(data))\n    datarange = hi - lo\n    lo -= 0.1 * datarange\n    hi += 0.1 * datarange\n    pyplot((lo, hi), (lo, hi))\n\n    # Plot options\n    xlabel('Observed deviates', fontsize='x-small')\n    ylabel('Simulated deviates', fontsize='x-small')\n\n    if report_p:\n        # Put p-value in legend\n        count = sum(s > o for o, s in zip(x, y))\n        text(lo + 0.1 * datarange, hi - 0.1 * datarange,\n             'p=%.3f' % (count / len(x)), horizontalalignment='center',\n             fontsize=10)\n\n    # Save to file\n    if not os.path.exists(path):\n        os.mkdir(path)\n    if not path.endswith('/'):\n        path += '/'\n    savefig(\"%s%s%s.%s\" % (path, name, suffix, format))", "response": "Generate a goodness - of - fit deviate scatter plot."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef gof_plot(\n    simdata, trueval, name=None, bins=None, format='png', suffix='-gof', path='./',\n        fontmap=None, verbose=0):\n    \"\"\"\n    Plots histogram of replicated data, indicating the location of the observed data\n\n    :Arguments:\n        simdata: array or PyMC object\n            Trace of simulated data or the PyMC stochastic object containing trace.\n\n        trueval: numeric\n            True (observed) value of the data\n\n        bins: int or string\n            The number of bins, or a preferred binning method. Available methods include\n            'doanes', 'sturges' and 'sqrt' (defaults to 'doanes').\n\n        format (optional): string\n            Graphic output format (defaults to png).\n\n        suffix (optional): string\n            Filename suffix.\n\n        path (optional): string\n            Specifies location for saving plots (defaults to local directory).\n\n        fontmap (optional): dict\n            Font map for plot.\n\n    \"\"\"\n\n    if fontmap is None:\n        fontmap = {1: 10, 2: 8, 3: 6, 4: 5, 5: 4}\n\n    if not isinstance(simdata, ndarray):\n        ## Can't just try and catch because ndarray objects also have\n        ## `trace` method.\n        simdata = simdata.trace()\n\n    if ndim(trueval) == 1 and ndim(simdata == 2):\n        # Iterate over more than one set of data\n        for i in range(len(trueval)):\n            n = name or 'MCMC'\n            gof_plot(\n                simdata[\n                    :,\n                    i],\n                trueval[\n                    i],\n                '%s[%i]' % (\n                    n,\n                    i),\n                bins=bins,\n                format=format,\n                suffix=suffix,\n                path=path,\n                fontmap=fontmap,\n                verbose=verbose)\n        return\n\n    if verbose > 0:\n        print_('Plotting', (name or 'MCMC') + suffix)\n\n    figure()\n\n    # Specify number of bins\n    if bins is None:\n        bins = 'sqrt'\n    uniquevals = len(unique(simdata))\n    if bins == 'sturges':\n        bins = uniquevals * (uniquevals <= 25) or _sturges(len(simdata))\n    elif bins == 'doanes':\n        bins = uniquevals * (\n            uniquevals <= 25) or _doanes(simdata,\n                                         len(simdata))\n    elif bins == 'sqrt':\n        bins = uniquevals * (uniquevals <= 25) or _sqrt_choice(len(simdata))\n    elif isinstance(bins, int):\n        bins = bins\n    else:\n        raise ValueError('Invalid bins argument in gof_plot')\n\n    # Generate histogram\n    hist(simdata, bins)\n\n    # Plot options\n    xlabel(name or 'Value', fontsize='x-small')\n\n    ylabel(\"Frequency\", fontsize='x-small')\n\n    # Smaller tick labels\n    tlabels = gca().get_xticklabels()\n    setp(tlabels, 'fontsize', fontmap[1])\n    tlabels = gca().get_yticklabels()\n    setp(tlabels, 'fontsize', fontmap[1])\n\n    # Plot vertical line at location of true data value\n    axvline(x=trueval, linewidth=2, color='r', linestyle='dotted')\n\n    if not os.path.exists(path):\n        os.mkdir(path)\n    if not path.endswith('/'):\n        path += '/'\n    # Save to file\n    savefig(\"%s%s%s.%s\" % (path, name or 'MCMC', suffix, format))", "response": "Plots histogram of replicated data for the current state of the object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate a bar plot of the autocorrelation function for a series of MCMC objects.", "response": "def autocorrelation(\n    data, name, maxlags=100, format='png', reflected=False, suffix='-acf', path='./',\n        fontmap=None, new=True, last=True, rows=1, columns=1, num=1, verbose=1):\n    \"\"\"\n    Generate bar plot of the autocorrelation function for a series (usually an MCMC trace).\n\n    :Arguments:\n        data: PyMC object, trace or array\n            A trace from an MCMC sample or a PyMC object with one or more traces.\n\n        name: string\n            The name of the object.\n\n        maxlags (optional): int\n            The largest discrete value for the autocorrelation to be calculated (defaults to 100).\n\n        format (optional): string\n            Graphic output format (defaults to png).\n\n        suffix (optional): string\n            Filename suffix.\n\n        path (optional): string\n            Specifies location for saving plots (defaults to local directory).\n\n        fontmap (optional): dict\n            Font mapping for plot labels; most users should not specify this.\n\n        verbose (optional): int\n            Level of output verbosity.\n\n    \"\"\"\n    # Internal plotting specification for handling nested arrays\n\n    if fontmap is None:\n        fontmap = {1: 10, 2: 8, 3: 6, 4: 5, 5: 4}\n\n    # Stand-alone plot or subplot?\n    standalone = rows == 1 and columns == 1 and num == 1\n\n    if standalone:\n        if verbose > 0:\n            print_('Plotting', name)\n        figure()\n\n    subplot(rows, columns, num)\n    if ndim(data) == 1:\n        maxlags = min(len(data) - 1, maxlags)\n        try:\n            acorr(data, detrend=mlab.detrend_mean, maxlags=maxlags)\n        except:\n            print_('Cannot plot autocorrelation for %s' % name)\n            return\n\n        # Set axis bounds\n        ylim(-.1, 1.1)\n        xlim(-maxlags * reflected or 0, maxlags)\n\n        # Plot options\n        title(\n            '\\n\\n   %s acorr' %\n            name,\n            x=0.,\n            y=1.,\n            ha='left',\n            va='top',\n            fontsize='small')\n\n        # Smaller tick labels\n        tlabels = gca().get_xticklabels()\n        setp(tlabels, 'fontsize', fontmap[1])\n\n        tlabels = gca().get_yticklabels()\n        setp(tlabels, 'fontsize', fontmap[1])\n    elif ndim(data) == 2:\n        # generate acorr plot for each dimension\n        rows = data.shape[1]\n        for j in range(rows):\n            autocorrelation(\n                data[:,\n                     j],\n                '%s_%d' % (name,\n                           j),\n                maxlags,\n                fontmap=fontmap,\n                rows=rows,\n                columns=1,\n                num=j + 1)\n    else:\n        raise ValueError(\n            'Only 1- and 2- dimensional functions can be displayed')\n\n    if standalone:\n        if not os.path.exists(path):\n            os.mkdir(path)\n        if not path.endswith('/'):\n            path += '/'\n        # Save to fiel\n        savefig(\"%s%s%s.%s\" % (path, name, suffix, format))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef zplot(pvalue_dict, name='',\n          format='png', path='./', fontmap=None, verbose=1):\n    \"\"\"Plots absolute values of z-scores for model validation output from\n    diagnostics.validate().\"\"\"\n\n    if verbose:\n        print_('\\nGenerating model validation plot')\n\n    if fontmap is None:\n        fontmap = {1: 10, 2: 8, 3: 6, 4: 5, 5: 4}\n\n    x, y, labels = [], [], []\n\n    for i, var in enumerate(pvalue_dict):\n\n        # Get p-values\n        pvals = pvalue_dict[var]\n        # Take absolute values of inverse-standard normals\n        zvals = abs(special.ndtri(pvals))\n\n        x = append(x, zvals)\n        y = append(y, ones(size(zvals)) * (i + 1))\n\n        vname = var\n        vname += \" (%i)\" % size(zvals)\n        labels = append(labels, vname)\n\n    # Spawn new figure\n    figure()\n    subplot(111)\n    subplots_adjust(left=0.25, bottom=0.1)\n    # Plot scores\n    pyplot(x, y, 'o')\n    # Set range on axes\n    ylim(0, size(pvalue_dict) + 2)\n    xlim(xmin=0)\n    # Tick labels for y-axis\n    yticks(arange(len(labels) + 2), append(append(\"\", labels), \"\"))\n    # X label\n    xlabel(\"Absolute z transformation of p-values\")\n\n    if not os.path.exists(path):\n        os.mkdir(path)\n    if not path.endswith('/'):\n        path += '/'\n\n    if name:\n        name += '-'\n\n    savefig(\"%s%svalidation.%s\" % (path, name, format))", "response": "Plots absolute values of z - scores for model validation output from diagnostics. validate"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a sequence of strings naming the element of the tallyable object.", "response": "def var_str(name, shape):\n    \"\"\"Return a sequence of strings naming the element of the tallyable object.\n\n    :Example:\n    >>> var_str('theta', (4,))\n    ['theta[1]', 'theta[2]', 'theta[3]', 'theta[4]']\n\n    \"\"\"\n\n    size = prod(shape)\n    ind = (indices(shape) + 1).reshape(-1, size)\n    names = ['[' + ','.join(list(map(str, i))) + ']' for i in zip(*ind)]\n    names[0] = '%s %s' % (name, names[0])\n    return names"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmodel summary plot Generates a \"forest plot\" of 100*(1-alpha)% credible intervals for either the set of nodes in a given model, or a specified set of nodes. :Arguments: pymc_obj: PyMC object, trace or array A trace from an MCMC sample or a PyMC object with one or more traces. name (optional): string The name of the object. format (optional): string Graphic output format (defaults to png). suffix (optional): string Filename suffix. path (optional): string Specifies location for saving plots (defaults to local directory). alpha (optional): float Alpha value for (1-alpha)*100% credible intervals (defaults to 0.05). chain (optional): int Where there are multiple chains, specify a particular chain to plot. If not specified (chain=None), all chains are plotted. quartiles (optional): bool Flag for plotting the interquartile range, in addition to the (1-alpha)*100% intervals (defaults to True). hpd (optional): bool Flag for plotting the highest probability density (HPD) interval instead of the central (1-alpha)*100% interval (defaults to True). rhat (optional): bool Flag for plotting Gelman-Rubin statistics. Requires 2 or more chains (defaults to True). main (optional): string Title for main plot. Passing False results in titles being suppressed; passing False (default) results in default titles. xlab (optional): string Label for x-axis. Defaults to no label x_range (optional): list or tuple Range for x-axis. Defaults to matplotlib's best guess. custom_labels (optional): list User-defined labels for each node. If not provided, the node __name__ attributes are used. chain_spacing (optional): float Plot spacing between chains (defaults to 0.05). vline_pos (optional): numeric Location of vertical reference line (defaults to 0).", "response": "def summary_plot(\n    pymc_obj, name='model', format='png', suffix='-summary', path='./',\n    alpha=0.05, chain=None, quartiles=True, hpd=True, rhat=True, main=None,\n    xlab=None, x_range=None, custom_labels=None, chain_spacing=0.05, vline_pos=0):\n    \"\"\"\n    Model summary plot\n\n    Generates a \"forest plot\" of 100*(1-alpha)% credible intervals for either the\n    set of nodes in a given model, or a specified set of nodes.\n\n    :Arguments:\n        pymc_obj: PyMC object, trace or array\n            A trace from an MCMC sample or a PyMC object with one or more traces.\n\n        name (optional): string\n            The name of the object.\n\n        format (optional): string\n            Graphic output format (defaults to png).\n\n        suffix (optional): string\n            Filename suffix.\n\n        path (optional): string\n            Specifies location for saving plots (defaults to local directory).\n\n        alpha (optional): float\n            Alpha value for (1-alpha)*100% credible intervals (defaults to 0.05).\n            \n        chain (optional): int\n            Where there are multiple chains, specify a particular chain to plot.\n            If not specified (chain=None), all chains are plotted.\n\n        quartiles (optional): bool\n            Flag for plotting the interquartile range, in addition to the\n            (1-alpha)*100% intervals (defaults to True).\n\n        hpd (optional): bool\n            Flag for plotting the highest probability density (HPD) interval\n            instead of the central (1-alpha)*100% interval (defaults to True).\n\n        rhat (optional): bool\n            Flag for plotting Gelman-Rubin statistics. Requires 2 or more\n            chains (defaults to True).\n\n        main (optional): string\n            Title for main plot. Passing False results in titles being\n            suppressed; passing False (default) results in default titles.\n\n        xlab (optional): string\n            Label for x-axis. Defaults to no label\n\n        x_range (optional): list or tuple\n            Range for x-axis. Defaults to matplotlib's best guess.\n\n        custom_labels (optional): list\n            User-defined labels for each node. If not provided, the node\n            __name__ attributes are used.\n\n        chain_spacing (optional): float\n            Plot spacing between chains (defaults to 0.05).\n\n        vline_pos (optional): numeric\n            Location of vertical reference line (defaults to 0).\n\n    \"\"\"\n\n    if not gridspec:\n        print_(\n            '\\nYour installation of matplotlib is not recent enough to support summary_plot; this function is disabled until matplotlib is updated.')\n        return\n\n    # Quantiles to be calculated\n    quantiles = [100 * alpha / 2, 50, 100 * (1 - alpha / 2)]\n    if quartiles:\n        quantiles = [100 * alpha / 2, 25, 50, 75, 100 * (1 - alpha / 2)]\n\n    # Range for x-axis\n    plotrange = None\n\n    # Gridspec\n    gs = None\n\n    # Subplots\n    interval_plot = None\n    rhat_plot = None\n\n    try:\n        # First try Model type\n        vars = pymc_obj._variables_to_tally\n\n    except AttributeError:\n\n        try:\n\n            # Try a database object\n            vars = pymc_obj._traces\n\n        except AttributeError:\n\n            if isinstance(pymc_obj, Variable):\n                vars = [pymc_obj]\n            else:\n                # Assume an iterable\n                vars = pymc_obj\n\n    from .diagnostics import gelman_rubin\n\n    # Calculate G-R diagnostics\n    if rhat:\n        try:\n            R = {}\n            for variable in vars:\n                R[variable.__name__] = gelman_rubin(variable)\n        except (ValueError, TypeError):\n            print(\n                'Could not calculate Gelman-Rubin statistics. Requires multiple chains of equal length.')\n            rhat = False\n\n    # Empty list for y-axis labels\n    labels = []\n    # Counter for current variable\n    var = 1\n\n    # Make sure there is something to print\n    if all([v._plot == False for v in vars]):\n        print_('No variables to plot')\n        return\n\n    for variable in vars:\n\n        # If plot flag is off, do not print\n        if variable._plot == False:\n            continue\n\n        # Extract name\n        varname = variable.__name__\n\n        # Retrieve trace(s)\n        if chain is not None:\n            chains = 1\n            traces = [variable.trace(chain=chain)]\n        else:\n            chains = variable.trace.db.chains\n            traces = [variable.trace(chain=i) for i in range(chains)]\n\n        if gs is None:\n            # Initialize plot\n            if rhat and chains > 1:\n                gs = gridspec.GridSpec(1, 2, width_ratios=[3, 1])\n\n            else:\n\n                gs = gridspec.GridSpec(1, 1)\n\n            # Subplot for confidence intervals\n            interval_plot = subplot(gs[0])\n\n        # Get quantiles\n        data = [calc_quantiles(d, quantiles) for d in traces]\n        if hpd:\n            # Substitute HPD interval\n            for i, d in enumerate(traces):\n                hpd_interval = calc_hpd(d, alpha)\n                data[i][quantiles[0]] = hpd_interval[0]\n                data[i][quantiles[-1]] = hpd_interval[1]\n\n        data = [[d[q] for q in quantiles] for d in data]\n        # Ensure x-axis contains range of current interval\n        if plotrange:\n            plotrange = [min(\n                         plotrange[0],\n                         nmin(data)),\n                         max(plotrange[1],\n                             nmax(data))]\n        else:\n            plotrange = [nmin(data), nmax(data)]\n\n        try:\n            # First try missing-value stochastic\n            value = variable.get_stoch_value()\n        except AttributeError:\n            # All other variable types\n            value = variable.value\n\n        # Number of elements in current variable\n        k = size(value)\n        \n        # Append variable name(s) to list\n        if k > 1:\n            names = var_str(varname, shape(value)[int(shape(value)[0]==1):])\n            labels += names\n        else:\n            labels.append(varname)\n            # labels.append('\\n'.join(varname.split('_')))\n\n        # Add spacing for each chain, if more than one\n        e = [0] + [(chain_spacing * ((i + 2) / 2)) * (\n            -1) ** i for i in range(chains - 1)]\n\n        # Loop over chains\n        for j, quants in enumerate(data):\n\n            # Deal with multivariate nodes\n            if k > 1:\n                ravelled_quants = list(map(ravel, quants))\n                \n                for i, quant in enumerate(transpose(ravelled_quants)):\n\n                    q = ravel(quant)\n                    \n                    # Y coordinate with jitter\n                    y = -(var + i) + e[j]\n\n                    if quartiles:\n                        # Plot median\n                        pyplot(q[2], y, 'bo', markersize=4)\n                        # Plot quartile interval\n                        errorbar(\n                            x=(q[1],\n                                q[3]),\n                            y=(y,\n                                y),\n                            linewidth=2,\n                            color=\"blue\")\n\n                    else:\n                        # Plot median\n                        pyplot(q[1], y, 'bo', markersize=4)\n\n                    # Plot outer interval\n                    errorbar(\n                        x=(q[0],\n                            q[-1]),\n                        y=(y,\n                            y),\n                        linewidth=1,\n                        color=\"blue\")\n\n            else:\n\n                # Y coordinate with jitter\n                y = -var + e[j]\n\n                if quartiles:\n                    # Plot median\n                    pyplot(quants[2], y, 'bo', markersize=4)\n                    # Plot quartile interval\n                    errorbar(\n                        x=(quants[1],\n                            quants[3]),\n                        y=(y,\n                            y),\n                        linewidth=2,\n                        color=\"blue\")\n                else:\n                    # Plot median\n                    pyplot(quants[1], y, 'bo', markersize=4)\n\n                # Plot outer interval\n                errorbar(\n                    x=(quants[0],\n                        quants[-1]),\n                    y=(y,\n                        y),\n                    linewidth=1,\n                    color=\"blue\")\n\n        # Increment index\n        var += k\n\n    if custom_labels is not None:\n        labels = custom_labels\n\n    # Update margins\n    left_margin = max([len(x) for x in labels]) * 0.015\n    gs.update(left=left_margin, right=0.95, top=0.9, bottom=0.05)\n\n    # Define range of y-axis\n    ylim(-var + 0.5, -0.5)\n\n    datarange = plotrange[1] - plotrange[0]\n    xlim(plotrange[0] - 0.05 * datarange, plotrange[1] + 0.05 * datarange)\n\n    # Add variable labels\n    yticks([-(l + 1) for l in range(len(labels))], labels)\n\n    # Add title\n    if main is not False:\n        plot_title = main or str(int((\n            1 - alpha) * 100)) + \"% Credible Intervals\"\n        title(plot_title)\n\n    # Add x-axis label\n    if xlab is not None:\n        xlabel(xlab)\n\n    # Constrain to specified range\n    if x_range is not None:\n        xlim(*x_range)\n\n    # Remove ticklines on y-axes\n    for ticks in interval_plot.yaxis.get_major_ticks():\n        ticks.tick1On = False\n        ticks.tick2On = False\n\n    for loc, spine in six.iteritems(interval_plot.spines):\n        if loc in ['bottom', 'top']:\n            pass\n            # spine.set_position(('outward',10)) # outward by 10 points\n        elif loc in ['left', 'right']:\n            spine.set_color('none')  # don't draw spine\n\n    # Reference line\n    axvline(vline_pos, color='k', linestyle='--')\n\n    # Genenerate Gelman-Rubin plot\n    if rhat and chains > 1:\n\n        # If there are multiple chains, calculate R-hat\n        rhat_plot = subplot(gs[1])\n\n        if main is not False:\n            title(\"R-hat\")\n\n        # Set x range\n        xlim(0.9, 2.1)\n\n        # X axis labels\n        xticks((1.0, 1.5, 2.0), (\"1\", \"1.5\", \"2+\"))\n        yticks([-(l + 1) for l in range(len(labels))], \"\")\n\n        i = 1\n        for variable in vars:\n\n            if variable._plot == False:\n                continue\n\n            # Extract name\n            varname = variable.__name__\n\n            try:\n                value = variable.get_stoch_value()\n            except AttributeError:\n                value = variable.value\n\n            k = size(value)\n\n            if k > 1:\n                pyplot([min(r, 2) for r in R[varname]], [-(j + i)\n                                                         for j in range(k)], 'bo', markersize=4)\n            else:\n                pyplot(min(R[varname], 2), -i, 'bo', markersize=4)\n\n            i += k\n\n        # Define range of y-axis\n        ylim(-i + 0.5, -0.5)\n\n        # Remove ticklines on y-axes\n        for ticks in rhat_plot.yaxis.get_major_ticks():\n            ticks.tick1On = False\n            ticks.tick2On = False\n\n        for loc, spine in six.iteritems(rhat_plot.spines):\n            if loc in ['bottom', 'top']:\n                pass\n                # spine.set_position(('outward',10)) # outward by 10 points\n            elif loc in ['left', 'right']:\n                spine.set_color('none')  # don't draw spine\n\n    savefig(\"%s%s%s.%s\" % (path, name, suffix, format))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef display(self, xaxis, alpha, new=True):\n        if new:\n            figure()\n        if self.ndim == 1:\n            if self.mass > 0.:\n                x = concatenate((xaxis, xaxis[::-1]))\n                y = concatenate((self.lo, self.hi[::-1]))\n                fill(\n                    x,\n                    y,\n                    facecolor='%f' % self.mass,\n                    alpha=alpha,\n                    label=(\n                        'centered CI ' + str(\n                            self.mass)))\n            else:\n                pyplot(\n                    xaxis,\n                    self.value,\n                    'k-',\n                    alpha=alpha,\n                    label=(\n                        'median'))\n        else:\n            if self.mass > 0.:\n                subplot(1, 2, 1)\n                contourf(xaxis[0], xaxis[1], self.lo, cmap=cm.bone)\n                colorbar()\n                subplot(1, 2, 2)\n                contourf(xaxis[0], xaxis[1], self.hi, cmap=cm.bone)\n                colorbar()\n            else:\n                contourf(xaxis[0], xaxis[1], self.value, cmap=cm.bone)\n                colorbar()", "response": "Display the CI region on the current figure."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load(dbname):\n    db = Database(dbname)\n\n    # Get the name of the objects\n    tables = get_table_list(db.cur)\n\n    # Create a Trace instance for each object\n    chains = 0\n    for name in tables:\n        db._traces[name] = Trace(name=name, db=db)\n        db._traces[name]._shape = get_shape(db.cur, name)\n        setattr(db, name, db._traces[name])\n        db.cur.execute('SELECT MAX(trace) FROM [%s]' % name)\n        chains = max(chains, db.cur.fetchall()[0][0] + 1)\n\n    db.chains = chains\n    db.trace_names = chains * [tables, ]\n    db._state_ = {}\n    return db", "response": "Load an existing SQLite database.\n    Return a Database instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the shape of the table name.", "response": "def get_shape(cursor, name):\n    \"\"\"Return the shape of the table ``name``.\"\"\"\n    cursor.execute('select * from [%s]' % name)\n    inds = cursor.description[-1][0][1:].split('_')\n    return tuple([int(i) for i in inds])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a sequence of strings naming the element of the tallyable object.", "response": "def var_str(shape):\n    \"\"\"Return a sequence of strings naming the element of the tallyable object.\n\n    :Examples:\n    >>> var_str((5,))\n    ['v1', 'v2', 'v3', 'v4', 'v5']\n\n    >>> var_str((2,2))\n    ['v1_1', 'v1_2', 'v2_1', 'v2_2']\n    \"\"\"\n\n    if shape in [None, ()]:\n        return ['v1', ]\n\n    size = np.prod(shape)\n    indices = (np.indices(shape) + 1).reshape(-1, size)\n    return ['v' + '_'.join(list(map(str, i))) for i in zip(*indices)]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate an SQL table.", "response": "def _initialize(self, chain, length):\n        \"\"\"Create an SQL table.\n        \"\"\"\n\n        if self._getfunc is None:\n            self._getfunc = self.db.model._funs_to_tally[self.name]\n\n        # Determine size\n        try:\n            self._shape = np.shape(self._getfunc())\n        except TypeError:\n            self._shape = None\n\n        self._vstr = ', '.join(var_str(self._shape))\n\n        # If the table already exists, exit now.\n        if chain != 0:\n            return\n\n        # Create the variable name strings.\n        vstr = ', '.join(v + ' FLOAT' for v in var_str(self._shape))\n        query = \"\"\"CREATE TABLE IF NOT EXISTS [%s]\n                     (recid INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT,\n                      trace  int(5), %s)\"\"\" % (self.name, vstr)\n        self.db.cur.execute(query)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding current value to trace.", "response": "def tally(self, chain):\n        \"\"\"Adds current value to trace.\"\"\"\n\n        try:\n            # I changed str(x) to '%f'%x to solve a bug appearing due to\n            # locale settings. In french for instance, str prints a comma\n            # instead of a colon to indicate the decimal, which confuses\n            # the database into thinking that there are more values than there\n            # is.  A better solution would be to use another delimiter than the\n            # comma. -DH\n            valstring = ', '.join(\n                ['%f' %\n                 x for x in np.ravel(self._getfunc())])\n        except:\n            valstring = str(self._getfunc())\n\n        # Add value to database\n        query = \"INSERT INTO [%s] (recid, trace, %s) values (NULL, %s, %s)\" % \\\n            (self.name, self._vstr, chain, valstring)\n        self.db.cur.execute(query)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef gettrace(self, burn=0, thin=1, chain=-1, slicing=None):\n        # warnings.warn('Use Sampler.trace method instead.',\n        # DeprecationWarning)\n        if not slicing:\n            slicing = slice(burn, None, thin)\n\n        # If chain is None, get the data from all chains.\n        if chain is None:\n            self.db.cur.execute('SELECT * FROM [%s]' % self.name)\n            trace = self.db.cur.fetchall()\n        else:\n            # Deal with negative chains (starting from the end)\n            if chain < 0:\n                chain = range(self.db.chains)[chain]\n            self.db.cur.execute(\n                'SELECT * FROM [%s] WHERE trace=%s' %\n                (self.name, chain))\n            trace = self.db.cur.fetchall()\n        trace = np.array(trace)[:, 2:]\n        if len(self._shape) > 1:\n            trace = trace.reshape(-1, *self._shape)\n        return squeeze(trace[slicing])", "response": "Return the trace of the sampler."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert NumPy ufuncs to deterministic factories.", "response": "def pufunc(func):\n    \"\"\"\n    Called by pfunc to convert NumPy ufuncs to deterministic factories.\n    \"\"\"\n    def dtrm_generator(*args):\n        if len(args) != func.nin:\n            raise ValueError('invalid number of arguments')\n        name = func.__name__ + '(' + '_'.join(\n            [str(arg) for arg in list(args)]) + ')'\n        doc_str = 'A deterministic returning %s(%s)' % (\n            func.__name__,\n            ', '.join([str(arg) for arg in args]))\n        parents = {}\n        for i in xrange(func.nin):\n            parents['in%i' % i] = args[i]\n\n        def wrapper(**kwargs):\n            return func(*[kwargs['in%i' % i] for i in xrange(func.nin)])\n        return pm.Deterministic(\n            wrapper, doc_str, name, parents, trace=False, plot=False)\n    dtrm_generator.__name__ = func.__name__ + '_deterministic_generator'\n    dtrm_generator.__doc__ = \"\"\"\nDeterministic-generating wrapper for %s. Original docstring:\n%s\n\n%s\n    \"\"\" % (func.__name__, '_' * 60, func.__doc__)\n    return dtrm_generator"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a new univariate method for the given operation.", "response": "def create_uni_method(op_name, klass, jacobians=None):\n    \"\"\"\n    Creates a new univariate special method, such as A.__neg__() <=> -A,\n    for target class. The method is called __op_name__.\n    \"\"\"\n    # This function will become the actual method.\n    op_modules = [operator, builtins]\n    op_names = [op_name, op_name + '_']\n\n    op_function_base = find_element(op_names, op_modules, error_on_fail=True)\n    # many such functions do not take keyword arguments, so we need to wrap\n    # them\n\n    def op_function(self):\n        return op_function_base(self)\n\n    def new_method(self):\n        # This code creates a Deterministic object.\n        if not check_special_methods():\n            raise NotImplementedError(\n                'Special method %s called on %s, but special methods have been disabled. Set pymc.special_methods_available to True to enable them.' %\n                (op_name, str(self)))\n\n        jacobian_formats = {'self': 'transformation_operation'}\n        return pm.Deterministic(op_function,\n                                'A Deterministic returning the value of %s(%s)' % (\n                                    op_name, self.__name__),\n                                '(' + op_name + '_' + self.__name__ + ')',\n                                parents={'self': self},\n                                trace=False,\n                                plot=False,\n                                jacobians=jacobians,\n                                jacobian_formats=jacobian_formats)\n    # Make the function into a method for klass.\n\n    new_method.__name__ = '__' + op_name + '__'\n    setattr(\n        klass,\n        new_method.__name__,\n        UnboundMethodType(\n            new_method,\n            None,\n            klass))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_casting_method(op, klass):\n    # This function will become the actual method.\n\n    def new_method(self, op=op):\n        if not check_special_methods():\n            raise NotImplementedError(\n                'Special method %s called on %s, but special methods have been disabled. Set pymc.special_methods_available to True to enable them.' %\n                (op_name, str(self)))\n        return op(self.value)\n    # Make the function into a method for klass.\n    new_method.__name__ = '__' + op.__name__ + '__'\n    setattr(\n        klass,\n        new_method.__name__,\n        UnboundMethodType(\n            new_method,\n            None,\n            klass))", "response": "Creates a univariate special method that can be used to cast the value of the object to the target class."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a binary method that returns the value of the specified operation.", "response": "def create_rl_bin_method(op_name, klass, jacobians={}):\n    \"\"\"\n    Creates a new binary special method with left and right versions, such as\n        A.__mul__(B) <=> A*B,\n        A.__rmul__(B) <=> [B*A if B.__mul__(A) fails]\n    for target class. The method is called __op_name__.\n    \"\"\"\n    # Make left and right versions.\n    for prefix in ['r', '']:\n        # This function will became the methods.\n        op_modules = [operator, builtins]\n        op_names = [op_name, op_name + '_']\n\n        op_function_base = find_element(\n            op_names,\n            op_modules,\n            error_on_fail=True)\n        # many such functions do not take keyword arguments, so we need to wrap\n        # them\n\n        def op_function(a, b):\n            return op_function_base(a, b)\n\n        def new_method(self, other, prefix=prefix):\n            if not check_special_methods():\n                raise NotImplementedError(\n                    'Special method %s called on %s, but special methods have been disabled. Set pymc.special_methods_available to True to enable them.' %\n                    (op_name, str(self)))\n            # This code will create one of two Deterministic objects.\n            if prefix == 'r':\n                parents = {'a': other, 'b': self}\n\n            else:\n                parents = {'a': self, 'b': other}\n            jacobian_formats = {'a': 'broadcast_operation',\n                                'b': 'broadcast_operation'}\n            return pm.Deterministic(op_function,\n                                    'A Deterministic returning the value of %s(%s,%s)' % (\n                                        prefix + op_name, self.__name__, str(\n                                            other)),\n                                    '(' + '_'.join(\n                                        [self.__name__,\n                                         prefix + op_name,\n                                         str(other)]) + ')',\n                                    parents,\n                                    trace=False,\n                                    plot=False,\n                                    jacobians=jacobians,\n                                    jacobian_formats=jacobian_formats)\n        # Convert the functions into methods for klass.\n        new_method.__name__ = '__' + prefix + op_name + '__'\n        setattr(\n            klass,\n            new_method.__name__,\n            UnboundMethodType(\n                new_method,\n                None,\n                klass))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_rl_lin_comb_method(op_name, klass, x_roles, y_roles):\n    # This function will became the methods.\n\n    def new_method(self, other, x_roles=x_roles, y_roles=y_roles):\n        if not check_special_methods():\n            raise NotImplementedError(\n                'Special method %s called on %s, but special methods have been disabled. Set pymc.special_methods_available to True to enable them.' %\n                (op_name, str(self)))\n        x = []\n        y = []\n        for xr in x_roles:\n            if xr == 'self':\n                x.append(self)\n            elif xr == 'other':\n                x.append(other)\n            else:\n                x.append(xr)\n        for yr in y_roles:\n            if yr == 'self':\n                y.append(self)\n            elif yr == 'other':\n                y.append(other)\n            else:\n                y.append(yr)\n        # This code will create one of two Deterministic objects.\n        return LinearCombination(\n            '(' + '_'.join([self.__name__, op_name, str(other)]) + ')', x, y, trace=False, plot=False)\n\n    # Convert the functions into methods for klass.\n    new_method.__name__ = '__' + op_name + '__'\n    setattr(\n        klass,\n        new_method.__name__,\n        UnboundMethodType(\n            new_method,\n            None,\n            klass))", "response": "Creates a binary special method with left and right versions of the class."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a binary special method that returns the value of the object with the given name.", "response": "def create_bin_method(op_name, klass):\n    \"\"\"\n    Creates a new binary special method with only a left version, such as\n    A.__eq__(B) <=> A==B, for target class. The method is called __op_name__.\n    \"\"\"\n    # This function will become the method.\n\n    def new_method(self, other):\n        if not check_special_methods():\n            raise NotImplementedError(\n                'Special method %s called on %s, but special methods have been disabled. Set pymc.special_methods_available to True to enable them.' %\n                (op_name, str(self)))\n        # This code creates a Deterministic object.\n\n        def eval_fun(self, other, op):\n            return getattr(self, op)(other)\n        return pm.Deterministic(eval_fun,\n                                'A Deterministic returning the value of %s(%s,%s)' % (\n                                    op_name, self.__name__, str(other)),\n                                '(' + '_'.join(\n                                    [self.__name__,\n                                     op_name,\n                                     str(other)]) + ')',\n                                {'self': self,\n                                 'other': other,\n                                 'op': '__' + op_name + '__'},\n                                trace=False,\n                                plot=False)\n    # Convert the function into a method for klass.\n    new_method.__name__ = '__' + op_name + '__'\n    setattr(\n        klass,\n        new_method.__name__,\n        UnboundMethodType(\n            new_method,\n            None,\n            klass))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_nonimplemented_method(op_name, klass):\n\n    def new_method(self, *args):\n        raise NotImplementedError(\n            'Special method %s has not been implemented for PyMC variables.' %\n            op_name)\n    new_method.__name__ = '__' + op_name + '__'\n    setattr(\n        klass,\n        new_method.__name__,\n        UnboundMethodType(\n            new_method,\n            None,\n            klass))", "response": "Creates a new method that raises NotImplementedError."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nuses a step method.", "response": "def use_step_method(self, step_method_class, *args, **kwds):\n        \"\"\"\n        M.use_step_method(step_method_class, *args, **kwds)\n\n        Example of usage: To handle stochastic A with a Metropolis instance,\n\n            M.use_step_method(Metropolis, A, sig=.1)\n\n        To subsequently get a reference to the new step method,\n\n            S = M.step_method_dict[A][0]\n        \"\"\"\n\n        new_method = step_method_class(*args, **kwds)\n        if self.verbose > 1:\n            print_(\n                'Using step method %s. Stochastics: ' %\n                step_method_class.__name__)\n\n        for s in new_method.stochastics:\n            self.step_method_dict[s].append(new_method)\n            if self.verbose > 1:\n                print_('\\t' + s.__name__)\n        if self._sm_assigned:\n            self.step_methods.add(new_method)\n\n        setattr(new_method, '_model', self)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nremoves a step method from the step method list.", "response": "def remove_step_method(self, step_method):\n        \"\"\"\n        Removes a step method.\n        \"\"\"\n        try:\n            for s in step_method.stochastics:\n                self.step_method_dict[s].remove(step_method)\n            if hasattr(self, \"step_methods\"):\n                self.step_methods.discard(step_method)\n            self._sm_assigned = False\n        except AttributeError:\n            for sm in step_method:\n                self.remove_step_method(sm)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nassigning a step method to every stochastic variable. If not assign a step method from the registry.", "response": "def assign_step_methods(self, verbose=-1, draw_from_prior_when_possible=True):\n        \"\"\"\n        Make sure every stochastic variable has a step method. If not,\n        assign a step method from the registry.\n        \"\"\"\n\n        if not self._sm_assigned:\n\n            if draw_from_prior_when_possible:\n                # Assign dataless stepper first\n                last_gen = set([])\n                for s in self.stochastics - self.observed_stochastics:\n                    if s._random is not None:\n                        if len(s.extended_children) == 0:\n                            last_gen.add(s)\n\n                dataless, dataless_gens = crawl_dataless(\n                    set(last_gen), [last_gen])\n                if len(dataless):\n                    new_method = DrawFromPrior(\n                        dataless,\n                        dataless_gens[::-1],\n                        verbose=verbose)\n                    setattr(new_method, '_model', self)\n                    for d in dataless:\n                        if not d.observed:\n                            self.step_method_dict[d].append(new_method)\n                            if self.verbose > 1:\n                                print_(\n                                    'Assigning step method %s to stochastic %s' %\n                                    (new_method.__class__.__name__, d.__name__))\n\n            for s in self.stochastics:\n                # If not handled by any step method, make it a new step method\n                # using the registry\n                if len(self.step_method_dict[s]) == 0:\n                    new_method = assign_method(s, verbose=verbose)\n                    setattr(new_method, '_model', self)\n                    self.step_method_dict[s].append(new_method)\n                    if self.verbose > 1:\n                        print_(\n                            'Assigning step method %s to stochastic %s' %\n                            (new_method.__class__.__name__, s.__name__))\n\n            self.step_methods = set()\n            for s in self.stochastics:\n                self.step_methods |= set(self.step_method_dict[s])\n\n            for sm in self.step_methods:\n                if sm.tally:\n                    for name in sm._tuning_info:\n                        self._funs_to_tally[\n                            sm._id + '_' + name] = lambda name=name, sm=sm: getattr(sm, name)\n\n        else:\n            # Change verbosity for step methods\n            for sm_key in self.step_method_dict:\n                for sm in self.step_method_dict[sm_key]:\n                    sm.verbose = verbose\n\n        self.restore_sm_state()\n        self._sm_assigned = True"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsamples the current state of the object.", "response": "def sample(\n        self, iter, burn=0, thin=1, tune_interval=1000, tune_throughout=True,\n        save_interval=None, burn_till_tuned=False, stop_tuning_after=5,\n            verbose=0, progress_bar=True):\n        \"\"\"\n        sample(iter, burn, thin, tune_interval, tune_throughout, save_interval, verbose, progress_bar)\n\n        Initialize traces, run sampling loop, clean up afterward. Calls _loop.\n\n        :Parameters:\n          - iter : int\n            Total number of iterations to do\n          - burn : int\n            Variables will not be tallied until this many iterations are complete, default 0\n          - thin : int\n            Variables will be tallied at intervals of this many iterations, default 1\n          - tune_interval : int\n            Step methods will be tuned at intervals of this many iterations, default 1000\n          - tune_throughout : boolean\n            If true, tuning will continue after the burnin period (True); otherwise tuning\n            will halt at the end of the burnin period.\n          - save_interval : int or None\n            If given, the model state will be saved at intervals of this many iterations\n          - verbose : boolean\n          - progress_bar : boolean\n            Display progress bar while sampling.\n          - burn_till_tuned: boolean\n            If True the Sampler would burn samples until all step methods are tuned.\n            A tuned step methods is one that was not tuned for the last `stop_tuning_after` tuning intervals.\n            The burn-in phase will have a minimum of 'burn' iterations but could be longer if\n            tuning is needed. After the phase is done the sampler will run for another\n            (iter - burn) iterations, and will tally the samples according to the 'thin' argument.\n            This means that the total number of iteration is update throughout the sampling\n            procedure.\n            If burn_till_tuned is True it also overrides the tune_thorughout argument, so no step method\n            will be tuned when sample are being tallied.\n          - stop_tuning_after: int\n            the number of untuned successive tuning interval needed to be reach in order for\n            the burn-in phase to be done (If burn_till_tuned is True).\n        \"\"\"\n\n        self.assign_step_methods(verbose=verbose)\n        \n        iter, burn, thin = np.floor([iter, burn, thin]).astype(int)\n\n        if burn > iter:\n            raise ValueError(\n                'Burn interval cannot be larger than specified number of iterations.')\n\n        self._n_tally = int(iter) - int(burn)\n        if burn_till_tuned:\n            self._stop_tuning_after = stop_tuning_after\n            tune_throughout = False\n            if verbose > 0:\n                print(\n                    \"burn_til_tuned is True. tune_throughout is set to False\")\n            burn = int(max(burn, stop_tuning_after * tune_interval))\n            iter = self._n_tally + burn\n\n        self._iter = int(iter)\n        self._burn = int(burn)\n        self._thin = int(thin)\n        self._tune_interval = int(tune_interval)\n        self._tune_throughout = tune_throughout\n        self._burn_till_tuned = burn_till_tuned\n        self._save_interval = save_interval\n\n        length = max(int(np.round((1.0 * iter - burn) / thin, 0)), 1)\n        self.max_trace_length = length\n\n        # Flags for tuning\n        self._tuning = True\n        self._tuned_count = 0\n\n        # Progress bar\n        self.pbar = None\n        if not verbose and progress_bar:\n            self.pbar = pbar(self._iter)\n\n        # Run sampler\n        Sampler.sample(self, iter, length, verbose)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef tune(self):\n\n        if self.verbose > 0:\n            print_('\\tTuning at iteration', self._current_iter)\n\n        # Initialize counter for number of tuning stochastics\n        tuning_count = 0\n\n        for step_method in self.step_methods:\n            verbose = self.verbose\n            if step_method.verbose > -1:\n                verbose = step_method.verbose\n            # Tune step methods\n            tuning_count += step_method.tune(verbose=self.verbose)\n            if verbose > 1:\n                print_(\n                    '\\t\\tTuning step method %s, returned %i\\n' % (\n                        step_method._id, tuning_count\n                    )\n                )\n                sys.stdout.flush()\n\n        if self._burn_till_tuned:\n            if not tuning_count:\n                # If no step methods needed tuning, increment count\n                self._tuned_count += 1\n            else:\n                # Otherwise re-initialize count\n                self._tuned_count = 0\n\n            # n consecutive clean intervals removed tuning\n            # n is equal to self._stop_tuning_after\n            if self._tuned_count == self._stop_tuning_after:\n                if self.verbose > 0:\n                    print_('\\nFinished tuning')\n                self._tuning = False", "response": "Tune all step methods in the current iteration."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_state(self):\n\n        self.step_methods = set()\n        for s in self.stochastics:\n            self.step_methods |= set(self.step_method_dict[s])\n\n        state = Sampler.get_state(self)\n        state['step_methods'] = {}\n\n        # The state of each StepMethod.\n        for sm in self.step_methods:\n            state['step_methods'][sm._id] = sm.current_state().copy()\n\n        return state", "response": "Return the sampler and step methods current state in order to\n        restart sampling at a later time."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _calc_dic(self):\n\n        # Find mean deviance\n        mean_deviance = np.mean(self.db.trace('deviance')(), axis=0)\n\n        # Set values of all parameters to their mean\n        for stochastic in self.stochastics:\n\n            # Calculate mean of paramter\n            try:\n                mean_value = np.mean(\n                    self.db.trace(\n                        stochastic.__name__)(\n                    ),\n                    axis=0)\n\n                # Set current value to mean\n                stochastic.value = mean_value\n\n            except KeyError:\n                print_(\n                    \"No trace available for %s. DIC value may not be valid.\" %\n                    stochastic.__name__)\n            except TypeError:\n                print_(\n                    \"Not able to calculate DIC: invalid stochastic %s\" %\n                    stochastic.__name__)\n                return None\n\n        # Return twice deviance minus deviance at means\n        return 2 * mean_deviance - self.deviance", "response": "Calculates the deviance information Criterion for all the parameters in the current object"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef plot_GP_envelopes(f, x, HPD=[\n                      .25, .5, .95], transx=None, transy=None):\n    \"\"\"\n    plot_GP_envelopes(f, x[, HPD, transx, transy])\n\n\n    Plots centered posterior probability envelopes for f, which is a GP instance,\n    which is a function of one variable.\n\n\n    :Arguments:\n\n        -   `f`: A GaussianProcess object.\n\n        -   `x`: The mesh on which to plot the envelopes.\n\n        -   `HPD`: A list of values between 0 and 1 giving the probability mass\n            contained in each envelope.\n\n        -   `transx`: Any transformation of the x-axis.\n\n        -   `transy`: Any transformation of the y-axis.\n    \"\"\"\n    try:\n        from pymc.Matplot import centered_envelope\n\n        f_trace = f.trace()\n        x = x.ravel()\n        N = len(f_trace)\n        func_stacks = np.zeros((N, len(x)), dtype=float)\n\n        def identity(y):\n            return y\n\n        if transy is None:\n            transy = identity\n        if transx is None:\n            transx = identity\n\n        # Get evaluations\n        for i in range(N):\n            f = copy(f_trace[i])\n            func_stacks[i, :] = transy(f(transx(x)))\n\n        # Plot envelopes\n        HPD = np.sort(HPD)\n        sorted_func_stack = np.sort(func_stacks, 0)\n        for m in HPD[::-1]:\n            env = centered_envelope(sorted_func_stack, m)\n            # from IPython.Debugger import Pdb\n            # Pdb(color_scheme='LightBG').set_trace()\n            env.display(x, alpha=1. - m * .5, new=False)\n        centered_envelope(\n            sorted_func_stack,\n            0.).display(x,\n                        alpha=1.,\n                        new=False)\n    except ImportError:\n        six.print_('Plotter could not be imported; plotting disabled')", "response": "Plots the posterior probability envelopes for a GP instance."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef new_dist_class(*new_class_args):\n\n    (dtype,\n     name,\n     parent_names,\n     parents_default,\n     docstr,\n     logp,\n     random,\n     mv,\n     logp_partial_gradients) = new_class_args\n\n    class new_class(Stochastic):\n        __doc__ = docstr\n\n        def __init__(self, *args, **kwds):\n            (dtype,\n             name,\n             parent_names,\n             parents_default,\n             docstr,\n             logp,\n             random,\n             mv,\n             logp_partial_gradients) = new_class_args\n            parents = parents_default\n\n            # Figure out what argument names are needed.\n            arg_keys = [\n                'name',\n                'parents',\n                'value',\n                'observed',\n                'size',\n                'trace',\n                'rseed',\n                'doc',\n                'debug',\n                'plot',\n                'verbose']\n            arg_vals = [\n                None, parents, None, False, None, True, True, None, False, None, -1]\n\n            # No size argument allowed for multivariate distributions.\n            if mv:\n                arg_keys.pop(4)\n                arg_vals.pop(4)\n\n            arg_dict_out = dict(zip(arg_keys, arg_vals))\n            args_needed = ['name'] + parent_names + arg_keys[2:]\n\n            # Sort positional arguments\n            for i in xrange(len(args)):\n                try:\n                    k = args_needed.pop(0)\n                    if k in parent_names:\n                        parents[k] = args[i]\n                    else:\n                        arg_dict_out[k] = args[i]\n                except:\n                    raise ValueError(\n                        'Too many positional arguments provided. Arguments for class ' +\n                        self.__class__.__name__ +\n                        ' are: ' +\n                        str(args_needed))\n\n            # Sort keyword arguments\n            for k in args_needed:\n                if k in parent_names:\n                    try:\n                        parents[k] = kwds.pop(k)\n                    except:\n                        if k in parents_default:\n                            parents[k] = parents_default[k]\n                        else:\n                            raise ValueError('No value given for parent ' + k)\n                elif k in arg_dict_out.keys():\n                    try:\n                        arg_dict_out[k] = kwds.pop(k)\n                    except:\n                        pass\n\n            # Remaining unrecognized arguments raise an error.\n            if len(kwds) > 0:\n                raise TypeError('Keywords ' +\n                                str(kwds.keys()) +\n                                ' not recognized. Arguments recognized are ' +\n                                str(args_needed))\n\n        # Determine size desired for scalar variables.\n        # Notes\n        # -----\n        # Case | init_val     | parents       | size | value.shape | bind size\n        # ------------------------------------------------------------------\n        # 1.1  | None         | scalars       | None | 1           | 1\n        # 1.2  | None         | scalars       | n    | n           | n\n        # 1.3  | None         | n             | None | n           | 1\n        # 1.4  | None         | n             | n(m) | n (Error)   | 1 (-)\n        # 2.1  | scalar       | scalars       | None | 1           | 1\n        # 2.2  | scalar       | scalars       | n    | n           | n\n        # 2.3  | scalar       | n             | None | n           | 1\n        # 2.4  | scalar       | n             | n(m) | n (Error)   | 1 (-)\n        # 3.1  | n            | scalars       | None | n           | n\n        # 3.2  | n            | scalars       | n(m) | n (Error)   | n (-)\n        # 3.3  | n            | n             | None | n           | 1\n        # 3.4  | n            | n             | n(m) | n (Error)   | 1 (-)\n\n            if not mv:\n\n                shape = arg_dict_out.pop('size')\n                shape = None if shape is None else tuple(np.atleast_1d(shape))\n\n                init_val = arg_dict_out['value']\n                init_val_shape = None if init_val is None else np.shape(\n                    init_val)\n\n                if len(parents) > 0:\n                    pv = [np.shape(utils.value(v)) for v in parents.values()]\n                    biggest_parent = np.argmax(\n                        [(np.prod(v) if v else 0) for v in pv])\n                    parents_shape = pv[biggest_parent]\n\n                    # Scalar parents can support any shape.\n                    if np.prod(parents_shape) < 1:\n                        parents_shape = None\n\n                else:\n                    parents_shape = None\n\n                def shape_error():\n                    raise ValueError(\n                        'Shapes are incompatible: value %s, largest parent %s, shape argument %s' %\n                        (shape, init_val_shape, parents_shape))\n\n                if init_val_shape is not None and shape is not None and init_val_shape != shape:\n                    shape_error()\n\n                given_shape = init_val_shape or shape\n                bindshape = given_shape or parents_shape\n\n                # Check consistency of bindshape and parents_shape\n                if parents_shape is not None:\n                    # Uncomment to leave broadcasting completely up to NumPy's random functions\n                    # if bindshape[-np.alen(parents_shape):]!=parents_shape:\n                    # Uncomment to limit broadcasting flexibility to what the\n                    # Fortran likelihoods can handle.\n                    if bindshape < parents_shape:\n                        shape_error()\n\n                if random is not None:\n                    random = bind_size(random, bindshape)\n\n            elif 'size' in kwds.keys():\n                raise ValueError(\n                    'No size argument allowed for multivariate stochastic variables.')\n\n            # Call base class initialization method\n            if arg_dict_out.pop('debug'):\n                logp = debug_wrapper(logp)\n                random = debug_wrapper(random)\n            else:\n                Stochastic.__init__(\n                    self,\n                    logp=logp,\n                    random=random,\n                    logp_partial_gradients=logp_partial_gradients,\n                    dtype=dtype,\n                    **arg_dict_out)\n\n    new_class.__name__ = name\n    new_class.parent_names = parent_names\n    new_class.parents_default = parents_default\n    new_class.dtype = dtype\n    new_class.mv = mv\n    new_class.raw_fns = {'logp': logp, 'random': random}\n\n    return new_class", "response": "Returns a new class from a distribution."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef stochastic_from_dist(\n        name, logp, random=None, logp_partial_gradients={}, dtype=np.float, mv=False):\n    \"\"\"\n    Return a Stochastic subclass made from a particular distribution.\n\n    :Parameters:\n      name : string\n        The name of the new class.\n      logp : function\n        The log-probability function.\n      random : function\n        The random function\n      dtype : numpy dtype\n        The dtype of values of instances.\n      mv : boolean\n        A flag indicating whether this class represents\n        array-valued variables.\n\n    :Example:\n      >>> Exponential = stochastic_from_dist('exponential',\n                                              logp=exponential_like,\n                                              random=rexponential,\n                                              dtype=np.float,\n                                              mv=False)\n      >>> A = Exponential(self_name, value, beta)\n\n    .. note::\n      new_dist_class is a more flexible class factory. Also consider\n      subclassing Stochastic directly.\n      stochastic_from_data is suited for non-parametric distributions.\n\n    :SeeAlso:\n      new_dist_class, stochastic_from_data\n    \"\"\"\n\n    (args, defaults) = utils.get_signature(logp)\n    parent_names = args[1:]\n    try:\n        parents_default = dict(zip(args[-len(defaults):], defaults))\n    except TypeError:  # No parents at all.\n        parents_default = {}\n\n    name = capitalize(name)\n\n    # Build docstring from distribution\n    parents_str = ''\n    if parent_names:\n        parents_str = ', '.join(parent_names) + ', '\n    docstr = name[0] + ' = ' + name + \\\n        '(name, ' + parents_str + 'value=None, observed=False,'\n    if not mv:\n        docstr += ' size=1,'\n    docstr += ' trace=True, rseed=True, doc=None, verbose=-1, debug=False)\\n\\n'\n    docstr += 'Stochastic variable with ' + name + \\\n        ' distribution.\\nParents are: ' + ', '.join(parent_names) + '.\\n\\n'\n    docstr += 'Docstring of log-probability function:\\n'\n    try:\n        docstr += logp.__doc__\n    except TypeError:\n        pass  # This will happen when logp doesn't have a docstring\n\n    logp = valuewrapper(logp)\n    distribution_arguments = logp.__dict__\n\n    wrapped_logp_partial_gradients = {}\n\n    for parameter, func in six.iteritems(logp_partial_gradients):\n        wrapped_logp_partial_gradients[parameter] = valuewrapper(\n            logp_partial_gradients[parameter],\n            arguments=distribution_arguments)\n\n    return new_dist_class(dtype, name, parent_names, parents_default, docstr,\n                          logp, random, mv, wrapped_logp_partial_gradients)", "response": "Returns a Stochastic subclass made from a particular distribution."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a Stochastic subclass made from arbitrary data.", "response": "def stochastic_from_data(name, data, lower=-np.inf, upper=np.inf,\n                         value=None, observed=False, trace=True, verbose=-1, debug=False):\n    \"\"\"\n    Return a Stochastic subclass made from arbitrary data.\n\n    The histogram for the data is fitted with Kernel Density Estimation.\n\n    :Parameters:\n      - `data`  : An array with samples (e.g. trace[:])\n      - `lower` : Lower bound on possible outcomes\n      - `upper` : Upper bound on possible outcomes\n\n    :Example:\n       >>> from pymc import stochastic_from_data\n       >>> pos = stochastic_from_data('posterior', posterior_samples)\n       >>> prior = pos # update the prior with arbitrary distributions\n\n    :Alias:\n      Histogram\n    \"\"\"\n    pdf = gaussian_kde(data)  # automatic bandwidth selection\n\n    # account for tail contribution\n    lower_tail = upper_tail = 0.\n    if lower > -np.inf:\n        lower_tail = pdf.integrate_box(-np.inf, lower)\n    if upper < np.inf:\n        upper_tail = pdf.integrate_box(upper, np.inf)\n    factor = 1. / (1. - (lower_tail + upper_tail))\n\n    def logp(value):\n        prob = factor * pdf(value)\n        if value < lower or value > upper:\n            return -np.inf\n        elif prob <= 0.:\n            return -np.inf\n        else:\n            return np.log(prob)\n\n    def random():\n        res = pdf.resample(1)[0][0]\n        while res < lower or res > upper:\n            res = pdf.resample(1)[0][0]\n        return res\n\n    if value is None:\n        value = random()\n\n    return Stochastic(logp=logp,\n                      doc='Non-parametric density with Gaussian Kernels.',\n                      name=name,\n                      parents={},\n                      random=random,\n                      trace=trace,\n                      value=value,\n                      dtype=float,\n                      observed=observed,\n                      verbose=verbose)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef constrain(value, lower=-np.Inf, upper=np.Inf, allow_equal=False):\n\n    ok = flib.constrain(value, lower, upper, allow_equal)\n    if ok == 0:\n        raise ZeroProbability", "response": "Apply interval constraint on stochastic value."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nexpanding flattened triangular matrix.", "response": "def expand_triangular(X, k):\n    \"\"\"\n    Expand flattened triangular matrix.\n    \"\"\"\n\n    X = X.tolist()\n    # Unflatten matrix\n    Y = np.asarray(\n        [[0] * i + X[i * k - (i * (i - 1)) / 2: i * k + (k - i)] for i in range(k)])\n    # Loop over rows\n    for i in range(k):\n        # Loop over columns\n        for j in range(k):\n            Y[j, i] = Y[i, j]\n    return Y"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef gofwrapper(f, loss_function='squared'):\n\n    name = f.__name__[:-5]\n    # Take a snapshot of the main namespace.\n\n    # Find the functions needed to compute the gof points.\n    expval_func = eval(name + '_expval')\n    random_func = eval('r' + name)\n\n    def wrapper(*args, **kwds):\n        \"\"\"\n        This wraps a likelihood.\n        \"\"\"\n\n        \"\"\"Return gof points.\"\"\"\n\n        # Calculate loss\n        loss = kwds.pop('gof', loss_functions[loss_function])\n\n        # Expected value, given parameters\n        expval = expval_func(*args[1:], **kwds)\n        y = random_func(size=len(args[0]), *args[1:], **kwds)\n        f.gof_points = GOFpoints(args[0], y, expval, loss)\n\n        \"\"\"Return likelihood.\"\"\"\n\n        return f(*args, **kwds)\n\n    # Assign function attributes to wrapper.\n    wrapper.__doc__ = f.__doc__\n    wrapper.__name__ = f.__name__\n    wrapper.name = name\n\n    return wrapper", "response": "This is a function that returns a function that computes the goodness - of - fit points for a likelihood."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef rarlognormal(a, sigma, rho, size=1):\n    f = utils.ar1\n    if np.isscalar(a):\n        r = f(rho, 0, sigma, size)\n    else:\n        n = len(a)\n        r = [f(rho, 0, sigma, n) for i in range(size)]\n        if size == 1:\n            r = r[0]\n    return a * np.exp(r)", "response": "R Autoregressive normal random variates."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef betabin_like(x, alpha, beta, n):\n    return flib.betabin_like(x, alpha, beta, n)", "response": "Beta - binomial log - likelihood. Equivalent to binomial random\n    variables with probabilities drawn from a\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef categorical_like(x, p):\n\n    p = np.atleast_2d(p)\n    if np.any(abs(np.sum(p, 1) - 1) > 0.0001):\n        print_(\"Probabilities in categorical_like sum to\", np.sum(p, 1))\n    return flib.categorical(np.array(x).astype(int), p)", "response": "Categorical log - likelihood."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef rcauchy(alpha, beta, size=None):\n\n    return alpha + beta * np.tan(pi * random_number(size) - pi / 2.0)", "response": "Returns Cauchy random variates."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef dirichlet_like(x, theta):\n    x = np.atleast_2d(x)\n    theta = np.atleast_2d(theta)\n    if (np.shape(x)[-1] + 1) != np.shape(theta)[-1]:\n        raise ValueError('The dimension of x in dirichlet_like must be k-1.')\n    return flib.dirichlet(x, theta)", "response": "R Dirichlet log - likelihood."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef gev_expval(xi, mu=0, sigma=1):\n    return mu - (sigma / xi) + (sigma / xi) * flib.gamfun(1 - xi)", "response": "Calculates the value of generalized extreme value distribution."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngeneralizes Extreme Value log - likelihood", "response": "def gev_like(x, xi, mu=0, sigma=1):\n    R\"\"\"\n    Generalized Extreme Value log-likelihood\n\n    .. math::\n        pdf(x \\mid \\xi,\\mu,\\sigma) = \\frac{1}{\\sigma}(1 + \\xi \\left[\\frac{x-\\mu}{\\sigma}\\right])^{-1/\\xi-1}\\exp{-(1+\\xi \\left[\\frac{x-\\mu}{\\sigma}\\right])^{-1/\\xi}}\n\n    .. math::\n        \\sigma & > 0,\\\\\n        x & > \\mu-\\sigma/\\xi \\text{ if } \\xi > 0,\\\\\n        x & < \\mu-\\sigma/\\xi \\text{ if } \\xi < 0\\\\\n        x & \\in [-\\infty,\\infty] \\text{ if } \\xi = 0\n\n    \"\"\"\n\n    return flib.gev(x, xi, mu, sigma)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning half - Cauchy random variates.", "response": "def rhalf_cauchy(alpha, beta, size=None):\n    \"\"\"\n    Returns half-Cauchy random variates.\n    \"\"\"\n\n    return abs(alpha + beta * np.tan(pi * random_number(size) - pi / 2.0))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef half_cauchy_like(x, alpha, beta):\n\n    x = np.atleast_1d(x)\n    if sum(x.ravel() < 0):\n        return -inf\n    return flib.cauchy(x, alpha, beta) + len(x) * np.log(2)", "response": "R | half - Cauchy log - likelihood. Simply the absolute value of Cauchy."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef rhalf_normal(tau, size=None):\n\n    return abs(np.random.normal(0, np.sqrt(1 / tau), size))", "response": "Random half - normal variates."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a hypergeometric random variates.", "response": "def rhypergeometric(n, m, N, size=None):\n    \"\"\"\n    Returns hypergeometric random variates.\n    \"\"\"\n    if n == 0:\n        return np.zeros(size, dtype=int)\n    elif n == N:\n        out = np.empty(size, dtype=int)\n        out.fill(m)\n        return out\n    return np.random.hypergeometric(n, N - n, m, size)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef hypergeometric_like(x, n, m, N):\n\n    return flib.hyperg(x, n, m, N)", "response": "R Hypergeometric log - likelihood."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef laplace_like(x, mu, tau):\n\n    return flib.gamma(np.abs(np.array(x) - mu), 1, tau) - \\\n        np.size(x) * np.log(2)", "response": "R Laplace - like log - likelihood."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning random lognormal variates.", "response": "def rlognormal(mu, tau, size=None):\n    \"\"\"\n    Return random lognormal variates.\n    \"\"\"\n\n    return np.random.lognormal(mu, np.sqrt(1. / tau), size)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef multinomial_like(x, n, p):\n    # flib expects 2d arguments. Do we still want to support multiple p\n    # values along realizations ?\n    x = np.atleast_2d(x)\n    p = np.atleast_2d(p)\n\n    return flib.multinomial(x, n, p)", "response": "R Multinomial log - likelihood."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef rmultivariate_hypergeometric(n, m, size=None):\n\n    N = len(m)\n    urn = np.repeat(np.arange(N), m)\n\n    if size:\n        draw = np.array([[urn[i] for i in np.random.permutation(len(urn))[:n]]\n                         for j in range(size)])\n\n        r = [[np.sum(draw[j] == i) for i in range(len(m))]\n             for j in range(size)]\n    else:\n        draw = np.array([urn[i] for i in np.random.permutation(len(urn))[:n]])\n\n        r = [np.sum(draw == i) for i in range(len(m))]\n    return np.asarray(r)", "response": "Random multivariate hypergeometric variates."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the expected value of multivariate hypergeometric distribution.", "response": "def multivariate_hypergeometric_expval(n, m):\n    \"\"\"\n    Expected value of multivariate hypergeometric distribution.\n\n    Parameters:\n      - `n` : Number of draws.\n      - `m` : Number of items in each categoy.\n    \"\"\"\n    m = np.asarray(m, float)\n    return n * (m / m.sum())"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef rmv_normal(mu, tau, size=1):\n\n    sig = np.linalg.cholesky(tau)\n    mu_size = np.shape(mu)\n\n    if size == 1:\n        out = np.random.normal(size=mu_size)\n        try:\n            flib.dtrsm_wrap(sig, out, 'L', 'T', 'L', 1.)\n        except:\n            out = np.linalg.solve(sig, out)\n        out += mu\n        return out\n    else:\n        if not hasattr(size, '__iter__'):\n            size = (size,)\n        tot_size = np.prod(size)\n        out = np.random.normal(size=(tot_size,) + mu_size)\n        for i in xrange(tot_size):\n            try:\n                flib.dtrsm_wrap(sig, out[i, :], 'L', 'T', 'L', 1.)\n            except:\n                out[i, :] = np.linalg.solve(sig, out[i,:])\n            out[i, :] += mu\n        return out.reshape(size + mu_size)", "response": "Random multivariate normal variates."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef mv_normal_like(x, mu, tau):\n    # TODO: Vectorize in Fortran\n    if len(np.shape(x)) > 1:\n        return np.sum([flib.prec_mvnorm(r, mu, tau) for r in x])\n    else:\n        return flib.prec_mvnorm(x, mu, tau)", "response": "R Multivariate normal log - likelihood."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef mv_normal_cov_like(x, mu, C):\n    # TODO: Vectorize in Fortran\n    if len(np.shape(x)) > 1:\n        return np.sum([flib.cov_mvnorm(r, mu, C) for r in x])\n    else:\n        return flib.cov_mvnorm(x, mu, C)", "response": "R Multivariate normal log - likelihood parameterized by a covariance matrix."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef rmv_normal_chol(mu, sig, size=1):\n    mu_size = np.shape(mu)\n\n    if size == 1:\n        out = np.random.normal(size=mu_size)\n        try:\n            flib.dtrmm_wrap(sig, out, 'L', 'N', 'L', 1.)\n        except:\n            out = np.dot(sig, out)\n        out += mu\n        return out\n    else:\n        if not hasattr(size, '__iter__'):\n            size = (size,)\n        tot_size = np.prod(size)\n        out = np.random.normal(size=(tot_size,) + mu_size)\n        for i in xrange(tot_size):\n            try:\n                flib.dtrmm_wrap(sig, out[i, :], 'L', 'N', 'L', 1.)\n            except:\n                out[i, :] = np.dot(sig, out[i,:])\n            out[i, :] += mu\n        return out.reshape(size + mu_size)", "response": "Random multivariate normal variates."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef mv_normal_chol_like(x, mu, sig):\n    # TODO: Vectorize in Fortran\n    if len(np.shape(x)) > 1:\n        return np.sum([flib.chol_mvnorm(r, mu, sig) for r in x])\n    else:\n        return flib.chol_mvnorm(x, mu, sig)", "response": "MV - Normal log - likelihood."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef rnegative_binomial(mu, alpha, size=None):\n    # Using gamma-poisson mixture rather than numpy directly\n    # because numpy apparently rounds\n    mu = np.asarray(mu, dtype=float)\n    pois_mu = np.random.gamma(alpha, mu / alpha, size)\n    return np.random.poisson(pois_mu, size)", "response": "Random negative binomial variates."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef rtruncated_pareto(alpha, m, b, size=None):\n    u = random_number(size)\n    return (-(u * b ** alpha - u * m ** alpha - b ** alpha) /\n            (b ** alpha * m ** alpha)) ** (-1. / alpha)", "response": "Random bounded Pareto variates."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef truncated_pareto_expval(alpha, m, b):\n\n    if alpha <= 1:\n        return inf\n    part1 = (m ** alpha) / (1. - (m / b) ** alpha)\n    part2 = 1. * alpha / (alpha - 1)\n    part3 = (1. / (m ** (alpha - 1)) - 1. / (b ** (alpha - 1.)))\n    return part1 * part2 * part3", "response": "Calculates the exponential value of truncated Pareto distribution."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef rtruncated_poisson(mu, k, size=None):\n\n    # Calculate m\n    try:\n        m = max(0, np.floor(k - mu))\n    except (TypeError, ValueError):\n        # More than one mu\n        return np.array([rtruncated_poisson(x, i)\n                         for x, i in zip(mu, np.resize(k, np.size(mu)))]).squeeze()\n    k -= 1\n\n    # Calculate constant for acceptance probability\n    C = np.exp(flib.factln(k + 1) - flib.factln(k + 1 - m))\n\n    # Empty array to hold random variates\n    rvs = np.empty(0, int)\n\n    total_size = np.prod(size or 1)\n\n    while(len(rvs) < total_size):\n\n        # Propose values by sampling from untruncated Poisson with mean mu + m\n        proposals = np.random.poisson(\n            mu + m, (total_size * 4, np.size(m))).squeeze()\n\n        # Acceptance probability\n        a = C * np.array([np.exp(flib.factln(y - m) - flib.factln(y))\n                          for y in proposals])\n        a *= proposals > k\n\n        # Uniform random variates\n        u = np.random.random(total_size * 4)\n\n        rvs = np.append(rvs, proposals[u < a])\n\n    return np.reshape(rvs[:total_size], size)", "response": "Random truncated Poisson variates with minimum value k generated by rejection sampling."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the expected value of the truncated normal distribution.", "response": "def truncated_normal_expval(mu, tau, a, b):\n    \"\"\"Expected value of the truncated normal distribution.\n\n    .. math::\n       E(X) =\\mu + \\frac{\\sigma(\\varphi_1-\\varphi_2)}{T}\n\n\n    where\n\n    .. math::\n       T & =\\Phi\\left(\\frac{B-\\mu}{\\sigma}\\right)-\\Phi\n       \\left(\\frac{A-\\mu}{\\sigma}\\right)\\text \\\\\n       \\varphi_1 &=\n       \\varphi\\left(\\frac{A-\\mu}{\\sigma}\\right) \\\\\n       \\varphi_2 &=\n       \\varphi\\left(\\frac{B-\\mu}{\\sigma}\\right) \\\\\n\n    and :math:`\\varphi = N(0,1)` and :math:`tau & 1/sigma**2`.\n\n    :Parameters:\n      - `mu` : Mean of the distribution.\n      - `tau` : Precision of the distribution, which corresponds to 1/sigma**2 (tau > 0).\n      - `a` : Left bound of the distribution.\n      - `b` : Right bound of the distribution.\n\n    \"\"\"\n    phia = np.exp(normal_like(a, mu, tau))\n    phib = np.exp(normal_like(b, mu, tau))\n    sigma = 1. / np.sqrt(tau)\n    Phia = utils.normcdf((a - mu) / sigma)\n    if b == np.inf:\n        Phib = 1.0\n    else:\n        Phib = utils.normcdf((b - mu) / sigma)\n    return (mu + (phia - phib) / (Phib - Phia))[0]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nskew - normal random variates.", "response": "def rskew_normal(mu, tau, alpha, size=()):\n    \"\"\"\n    Skew-normal random variates.\n    \"\"\"\n    size_ = size or (1,)\n    len_ = np.prod(size_)\n    return flib.rskewnorm(\n        len_, mu, tau, alpha, np.random.normal(size=2 * len_)).reshape(size)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef skew_normal_expval(mu, tau, alpha):\n    delta = alpha / np.sqrt(1. + alpha ** 2)\n    return mu + np.sqrt(2 / pi / tau) * delta", "response": "Return the exponential of the skew - normal random variables."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef rt(nu, size=None):\n    return rnormal(0, 1, size) / np.sqrt(rchi2(nu, size) / nu)", "response": "Student's t random variates."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef t_like(x, nu):\n    nu = np.asarray(nu)\n    return flib.t(x, nu)", "response": "R |t| - > T log - likelihood."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef rnoncentral_t(mu, lam, nu, size=None):\n    tau = rgamma(nu / 2., nu / (2. * lam), size)\n    return rnormal(mu, tau)", "response": "Random non - central variation t random variates."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef noncentral_t_like(x, mu, lam, nu):\n    mu = np.asarray(mu)\n    lam = np.asarray(lam)\n    nu = np.asarray(nu)\n    return flib.nct(x, mu, lam, nu)", "response": "Non - central Student s T log - likelihood."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef rwishart_cov(n, C):\n    # return rwishart(n, np.linalg.inv(C))\n\n    p = np.shape(C)[0]\n    # Need cholesky decomposition of precision matrix C^-1?\n    sig = np.linalg.cholesky(C)\n\n    if n <= (p-1):\n        raise ValueError('Wishart parameter n must be greater '\n                         'than size of matrix.')\n\n    norms = np.random.normal(size=(p * (p - 1)) // 2)\n    chi_sqs = np.sqrt(np.random.chisquare(df=np.arange(n, n - p, -1)))\n    A = flib.expand_triangular(chi_sqs, norms)\n\n    flib.dtrmm_wrap(sig, A, side='L', uplo='L', transa='N', alpha=1.)\n    w = np.asmatrix(np.dot(A, A.T))\n    flib.symmetrize(w)\n    return w", "response": "Returns a Wishart random matrix."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef valuewrapper(f, arguments=None):\n    def wrapper(**kwds):\n        value = kwds.pop('value')\n        return f(value, **kwds)\n\n    if arguments is None:\n        wrapper.__dict__.update(f.__dict__)\n    else:\n        wrapper.__dict__.update(arguments)\n\n    return wrapper", "response": "Return a likelihood accepting value instead of x as a keyword argument."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef local_decorated_likelihoods(obj):\n\n    for name, like in six.iteritems(likelihoods):\n        obj[name + '_like'] = gofwrapper(like, snapshot)", "response": "Decorate likelihoods with local_like"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef one_over_x_like(x):\n    if np.any(x < 0):\n        return -np.Inf\n    else:\n        return -np.sum(np.log(x))", "response": "returns the log - likelihood of a single item"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef extend_dirichlet(p):\n    if len(np.shape(p)) > 1:\n        return np.hstack((p, np.atleast_2d(1. - np.sum(p))))\n    else:\n        return np.hstack((p, 1. - np.sum(p)))", "response": "Extend a directoryichlet by adding 1 - sum to the end of p."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the expval of a categorical distribution with parent p of length k - 1.", "response": "def mod_categorical_expval(p):\n    \"\"\"\n    Expected value of categorical distribution with parent p of length k-1.\n\n    An implicit k'th category  is assumed to exist with associated\n    probability 1-sum(p).\n    \"\"\"\n    p = extend_dirichlet(p)\n    return np.sum([p * i for i, p in enumerate(p)])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef deterministic_from_funcs(\n        name, eval, jacobians={}, jacobian_formats={}, dtype=np.float, mv=False):\n    \"\"\"\n    Return a Stochastic subclass made from a particular distribution.\n\n    :Parameters:\n      name : string\n        The name of the new class.\n      jacobians : function\n        The log-probability function.\n      random : function\n        The random function\n      dtype : numpy dtype\n        The dtype of values of instances.\n      mv : boolean\n        A flag indicating whether this class represents\n        array-valued variables.\n\n    \"\"\"\n\n    (args, defaults) = get_signature(eval)\n    parent_names = args[0:]\n    try:\n        parents_default = dict(zip(args[-len(defaults):], defaults))\n    except TypeError:  # No parents at all.\n        parents_default = {}\n\n    # Build docstring from distribution\n    docstr = name[0] + ' = ' + name + '('.join(parent_names) + ')\\n\\n'\n    docstr += 'Deterministic variable with ' + name + \\\n        ' distribution.\\nParents are: ' + ', '.join(parent_names) + '.\\n\\n'\n    docstr += 'Docstring of evaluatio function:\\n'\n    docstr += eval.__doc__\n\n    return new_deterministic_class(\n        dtype, name, parent_names, parents_default, docstr, eval, jacobians, jacobian_formats)", "response": "Returns a Stochastic subclass made from a particular distribution."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a new class from a distribution of class parameters.", "response": "def new_deterministic_class(*new_class_args):\n    \"\"\"\n    Returns a new class from a distribution.\n\n    :Parameters:\n      dtype : numpy dtype\n        The dtype values of instances of this class.\n      name : string\n        Name of the new class.\n      parent_names : list of strings\n        The labels of the parents of this class.\n      parents_default : list\n        The default values of parents.\n      docstr : string\n        The docstring of this class.\n      eval : function\n        The function for this class.\n      jacobians : dictionary of functions\n        The dictionary of jacobian functions for the class\n      jacobian_formats : dictionary of strings\n        A dictionary indicating the format of each jacobian function\n    \"\"\"\n\n    (dtype, name, parent_names, parents_default, docstr,\n     eval, jacobians, jacobian_formats) = new_class_args\n\n    class new_class(pm.Deterministic):\n        __doc__ = docstr\n\n        def __init__(self, *args, **kwds):\n            (dtype, name, parent_names, parents_default, docstr,\n             eval, jacobians, jacobian_formats) = new_class_args\n            parents = parents_default\n\n            # Figure out what argument names are needed.\n            arg_keys = ['parents', 'trace', 'doc', 'debug', 'plot', 'verbose']\n            arg_vals = [parents, False, True, None, False, -1]\n\n            arg_dict_out = dict(zip(arg_keys, arg_vals))\n            args_needed = parent_names + arg_keys[2:]\n\n            # Sort positional arguments\n            for i in xrange(len(args)):\n                try:\n                    k = args_needed.pop(0)\n                    if k in parent_names:\n                        parents[k] = args[i]\n                    else:\n                        arg_dict_out[k] = args[i]\n                except:\n                    raise ValueError(\n                        'Too many positional arguments provided. Arguments for class ' + self.__class__.__name__ + ' are: ' + str(\n                            all_args_needed))\n\n            # Sort keyword arguments\n            for k in args_needed:\n                if k in parent_names:\n                    try:\n                        parents[k] = kwds.pop(k)\n                    except:\n                        if k in parents_default:\n                            parents[k] = parents_default[k]\n                        else:\n                            raise ValueError('No value given for parent ' + k)\n                elif k in arg_dict_out.keys():\n                    try:\n                        arg_dict_out[k] = kwds.pop(k)\n                    except:\n                        pass\n\n            # Remaining unrecognized arguments raise an error.\n            if len(kwds) > 0:\n                raise TypeError(\n                    'Keywords ' + str(\n                        kwds.keys(\n                        )) + ' not recognized. Arguments recognized are ' + str(\n                        args_needed))\n\n            # Call base class initialization method\n            if arg_dict_out.pop('debug'):\n                pass\n            else:\n                parent_strs = []\n                for key in parents.keys():\n                    parent_strs.append(str(key))\n\n                instance_name = name + '(' + ','.join(parent_strs) + ')'\n\n                pm.Deterministic.__init__(\n                    self,\n                    name=instance_name,\n                    eval=eval,\n                    jacobians=jacobians,\n                    jacobian_formats=jacobian_formats,\n                    dtype=dtype,\n                    **arg_dict_out)\n\n    new_class.__name__ = name\n    new_class.parent_names = parent_names\n\n    return new_class"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef logp_gradient_of_set(variable_set, calculation_set=None):\n\n    logp_gradients = {}\n    for variable in variable_set:\n        logp_gradients[variable] = logp_gradient(variable, calculation_set)\n\n    return logp_gradients", "response": "Calculates the gradient of the joint log posterior with respect to all the variables in variable_set."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef logp_gradient(variable, calculation_set=None):\n    return variable.logp_partial_gradient(variable, calculation_set) + sum(\n        [child.logp_partial_gradient(variable, calculation_set) for child in variable.children])", "response": "Calculates the gradient of the joint log posterior with respect to variable."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate posterior statistics for the current node.", "response": "def stats(self, alpha=0.05, start=0, batches=100,\n              chain=None, quantiles=(2.5, 25, 50, 75, 97.5)):\n        \"\"\"\n        Generate posterior statistics for node.\n\n        :Parameters:\n        alpha : float\n          The alpha level for generating posterior intervals. Defaults to\n          0.05.\n\n        start : int\n          The starting index from which to summarize (each) chain. Defaults\n          to zero.\n\n        batches : int\n          Batch size for calculating standard deviation for non-independent\n          samples. Defaults to 100.\n\n        chain : int\n          The index for which chain to summarize. Defaults to None (all\n          chains).\n\n        quantiles : tuple or list\n          The desired quantiles to be calculated. Defaults to (2.5, 25, 50, 75, 97.5).\n        \"\"\"\n        return self.trace.stats(alpha=alpha, start=start, batches=batches,\n                                chain=chain, quantiles=quantiles)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef summary(self, alpha=0.05, start=0, batches=100, chain=None, roundto=3):\n\n        # Calculate statistics for Node\n        statdict = self.stats(\n            alpha=alpha,\n            start=start,\n            batches=batches,\n            chain=chain)\n        \n        size = np.size(statdict['mean'])\n\n        print_('\\n%s:' % self.__name__)\n        print_(' ')\n\n        # Initialize buffer\n        buffer = []\n\n        # Index to interval label\n        iindex = [key.split()[-1] for key in statdict.keys()].index('interval')\n        interval = list(statdict.keys())[iindex]\n\n        # Print basic stats\n        buffer += [\n            'Mean             SD               MC Error        %s' %\n            interval]\n        buffer += ['-' * len(buffer[-1])]\n\n        indices = range(size)\n        if len(indices) == 1:\n            indices = [None]\n        \n        _format_str = lambda x, i=None, roundto=2: str(np.round(x.ravel()[i].squeeze(), roundto))\n            \n        for index in indices:\n            # Extract statistics and convert to string\n            m = _format_str(statdict['mean'], index, roundto)\n            sd = _format_str(statdict['standard deviation'], index, roundto)\n            mce = _format_str(statdict['mc error'], index, roundto)\n            hpd = str(statdict[interval].reshape(\n                    (2, size))[:,index].squeeze().round(roundto))\n\n            # Build up string buffer of values\n            valstr = m\n            valstr += ' ' * (17 - len(m)) + sd\n            valstr += ' ' * (17 - len(sd)) + mce\n            valstr += ' ' * (len(buffer[-1]) - len(valstr) - len(hpd)) + hpd\n\n            buffer += [valstr]\n\n        buffer += [''] * 2\n\n        # Print quantiles\n        buffer += ['Posterior quantiles:', '']\n\n        buffer += [\n            '2.5             25              50              75             97.5']\n        buffer += [\n            ' |---------------|===============|===============|---------------|']\n\n        for index in indices:\n            quantile_str = ''\n            for i, q in enumerate((2.5, 25, 50, 75, 97.5)):\n                qstr = _format_str(statdict['quantiles'][q], index, roundto)\n                quantile_str += qstr + ' ' * (17 - i - len(qstr))\n            buffer += [quantile_str.strip()]\n\n        buffer += ['']\n\n        print_('\\t' + '\\n\\t'.join(buffer))", "response": "Generates a pretty - printed summary of the node."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef observe(self, obs_mesh, obs_V, output_type='r'):\n\n        # Number of spatial dimensions.\n        ndim = obs_mesh.shape[1]\n\n        if self.ndim is not None:\n            if not ndim == self.ndim:\n                raise ValueError(\n                    \"Dimension of observation mesh is not equal to dimension of base mesh.\")\n        else:\n            self.ndim = ndim\n\n        # print ndim\n\n        # =====================================\n        # = If self hasn't been observed yet: =\n        # =====================================\n        if not self.observed:\n\n            # If self has not been observed, get the Cholesky factor of self(obs_mesh, obs_mesh)\n            # and the side information and store it.\n\n            # Number of observation points so far is 0.\n            N_old = 0\n            N_new = obs_mesh.shape[0]\n\n            if output_type == 's':\n                U, C_eval = self.cholesky(\n                    obs_mesh, nugget=obs_V, observed=False, return_eval_also=True)\n                U_new = U\n            else:\n                U = self.cholesky(obs_mesh, nugget=obs_V, observed=False)\n\n            # Upper-triangular Cholesky factor of self(obs_mesh, obs_mesh)\n            self.full_Uo = U\n            self.Uo = U\n\n            # Pivots.\n            piv_new = arange(N_new)\n            self.full_piv = piv_new\n            self.obs_piv = piv_new\n\n            # Remember full observation mesh.\n            self.full_obs_mesh = obs_mesh\n\n            # relevant slice is the positive-definite indices, which get into\n            # obs_mesh_*. See documentation.\n            relevant_slice = self.obs_piv\n\n            self.obs_mesh = obs_mesh\n            self.obs_V = obs_V\n            self.obs_len = N_new\n\n        # =======================================\n        # = If self has been observed already:  =\n        # =======================================\n        else:\n\n            # If self has been observed, get the Cholesky factor of the _full_ observation mesh (new\n            # and old observations) using continue_cholesky, along with side\n            # information, and store it.\n\n            # Number of observations so far.\n            N_old = self.full_obs_mesh.shape[0]\n\n            # Number of new observations.\n            N_new = obs_mesh.shape[0]\n\n            # Call to self.continue_cholesky.\n            if output_type == 's':\n                U, U_new, C_eval = self.continue_cholesky(x=obs_mesh,\n                                                          x_old=self.full_obs_mesh,\n                                                          U_old=self.full_Uo,\n                                                          observed=False,\n                                                          nugget=obs_V,\n                                                          return_eval_also=True)\n\n            else:\n                U = self.continue_cholesky(x=obs_mesh,\n                                           x_old=self.full_obs_mesh,\n                                           U_old=self.full_Uo,\n                                           observed=False,\n                                           nugget=obs_V)\n\n            # Full Cholesky factor of self(obs_mesh, obs_mesh), where obs_mesh\n            # is the combined observation mesh.\n            self.full_Uo = U\n\n            # Square upper-triangular Cholesky factor of self(obs_mesh_*,\n            # obs_mesh_*). See documentation.\n            self.Uo = self.full_Uo\n\n            # Pivots.\n            piv_new = arange(N_old + N_new)\n            self.obs_piv = piv_new\n            self.full_piv = piv_new\n\n            # Concatenate old and new observation meshes.\n            self.full_obs_mesh = vstack((self.full_obs_mesh, obs_mesh))\n            self.obs_mesh = self.full_obs_mesh\n            self.obs_V = hstack((self.obs_V, obs_V))\n\n            # Length of obs_mesh_*.\n            self.obs_len = N_old + N_new\n\n        self.observed = True\n        # Output expected by Realization\n        if output_type == 'r':\n            return slice(None, None, None), obs_mesh, self.full_Uo[\n                N_old:N_new + N_old, N_old:N_new + N_old], self.full_Uo[:N_old, N_old:N_new + N_old]\n\n        # Ouptut expected by observe\n        if output_type == 'o':\n            return slice(None, None, None), obs_mesh\n\n        # Output expected by the GP submodel\n        if output_type == 's':\n            return U_new, C_eval, self.full_Uo[:N_old, N_old:N_new + N_old]", "response": "Observe self on observation mesh with observation variance obs_V and store the information needed by the realization object."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwraps Metropolis step methods so they can handle extended parents of Gaussian processes.", "response": "def wrap_metropolis_for_gp_parents(metro_class):\n    \"\"\"\n    Wraps Metropolis step methods so they can handle extended parents of\n    Gaussian processes.\n    \"\"\"\n    class wrapper(metro_class):\n        __doc__ = \"\"\"A modified version of class %s that handles parents of Gaussian processes.\nDocstring of class %s: \\n\\n%s\"\"\" % (metro_class.__name__, metro_class.__name__, metro_class.__doc__)\n\n        def __init__(self, stochastic, *args, **kwds):\n\n            self.metro_class.__init__(self, stochastic, *args, **kwds)\n\n            mb = set(self.markov_blanket)\n            for c in list(self.children):\n                if isinstance(c, GaussianProcess):\n                    self.children |= c.extended_children\n                    mb |= c.extended_children\n            self.markov_blanket = list(mb)\n\n            # Remove f from the set that will be used to compute\n            # logp_plus_loglike.\n            self.markov_blanket_no_f = set(\n                filter(\n                    lambda x: not isinstance(\n                        x,\n                        GaussianProcess),\n                    self.markov_blanket))\n            self.fs = filter(\n                lambda x: isinstance(\n                    x,\n                    GaussianProcess),\n                self.markov_blanket)\n            self.fr_checks = [f.submodel.fr_check for f in self.fs]\n\n        def get_logp_plus_loglike(self):\n            return pm.logp_of_set(self.markov_blanket_no_f)\n        logp_plus_loglike = property(get_logp_plus_loglike)\n\n        def propose(self):\n            self.metro_class.propose(self)\n            try:\n                # First make sure none of the stochastics handled by\n                # metro_method forbid their current values.\n                for s in self.stochastics:\n                    s.logp\n                # Then make sure the covariances are all still full-rank on the\n                # observation locations.\n                for frc in self.fr_checks:\n                    frc.logp\n                for f in self.fs:\n                    f.rand()\n                self.f_proposed = True\n            except pm.ZeroProbability:\n                self.f_proposed = False\n\n        def reject(self):\n            self.metro_class.reject(self)\n            if self.f_proposed:\n                for f in self.fs:\n                    f.revert()\n\n        @staticmethod\n        def competence(stochastic, metro_class=metro_class):\n            if any([isinstance(child, GaussianProcess)\n                    for child in stochastic.extended_children]):\n                return metro_class.competence(stochastic) + .01\n            else:\n                return 0\n\n    wrapper.__name__ = 'GPParent%s' % metro_class.__name__\n    wrapper.metro_class = metro_class\n\n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef file_items(container, iterable):\n\n    # container._value = copy(iterable)\n\n    container.nodes = set()\n    container.variables = set()\n    container.deterministics = set()\n    container.stochastics = set()\n    container.potentials = set()\n    container.observed_stochastics = set()\n\n    # containers needs to be a list to hold unhashable items.\n    container.containers = []\n\n    i = -1\n\n    for item in iterable:\n\n        # If this is a dictionary, switch from key to item.\n        if isinstance(iterable, (dict, dict_proxy_type)):\n            key = item\n            item = iterable[key]\n        # Item counter\n        else:\n            i += 1\n\n        # If the item isn't iterable, file it away.\n        if isinstance(item, Variable):\n            container.variables.add(item)\n            if isinstance(item, StochasticBase):\n                if item.observed or not getattr(item, 'mask', None) is None:\n                    container.observed_stochastics.add(item)\n                if not item.observed:\n                    container.stochastics.add(item)\n            elif isinstance(item, DeterministicBase):\n                container.deterministics.add(item)\n        elif isinstance(item, PotentialBase):\n            container.potentials.add(item)\n\n        elif isinstance(item, ContainerBase):\n            container.assimilate(item)\n            container.containers.append(item)\n\n        # Wrap internal containers\n        elif hasattr(item, '__iter__'):\n\n            # If this is a non-object-valued ndarray, don't container-ize it.\n            if isinstance(item, ndarray):\n                if item.dtype != dtype('object'):\n                    continue\n\n            # If the item is iterable, wrap it in a container. Replace the item\n            # with the wrapped version.\n            try:\n                new_container = Container(item)\n            except:\n                continue\n\n            # Update all of container's variables, potentials, etc. with the new wrapped\n            # iterable's. This process recursively unpacks nested iterables.\n            container.assimilate(new_container)\n\n            if isinstance(container, dict):\n                container.replace(key, new_container)\n            elif isinstance(container, tuple):\n                return container[:i] + (new_container,) + container[i + 1:]\n            else:\n                container.replace(item, new_container, i)\n\n    container.nodes = container.potentials | container.variables\n\n    # 'Freeze' markov blanket, moral neighbors, coparents of all constituent stochastics\n    # for future use\n    for attr in ['moral_neighbors', 'markov_blanket', 'coparents']:\n        setattr(container, attr, {})\n    for s in container.stochastics:\n        for attr in ['moral_neighbors', 'markov_blanket', 'coparents']:\n            getattr(container, attr)[s] = getattr(s, attr)", "response": "File items into the appropriate attributes of the container."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef solidityKeccak(cls, abi_types, values):\n        if len(abi_types) != len(values):\n            raise ValueError(\n                \"Length mismatch between provided abi types and values.  Got \"\n                \"{0} types and {1} values.\".format(len(abi_types), len(values))\n            )\n\n        if isinstance(cls, type):\n            w3 = None\n        else:\n            w3 = cls\n        normalized_values = map_abi_data([abi_ens_resolver(w3)], abi_types, values)\n\n        hex_string = add_0x_prefix(''.join(\n            remove_0x_prefix(hex_encode_abi_type(abi_type, value))\n            for abi_type, value\n            in zip(abi_types, normalized_values)\n        ))\n        return cls.keccak(hexstr=hex_string)", "response": "Returns a new instance of the class with keccak256 exactly as Solidity does."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a middleware that adds a gas price to the list of objects that can be used to send the transaction.", "response": "def gas_price_strategy_middleware(make_request, web3):\n    \"\"\"\n    Includes a gas price using the gas price strategy\n    \"\"\"\n    def middleware(method, params):\n        if method == 'eth_sendTransaction':\n            transaction = params[0]\n            if 'gasPrice' not in transaction:\n                generated_gas_price = web3.eth.generateGasPrice(transaction)\n                if generated_gas_price is not None:\n                    transaction = assoc(transaction, 'gasPrice', generated_gas_price)\n                    return make_request(method, [transaction])\n        return make_request(method, params)\n    return middleware"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfill the transaction with default values.", "response": "def fill_transaction_defaults(web3, transaction):\n    \"\"\"\n    if web3 is None, fill as much as possible while offline\n    \"\"\"\n    defaults = {}\n    for key, default_getter in TRANSACTION_DEFAULTS.items():\n        if key not in transaction:\n            if callable(default_getter):\n                if web3 is not None:\n                    default_val = default_getter(web3, transaction)\n                else:\n                    raise ValueError(\"You must specify %s in the transaction\" % key)\n            else:\n                default_val = default_getter\n            defaults[key] = default_val\n    return merge(defaults, transaction)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncomputes the probabilities that a txn will be accepted at each of the gas prices accepted by the miners.", "response": "def _compute_probabilities(miner_data, wait_blocks, sample_size):\n    \"\"\"\n    Computes the probabilities that a txn will be accepted at each of the gas\n    prices accepted by the miners.\n    \"\"\"\n    miner_data_by_price = tuple(sorted(\n        miner_data,\n        key=operator.attrgetter('low_percentile_gas_price'),\n        reverse=True,\n    ))\n    for idx in range(len(miner_data_by_price)):\n        low_percentile_gas_price = miner_data_by_price[idx].low_percentile_gas_price\n        num_blocks_accepting_price = sum(m.num_blocks for m in miner_data_by_price[idx:])\n        inv_prob_per_block = (sample_size - num_blocks_accepting_price) / sample_size\n        probability_accepted = 1 - inv_prob_per_block ** wait_blocks\n        yield Probability(low_percentile_gas_price, probability_accepted)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompute the gas price of a code block based on the given probability.", "response": "def _compute_gas_price(probabilities, desired_probability):\n    \"\"\"\n    Given a sorted range of ``Probability`` named-tuples returns a gas price\n    computed based on where the ``desired_probability`` would fall within the\n    range.\n\n    :param probabilities: An iterable of `Probability` named-tuples sorted in reverse order.\n    :param desired_probability: An floating point representation of the desired\n        probability. (e.g. ``85% -> 0.85``)\n    \"\"\"\n    first = probabilities[0]\n    last = probabilities[-1]\n\n    if desired_probability >= first.prob:\n        return int(first.gas_price)\n    elif desired_probability <= last.prob:\n        return int(last.gas_price)\n\n    for left, right in sliding_window(2, probabilities):\n        if desired_probability < right.prob:\n            continue\n        elif desired_probability > left.prob:\n            # This code block should never be reachable as it would indicate\n            # that we already passed by the probability window in which our\n            # `desired_probability` is located.\n            raise Exception('Invariant')\n\n        adj_prob = desired_probability - right.prob\n        window_size = left.prob - right.prob\n        position = adj_prob / window_size\n        gas_window_size = left.gas_price - right.gas_price\n        gas_price = int(math.ceil(right.gas_price + gas_window_size * position))\n        return gas_price\n    else:\n        # The initial `if/else` clause in this function handles the case where\n        # the `desired_probability` is either above or below the min/max\n        # probability found in the `probabilities`.\n        #\n        # With these two cases handled, the only way this code block should be\n        # reachable would be if the `probabilities` were not sorted correctly.\n        # Otherwise, the `desired_probability` **must** fall between two of the\n        # values in the `probabilities``.\n        raise Exception('Invariant')"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconstructs a gas pricing strategy that uses recently mined block data to derive a gas price for which a transaction is likely to be mined within X seconds.", "response": "def construct_time_based_gas_price_strategy(max_wait_seconds,\n                                            sample_size=120,\n                                            probability=98):\n    \"\"\"\n    A gas pricing strategy that uses recently mined block data to derive a gas\n    price for which a transaction is likely to be mined within X seconds with\n    probability P.\n\n    :param max_wait_seconds: The desired maxiumum number of seconds the\n        transaction should take to mine.\n    :param sample_size: The number of recent blocks to sample\n    :param probability: An integer representation of the desired probability\n        that the transaction will be mined within ``max_wait_seconds``.  0 means 0%\n        and 100 means 100%.\n    \"\"\"\n    def time_based_gas_price_strategy(web3, transaction_params):\n        avg_block_time = _get_avg_block_time(web3, sample_size=sample_size)\n        wait_blocks = int(math.ceil(max_wait_seconds / avg_block_time))\n\n        raw_miner_data = _get_raw_miner_data(web3, sample_size=sample_size)\n        miner_data = _aggregate_miner_data(raw_miner_data)\n\n        probabilities = _compute_probabilities(\n            miner_data,\n            wait_blocks=wait_blocks,\n            sample_size=sample_size,\n        )\n\n        gas_price = _compute_gas_price(probabilities, probability / 100)\n        return gas_price\n    return time_based_gas_price_strategy"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a middleware that checks that the latest block in the blockchain is older than the allowable_delay seconds.", "response": "def make_stalecheck_middleware(\n        allowable_delay,\n        skip_stalecheck_for_methods=SKIP_STALECHECK_FOR_METHODS):\n    \"\"\"\n    Use to require that a function will run only of the blockchain is recently updated.\n\n    This middleware takes an argument, so unlike other middleware, you must make the middleware\n    with a method call.\n    For example: `make_stalecheck_middleware(60*5)`\n\n    If the latest block in the chain is older than 5 minutes in this example, then the\n    middleware will raise a StaleBlockchain exception.\n    \"\"\"\n    if allowable_delay <= 0:\n        raise ValueError(\"You must set a positive allowable_delay in seconds for this middleware\")\n\n    def stalecheck_middleware(make_request, web3):\n        cache = {'latest': None}\n\n        def middleware(method, params):\n            if method not in skip_stalecheck_for_methods:\n                if _isfresh(cache['latest'], allowable_delay):\n                    pass\n                else:\n                    latest = web3.eth.getBlock('latest')\n                    if _isfresh(latest, allowable_delay):\n                        cache['latest'] = latest\n                    else:\n                        raise StaleBlockchain(latest, allowable_delay)\n\n            return make_request(method, params)\n        return middleware\n    return stalecheck_middleware"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef default_middlewares(web3):\n        return [\n            (request_parameter_normalizer, 'request_param_normalizer'),\n            (gas_price_strategy_middleware, 'gas_price_strategy'),\n            (name_to_address_middleware(web3), 'name_to_address'),\n            (attrdict_middleware, 'attrdict'),\n            (pythonic_middleware, 'pythonic'),\n            (normalize_errors_middleware, 'normalize_errors'),\n            (validation_middleware, 'validation'),\n            (abi_middleware, 'abi'),\n        ]", "response": "Return a list of default middlewares for the request manager."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef request_blocking(self, method, params):\n        response = self._make_request(method, params)\n\n        if \"error\" in response:\n            raise ValueError(response[\"error\"])\n\n        return response['result']", "response": "Make a synchronous request using the provider s request method and params."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def coro_request(self, method, params):\n        response = await self._coro_make_request(method, params)\n\n        if \"error\" in response:\n            raise ValueError(response[\"error\"])\n\n        if response['result'] is None:\n            raise ValueError(f\"The call to {method} did not return a value.\")\n\n        return response['result']", "response": "Coroutine for making a request using the provider"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconstructs a middleware which returns a static response for any method which is found in the provided fixtures.", "response": "def construct_fixture_middleware(fixtures):\n    \"\"\"\n    Constructs a middleware which returns a static response for any method\n    which is found in the provided fixtures.\n    \"\"\"\n    def fixture_middleware(make_request, web3):\n        def middleware(method, params):\n            if method in fixtures:\n                result = fixtures[method]\n                return {'result': result}\n            else:\n                return make_request(method, params)\n        return middleware\n    return fixture_middleware"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconstructing a middleware which intercepts requests for any method found in the provided mapping of endpoints to generator functions returning Insights which is the result of the generator function.", "response": "def construct_result_generator_middleware(result_generators):\n    \"\"\"\n    Constructs a middleware which intercepts requests for any method found in\n    the provided mapping of endpoints to generator functions, returning\n    whatever response the generator function returns.  Callbacks must be\n    functions with the signature `fn(method, params)`.\n    \"\"\"\n    def result_generator_middleware(make_request, web3):\n        def middleware(method, params):\n            if method in result_generators:\n                result = result_generators[method](method, params)\n                return {'result': result}\n            else:\n                return make_request(method, params)\n        return middleware\n    return result_generator_middleware"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef construct_error_generator_middleware(error_generators):\n    def error_generator_middleware(make_request, web3):\n        def middleware(method, params):\n            if method in error_generators:\n                error_msg = error_generators[method](method, params)\n                return {'error': error_msg}\n            else:\n                return make_request(method, params)\n        return middleware\n    return error_generator_middleware", "response": "Constructs a middleware which intercepts requests for any method found in\n    and returns whatever error message the generator function returns."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef combine_middlewares(middlewares, web3, provider_request_fn):\n    return functools.reduce(\n        lambda request_fn, middleware: middleware(request_fn, web3),\n        reversed(middlewares),\n        provider_request_fn,\n    )", "response": "Returns a callable function which will call the provider. provider_request_fn function wrapped with all of the middlewares."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngiving an event ABI and a log entry return the decoded event data.", "response": "def get_event_data(event_abi, log_entry):\n    \"\"\"\n    Given an event ABI and a log entry for that event, return the decoded\n    event data\n    \"\"\"\n    if event_abi['anonymous']:\n        log_topics = log_entry['topics']\n    elif not log_entry['topics']:\n        raise MismatchedABI(\"Expected non-anonymous event to have 1 or more topics\")\n    elif event_abi_to_log_topic(event_abi) != log_entry['topics'][0]:\n        raise MismatchedABI(\"The event signature did not match the provided ABI\")\n    else:\n        log_topics = log_entry['topics'][1:]\n\n    log_topics_abi = get_indexed_event_inputs(event_abi)\n    log_topic_normalized_inputs = normalize_event_input_types(log_topics_abi)\n    log_topic_types = get_event_abi_types_for_decoding(log_topic_normalized_inputs)\n    log_topic_names = get_abi_input_names({'inputs': log_topics_abi})\n\n    if len(log_topics) != len(log_topic_types):\n        raise ValueError(\"Expected {0} log topics.  Got {1}\".format(\n            len(log_topic_types),\n            len(log_topics),\n        ))\n\n    log_data = hexstr_if_str(to_bytes, log_entry['data'])\n    log_data_abi = exclude_indexed_event_inputs(event_abi)\n    log_data_normalized_inputs = normalize_event_input_types(log_data_abi)\n    log_data_types = get_event_abi_types_for_decoding(log_data_normalized_inputs)\n    log_data_names = get_abi_input_names({'inputs': log_data_abi})\n\n    # sanity check that there are not name intersections between the topic\n    # names and the data argument names.\n    duplicate_names = set(log_topic_names).intersection(log_data_names)\n    if duplicate_names:\n        raise ValueError(\n            \"Invalid Event ABI:  The following argument names are duplicated \"\n            \"between event inputs: '{0}'\".format(', '.join(duplicate_names))\n        )\n\n    decoded_log_data = decode_abi(log_data_types, log_data)\n    normalized_log_data = map_abi_data(\n        BASE_RETURN_NORMALIZERS,\n        log_data_types,\n        decoded_log_data\n    )\n\n    decoded_topic_data = [\n        decode_single(topic_type, topic_data)\n        for topic_type, topic_data\n        in zip(log_topic_types, log_topics)\n    ]\n    normalized_topic_data = map_abi_data(\n        BASE_RETURN_NORMALIZERS,\n        log_topic_types,\n        decoded_topic_data\n    )\n\n    event_args = dict(itertools.chain(\n        zip(log_topic_names, normalized_topic_data),\n        zip(log_data_names, normalized_log_data),\n    ))\n\n    event_data = {\n        'args': event_args,\n        'event': event_abi['name'],\n        'logIndex': log_entry['logIndex'],\n        'transactionIndex': log_entry['transactionIndex'],\n        'transactionHash': log_entry['transactionHash'],\n        'address': log_entry['address'],\n        'blockHash': log_entry['blockHash'],\n        'blockNumber': log_entry['blockNumber'],\n    }\n\n    return AttributeDict.recursive(event_data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef exception_retry_middleware(make_request, web3, errors, retries=5):\n    def middleware(method, params):\n        if check_if_retry_on_failure(method):\n            for i in range(retries):\n                try:\n                    return make_request(method, params)\n                except errors:\n                    if i < retries - 1:\n                        continue\n                    else:\n                        raise\n        else:\n            return make_request(method, params)\n    return middleware", "response": "Creates middleware that retries failed HTTP requests."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef iso13616Prepare(iban):\n    A = ord(\"A\")\n    Z = ord(\"Z\")\n\n    iban = iban.upper()\n    iban = iban[4:] + iban[:4]\n\n    def charfunc(n):\n        code = ord(n)\n        if code >= A and code <= Z:\n            return str(code - A + 10)\n        else:\n            return str(n)\n\n    return \"\".join(map(charfunc, list(iban)))", "response": "This method is used to prepare an IBAN for mod 97 computation."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalculating the MOD 97 10 of the passed IBAN as specified in ISO7064.", "response": "def mod9710(iban):\n    \"\"\"\n    Calculates the MOD 97 10 of the passed IBAN as specified in ISO7064.\n\n    @method mod9710\n    @param {String} iban\n    @returns {Number}\n    \"\"\"\n    remainder = iban\n    block = None\n\n    while len(remainder) > 2:\n        block = remainder[:9]\n        remainder = str(int(block) % 97) + remainder[len(block):]\n\n    return int(remainder) % 97"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef baseN(num, b, numerals=\"0123456789abcdefghijklmnopqrstuvwxyz\"):\n    return ((num == 0) and numerals[0]) or \\\n        (baseN(num // b, b, numerals).lstrip(numerals[0]) + numerals[num % b])", "response": "Returns a base N string"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fromBban(bban):\n        countryCode = \"XE\"\n\n        remainder = mod9710(iso13616Prepare(countryCode + \"00\" + bban))\n        checkDigit = (\"0\" + str(98 - remainder))[-2:]\n\n        return Iban(countryCode + checkDigit + bban)", "response": "Convert the passed BBAN to an IBAN object."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the client direct address of the user s iban.", "response": "def address(self):\n        \"\"\"\n        Should be called to get client direct address\n\n        @method address\n        @returns {String} client direct address\n        \"\"\"\n        if self.isDirect():\n            base36 = self._iban[4:]\n            asInt = int(base36, 36)\n            return to_checksum_address(pad_left_hex(baseN(asInt, 16), 20))\n\n        return \"\""}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef block_ranges(start_block, last_block, step=5):\n\n    if last_block is not None and start_block > last_block:\n        raise TypeError(\n            \"Incompatible start and stop arguments.\",\n            \"Start must be less than or equal to stop.\")\n\n    return (\n        (from_block, to_block - 1)\n        for from_block, to_block\n        in segment_count(start_block, last_block + 1, step)\n    )", "response": "Returns 2 - tuple ranges describing ranges of block from start_block to last_block."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_logs_multipart(\n        w3,\n        startBlock,\n        stopBlock,\n        address,\n        topics,\n        max_blocks):\n    \"\"\"Used to break up requests to ``eth_getLogs``\n\n    The getLog request is partitioned into multiple calls of the max number of blocks\n    ``max_blocks``.\n    \"\"\"\n    _block_ranges = block_ranges(startBlock, stopBlock, max_blocks)\n    for from_block, to_block in _block_ranges:\n        params = {\n            'fromBlock': from_block,\n            'toBlock': to_block,\n            'address': address,\n            'topics': topics\n        }\n        yield w3.eth.getLogs(\n            drop_items_with_none_value(params))", "response": "This is a generator function that yields the logs from the network."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef method_selector_fn(self):\n        if callable(self.json_rpc_method):\n            return self.json_rpc_method\n        elif isinstance(self.json_rpc_method, (str,)):\n            return lambda *_: self.json_rpc_method\n        raise ValueError(\"``json_rpc_method`` config invalid.  May be a string or function\")", "response": "Gets the method selector from the config."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates a cache key for the given value.", "response": "def generate_cache_key(value):\n    \"\"\"\n    Generates a cache key for the *args and **kwargs\n    \"\"\"\n    if is_bytes(value):\n        return hashlib.md5(value).hexdigest()\n    elif is_text(value):\n        return generate_cache_key(to_bytes(text=value))\n    elif is_boolean(value) or is_null(value) or is_number(value):\n        return generate_cache_key(repr(value))\n    elif is_dict(value):\n        return generate_cache_key((\n            (key, value[key])\n            for key\n            in sorted(value.keys())\n        ))\n    elif is_list_like(value) or isinstance(value, collections.abc.Generator):\n        return generate_cache_key(\"\".join((\n            generate_cache_key(item)\n            for item\n            in value\n        )))\n    else:\n        raise TypeError(\"Cannot generate cache key for value {0} of type {1}\".format(\n            value,\n            type(value),\n        ))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef hex_encode_abi_type(abi_type, value, force_size=None):\n    validate_abi_type(abi_type)\n    validate_abi_value(abi_type, value)\n\n    data_size = force_size or size_of_type(abi_type)\n    if is_array_type(abi_type):\n        sub_type = sub_type_of_array_type(abi_type)\n        return \"\".join([remove_0x_prefix(hex_encode_abi_type(sub_type, v, 256)) for v in value])\n    elif is_bool_type(abi_type):\n        return to_hex_with_size(value, data_size)\n    elif is_uint_type(abi_type):\n        return to_hex_with_size(value, data_size)\n    elif is_int_type(abi_type):\n        return to_hex_twos_compliment(value, data_size)\n    elif is_address_type(abi_type):\n        return pad_hex(value, data_size)\n    elif is_bytes_type(abi_type):\n        if is_bytes(value):\n            return encode_hex(value)\n        else:\n            return value\n    elif is_string_type(abi_type):\n        return to_hex(text=value)\n    else:\n        raise ValueError(\n            \"Unsupported ABI type: {0}\".format(abi_type)\n        )", "response": "Encodes value into a hex string in format of abi_type"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert integer value to twos compliment hex representation with given bit_size", "response": "def to_hex_twos_compliment(value, bit_size):\n    \"\"\"\n    Converts integer value to twos compliment hex representation with given bit_size\n    \"\"\"\n    if value >= 0:\n        return to_hex_with_size(value, bit_size)\n\n    value = (1 << bit_size) + value\n    hex_value = hex(value)\n    hex_value = hex_value.rstrip(\"L\")\n    return hex_value"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npadding a hex string up to the given bit_size.", "response": "def pad_hex(value, bit_size):\n    \"\"\"\n    Pads a hex string up to the given bit_size\n    \"\"\"\n    value = remove_0x_prefix(value)\n    return add_0x_prefix(value.zfill(int(bit_size / 4)))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_int(value=None, hexstr=None, text=None):\n    assert_one_val(value, hexstr=hexstr, text=text)\n\n    if hexstr is not None:\n        return int(hexstr, 16)\n    elif text is not None:\n        return int(text)\n    elif isinstance(value, bytes):\n        return big_endian_to_int(value)\n    elif isinstance(value, str):\n        raise TypeError(\"Pass in strings with keyword hexstr or text\")\n    else:\n        return int(value)", "response": "Converts value to integer representation."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert a string to a type assuming that it can be only unicode text", "response": "def text_if_str(to_type, text_or_primitive):\n    \"\"\"\n    Convert to a type, assuming that strings can be only unicode text (not a hexstr)\n\n    @param to_type is a function that takes the arguments (primitive, hexstr=hexstr, text=text),\n        eg~ to_bytes, to_text, to_hex, to_int, etc\n    @param hexstr_or_primitive in bytes, str, or int.\n    \"\"\"\n    if isinstance(text_or_primitive, str):\n        (primitive, text) = (None, text_or_primitive)\n    else:\n        (primitive, text) = (text_or_primitive, None)\n    return to_type(primitive, text=text)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef hexstr_if_str(to_type, hexstr_or_primitive):\n    if isinstance(hexstr_or_primitive, str):\n        (primitive, hexstr) = (None, hexstr_or_primitive)\n        if remove_0x_prefix(hexstr) and not is_hex(hexstr):\n            raise ValueError(\n                \"when sending a str, it must be a hex string. Got: {0!r}\".format(\n                    hexstr_or_primitive,\n                )\n            )\n    else:\n        (primitive, hexstr) = (hexstr_or_primitive, None)\n    return to_type(primitive, hexstr=hexstr)", "response": "Convert to a type assuming that the input is a hex string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef deploy_new_instance(cls, w3: Web3) -> \"VyperReferenceRegistry\":\n        manifest = get_vyper_registry_manifest()\n        registry_package = Package(manifest, w3)\n        registry_factory = registry_package.get_contract_factory(\"registry\")\n        tx_hash = registry_factory.constructor().transact()\n        tx_receipt = w3.eth.waitForTransactionReceipt(tx_hash)\n        registry_address = to_canonical_address(tx_receipt.contractAddress)\n        return cls(registry_address, w3)", "response": "Returns a new VyperReferenceRegistry instance representing a freshly deployed version of the Vyper Reference Registry implementation on the given web3 instance."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntransferring ownership of this registry instance to the given new owner.", "response": "def transfer_owner(self, new_owner: Address) -> TxReceipt:\n        \"\"\"\n        Transfers ownership of this registry instance to the given ``new_owner``. Only the\n        ``owner`` is allowed to transfer ownership.\n\n        * Parameters:\n            * ``new_owner``: The address of the new owner.\n        \"\"\"\n        tx_hash = self.registry.functions.transferOwner(new_owner).transact()\n        return self.w3.eth.waitForTransactionReceipt(tx_hash)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_package_from_uri(self, manifest_uri: URI) -> Package:\n        return Package.from_uri(manifest_uri, self.web3)", "response": "Returns a Package instance built with the manifest at the given URI."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_registry(self, address: Address) -> None:\n        if is_canonical_address(address) or is_checksum_address(address):\n            canonical_address = to_canonical_address(address)\n            self.registry = VyperReferenceRegistry(canonical_address, self.web3)\n        elif is_ens_name(address):\n            self._validate_set_ens()\n            addr_lookup = self.web3.ens.address(address)\n            if not addr_lookup:\n                raise NameNotFound(\n                    \"No address found after ENS lookup for name: {0}.\".format(address)\n                )\n            self.registry = VyperReferenceRegistry(\n                to_canonical_address(addr_lookup), self.web3\n            )\n        else:\n            raise PMError(\n                \"Expected a canonical/checksummed address or ENS name for the address, \"\n                \"instead received {0}.\".format(type(address))\n            )", "response": "Sets the current Vyper Reference Registry for the given address."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndeploying and set the current VyperReferenceRegistry instance.", "response": "def deploy_and_set_registry(self) -> Address:\n        \"\"\"\n        Returns the address of a freshly deployed instance of the `vyper registry\n        <https://github.com/ethpm/py-ethpm/blob/master/ethpm/assets/vyper_registry/registry.vy>`__,\n        and sets the newly deployed registry as the active registry on ``web3.pm.registry``.\n\n        To tie your registry to an ENS name, use web3's ENS module, ie.\n\n        .. code-block:: python\n\n           w3.ens.setup_address(ens_name, w3.pm.registry.address)\n        \"\"\"\n        self.registry = VyperReferenceRegistry.deploy_new_instance(self.web3)\n        return to_checksum_address(self.registry.address)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef release_package(\n        self, package_name: str, version: str, manifest_uri: str\n    ) -> bytes:\n        \"\"\"\n        Returns the release id generated by releasing a package on the current registry.\n        Requires ``web3.PM`` to have a registry set. Requires ``web3.eth.defaultAccount``\n        to be the registry owner.\n\n        * Parameters:\n            * ``package_name``: Must be a valid package name, matching the given manifest.\n            * ``version``: Must be a valid package version, matching the given manifest.\n            * ``manifest_uri``: Must be a valid content-addressed URI. Currently, only IPFS\n              and Github content-addressed URIs are supported.\n\n        \"\"\"\n        validate_is_supported_manifest_uri(manifest_uri)\n        raw_manifest = to_text(resolve_uri_contents(manifest_uri))\n        validate_raw_manifest_format(raw_manifest)\n        manifest = json.loads(raw_manifest)\n        validate_manifest_against_schema(manifest)\n        if package_name != manifest['package_name']:\n            raise ManifestValidationError(\n                f\"Provided package name: {package_name} does not match the package name \"\n                f\"found in the manifest: {manifest['package_name']}.\"\n            )\n\n        if version != manifest['version']:\n            raise ManifestValidationError(\n                f\"Provided package version: {version} does not match the package version \"\n                f\"found in the manifest: {manifest['version']}.\"\n            )\n\n        self._validate_set_registry()\n        return self.registry._release(package_name, version, manifest_uri)", "response": "Returns the release id for the given package on the current registry."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_all_package_names(self) -> Iterable[str]:\n        self._validate_set_registry()\n        package_ids = self.registry._get_all_package_ids()\n        for package_id in package_ids:\n            yield self.registry._get_package_name(package_id)", "response": "Returns an iterable containing all the package names available on the current registry."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the number of releases of the given package name available on the current registry.", "response": "def get_release_count(self, package_name: str) -> int:\n        \"\"\"\n        Returns the number of releases of the given package name available on the current registry.\n        \"\"\"\n        validate_package_name(package_name)\n        self._validate_set_registry()\n        return self.registry._num_release_ids(package_name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_release_id(self, package_name: str, version: str) -> bytes:\n        validate_package_name(package_name)\n        validate_package_version(version)\n        self._validate_set_registry()\n        return self.registry._get_release_id(package_name, version)", "response": "Returns the 32 byte identifier of a release for the given package name and version."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_all_package_releases(self, package_name: str) -> Iterable[Tuple[str, str]]:\n        validate_package_name(package_name)\n        self._validate_set_registry()\n        release_ids = self.registry._get_all_release_ids(package_name)\n        for release_id in release_ids:\n            _, version, manifest_uri = self.registry._get_release_data(release_id)\n            yield (version, manifest_uri)", "response": "Returns an iterable of tuple of version manifest_ur for every release of the given package name."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_release_id_data(self, release_id: bytes) -> Tuple[str, str, str]:\n        self._validate_set_registry()\n        return self.registry._get_release_data(release_id)", "response": "Returns the package name version manifest uri associated with the given release id."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_release_data(self, package_name: str, version: str) -> Tuple[str, str, str]:\n        validate_package_name(package_name)\n        validate_package_version(version)\n        self._validate_set_registry()\n        release_id = self.registry._get_release_id(package_name, version)\n        return self.get_release_id_data(release_id)", "response": "Returns the manifest_uri and manifest_uri associated with the given package name and version."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_package(self, package_name: str, version: str) -> Package:\n        validate_package_name(package_name)\n        validate_package_version(version)\n        self._validate_set_registry()\n        _, _, release_uri = self.get_release_data(package_name, version)\n        return self.get_package_from_uri(release_uri)", "response": "Returns a Package instance associated with the given package name and version."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef normalize_data_values(type_string, data_value):\n    _type = parse_type_string(type_string)\n    if _type.base == \"string\":\n        if _type.arrlist is not None:\n            return tuple((normalize_to_text(value) for value in data_value))\n        else:\n            return normalize_to_text(data_value)\n    return data_value", "response": "Decodes utf - 8 bytes to strings for abi string values."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef match_fn(match_values_and_abi, data):\n    abi_types, all_match_values = zip(*match_values_and_abi)\n    decoded_values = decode_abi(abi_types, HexBytes(data))\n    for data_value, match_values, abi_type in zip(decoded_values, all_match_values, abi_types):\n        if match_values is None:\n            continue\n        normalized_data = normalize_data_values(abi_type, data_value)\n        for value in match_values:\n            if not is_encodable(abi_type, value):\n                raise ValueError(\n                    \"Value {0} is of the wrong abi type. \"\n                    \"Expected {1} typed value.\".format(value, abi_type))\n            if value == normalized_data:\n                break\n        else:\n            return False\n\n    return True", "response": "Match function used for filtering non - indexed event arguments."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the data filters for the current object", "response": "def set_data_filters(self, data_filter_set):\n        \"\"\"Sets the data filters (non indexed argument filters)\n\n        Expects a set of tuples with the type and value, e.g.:\n        (('uint256', [12345, 54321]), ('string', ('a-single-string',)))\n        \"\"\"\n        self.data_filter_set = data_filter_set\n        if any(data_filter_set):\n            self.data_filter_set_function = match_fn(data_filter_set)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef attrdict_middleware(make_request, web3):\n    def middleware(method, params):\n        response = make_request(method, params)\n\n        if 'result' in response:\n            result = response['result']\n            if is_dict(result) and not isinstance(result, AttributeDict):\n                return assoc(response, 'result', AttributeDict.recursive(result))\n            else:\n                return response\n        else:\n            return response\n    return middleware", "response": "Returns a middleware that converts any result which is a dictionary into an a\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fromWeb3(cls, web3, addr=None):\n        return cls(web3.manager.provider, addr=addr)", "response": "Generate an ENS instance with web3"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef name(self, address):\n        reversed_domain = address_to_reverse_domain(address)\n        return self.resolve(reversed_domain, get='name')", "response": "Look up the name that the address points to."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef setup_address(self, name, address=default, transact={}):\n        owner = self.setup_owner(name, transact=transact)\n        self._assert_control(owner, name)\n        if is_none_or_zero_address(address):\n            address = None\n        elif address is default:\n            address = owner\n        elif is_binary_address(address):\n            address = to_checksum_address(address)\n        elif not is_checksum_address(address):\n            raise ValueError(\"You must supply the address in checksum format\")\n        if self.address(name) == address:\n            return None\n        if address is None:\n            address = EMPTY_ADDR_HEX\n        transact['from'] = owner\n        resolver = self._set_resolver(name, transact=transact)\n        return resolver.functions.setAddr(raw_name_to_hash(name), address).transact(transact)", "response": "Set up the name to point to the supplied address."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef setup_name(self, name, address=None, transact={}):\n        if not name:\n            self._assert_control(address, 'the reverse record')\n            return self._setup_reverse(None, address, transact=transact)\n        else:\n            resolved = self.address(name)\n            if is_none_or_zero_address(address):\n                address = resolved\n            elif resolved and address != resolved and resolved != EMPTY_ADDR_HEX:\n                raise AddressMismatch(\n                    \"Could not set address %r to point to name, because the name resolves to %r. \"\n                    \"To change the name for an existing address, call setup_address() first.\" % (\n                        address, resolved\n                    )\n                )\n            if is_none_or_zero_address(address):\n                address = self.owner(name)\n            if is_none_or_zero_address(address):\n                raise UnownedName(\"claim subdomain using setup_address() first\")\n            if is_binary_address(address):\n                address = to_checksum_address(address)\n            if not is_checksum_address(address):\n                raise ValueError(\"You must supply the address in checksum format\")\n            self._assert_control(address, name)\n            if not resolved:\n                self.setup_address(name, address, transact=transact)\n            return self._setup_reverse(name, address, transact=transact)", "response": "Set up the name for reverse lookup."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the owner of a name.", "response": "def owner(self, name):\n        \"\"\"\n        Get the owner of a name. Note that this may be different from the\n        deed holder in the '.eth' registrar. Learn more about the difference\n        between deed and name ownership in the ENS `Managing Ownership docs\n        <http://docs.ens.domains/en/latest/userguide.html#managing-ownership>`_\n\n        :param str name: ENS name to look up\n        :return: owner address\n        :rtype: str\n        \"\"\"\n        node = raw_name_to_hash(name)\n        return self.ens.caller.owner(node)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets up the owner of the supplied name.", "response": "def setup_owner(self, name, new_owner=default, transact={}):\n        \"\"\"\n        Set the owner of the supplied name to `new_owner`.\n\n        For typical scenarios, you'll never need to call this method directly,\n        simply call :meth:`setup_name` or :meth:`setup_address`. This method does *not*\n        set up the name to point to an address.\n\n        If `new_owner` is not supplied, then this will assume you\n        want the same owner as the parent domain.\n\n        If the caller owns ``parentname.eth`` with no subdomains\n        and calls this method with ``sub.parentname.eth``,\n        then ``sub`` will be created as part of this call.\n\n        :param str name: ENS name to set up\n        :param new_owner: account that will own `name`. If ``None``, set owner to empty addr.\n            If not specified, name will point to the parent domain owner's address.\n        :param dict transact: the transaction configuration, like in\n            :meth:`~web3.eth.Eth.sendTransaction`\n        :raises InvalidName: if `name` has invalid syntax\n        :raises UnauthorizedError: if ``'from'`` in `transact` does not own `name`\n        :returns: the new owner's address\n        \"\"\"\n        (super_owner, unowned, owned) = self._first_owner(name)\n        if new_owner is default:\n            new_owner = super_owner\n        elif not new_owner:\n            new_owner = EMPTY_ADDR_HEX\n        else:\n            new_owner = to_checksum_address(new_owner)\n        current_owner = self.owner(name)\n        if new_owner == EMPTY_ADDR_HEX and not current_owner:\n            return None\n        elif current_owner == new_owner:\n            return current_owner\n        else:\n            self._assert_control(super_owner, name, owned)\n            self._claim_ownership(new_owner, unowned, owned, super_owner, transact=transact)\n            return new_owner"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _first_owner(self, name):\n        owner = None\n        unowned = []\n        pieces = normalize_name(name).split('.')\n        while pieces and is_none_or_zero_address(owner):\n            name = '.'.join(pieces)\n            owner = self.owner(name)\n            if is_none_or_zero_address(owner):\n                unowned.append(pieces.pop(0))\n        return (owner, unowned, name)", "response": "Takes a name and returns the owner of the deepest subdomain that has an owner\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef call_contract_function(\n        web3,\n        address,\n        normalizers,\n        function_identifier,\n        transaction,\n        block_id=None,\n        contract_abi=None,\n        fn_abi=None,\n        *args,\n        **kwargs):\n    \"\"\"\n    Helper function for interacting with a contract function using the\n    `eth_call` API.\n    \"\"\"\n    call_transaction = prepare_transaction(\n        address,\n        web3,\n        fn_identifier=function_identifier,\n        contract_abi=contract_abi,\n        fn_abi=fn_abi,\n        transaction=transaction,\n        fn_args=args,\n        fn_kwargs=kwargs,\n    )\n\n    if block_id is None:\n        return_data = web3.eth.call(call_transaction)\n    else:\n        return_data = web3.eth.call(call_transaction, block_identifier=block_id)\n\n    if fn_abi is None:\n        fn_abi = find_matching_fn_abi(contract_abi, function_identifier, args, kwargs)\n\n    output_types = get_abi_output_types(fn_abi)\n\n    try:\n        output_data = decode_abi(output_types, return_data)\n    except DecodingError as e:\n        # Provide a more helpful error message than the one provided by\n        # eth-abi-utils\n        is_missing_code_error = (\n            return_data in ACCEPTABLE_EMPTY_STRINGS and\n            web3.eth.getCode(address) in ACCEPTABLE_EMPTY_STRINGS\n        )\n        if is_missing_code_error:\n            msg = (\n                \"Could not transact with/call contract function, is contract \"\n                \"deployed correctly and chain synced?\"\n            )\n        else:\n            msg = (\n                \"Could not decode contract function call {} return data {} for \"\n                \"output_types {}\".format(\n                    function_identifier,\n                    return_data,\n                    output_types\n                )\n            )\n        raise BadFunctionCallOutput(msg) from e\n\n    _normalizers = itertools.chain(\n        BASE_RETURN_NORMALIZERS,\n        normalizers,\n    )\n    normalized_data = map_abi_data(_normalizers, output_types, output_data)\n\n    if len(normalized_data) == 1:\n        return normalized_data[0]\n    else:\n        return normalized_data", "response": "This function interacts with a contract function using the eth_call API."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef estimate_gas_for_function(\n        address,\n        web3,\n        fn_identifier=None,\n        transaction=None,\n        contract_abi=None,\n        fn_abi=None,\n        *args,\n        **kwargs):\n    \"\"\"Estimates gas cost a function call would take.\n\n    Don't call this directly, instead use :meth:`Contract.estimateGas`\n    on your contract instance.\n    \"\"\"\n    estimate_transaction = prepare_transaction(\n        address,\n        web3,\n        fn_identifier=fn_identifier,\n        contract_abi=contract_abi,\n        fn_abi=fn_abi,\n        transaction=transaction,\n        fn_args=args,\n        fn_kwargs=kwargs,\n    )\n\n    gas_estimate = web3.eth.estimateGas(estimate_transaction)\n    return gas_estimate", "response": "Estimate gas cost a function call would take."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef build_transaction_for_function(\n        address,\n        web3,\n        function_name=None,\n        transaction=None,\n        contract_abi=None,\n        fn_abi=None,\n        *args,\n        **kwargs):\n    \"\"\"Builds a dictionary with the fields required to make the given transaction\n\n    Don't call this directly, instead use :meth:`Contract.buildTransaction`\n    on your contract instance.\n    \"\"\"\n    prepared_transaction = prepare_transaction(\n        address,\n        web3,\n        fn_identifier=function_name,\n        contract_abi=contract_abi,\n        fn_abi=fn_abi,\n        transaction=transaction,\n        fn_args=args,\n        fn_kwargs=kwargs,\n    )\n\n    prepared_transaction = fill_transaction_defaults(web3, prepared_transaction)\n\n    return prepared_transaction", "response": "Builds a dictionary with the fields required to make the given transaction"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a ContractConstructor object that can be used to create a new instance of the class.", "response": "def constructor(cls, *args, **kwargs):\n        \"\"\"\n        :param args: The contract constructor arguments as positional arguments\n        :param kwargs: The contract constructor arguments as keyword arguments\n        :return: a contract constructor object\n        \"\"\"\n        if cls.bytecode is None:\n            raise ValueError(\n                \"Cannot call constructor on a contract that does not have 'bytecode' associated \"\n                \"with it\"\n            )\n\n        return ContractConstructor(cls.web3,\n                                   cls.abi,\n                                   cls.bytecode,\n                                   *args,\n                                   **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef encodeABI(cls, fn_name, args=None, kwargs=None, data=None):\n        fn_abi, fn_selector, fn_arguments = get_function_info(\n            fn_name, contract_abi=cls.abi, args=args, kwargs=kwargs,\n        )\n\n        if data is None:\n            data = fn_selector\n\n        return encode_abi(cls.web3, fn_abi, fn_arguments, data)", "response": "Encodes the arguments using the Ethereum ABI for the given function name and arguments.."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef buildTransaction(self, transaction=None):\n\n        if transaction is None:\n            built_transaction = {}\n        else:\n            built_transaction = dict(**transaction)\n            self.check_forbidden_keys_in_transaction(built_transaction,\n                                                     [\"data\", \"to\"])\n\n        if self.web3.eth.defaultAccount is not empty:\n            built_transaction.setdefault('from', self.web3.eth.defaultAccount)\n\n        built_transaction['data'] = self.data_in_transaction\n        built_transaction['to'] = b''\n        return fill_transaction_defaults(self.web3, built_transaction)", "response": "Build the transaction dictionary without sending it"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef call(self, transaction=None, block_identifier='latest'):\n        if transaction is None:\n            call_transaction = {}\n        else:\n            call_transaction = dict(**transaction)\n\n        if 'data' in call_transaction:\n            raise ValueError(\"Cannot set data in call transaction\")\n\n        if self.address:\n            call_transaction.setdefault('to', self.address)\n        if self.web3.eth.defaultAccount is not empty:\n            call_transaction.setdefault('from', self.web3.eth.defaultAccount)\n\n        if 'to' not in call_transaction:\n            if isinstance(self, type):\n                raise ValueError(\n                    \"When using `Contract.[methodtype].[method].call()` from\"\n                    \" a contract factory you \"\n                    \"must provide a `to` address with the transaction\"\n                )\n            else:\n                raise ValueError(\n                    \"Please ensure that this contract instance has an address.\"\n                )\n\n        block_id = parse_block_identifier(self.web3, block_identifier)\n\n        return call_contract_function(\n            self.web3,\n            self.address,\n            self._return_data_normalizers,\n            self.function_identifier,\n            call_transaction,\n            block_id,\n            self.contract_abi,\n            self.abi,\n            *self.args,\n            **self.kwargs\n        )", "response": "Execute a contract function call using the eth_call interface."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef buildTransaction(self, transaction=None):\n        if transaction is None:\n            built_transaction = {}\n        else:\n            built_transaction = dict(**transaction)\n\n        if 'data' in built_transaction:\n            raise ValueError(\"Cannot set data in build transaction\")\n\n        if not self.address and 'to' not in built_transaction:\n            raise ValueError(\n                \"When using `ContractFunction.buildTransaction` from a contract factory \"\n                \"you must provide a `to` address with the transaction\"\n            )\n        if self.address and 'to' in built_transaction:\n            raise ValueError(\"Cannot set to in contract call build transaction\")\n\n        if self.address:\n            built_transaction.setdefault('to', self.address)\n\n        if 'to' not in built_transaction:\n            raise ValueError(\n                \"Please ensure that this contract instance has an address.\"\n            )\n\n        return build_transaction_for_function(\n            self.address,\n            self.web3,\n            self.function_identifier,\n            built_transaction,\n            self.contract_abi,\n            self.abi,\n            *self.args,\n            **self.kwargs\n        )", "response": "Builds the transaction dictionary without sending it"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef createFilter(\n            self, *,  # PEP 3102\n            argument_filters=None,\n            fromBlock=None,\n            toBlock=\"latest\",\n            address=None,\n            topics=None):\n        \"\"\"\n        Create filter object that tracks logs emitted by this contract event.\n        :param filter_params: other parameters to limit the events\n        \"\"\"\n        if fromBlock is None:\n            raise TypeError(\"Missing mandatory keyword argument to createFilter: fromBlock\")\n\n        if argument_filters is None:\n            argument_filters = dict()\n\n        _filters = dict(**argument_filters)\n\n        event_abi = self._get_event_abi()\n\n        check_for_forbidden_api_filter_arguments(event_abi, _filters)\n\n        _, event_filter_params = construct_event_filter_params(\n            self._get_event_abi(),\n            contract_address=self.address,\n            argument_filters=_filters,\n            fromBlock=fromBlock,\n            toBlock=toBlock,\n            address=address,\n            topics=topics,\n        )\n\n        filter_builder = EventFilterBuilder(event_abi)\n        filter_builder.address = event_filter_params.get('address')\n        filter_builder.fromBlock = event_filter_params.get('fromBlock')\n        filter_builder.toBlock = event_filter_params.get('toBlock')\n        match_any_vals = {\n            arg: value for arg, value in _filters.items()\n            if not is_array_type(filter_builder.args[arg].arg_type) and is_list_like(value)\n        }\n        for arg, value in match_any_vals.items():\n            filter_builder.args[arg].match_any(*value)\n\n        match_single_vals = {\n            arg: value for arg, value in _filters.items()\n            if not is_array_type(filter_builder.args[arg].arg_type) and not is_list_like(value)\n        }\n        for arg, value in match_single_vals.items():\n            filter_builder.args[arg].match_single(value)\n\n        log_filter = filter_builder.deploy(self.web3)\n        log_filter.log_entry_formatter = get_event_data(self._get_event_abi())\n        log_filter.builder = filter_builder\n\n        return log_filter", "response": "Create a filter object that tracks logs emitted by this contract event."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getLogs(self,\n                argument_filters=None,\n                fromBlock=None,\n                toBlock=None,\n                blockHash=None):\n        \"\"\"Get events for this contract instance using eth_getLogs API.\n\n        This is a stateless method, as opposed to createFilter.\n        It can be safely called against nodes which do not provide\n        eth_newFilter API, like Infura nodes.\n\n        If there are many events,\n        like ``Transfer`` events for a popular token,\n        the Ethereum node might be overloaded and timeout\n        on the underlying JSON-RPC call.\n\n        Example - how to get all ERC-20 token transactions\n        for the latest 10 blocks:\n\n        .. code-block:: python\n\n            from = max(mycontract.web3.eth.blockNumber - 10, 1)\n            to = mycontract.web3.eth.blockNumber\n\n            events = mycontract.events.Transfer.getLogs(fromBlock=from, toBlock=to)\n\n            for e in events:\n                print(e[\"args\"][\"from\"],\n                    e[\"args\"][\"to\"],\n                    e[\"args\"][\"value\"])\n\n        The returned processed log values will look like:\n\n        .. code-block:: python\n\n            (\n                AttributeDict({\n                 'args': AttributeDict({}),\n                 'event': 'LogNoArguments',\n                 'logIndex': 0,\n                 'transactionIndex': 0,\n                 'transactionHash': HexBytes('...'),\n                 'address': '0xF2E246BB76DF876Cef8b38ae84130F4F55De395b',\n                 'blockHash': HexBytes('...'),\n                 'blockNumber': 3\n                }),\n                AttributeDict(...),\n                ...\n            )\n\n        See also: :func:`web3.middleware.filter.local_filter_middleware`.\n\n        :param argument_filters:\n        :param fromBlock: block number or \"latest\", defaults to \"latest\"\n        :param toBlock: block number or \"latest\". Defaults to \"latest\"\n        :param blockHash: block hash. blockHash cannot be set at the\n          same time as fromBlock or toBlock\n        :yield: Tuple of :class:`AttributeDict` instances\n        \"\"\"\n\n        if not self.address:\n            raise TypeError(\"This method can be only called on \"\n                            \"an instated contract with an address\")\n\n        abi = self._get_event_abi()\n\n        if argument_filters is None:\n            argument_filters = dict()\n\n        _filters = dict(**argument_filters)\n\n        blkhash_set = blockHash is not None\n        blknum_set = fromBlock is not None or toBlock is not None\n        if blkhash_set and blknum_set:\n            raise ValidationError(\n                'blockHash cannot be set at the same'\n                ' time as fromBlock or toBlock')\n\n        # Construct JSON-RPC raw filter presentation based on human readable Python descriptions\n        # Namely, convert event names to their keccak signatures\n        data_filter_set, event_filter_params = construct_event_filter_params(\n            abi,\n            contract_address=self.address,\n            argument_filters=_filters,\n            fromBlock=fromBlock,\n            toBlock=toBlock,\n            address=self.address,\n        )\n\n        if blockHash is not None:\n            event_filter_params['blockHash'] = blockHash\n\n        # Call JSON-RPC API\n        logs = self.web3.eth.getLogs(event_filter_params)\n\n        # Convert raw binary data to Python proxy objects as described by ABI\n        return tuple(get_event_data(abi, entry) for entry in logs)", "response": "Get all log values for this contract instance."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncopying dict keyword args to avoid modifying caller s copy", "response": "def dict_copy(func):\n    \"copy dict keyword args, to avoid modifying caller's copy\"\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        copied_kwargs = copy.deepcopy(kwargs)\n        return func(*args, **copied_kwargs)\n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef normalize_name(name):\n    if not name:\n        return name\n    elif isinstance(name, (bytes, bytearray)):\n        name = name.decode('utf-8')\n    try:\n        return idna.decode(name, uts46=True, std3_rules=True)\n    except idna.IDNAError as exc:\n        raise InvalidName(\"%s is an invalid name, because %s\" % (name, exc)) from exc", "response": "Normalizes the name of a resource in the ENS name - syntax format."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting from a name like ethfinex. eth to a label like ethfinex. eth", "response": "def dot_eth_label(name):\n    \"\"\"\n    Convert from a name, like 'ethfinex.eth', to a label, like 'ethfinex'\n    If name is already a label, this should be a noop, except for converting to a string\n    and validating the name syntax.\n    \"\"\"\n    label = name_to_label(name, registrar='eth')\n    if len(label) < MIN_ETH_LABEL_LENGTH:\n        raise InvalidLabel('name %r is too short' % label)\n    else:\n        return label"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef map_collection(func, collection):\n    datatype = type(collection)\n    if isinstance(collection, Mapping):\n        return datatype((key, func(val)) for key, val in collection.items())\n    if is_string(collection):\n        return collection\n    elif isinstance(collection, Iterable):\n        return datatype(map(func, collection))\n    else:\n        return collection", "response": "Apply func to each element of a collection or value of a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\napply func to data and any collection items inside data", "response": "def recursive_map(func, data):\n    \"\"\"\n    Apply func to data, and any collection items inside data (using map_collection).\n    Define func so that it only applies to the type of value that you want it to apply to.\n    \"\"\"\n    def recurse(item):\n        return recursive_map(func, item)\n    items_mapped = map_collection(recurse, data)\n    return func(items_mapped)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getBlock(self, block_identifier, full_transactions=False):\n        method = select_method_for_block_identifier(\n            block_identifier,\n            if_predefined='eth_getBlockByNumber',\n            if_hash='eth_getBlockByHash',\n            if_number='eth_getBlockByNumber',\n        )\n\n        result = self.web3.manager.request_blocking(\n            method,\n            [block_identifier, full_transactions],\n        )\n        if result is None:\n            raise BlockNotFound(f\"Block with id: {block_identifier} not found.\")\n        return result", "response": "Get the block with the given identifier."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the number of uncle entries for a specific block.", "response": "def getUncleCount(self, block_identifier):\n        \"\"\"\n        `eth_getUncleCountByBlockHash`\n        `eth_getUncleCountByBlockNumber`\n        \"\"\"\n        method = select_method_for_block_identifier(\n            block_identifier,\n            if_predefined='eth_getUncleCountByBlockNumber',\n            if_hash='eth_getUncleCountByBlockHash',\n            if_number='eth_getUncleCountByBlockNumber',\n        )\n        result = self.web3.manager.request_blocking(\n            method,\n            [block_identifier],\n        )\n        if result is None:\n            raise BlockNotFound(f\"Block with id: {block_identifier} not found.\")\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the uncle with the given block identifier and index.", "response": "def getUncleByBlock(self, block_identifier, uncle_index):\n        \"\"\"\n        `eth_getUncleByBlockHashAndIndex`\n        `eth_getUncleByBlockNumberAndIndex`\n        \"\"\"\n        method = select_method_for_block_identifier(\n            block_identifier,\n            if_predefined='eth_getUncleByBlockNumberAndIndex',\n            if_hash='eth_getUncleByBlockHashAndIndex',\n            if_number='eth_getUncleByBlockNumberAndIndex',\n        )\n        result = self.web3.manager.request_blocking(\n            method,\n            [block_identifier, uncle_index],\n        )\n        if result is None:\n            raise BlockNotFound(\n                f\"Uncle at index: {uncle_index} of block with id: {block_identifier} not found.\"\n            )\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getTransactionByBlock(self, block_identifier, transaction_index):\n        method = select_method_for_block_identifier(\n            block_identifier,\n            if_predefined='eth_getTransactionByBlockNumberAndIndex',\n            if_hash='eth_getTransactionByBlockHashAndIndex',\n            if_number='eth_getTransactionByBlockNumberAndIndex',\n        )\n        result = self.web3.manager.request_blocking(\n            method,\n            [block_identifier, transaction_index],\n        )\n        if result is None:\n            raise TransactionNotFound(\n                f\"Transaction index: {transaction_index} \"\n                f\"on block id: {block_identifier} not found.\"\n            )\n        return result", "response": "Get a transaction by block identifier and index."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef percentile(values=None, percentile=None):\n    if values in [None, tuple(), []] or len(values) < 1:\n        raise InsufficientData(\n            \"Expected a sequence of at least 1 integers, got {0!r}\".format(values))\n    if percentile is None:\n        raise ValueError(\"Expected a percentile choice, got {0}\".format(percentile))\n\n    sorted_values = sorted(values)\n\n    rank = len(values) * percentile / 100\n    if rank > 0:\n        index = rank - 1\n        if index < 0:\n            return sorted_values[0]\n    else:\n        index = rank\n\n    if index % 1 == 0:\n        return sorted_values[int(index)]\n    else:\n        fractional = index % 1\n        integer = int(index - fractional)\n        lower = sorted_values[integer]\n        higher = sorted_values[integer + 1]\n        return lower + fractional * (higher - lower)", "response": "Calculates a simplified weighted average percentile\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ninjects a named element to an arbitrary layer in the onion.", "response": "def inject(self, element, name=None, layer=None):\n        \"\"\"\n        Inject a named element to an arbitrary layer in the onion.\n\n        The current implementation only supports insertion at the innermost layer,\n        or at the outermost layer. Note that inserting to the outermost is equivalent\n        to calling :meth:`add` .\n        \"\"\"\n        if not is_integer(layer):\n            raise TypeError(\"The layer for insertion must be an int.\")\n        elif layer != 0 and layer != len(self._queue):\n            raise NotImplementedError(\n                \"You can only insert to the beginning or end of a %s, currently. \"\n                \"You tried to insert to %d, but only 0 and %d are permitted. \" % (\n                    type(self),\n                    layer,\n                    len(self._queue),\n                )\n            )\n\n        self.add(element, name=name)\n\n        if layer == 0:\n            if name is None:\n                name = element\n            self._queue.move_to_end(name, last=False)\n        elif layer == len(self._queue):\n            return\n        else:\n            raise AssertionError(\"Impossible to reach: earlier validation raises an error\")"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_basic_type_str(old_normalizer):\n    @functools.wraps(old_normalizer)\n    def new_normalizer(type_str, data):\n        try:\n            abi_type = parse(type_str)\n        except ParseError:\n            # If type string is not parsable, do nothing\n            return type_str, data\n\n        if not isinstance(abi_type, BasicType):\n            return type_str, data\n\n        return old_normalizer(abi_type, type_str, data)\n\n    return new_normalizer", "response": "A normalizer to automatically parse the incoming type string."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconstructing a middleware that signs and sends raw transactions.", "response": "def construct_sign_and_send_raw_middleware(private_key_or_account):\n    \"\"\"Capture transactions sign and send as raw transactions\n\n\n    Keyword arguments:\n    private_key_or_account -- A single private key or a tuple,\n    list or set of private keys. Keys can be any of the following formats:\n      - An eth_account.LocalAccount object\n      - An eth_keys.PrivateKey object\n      - A raw private key as a hex string or byte string\n    \"\"\"\n\n    accounts = gen_normalized_accounts(private_key_or_account)\n\n    def sign_and_send_raw_middleware(make_request, w3):\n\n        format_and_fill_tx = compose(\n            format_transaction,\n            fill_transaction_defaults(w3),\n            fill_nonce(w3))\n\n        def middleware(method, params):\n            if method != \"eth_sendTransaction\":\n                return make_request(method, params)\n            else:\n                transaction = format_and_fill_tx(params[0])\n\n            if 'from' not in transaction:\n                return make_request(method, params)\n            elif transaction.get('from') not in accounts:\n                return make_request(method, params)\n\n            account = accounts[transaction['from']]\n            raw_tx = account.signTransaction(transaction).rawTransaction\n\n            return make_request(\n                \"eth_sendRawTransaction\",\n                [raw_tx])\n\n        return middleware\n\n    return sign_and_send_raw_middleware"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef validate_abi_value(abi_type, value):\n    if is_array_type(abi_type) and is_list_like(value):\n        # validate length\n        specified_length = length_of_array_type(abi_type)\n        if specified_length is not None:\n            if specified_length < 1:\n                raise TypeError(\n                    \"Invalid abi-type: {abi_type}. Length of fixed sized arrays\"\n                    \"must be greater than 0.\"\n                    .format(abi_type=abi_type)\n                )\n            if specified_length != len(value):\n                raise TypeError(\n                    \"The following array length does not the length specified\"\n                    \"by the abi-type, {abi_type}: {value}\"\n                    .format(abi_type=abi_type, value=value)\n                )\n\n        # validate sub_types\n        sub_type = sub_type_of_array_type(abi_type)\n        for v in value:\n            validate_abi_value(sub_type, v)\n        return\n    elif is_bool_type(abi_type) and is_boolean(value):\n        return\n    elif is_uint_type(abi_type) and is_integer(value) and value >= 0:\n        return\n    elif is_int_type(abi_type) and is_integer(value):\n        return\n    elif is_address_type(abi_type):\n        validate_address(value)\n        return\n    elif is_bytes_type(abi_type):\n        if is_bytes(value):\n            return\n        elif is_string(value):\n            if is_0x_prefixed(value):\n                return\n            else:\n                raise TypeError(\n                    \"ABI values of abi-type 'bytes' must be either\"\n                    \"a python3 'bytes' object or an '0x' prefixed string.\"\n                )\n    elif is_string_type(abi_type) and is_string(value):\n        return\n\n    raise TypeError(\n        \"The following abi value is not a '{abi_type}': {value}\"\n        .format(abi_type=abi_type, value=value)\n    )", "response": "Validates a value against the expected abi - type"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconstructing a middleware which caches responses based on the request method and params.", "response": "def construct_simple_cache_middleware(\n        cache_class,\n        rpc_whitelist=SIMPLE_CACHE_RPC_WHITELIST,\n        should_cache_fn=_should_cache):\n    \"\"\"\n    Constructs a middleware which caches responses based on the request\n    ``method`` and ``params``\n\n    :param cache: Any dictionary-like object\n    :param rpc_whitelist: A set of RPC methods which may have their responses cached.\n    :param should_cache_fn: A callable which accepts ``method`` ``params`` and\n        ``response`` and returns a boolean as to whether the response should be\n        cached.\n    \"\"\"\n    def simple_cache_middleware(make_request, web3):\n        cache = cache_class()\n        lock = threading.Lock()\n\n        def middleware(method, params):\n            lock_acquired = lock.acquire(blocking=False)\n\n            try:\n                if lock_acquired and method in rpc_whitelist:\n                    cache_key = generate_cache_key((method, params))\n                    if cache_key not in cache:\n                        response = make_request(method, params)\n                        if should_cache_fn(method, params, response):\n                            cache[cache_key] = response\n                        return response\n                    return cache[cache_key]\n                else:\n                    return make_request(method, params)\n            finally:\n                if lock_acquired:\n                    lock.release()\n        return middleware\n    return simple_cache_middleware"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconstructing a middleware which caches responses based on a maximum amount of time as specified by the given parameters.", "response": "def construct_time_based_cache_middleware(\n        cache_class,\n        cache_expire_seconds=15,\n        rpc_whitelist=TIME_BASED_CACHE_RPC_WHITELIST,\n        should_cache_fn=_should_cache):\n    \"\"\"\n    Constructs a middleware which caches responses based on the request\n    ``method`` and ``params`` for a maximum amount of time as specified\n\n    :param cache: Any dictionary-like object\n    :param cache_expire_seconds: The number of seconds an item may be cached\n        before it should expire.\n    :param rpc_whitelist: A set of RPC methods which may have their responses cached.\n    :param should_cache_fn: A callable which accepts ``method`` ``params`` and\n        ``response`` and returns a boolean as to whether the response should be\n        cached.\n    \"\"\"\n    def time_based_cache_middleware(make_request, web3):\n        cache = cache_class()\n        lock = threading.Lock()\n\n        def middleware(method, params):\n            lock_acquired = lock.acquire(blocking=False)\n\n            try:\n                if lock_acquired and method in rpc_whitelist:\n                    cache_key = generate_cache_key((method, params))\n                    if cache_key in cache:\n                        # check that the cached response is not expired.\n                        cached_at, cached_response = cache[cache_key]\n                        cached_for = time.time() - cached_at\n\n                        if cached_for <= cache_expire_seconds:\n                            return cached_response\n                        else:\n                            del cache[cache_key]\n\n                    # cache either missed or expired so make the request.\n                    response = make_request(method, params)\n\n                    if should_cache_fn(method, params, response):\n                        cache[cache_key] = (time.time(), response)\n\n                    return response\n                else:\n                    return make_request(method, params)\n            finally:\n                if lock_acquired:\n                    lock.release()\n        return middleware\n    return time_based_cache_middleware"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprevent simple cycles by returning None when called recursively with same instance", "response": "def reject_recursive_repeats(to_wrap):\n    \"\"\"\n    Prevent simple cycles by returning None when called recursively with same instance\n    \"\"\"\n    to_wrap.__already_called = {}\n\n    @functools.wraps(to_wrap)\n    def wrapped(*args):\n        arg_instances = tuple(map(id, args))\n        thread_id = threading.get_ident()\n        thread_local_args = (thread_id,) + arg_instances\n        if thread_local_args in to_wrap.__already_called:\n            raise ValueError('Recursively called %s with %r' % (to_wrap, args))\n        to_wrap.__already_called[thread_local_args] = True\n        try:\n            wrapped_val = to_wrap(*args)\n        finally:\n            del to_wrap.__already_called[thread_local_args]\n        return wrapped_val\n    return wrapped"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef deprecated_for(replace_message):\n    def decorator(to_wrap):\n        @functools.wraps(to_wrap)\n        def wrapper(*args, **kwargs):\n            warnings.warn(\n                \"%s is deprecated in favor of %s\" % (to_wrap.__name__, replace_message),\n                category=DeprecationWarning,\n                stacklevel=2)\n            return to_wrap(*args, **kwargs)\n        return wrapper\n    return decorator", "response": "Decorate a deprecated function, with info about what to use instead, like:\n\n    @deprecated_for(\"toBytes()\")\n    def toAscii(arg):\n        ..."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef merge_args_and_kwargs(function_abi, args, kwargs):\n    # Ensure the function is being applied to the correct number of args\n    if len(args) + len(kwargs) != len(function_abi.get('inputs', [])):\n        raise TypeError(\n            \"Incorrect argument count.  Expected '{0}'.  Got '{1}'\".format(\n                len(function_abi['inputs']),\n                len(args) + len(kwargs),\n            )\n        )\n\n    # If no keyword args were given, we don't need to align them\n    if not kwargs:\n        return args\n\n    kwarg_names = set(kwargs.keys())\n    sorted_arg_names = tuple(arg_abi['name'] for arg_abi in function_abi['inputs'])\n    args_as_kwargs = dict(zip(sorted_arg_names, args))\n\n    # Check for duplicate args\n    duplicate_args = kwarg_names.intersection(args_as_kwargs.keys())\n    if duplicate_args:\n        raise TypeError(\n            \"{fn_name}() got multiple values for argument(s) '{dups}'\".format(\n                fn_name=function_abi['name'],\n                dups=', '.join(duplicate_args),\n            )\n        )\n\n    # Check for unknown args\n    unknown_args = kwarg_names.difference(sorted_arg_names)\n    if unknown_args:\n        if function_abi.get('name'):\n            raise TypeError(\n                \"{fn_name}() got unexpected keyword argument(s) '{dups}'\".format(\n                    fn_name=function_abi.get('name'),\n                    dups=', '.join(unknown_args),\n                )\n            )\n        raise TypeError(\n            \"Type: '{_type}' got unexpected keyword argument(s) '{dups}'\".format(\n                _type=function_abi.get('type'),\n                dups=', '.join(unknown_args),\n            )\n        )\n\n    # Sort args according to their position in the ABI and unzip them from their\n    # names\n    sorted_args = tuple(zip(\n        *sorted(\n            itertools.chain(kwargs.items(), args_as_kwargs.items()),\n            key=lambda kv: sorted_arg_names.index(kv[0]),\n        )\n    ))\n\n    if sorted_args:\n        return sorted_args[1]\n    else:\n        return tuple()", "response": "Merges positional args and keyword args into a single object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntaking a JSON ABI type string and returns the separated prefix and array dimension parts.", "response": "def get_tuple_type_str_parts(s: str) -> Optional[Tuple[str, Optional[str]]]:\n    \"\"\"\n    Takes a JSON ABI type string.  For tuple type strings, returns the separated\n    prefix and array dimension parts.  For all other strings, returns ``None``.\n    \"\"\"\n    match = TUPLE_TYPE_STR_RE.match(s)\n\n    if match is not None:\n        tuple_prefix = match.group(1)\n        tuple_dims = match.group(2)\n\n        return tuple_prefix, tuple_dims\n\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _align_abi_input(arg_abi, arg):\n    tuple_parts = get_tuple_type_str_parts(arg_abi['type'])\n\n    if tuple_parts is None:\n        # Arg is non-tuple.  Just return value.\n        return arg\n\n    tuple_prefix, tuple_dims = tuple_parts\n    if tuple_dims is None:\n        # Arg is non-list tuple.  Each sub arg in `arg` will be aligned\n        # according to its corresponding abi.\n        sub_abis = arg_abi['components']\n    else:\n        # Arg is list tuple.  A non-list version of its abi will be used to\n        # align each element in `arg`.\n        new_abi = copy.copy(arg_abi)\n        new_abi['type'] = tuple_prefix\n\n        sub_abis = itertools.repeat(new_abi)\n\n    if isinstance(arg, abc.Mapping):\n        # Arg is mapping.  Align values according to abi order.\n        aligned_arg = tuple(arg[abi['name']] for abi in sub_abis)\n    else:\n        aligned_arg = arg\n\n    if not is_list_like(aligned_arg):\n        raise TypeError(\n            'Expected non-string sequence for \"{}\" component type: got {}'.format(\n                arg_abi['type'],\n                aligned_arg,\n            ),\n        )\n\n    return type(aligned_arg)(\n        _align_abi_input(sub_abi, sub_arg)\n        for sub_abi, sub_arg in zip(sub_abis, aligned_arg)\n    )", "response": "Aligns the values of any mapping at any level of nesting in arg according to the layout of the corresponding abi spec."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_aligned_abi_inputs(abi, args):\n    input_abis = abi.get('inputs', [])\n\n    if isinstance(args, abc.Mapping):\n        # `args` is mapping.  Align values according to abi order.\n        args = tuple(args[abi['name']] for abi in input_abis)\n\n    return (\n        tuple(collapse_if_tuple(abi) for abi in input_abis),\n        type(args)(\n            _align_abi_input(abi, arg)\n            for abi, arg in zip(input_abis, args)\n        ),\n    )", "response": "Returns a list of type strings for the function s inputs and a list of tuple - encoded arguments."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef size_of_type(abi_type):\n    if 'string' in abi_type:\n        return None\n    if 'byte' in abi_type:\n        return None\n    if '[' in abi_type:\n        return None\n    if abi_type == 'bool':\n        return 8\n    if abi_type == 'address':\n        return 160\n    return int(re.sub(r\"\\D\", \"\", abi_type))", "response": "Returns size of a given abi type"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef abi_data_tree(types, data):\n    return [\n        abi_sub_tree(data_type, data_value)\n        for data_type, data_value\n        in zip(types, data)\n    ]", "response": "Decorate the data tree with pairs of type and data."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef data_tree_map(func, data_tree):\n    def map_to_typed_data(elements):\n        if isinstance(elements, ABITypedData) and elements.abi_type is not None:\n            return ABITypedData(func(*elements))\n        else:\n            return elements\n    return recursive_map(map_to_typed_data, data_tree)", "response": "Map func to every ABITypedData element in the tree."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nprepare a transaction that can be used to call a function in a node.", "response": "def prepare_transaction(\n        address,\n        web3,\n        fn_identifier,\n        contract_abi=None,\n        fn_abi=None,\n        transaction=None,\n        fn_args=None,\n        fn_kwargs=None):\n    \"\"\"\n    :parameter `is_function_abi` is used to distinguish  function abi from contract abi\n    Returns a dictionary of the transaction that could be used to call this\n    TODO: make this a public API\n    TODO: add new prepare_deploy_transaction API\n    \"\"\"\n    if fn_abi is None:\n        fn_abi = find_matching_fn_abi(contract_abi, fn_identifier, fn_args, fn_kwargs)\n\n    validate_payable(transaction, fn_abi)\n\n    if transaction is None:\n        prepared_transaction = {}\n    else:\n        prepared_transaction = dict(**transaction)\n\n    if 'data' in prepared_transaction:\n        raise ValueError(\"Transaction parameter may not contain a 'data' key\")\n\n    if address:\n        prepared_transaction.setdefault('to', address)\n\n    prepared_transaction['data'] = encode_transaction_data(\n        web3,\n        fn_identifier,\n        contract_abi,\n        fn_abi,\n        fn_args,\n        fn_kwargs,\n    )\n    return prepared_transaction"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ix(self, word):\n        temp = np.where(self.vocab == word)[0]\n        if temp.size == 0:\n            raise KeyError(\"Word not in vocabulary\")\n        else:\n            return temp[0]", "response": "Returns the index of the cluster with the given word."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_cluster(self, word):\n        idx = self.ix(word)\n        return self.clusters[idx]", "response": "Returns the cluster number for a word in the vocabulary"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncomputing the distance between two vectors or more words.", "response": "def distance(self, *args, **kwargs):\n        \"\"\"\n        Compute the distance distance between two vectors or more (all combinations) of words\n\n        Parameters\n        ----------\n        words : one or more words\n        n : int (default 10)\n            number of neighbors to return\n        metric : string (default \"cosine\")\n            What metric to use\n        \"\"\"\n        metric = kwargs.get(\"metric\", \"cosine\")    # Default is cosine\n\n        combinations = list(itertools.combinations(args, r=2))\n\n        ret = []\n        for word1, word2 in combinations:\n            dist = distance(self[word1], self[word2], metric=metric)\n            ret.append((word1, word2, dist))\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef closest(self, vector, n=10, metric=\"cosine\"):\n        distances = distance(self.vectors, vector, metric=metric)\n        best = np.argsort(distances)[::-1][1:n + 1]\n        best_metrics = distances[best]\n        return best, best_metrics", "response": "Returns the closest n words to a vector"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef similar(self, word, n=10, metric=\"cosine\"):\n        return self.closest(self[word], n=n, metric=metric)", "response": "Returns similar words based on a metric"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates a numpy array based on numpy arrays", "response": "def generate_response(self, indexes, metrics, clusters=True):\n        \"\"\"\n        Generates a pure python (no numpy) response based on numpy arrays\n        returned by `self.cosine` and `self.analogy`\n        \"\"\"\n        if self.clusters and clusters:\n            return np.rec.fromarrays(\n                (self.vocab[indexes], metrics, self.clusters.clusters[indexes]),\n                names=(\"word\", \"metric\", \"cluster\"),\n            )\n        else:\n            return np.rec.fromarrays((self.vocab[indexes], metrics), names=(\"word\", \"metric\"))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_binary(\n            cls,\n            fname,\n            vocab_unicode_size=78,\n            desired_vocab=None,\n            encoding=\"utf-8\",\n            new_lines=True,\n    ):\n        \"\"\"\n        Create a WordVectors class based on a word2vec binary file\n\n        Parameters\n        ----------\n        fname : path to file\n        vocabUnicodeSize: the maximum string length (78, by default)\n        desired_vocab: if set any words that don't fall into this vocab will be droped\n\n        Returns\n        -------\n        WordVectors instance\n        \"\"\"\n        with open(fname, \"rb\") as fin:\n            # The first line has the vocab_size and the vector_size as text\n            header = fin.readline()\n            vocab_size, vector_size = list(map(int, header.split()))\n\n            vocab = np.empty(vocab_size, dtype=\"<U%s\" % vocab_unicode_size)\n            vectors = np.empty((vocab_size, vector_size), dtype=np.float)\n            binary_len = np.dtype(np.float32).itemsize * vector_size\n            for i in range(vocab_size):\n                # read word\n                word = b\"\"\n                while True:\n                    ch = fin.read(1)\n                    if ch == b\" \":\n                        break\n                    word += ch\n                include = desired_vocab is None or word in desired_vocab\n                if include:\n                    vocab[i] = word.decode(encoding)\n\n                # read vector\n                vector = np.fromstring(fin.read(binary_len), dtype=np.float32)\n                if include:\n                    vectors[i] = unitvec(vector)\n                if new_lines:\n                    fin.read(1)    # newline char\n\n            if desired_vocab is not None:\n                vectors = vectors[vocab != \"\", :]\n                vocab = vocab[vocab != \"\"]\n        return cls(vocab=vocab, vectors=vectors)", "response": "Create a WordVectors instance from a binary file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a WordVectors class based on a word2vec text file.", "response": "def from_text(cls, fname, vocabUnicodeSize=78, desired_vocab=None, encoding=\"utf-8\"):\n        \"\"\"\n        Create a WordVectors class based on a word2vec text file\n\n        Parameters\n        ----------\n        fname : path to file\n        vocabUnicodeSize: the maximum string length (78, by default)\n        desired_vocab: if set, this will ignore any word and vector that\n                       doesn't fall inside desired_vocab.\n\n        Returns\n        -------\n        WordVectors instance\n        \"\"\"\n        with open(fname, \"rb\") as fin:\n            header = fin.readline()\n            vocab_size, vector_size = list(map(int, header.split()))\n\n            vocab = np.empty(vocab_size, dtype=\"<U%s\" % vocabUnicodeSize)\n            vectors = np.empty((vocab_size, vector_size), dtype=np.float)\n            for i, line in enumerate(fin):\n                line = line.decode(encoding).rstrip()\n                parts = line.split(\" \")\n                word = parts[0]\n                include = desired_vocab is None or word in desired_vocab\n                if include:\n                    vector = np.array(parts[1:], dtype=np.float)\n                    vocab[i] = word\n                    vectors[i] = unitvec(vector)\n\n            if desired_vocab is not None:\n                vectors = vectors[vocab != \"\", :]\n                vocab = vocab[vocab != \"\"]\n        return cls(vocab=vocab, vectors=vectors)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef from_mmap(cls, fname):\n        memmaped = joblib.load(fname, mmap_mode=\"r+\")\n        return cls(vocab=memmaped.vocab, vectors=memmaped.vectors)", "response": "Create a WordVectors class from a memory map file."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalculates distance between two vectors based on a Metric Metrics", "response": "def distance(a, b, metric=\"cosine\"):\n    \"\"\"\n    Calculate distance between two vectors based on a Metric\n\n    Metrics:\n    1. cosine distance. Note that in word2vec all the norms are 1 so the dot product is the same as cosine distance\n    \"\"\"\n    if metric == \"cosine\":\n        return np.dot(a, b.T)\n    raise Exception(\"Unknown metric '{metric}'\".format(metric=metric))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load(fname, kind=\"auto\", *args, **kwargs):\n    if kind == \"auto\":\n        if fname.endswith(\".bin\"):\n            kind = \"bin\"\n        elif fname.endswith(\".txt\"):\n            kind = \"txt\"\n        else:\n            raise Exception(\"Could not identify kind\")\n    if kind == \"bin\":\n        return word2vec.WordVectors.from_binary(fname, *args, **kwargs)\n    elif kind == \"txt\":\n        return word2vec.WordVectors.from_text(fname, *args, **kwargs)\n    elif kind == \"mmap\":\n        return word2vec.WordVectors.from_mmap(fname, *args, **kwargs)\n    else:\n        raise Exception(\"Unknown kind\")", "response": "Loads a word vectors file"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef word2vec(\n        train,\n        output,\n        size=100,\n        window=5,\n        sample=\"1e-3\",\n        hs=0,\n        negative=5,\n        threads=12,\n        iter_=5,\n        min_count=5,\n        alpha=0.025,\n        debug=2,\n        binary=1,\n        cbow=1,\n        save_vocab=None,\n        read_vocab=None,\n        verbose=False,\n):\n    \"\"\"\n    word2vec execution\n\n    Parameters for training:\n        train <file>\n            Use text data from <file> to train the model\n        output <file>\n            Use <file> to save the resulting word vectors / word clusters\n        size <int>\n            Set size of word vectors; default is 100\n        window <int>\n            Set max skip length between words; default is 5\n        sample <float>\n            Set threshold for occurrence of words. Those that appear with\n            higher frequency in the training data will be randomly\n            down-sampled; default is 0 (off), useful value is 1e-5\n        hs <int>\n            Use Hierarchical Softmax; default is 1 (0 = not used)\n        negative <int>\n            Number of negative examples; default is 0, common values are 5 - 10\n            (0 = not used)\n        threads <int>\n            Use <int> threads (default 1)\n        min_count <int>\n            This will discard words that appear less than <int> times; default\n            is 5\n        alpha <float>\n            Set the starting learning rate; default is 0.025\n        debug <int>\n            Set the debug mode (default = 2 = more info during training)\n        binary <int>\n            Save the resulting vectors in binary moded; default is 0 (off)\n        cbow <int>\n            Use the continuous back of words model; default is 1 (use 0 for\n            skip-gram model)\n        save_vocab <file>\n            The vocabulary will be saved to <file>\n        read_vocab <file>\n            The vocabulary will be read from <file>, not constructed from the\n            training data\n        verbose\n            Print output from training\n    \"\"\"\n    command = [\"word2vec\"]\n    args = [\n        \"-train\",\n        \"-output\",\n        \"-size\",\n        \"-window\",\n        \"-sample\",\n        \"-hs\",\n        \"-negative\",\n        \"-threads\",\n        \"-iter\",\n        \"-min-count\",\n        \"-alpha\",\n        \"-debug\",\n        \"-binary\",\n        \"-cbow\",\n    ]\n    values = [\n        train,\n        output,\n        size,\n        window,\n        sample,\n        hs,\n        negative,\n        threads,\n        iter_,\n        min_count,\n        alpha,\n        debug,\n        binary,\n        cbow,\n    ]\n\n    for arg, value in zip(args, values):\n        command.append(arg)\n        command.append(str(value))\n    if save_vocab is not None:\n        command.append(\"-save-vocab\")\n        command.append(str(save_vocab))\n    if read_vocab is not None:\n        command.append(\"-read-vocab\")\n        command.append(str(read_vocab))\n\n    run_cmd(command, verbose=verbose)", "response": "This function returns the word2vec model for training and training."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef iterate(self):\n        self.counter += 1\n        self.counter0 += 1\n        self.revcounter -= 1\n        self.revcounter0 -= 1\n        self.first = False\n        self.last = (self.revcounter0 == self.len_values - 1)", "response": "Iterate over the set of entries."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a new context object with all the necessary stuff for rendering the form.", "response": "def get_render(self, context):\n        \"\"\"\n        Returns a `Context` object with all the necessary stuff for rendering the form\n\n        :param context: `django.template.Context` variable holding the context for the node\n\n        `self.form` and `self.helper` are resolved into real Python objects resolving them\n        from the `context`. The `actual_form` can be a form or a formset. If it's a formset\n        `is_formset` is set to True. If the helper has a layout we use it, for rendering the\n        form or the formset's forms.\n        \"\"\"\n        # Nodes are not thread safe in multithreaded environments\n        # https://docs.djangoproject.com/en/dev/howto/custom-template-tags/#thread-safety-considerations\n        if self not in context.render_context:\n            context.render_context[self] = (\n                template.Variable(self.form),\n                template.Variable(self.helper) if self.helper else None\n            )\n        form, helper = context.render_context[self]\n\n        actual_form = form.resolve(context)\n        if self.helper is not None:\n            helper = helper.resolve(context)\n        else:\n            # If the user names the helper within the form `helper` (standard), we use it\n            # This allows us to have simplified tag syntax: {% crispy form %}\n            helper = FormHelper() if not hasattr(actual_form, 'helper') else actual_form.helper\n\n        # use template_pack from helper, if defined\n        try:\n            if helper.template_pack:\n                self.template_pack = helper.template_pack\n        except AttributeError:\n            pass\n\n        self.actual_helper = helper\n\n        # We get the response dictionary\n        is_formset = isinstance(actual_form, BaseFormSet)\n        response_dict = self.get_response_dict(helper, context, is_formset)\n        node_context = context.__copy__()\n        node_context.update(response_dict)\n        final_context = node_context.__copy__()\n\n        # If we have a helper's layout we use it, for the form or the formset's forms\n        if helper and helper.layout:\n            if not is_formset:\n                actual_form.form_html = helper.render_layout(actual_form, node_context, template_pack=self.template_pack)\n            else:\n                forloop = ForLoopSimulator(actual_form)\n                helper.render_hidden_fields = True\n                for form in actual_form:\n                    node_context.update({'forloop': forloop})\n                    node_context.update({'formset_form': form})\n                    form.form_html = helper.render_layout(form, node_context, template_pack=self.template_pack)\n                    forloop.iterate()\n\n        if is_formset:\n            final_context['formset'] = actual_form\n        else:\n            final_context['form'] = actual_form\n\n        return final_context"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_response_dict(self, helper, context, is_formset):\n        if not isinstance(helper, FormHelper):\n            raise TypeError('helper object provided to {% crispy %} tag must be a crispy.helper.FormHelper object.')\n\n        attrs = helper.get_attributes(template_pack=self.template_pack)\n        form_type = \"form\"\n        if is_formset:\n            form_type = \"formset\"\n\n        # We take form/formset parameters from attrs if they are set, otherwise we use defaults\n        response_dict = {\n            'template_pack': self.template_pack,\n            '%s_action' % form_type: attrs['attrs'].get(\"action\", ''),\n            '%s_method' % form_type: attrs.get(\"form_method\", 'post'),\n            '%s_tag' % form_type: attrs.get(\"form_tag\", True),\n            '%s_class' % form_type: attrs['attrs'].get(\"class\", ''),\n            '%s_id' % form_type: attrs['attrs'].get(\"id\", \"\"),\n            '%s_style' % form_type: attrs.get(\"form_style\", None),\n            'form_error_title': attrs.get(\"form_error_title\", None),\n            'formset_error_title': attrs.get(\"formset_error_title\", None),\n            'form_show_errors': attrs.get(\"form_show_errors\", True),\n            'help_text_inline': attrs.get(\"help_text_inline\", False),\n            'html5_required': attrs.get(\"html5_required\", False),\n            'form_show_labels': attrs.get(\"form_show_labels\", True),\n            'disable_csrf': attrs.get(\"disable_csrf\", False),\n            'inputs': attrs.get('inputs', []),\n            'is_formset': is_formset,\n            '%s_attrs' % form_type: attrs.get('attrs', ''),\n            'flat_attrs': attrs.get('flat_attrs', ''),\n            'error_text_inline': attrs.get('error_text_inline', True),\n            'label_class': attrs.get('label_class', ''),\n            'field_class': attrs.get('field_class', ''),\n            'include_media': attrs.get('include_media', True),\n        }\n\n        # Handles custom attributes added to helpers\n        for attribute_name, value in attrs.items():\n            if attribute_name not in response_dict:\n                response_dict[attribute_name] = value\n\n        if 'csrf_token' in context:\n            response_dict['csrf_token'] = context['csrf_token']\n\n        return response_dict", "response": "Returns a dictionary with all the parameters necessary to render the form and formset in a template."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving whitespace between HTML tags introduces a whitespace between buttons and inputs necessary for Bootstrap to place them together in the layout.", "response": "def specialspaceless(parser, token):\n    \"\"\"\n    Removes whitespace between HTML tags, and introduces a whitespace\n    after buttons an inputs, necessary for Bootstrap to place them\n    correctly in the layout.\n    \"\"\"\n    nodelist = parser.parse(('endspecialspaceless',))\n    parser.delete_first_token()\n\n    return SpecialSpacelessNode(nodelist)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the first container with errors.", "response": "def first_container_with_errors(self, errors):\n        \"\"\"\n        Returns the first container with errors, otherwise returns None.\n        \"\"\"\n        for tab in self.fields:\n            errors_here = any(error in tab for error in errors)\n            if errors_here:\n                return tab\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef open_target_group_for_form(self, form):\n        target = self.first_container_with_errors(form.errors.keys())\n        if target is None:\n            target = self.fields[0]\n            if not getattr(target, '_active_originally_included', None):\n                target.active = True\n            return target\n\n        target.active = True\n        return target", "response": "Returns the first group that should be open for the given form."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nrenders the link for the tab - pane.", "response": "def render_link(self, template_pack=TEMPLATE_PACK, **kwargs):\n        \"\"\"\n        Render the link for the tab-pane. It must be called after render so css_class is updated\n        with active if needed.\n        \"\"\"\n        link_template = self.link_template % template_pack\n        return render_to_string(link_template, {'link': self})"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list of lists pointing to layout objects of any type matchingLayoutClasses.", "response": "def get_layout_objects(self, *LayoutClasses, **kwargs):\n        \"\"\"\n        Returns a list of lists pointing to layout objects of any type matching\n        `LayoutClasses`::\n\n            [\n                [[0,1,2], 'div'],\n                [[0,3], 'field_name']\n            ]\n\n        :param max_level: An integer that indicates max level depth to reach when\n        traversing a layout.\n        :param greedy: Boolean that indicates whether to be greedy. If set, max_level\n        is skipped.\n        \"\"\"\n        index = kwargs.pop('index', None)\n        max_level = kwargs.pop('max_level', 0)\n        greedy = kwargs.pop('greedy', False)\n\n        pointers = []\n\n        if index is not None and not isinstance(index, list):\n            index = [index]\n        elif index is None:\n            index = []\n\n        for i, layout_object in enumerate(self.fields):\n            if isinstance(layout_object, LayoutClasses):\n                if len(LayoutClasses) == 1 and LayoutClasses[0] == string_types:\n                    pointers.append([index + [i], layout_object])\n                else:\n                    pointers.append([index + [i], layout_object.__class__.__name__.lower()])\n\n            # If it's a layout object and we haven't reached the max depth limit or greedy\n            # we recursive call\n            if hasattr(layout_object, 'get_field_names') and (len(index) < max_level or greedy):\n                new_kwargs = {'index': index + [i], 'max_level': max_level, 'greedy': greedy}\n                pointers = pointers + layout_object.get_layout_objects(*LayoutClasses, **new_kwargs)\n\n        return pointers"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse a crispy_field tag.", "response": "def crispy_field(parser, token):\n    \"\"\"\n    {% crispy_field field attrs %}\n    \"\"\"\n    token = token.split_contents()\n    field = token.pop(1)\n    attrs = {}\n\n    # We need to pop tag name, or pairwise would fail\n    token.pop(0)\n    for attribute_name, value in pairwise(token):\n        attrs[attribute_name] = value\n\n    return CrispyFieldNode(field, attrs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a crispy_addon form field using bootstrap s prepended or appended text.", "response": "def crispy_addon(field, append=\"\", prepend=\"\", form_show_labels=True):\n    \"\"\"\n    Renders a form field using bootstrap's prepended or appended text::\n\n        {% crispy_addon form.my_field prepend=\"$\" append=\".00\" %}\n\n    You can also just prepend or append like so\n\n        {% crispy_addon form.my_field prepend=\"$\" %}\n        {% crispy_addon form.my_field append=\".00\" %}\n    \"\"\"\n    if field:\n        context = Context({\n            'field': field,\n            'form_show_errors': True,\n            'form_show_labels': form_show_labels,\n        })\n        template = loader.get_template('%s/layout/prepended_appended_text.html' % get_template_pack())\n        context['crispy_prepended_text'] = prepend\n        context['crispy_appended_text'] = append\n\n        if not prepend and not append:\n            raise TypeError(\"Expected a prepend and/or append argument\")\n\n        context = context.flatten()\n\n    return template.render(context)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef as_crispy_form(form, template_pack=TEMPLATE_PACK, label_class=\"\", field_class=\"\"):\n    if isinstance(form, BaseFormSet):\n        template = uni_formset_template(template_pack)\n        c = Context({\n            'formset': form,\n            'form_show_errors': True,\n            'form_show_labels': True,\n            'label_class': label_class,\n            'field_class': field_class,\n        }).flatten()\n    else:\n        template = uni_form_template(template_pack)\n        c = Context({\n            'form': form,\n            'form_show_errors': True,\n            'form_show_labels': True,\n            'label_class': label_class,\n            'field_class': field_class,\n        }).flatten()\n\n    return template.render(c)", "response": "Returns a crispy form for the given form."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef as_crispy_errors(form, template_pack=TEMPLATE_PACK):\n    if isinstance(form, BaseFormSet):\n        template = get_template('%s/errors_formset.html' % template_pack)\n        c = Context({'formset': form}).flatten()\n    else:\n        template = get_template('%s/errors.html' % template_pack)\n        c = Context({'form': form}).flatten()\n\n    return template.render(c)", "response": "Render a form as a crispy - errors page."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef as_crispy_field(field, template_pack=TEMPLATE_PACK, label_class=\"\", field_class=\"\"):\n    if not isinstance(field, forms.BoundField) and settings.DEBUG:\n        raise CrispyError('|as_crispy_field got passed an invalid or inexistent field')\n\n    attributes = {\n        'field': field,\n        'form_show_errors': True,\n        'form_show_labels': True,\n        'label_class': label_class,\n        'field_class': field_class,\n    }\n    helper = getattr(field.form, 'helper', None)\n\n    template_path = None\n    if helper is not None:\n        attributes.update(helper.get_attributes(template_pack))\n        template_path = helper.field_template\n    if not template_path:\n        template_path = '%s/field.html' % template_pack\n    template = get_template(template_path)\n\n    c = Context(attributes).flatten()\n    return template.render(c)", "response": "Returns a crispy form field as a string."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a layout object of type LayoutClass with args and kwargs wrapped inside.", "response": "def wrapped_object(self, LayoutClass, fields, *args, **kwargs):\n        \"\"\"\n        Returns a layout object of type `LayoutClass` with `args` and `kwargs` that\n        wraps `fields` inside.\n        \"\"\"\n        if args:\n            if isinstance(fields, list):\n                fields = tuple(fields)\n            else:\n                fields = (fields,)\n\n            if LayoutClass in self.args_first:\n                arguments = args + fields\n            else:\n                arguments = fields + args\n\n            return LayoutClass(*arguments, **kwargs)\n        else:\n            if isinstance(fields, list):\n                return LayoutClass(*fields, **kwargs)\n            else:\n                return LayoutClass(fields, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pre_map(self, function):\n        if isinstance(self.slice, slice):\n            for i in range(*self.slice.indices(len(self.layout.fields))):\n                function(self.layout, i)\n\n        elif isinstance(self.slice, list):\n            # A list of pointers  Ex: [[[0, 0], 'div'], [[0, 2, 3], 'field_name']]\n            for pointer in self.slice:\n                position = pointer[0]\n\n                # If it's pointing first level\n                if len(position) == 1:\n                    function(self.layout, position[-1])\n                else:\n                    layout_object = self.layout.fields[position[0]]\n                    for i in position[1:-1]:\n                        layout_object = layout_object.fields[i]\n\n                    try:\n                        function(layout_object, position[-1])\n                    except IndexError:\n                        # We could avoid this exception, recalculating pointers.\n                        # However this case is most of the time an undesired behavior\n                        raise DynamicError(\"Trying to wrap a field within an already wrapped field, \\\n                            recheck your filter or layout\")", "response": "This method is called before the filter is applied to the layout object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwrapping every layout object pointed in self. slice under a LayoutClass instance with args and kwargs passed.", "response": "def wrap(self, LayoutClass, *args, **kwargs):\n        \"\"\"\n        Wraps every layout object pointed in `self.slice` under a `LayoutClass` instance with\n        `args` and `kwargs` passed.\n        \"\"\"\n        def wrap_object(layout_object, j):\n            layout_object.fields[j] = self.wrapped_object(\n                LayoutClass, layout_object.fields[j], *args, **kwargs\n            )\n\n        self.pre_map(wrap_object)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef wrap_once(self, LayoutClass, *args, **kwargs):\n        def wrap_object_once(layout_object, j):\n            if not isinstance(layout_object, LayoutClass):\n                layout_object.fields[j] = self.wrapped_object(\n                    LayoutClass, layout_object.fields[j], *args, **kwargs\n                )\n\n        self.pre_map(wrap_object_once)", "response": "Wraps every layout object pointed in self. slice under a LayoutClass instance with args and kwargs passed."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwrapping all layout objects pointed in self. slice together under a LayoutClass instance with args and kwargs passed.", "response": "def wrap_together(self, LayoutClass, *args, **kwargs):\n        \"\"\"\n        Wraps all layout objects pointed in `self.slice` together under a `LayoutClass`\n        instance with `args` and `kwargs` passed.\n        \"\"\"\n        if isinstance(self.slice, slice):\n            # The start of the slice is replaced\n            start = self.slice.start if self.slice.start is not None else 0\n            self.layout.fields[start] = self.wrapped_object(\n                LayoutClass, self.layout.fields[self.slice], *args, **kwargs\n            )\n\n            # The rest of places of the slice are removed, as they are included in the previous\n            for i in reversed(range(*self.slice.indices(len(self.layout.fields)))):\n                if i != start:\n                    del self.layout.fields[i]\n\n        elif isinstance(self.slice, list):\n            raise DynamicError(\"wrap_together doesn't work with filter, only with [] operator\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef map(self, function):\n        if isinstance(self.slice, slice):\n            for i in range(*self.slice.indices(len(self.layout.fields))):\n                function(self.layout.fields[i])\n\n        elif isinstance(self.slice, list):\n            # A list of pointers  Ex: [[[0, 0], 'div'], [[0, 2, 3], 'field_name']]\n            for pointer in self.slice:\n                position = pointer[0]\n\n                layout_object = self.layout.fields[position[0]]\n                for i in position[1:]:\n                    previous_layout_object = layout_object\n                    layout_object = layout_object.fields[i]\n\n                # If update_attrs is applied to a string, we call to its wrapping layout object\n                if (\n                    function.__name__ == 'update_attrs'\n                    and isinstance(layout_object, string_types)\n                ):\n                    function(previous_layout_object)\n                else:\n                    function(layout_object)", "response": "Applies function to the last layout object pointed in self. slice"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update_attributes(self, **original_kwargs):\n        def update_attrs(layout_object):\n            kwargs = original_kwargs.copy()\n            if hasattr(layout_object, 'attrs'):\n                if 'css_class' in kwargs:\n                    if 'class' in layout_object.attrs:\n                        layout_object.attrs['class'] += \" %s\" % kwargs.pop('css_class')\n                    else:\n                        layout_object.attrs['class'] = kwargs.pop('css_class')\n                layout_object.attrs.update(kwargs)\n\n        self.map(update_attrs)", "response": "Updates attributes of every layout object pointed in self. slice using kwargs\nTracingEnabled"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn all layout objects of the first level of depth", "response": "def all(self):\n        \"\"\"\n        Returns all layout objects of first level of depth\n        \"\"\"\n        self._check_layout()\n        return LayoutSlice(self.layout, slice(0, len(self.layout.fields), 1))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef filter(self, *LayoutClasses, **kwargs):\n        self._check_layout()\n        max_level = kwargs.pop('max_level', 0)\n        greedy = kwargs.pop('greedy', False)\n        filtered_layout_objects = self.layout.get_layout_objects(LayoutClasses, max_level=max_level, greedy=greedy)\n\n        return LayoutSlice(self.layout, filtered_layout_objects)", "response": "Returns a LayoutSlice pointing to layout objects of type LayoutClass"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a LayoutSlice pointing to fields with widgets of widget_type", "response": "def filter_by_widget(self, widget_type):\n        \"\"\"\n        Returns a LayoutSlice pointing to fields with widgets of `widget_type`\n        \"\"\"\n        self._check_layout_and_form()\n        layout_field_names = self.layout.get_field_names()\n\n        # Let's filter all fields with widgets like widget_type\n        filtered_fields = []\n        for pointer in layout_field_names:\n            if isinstance(self.form.fields[pointer[1]].widget, widget_type):\n                filtered_fields.append(pointer)\n\n        return LayoutSlice(self.layout, filtered_fields)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrender the layout of the specified form and context.", "response": "def render_layout(self, form, context, template_pack=TEMPLATE_PACK):\n        \"\"\"\n        Returns safe html of the rendering of the layout\n        \"\"\"\n        form.rendered_fields = set()\n        form.crispy_field_template = self.field_template\n\n        # This renders the specified Layout strictly\n        html = self.layout.render(\n            form,\n            self.form_style,\n            context,\n            template_pack=template_pack\n        )\n\n        # Rendering some extra fields if specified\n        if self.render_unmentioned_fields or self.render_hidden_fields or self.render_required_fields:\n            fields = set(form.fields.keys())\n            left_fields_to_render = fields - form.rendered_fields\n            for field in left_fields_to_render:\n                if (\n                    self.render_unmentioned_fields or\n                    self.render_hidden_fields and form.fields[field].widget.is_hidden or\n                    self.render_required_fields and form.fields[field].widget.is_required\n                ):\n                    html += render_field(\n                        field,\n                        form,\n                        self.form_style,\n                        context,\n                        template_pack=template_pack\n                    )\n\n        # If the user has Meta.fields defined, not included in the layout,\n        # we suppose they need to be rendered\n        if hasattr(form, 'Meta'):\n            if hasattr(form.Meta, 'fields'):\n                current_fields = tuple(getattr(form, 'fields', {}).keys())\n                meta_fields = getattr(form.Meta, 'fields')\n\n                fields_to_render = list_intersection(current_fields, meta_fields)\n                left_fields_to_render = list_difference(fields_to_render, form.rendered_fields)\n\n                for field in left_fields_to_render:\n                    # We still respect the configuration of the helper\n                    # regarding which fields to render\n                    if (\n                        self.render_unmentioned_fields or\n                        (self.render_hidden_fields and\n                         form.fields[field].widget.is_hidden) or\n                        (self.render_required_fields and\n                         form.fields[field].widget.is_required)\n                    ):\n                        html += render_field(field, form, self.form_style, context)\n\n        return mark_safe(html)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a dictionary of all attributes that are defined in this object.", "response": "def get_attributes(self, template_pack=TEMPLATE_PACK):\n        \"\"\"\n        Used by crispy_forms_tags to get helper attributes\n        \"\"\"\n        items = {\n            'form_method': self.form_method.strip(),\n            'form_tag': self.form_tag,\n            'form_style': self.form_style.strip(),\n            'form_show_errors': self.form_show_errors,\n            'help_text_inline': self.help_text_inline,\n            'error_text_inline': self.error_text_inline,\n            'html5_required': self.html5_required,\n            'form_show_labels': self.form_show_labels,\n            'disable_csrf': self.disable_csrf,\n            'label_class': self.label_class,\n            'field_class': self.field_class,\n            'include_media': self.include_media\n        }\n        \n        if template_pack == 'bootstrap4':\n            bootstrap_size_match = re.findall('col-(xl|lg|md|sm)-(\\d+)', self.label_class)\n            if bootstrap_size_match:\n                if template_pack == 'bootstrap4':\n                    offset_pattern = 'offset-%s-%s'\n                else:\n                    offset_pattern = 'col-%s-offset-%s'\n                items['bootstrap_checkbox_offsets'] = [offset_pattern % m for m in bootstrap_size_match]\n        else:\n            bootstrap_size_match = re.findall('col-(lg|md|sm|xs)-(\\d+)', self.label_class)\n            if bootstrap_size_match:\n                if template_pack == 'bootstrap4':\n                    offset_pattern = 'offset-%s-%s'\n                else:\n                    offset_pattern = 'col-%s-offset-%s'\n                items['bootstrap_checkbox_offsets'] = [offset_pattern % m for m in bootstrap_size_match]\n\n        items['attrs'] = {}\n        if self.attrs:\n            items['attrs'] = self.attrs.copy()\n        if self.form_action:\n            items['attrs']['action'] = self.form_action.strip()\n        if self.form_id:\n            items['attrs']['id'] = self.form_id.strip()\n        if self.form_class:\n            # uni_form TEMPLATE PACK has a uniForm class by default\n            if template_pack == 'uni_form':\n                items['attrs']['class'] = \"uniForm %s\" % self.form_class.strip()\n            else:\n                items['attrs']['class'] = self.form_class.strip()\n        else:\n            if template_pack == 'uni_form':\n                items['attrs']['class'] = self.attrs.get('class', '') + \" uniForm\"\n        if self.form_group_wrapper_class:\n            items['attrs']['form_group_wrapper_class'] = self.form_group_wrapper_class\n\n        items['flat_attrs'] = flatatt(items['attrs'])\n\n        if self.inputs:\n            items['inputs'] = self.inputs\n        if self.form_error_title:\n            items['form_error_title'] = self.form_error_title.strip()\n        if self.formset_error_title:\n            items['formset_error_title'] = self.formset_error_title.strip()\n\n        for attribute_name, value in self.__dict__.items():\n            if attribute_name not in items and attribute_name not in ['layout', 'inputs'] and not attribute_name.startswith('_'):\n                items[attribute_name] = value\n\n        return items"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef render_field(\n    field, form, form_style, context, template=None, labelclass=None,\n    layout_object=None, attrs=None, template_pack=TEMPLATE_PACK,\n    extra_context=None, **kwargs\n):\n    \"\"\"\n    Renders a django-crispy-forms field\n\n    :param field: Can be a string or a Layout object like `Row`. If it's a layout\n        object, we call its render method, otherwise we instantiate a BoundField\n        and render it using default template 'CRISPY_TEMPLATE_PACK/field.html'\n        The field is added to a list that the form holds called `rendered_fields`\n        to avoid double rendering fields.\n    :param form: The form/formset to which that field belongs to.\n    :param form_style: A way to pass style name to the CSS framework used.\n    :template: Template used for rendering the field.\n    :layout_object: If passed, it points to the Layout object that is being rendered.\n        We use it to store its bound fields in a list called `layout_object.bound_fields`\n    :attrs: Attributes for the field's widget\n    :template_pack: Name of the template pack to be used for rendering `field`\n    :extra_context: Dictionary to be added to context, added variables by the layout object\n    \"\"\"\n    added_keys = [] if extra_context is None else extra_context.keys()\n    with KeepContext(context, added_keys):\n        if field is None:\n            return ''\n\n        FAIL_SILENTLY = getattr(settings, 'CRISPY_FAIL_SILENTLY', True)\n\n        if hasattr(field, 'render'):\n            return field.render(\n                form, form_style, context, template_pack=template_pack,\n            )\n        else:\n            # In Python 2 form field names cannot contain unicode characters without ASCII mapping\n            if PY2:\n                # This allows fields to be unicode strings, always they don't use non ASCII\n                try:\n                    if isinstance(field, text_type):\n                        field = field.encode('ascii').decode()\n                    # If `field` is not unicode then we turn it into a unicode string, otherwise doing\n                    # str(field) would give no error and the field would not be resolved, causing confusion\n                    else:\n                        field = text_type(field)\n\n                except (UnicodeEncodeError, UnicodeDecodeError):\n                    raise Exception(\"Field '%s' is using forbidden unicode characters\" % field)\n\n        try:\n            # Injecting HTML attributes into field's widget, Django handles rendering these\n            bound_field = form[field]\n            field_instance = bound_field.field\n            if attrs is not None:\n                widgets = getattr(field_instance.widget, 'widgets', [field_instance.widget])\n\n                # We use attrs as a dictionary later, so here we make a copy\n                list_attrs = attrs\n                if isinstance(attrs, dict):\n                    list_attrs = [attrs] * len(widgets)\n\n                for index, (widget, attr) in enumerate(zip(widgets, list_attrs)):\n                    if hasattr(field_instance.widget, 'widgets'):\n                        if 'type' in attr and attr['type'] == \"hidden\":\n                            field_instance.widget.widgets[index] = field_instance.hidden_widget(attr)\n\n                        else:\n                            field_instance.widget.widgets[index].attrs.update(attr)\n                    else:\n                        if 'type' in attr and attr['type'] == \"hidden\":\n                            field_instance.widget = field_instance.hidden_widget(attr)\n\n                        else:\n                            field_instance.widget.attrs.update(attr)\n\n        except KeyError:\n            if not FAIL_SILENTLY:\n                raise Exception(\"Could not resolve form field '%s'.\" % field)\n            else:\n                field_instance = None\n                logging.warning(\"Could not resolve form field '%s'.\" % field, exc_info=sys.exc_info())\n\n        if hasattr(form, 'rendered_fields'):\n            if not field in form.rendered_fields:\n                form.rendered_fields.add(field)\n            else:\n                if not FAIL_SILENTLY:\n                    raise Exception(\"A field should only be rendered once: %s\" % field)\n                else:\n                    logging.warning(\"A field should only be rendered once: %s\" % field, exc_info=sys.exc_info())\n\n        if field_instance is None:\n            html = ''\n        else:\n            if template is None:\n                if form.crispy_field_template is None:\n                    template = default_field_template(template_pack)\n                else:   # FormHelper.field_template set\n                    template = get_template(form.crispy_field_template)\n            else:\n                template = get_template(template)\n\n            # We save the Layout object's bound fields in the layout object's `bound_fields` list\n            if layout_object is not None:\n                if hasattr(layout_object, 'bound_fields') and isinstance(layout_object.bound_fields, list):\n                    layout_object.bound_fields.append(bound_field)\n                else:\n                    layout_object.bound_fields = [bound_field]\n\n            context.update({\n                'field': bound_field,\n                'labelclass': labelclass,\n                'flat_attrs': flatatt(attrs if isinstance(attrs, dict) else {}),\n            })\n            if extra_context is not None:\n                context.update(extra_context)\n\n            context = context.flatten()\n            html = template.render(context)\n\n        return html", "response": "Renders a single field in django - crispy - forms."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef flatatt(attrs):\n    return _flatatt({k.replace('_', '-'): v for k, v in attrs.items()})", "response": "Convert a dictionary of attributes to a single string."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nrenders a form and returns its HTML output.", "response": "def render_crispy_form(form, helper=None, context=None):\n    \"\"\"\n    Renders a form and returns its HTML output.\n\n    This function wraps the template logic in a function easy to use in a Django view.\n    \"\"\"\n    from crispy_forms.templatetags.crispy_forms_tags import CrispyFormNode\n\n    if helper is not None:\n        node = CrispyFormNode('form', 'helper')\n    else:\n        node = CrispyFormNode('form', None)\n\n    node_context = Context(context)\n    node_context.update({\n        'form': form,\n        'helper': helper\n    })\n\n    return node.render(node_context)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef list_difference(left, right):\n    blocked = set(right)\n    difference = []\n    for item in left:\n        if item not in blocked:\n            blocked.add(item)\n            difference.append(item)\n    return difference", "response": "Take the not - in - place difference of two lists left and right."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrender the current object in the specified mode.", "response": "def render(self, mode=None, vertices=-1, *, first=0, instances=1) -> None:\n        '''\n            The render primitive (mode) must be the same as\n            the input primitive of the GeometryShader.\n\n            Args:\n                mode (int): By default :py:data:`TRIANGLES` will be used.\n                vertices (int): The number of vertices to transform.\n\n            Keyword Args:\n                first (int): The index of the first vertex to start with.\n                instances (int): The number of instances.\n        '''\n\n        if mode is None:\n            mode = TRIANGLES\n\n        self.mglo.render(mode, vertices, first, instances)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrender indirect drawing commands.", "response": "def render_indirect(self, buffer, mode=None, count=-1, *, first=0) -> None:\n        '''\n            The render primitive (mode) must be the same as\n            the input primitive of the GeometryShader.\n\n            The draw commands are 5 integers: (count, instanceCount, firstIndex, baseVertex, baseInstance).\n\n            Args:\n                buffer (Buffer): Indirect drawing commands.\n                mode (int): By default :py:data:`TRIANGLES` will be used.\n                count (int): The number of draws.\n\n            Keyword Args:\n                first (int): The index of the first indirect draw command.\n        '''\n\n        if mode is None:\n            mode = TRIANGLES\n\n        self.mglo.render_indirect(buffer.mglo, mode, count, first)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntransforms vertices Stores the output in a single buffer.", "response": "def transform(self, buffer, mode=None, vertices=-1, *, first=0, instances=1) -> None:\n        '''\n            Transform vertices.\n            Stores the output in a single buffer.\n            The transform primitive (mode) must be the same as\n            the input primitive of the GeometryShader.\n\n            Args:\n                buffer (Buffer): The buffer to store the output.\n                mode (int): By default :py:data:`POINTS` will be used.\n                vertices (int): The number of vertices to transform.\n\n            Keyword Args:\n                first (int): The index of the first vertex to start with.\n                instances (int): The number of instances.\n        '''\n\n        if mode is None:\n            mode = POINTS\n\n        self.mglo.transform(buffer.mglo, mode, vertices, first, instances)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef bind(self, attribute, cls, buffer, fmt, *, offset=0, stride=0, divisor=0, normalize=False) -> None:\n        '''\n            Bind individual attributes to buffers.\n\n            Args:\n                location (int): The attribute location.\n                cls (str): The attribute class. Valid values are ``f``, ``i`` or ``d``.\n                buffer (Buffer): The buffer.\n                format (str): The buffer format.\n\n            Keyword Args:\n                offset (int): The offset.\n                stride (int): The stride.\n                divisor (int): The divisor.\n                normalize (bool): The normalize parameter, if applicable.\n        '''\n\n        self.mglo.bind(attribute, cls, buffer.mglo, fmt, offset, stride, divisor, normalize)", "response": "Binds individual attributes to buffers."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_context(require=None) -> Context:\n    '''\n        Create a ModernGL context by loading OpenGL functions from an existing OpenGL context.\n        An OpenGL context must exists. If rendering is done without a window please use the\n        :py:func:`create_standalone_context` instead.\n\n        Example::\n\n            # Accept the current context version\n            ctx = moderngl.create_context()\n\n            # Require at least OpenGL 4.3\n            ctx = moderngl.create_context(require=430)\n\n        Keyword Arguments:\n            require (int): OpenGL version code.\n\n        Returns:\n            :py:class:`Context` object\n    '''\n\n    ctx = Context.__new__(Context)\n    ctx.mglo, ctx.version_code = mgl.create_context()\n    ctx._screen = ctx.detect_framebuffer(0)\n    ctx.fbo = ctx.detect_framebuffer()\n    ctx.mglo.fbo = ctx.fbo.mglo\n    ctx._info = None\n    ctx.extra = None\n\n    if require is not None and ctx.version_code < require:\n        raise ValueError('Requested OpenGL version {}, got version {}'.format(\n            require, ctx.version_code))\n\n    return ctx", "response": "Create a ModernGL context by loading OpenGL functions from an existing OpenGL context."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_standalone_context(require=None, **settings) -> 'Context':\n    '''\n        Create a standalone ModernGL context.\n\n        Example::\n\n            # Create a context with highest possible supported version\n            ctx = moderngl.create_context()\n\n            # Require at least OpenGL 4.3\n            ctx = moderngl.create_context(require=430)\n\n        Keyword Arguments:\n            require (int): OpenGL version code.\n\n        Returns:\n            :py:class:`Context` object\n    '''\n\n    backend = os.environ.get('MODERNGL_BACKEND')\n    if backend is not None:\n        settings['backend'] = backend\n\n    ctx = Context.__new__(Context)\n    ctx.mglo, ctx.version_code = mgl.create_standalone_context(settings)\n    ctx._screen = None\n    ctx.fbo = None\n    ctx._info = None\n    ctx.extra = None\n\n    if require is not None and ctx.version_code < require:\n        raise ValueError('Requested OpenGL version {}, got version {}'.format(\n            require, ctx.version_code))\n\n    return ctx", "response": "Create a standalone ModernGL context."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef info(self) -> Dict[str, object]:\n        '''\n            dict: Information about the context\n\n            Example::\n\n                {\n                    'GL_VENDOR': 'NVIDIA Corporation', \n                    'GL_RENDERER': 'NVIDIA GeForce GT 650M OpenGL Engine', \n                    'GL_VERSION': '4.1 NVIDIA-10.32.0 355.11.10.10.40.102', \n                    'GL_POINT_SIZE_RANGE': (1.0, 2047.0), \n                    'GL_SMOOTH_LINE_WIDTH_RANGE': (0.5, 1.0), \n                    'GL_ALIASED_LINE_WIDTH_RANGE': (1.0, 1.0), \n                    'GL_POINT_FADE_THRESHOLD_SIZE': 1.0, \n                    'GL_POINT_SIZE_GRANULARITY': 0.125, \n                    'GL_SMOOTH_LINE_WIDTH_GRANULARITY': 0.125, \n                    'GL_MIN_PROGRAM_TEXEL_OFFSET': -8.0, \n                    'GL_MAX_PROGRAM_TEXEL_OFFSET': 7.0, \n                    'GL_MINOR_VERSION': 1, \n                    'GL_MAJOR_VERSION': 4, \n                    'GL_SAMPLE_BUFFERS': 0, \n                    'GL_SUBPIXEL_BITS': 8, \n                    'GL_CONTEXT_PROFILE_MASK': 1, \n                    'GL_UNIFORM_BUFFER_OFFSET_ALIGNMENT': 256, \n                    'GL_DOUBLEBUFFER': False, \n                    'GL_STEREO': False, \n                    'GL_MAX_VIEWPORT_DIMS': (16384, 16384), \n                    'GL_MAX_3D_TEXTURE_SIZE': 2048, \n                    'GL_MAX_ARRAY_TEXTURE_LAYERS': 2048, \n                    'GL_MAX_CLIP_DISTANCES': 8, \n                    'GL_MAX_COLOR_ATTACHMENTS': 8, \n                    'GL_MAX_COLOR_TEXTURE_SAMPLES': 8, \n                    'GL_MAX_COMBINED_FRAGMENT_UNIFORM_COMPONENTS': 233472, \n                    'GL_MAX_COMBINED_GEOMETRY_UNIFORM_COMPONENTS': 231424, \n                    'GL_MAX_COMBINED_TEXTURE_IMAGE_UNITS': 80, \n                    'GL_MAX_COMBINED_UNIFORM_BLOCKS': 70, \n                    'GL_MAX_COMBINED_VERTEX_UNIFORM_COMPONENTS': 233472, \n                    'GL_MAX_CUBE_MAP_TEXTURE_SIZE': 16384, \n                    'GL_MAX_DEPTH_TEXTURE_SAMPLES': 8, \n                    'GL_MAX_DRAW_BUFFERS': 8, \n                    'GL_MAX_DUAL_SOURCE_DRAW_BUFFERS': 1, \n                    'GL_MAX_ELEMENTS_INDICES': 150000, \n                    'GL_MAX_ELEMENTS_VERTICES': 1048575, \n                    'GL_MAX_FRAGMENT_INPUT_COMPONENTS': 128, \n                    'GL_MAX_FRAGMENT_UNIFORM_COMPONENTS': 4096, \n                    'GL_MAX_FRAGMENT_UNIFORM_VECTORS': 1024, \n                    'GL_MAX_FRAGMENT_UNIFORM_BLOCKS': 14, \n                    'GL_MAX_GEOMETRY_INPUT_COMPONENTS': 128, \n                    'GL_MAX_GEOMETRY_OUTPUT_COMPONENTS': 128, \n                    'GL_MAX_GEOMETRY_TEXTURE_IMAGE_UNITS': 16, \n                    'GL_MAX_GEOMETRY_UNIFORM_BLOCKS': 14, \n                    'GL_MAX_GEOMETRY_UNIFORM_COMPONENTS': 2048, \n                    'GL_MAX_INTEGER_SAMPLES': 1, \n                    'GL_MAX_SAMPLES': 8, \n                    'GL_MAX_RECTANGLE_TEXTURE_SIZE': 16384, \n                    'GL_MAX_RENDERBUFFER_SIZE': 16384, \n                    'GL_MAX_SAMPLE_MASK_WORDS': 1, \n                    'GL_MAX_SERVER_WAIT_TIMEOUT': -1, \n                    'GL_MAX_TEXTURE_BUFFER_SIZE': 134217728, \n                    'GL_MAX_TEXTURE_IMAGE_UNITS': 16, \n                    'GL_MAX_TEXTURE_LOD_BIAS': 15, \n                    'GL_MAX_TEXTURE_SIZE': 16384, \n                    'GL_MAX_UNIFORM_BUFFER_BINDINGS': 70, \n                    'GL_MAX_UNIFORM_BLOCK_SIZE': 65536, \n                    'GL_MAX_VARYING_COMPONENTS': 0, \n                    'GL_MAX_VARYING_VECTORS': 31, \n                    'GL_MAX_VARYING_FLOATS': 0, \n                    'GL_MAX_VERTEX_ATTRIBS': 16, \n                    'GL_MAX_VERTEX_TEXTURE_IMAGE_UNITS': 16, \n                    'GL_MAX_VERTEX_UNIFORM_COMPONENTS': 4096, \n                    'GL_MAX_VERTEX_UNIFORM_VECTORS': 1024, \n                    'GL_MAX_VERTEX_OUTPUT_COMPONENTS': 128, \n                    'GL_MAX_VERTEX_UNIFORM_BLOCKS': 14, \n                    'GL_MAX_VERTEX_ATTRIB_RELATIVE_OFFSET': 0, \n                    'GL_MAX_VERTEX_ATTRIB_BINDINGS': 0, \n                    'GL_VIEWPORT_BOUNDS_RANGE': (-32768, 32768), \n                    'GL_VIEWPORT_SUBPIXEL_BITS': 0, \n                    'GL_MAX_VIEWPORTS': 16\n                }\n        '''\n\n        if self._info is None:\n            self._info = self.mglo.info\n\n        return self._info", "response": "Return a dictionary of information about the context containing the available context types."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncopying the contents of src into dst.", "response": "def copy_buffer(self, dst, src, size=-1, *, read_offset=0, write_offset=0) -> None:\n        '''\n            Copy buffer content.\n\n            Args:\n                dst (Buffer): The destination buffer.\n                src (Buffer): The source buffer.\n                size (int): The number of bytes to copy.\n\n            Keyword Args:\n                read_offset (int): The read offset.\n                write_offset (int): The write offset.\n        '''\n\n        self.mglo.copy_buffer(dst.mglo, src.mglo, size, read_offset, write_offset)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncopy a framebuffer to another framebuffer.", "response": "def copy_framebuffer(self, dst, src) -> None:\n        '''\n            Copy framebuffer content.\n\n            Use this method to:\n\n                - blit framebuffers.\n                - copy framebuffer content into a texture.\n                - downsample framebuffers. (it will allow to read the framebuffer's content)\n                - downsample a framebuffer directly to a texture.\n\n            Args:\n                dst (Framebuffer or Texture): Destination framebuffer or texture.\n                src (Framebuffer): Source framebuffer.\n        '''\n\n        self.mglo.copy_framebuffer(dst.mglo, src.mglo)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndetect the framebuffer for the given glo.", "response": "def detect_framebuffer(self, glo=None) -> 'Framebuffer':\n        '''\n            Detect framebuffer.\n\n            Args:\n                glo (int): Framebuffer object.\n\n            Returns:\n                :py:class:`Framebuffer` object\n        '''\n\n        res = Framebuffer.__new__(Framebuffer)\n        res.mglo, res._size, res._samples, res._glo = self.mglo.detect_framebuffer(glo)\n        res._color_attachments = None\n        res._depth_attachment = None\n        res.ctx = self\n        res.extra = None\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a new buffer object.", "response": "def buffer(self, data=None, *, reserve=0, dynamic=False) -> Buffer:\n        '''\n            Create a :py:class:`Buffer` object.\n\n            Args:\n                data (bytes): Content of the new buffer.\n\n            Keyword Args:\n                reserve (int): The number of bytes to reserve.\n                dynamic (bool): Treat buffer as dynamic.\n\n            Returns:\n                :py:class:`Buffer` object\n        '''\n\n        if type(reserve) is str:\n            reserve = mgl.strsize(reserve)\n\n        res = Buffer.__new__(Buffer)\n        res.mglo, res._size, res._glo = self.mglo.buffer(data, reserve, dynamic)\n        res._dynamic = dynamic\n        res.ctx = self\n        res.extra = None\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a new texture object.", "response": "def texture(self, size, components, data=None, *, samples=0, alignment=1, dtype='f1') -> 'Texture':\n        '''\n            Create a :py:class:`Texture` object.\n\n            Args:\n                size (tuple): The width and height of the texture.\n                components (int): The number of components 1, 2, 3 or 4.\n                data (bytes): Content of the texture.\n\n            Keyword Args:\n                samples (int): The number of samples. Value 0 means no multisample format.\n                alignment (int): The byte alignment 1, 2, 4 or 8.\n                dtype (str): Data type.\n\n            Returns:\n                :py:class:`Texture` object\n        '''\n\n        res = Texture.__new__(Texture)\n        res.mglo, res._glo = self.mglo.texture(size, components, data, samples, alignment, dtype)\n        res._size = size\n        res._components = components\n        res._samples = samples\n        res._dtype = dtype\n        res._depth = False\n        res.ctx = self\n        res.extra = None\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a new array of texture objects.", "response": "def texture_array(self, size, components, data=None, *, alignment=1, dtype='f1') -> 'TextureArray':\n        '''\n            Create a :py:class:`TextureArray` object.\n\n            Args:\n                size (tuple): The ``(width, height, layers)`` of the texture.\n                components (int): The number of components 1, 2, 3 or 4.\n                data (bytes): Content of the texture. The size must be ``(width, height * layers)``\n                              so each layer is stacked vertically.\n\n            Keyword Args:\n                alignment (int): The byte alignment 1, 2, 4 or 8.\n                dtype (str): Data type.\n\n            Returns:\n                :py:class:`Texture3D` object\n        '''\n\n        res = TextureArray.__new__(TextureArray)\n        res.mglo, res._glo = self.mglo.texture_array(size, components, data, alignment, dtype)\n        res._size = size\n        res._components = components\n        res._dtype = dtype\n        res.ctx = self\n        res.extra = None\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a new instance of the object containing a 3D texture.", "response": "def texture3d(self, size, components, data=None, *, alignment=1, dtype='f1') -> 'Texture3D':\n        '''\n            Create a :py:class:`Texture3D` object.\n\n            Args:\n                size (tuple): The width, height and depth of the texture.\n                components (int): The number of components 1, 2, 3 or 4.\n                data (bytes): Content of the texture.\n\n            Keyword Args:\n                alignment (int): The byte alignment 1, 2, 4 or 8.\n                dtype (str): Data type.\n\n            Returns:\n                :py:class:`Texture3D` object\n        '''\n\n        res = Texture3D.__new__(Texture3D)\n        res.mglo, res._glo = self.mglo.texture3d(size, components, data, alignment, dtype)\n        res.ctx = self\n        res.extra = None\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new texture cube with the specified size components and data.", "response": "def texture_cube(self, size, components, data=None, *, alignment=1, dtype='f1') -> 'TextureCube':\n        '''\n            Create a :py:class:`TextureCube` object.\n\n            Args:\n                size (tuple): The width, height of the texture. Each side of the cube will have this size.\n                components (int): The number of components 1, 2, 3 or 4.\n                data (bytes): Content of the texture.\n\n            Keyword Args:\n                alignment (int): The byte alignment 1, 2, 4 or 8.\n                dtype (str): Data type.\n\n            Returns:\n                :py:class:`TextureCube` object\n        '''\n\n        res = TextureCube.__new__(TextureCube)\n        res.mglo, res._glo = self.mglo.texture_cube(size, components, data, alignment, dtype)\n        res._size = size\n        res._components = components\n        res._dtype = dtype\n        res.ctx = self\n        res.extra = None\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef depth_texture(self, size, data=None, *, samples=0, alignment=4) -> 'Texture':\n        '''\n            Create a :py:class:`Texture` object.\n\n            Args:\n                size (tuple): The width and height of the texture.\n                data (bytes): Content of the texture.\n\n            Keyword Args:\n                samples (int): The number of samples. Value 0 means no multisample format.\n                alignment (int): The byte alignment 1, 2, 4 or 8.\n\n            Returns:\n                :py:class:`Texture` object\n        '''\n\n        res = Texture.__new__(Texture)\n        res.mglo, res._glo = self.mglo.depth_texture(size, data, samples, alignment)\n        res._size = size\n        res._components = 1\n        res._samples = samples\n        res._dtype = 'f4'\n        res._depth = True\n        res.ctx = self\n        res.extra = None\n        return res", "response": "Create a new depth texture."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef vertex_array(self, program, content,\n                     index_buffer=None, index_element_size=4, *, skip_errors=False) -> 'VertexArray':\n        '''\n            Create a :py:class:`VertexArray` object.\n\n            Args:\n                program (Program): The program used when rendering.\n                content (list): A list of (buffer, format, attributes). See :ref:`buffer-format-label`.\n                index_buffer (Buffer): An index buffer.\n\n            Keyword Args:\n                index_element_size (int): byte size of each index element, 1, 2 or 4.\n                skip_errors (bool): Ignore skip_errors varyings.\n\n            Returns:\n                :py:class:`VertexArray` object\n        '''\n        members = program._members\n        index_buffer_mglo = None if index_buffer is None else index_buffer.mglo\n        content = tuple((a.mglo, b) + tuple(getattr(members.get(x), 'mglo', None) for x in c) for a, b, *c in content)\n\n        res = VertexArray.__new__(VertexArray)\n        res.mglo, res._glo = self.mglo.vertex_array(program.mglo, content, index_buffer_mglo,\n                                                    index_element_size, skip_errors)\n        res._program = program\n        res._index_buffer = index_buffer\n        res._index_element_size = index_element_size\n        res.ctx = self\n        res.extra = None\n        return res", "response": "Create a vertex array from a list of content."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef simple_vertex_array(self, program, buffer, *attributes,\n                            index_buffer=None, index_element_size=4) -> 'VertexArray':\n        '''\n            Create a :py:class:`VertexArray` object.\n\n            Args:\n                program (Program): The program used when rendering.\n                buffer (Buffer): The buffer.\n                attributes (list): A list of attribute names.\n\n            Keyword Args:\n                index_element_size (int): byte size of each index element, 1, 2 or 4.\n                index_buffer (Buffer): An index buffer.\n\n            Returns:\n                :py:class:`VertexArray` object\n        '''\n\n        if type(buffer) is list:\n            raise SyntaxError('Change simple_vertex_array to vertex_array')\n\n        content = [(buffer, detect_format(program, attributes)) + attributes]\n        return self.vertex_array(program, content, index_buffer, index_element_size)", "response": "Create a simple vertex array."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a program that draws the entire tree of resources.", "response": "def program(self, *, vertex_shader, fragment_shader=None, geometry_shader=None,\n                tess_control_shader=None, tess_evaluation_shader=None, varyings=()) -> 'Program':\n        '''\n            Create a :py:class:`Program` object.\n\n            Only linked programs will be returned.\n\n            A single shader in the `shaders` parameter is also accepted.\n            The varyings are only used when a transform program is created.\n\n            Args:\n                shaders (list): A list of :py:class:`Shader` objects.\n                varyings (list): A list of varying names.\n\n            Returns:\n                :py:class:`Program` object\n        '''\n\n        if type(varyings) is str:\n            varyings = (varyings,)\n\n        varyings = tuple(varyings)\n\n        res = Program.__new__(Program)\n        res.mglo, ls1, ls2, ls3, ls4, ls5, res._subroutines, res._geom, res._glo = self.mglo.program(\n            vertex_shader, fragment_shader, geometry_shader, tess_control_shader, tess_evaluation_shader,\n            varyings\n        )\n\n        members = {}\n\n        for item in ls1:\n            obj = Attribute.__new__(Attribute)\n            obj.mglo, obj._location, obj._array_length, obj._dimension, obj._shape, obj._name = item\n            members[obj.name] = obj\n\n        for item in ls2:\n            obj = Varying.__new__(Varying)\n            obj._number, obj._array_length, obj._dimension, obj._name = item\n            members[obj.name] = obj\n\n        for item in ls3:\n            obj = Uniform.__new__(Uniform)\n            obj.mglo, obj._location, obj._array_length, obj._dimension, obj._name = item\n            members[obj.name] = obj\n\n        for item in ls4:\n            obj = UniformBlock.__new__(UniformBlock)\n            obj.mglo, obj._index, obj._size, obj._name = item\n            members[obj.name] = obj\n\n        for item in ls5:\n            obj = Subroutine.__new__(Subroutine)\n            obj._index, obj._name = item\n            members[obj.name] = obj\n\n        res._members = members\n        res.ctx = self\n        res.extra = None\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef query(self, *, samples=False, any_samples=False, time=False, primitives=False) -> 'Query':\n        '''\n            Create a :py:class:`Query` object.\n\n            Keyword Args:\n                samples (bool): Query ``GL_SAMPLES_PASSED`` or not.\n                any_samples (bool): Query ``GL_ANY_SAMPLES_PASSED`` or not.\n                time (bool): Query ``GL_TIME_ELAPSED`` or not.\n                primitives (bool): Query ``GL_PRIMITIVES_GENERATED`` or not.\n        '''\n\n        res = Query.__new__(Query)\n        res.mglo = self.mglo.query(samples, any_samples, time, primitives)\n        res.crender = None\n\n        if samples or any_samples:\n            res.crender = ConditionalRender.__new__(ConditionalRender)\n            res.crender.mglo = res.mglo\n\n        res.ctx = self\n        res.extra = None\n        return res", "response": "Query the cache for the current user."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef scope(self, framebuffer, enable_only=None, *, textures=(), uniform_buffers=(), storage_buffers=()) -> 'Scope':\n        '''\n            Create a :py:class:`Scope` object.\n\n            Args:\n                framebuffer (Framebuffer): The framebuffer to use when entering.\n                enable_only (int): The enable_only flags to set when entering.\n\n            Keyword Args:\n                textures (list): List of (texture, binding) tuples.\n                uniform_buffers (list): List of (buffer, binding) tuples.\n                storage_buffers (list): List of (buffer, binding) tuples.\n        '''\n\n        textures = tuple((tex.mglo, idx) for tex, idx in textures)\n        uniform_buffers = tuple((buf.mglo, idx) for buf, idx in uniform_buffers)\n        storage_buffers = tuple((buf.mglo, idx) for buf, idx in storage_buffers)\n\n        res = Scope.__new__(Scope)\n        res.mglo = self.mglo.scope(framebuffer.mglo, enable_only, textures, uniform_buffers, storage_buffers)\n        res.ctx = self\n        res.extra = None\n        return res", "response": "Create a new Scope object that is a copy of the current context."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef simple_framebuffer(self, size, components=4, *, samples=0, dtype='f1') -> 'Framebuffer':\n        '''\n            A :py:class:`Framebuffer` is a collection of buffers that can be used as the destination for rendering.\n            The buffers for Framebuffer objects reference images from either Textures or Renderbuffers.\n\n            Args:\n                size (tuple): The width and height of the renderbuffer.\n                components (int): The number of components 1, 2, 3 or 4.\n\n            Keyword Args:\n                samples (int): The number of samples. Value 0 means no multisample format.\n                dtype (str): Data type.\n\n            Returns:\n                :py:class:`Framebuffer` object\n        '''\n\n        return self.framebuffer(\n            self.renderbuffer(size, components, samples=samples, dtype=dtype),\n            self.depth_renderbuffer(size, samples=samples),\n        )", "response": "A simple Framebuffer object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef framebuffer(self, color_attachments=(), depth_attachment=None) -> 'Framebuffer':\n        '''\n            A :py:class:`Framebuffer` is a collection of buffers that can be used as the destination for rendering.\n            The buffers for Framebuffer objects reference images from either Textures or Renderbuffers.\n\n            Args:\n                color_attachments (list): A list of :py:class:`Texture` or :py:class:`Renderbuffer` objects.\n                depth_attachment (Renderbuffer or Texture): The depth attachment.\n\n            Returns:\n                :py:class:`Framebuffer` object\n        '''\n\n        if type(color_attachments) is Texture or type(color_attachments) is Renderbuffer:\n            color_attachments = (color_attachments,)\n\n        ca_mglo = tuple(x.mglo for x in color_attachments)\n        da_mglo = None if depth_attachment is None else depth_attachment.mglo\n\n        res = Framebuffer.__new__(Framebuffer)\n        res.mglo, res._size, res._samples, res._glo = self.mglo.framebuffer(ca_mglo, da_mglo)\n        res._color_attachments = tuple(color_attachments)\n        res._depth_attachment = depth_attachment\n        res.ctx = self\n        res.extra = None\n        return res", "response": "A method to create a new Framebuffer object that can be used as the destination for rendering."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef renderbuffer(self, size, components=4, *, samples=0, dtype='f1') -> 'Renderbuffer':\n        '''\n            :py:class:`Renderbuffer` objects are OpenGL objects that contain images.\n            They are created and used specifically with :py:class:`Framebuffer` objects.\n\n            Args:\n                size (tuple): The width and height of the renderbuffer.\n                components (int): The number of components 1, 2, 3 or 4.\n\n            Keyword Args:\n                samples (int): The number of samples. Value 0 means no multisample format.\n                dtype (str): Data type.\n\n            Returns:\n                :py:class:`Renderbuffer` object\n        '''\n\n        res = Renderbuffer.__new__(Renderbuffer)\n        res.mglo, res._glo = self.mglo.renderbuffer(size, components, samples, dtype)\n        res._size = size\n        res._components = components\n        res._samples = samples\n        res._dtype = dtype\n        res._depth = False\n        res.ctx = self\n        res.extra = None\n        return res", "response": "Create a new Renderbuffer object that contains images."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a depth renderbuffer object.", "response": "def depth_renderbuffer(self, size, *, samples=0) -> 'Renderbuffer':\n        '''\n            :py:class:`Renderbuffer` objects are OpenGL objects that contain images.\n            They are created and used specifically with :py:class:`Framebuffer` objects.\n\n            Args:\n                size (tuple): The width and height of the renderbuffer.\n\n            Keyword Args:\n                samples (int): The number of samples. Value 0 means no multisample format.\n\n            Returns:\n                :py:class:`Renderbuffer` object\n        '''\n\n        res = Renderbuffer.__new__(Renderbuffer)\n        res.mglo, res._glo = self.mglo.depth_renderbuffer(size, samples)\n        res._size = size\n        res._components = 1\n        res._samples = samples\n        res._dtype = 'f4'\n        res._depth = True\n        res.ctx = self\n        res.extra = None\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a sampler object for the current context and return it.", "response": "def sampler(self, repeat_x=True, repeat_y=True, repeat_z=True, filter=None, anisotropy=1.0,\n                compare_func='?', border_color=None, min_lod=-1000.0, max_lod=1000.0) -> Sampler:\n        '''\n            Create a :py:class:`Sampler` object.\n\n            Keyword Arguments:\n                repeat_x (bool): Repeat texture on x\n                repeat_y (bool): Repeat texture on y\n                repeat_z (bool): Repeat texture on z\n                filter (tuple): The min and max filter\n                anisotropy (float): Number of samples for anisotropic filtering. Any value greater than 1.0 counts as a use of anisotropic filtering\n                compare_func: Compare function for depth textures\n                border_color (tuple): The (r, g, b, a) color for the texture border.\n                                      When this value is set the ``repeat_`` values are overriden\n                                      setting the texture wrap to return the border color when outside ``[0, 1]`` range.\n                min_lod (float): Minimum level-of-detail parameter (Default ``-1000.0``).\n                                 This floating-point value limits the selection of highest resolution mipmap (lowest mipmap level)\n                max_lod (float): Minimum level-of-detail parameter (Default ``1000.0``).\n                                 This floating-point value limits the selection of the lowest resolution mipmap (highest mipmap level)\n        '''\n\n        res = Sampler.__new__(Sampler)\n        res.mglo, res._glo = self.mglo.sampler()\n        res.ctx = self\n        res.repeat_x = repeat_x\n        res.repeat_y = repeat_y\n        res.repeat_z = repeat_z\n        res.filter = filter or (9729, 9729)\n        res.anisotropy = anisotropy\n        res.compare_func = compare_func\n        if border_color:\n            res.border_color = border_color\n        res.min_lod = min_lod\n        res.max_lod = max_lod\n        res.extra = None\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef core_profile_check(self) -> None:\n        '''\n            Core profile check.\n\n            FOR DEBUG PURPOSES ONLY\n        '''\n\n        profile_mask = self.info['GL_CONTEXT_PROFILE_MASK']\n        if profile_mask != 1:\n            warnings.warn('The window should request a CORE OpenGL profile')\n\n        version_code = self.version_code\n        if not version_code:\n            major, minor = map(int, self.info['GL_VERSION'].split('.', 2)[:2])\n            version_code = major * 100 + minor * 10\n\n        if version_code < 330:\n            warnings.warn('The window should support OpenGL 3.3+ (version_code=%d)' % version_code)", "response": "Core profile check.\n\n            FOR DEBUG PURPOSES ONLY"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nkeys event callback for glfw. Translates and forwards keyboard event to :py:func:`keyboard_event` Args: window: Window event origin key: The key that was pressed or released. scancode: The system-specific scancode of the key. action: GLFW_PRESS, GLFW_RELEASE or GLFW_REPEAT mods: Bit field describing which modifier keys were held down.", "response": "def key_event_callback(self, window, key, scancode, action, mods):\r\n        \"\"\"\r\n        Key event callback for glfw.\r\n        Translates and forwards keyboard event to :py:func:`keyboard_event`\r\n\r\n        Args:\r\n            window: Window event origin\r\n            key: The key that was pressed or released.\r\n            scancode: The system-specific scancode of the key.\r\n            action: GLFW_PRESS, GLFW_RELEASE or GLFW_REPEAT\r\n            mods: Bit field describing which modifier keys were held down.\r\n        \"\"\"\r\n        if key == self.keys.ESCAPE:\r\n            self.close()\r\n\r\n        self.example.key_event(key, action)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef mouse_event_callback(self, window, xpos, ypos):\r\n        # screen coordinates relative to the top-left corner\r\n        self.example.mouse_position_event(xpos, ypos)", "response": "This is the main event callback from glfw.\r\n           ."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef mouse_button_callback(self, window, button, action, mods):\r\n        # Offset button index by 1 to make it match the other libraries\r\n        button += 1\r\n        # Support left and right mouse button for now\r\n        if button not in [1, 2]:\r\n            return\r\n\r\n        xpos, ypos = glfw.get_cursor_pos(self.window)\r\n\r\n        if action == glfw.PRESS:\r\n            self.example.mouse_press_event(xpos, ypos, button)\r\n        else:\r\n            self.example.mouse_release_event(xpos, ypos, button)", "response": "Handle mouse button events and forward them to the example"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwriting the data to count equal parts.", "response": "def write_chunks(self, data, start, step, count) -> None:\n        '''\n            Split data to count equal parts.\n\n            Write the chunks using offsets calculated from start, step and stop.\n\n            Args:\n                data (bytes): The data.\n                start (int): First offset.\n                step (int): Offset increment.\n                count (int): The number of offsets.\n        '''\n\n        self.mglo.write_chunks(data, start, step, count)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read(self, size=-1, *, offset=0) -> bytes:\n        '''\n            Read the content.\n\n            Args:\n                size (int): The size. Value ``-1`` means all.\n\n            Keyword Args:\n                offset (int): The offset.\n\n            Returns:\n                bytes\n        '''\n\n        return self.mglo.read(size, offset)", "response": "Reads the content of the content."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads the content into a buffer.", "response": "def read_into(self, buffer, size=-1, *, offset=0, write_offset=0) -> None:\n        '''\n            Read the content into a buffer.\n\n            Args:\n                buffer (bytarray): The buffer that will receive the content.\n                size (int): The size. Value ``-1`` means all.\n\n            Keyword Args:\n                offset (int): The read offset.\n                write_offset (int): The write offset.\n        '''\n\n        return self.mglo.read_into(buffer, size, offset, write_offset)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef read_chunks(self, chunk_size, start, step, count) -> bytes:\n        '''\n            Read the content.\n\n            Read and concatenate the chunks of size chunk_size\n            using offsets calculated from start, step and stop.\n\n            Args:\n                chunk_size (int): The chunk size.\n                start (int): First offset.\n                step (int): Offset increment.\n                count (int): The number of offsets.\n\n            Returns:\n                bytes\n        '''\n\n        return self.mglo.read_chunks(chunk_size, start, step, count)", "response": "Read the content.\n            Read and concatenate the chunks of size chunk_size using offsets calculated from start step and count."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef read_chunks_into(self, buffer, chunk_size, start, step, count, *, write_offset=0) -> None:\n        '''\n            Read the content.\n\n            Read and concatenate the chunks of size chunk_size\n            using offsets calculated from start, step and stop.\n\n            Args:\n                buffer (bytarray): The buffer that will receive the content.\n                chunk_size (int): The chunk size.\n                start (int): First offset.\n                step (int): Offset increment.\n                count (int): The number of offsets.\n\n            Keyword Args:\n                write_offset (int): The write offset.\n        '''\n\n        return self.mglo.read(buffer, chunk_size, start, step, count, write_offset)", "response": "Read the content.\n            Read and concatenate the chunks of size chunk_size using offsets calculated from start step and stop."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef clear(self, size=-1, *, offset=0, chunk=None) -> None:\n        '''\n            Clear the content.\n\n            Args:\n                size (int): The size. Value ``-1`` means all.\n\n            Keyword Args:\n                offset (int): The offset.\n                chunk (bytes): The chunk to use repeatedly.\n        '''\n\n        self.mglo.clear(size, offset, chunk)", "response": "Clear the content of the content of the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nbinds the buffer to a uniform block.", "response": "def bind_to_uniform_block(self, binding=0, *, offset=0, size=-1) -> None:\n        '''\n            Bind the buffer to a uniform block.\n\n            Args:\n                binding (int): The uniform block binding.\n\n            Keyword Args:\n                offset (int): The offset.\n                size (int): The size. Value ``-1`` means all.\n        '''\n\n        self.mglo.bind_to_uniform_block(binding, offset, size)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef bind_to_storage_buffer(self, binding=0, *, offset=0, size=-1) -> None:\n        '''\n            Bind the buffer to a shader storage buffer.\n\n            Args:\n                binding (int): The shader storage binding.\n\n            Keyword Args:\n                offset (int): The offset.\n                size (int): The size. Value ``-1`` means all.\n        '''\n\n        self.mglo.bind_to_storage_buffer(binding, offset, size)", "response": "Binds the buffer to a shader storage buffer."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nswap buffers set viewport trigger events and increment frame counter", "response": "def swap_buffers(self):\r\n        \"\"\"\r\n        Swap buffers, set viewport, trigger events and increment frame counter\r\n        \"\"\"\r\n        self.widget.swapBuffers()\r\n        self.set_default_viewport()\r\n        self.app.processEvents()\r\n        self.frames += 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef resize(self, width: int,  height: int):\r\n        self.width = width // self.widget.devicePixelRatio()\r\n        self.height = height // self.widget.devicePixelRatio()\r\n        self.buffer_width = width\r\n        self.buffer_height = height\r\n\r\n        if self.ctx:\r\n            self.set_default_viewport()\r\n\r\n        # Make sure we notify the example about the resize\r\n        super().resize(self.buffer_width, self.buffer_height)", "response": "Replacement for Qt s resizeGL method."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprocesses Qt key press events forwarding them to the example", "response": "def key_pressed_event(self, event):\r\n        \"\"\"\r\n        Process Qt key press events forwarding them to the example\r\n        \"\"\"\r\n        if event.key() == self.keys.ESCAPE:\r\n            self.close()\r\n\r\n        self.example.key_event(event.key(), self.keys.ACTION_PRESS)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprocess Qt key release events forwarding them to the example", "response": "def key_release_event(self, event):\r\n        \"\"\"\r\n        Process Qt key release events forwarding them to the example\r\n        \"\"\"\r\n        self.example.key_event(event.key(), self.keys.ACTION_RELEASE)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef mouse_move_event(self, event):\r\n        self.example.mouse_position_event(event.x(), event.y())", "response": "Forward mouse cursor position events to the example"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nforward mouse press events to the example", "response": "def mouse_press_event(self, event):\r\n        \"\"\"\r\n        Forward mouse press events to the example\r\n        \"\"\"\r\n        # Support left and right mouse button for now\r\n        if event.button() not in [1, 2]:\r\n            return\r\n\r\n        self.example.mouse_press_event(event.x(), event.y(), event.button())"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef mouse_release_event(self, event):\r\n        # Support left and right mouse button for now\r\n        if event.button() not in [1, 2]:\r\n            return\r\n\r\n        self.example.mouse_release_event(event.x(), event.y(), event.button())", "response": "Forward mouse release events to the example"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef viewport(self) -> Tuple[int, int, int, int]:\n        '''\n            tuple: The viewport of the framebuffer.\n        '''\n\n        return self.mglo.viewport", "response": "Returns the viewport of the framebuffer."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the color mask of the current object.", "response": "def color_mask(self) -> Tuple[bool, bool, bool, bool]:\n        '''\n            tuple: The color mask of the framebuffer.\n        '''\n\n        return self.mglo.color_mask"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read(self, viewport=None, components=3, *, attachment=0, alignment=1, dtype='f1') -> bytes:\n        '''\n            Read the content of the framebuffer.\n\n            Args:\n                viewport (tuple): The viewport.\n                components (int): The number of components to read.\n\n            Keyword Args:\n                attachment (int): The color attachment.\n                alignment (int): The byte alignment of the pixels.\n                dtype (str): Data type.\n\n            Returns:\n                bytes\n        '''\n\n        return self.mglo.read(viewport, components, attachment, alignment, dtype)", "response": "Reads the content of the framebuffer."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read_into(self, buffer, viewport=None, components=3, *,\n                  attachment=0, alignment=1, dtype='f1', write_offset=0) -> None:\n        '''\n            Read the content of the framebuffer into a buffer.\n\n            Args:\n                buffer (bytearray): The buffer that will receive the pixels.\n                viewport (tuple): The viewport.\n                components (int): The number of components to read.\n\n            Keyword Args:\n                attachment (int): The color attachment.\n                alignment (int): The byte alignment of the pixels.\n                dtype (str): Data type.\n                write_offset (int): The write offset.\n        '''\n\n        if type(buffer) is Buffer:\n            buffer = buffer.mglo\n\n        return self.mglo.read_into(buffer, viewport, components, attachment, alignment, dtype, write_offset)", "response": "Read the content of the framebuffer into a buffer."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrendering the assigned example", "response": "def render(self, time: float, frame_time: float):\r\n        \"\"\"\r\n        Renders the assigned example\r\n\r\n        Args:\r\n            time (float): Current time in seconds\r\n            frame_time (float): Delta time from last frame in seconds\r\n        \"\"\"\r\n        self.example.render(time, frame_time)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalls every time window is resized", "response": "def resize(self, width, height):\r\n        \"\"\"\r\n        Should be called every time window is resized\r\n        so the example can adapt to the new size if needed\r\n        \"\"\"\r\n        if self.example:\r\n            self.example.resize(width, height)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_default_viewport(self):\r\n        if self.aspect_ratio:\r\n            expected_width = int(self.buffer_height * self.aspect_ratio)\r\n            expected_height = int(expected_width / self.aspect_ratio)\r\n\r\n            if expected_width > self.buffer_width:\r\n                expected_width = self.buffer_width\r\n                expected_height =  int(expected_width / self.aspect_ratio)\r\n\r\n            blank_space_x = self.buffer_width - expected_width\r\n            blank_space_y = self.buffer_height - expected_height\r\n\r\n            self.ctx.viewport = (\r\n                blank_space_x // 2,\r\n                blank_space_y // 2,\r\n                expected_width,\r\n                expected_height,\r\n            )\r\n        else:\r\n            self.ctx.viewport = (0, 0, self.buffer_width, self.buffer_height)", "response": "Sets the default viewport for the current context."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprints moderngl context info.", "response": "def print_context_info(self):\r\n        \"\"\"\r\n        Prints moderngl context info.\r\n        \"\"\"\r\n        print(\"Context Version:\")\r\n        print('ModernGL:', moderngl.__version__)\r\n        print('vendor:', self.ctx.info['GL_VENDOR'])\r\n        print('renderer:', self.ctx.info['GL_RENDERER'])\r\n        print('version:', self.ctx.info['GL_VERSION'])\r\n        print('python:', sys.version)\r\n        print('platform:', sys.platform)\r\n        print('code:', self.ctx.version_code)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef read(self, *, level=0, alignment=1) -> bytes:\n        '''\n            Read the content of the texture into a buffer.\n\n            Keyword Args:\n                level (int): The mipmap level.\n                alignment (int): The byte alignment of the pixels.\n\n            Returns:\n                bytes\n        '''\n\n        return self.mglo.read(level, alignment)", "response": "Reads the content of the texture into a buffer."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef run_example(example_cls: Example, args=None):\r\n    values = parse_args(args)\r\n    window_cls = get_window_cls(values.window)\r\n\r\n    window = window_cls(\r\n        title=example_cls.title,\r\n        size=example_cls.window_size,\r\n        fullscreen=values.fullscreen,\r\n        resizable=example_cls.resizable,\r\n        gl_version=example_cls.gl_version,\r\n        aspect_ratio=example_cls.aspect_ratio,\r\n        vsync=values.vsync,\r\n        samples=values.samples,\r\n        cursor=values.cursor,\r\n    )\r\n\r\n    window.example = example_cls(ctx=window.ctx, wnd=window)\r\n\r\n    start_time = time.time()\r\n    current_time = start_time\r\n    prev_time = start_time\r\n    frame_time = 0\r\n\r\n    while not window.is_closing:\r\n        current_time, prev_time = time.time(), current_time\r\n        frame_time = max(current_time - prev_time, 1 / 1000)\r\n\r\n        window.render(current_time - start_time, frame_time)\r\n        window.swap_buffers()\r\n\r\n    duration = time.time() - start_time\r\n    window.destroy()\r\n    print(\"Duration: {0:.2f}s @ {1:.2f} FPS\".format(duration, window.frames / duration))", "response": "Runs an example in a blocking main loop"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_args(args=None):\r\n    parser = argparse.ArgumentParser()\r\n\r\n    parser.add_argument(\r\n        '-w', '--window',\r\n        default=\"pyqt5\",\r\n        choices=find_window_classes(),\r\n        help='Name for the window type to use',\r\n    )\r\n    parser.add_argument(\r\n        '-fs', '--fullscreen',\r\n        action=\"store_true\",\r\n        help='Open the window in fullscreen mode',\r\n    )\r\n    parser.add_argument(\r\n        '-vs', '--vsync',\r\n        type=str2bool,\r\n        default=\"1\",\r\n        help=\"Enable or disable vsync\",\r\n    )\r\n    parser.add_argument(\r\n        '-s', '--samples',\r\n        type=int,\r\n        default=4,\r\n        help=\"Specify the desired number of samples to use for multisampling\",\r\n    )\r\n    parser.add_argument(\r\n        '-c', '--cursor',\r\n        type=str2bool,\r\n        default=\"true\",\r\n        help=\"Enable or disable displaying the mouse cursor\",\r\n    )\r\n\r\n    return parser.parse_args(args or sys.argv[1:])", "response": "Parse command line arguments from sys. argv."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfind available window packages", "response": "def find_window_classes() -> List[str]:\r\n    \"\"\"\r\n    Find available window packages\r\n\r\n    Returns:\r\n        A list of avaialble window packages\r\n    \"\"\"\r\n    return [\r\n        path.parts[-1] for path in Path(__file__).parent.iterdir()\r\n        if path.is_dir() and not path.parts[-1].startswith('__')\r\n    ]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nimport a dotted module path and returns the class designated by the getTerminalName in the module. Raise ImportError if the import failed.", "response": "def import_string(dotted_path):\r\n    \"\"\"\r\n    Import a dotted module path and return the attribute/class designated by the\r\n    last name in the path. Raise ImportError if the import failed.\r\n    \r\n    Args:\r\n        dotted_path: The path to attempt importing\r\n\r\n    Returns:\r\n        Imported class/attribute\r\n    \"\"\"\r\n    try:\r\n        module_path, class_name = dotted_path.rsplit('.', 1)\r\n    except ValueError as err:\r\n        raise ImportError(\"%s doesn't look like a module path\" % dotted_path) from err\r\n\r\n    module = import_module(module_path)\r\n\r\n    try:\r\n        return getattr(module, class_name)\r\n    except AttributeError as err:\r\n        raise ImportError('Module \"%s\" does not define a \"%s\" attribute/class' % (\r\n            module_path, class_name)) from err"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the default context.", "response": "def get_default_context(allow_fallback_standalone_context=True) -> moderngl.Context:\n        '''\n            Default context\n        '''\n\n        if ContextManager.ctx is None:\n            try:\n                ContextManager.ctx = moderngl.create_context()\n            except moderngl.Error:\n                if allow_fallback_standalone_context:\n                    ContextManager.ctx = moderngl.create_standalone_context()\n                else:\n                    raise\n\n        return ContextManager.ctx"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrunning the compute shader.", "response": "def run(self, group_x=1, group_y=1, group_z=1) -> None:\n        '''\n            Run the compute shader.\n\n            Args:\n                group_x (int): The number of work groups to be launched in the X dimension.\n                group_y (int): The number of work groups to be launched in the Y dimension.\n                group_z (int): The number of work groups to be launched in the Z dimension.\n        '''\n\n        return self.mglo.run(group_x, group_y, group_z)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get(self, key, default) -> Union[Uniform, UniformBlock, Subroutine, Attribute, Varying]:\n        '''\n            Returns a Uniform, UniformBlock, Subroutine, Attribute or Varying.\n\n            Args:\n                default: This is the value to be returned in case key does not exist.\n\n            Returns:\n                :py:class:`Uniform`, :py:class:`UniformBlock`, :py:class:`Subroutine`,\n                :py:class:`Attribute` or :py:class:`Varying`\n        '''\n\n        return self._members.get(key, default)", "response": "Returns a UniformBlock Subroutine Attribute or Varying."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef resize(self, width, height):\r\n        self.width = width\r\n        self.height = height\r\n        self.buffer_width, self.buffer_height = self.width, self.height\r\n        self.set_default_viewport()\r\n\r\n        super().resize(self.buffer_width, self.buffer_height)", "response": "Sets the new size and buffer size internally"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nloop through and handle all queued events and handle them.", "response": "def process_events(self):\r\n        \"\"\"\r\n        Loop through and handle all the queued events.\r\n        \"\"\"\r\n        for event in sdl2.ext.get_events():\r\n            if event.type == sdl2.SDL_MOUSEMOTION:\r\n                self.example.mouse_position_event(event.motion.x, event.motion.y)\r\n\r\n            elif event.type == sdl2.SDL_MOUSEBUTTONUP:\r\n                # Support left and right mouse button for now\r\n                if  event.button.button in [1, 3]:\r\n                    self.example.mouse_press_event(\r\n                        event.motion.x, event.motion.y,\r\n                        1 if event.button.button == 1 else 2,\r\n                    )\r\n\r\n            elif event.type == sdl2.SDL_MOUSEBUTTONDOWN:\r\n                # Support left and right mouse button for now\r\n                if  event.button.button in [1, 3]:\r\n                    self.example.mouse_release_event(\r\n                        event.motion.x, event.motion.y,\r\n                        1 if event.button.button == 1 else 2,\r\n                    )\r\n\r\n            elif event.type in [sdl2.SDL_KEYDOWN, sdl2.SDL_KEYUP]:\r\n                if event.key.keysym.sym == sdl2.SDLK_ESCAPE:\r\n                    self.close()\r\n\r\n                self.example.key_event(event.key.keysym.sym, event.type)\r\n\r\n            elif event.type == sdl2.SDL_QUIT:\r\n                self.close()\r\n\r\n            elif event.type == sdl2.SDL_WINDOWEVENT:\r\n                if event.window.event == sdl2.SDL_WINDOWEVENT_RESIZED:\r\n                    self.resize(event.window.data1, event.window.data2)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef destroy(self):\r\n        sdl2.SDL_GL_DeleteContext(self.context)\r\n        sdl2.SDL_DestroyWindow(self.window)\r\n        sdl2.SDL_Quit()", "response": "Close the context and window."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef on_key_press(self, symbol, modifiers):\r\n        self.example.key_event(symbol, self.keys.ACTION_PRESS)", "response": "Handles key press events"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nhandles key release events", "response": "def on_key_release(self, symbol, modifiers):\r\n        \"\"\"\r\n        Pyglet specific key release callback.\r\n        Forwards and translates the events to the example\r\n        \"\"\"\r\n        self.example.key_event(symbol, self.keys.ACTION_RELEASE)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef on_mouse_motion(self, x, y, dx, dy):\r\n        # Screen coordinates relative to the lower-left corner\r\n        # so we have to flip the y axis to make this consistent with\r\n        # other window libraries\r\n        self.example.mouse_position_event(x, self.buffer_height - y)", "response": "Handles mouse motion events."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nhandle mouse press events and forward to example window", "response": "def on_mouse_press(self, x: int, y: int, button, mods):\r\n        \"\"\"\r\n        Handle mouse press events and forward to example window\r\n        \"\"\"\r\n        if button in [1, 4]:\r\n            self.example.mouse_press_event(\r\n                x, self.buffer_height - y,\r\n                1 if button == 1 else 2,\r\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef on_mouse_release(self, x: int, y: int, button, mods):\r\n        if button in [1, 4]:\r\n            self.example.mouse_release_event(\r\n                x, self.buffer_height - y,\r\n                1 if button == 1 else 2,\r\n            )", "response": "Handle mouse release events and forward to example window"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread a face from the cubemap texture.", "response": "def read(self, face, *, alignment=1) -> bytes:\n        '''\n            Read a face from the cubemap texture.\n\n            Args:\n                face (int): The face to read.\n\n            Keyword Args:\n                alignment (int): The byte alignment of the pixels.\n        '''\n\n        return self.mglo.read(face, alignment)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreads a face from the cubemap texture into a buffer.", "response": "def read_into(self, buffer, face, *, alignment=1, write_offset=0) -> None:\n        '''\n            Read a face from the cubemap texture.\n\n            Args:\n                buffer (bytearray): The buffer that will receive the pixels.\n                face (int): The face to read.\n\n            Keyword Args:\n                alignment (int): The byte alignment of the pixels.\n                write_offset (int): The write offset.\n        '''\n\n        if type(buffer) is Buffer:\n            buffer = buffer.mglo\n\n        return self.mglo.read_into(buffer, face, alignment, write_offset)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrite the content of the texture.", "response": "def write(self, face, data, viewport=None, *, alignment=1) -> None:\n        '''\n            Update the content of the texture.\n\n            Args:\n                face (int): The face to update.\n                data (bytes): The pixel data.\n                viewport (tuple): The viewport.\n\n            Keyword Args:\n                alignment (int): The byte alignment of the pixels.\n        '''\n\n        if type(data) is Buffer:\n            data = data.mglo\n\n        self.mglo.write(face, data, viewport, alignment)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef key_event(self, key, action):\n        if action == self.wnd.keys.ACTION_PRESS:\n            if key == self.wnd.keys.SPACE:\n                print(\"Space was pressed\")\n\n        if action == self.wnd.keys.ACTION_RELEASE:\n            if key == self.wnd.keys.SPACE:\n                print(\"Space was released\")", "response": "Handle key events in a generic way that supports all window types."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef mouse_press_event(self, x, y, button):\n        if button == 1:\n            print(\"Left mouse button pressed @\", x, y)\n        if button == 2:\n            print(\"Right mouse button pressed @\", x, y)", "response": "Reports left and right mouse button presses + position"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef mouse_release_event(self, x, y, button):\n        if button == 1:\n            print(\"Left mouse button released @\", x, y)\n        if button == 2:\n            print(\"Right mouse button released @\", x, y)", "response": "Reports left and right mouse button releases + position"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef detect_format(program, attributes) -> str:\n    '''\n        Detect format for vertex attributes.\n        The format returned does not contain padding.\n\n        Args:\n            program (Program): The program.\n            attributes (list): A list of attribute names.\n\n        Returns:\n            str\n    '''\n\n    def fmt(attr):\n        '''\n            For internal use only.\n        '''\n\n        return attr.array_length * attr.dimension, attr.shape\n\n    return ' '.join('%d%s' % fmt(program[a]) for a in attributes)", "response": "Detect format for vertex attributes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrap a callback's method to pull the desired arguments from the vars dict also checks to ensure the method's arguments are in the vars dict Parameters ---------- method : callable Returns ------- validated callable", "response": "def validate_callback_data(method):\n    \"\"\"\n    wraps a callback's method to pull the desired arguments from the vars dict\n    also checks to ensure the method's arguments are in the vars dict\n\n    Parameters\n    ----------\n    method : callable\n\n    Returns\n    -------\n    validated callable\n    \"\"\"\n    @wraps(method)\n    def method_wrapper(*args, **kwargs):\n        \"\"\"\n\n        Parameters\n        ----------\n        *args\n        **kwargs\n\n        Returns\n        -------\n        method's output\n        \"\"\"\n        expected = method.__code__.co_varnames\n\n        # rename curret gam object\n        if 'self' in kwargs:\n            gam = kwargs['self']\n            del(kwargs['self'])\n            kwargs['gam'] = gam\n\n        # loop once to check any missing\n        missing = []\n        for e in expected:\n            if e == 'self':\n                continue\n            if e not in kwargs:\n                missing.append(e)\n        assert len(missing) == 0, 'CallBack cannot reference: {}'.\\\n                                  format(', '.join(missing))\n\n        # loop again to extract desired\n        kwargs_subset = {}\n        for e in expected:\n            if e == 'self':\n                continue\n            kwargs_subset[e] = kwargs[e]\n\n        return method(*args, **kwargs_subset)\n\n    return method_wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef validate_callback(callback):\n    if not(hasattr(callback, '_validated')) or callback._validated == False:\n        assert hasattr(callback, 'on_loop_start') \\\n               or hasattr(callback, 'on_loop_end'), \\\n               'callback must have `on_loop_start` or `on_loop_end` method'\n        if hasattr(callback, 'on_loop_start'):\n            setattr(callback, 'on_loop_start',\n                    validate_callback_data(callback.on_loop_start))\n        if hasattr(callback, 'on_loop_end'):\n            setattr(callback, 'on_loop_end',\n                    validate_callback_data(callback.on_loop_end))\n        setattr(callback, '_validated', True)\n    return callback", "response": "Validates a callback object and sets the _validated attribute to True."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef phi(self, y, mu, edof, weights):\n        if self._known_scale:\n            return self.scale\n        else:\n            return (np.sum(weights * self.V(mu)**-1 * (y - mu)**2) /\n                    (len(mu) - edof))", "response": "Estimate the unity of a set of n - n - n - n - n - n - n - n - n - n - n - n - n - n - n - n - n - n - n - n - n - n - n - n - n - n - n - n - n - n - n - n - n - n - n - n - n - n - n - n - n - n - n - n - n - 1"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompute the log of the pdf or pmf of the values under the current distribution.", "response": "def log_pdf(self, y, mu, weights=None):\n        \"\"\"\n        computes the log of the pdf or pmf of the values under the current distribution\n\n        Parameters\n        ----------\n        y : array-like of length n\n            target values\n        mu : array-like of length n\n            expected values\n        weights : array-like shape (n,) or None, default: None\n            sample weights\n            if None, defaults to array of ones\n\n        Returns\n        -------\n        pdf/pmf : np.array of length n\n        \"\"\"\n        if weights is None:\n            weights = np.ones_like(mu)\n        scale = self.scale / weights\n        return sp.stats.norm.logpdf(y, loc=mu, scale=scale)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmodels deviance for a gaussian linear model, this is equal to the SSE Parameters ---------- y : array-like of length n target values mu : array-like of length n expected values scaled : boolean, default: True whether to divide the deviance by the distribution scaled Returns ------- deviances : np.array of length n", "response": "def deviance(self, y, mu, scaled=True):\n        \"\"\"\n        model deviance\n\n        for a gaussian linear model, this is equal to the SSE\n\n        Parameters\n        ----------\n        y : array-like of length n\n            target values\n        mu : array-like of length n\n            expected values\n        scaled : boolean, default: True\n            whether to divide the deviance by the distribution scaled\n\n        Returns\n        -------\n        deviances : np.array of length n\n        \"\"\"\n        dev = (y - mu)**2\n        if scaled:\n            dev /= self.scale\n        return dev"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns random samples from this Normal distribution.", "response": "def sample(self, mu):\n        \"\"\"\n        Return random samples from this Normal distribution.\n\n        Samples are drawn independently from univariate normal distributions\n        with means given by the values in `mu` and with standard deviations\n        equal to the `scale` attribute if it exists otherwise 1.0.\n\n        Parameters\n        ----------\n        mu : array-like of shape n_samples or shape (n_simulations, n_samples)\n            expected values\n\n        Returns\n        -------\n        random_samples : np.array of same shape as mu\n        \"\"\"\n        standard_deviation = self.scale**0.5 if self.scale else 1.0\n        return np.random.normal(loc=mu, scale=standard_deviation, size=None)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef log_pdf(self, y, mu, weights=None):\n        if weights is None:\n            weights = np.ones_like(mu)\n        n = self.levels\n        p = mu / self.levels\n        return sp.stats.binom.logpmf(y, n, p)", "response": "Computes the log of the pdf or pmf of the values under the current distribution."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning random samples from this Normal distribution.", "response": "def sample(self, mu):\n        \"\"\"\n        Return random samples from this Normal distribution.\n\n        Parameters\n        ----------\n        mu : array-like of shape n_samples or shape (n_simulations, n_samples)\n            expected values\n\n        Returns\n        -------\n        random_samples : np.array of same shape as mu\n        \"\"\"\n        number_of_trials = self.levels\n        success_probability = mu / number_of_trials\n        return np.random.binomial(n=number_of_trials, p=success_probability,\n                                  size=None)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompute the log of the pdf or pmf of the values under the current distribution Parameters ---------- y : array-like of length n target values mu : array-like of length n expected values weights : array-like shape (n,) or None, default: None containing sample weights if None, defaults to array of ones Returns ------- pdf/pmf : np.array of length n", "response": "def log_pdf(self, y, mu, weights=None):\n        \"\"\"\n        computes the log of the pdf or pmf of the values under the current distribution\n\n        Parameters\n        ----------\n        y : array-like of length n\n            target values\n        mu : array-like of length n\n            expected values\n        weights : array-like shape (n,) or None, default: None\n            containing sample weights\n            if None, defaults to array of ones\n\n        Returns\n        -------\n        pdf/pmf : np.array of length n\n        \"\"\"\n        if weights is None:\n            weights = np.ones_like(mu)\n        # in Poisson regression weights are proportional to the exposure\n        # so we want to pump up all our predictions\n        # NOTE: we assume the targets are counts, not rate.\n        # ie if observations were scaled to account for exposure, they have\n        # been rescaled before calling this function.\n        # since some samples have higher exposure,\n        # they also need to have higher variance,\n        # we do this by multiplying mu by the weight=exposure\n        mu = mu * weights\n        return sp.stats.poisson.logpmf(y, mu=mu)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef log_pdf(self, y, mu, weights=None):\n        if weights is None:\n            weights = np.ones_like(mu)\n        nu = weights / self.scale\n        return sp.stats.gamma.logpdf(x=y, a=nu, scale=mu / nu)", "response": "Computes the log of the pdf or pmf of the values under the current distribution."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning random samples from this Gamma distribution.", "response": "def sample(self, mu):\n        \"\"\"\n        Return random samples from this Gamma distribution.\n\n        Parameters\n        ----------\n        mu : array-like of shape n_samples or shape (n_simulations, n_samples)\n            expected values\n\n        Returns\n        -------\n        random_samples : np.array of same shape as mu\n        \"\"\"\n        # in numpy.random.gamma, `shape` is the parameter sometimes denoted by\n        # `k` that corresponds to `nu` in S. Wood (2006) Table 2.1\n        shape = 1. / self.scale\n        # in numpy.random.gamma, `scale` is the parameter sometimes denoted by\n        # `theta` that corresponds to mu / nu in S. Wood (2006) Table 2.1\n        scale = mu / shape\n        return np.random.gamma(shape=shape, scale=scale, size=None)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef log_pdf(self, y, mu, weights=None):\n        if weights is None:\n            weights = np.ones_like(mu)\n        gamma = weights / self.scale\n        return sp.stats.invgauss.logpdf(y, mu, scale=1./gamma)", "response": "Computes the log of the pdf or pmf of the values under the current distribution."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn random samples from this Inverse Gaussian ( Wald distribution.", "response": "def sample(self, mu):\n        \"\"\"\n        Return random samples from this Inverse Gaussian (Wald) distribution.\n\n        Parameters\n        ----------\n        mu : array-like of shape n_samples or shape (n_simulations, n_samples)\n            expected values\n\n        Returns\n        -------\n        random_samples : np.array of same shape as mu\n        \"\"\"\n        return np.random.wald(mean=mu, scale=self.scale, size=None)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nensure that X and y data are float and correct shapes", "response": "def _clean_X_y(X, y):\n    \"\"\"ensure that X and y data are float and correct shapes\n    \"\"\"\n    return make_2d(X, verbose=False).astype('float'), y.astype('float')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwage dataset for the current education category", "response": "def wage(return_X_y=True):\n    \"\"\"wage dataset\n\n    Parameters\n    ----------\n    return_X_y : bool,\n        if True, returns a model-ready tuple of data (X, y)\n        otherwise, returns a Pandas DataFrame\n\n    Returns\n    -------\n    model-ready tuple of data (X, y)\n        OR\n    Pandas DataFrame\n\n    Notes\n    -----\n    X contains the year, age and education of each sampled person.\n    The education category has been transformed to integers.\n\n    y contains the wage.\n\n    Source:\n    https://github.com/JWarmenhoven/ISLR-python/blob/master/Notebooks/Data/Wage.csv\n    \"\"\"\n    # y is real\n    # recommend LinearGAM\n    wage = pd.read_csv(PATH + '/wage.csv', index_col=0)\n    if return_X_y:\n        X = wage[['year', 'age', 'education']].values\n        X[:,-1] = np.unique(X[:,-1], return_inverse=True)[1]\n        y = wage['wage'].values\n        return _clean_X_y(X, y)\n    return wage"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef trees(return_X_y=True):\n    # y is real.\n    # recommend InvGaussGAM, or GAM(distribution='gamma', link='log')\n    trees = pd.read_csv(PATH + '/trees.csv', index_col=0)\n    if return_X_y:\n        y = trees.Volume.values\n        X = trees[['Girth', 'Height']].values\n        return _clean_X_y(X, y)\n    return trees", "response": "Returns a Pandas DataFrame of the cherry trees dataset."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncredit default dataset Parameters ---------- return_X_y : bool, if True, returns a model-ready tuple of data (X, y) otherwise, returns a Pandas DataFrame Returns ------- model-ready tuple of data (X, y) OR Pandas DataFrame Notes ----- X contains the category of student or not, credit card balance, and income. y contains the outcome of default (0) or not (1). Source: https://vincentarelbundock.github.io/Rdatasets/doc/ISLR/Default.html", "response": "def default(return_X_y=True):\n    \"\"\"credit default dataset\n\n    Parameters\n    ----------\n    return_X_y : bool,\n        if True, returns a model-ready tuple of data (X, y)\n        otherwise, returns a Pandas DataFrame\n\n    Returns\n    -------\n    model-ready tuple of data (X, y)\n        OR\n    Pandas DataFrame\n\n    Notes\n    -----\n    X contains the category of student or not, credit card balance,\n    and  income.\n\n    y contains the outcome of default (0) or not (1).\n\n    Source:\n    https://vincentarelbundock.github.io/Rdatasets/doc/ISLR/Default.html\n    \"\"\"\n    # y is binary\n    # recommend LogisticGAM\n    default = pd.read_csv(PATH + '/default.csv', index_col=0)\n    if return_X_y:\n        default = default.values\n        default[:,0] = np.unique(default[:,0], return_inverse=True)[1]\n        default[:,1] = np.unique(default[:,1], return_inverse=True)[1]\n        X = default[:,1:]\n        y = default[:,0]\n        return _clean_X_y(X, y)\n    return default"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cake(return_X_y=True):\n    # y is real\n    # recommend LinearGAM\n    cake = pd.read_csv(PATH + '/cake.csv', index_col=0)\n    if return_X_y:\n        X = cake[['recipe', 'replicate', 'temperature']].values\n        X[:,0] = np.unique(cake.values[:,1], return_inverse=True)[1]\n        X[:,1] -= 1\n        y = cake['angle'].values\n        return _clean_X_y(X, y)\n    return cake", "response": "Returns a Pandas DataFrame of the cake dataset."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef hepatitis(return_X_y=True):\n    # y is real\n    # recommend LinearGAM\n    hep = pd.read_csv(PATH + '/hepatitis_A_bulgaria.csv').astype(float)\n    if return_X_y:\n        # eliminate 0/0\n        mask = (hep.total > 0).values\n        hep = hep[mask]\n\n        X = hep.age.values\n        y = hep.hepatitis_A_positive.values / hep.total.values\n        return _clean_X_y(X, y)\n    return hep", "response": "hepatitis in Bulgaria dataset\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef toy_classification(return_X_y=True, n=5000):\n    # make features\n    X = np.random.rand(n,5) * 10 - 5\n    cat = np.random.randint(0,4, n)\n    X = np.c_[X, cat]\n\n    # make observations\n    log_odds = (-0.5*X[:,0]**2) + 5 +(-0.5*X[:,1]**2) + np.mod(X[:,-1], 2)*-30\n    p = 1/(1+np.exp(-log_odds)).squeeze()\n    y = (np.random.rand(n) < p).astype(np.int)\n\n    if return_X_y:\n        return X, y\n    else:\n        return pd.DataFrame(np.c_[X, y], columns=[['continuous0',\n                                                   'continuous1',\n                                                   'irrelevant0',\n                                                   'irrelevant1',\n                                                   'irrelevant2',\n                                                   'categorical0',\n                                                   'observations'\n                                                   ]])", "response": "toy classification dataset with irrelevant features fitting a logistic model on this data and performing a model summary\n   "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef head_circumference(return_X_y=True):\n    # y is real\n    # recommend ExpectileGAM\n    head = pd.read_csv(PATH + '/head_circumference.csv', index_col=0).astype(float)\n    if return_X_y:\n        y = head['head'].values\n        X = head[['age']].values\n        return _clean_X_y(X, y)\n    return head", "response": "head circumference for dutch boys\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef chicago(return_X_y=True):\n    # recommend PoissonGAM\n    chi = pd.read_csv(PATH + '/chicago.csv', index_col=0).astype(float)\n    if return_X_y:\n        chi = chi[['time', 'tmpd', 'pm10median', 'o3median', 'death']].dropna()\n\n        X = chi[['time', 'tmpd', 'pm10median', 'o3median']].values\n        y = chi['death'].values\n\n        return X, y\n    else:\n        return chi", "response": "Chicago air pollution and death rate data"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates a model - ready tuple of data for a toy interaction.", "response": "def toy_interaction(return_X_y=True, n=50000, stddev=0.1):\n    \"\"\"a sinusoid modulated by a linear function\n\n    this is a simple dataset to test a model's capacity to fit interactions\n    between features.\n\n    a GAM with no interaction terms will have an R-squared close to 0,\n    while a GAM with a tensor product will have R-squared close to 1.\n\n    the data is random, and will vary on each invocation.\n\n    Parameters\n    ----------\n    return_X_y : bool,\n        if True, returns a model-ready tuple of data (X, y)\n        otherwise, returns a Pandas DataFrame\n\n    n : int, optional\n        number of points to generate\n\n    stddev : positive float, optional,\n        standard deviation of irreducible error\n\n    Returns\n    -------\n    model-ready tuple of data (X, y)\n        OR\n    Pandas DataFrame\n\n    Notes\n    -----\n    X contains [['sinusoid', 'linear']]\n\n    y is formed by multiplying the sinusoid by the linear function.\n\n    Source:\n    \"\"\"\n    X = np.random.uniform(-1,1, size=(n, 2))\n    X[:, 1] *= 5\n\n    y = np.sin(X[:,0] * 2 * np.pi * 1.5) * X[:,1]\n    y += np.random.randn(len(X)) * stddev\n\n    if return_X_y:\n        return X, y\n\n    else:\n        data = pd.DataFrame(np.c_[X, y])\n        data.columns = [['sinusoid', 'linear', 'y']]\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating multivariate Logistic problem", "response": "def gen_multi_data(n=5000):\n    \"\"\"\n    multivariate Logistic problem\n    \"\"\"\n    X, y = toy_classification(return_X_y=True, n=10000)\n\n    lgam = LogisticGAM(s(0) + s(1) + s(2) + s(3) + s(4) + f(5))\n    lgam.fit(X, y)\n\n    plt.figure()\n    for i, term in enumerate(lgam.terms):\n        if term.isintercept:\n            continue\n        plt.plot(lgam.partial_dependence(term=i))\n\n    plt.savefig('imgs/pygam_multi_pdep.png', dpi=300)\n\n    plt.figure()\n    plt.plot(lgam.logs_['deviance'])\n    plt.savefig('imgs/pygam_multi_deviance.png', dpi=300)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef gen_tensor_data():\n    X, y = toy_interaction(return_X_y=True, n=10000)\n\n    gam = LinearGAM(te(0, 1,lam=0.1)).fit(X, y)\n\n    XX = gam.generate_X_grid(term=0, meshgrid=True)\n    Z = gam.partial_dependence(term=0, meshgrid=True)\n\n    fig = plt.figure(figsize=(9,6))\n    ax = plt.axes(projection='3d')\n    ax.dist = 7.5\n    ax.plot_surface(XX[0], XX[1], Z, cmap='viridis')\n    ax.set_axis_off()\n    fig.tight_layout()\n    plt.savefig('imgs/pygam_tensor.png', transparent=True, dpi=300)", "response": "Generate a tensor data for the toy interaction data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cholesky(A, sparse=True, verbose=True):\n    if SKSPIMPORT:\n        A = sp.sparse.csc_matrix(A)\n        try:\n            F = spcholesky(A)\n\n            # permutation matrix P\n            P = sp.sparse.lil_matrix(A.shape)\n            p = F.P()\n            P[np.arange(len(p)), p] = 1\n\n            # permute\n            L = F.L()\n            L = P.T.dot(L)\n        except CholmodNotPositiveDefiniteError as e:\n            raise NotPositiveDefiniteError('Matrix is not positive definite')\n\n        if sparse:\n            return L.T # upper triangular factorization\n        return L.T.A # upper triangular factorization\n\n    else:\n        msg = 'Could not import Scikit-Sparse or Suite-Sparse.\\n'\\\n              'This will slow down optimization for models with '\\\n              'monotonicity/convexity penalties and many splines.\\n'\\\n              'See installation instructions for installing '\\\n              'Scikit-Sparse and Suite-Sparse via Conda.'\n        if verbose:\n            warnings.warn(msg)\n\n        if sp.sparse.issparse(A):\n            A = A.A\n\n        try:\n            L = sp.linalg.cholesky(A, lower=False)\n        except LinAlgError as e:\n            raise NotPositiveDefiniteError('Matrix is not positive definite')\n\n        if sparse:\n            return sp.sparse.csc_matrix(L)\n        return L", "response": "Choose the best possible cholesky factorizor for a given array of elements."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make_2d(array, verbose=True):\n    array = np.asarray(array)\n    if array.ndim < 2:\n        msg = 'Expected 2D input data array, but found {}D. '\\\n              'Expanding to 2D.'.format(array.ndim)\n        if verbose:\n            warnings.warn(msg)\n        array = np.atleast_1d(array)[:,None]\n    return array", "response": "tiny tool to expand 1D arrays the way i want\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef check_array(array, force_2d=False, n_feats=None, ndim=None,\n                min_samples=1, name='Input data', verbose=True):\n    \"\"\"\n    tool to perform basic data validation.\n    called by check_X and check_y.\n\n    ensures that data:\n    - is ndim dimensional\n    - contains float-compatible data-types\n    - has at least min_samples\n    - has n_feats\n    - is finite\n\n    Parameters\n    ----------\n    array : array-like\n    force_2d : boolean, default: False\n        whether to force a 2d array. Setting to True forces ndim = 2\n    n_feats : int, default: None\n              represents number of features that the array should have.\n              not enforced if n_feats is None.\n    ndim : int default: None\n        number of dimensions expected in the array\n    min_samples : int, default: 1\n    name : str, default: 'Input data'\n        name to use when referring to the array\n    verbose : bool, default: True\n        whether to print warnings\n\n    Returns\n    -------\n    array : validated array\n    \"\"\"\n    # make array\n    if force_2d:\n        array = make_2d(array, verbose=verbose)\n        ndim = 2\n    else:\n        array = np.array(array)\n\n    # cast to float\n    dtype = array.dtype\n    if dtype.kind not in ['i', 'f']:\n        try:\n            array = array.astype('float')\n        except ValueError as e:\n            raise ValueError('{} must be type int or float, '\\\n                             'but found type: {}\\n'\\\n                             'Try transforming data with a LabelEncoder first.'\\\n                             .format(name, dtype.type))\n\n    # check finite\n    if not(np.isfinite(array).all()):\n        raise ValueError('{} must not contain Inf nor NaN'.format(name))\n\n    # check ndim\n    if ndim is not None:\n        if array.ndim != ndim:\n            raise ValueError('{} must have {} dimensions. '\\\n                             'found shape {}'.format(name, ndim, array.shape))\n\n    # check n_feats\n    if n_feats is not None:\n        m = array.shape[1]\n        if m != n_feats:\n           raise ValueError('{} must have {} features, '\\\n                            'but found {}'.format(name, n_feats, m))\n\n    # minimum samples\n    n = array.shape[0]\n    if n < min_samples:\n        raise ValueError('{} should have at least {} samples, '\\\n                         'but found {}'.format(name, min_samples, n))\n\n    return array", "response": "Checks that the input array is valid."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck that the y data is in the domain of the link function.", "response": "def check_y(y, link, dist, min_samples=1, verbose=True):\n    \"\"\"\n    tool to ensure that the targets:\n    - are in the domain of the link function\n    - are numerical\n    - have at least min_samples\n    - is finite\n\n    Parameters\n    ----------\n    y : array-like\n    link : Link object\n    dist : Distribution object\n    min_samples : int, default: 1\n    verbose : bool, default: True\n        whether to print warnings\n\n    Returns\n    -------\n    y : array containing validated y-data\n    \"\"\"\n    y = np.ravel(y)\n\n    y = check_array(y, force_2d=False, min_samples=min_samples, ndim=1,\n                    name='y data', verbose=verbose)\n\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\")\n        \n        if np.any(np.isnan(link.link(y, dist))):\n            raise ValueError('y data is not in domain of {} link function. ' \\\n                             'Expected domain: {}, but found {}' \\\n                             .format(link, get_link_domain(link, dist),\n                                     [float('%.2f'%np.min(y)),\n                                      float('%.2f'%np.max(y))]))\n    return y"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks that X is 2 dimensional and that X contains at least min_samples categorical data and that X contains at least min_samples categorical data.", "response": "def check_X(X, n_feats=None, min_samples=1, edge_knots=None, dtypes=None,\n            features=None, verbose=True):\n    \"\"\"\n    tool to ensure that X:\n    - is 2 dimensional\n    - contains float-compatible data-types\n    - has at least min_samples\n    - has n_feats\n    - has categorical features in the right range\n    - is finite\n\n    Parameters\n    ----------\n    X : array-like\n    n_feats : int. default: None\n              represents number of features that X should have.\n              not enforced if n_feats is None.\n    min_samples : int, default: 1\n    edge_knots : list of arrays, default: None\n    dtypes : list of strings, default: None\n    features : list of ints,\n        which features are considered by the model\n    verbose : bool, default: True\n        whether to print warnings\n\n    Returns\n    -------\n    X : array with ndims == 2 containing validated X-data\n    \"\"\"\n    # check all features are there\n    if bool(features):\n        features = flatten(features)\n        max_feat = max(flatten(features))\n\n        if n_feats is None:\n            n_feats = max_feat\n\n        n_feats = max(n_feats, max_feat)\n\n    # basic diagnostics\n    X = check_array(X, force_2d=True, n_feats=n_feats, min_samples=min_samples,\n                    name='X data', verbose=verbose)\n\n    # check our categorical data has no new categories\n    if (edge_knots is not None) and (dtypes is not None) and (features is not None):\n\n        # get a flattened list of tuples\n        edge_knots = flatten(edge_knots)[::-1]\n        dtypes = flatten(dtypes)\n        assert len(edge_knots) % 2 == 0 # sanity check\n\n        # form pairs\n        n = len(edge_knots) // 2\n        edge_knots = [(edge_knots.pop(), edge_knots.pop()) for _ in range(n)]\n\n        # check each categorical term\n        for i, ek in enumerate(edge_knots):\n            dt = dtypes[i]\n            feature = features[i]\n            x = X[:, feature]\n\n            if dt == 'categorical':\n                min_ = ek[0]\n                max_ = ek[-1]\n                if (np.unique(x) < min_).any() or \\\n                   (np.unique(x) > max_).any():\n                    min_ += .5\n                    max_ -= 0.5\n                    raise ValueError('X data is out of domain for categorical '\\\n                                     'feature {}. Expected data on [{}, {}], '\\\n                                     'but found data on [{}, {}]'\\\n                                     .format(i, min_, max_, x.min(), x.max()))\n\n    return X"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks that input and output data arrays are the same number of samples.", "response": "def check_X_y(X, y):\n    \"\"\"\n    tool to ensure input and output data have the same number of samples\n\n    Parameters\n    ----------\n    X : array-like\n    y : array-like\n\n    Returns\n    -------\n    None\n    \"\"\"\n    if len(X) != len(y):\n        raise ValueError('Inconsistent input and output data shapes. '\\\n                         'found X: {} and y: {}'.format(X.shape, y.shape))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck that all input and output data arrays have the same number of samples.", "response": "def check_lengths(*arrays):\n    \"\"\"\n    tool to ensure input and output data have the same number of samples\n\n    Parameters\n    ----------\n    *arrays : iterable of arrays to be checked\n\n    Returns\n    -------\n    None\n    \"\"\"\n    lengths = [len(array) for array in arrays]\n    if len(np.unique(lengths)) > 1:\n        raise ValueError('Inconsistent data lengths: {}'.format(lengths))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef check_param(param, param_name, dtype, constraint=None, iterable=True,\n                max_depth=2):\n    \"\"\"\n    checks the dtype of a parameter,\n    and whether it satisfies a numerical contraint\n\n    Parameters\n    ---------\n    param : object\n    param_name : str, name of the parameter\n    dtype : str, desired dtype of the parameter\n    contraint : str, default: None\n                numerical constraint of the parameter.\n                if None, no constraint is enforced\n    iterable : bool, default: True\n               whether to allow iterable param\n    max_depth : int, default: 2\n                maximum nesting of the iterable.\n                only used if iterable == True\n    Returns\n    -------\n    list of validated and converted parameter(s)\n    \"\"\"\n    msg = []\n    msg.append(param_name + \" must be \"+ dtype)\n    if iterable:\n        msg.append(\" or nested iterable of depth \" + str(max_depth) +\n                   \" containing \" + dtype + \"s\")\n\n    msg.append(\", but found \" + param_name + \" = {}\".format(repr(param)))\n\n    if constraint is not None:\n        msg = (\" \" + constraint).join(msg)\n    else:\n        msg = ''.join(msg)\n\n    # check param is numerical\n    try:\n        param_dt = np.array(flatten(param))# + np.zeros_like(flatten(param), dtype='int')\n        # param_dt = np.array(param).astype(dtype)\n    except (ValueError, TypeError):\n        raise TypeError(msg)\n\n    # check iterable\n    if iterable:\n        if check_iterable_depth(param) > max_depth:\n            raise TypeError(msg)\n    if (not iterable) and isiterable(param):\n        raise TypeError(msg)\n\n    # check param is correct dtype\n    if not (param_dt == np.array(flatten(param)).astype(float)).all():\n        raise TypeError(msg)\n\n    # check constraint\n    if constraint is not None:\n        if not (eval('np.' + repr(param_dt) + constraint)).all():\n            raise ValueError(msg)\n\n    return param", "response": "Checks the dtype of a parameter and whether it satisfies a numerical contraint."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_link_domain(link, dist):\n    domain = np.array([-np.inf, -1, 0, 1, np.inf])\n    domain = domain[~np.isnan(link.link(domain, dist))]\n    return [domain[0], domain[-1]]", "response": "Returns the domain of a given monotonic link function."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the given square matrix with a small amount added to the diagonal to make it positive semi - definite.", "response": "def load_diagonal(cov, load=None):\n        \"\"\"Return the given square matrix with a small amount added to the diagonal\n        to make it positive semi-definite.\n        \"\"\"\n        n, m = cov.shape\n        assert n == m, \"matrix must be square, but found shape {}\".format((n, m))\n\n        if load is None:\n            load = np.sqrt(np.finfo(np.float64).eps) # machine epsilon\n        return cov + np.eye(n) * load"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef round_to_n_decimal_places(array, n=3):\n    # check if in scientific notation\n    if issubclass(array.__class__, float) and '%.e'%array == str(array):\n        return array # do nothing\n\n    shape = np.shape(array)\n    out = ((np.atleast_1d(array) * 10**n).round().astype('int') / (10.**n))\n    return out.reshape(shape)", "response": "tool to keep round a float to n decimal places."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef space_row(left, right, filler=' ', total_width=-1):\n    left = str(left)\n    right = str(right)\n    filler = str(filler)[:1]\n\n    if total_width < 0:\n        spacing = - total_width\n    else:\n        spacing = total_width - len(left) - len(right)\n\n    return left + filler * spacing + right", "response": "space the data in a row with optional filling"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating uniform knots from data including the edges of the data.", "response": "def gen_edge_knots(data, dtype, verbose=True):\n    \"\"\"\n    generate uniform knots from data including the edges of the data\n\n    for discrete data, assumes k categories in [0, k-1] interval\n\n    Parameters\n    ----------\n    data : array-like with one dimension\n    dtype : str in {'categorical', 'numerical'}\n    verbose : bool, default: True\n        whether to print warnings\n\n    Returns\n    -------\n    np.array containing ordered knots\n    \"\"\"\n    if dtype not in ['categorical', 'numerical']:\n        raise ValueError('unsupported dtype: {}'.format(dtype))\n    if dtype == 'categorical':\n        return np.r_[np.min(data) - 0.5, np.max(data) + 0.5]\n    else:\n        knots = np.r_[np.min(data), np.max(data)]\n        if knots[0] == knots[1] and verbose:\n            warnings.warn('Data contains constant feature. '\\\n                          'Consider removing and setting fit_intercept=True',\n                          stacklevel=2)\n        return knots"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntooling to generate b-spline basis using vectorized De Boor recursion the basis functions extrapolate linearly past the end-knots. Parameters ---------- x : array-like, with ndims == 1. edge_knots : array-like contaning locations of the 2 edge knots. n_splines : int. number of splines to generate. must be >= spline_order+1 default: 20 spline_order : int. order of spline basis to create default: 3 sparse : boolean. whether to return a sparse basis matrix or not. default: True verbose : bool, default: True whether to print warnings Returns ------- basis : sparse csc matrix or array containing b-spline basis functions with shape (len(x), n_splines)", "response": "def b_spline_basis(x, edge_knots, n_splines=20, spline_order=3, sparse=True,\n                   periodic=True, verbose=True):\n    \"\"\"\n    tool to generate b-spline basis using vectorized De Boor recursion\n    the basis functions extrapolate linearly past the end-knots.\n\n    Parameters\n    ----------\n    x : array-like, with ndims == 1.\n    edge_knots : array-like contaning locations of the 2 edge knots.\n    n_splines : int. number of splines to generate. must be >= spline_order+1\n                default: 20\n    spline_order : int. order of spline basis to create\n                   default: 3\n    sparse : boolean. whether to return a sparse basis matrix or not.\n             default: True\n    verbose : bool, default: True\n        whether to print warnings\n\n    Returns\n    -------\n    basis : sparse csc matrix or array containing b-spline basis functions\n            with shape (len(x), n_splines)\n    \"\"\"\n    if np.ravel(x).ndim != 1:\n        raise ValueError('Data must be 1-D, but found {}'\\\n                         .format(np.ravel(x).ndim))\n\n    if (n_splines < 1) or not isinstance(n_splines, numbers.Integral):\n        raise ValueError('n_splines must be int >= 1')\n\n    if (spline_order < 0) or not isinstance(spline_order, numbers.Integral):\n        raise ValueError('spline_order must be int >= 1')\n\n    if n_splines < spline_order + 1:\n        raise ValueError('n_splines must be >= spline_order + 1. '\\\n                         'found: n_splines = {} and spline_order = {}'\\\n                         .format(n_splines, spline_order))\n\n    if n_splines == 0 and verbose:\n        warnings.warn('Requested 1 spline. This is equivalent to '\\\n                      'fitting an intercept', stacklevel=2)\n\n    n_splines += spline_order * periodic\n\n    # rescale edge_knots to [0,1], and generate boundary knots\n    edge_knots = np.sort(deepcopy(edge_knots))\n    offset = edge_knots[0]\n    scale = edge_knots[-1] - edge_knots[0]\n    if scale == 0:\n        scale = 1\n    boundary_knots = np.linspace(0, 1, 1 + n_splines - spline_order)\n    diff = np.diff(boundary_knots[:2])[0]\n\n    # rescale x as well\n    x = (np.ravel(deepcopy(x)) - offset) / scale\n\n    # wrap periodic values\n    if periodic:\n        x = x % (1 + 1e-9)\n\n    # append 0 and 1 in order to get derivatives for extrapolation\n    x = np.r_[x, 0., 1.]\n\n    # determine extrapolation indices\n    x_extrapolte_l = (x < 0)\n    x_extrapolte_r = (x > 1)\n    x_interpolate = ~(x_extrapolte_r + x_extrapolte_l)\n\n    # formatting\n    x = np.atleast_2d(x).T\n    n = len(x)\n\n    # augment knots\n    aug = np.arange(1, spline_order + 1) * diff\n    aug_knots = np.r_[-aug[::-1],\n                      boundary_knots,\n                      1 + aug]\n    aug_knots[-1] += 1e-9 # want last knot inclusive\n\n    # prepare Haar Basis\n    bases = (x >= aug_knots[:-1]).astype(np.int) * \\\n            (x < aug_knots[1:]).astype(np.int)\n    bases[-1] = bases[-2][::-1] # force symmetric bases at 0 and 1\n\n    # do recursion from Hastie et al. vectorized\n    maxi = len(aug_knots) - 1\n    for m in range(2, spline_order + 2):\n        maxi -= 1\n\n        # left sub-basis\n        num = (x - aug_knots[:maxi])\n        num *= bases[:, :maxi]\n        denom = aug_knots[m-1 : maxi+m-1] - aug_knots[:maxi]\n        left = num/denom\n\n        # right sub-basis\n        num = (aug_knots[m : maxi+m] - x) * bases[:, 1:maxi+1]\n        denom = aug_knots[m:maxi+m] - aug_knots[1 : maxi+1]\n        right = num/denom\n\n        # track previous bases and update\n        prev_bases = bases[-2:]\n        bases = left + right\n\n    if periodic and spline_order > 0:\n        # make spline domain periodic\n        bases[:, :spline_order] = np.max([bases[:, :spline_order],\n                                          bases[:, -spline_order:]],\n                                         axis=0)\n        # remove extra splines used only for ensuring correct domain\n        bases = bases[:, :-spline_order]\n\n    # extrapolate\n    # since we have repeated end-knots, only the last 2 basis functions are\n    # non-zero at the end-knots, and they have equal and opposite gradient.\n    if (any(x_extrapolte_r) or any(x_extrapolte_l)) and spline_order>0:\n        bases[~x_interpolate] = 0.\n\n        denom = (aug_knots[spline_order:-1] - aug_knots[: -spline_order - 1])\n        left = prev_bases[:, :-1] / denom\n\n        denom = (aug_knots[spline_order+1:] - aug_knots[1: -spline_order])\n        right = prev_bases[:, 1:] / denom\n\n        grads = (spline_order) * (left - right)\n\n        if any(x_extrapolte_l):\n            val = grads[0] * x[x_extrapolte_l] + bases[-2]\n            bases[x_extrapolte_l] = val\n        if any(x_extrapolte_r):\n            val = grads[1] * (x[x_extrapolte_r] - 1) + bases[-1]\n            bases[x_extrapolte_r] = val\n    # get rid of the added values at 0, and 1\n    bases = bases[:-2]\n\n    if sparse:\n        return sp.sparse.csc_matrix(bases)\n\n    return bases"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ylogydu(y, u):\n    mask = (np.atleast_1d(y)!=0.)\n    out = np.zeros_like(u)\n    out[mask] = y[mask] * np.log(y[mask] / u[mask])\n    return out", "response": "Tool to give desired output for the limit as y -> 0 which is 0"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntooling to perform tree search via recursion useful for developing the grid in a grid search Parameters ---------- args : list of lists Returns ------- list of all the combinations of the elements in the input lists", "response": "def combine(*args):\n    \"\"\"\n    tool to perform tree search via recursion\n    useful for developing the grid in a grid search\n\n    Parameters\n    ----------\n    args : list of lists\n\n    Returns\n    -------\n    list of all the combinations of the elements in the input lists\n    \"\"\"\n    if hasattr(args, '__iter__') and (len(args) > 1):\n        subtree = combine(*args[:-1])\n        tree = []\n        for leaf in subtree:\n            for node in args[-1]:\n                if hasattr(leaf, '__iter__'):\n                    tree.append(leaf + [node])\n                else:\n                    tree.append([leaf] + [node])\n        return tree\n    else:\n        return [[arg] for arg in args[0]]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef isiterable(obj, reject_string=True):\n\n    iterable =  hasattr(obj, '__len__')\n\n    if reject_string:\n        iterable = iterable and not isinstance(obj, str)\n\n    return iterable", "response": "returns True if the object is iterable."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef check_iterable_depth(obj, max_depth=100):\n    def find_iterables(obj):\n        iterables = []\n        for item in obj:\n            if isiterable(item):\n                iterables += list(item)\n        return iterables\n\n    depth = 0\n    while (depth < max_depth) and isiterable(obj) and len(obj) > 0:\n        depth += 1\n        obj = find_iterables(obj)\n    return depth", "response": "find the maximum depth of nesting of the iterable"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomputing the tensor protuct of two matrices a and b.", "response": "def tensor_product(a, b, reshape=True):\n    \"\"\"\n    compute the tensor protuct of two matrices a and b\n\n    if a is (n, m_a), b is (n, m_b),\n    then the result is\n        (n, m_a * m_b) if reshape = True.\n    or\n        (n, m_a, m_b) otherwise\n\n    Parameters\n    ---------\n    a : array-like of shape (n, m_a)\n\n    b : array-like of shape (n, m_b)\n\n    reshape : bool, default True\n        whether to reshape the result to be 2-dimensional ie\n        (n, m_a * m_b)\n        or return a 3-dimensional tensor ie\n        (n, m_a, m_b)\n\n    Returns\n    -------\n    dense np.ndarray of shape\n        (n, m_a * m_b) if reshape = True.\n    or\n        (n, m_a, m_b) otherwise\n    \"\"\"\n    assert a.ndim == 2, 'matrix a must be 2-dimensional, but found {} dimensions'.format(a.ndim)\n    assert b.ndim == 2, 'matrix b must be 2-dimensional, but found {} dimensions'.format(b.ndim)\n\n    na, ma = a.shape\n    nb, mb = b.shape\n\n    if na != nb:\n        raise ValueError('both arguments must have the same number of samples')\n\n    if sp.sparse.issparse(a):\n        a = a.A\n\n    if sp.sparse.issparse(b):\n        b = b.A\n\n    tensor = a[..., :, None] * b[..., None, :]\n\n    if reshape:\n        return tensor.reshape(na, ma * mb)\n\n    return tensor"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef gradient(self, mu, dist):\n        return dist.levels/(mu*(dist.levels - mu))", "response": "Returns the derivative of the link function wrt mu"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef derivative(n, coef, derivative=2, periodic=False):\n    if n == 1:\n        # no derivative for constant functions\n        return sp.sparse.csc_matrix(0.)\n    D = sparse_diff(sp.sparse.identity(n + 2*derivative*periodic).tocsc(), n=derivative).tolil()\n\n    if periodic:\n        # wrap penalty\n        cols = D[:, :derivative]\n        D[:, -2 * derivative:-derivative] += cols * (-1) ** derivative\n\n        # do symmetric operation on lower half of matrix\n        n_rows = int((n + 2 * derivative)/2)\n        D[-n_rows:] = D[:n_rows][::-1, ::-1]\n\n        # keep only the center of the augmented matrix\n        D = D[derivative:-derivative, derivative:-derivative]\n    return D.dot(D.T).tocsc()", "response": "Builds a penalty matrix for P - Splines with continuous features with derivative."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef monotonicity_(n, coef, increasing=True):\n    if n != len(coef.ravel()):\n        raise ValueError('dimension mismatch: expected n equals len(coef), '\\\n                         'but found n = {}, coef.shape = {}.'\\\n                         .format(n, coef.shape))\n\n    if n==1:\n        # no monotonic penalty for constant functions\n        return sp.sparse.csc_matrix(0.)\n\n    if increasing:\n        # only penalize the case where coef_i-1 > coef_i\n        mask = sp.sparse.diags((np.diff(coef.ravel()) < 0).astype(float))\n    else:\n        # only penalize the case where coef_i-1 < coef_i\n        mask = sp.sparse.diags((np.diff(coef.ravel()) > 0).astype(float))\n\n    derivative = 1\n    D = sparse_diff(sp.sparse.identity(n).tocsc(), n=derivative) * mask\n    return D.dot(D.T).tocsc()", "response": "Builds a penalty matrix for P - Splines with continuous features with monotonicity."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nbuilds a matrix of zeros for features that should go unpenalized", "response": "def none(n, coef):\n    \"\"\"\n    Build a matrix of zeros for features that should go unpenalized\n\n    Parameters\n    ----------\n    n : int\n        number of splines\n    coef : unused\n        for compatibility with constraints\n\n    Returns\n    -------\n    penalty matrix : sparse csc matrix of shape (n,n)\n    \"\"\"\n    return sp.sparse.csc_matrix(np.zeros((n, n)))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef wrap_penalty(p, fit_linear, linear_penalty=0.):\n    def wrapped_p(n, *args):\n        if fit_linear:\n            if n == 1:\n                return sp.sparse.block_diag([linear_penalty], format='csc')\n            return sp.sparse.block_diag([linear_penalty,\n                                         p(n-1, *args)], format='csc')\n        else:\n            return p(n, *args)\n    return wrapped_p", "response": "This function wraps a function to account for unity penalty on the linear term of the current feature."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef loglikelihood(self, X, y, weights=None):\n        y = check_y(y, self.link, self.distribution, verbose=self.verbose)\n        mu = self.predict_mu(X)\n\n        if weights is not None:\n            weights = np.array(weights).astype('f').ravel()\n            weights = check_array(weights, name='sample weights',\n                                  ndim=1, verbose=self.verbose)\n            check_lengths(y, weights)\n        else:\n            weights = np.ones_like(y).astype('float64')\n\n        return self._loglikelihood(y, mu, weights=weights)", "response": "compute the log - likelihood of the dataset using the current model"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncomputes the log - likelihood of the dataset using the current model and target values y mu and weights", "response": "def _loglikelihood(self, y, mu, weights=None):\n        \"\"\"\n        compute the log-likelihood of the dataset using the current model\n\n        Parameters\n        ---------\n        y : array-like of shape (n,)\n            containing target values\n        mu : array-like of shape (n_samples,)\n            expected value of the targets given the model and inputs\n        weights : array-like of shape (n,), optional\n            containing sample weights\n\n        Returns\n        -------\n        log-likelihood : np.array of shape (n,)\n            containing log-likelihood scores\n        \"\"\"\n        return self.distribution.log_pdf(y=y, mu=mu, weights=weights).sum()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef predict_mu(self, X):\n        if not self._is_fitted:\n            raise AttributeError('GAM has not been fitted. Call fit first.')\n\n        X = check_X(X, n_feats=self.statistics_['m_features'],\n                    edge_knots=self.edge_knots_, dtypes=self.dtype,\n                    features=self.feature, verbose=self.verbose)\n\n        lp = self._linear_predictor(X)\n        return self.link.mu(lp, self.distribution)", "response": "predict_mu computes the expected value of target given model and input X"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _modelmat(self, X, term=-1):\n        X = check_X(X, n_feats=self.statistics_['m_features'],\n                    edge_knots=self.edge_knots_, dtypes=self.dtype,\n                    features=self.feature, verbose=self.verbose)\n\n        return self.terms.build_columns(X, term=term)", "response": "Builds a model matrix B out of the spline basis for each feature and returns the model matrix for each feature."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _cholesky(self, A, **kwargs):\n        # create appropriate-size diagonal matrix\n        if sp.sparse.issparse(A):\n            diag = sp.sparse.eye(A.shape[0])\n        else:\n            diag = np.eye(A.shape[0])\n\n        constraint_l2 = self._constraint_l2\n        while constraint_l2 <= self._constraint_l2_max:\n            try:\n                L = cholesky(A, **kwargs)\n                self._constraint_l2 = constraint_l2\n                return L\n            except NotPositiveDefiniteError:\n                if self.verbose:\n                    warnings.warn('Matrix is not positive definite. \\n'\\\n                                  'Increasing l2 reg by factor of 10.',\n                                  stacklevel=2)\n                A -= constraint_l2 * diag\n                constraint_l2 *= 10\n                A += constraint_l2 * diag\n\n        raise NotPositiveDefiniteError('Matrix is not positive \\n'\n                                       'definite.')", "response": "This method is used to handle potential problems with the cholesky decomposition."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the GAM block - diagonal constraint matrix for the given set of model entries.", "response": "def _C(self):\n        \"\"\"\n        builds the GAM block-diagonal constraint matrix in quadratic form\n        out of constraint matrices specified for each feature.\n\n        behaves like a penalty, but with a very large lambda value, ie 1e6.\n\n        Parameters\n        ---------\n        None\n\n        Returns\n        -------\n        C : sparse CSC matrix containing the model constraints in quadratic form\n        \"\"\"\n        return self.terms.build_constraints(self.coef_,\n                                            self._constraint_lam,\n                                            self._constraint_l2)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompute the pseudo data for a PIRLS iterations.", "response": "def _pseudo_data(self, y, lp, mu):\n        \"\"\"\n        compute the pseudo data for a PIRLS iterations\n\n        Parameters\n        ---------\n        y : array-like of shape (n,)\n            containing target data\n        lp : array-like of shape (n,)\n            containing linear predictions by the model\n        mu : array-like of shape (n_samples,)\n            expected value of the targets given the model and inputs\n\n        Returns\n        -------\n        pseudo_data : np.array of shape (n,)\n        \"\"\"\n        return lp + (y - mu) * self.link.gradient(mu, self.distribution)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _W(self, mu, weights, y=None):\n        return sp.sparse.diags((self.link.gradient(mu, self.distribution)**2 *\n                                self.distribution.V(mu=mu) *\n                                weights ** -1)**-0.5)", "response": "compute the PIRLS weights for model predictions"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _mask(self, weights):\n        mask = (np.abs(weights) >= np.sqrt(EPS)) * np.isfinite(weights)\n        if mask.sum() == 0:\n            raise OptimizationError('PIRLS optimization has diverged.\\n' +\n                'Try increasing regularization, or specifying an initial value for self.coef_')\n        return mask", "response": "Returns a boolean array that contains the mask at which the weights are greater than the machine epsilon."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _initial_estimate(self, y, modelmat):\n\n        # do a simple initialization for LinearGAMs\n        if isinstance(self, LinearGAM):\n            n, m = modelmat.shape\n            return np.ones(m) * np.sqrt(EPS)\n\n        # transform the problem to the linear scale\n        y = deepcopy(y).astype('float64')\n        y[y == 0] += .01 # edge case for log link, inverse link, and logit link\n        y[y == 1] -= .01 # edge case for logit link\n\n        y_ = self.link.link(y, self.distribution)\n        y_ = make_2d(y_, verbose=False)\n        assert np.isfinite(y_).all(), \"transformed response values should be well-behaved.\"\n\n        # solve the linear problem\n        return np.linalg.solve(load_diagonal(modelmat.T.dot(modelmat).A),\n                               modelmat.T.dot(y_))", "response": "This method initializes the initial estimate for the model coefficients."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nperform stable PIRLS iterations to estimate GAM coefficients for a specific entry in the log - likelihood model.", "response": "def _pirls(self, X, Y, weights):\n        \"\"\"\n        Performs stable PIRLS iterations to estimate GAM coefficients\n\n        Parameters\n        ---------\n        X : array-like of shape (n_samples, m_features)\n            containing input data\n        Y : array-like of shape (n,)\n            containing target data\n        weights : array-like of shape (n,)\n            containing sample weights\n\n        Returns\n        -------\n        None\n        \"\"\"\n        modelmat = self._modelmat(X) # build a basis matrix for the GLM\n        n, m = modelmat.shape\n\n        # initialize GLM coefficients if model is not yet fitted\n        if (not self._is_fitted\n            or len(self.coef_) != self.terms.n_coefs\n            or not np.isfinite(self.coef_).all()):\n\n           # initialize the model\n           self.coef_ = self._initial_estimate(Y, modelmat)\n\n        assert np.isfinite(self.coef_).all(), \"coefficients should be well-behaved, but found: {}\".format(self.coef_)\n\n        P = self._P()\n        S = sp.sparse.diags(np.ones(m) * np.sqrt(EPS)) # improve condition\n        # S += self._H # add any user-chosen minumum penalty to the diagonal\n\n        # if we dont have any constraints, then do cholesky now\n        if not self.terms.hasconstraint:\n            E = self._cholesky(S + P, sparse=False, verbose=self.verbose)\n\n        min_n_m = np.min([m,n])\n        Dinv = np.zeros((min_n_m + m, m)).T\n\n        for _ in range(self.max_iter):\n\n            # recompute cholesky if needed\n            if self.terms.hasconstraint:\n                P = self._P()\n                C = self._C()\n                E = self._cholesky(S + P + C, sparse=False, verbose=self.verbose)\n\n            # forward pass\n            y = deepcopy(Y) # for simplicity\n            lp = self._linear_predictor(modelmat=modelmat)\n            mu = self.link.mu(lp, self.distribution)\n            W = self._W(mu, weights, y) # create pirls weight matrix\n\n            # check for weghts == 0, nan, and update\n            mask = self._mask(W.diagonal())\n            y = y[mask] # update\n            lp = lp[mask] # update\n            mu = mu[mask] # update\n            W = sp.sparse.diags(W.diagonal()[mask]) # update\n\n            # PIRLS Wood pg 183\n            pseudo_data = W.dot(self._pseudo_data(y, lp, mu))\n\n            # log on-loop-start stats\n            self._on_loop_start(vars())\n\n            WB = W.dot(modelmat[mask,:]) # common matrix product\n            Q, R = np.linalg.qr(WB.A)\n\n            if not np.isfinite(Q).all() or not np.isfinite(R).all():\n                raise ValueError('QR decomposition produced NaN or Inf. '\\\n                                     'Check X data.')\n\n            # need to recompute the number of singular values\n            min_n_m = np.min([m, n, mask.sum()])\n            Dinv = np.zeros((m, min_n_m))\n\n            # SVD\n            U, d, Vt = np.linalg.svd(np.vstack([R, E]))\n            svd_mask = d <= (d.max() * np.sqrt(EPS)) # mask out small singular values\n\n            np.fill_diagonal(Dinv, d**-1) # invert the singular values\n            U1 = U[:min_n_m,:min_n_m] # keep only top corner of U\n\n            # update coefficients\n            B = Vt.T.dot(Dinv).dot(U1.T).dot(Q.T)\n            coef_new = B.dot(pseudo_data).flatten()\n            diff = np.linalg.norm(self.coef_ - coef_new)/np.linalg.norm(coef_new)\n            self.coef_ = coef_new # update\n\n            # log on-loop-end stats\n            self._on_loop_end(vars())\n\n            # check convergence\n            if diff < self.tol:\n                break\n\n        # estimate statistics even if not converged\n        self._estimate_model_statistics(Y, modelmat, inner=None, BW=WB.T, B=B,\n                                        weights=weights, U1=U1)\n        if diff < self.tol:\n            return\n\n        print('did not converge')\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nperform callbacks that are called when the loop starts.", "response": "def _on_loop_start(self, variables):\n        \"\"\"\n        performs on-loop-start actions like callbacks\n\n        variables contains local namespace variables.\n\n        Parameters\n        ---------\n        variables : dict of available variables\n\n        Returns\n        -------\n        None\n        \"\"\"\n        for callback in self.callbacks:\n            if hasattr(callback, 'on_loop_start'):\n                self.logs_[str(callback)].append(callback.on_loop_start(**variables))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nperforming on - loop - end actions like callbacks variables contains local namespace variables.", "response": "def _on_loop_end(self, variables):\n        \"\"\"\n        performs on-loop-end actions like callbacks\n\n        variables contains local namespace variables.\n\n        Parameters\n        ---------\n        variables : dict of available variables\n\n        Returns\n        -------\n        None\n        \"\"\"\n        for callback in self.callbacks:\n            if hasattr(callback, 'on_loop_end'):\n                self.logs_[str(callback)].append(callback.on_loop_end(**variables))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fit(self, X, y, weights=None):\n\n        # validate parameters\n        self._validate_params()\n\n        # validate data\n        y = check_y(y, self.link, self.distribution, verbose=self.verbose)\n        X = check_X(X, verbose=self.verbose)\n        check_X_y(X, y)\n\n        if weights is not None:\n            weights = np.array(weights).astype('f').ravel()\n            weights = check_array(weights, name='sample weights',\n                                  ndim=1, verbose=self.verbose)\n            check_lengths(y, weights)\n        else:\n            weights = np.ones_like(y).astype('float64')\n\n        # validate data-dependent parameters\n        self._validate_data_dep_params(X)\n\n        # set up logging\n        if not hasattr(self, 'logs_'):\n            self.logs_ = defaultdict(list)\n\n        # begin capturing statistics\n        self.statistics_ = {}\n        self.statistics_['n_samples'] = len(y)\n        self.statistics_['m_features'] = X.shape[1]\n\n        # optimize\n        self._pirls(X, y, weights)\n        # if self._opt == 0:\n        #     self._pirls(X, y, weights)\n        # if self._opt == 1:\n        #     self._pirls_naive(X, y)\n        return self", "response": "Fit the generalized additive model."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef deviance_residuals(self, X, y, weights=None, scaled=False):\n        if not self._is_fitted:\n            raise AttributeError('GAM has not been fitted. Call fit first.')\n\n        y = check_y(y, self.link, self.distribution, verbose=self.verbose)\n        X = check_X(X, n_feats=self.statistics_['m_features'],\n                    edge_knots=self.edge_knots_, dtypes=self.dtype,\n                    features=self.feature, verbose=self.verbose)\n        check_X_y(X, y)\n\n        if weights is not None:\n            weights = np.array(weights).astype('f').ravel()\n            weights = check_array(weights, name='sample weights',\n                                  ndim=1, verbose=self.verbose)\n            check_lengths(y, weights)\n        else:\n            weights = np.ones_like(y).astype('float64')\n\n        mu = self.predict_mu(X)\n        sign = np.sign(y-mu)\n        return sign * self.distribution.deviance(y, mu,\n                                                 weights=weights,\n                                                 scaled=scaled) ** 0.5", "response": "This method computes the deviance residuals of the model."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _estimate_AIC(self, y, mu, weights=None):\n        estimated_scale = not(self.distribution._known_scale) # if we estimate the scale, that adds 2 dof\n        return -2*self._loglikelihood(y=y, mu=mu, weights=weights) + \\\n                2*self.statistics_['edof'] + 2*estimated_scale", "response": "estimate the Akaike Information Criterion for a specific entry set"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _estimate_AICc(self, y, mu, weights=None):\n        edof = self.statistics_['edof']\n        if self.statistics_['AIC'] is None:\n            self.statistics_['AIC'] = self._estimate_AIC(y, mu, weights)\n        return self.statistics_['AIC'] + 2*(edof + 1)*(edof + 2)/(y.shape[0] - edof -2)", "response": "estimate the corrected Akaike Information Criterion AIC"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _estimate_r2(self, X=None, y=None, mu=None, weights=None):\n        if mu is None:\n            mu = self.predict_mu(X=X)\n\n        if weights is None:\n            weights = np.ones_like(y).astype('float64')\n\n        null_mu = y.mean() * np.ones_like(y).astype('float64')\n\n        null_d = self.distribution.deviance(y=y, mu=null_mu, weights=weights)\n        full_d = self.distribution.deviance(y=y, mu=mu, weights=weights)\n\n        null_ll = self._loglikelihood(y=y, mu=null_mu, weights=weights)\n        full_ll = self._loglikelihood(y=y, mu=mu, weights=weights)\n\n        r2 = OrderedDict()\n        r2['explained_deviance'] = 1. - full_d.sum()/null_d.sum()\n        r2['McFadden'] = full_ll/null_ll\n        r2['McFadden_adj'] = 1. - (full_ll - self.statistics_['edof'])/null_ll\n\n        return r2", "response": "estimate some pseudo R^2 values for the log - likelihood of the current state of the object"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngeneralizing Cross Validation and Un - Biased Risk Estimator.", "response": "def _estimate_GCV_UBRE(self, X=None, y=None, modelmat=None, gamma=1.4,\n                           add_scale=True, weights=None):\n        \"\"\"\n        Generalized Cross Validation and Un-Biased Risk Estimator.\n\n        UBRE is used when the scale parameter is known,\n        like Poisson and Binomial families.\n\n        Parameters\n        ----------\n        y : array-like of shape (n_samples,)\n            output data vector\n        modelmat : array-like, default: None\n            contains the spline basis for each feature evaluated at the input\n        gamma : float, default: 1.4\n            serves as a weighting to increase the impact of the influence matrix\n            on the score\n        add_scale : boolean, default: True\n            UBRE score can be negative because the distribution scale\n            is subtracted. to keep things positive we can add the scale back.\n        weights : array-like shape (n_samples,) or None, default: None\n            containing sample weights\n            if None, defaults to array of ones\n\n        Returns\n        -------\n        score : float\n            Either GCV or UBRE, depending on if the scale parameter is known.\n\n        Notes\n        -----\n        Sometimes the GCV or UBRE selected model is deemed to be too wiggly,\n        and a smoother model is desired. One way to achieve this, in a\n        systematic way, is to increase the amount that each model effective\n        degree of freedom counts, in the GCV or UBRE score, by a factor \u03b3 \u2265 1\n\n        see Wood 2006 pg. 177-182, 220 for more details.\n        \"\"\"\n        if gamma < 1:\n            raise ValueError('gamma scaling should be greater than 1, '\\\n                             'but found gamma = {}',format(gamma))\n\n        if modelmat is None:\n            modelmat = self._modelmat(X)\n\n        if weights is None:\n            weights = np.ones_like(y).astype('float64')\n\n        lp = self._linear_predictor(modelmat=modelmat)\n        mu = self.link.mu(lp, self.distribution)\n        n = y.shape[0]\n        edof = self.statistics_['edof']\n\n        GCV = None\n        UBRE = None\n\n        dev = self.distribution.deviance(mu=mu, y=y, scaled=False, weights=weights).sum()\n\n        if self.distribution._known_scale:\n            # scale is known, use UBRE\n            scale = self.distribution.scale\n            UBRE = 1./n *  dev - (~add_scale)*(scale) + 2.*gamma/n * edof * scale\n        else:\n            # scale unkown, use GCV\n            GCV = (n * dev) / (n - gamma * edof)**2\n        return (GCV, UBRE)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nestimating the p - values for all features", "response": "def _estimate_p_values(self):\n        \"\"\"estimate the p-values for all features\n        \"\"\"\n        if not self._is_fitted:\n            raise AttributeError('GAM has not been fitted. Call fit first.')\n\n        p_values = []\n        for term_i in range(len(self.terms)):\n            p_values.append(self._compute_p_value(term_i))\n\n        return p_values"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _compute_p_value(self, term_i):\n        if not self._is_fitted:\n            raise AttributeError('GAM has not been fitted. Call fit first.')\n\n        idxs = self.terms.get_coef_indices(term_i)\n        cov = self.statistics_['cov'][idxs][:, idxs]\n        coef = self.coef_[idxs]\n\n        # center non-intercept term functions\n        if isinstance(self.terms[term_i], SplineTerm):\n            coef -= coef.mean()\n\n        inv_cov, rank = sp.linalg.pinv(cov, return_rank=True)\n        score = coef.T.dot(inv_cov).dot(coef)\n\n        # compute p-values\n        if self.distribution._known_scale:\n            # for known scale use chi-squared statistic\n            return 1 - sp.stats.chi2.cdf(x=score, df=rank)\n        else:\n            # if scale has been estimated, prefer to use f-statisitc\n            score = score / rank\n            return 1 - sp.stats.f.cdf(score, rank, self.statistics_['n_samples'] - self.statistics_['edof'])", "response": "compute the p - value of the desired feature and term"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nestimates confidence intervals for the current state of the object.", "response": "def confidence_intervals(self, X, width=.95, quantiles=None):\n        \"\"\"estimate confidence intervals for the model.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, m_features)\n            Input data matrix\n        width : float on [0,1], optional\n        quantiles : array-like of floats in (0, 1), optional\n            Instead of specifying the prediciton width, one can specify the\n            quantiles. So ``width=.95`` is equivalent to ``quantiles=[.025, .975]``\n\n        Returns\n        -------\n        intervals: np.array of shape (n_samples, 2 or len(quantiles))\n\n\n        Notes\n        -----\n        Wood 2006, section 4.9\n            Confidence intervals based on section 4.8 rely on large sample results to deal with\n            non-Gaussian distributions, and treat the smoothing parameters as fixed, when in\n            reality they are estimated from the data.\n        \"\"\"\n        if not self._is_fitted:\n            raise AttributeError('GAM has not been fitted. Call fit first.')\n\n        X = check_X(X, n_feats=self.statistics_['m_features'],\n                    edge_knots=self.edge_knots_, dtypes=self.dtype,\n                    features=self.feature, verbose=self.verbose)\n\n        return self._get_quantiles(X, width, quantiles, prediction=False)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_quantiles(self, X, width, quantiles, modelmat=None, lp=None,\n                       prediction=False, xform=True, term=-1):\n        \"\"\"\n        estimate prediction intervals for LinearGAM\n\n        Parameters\n        ----------\n        X : array\n            input data of shape (n_samples, m_features)\n        width : float on (0, 1)\n        quantiles : array-like of floats on (0, 1)\n            instead of specifying the prediciton width, one can specify the\n            quantiles. so width=.95 is equivalent to quantiles=[.025, .975]\n        modelmat : array of shape or None, default: None\n        lp : array or None, default: None\n        prediction : bool, default: True.\n            whether to compute prediction intervals (True)\n            or confidence intervals (False)\n        xform : bool, default: True,\n            whether to apply the inverse link function and return values\n            on the scale of the distribution mean (True),\n            or to keep on the linear predictor scale (False)\n        term : int, default: -1\n\n        Returns\n        -------\n        intervals: np.array of shape (n_samples, 2 or len(quantiles))\n\n        Notes\n        -----\n        when the scale parameter is known, then we can proceed with a large\n        sample approximation to the distribution of the model coefficients\n        where B_hat ~ Normal(B, cov)\n\n        when the scale parameter is unknown, then we have to account for\n        the distribution of the estimated scale parameter, which is Chi-squared.\n        since we scale our estimate of B_hat by the sqrt of estimated scale,\n        we get a t distribution: Normal / sqrt(Chi-squared) ~ t\n\n        see Simon Wood section 1.3.2, 1.3.3, 1.5.5, 2.1.5\n        \"\"\"\n        if quantiles is not None:\n            quantiles = np.atleast_1d(quantiles)\n        else:\n            alpha = (1 - width)/2.\n            quantiles = [alpha, 1 - alpha]\n        for quantile in quantiles:\n            if (quantile >= 1) or (quantile <= 0):\n                raise ValueError('quantiles must be in (0, 1), but found {}'\\\n                                 .format(quantiles))\n\n        if modelmat is None:\n            modelmat = self._modelmat(X, term=term)\n        if lp is None:\n            lp = self._linear_predictor(modelmat=modelmat, term=term)\n\n        idxs = self.terms.get_coef_indices(term)\n        cov = self.statistics_['cov'][idxs][:, idxs]\n\n        var = (modelmat.dot(cov) * modelmat.A).sum(axis=1)\n        if prediction:\n            var += self.distribution.scale\n\n        lines = []\n        for quantile in quantiles:\n            if self.distribution._known_scale:\n                q = sp.stats.norm.ppf(quantile)\n            else:\n                q = sp.stats.t.ppf(quantile, df=self.statistics_['n_samples'] -\n                                                self.statistics_['edof'])\n\n            lines.append(lp + q * var**0.5)\n        lines = np.vstack(lines).T\n\n        if xform:\n            lines = self.link.mu(lines, self.distribution)\n        return lines", "response": "This function takes an array of input data and returns the quantiles for LinearGAMClusterer."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _flatten_mesh(self, Xs, term):\n        n = Xs[0].size\n\n        if self.terms[term].istensor:\n            terms = self.terms[term]\n        else:\n            terms = [self.terms[term]]\n\n        X = np.zeros((n, self.statistics_['m_features']))\n        for term_, x in zip(terms, Xs):\n            X[:, term_.feature] = x.ravel()\n        return X", "response": "flatten the mesh and distribute into a feature matrix"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef generate_X_grid(self, term, n=100, meshgrid=False):\n        if not self._is_fitted:\n            raise AttributeError('GAM has not been fitted. Call fit first.')\n\n        # cant do Intercept\n        if self.terms[term].isintercept:\n            raise ValueError('cannot create grid for intercept term')\n\n        # process each subterm in a TensorTerm\n        if self.terms[term].istensor:\n            Xs = []\n            for term_ in self.terms[term]:\n                Xs.append(np.linspace(term_.edge_knots_[0],\n                                      term_.edge_knots_[1],\n                                      num=n))\n\n            Xs = np.meshgrid(*Xs, indexing='ij')\n            if meshgrid:\n                return tuple(Xs)\n            else:\n                return self._flatten_mesh(Xs, term=term)\n\n        # all other Terms\n        elif hasattr(self.terms[term], 'edge_knots_'):\n            x = np.linspace(self.terms[term].edge_knots_[0],\n                            self.terms[term].edge_knots_[1],\n                            num=n)\n\n            if meshgrid:\n                return (x,)\n\n            # fill in feature matrix with only relevant features for this term\n            X = np.zeros((n, self.statistics_['m_features']))\n            X[:, self.terms[term].feature] = x\n            if getattr(self.terms[term], 'by', None) is not None:\n                X[:, self.terms[term].by] = 1.\n\n            return X\n\n        # dont know what to do here\n        else:\n            raise TypeError('Unexpected term type: {}'.format(self.terms[term]))", "response": "generate a nice grid of X data points for a given term"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the partial dependence functions for the GAM term and optionally a grid of points.", "response": "def partial_dependence(self, term, X=None, width=None, quantiles=None,\n                           meshgrid=False):\n        \"\"\"\n        Computes the term functions for the GAM\n        and possibly their confidence intervals.\n\n        if both width=None and quantiles=None,\n        then no confidence intervals are computed\n\n        Parameters\n        ----------\n        term : int, optional\n            Term for which to compute the partial dependence functions.\n\n        X : array-like with input data, optional\n\n            if `meshgrid=False`, then `X` should be an array-like\n            of shape (n_samples, m_features).\n\n            if `meshgrid=True`, then `X` should be a tuple containing\n            an array for each feature in the term.\n\n            if None, an equally spaced grid of points is generated.\n\n        width : float on (0, 1), optional\n            Width of the confidence interval.\n\n        quantiles : array-like of floats on (0, 1), optional\n            instead of specifying the prediciton width, one can specify the\n            quantiles. so width=.95 is equivalent to quantiles=[.025, .975].\n            if None, defaults to width.\n\n        meshgrid : bool, whether to return and accept meshgrids.\n\n            Useful for creating outputs that are suitable for\n            3D plotting.\n\n            Note, for simple terms with no interactions, the output\n            of this function will be the same for ``meshgrid=True`` and\n            ``meshgrid=False``, but the inputs will need to be different.\n\n        Returns\n        -------\n        pdeps : np.array of shape (n_samples,)\n        conf_intervals : list of length len(term)\n            containing np.arrays of shape (n_samples, 2 or len(quantiles))\n\n        Raises\n        ------\n        ValueError :\n            If the term requested is an intercept\n            since it does not make sense to process the intercept term.\n\n        See Also\n        --------\n        generate_X_grid : for help creating meshgrids.\n        \"\"\"\n        if not self._is_fitted:\n            raise AttributeError('GAM has not been fitted. Call fit first.')\n\n        if not isinstance(term, int):\n            raise ValueError('term must be an integer, but found term: {}'.format(term))\n\n        # ensure term exists\n        if (term >= len(self.terms)) or (term < -1):\n            raise ValueError('Term {} out of range for model with {} terms'\\\n                             .format(term, len(self.terms)))\n\n        # cant do Intercept\n        if self.terms[term].isintercept:\n            raise ValueError('cannot create grid for intercept term')\n\n        if X is None:\n            X = self.generate_X_grid(term=term, meshgrid=meshgrid)\n\n        if meshgrid:\n            if not isinstance(X, tuple):\n                raise ValueError('X must be a tuple of grids if `meshgrid=True`, '\\\n                                 'but found X: {}'.format(X))\n            shape = X[0].shape\n\n            X = self._flatten_mesh(X, term=term)\n            X = check_X(X, n_feats=self.statistics_['m_features'],\n                        edge_knots=self.edge_knots_, dtypes=self.dtype,\n                        features=self.feature, verbose=self.verbose)\n\n        modelmat = self._modelmat(X, term=term)\n        pdep = self._linear_predictor(modelmat=modelmat, term=term)\n        out = [pdep]\n\n        compute_quantiles = (width is not None) or (quantiles is not None)\n        if compute_quantiles:\n            conf_intervals = self._get_quantiles(X, width=width,\n                                                 quantiles=quantiles,\n                                                 modelmat=modelmat,\n                                                 lp=pdep,\n                                                 term=term,\n                                                 xform=False)\n\n            out += [conf_intervals]\n\n        if meshgrid:\n            for i, array in enumerate(out):\n                # add extra dimensions arising from multiple confidence intervals\n                if array.ndim > 1:\n                    depth = array.shape[-1]\n                    shape += (depth,)\n                out[i] = np.reshape(array, shape)\n\n        if compute_quantiles:\n            return out\n\n        return out[0]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef summary(self):\n        if not self._is_fitted:\n            raise AttributeError('GAM has not been fitted. Call fit first.')\n\n        # high-level model summary\n        width_details = 47\n        width_results = 58\n\n        model_fmt = [\n            (self.__class__.__name__, 'model_details', width_details),\n            ('', 'model_results', width_results)\n            ]\n\n        model_details = []\n\n        objective = 'UBRE' if self.distribution._known_scale else 'GCV'\n\n        model_details.append({'model_details': space_row('Distribution:', self.distribution.__class__.__name__, total_width=width_details),\n                              'model_results': space_row('Effective DoF:', str(np.round(self.statistics_['edof'], 4)), total_width=width_results)})\n        model_details.append({'model_details': space_row('Link Function:', self.link.__class__.__name__, total_width=width_details),\n                              'model_results': space_row('Log Likelihood:', str(np.round(self.statistics_['loglikelihood'], 4)), total_width=width_results)})\n        model_details.append({'model_details': space_row('Number of Samples:', str(self.statistics_['n_samples']), total_width=width_details),\n                              'model_results': space_row('AIC: ', str(np.round(self.statistics_['AIC'], 4)), total_width=width_results)})\n        model_details.append({'model_results': space_row('AICc: ', str(np.round(self.statistics_['AICc'], 4)), total_width=width_results)})\n        model_details.append({'model_results': space_row(objective + ':', str(np.round(self.statistics_[objective], 4)), total_width=width_results)})\n        model_details.append({'model_results': space_row('Scale:', str(np.round(self.statistics_['scale'], 4)), total_width=width_results)})\n        model_details.append({'model_results': space_row('Pseudo R-Squared:', str(np.round(self.statistics_['pseudo_r2']['explained_deviance'], 4)), total_width=width_results)})\n\n        # term summary\n        data = []\n\n        for i, term in enumerate(self.terms):\n\n            # TODO bug: if the number of samples is less than the number of coefficients\n            # we cant get the edof per term\n            if len(self.statistics_['edof_per_coef']) == len(self.coef_):\n                idx = self.terms.get_coef_indices(i)\n                edof = np.round(self.statistics_['edof_per_coef'][idx].sum(), 1)\n            else:\n                edof = ''\n\n            term_data = {\n                        'feature_func': repr(term),\n                        'lam': '' if term.isintercept else np.round(flatten(term.lam), 4),\n                        'rank': '{}'.format(term.n_coefs),\n                        'edof': '{}'.format(edof),\n                        'p_value': '%.2e'%(self.statistics_['p_values'][i]),\n                        'sig_code': sig_code(self.statistics_['p_values'][i])\n                        }\n\n            data.append(term_data)\n\n        fmt = [\n            ('Feature Function', 'feature_func', 33),\n            ('Lambda', 'lam', 20),\n            ('Rank', 'rank', 12),\n            ('EDoF', 'edof', 12),\n            ('P > x', 'p_value', 12),\n            ('Sig. Code', 'sig_code', 12)\n            ]\n\n        print( TablePrinter(model_fmt, ul='=', sep=' ')(model_details) )\n        print(\"=\"*106)\n        print( TablePrinter(fmt, ul='=')(data) )\n        print(\"=\"*106)\n        print(\"Significance codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\")\n        print()\n        print(\"WARNING: Fitting splines and a linear function to a feature introduces a model identifiability problem\\n\" \\\n              \"         which can cause p-values to appear significant when they are not.\")\n        print()\n        print(\"WARNING: p-values calculated in this manner behave correctly for un-penalized models or models with\\n\" \\\n              \"         known smoothing parameters, but when smoothing parameters have been estimated, the p-values\\n\" \\\n              \"         are typically lower than they should be, meaning that the tests reject the null too readily.\")\n\n        # P-VALUE BUG\n        warnings.warn(\"KNOWN BUG: p-values computed in this summary are likely \"\\\n                      \"much smaller than they should be. \\n \\n\"\\\n                      \"Please do not make inferences based on these values! \\n\\n\"\\\n                      \"Collaborate on a solution, and stay up to date at: \\n\"\\\n                      \"github.com/dswah/pyGAM/issues/163 \\n\", stacklevel=2)", "response": "produce a summary of the model statistics"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef gridsearch(self, X, y, weights=None, return_scores=False,\n                   keep_best=True, objective='auto', progress=True,\n                   **param_grids):\n        \"\"\"\n        Performs a grid search over a space of parameters for a given\n        objective\n\n        Warnings\n        --------\n        ``gridsearch`` is lazy and will not remove useless combinations\n        from the search space, eg.\n\n        >>> n_splines=np.arange(5,10), fit_splines=[True, False]\n\n        will result in 10 loops, of which 5 are equivalent because\n        ``fit_splines = False``\n\n        Also, it is not recommended to search over a grid that alternates\n        between known scales and unknown scales, as the scores of the\n        candidate models will not be comparable.\n\n        Parameters\n        ----------\n        X : array-like\n          input data of shape (n_samples, m_features)\n\n        y : array-like\n          label data of shape (n_samples,)\n\n        weights : array-like shape (n_samples,), optional\n            sample weights\n\n        return_scores : boolean, optional\n            whether to return the hyperpamaters and score for each element\n            in the grid\n\n        keep_best : boolean, optional\n            whether to keep the best GAM as self.\n\n        objective : {'auto', 'AIC', 'AICc', 'GCV', 'UBRE'}, optional\n            Metric to optimize.\n            If `auto`, then grid search will optimize `GCV` for models with unknown\n            scale and `UBRE` for models with known scale.\n\n        progress : bool, optional\n            whether to display a progress bar\n\n        **kwargs\n            pairs of parameters and iterables of floats, or\n            parameters and iterables of iterables of floats.\n\n            If no parameter are specified, ``lam=np.logspace(-3, 3, 11)`` is used.\n            This results in a 11 points, placed diagonally across lam space.\n\n            If grid is iterable of iterables of floats,\n            the outer iterable must have length ``m_features``.\n            the cartesian product of the subgrids in the grid will be tested.\n\n            If grid is a 2d numpy array,\n            each row of the array will be tested.\n\n            The method will make a grid of all the combinations of the parameters\n            and fit a GAM to each combination.\n\n\n        Returns\n        -------\n        if ``return_scores=True``:\n            model_scores: dict containing each fitted model as keys and corresponding\n            objective scores as values\n        else:\n            self: ie possibly the newly fitted model\n\n        Examples\n        --------\n        For a model with 4 terms, and where we expect 4 lam values,\n        our search space for lam must have 4 dimensions.\n\n        We can search the space in 3 ways:\n\n        1. via cartesian product by specifying the grid as a list.\n        our grid search will consider ``11 ** 4`` points:\n\n        >>> lam = np.logspace(-3, 3, 11)\n        >>> lams = [lam] * 4\n        >>> gam.gridsearch(X, y, lam=lams)\n\n        2. directly by specifying the grid as a np.ndarray.\n        This is useful for when the dimensionality of the search space\n        is very large, and we would prefer to execute a randomized search:\n\n        >>> lams = np.exp(np.random.random(50, 4) * 6 - 3)\n        >>> gam.gridsearch(X, y, lam=lams)\n\n        3. copying grids for parameters with multiple dimensions.\n        if we specify a 1D np.ndarray for lam, we are implicitly testing the\n        space where all points have the same value\n\n        >>> gam.gridsearch(lam=np.logspace(-3, 3, 11))\n\n        is equivalent to:\n\n        >>> lam = np.logspace(-3, 3, 11)\n        >>> lams = np.array([lam] * 4)\n        >>> gam.gridsearch(X, y, lam=lams)\n        \"\"\"\n        # check if model fitted\n        if not self._is_fitted:\n            self._validate_params()\n            self._validate_data_dep_params(X)\n\n        y = check_y(y, self.link, self.distribution, verbose=self.verbose)\n        X = check_X(X, verbose=self.verbose)\n        check_X_y(X, y)\n\n        if weights is not None:\n            weights = np.array(weights).astype('f').ravel()\n            weights = check_array(weights, name='sample weights',\n                                  ndim=1, verbose=self.verbose)\n            check_lengths(y, weights)\n        else:\n            weights = np.ones_like(y).astype('float64')\n\n        # validate objective\n        if objective not in ['auto', 'GCV', 'UBRE', 'AIC', 'AICc']:\n            raise ValueError(\"objective mut be in \"\\\n                             \"['auto', 'GCV', 'UBRE', 'AIC', 'AICc'], '\\\n                             'but found objective = {}\".format(objective))\n\n        # check objective\n        if self.distribution._known_scale:\n            if objective == 'GCV':\n                raise ValueError('GCV should be used for models with'\\\n                                 'unknown scale')\n            if objective == 'auto':\n                objective = 'UBRE'\n\n        else:\n            if objective == 'UBRE':\n                raise ValueError('UBRE should be used for models with '\\\n                                 'known scale')\n            if objective == 'auto':\n                objective = 'GCV'\n\n        # if no params, then set up default gridsearch\n        if not bool(param_grids):\n            param_grids['lam'] = np.logspace(-3, 3, 11)\n\n        # validate params\n        admissible_params = list(self.get_params()) + self._plural\n        params = []\n        grids = []\n        for param, grid in list(param_grids.items()):\n\n            # check param exists\n            if param not in (admissible_params):\n                raise ValueError('unknown parameter: {}'.format(param))\n\n            # check grid is iterable at all\n            if not (isiterable(grid) and (len(grid) > 1)): \\\n                raise ValueError('{} grid must either be iterable of '\n                                 'iterables, or an iterable of lengnth > 1, '\\\n                                 'but found {}'.format(param, grid))\n\n            # prepare grid\n            if any(isiterable(g) for g in grid):\n\n                # get required parameter shape\n                target_len = len(flatten(getattr(self, param)))\n\n                # check if cartesian product needed\n                cartesian = (not isinstance(grid, np.ndarray) or grid.ndim != 2)\n\n                # build grid\n                grid = [np.atleast_1d(g) for g in grid]\n\n                # check chape\n                msg = '{} grid should have {} columns, '\\\n                      'but found grid with {} columns'.format(param, target_len, len(grid))\n                if cartesian:\n                    if len(grid) != target_len:\n                        raise ValueError(msg)\n                    grid = combine(*grid)\n\n                if not all([len(subgrid) == target_len for subgrid in grid]):\n                    raise ValueError(msg)\n\n            # save param name and grid\n            params.append(param)\n            grids.append(grid)\n\n        # build a list of dicts of candidate model params\n        param_grid_list = []\n        for candidate in combine(*grids):\n            param_grid_list.append(dict(zip(params,candidate)))\n\n        # set up data collection\n        best_model = None # keep the best model\n        best_score = np.inf\n        scores = []\n        models = []\n\n        # check if our model has been fitted already and store it\n        if self._is_fitted:\n            models.append(self)\n            scores.append(self.statistics_[objective])\n\n            # our model is currently the best\n            best_model = models[-1]\n            best_score = scores[-1]\n\n        # make progressbar optional\n        if progress:\n            pbar = ProgressBar()\n        else:\n            pbar = lambda x: x\n\n        # loop through candidate model params\n        for param_grid in pbar(param_grid_list):\n            try:\n                # try fitting\n                # define new model\n                gam = deepcopy(self)\n                gam.set_params(self.get_params())\n                gam.set_params(**param_grid)\n\n                # warm start with parameters from previous build\n                if models:\n                    coef = models[-1].coef_\n                    gam.set_params(coef_=coef, force=True, verbose=False)\n                gam.fit(X, y, weights)\n\n            except ValueError as error:\n                msg = str(error) + '\\non model with params:\\n' + str(param_grid)\n                msg += '\\nskipping...\\n'\n                if self.verbose:\n                    warnings.warn(msg)\n                continue\n\n            # record results\n            models.append(gam)\n            scores.append(gam.statistics_[objective])\n\n            # track best\n            if scores[-1] < best_score:\n                best_model = models[-1]\n                best_score = scores[-1]\n\n        # problems\n        if len(models) == 0:\n            msg = 'No models were fitted.'\n            if self.verbose:\n                warnings.warn(msg)\n            return self\n\n        # copy over the best\n        if keep_best:\n            self.set_params(deep=True,\n                            force=True,\n                            **best_model.get_params(deep=True))\n        if return_scores:\n            return OrderedDict(zip(models, scores))\n        else:\n            return self", "response": "This method performs a grid search over a set of candidate models."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsimulates from the posterior of the coefficients and smoothing params given the response data X and y.", "response": "def sample(self, X, y, quantity='y', sample_at_X=None,\n               weights=None, n_draws=100, n_bootstraps=5, objective='auto'):\n        \"\"\"Simulate from the posterior of the coefficients and smoothing params.\n\n        Samples are drawn from the posterior of the coefficients and smoothing\n        parameters given the response in an approximate way. The GAM must\n        already be fitted before calling this method; if the model has not\n        been fitted, then an exception is raised. Moreover, it is recommended\n        that the model and its hyperparameters be chosen with `gridsearch`\n        (with the parameter `keep_best=True`) before calling `sample`, so that\n        the result of that gridsearch can be used to generate useful response\n        data and so that the model's coefficients (and their covariance matrix)\n        can be used as the first bootstrap sample.\n\n        These samples are drawn as follows. Details are in the reference below.\n\n        1. ``n_bootstraps`` many \"bootstrap samples\" of the response (``y``) are\n        simulated by drawing random samples from the model's distribution\n        evaluated at the expected values (``mu``) for each sample in ``X``.\n\n        2. A copy of the model is fitted to each of those bootstrap samples of\n        the response. The result is an approximation of the distribution over\n        the smoothing parameter ``lam`` given the response data ``y``.\n\n        3. Samples of the coefficients are simulated from a multivariate normal\n        using the bootstrap samples of the coefficients and their covariance\n        matrices.\n\n        Notes\n        -----\n        A ``gridsearch`` is done ``n_bootstraps`` many times, so keep\n        ``n_bootstraps`` small. Make ``n_bootstraps < n_draws`` to take advantage\n        of the expensive bootstrap samples of the smoothing parameters.\n\n        Parameters\n        -----------\n        X : array of shape (n_samples, m_features)\n              empirical input data\n\n        y : array of shape (n_samples,)\n              empirical response vector\n\n        quantity : {'y', 'coef', 'mu'}, default: 'y'\n            What quantity to return pseudorandom samples of.\n            If `sample_at_X` is not None and `quantity` is either `'y'` or\n            `'mu'`, then samples are drawn at the values of `X` specified in\n            `sample_at_X`.\n\n        sample_at_X : array of shape (n_samples_to_simulate, m_features) or\n        None, optional\n            Input data at which to draw new samples.\n\n            Only applies for `quantity` equal to `'y'` or to `'mu`'.\n            If `None`, then `sample_at_X` is replaced by `X`.\n\n        weights : np.array of shape (n_samples,)\n            sample weights\n\n        n_draws : positive int, optional (default=100)\n            The number of samples to draw from the posterior distribution of\n            the coefficients and smoothing parameters\n\n        n_bootstraps : positive int, optional (default=5)\n            The number of bootstrap samples to draw from simulations of the\n            response (from the already fitted model) to estimate the\n            distribution of the smoothing parameters given the response data.\n            If `n_bootstraps` is 1, then only the already fitted model's\n            smoothing parameter is used, and the distribution over the\n            smoothing parameters is not estimated using bootstrap sampling.\n\n        objective : string, optional (default='auto'\n            metric to optimize in grid search. must be in\n            ['AIC', 'AICc', 'GCV', 'UBRE', 'auto']\n            if 'auto', then grid search will optimize GCV for models with\n            unknown scale and UBRE for models with known scale.\n\n        Returns\n        -------\n        draws : 2D array of length n_draws\n            Simulations of the given `quantity` using samples from the\n            posterior distribution of the coefficients and smoothing parameter\n            given the response data. Each row is a pseudorandom sample.\n\n            If `quantity == 'coef'`, then the number of columns of `draws` is\n            the number of coefficients (`len(self.coef_)`).\n\n            Otherwise, the number of columns of `draws` is the number of\n            rows of `sample_at_X` if `sample_at_X` is not `None` or else\n            the number of rows of `X`.\n\n        References\n        ----------\n        Simon N. Wood, 2006. Generalized Additive Models: an introduction with\n        R. Section 4.9.3 (pages 198\u2013199) and Section 5.4.2 (page 256\u2013257).\n        \"\"\"\n        if quantity not in {'mu', 'coef', 'y'}:\n            raise ValueError(\"`quantity` must be one of 'mu', 'coef', 'y';\"\n                             \" got {}\".format(quantity))\n\n        coef_draws = self._sample_coef(\n            X, y, weights=weights, n_draws=n_draws,\n            n_bootstraps=n_bootstraps, objective=objective)\n\n        if quantity == 'coef':\n            return coef_draws\n\n        if sample_at_X is None:\n            sample_at_X = X\n\n        linear_predictor = self._modelmat(sample_at_X).dot(coef_draws.T)\n        mu_shape_n_draws_by_n_samples = self.link.mu(\n            linear_predictor, self.distribution).T\n        if quantity == 'mu':\n            return mu_shape_n_draws_by_n_samples\n        else:\n            return self.distribution.sample(mu_shape_n_draws_by_n_samples)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsimulates from the posterior of the coefficients and the response data.", "response": "def _sample_coef(self, X, y, weights=None, n_draws=100, n_bootstraps=1,\n                     objective='auto'):\n        \"\"\"Simulate from the posterior of the coefficients.\n\n        NOTE: A `gridsearch` is done `n_bootstraps` many times, so keep\n        `n_bootstraps` small. Make `n_bootstraps < n_draws` to take advantage\n        of the expensive bootstrap samples of the smoothing parameters.\n\n        Parameters\n        -----------\n        X : array of shape (n_samples, m_features)\n              input data\n\n        y : array of shape (n_samples,)\n              response vector\n\n        weights : np.array of shape (n_samples,)\n            sample weights\n\n        n_draws : positive int, optional (default=100\n            The number of samples to draw from the posterior distribution of\n            the coefficients and smoothing parameters\n\n        n_bootstraps : positive int, optional (default=1\n            The number of bootstrap samples to draw from simulations of the\n            response (from the already fitted model) to estimate the\n            distribution of the smoothing parameters given the response data.\n            If `n_bootstraps` is 1, then only the already fitted model's\n            smoothing parameters is used.\n\n        objective : string, optional (default='auto'\n            metric to optimize in grid search. must be in\n            ['AIC', 'AICc', 'GCV', 'UBRE', 'auto']\n            if 'auto', then grid search will optimize GCV for models with\n            unknown scale and UBRE for models with known scale.\n\n        Returns\n        -------\n        coef_samples : array of shape (n_draws, n_samples)\n            Approximate simulations of the coefficients drawn from the\n            posterior distribution of the coefficients and smoothing\n            parameters given the response data\n\n        References\n        ----------\n        Simon N. Wood, 2006. Generalized Additive Models: an introduction with\n        R. Section 4.9.3 (pages 198\u2013199) and Section 5.4.2 (page 256\u2013257).\n        \"\"\"\n        if not self._is_fitted:\n            raise AttributeError('GAM has not been fitted. Call fit first.')\n        if n_bootstraps < 1:\n            raise ValueError('n_bootstraps must be >= 1;'\n                             ' got {}'.format(n_bootstraps))\n        if n_draws < 1:\n            raise ValueError('n_draws must be >= 1;'\n                             ' got {}'.format(n_draws))\n\n        coef_bootstraps, cov_bootstraps = (\n            self._bootstrap_samples_of_smoothing(X, y, weights=weights,\n                                                 n_bootstraps=n_bootstraps,\n                                                 objective=objective))\n        coef_draws = self._simulate_coef_from_bootstraps(\n            n_draws, coef_bootstraps, cov_bootstraps)\n\n        return coef_draws"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsamples the smoothing parameters using simulated response data.", "response": "def _bootstrap_samples_of_smoothing(self, X, y, weights=None,\n                                        n_bootstraps=1, objective='auto'):\n        \"\"\"Sample the smoothing parameters using simulated response data.\n\n\n        For now, the grid of `lam` values is 11 random points in M-dimensional\n        space, where M = the number of lam values, ie len(flatten(gam.lam))\n\n        all values are in [1e-3, 1e3]\n        \"\"\"\n        mu = self.predict_mu(X)  # Wood pg. 198 step 1\n        coef_bootstraps = [self.coef_]\n        cov_bootstraps = [\n            load_diagonal(self.statistics_['cov'])]\n\n        for _ in range(n_bootstraps - 1):  # Wood pg. 198 step 2\n            # generate response data from fitted model (Wood pg. 198 step 3)\n            y_bootstrap = self.distribution.sample(mu)\n\n            # fit smoothing parameters on the bootstrap data\n            # (Wood pg. 198 step 4)\n            # TODO: Either enable randomized searches over hyperparameters\n            # (like in sklearn's RandomizedSearchCV), or draw enough samples of\n            # `lam` so that each of these bootstrap samples get different\n            # values of `lam`. Right now, each bootstrap sample uses the exact\n            # same grid of values for `lam`, so it is not worth setting\n            # `n_bootstraps > 1`.\n            gam = deepcopy(self)\n            gam.set_params(self.get_params())\n\n            # create a random search of 11 points in lam space\n            # with all values in [1e-3, 1e3]\n            lam_grid = np.random.randn(11, len(flatten(self.lam))) * 6 - 3\n            lam_grid = np.exp(lam_grid)\n            gam.gridsearch(X, y_bootstrap, weights=weights, lam=lam_grid,\n                           objective=objective)\n            lam = gam.lam\n\n            # fit coefficients on the original data given the smoothing params\n            # (Wood pg. 199 step 5)\n            gam = deepcopy(self)\n            gam.set_params(self.get_params())\n            gam.lam = lam\n            gam.fit(X, y, weights=weights)\n\n            coef_bootstraps.append(gam.coef_)\n\n            cov = load_diagonal(gam.statistics_['cov'])\n\n            cov_bootstraps.append(cov)\n        return coef_bootstraps, cov_bootstraps"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _simulate_coef_from_bootstraps(\n            self, n_draws, coef_bootstraps, cov_bootstraps):\n        \"\"\"Simulate coefficients using bootstrap samples.\"\"\"\n        # Sample indices uniformly from {0, ..., n_bootstraps - 1}\n        # (Wood pg. 199 step 6)\n        random_bootstrap_indices = np.random.choice(\n            np.arange(len(coef_bootstraps)), size=n_draws, replace=True)\n\n        # Simulate `n_draws` many random coefficient vectors from a\n        # multivariate normal distribution with mean and covariance given by\n        # the bootstrap samples (indexed by `random_bootstrap_indices`) of\n        # `coef_bootstraps` and `cov_bootstraps`. Because it's faster to draw\n        # many samples from a certain distribution all at once, we make a dict\n        # mapping bootstrap indices to draw indices and use the `size`\n        # parameter of `np.random.multivariate_normal` to sample the draws\n        # needed from that bootstrap sample all at once.\n        bootstrap_index_to_draw_indices = defaultdict(list)\n        for draw_index, bootstrap_index in enumerate(random_bootstrap_indices):\n            bootstrap_index_to_draw_indices[bootstrap_index].append(draw_index)\n\n        coef_draws = np.empty((n_draws, len(self.coef_)))\n\n        for bootstrap, draw_indices in bootstrap_index_to_draw_indices.items():\n            coef_draws[draw_indices] = np.random.multivariate_normal(\n                coef_bootstraps[bootstrap], cov_bootstraps[bootstrap],\n                size=len(draw_indices))\n\n        return coef_draws", "response": "Simulate coefficients using bootstrap samples."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _validate_params(self):\n        self.distribution = NormalDist(scale=self.scale)\n        super(LinearGAM, self)._validate_params()", "response": "Validate the parameters of the object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef accuracy(self, X=None, y=None, mu=None):\n        if not self._is_fitted:\n            raise AttributeError('GAM has not been fitted. Call fit first.')\n\n        y = check_y(y, self.link, self.distribution, verbose=self.verbose)\n        if X is not None:\n            X = check_X(X, n_feats=self.statistics_['m_features'],\n                        edge_knots=self.edge_knots_, dtypes=self.dtype,\n                        features=self.feature, verbose=self.verbose)\n\n        if mu is None:\n            mu = self.predict_mu(X)\n        check_X_y(mu, y)\n        return ((mu > 0.5).astype(int) == y).mean()", "response": "Compute the accuracy of the LogisticGAM."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _loglikelihood(self, y, mu, weights=None, rescale_y=True):\n        if rescale_y:\n            y = np.round(y * weights).astype('int')\n\n        return self.distribution.log_pdf(y=y, mu=mu, weights=weights).sum()", "response": "Compute the log - likelihood of the current model using the current model and target values y mu and weights"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _exposure_to_weights(self, y, exposure=None, weights=None):\n        y = y.ravel()\n\n        if exposure is not None:\n            exposure = np.array(exposure).astype('f').ravel()\n            exposure = check_array(exposure, name='sample exposure',\n                                   ndim=1, verbose=self.verbose)\n        else:\n            exposure = np.ones_like(y.ravel()).astype('float64')\n\n        # check data\n        exposure = exposure.ravel()\n        check_lengths(y, exposure)\n\n        # normalize response\n        y = y / exposure\n\n        if weights is not None:\n            weights = np.array(weights).astype('f').ravel()\n            weights = check_array(weights, name='sample weights',\n                                  ndim=1, verbose=self.verbose)\n        else:\n            weights = np.ones_like(y).astype('float64')\n        check_lengths(weights, exposure)\n\n        # set exposure as the weight\n        # we do this because we have divided our response\n        # so if we make an error of 1 now, we need it to count more heavily.\n        weights = weights * exposure\n\n        return y, weights", "response": "simple tool to create a common API for the given exposure and weights"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfit the generalized additive model.", "response": "def fit(self, X, y, exposure=None, weights=None):\n        \"\"\"Fit the generalized additive model.\n\n        Parameters\n        ----------\n        X : array-like, shape (n_samples, m_features)\n            Training vectors, where n_samples is the number of samples\n            and m_features is the number of features.\n\n        y : array-like, shape (n_samples,)\n            Target values (integers in classification, real numbers in\n            regression)\n            For classification, labels must correspond to classes.\n\n        exposure : array-like shape (n_samples,) or None, default: None\n            containing exposures\n            if None, defaults to array of ones\n\n        weights : array-like shape (n_samples,) or None, default: None\n            containing sample weights\n            if None, defaults to array of ones\n\n        Returns\n        -------\n        self : object\n            Returns fitted GAM object\n        \"\"\"\n        y, weights = self._exposure_to_weights(y, exposure, weights)\n        return super(PoissonGAM, self).fit(X, y, weights)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef predict(self, X, exposure=None):\n        if not self._is_fitted:\n            raise AttributeError('GAM has not been fitted. Call fit first.')\n\n        X = check_X(X, n_feats=self.statistics_['m_features'],\n                    edge_knots=self.edge_knots_, dtypes=self.dtype,\n                    features=self.feature, verbose=self.verbose)\n\n        if exposure is not None:\n            exposure = np.array(exposure).astype('f')\n        else:\n            exposure = np.ones(X.shape[0]).astype('f')\n        check_lengths(X, exposure)\n\n        return self.predict_mu(X) * exposure", "response": "predicts the model for a set of samples X"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nperforms a grid search over a space of parameters for a given objective NOTE: gridsearch method is lazy and will not remove useless combinations from the search space, eg. >>> n_splines=np.arange(5,10), fit_splines=[True, False] will result in 10 loops, of which 5 are equivalent because even though fit_splines==False it is not recommended to search over a grid that alternates between known scales and unknown scales, as the scores of the candidate models will not be comparable. Parameters ---------- X : array input data of shape (n_samples, m_features) y : array label data of shape (n_samples,) exposure : array-like shape (n_samples,) or None, default: None containing exposures if None, defaults to array of ones weights : array-like shape (n_samples,) or None, default: None containing sample weights if None, defaults to array of ones return_scores : boolean, default False whether to return the hyperpamaters and score for each element in the grid keep_best : boolean whether to keep the best GAM as self. default: True objective : string, default: 'auto' metric to optimize. must be in ['AIC', 'AICc', 'GCV', 'UBRE', 'auto'] if 'auto', then grid search will optimize GCV for models with unknown scale and UBRE for models with known scale. **kwargs : dict, default {'lam': np.logspace(-3, 3, 11)} pairs of parameters and iterables of floats, or parameters and iterables of iterables of floats. if iterable of iterables of floats, the outer iterable must have length m_features. the method will make a grid of all the combinations of the parameters and fit a GAM to each combination. Returns ------- if return_values == True: model_scores : dict Contains each fitted model as keys and corresponding objective scores as values else: self, ie possibly the newly fitted model", "response": "def gridsearch(self, X, y, exposure=None, weights=None,\n                   return_scores=False, keep_best=True, objective='auto',\n                   **param_grids):\n        \"\"\"\n        performs a grid search over a space of parameters for a given objective\n\n        NOTE:\n        gridsearch method is lazy and will not remove useless combinations\n        from the search space, eg.\n\n        >>> n_splines=np.arange(5,10), fit_splines=[True, False]\n\n        will result in 10 loops, of which 5 are equivalent because\n        even though fit_splines==False\n\n        it is not recommended to search over a grid that alternates\n        between known scales and unknown scales, as the scores of the\n        candidate models will not be comparable.\n\n        Parameters\n        ----------\n        X : array\n          input data of shape (n_samples, m_features)\n\n        y : array\n          label data of shape (n_samples,)\n\n        exposure : array-like shape (n_samples,) or None, default: None\n            containing exposures\n            if None, defaults to array of ones\n\n        weights : array-like shape (n_samples,) or None, default: None\n            containing sample weights\n            if None, defaults to array of ones\n\n        return_scores : boolean, default False\n          whether to return the hyperpamaters\n          and score for each element in the grid\n\n        keep_best : boolean\n          whether to keep the best GAM as self.\n          default: True\n\n        objective : string, default: 'auto'\n          metric to optimize. must be in ['AIC', 'AICc', 'GCV', 'UBRE', 'auto']\n          if 'auto', then grid search will optimize GCV for models with unknown\n          scale and UBRE for models with known scale.\n\n        **kwargs : dict, default {'lam': np.logspace(-3, 3, 11)}\n          pairs of parameters and iterables of floats, or\n          parameters and iterables of iterables of floats.\n\n          if iterable of iterables of floats, the outer iterable must have\n          length m_features.\n\n          the method will make a grid of all the combinations of the parameters\n          and fit a GAM to each combination.\n\n\n        Returns\n        -------\n        if return_values == True:\n            model_scores : dict\n                Contains each fitted model as keys and corresponding\n                objective scores as values\n        else:\n            self, ie possibly the newly fitted model\n        \"\"\"\n        y, weights = self._exposure_to_weights(y, exposure, weights)\n        return super(PoissonGAM, self).gridsearch(X, y,\n                                                  weights=weights,\n                                                  return_scores=return_scores,\n                                                  keep_best=keep_best,\n                                                  objective=objective,\n                                                  **param_grids)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _validate_params(self):\n        self.distribution = GammaDist(scale=self.scale)\n        super(GammaGAM, self)._validate_params()", "response": "Validate the parameters of the object."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nvalidates the parameters of the object.", "response": "def _validate_params(self):\n        \"\"\"\n        method to sanitize model parameters\n\n        Parameters\n        ---------\n        None\n\n        Returns\n        -------\n        None\n        \"\"\"\n        self.distribution = InvGaussDist(scale=self.scale)\n        super(InvGaussGAM, self)._validate_params()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nvalidates the parameters of expectile_gam and expectil_gam.", "response": "def _validate_params(self):\n        \"\"\"\n        method to sanitize model parameters\n\n        Parameters\n        ---------\n        None\n\n        Returns\n        -------\n        None\n        \"\"\"\n        if self.expectile >= 1 or self.expectile <= 0:\n            raise ValueError('expectile must be in (0,1), but found {}'.format(self.expectile))\n        self.distribution = NormalDist(scale=self.scale)\n        super(ExpectileGAM, self)._validate_params()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncomputes the PIRLS weights for model predictions.", "response": "def _W(self, mu, weights, y=None):\n        \"\"\"\n        compute the PIRLS weights for model predictions.\n\n        TODO lets verify the formula for this.\n        if we use the square root of the mu with the stable opt,\n        we get the same results as when we use non-sqrt mu with naive opt.\n\n        this makes me think that they are equivalent.\n\n        also, using non-sqrt mu with stable opt gives very small edofs for even lam=0.001\n        and the parameter variance is huge. this seems strange to me.\n\n        computed [V * d(link)/d(mu)] ^(-1/2) by hand and the math checks out as hoped.\n\n        ive since moved the square to the naive pirls method to make the code modular.\n\n        Parameters\n        ---------\n        mu : array-like of shape (n_samples,)\n            expected value of the targets given the model and inputs\n        weights : array-like of shape (n_samples,)\n            containing sample weights\n        y = array-like of shape (n_samples,) or None, default None\n            useful for computing the asymmetric weight.\n\n        Returns\n        -------\n        weights : scipy.sparse array of shape (n_samples, n_samples)\n        \"\"\"\n        # asymmetric weight\n        asym = (y > mu) * self.expectile + (y <= mu) * (1 - self.expectile)\n\n        return sp.sparse.diags((self.link.gradient(mu, self.distribution)**2 *\n                                self.distribution.V(mu=mu) *\n                                weights ** -1)**-0.5 * asym**0.5)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfind the expirical quantile of the model", "response": "def _get_quantile_ratio(self, X, y):\n        \"\"\"find the expirical quantile of the model\n\n        Parameters\n        ----------\n        X : array-like, shape (n_samples, m_features)\n            Training vectors, where n_samples is the number of samples\n            and m_features is the number of features.\n        y : array-like, shape (n_samples,)\n            Target values (integers in classification, real numbers in\n            regression)\n            For classification, labels must correspond to classes.\n\n        Returns\n        -------\n        ratio : float on [0, 1]\n        \"\"\"\n        y_pred = self.predict(X)\n        return (y_pred > y).mean()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfitting ExpectileGAM to a desired quantile", "response": "def fit_quantile(self, X, y, quantile, max_iter=20, tol=0.01, weights=None):\n        \"\"\"fit ExpectileGAM to a desired quantile via binary search\n\n        Parameters\n        ----------\n        X : array-like, shape (n_samples, m_features)\n            Training vectors, where n_samples is the number of samples\n            and m_features is the number of features.\n        y : array-like, shape (n_samples,)\n            Target values (integers in classification, real numbers in\n            regression)\n            For classification, labels must correspond to classes.\n        quantile : float on (0, 1)\n            desired quantile to fit.\n        max_iter : int, default: 20\n            maximum number of binary search iterations to perform\n        tol : float > 0, default: 0.01\n            maximum distance between desired quantile and fitted quantile\n        weights : array-like shape (n_samples,) or None, default: None\n            containing sample weights\n            if None, defaults to array of ones\n\n        Returns\n        -------\n        self : fitted GAM object\n        \"\"\"\n        def _within_tol(a, b, tol):\n            return np.abs(a - b) <= tol\n\n        # validate arguments\n        if quantile <= 0 or quantile >= 1:\n            raise ValueError('quantile must be on (0, 1), but found {}'.format(quantile))\n\n        if tol <= 0:\n            raise ValueError('tol must be float > 0 {}'.format(tol))\n\n        if max_iter <= 0:\n            raise ValueError('max_iter must be int > 0 {}'.format(max_iter))\n\n        # perform a first fit if necessary\n        if not self._is_fitted:\n            self.fit(X, y, weights=weights)\n\n        # do binary search\n        max_ = 1.0\n        min_ = 0.0\n        n_iter = 0\n        while n_iter < max_iter:\n            ratio = self._get_quantile_ratio(X, y)\n\n            if _within_tol(ratio, quantile, tol):\n                break\n\n            if ratio < quantile:\n                min_ = self.expectile\n            else:\n                max_ = self.expectile\n\n            expectile = (max_ + min_) / 2.\n            self.set_params(expectile=expectile)\n            self.fit(X, y, weights=weights)\n\n            n_iter += 1\n\n        # print diagnostics\n        if not _within_tol(ratio, quantile, tol) and self.verbose:\n            warnings.warn('maximum iterations reached')\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef nice_repr(name, param_kvs, line_width=30, line_offset=5, decimals=3, args=None, flatten_attrs=True):\n    if not param_kvs and not args :\n        # if the object has no params it's easy\n        return '{}()'.format(name)\n\n    # sort keys and values\n    ks = list(param_kvs.keys())\n    vs = list(param_kvs.values())\n    idxs = np.argsort(ks)\n    param_kvs = [(ks[i],vs[i]) for i in idxs]\n\n    if args is not None:\n        param_kvs = [(None, arg) for arg in args] + param_kvs\n\n    param_kvs = param_kvs[::-1]\n    out = ''\n    current_line = name + '('\n    while len(param_kvs) > 0:\n\n        # flatten sub-term properties, but not `terms`\n        k, v = param_kvs.pop()\n        if flatten_attrs and k is not 'terms':\n            v = flatten(v)\n\n        # round the floats first\n        if issubclass(v.__class__, (float, np.ndarray)):\n            v = round_to_n_decimal_places(v, n=decimals)\n            v = str(v)\n        else:\n            v = repr(v)\n\n        # handle args\n        if k is None:\n            param = '{},'.format(v)\n        else:\n            param = '{}={},'.format(k, v)\n\n        # print\n        if len(current_line + param) <= line_width:\n            current_line += param\n        else:\n            out += current_line + '\\n'\n            current_line = ' '*line_offset + param\n\n        if len(current_line) < line_width and len(param_kvs) > 0:\n            current_line += ' '\n\n    out += current_line[:-1] # remove trailing comma\n    out += ')'\n    return out", "response": "This function returns a nicely formatted version of the class name."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_params(self, deep=False):\n        attrs = self.__dict__\n        for attr in self._include:\n            attrs[attr] = getattr(self, attr)\n\n        if deep is True:\n            return attrs\n        return dict([(k,v) for k,v in list(attrs.items()) \\\n                     if (k[0] != '_') \\\n                        and (k[-1] != '_') \\\n                        and (k not in self._exclude)])", "response": "Returns a dict of all of the object s user - facing parameters."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the parameters of an object.", "response": "def set_params(self, deep=False, force=False, **parameters):\n        \"\"\"\n        sets an object's paramters\n\n        Parameters\n        ----------\n        deep : boolean, default: False\n            when True, also sets non-user-facing paramters\n        force : boolean, default: False\n            when True, also sets parameters that the object does not already\n            have\n        **parameters : paramters to set\n\n        Returns\n        ------\n        self\n        \"\"\"\n        param_names = self.get_params(deep=deep).keys()\n        for parameter, value in parameters.items():\n            if (parameter in param_names\n                or force\n                or (hasattr(self, parameter) and parameter == parameter.strip('_'))):\n                setattr(self, parameter, value)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef info(self):\n        info = self.get_params()\n        info.update({'term_type': self._name})\n        return info", "response": "get information about this term"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef build_from_info(cls, info):\n        info = deepcopy(info)\n        if 'term_type' in info:\n            cls_ = TERMS[info.pop('term_type')]\n\n            if issubclass(cls_, MetaTermMixin):\n                return cls_.build_from_info(info)\n        else:\n            cls_ = cls\n        return cls_(**info)", "response": "build a Term instance from a dict containing all information needed to build the term"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef build_penalties(self, verbose=False):\n        if self.isintercept:\n            return np.array([[0.]])\n\n        Ps = []\n        for penalty, lam in zip(self.penalties, self.lam):\n            if penalty == 'auto':\n                if self.dtype == 'numerical':\n                    if self._name == 'spline_term':\n                        if self.basis in ['cp']:\n                            penalty = 'periodic'\n                        else:\n                            penalty = 'derivative'\n                    else:\n                        penalty = 'l2'\n                if self.dtype == 'categorical':\n                    penalty = 'l2'\n            if penalty is None:\n                penalty = 'none'\n            if penalty in PENALTIES:\n                penalty = PENALTIES[penalty]\n\n            P = penalty(self.n_coefs, coef=None) # penalties dont need coef\n            Ps.append(np.multiply(P, lam))\n        return np.sum(Ps)", "response": "Builds the GAM block - diagonal penalty matrix in quadratic form."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef build_constraints(self, coef, constraint_lam, constraint_l2):\n        if self.isintercept:\n            return np.array([[0.]])\n\n        Cs = []\n        for constraint in self.constraints:\n\n            if constraint is None:\n                constraint = 'none'\n            if constraint in CONSTRAINTS:\n                constraint = CONSTRAINTS[constraint]\n\n            C = constraint(self.n_coefs, coef) * constraint_lam\n            Cs.append(C)\n\n        Cs = np.sum(Cs)\n\n        # improve condition\n        if Cs.nnz > 0:\n            Cs += sp.sparse.diags(constraint_l2 * np.ones(Cs.shape[0]))\n\n        return Cs", "response": "Builds the GAM block - diagonal constraint matrix in quadratic form for the specified coefficients and constraint_lam and constraint_l2."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef build_columns(self, X, verbose=False):\n        return sp.sparse.csc_matrix(np.ones((len(X), 1)))", "response": "construct the model matrix columns for the term term\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef compile(self, X, verbose=False):\n        if self.feature >= X.shape[1]:\n            raise ValueError('term requires feature {}, '\\\n                             'but X has only {} dimensions'\\\n                             .format(self.feature, X.shape[1]))\n\n        self.edge_knots_ = gen_edge_knots(X[:, self.feature],\n                                          self.dtype,\n                                          verbose=verbose)\n        return self", "response": "method to validate and prepare data - dependent parameters"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef build_columns(self, X, verbose=False):\n        return sp.sparse.csc_matrix(X[:, self.feature][:, np.newaxis])", "response": "construct the model matrix columns for the term\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef compile(self, X, verbose=False):\n        if self.feature >= X.shape[1]:\n            raise ValueError('term requires feature {}, '\\\n                             'but X has only {} dimensions'\\\n                             .format(self.feature, X.shape[1]))\n\n        if self.by is not None and self.by >= X.shape[1]:\n            raise ValueError('by variable requires feature {}, '\\\n                             'but X has only {} dimensions'\\\n                             .format(self.by, X.shape[1]))\n\n        if not hasattr(self, 'edge_knots_'):\n            self.edge_knots_ = gen_edge_knots(X[:, self.feature],\n                                              self.dtype,\n                                              verbose=verbose)\n        return self", "response": "method to validate and prepare data - dependent parameters Parameters ---------\n            self. feature X. array - like\n            Input dataset X. bool verbose whether to show warnings\n            is True"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconstructs the model matrix columns for the term term", "response": "def build_columns(self, X, verbose=False):\n        \"\"\"construct the model matrix columns for the term\n\n        Parameters\n        ----------\n        X : array-like\n            Input dataset with n rows\n\n        verbose : bool\n            whether to show warnings\n\n        Returns\n        -------\n        scipy sparse array with n rows\n        \"\"\"\n        X[:, self.feature][:, np.newaxis]\n\n        splines = b_spline_basis(X[:, self.feature],\n                                 edge_knots=self.edge_knots_,\n                                 spline_order=self.spline_order,\n                                 n_splines=self.n_splines,\n                                 sparse=True,\n                                 periodic=self.basis in ['cp'],\n                                 verbose=verbose)\n\n        if self.by is not None:\n            splines = splines.multiply(X[:, self.by][:, np.newaxis])\n\n        return splines"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef compile(self, X, verbose=False):\n        super(FactorTerm, self).compile(X)\n\n        self.n_splines = len(np.unique(X[:, self.feature]))\n        self.edge_knots_ = gen_edge_knots(X[:, self.feature],\n                                          self.dtype,\n                                          verbose=verbose)\n        return self", "response": "method to validate and prepare data - dependent parameters"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconstruct the model matrix columns for the term", "response": "def build_columns(self, X, verbose=False):\n        \"\"\"construct the model matrix columns for the term\n\n        Parameters\n        ----------\n        X : array-like\n            Input dataset with n rows\n\n        verbose : bool\n            whether to show warnings\n\n        Returns\n        -------\n        scipy sparse array with n rows\n        \"\"\"\n        columns = super(FactorTerm, self).build_columns(X, verbose=verbose)\n        if self.coding == 'dummy':\n            columns = columns[:, 1:]\n\n        return columns"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _has_terms(self):\n        loc = self._super_get('_term_location')\n        return self._super_has(loc) \\\n               and isiterable(self._super_get(loc)) \\\n               and len(self._super_get(loc)) > 0 \\\n               and all([isinstance(term, Term) for term in self._super_get(loc)])", "response": "bool whether the instance has any terms in the super - terms set."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting information about this term Returns a dict containing only the information about this term", "response": "def info(self):\n        \"\"\"get information about this term\n\n        Parameters\n        ----------\n\n        Returns\n        -------\n        dict containing information to duplicate this term\n        \"\"\"\n        info = super(TensorTerm, self).info\n        info.update({'terms':[term.info for term in self._terms]})\n        return info"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef build_from_info(cls, info):\n        terms = []\n        for term_info in info['terms']:\n            terms.append(SplineTerm.build_from_info(term_info))\n        return cls(*terms)", "response": "build a TensorTerm instance from a dict containing information needed to build the term"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef hasconstraint(self):\n        constrained = False\n        for term in self._terms:\n            constrained = constrained or term.hasconstraint\n        return constrained", "response": "bool whether the term has any constraints"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef build_columns(self, X, verbose=False):\n        splines = self._terms[0].build_columns(X, verbose=verbose)\n        for term in self._terms[1:]:\n            marginal_splines = term.build_columns(X, verbose=verbose)\n            splines = tensor_product(splines, marginal_splines)\n\n        if self.by is not None:\n            splines *= X[:, self.by][:, np.newaxis]\n\n        return sp.sparse.csc_matrix(splines)", "response": "construct the model matrix columns for the term\n           "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nbuild the GAM block - diagonal penalty matrix in quadratic form containing the model penalties in the quadratic form.", "response": "def build_penalties(self):\n        \"\"\"\n        builds the GAM block-diagonal penalty matrix in quadratic form\n        out of penalty matrices specified for each feature.\n\n        each feature penalty matrix is multiplied by a lambda for that feature.\n\n        so for m features:\n        P = block_diag[lam0 * P0, lam1 * P1, lam2 * P2, ... , lamm * Pm]\n\n        Parameters\n        ----------\n        None\n\n        Returns\n        -------\n        P : sparse CSC matrix containing the model penalties in quadratic form\n        \"\"\"\n        P = sp.sparse.csc_matrix(np.zeros((self.n_coefs, self.n_coefs)))\n        for i in range(len(self._terms)):\n            P += self._build_marginal_penalties(i)\n\n        return sp.sparse.csc_matrix(P)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nbuilds the GAM block - diagonal constraint matrix in quadratic form containing the model constraints.", "response": "def build_constraints(self, coef, constraint_lam, constraint_l2):\n        \"\"\"\n        builds the GAM block-diagonal constraint matrix in quadratic form\n        out of constraint matrices specified for each feature.\n\n        Parameters\n        ----------\n        coefs : array-like containing the coefficients of a term\n\n        constraint_lam : float,\n            penalty to impose on the constraint.\n\n            typically this is a very large number.\n\n        constraint_l2 : float,\n            loading to improve the numerical conditioning of the constraint\n            matrix.\n\n            typically this is a very small number.\n\n        Returns\n        -------\n        C : sparse CSC matrix containing the model constraints in quadratic form\n        \"\"\"\n        C = sp.sparse.csc_matrix(np.zeros((self.n_coefs, self.n_coefs)))\n        for i in range(len(self._terms)):\n            C += self._build_marginal_constraints(i, coef, constraint_lam, constraint_l2)\n\n        return sp.sparse.csc_matrix(C)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nbuilds a constraint matrix for a marginal term in the tensor term i and returns the corresponding constraint matrix.", "response": "def _build_marginal_constraints(self, i, coef, constraint_lam, constraint_l2):\n        \"\"\"builds a constraint matrix for a marginal term in the tensor term\n\n        takes a tensor's coef vector, and slices it into pieces corresponding\n        to term i, then builds a constraint matrix for each piece of the coef vector,\n        and assembles them into a composite constraint matrix\n\n        Parameters\n        ----------\n        i : int,\n            index of the marginal term for which to build a constraint matrix\n\n        coefs : array-like containing the coefficients of the tensor term\n\n        constraint_lam : float,\n            penalty to impose on the constraint.\n\n            typically this is a very large number.\n\n        constraint_l2 : float,\n            loading to improve the numerical conditioning of the constraint\n            matrix.\n\n            typically this is a very small number.\n\n        Returns\n        -------\n        C : sparse CSC matrix containing the model constraints in quadratic form\n        \"\"\"\n\n        composite_C = np.zeros((len(coef), len(coef)))\n\n        for slice_ in self._iterate_marginal_coef_slices(i):\n            # get the slice of coefficient vector\n            coef_slice = coef[slice_]\n\n            # build the constraint matrix for that slice\n            slice_C = self._terms[i].build_constraints(coef_slice, constraint_lam, constraint_l2)\n\n            # now enter it into the composite\n            composite_C[tuple(np.meshgrid(slice_, slice_))] = slice_C.A\n\n        return sp.sparse.csc_matrix(composite_C)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _iterate_marginal_coef_slices(self, i):\n        dims = [term_.n_coefs for term_ in self]\n\n        # make all linear indices\n        idxs = np.arange(np.prod(dims))\n\n        # reshape indices to a Nd matrix\n        idxs = idxs.reshape(dims)\n\n        # reshape to a 2d matrix, where we can loop over rows\n        idxs = np.moveaxis(idxs, i, 0).reshape(idxs.shape[i], int(idxs.size/idxs.shape[i]))\n\n        # loop over rows\n        for slice_ in idxs.T:\n            yield slice_", "response": "iterate over indices into tensor s coef vector for marginal term i returns an iterator of indices into tensor s coef vector for marginal term i s coefs\n        returns an iterator of indices into tensor s coef vector for marginal term i s coefs\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef info(self):\n        info = {'term_type': 'term_list', 'verbose': self.verbose}\n        info.update({'terms':[term.info for term in self._terms]})\n        return info", "response": "get information about the terms in the term list"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbuilding a TermList instance from a dict containing all information needed to build the TermList instance", "response": "def build_from_info(cls, info):\n        \"\"\"build a TermList instance from a dict\n\n        Parameters\n        ----------\n        cls : class\n\n        info : dict\n            contains all information needed to build the term\n\n        Return\n        ------\n        TermList instance\n        \"\"\"\n        info = deepcopy(info)\n        terms = []\n        for term_info in info['terms']:\n            terms.append(Term.build_from_info(term_info))\n        return cls(*terms)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pop(self, i=None):\n        if i == None:\n            i = len(self) - 1\n\n        if i >= len(self._terms) or i < 0:\n            raise ValueError('requested pop {}th term, but found only {} terms'\\\n                            .format(i, len(self._terms)))\n\n        term = self._terms[i]\n        self._terms = self._terms[:i] + self._terms[i+1:]\n        return term", "response": "remove the ith term from the term list"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_coef_indices(self, i=-1):\n        if i == -1:\n            return list(range(self.n_coefs))\n\n        if i >= len(self._terms):\n            raise ValueError('requested {}th term, but found only {} terms'\\\n                            .format(i, len(self._terms)))\n\n        start = 0\n        for term in self._terms[:i]:\n            start += term.n_coefs\n        stop = start + self._terms[i].n_coefs\n        return list(range(start, stop))", "response": "get the indices for the coefficients of a term in the term list"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef build_columns(self, X, term=-1, verbose=False):\n        if term == -1:\n            term = range(len(self._terms))\n        term = list(np.atleast_1d(term))\n\n        columns = []\n        for term_id in term:\n            columns.append(self._terms[term_id].build_columns(X, verbose=verbose))\n        return sp.sparse.hstack(columns, format='csc')", "response": "construct the model matrix columns for the term\n           "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nbuilding the GAM block - diagonal penalty matrix in quadratic form containing the model penalties in the quadratic form.", "response": "def build_penalties(self):\n        \"\"\"\n        builds the GAM block-diagonal penalty matrix in quadratic form\n        out of penalty matrices specified for each feature.\n\n        each feature penalty matrix is multiplied by a lambda for that feature.\n\n        so for m features:\n        P = block_diag[lam0 * P0, lam1 * P1, lam2 * P2, ... , lamm * Pm]\n\n\n        Parameters\n        ----------\n        None\n\n        Returns\n        -------\n        P : sparse CSC matrix containing the model penalties in quadratic form\n        \"\"\"\n        P = []\n        for term in self._terms:\n            P.append(term.build_penalties())\n        return sp.sparse.block_diag(P)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef build_constraints(self, coefs, constraint_lam, constraint_l2):\n        C = []\n        for i, term in enumerate(self._terms):\n            idxs = self.get_coef_indices(i=i)\n            C.append(term.build_constraints(coefs[idxs], constraint_lam, constraint_l2))\n        return sp.sparse.block_diag(C)", "response": "Builds the GAM block - diagonal constraint matrix in quadratic form for each feature."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load_data(self):\n        print('Extracting training data from csv...')\n        images = list()\n        labels = list()\n        emotion_index_map = dict()\n        with open(self.datapath) as csv_file:\n            reader = csv.reader(csv_file, delimiter=',', quotechar='\"')\n            for row in reader:\n                label_class = row[self.csv_label_col]\n                if label_class not in self.target_emotion_map.keys():\n                    continue\n                label_class = self.target_emotion_map[label_class]\n                if label_class not in emotion_index_map.keys():\n                    emotion_index_map[label_class] = len(emotion_index_map.keys())\n                labels.append(label_class)\n\n                image = np.asarray([int(pixel) for pixel in row[self.csv_image_col].split(' ')], dtype=np.uint8).reshape(self.image_dimensions)\n                image = self._reshape(image)\n                images.append(image)\n\n        vectorized_labels = self._vectorize_labels(emotion_index_map, labels)\n        self._check_data_not_empty(images)\n\n        return self._load_dataset(np.array(images), np.array(vectorized_labels), emotion_index_map)", "response": "Loads image and label data from specified csv file path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading Dataset object with images labels and other data.", "response": "def _load_dataset(self, images, labels, emotion_index_map):\n        \"\"\"\n        Loads Dataset object with images, labels, and other data.\n\n        :param images: numpy array of image data\n        :param labels: numpy array of one-hot vector labels\n        :param emotion_index_map: map linking string/integer emotion class to integer index used in labels vectors\n\n        :return: Dataset object containing image and label data.\n        \"\"\"\n        train_images, test_images, train_labels, test_labels = train_test_split(images, labels, test_size=self.validation_split, random_state=42, stratify=labels)\n        dataset = Dataset(train_images, test_images, train_labels, test_labels, emotion_index_map, self.time_delay)\n        return dataset"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_data(self):\n        images = list()\n        labels = list()\n        emotion_index_map = dict()\n        label_directories = [dir for dir in os.listdir(self.datapath) if not dir.startswith('.')]\n        for label_directory in label_directories:\n            if self.target_emotion_map:\n                if label_directory not in self.target_emotion_map.keys():    continue\n            self._add_new_label_to_map(label_directory, emotion_index_map)\n            label_directory_path = self.datapath + '/' + label_directory\n\n            if self.time_delay:\n                self._load_series_for_single_emotion_directory(images, label_directory, label_directory_path, labels)\n            else:\n                image_files = [image_file for image_file in os.listdir(label_directory_path) if not image_file.startswith('.')]\n                self._load_images_from_directory_to_array(image_files, images, label_directory, label_directory_path, labels)\n\n        vectorized_labels = self._vectorize_labels(emotion_index_map, labels)\n        self._check_data_not_empty(images)\n        return self._load_dataset(np.array(images), np.array(vectorized_labels), emotion_index_map)", "response": "Loads image and label data from specified directory path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking that the directory arguments for loading from directories.", "response": "def _check_directory_arguments(self):\n        \"\"\"\n        Validates arguments for loading from directories, including static image and time series directories.\n        \"\"\"\n        if not os.path.isdir(self.datapath):\n            raise (NotADirectoryError('Directory does not exist: %s' % self.datapath))\n        if self.time_delay:\n            if self.time_delay < 1:\n                raise ValueError('Time step argument must be greater than 0, but gave: %i' % self.time_delay)\n            if not isinstance(self.time_delay, int):\n                raise ValueError('Time step argument must be an integer, but gave: %s' % str(self.time_delay))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef predict(self, image_file):\n        image = misc.imread(image_file)\n        gray_image = image\n        if len(image.shape) > 2:\n            gray_image = cv2.cvtColor(image, code=cv2.COLOR_BGR2GRAY)\n        resized_image = cv2.resize(gray_image, self.target_dimensions, interpolation=cv2.INTER_LINEAR)\n        final_image = np.array([np.array([resized_image]).reshape(list(self.target_dimensions)+[self.channels])])\n        prediction = self.model.predict(final_image)\n        # Return the dominant expression\n        dominant_expression = self._print_prediction(prediction[0])\n        return dominant_expression", "response": "Predicts discrete emotion for given image."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks that the emotion set is supported.", "response": "def _check_emotion_set_is_supported(self):\n        \"\"\"\n        Validates set of user-supplied target emotions.\n        \"\"\"\n        supported_emotion_subsets = [\n            set(['anger', 'fear', 'surprise', 'calm']),\n            set(['happiness', 'disgust', 'surprise']),\n            set(['anger', 'fear', 'surprise']),\n            set(['anger', 'fear', 'calm']),\n            set(['anger', 'happiness', 'calm']),\n            set(['anger', 'fear', 'disgust']),\n            set(['calm', 'disgust', 'surprise']),\n            set(['sadness', 'disgust', 'surprise']),\n            set(['anger', 'happiness'])\n        ]\n        if not set(self.target_emotions) in supported_emotion_subsets:\n            error_string = 'Target emotions must be a supported subset. '\n            error_string += 'Choose from one of the following emotion subset: \\n'\n            possible_subset_string = ''\n            for emotion_set in supported_emotion_subsets:\n                possible_subset_string += ', '.join(emotion_set)\n                possible_subset_string += '\\n'\n            error_string += possible_subset_string\n            raise ValueError(error_string)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _choose_model_from_target_emotions(self):\n        model_indices = [self.emotion_index_map[emotion] for emotion in self.target_emotions]\n        sorted_indices = [str(idx) for idx in sorted(model_indices)]\n        model_suffix = ''.join(sorted_indices)\n        #Modify the path to choose the model file and the emotion map that you want to use\n        model_file = 'models/conv_model_%s.hdf5' % model_suffix\n        emotion_map_file = 'models/conv_emotion_map_%s.json' % model_suffix\n        emotion_map = json.loads(open(resource_filename('EmoPy', emotion_map_file)).read())\n        return load_model(resource_filename('EmoPy', model_file)), emotion_map", "response": "Returns a deep learning model for the set of target emotions."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef apply_transform(sample,\n                    transform_matrix,\n                    channel_axis=0,\n                    fill_mode='nearest',\n                    cval=0.):\n    \"\"\"Apply the image transformation specified by a matrix.\n\n    # Arguments\n        sample: 2D numpy array, single sample.\n        transform_matrix: Numpy array specifying the geometric transformation.\n        channel_axis: Index of axis for channels in the input tensor.\n        fill_mode: Points outside the boundaries of the input\n            are filled according to the given mode\n            (one of `{'constant', 'nearest', 'reflect', 'wrap'}`).\n        cval: Value used for points outside the boundaries\n            of the input if `mode='constant'`.\n\n    # Returns\n        The transformed version of the input.\n    \"\"\"\n    if sample.ndim == 4:\n        channel_axis = channel_axis - 1\n        transformed_frames = [transform(frame, transform_matrix, channel_axis, fill_mode, cval) for frame in sample]\n        return np.stack(transformed_frames, axis=0)\n\n    if sample.ndim == 3:\n        return transform(sample, transform_matrix, channel_axis, fill_mode, cval)", "response": "Applies the image transformation specified by a matrix."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\napplies the normalization configuration to a batch of inputs.", "response": "def standardize(self, x):\n        \"\"\"Apply the normalization configuration to a batch of inputs.\n\n        # Arguments\n            x: batch of inputs to be normalized.\n\n        # Returns\n            The inputs, normalized.\n        \"\"\"\n        if self.preprocessing_function:\n            x = self.preprocessing_function(x)\n        if self.rescale:\n            x *= self.rescale\n        if self.samplewise_center:\n            x -= np.mean(x, keepdims=True)\n        if self.samplewise_std_normalization:\n            x /= np.std(x, keepdims=True) + 1e-7\n\n        if self.featurewise_center:\n            if self.mean is not None:\n                x -= self.mean\n            else:\n                warnings.warn('This ImageDataGenerator specifies '\n                              '`featurewise_center`, but it hasn\\'t '\n                              'been fit on any training data. Fit it '\n                              'first by calling `.fit(numpy_data)`.')\n        if self.featurewise_std_normalization:\n            if self.std is not None:\n                x /= (self.std + 1e-7)\n            else:\n                warnings.warn('This ImageDataGenerator specifies '\n                              '`featurewise_std_normalization`, but it hasn\\'t '\n                              'been fit on any training data. Fit it '\n                              'first by calling `.fit(numpy_data)`.')\n        if self.zca_whitening:\n            if self.principal_components is not None:\n                flatx = np.reshape(x, (-1, np.prod(x.shape[-3:])))\n                whitex = np.dot(flatx, self.principal_components)\n                x = np.reshape(whitex, x.shape)\n            else:\n                warnings.warn('This ImageDataGenerator specifies '\n                              '`zca_whitening`, but it hasn\\'t '\n                              'been fit on any training data. Fit it '\n                              'first by calling `.fit(numpy_data)`.')\n        return x"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_random_transform_matrix(self, sample, seed=None):\n        # x is a single image, so it doesn't have image number at index 0\n        img_row_axis = self.row_axis - 1\n        img_col_axis = self.col_axis - 1\n\n        if seed is not None:\n            np.random.seed(seed)\n\n        # use composition of homographies\n        # to generate final transform that needs to be applied\n        if self.rotation_angle:\n            theta = np.pi / 180 * np.random.uniform(-self.rotation_angle, self.rotation_angle)\n        else:\n            theta = 0\n\n        if self.height_shift_range:\n            tx = np.random.uniform(-self.height_shift_range, self.height_shift_range) * sample.shape[img_row_axis]\n        else:\n            tx = 0\n\n        if self.width_shift_range:\n            ty = np.random.uniform(-self.width_shift_range, self.width_shift_range) * sample.shape[img_col_axis]\n        else:\n            ty = 0\n\n        if self.shear_range:\n            shear = np.random.uniform(-self.shear_range, self.shear_range)\n        else:\n            shear = 0\n\n        if self.zoom_range[0] == 1 and self.zoom_range[1] == 1:\n            zx, zy = 1, 1\n        else:\n            zx, zy = np.random.uniform(self.zoom_range[0], self.zoom_range[1], 2)\n\n        transform_matrix = np.identity(3)\n\n        if theta != 0:\n            rotation_matrix = np.array([[np.cos(theta), -np.sin(theta), 0],\n                                        [np.sin(theta), np.cos(theta), 0],\n                                        [0, 0, 1]])\n            transform_matrix = np.dot(transform_matrix, rotation_matrix)\n\n        if tx != 0 or ty != 0:\n            shift_matrix = np.array([[1, 0, tx],\n                                     [0, 1, ty],\n                                     [0, 0, 1]])\n            transform_matrix = np.dot(transform_matrix, shift_matrix)\n\n        if shear != 0:\n            shear_matrix = np.array([[1, -np.sin(shear), 0],\n                                     [0, np.cos(shear), 0],\n                                     [0, 0, 1]])\n            transform_matrix = np.dot(transform_matrix, shear_matrix)\n\n        if zx != 1 or zy != 1:\n            zoom_matrix = np.array([[zx, 0, 0],\n                                    [0, zy, 0],\n                                    [0, 0, 1]])\n            transform_matrix = np.dot(transform_matrix, zoom_matrix)\n\n        return transform_matrix", "response": "Generate a random transformation matrix for a single image tensor."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfit internal statistics to some sample data.", "response": "def fit(self, x,\n            augment=False,\n            rounds=1,\n            seed=None):\n        \"\"\"Fits internal statistics to some sample data.\n\n        Required for featurewise_center, featurewise_std_normalization\n        and zca_whitening.\n\n        # Arguments\n            x: Numpy array, the data to fit on. Should have rank 5 or 4 when time_delay is None.\n                In case of grayscale data,\n                the channels axis should have value 1, and in case\n                of RGB data, it should have value 3.\n            augment: Whether to fit on randomly augmented samples\n            rounds: If `augment`,\n                how many augmentation passes to do over the data\n            seed: random seed.\n\n        # Raises\n            ValueError: in case of invalid input `x`.\n        \"\"\"\n        x = np.asarray(x, dtype=K.floatx())\n        if x.shape[self.channel_axis] not in {1, 3, 4}:\n            warnings.warn(\n                'Expected input to be images (as Numpy array) '\n                'following the data format convention \"' + self.data_format + '\" '\n                                                                              '(channels on axis ' + str(\n                    self.channel_axis) + '), i.e. expected '\n                                         'either 1, 3 or 4 channels on axis ' + str(self.channel_axis) + '. '\n                                                                                                         'However, it was passed an array with shape ' + str(\n                    x.shape) +\n                ' (' + str(x.shape[self.channel_axis]) + ' channels).')\n\n        if seed is not None:\n            np.random.seed(seed)\n\n        x = np.copy(x)\n        if augment:\n            ax = np.zeros(tuple([rounds * x.shape[0]] + list(x.shape)[1:]), dtype=K.floatx())\n            for r in range(rounds):\n                for i in range(x.shape[0]):\n                    ax[i + r * x.shape[0]] = self.random_transform(x[i])\n            x = ax\n\n        if self.featurewise_center:\n            self.mean = np.mean(x, axis=0)\n            x -= self.mean\n\n        if self.featurewise_std_normalization:\n            self.std = np.std(x, axis=0)\n            x /= (self.std + K.epsilon())\n\n        if self.zca_whitening:\n            flat_x = np.reshape(x, (x.shape[0], x.shape[1] * x.shape[2] * x.shape[3]))\n            sigma = np.dot(flat_x.T, flat_x) / flat_x.shape[0]\n            u, s, _ = linalg.svd(sigma)\n            self.principal_components = np.dot(np.dot(u, np.diag(1. / np.sqrt(s + self.zca_epsilon))), u.T)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef next(self):\n        # Keeps under lock only the mechanism which advances\n        # the indexing of each batch.\n        with self.lock:\n            index_array = next(self.index_generator)\n        # The transformation of images is not under thread lock\n        # so it can be done in parallel\n        return self._get_batches_of_transformed_samples(index_array)", "response": "Returns the next batch of images."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninitialize base model from Keras and add top layers to match number of training emotions labels.", "response": "def _init_model(self):\n        \"\"\"\n        Initialize base model from Keras and add top layers to match number of training emotions labels.\n        :return:\n        \"\"\"\n        base_model = self._get_base_model()\n\n        top_layer_model = base_model.output\n        top_layer_model = GlobalAveragePooling2D()(top_layer_model)\n        top_layer_model = Dense(1024, activation='relu')(top_layer_model)\n        prediction_layer = Dense(output_dim=len(self.emotion_map.keys()), activation='softmax')(top_layer_model)\n\n        model = Model(input=base_model.input, output=prediction_layer)\n        print(model.summary())\n        for layer in base_model.layers:\n            layer.trainable = False\n        model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n\n        self.model = model"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the base model based on the user - supplied model name", "response": "def _get_base_model(self):\n        \"\"\"\n        :return: base model from Keras based on user-supplied model name\n        \"\"\"\n        if self.model_name == 'inception_v3':\n            return InceptionV3(weights='imagenet', include_top=False)\n        elif self.model_name == 'xception':\n            return Xception(weights='imagenet', include_top=False)\n        elif self.model_name == 'vgg16':\n            return VGG16(weights='imagenet', include_top=False)\n        elif self.model_name == 'vgg19':\n            return VGG19(weights='imagenet', include_top=False)\n        elif self.model_name == 'resnet50':\n            return ResNet50(weights='imagenet', include_top=False)\n        else:\n            raise ValueError('Cannot find base model %s' % self.model_name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntrain the neural net on the data provided.", "response": "def fit(self, features, labels, validation_split, epochs=50):\n        \"\"\"\n        Trains the neural net on the data provided.\n\n        :param features: Numpy array of training data.\n        :param labels: Numpy array of target (label) data.\n        :param validation_split: Float between 0 and 1. Percentage of training data to use for validation\n        :param epochs: Max number of times to train over dataset.\n        \"\"\"\n        self.model.fit(x=features, y=labels, epochs=epochs, verbose=1,\n                       callbacks=[ReduceLROnPlateau(), EarlyStopping(patience=3)], validation_split=validation_split,\n                       shuffle=True)\n\n        for layer in self.model.layers[:self._NUM_BOTTOM_LAYERS_TO_RETRAIN]:\n            layer.trainable = False\n        for layer in self.model.layers[self._NUM_BOTTOM_LAYERS_TO_RETRAIN:]:\n            layer.trainable = True\n\n        self.model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n        self.model.fit(x=features, y=labels, epochs=50, verbose=1,\n                       callbacks=[ReduceLROnPlateau(), EarlyStopping(patience=3)], validation_split=validation_split,\n                       shuffle=True)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _init_model(self):\n        model = Sequential()\n        model.add(ConvLSTM2D(filters=self.filters, kernel_size=self.kernel_size, activation=self.activation,\n                             input_shape=[self.time_delay] + list(self.image_size) + [self.channels],\n                             data_format='channels_last', return_sequences=True))\n        model.add(BatchNormalization())\n        model.add(ConvLSTM2D(filters=self.filters, kernel_size=self.kernel_size, activation=self.activation,\n                             input_shape=(self.time_delay, self.channels) + self.image_size,\n                             data_format='channels_last', return_sequences=True))\n        model.add(BatchNormalization())\n        model.add(ConvLSTM2D(filters=self.filters, kernel_size=self.kernel_size, activation=self.activation))\n        model.add(BatchNormalization())\n        model.add(Conv2D(filters=1, kernel_size=self.kernel_size, activation=\"sigmoid\", data_format=\"channels_last\"))\n        model.add(Flatten())\n        model.add(Dense(units=len(self.emotion_map.keys()), activation=\"sigmoid\"))\n        if self.verbose:\n            model.summary()\n        self.model = model", "response": "Initializes the model for the CNN."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninitialize the model for the current image.", "response": "def _init_model(self):\n        \"\"\"\n        Composes all layers of 2D CNN.\n        \"\"\"\n        model = Sequential()\n        model.add(Conv2D(input_shape=list(self.image_size) + [self.channels], filters=self.filters,\n                         kernel_size=self.kernel_size, activation='relu', data_format='channels_last'))\n        model.add(\n            Conv2D(filters=self.filters, kernel_size=self.kernel_size, activation='relu', data_format='channels_last'))\n        model.add(MaxPooling2D())\n        model.add(\n            Conv2D(filters=self.filters, kernel_size=self.kernel_size, activation='relu', data_format='channels_last'))\n        model.add(\n            Conv2D(filters=self.filters, kernel_size=self.kernel_size, activation='relu', data_format='channels_last'))\n        model.add(MaxPooling2D())\n\n        model.add(Flatten())\n        model.add(Dense(units=len(self.emotion_map.keys()), activation=\"relu\"))\n        if self.verbose:\n            model.summary()\n        self.model = model"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fit(self, image_data, labels, validation_split, epochs=50):\n        self.model.compile(optimizer=\"RMSProp\", loss=\"cosine_proximity\", metrics=[\"accuracy\"])\n        self.model.fit(image_data, labels, epochs=epochs, validation_split=validation_split,\n                       callbacks=[ReduceLROnPlateau(), EarlyStopping(patience=3)])", "response": "Train the neural net on the data provided."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _init_model(self):\n        model = Sequential()\n        model.add(Conv3D(input_shape=[self.time_delay] + list(self.image_size) + [self.channels], filters=self.filters,\n                         kernel_size=self.kernel_size, activation='relu', data_format='channels_last'))\n        model.add(\n            Conv3D(filters=self.filters, kernel_size=self.kernel_size, activation='relu', data_format='channels_last'))\n        model.add(MaxPooling3D(pool_size=(1, 2, 2), data_format='channels_last'))\n        model.add(\n            Conv3D(filters=self.filters, kernel_size=self.kernel_size, activation='relu', data_format='channels_last'))\n        model.add(\n            Conv3D(filters=self.filters, kernel_size=self.kernel_size, activation='relu', data_format='channels_last'))\n        model.add(MaxPooling3D(pool_size=(1, 2, 2), data_format='channels_last'))\n\n        model.add(Flatten())\n        model.add(Dense(units=len(self.emotion_map.keys()), activation=\"relu\"))\n        if self.verbose:\n            model.summary()\n        self.model = model", "response": "Initializes the model for the current state of the module."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nbuild the command needed to invoke the postgres query as the postgres user.", "response": "def build_query_cmd(self, query, csv=False):\n        \"\"\"\n        Builds the command needed to invoke the pgsql query as the postgres\n        user.\n        The query requires significant quoting work to satisfy both the\n        shell and postgres parsing requirements. Note that this will generate\n        a large amount of quoting in sos logs referencing the command being run\n        \"\"\"\n        _cmd = \"su postgres -c %s\"\n        if not csv:\n            _dbcmd = \"psql foreman -c %s\"\n        else:\n            _dbcmd = \"psql foreman -A -F , -X -c %s\"\n        dbq = _dbcmd % quote(query)\n        return _cmd % quote(dbq)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _add_vdsm_forbidden_paths(self):\n\n        for file_path in glob.glob(\"/var/run/vdsm/*\"):\n            if file_path.endswith(('.vfd', '/isoUploader', '/storage')):\n                self.add_forbidden_path(file_path)", "response": "Add confidential sysprep vfds under / var / run / vfds to\n         forbidden paths"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_enabled(self, name):\n        if self.services and name in self.services:\n            return self.services[name]['config'] == 'enabled'\n        return False", "response": "Check if given service name is enabled"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if a given service name is disabled", "response": "def is_disabled(self, name):\n        \"\"\"Check if a given service name is disabled \"\"\"\n        if self.services and name in self.services:\n            return self.services[name]['config'] == 'disabled'\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nquerying an individual service", "response": "def _query_service(self, name):\n        \"\"\"Query an individual service\"\"\"\n        if self.query_cmd:\n            try:\n                return sos_get_command_output(\"%s %s\" % (self.query_cmd, name))\n            except Exception:\n                return None\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_service_status(self, name):\n        svc = self._query_service(name)\n        if svc is not None:\n            return {'name': name,\n                    'status': self.parse_query(svc['output']),\n                    'output': svc['output']\n                    }\n        else:\n            return {'name': name,\n                    'status': 'missing',\n                    'output': ''\n                    }", "response": "Returns the status of the given service name along with the output of the query command"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef all_pkgs_by_name_regex(self, regex_name, flags=0):\n        reg = re.compile(regex_name, flags)\n        return [pkg for pkg in self.all_pkgs().keys() if reg.match(pkg)]", "response": "Return a list of all packages that match regex_name."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pkg_by_name(self, name):\n        pkgmatches = self.all_pkgs_by_name(name)\n        if (len(pkgmatches) != 0):\n            return self.all_pkgs_by_name(name)[-1]\n        else:\n            return None", "response": "Return a single package that matches name."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_pkg_list(self):\n        if self.query_command:\n            cmd = self.query_command\n            pkg_list = shell_out(\n                cmd, timeout=0, chroot=self.chroot\n            ).splitlines()\n\n            for pkg in pkg_list:\n                if '|' not in pkg:\n                    continue\n                elif pkg.count(\"|\") == 1:\n                    name, version = pkg.split(\"|\")\n                    release = None\n                elif pkg.count(\"|\") == 2:\n                    name, version, release = pkg.split(\"|\")\n                self.packages[name] = {\n                    'name': name,\n                    'version': version.split(\".\")\n                }\n                release = release if release else None\n                self.packages[name]['release'] = release\n\n        return self.packages", "response": "Returns a dictionary of packages in the following format::\n            name version release"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef all_pkgs(self):\n        if not self.packages:\n            self.packages = self.get_pkg_list()\n        return self.packages", "response": "Return a list of all packages."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef all_files(self):\n        if self.files_command and not self.files:\n            cmd = self.files_command\n            files = shell_out(cmd, timeout=0, chroot=self.chroot)\n            self.files = files.splitlines()\n        return self.files", "response": "Returns a list of files known by the package manager"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef build_verify_command(self, packages):\n        if not self.verify_command:\n            return None\n\n        # The re.match(pkg) used by all_pkgs_by_name_regex() may return\n        # an empty list (`[[]]`) when no package matches: avoid building\n        # an rpm -V command line with the empty string as the package\n        # list in this case.\n        by_regex = self.all_pkgs_by_name_regex\n        verify_list = filter(None, map(by_regex, packages))\n\n        # No packages after regex match?\n        if not verify_list:\n            return None\n\n        verify_packages = \"\"\n        for package_list in verify_list:\n            for package in package_list:\n                if any([f in package for f in self.verify_filter]):\n                    continue\n                if len(verify_packages):\n                    verify_packages += \" \"\n                verify_packages += package\n        return self.verify_command + \" \" + verify_packages", "response": "Build a command to verify the list of packages given in packages."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwriting this preset to disk in JSON notation.", "response": "def write(self, presets_path):\n        \"\"\"Write this preset to disk in JSON notation.\n\n            :param presets_path: the directory where the preset will be\n                                 written.\n        \"\"\"\n        if self.builtin:\n            raise TypeError(\"Cannot write built-in preset\")\n\n        # Make dictionaries of PresetDefaults values\n        odict = self.opts.dict()\n        pdict = {self.name: {DESC: self.desc, NOTE: self.note, OPTS: odict}}\n\n        if not os.path.exists(presets_path):\n            os.makedirs(presets_path, mode=0o755)\n\n        with open(os.path.join(presets_path, self.name), \"w\") as pfile:\n            json.dump(pdict, pfile)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_archive_name(self):\n        name = self.get_local_name().split('.')[0]\n        case = self.case_id\n        label = self.commons['cmdlineopts'].label\n        date = ''\n        rand = ''.join(random.choice(string.ascii_lowercase) for x in range(7))\n\n        if self.name_pattern == 'legacy':\n            nstr = \"sosreport-{name}{case}{date}\"\n            case = '.' + case if case else ''\n            date = '-%Y%m%d%H%M%S'\n        elif self.name_pattern == 'friendly':\n            nstr = \"sosreport-{name}{label}{case}{date}-{rand}\"\n            case = '-' + case if case else ''\n            label = '-' + label if label else ''\n            date = '-%Y-%m-%d'\n        else:\n            nstr = self.name_pattern\n\n        nstr = nstr.format(\n            name=name,\n            label=label,\n            case=case,\n            date=date,\n            rand=rand\n        )\n        return self.sanitize_filename(time.strftime(nstr))", "response": "This function returns the name of the archive without the extension."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nverify that the plugin_class should execute under this policy.", "response": "def validate_plugin(self, plugin_class, experimental=False):\n        \"\"\"\n        Verifies that the plugin_class should execute under this policy\n        \"\"\"\n        valid_subclasses = [IndependentPlugin] + self.valid_subclasses\n        if experimental:\n            valid_subclasses += [ExperimentalPlugin]\n        return any(issubclass(plugin_class, class_) for\n                   class_ in valid_subclasses)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _print(self, msg=None, always=False):\n        if always or not self.commons['cmdlineopts'].quiet:\n            if msg:\n                print_(msg)\n            else:\n                print_()", "response": "A wrapper around print that only prints if we are not running in\n            quiet mode"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef register_presets(self, presets, replace=False):\n        if replace:\n            self.presets = {}\n        self.presets.update(presets)", "response": "Add new presets to this policy object."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfinds a preset profile matching the specified preset string.", "response": "def find_preset(self, preset):\n        \"\"\"Find a preset profile matching the specified preset string.\n\n            :param preset: a string containing a preset profile name.\n            :returns: a matching PresetProfile.\n        \"\"\"\n        # FIXME: allow fuzzy matching?\n        for match in self.presets.keys():\n            if match == preset:\n                return self.presets[match]\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads presets from disk.", "response": "def load_presets(self, presets_path=None):\n        \"\"\"Load presets from disk.\n\n            Read JSON formatted preset data from the specified path,\n            or the default location at ``/var/lib/sos/presets``.\n\n            :param presets_path: a directory containing JSON presets.\n        \"\"\"\n        presets_path = presets_path or self.presets_path\n        if not os.path.exists(presets_path):\n            return\n        for preset_path in os.listdir(presets_path):\n            preset_path = os.path.join(presets_path, preset_path)\n\n            try:\n                preset_data = json.load(open(preset_path))\n            except ValueError:\n                continue\n\n            for preset in preset_data.keys():\n                pd = PresetDefaults(preset, opts=SoSOptions())\n                data = preset_data[preset]\n                pd.desc = data[DESC] if DESC in data else \"\"\n                pd.note = data[NOTE] if NOTE in data else \"\"\n\n                if OPTS in data:\n                    for arg in _arg_names:\n                        if arg in data[OPTS]:\n                            setattr(pd.opts, arg, data[OPTS][arg])\n                pd.builtin = False\n                self.presets[preset] = pd"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_preset(self, name=None, desc=None, note=None, opts=SoSOptions()):\n        presets_path = self.presets_path\n\n        if not name:\n            raise ValueError(\"Preset name cannot be empty\")\n\n        if name in self.presets.keys():\n            raise ValueError(\"A preset with name '%s' already exists\" % name)\n\n        preset = PresetDefaults(name=name, desc=desc, note=note, opts=opts)\n        preset.builtin = False\n        self.presets[preset.name] = preset\n        preset.write(presets_path)", "response": "Add a new on - disk preset and write it to the configured\n            presets path."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of kernel module names as strings.", "response": "def lsmod(self):\n        \"\"\"Return a list of kernel module names as strings.\n        \"\"\"\n        lines = shell_out(\"lsmod\", timeout=0).splitlines()\n        return [line.split()[0].strip() for line in lines]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef do_lvmdump(self, metadata=False):\n        lvmdump_path = self.get_cmd_output_path(name=\"lvmdump\", make=False)\n        lvmdump_cmd = \"lvmdump %s -d '%s'\"\n        lvmdump_opts = \"\"\n\n        if metadata:\n            lvmdump_opts = \"-a -m\"\n\n        cmd = lvmdump_cmd % (lvmdump_opts, lvmdump_path)\n\n        self.add_cmd_output(cmd, chroot=self.tmp_in_sysroot())", "response": "Collects an lvmdump in standard format with optional metadata\n           archives for each physical volume present."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nformats a SoSOptions object as a human readable string.", "response": "def __str(self, quote=False, sep=\" \", prefix=\"\", suffix=\"\"):\n        \"\"\"Format a SoSOptions object as a human or machine readable string.\n\n            :param quote: quote option values\n            :param sep: list separator string\n            :param prefix: arbitrary prefix string\n            :param suffix: arbitrary suffix string\n            :param literal: print values as Python literals\n        \"\"\"\n        args = prefix\n        arg_fmt = \"=%s\"\n        for arg in _arg_names:\n            args += arg + arg_fmt + sep\n        args.strip(sep)\n\n        vals = [getattr(self, arg) for arg in _arg_names]\n        if not quote:\n            # Convert Python source notation for sequences into plain strings\n            vals = [\",\".join(v) if _is_seq(v) else v for v in vals]\n        else:\n            def is_string(val):\n                return isinstance(val, six.string_types)\n            # Only quote strings if quote=False\n            vals = [\"'%s'\" % v if is_string(v) else v for v in vals]\n\n        return (args % tuple(vals)).strip(sep) + suffix"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_args(cls, args):\n        opts = SoSOptions()\n        opts._merge_opts(args, True)\n        return opts", "response": "Initialise a new SoSOptions object from a parsed command line arguments."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting a named option and optional value to command line argument notation.", "response": "def _opt_to_args(cls, opt, val):\n        \"\"\"Convert a named option and optional value to command line\n            argument notation, correctly handling options that take\n            no value or that have special representations (e.g. verify\n            and verbose).\n        \"\"\"\n        no_value = (\n            \"alloptions\", \"all-logs\", \"batch\", \"build\", \"debug\",\n            \"experimental\", \"list-plugins\", \"list-presets\", \"list-profiles\",\n            \"noreport\", \"quiet\", \"verify\"\n        )\n        count = (\"verbose\",)\n        if opt in no_value:\n            return [\"--%s\" % opt]\n        if opt in count:\n            return [\"--%s\" % opt for d in range(0, int(val))]\n        return [\"--\" + opt + \"=\" + val]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmerge another set of SoSOptions into this set.", "response": "def merge(self, src, skip_default=True):\n        \"\"\"Merge another set of ``SoSOptions`` into this object.\n\n            Merge two ``SoSOptions`` objects by setting unset or default\n            values to their value in the ``src`` object.\n\n            :param src: the ``SoSOptions`` object to copy from\n            :param is_default: ``True`` if new default values are to be set.\n        \"\"\"\n        for arg in _arg_names:\n            if not hasattr(src, arg):\n                continue\n            if getattr(src, arg) is not None or not skip_default:\n                self._merge_opt(arg, src, False)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dict(self):\n        odict = {}\n        for arg in _arg_names:\n            value = getattr(self, arg)\n            # Do not attempt to store preset option values in presets\n            if arg in ('add_preset', 'del_preset', 'desc', 'note'):\n                value = None\n            odict[arg] = value\n        return odict", "response": "Return this SoSOptions option values as a dictionary of name to value mappings."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef to_args(self):\n        def has_value(name, value):\n            \"\"\" Test for non-null option values.\n            \"\"\"\n            null_values = (\"False\", \"None\", \"[]\", '\"\"', \"''\", \"0\")\n            if not value or value in null_values:\n                return False\n            if name in _arg_defaults:\n                if str(value) == str(_arg_defaults[name]):\n                    return False\n            return True\n\n        def filter_opt(name, value):\n            \"\"\" Filter out preset and null-valued options.\n            \"\"\"\n            if name in (\"add_preset\", \"del_preset\", \"desc\", \"note\"):\n                return False\n            return has_value(name, value)\n\n        def argify(name, value):\n            \"\"\" Convert sos option notation to command line arguments.\n            \"\"\"\n            # Handle --verbosity specially\n            if name.startswith(\"verbosity\"):\n                arg = \"-\" + int(value) * \"v\"\n                return arg\n\n            name = name.replace(\"_\", \"-\")\n\n            value = \",\".join(value) if _is_seq(value) else value\n\n            if value is not True:\n                opt = \"%s %s\" % (name, value)\n            else:\n                opt = name\n\n            arg = \"--\" + opt if len(opt) > 1 else \"-\" + opt\n            return arg\n\n        opt_items = sorted(self.dict().items(), key=lambda x: x[0])\n        return [argify(n, v) for (n, v) in opt_items if filter_opt(n, v)]", "response": "Convert this object into a list of command line arguments."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_dns_dir(self, config_file):\n        directory_list = self.do_regex_find_all(r\"directory\\s+\\\"(.*)\\\"\",\n                                                config_file)\n        if directory_list:\n            return normpath(directory_list[0])\n        else:\n            return \"\"", "response": "grab directory path from named { conf boot }"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef checkdebug(self):\n        # Global debugging\n        opt = self.file_grep(r\"^(DEFAULT_LOGGING|DAEMONOPTIONS)=(.*)\",\n                             *self.files)\n        for opt1 in opt:\n            for opt2 in opt1.split(\" \"):\n                if opt2 in (\"--debug\", \"debug\"):\n                    return True\n        return False", "response": "testing if autofs debug has been enabled anywhere\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncaptures daemon debug output", "response": "def getdaemondebug(self):\n        \"\"\" capture daemon debug output\n        \"\"\"\n        debugout = self.file_grep(r\"^(daemon.*)\\s+(\\/var\\/log\\/.*)\",\n                                  *self.files)\n        for i in debugout:\n            return i[1]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_jar(path):\n        if os.path.isfile(path) and zipfile.is_zipfile(path):\n            try:\n                with zipfile.ZipFile(path) as f:\n                    if \"META-INF/MANIFEST.MF\" in f.namelist():\n                        return True\n            except (IOError, zipfile.BadZipfile):\n                pass\n        return False", "response": "Check whether given file is a JAR file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nextracting Maven coordinates from a given JAR file.", "response": "def get_maven_id(jar_path):\n        \"\"\"Extract Maven coordinates from a given JAR file, if possible.\n\n        JARs build by Maven (most popular Java build system) contain\n        'pom.properties' file. We can extract Maven coordinates\n         from there.\n        \"\"\"\n        props = {}\n        try:\n            with zipfile.ZipFile(jar_path) as f:\n                r = re.compile(\"META-INF/maven/[^/]+/[^/]+/pom.properties$\")\n                result = [x for x in f.namelist() if r.match(x)]\n                if len(result) != 1:\n                    return None\n                with f.open(result[0]) as props_f:\n                    for line in props_f.readlines():\n                        line = line.strip()\n                        if not line.startswith(b\"#\"):\n                            try:\n                                (key, value) = line.split(b\"=\")\n                                key = key.decode('utf8').strip()\n                                value = value.decode('utf8').strip()\n                                props[key] = value\n                            except ValueError:\n                                return None\n        except IOError:\n            pass\n        return props"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_jar_id(jar_path):\n        jar_id = \"\"\n        try:\n            with open(jar_path, mode=\"rb\") as f:\n                m = hashlib.sha1()\n                for buf in iter(partial(f.read, 4096), b''):\n                    m.update(buf)\n            jar_id = m.hexdigest()\n        except IOError:\n            pass\n        return jar_id", "response": "Compute JAR id.\n            Returns sha1 hash of a given JAR file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _find_modules_in_npm_cache(self):\n        output = {}\n        # with chroot=True (default) the command fails when run as non-root\n        user_cache = self.get_command_output(\"npm cache ls\", chroot=False)\n        if user_cache['status'] == 0:\n            # filter out dirs with .cache.json ('registry.npmjs.org')\n            for package in [l for l in user_cache['output'].splitlines()\n                            if l.endswith('package.tgz')]:\n                five_tuple = package.split(os.path.sep)\n                if len(five_tuple) != 5:  # sanity check\n                    continue\n                home, cache, name, version, package_tgz = five_tuple\n                if name not in output:\n                    output[name] = [version]\n                else:\n                    output[name].append(version)\n        self._log_debug(\"modules in cache: %s\" % output)\n\n        outfn = self._make_command_filename(\"npm_cache_modules\")\n        self.add_string_as_file(json.dumps(output), outfn)", "response": "Find modules in npm cache"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef setup(self):\n        options = \"\"\n        amqps_prefix = \"\"  # set amqps:// when SSL is used\n        if self.get_option(\"ssl\"):\n            amqps_prefix = \"amqps://\"\n        # for either present option, add --option=value to 'options' variable\n        for option in [\"ssl-certificate\", \"ssl-key\"]:\n            if self.get_option(option):\n                amqps_prefix = \"amqps://\"\n                options = (options + \" --%s=\" % (option) +\n                           self.get_option(option))\n        if self.get_option(\"port\"):\n            options = (options + \" -b \" + amqps_prefix +\n                       \"localhost:%s\" % (self.get_option(\"port\")))\n\n        self.add_cmd_output([\n            \"qpid-stat -g\" + options,  # applies since 0.18 version\n            \"qpid-stat -b\" + options,  # applies to pre-0.18 versions\n            \"qpid-stat -c\" + options,\n            \"qpid-stat -e\" + options,\n            \"qpid-stat -q\" + options,\n            \"qpid-stat -u\" + options,\n            \"qpid-stat -m\" + options,  # applies since 0.18 version\n            \"qpid-config exchanges\" + options,\n            \"qpid-config queues\" + options,\n            \"qpid-config exchanges -b\" + options,  # applies to pre-0.18 vers.\n            \"qpid-config queues -b\" + options,  # applies to pre-0.18 versions\n            \"qpid-config exchanges -r\" + options,  # applies since 0.18 version\n            \"qpid-config queues -r\" + options,  # applies since 0.18 version\n            \"qpid-route link list\" + options,\n            \"qpid-route route list\" + options,\n            \"qpid-cluster\" + options,  # applies to pre-0.22 versions\n            \"qpid-ha query\" + options,  # applies since 0.22 version\n            \"ls -lanR /var/lib/qpidd\"\n        ])\n\n        self.add_copy_spec([\n            \"/etc/qpidd.conf\",  # applies to pre-0.22 versions\n            \"/etc/qpid/qpidd.conf\",  # applies since 0.22 version\n            \"/var/lib/qpid/syslog\",\n            \"/etc/ais/openais.conf\",\n            \"/var/log/cumin.log\",\n            \"/var/log/mint.log\",\n            \"/etc/sasl2/qpidd.conf\",\n            \"/etc/qpid/qpidc.conf\",\n            \"/etc/sesame/sesame.conf\",\n            \"/etc/cumin/cumin.conf\",\n            \"/etc/corosync/corosync.conf\",\n            \"/var/lib/sesame\",\n            \"/var/log/qpidd.log\",\n            \"/var/log/sesame\",\n            \"/var/log/cumin\"\n        ])", "response": "Sets up the command line arguments for the qpid broker"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_parser():\n\n    usage_string = (\"%(prog)s [options]\\n\\n\"\n                    \"Some examples:\\n\\n\"\n                    \"enable dlm plugin only and collect dlm lockdumps:\\n\"\n                    \"  # sosreport -o dlm -k dlm.lockdump\\n\\n\"\n                    \"disable memory and samba plugins, turn off rpm \"\n                    \"-Va collection:\\n\"\n                    \"  # sosreport -n memory,samba -k rpm.rpmva=off\")\n\n    parser = ArgumentParser(usage=usage_string)\n    parser.register('action', 'extend', SosListOption)\n    parser.add_argument(\"-a\", \"--alloptions\", action=\"store_true\",\n                        dest=\"alloptions\", default=False,\n                        help=\"enable all options for loaded plugins\")\n    parser.add_argument(\"--all-logs\", action=\"store_true\",\n                        dest=\"all_logs\", default=False,\n                        help=\"collect all available logs regardless \"\n                             \"of size\")\n    parser.add_argument(\"--batch\", action=\"store_true\",\n                        dest=\"batch\", default=False,\n                        help=\"batch mode - do not prompt interactively\")\n    parser.add_argument(\"--build\", action=\"store_true\",\n                        dest=\"build\", default=False,\n                        help=\"preserve the temporary directory and do not \"\n                             \"package results\")\n    parser.add_argument(\"--case-id\", action=\"store\",\n                        dest=\"case_id\",\n                        help=\"specify case identifier\")\n    parser.add_argument(\"-c\", \"--chroot\", action=\"store\", dest=\"chroot\",\n                        help=\"chroot executed commands to SYSROOT \"\n                             \"[auto, always, never] (default=auto)\",\n                        default=_arg_defaults[\"chroot\"])\n    parser.add_argument(\"--config-file\", type=str, action=\"store\",\n                        dest=\"config_file\", default=\"/etc/sos.conf\",\n                        help=\"specify alternate configuration file\")\n    parser.add_argument(\"--debug\", action=\"store_true\", dest=\"debug\",\n                        help=\"enable interactive debugging using the \"\n                             \"python debugger\")\n    parser.add_argument(\"--desc\", \"--description\", type=str, action=\"store\",\n                        help=\"Description for a new preset\", default=\"\")\n    parser.add_argument(\"--dry-run\", action=\"store_true\",\n                        help=\"Run plugins but do not collect data\")\n    parser.add_argument(\"--experimental\", action=\"store_true\",\n                        dest=\"experimental\", default=False,\n                        help=\"enable experimental plugins\")\n    parser.add_argument(\"-e\", \"--enable-plugins\", action=\"extend\",\n                        dest=\"enableplugins\", type=str,\n                        help=\"enable these plugins\", default=[])\n    parser.add_argument(\"-k\", \"--plugin-option\", action=\"extend\",\n                        dest=\"plugopts\", type=str,\n                        help=\"plugin options in plugname.option=value \"\n                             \"format (see -l)\", default=[])\n    parser.add_argument(\"--label\", \"--name\", action=\"store\", dest=\"label\",\n                        help=\"specify an additional report label\")\n    parser.add_argument(\"-l\", \"--list-plugins\", action=\"store_true\",\n                        dest=\"list_plugins\", default=False,\n                        help=\"list plugins and available plugin options\")\n    parser.add_argument(\"--list-presets\", action=\"store_true\",\n                        help=\"display a list of available presets\")\n    parser.add_argument(\"--list-profiles\", action=\"store_true\",\n                        dest=\"list_profiles\", default=False,\n                        help=\"display a list of available profiles and \"\n                             \"plugins that they include\")\n    parser.add_argument(\"--log-size\", action=\"store\", dest=\"log_size\",\n                        type=int, default=_arg_defaults[\"log_size\"],\n                        help=\"limit the size of collected logs (in MiB)\")\n    parser.add_argument(\"-n\", \"--skip-plugins\", action=\"extend\",\n                        dest=\"noplugins\", type=str,\n                        help=\"disable these plugins\", default=[])\n    parser.add_argument(\"--no-report\", action=\"store_true\",\n                        dest=\"noreport\",\n                        help=\"disable plaintext/HTML reporting\", default=False)\n    parser.add_argument(\"--note\", type=str, action=\"store\", default=\"\",\n                        help=\"Behaviour notes for new preset\")\n    parser.add_argument(\"-o\", \"--only-plugins\", action=\"extend\",\n                        dest=\"onlyplugins\", type=str,\n                        help=\"enable these plugins only\", default=[])\n    parser.add_argument(\"--preset\", action=\"store\", type=str,\n                        help=\"A preset identifier\", default=\"auto\")\n    parser.add_argument(\"--plugin-timeout\", default=None,\n                        help=\"set a timeout for all plugins\")\n    parser.add_argument(\"-p\", \"--profile\", action=\"extend\",\n                        dest=\"profiles\", type=str, default=[],\n                        help=\"enable plugins used by the given profiles\")\n    parser.add_argument(\"-q\", \"--quiet\", action=\"store_true\",\n                        dest=\"quiet\", default=False,\n                        help=\"only print fatal errors\")\n    parser.add_argument(\"-s\", \"--sysroot\", action=\"store\", dest=\"sysroot\",\n                        help=\"system root directory path (default='/')\",\n                        default=None)\n    parser.add_argument(\"--ticket-number\", action=\"store\",\n                        dest=\"case_id\",\n                        help=\"specify ticket number\")\n    parser.add_argument(\"--tmp-dir\", action=\"store\",\n                        dest=\"tmp_dir\",\n                        help=\"specify alternate temporary directory\",\n                        default=None)\n    parser.add_argument(\"-v\", \"--verbose\", action=\"count\", dest=\"verbosity\",\n                        default=_arg_defaults[\"verbosity\"],\n                        help=\"increase verbosity\"),\n    parser.add_argument(\"--verify\", action=\"store_true\",\n                        dest=\"verify\", default=False,\n                        help=\"perform data verification during collection\")\n    parser.add_argument(\"-z\", \"--compression-type\", dest=\"compression_type\",\n                        default=_arg_defaults[\"compression_type\"],\n                        help=\"compression technology to use [auto, \"\n                             \"gzip, bzip2, xz] (default=auto)\")\n    parser.add_argument(\"-t\", \"--threads\", action=\"store\", dest=\"threads\",\n                        help=\"specify number of concurrent plugins to run\"\n                        \" (default=4)\", default=4, type=int)\n\n    # Group to make add/del preset exclusive\n    preset_grp = parser.add_mutually_exclusive_group()\n    preset_grp.add_argument(\"--add-preset\", type=str, action=\"store\",\n                            help=\"Add a new named command line preset\")\n    preset_grp.add_argument(\"--del-preset\", type=str, action=\"store\",\n                            help=\"Delete the named command line preset\")\n\n    # Group to make tarball encryption (via GPG/password) exclusive\n    encrypt_grp = parser.add_mutually_exclusive_group()\n    encrypt_grp.add_argument(\"--encrypt-key\",\n                             help=\"Encrypt the final archive using a GPG \"\n                                  \"key-pair\")\n    encrypt_grp.add_argument(\"--encrypt-pass\",\n                             help=\"Encrypt the final archive using a password\")\n\n    return parser", "response": "Build the ArgumentParser content for the SPL - list command line."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwraps exception in debugger if interactive mode.", "response": "def _exception(etype, eval_, etrace):\n        \"\"\" Wrap exception in debugger if not in tty \"\"\"\n        if hasattr(sys, 'ps1') or not sys.stderr.isatty():\n            # we are in interactive mode or we don't have a tty-like\n            # device, so we call the default hook\n            sys.__excepthook__(etype, eval_, etrace)\n        else:\n            # we are NOT in interactive mode, print the exception...\n            traceback.print_exception(etype, eval_, etrace, limit=2,\n                                      file=sys.stdout)\n            six.print_()\n            # ...then start the debugger in post-mortem mode.\n            pdb.pm()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_preset(self, name, desc=\"\", note=\"\"):\n        policy = self.policy\n        if policy.find_preset(name):\n            self.ui_log.error(\"A preset named '%s' already exists\" % name)\n            return False\n\n        desc = desc or self.opts.desc\n        note = note or self.opts.note\n\n        try:\n            policy.add_preset(name=name, desc=desc, note=note, opts=self.opts)\n        except Exception as e:\n            self.ui_log.error(\"Could not add preset: %s\" % e)\n            return False\n\n        # Filter --add-preset <name> from arguments list\n        arg_index = self._args.index(\"--add-preset\")\n        args = self._args[0:arg_index] + self._args[arg_index + 2:]\n\n        self.ui_log.info(\"Added preset '%s' with options %s\\n\" %\n                         (name, \" \".join(args)))\n        return True", "response": "Adds a new command line preset for the current options with the specified name."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef del_preset(self, name):\n        policy = self.policy\n        if not policy.find_preset(name):\n            self.ui_log.error(\"Preset '%s' not found\" % name)\n            return False\n\n        try:\n            policy.del_preset(name=name)\n        except Exception as e:\n            self.ui_log.error(str(e) + \"\\n\")\n            return False\n\n        self.ui_log.info(\"Deleted preset '%s'\\n\" % name)\n        return True", "response": "Delete a named command line preset."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef version(self):\n\n        versions = []\n        versions.append(\"sosreport: %s\" % __version__)\n\n        for plugname, plug in self.loaded_plugins:\n            versions.append(\"%s: %s\" % (plugname, plug.version))\n\n        self.archive.add_string(content=\"\\n\".join(versions),\n                                dest='version.txt')", "response": "Fetch version information from all plugins and store in the report\n        version file"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrap the collect_plugin method so we can apply a timeout against the plugin as a whole", "response": "def _collect_plugin(self, plugin):\n        '''Wraps the collect_plugin() method so we can apply a timeout\n        against the plugin as a whole'''\n        with ThreadPoolExecutor(1) as pool:\n            try:\n                t = pool.submit(self.collect_plugin, plugin)\n                # Re-type int 0 to NoneType, as otherwise result() will treat\n                # it as a literal 0-second timeout\n                timeout = self.loaded_plugins[plugin[0]-1][1].timeout or None\n                t.result(timeout=timeout)\n            except TimeoutError:\n                self.ui_log.error(\"\\n Plugin %s timed out\\n\" % plugin[1])\n                self.running_plugs.remove(plugin[1])\n                self.loaded_plugins[plugin[0]-1][1]._timeout_hit = True\n                pool._threads.clear()\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_navicli_SP_info(self, SP_address):\n        self.add_cmd_output([\n            \"navicli -h %s getall\" % SP_address,\n            \"navicli -h %s getsptime -spa\" % SP_address,\n            \"navicli -h %s getsptime -spb\" % SP_address,\n            \"navicli -h %s getlog\" % SP_address,\n            \"navicli -h %s getdisk\" % SP_address,\n            \"navicli -h %s getcache\" % SP_address,\n            \"navicli -h %s getlun\" % SP_address,\n            \"navicli -h %s getlun -rg -type -default -owner -crus \"\n            \"-capacity\" % SP_address,\n            \"navicli -h %s lunmapinfo\" % SP_address,\n            \"navicli -h %s getcrus\" % SP_address,\n            \"navicli -h %s port -list -all\" % SP_address,\n            \"navicli -h %s storagegroup -list\" % SP_address,\n            \"navicli -h %s spportspeed -get\" % SP_address\n        ])", "response": "Emc NAVISphere Host Agent NAVICLI specific structures - NAVISphere Host Agent NAVICLI specific structures - NAVISphere Host Agent NAVISphere SP information - CLARiiON - commands"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndetermine if we are on a node running etcd", "response": "def is_static_etcd(self):\n        '''Determine if we are on a node running etcd'''\n        return os.path.exists(os.path.join(self.static_pod_dir, \"etcd.yaml\"))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list for which items are namespaces in the output of ip netns stored in the ip_netns_file.", "response": "def get_ip_netns(self, ip_netns_file):\n        \"\"\"Returns a list for which items are namespaces in the output of\n        ip netns stored in the ip_netns_file.\n        \"\"\"\n        out = []\n        try:\n            ip_netns_out = open(ip_netns_file).read()\n        except IOError:\n            return out\n        for line in ip_netns_out.splitlines():\n            # If there's no namespaces, no need to continue\n            if line.startswith(\"Object \\\"netns\\\" is unknown\") \\\n               or line.isspace() \\\n               or line[:1].isspace():\n                return out\n            out.append(line.partition(' ')[0])\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef collect_iptable(self, tablename):\n\n        modname = \"iptable_\"+tablename\n        if self.check_ext_prog(\"grep -q %s /proc/modules\" % modname):\n            cmd = \"iptables -t \"+tablename+\" -nvL\"\n            self.add_cmd_output(cmd)", "response": "Collect all the iptables rules for a table."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncollects all entries in the specified table.", "response": "def collect_ip6table(self, tablename):\n        \"\"\" Same as function above, but for ipv6 \"\"\"\n\n        modname = \"ip6table_\"+tablename\n        if self.check_ext_prog(\"grep -q %s /proc/modules\" % modname):\n            cmd = \"ip6tables -t \"+tablename+\" -nvL\"\n            self.add_cmd_output(cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef postproc(self):\n        self.do_file_sub(\n            \"/etc/ovirt-engine/engine-config/engine-config.properties\",\n            r\"Password.type=(.*)\",\n            r\"Password.type=********\"\n        )\n        self.do_file_sub(\n            \"/etc/rhevm/rhevm-config/rhevm-config.properties\",\n            r\"Password.type=(.*)\",\n            r\"Password.type=********\"\n        )\n\n        engine_files = (\n            'ovirt-engine.xml',\n            'ovirt-engine_history/current/ovirt-engine.v1.xml',\n            'ovirt-engine_history/ovirt-engine.boot.xml',\n            'ovirt-engine_history/ovirt-engine.initial.xml',\n            'ovirt-engine_history/ovirt-engine.last.xml',\n        )\n        for filename in engine_files:\n            self.do_file_sub(\n                \"/var/tmp/ovirt-engine/config/%s\" % filename,\n                r\"<password>(.*)</password>\",\n                r\"<password>********</password>\"\n            )\n\n        self.do_file_sub(\n            \"/etc/ovirt-engine/redhatsupportplugin.conf\",\n            r\"proxyPassword=(.*)\",\n            r\"proxyPassword=********\"\n        )\n\n        passwd_files = [\n            \"logcollector.conf\",\n            \"imageuploader.conf\",\n            \"isouploader.conf\"\n        ]\n        for conf_file in passwd_files:\n            conf_path = os.path.join(\"/etc/ovirt-engine\", conf_file)\n            self.do_file_sub(\n                conf_path,\n                r\"passwd=(.*)\",\n                r\"passwd=********\"\n            )\n            self.do_file_sub(\n                conf_path,\n                r\"pg-pass=(.*)\",\n                r\"pg-pass=********\"\n            )\n\n        sensitive_keys = self.DEFAULT_SENSITIVE_KEYS\n        # Handle --alloptions case which set this to True.\n        keys_opt = self.get_option('sensitive_keys')\n        if keys_opt and keys_opt is not True:\n            sensitive_keys = keys_opt\n        key_list = [x for x in sensitive_keys.split(':') if x]\n        for key in key_list:\n            self.do_path_regex_sub(\n                self.DB_PASS_FILES,\n                r'{key}=(.*)'.format(key=key),\n                r'{key}=********'.format(key=key)\n            )\n\n        # Answer files contain passwords\n        for key in (\n            'OVESETUP_CONFIG/adminPassword',\n            'OVESETUP_CONFIG/remoteEngineHostRootPassword',\n            'OVESETUP_DWH_DB/password',\n            'OVESETUP_DB/password',\n            'OVESETUP_REPORTS_CONFIG/adminPassword',\n            'OVESETUP_REPORTS_DB/password',\n        ):\n            self.do_path_regex_sub(\n                r'/var/lib/ovirt-engine/setup/answers/.*',\n                r'{key}=(.*)'.format(key=key),\n                r'{key}=********'.format(key=key)\n            )\n\n        # aaa profiles contain passwords\n        protect_keys = [\n            \"vars.password\",\n            \"pool.default.auth.simple.password\",\n            \"pool.default.ssl.truststore.password\",\n            \"config.datasource.dbpassword\"\n        ]\n        regexp = r\"((?m)^\\s*#*(%s)\\s*=\\s*)(.*)\" % \"|\".join(protect_keys)\n\n        self.do_path_regex_sub(r\"/etc/ovirt-engine/aaa/.*\\.properties\", regexp,\n                               r\"\\1*********\")", "response": "Postprocessing of the Obfuscate sensitive keys."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting watchdog log directory path configured in conf_file.", "response": "def get_log_dir(self, conf_file):\n        \"\"\"Get watchdog log directory.\n\n            Get watchdog log directory path configured in ``conf_file``.\n\n            :returns: The watchdog log directory path.\n            :returntype: str.\n            :raises: IOError if ``conf_file`` is not readable.\n        \"\"\"\n        log_dir = None\n\n        with open(conf_file, 'r') as conf_f:\n            for line in conf_f:\n                line = line.split('#')[0].strip()\n\n                try:\n                    (key, value) = line.split('=', 1)\n                    if key.strip() == 'log-dir':\n                        log_dir = value.strip()\n                except ValueError:\n                    pass\n\n        return log_dir"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef setup(self):\n        conf_file = self.get_option('conf_file')\n        log_dir = '/var/log/watchdog'\n\n        # Get service configuration and sysconfig files\n        self.add_copy_spec([\n            conf_file,\n            '/etc/sysconfig/watchdog',\n        ])\n\n        # Get custom executables\n        self.add_copy_spec([\n            '/etc/watchdog.d',\n            '/usr/libexec/watchdog/scripts',\n        ])\n\n        # Get logs\n        try:\n            res = self.get_log_dir(conf_file)\n            if res:\n                log_dir = res\n        except IOError as ex:\n            self._log_warn(\"Could not read %s: %s\" % (conf_file, ex))\n\n        if self.get_option('all_logs'):\n            log_files = glob(os.path.join(log_dir, '*'))\n        else:\n            log_files = (glob(os.path.join(log_dir, '*.stdout')) +\n                         glob(os.path.join(log_dir, '*.stderr')))\n\n        self.add_copy_spec(log_files)\n\n        # Get output of \"wdctl <device>\" for each /dev/watchdog*\n        for dev in glob('/dev/watchdog*'):\n            self.add_cmd_output(\"wdctl %s\" % dev)", "response": "Collect watchdog information.\n\n            Collect configuration files, custom executables for test-binary\n            and repair-binary, and stdout/stderr logs."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a dictionary for which key are volume names according to the output of gluster volume info stored in volume_file.", "response": "def get_volume_names(self, volume_file):\n        \"\"\"Return a dictionary for which key are volume names according to the\n        output of gluster volume info stored in volume_file.\n        \"\"\"\n        out = []\n        fp = open(volume_file, 'r')\n        for line in fp.readlines():\n            if not line.startswith(\"Volume Name:\"):\n                continue\n            volname = line[12:-1]\n            out.append(volname)\n        fp.close()\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dist_version(self):\n        try:\n            with open('/etc/lsb-release', 'r') as fp:\n                lines = fp.readlines()\n                for line in lines:\n                    if \"DISTRIB_RELEASE\" in line:\n                        return line.split(\"=\")[1].strip()\n            return False\n        except IOError:\n            return False", "response": "Returns the version stated in DISTRIB_RELEASE\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates leading paths for the source path.", "response": "def _make_leading_paths(self, src, mode=0o700):\n        \"\"\"Create leading path components\n\n            The standard python `os.makedirs` is insufficient for our\n            needs: it will only create directories, and ignores the fact\n            that some path components may be symbolic links.\n\n            :param src: The source path in the host file system for which\n                        leading components should be created, or the path\n                        to an sos_* virtual directory inside the archive.\n\n                        Host paths must be absolute (initial '/'), and\n                        sos_* directory paths must be a path relative to\n                        the root of the archive.\n\n            :param mode: An optional mode to be used when creating path\n                         components.\n            :returns: A rewritten destination path in the case that one\n                      or more symbolic links in intermediate components\n                      of the path have altered the path destination.\n        \"\"\"\n        self.log_debug(\"Making leading paths for %s\" % src)\n        root = self._archive_root\n        dest = src\n\n        def in_archive(path):\n            \"\"\"Test whether path ``path`` is inside the archive.\n            \"\"\"\n            return path.startswith(os.path.join(root, \"\"))\n\n        if not src.startswith(\"/\"):\n            # Sos archive path (sos_commands, sos_logs etc.)\n            src_dir = src\n        else:\n            # Host file path\n            src_dir = src if os.path.isdir(src) else os.path.split(src)[0]\n\n        # Build a list of path components in root-to-leaf order.\n        path = src_dir\n        path_comps = []\n        while path != '/' and path != '':\n            head, tail = os.path.split(path)\n            path_comps.append(tail)\n            path = head\n        path_comps.reverse()\n\n        abs_path = root\n        src_path = \"/\"\n\n        # Check and create components as needed\n        for comp in path_comps:\n            abs_path = os.path.join(abs_path, comp)\n\n            # Do not create components that are above the archive root.\n            if not in_archive(abs_path):\n                continue\n\n            src_path = os.path.join(src_path, comp)\n\n            if not os.path.exists(abs_path):\n                self.log_debug(\"Making path %s\" % abs_path)\n                if os.path.islink(src_path) and os.path.isdir(src_path):\n                    target = os.readlink(src_path)\n\n                    # The directory containing the source in the host fs,\n                    # adjusted for the current level of path creation.\n                    target_dir = os.path.split(src_path)[0]\n\n                    # The source path of the target in the host fs to be\n                    # recursively copied.\n                    target_src = os.path.join(target_dir, target)\n\n                    # Recursively create leading components of target\n                    dest = self._make_leading_paths(target_src, mode=mode)\n                    dest = os.path.normpath(dest)\n\n                    self.log_debug(\"Making symlink '%s' -> '%s'\" %\n                                   (abs_path, target))\n                    os.symlink(target, abs_path)\n                else:\n                    self.log_debug(\"Making directory %s\" % abs_path)\n                    os.mkdir(abs_path, mode)\n                    dest = src_path\n\n        return dest"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if a new path is needed for the archive.", "response": "def _check_path(self, src, path_type, dest=None, force=False):\n        \"\"\"Check a new destination path in the archive.\n\n            Since it is possible for multiple plugins to collect the same\n            paths, and since plugins can now run concurrently, it is possible\n            for two threads to race in archive methods: historically the\n            archive class only needed to test for the actual presence of a\n            path, since it was impossible for another `Archive` client to\n            enter the class while another method invocation was being\n            dispatched.\n\n            Deal with this by implementing a locking scheme for operations\n            that modify the path structure of the archive, and by testing\n            explicitly for conflicts with any existing content at the\n            specified destination path.\n\n            It is not an error to attempt to create a path that already\n            exists in the archive so long as the type of the object to be\n            added matches the type of object already found at the path.\n\n            It is an error to attempt to re-create an existing path with\n            a different path type (for example, creating a symbolic link\n            at a path already occupied by a regular file).\n\n            :param src: the source path to be copied to the archive\n            :param path_type: the type of object to be copied\n            :param dest: an optional destination path\n            :param force: force file creation even if the path exists\n            :returns: An absolute destination path if the path should be\n                      copied now or `None` otherwise\n        \"\"\"\n        dest = dest or self.dest_path(src)\n        if path_type == P_DIR:\n            dest_dir = dest\n        else:\n            dest_dir = os.path.split(dest)[0]\n        if not dest_dir:\n            return dest\n\n        # Check containing directory presence and path type\n        if os.path.exists(dest_dir) and not os.path.isdir(dest_dir):\n            raise ValueError(\"path '%s' exists and is not a directory\" %\n                             dest_dir)\n        elif not os.path.exists(dest_dir):\n            src_dir = src if path_type == P_DIR else os.path.split(src)[0]\n            self._make_leading_paths(src_dir)\n\n        def is_special(mode):\n            return any([\n                stat.S_ISBLK(mode),\n                stat.S_ISCHR(mode),\n                stat.S_ISFIFO(mode),\n                stat.S_ISSOCK(mode)\n            ])\n\n        if force:\n            return dest\n\n        # Check destination path presence and type\n        if os.path.exists(dest):\n            # Use lstat: we care about the current object, not the referent.\n            st = os.lstat(dest)\n            ve_msg = \"path '%s' exists and is not a %s\"\n            if path_type == P_FILE and not stat.S_ISREG(st.st_mode):\n                raise ValueError(ve_msg % (dest, \"regular file\"))\n            if path_type == P_LINK and not stat.S_ISLNK(st.st_mode):\n                raise ValueError(ve_msg % (dest, \"symbolic link\"))\n            if path_type == P_NODE and not is_special(st.st_mode):\n                raise ValueError(ve_msg % (dest, \"special file\"))\n            if path_type == P_DIR and not stat.S_ISDIR(st.st_mode):\n                raise ValueError(ve_msg % (dest, \"directory\"))\n            # Path has already been copied: skip\n            return None\n        return dest"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a directory at the given path.", "response": "def makedirs(self, path, mode=0o700):\n        \"\"\"Create path, including leading components.\n\n            Used by sos.sosreport to set up sos_* directories.\n        \"\"\"\n        os.makedirs(os.path.join(self._archive_root, path), mode=mode)\n        self.log_debug(\"created directory at '%s' in FileCacheArchive '%s'\"\n                       % (path, self._archive_root))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _encrypt(self, archive):\n        arc_name = archive.replace(\"sosreport-\", \"secured-sosreport-\")\n        arc_name += \".gpg\"\n        enc_cmd = \"gpg --batch -o %s \" % arc_name\n        env = None\n        if self.enc_opts[\"key\"]:\n            # need to assume a trusted key here to be able to encrypt the\n            # archive non-interactively\n            enc_cmd += \"--trust-model always -e -r %s \" % self.enc_opts[\"key\"]\n            enc_cmd += archive\n        if self.enc_opts[\"password\"]:\n            # prevent change of gpg options using a long password, but also\n            # prevent the addition of quote characters to the passphrase\n            passwd = \"%s\" % self.enc_opts[\"password\"].replace('\\'\"', '')\n            env = {\"sos_gpg\": passwd}\n            enc_cmd += \"-c --passphrase-fd 0 \"\n            enc_cmd = \"/bin/bash -c \\\"echo $sos_gpg | %s\\\"\" % enc_cmd\n            enc_cmd += archive\n        r = sos_get_command_output(enc_cmd, timeout=0, env=env)\n        if r[\"status\"] == 0:\n            return arc_name\n        elif r[\"status\"] == 2:\n            if self.enc_opts[\"key\"]:\n                msg = \"Specified key not in keyring\"\n            else:\n                msg = \"Could not read passphrase\"\n        else:\n            # TODO: report the actual error from gpg. Currently, we cannot as\n            # sos_get_command_output() does not capture stderr\n            msg = \"gpg exited with code %s\" % r[\"status\"]\n        raise Exception(msg)", "response": "Encrypts the archive using GPG and returns the name of the encrypted archive."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add(self, name, arcname=None, recursive=True,\n            exclude=None, filter=None):\n        \"\"\"Add the file `name' to the archive. `name' may be any type of file\n           (directory, fifo, symbolic link, etc.). If given, `arcname'\n           specifies an alternative name for the file in the archive.\n           Directories are added recursively by default. This can be avoided by\n           setting `recursive' to False. `exclude' is a function that should\n           return True for each filename to be excluded. `filter' is a function\n           that expects a TarInfo object argument and returns the changed\n           TarInfo object, if it returns None the TarInfo object will be\n           excluded from the archive.\n        \"\"\"\n        self._check(\"aw\")\n\n        if arcname is None:\n            arcname = name\n\n        # Exclude pathnames.\n        if exclude is not None:\n            import warnings\n            warnings.warn(\"use the filter argument instead\",\n                          DeprecationWarning, 2)\n            if exclude(name):\n                self._dbg(2, \"tarfile: Excluded %r\" % name)\n                return\n\n        # Skip if somebody tries to archive the archive...\n        if self.name is not None and os.path.abspath(name) == self.name:\n            self._dbg(2, \"tarfile: Skipped %r\" % name)\n            return\n\n        self._dbg(1, name)\n\n        # Create a TarInfo object from the file.\n        tarinfo = self.gettarinfo(name, arcname)\n\n        if tarinfo is None:\n            self._dbg(1, \"tarfile: Unsupported type %r\" % name)\n            return\n\n        # Change or exclude the TarInfo object.\n        if filter is not None:\n            tarinfo = filter(tarinfo)\n            if tarinfo is None:\n                self._dbg(2, \"tarfile: Excluded %r\" % name)\n                return\n\n        # Append the tar header and data to the archive.\n        if tarinfo.isreg():\n            with tarfile.bltn_open(name, \"rb\") as f:\n                self.addfile(tarinfo, f)\n\n        elif tarinfo.isdir():\n            self.addfile(tarinfo)\n            if recursive:\n                for f in os.listdir(name):\n                    self.add(os.path.join(name, f), os.path.join(arcname, f),\n                             recursive, exclude, filter)\n\n        else:\n            self.addfile(tarinfo)", "response": "Add a file to the archive."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef tail(filename, number_of_bytes):\n    with open(filename, \"rb\") as f:\n        if os.stat(filename).st_size > number_of_bytes:\n            f.seek(-number_of_bytes, 2)\n        return f.read()", "response": "Returns the last number_of_bytes of filename"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a file - like object that can be used as a context manager", "response": "def fileobj(path_or_file, mode='r'):\n    \"\"\"Returns a file-like object that can be used as a context manager\"\"\"\n    if isinstance(path_or_file, six.string_types):\n        try:\n            return open(path_or_file, mode)\n        except IOError:\n            log = logging.getLogger('sos')\n            log.debug(\"fileobj: %s could not be opened\" % path_or_file)\n            return closing(six.StringIO())\n    else:\n        return closing(path_or_file)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting a number of bytes to a shorter human friendly format", "response": "def convert_bytes(bytes_, K=1 << 10, M=1 << 20, G=1 << 30, T=1 << 40):\n    \"\"\"Converts a number of bytes to a shorter, more human friendly format\"\"\"\n    fn = float(bytes_)\n    if bytes_ >= T:\n        return '%.1fT' % (fn / T)\n    elif bytes_ >= G:\n        return '%.1fG' % (fn / G)\n    elif bytes_ >= M:\n        return '%.1fM' % (fn / M)\n    elif bytes_ >= K:\n        return '%.1fK' % (fn / K)\n    else:\n        return '%d' % bytes_"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find(file_pattern, top_dir, max_depth=None, path_pattern=None):\n    if max_depth:\n        base_depth = os.path.dirname(top_dir).count(os.path.sep)\n        max_depth += base_depth\n\n    for path, dirlist, filelist in os.walk(top_dir):\n        if max_depth and path.count(os.path.sep) >= max_depth:\n            del dirlist[:]\n\n        if path_pattern and not fnmatch.fnmatch(path, path_pattern):\n            continue\n\n        for name in fnmatch.filter(filelist, file_pattern):\n            yield os.path.join(path, name)", "response": "Generator function to find files recursively."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn lines matched in fnames where fnames can either be pathnames to Taxonomy files to grep through or open file objects to grep through line by line", "response": "def grep(pattern, *files_or_paths):\n    \"\"\"Returns lines matched in fnames, where fnames can either be pathnames to\n    files to grep through or open file objects to grep through line by line\"\"\"\n    matches = []\n\n    for fop in files_or_paths:\n        with fileobj(fop) as fo:\n            matches.extend((line for line in fo if re.match(pattern, line)))\n\n    return matches"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_executable(command):\n\n    paths = os.environ.get(\"PATH\", \"\").split(os.path.pathsep)\n    candidates = [command] + [os.path.join(p, command) for p in paths]\n    return any(os.access(path, os.X_OK) for path in candidates)", "response": "Returns True if a command matches an executable on the PATH"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sos_get_command_output(command, timeout=300, stderr=False,\n                           chroot=None, chdir=None, env=None,\n                           binary=False, sizelimit=None, poller=None):\n    \"\"\"Execute a command and return a dictionary of status and output,\n    optionally changing root or current working directory before\n    executing command.\n    \"\"\"\n    # Change root or cwd for child only. Exceptions in the prexec_fn\n    # closure are caught in the parent (chroot and chdir are bound from\n    # the enclosing scope).\n    def _child_prep_fn():\n        if (chroot):\n            os.chroot(chroot)\n        if (chdir):\n            os.chdir(chdir)\n\n    cmd_env = os.environ.copy()\n    # ensure consistent locale for collected command output\n    cmd_env['LC_ALL'] = 'C'\n    # optionally add an environment change for the command\n    if env:\n        for key, value in env.items():\n            if value:\n                cmd_env[key] = value\n            else:\n                cmd_env.pop(key, None)\n    # use /usr/bin/timeout to implement a timeout\n    if timeout and is_executable(\"timeout\"):\n        command = \"timeout %ds %s\" % (timeout, command)\n\n    # shlex.split() reacts badly to unicode on older python runtimes.\n    if not six.PY3:\n        command = command.encode('utf-8', 'ignore')\n    args = shlex.split(command)\n    # Expand arguments that are wildcard paths.\n    expanded_args = []\n    for arg in args:\n        expanded_arg = glob.glob(arg)\n        if expanded_arg:\n            expanded_args.extend(expanded_arg)\n        else:\n            expanded_args.append(arg)\n    try:\n        p = Popen(expanded_args, shell=False, stdout=PIPE,\n                  stderr=STDOUT if stderr else PIPE,\n                  bufsize=-1, env=cmd_env, close_fds=True,\n                  preexec_fn=_child_prep_fn)\n\n        reader = AsyncReader(p.stdout, sizelimit, binary)\n        if poller:\n            while reader.running:\n                if poller():\n                    p.terminate()\n                    raise SoSTimeoutError\n        stdout = reader.get_contents()\n        while p.poll() is None:\n            pass\n\n    except OSError as e:\n        if e.errno == errno.ENOENT:\n            return {'status': 127, 'output': \"\"}\n        else:\n            raise e\n\n    if p.returncode == 126 or p.returncode == 127:\n        stdout = six.binary_type(b\"\")\n\n    return {\n        'status': p.returncode,\n        'output': stdout\n    }", "response": "Execute a command and return a dictionary of status and output."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nimport the module module_fqname and returns a list of classes from that module.", "response": "def import_module(module_fqname, superclasses=None):\n    \"\"\"Imports the module module_fqname and returns a list of defined classes\n    from that module. If superclasses is defined then the classes returned will\n    be subclasses of the specified superclass or superclasses. If superclasses\n    is plural it must be a tuple of classes.\"\"\"\n    module_name = module_fqname.rpartition(\".\")[-1]\n    module = __import__(module_fqname, globals(), locals(), [module_name])\n    modules = [class_ for cname, class_ in\n               inspect.getmembers(module, inspect.isclass)\n               if class_.__module__ == module_fqname]\n    if superclasses:\n        modules = [m for m in modules if issubclass(m, superclasses)]\n\n    return modules"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef shell_out(cmd, timeout=30, chroot=None, runat=None):\n    return sos_get_command_output(cmd, timeout=timeout,\n                                  chroot=chroot, chdir=runat)['output']", "response": "Shell out to an external command and return the output or the empty\n    string in case of error."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef run(self):\n        '''Reads from the channel (pipe) that is the output pipe for a\n        called Popen. As we are reading from the pipe, the output is added\n        to a deque. After the size of the deque exceeds the sizelimit\n        earlier (older) entries are removed.\n\n        This means the returned output is chunksize-sensitive, but is not\n        really byte-sensitive.\n        '''\n        try:\n            while True:\n                line = self.chan.read(self.chunksize)\n                if not line:\n                    # Pipe can remain open after output has completed\n                    break\n                self.deque.append(line)\n        except (ValueError, IOError):\n            # pipe has closed, meaning command output is done\n            pass\n        self.running = False", "response": "Reads from the channel that is the output pipe that is the output pipe for a\n        called Popen."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_contents(self):\n        '''Returns the contents of the deque as a string'''\n        # block until command completes or timesout (separate from the plugin\n        # hitting a timeout)\n        while self.running:\n            pass\n        if not self.binary:\n            return ''.join(ln.decode('utf-8', 'ignore') for ln in self.deque)\n        else:\n            return b''.join(ln for ln in self.deque)", "response": "Returns the contents of the deque as a string"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the plugin module name given the path", "response": "def _plugin_name(self, path):\n        \"Returns the plugin module name given the path\"\n        base = os.path.basename(path)\n        name, ext = os.path.splitext(base)\n        return name"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_modules(self):\n        plugins = []\n        for path in self.package.__path__:\n            if os.path.isdir(path):\n                plugins.extend(self._find_plugins_in_dir(path))\n\n        return plugins", "response": "Returns the list of importable modules in the configured python\n        package."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef check_usrmove(self, pkgs):\n        if 'filesystem' not in pkgs:\n            return os.path.islink('/bin') and os.path.islink('/sbin')\n        else:\n            filesys_version = pkgs['filesystem']['version']\n            return True if filesys_version[0] == '3' else False", "response": "Test whether the running system implements UsrMove."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmangles the path of the files in the package managed files with the path of the user - specified binaries.", "response": "def mangle_package_path(self, files):\n        \"\"\"Mangle paths for post-UsrMove systems.\n\n            If the system implements UsrMove, all files will be in\n            '/usr/[s]bin'. This method substitutes all the /[s]bin\n            references in the 'files' list with '/usr/[s]bin'.\n\n            :param files: the list of package managed files\n        \"\"\"\n        paths = []\n\n        def transform_path(path):\n            # Some packages actually own paths in /bin: in this case,\n            # duplicate the path as both the / and /usr version.\n            skip_paths = [\"/bin/rpm\", \"/bin/mailx\"]\n            if path in skip_paths:\n                return (path, os.path.join(\"/usr\", path[1:]))\n            return (re.sub(r'(^)(/s?bin)', r'\\1/usr\\2', path),)\n\n        if self.usrmove:\n            for f in files:\n                paths.extend(transform_path(f))\n            return paths\n        else:\n            return files"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if sos is running in a container and perform container specific initialisation based on ENV_HOST_SYSROOT.", "response": "def _container_init(self):\n        \"\"\"Check if sos is running in a container and perform container\n        specific initialisation based on ENV_HOST_SYSROOT.\n        \"\"\"\n        if ENV_CONTAINER in os.environ:\n            if os.environ[ENV_CONTAINER] in ['docker', 'oci']:\n                self._in_container = True\n        if ENV_HOST_SYSROOT in os.environ:\n            self._host_sysroot = os.environ[ENV_HOST_SYSROOT]\n        use_sysroot = self._in_container and self._host_sysroot != '/'\n        if use_sysroot:\n            host_tmp_dir = os.path.abspath(self._host_sysroot + self._tmp_dir)\n            self._tmp_dir = host_tmp_dir\n        return self._host_sysroot if use_sysroot else None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef check(cls):\n        if not os.path.exists(OS_RELEASE):\n            return False\n\n        with open(OS_RELEASE, \"r\") as f:\n            for line in f:\n                if line.startswith(\"NAME\"):\n                    (name, value) = line.split(\"=\")\n                    value = value.strip(\"\\\"'\")\n                    if value.startswith(cls.distro):\n                        return True\n        return False", "response": "Test to see if the running host is a RHEL installation."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_params(self, name, param_list):\n        '''Use lctl get_param to collect a selection of parameters into a\n            file.\n\n        '''\n        self.add_cmd_output(\"lctl get_param %s\" % \" \".join(param_list),\n                            suggest_filename=\"params-%s\" % name,\n                            stderr=False)", "response": "Use lctl get_param to collect a selection of parameters into a\n            file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset up the data collection for the qpid dispatch router", "response": "def setup(self):\n        \"\"\" performs data collection for qpid dispatch router \"\"\"\n        options = \"\"\n        if self.get_option(\"port\"):\n            options = (options + \" -b \" + gethostname() +\n                       \":%s\" % (self.get_option(\"port\")))\n        # gethostname() is due to DISPATCH-156\n\n        # for either present option, add --option=value to 'options' variable\n        for option in [\"ssl-certificate\", \"ssl-key\", \"ssl-trustfile\"]:\n            if self.get_option(option):\n                options = (options + \" --%s=\" % (option) +\n                           self.get_option(option))\n\n        self.add_cmd_output([\n            \"qdstat -a\" + options,  # Show Router Addresses\n            \"qdstat -n\" + options,  # Show Router Nodes\n            \"qdstat -c\" + options,  # Show Connections\n            \"qdstat -m\" + options   # Show Broker Memory Stats\n        ])\n\n        self.add_copy_spec([\n            \"/etc/qpid-dispatch/qdrouterd.conf\"\n        ])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of all non overlapping matches in the string ( s )", "response": "def regex_findall(regex, fname):\n    '''Return a list of all non overlapping matches in the string(s)'''\n    try:\n        with fileobj(fname) as f:\n            return re.findall(regex, f.read(), re.MULTILINE)\n    except AttributeError:\n        return []"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a string indicating the type of special node represented by the stat buffer st", "response": "def _node_type(st):\n    \"\"\" return a string indicating the type of special node represented by\n    the stat buffer st (block, character, fifo, socket).\n    \"\"\"\n    _types = [\n        (stat.S_ISBLK, \"block device\"),\n        (stat.S_ISCHR, \"character device\"),\n        (stat.S_ISFIFO, \"named pipe\"),\n        (stat.S_ISSOCK, \"socket\")\n    ]\n    for t in _types:\n        if t[0](st.st_mode):\n            return t[1]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nimport name as a module and return a list of all classes defined in that module.", "response": "def import_plugin(name, superclasses=None):\n    \"\"\"Import name as a module and return a list of all classes defined in that\n    module. superclasses should be a tuple of valid superclasses to import,\n    this defaults to (Plugin,).\n    \"\"\"\n    plugin_fqname = \"sos.plugins.%s\" % name\n    if not superclasses:\n        superclasses = (Plugin,)\n    return import_module(plugin_fqname, superclasses)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a string representation of this SoSPredicate with optional prefix suffix and value quoting.", "response": "def __str(self, quote=False, prefix=\"\", suffix=\"\"):\n        \"\"\"Return a string representation of this SoSPredicate with\n            optional prefix, suffix and value quoting.\n        \"\"\"\n        quotes = '\"%s\"'\n        pstr = \"dry_run=%s, \" % self._dry_run\n\n        kmods = self._kmods\n        kmods = [quotes % k for k in kmods] if quote else kmods\n        pstr += \"kmods=[%s], \" % (\",\".join(kmods))\n\n        services = self._services\n        services = [quotes % s for s in services] if quote else services\n        pstr += \"services=[%s]\" % (\",\".join(services))\n\n        return prefix + pstr + suffix"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning either the default plugin timeout value the value as provided on the commandline via - k plugin. timeout = value or the value as of the global -- plugin - timeout option.", "response": "def timeout(self):\n        '''Returns either the default plugin timeout value, the value as\n        provided on the commandline via -k plugin.timeout=value, or the value\n        of the global --plugin-timeout option.\n        '''\n        _timeout = None\n        try:\n            opt_timeout = self.get_option('plugin_timeout')\n            own_timeout = int(self.get_option('timeout'))\n            if opt_timeout is None:\n                _timeout = own_timeout\n            elif opt_timeout is not None and own_timeout == -1:\n                _timeout = int(opt_timeout)\n            elif opt_timeout is not None and own_timeout > -1:\n                _timeout = own_timeout\n            else:\n                return None\n        except ValueError:\n            return self.plugin_timeout  # Default to known safe value\n        if _timeout is not None and _timeout > -1:\n            return _timeout\n        return self.plugin_timeout"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_predicate(self, cmd=False, pred=None):\n        if pred is not None:\n            return pred\n        if cmd and self.cmd_predicate is not None:\n            return self.cmd_predicate\n        return self.predicate", "response": "Get the current default plugin or command predicate."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nremoves certificate and key output archived by sosreport.", "response": "def do_cmd_private_sub(self, cmd):\n        '''Remove certificate and key output archived by sosreport. cmd\n        is the command name from which output is collected (i.e. exlcuding\n        parameters). Any matching instances are replaced with: '-----SCRUBBED'\n        and this function does not take a regexp or substituting string.\n\n        This function returns the number of replacements made.\n        '''\n        globstr = '*' + cmd + '*'\n        self._log_debug(\"Scrubbing certs and keys for commands matching %s\"\n                        % (cmd))\n\n        if not self.executed_commands:\n            return 0\n\n        replacements = None\n        try:\n            for called in self.executed_commands:\n                if called['file'] is None:\n                    continue\n                if called['binary'] == 'yes':\n                    self._log_warn(\"Cannot apply regex substitution to binary\"\n                                   \" output: '%s'\" % called['exe'])\n                    continue\n                if fnmatch.fnmatch(called['exe'], globstr):\n                    path = os.path.join(self.commons['cmddir'], called['file'])\n                    readable = self.archive.open_file(path)\n                    certmatch = re.compile(\"-----BEGIN.*?-----END\", re.DOTALL)\n                    result, replacements = certmatch.subn(\n                        \"-----SCRUBBED\", readable.read())\n                    if replacements:\n                        self.archive.add_string(result, path)\n        except Exception as e:\n            msg = \"Certificate/key scrubbing failed for '%s' with: '%s'\"\n            self._log_error(msg % (called['exe'], e))\n            replacements = None\n        return replacements"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef do_cmd_output_sub(self, cmd, regexp, subst):\n        '''Apply a regexp substitution to command output archived by sosreport.\n        cmd is the command name from which output is collected (i.e. excluding\n        parameters). The regexp can be a string or a compiled re object. The\n        substitution string, subst, is a string that replaces each occurrence\n        of regexp in each file collected from cmd. Internally 'cmd' is treated\n        as a glob with a leading and trailing '*' and each matching file from\n        the current module's command list is subjected to the replacement.\n\n        This function returns the number of replacements made.\n        '''\n        globstr = '*' + cmd + '*'\n        self._log_debug(\"substituting '%s' for '%s' in commands matching '%s'\"\n                        % (subst, regexp, globstr))\n\n        if not self.executed_commands:\n            return 0\n\n        replacements = None\n        try:\n            for called in self.executed_commands:\n                # was anything collected?\n                if called['file'] is None:\n                    continue\n                if called['binary'] == 'yes':\n                    self._log_warn(\"Cannot apply regex substitution to binary\"\n                                   \" output: '%s'\" % called['exe'])\n                    continue\n                if fnmatch.fnmatch(called['exe'], globstr):\n                    path = os.path.join(self.commons['cmddir'], called['file'])\n                    self._log_debug(\"applying substitution to '%s'\" % path)\n                    readable = self.archive.open_file(path)\n                    result, replacements = re.subn(\n                        regexp, subst, readable.read())\n                    if replacements:\n                        self.archive.add_string(result, path)\n\n        except Exception as e:\n            msg = \"regex substitution failed for '%s' with: '%s'\"\n            self._log_error(msg % (called['exe'], e))\n            replacements = None\n        return replacements", "response": "Apply a regexp substitution to command output archived by sosreport."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef do_file_sub(self, srcpath, regexp, subst):\n        '''Apply a regexp substitution to a file archived by sosreport.\n        srcpath is the path in the archive where the file can be found.  regexp\n        can be a regexp string or a compiled re object.  subst is a string to\n        replace each occurance of regexp in the content of srcpath.\n\n        This function returns the number of replacements made.\n        '''\n        try:\n            path = self._get_dest_for_srcpath(srcpath)\n            self._log_debug(\"substituting scrpath '%s'\" % srcpath)\n            self._log_debug(\"substituting '%s' for '%s' in '%s'\"\n                            % (subst, regexp, path))\n            if not path:\n                return 0\n            readable = self.archive.open_file(path)\n            content = readable.read()\n            if not isinstance(content, six.string_types):\n                content = content.decode('utf8', 'ignore')\n            result, replacements = re.subn(regexp, subst, content)\n            if replacements:\n                self.archive.add_string(result, srcpath)\n            else:\n                replacements = 0\n        except (OSError, IOError) as e:\n            # if trying to regexp a nonexisting file, dont log it as an\n            # error to stdout\n            if e.errno == errno.ENOENT:\n                msg = \"file '%s' not collected, substitution skipped\"\n                self._log_debug(msg % path)\n            else:\n                msg = \"regex substitution failed for '%s' with: '%s'\"\n                self._log_error(msg % (path, e))\n            replacements = 0\n        return replacements", "response": "Apply a regexp substitution to a file archived by sosreport."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef do_path_regex_sub(self, pathexp, regexp, subst):\n        '''Apply a regexp substituation to a set of files archived by\n        sos. The set of files to be substituted is generated by matching\n        collected file pathnames against pathexp which may be a regular\n        expression string or compiled re object. The portion of the file\n        to be replaced is specified via regexp and the replacement string\n        is passed in subst.'''\n        if not hasattr(pathexp, \"match\"):\n            pathexp = re.compile(pathexp)\n        match = pathexp.match\n        file_list = [f for f in self.copied_files if match(f['srcpath'])]\n        for file in file_list:\n            self.do_file_sub(file['srcpath'], regexp, subst)", "response": "Apply a regexp substituation to a set of files archived by\n        sos."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _do_copy_path(self, srcpath, dest=None):\n        '''Copy file or directory to the destination tree. If a directory, then\n        everything below it is recursively copied. A list of copied files are\n        saved for use later in preparing a report.\n        '''\n        if self._is_forbidden_path(srcpath):\n            self._log_debug(\"skipping forbidden path '%s'\" % srcpath)\n            return ''\n\n        if not dest:\n            dest = srcpath\n\n        if self.use_sysroot():\n            dest = self.strip_sysroot(dest)\n\n        try:\n            st = os.lstat(srcpath)\n        except (OSError, IOError):\n            self._log_info(\"failed to stat '%s'\" % srcpath)\n            return\n\n        if stat.S_ISLNK(st.st_mode):\n            self._copy_symlink(srcpath)\n            return\n        else:\n            if stat.S_ISDIR(st.st_mode) and os.access(srcpath, os.R_OK):\n                self._copy_dir(srcpath)\n                return\n\n        # handle special nodes (block, char, fifo, socket)\n        if not (stat.S_ISREG(st.st_mode) or stat.S_ISDIR(st.st_mode)):\n            ntype = _node_type(st)\n            self._log_debug(\"creating %s node at archive:'%s'\"\n                            % (ntype, dest))\n            self._copy_node(srcpath, st)\n            return\n\n        # if we get here, it's definitely a regular file (not a symlink or dir)\n        self._log_debug(\"copying path '%s' to archive:'%s'\" % (srcpath, dest))\n\n        # if not readable(srcpath)\n        if not st.st_mode & 0o444:\n            # FIXME: reflect permissions in archive\n            self.archive.add_string(\"\", dest)\n        else:\n            self.archive.add_file(srcpath, dest)\n\n        self.copied_files.append({\n            'srcpath': srcpath,\n            'dstpath': dest,\n            'symlink': \"no\"\n        })", "response": "Copy a file or directory to the destination tree. If a directory then it is recursively copied. If a file then it is recursively copied. If a directory then it is recursively copied. If a file then it is recursively copied."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a path or list of paths to not copy even if it s part of a copy_specs[] entry.", "response": "def add_forbidden_path(self, forbidden):\n        \"\"\"Specify a path, or list of paths, to not copy, even if it's\n            part of a copy_specs[] entry.\n        \"\"\"\n        if isinstance(forbidden, six.string_types):\n            forbidden = [forbidden]\n\n        if self.use_sysroot():\n            forbidden = [self.join_sysroot(f) for f in forbidden]\n\n        for forbid in forbidden:\n            self._log_info(\"adding forbidden path '%s'\" % forbid)\n            for path in glob.glob(forbid):\n                self.forbidden_paths.append(path)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the named option to value.", "response": "def set_option(self, optionname, value):\n        \"\"\"Set the named option to value. Ensure the original type\n           of the option value is preserved.\n        \"\"\"\n        for name, parms in zip(self.opt_names, self.opt_parms):\n            if name == optionname:\n                # FIXME: ensure that the resulting type of the set option\n                # matches that of the default value. This prevents a string\n                # option from being coerced to int simply because it holds\n                # a numeric value (e.g. a password).\n                # See PR #1526 and Issue #1597\n                defaulttype = type(parms['enabled'])\n                if defaulttype != type(value) and defaulttype != type(None):\n                    value = (defaulttype)(value)\n                parms['enabled'] = value\n                return True\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the first value that matches optionname in parameters or default if no value is found.", "response": "def get_option(self, optionname, default=0):\n        \"\"\"Returns the first value that matches 'optionname' in parameters\n        passed in via the command line or set via set_option or via the\n        global_plugin_options dictionary, in that order.\n\n        optionaname may be iterable, in which case the first option that\n        matches any of the option names is returned.\n        \"\"\"\n\n        global_options = ('verify', 'all_logs', 'log_size', 'plugin_timeout')\n\n        if optionname in global_options:\n            return getattr(self.commons['cmdlineopts'], optionname)\n\n        for name, parms in zip(self.opt_names, self.opt_parms):\n            if name == optionname:\n                val = parms['enabled']\n                if val is not None:\n                    return val\n\n        return default"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_option_as_list(self, optionname, delimiter=\",\", default=None):\n        '''Will try to return the option as a list separated by the\n        delimiter.\n        '''\n        option = self.get_option(optionname)\n        try:\n            opt_list = [opt.strip() for opt in option.split(delimiter)]\n            return list(filter(None, opt_list))\n        except Exception:\n            return default", "response": "Will try to return the option as a list separated by the\n        delimiter. The option name is the name of the option to return. If the option is not found in the configuration return default."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_copy_spec(self, copyspecs, sizelimit=None, tailit=True, pred=None):\n        if not self.test_predicate(pred=pred):\n            self._log_info(\"skipped copy spec '%s' due to predicate (%s)\" %\n                           (copyspecs, self.get_predicate(pred=pred)))\n            return\n\n        if sizelimit is None:\n            sizelimit = self.get_option(\"log_size\")\n\n        if self.get_option('all_logs'):\n            sizelimit = None\n\n        if sizelimit:\n            sizelimit *= 1024 * 1024  # in MB\n\n        if not copyspecs:\n            return False\n\n        if isinstance(copyspecs, six.string_types):\n            copyspecs = [copyspecs]\n\n        for copyspec in copyspecs:\n            if not (copyspec and len(copyspec)):\n                return False\n\n            if self.use_sysroot():\n                copyspec = self.join_sysroot(copyspec)\n\n            files = self._expand_copy_spec(copyspec)\n\n            if len(files) == 0:\n                continue\n\n            # Files hould be sorted in most-recently-modified order, so that\n            # we collect the newest data first before reaching the limit.\n            def getmtime(path):\n                try:\n                    return os.path.getmtime(path)\n                except OSError:\n                    return 0\n\n            files.sort(key=getmtime, reverse=True)\n            current_size = 0\n            limit_reached = False\n            _file = None\n\n            for _file in files:\n                if self._is_forbidden_path(_file):\n                    self._log_debug(\"skipping forbidden path '%s'\" % _file)\n                    continue\n                try:\n                    current_size += os.stat(_file)[stat.ST_SIZE]\n                except OSError:\n                    self._log_info(\"failed to stat '%s'\" % _file)\n                if sizelimit and current_size > sizelimit:\n                    limit_reached = True\n                    break\n                self._add_copy_paths([_file])\n\n            if limit_reached and tailit and not _file_is_compressed(_file):\n                file_name = _file\n\n                if file_name[0] == os.sep:\n                    file_name = file_name.lstrip(os.sep)\n                strfile = file_name.replace(os.path.sep, \".\") + \".tailed\"\n                self.add_string_as_file(tail(_file, sizelimit), strfile)\n                rel_path = os.path.relpath('/', os.path.dirname(_file))\n                link_path = os.path.join(rel_path, 'sos_strings',\n                                         self.name(), strfile)\n                self.archive.add_link(link_path, _file)", "response": "Add a file or glob but limit it to sizelimit megabytes."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef call_ext_prog(self, prog, timeout=300, stderr=True,\n                      chroot=True, runat=None):\n        \"\"\"Execute a command independantly of the output gathering part of\n        sosreport.\n        \"\"\"\n        return self.get_command_output(prog, timeout=timeout, stderr=stderr,\n                                       chroot=chroot, runat=runat)", "response": "Execute a command independantly of the output gathering part of\nLogFile sosreport."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_cmd_output(self, cmds, suggest_filename=None,\n                       root_symlink=None, timeout=300, stderr=True,\n                       chroot=True, runat=None, env=None, binary=False,\n                       sizelimit=None, pred=None):\n        \"\"\"Run a program or a list of programs and collect the output\"\"\"\n        if isinstance(cmds, six.string_types):\n            cmds = [cmds]\n        if len(cmds) > 1 and (suggest_filename or root_symlink):\n            self._log_warn(\"ambiguous filename or symlink for command list\")\n        if sizelimit is None:\n            sizelimit = self.get_option(\"log_size\")\n        for cmd in cmds:\n            self._add_cmd_output(cmd, suggest_filename=suggest_filename,\n                                 root_symlink=root_symlink, timeout=timeout,\n                                 stderr=stderr, chroot=chroot, runat=runat,\n                                 env=env, binary=binary, sizelimit=sizelimit,\n                                 pred=pred)", "response": "Run a program or a list of programs and collect the output"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a path into which this module should store collected command output", "response": "def get_cmd_output_path(self, name=None, make=True):\n        \"\"\"Return a path into which this module should store collected\n        command output\n        \"\"\"\n        cmd_output_path = os.path.join(self.archive.get_tmp_dir(),\n                                       'sos_commands', self.name())\n        if name:\n            cmd_output_path = os.path.join(cmd_output_path, name)\n        if make:\n            os.makedirs(cmd_output_path)\n\n        return cmd_output_path"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_string_as_file(self, content, filename, pred=None):\n\n        # Generate summary string for logging\n        summary = content.splitlines()[0] if content else ''\n        if not isinstance(summary, six.string_types):\n            summary = content.decode('utf8', 'ignore')\n\n        if not self.test_predicate(cmd=False, pred=pred):\n            self._log_info(\"skipped string ...'%s' due to predicate (%s)\" %\n                           (summary, self.get_predicate(pred=pred)))\n            return\n\n        self.copy_strings.append((content, filename))\n        self._log_debug(\"added string ...'%s' as '%s'\" % (summary, filename))", "response": "Add a string to the archive as a file named filename"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nexecuting a command and save the output to the archive file.", "response": "def _get_cmd_output_now(self, exe, suggest_filename=None,\n                            root_symlink=False, timeout=300, stderr=True,\n                            chroot=True, runat=None, env=None,\n                            binary=False, sizelimit=None):\n        \"\"\"Execute a command and save the output to a file for inclusion in the\n        report.\n        \"\"\"\n        start = time()\n\n        result = self.get_command_output(exe, timeout=timeout, stderr=stderr,\n                                         chroot=chroot, runat=runat,\n                                         env=env, binary=binary,\n                                         sizelimit=sizelimit)\n        self._log_debug(\"collected output of '%s' in %s\"\n                        % (exe.split()[0], time() - start))\n\n        if suggest_filename:\n            outfn = self._make_command_filename(suggest_filename)\n        else:\n            outfn = self._make_command_filename(exe)\n\n        outfn_strip = outfn[len(self.commons['cmddir'])+1:]\n        if binary:\n            self.archive.add_binary(result['output'], outfn)\n        else:\n            self.archive.add_string(result['output'], outfn)\n        if root_symlink:\n            self.archive.add_link(outfn, root_symlink)\n\n        # save info for later\n        self.executed_commands.append({'exe': exe, 'file': outfn_strip,\n                                       'binary': 'yes' if binary else 'no'})\n\n        return os.path.join(self.archive.get_archive_path(), outfn)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_cmd_output_now(self, exe, suggest_filename=None,\n                           root_symlink=False, timeout=300, stderr=True,\n                           chroot=True, runat=None, env=None,\n                           binary=False, sizelimit=None, pred=None):\n        \"\"\"Execute a command and save the output to a file for inclusion in the\n        report.\n        \"\"\"\n        if not self.test_predicate(cmd=True, pred=pred):\n            self._log_info(\"skipped cmd output '%s' due to predicate (%s)\" %\n                           (exe, self.get_predicate(cmd=True, pred=pred)))\n            return None\n\n        return self._get_cmd_output_now(exe, timeout=timeout, stderr=stderr,\n                                        chroot=chroot, runat=runat,\n                                        env=env, binary=binary,\n                                        sizelimit=sizelimit)", "response": "Execute a command and save the output to a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_journal(self, units=None, boot=None, since=None, until=None,\n                    lines=None, allfields=False, output=None, timeout=None,\n                    identifier=None, catalog=None, sizelimit=None, pred=None):\n        \"\"\"Collect journald logs from one of more units.\n\n        :param units: A string, or list of strings specifying the\n                       systemd units for which journal entries will be\n                       collected.\n\n        :param boot: A string selecting a boot index using the\n                      journalctl syntax. The special values 'this' and\n                      'last' are also accepted.\n\n        :param since: A string representation of the start time for\n                       journal messages.\n\n        :param until: A string representation of the end time for\n                       journal messages.\n\n        :param lines: The maximum number of lines to be collected.\n\n        :param allfields: A bool. Include all journal fields\n                           regardless of size or non-printable\n                           characters.\n\n        :param output: A journalctl output control string, for\n                        example \"verbose\".\n\n        :param timeout: An optional timeout in seconds.\n        :param identifier: An optional message identifier.\n        :param catalog: Bool. If True, augment lines with descriptions\n                        from the system catalog.\n        :param sizelimit: Limit to the size of output returned in MB.\n                          Defaults to the value of --log-size.\n        \"\"\"\n        journal_cmd = \"journalctl --no-pager \"\n        unit_opt = \" --unit %s\"\n        boot_opt = \" --boot %s\"\n        since_opt = \" --since %s\"\n        until_opt = \" --until %s\"\n        lines_opt = \" --lines %s\"\n        output_opt = \" --output %s\"\n        identifier_opt = \" --identifier %s\"\n        catalog_opt = \" --catalog\"\n\n        journal_size = 100\n        all_logs = self.get_option(\"all_logs\")\n        log_size = sizelimit or self.get_option(\"log_size\")\n        log_size = max(log_size, journal_size) if not all_logs else 0\n\n        if isinstance(units, six.string_types):\n            units = [units]\n\n        if units:\n            for unit in units:\n                journal_cmd += unit_opt % unit\n\n        if identifier:\n            journal_cmd += identifier_opt % identifier\n\n        if catalog:\n            journal_cmd += catalog_opt\n\n        if allfields:\n            journal_cmd += \" --all\"\n\n        if boot:\n            if boot == \"this\":\n                boot = \"\"\n            if boot == \"last\":\n                boot = \"-1\"\n            journal_cmd += boot_opt % boot\n\n        if since:\n            journal_cmd += since_opt % since\n\n        if until:\n            journal_cmd += until_opt % until\n\n        if lines:\n            journal_cmd += lines_opt % lines\n\n        if output:\n            journal_cmd += output_opt % output\n\n        self._log_debug(\"collecting journal: %s\" % journal_cmd)\n        self._add_cmd_output(journal_cmd, timeout=timeout,\n                             sizelimit=log_size, pred=pred)", "response": "Add a journal to a systemd system."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_udev_info(self, device, attrs=False):\n        udev_cmd = 'udevadm info'\n        if attrs:\n            udev_cmd += ' -a'\n\n        if isinstance(device, six.string_types):\n            device = [device]\n\n        for dev in device:\n            self._log_debug(\"collecting udev info for: %s\" % dev)\n            self._add_cmd_output('%s %s' % (udev_cmd, dev))", "response": "Collect udevadm info output for a given device."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef collect(self):\n        start = time()\n        self._collect_copy_specs()\n        self._collect_cmd_output()\n        self._collect_strings()\n        fields = (self.name(), time() - start)\n        self._log_debug(\"collected plugin '%s' in %s\" % fields)", "response": "Collect the data for a plugin."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_description(self):\n        try:\n            if hasattr(self, '__doc__') and self.__doc__:\n                return self.__doc__.strip()\n            return super(self.__class__, self).__doc__.strip()\n        except Exception:\n            return \"<no description available>\"", "response": "This function will return the description for the plugin"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check_enabled(self):\n        # some files or packages have been specified for this package\n        if any([self.files, self.packages, self.commands, self.kernel_mods,\n                self.services]):\n            if isinstance(self.files, six.string_types):\n                self.files = [self.files]\n\n            if isinstance(self.packages, six.string_types):\n                self.packages = [self.packages]\n\n            if isinstance(self.commands, six.string_types):\n                self.commands = [self.commands]\n\n            if isinstance(self.kernel_mods, six.string_types):\n                self.kernel_mods = [self.kernel_mods]\n\n            if isinstance(self.services, six.string_types):\n                self.services = [self.services]\n\n            if isinstance(self, SCLPlugin):\n                # save SCLs that match files or packages\n                type(self)._scls_matched = []\n                for scl in self._get_scls():\n                    files = [f % {\"scl_name\": scl} for f in self.files]\n                    packages = [p % {\"scl_name\": scl} for p in self.packages]\n                    commands = [c % {\"scl_name\": scl} for c in self.commands]\n                    services = [s % {\"scl_name\": scl} for s in self.services]\n                    if self._check_plugin_triggers(files,\n                                                   packages,\n                                                   commands,\n                                                   services):\n                        type(self)._scls_matched.append(scl)\n                return len(type(self)._scls_matched) > 0\n\n            return self._check_plugin_triggers(self.files,\n                                               self.packages,\n                                               self.commands,\n                                               self.services)\n\n        if isinstance(self, SCLPlugin):\n            # if files and packages weren't specified, we take all SCLs\n            type(self)._scls_matched = self._get_scls()\n\n        return True", "response": "This method will be used to verify that a plugin is enabled for this package."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the HTML file that contains all information that was gathered in an html file that allows browsing the results.", "response": "def report(self):\n        \"\"\" Present all information that was gathered in an html file that\n        allows browsing the results.\n        \"\"\"\n        # make this prettier\n        html = u'<hr/><a name=\"%s\"></a>\\n' % self.name()\n\n        # Intro\n        html = html + \"<h2> Plugin <em>\" + self.name() + \"</em></h2>\\n\"\n\n        # Files\n        if len(self.copied_files):\n            html = html + \"<p>Files copied:<br><ul>\\n\"\n            for afile in self.copied_files:\n                html = html + '<li><a href=\"%s\">%s</a>' % \\\n                    (u'..' + _to_u(afile['dstpath']), _to_u(afile['srcpath']))\n                if afile['symlink'] == \"yes\":\n                    html = html + \" (symlink to %s)\" % _to_u(afile['pointsto'])\n                html = html + '</li>\\n'\n            html = html + \"</ul></p>\\n\"\n\n        # Command Output\n        if len(self.executed_commands):\n            html = html + \"<p>Commands Executed:<br><ul>\\n\"\n            # convert file name to relative path from our root\n            # don't use relpath - these are HTML paths not OS paths.\n            for cmd in self.executed_commands:\n                if cmd[\"file\"] and len(cmd[\"file\"]):\n                    cmd_rel_path = u\"../\" + _to_u(self.commons['cmddir']) \\\n                        + \"/\" + _to_u(cmd['file'])\n                    html = html + '<li><a href=\"%s\">%s</a></li>\\n' % \\\n                        (cmd_rel_path, _to_u(cmd['exe']))\n                else:\n                    html = html + '<li>%s</li>\\n' % (_to_u(cmd['exe']))\n            html = html + \"</ul></p>\\n\"\n\n        # Alerts\n        if len(self.alerts):\n            html = html + \"<p>Alerts:<br><ul>\\n\"\n            for alert in self.alerts:\n                html = html + '<li>%s</li>\\n' % _to_u(alert)\n            html = html + \"</ul></p>\\n\"\n\n        # Custom Text\n        if self.custom_text != \"\":\n            html = html + \"<p>Additional Information:<br>\\n\"\n            html = html + _to_u(self.custom_text) + \"</p>\\n\"\n\n        if six.PY2:\n            return html.encode('utf8')\n        else:\n            return html"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if a named process is found in the command line. Returns either True or False.", "response": "def check_process_by_name(self, process):\n        \"\"\"Checks if a named process is found in /proc/[0-9]*/cmdline.\n        Returns either True or False.\"\"\"\n        status = False\n        cmd_line_glob = \"/proc/[0-9]*/cmdline\"\n        try:\n            cmd_line_paths = glob.glob(cmd_line_glob)\n            for path in cmd_line_paths:\n                f = open(path, 'r')\n                cmd_line = f.read().strip()\n                if process in cmd_line:\n                    status = True\n        except IOError as e:\n            return False\n        return status"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_process_pids(self, process):\n        pids = []\n        cmd_line_glob = \"/proc/[0-9]*/cmdline\"\n        cmd_line_paths = glob.glob(cmd_line_glob)\n        for path in cmd_line_paths:\n            try:\n                with open(path, 'r') as f:\n                    cmd_line = f.read().strip()\n                    if process in cmd_line:\n                        pids.append(path.split(\"/\")[2])\n            except IOError as e:\n                continue\n        return pids", "response": "Returns a list of all processes with the given process name. Returns an empty list if the process doesn t exist returns an empty list"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef convert_cmd_scl(self, scl, cmd):\n        # load default SCL prefix to PATH\n        prefix = self.policy.get_default_scl_prefix()\n        # read prefix from /etc/scl/prefixes/${scl} and strip trailing '\\n'\n        try:\n            prefix = open('/etc/scl/prefixes/%s' % scl, 'r').read()\\\n                     .rstrip('\\n')\n        except Exception as e:\n            self._log_error(\"Failed to find prefix for SCL %s, using %s\"\n                            % (scl, prefix))\n\n        # expand PATH by equivalent prefixes under the SCL tree\n        path = os.environ[\"PATH\"]\n        for p in path.split(':'):\n            path = '%s/%s%s:%s' % (prefix, scl, p, path)\n\n        scl_cmd = \"scl enable %s \\\"PATH=%s %s\\\"\" % (scl, path, cmd)\n        return scl_cmd", "response": "wrapping command in scl enable call and adds proper PATH\n       "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_copy_spec_scl(self, scl, copyspecs):\n        if isinstance(copyspecs, six.string_types):\n            copyspecs = [copyspecs]\n        scl_copyspecs = []\n        for copyspec in copyspecs:\n            scl_copyspecs.append(self.convert_copyspec_scl(scl, copyspec))\n        self.add_copy_spec(scl_copyspecs)", "response": "Same as add_copy_spec except that it prepends path to SCL root\n        to copyspecs."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_copy_spec_limit_scl(self, scl, copyspec, **kwargs):\n        self.add_copy_spec_limit(\n            self.convert_copyspec_scl(scl, copyspec),\n            **kwargs\n        )", "response": "Same as add_copy_spec_limit except that it prepends path to copyspec."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ninterfacing with vrtsexplorer to capture veritas related data", "response": "def setup(self):\n        \"\"\" interface with vrtsexplorer to capture veritas related data \"\"\"\n        r = self.call_ext_prog(self.get_option(\"script\"))\n        if r['status'] == 0:\n            tarfile = \"\"\n            for line in r['output']:\n                line = line.strip()\n                tarfile = self.do_regex_find_all(r\"ftp (.*tar.gz)\", line)\n            if len(tarfile) == 1:\n                self.add_copy_spec(tarfile[0])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove sensitive keys and passwords from YAML files.", "response": "def postproc(self):\n        \"\"\"Remove sensitive keys and passwords from YAML files.\"\"\"\n        secrets_files = [\n            \"/etc/openstack_deploy/user_secrets.yml\",\n            \"/etc/rpc_deploy/user_secrets.yml\"\n        ]\n        regexp = r\"(?m)^\\s*#*([\\w_]*:\\s*).*\"\n        for secrets_file in secrets_files:\n            self.do_path_regex_sub(\n                secrets_file,\n                regexp,\n                r\"\\1*********\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef iter_source_code(paths: Iterable[str], config: MutableMapping[str, Any], skipped: List[str]) -> Iterator[str]:\n    if 'not_skip' in config:\n        config['skip'] = list(set(config['skip']).difference(config['not_skip']))\n\n    for path in paths:\n        if os.path.isdir(path):\n            for dirpath, dirnames, filenames in os.walk(path, topdown=True, followlinks=True):\n                for dirname in list(dirnames):\n                    if file_should_be_skipped(dirname, config, dirpath):\n                        skipped.append(dirname)\n                        dirnames.remove(dirname)\n                for filename in filenames:\n                    filepath = os.path.join(dirpath, filename)\n                    if is_python_file(filepath):\n                        relative_file = os.path.relpath(filepath, path)\n                        if file_should_be_skipped(relative_file, config, path):\n                            skipped.append(filename)\n                        else:\n                            yield filepath\n        else:\n            yield path", "response": "Iterate over all Python source files defined in paths."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef finalize_options(self) -> None:\n        \"Get options from config files.\"\n        self.arguments = {}  # type: Dict[str, Any]\n        computed_settings = from_path(os.getcwd())\n        for key, value in computed_settings.items():\n            self.arguments[key] = value", "response": "Get options from config files."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef file_should_be_skipped(\n    filename: str,\n    config: Mapping[str, Any],\n    path: str = ''\n) -> bool:\n    \"\"\"Returns True if the file and/or folder should be skipped based on the passed in settings.\"\"\"\n    os_path = os.path.join(path, filename)\n\n    normalized_path = os_path.replace('\\\\', '/')\n    if normalized_path[1:2] == ':':\n        normalized_path = normalized_path[2:]\n\n    if path and config['safety_excludes']:\n        check_exclude = '/' + filename.replace('\\\\', '/') + '/'\n        if path and os.path.basename(path) in ('lib', ):\n            check_exclude = '/' + os.path.basename(path) + check_exclude\n        if safety_exclude_re.search(check_exclude):\n            return True\n\n    for skip_path in config['skip']:\n        if posixpath.abspath(normalized_path) == posixpath.abspath(skip_path.replace('\\\\', '/')):\n            return True\n\n    position = os.path.split(filename)\n    while position[1]:\n        if position[1] in config['skip']:\n            return True\n        position = os.path.split(position[0])\n\n    for glob in config['skip_glob']:\n        if fnmatch.fnmatch(filename, glob) or fnmatch.fnmatch('/' + filename, glob):\n            return True\n\n    if not (os.path.isfile(os_path) or os.path.isdir(os_path) or os.path.islink(os_path)):\n        return True\n\n    return False", "response": "Returns True if the file and folder should be skipped based on the passed in settings."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef union(a: Iterable[Any], b: Iterable[Any]) -> List[Any]:\n    u = []  # type: List[Any]\n    for item in a:\n        if item not in u:\n            u.append(item)\n    for item in b:\n        if item not in u:\n            u.append(item)\n    return u", "response": "Return a list of items that are in a or b."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of items from a that are not in b.", "response": "def difference(a: Iterable[Any], b: Container[Any]) -> List[Any]:\n    \"\"\" Return a list of items from `a` that are not in `b`.\n    \"\"\"\n    d = []\n    for item in a:\n        if item not in b:\n            d.append(item)\n    return d"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef sort_kate_imports(add_imports=(), remove_imports=()):\n    document = kate.activeDocument()\n    view = document.activeView()\n    position = view.cursorPosition()\n    selection = view.selectionRange()\n    sorter = SortImports(file_contents=document.text(), add_imports=add_imports, remove_imports=remove_imports,\n                         settings_path=os.path.dirname(os.path.abspath(str(document.url().path()))))\n    document.setText(sorter.output)\n    position.setLine(position.line() + sorter.length_change)\n    if selection:\n        start = selection.start()\n        start.setLine(start.line() + sorter.length_change)\n        end = selection.end()\n        end.setLine(end.line() + sorter.length_change)\n        selection.setRange(start, end)\n        view.setSelection(selection)\n    view.setCursorPosition(position)", "response": "Sorts imports within Kate while maintaining cursor position and selection even if length of file changes."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlints the file. Return an array of error dicts if appropriate.", "response": "def run(self, path: str, **meta: Any) -> List[Dict[str, Any]]:\n        \"\"\"Lint the file. Return an array of error dicts if appropriate.\"\"\"\n        with open(os.devnull, 'w') as devnull:\n            # Suppress isort messages\n            sys.stdout = devnull\n\n            if SortImports(path, check=True).incorrectly_sorted:\n                return [{\n                    'lnum': 0,\n                    'col': 0,\n                    'text': 'Incorrectly sorted imports.',\n                    'type': 'ISORT'\n                }]\n            else:\n                return []"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nstripping comments that exist at the top of the given lines.", "response": "def _strip_top_comments(lines: Sequence[str], line_separator: str) -> str:\n        \"\"\"Strips # comments that exist at the top of the given lines\"\"\"\n        lines = copy.copy(lines)\n        while lines and lines[0].startswith(\"#\"):\n            lines = lines[1:]\n        return line_separator.join(lines)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntry to place a module in the cache if it can t find it", "response": "def place_module(self, module_name: str) -> Optional[str]:\n        \"\"\"Tries to determine if a module is a python std import, third party import, or project code:\n\n        if it can't determine - it assumes it is project code\n\n        \"\"\"\n        return self.finder.find(module_name)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the current line from the file while incrementing the index.", "response": "def _get_line(self) -> str:\n        \"\"\"Returns the current line from the file while incrementing the index.\"\"\"\n        line = self.in_lines[self.index]\n        self.index += 1\n        return line"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _import_type(line: str) -> Optional[str]:\n        if \"isort:skip\" in line or \"NOQA\" in line:\n            return None\n        elif line.startswith('import '):\n            return \"straight\"\n        elif line.startswith('from '):\n            return \"from\"", "response": "Returns the type of the current line if it is an import line or straight if it is a straight import line."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding comments to the original string if comments is not set.", "response": "def _add_comments(\n        self,\n        comments: Optional[Sequence[str]],\n        original_string: str = \"\"\n    ) -> str:\n        \"\"\"\n            Returns a string with comments added if ignore_comments is not set.\n        \"\"\"\n        if self.config['ignore_comments']:\n            return self._strip_comments(original_string)[0]\n\n        if not comments:\n            return original_string\n        else:\n            return \"{0}{1} {2}\".format(self._strip_comments(original_string)[0],\n                                       self.config['comment_prefix'],\n                                       \"; \".join(comments))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwrapping a line of text into a single line if possible.", "response": "def _wrap(self, line: str) -> str:\n        \"\"\"\n            Returns an import wrapped to the specified line-length, if possible.\n        \"\"\"\n        wrap_mode = self.config['multi_line_output']\n        if len(line) > self.config['line_length'] and wrap_mode != WrapModes.NOQA:\n            line_without_comment = line\n            comment = None\n            if '#' in line:\n                line_without_comment, comment = line.split('#', 1)\n            for splitter in (\"import \", \".\", \"as \"):\n                exp = r\"\\b\" + re.escape(splitter) + r\"\\b\"\n                if re.search(exp, line_without_comment) and not line_without_comment.strip().startswith(splitter):\n                    line_parts = re.split(exp, line_without_comment)\n                    if comment:\n                        line_parts[-1] = '{0}#{1}'.format(line_parts[-1], comment)\n                    next_line = []\n                    while (len(line) + 2) > (self.config['wrap_length'] or self.config['line_length']) and line_parts:\n                        next_line.append(line_parts.pop())\n                        line = splitter.join(line_parts)\n                    if not line:\n                        line = next_line.pop()\n\n                    cont_line = self._wrap(self.config['indent'] + splitter.join(next_line).lstrip())\n                    if self.config['use_parentheses']:\n                        output = \"{0}{1}({2}{3}{4}{5})\".format(\n                            line, splitter, self.line_separator, cont_line,\n                            \",\" if self.config['include_trailing_comma'] else \"\",\n                            self.line_separator if wrap_mode in {WrapModes.VERTICAL_HANGING_INDENT,\n                                                                 WrapModes.VERTICAL_GRID_GROUPED}\n                            else \"\")\n                        lines = output.split(self.line_separator)\n                        if self.config['comment_prefix'] in lines[-1] and lines[-1].endswith(')'):\n                            line, comment = lines[-1].split(self.config['comment_prefix'], 1)\n                            lines[-1] = line + ')' + self.config['comment_prefix'] + comment[:-1]\n                        return self.line_separator.join(lines)\n                    return \"{0}{1}\\\\{2}{3}\".format(line, splitter, self.line_separator, cont_line)\n        elif len(line) > self.config['line_length'] and wrap_mode == settings.WrapModes.NOQA:\n            if \"# NOQA\" not in line:\n                return \"{0}{1} NOQA\".format(line, self.config['comment_prefix'])\n\n        return line"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd the imports back to the file.", "response": "def _add_formatted_imports(self) -> None:\n        \"\"\"Adds the imports back to the file.\n\n        (at the index of the first import) sorted alphabetically and split between groups\n\n        \"\"\"\n        sort_ignore_case = self.config['force_alphabetical_sort_within_sections']\n        sections = itertools.chain(self.sections, self.config['forced_separate'])  # type: Iterable[str]\n\n        if self.config['no_sections']:\n            self.imports['no_sections'] = {'straight': [], 'from': {}}\n            for section in sections:\n                self.imports['no_sections']['straight'].extend(self.imports[section].get('straight', []))\n                self.imports['no_sections']['from'].update(self.imports[section].get('from', {}))\n            sections = ('no_sections', )\n\n        output = []  # type: List[str]\n        pending_lines_before = False\n        for section in sections:\n            straight_modules = self.imports[section]['straight']\n            straight_modules = nsorted(straight_modules, key=lambda key: self._module_key(key, self.config, section_name=section))\n            from_modules = self.imports[section]['from']\n            from_modules = nsorted(from_modules, key=lambda key: self._module_key(key, self.config, section_name=section))\n\n            section_output = []  # type: List[str]\n            if self.config['from_first']:\n                self._add_from_imports(from_modules, section, section_output, sort_ignore_case)\n                if self.config['lines_between_types'] and from_modules and straight_modules:\n                    section_output.extend([''] * self.config['lines_between_types'])\n                self._add_straight_imports(straight_modules, section, section_output)\n            else:\n                self._add_straight_imports(straight_modules, section, section_output)\n                if self.config['lines_between_types'] and from_modules and straight_modules:\n                    section_output.extend([''] * self.config['lines_between_types'])\n                self._add_from_imports(from_modules, section, section_output, sort_ignore_case)\n\n            if self.config['force_sort_within_sections']:\n                def by_module(line: str) -> str:\n                    section = 'B'\n                    if line.startswith('#'):\n                        return 'AA'\n\n                    line = re.sub('^from ', '', line)\n                    line = re.sub('^import ', '', line)\n                    if line.split(' ')[0] in self.config['force_to_top']:\n                        section = 'A'\n                    if not self.config['order_by_type']:\n                        line = line.lower()\n                    return '{0}{1}'.format(section, line)\n                section_output = nsorted(section_output, key=by_module)\n\n            section_name = section\n            no_lines_before = section_name in self.config['no_lines_before']\n\n            if section_output:\n                if section_name in self.place_imports:\n                    self.place_imports[section_name] = section_output\n                    continue\n\n                section_title = self.config.get('import_heading_' + str(section_name).lower(), '')\n                if section_title:\n                    section_comment = \"# {0}\".format(section_title)\n                    if section_comment not in self.out_lines[0:1] and section_comment not in self.in_lines[0:1]:\n                        section_output.insert(0, section_comment)\n\n                if pending_lines_before or not no_lines_before:\n                    output += ([''] * self.config['lines_between_sections'])\n\n                output += section_output\n\n                pending_lines_before = False\n            else:\n                pending_lines_before = pending_lines_before or not no_lines_before\n\n        while output and output[-1].strip() == '':\n            output.pop()\n        while output and output[0].strip() == '':\n            output.pop(0)\n\n        output_at = 0\n        if self.import_index < self.original_num_of_lines:\n            output_at = self.import_index\n        elif self._first_comment_index_end != -1 and self._first_comment_index_start <= 2:\n            output_at = self._first_comment_index_end\n        self.out_lines[output_at:0] = output\n\n        imports_tail = output_at + len(output)\n        while [character.strip() for character in self.out_lines[imports_tail: imports_tail + 1]] == [\"\"]:\n            self.out_lines.pop(imports_tail)\n\n        if len(self.out_lines) > imports_tail:\n            next_construct = \"\"\n            self._in_quote = False  # type: Any\n            tail = self.out_lines[imports_tail:]\n\n            for index, line in enumerate(tail):\n                in_quote = self._in_quote\n                if not self._skip_line(line) and line.strip():\n                    if line.strip().startswith(\"#\") and len(tail) > (index + 1) and tail[index + 1].strip():\n                        continue\n                    next_construct = line\n                    break\n                elif not in_quote:\n                    parts = line.split()\n                    if len(parts) >= 3 and parts[1] == '=' and \"'\" not in parts[0] and '\"' not in parts[0]:\n                        next_construct = line\n                        break\n\n            if self.config['lines_after_imports'] != -1:\n                self.out_lines[imports_tail:0] = [\"\" for line in range(self.config['lines_after_imports'])]\n            elif next_construct.startswith(\"def \") or next_construct.startswith(\"class \") or \\\n               next_construct.startswith(\"@\") or next_construct.startswith(\"async def\"):\n                self.out_lines[imports_tail:0] = [\"\", \"\"]\n            else:\n                self.out_lines[imports_tail:0] = [\"\"]\n\n        if self.place_imports:\n            new_out_lines = []\n            for index, line in enumerate(self.out_lines):\n                new_out_lines.append(line)\n                if line in self.import_placements:\n                    new_out_lines.extend(self.place_imports[self.import_placements[line]])\n                    if len(self.out_lines) <= index or self.out_lines[index + 1].strip() != \"\":\n                        new_out_lines.append(\"\")\n            self.out_lines = new_out_lines"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove comments from import line.", "response": "def _strip_comments(\n        line: str,\n        comments: Optional[List[str]] = None\n    ) -> Tuple[str, List[str], bool]:\n        \"\"\"Removes comments from import line.\"\"\"\n        if comments is None:\n            comments = []\n\n        new_comments = False\n        comment_start = line.find(\"#\")\n        if comment_start != -1:\n            comments.append(line[comment_start + 1:].strip())\n            new_comments = True\n            line = line[:comment_start]\n\n        return line, comments, new_comments"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _parse(self) -> None:\n        self._in_quote = False\n        self._in_top_comment = False\n        while not self._at_end():\n            raw_line = line = self._get_line()\n            line = line.replace(\"from.import \", \"from . import \")\n            line = line.replace(\"\\t\", \" \").replace('import*', 'import *')\n            line = line.replace(\" .import \", \" . import \")\n            statement_index = self.index\n            skip_line = self._skip_line(line)\n\n            if line in self._section_comments and not skip_line:\n                if self.import_index == -1:\n                    self.import_index = self.index - 1\n                continue\n\n            if \"isort:imports-\" in line and line.startswith(\"#\"):\n                section = line.split(\"isort:imports-\")[-1].split()[0].upper()\n                self.place_imports[section] = []\n                self.import_placements[line] = section\n\n            if \";\" in line:\n                for part in (part.strip() for part in line.split(\";\")):\n                    if part and not part.startswith(\"from \") and not part.startswith(\"import \"):\n                        skip_line = True\n\n            import_type = self._import_type(line)\n            if not import_type or skip_line:\n                self.out_lines.append(raw_line)\n                continue\n\n            for line in (line.strip() for line in line.split(\";\")):\n                import_type = self._import_type(line)\n                if not import_type:\n                    self.out_lines.append(line)\n                    continue\n\n                if self.import_index == -1:\n                    self.import_index = self.index - 1\n                nested_comments = {}\n                import_string, comments, new_comments = self._strip_comments(line)\n                line_parts = [part for part in self._strip_syntax(import_string).strip().split(\" \") if part]\n                if import_type == \"from\" and len(line_parts) == 2 and line_parts[1] != \"*\" and new_comments:\n                    nested_comments[line_parts[-1]] = comments[0]\n\n                if \"(\" in line.split(\"#\")[0] and not self._at_end():\n                    while not line.strip().endswith(\")\") and not self._at_end():\n                        line, comments, new_comments = self._strip_comments(self._get_line(), comments)\n                        stripped_line = self._strip_syntax(line).strip()\n                        if import_type == \"from\" and stripped_line and \" \" not in stripped_line and new_comments:\n                            nested_comments[stripped_line] = comments[-1]\n                        import_string += self.line_separator + line\n                else:\n                    while line.strip().endswith(\"\\\\\"):\n                        line, comments, new_comments = self._strip_comments(self._get_line(), comments)\n\n                        # Still need to check for parentheses after an escaped line\n                        if \"(\" in line.split(\"#\")[0] and \")\" not in line.split(\"#\")[0] and not self._at_end():\n                            stripped_line = self._strip_syntax(line).strip()\n                            if import_type == \"from\" and stripped_line and \" \" not in stripped_line and new_comments:\n                                nested_comments[stripped_line] = comments[-1]\n                            import_string += self.line_separator + line\n\n                            while not line.strip().endswith(\")\") and not self._at_end():\n                                line, comments, new_comments = self._strip_comments(self._get_line(), comments)\n                                stripped_line = self._strip_syntax(line).strip()\n                                if import_type == \"from\" and stripped_line and \" \" not in stripped_line and new_comments:\n                                    nested_comments[stripped_line] = comments[-1]\n                                import_string += self.line_separator + line\n\n                        stripped_line = self._strip_syntax(line).strip()\n                        if import_type == \"from\" and stripped_line and \" \" not in stripped_line and new_comments:\n                            nested_comments[stripped_line] = comments[-1]\n                        if import_string.strip().endswith(\" import\") or line.strip().startswith(\"import \"):\n                            import_string += self.line_separator + line\n                        else:\n                            import_string = import_string.rstrip().rstrip(\"\\\\\") + \" \" + line.lstrip()\n\n                if import_type == \"from\":\n                    import_string = import_string.replace(\"import(\", \"import (\")\n                    parts = import_string.split(\" import \")\n                    from_import = parts[0].split(\" \")\n                    import_string = \" import \".join([from_import[0] + \" \" + \"\".join(from_import[1:])] + parts[1:])\n\n                imports = [item.replace(\"{|\", \"{ \").replace(\"|}\", \" }\") for item in\n                           self._strip_syntax(import_string).split()]\n                if \"as\" in imports and (imports.index('as') + 1) < len(imports):\n                    while \"as\" in imports:\n                        index = imports.index('as')\n                        if import_type == \"from\":\n                            module = imports[0] + \".\" + imports[index - 1]\n                            self.as_map[module] = imports[index + 1]\n                        else:\n                            module = imports[index - 1]\n                            self.as_map[module] = imports[index + 1]\n                        if not self.config['combine_as_imports']:\n                            self.comments['straight'][module] = comments\n                            comments = []\n                        del imports[index:index + 2]\n                if import_type == \"from\":\n                    import_from = imports.pop(0)\n                    placed_module = self.place_module(import_from)\n                    if self.config['verbose']:\n                        print(\"from-type place_module for %s returned %s\" % (import_from, placed_module))\n                    if placed_module == '':\n                        print(\n                            \"WARNING: could not place module {0} of line {1} --\"\n                            \" Do you need to define a default section?\".format(import_from, line)\n                        )\n                    root = self.imports[placed_module][import_type]\n                    for import_name in imports:\n                        associated_comment = nested_comments.get(import_name)\n                        if associated_comment:\n                            self.comments['nested'].setdefault(import_from, {})[import_name] = associated_comment\n                            comments.pop(comments.index(associated_comment))\n                    if comments:\n                        self.comments['from'].setdefault(import_from, []).extend(comments)\n\n                    if len(self.out_lines) > max(self.import_index, self._first_comment_index_end + 1, 1) - 1:\n                        last = self.out_lines and self.out_lines[-1].rstrip() or \"\"\n                        while (last.startswith(\"#\") and not last.endswith('\"\"\"') and not last.endswith(\"'''\") and\n                               'isort:imports-' not in last):\n                            self.comments['above']['from'].setdefault(import_from, []).insert(0, self.out_lines.pop(-1))\n                            if len(self.out_lines) > max(self.import_index - 1, self._first_comment_index_end + 1, 1) - 1:\n                                last = self.out_lines[-1].rstrip()\n                            else:\n                                last = \"\"\n                        if statement_index - 1 == self.import_index:\n                            self.import_index -= len(self.comments['above']['from'].get(import_from, []))\n\n                    if import_from not in root:\n                        root[import_from] = OrderedDict()\n                    root[import_from].update((module, None) for module in imports)\n                else:\n                    for module in imports:\n                        if comments:\n                            self.comments['straight'][module] = comments\n                            comments = None\n\n                        if len(self.out_lines) > max(self.import_index, self._first_comment_index_end + 1, 1) - 1:\n\n                            last = self.out_lines and self.out_lines[-1].rstrip() or \"\"\n                            while (last.startswith(\"#\") and not last.endswith('\"\"\"') and not last.endswith(\"'''\") and\n                                   'isort:imports-' not in last):\n                                self.comments['above']['straight'].setdefault(module, []).insert(0,\n                                                                                                 self.out_lines.pop(-1))\n                                if len(self.out_lines) > 0 and len(self.out_lines) != self._first_comment_index_end:\n                                    last = self.out_lines[-1].rstrip()\n                                else:\n                                    last = \"\"\n                            if self.index - 1 == self.import_index:\n                                self.import_index -= len(self.comments['above']['straight'].get(module, []))\n                        placed_module = self.place_module(module)\n                        if self.config['verbose']:\n                            print(\"else-type place_module for %s returned %s\" % (module, placed_module))\n                        if placed_module == '':\n                            print(\n                                \"WARNING: could not place module {0} of line {1} --\"\n                                \" Do you need to define a default section?\".format(import_from, line)\n                            )\n                        self.imports[placed_module][import_type][module] = None", "response": "Parses a python file taking out and categorizing imports."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nexpands pattern if identified as a directory and return found sub packages", "response": "def _parse_known_pattern(self, pattern: str) -> List[str]:\n        \"\"\"\n        Expand pattern if identified as a directory and return found sub packages\n        \"\"\"\n        if pattern.endswith(os.path.sep):\n            patterns = [\n                filename\n                for filename in os.listdir(pattern)\n                if os.path.isdir(os.path.join(pattern, filename))\n            ]\n        else:\n            patterns = [pattern]\n\n        return patterns"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _load_mapping() -> Optional[Dict[str, str]]:\n        if not pipreqs:\n            return None\n        path = os.path.dirname(inspect.getfile(pipreqs))\n        path = os.path.join(path, 'mapping')\n        with open(path) as f:\n            # pypi_name: import_name\n            mappings = {}  # type: Dict[str, str]\n            for line in f:\n                import_name, _, pypi_name = line.strip().partition(\":\")\n                mappings[pypi_name] = import_name\n            return mappings", "response": "Load the mapping file."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn list of third party modules from requirements", "response": "def _load_names(self) -> List[str]:\n        \"\"\"Return list of thirdparty modules from requirements\n        \"\"\"\n        names = []\n        for path in self._get_files():\n            for name in self._get_names(path):\n                names.append(self._normalize_name(name))\n        return names"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning paths to all requirements files", "response": "def _get_files(self) -> Iterator[str]:\n        \"\"\"Return paths to all requirements files\n        \"\"\"\n        path = os.path.abspath(self.path)\n        if os.path.isfile(path):\n            path = os.path.dirname(path)\n\n        for path in self._get_parents(path):\n            for file_path in self._get_files_from_dir(path):\n                yield file_path"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _normalize_name(self, name: str) -> str:\n        if self.mapping:\n            name = self.mapping.get(name, name)\n        return name.lower().replace('-', '_')", "response": "Convert package name to module name."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_names(self, path: str) -> Iterator[str]:\n        for i in RequirementsFinder._get_names_cached(path):\n            yield i", "response": "Load required packages from path to requirements file"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a naturally sorted list of the items in to_sort.", "response": "def nsorted(\n    to_sort: Iterable[str],\n    key: Optional[Callable[[str], Any]] = None\n) -> List[str]:\n    \"\"\"Returns a naturally sorted list\"\"\"\n    if key is None:\n        key_callback = _natural_keys\n    else:\n        def key_callback(text: str) -> List[Any]:\n            return _natural_keys(key(text))  # type: ignore\n\n    return sorted(to_sort, key=key_callback)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef main():\n    colorama.init()\n    print(\"aaa\")\n    print(\"aaa\")\n    print(\"aaa\")\n    print(forward() + up(2) + \"b\" + up() + back(2) + \"1\" + forward() + \"2\" + back(3) + down(2) + \"3\" + forward() + \"4\")", "response": "A simple test for reading the alphabetical order."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef receive(self, content, **kwargs):\n        self.connection_context = DjangoChannelConnectionContext(self.message)\n        self.subscription_server = DjangoChannelSubscriptionServer(graphene_settings.SCHEMA)\n        self.subscription_server.on_open(self.connection_context)\n        self.subscription_server.handle(content, self.connection_context)", "response": "Called when a message is received with either text or bytes\n        filled out."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef save(self):\n        logger.debug(\"User requested to save settings. New settings: \" + self._settings_str())\n        cm.ConfigManager.SETTINGS[cm.PROMPT_TO_SAVE] = not self.autosave_checkbox.isChecked()\n        cm.ConfigManager.SETTINGS[cm.SHOW_TRAY_ICON] = self.show_tray_checkbox.isChecked()\n        # cm.ConfigManager.SETTINGS[cm.MENU_TAKES_FOCUS] = self.allow_kb_nav_checkbox.isChecked()\n        cm.ConfigManager.SETTINGS[cm.SORT_BY_USAGE_COUNT] = self.sort_by_usage_checkbox.isChecked()\n        cm.ConfigManager.SETTINGS[cm.UNDO_USING_BACKSPACE] = self.enable_undo_checkbox.isChecked()\n        cm.ConfigManager.SETTINGS[cm.NOTIFICATION_ICON] = self.system_tray_icon_theme_combobox.currentData(Qt.UserRole)\n        # TODO: After saving the notification icon, apply it to the currently running instance.\n        self._save_autostart_settings()", "response": "Called by the parent settings dialog when the user clicks on the Save button. Stores the current settings in the ConfigManager."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a human readable string representation for logging purposes.", "response": "def _settings_str(self):\n        \"\"\"Returns a human readable settings representation for logging purposes.\"\"\"\n        settings = \"Automatically save changes: {}, \" \\\n            \"Show tray icon: {}, \" \\\n            \"Allow keyboard navigation: {}, \" \\\n            \"Sort by usage count: {}, \" \\\n            \"Enable undo using backspace: {}, \" \\\n            \"Tray icon theme: {}\".format(\n               self.autosave_checkbox.isChecked(),\n               self.show_tray_checkbox.isChecked(),\n               self.allow_kb_nav_checkbox.isChecked(),\n               self.sort_by_usage_checkbox.isChecked(),\n               self.enable_undo_checkbox.isChecked(),\n               self.system_tray_icon_theme_combobox.currentData(Qt.UserRole)\n            )\n        return settings"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _should_trigger_abbreviation(self, buffer):\n        return any(self.__checkInput(buffer, abbr) for abbr in self.abbreviations)", "response": "Checks whether the given input should trigger the abbreviation."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\npartitions the input into text before typed abbreviation and text after the current string.", "response": "def _partition_input(self, current_string: str, abbr: typing.Optional[str]) -> typing.Tuple[str, str, str]:\n        \"\"\"\n        Partition the input into text before, typed abbreviation (if it exists), and text after\n        \"\"\"\n        if abbr:\n            if self.ignoreCase:\n                string_before, typed_abbreviation, string_after = self._case_insensitive_rpartition(\n                    current_string, abbr\n                )\n                abbr_start_index = len(string_before)\n                abbr_end_index = abbr_start_index + len(typed_abbreviation)\n                typed_abbreviation = current_string[abbr_start_index:abbr_end_index]\n            else:\n                string_before, typed_abbreviation, string_after = current_string.rpartition(abbr)\n\n            return string_before, typed_abbreviation, string_after\n        else:\n            # abbr is None. This happens if the phrase was typed/pasted using a hotkey and is about to be un-done.\n            # In this case, there is no trigger character (thus empty before and after text). The complete string\n            # should be undone.\n            return \"\", current_string, \"\""}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the pattern of the filter that is used by the GUI to obtain human - readable version of the filter.", "response": "def get_filter_regex(self):\n        \"\"\"\n        Used by the GUI to obtain human-readable version of the filter\n        \"\"\"\n        if self.windowInfoRegex is not None:\n            if self.isRecursive:\n                return self.windowInfoRegex.pattern\n            else:\n                return self.windowInfoRegex.pattern\n        elif self.parent is not None:\n            return self.parent.get_child_filter()\n        else:\n            return \"\""}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_item(self, item):\n        item.parent = self\n        #self.phrases[phrase.description] = phrase\n        self.items.append(item)", "response": "Add a new item to the folder."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngiving the input buffer calculate how many backspaces needed to erase the text that triggered this folder.", "response": "def get_backspace_count(self, buffer):\n        \"\"\"\n        Given the input buffer, calculate how many backspaces are needed to erase the text\n        that triggered this folder.\n        \"\"\"\n        if TriggerMode.ABBREVIATION in self.modes and self.backspace:\n            if self._should_trigger_abbreviation(buffer):\n                abbr = self._get_trigger_abbreviation(buffer)\n                stringBefore, typedAbbr, stringAfter = self._partition_input(buffer, abbr)\n                return len(abbr) + len(stringAfter)\n\n        if self.parent is not None:\n            return self.parent.get_backspace_count(buffer)\n\n        return 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalculates how many keystrokes were used in triggering this folder.", "response": "def calculate_input(self, buffer):\n        \"\"\"\n        Calculate how many keystrokes were used in triggering this folder (if applicable).\n        \"\"\"\n        if TriggerMode.ABBREVIATION in self.modes and self.backspace:\n            if self._should_trigger_abbreviation(buffer):\n                if self.immediate:\n                    return len(self._get_trigger_abbreviation(buffer))\n                else:\n                    return len(self._get_trigger_abbreviation(buffer)) + 1\n\n        if self.parent is not None:\n            return self.parent.calculate_input(buffer)\n\n        return 0"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalculates how many keystrokes were used in triggering this phrase.", "response": "def calculate_input(self, buffer):\n        \"\"\"\n        Calculate how many keystrokes were used in triggering this phrase.\n        \"\"\"\n        # TODO: This function is unused?\n        if TriggerMode.ABBREVIATION in self.modes:\n            if self._should_trigger_abbreviation(buffer):\n                if self.immediate:\n                    return len(self._get_trigger_abbreviation(buffer))\n                else:\n                    return len(self._get_trigger_abbreviation(buffer)) + 1\n\n        # TODO - re-enable me if restoring predictive functionality\n        #if TriggerMode.PREDICTIVE in self.modes:\n        #    if self._should_trigger_predictive(buffer):\n        #        return ConfigManager.SETTINGS[PREDICTIVE_LENGTH]\n\n        if TriggerMode.HOTKEY in self.modes:\n            if buffer == '':\n                return len(self.modifiers) + 1\n\n        return self.parent.calculate_input(buffer)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _persist_metadata(self):\n        serializable_data = self.get_serializable()\n        try:\n            self._try_persist_metadata(serializable_data)\n        except TypeError:\n            # The user added non-serializable data to the store, so skip all non-serializable keys or values.\n            cleaned_data = Script._remove_non_serializable_store_entries(serializable_data[\"store\"])\n            self._try_persist_metadata(cleaned_data)", "response": "Write all script meta - data including the persistent script Store."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _remove_non_serializable_store_entries(store: Store) -> dict:\n        cleaned_store_data = {}\n        for key, value in store.items():\n            if Script._is_serializable(key) and Script._is_serializable(value):\n                cleaned_store_data[key] = value\n            else:\n                _logger.info(\"Skip non-serializable item in the local script store. Key: '{}', Value: '{}'. \"\n                             \"This item cannot be saved and therefore will be lost when autokey quits.\".format(\n                                key, value\n                ))\n        return cleaned_store_data", "response": "Remove all non - serializable items from the given store."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate various storage directories if those do not exist.", "response": "def _create_storage_directories():\n        \"\"\"Create various storage directories, if those do not exist.\"\"\"\n        # Create configuration directory\n        if not os.path.exists(common.CONFIG_DIR):\n            os.makedirs(common.CONFIG_DIR)\n        # Create data directory (for log file)\n        if not os.path.exists(common.DATA_DIR):\n            os.makedirs(common.DATA_DIR)\n        # Create run directory (for lock file)\n        if not os.path.exists(common.RUN_DIR):\n            os.makedirs(common.RUN_DIR)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef shutdown(self):\n        logging.info(\"Shutting down\")\n        self.closeAllWindows()\n        self.notifier.hide()\n        self.service.shutdown()\n        self.monitor.stop()\n        self.quit()\n        os.remove(common.LOCK_FILE)  # TODO: maybe use atexit to remove the lock/pid file?\n        logging.debug(\"All shutdown tasks complete... quitting\")", "response": "Shut down the entire application."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nshowing the configuration window or deiconify it if it s already open.", "response": "def show_configure(self):\n        \"\"\"\n        Show the configuration window, or deiconify (un-minimise) it if it's already open.\n        \"\"\"\n        logging.info(\"Displaying configuration window\")\n        self.configWindow.show()\n        self.configWindow.showNormal()\n        self.configWindow.activateWindow()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef show_script_error(self):\n        # TODO: i18n\n        if self.service.scriptRunner.error:\n            details = self.service.scriptRunner.error\n            self.service.scriptRunner.error = ''\n        else:\n            details = \"No error information available\"\n        QMessageBox.information(None, \"View Script Error Details\", details)", "response": "Show the last script error"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates action_create for new items.", "response": "def _create_action_create(self) -> QAction:\n        \"\"\"\n        The action_create action contains a menu with all four \"new\" actions. It is inserted into the main window\n        tool bar and lets the user create new items in the file tree.\n        QtCreator currently does not support defining such actions that open a menu with choices, so do it in code.\n        \"\"\"\n        icon = QIcon.fromTheme(\"document-new\")\n        action_create = QAction(icon, \"New\u2026\", self)\n        create_menu = QMenu(self)\n        create_menu.insertActions(None, (  # \"Insert before None\", so append all items to the (empty) action list\n            self.action_new_top_folder,\n            self.action_new_sub_folder,\n            self.action_new_phrase,\n            self.action_new_script\n        ))\n        action_create.setMenu(create_menu)\n        return action_create"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _initialise_action_states(self):\n        self.action_enable_monitoring.setChecked(self.app.service.is_running())\n        self.action_enable_monitoring.setEnabled(not self.app.serviceDisabled)", "response": "Perform all actions that have to be initialised"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _set_platform_specific_keyboard_shortcuts(self):\n        self.action_new_phrase.setShortcuts(QKeySequence.New)\n        self.action_save.setShortcuts(QKeySequence.Save)\n        self.action_close_window.setShortcuts(QKeySequence.Close)\n        self.action_quit.setShortcuts(QKeySequence.Quit)\n\n        self.action_undo.setShortcuts(QKeySequence.Undo)\n        self.action_redo.setShortcuts(QKeySequence.Redo)\n        self.action_cut_item.setShortcuts(QKeySequence.Cut)\n        self.action_copy_item.setShortcuts(QKeySequence.Copy)\n        self.action_paste_item.setShortcuts(QKeySequence.Paste)\n        self.action_delete_item.setShortcuts(QKeySequence.Delete)\n\n        self.action_configure_autokey.setShortcuts(QKeySequence.Preferences)", "response": "Set the default keyboard shortcuts for the current platform."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a context menu and assign it to the current context menu.", "response": "def create_assign_context_menu(self):\n        \"\"\"\n        Create a context menu, then set the created QMenu as the context menu.\n        This builds the menu with all required actions and signal-slot connections.\n        \"\"\"\n        menu = QMenu(\"AutoKey\")\n        self._build_menu(menu)\n        self.setContextMenu(menu)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_tool_tip(self, service_running: bool):\n        if service_running:\n            self.setToolTip(TOOLTIP_RUNNING)\n        else:\n            self.setToolTip(TOOLTIP_PAUSED)", "response": "Slot function that updates the tooltip when the user activates or deactivates the expansion service."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _create_action(\n            self,\n            icon_name: Optional[str],\n            title: str,\n            slot_function: Callable[[None], None],\n            tool_tip: Optional[str]=None)-> QAction:\n        \"\"\"\n        QAction factory. All items created belong to the calling instance, i.e. created QAction parent is self.\n        \"\"\"\n        action = QAction(title, self)\n        if icon_name:\n            action.setIcon(QIcon.fromTheme(icon_name))\n        action.triggered.connect(slot_function)\n        if tool_tip:\n            action.setToolTip(tool_tip)\n        return action", "response": "Create a QAction instance from the passed in parameters."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate all static actions.", "response": "def _create_static_actions(self):\n        \"\"\"\n        Create all static menu actions. The created actions will be placed in the tray icon context menu.\n        \"\"\"\n        logger.info(\"Creating static context menu actions.\")\n        self.action_view_script_error = self._create_action(\n            None, \"&View script error\", self.reset_tray_icon,\n            \"View the last script error.\"\n        )\n        self.action_view_script_error.triggered.connect(self.app.show_script_error)\n        # The action should disable itself\n        self.action_view_script_error.setDisabled(True)\n        self.action_view_script_error.triggered.connect(self.action_view_script_error.setEnabled)\n        self.action_hide_icon = self._create_action(\n            \"edit-clear\", \"Temporarily &Hide Icon\", self.hide,\n            \"Temporarily hide the system tray icon.\\nUse the settings to hide it permanently.\"\n        )\n        self.action_show_config_window = self._create_action(\n            \"configure\", \"&Show Main Window\", self.app.show_configure,\n            \"Show the main AutoKey window. This does the same as left clicking the tray icon.\"\n        )\n        self.action_quit = self._create_action(\"application-exit\", \"Exit AutoKey\", self.app.shutdown)\n        # TODO: maybe import this from configwindow.py ? The exact same Action is defined in the main window.\n        self.action_enable_monitoring = self._create_action(\n            None, \"&Enable Monitoring\", self.app.toggle_service,\n            \"Pause the phrase expansion and script execution, both by abbreviations and hotkeys.\\n\"\n            \"The global hotkeys to show the main window and to toggle this setting, as defined in the AutoKey \"\n            \"settings, are not affected and will work regardless.\"\n        )\n        self.action_enable_monitoring.setCheckable(True)\n        self.action_enable_monitoring.setChecked(self.app.service.is_running())\n        self.action_enable_monitoring.setDisabled(self.app.serviceDisabled)\n        # Sync action state with internal service state\n        self.app.monitoring_disabled.connect(self.action_enable_monitoring.setChecked)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _fill_context_menu_with_model_item_actions(self, context_menu: QMenu):\n        # Get phrase folders to add to main menu\n        logger.info(\"Rebuilding model item actions, adding all items marked for access through the tray icon.\")\n        folders = [folder for folder in self.config_manager.allFolders if folder.show_in_tray_menu]\n        items = [item for item in self.config_manager.allItems if item.show_in_tray_menu]\n        # Only extract the QActions, but discard the PopupMenu instance.\n        # This is done, because the PopupMenu class is not directly usable as a context menu here.\n        menu = popupmenu.PopupMenu(self.app.service, folders, items, False, \"AutoKey\")\n        new_item_actions = menu.actions()\n        context_menu.addActions(new_item_actions)\n        for action in new_item_actions:  # type: QAction\n            # QMenu does not take the ownership when adding QActions, so manually re-parent all actions.\n            # This causes the QActions to be destroyed when the context menu is cleared or re-created.\n            action.setParent(context_menu)\n\n        if not context_menu.isEmpty():\n            # Avoid a stray separator line, if no items are marked for display in the context menu.\n            context_menu.addSeparator()", "response": "Fill the given context menu with model item actions."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nbuilds the context menu.", "response": "def _build_menu(self, context_menu: QMenu):\n        \"\"\"Build the context menu.\"\"\"\n        logger.debug(\"Show tray icon enabled in settings: {}\".format(cm.ConfigManager.SETTINGS[cm.SHOW_TRAY_ICON]))\n        # Items selected for display are shown on top\n        self._fill_context_menu_with_model_item_actions(context_menu)\n        # The static actions are added at the bottom\n        context_menu.addAction(self.action_view_script_error)\n        context_menu.addAction(self.action_enable_monitoring)\n        context_menu.addAction(self.action_hide_icon)\n        context_menu.addAction(self.action_show_config_window)\n        context_menu.addAction(self.action_quit)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef shutdown(self):\n        if self.configWindow is not None:\n            if self.configWindow.promptToSave():\n                return\n\n            self.configWindow.hide()\n\n        self.notifier.hide_icon()\n\n        t = threading.Thread(target=self.__completeShutdown)\n        t.start()", "response": "Shut down the entire application."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nshows the configuration window or deiconify it.", "response": "def show_configure(self):\n        \"\"\"\n        Show the configuration window, or deiconify (un-minimise) it if it's already open.\n        \"\"\"\n        logging.info(\"Displaying configuration window\")\n        if self.configWindow is None:\n            self.configWindow = ConfigWindow(self)\n            self.configWindow.show()\n        else:\n            self.configWindow.deiconify()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef show_error_dialog(self, message, details=None):\n        dlg = Gtk.MessageDialog(type=Gtk.MessageType.ERROR, buttons=Gtk.ButtonsType.OK,\n                                 message_format=message)\n        if details is not None:\n            dlg.format_secondary_text(details)\n        dlg.run()\n        dlg.destroy()", "response": "Convenience method for showing an error dialog."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef show_script_error(self, parent):\n        if self.service.scriptRunner.error != '':\n            dlg = Gtk.MessageDialog(type=Gtk.MessageType.INFO, buttons=Gtk.ButtonsType.OK,\n                                     message_format=self.service.scriptRunner.error)\n            self.service.scriptRunner.error = ''\n            # revert the tray icon\n            self.notifier.set_icon(cm.ConfigManager.SETTINGS[cm.NOTIFICATION_ICON])\n            self.notifier.errorItem.hide()\n            self.notifier.update_visible_status()\n\n        else:\n            dlg = Gtk.MessageDialog(type=Gtk.MessageType.INFO, buttons=Gtk.ButtonsType.OK,\n                                     message_format=_(\"No error information available\"))\n\n        dlg.set_title(_(\"View script error\"))\n        dlg.set_transient_for(parent)\n        dlg.run()\n        dlg.destroy()", "response": "Show the last script error"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _persist_settings(config_manager):\n    serializable_data = config_manager.get_serializable()\n    try:\n        _try_persist_settings(serializable_data)\n    except (TypeError, ValueError):\n        # The user added non-serializable data to the store, so remove all non-serializable keys or values.\n        _remove_non_serializable_store_entries(serializable_data[\"settings\"][SCRIPT_GLOBALS])\n        _try_persist_settings(serializable_data)", "response": "Write the settings including the persistent global script Store."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _try_persist_settings(serializable_data: dict):\n    with open(CONFIG_FILE, \"w\") as json_file:\n            json.dump(serializable_data, json_file, indent=4)", "response": "Write the settings as JSON to the configuration file."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the autostart settings as read from the system.", "response": "def get_autostart() -> AutostartSettings:\n    \"\"\"Returns the autostart settings as read from the system.\"\"\"\n    autostart_file = Path(common.AUTOSTART_DIR) / \"autokey.desktop\"\n    if not autostart_file.exists():\n        return AutostartSettings(None, False)\n    else:\n        return _extract_data_from_desktop_file(autostart_file)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates or update the autostart entry for the autokey.", "response": "def set_autostart_entry(autostart_data: AutostartSettings):\n    \"\"\"\n    Activates or deactivates autostarting autokey during user login.\n    Autostart is handled by placing a .desktop file into '$XDG_CONFIG_HOME/autostart', typically '~/.config/autostart'\n    \"\"\"\n    _logger.info(\"Save autostart settings: {}\".format(autostart_data))\n    autostart_file = Path(common.AUTOSTART_DIR) / \"autokey.desktop\"\n    if autostart_data.desktop_file_name is None:  # Choosing None as the GUI signals deleting the entry.\n        delete_autostart_entry()\n    else:\n        autostart_file.parent.mkdir(exist_ok=True)  # make sure that the parent autostart directory exists.\n        _create_autostart_entry(autostart_data, autostart_file)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate an autostart. desktop file in the autostart directory if possible.", "response": "def _create_autostart_entry(autostart_data: AutostartSettings, autostart_file: Path):\n    \"\"\"Create an autostart .desktop file in the autostart directory, if possible.\"\"\"\n    try:\n        source_desktop_file = get_source_desktop_file(autostart_data.desktop_file_name)\n    except FileNotFoundError:\n        _logger.exception(\"Failed to find a usable .desktop file! Unable to find: {}\".format(\n            autostart_data.desktop_file_name))\n    else:\n        _logger.debug(\"Found source desktop file that will be placed into the autostart directory: {}\".format(\n            source_desktop_file))\n        with open(str(source_desktop_file), \"r\") as opened_source_desktop_file:\n            desktop_file_content = opened_source_desktop_file.read()\n        desktop_file_content = \"\\n\".join(_manage_autostart_desktop_file_launch_flags(\n            desktop_file_content, autostart_data.switch_show_configure\n        )) + \"\\n\"\n        with open(str(autostart_file), \"w\", encoding=\"UTF-8\") as opened_autostart_file:\n            opened_autostart_file.write(desktop_file_content)\n        _logger.debug(\"Written desktop file: {}\".format(autostart_file))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nremoves an existing autostart entry. If none is found nothing happens.", "response": "def delete_autostart_entry():\n    \"\"\"Remove a present autostart entry. If none is found, nothing happens.\"\"\"\n    autostart_file = Path(common.AUTOSTART_DIR) / \"autokey.desktop\"\n    if autostart_file.exists():\n        autostart_file.unlink()\n        _logger.info(\"Deleted old autostart entry: {}\".format(autostart_file))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_source_desktop_file(desktop_file_name: str) -> Path:\n    possible_paths = (\n        # Copy from local installation. Also used if the user explicitely customized the launcher .desktop file.\n        Path(common.XDG_DATA_HOME) / \"applications\",\n        # Copy from system-wide installation\n        Path(\"/\", \"usr\", \"share\", \"applications\"),\n        # Copy from git source tree. This will probably not work when used, because the application won\u2019t be in the PATH\n        Path(__file__).parent.parent.parent / \"config\"\n    )\n    for possible_path in possible_paths:\n        desktop_file = possible_path / desktop_file_name\n        if desktop_file.exists():\n            return desktop_file\n    raise FileNotFoundError(\"Desktop file for autokey could not be found. Searched paths: {}\".format(possible_paths))", "response": "Try to get the source. desktop file with the given name."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\niterates over the contents of the desktop file and manage the launch flags.", "response": "def _manage_autostart_desktop_file_launch_flags(desktop_file_content: str, show_configure: bool) -> typing.Iterable[str]:\n    \"\"\"Iterate over the desktop file contents. Yields all lines except for the \"Exec=\" line verbatim. Modifies\n    the Exec line to include the user desired command line switches (currently only one implemented).\"\"\"\n    for line in desktop_file_content.splitlines(keepends=False):\n        if line.startswith(\"Exec=\"):\n            exec_line = _modify_exec_line(line, show_configure)\n            _logger.info(\"Used 'Exec' line in desktop file: {}\".format(exec_line))\n            yield exec_line\n        else:\n            yield line"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\napplying the given settings to the current configuration.", "response": "def apply_settings(settings):\n    \"\"\"\n    Allows new settings to be added without users having to lose all their configuration\n    \"\"\"\n    for key, value in settings.items():\n        ConfigManager.SETTINGS[key] = value"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts rename autostart entries for GUIs in 0. 95. 3 to autokey. desktop.", "response": "def convert_rename_autostart_entries_for_v0_95_3():\n    \"\"\"\n    In versions <= 0.95.2, the autostart option in autokey-gtk copied the default autokey-gtk.desktop file into\n    $XDG_CONFIG_DIR/autostart (with minor, unrelated modifications).\n    For versions >= 0.95.3, the autostart file is renamed to autokey.desktop. In 0.95.3, the autostart functionality\n    is implemented for autokey-qt. Thus, it becomes possible to have an autostart file for both GUIs in the autostart\n    directory simultaneously. Because of the singleton nature of autokey, this becomes an issue and race-conditions\n    determine which GUI starts first. To prevent this, both GUIs will share a single autokey.desktop autostart entry,\n    allowing only one GUI to be started during login. This allows for much simpler code.\n    \"\"\"\n    old_autostart_file = Path(common.AUTOSTART_DIR) / \"autokey-gtk.desktop\"\n    if old_autostart_file.exists():\n        new_file_name = Path(common.AUTOSTART_DIR) / \"autokey.desktop\"\n        _logger.info(\"Migration task: Found old autostart entry: '{}'. Rename to: '{}'\".format(\n            old_autostart_file, new_file_name)\n        )\n        old_autostart_file.rename(new_file_name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncall when some element of configuration has been altered to update the lists of phrases and folders.", "response": "def config_altered(self, persistGlobal):\n        \"\"\"\n        Called when some element of configuration has been altered, to update\n        the lists of phrases/folders. \n        \n        @param persistGlobal: save the global configuration at the end of the process\n        \"\"\"\n        _logger.info(\"Configuration changed - rebuilding in-memory structures\")\n        \n        self.lock.acquire()\n        # Rebuild root folder list\n        #rootFolders = self.folders\n        #self.folders = []\n        #for folder in rootFolders:\n        #    self.folders.append(folder)\n        \n        self.hotKeyFolders = []\n        self.hotKeys = []\n        \n        self.abbreviations = []\n        \n        self.allFolders = []\n        self.allItems = []\n        \n        for folder in self.folders:\n            if model.TriggerMode.HOTKEY in folder.modes:\n                self.hotKeyFolders.append(folder)\n            self.allFolders.append(folder)\n            \n            if not self.app.monitor.has_watch(folder.path):\n                self.app.monitor.add_watch(folder.path)\n            \n            self.__processFolder(folder)\n        \n        self.globalHotkeys = []\n        self.globalHotkeys.append(self.configHotkey)\n        self.globalHotkeys.append(self.toggleServiceHotkey)\n        #_logger.debug(\"Global hotkeys: %s\", self.globalHotkeys)\n        \n        #_logger.debug(\"Hotkey folders: %s\", self.hotKeyFolders)\n        #_logger.debug(\"Hotkey phrases: %s\", self.hotKeys)\n        #_logger.debug(\"Abbreviation phrases: %s\", self.abbreviations)\n        #_logger.debug(\"All folders: %s\", self.allFolders)\n        #_logger.debug(\"All phrases: %s\", self.allItems)\n        \n        if persistGlobal:\n            save_config(self)\n\n        self.lock.release()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check_abbreviation_unique(self, abbreviation, newFilterPattern, targetItem):\n        for item in self.allFolders:\n            if model.TriggerMode.ABBREVIATION in item.modes:\n                if abbreviation in item.abbreviations and item.filter_matches(newFilterPattern):\n                    return item is targetItem, item\n            \n        for item in self.allItems:\n            if model.TriggerMode.ABBREVIATION in item.modes:\n                if abbreviation in item.abbreviations and item.filter_matches(newFilterPattern):\n                    return item is targetItem, item\n\n        return True, None", "response": "Checks that the given abbreviation is not already in use."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck that the given hotkey is unique.", "response": "def check_hotkey_unique(self, modifiers, hotKey, newFilterPattern, targetItem):\n        \"\"\"\n        Checks that the given hotkey is not already in use. Also checks the \n        special hotkeys configured from the advanced settings dialog.\n        \n        @param modifiers: modifiers for the hotkey\n        @param hotKey: the hotkey to check\n        @param newFilterPattern:\n        @param targetItem: the phrase for which the hotKey to be used        \n        \"\"\"\n        for item in self.allFolders:\n            if model.TriggerMode.HOTKEY in item.modes:\n                if item.modifiers == modifiers and item.hotKey == hotKey and item.filter_matches(newFilterPattern):\n                    return item is targetItem, item\n            \n        for item in self.allItems:\n            if model.TriggerMode.HOTKEY in item.modes:\n                if item.modifiers == modifiers and item.hotKey == hotKey and item.filter_matches(newFilterPattern):\n                    return item is targetItem, item\n\n        for item in self.globalHotkeys:\n            if item.enabled:\n                if item.modifiers == modifiers and item.hotKey == hotKey and item.filter_matches(newFilterPattern):\n                    return item is targetItem, item\n\n        return True, None"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstarts recording a key combination when the user clicks on the setButton.", "response": "def on_setButton_pressed(self):\n        \"\"\"\n        Start recording a key combination when the user clicks on the setButton.\n        The button itself is automatically disabled during the recording process.\n        \"\"\"\n        self.keyLabel.setText(\"Press a key or combination...\")  # TODO: i18n\n        logger.debug(\"User starts to record a key combination.\")\n        self.grabber = iomediator.KeyGrabber(self)\n        self.grabber.start()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_key(self, key, modifiers: typing.List[Key]=None):\n        if modifiers is None:\n            modifiers = []  # type: typing.List[Key]\n        if key in self.KEY_MAP:\n            key = self.KEY_MAP[key]\n        self._setKeyLabel(key)\n        self.key = key\n        self.controlButton.setChecked(Key.CONTROL in modifiers)\n        self.altButton.setChecked(Key.ALT in modifiers)\n        self.shiftButton.setChecked(Key.SHIFT in modifiers)\n        self.superButton.setChecked(Key.SUPER in modifiers)\n        self.hyperButton.setChecked(Key.HYPER in modifiers)\n        self.metaButton.setChecked(Key.META in modifiers)\n        self.recording_finished.emit(True)", "response": "This is called when the user successfully finishes recording a key combination."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef handle_modifier_down(self, modifier):\n        _logger.debug(\"%s pressed\", modifier)\n        if modifier in (Key.CAPSLOCK, Key.NUMLOCK):\n            if self.modifiers[modifier]:\n                self.modifiers[modifier] = False\n            else:\n                self.modifiers[modifier] = True\n        else:\n            self.modifiers[modifier] = True", "response": "Handles the modifier down key."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nhandle the key up event.", "response": "def handle_modifier_up(self, modifier):\n        \"\"\"\n        Updates the state of the given modifier key to 'released'.\n        \"\"\"\n        _logger.debug(\"%s released\", modifier)\n        # Caps and num lock are handled on key down only\n        if modifier not in (Key.CAPSLOCK, Key.NUMLOCK):\n            self.modifiers[modifier] = False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef send_string(self, string: str):\n        if not string:\n            return\n\n        string = string.replace('\\n', \"<enter>\")\n        string = string.replace('\\t', \"<tab>\")\n        \n        _logger.debug(\"Send via event interface\")\n        self.__clearModifiers()\n        modifiers = []\n        for section in KEY_SPLIT_RE.split(string):\n            if len(section) > 0:\n                if Key.is_key(section[:-1]) and section[-1] == '+' and section[:-1] in MODIFIERS:\n                    # Section is a modifier application (modifier followed by '+')\n                    modifiers.append(section[:-1])\n                    \n                else:\n                    if len(modifiers) > 0:\n                        # Modifiers ready for application - send modified key\n                        if Key.is_key(section):\n                            self.interface.send_modified_key(section, modifiers)\n                            modifiers = []\n                        else:\n                            self.interface.send_modified_key(section[0], modifiers)\n                            if len(section) > 1:\n                                self.interface.send_string(section[1:])\n                            modifiers = []\n                    else:\n                        # Normal string/key operation\n                        if Key.is_key(section):\n                            self.interface.send_key(section)\n                        else:\n                            self.interface.send_string(section)\n                            \n        self.__reapplyModifiers()", "response": "Sends the given string for output."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsends the given number of left key presses.", "response": "def send_left(self, count):\n        \"\"\"\n        Sends the given number of left key presses.\n        \"\"\"\n        for i in range(count):\n            self.interface.send_key(Key.LEFT)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef send_up(self, count):\n        for i in range(count):\n            self.interface.send_key(Key.UP)", "response": "Sends up key presses."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef send_backspace(self, count):\n        for i in range(count):\n            self.interface.send_key(Key.BACKSPACE)", "response": "Sends the given number of backspace key presses."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef from_html(html_style_colour_str: str):\n        html_style_colour_str = html_style_colour_str.lstrip(\"#\")\n        components = list(map(\"\".join, zip(*[iter(html_style_colour_str)]*2)))\n        return ColourData(*(int(colour, 16) for colour in components))", "response": "Parser for KDialog output which outputs a HTML style hex string encoded colour."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsends a sequence of keys via keyboard events .", "response": "def send_keys(self, keyString):\n        \"\"\"\n        Send a sequence of keys via keyboard events\n        \n        Usage: C{keyboard.send_keys(keyString)}\n        \n        @param keyString: string of keys (including special keys) to send\n        \"\"\"\n        assert type(keyString) is str\n        self.mediator.interface.begin_send()\n        try:\n            self.mediator.send_string(keyString)\n        finally:\n            self.mediator.interface.finish_send()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsends a keyboard event to all the related objects.", "response": "def send_key(self, key, repeat=1):\n        \"\"\"\n        Send a keyboard event\n        \n        Usage: C{keyboard.send_key(key, repeat=1)}\n        \n        @param key: they key to be sent (e.g. \"s\" or \"<enter>\")\n        @param repeat: number of times to repeat the key event\n        \"\"\"        \n        for _ in range(repeat):\n            self.mediator.send_key(key)\n        self.mediator.flush()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fake_keypress(self, key, repeat=1):\n        for _ in range(repeat):\n            self.mediator.fake_keypress(key)", "response": "Fake a keypress using XTest to send the keypresses to the related object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwait for a keypress or key combination with a key.", "response": "def wait_for_keypress(self, key, modifiers: list=None, timeOut=10.0):\n        \"\"\"\n        Wait for a keypress or key combination\n        \n        Usage: C{keyboard.wait_for_keypress(self, key, modifiers=[], timeOut=10.0)}\n        \n        Note: this function cannot be used to wait for modifier keys on their own\n\n        @param key: they key to wait for\n        @param modifiers: list of modifiers that should be pressed with the key\n        @param timeOut: maximum time, in seconds, to wait for the keypress to occur\n        \"\"\"\n        if modifiers is None:\n            modifiers = []\n        w = iomediator.Waiter(key, modifiers, None, timeOut)\n        return w.wait()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef click_relative(self, x, y, button):\n        self.interface.send_mouse_click(x, y, button, True)", "response": "Send a mouse click relative to the active window"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsend a mouse click relative to the current mouse position", "response": "def click_relative_self(self, x, y, button):\n        \"\"\"\n        Send a mouse click relative to the current mouse position\n        \n        Usage: C{mouse.click_relative_self(x, y, button)}\n        \n        @param x: x-offset in pixels, relative to current mouse position\n        @param y: y-offset in pixels, relative to current mouse position\n        @param button: mouse button to simulate (left=1, middle=2, right=3)\n        \"\"\"\n        self.interface.send_mouse_click_relative(x, y, button)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef click_absolute(self, x, y, button):\n        self.interface.send_mouse_click(x, y, button, False)", "response": "Send a mouse click relative to the screen"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef wait_for_click(self, button, timeOut=10.0):\n        button = int(button)\n        w = iomediator.Waiter(None, None, button, timeOut)\n        w.wait()", "response": "Wait for a mouse click to occur\n        \n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nshow an information dialog", "response": "def info_dialog(self, title=\"Information\", message=\"\", **kwargs):\n        \"\"\"\n        Show an information dialog\n\n        Usage: C{dialog.info_dialog(title=\"Information\", message=\"\", **kwargs)}\n\n        @param title: window title for the dialog\n        @param message: message displayed in the dialog\n        @return: a tuple containing the exit code and user input\n        @rtype: C{DialogData(int, str)}\n        \"\"\"\n        return self._run_kdialog(title, [\"--msgbox\", message], kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nshow an input dialog", "response": "def input_dialog(self, title=\"Enter a value\", message=\"Enter a value\", default=\"\", **kwargs):\n        \"\"\"\n        Show an input dialog\n        \n        Usage: C{dialog.input_dialog(title=\"Enter a value\", message=\"Enter a value\", default=\"\", **kwargs)}\n        \n        @param title: window title for the dialog\n        @param message: message displayed above the input box\n        @param default: default value for the input box\n        @return: a tuple containing the exit code and user input\n        @rtype: C{DialogData(int, str)}\n        \"\"\"\n        return self._run_kdialog(title, [\"--inputbox\", message, default], kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nshow a password input dialog", "response": "def password_dialog(self, title=\"Enter password\", message=\"Enter password\", **kwargs):\n        \"\"\"\n        Show a password input dialog\n        \n        Usage: C{dialog.password_dialog(title=\"Enter password\", message=\"Enter password\", **kwargs)}\n        \n        @param title: window title for the dialog\n        @param message: message displayed above the password input box\n        @return: a tuple containing the exit code and user input\n        @rtype: C{DialogData(int, str)}\n        \"\"\"\n        return self._run_kdialog(title, [\"--password\", message], kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef combo_menu(self, options, title=\"Choose an option\", message=\"Choose an option\", **kwargs):\n        return self._run_kdialog(title, [\"--combobox\", message] + options, kwargs)", "response": "Show a combobox menu"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nshow a single - selection list menu", "response": "def list_menu(self, options, title=\"Choose a value\", message=\"Choose a value\", default=None, **kwargs):\n        \"\"\"\n        Show a single-selection list menu\n        \n        Usage: C{dialog.list_menu(options, title=\"Choose a value\", message=\"Choose a value\", default=None, **kwargs)}\n        \n        @param options: list of options (strings) for the dialog\n        @param title: window title for the dialog\n        @param message: message displayed above the list\n        @param default: default value to be selected\n        @return: a tuple containing the exit code and user choice\n        @rtype: C{DialogData(int, str)}\n        \"\"\"\n        \n        choices = []\n        optionNum = 0\n        for option in options:\n            choices.append(str(optionNum))\n            choices.append(option)\n            if option == default:\n                choices.append(\"on\")\n            else:\n                choices.append(\"off\")\n            optionNum += 1\n            \n        return_code, result = self._run_kdialog(title, [\"--radiolist\", message] + choices, kwargs)\n        choice = options[int(result)]\n        \n        return DialogData(return_code, choice)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef list_menu_multi(self, options, title=\"Choose one or more values\", message=\"Choose one or more values\",\n                        defaults: list=None, **kwargs):\n        \"\"\"\n        Show a multiple-selection list menu\n        \n        Usage: C{dialog.list_menu_multi(options, title=\"Choose one or more values\", message=\"Choose one or more values\", defaults=[], **kwargs)}\n        \n        @param options: list of options (strings) for the dialog\n        @param title: window title for the dialog\n        @param message: message displayed above the list\n        @param defaults: list of default values to be selected\n        @return: a tuple containing the exit code and user choice\n        @rtype: C{DialogData(int, List[str])}\n        \"\"\"\n\n        if defaults is None:\n            defaults = []\n        choices = []\n        optionNum = 0\n        for option in options:\n            choices.append(str(optionNum))\n            choices.append(option)\n            if option in defaults:\n                choices.append(\"on\")\n            else:\n                choices.append(\"off\")\n            optionNum += 1\n            \n        return_code, output = self._run_kdialog(title, [\"--separate-output\", \"--checklist\", message] + choices, kwargs)\n        results = output.split()\n\n        choices = [options[int(choice_index)] for choice_index in results]\n        \n        return DialogData(return_code, choices)", "response": "Show a multiple - selection list menu for one or more values"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef open_file(self, title=\"Open File\", initialDir=\"~\", fileTypes=\"*|All Files\", rememberAs=None, **kwargs):\n        if rememberAs is not None:\n            return self._run_kdialog(title, [\"--getopenfilename\", initialDir, fileTypes, \":\" + rememberAs], kwargs)\n        else:\n            return self._run_kdialog(title, [\"--getopenfilename\", initialDir, fileTypes], kwargs)", "response": "Show an Open File dialog with the specified title initialDir and fileTypes."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nshows a Save As dialog and return the path of the saved file.", "response": "def save_file(self, title=\"Save As\", initialDir=\"~\", fileTypes=\"*|All Files\", rememberAs=None, **kwargs):\n        \"\"\"\n        Show a Save As dialog\n        \n        Usage: C{dialog.save_file(title=\"Save As\", initialDir=\"~\", fileTypes=\"*|All Files\", rememberAs=None, **kwargs)}\n        \n        @param title: window title for the dialog\n        @param initialDir: starting directory for the file dialog\n        @param fileTypes: file type filter expression\n        @param rememberAs: gives an ID to this file dialog, allowing it to open at the last used path next time\n        @return: a tuple containing the exit code and file path\n        @rtype: C{DialogData(int, str)}\n        \"\"\"\n        if rememberAs is not None:\n            return self._run_kdialog(title, [\"--getsavefilename\", initialDir, fileTypes, \":\" + rememberAs], kwargs)\n        else:\n            return self._run_kdialog(title, [\"--getsavefilename\", initialDir, fileTypes], kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nshow a Directory Chooser dialog", "response": "def choose_directory(self, title=\"Select Directory\", initialDir=\"~\", rememberAs=None, **kwargs):\n        \"\"\"\n        Show a Directory Chooser dialog\n        \n        Usage: C{dialog.choose_directory(title=\"Select Directory\", initialDir=\"~\", rememberAs=None, **kwargs)}\n        \n        @param title: window title for the dialog\n        @param initialDir: starting directory for the directory chooser dialog\n        @param rememberAs: gives an ID to this file dialog, allowing it to open at the last used path next time\n        @return: a tuple containing the exit code and chosen path\n        @rtype: C{DialogData(int, str)}\n        \"\"\"\n        if rememberAs is not None:\n            return self._run_kdialog(title, [\"--getexistingdirectory\", initialDir, \":\" + rememberAs], kwargs)\n        else:\n            return self._run_kdialog(title, [\"--getexistingdirectory\", initialDir], kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef choose_colour(self, title=\"Select Colour\", **kwargs):\n        return_data = self._run_kdialog(title, [\"--getcolor\"], kwargs)\n        if return_data.successful:\n            return DialogData(return_data.return_code, ColourData.from_html(return_data.data))\n        else:\n            return DialogData(return_data.return_code, None)", "response": "Show a Colour Chooser dialog"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nshowing a calendar dialog", "response": "def calendar(self, title=\"Choose a date\", format_str=\"%Y-%m-%d\", date=\"today\", **kwargs):\n        \"\"\"\n        Show a calendar dialog\n\n        Usage: C{dialog.calendar_dialog(title=\"Choose a date\", format=\"%Y-%m-%d\", date=\"YYYY-MM-DD\", **kwargs)}\n\n        Note: the format and date parameters are not currently used\n\n        @param title: window title for the dialog\n        @param format_str: format of date to be returned\n        @param date: initial date as YYYY-MM-DD, otherwise today\n        @return: a tuple containing the exit code and date\n        @rtype: C{DialogData(int, str)}\n        \"\"\"\n        return self._run_kdialog(title, [\"--calendar\", title], kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nexecutes a shell command and return the output of the command.", "response": "def exec_command(self, command, getOutput=True):\n        \"\"\"\n        Execute a shell command\n        \n        Usage: C{system.exec_command(command, getOutput=True)}\n\n        Set getOutput to False if the command does not exit and return immediately. Otherwise\n        AutoKey will not respond to any hotkeys/abbreviations etc until the process started\n        by the command exits.\n        \n        @param command: command to be executed (including any arguments) - e.g. \"ls -l\"\n        @param getOutput: whether to capture the (stdout) output of the command\n        @raise subprocess.CalledProcessError: if the command returns a non-zero exit code\n        \"\"\"\n        if getOutput:\n            with subprocess.Popen(\n                    command,\n                    shell=True,\n                    bufsize=-1,\n                    stdout=subprocess.PIPE,\n                    universal_newlines=True) as p:\n                output = p.communicate()[0][:-1]  # Drop the trailing newline character\n                if p.returncode:\n                    raise subprocess.CalledProcessError(p.returncode, output)\n                return output\n        else:\n            subprocess.Popen(command, shell=True, bufsize=-1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a file with contents", "response": "def create_file(self, fileName, contents=\"\"):\n        \"\"\"\n        Create a file with contents\n        \n        Usage: C{system.create_file(fileName, contents=\"\")}\n        \n        @param fileName: full path to the file to be created\n        @param contents: contents to insert into the file\n        \"\"\"\n        with open(fileName, \"w\") as written_file:\n            written_file.write(contents)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef info_dialog(self, title=\"Information\", message=\"\", **kwargs):\n        return self._run_zenity(title, [\"--info\", \"--text\", message], kwargs)", "response": "Show an information dialog"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nshowing an input dialog", "response": "def input_dialog(self, title=\"Enter a value\", message=\"Enter a value\", default=\"\", **kwargs):\n        \"\"\"\n        Show an input dialog\n        \n        Usage: C{dialog.input_dialog(title=\"Enter a value\", message=\"Enter a value\", default=\"\", **kwargs)}\n        \n        @param title: window title for the dialog\n        @param message: message displayed above the input box\n        @param default: default value for the input box\n        @return: a tuple containing the exit code and user input\n        @rtype: C{DialogData(int, str)}\n        \"\"\"\n        return self._run_zenity(title, [\"--entry\", \"--text\", message, \"--entry-text\", default], kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndisplaying a password input dialog", "response": "def password_dialog(self, title=\"Enter password\", message=\"Enter password\", **kwargs):\n        \"\"\"\n        Show a password input dialog\n        \n        Usage: C{dialog.password_dialog(title=\"Enter password\", message=\"Enter password\")}\n        \n        @param title: window title for the dialog\n        @param message: message displayed above the password input box\n        @return: a tuple containing the exit code and user input\n        @rtype: C{DialogData(int, str)}\n        \"\"\"\n        return self._run_zenity(title, [\"--entry\", \"--text\", message, \"--hide-text\"], kwargs)\n        \n    #def combo_menu(self, options, title=\"Choose an option\", message=\"Choose an option\"):\n        \"\"\"\n        Show a combobox menu - not supported by zenity\n        \n        Usage: C{dialog.combo_menu(options, title=\"Choose an option\", message=\"Choose an option\")}\n        \n        @param options: list of options (strings) for the dialog\n        @param title: window title for the dialog\n        @param message: message displayed above the combobox      \n        \"\"\""}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nshows a single - selection list menu", "response": "def list_menu(self, options, title=\"Choose a value\", message=\"Choose a value\", default=None, **kwargs):\n        \"\"\"\n        Show a single-selection list menu\n        \n        Usage: C{dialog.list_menu(options, title=\"Choose a value\", message=\"Choose a value\", default=None, **kwargs)}\n        \n        @param options: list of options (strings) for the dialog\n        @param title: window title for the dialog\n        @param message: message displayed above the list\n        @param default: default value to be selected\n        @return: a tuple containing the exit code and user choice\n        @rtype: C{DialogData(int, str)}\n        \"\"\"\n        \n        choices = []\n        for option in options:\n            if option == default:\n                choices.append(\"TRUE\")\n            else:\n                choices.append(\"FALSE\")\n                \n            choices.append(option)\n\n        return self._run_zenity(\n            title,\n            [\"--list\", \"--radiolist\", \"--text\", message, \"--column\", \" \", \"--column\", \"Options\"] + choices,\n            kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef list_menu_multi(self, options, title=\"Choose one or more values\", message=\"Choose one or more values\",\n                        defaults: list=None, **kwargs):\n        \"\"\"\n        Show a multiple-selection list menu\n        \n        Usage: C{dialog.list_menu_multi(options, title=\"Choose one or more values\", message=\"Choose one or more values\", defaults=[], **kwargs)}\n        \n        @param options: list of options (strings) for the dialog\n        @param title: window title for the dialog\n        @param message: message displayed above the list\n        @param defaults: list of default values to be selected\n        @return: a tuple containing the exit code and user choice\n        @rtype: C{DialogData(int, List[str])}\n        \"\"\"\n\n        if defaults is None:\n            defaults = []\n        choices = []\n        for option in options:\n            if option in defaults:\n                choices.append(\"TRUE\")\n            else:\n                choices.append(\"FALSE\")\n                \n            choices.append(option)\n        return_code, output = self._run_zenity(\n            title,\n            [\"--list\", \"--checklist\", \"--text\", message, \"--column\", \" \", \"--column\", \"Options\"] + choices,\n            kwargs)\n        results = output.split('|')\n\n        return DialogData(return_code, results)", "response": "Show a multiple - selection list menu for a set of options"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nshows a Colour Chooser dialog", "response": "def choose_colour(self, title=\"Select Colour\", **kwargs):\n        \"\"\"\n        Show a Colour Chooser dialog\n        \n        Usage: C{dialog.choose_colour(title=\"Select Colour\")}\n        \n        @param title: window title for the dialog\n        @return:\n        @rtype: C{DialogData(int, Optional[ColourData])}\n        \"\"\"\n        return_data = self._run_zenity(title, [\"--color-selection\"], kwargs)\n        if return_data.successful:\n            converted_colour = ColourData.from_zenity_tuple_str(return_data.data)\n            return DialogData(return_data.return_code, converted_colour)\n        else:\n            return DialogData(return_data.return_code, None)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nshowing a calendar dialog", "response": "def calendar(self, title=\"Choose a date\", format_str=\"%Y-%m-%d\", date=\"today\", **kwargs):\n        \"\"\"\n        Show a calendar dialog\n        \n        Usage: C{dialog.calendar_dialog(title=\"Choose a date\", format=\"%Y-%m-%d\", date=\"YYYY-MM-DD\", **kwargs)}\n        \n        @param title: window title for the dialog\n        @param format_str: format of date to be returned\n        @param date: initial date as YYYY-MM-DD, otherwise today\n        @return: a tuple containing the exit code and date\n        @rtype: C{DialogData(int, str)}\n        \"\"\"\n        if re.match(r\"[0-9]{4}-[0-9]{2}-[0-9]{2}\", date):\n            year = date[0:4]\n            month = date[5:7]\n            day = date[8:10]\n            date_args = [\"--year=\" + year, \"--month=\" + month, \"--day=\" + day]\n        else:\n            date_args = []\n        return self._run_zenity(title, [\"--calendar\", \"--date-format=\" + format_str] + date_args, kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread the current text from the X selection", "response": "def get_selection(self):\n        \"\"\"\n        Read text from the X selection\n        \n        Usage: C{clipboard.get_selection()}\n\n        @return: text contents of the mouse selection\n        @rtype: C{str}\n        @raise Exception: if no text was found in the selection\n        \"\"\"\n        Gdk.threads_enter()\n        text = self.selection.wait_for_text()\n        Gdk.threads_leave()\n        if text is not None:\n            return text\n        else:\n            raise Exception(\"No text found in X selection\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fill_clipboard(self, contents):\n        Gdk.threads_enter()\n        if Gtk.get_major_version() >= 3:\n            self.clipBoard.set_text(contents, -1)\n        else:\n            self.clipBoard.set_text(contents)\n        Gdk.threads_leave()", "response": "Fill the clipboard with the contents"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads text from the clipboard and return it as a string", "response": "def get_clipboard(self):\n        \"\"\"\n        Read text from the clipboard\n        \n        Usage: C{clipboard.get_clipboard()}\n\n        @return: text contents of the clipboard\n        @rtype: C{str}\n        @raise Exception: if no text was found on the clipboard\n        \"\"\"\n        Gdk.threads_enter()\n        text = self.clipBoard.wait_for_text()\n        Gdk.threads_leave()\n        if text is not None:\n            return text\n        else:\n            raise Exception(\"No text found on clipboard\")"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwaiting for the given title to have focus.", "response": "def wait_for_focus(self, title, timeOut=5):\n        \"\"\"\n        Wait for window with the given title to have focus\n        \n        Usage: C{window.wait_for_focus(title, timeOut=5)}\n        \n        If the window becomes active, returns True. Otherwise, returns False if\n        the window has not become active by the time the timeout has elapsed.\n        \n        @param title: title to match against (as a regular expression)\n        @param timeOut: period (seconds) to wait before giving up\n        @rtype: boolean\n        \"\"\"\n        regex = re.compile(title)\n        waited = 0\n        while waited <= timeOut:\n            if regex.match(self.mediator.interface.get_window_title()):\n                return True\n            \n            if timeOut == 0:\n                break  # zero length timeout, if not matched go straight to end\n                \n            time.sleep(0.3)\n            waited += 0.3\n            \n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef wait_for_exist(self, title, timeOut=5):\n        regex = re.compile(title)\n        waited = 0\n        while waited <= timeOut:\n            retCode, output = self._run_wmctrl([\"-l\"])\n            for line in output.split('\\n'):\n                if regex.match(line[14:].split(' ', 1)[-1]):\n                    return True\n                    \n            if timeOut == 0:\n                break  # zero length timeout, if not matched go straight to end\n\n            time.sleep(0.3)\n            waited += 0.3\n            \n        return False", "response": "Wait for a window with the given title to be created. Returns True if the window is in existence False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef activate(self, title, switchDesktop=False, matchClass=False):\n        if switchDesktop:\n            args = [\"-a\", title]\n        else:\n            args = [\"-R\", title]\n        if matchClass:\n            args += [\"-x\"]\n        self._run_wmctrl(args)", "response": "Activate the specified window giving it input focus"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nclose the specified window gracefully", "response": "def close(self, title, matchClass=False):\n        \"\"\"\n        Close the specified window gracefully\n        \n        Usage: C{window.close(title, matchClass=False)}\n        \n        @param title: window title to match against (as case-insensitive substring match)\n        @param matchClass: if True, match on the window class instead of the title\n        \"\"\"\n        if matchClass:\n            self._run_wmctrl([\"-c\", title, \"-x\"])\n        else:\n            self._run_wmctrl([\"-c\", title])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef resize_move(self, title, xOrigin=-1, yOrigin=-1, width=-1, height=-1, matchClass=False):\n        mvArgs = [\"0\", str(xOrigin), str(yOrigin), str(width), str(height)]\n        if matchClass:\n            xArgs = [\"-x\"]\n        else:\n            xArgs = []\n        self._run_wmctrl([\"-r\", title, \"-e\", ','.join(mvArgs)] + xArgs)", "response": "Resize and or move the specified window"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmove the specified window to the given desktop", "response": "def move_to_desktop(self, title, deskNum, matchClass=False):\n        \"\"\"\n        Move the specified window to the given desktop\n        \n        Usage: C{window.move_to_desktop(title, deskNum, matchClass=False)}\n        \n        @param title: window title to match against (as case-insensitive substring match)\n        @param deskNum: desktop to move the window to (note: zero based)\n        @param matchClass: if True, match on the window class instead of the title\n        \"\"\"\n        if matchClass:\n            xArgs = [\"-x\"]\n        else:\n            xArgs = []\n        self._run_wmctrl([\"-r\", title, \"-t\", str(deskNum)] + xArgs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_property(self, title, action, prop, matchClass=False):\n        if matchClass:\n            xArgs = [\"-x\"]\n        else:\n            xArgs = []\n        self._run_wmctrl([\"-r\", title, \"-b\" + action + ',' + prop] + xArgs)", "response": "Set a property on the given window using the specified action"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_active_geometry(self):\n        active = self.mediator.interface.get_window_title()\n        result, output = self._run_wmctrl([\"-l\", \"-G\"])\n        matchingLine = None\n        for line in output.split('\\n'):\n            if active in line[34:].split(' ', 1)[-1]:\n                matchingLine = line\n                \n        if matchingLine is not None:\n            output = matchingLine.split()[2:6]\n            # return [int(x) for x in output]\n            return list(map(int, output))\n        else:\n            return None", "response": "Get the geometry of the currently active window."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_folder(self, title):\n        for folder in self.configManager.allFolders:\n            if folder.title == title:\n                return folder\n        return None", "response": "Retrieve a folder by its title"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_phrase(self, folder, description, contents):\n        self.monitor.suspend()\n        p = model.Phrase(description, contents)\n        folder.add_item(p)\n        p.persist()\n        self.monitor.unsuspend()\n        self.configManager.config_altered(False)", "response": "Create a new phrase in the specified folder"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a text abbreviation in the given folder.", "response": "def create_abbreviation(self, folder, description, abbr, contents):\n        \"\"\"\n        Create a text abbreviation\n        \n        Usage: C{engine.create_abbreviation(folder, description, abbr, contents)}\n        \n        When the given abbreviation is typed, it will be replaced with the given\n        text.\n        \n        @param folder: folder to place the abbreviation in, retrieved using C{engine.get_folder()}\n        @param description: description for the phrase\n        @param abbr: the abbreviation that will trigger the expansion\n        @param contents: the expansion text\n        @raise Exception: if the specified abbreviation is not unique\n        \"\"\"\n        if not self.configManager.check_abbreviation_unique(abbr, None, None):\n            raise Exception(\"The specified abbreviation is already in use\")\n        \n        self.monitor.suspend()\n        p = model.Phrase(description, contents)\n        p.modes.append(model.TriggerMode.ABBREVIATION)\n        p.abbreviations = [abbr]\n        folder.add_item(p)\n        p.persist()\n        self.monitor.unsuspend()\n        self.configManager.config_altered(False)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_hotkey(self, folder, description, modifiers, key, contents):\n        modifiers.sort()\n        if not self.configManager.check_hotkey_unique(modifiers, key, None, None):\n            raise Exception(\"The specified hotkey and modifier combination is already in use\")\n        \n        self.monitor.suspend()\n        p = model.Phrase(description, contents)\n        p.modes.append(model.TriggerMode.HOTKEY)\n        p.set_hotkey(modifiers, key)\n        folder.add_item(p)\n        p.persist()\n        self.monitor.unsuspend()\n        self.configManager.config_altered(False)", "response": "Create a text hotkey in the given folder."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrun an existing script using its description to look it up", "response": "def run_script(self, description):\n        \"\"\"\n        Run an existing script using its description to look it up\n        \n        Usage: C{engine.run_script(description)}\n        \n        @param description: description of the script to run\n        @raise Exception: if the specified script does not exist\n        \"\"\"\n        targetScript = None\n        for item in self.configManager.allItems:\n            if item.description == description and isinstance(item, model.Script):\n                targetScript = item\n\n        if targetScript is not None:\n            self.runner.run_subscript(targetScript)\n        else:\n            raise Exception(\"No script with description '%s' found\" % description)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run_script_from_macro(self, args):\n        self.__macroArgs = args[\"args\"].split(',')\n        \n        try:\n            self.run_script(args[\"name\"])\n        except Exception as e:\n            self.set_return_value(\"{ERROR: %s}\" % str(e))", "response": "This method runs the script from the macros passed in."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_ui_qfile(name: str):\n    file_path = RESOURCE_PATH_PREFIX + \"/ui/{ui_file_name}.ui\".format(ui_file_name=name)\n    file = QFile(file_path)\n    if not file.exists():\n        raise FileNotFoundError(\"UI file not found: \" + file_path)\n    file.open(QFile.ReadOnly)\n    return file", "response": "Returns an opened read - only QFile for the given QtDesigner UI file name. Expects a plain name like centralwidget."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load_ui_from_file(name: str):\n    ui_file = _get_ui_qfile(name)\n    try:\n        base_type = uic.loadUiType(ui_file, from_imports=True)\n    finally:\n        ui_file.close()\n    return base_type", "response": "Load the base type of the given name."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_png_dim(filepath: str) -> int:\n    if not imghdr.what(filepath) == 'png':\n        raise Exception(\"not PNG\")\n    head = open(filepath, 'rb').read(24)\n    return struct.unpack('!II', head[16:24])", "response": "Returns the dimension of a PNG file."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nclicks on a pattern.", "response": "def click_on_pat(pat: str, mousebutton: int=1, offset: (float, float)=None, tolerance: int=0, restore_pos: bool=False) -> None:\n    \"\"\"\n    Requires imagemagick, xautomation, xwd.\n    Click on a pattern at a specified offset (x,y) in percent of the pattern dimension. x is the horizontal distance from the top left corner, y is the vertical distance from the top left corner. By default, the offset is (50,50), which means that the center of the pattern will be clicked at.\n    Exception PatternNotFound is raised when the pattern is not found on the screen.\n    :param pat: path of pattern image (PNG) to click on.\n    :param mousebutton: mouse button number used for the click\n    :param offset: offset from the top left point of the match. (float,float)\n    :param tolerance: An integer \u2265 0 to specify the level of tolerance for 'fuzzy' matches. If negative or not convertible to int, raises ValueError.\n    :param restore_pos: return to the initial mouse position after the click.\n    \"\"\"\n    x0, y0 = mouse_pos()\n    move_to_pat(pat, offset, tolerance)\n    mouse_click(mousebutton)\n    if restore_pos:\n        mouse_move(x0, y0)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmoves the image to pat.", "response": "def move_to_pat(pat: str, offset: (float, float)=None, tolerance: int=0) -> None:\n    \"\"\"See help for click_on_pat\"\"\"\n    with tempfile.NamedTemporaryFile() as f:\n        subprocess.call('''\n        xwd -root -silent -display :0 | \n        convert xwd:- png:''' + f.name, shell=True)\n        loc = visgrep(f.name, pat, tolerance)\n    pat_size = get_png_dim(pat)\n    if offset is None:\n        x, y = [l + ps//2 for l, ps in zip(loc, pat_size)]\n    else:\n        x, y = [l + ps*(off/100) for off, l, ps in zip(offset, loc, pat_size)]\n    mouse_move(x, y)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef acknowledge_gnome_notification():\n    x0, y0 = mouse_pos()\n    mouse_move(10000, 10000)  # TODO: What if the screen is larger? Loop until mouse position does not change anymore?\n    x, y = mouse_pos()\n    mouse_rmove(-x/2, 0)\n    mouse_click(LEFT)\n    time.sleep(.2)\n    mouse_move(x0, y0)", "response": "Acknowledges the GNome notification."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndetermines extra keys pressed since the given buffer was built.", "response": "def calculate_extra_keys(self, buffer):\n        \"\"\"\n        Determine extra keys pressed since the given buffer was built\n        \"\"\"\n        extraBs = len(self.inputStack) - len(buffer)\n        if extraBs > 0:\n            extraKeys = ''.join(self.inputStack[len(buffer)])\n        else:\n            extraBs = 0\n            extraKeys = ''\n        return extraBs, extraKeys"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __updateStack(self, key):\n        #if self.lastMenu is not None:\n        #    if not ConfigManager.SETTINGS[MENU_TAKES_FOCUS]:\n        #        self.app.hide_menu()\n        #\n        #    self.lastMenu = None\n\n        if key == Key.ENTER:\n            # Special case - map Enter to \\n\n            key = '\\n'\n        if key == Key.TAB:\n            # Special case - map Tab to \\t\n            key = '\\t'\n\n        if key == Key.BACKSPACE:\n            if ConfigManager.SETTINGS[UNDO_USING_BACKSPACE] and self.phraseRunner.can_undo():\n                self.phraseRunner.undo_expansion()\n            else:\n                # handle backspace by dropping the last saved character\n                try:\n                    self.inputStack.pop()\n                except IndexError:\n                    # in case self.inputStack is empty\n                    pass\n\n            return False\n\n        elif len(key) > 1:\n            # non-simple key\n            self.inputStack.clear()\n            self.phraseRunner.clear_last()\n            return False\n        else:\n            # Key is a character\n            self.phraseRunner.clear_last()\n            # if len(self.inputStack) == MAX_STACK_LENGTH, front items will removed for appending new items.\n            self.inputStack.append(key)\n            return True", "response": "Update the input stack in non - hotkey mode and determine if anything is needed."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __checkTextMatches(self, folders, items, buffer, windowInfo, immediate=False):\n        itemMatches = []\n        folderMatches = []\n\n        for item in items:\n            if item.check_input(buffer, windowInfo):\n                if not item.prompt and immediate:\n                    return item, None\n                else:\n                    itemMatches.append(item)\n\n        for folder in folders:\n            if folder.check_input(buffer, windowInfo):\n                folderMatches.append(folder)\n                break # There should never be more than one folder match anyway\n\n        if self.__menuRequired(folderMatches, itemMatches, buffer):\n            self.lastStackState = buffer\n            #return (None, PopupMenu(self, folderMatches, itemMatches))\n            return None, (folderMatches, itemMatches)\n        elif len(itemMatches) == 1:\n            self.lastStackState = buffer\n            return itemMatches[0], None\n        else:\n            return None, None", "response": "Check for an abbreviation or predictive match among the given folder and items."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndetermine if the expansion contains any special keys.", "response": "def phrase_contains_special_keys(expansion: model.Expansion) -> bool:\n        \"\"\"\n        Determine if the expansion contains any special keys, including those resulting from any processed macros\n        (<script>, <file>, etc). If any are found, the phrase cannot be undone.\n\n        Python Zen: \u00bbIn the face of ambiguity, refuse the temptation to guess.\u00ab\n        The question 'What does the phrase expansion \"<ctrl>+a<shift>+<insert>\" do?' cannot be answered. Because the key\n        bindings cannot be assumed to result in the actions \"select all text, then replace with clipboard content\",\n        the undo operation can not be performed. Thus always disable undo, when special keys are found.\n        \"\"\"\n        found_special_keys = KEY_FIND_RE.findall(expansion.string.lower())\n        return bool(found_special_keys)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngrab global and specific hotkeys in all open windows", "response": "def __grabHotkeys(self):\n        \"\"\"\n        Run during startup to grab global and specific hotkeys in all open windows\n        \"\"\"\n        c = self.app.configManager\n        hotkeys = c.hotKeys + c.hotKeyFolders\n\n        # Grab global hotkeys in root window\n        for item in c.globalHotkeys:\n            if item.enabled:\n                self.__enqueue(self.__grabHotkey, item.hotKey, item.modifiers, self.rootWindow)\n                if self.__needsMutterWorkaround(item):\n                    self.__enqueue(self.__grabRecurse, item, self.rootWindow, False)\n\n        # Grab hotkeys without a filter in root window\n        for item in hotkeys:\n            if item.get_applicable_regex() is None:\n                self.__enqueue(self.__grabHotkey, item.hotKey, item.modifiers, self.rootWindow)\n                if self.__needsMutterWorkaround(item):\n                    self.__enqueue(self.__grabRecurse, item, self.rootWindow, False)\n\n        self.__enqueue(self.__recurseTree, self.rootWindow, hotkeys)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __ungrabAllHotkeys(self):\n        c = self.app.configManager\n        hotkeys = c.hotKeys + c.hotKeyFolders\n\n        # Ungrab global hotkeys in root window, recursively\n        for item in c.globalHotkeys:\n            if item.enabled:\n                self.__ungrabHotkey(item.hotKey, item.modifiers, self.rootWindow)\n                if self.__needsMutterWorkaround(item):\n                    self.__ungrabRecurse(item, self.rootWindow, False)\n        \n        # Ungrab hotkeys without a filter in root window, recursively\n        for item in hotkeys:\n            if item.get_applicable_regex() is None:\n                self.__ungrabHotkey(item.hotKey, item.modifiers, self.rootWindow)\n                if self.__needsMutterWorkaround(item):\n                    self.__ungrabRecurse(item, self.rootWindow, False)\n                \n        self.__recurseTreeUngrab(self.rootWindow, hotkeys)", "response": "Ungrab all hotkeys in preparation for keymap change"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngrabs all hotkeys relevant to the window", "response": "def __grabHotkeysForWindow(self, window):\n        \"\"\"\n        Grab all hotkeys relevant to the window\n\n        Used when a new window is created\n        \"\"\"\n        c = self.app.configManager\n        hotkeys = c.hotKeys + c.hotKeyFolders\n        window_info = self.get_window_info(window)\n        for item in hotkeys:\n            if item.get_applicable_regex() is not None and item._should_trigger_window_title(window_info):\n                self.__enqueue(self.__grabHotkey, item.hotKey, item.modifiers, window)\n            elif self.__needsMutterWorkaround(item):\n                self.__enqueue(self.__grabHotkey, item.hotKey, item.modifiers, window)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __grabHotkey(self, key, modifiers, window):\n        logger.debug(\"Grabbing hotkey: %r %r\", modifiers, key)\n        try:\n            keycode = self.__lookupKeyCode(key)\n            mask = 0\n            for mod in modifiers:\n                mask |= self.modMasks[mod]\n\n            window.grab_key(keycode, mask, True, X.GrabModeAsync, X.GrabModeAsync)\n\n            if Key.NUMLOCK in self.modMasks:\n                window.grab_key(keycode, mask|self.modMasks[Key.NUMLOCK], True, X.GrabModeAsync, X.GrabModeAsync)\n\n            if Key.CAPSLOCK in self.modMasks:\n                window.grab_key(keycode, mask|self.modMasks[Key.CAPSLOCK], True, X.GrabModeAsync, X.GrabModeAsync)\n\n            if Key.CAPSLOCK in self.modMasks and Key.NUMLOCK in self.modMasks:\n                window.grab_key(keycode, mask|self.modMasks[Key.CAPSLOCK]|self.modMasks[Key.NUMLOCK], True, X.GrabModeAsync, X.GrabModeAsync)\n\n        except Exception as e:\n            logger.warning(\"Failed to grab hotkey %r %r: %s\", modifiers, key, str(e))", "response": "Grab a specific hotkey in the given window."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef grab_hotkey(self, item):\n        if item.get_applicable_regex() is None:\n            self.__enqueue(self.__grabHotkey, item.hotKey, item.modifiers, self.rootWindow)\n            if self.__needsMutterWorkaround(item):\n                self.__enqueue(self.__grabRecurse, item, self.rootWindow, False)\n        else:\n            self.__enqueue(self.__grabRecurse, item, self.rootWindow)", "response": "Grab a hotkey from the root window and all children of the root window."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef send_string_clipboard(self, string: str, paste_command: model.SendMode):\n        logger.debug(\"Sending string via clipboard: \" + string)\n        if common.USING_QT:\n            if paste_command is None:\n                self.__enqueue(self.app.exec_in_main, self._send_string_selection, string)\n            else:\n                self.__enqueue(self.app.exec_in_main, self._send_string_clipboard, string, paste_command)\n        else:\n            if paste_command is None:\n                self.__enqueue(self._send_string_selection, string)\n            else:\n                self.__enqueue(self._send_string_clipboard, string, paste_command)\n        logger.debug(\"Sending via clipboard enqueued.\")", "response": "Sends a string to the target application using the clipboard."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsends a string to the clipboard.", "response": "def _send_string_clipboard(self, string: str, paste_command: model.SendMode):\n        \"\"\"\n        Use the clipboard to send a string.\n        \"\"\"\n        backup = self.clipboard.text  # Keep a backup of current content, to restore the original afterwards.\n        if backup is None:\n            logger.warning(\"Tried to backup the X clipboard content, but got None instead of a string.\")\n        self.clipboard.text = string\n        try:\n            self.mediator.send_string(paste_command.value)\n        finally:\n            self.ungrab_keyboard()\n        # Because send_string is queued, also enqueue the clipboard restore, to keep the proper action ordering.\n        self.__enqueue(self._restore_clipboard_text, backup)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _restore_clipboard_text(self, backup: str):\n        # Pasting takes some time, so wait a bit before restoring the content. Otherwise the restore is done before\n        # the pasting happens, causing the backup to be pasted instead of the desired clipboard content.\n        time.sleep(0.2)\n        self.clipboard.text = backup if backup is not None else \"\"", "response": "Restore the clipboard content."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _send_string_selection(self, string: str):\n        backup = self.clipboard.selection  # Keep a backup of current content, to restore the original afterwards.\n        if backup is None:\n            logger.warning(\"Tried to backup the X PRIMARY selection content, but got None instead of a string.\")\n        self.clipboard.selection = string\n        self.__enqueue(self._paste_using_mouse_button_2)\n        self.__enqueue(self._restore_clipboard_selection, backup)", "response": "Use the mouse selection clipboard to send a string."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _restore_clipboard_selection(self, backup: str):\n        # Pasting takes some time, so wait a bit before restoring the content. Otherwise the restore is done before\n        # the pasting happens, causing the backup to be pasted instead of the desired clipboard content.\n\n        # Programmatically pressing the middle mouse button seems VERY slow, so wait rather long.\n        # It might be a good idea to make this delay configurable. There might be systems that need even longer.\n        time.sleep(1)\n        self.clipboard.selection = backup if backup is not None else \"\"", "response": "Restore the selection clipboard content."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\npaste using the mouse button 2.", "response": "def _paste_using_mouse_button_2(self):\n        \"\"\"Paste using the mouse: Press the second mouse button, then release it again.\"\"\"\n        focus = self.localDisplay.get_input_focus().focus\n        xtest.fake_input(focus, X.ButtonPress, X.Button2)\n        xtest.fake_input(focus, X.ButtonRelease, X.Button2)\n        logger.debug(\"Mouse Button2 event sent.\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __sendString(self, string):\n        logger.debug(\"Sending string: %r\", string)\n        # Determine if workaround is needed\n        if not cm.ConfigManager.SETTINGS[cm.ENABLE_QT4_WORKAROUND]:\n            self.__checkWorkaroundNeeded()\n\n        # First find out if any chars need remapping\n        remapNeeded = False\n        for char in string:\n            keyCodeList = self.localDisplay.keysym_to_keycodes(ord(char))\n            usableCode, offset = self.__findUsableKeycode(keyCodeList)\n            if usableCode is None and char not in self.remappedChars:\n                remapNeeded = True\n                break\n\n        # Now we know chars need remapping, do it\n        if remapNeeded:\n            self.__ignoreRemap = True\n            self.remappedChars = {}\n            remapChars = []\n\n            for char in string:\n                keyCodeList = self.localDisplay.keysym_to_keycodes(ord(char))\n                usableCode, offset = self.__findUsableKeycode(keyCodeList)\n                if usableCode is None:\n                    remapChars.append(char)\n\n            logger.debug(\"Characters requiring remapping: %r\", remapChars)\n            availCodes = self.__availableKeycodes\n            logger.debug(\"Remapping with keycodes in the range: %r\", availCodes)\n            mapping = self.localDisplay.get_keyboard_mapping(8, 200)\n            firstCode = 8\n\n            for i in range(len(availCodes) - 1):\n                code = availCodes[i]\n                sym1 = 0\n                sym2 = 0\n\n                if len(remapChars) > 0:\n                    char = remapChars.pop(0)\n                    self.remappedChars[char] = (code, 0)\n                    sym1 = ord(char)\n                if len(remapChars) > 0:\n                    char = remapChars.pop(0)\n                    self.remappedChars[char] = (code, 1)\n                    sym2 = ord(char)\n\n                if sym1 != 0:\n                    mapping[code - firstCode][0] = sym1\n                    mapping[code - firstCode][1] = sym2\n\n            mapping = [tuple(l) for l in mapping]\n            self.localDisplay.change_keyboard_mapping(firstCode, mapping)\n            self.localDisplay.flush()\n\n        focus = self.localDisplay.get_input_focus().focus\n\n        for char in string:\n            try:\n                keyCodeList = self.localDisplay.keysym_to_keycodes(ord(char))\n                keyCode, offset = self.__findUsableKeycode(keyCodeList)\n                if keyCode is not None:\n                    if offset == 0:\n                        self.__sendKeyCode(keyCode, theWindow=focus)\n                    if offset == 1:\n                        self.__pressKey(Key.SHIFT)\n                        self.__sendKeyCode(keyCode, self.modMasks[Key.SHIFT], focus)\n                        self.__releaseKey(Key.SHIFT)\n                    if offset == 4:\n                        self.__pressKey(Key.ALT_GR)\n                        self.__sendKeyCode(keyCode, self.modMasks[Key.ALT_GR], focus)\n                        self.__releaseKey(Key.ALT_GR)\n                    if offset == 5:\n                        self.__pressKey(Key.ALT_GR)\n                        self.__pressKey(Key.SHIFT)\n                        self.__sendKeyCode(keyCode, self.modMasks[Key.ALT_GR]|self.modMasks[Key.SHIFT], focus)\n                        self.__releaseKey(Key.SHIFT)\n                        self.__releaseKey(Key.ALT_GR)\n\n                elif char in self.remappedChars:\n                    keyCode, offset = self.remappedChars[char]\n                    if offset == 0:\n                        self.__sendKeyCode(keyCode, theWindow=focus)\n                    if offset == 1:\n                        self.__pressKey(Key.SHIFT)\n                        self.__sendKeyCode(keyCode, self.modMasks[Key.SHIFT], focus)\n                        self.__releaseKey(Key.SHIFT)\n                else:\n                    logger.warning(\"Unable to send character %r\", char)\n            except Exception as e:\n                logger.exception(\"Error sending char %r: %s\", char, str(e))\n\n        self.__ignoreRemap = False", "response": "Send a string of printable characters."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef send_modified_key(self, keyName, modifiers):\n        self.__enqueue(self.__sendModifiedKey, keyName, modifiers)", "response": "Send a modified key to the local cache."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if the given keyCode is a modifier key and returns the modifier nameCJK.", "response": "def __decodeModifier(self, keyCode):\n        \"\"\"\n        Checks if the given keyCode is a modifier key. If it is, returns the modifier name\n        constant as defined in the iomediator module. If not, returns C{None}\n        \"\"\"\n        keyName = self.lookup_string(keyCode, False, False, False)\n        if keyName in MODIFIERS:\n            return keyName\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a WindowInfo object from the window title and WM_CLASS.", "response": "def _create_window_info(self, window, wm_title: str, wm_class: str):\n        \"\"\"\n        Creates a WindowInfo object from the window title and WM_CLASS.\n        Also checks for the Java XFocusProxyWindow workaround and applies it if needed:\n\n        Workaround for Java applications: Java AWT uses a XFocusProxyWindow class, so to get usable information,\n        the parent window needs to be queried. Credits: https://github.com/mooz/xkeysnail/pull/32\n        https://github.com/JetBrains/jdk8u_jdk/blob/master/src/solaris/classes/sun/awt/X11/XFocusProxyWindow.java#L35\n        \"\"\"\n        if \"FocusProxy\" in wm_class:\n            parent = window.query_tree().parent\n            # Discard both the already known wm_class and window title, because both are known to be wrong.\n            return self._get_window_info(parent, False)\n        else:\n            return WindowInfo(wm_title=wm_title, wm_class=wm_class)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef on_browse_button_pressed(self):\n        path = QFileDialog.getExistingDirectory(self.parentWidget(), \"Choose a directory containing Python modules\")\n\n        if path:  # Non-empty means the user chose a path and clicked on OK\n            self.path = path\n            self.clear_button.setEnabled(True)\n            self.folder_label.setText(path)\n            logger.debug(\"User selects a custom module search path: {}\".format(self.path))", "response": "Called when the user clicks the Browse button."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalling when the user hits the Clear button.", "response": "def on_clear_button_pressed(self):\n        \"\"\"\n        PyQt slot called when the user hits the \"Clear\" button.\n        Removes any set custom module search path.\n        \"\"\"\n        self.path = None\n        self.clear_button.setEnabled(False)\n        self.folder_label.setText(self.initial_folder_label_text)\n        logger.debug(\"User selects to clear the custom module search path.\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef quickvolshow(\n    data,\n    lighting=False,\n    data_min=None,\n    data_max=None,\n    max_shape=256,\n    level=[0.1, 0.5, 0.9],\n    opacity=[0.01, 0.05, 0.1],\n    level_width=0.1,\n    extent=None,\n    memorder='C',\n    **kwargs\n):\n    \"\"\"Visualize a 3d array using volume rendering.\n\n    :param data: 3d numpy array\n    :param lighting: boolean, to use lighting or not, if set to false, lighting parameters will be overriden\n    :param data_min: minimum value to consider for data, if None, computed using np.nanmin\n    :param data_max: maximum value to consider for data, if None, computed using np.nanmax\n    :param int max_shape: maximum shape for the 3d cube, if larger, the data is reduced by skipping/slicing (data[::N]),\n                          set to None to disable.\n    :param extent: list of [[xmin, xmax], [ymin, ymax], [zmin, zmax]] values that define the bounds of the volume,\n                   otherwise the viewport is used\n    :param level: level(s) for the where the opacity in the volume peaks, maximum sequence of length 3\n    :param opacity: opacity(ies) for each level, scalar or sequence of max length 3\n    :param level_width: width of the (gaussian) bumps where the opacity peaks, scalar or sequence of max length 3\n    :param kwargs: extra argument passed to Volume and default transfer function\n    :return:\n\n    \"\"\"\n    ipv.figure()\n    ipv.volshow(\n        data,\n        lighting=lighting,\n        data_min=data_min,\n        data_max=data_max,\n        max_shape=max_shape,\n        level=level,\n        opacity=opacity,\n        level_width=level_width,\n        extent=extent,\n        memorder=memorder,\n        **kwargs\n    )\n    return ipv.gcc()", "response": "Visualize a 3d array using volume rendering."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nshow a spherical harmonic.", "response": "def example_ylm(m=0, n=2, shape=128, limits=[-4, 4], draw=True, show=True, **kwargs):\n    \"\"\"Show a spherical harmonic.\"\"\"\n    import ipyvolume.pylab as p3\n\n    __, __, __, r, theta, phi = xyz(shape=shape, limits=limits, spherical=True)\n    radial = np.exp(-(r - 2) ** 2)\n    data = np.abs(scipy.special.sph_harm(m, n, theta, phi) ** 2) * radial  # pylint: disable=no-member\n    if draw:\n        vol = p3.volshow(data=data, **kwargs)\n        if show:\n            p3.show()\n        return vol\n    else:\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef klein_bottle(\n    draw=True,\n    show=True,\n    figure8=False,\n    endpoint=True,\n    uv=True,\n    wireframe=False,\n    texture=None,\n    both=False,\n    interval=1000,\n):\n    \"\"\"Show one or two Klein bottles.\"\"\"\n    import ipyvolume.pylab as p3\n\n    # http://paulbourke.net/geometry/klein/\n    u = np.linspace(0, 2 * pi, num=40, endpoint=endpoint)\n    v = np.linspace(0, 2 * pi, num=40, endpoint=endpoint)\n    u, v = np.meshgrid(u, v)\n    if both:\n        x1, y1, z1, _u1, _v1 = klein_bottle(endpoint=endpoint, draw=False, show=False)\n        x2, y2, z2, _u2, _v2 = klein_bottle(endpoint=endpoint, draw=False, show=False, figure8=True)\n        x = [x1, x2]\n        y = [y1, y2]\n        z = [z1, z2]\n    else:\n        if figure8:\n            # u -= np.pi\n            # v -= np.pi\n            a = 2\n            s = 5\n            x = s * (a + cos(u / 2) * sin(v) - sin(u / 2) * sin(2 * v) / 2) * cos(u)\n            y = s * (a + cos(u / 2) * sin(v) - sin(u / 2) * sin(2 * v) / 2) * sin(u)\n            z = s * (sin(u / 2) * sin(v) + cos(u / 2) * sin(2 * v) / 2)\n        else:\n            r = 4 * (1 - cos(u) / 2)\n            x = 6 * cos(u) * (1 + sin(u)) + r * cos(u) * cos(v) * (u < pi) + r * cos(v + pi) * (u >= pi)\n            y = 16 * sin(u) + r * sin(u) * cos(v) * (u < pi)\n            z = r * sin(v)\n    if draw:\n        if texture:\n            uv = True\n        if uv:\n            mesh = p3.plot_mesh(\n                x,\n                y,\n                z,\n                wrapx=not endpoint,\n                wrapy=not endpoint,\n                u=u / (2 * np.pi),\n                v=v / (2 * np.pi),\n                wireframe=wireframe,\n                texture=texture,\n            )\n        else:\n            mesh = p3.plot_mesh(x, y, z, wrapx=not endpoint, wrapy=not endpoint, wireframe=wireframe, texture=texture)\n        if show:\n            if both:\n                p3.animation_control(mesh, interval=interval)\n            p3.squarelim()\n            p3.show()\n        return mesh\n    else:\n        return x, y, z, u, v", "response": "Show one or two Klein bottles."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef brain(\n    draw=True, show=True, fiducial=True, flat=True, inflated=True, subject='S1', interval=1000, uv=True, color=None\n):\n    \"\"\"Show a human brain model.\n\n    Requirement:\n\n        $ pip install https://github.com/gallantlab/pycortex\n    \"\"\"\n    import ipyvolume as ipv\n\n    try:\n        import cortex\n    except:\n        warnings.warn(\"it seems pycortex is not installed, which is needed for this example\")\n        raise\n    xlist, ylist, zlist = [], [], []\n    polys_list = []\n\n    def add(pts, polys):\n        xlist.append(pts[:, 0])\n        ylist.append(pts[:, 1])\n        zlist.append(pts[:, 2])\n        polys_list.append(polys)\n\n    def n(x):\n        return (x - x.min()) / x.ptp()\n\n    if fiducial or color is True:\n        pts, polys = cortex.db.get_surf('S1', 'fiducial', merge=True)\n        x, y, z = pts.T\n        r = n(x)\n        g = n(y)\n        b = n(z)\n        if color is True:\n            color = np.array([r, g, b]).T.copy()\n        else:\n            color = None\n        if fiducial:\n            add(pts, polys)\n    else:\n        if color is False:\n            color = None\n    if inflated:\n        add(*cortex.db.get_surf('S1', 'inflated', merge=True, nudge=True))\n    u = v = None\n    if flat or uv:\n        pts, polys = cortex.db.get_surf('S1', 'flat', merge=True, nudge=True)\n        x, y, z = pts.T\n        u = n(x)\n        v = n(y)\n        if flat:\n            add(pts, polys)\n\n    polys_list.sort(key=lambda x: len(x))\n    polys = polys_list[0]\n    if draw:\n        if color is None:\n            mesh = ipv.plot_trisurf(xlist, ylist, zlist, polys, u=u, v=v)\n        else:\n            mesh = ipv.plot_trisurf(xlist, ylist, zlist, polys, color=color, u=u, v=v)\n        if show:\n            if len(x) > 1:\n                ipv.animation_control(mesh, interval=interval)\n            ipv.squarelim()\n            ipv.show()\n        return mesh\n    else:\n        return xlist, ylist, zlist, polys", "response": "Show a human brain model."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nshow a volumetric rendering of a human male head.", "response": "def head(draw=True, show=True, max_shape=256):\n    \"\"\"Show a volumetric rendering of a human male head.\"\"\"\n    # inspired by http://graphicsrunner.blogspot.com/2009/01/volume-rendering-102-transfer-functions.html\n    import ipyvolume as ipv\n    from scipy.interpolate import interp1d\n\n    # First part is a simpler version of setting up the transfer function. Interpolation with higher order\n    # splines does not work well, the original must do sth different\n    colors = [[0.91, 0.7, 0.61, 0.0], [0.91, 0.7, 0.61, 80.0], [1.0, 1.0, 0.85, 82.0], [1.0, 1.0, 0.85, 256]]\n    x = np.array([k[-1] for k in colors])\n    rgb = np.array([k[:3] for k in colors])\n    N = 256\n    xnew = np.linspace(0, 256, N)\n    tf_data = np.zeros((N, 4))\n    kind = 'linear'\n    for channel in range(3):\n        f = interp1d(x, rgb[:, channel], kind=kind)\n        ynew = f(xnew)\n        tf_data[:, channel] = ynew\n    alphas = [[0, 0], [0, 40], [0.2, 60], [0.05, 63], [0, 80], [0.9, 82], [1.0, 256]]\n    x = np.array([k[1] * 1.0 for k in alphas])\n    y = np.array([k[0] * 1.0 for k in alphas])\n    f = interp1d(x, y, kind=kind)\n    ynew = f(xnew)\n    tf_data[:, 3] = ynew\n    tf = ipv.TransferFunction(rgba=tf_data.astype(np.float32))\n\n    head_data = ipv.datasets.head.fetch().data\n    if draw:\n        vol = ipv.volshow(head_data, tf=tf, max_shape=max_shape)\n        if show:\n            ipv.show()\n        return vol\n    else:\n        return head_data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef gaussian(N=1000, draw=True, show=True, seed=42, color=None, marker='sphere'):\n    import ipyvolume as ipv\n\n    rng = np.random.RandomState(seed)  # pylint: disable=no-member\n    x, y, z = rng.normal(size=(3, N))\n\n    if draw:\n        if color:\n            mesh = ipv.scatter(x, y, z, marker=marker, color=color)\n        else:\n            mesh = ipv.scatter(x, y, z, marker=marker)\n        if show:\n            # ipv.squarelim()\n            ipv.show()\n        return mesh\n    else:\n        return x, y, z", "response": "Show N random gaussian distributed points using a scatter plot."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef figure(\n    key=None,\n    width=400,\n    height=500,\n    lighting=True,\n    controls=True,\n    controls_vr=False,\n    controls_light=False,\n    debug=False,\n    **kwargs\n):\n    \"\"\"Create a new figure if no key is given, or return the figure associated with key.\n\n    :param key: Python object that identifies this figure\n    :param int width: pixel width of WebGL canvas\n    :param int height:  .. height ..\n    :param bool lighting: use lighting or not\n    :param bool controls: show controls or not\n    :param bool controls_vr: show controls for VR or not\n    :param bool debug: show debug buttons or not\n    :return: :any:`Figure`\n    \"\"\"\n    if key is not None and key in current.figures:\n        current.figure = current.figures[key]\n        current.container = current.containers[key]\n    elif isinstance(key, ipv.Figure) and key in current.figures.values():\n        key_index = list(current.figures.values()).index(key)\n        key = list(current.figures.keys())[key_index]\n        current.figure = current.figures[key]\n        current.container = current.containers[key]\n    else:\n        current.figure = ipv.Figure(width=width, height=height, **kwargs)\n        current.container = ipywidgets.VBox()\n        current.container.children = [current.figure]\n        if key is None:\n            key = uuid.uuid4().hex\n        current.figures[key] = current.figure\n        current.containers[key] = current.container\n        if controls:\n            # stereo = ipywidgets.ToggleButton(value=current.figure.stereo, description='stereo', icon='eye')\n            # l1 = ipywidgets.jslink((current.figure, 'stereo'), (stereo, 'value'))\n            # current.container.children += (ipywidgets.HBox([stereo, ]),)\n            pass  # stereo and fullscreen are now include in the js code (per view)\n        if controls_vr:\n            eye_separation = ipywidgets.FloatSlider(value=current.figure.eye_separation, min=-10, max=10, icon='eye')\n            ipywidgets.jslink((eye_separation, 'value'), (current.figure, 'eye_separation'))\n            current.container.children += (eye_separation,)\n        if controls_light:\n            globals()['controls_light']()\n        if debug:\n            show = ipywidgets.ToggleButtons(options=[\"Volume\", \"Back\", \"Front\", \"Coordinate\"])\n            current.container.children += (show,)\n            # ipywidgets.jslink((current.figure, 'show'), (show, 'value'))\n            traitlets.link((current.figure, 'show'), (show, 'value'))\n    return current.figure", "response": "Create a new figure if no key is given or return the figure associated with key."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting limits or all axis the same.", "response": "def xyzlim(vmin, vmax=None):\n    \"\"\"Set limits or all axis the same, if vmax not given, use [-vmin, vmin].\"\"\"\n    if vmax is None:\n        vmin, vmax = -vmin, vmin\n    xlim(vmin, vmax)\n    ylim(vmin, vmax)\n    zlim(vmin, vmax)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef squarelim():\n    fig = gcf()\n    xmin, xmax = fig.xlim\n    ymin, ymax = fig.ylim\n    zmin, zmax = fig.zlim\n    width = max([abs(xmax - xmin), abs(ymax - ymin), abs(zmax - zmin)])\n    xc = (xmin + xmax) / 2\n    yc = (ymin + ymax) / 2\n    zc = (zmin + zmax) / 2\n    xlim(xc - width / 2, xc + width / 2)\n    ylim(yc - width / 2, yc + width / 2)\n    zlim(zc - width / 2, zc + width / 2)", "response": "Set all axes with equal aspect ratio such that the space is square."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nplots a polygon or triangle mesh defined by a coordinate and triangle indices.", "response": "def plot_trisurf(x, y, z, triangles=None, lines=None, color=default_color, u=None, v=None, texture=None):\n    \"\"\"Draw a polygon/triangle mesh defined by a coordinate and triangle indices.\n\n    The following example plots a rectangle in the z==2 plane, consisting of 2 triangles:\n\n    >>> plot_trisurf([0, 0, 3., 3.], [0, 4., 0, 4.], 2,\n           triangles=[[0, 2, 3], [0, 3, 1]])\n\n    Note that the z value is constant, and thus not a list/array. For guidance, the triangles\n    refer to the vertices in this manner::\n\n        ^ ydir\n        |\n        2 3\n        0 1  ---> x dir\n\n    Note that if you want per face/triangle colors, you need to duplicate each vertex.\n\n\n    :param x: {x}\n    :param y: {y}\n    :param z: {z}\n    :param triangles: numpy array with indices referring to the vertices, defining the triangles, with shape (M, 3)\n    :param lines: numpy array with indices referring to the vertices, defining the lines, with shape (K, 2)\n    :param color: {color}\n    :param u: {u}\n    :param v: {v}\n    :param texture: {texture}\n    :return: :any:`Mesh`\n    \"\"\"\n    fig = gcf()\n    if triangles is not None:\n        triangles = np.array(triangles).astype(dtype=np.uint32)\n    if lines is not None:\n        lines = np.array(lines).astype(dtype=np.uint32)\n    mesh = ipv.Mesh(x=x, y=y, z=z, triangles=triangles, lines=lines, color=color, u=u, v=v, texture=texture)\n    _grow_limits(np.array(x).reshape(-1), np.array(y).reshape(-1), np.array(z).reshape(-1))\n    fig.meshes = fig.meshes + [mesh]\n    return mesh"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef plot_surface(x, y, z, color=default_color, wrapx=False, wrapy=False):\n    return plot_mesh(x, y, z, color=color, wrapx=wrapx, wrapy=wrapy, wireframe=False)", "response": "Draws a 2d surface in 3d defined by the 2d ordered arrays x y z."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef plot_wireframe(x, y, z, color=default_color, wrapx=False, wrapy=False):\n    return plot_mesh(x, y, z, color=color, wrapx=wrapx, wrapy=wrapy, wireframe=True, surface=False)", "response": "Draws a 2d wireframe in 3d defines by the 2d ordered arrays x y z."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef plot_mesh(\n    x, y, z, color=default_color, wireframe=True, surface=True, wrapx=False, wrapy=False, u=None, v=None, texture=None\n):\n    \"\"\"Draws a 2d wireframe+surface in 3d: generalization of :any:`plot_wireframe` and :any:`plot_surface`.\n\n    :param x: {x2d}\n    :param y: {y2d}\n    :param z: {z2d}\n    :param color: {color2d}\n    :param bool wireframe: draw lines between the vertices\n    :param bool surface: draw faces/triangles between the vertices\n    :param bool wrapx: when True, the x direction is assumed to wrap, and polygons are drawn between the begin and end points\n    :param boool wrapy: idem for y\n    :param u: {u}\n    :param v: {v}\n    :param texture: {texture}\n    :return: :any:`Mesh`\n    \"\"\"\n    fig = gcf()\n\n    # assert len(x.shape) == 2\n    # assert len(y.shape) == 2\n    # assert len(z.shape) == 2\n    # if isinstance(color, np.ndarray):\n    # \tassert len(color.shape) == 3\n    # \tassert color.shape[:2] == x.shape\n    # \tcolor = color.reshape(-1)\n\n    def dim(x):\n        d = 0\n        el = x\n        while True:\n            try:\n                el = el[0]\n                d += 1\n            except:\n                break\n        return d\n\n    if dim(x) == 2:\n        nx, ny = x.shape\n    else:\n        nx, ny = x[0].shape\n\n    # assert len(x.shape) == 2, \"Array x must be 2 dimensional.\"\n    # assert len(y.shape) == 2, \"Array y must be 2 dimensional.\"\n    # assert len(z.shape) == 2, \"Array z must be 2 dimensional.\"\n    # assert x.shape == y.shape, \"Arrays x and y must have same shape.\"\n    # assert y.shape == z.shape, \"Arrays y and z must have same shape.\"\n    # convert x, y, z from shape (nx, ny) to (nx * ny) or\n    # (frame, nx, ny) to (frame, nx*ny)\n    def reshape(ar):\n        if dim(ar) == 3:\n            return [k.reshape(-1) for k in ar]\n        else:\n            return ar.reshape(-1)\n\n    x = reshape(x)\n    y = reshape(y)\n    z = reshape(z)\n    # similar for texture coordinates\n    if u is not None:\n        u = reshape(u)\n    if v is not None:\n        v = reshape(v)\n\n    # convert color from shape (nx, ny, {3,4}) to (nx * ny, {3, 4}) or\n    # (frame, nx, ny, {3,4}) to (frame, nx*ny, {3,4})\n    def reshape_color(ar):\n        if dim(ar) == 4:\n            return [k.reshape(-1, k.shape[-1]) for k in ar]\n        else:\n            return ar.reshape(-1, ar.shape[-1])\n\n    if isinstance(color, np.ndarray):\n        color = reshape_color(color)\n\n    _grow_limits(np.array(x).reshape(-1), np.array(y).reshape(-1), np.array(z).reshape(-1))\n    triangles, lines = _make_triangles_lines((nx, ny), wrapx, wrapy)\n    mesh = ipv.Mesh(\n        x=x,\n        y=y,\n        z=z,\n        triangles=triangles if surface else None,\n        color=color,\n        lines=lines if wireframe else None,\n        u=u,\n        v=v,\n        texture=texture,\n    )\n    fig.meshes = fig.meshes + [mesh]\n    return mesh", "response": "Draws a 2d wireframe + surface in 3d generalization of plot_wireframe and plot_surface."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nplot a line in 3d.", "response": "def plot(x, y, z, color=default_color, **kwargs):\n    \"\"\"Plot a line in 3d.\n\n    :param x: {x}\n    :param y: {y}\n    :param z: {z}\n    :param color: {color}\n    :param kwargs: extra arguments passed to the Scatter constructor\n    :return: :any:`Scatter`\n    \"\"\"\n    fig = gcf()\n    _grow_limits(x, y, z)\n    defaults = dict(\n        visible_lines=True, color_selected=None, size_selected=1, size=1, connected=True, visible_markers=False\n    )\n    kwargs = dict(defaults, **kwargs)\n    s = ipv.Scatter(x=x, y=y, z=z, color=color, **kwargs)\n    s.material.visible = False\n    fig.scatters = fig.scatters + [s]\n    return s"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef scatter(\n    x,\n    y,\n    z,\n    color=default_color,\n    size=default_size,\n    size_selected=default_size_selected,\n    color_selected=default_color_selected,\n    marker=\"diamond\",\n    selection=None,\n    grow_limits=True,\n    **kwargs\n):\n    \"\"\"Plot many markers/symbols in 3d.\n\n    :param x: {x}\n    :param y: {y}\n    :param z: {z}\n    :param color: {color}\n    :param size: {size}\n    :param size_selected: like size, but for selected glyphs\n    :param color_selected:  like color, but for selected glyphs\n    :param marker: {marker}\n    :param selection: numpy array of shape (N,) or (S, N) with indices of x,y,z arrays of the selected markers, which\n                      can have a different size and color\n    :param kwargs:\n    :return: :any:`Scatter`\n    \"\"\"\n    fig = gcf()\n    if grow_limits:\n        _grow_limits(x, y, z)\n    s = ipv.Scatter(\n        x=x,\n        y=y,\n        z=z,\n        color=color,\n        size=size,\n        color_selected=color_selected,\n        size_selected=size_selected,\n        geo=marker,\n        selection=selection,\n        **kwargs\n    )\n    fig.scatters = fig.scatters + [s]\n    return s", "response": "Plot many markers or symbols in 3d."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a quiver plot for a single object.", "response": "def quiver(\n    x,\n    y,\n    z,\n    u,\n    v,\n    w,\n    size=default_size * 10,\n    size_selected=default_size_selected * 10,\n    color=default_color,\n    color_selected=default_color_selected,\n    marker=\"arrow\",\n    **kwargs\n):\n    \"\"\"Create a quiver plot, which is like a scatter plot but with arrows pointing in the direction given by u, v and w.\n\n    :param x: {x}\n    :param y: {y}\n    :param z: {z}\n    :param u: {u_dir}\n    :param v: {v_dir}\n    :param w: {w_dir}\n    :param size: {size}\n    :param size_selected: like size, but for selected glyphs\n    :param color: {color}\n    :param color_selected: like color, but for selected glyphs\n    :param marker: (currently only 'arrow' would make sense)\n    :param kwargs: extra arguments passed on to the Scatter constructor\n    :return: :any:`Scatter`\n    \"\"\"\n    fig = gcf()\n    _grow_limits(x, y, z)\n    if 'vx' in kwargs or 'vy' in kwargs or 'vz' in kwargs:\n        raise KeyError('Please use u, v, w instead of vx, vy, vz')\n    s = ipv.Scatter(\n        x=x,\n        y=y,\n        z=z,\n        vx=u,\n        vy=v,\n        vz=w,\n        color=color,\n        size=size,\n        color_selected=color_selected,\n        size_selected=size_selected,\n        geo=marker,\n        **kwargs\n    )\n    fig.scatters = fig.scatters + [s]\n    return s"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nanimates scatter or quiver or mesh control.", "response": "def animation_control(object, sequence_length=None, add=True, interval=200):\n    \"\"\"Animate scatter, quiver or mesh by adding a slider and play button.\n\n    :param object: :any:`Scatter` or :any:`Mesh` object (having an sequence_index property), or a list of these to\n                   control multiple.\n    :param sequence_length: If sequence_length is None we try try our best to figure out, in case we do it badly,\n            you can tell us what it should be. Should be equal to the S in the shape of the numpy arrays as for instance\n            documented in :any:`scatter` or :any:`plot_mesh`.\n    :param add: if True, add the widgets to the container, else return a HBox with the slider and play button. Useful when you\n            want to customise the layout of the widgets yourself.\n    :param interval: interval in msec between each frame\n    :return: If add is False, if returns the ipywidgets.HBox object containing the controls\n    \"\"\"\n    if isinstance(object, (list, tuple)):\n        objects = object\n    else:\n        objects = [object]\n    del object\n    if sequence_length is None:\n        # get all non-None arrays\n        sequence_lengths = []\n        for object in objects:\n            sequence_lengths_previous = list(sequence_lengths)\n            values = [getattr(object, name) for name in \"x y z vx vy vz\".split() if hasattr(object, name)]\n            values = [k for k in values if k is not None]\n            # sort them such that the higest dim is first\n            values.sort(key=lambda key: -len(key.shape))\n            try:\n                sequence_length = values[0].shape[0]  # assume this defines the sequence length\n                if isinstance(object, ipv.Mesh):  # for a mesh, it does not make sense to have less than 1 dimension\n                    if len(values[0].shape) >= 2:  # if just 1d, it is most likely not an animation\n                        sequence_lengths.append(sequence_length)\n                else:\n                    sequence_lengths.append(sequence_length)\n            except IndexError:  # scalars get ignored\n                pass\n            if hasattr(object, 'color'):\n                color = object.color\n                if color is not None:\n                    shape = color.shape\n                    if len(shape) == 3:  # would be the case for for (frame, point_index, color_index)\n                        sequence_lengths.append(shape[0])\n                    # TODO: maybe support arrays of string type of form (frame, point_index)\n            if len(sequence_lengths) == len(sequence_lengths_previous):\n                raise ValueError('no frame dimension found for object: {}'.format(object))\n        sequence_length = max(sequence_lengths)\n    fig = gcf()\n    fig.animation = interval\n    fig.animation_exponent = 1.0\n    play = ipywidgets.Play(min=0, max=sequence_length - 1, interval=interval, value=0, step=1)\n    slider = ipywidgets.FloatSlider(min=0, max=play.max, step=1)\n    ipywidgets.jslink((play, 'value'), (slider, 'value'))\n    for object in objects:\n        ipywidgets.jslink((slider, 'value'), (object, 'sequence_index'))\n    control = ipywidgets.HBox([play, slider])\n    if add:\n        current.container.children += (control,)\n    else:\n        return control"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a transfer function for a given taxonomy.", "response": "def transfer_function(\n    level=[0.1, 0.5, 0.9], opacity=[0.01, 0.05, 0.1], level_width=0.1, controls=True, max_opacity=0.2\n):\n    \"\"\"Create a transfer function, see volshow.\"\"\"\n    tf_kwargs = {}\n    # level, opacity and widths can be scalars\n    try:\n        level[0]\n    except:\n        level = [level]\n    try:\n        opacity[0]\n    except:\n        opacity = [opacity] * 3\n    try:\n        level_width[0]\n    except:\n        level_width = [level_width] * 3\n        # clip off lists\n    min_length = min(len(level), len(level_width), len(opacity))\n    level = list(level[:min_length])\n    opacity = list(opacity[:min_length])\n    level_width = list(level_width[:min_length])\n    # append with zeros\n    while len(level) < 3:\n        level.append(0)\n    while len(opacity) < 3:\n        opacity.append(0)\n    while len(level_width) < 3:\n        level_width.append(0)\n    for i in range(1, 4):\n        tf_kwargs[\"level\" + str(i)] = level[i - 1]\n        tf_kwargs[\"opacity\" + str(i)] = opacity[i - 1]\n        tf_kwargs[\"width\" + str(i)] = level_width[i - 1]\n    tf = ipv.TransferFunctionWidgetJs3(**tf_kwargs)\n    gcf()  # make sure a current container/figure exists\n    if controls:\n        current.container.children = (tf.control(max_opacity=max_opacity),) + current.container.children\n    return tf"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef plot_isosurface(data, level=None, color=default_color, wireframe=True, surface=True, controls=True, extent=None):\n    if level is None:\n        level = np.median(data)\n    if hasattr(skimage.measure, 'marching_cubes_lewiner'):\n        values = skimage.measure.marching_cubes_lewiner(data, level)\n    else:\n        values = skimage.measure.marching_cubes(data, level)  # pylint: disable=no-member\n    verts, triangles = values[:2]  # version 0.13 returns 4 values, normals, values\n    # in the future we may want to support normals and the values (with colormap)\n    # and require skimage >= 0.13\n    x, y, z = verts.T\n\n    # Rescale coordinates to given limits\n    if extent:\n        xlim, ylim, zlim = extent\n        x = x * np.diff(xlim) / (data.shape[0] - 1) + xlim[0]\n        y = y * np.diff(ylim) / (data.shape[1] - 1) + ylim[0]\n        z = z * np.diff(zlim) / (data.shape[2] - 1) + zlim[0]\n        _grow_limits(*extent)\n\n    mesh = plot_trisurf(x, y, z, triangles=triangles, color=color)\n    if controls:\n        vmin, vmax = np.percentile(data, 1), np.percentile(data, 99)\n        step = (vmax - vmin) / 250\n        level_slider = ipywidgets.FloatSlider(value=level, min=vmin, max=vmax, step=step, icon='eye')\n        recompute_button = ipywidgets.Button(description='update')\n        controls = ipywidgets.HBox(children=[level_slider, recompute_button])\n        current.container.children += (controls,)\n\n        def recompute(*_ignore):\n            level = level_slider.value\n            recompute_button.description = \"updating...\"\n            if hasattr(skimage.measure, 'marching_cubes_lewiner'):\n                values = skimage.measure.marching_cubes_lewiner(data, level)\n            else:\n                values = skimage.measure.marching_cubes(data, level)  # pylint: disable=no-member\n            verts, triangles = values[:2]  # version 0.13 returns 4 values, normals, values\n            # in the future we may want to support normals and the values (with colormap)\n            # and require skimage >= 0.13\n            x, y, z = verts.T\n            with mesh.hold_sync():\n                mesh.x = x\n                mesh.y = y\n                mesh.z = z\n                mesh.triangles = triangles.astype(dtype=np.uint32)\n                recompute_button.description = \"update\"\n\n        recompute_button.on_click(recompute)\n    return mesh", "response": "Plot a single isosurface at a given level."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nvisualize a 3d array using volume rendering.", "response": "def volshow(\n    data,\n    lighting=False,\n    data_min=None,\n    data_max=None,\n    max_shape=256,\n    tf=None,\n    stereo=False,\n    ambient_coefficient=0.5,\n    diffuse_coefficient=0.8,\n    specular_coefficient=0.5,\n    specular_exponent=5,\n    downscale=1,\n    level=[0.1, 0.5, 0.9],\n    opacity=[0.01, 0.05, 0.1],\n    level_width=0.1,\n    controls=True,\n    max_opacity=0.2,\n    memorder='C',\n    extent=None,\n):\n    \"\"\"Visualize a 3d array using volume rendering.\n\n    Currently only 1 volume can be rendered.\n\n\n    :param data: 3d numpy array\n    :param origin: origin of the volume data, this is to match meshes which have a different origin\n    :param domain_size: domain size is the size of the volume\n    :param bool lighting: use lighting or not, if set to false, lighting parameters will be overriden\n    :param float data_min: minimum value to consider for data, if None, computed using np.nanmin\n    :param float data_max: maximum value to consider for data, if None, computed using np.nanmax\n    :parap int max_shape: maximum shape for the 3d cube, if larger, the data is reduced by skipping/slicing (data[::N]),\n                          set to None to disable.\n    :param tf: transfer function (or a default one)\n    :param bool stereo: stereo view for virtual reality (cardboard and similar VR head mount)\n    :param ambient_coefficient: lighting parameter\n    :param diffuse_coefficient: lighting parameter\n    :param specular_coefficient: lighting parameter\n    :param specular_exponent: lighting parameter\n    :param float downscale: downscale the rendering for better performance, for instance when set to 2, a 512x512\n                            canvas will show a 256x256 rendering upscaled, but it will render twice as fast.\n    :param level: level(s) for the where the opacity in the volume peaks, maximum sequence of length 3\n    :param opacity: opacity(ies) for each level, scalar or sequence of max length 3\n    :param level_width: width of the (gaussian) bumps where the opacity peaks, scalar or sequence of max length 3\n    :param bool controls: add controls for lighting and transfer function or not\n    :param float max_opacity: maximum opacity for transfer function controls\n    :param extent: list of [[xmin, xmax], [ymin, ymax], [zmin, zmax]] values that define the bounds of the volume,\n                   otherwise the viewport is used\n    :return:\n    \"\"\"\n    fig = gcf()\n\n    if tf is None:\n        tf = transfer_function(level, opacity, level_width, controls=controls, max_opacity=max_opacity)\n    if data_min is None:\n        data_min = np.nanmin(data)\n    if data_max is None:\n        data_max = np.nanmax(data)\n    if memorder == 'F':\n        data = data.T\n\n    if extent is None:\n        extent = [(0, k) for k in data.shape[::-1]]\n\n    if extent:\n        _grow_limits(*extent)\n\n    vol = ipv.Volume(\n        data_original=data,\n        tf=tf,\n        data_min=data_min,\n        data_max=data_max,\n        show_min=data_min,\n        show_max=data_max,\n        extent_original=extent,\n        data_max_shape=max_shape,\n        ambient_coefficient=ambient_coefficient,\n        diffuse_coefficient=diffuse_coefficient,\n        specular_coefficient=specular_coefficient,\n        specular_exponent=specular_exponent,\n        rendering_lighting=lighting,\n    )\n\n    vol._listen_to(fig)\n\n    if controls:\n        widget_opacity_scale = ipywidgets.FloatLogSlider(base=10, min=-2, max=2, description=\"opacity\")\n        widget_brightness = ipywidgets.FloatLogSlider(base=10, min=-1, max=1, description=\"brightness\")\n        ipywidgets.jslink((vol, 'opacity_scale'), (widget_opacity_scale, 'value'))\n        ipywidgets.jslink((vol, 'brightness'), (widget_brightness, 'value'))\n        widgets_bottom = [ipywidgets.HBox([widget_opacity_scale, widget_brightness])]\n        current.container.children += tuple(widgets_bottom)\n\n    fig.volumes = fig.volumes + [vol]\n\n    return vol"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef save(\n    filepath,\n    makedirs=True,\n    title=u'IPyVolume Widget',\n    all_states=False,\n    offline=False,\n    scripts_path='js',\n    drop_defaults=False,\n    template_options=((\"extra_script_head\", \"\"), (\"body_pre\", \"\"), (\"body_post\", \"\")),\n    devmode=False,\n    offline_cors=False,\n):\n    \"\"\"Save the current container to a HTML file.\n\n    By default the HTML file is not standalone and requires an internet connection to fetch a few javascript\n    libraries. Use offline=True to download these and make the HTML file work without an internet connection.\n\n    :param str filepath: The file to write the HTML output to.\n    :param bool makedirs: whether to make directories in the filename path, if they do not already exist\n    :param str title: title for the html page\n    :param bool all_states: if True, the state of all widgets know to the widget manager is included, else only those in widgets\n    :param bool offline: if True, use local urls for required js/css packages and download all js/css required packages\n            (if not already available), such that the html can be viewed with no internet connection\n    :param str scripts_path: the folder to save required js/css packages to (relative to the filepath)\n    :param bool drop_defaults: Whether to drop default values from the widget states\n    :param template_options: list or dict of additional template options\n    :param bool devmode: if True, attempt to get index.js from local js/dist folder\n    :param bool offline_cors: if True, sets crossorigin attribute of script tags to anonymous\n\n    \"\"\"\n    ipyvolume.embed.embed_html(\n        filepath,\n        current.container,\n        makedirs=makedirs,\n        title=title,\n        all_states=all_states,\n        offline=offline,\n        scripts_path=scripts_path,\n        drop_defaults=drop_defaults,\n        template_options=template_options,\n        devmode=devmode,\n        offline_cors=offline_cors,\n    )", "response": "Save the current container to a HTML file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a movie from a movie. mp4 or gif file.", "response": "def movie(\n    f=\"movie.mp4\",\n    function=_change_azimuth_angle,\n    fps=30,\n    frames=30,\n    endpoint=False,\n    cmd_template_ffmpeg=\"ffmpeg -y -r {fps} -i {tempdir}/frame-%5d.png -vcodec h264 -pix_fmt yuv420p {filename}\",\n    cmd_template_gif=\"convert -delay {delay} {loop} {tempdir}/frame-*.png {filename}\",\n    gif_loop=0,\n):\n    \"\"\"Create a movie out of many frames in e.g. mp4 or gif format.\n\n    If the filename ends in `.gif`, `convert` is used to convert all frames to an animated gif using the `cmd_template_gif`\n    template. Otherwise `ffmpeg is assumed to know the file format`.\n\n    Example:\n\n    >>> def set_angles(fig, i, fraction):\n    >>>     fig.angley = fraction*np.pi*2\n    >>> # 4 second movie, that rotates around the y axis\n    >>> p3.movie('test2.gif', set_angles, fps=20, frames=20*4,\n            endpoint=False)\n\n    Note that in the example above we use `endpoint=False` to avoid to first and last frame to be the same\n\n    :param str f: filename out output movie (e.g. 'movie.mp4' or 'movie.gif')\n    :param function: function called before each frame with arguments (figure, framenr, fraction)\n    :param fps: frames per seconds\n    :param int frames: total number of frames\n    :param bool endpoint: if fraction goes from [0, 1] (inclusive) or [0, 1) (endpoint=False is useful for loops/rotatations)\n    :param str cmd_template_ffmpeg: template command when running ffmpeg (non-gif ending filenames)\n    :param str cmd_template_gif: template command when running imagemagick's convert (if filename ends in .gif)\n    :param gif_loop: None for no loop, otherwise the framenumber to go to after the last frame\n    :return: the temp dir where the frames are stored\n    \"\"\"\n    movie_filename = f\n    tempdir = tempfile.mkdtemp()\n    output = ipywidgets.Output()\n    display(output)\n    fig = gcf()\n    for i in range(frames):\n        with output:\n            fraction = i / (frames - 1.0 if endpoint else frames)\n            function(fig, i, fraction)\n            frame_filename = os.path.join(tempdir, \"frame-%05d.png\" % i)\n            savefig(frame_filename, output_widget=output)\n    with output:\n        if movie_filename.endswith(\".gif\"):\n            if gif_loop is None:\n                loop = \"\"\n            else:\n                loop = \"-loop %d\" % gif_loop\n            delay = 100 / fps\n            cmd = cmd_template_gif.format(delay=delay, loop=loop, tempdir=tempdir, filename=movie_filename)\n        else:\n            cmd = cmd_template_ffmpeg.format(fps=fps, tempdir=tempdir, filename=movie_filename)\n        print(cmd)\n        os.system(cmd)\n    return tempdir"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsave the current figure to a PIL. Image object.", "response": "def screenshot(\n    width=None,\n    height=None,\n    format=\"png\",\n    fig=None,\n    timeout_seconds=10,\n    output_widget=None,\n    headless=False,\n    devmode=False,\n):\n    \"\"\"Save the figure to a PIL.Image object.\n\n    :param int width: the width of the image in pixels\n    :param int height: the height of the image in pixels\n    :param format: format of output data (png, jpeg or svg)\n    :type fig: ipyvolume.widgets.Figure or None\n    :param fig: if None use the current figure\n    :type timeout_seconds: int\n    :param timeout_seconds: maximum time to wait for image data to return\n    :type output_widget: ipywidgets.Output\n    :param output_widget: a widget to use as a context manager for capturing the data\n    :param bool headless: if True, use headless chrome to take screenshot\n    :param bool devmode: if True, attempt to get index.js from local js/dist folder\n    :return: PIL.Image\n\n    \"\"\"\n    assert format in ['png', 'jpeg', 'svg'], \"image format must be png, jpeg or svg\"\n    data = _screenshot_data(\n        timeout_seconds=timeout_seconds,\n        output_widget=output_widget,\n        format=format,\n        width=width,\n        height=height,\n        fig=fig,\n        headless=headless,\n        devmode=devmode,\n    )\n    f = StringIO(data)\n    return PIL.Image.open(f)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef savefig(\n    filename, width=None, height=None, fig=None, timeout_seconds=10, output_widget=None, headless=False, devmode=False\n):\n    \"\"\"Save the figure to an image file.\n\n    :param str filename: must have extension .png, .jpeg or .svg\n    :param int width: the width of the image in pixels\n    :param int height: the height of the image in pixels\n    :type fig: ipyvolume.widgets.Figure or None\n    :param fig: if None use the current figure\n    :param float timeout_seconds: maximum time to wait for image data to return\n    :param ipywidgets.Output output_widget: a widget to use as a context manager for capturing the data\n    :param bool headless: if True, use headless chrome to save figure\n    :param bool devmode: if True, attempt to get index.js from local js/dist folder\n    \"\"\"\n    __, ext = os.path.splitext(filename)\n    format = ext[1:]\n    assert format in ['png', 'jpeg', 'svg'], \"image format must be png, jpeg or svg\"\n    with open(filename, \"wb\") as f:\n        f.write(\n            _screenshot_data(\n                timeout_seconds=timeout_seconds,\n                output_widget=output_widget,\n                format=format,\n                width=width,\n                height=height,\n                fig=fig,\n                headless=headless,\n                devmode=devmode,\n            )\n        )", "response": "Save the current figure to an image file."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets all labels at once.", "response": "def xyzlabel(labelx, labely, labelz):\n    \"\"\"Set all labels at once.\"\"\"\n    xlabel(labelx)\n    ylabel(labely)\n    zlabel(labelz)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset camera angles and distance and return the current.", "response": "def view(azimuth=None, elevation=None, distance=None):\n    \"\"\"Set camera angles and distance and return the current.\n\n    :param float azimuth: rotation around the axis pointing up in degrees\n    :param float elevation: rotation where +90 means 'up', -90 means 'down', in degrees\n    :param float distance: radial distance from the center to the camera.\n    \"\"\"\n    fig = gcf()\n    # first calculate the current values\n    x, y, z = fig.camera.position\n    r = np.sqrt(x ** 2 + y ** 2 + z ** 2)\n    az = np.degrees(np.arctan2(x, z))\n    el = np.degrees(np.arcsin(y / r))\n    if azimuth is None:\n        azimuth = az\n    if elevation is None:\n        elevation = el\n    if distance is None:\n        distance = r\n    cosaz = np.cos(np.radians(azimuth))\n    sinaz = np.sin(np.radians(azimuth))\n    sine = np.sin(np.radians(elevation))\n    cose = np.cos(np.radians(elevation))\n    fig.camera.position = (distance * sinaz * cose, distance * sine, distance * cosaz * cose)\n    return azimuth, elevation, distance"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nplot a single plane at a particular location in the viewbox.", "response": "def plot_plane(where=\"back\", texture=None):\n    \"\"\"Plot a plane at a particular location in the viewbox.\n\n    :param str where: 'back', 'front', 'left', 'right', 'top', 'bottom'\n    :param texture: {texture}\n    :return: :any:`Mesh`\n    \"\"\"\n    fig = gcf()\n    xmin, xmax = fig.xlim\n    ymin, ymax = fig.ylim\n    zmin, zmax = fig.zlim\n    if where == \"back\":\n        x = [xmin, xmax, xmax, xmin]\n        y = [ymin, ymin, ymax, ymax]\n        z = [zmin, zmin, zmin, zmin]\n    if where == \"front\":\n        x = [xmin, xmax, xmax, xmin][::-1]\n        y = [ymin, ymin, ymax, ymax]\n        z = [zmax, zmax, zmax, zmax]\n    if where == \"left\":\n        x = [xmin, xmin, xmin, xmin]\n        y = [ymin, ymin, ymax, ymax]\n        z = [zmin, zmax, zmax, zmin]\n    if where == \"right\":\n        x = [xmax, xmax, xmax, xmax]\n        y = [ymin, ymin, ymax, ymax]\n        z = [zmin, zmax, zmax, zmin][::-1]\n    if where == \"top\":\n        x = [xmin, xmax, xmax, xmin]\n        y = [ymax, ymax, ymax, ymax]\n        z = [zmax, zmax, zmin, zmin]\n    if where == \"bottom\":\n        x = [xmax, xmin, xmin, xmax]\n        y = [ymin, ymin, ymin, ymin]\n        z = [zmin, zmin, zmax, zmax]\n    triangles = [(0, 1, 2), (0, 2, 3)]\n    u = v = None\n    if texture is not None:\n        u = [0.0, 1.0, 1.0, 0.0]\n        v = [0.0, 0.0, 1.0, 1.0]\n    mesh = plot_trisurf(x, y, z, triangles, texture=texture, u=u, v=v)\n    return mesh"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef selector_default(output_widget=None):\n    fig = gcf()\n    if output_widget is None:\n        output_widget = ipywidgets.Output()\n        display(output_widget)\n\n    def lasso(data, other=None, fig=fig):\n        with output_widget:\n            inside = None\n            if data['device'] and data['type'] == 'lasso':\n                region = shapely.geometry.Polygon(data['device'])\n\n                @np.vectorize\n                def inside_polygon(x, y):\n                    return region.contains(shapely.geometry.Point([x, y]))\n\n                inside = inside_polygon\n\n            if data['device'] and data['type'] == 'circle':\n                x1, y1 = data['device']['begin']\n                x2, y2 = data['device']['end']\n                dx = x2 - x1\n                dy = y2 - y1\n                r = (dx ** 2 + dy ** 2) ** 0.5\n\n                def inside_circle(x, y):\n                    return ((x - x1) ** 2 + (y - y1) ** 2) < r ** 2\n\n                inside = inside_circle\n\n            if data['device'] and data['type'] == 'rectangle':\n                x1, y1 = data['device']['begin']\n                x2, y2 = data['device']['end']\n                x = [x1, x2]\n                y = [y1, y2]\n                xmin, xmax = min(x), max(x)\n                ymin, ymax = min(y), max(y)\n\n                def inside_rectangle(x, y):\n                    return (x > xmin) & (x < xmax) & (y > ymin) & (y < ymax)\n\n                inside = inside_rectangle\n\n            def join(x, y, mode):\n                Nx = 0 if (x is None or len(x[0]) == 0) else np.max(x)\n                Ny = 0 if len(y[0]) == 0 else np.max(y)\n                N = max(Nx, Ny)\n                xmask = np.zeros(N + 1, np.bool)\n                ymask = np.zeros(N + 1, np.bool)\n                if x is not None:\n                    xmask[x] = True\n                ymask[y] = True\n                if mode == \"replace\":\n                    return np.where(ymask)\n                if mode == \"and\":\n                    mask = xmask & ymask\n                    return np.where(ymask if x is None else mask)\n                if mode == \"or\":\n                    mask = xmask | ymask\n                    return np.where(ymask if x is None else mask)\n                if mode == \"subtract\":\n                    mask = xmask & ~ymask\n                    return np.where(ymask if x is None else mask)\n\n            for scatter in fig.scatters:\n                x, y = fig.project(scatter.x, scatter.y, scatter.z)\n                mask = inside(x, y)\n                scatter.selected = join(scatter.selected, np.where(mask), fig.selection_mode)\n\n    fig.on_selection(lasso)", "response": "Capture selection events from the current figure and apply the selections to Scatter objects."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _make_triangles_lines(shape, wrapx=False, wrapy=False):\n    nx, ny = shape\n\n    mx = nx if wrapx else nx - 1\n    my = ny if wrapy else ny - 1\n\n    \"\"\"\n    create all pair of indices (i,j) of the rectangular grid\n    minus last row if wrapx = False => mx\n    minus last column if wrapy = False => my\n    |  (0,0)   ...   (0,j)    ...   (0,my-1)  |\n    |    .      .      .       .       .      |\n    |  (i,0)   ...   (i,j)    ...   (i,my-1)  |\n    |    .      .      .       .       .      |\n    |(mx-1,0)  ...  (mx-1,j)  ... (mx-1,my-1) |\n    \"\"\"\n    i, j = np.mgrid[0:mx, 0:my]\n\n    \"\"\"\n    collapsed i and j in one dimensional array, row-major order\n    ex :\n    array([[0,  1,  2],     =>   array([0, 1, 2, 3, *4*, 5])\n           [3, *4*, 5]])\n    if we want vertex 4 at (i=1,j=1) we must transform it in i*ny+j = 4\n    \"\"\"\n    i, j = np.ravel(i), np.ravel(j)\n\n    \"\"\"\n    Let's go for the triangles :\n        (i,j)    -  (i,j+1)   -> y dir\n        (i+1,j)  - (i+1,j+1)\n          |\n          v\n        x dir\n\n    in flatten coordinates:\n        i*ny+j     -  i*ny+j+1\n        (i+1)*ny+j -  (i+1)*ny+j+1\n    \"\"\"\n\n    t1 = (i * ny + j, (i + 1) % nx * ny + j, (i + 1) % nx * ny + (j + 1) % ny)\n    t2 = (i * ny + j, (i + 1) % nx * ny + (j + 1) % ny, i * ny + (j + 1) % ny)\n\n    \"\"\"\n        %nx and %ny are used for wrapx and wrapy :\n        if (i+1)=nx => (i+1)%nx=0 => close mesh in x direction\n        if (j+1)=ny => (j+1)%ny=0 => close mesh in y direction\n    \"\"\"\n\n    nt = len(t1[0])\n\n    triangles = np.zeros((nt * 2, 3), dtype=np.uint32)\n    triangles[0::2, 0], triangles[0::2, 1], triangles[0::2, 2] = t1\n    triangles[1::2, 0], triangles[1::2, 1], triangles[1::2, 2] = t2\n\n    lines = np.zeros((nt * 4, 2), dtype=np.uint32)\n    lines[::4, 0], lines[::4, 1] = t1[:2]\n    lines[1::4, 0], lines[1::4, 1] = t1[0], t2[2]\n    lines[2::4, 0], lines[2::4, 1] = t2[2:0:-1]\n    lines[3::4, 0], lines[3::4, 1] = t1[1], t2[1]\n\n    return triangles, lines", "response": "Create all triangles and lines for a given rectangular regular grid."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the style of the current figure or visualization.", "response": "def use(style):\n        \"\"\"Set the style of the current figure/visualization.\n\n        :param style: matplotlib style name, or dict with values, or a sequence of these, where the last value overrides previous\n        :return:\n        \"\"\"\n        def valid(value):  # checks if json'able\n            return isinstance(value, six.string_types)\n\n        def translate(mplstyle):\n            style = {}\n            mapping = [\n                ['figure.facecolor', 'background-color'],\n                ['xtick.color', 'axes.x.color'],  # TODO: is this the right thing?\n                ['xtick.color', 'axes.z.color'],  # map x to z as well\n                ['ytick.color', 'axes.y.color'],\n                ['axes.labelcolor', 'axes.label.color'],\n                ['text.color', 'color'],\n                ['axes.edgecolor', 'axes.color'],\n            ]\n            for from_name, to_name in mapping:\n                if from_name in mplstyle:\n                    value = mplstyle[from_name]\n                    if \"color\" in from_name:\n                        try:  # threejs doesn't like a color like '.13', so try to convert to proper format\n                            value = float(value) * 255\n                            value = \"rgb(%d, %d, %d)\" % (value, value, value)\n                        except:\n                            pass\n\n                    utils.nested_setitem(style, to_name, value)\n            return style\n\n        if isinstance(style, six.string_types + (dict,)):\n            styles = [style]\n        else:\n            styles = style\n        fig = gcf()\n        totalstyle = utils.dict_deep_update({}, fig.style)\n        for style in styles:\n            if isinstance(style, six.string_types):\n                if hasattr(ipyvolume.styles, style):\n                    style = getattr(ipyvolume.styles, style)\n                else:\n                    # lets see if we can copy matplotlib's style\n                    # we assume now it's a matplotlib style, get all properties that we understand\n                    cleaned_style = {\n                        key: value for key, value in dict(matplotlib.style.library[style]).items() if valid(value)\n                    }\n                    style = translate(cleaned_style)\n                    # totalstyle.update(cleaned_style)\n            else:\n                # otherwise assume it's a dict\n                pass\n            totalstyle = utils.dict_deep_update(totalstyle, style)\n\n        fig = gcf()\n        fig.style = totalstyle"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef save_ipyvolumejs(\n    target=\"\", devmode=False, version=ipyvolume._version.__version_js__, version3js=__version_threejs__\n):\n    \"\"\"Output the ipyvolume javascript to a local file.\n\n    :type target: str\n    :param bool devmode: if True get index.js from js/dist directory\n    :param str version: version number of ipyvolume\n    :param str version3js: version number of threejs\n\n    \"\"\"\n    url = \"https://unpkg.com/ipyvolume@{version}/dist/index.js\".format(version=version)\n    pyv_filename = 'ipyvolume_v{version}.js'.format(version=version)\n    pyv_filepath = os.path.join(target, pyv_filename)\n\n    devfile = os.path.join(os.path.abspath(ipyvolume.__path__[0]), \"..\", \"js\", \"dist\", \"index.js\")\n    if devmode:\n        if not os.path.exists(devfile):\n            raise IOError('devmode=True but cannot find : {}'.format(devfile))\n        if target and not os.path.exists(target):\n            os.makedirs(target)\n        shutil.copy(devfile, pyv_filepath)\n    else:\n        download_to_file(url, pyv_filepath)\n\n    # TODO: currently not in use, think about this if we want to have this external for embedding,\n    # see also https://github.com/jovyan/pythreejs/issues/109\n    # three_filename = 'three_v{version}.js'.format(version=__version_threejs__)\n    # three_filepath = os.path.join(target, three_filename)\n    # threejs = os.path.join(os.path.abspath(ipyvolume.__path__[0]), \"static\", \"three.js\")\n    # shutil.copy(threejs, three_filepath)\n\n    return pyv_filename", "response": "Output the ipyvolume javascript to a local file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndownload and save the require javascript to a local file.", "response": "def save_requirejs(target=\"\", version=\"2.3.4\"):\n    \"\"\"Download and save the require javascript to a local file.\n\n    :type target: str\n    :type version: str\n    \"\"\"\n    url = \"https://cdnjs.cloudflare.com/ajax/libs/require.js/{version}/require.min.js\".format(version=version)\n    filename = \"require.min.v{0}.js\".format(version)\n    filepath = os.path.join(target, filename)\n    download_to_file(url, filepath)\n    return filename"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef save_embed_js(target=\"\", version=wembed.__html_manager_version__):\n    url = u'https://unpkg.com/@jupyter-widgets/html-manager@{0:s}/dist/embed-amd.js'.format(version)\n    if version.startswith('^'):\n        version = version[1:]\n    filename = \"embed-amd_v{0:s}.js\".format(version)\n    filepath = os.path.join(target, filename)\n\n    download_to_file(url, filepath)\n    return filename", "response": "Download and save the ipywidgets embedding javascript to a local file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndownload and save the font - awesome package to a local directory.", "response": "def save_font_awesome(dirpath='', version=\"4.7.0\"):\n    \"\"\"Download and save the font-awesome package to a local directory.\n\n    :type dirpath: str\n    :type url: str\n\n    \"\"\"\n    directory_name = \"font-awesome-{0:s}\".format(version)\n    directory_path = os.path.join(dirpath, directory_name)\n    if os.path.exists(directory_path):\n        return directory_name\n    url = \"https://fontawesome.com/v{0:s}/assets/font-awesome-{0:s}.zip\".format(version)\n    content, _encoding = download_to_bytes(url)\n\n    try:\n        zip_directory = io.BytesIO(content)\n        unzip = zipfile.ZipFile(zip_directory)\n        top_level_name = unzip.namelist()[0]\n        unzip.extractall(dirpath)\n    except Exception as err:\n        raise IOError('Could not unzip content from: {0}\\n{1}'.format(url, err))\n\n    os.rename(os.path.join(dirpath, top_level_name), directory_path)\n\n    return directory_name"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef embed_html(\n    filepath,\n    widgets,\n    makedirs=True,\n    title=u'IPyVolume Widget',\n    all_states=False,\n    offline=False,\n    scripts_path='js',\n    drop_defaults=False,\n    template=html_template,\n    template_options=((\"extra_script_head\", \"\"), (\"body_pre\", \"\"), (\"body_post\", \"\")),\n    devmode=False,\n    offline_cors=False,\n):\n    \"\"\"Write a minimal HTML file with widget views embedded.\n\n    :param str filepath: The file to write the HTML output to.\n    :type widgets: widget or collection of widgets or None\n    :param widgets:The widgets to include views for. If None, all DOMWidgets are included (not just the displayed ones).\n    :param makedirs: whether to make directories in the filename path, if they do not already exist\n    :param title: title for the html page\n    :param all_states: if True, the state of all widgets know to the widget manager is included, else only those in widgets\n    :param offline: if True, use local urls for required js/css packages and download all js/css required packages\n    (if not already available), such that the html can be viewed with no internet connection\n    :param scripts_path: the directory to save required js/css packages to (relative to the filepath)\n    :param bool drop_defaults: Whether to drop default values from the widget states\n    :param template: template string for the html, must contain at least {title} and {snippet} place holders\n    :param template_options: list or dict of additional template options\n    :param devmode: if True, attempt to get index.js from local js/dist directory\n    :param devmode: if True, attempt to get index.js from local js/dist folder\n    :param offline_cors: if True, sets crossorigin attribute to anonymous, this allows for the return of error data\n    from js scripts but can block local loading of the scripts in some browsers\n\n    \"\"\"\n    dir_name_dst = os.path.dirname(os.path.abspath(filepath))\n    if not os.path.exists(dir_name_dst) and makedirs:\n        os.makedirs(dir_name_dst)\n\n    template_opts = {\"extra_script_head\": \"\", \"body_pre\": \"\", \"body_post\": \"\"}\n    template_opts.update(dict(template_options))\n\n    if all_states:\n        state = None\n    else:\n        state = wembed.dependency_state(widgets, drop_defaults=drop_defaults)\n\n    if not offline:\n        # we have to get the snippet (rather than just call embed_minimal_html), because if the new template includes\n        # {} characters (such as in the bokeh example) then an error is raised when trying to format\n        snippet = wembed.embed_snippet(widgets, state=state, requirejs=True, drop_defaults=drop_defaults)\n    else:\n\n        if not os.path.isabs(scripts_path):\n            scripts_path = os.path.join(os.path.dirname(filepath), scripts_path)\n        # ensure script path is above filepath\n        rel_script_path = os.path.relpath(scripts_path, os.path.dirname(filepath))\n        if rel_script_path.startswith(\"..\"):\n            raise ValueError(\"The scripts_path must have the same root directory as the filepath\")\n        elif rel_script_path == '.':\n            rel_script_path = ''\n        else:\n            rel_script_path += '/'\n\n        fname_pyv = save_ipyvolumejs(scripts_path, devmode=devmode)\n        fname_require = save_requirejs(os.path.join(scripts_path))\n        fname_embed = save_embed_js(os.path.join(scripts_path))\n        fname_fontawe = save_font_awesome(os.path.join(scripts_path))\n\n        subsnippet = wembed.embed_snippet(\n            widgets, embed_url=rel_script_path + fname_embed, requirejs=False, drop_defaults=drop_defaults, state=state\n        )\n        if not offline_cors:\n            # TODO DIRTY hack, we need to do this cleaner upstream\n            subsnippet = subsnippet.replace(' crossorigin=\"anonymous\"', '')\n\n        cors_attribute = 'crossorigin=\"anonymous\"' if offline_cors else ' '\n        snippet = \"\"\"\n<link href=\"{rel_script_path}{fname_fontawe}/css/font-awesome.min.css\" rel=\"stylesheet\">\n<script src=\"{rel_script_path}{fname_require}\"{cors} data-main='./{rel_script_path}' ></script>\n<script>\n    require.config({{\n      map: {{\n        '*': {{\n          'ipyvolume': '{fname_pyv}',\n        }}\n      }}}})\n</script>\n{subsnippet}\n        \"\"\".format(\n            rel_script_path=rel_script_path,\n            fname_fontawe=fname_fontawe,\n            fname_require=fname_require,\n            fname_pyv=os.path.splitext(fname_pyv)[0],\n            subsnippet=subsnippet,\n            cors=cors_attribute,\n        )\n\n    template_opts['snippet'] = snippet\n    template_opts['title'] = title\n    html_code = template.format(**template_opts)\n\n    with io.open(filepath, \"w\", encoding='utf8') as f:\n        f.write(html_code)", "response": "Write a minimal HTML file with widget views embedded."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndownloads a url to bytes.", "response": "def download_to_bytes(url, chunk_size=1024 * 1024 * 10, loadbar_length=10):\n    \"\"\"Download a url to bytes.\n\n    if chunk_size is not None, prints a simple loading bar [=*loadbar_length] to show progress (in console and notebook)\n\n    :param url: str or url\n    :param chunk_size: None or int in bytes\n    :param loadbar_length: int length of load bar\n    :return: (bytes, encoding)\n    \"\"\"\n    stream = False if chunk_size is None else True\n\n    print(\"Downloading {0:s}: \".format(url), end=\"\")\n\n    response = requests.get(url, stream=stream)\n    # raise error if download was unsuccessful\n    response.raise_for_status()\n\n    encoding = response.encoding\n    total_length = response.headers.get('content-length')\n    if total_length is not None:\n        total_length = float(total_length)\n        if stream:\n            print(\"{0:.2f}Mb/{1:} \".format(total_length / (1024 * 1024), loadbar_length), end=\"\")\n        else:\n            print(\"{0:.2f}Mb \".format(total_length / (1024 * 1024)), end=\"\")\n\n    if stream:\n        print(\"[\", end=\"\")\n        chunks = []\n        loaded = 0\n        loaded_size = 0\n        for chunk in response.iter_content(chunk_size=chunk_size):\n            if chunk:  # filter out keep-alive new chunks\n                # print our progress bar\n                if total_length is not None:\n                    while loaded < loadbar_length * loaded_size / total_length:\n                        print(\"=\", end='')\n                        loaded += 1\n                    loaded_size += chunk_size\n                chunks.append(chunk)\n        if total_length is None:\n            print(\"=\" * loadbar_length, end='')\n        else:\n            while loaded < loadbar_length:\n                print(\"=\", end='')\n                loaded += 1\n        content = b\"\".join(chunks)\n        print(\"] \", end=\"\")\n    else:\n        content = response.content\n    print(\"Finished\")\n\n    response.close()\n\n    return content, encoding"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef download_yield_bytes(url, chunk_size=1024 * 1024 * 10):\n    response = requests.get(url, stream=True)\n    # raise error if download was unsuccessful\n    response.raise_for_status()\n\n    total_length = response.headers.get('content-length')\n    if total_length is not None:\n        total_length = float(total_length)\n        length_str = \"{0:.2f}Mb \".format(total_length / (1024 * 1024))\n    else:\n        length_str = \"\"\n\n    print(\"Yielding {0:s} {1:s}\".format(url, length_str))\n    for chunk in response.iter_content(chunk_size=chunk_size):\n        yield chunk\n    response.close()", "response": "Yields a downloaded url as byte chunks."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef download_to_file(url, filepath, resume=False, overwrite=False, chunk_size=1024 * 1024 * 10, loadbar_length=10):\n    resume_header = None\n    loaded_size = 0\n    write_mode = 'wb'\n\n    if os.path.exists(filepath):\n        if overwrite:\n            os.remove(filepath)\n        elif resume:\n            # if we want to resume, first try and see if the file is already complete\n            loaded_size = os.path.getsize(filepath)\n            clength = requests.head(url).headers.get('content-length')\n            if clength is not None:\n                if int(clength) == loaded_size:\n                    return None\n            # give the point to resume at\n            resume_header = {'Range': 'bytes=%s-' % loaded_size}\n            write_mode = 'ab'\n        else:\n            return None\n\n    stream = False if chunk_size is None else True\n\n    # start printing with no return character, so that we can have everything on one line\n    print(\"Downloading {0:s}: \".format(url), end=\"\")\n\n    response = requests.get(url, stream=stream, headers=resume_header)\n    # raise error if download was unsuccessful\n    response.raise_for_status()\n\n    # get the size of the file if available\n    total_length = response.headers.get('content-length')\n    if total_length is not None:\n        total_length = float(total_length) + loaded_size\n        print(\"{0:.2f}Mb/{1:} \".format(total_length / (1024 * 1024), loadbar_length), end=\"\")\n    print(\"[\", end=\"\")\n\n    parent = os.path.dirname(filepath)\n    if not os.path.exists(parent) and parent:\n        os.makedirs(parent)\n\n    with io.open(filepath, write_mode) as f:\n        loaded = 0\n        for chunk in response.iter_content(chunk_size=chunk_size):\n            if chunk:  # filter out keep-alive new chunks\n                # print our progress bar\n                if total_length is not None and chunk_size is not None:\n                    while loaded < loadbar_length * loaded_size / total_length:\n                        print(\"=\", end='')\n                        loaded += 1\n                    loaded_size += chunk_size\n                f.write(chunk)\n        if total_length is None:\n            print(\"=\" * loadbar_length, end='')\n        else:\n            while loaded < loadbar_length:\n                print(\"=\", end='')\n                loaded += 1\n    print(\"] Finished\")", "response": "Download a url to a file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngiving a grid with shape and begin and end coordinates amin amax and shape bmin and bmax return a slice of the given shape.", "response": "def grid_slice(amin, amax, shape, bmin, bmax):\n    \"\"\"Give a slice such that [amin, amax] is in [bmin, bmax].\n\n    Given a grid with shape, and begin and end coordinates amin, amax, what slice\n    do we need to take such that it minimally covers bmin, bmax.\n\n    amin, amax = 0, 1; shape = 4\n    0  0.25  0.5  0.75  1\n    |    |    |    |    |\n    bmin, bmax = 0.5, 1.0 should give 2,4, 0.5, 1.0\n    bmin, bmax = 0.4, 1.0 should give 1,4, 0.25, 1.0\n\n    bmin, bmax = -1, 1.0 should give 0,4, 0, 1.0\n\n    what about negative bmin and bmax ?\n    It will just flip bmin and bmax\n    bmin, bmax = 1.0, 0.5 should give 2,4, 0.5, 1.5\n\n    amin, amax = 1, 0; shape = 4\n    1  0.75  0.5  0.25  0\n    |    |    |    |    |\n    bmin, bmax = 0.5, 1.0 should give 0,2, 1.0, 0.5\n    bmin, bmax = 0.4, 1.0 should give 0,3, 1.0, 0.25\n    \"\"\"\n    width = amax - amin\n    bmin, bmax = min(bmin, bmax), max(bmin, bmax)\n    # normalize the coordinates\n    nmin = (bmin - amin) / width\n    nmax = (bmax - amin) / width\n    # grid indices\n    if width < 0:\n        imin = max(0, int(np.floor(nmax * shape)))\n        imax = min(shape, int(np.ceil(nmin * shape)))\n    else:\n        imin = max(0, int(np.floor(nmin * shape)))\n        imax = min(shape, int(np.ceil(nmax * shape)))\n    # transform back to the coordinate system of x\n    nmin = imin / shape\n    nmax = imax / shape\n    #     if width < 0:\n    #         return imin, imax, amin + nmax * width, amin + nmin * width\n    #     else:\n    return (imin, imax), (amin + nmin * width, amin + nmax * width)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning random rotatation matrix algo by James Arvo.", "response": "def _randomSO3():\n    \"\"\"Return random rotatation matrix, algo by James Arvo.\"\"\"\n    u1 = np.random.random()\n    u2 = np.random.random()\n    u3 = np.random.random()\n    R = np.array(\n        [\n            [np.cos(2 * np.pi * u1), np.sin(2 * np.pi * u1), 0],\n            [-np.sin(2 * np.pi * u1), np.cos(2 * np.pi * u1), 0],\n            [0, 0, 1],\n        ]\n    )\n    v = np.array([np.cos(2 * np.pi * u2) * np.sqrt(u3), np.sin(2 * np.pi * u2) * np.sqrt(u3), np.sqrt(1 - u3)])\n    H = np.identity(3) - 2 * v * np.transpose([v])\n    return -np.dot(H, R)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef spherical_galaxy_orbit(\n    orbit_x,\n    orbit_y,\n    orbit_z,\n    N_stars=100,\n    sigma_r=1,\n    orbit_visible=False,\n    orbit_line_interpolate=5,\n    N_star_orbits=10,\n    color=[255, 220, 200],\n    size_star=1,\n    scatter_kwargs={},\n):\n    \"\"\"Create a fake galaxy around the points orbit_x/y/z with N_stars around it.\"\"\"\n    if orbit_line_interpolate > 1:\n        x = np.linspace(0, 1, len(orbit_x))\n        x_smooth = np.linspace(0, 1, len(orbit_x) * orbit_line_interpolate)\n        kind = 'quadratic'\n        orbit_x_line = scipy.interpolate.interp1d(x, orbit_x, kind)(x_smooth)\n        orbit_y_line = scipy.interpolate.interp1d(x, orbit_y, kind)(x_smooth)\n        orbit_z_line = scipy.interpolate.interp1d(x, orbit_z, kind)(x_smooth)\n    else:\n        orbit_x_line = orbit_x\n        orbit_y_line = orbit_y\n        orbit_z_line = orbit_z\n    line = ipv.plot(orbit_x_line, orbit_y_line, orbit_z_line, visible=orbit_visible)\n    x = np.repeat(orbit_x, N_stars).reshape((-1, N_stars))\n    y = np.repeat(orbit_y, N_stars).reshape((-1, N_stars))\n    z = np.repeat(orbit_z, N_stars).reshape((-1, N_stars))\n    xr, yr, zr = np.random.normal(0, scale=sigma_r, size=(3, N_stars))  # +\n    r = np.sqrt(xr ** 2 + yr ** 2 + zr ** 2)\n\n    for i in range(N_stars):\n        a = np.linspace(0, 1, x.shape[0]) * 2 * np.pi * N_star_orbits\n        xo = r[i] * np.sin(a)\n        yo = r[i] * np.cos(a)\n        zo = a * 0\n        xo, yo, zo = np.dot(_randomSO3(), [xo, yo, zo])\n        # print(x.shape, xo.shape)\n        x[:, i] += xo\n        y[:, i] += yo\n        z[:, i] += zo\n\n    sprite = ipv.scatter(\n        x, y, z, texture=radial_sprite((64, 64), color), marker='square_2d', size=size_star, **scatter_kwargs\n    )\n    with sprite.material.hold_sync():\n        sprite.material.blending = pythreejs.BlendingMode.CustomBlending  # pylint: disable=no-member\n        sprite.material.blendSrc = pythreejs.BlendFactors.SrcColorFactor  # pylint: disable=no-member\n        sprite.material.blendDst = pythreejs.BlendFactors.OneFactor  # pylint: disable=no-member\n        sprite.material.blendEquation = 'AddEquation'\n        sprite.material.transparent = True\n        sprite.material.depthWrite = False\n        sprite.material.alphaTest = 0.1\n    return sprite, line", "response": "Create a fake galaxy around the points orbit_x y and z with N_stars around it."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_client_id(self, client_id):\n        with self.lock:\n            if self.client_id is None:\n                self.client_id = client_id", "response": "Set the client ID of the throttler."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _init_polling(self):\n        with self.lock:\n            if not self.running:\n                return\n\n            r = random.Random()\n            delay = r.random() * self.refresh_interval\n            self.channel.io_loop.call_later(\n                delay=delay, callback=self._delayed_polling)\n            self.logger.info(\n                'Delaying throttling credit polling by %d sec', delay)", "response": "Initialize throttling credit polling for throttler."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef local_ip():\n    try:\n        ip = socket.gethostbyname(socket.gethostname())\n    except IOError:\n        ip = socket.gethostbyname('localhost')\n    if ip.startswith('127.'):\n        ip = get_local_ip_by_interfaces()\n        if ip is None:\n            ip = get_local_ip_by_socket()\n    return ip", "response": "Get the local network IP of this machine"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef close(self):\n        with self.stop_lock:\n            self.stopped = True\n\n        return ioloop_util.submit(self._flush, io_loop=self.io_loop)", "response": "Ensure that all spans from the queue are submitted."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nindicating that the work represented by this span has been completed and has been terminated.", "response": "def finish(self, finish_time=None):\n        \"\"\"Indicate that the work represented by this span has been completed\n        or terminated, and is ready to be sent to the Reporter.\n\n        If any tags / logs need to be added to the span, it should be done\n        before calling finish(), otherwise they may be ignored.\n\n        :param finish_time: an explicit Span finish timestamp as a unix\n            timestamp per time.time()\n        \"\"\"\n        if not self.is_sampled():\n            return\n\n        self.end_time = finish_time or time.time()  # no locking\n        self.tracer.report_span(self)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the tag value for the current resource.", "response": "def set_tag(self, key, value):\n        \"\"\"\n        :param key:\n        :param value:\n        \"\"\"\n        with self.update_lock:\n            if key == ext_tags.SAMPLING_PRIORITY and not self._set_sampling_priority(value):\n                return self\n            if self.is_sampled():\n                tag = thrift.make_tag(\n                    key=key,\n                    value=value,\n                    max_length=self.tracer.max_tag_value_length, )\n                self.tags.append(tag)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _set_sampling_priority(self, value):\n\n        # Ignore debug spans trying to re-enable debug.\n        if self.is_debug() and value:\n            return False\n\n        try:\n            value_num = int(value)\n        except ValueError:\n            return False\n        if value_num == 0:\n            self.context.flags &= ~(SAMPLED_FLAG | DEBUG_FLAG)\n            return False\n        if self.tracer.is_debug_allowed(self.operation_name):\n            self.context.flags |= SAMPLED_FLAG | DEBUG_FLAG\n            return True\n        return False", "response": "Set the sampling priority of the current context."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlogs an info message.", "response": "def info(self, message, payload=None):\n        \"\"\"DEPRECATED\"\"\"\n        if payload:\n            self.log(event=message, payload=payload)\n        else:\n            self.log(event=message)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndeprecate - Set error flag.", "response": "def error(self, message, payload=None):\n        \"\"\"DEPRECATED\"\"\"\n        self.set_tag('error', True)\n        if payload:\n            self.log(event=message, payload=payload)\n        else:\n            self.log(event=message)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef write(self, buf):\n        return self.transport_sock.sendto(\n            buf,\n            (self.transport_host, self.transport_port)\n        )", "response": "Raw write to the UDP socket."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a boolean value to indicate if 128bit trace_id generation is enabled.", "response": "def generate_128bit_trace_id(self):\n        \"\"\"\n        :return: Returns boolean value to indicate if 128bit trace_id\n        generation is enabled\n        \"\"\"\n        if 'generate_128bit_trace_id' in self.config:\n            return get_boolean(self.config['generate_128bit_trace_id'], False)\n        return os.getenv('JAEGER_TRACEID_128BIT') == 'true'"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning tags from config and JAEGER_TAGS environment variable to use as process - wide tracer tags", "response": "def tags(self):\n        \"\"\"\n        :return: Returns tags from config and `JAEGER_TAGS` environment variable\n        to use as process-wide tracer tags\n        \"\"\"\n        tags = self.config.get('tags', {})\n        env_tags = os.environ.get('JAEGER_TAGS', '')\n        if env_tags:\n            for kv in env_tags.split(','):\n                key, value = kv.split('=')\n                tags[key.strip()] = value.strip()\n        return tags"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef initialize_tracer(self, io_loop=None):\n\n        with Config._initialized_lock:\n            if Config._initialized:\n                logger.warn('Jaeger tracer already initialized, skipping')\n                return\n            Config._initialized = True\n\n        tracer = self.new_tracer(io_loop)\n\n        self._initialize_global_tracer(tracer=tracer)\n        return tracer", "response": "Initialize a Jaeger Tracer based on the passed in Jaeger client. Config."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef new_tracer(self, io_loop=None):\n        channel = self._create_local_agent_channel(io_loop=io_loop)\n        sampler = self.sampler\n        if not sampler:\n            sampler = RemoteControlledSampler(\n                channel=channel,\n                service_name=self.service_name,\n                logger=logger,\n                metrics_factory=self._metrics_factory,\n                error_reporter=self.error_reporter,\n                sampling_refresh_interval=self.sampling_refresh_interval,\n                max_operations=self.max_operations)\n        logger.info('Using sampler %s', sampler)\n\n        reporter = Reporter(\n            channel=channel,\n            queue_capacity=self.reporter_queue_size,\n            batch_size=self.reporter_batch_size,\n            flush_interval=self.reporter_flush_interval,\n            logger=logger,\n            metrics_factory=self._metrics_factory,\n            error_reporter=self.error_reporter)\n\n        if self.logging:\n            reporter = CompositeReporter(reporter, LoggingReporter(logger))\n\n        if not self.throttler_group() is None:\n            throttler = RemoteThrottler(\n                channel,\n                self.service_name,\n                refresh_interval=self.throttler_refresh_interval,\n                logger=logger,\n                metrics_factory=self._metrics_factory,\n                error_reporter=self.error_reporter)\n        else:\n            throttler = None\n\n        return self.create_tracer(\n            reporter=reporter,\n            sampler=sampler,\n            throttler=throttler,\n        )", "response": "Create a new Jaeger Tracer based on the passed JaegerClient. Config."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating an out - of - process channel communicating to the local jaeger - agent.", "response": "def _create_local_agent_channel(self, io_loop):\n        \"\"\"\n        Create an out-of-process channel communicating to local jaeger-agent.\n        Spans are submitted as SOCK_DGRAM Thrift, sampling strategy is polled\n        via JSON HTTP.\n\n        :param self: instance of Config\n        \"\"\"\n        logger.info('Initializing Jaeger Tracer with UDP reporter')\n        return LocalAgentSender(\n            host=self.local_agent_reporting_host,\n            sampling_port=self.local_agent_sampling_port,\n            reporting_port=self.local_agent_reporting_port,\n            throttling_port=self.throttler_port,\n            io_loop=io_loop\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef span_context_to_string(trace_id, span_id, parent_id, flags):\n    parent_id = parent_id or 0\n    return '{:x}:{:x}:{:x}:{:x}'.format(trace_id, span_id, parent_id, flags)", "response": "Serialize span ID to a string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef span_context_from_string(value):\n    if type(value) is list and len(value) > 0:\n        # sometimes headers are presented as arrays of values\n        if len(value) > 1:\n            raise SpanContextCorruptedException(\n                'trace context must be a string or array of 1: \"%s\"' % value)\n        value = value[0]\n    if not isinstance(value, six.string_types):\n        raise SpanContextCorruptedException(\n            'trace context not a string \"%s\"' % value)\n    parts = value.split(':')\n    if len(parts) != 4:\n        raise SpanContextCorruptedException(\n            'malformed trace context \"%s\"' % value)\n    try:\n        trace_id = int(parts[0], 16)\n        span_id = int(parts[1], 16)\n        parent_id = int(parts[2], 16)\n        flags = int(parts[3], 16)\n        if trace_id < 1 or span_id < 1 or parent_id < 0 or flags < 0:\n            raise SpanContextCorruptedException(\n                'malformed trace context \"%s\"' % value)\n        if parent_id == 0:\n            parent_id = None\n        return trace_id, span_id, parent_id, flags\n    except ValueError as e:\n        raise SpanContextCorruptedException(\n            'malformed trace context \"%s\": %s' % (value, e))", "response": "Decode span ID from a string into a TraceContext."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a new sampling strategy for the specified service name", "response": "def getSamplingStrategy(self, serviceName):\n    \"\"\"\n    Parameters:\n     - serviceName\n    \"\"\"\n    self._seqid += 1\n    future = self._reqs[self._seqid] = concurrent.Future()\n    self.send_getSamplingStrategy(serviceName)\n    return future"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_sampling_strategy(response):\n    s_type = response.strategyType\n    if s_type == sampling_manager.SamplingStrategyType.PROBABILISTIC:\n        if response.probabilisticSampling is None:\n            return None, 'probabilisticSampling field is None'\n        sampling_rate = response.probabilisticSampling.samplingRate\n        if 0 <= sampling_rate <= 1.0:\n            from jaeger_client.sampler import ProbabilisticSampler\n            return ProbabilisticSampler(rate=sampling_rate), None\n        return None, (\n            'Probabilistic sampling rate not in [0, 1] range: %s' %\n            sampling_rate\n        )\n    elif s_type == sampling_manager.SamplingStrategyType.RATE_LIMITING:\n        if response.rateLimitingSampling is None:\n            return None, 'rateLimitingSampling field is None'\n        mtps = response.rateLimitingSampling.maxTracesPerSecond\n        if 0 <= mtps < 500:\n            from jaeger_client.sampler import RateLimitingSampler\n            return RateLimitingSampler(max_traces_per_second=mtps), None\n        return None, (\n            'Rate limiting parameter not in [0, 500] range: %s' % mtps\n        )\n    return None, (\n        'Unsupported sampling strategy type: %s' % s_type\n    )", "response": "Parse a SamplingStrategyResponse and converts it to a Sampler."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef start_span(self,\n                   operation_name=None,\n                   child_of=None,\n                   references=None,\n                   tags=None,\n                   start_time=None,\n                   ignore_active_span=False,\n                   ):\n        \"\"\"\n        Start and return a new Span representing a unit of work.\n\n        :param operation_name: name of the operation represented by the new\n            span from the perspective of the current service.\n        :param child_of: shortcut for 'child_of' reference\n        :param references: (optional) either a single Reference object or a\n            list of Reference objects that identify one or more parent\n            SpanContexts. (See the opentracing.Reference documentation for detail)\n        :param tags: optional dictionary of Span Tags. The caller gives up\n            ownership of that dictionary, because the Tracer may use it as-is\n            to avoid extra data copying.\n        :param start_time: an explicit Span start time as a unix timestamp per\n            time.time()\n        :param ignore_active_span: an explicit flag that ignores the current\n            active :class:`Scope` and creates a root :class:`Span`\n\n        :return: Returns an already-started Span instance.\n        \"\"\"\n        parent = child_of\n\n        if self.active_span is not None \\\n                and not ignore_active_span \\\n                and not parent:\n            parent = self.active_span\n\n        # allow Span to be passed as reference, not just SpanContext\n        if isinstance(parent, Span):\n            parent = parent.context\n\n        valid_references = None\n        if references:\n            valid_references = list()\n            if not isinstance(references, list):\n                references = [references]\n            for reference in references:\n                if reference.referenced_context is not None:\n                    valid_references.append(reference)\n\n        # setting first reference as parent\n        if valid_references and (parent is None or not parent.has_trace):\n            parent = valid_references[0].referenced_context\n\n        rpc_server = tags and \\\n            tags.get(ext_tags.SPAN_KIND) == ext_tags.SPAN_KIND_RPC_SERVER\n\n        if parent is None or not parent.has_trace:\n            trace_id = self._random_id(self.max_trace_id_bits)\n            span_id = self._random_id(constants._max_id_bits)\n            parent_id = None\n            flags = 0\n            baggage = None\n            if parent is None:\n                sampled, sampler_tags = \\\n                    self.sampler.is_sampled(trace_id, operation_name)\n                if sampled:\n                    flags = SAMPLED_FLAG\n                    tags = tags or {}\n                    for k, v in six.iteritems(sampler_tags):\n                        tags[k] = v\n            elif parent.debug_id and self.is_debug_allowed(operation_name):\n                flags = SAMPLED_FLAG | DEBUG_FLAG\n                tags = tags or {}\n                tags[self.debug_id_header] = parent.debug_id\n            if parent and parent.baggage:\n                baggage = dict(parent.baggage)  # TODO do we need to clone?\n        else:\n            trace_id = parent.trace_id\n            if rpc_server and self.one_span_per_rpc:\n                # Zipkin-style one-span-per-RPC\n                span_id = parent.span_id\n                parent_id = parent.parent_id\n            else:\n                span_id = self._random_id(constants._max_id_bits)\n                parent_id = parent.span_id\n            flags = parent.flags\n            baggage = dict(parent.baggage)  # TODO do we need to clone?\n\n        span_ctx = SpanContext(trace_id=trace_id, span_id=span_id,\n                               parent_id=parent_id, flags=flags,\n                               baggage=baggage)\n        span = Span(context=span_ctx, tracer=self,\n                    operation_name=operation_name,\n                    tags=tags, start_time=start_time, references=valid_references)\n\n        self._emit_span_metrics(span=span, join=rpc_server)\n\n        return span", "response": "Start and return a new Span instance."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef submitBatches(self, batches):\n    self._seqid += 1\n    future = self._reqs[self._seqid] = concurrent.Future()\n    self.send_submitBatches(batches)\n    return future", "response": "Submit a batch of batches to the next batch."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a daemonized thread that will run Tornado IOLoop.", "response": "def _create_new_thread_loop(self):\n        \"\"\"\n        Create a daemonized thread that will run Tornado IOLoop.\n        :return: the IOLoop backed by the new thread.\n        \"\"\"\n        self._thread_loop = ThreadLoop()\n        if not self._thread_loop.is_ready():\n            self._thread_loop.start()\n        return self._thread_loop._io_loop"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef submit(fn, io_loop, *args, **kwargs):\n    future = Future()\n\n    def execute():\n        \"\"\"Execute fn on the IOLoop.\"\"\"\n        try:\n            result = gen.maybe_future(fn(*args, **kwargs))\n        except Exception:\n            # The function we ran didn't return a future and instead raised\n            # an exception. Let's pretend that it returned this dummy\n            # future with our stack trace.\n            f = gen.Future()\n            f.set_exc_info(sys.exc_info())\n            on_done(f)\n        else:\n            result.add_done_callback(on_done)\n\n    def on_done(tornado_future):\n        \"\"\"\n        Set tornado.Future results to the concurrent.Future.\n        :param tornado_future:\n        \"\"\"\n        exception = tornado_future.exception()\n        if not exception:\n            future.set_result(tornado_future.result())\n        else:\n            future.set_exception(exception)\n\n    io_loop.add_callback(execute)\n\n    return future", "response": "Submit a function to the IOLoop."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsubmit a batch of spans to the Zipkin server.", "response": "def submitZipkinBatch(self, spans):\n    \"\"\"\n    Parameters:\n     - spans\n    \"\"\"\n    self._seqid += 1\n    future = self._reqs[self._seqid] = concurrent.Future()\n    self.send_submitZipkinBatch(spans)\n    return future"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the actual list of component data based on how data is stored in component. data.", "response": "def get_shared_data(component):\n    \"\"\"\n    Returns the actual list of component data based on how data is\n    stored in component, either from the `data` attribute or from the\n    `data['content']` attribute.\n\n    Returns:\n        list: List of component data.\n    \"\"\"\n    if component:\n        return (copy.deepcopy(component.data)\n                if 'content' not in component.data\n                else copy.deepcopy(component.data['content']))\n    else:\n        return []"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef merge_lvm_data(primary, secondary, name_key):\n    pri_data = to_name_key_dict(primary, name_key)\n    # Prime results with secondary data, to be updated with primary data\n    combined_data = to_name_key_dict(secondary, name_key)\n    for name in pri_data:\n        if name not in combined_data:\n            # Data only in primary\n            combined_data[name] = pri_data[name]\n        else:\n            # Data in both primary and secondary, pick primary if better or no secondary\n            combined_data[name].update(dict(\n                (k, v) for k, v in pri_data[name].items()\n                if v is not None or k not in combined_data[name]\n            ))\n\n    return set_defaults(combined_data)", "response": "Merge the data from primary and secondary into a single object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_defaults(lvm_data):\n    for l in lvm_data:\n        for k, v in lvm_data[l].items():\n            if v == '':\n                lvm_data[l][k] = None\n\n    return lvm_data", "response": "Sets all existing null string values to None."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_output(self):\n        '''\n        Execute a command through system shell. First checks to see if\n        the requested command is executable. Returns (returncode, stdout, 0)\n        '''\n        if self.is_hostname:\n            # short circuit for hostame with internal method\n            return determine_hostname()\n\n        # all commands should timeout after a long interval so the client does not hang\n        # prepend native nix 'timeout' implementation\n        timeout_command = 'timeout -s KILL %s %s' % (\n            self.config.cmd_timeout, self.command)\n\n        # ensure consistent locale for collected command output\n        cmd_env = {'LC_ALL': 'C',\n                   'PATH': '/sbin:/bin:/usr/sbin:/usr/bin',\n                   'PYTHONPATH': os.getenv('PYTHONPATH')}\n        args = shlex.split(timeout_command)\n\n        # never execute this stuff\n        if set.intersection(set(args), constants.command_blacklist):\n            raise RuntimeError(\"Command Blacklist: \" + self.command)\n\n        try:\n            logger.debug('Executing: %s', args)\n            proc0 = Popen(args, shell=False, stdout=PIPE, stderr=STDOUT,\n                          bufsize=-1, env=cmd_env, close_fds=True)\n        except OSError as err:\n            if err.errno == errno.ENOENT:\n                logger.debug('Command %s not found', self.command)\n                return\n            else:\n                raise err\n\n        dirty = False\n\n        cmd = \"sed -rf \" + constants.default_sed_file\n        sedcmd = Popen(shlex.split(cmd),\n                       stdin=proc0.stdout,\n                       stdout=PIPE)\n        proc0.stdout.close()\n        proc0 = sedcmd\n\n        if self.exclude is not None:\n            exclude_file = NamedTemporaryFile()\n            exclude_file.write(\"\\n\".join(self.exclude).encode('utf-8'))\n            exclude_file.flush()\n            cmd = \"grep -F -v -f %s\" % exclude_file.name\n            proc1 = Popen(shlex.split(cmd),\n                          stdin=proc0.stdout,\n                          stdout=PIPE)\n            proc0.stdout.close()\n            stderr = None\n            if self.pattern is None or len(self.pattern) == 0:\n                stdout, stderr = proc1.communicate()\n\n            # always log return codes for debug\n            logger.debug('Proc1 Status: %s', proc1.returncode)\n            logger.debug('Proc1 stderr: %s', stderr)\n            proc0 = proc1\n\n            dirty = True\n\n        if self.pattern is not None and len(self.pattern):\n            pattern_file = NamedTemporaryFile()\n            pattern_file.write(\"\\n\".join(self.pattern).encode('utf-8'))\n            pattern_file.flush()\n            cmd = \"grep -F -f %s\" % pattern_file.name\n            proc2 = Popen(shlex.split(cmd),\n                          stdin=proc0.stdout,\n                          stdout=PIPE)\n            proc0.stdout.close()\n            stdout, stderr = proc2.communicate()\n\n            # always log return codes for debug\n            logger.debug('Proc2 Status: %s', proc2.returncode)\n            logger.debug('Proc2 stderr: %s', stderr)\n            proc0 = proc2\n\n            dirty = True\n\n        if not dirty:\n            stdout, stderr = proc0.communicate()\n\n        # Required hack while we still pass shell=True to Popen; a Popen\n        # call with shell=False for a non-existant binary will raise OSError.\n        if proc0.returncode == 126 or proc0.returncode == 127:\n            stdout = \"Could not find cmd: %s\", self.command\n\n        logger.debug(\"Proc0 Status: %s\", proc0.returncode)\n        logger.debug(\"Proc0 stderr: %s\", stderr)\n        return stdout.decode('utf-8', 'ignore').strip()", "response": "Execute a command through system shell and return the output of the command."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting file content selecting only lines we are interested in", "response": "def get_output(self):\n        '''\n        Get file content, selecting only lines we are interested in\n        '''\n        if not os.path.isfile(self.real_path):\n            logger.debug('File %s does not exist', self.real_path)\n            return\n\n        cmd = []\n        cmd.append('sed')\n        cmd.append('-rf')\n        cmd.append(constants.default_sed_file)\n        cmd.append(self.real_path)\n        sedcmd = Popen(cmd,\n                       stdout=PIPE)\n\n        if self.exclude is not None:\n            exclude_file = NamedTemporaryFile()\n            exclude_file.write(\"\\n\".join(self.exclude).encode('utf-8'))\n            exclude_file.flush()\n\n            cmd = \"grep -v -F -f %s\" % exclude_file.name\n            args = shlex.split(cmd)\n            proc = Popen(args, stdin=sedcmd.stdout, stdout=PIPE)\n            sedcmd.stdout.close()\n            stdin = proc.stdout\n            if self.pattern is None:\n                output = proc.communicate()[0]\n            else:\n                sedcmd = proc\n\n        if self.pattern is not None:\n            pattern_file = NamedTemporaryFile()\n            pattern_file.write(\"\\n\".join(self.pattern).encode('utf-8'))\n            pattern_file.flush()\n\n            cmd = \"grep -F -f %s\" % pattern_file.name\n            args = shlex.split(cmd)\n            proc1 = Popen(args, stdin=sedcmd.stdout, stdout=PIPE)\n            sedcmd.stdout.close()\n\n            if self.exclude is not None:\n                stdin.close()\n\n            output = proc1.communicate()[0]\n\n        if self.pattern is None and self.exclude is None:\n            output = sedcmd.communicate()[0]\n\n        return output.decode('utf-8', 'ignore').strip()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _parse_line(self, line):\n        fields = line.split('|', 4)  # stop splitting after fourth | found\n        line_info = {'raw_message': line}\n        if len(fields) == 5:\n            line_info.update(dict(zip(self._fieldnames, fields)))\n        return line_info", "response": "Parse a line into fields."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_content(self, content):\n        data = {}\n        data = split_kv_pairs(content, use_partition=False)\n\n        \"\"\"Remove empty key\"\"\"\n        self.data = dict((k, v) for k, v in data.items() if not v == '')", "response": "Parse the content of the log entry into a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nimport a component from the module or class.", "response": "def _import_component(name):\n    \"\"\"\n    Returns a class, function, or class method specified by the fully qualified\n    name.\n    \"\"\"\n    for f in (_get_from_module, _get_from_class):\n        try:\n            return f(name)\n        except:\n            pass\n    log.debug(\"Couldn't load %s\" % name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the string name of a component including module and class if applicable.", "response": "def get_name(component):\n    \"\"\"\n    Attempt to get the string name of component, including module and class if\n    applicable.\n    \"\"\"\n    if six.callable(component):\n        name = getattr(component, \"__qualname__\", component.__name__)\n        return '.'.join([component.__module__, name])\n    return str(component)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwalk the dependency tree of a root component function or class.", "response": "def walk_dependencies(root, visitor):\n    \"\"\"\n    Call visitor on root and all dependencies reachable from it in breadth\n    first order.\n\n    Args:\n        root (component): component function or class\n        visitor (function): signature is `func(component, parent)`.  The\n            call on root is `visitor(root, None)`.\n    \"\"\"\n    def visit(parent, visitor):\n        for d in get_dependencies(parent):\n            visitor(d, parent)\n            visit(d, visitor)\n\n    visitor(root, None)\n    visit(root, visitor)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_dependency_graph(component):\n    if component not in DEPENDENCIES:\n        raise Exception(\"%s is not a registered component.\" % get_name(component))\n\n    if not DEPENDENCIES[component]:\n        return {component: set()}\n\n    graph = defaultdict(set)\n\n    def visitor(c, parent):\n        if parent is not None:\n            graph[parent].add(c)\n\n    walk_dependencies(component, visitor)\n\n    graph = dict(graph)\n\n    # Find all items that don't depend on anything.\n    extra_items_in_deps = _reduce(set.union, graph.values(), set()) - set(graph.keys())\n\n    # Add empty dependencies where needed.\n    graph.update(dict((item, set()) for item in extra_items_in_deps))\n\n    return graph", "response": "Generates a component s graph of dependencies."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_subgraphs(graph=None):\n    graph = graph or DEPENDENCIES\n    keys = set(graph)\n    frontier = set()\n    seen = set()\n    while keys:\n        frontier.add(keys.pop())\n        while frontier:\n            component = frontier.pop()\n            seen.add(component)\n            frontier |= set([d for d in get_dependencies(component) if d in graph])\n            frontier |= set([d for d in get_dependents(component) if d in graph])\n            frontier -= seen\n        yield dict((s, get_dependencies(s)) for s in seen)\n        keys -= seen\n        seen.clear()", "response": "Given a graph of possibly disconnected components generate all graphs of\n    connected components."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload all components beneath a path.", "response": "def load_components(*paths, **kwargs):\n    \"\"\"\n    Loads all components on the paths. Each path should be a package or module.\n    All components beneath a path are loaded.\n\n    Args:\n        paths (str): A package or module to load\n\n    Keyword Args:\n        include (str): A regular expression of packages and modules to include.\n            Defaults to '.*'\n        exclude (str): A regular expression of packges and modules to exclude.\n            Defaults to 'test'\n        continue_on_error (bool): If True, continue importing even if something\n            raises an ImportError. If False, raise the first ImportError.\n\n    Returns:\n        int: The total number of modules loaded.\n\n    Raises:\n        ImportError\n    \"\"\"\n    num_loaded = 0\n    for path in paths:\n        num_loaded += _load_components(path, **kwargs)\n    return num_loaded"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_missing_requirements(func, requires, d):\n    if not requires:\n        return None\n    if any(i in d for i in IGNORE.get(func, [])):\n        raise SkipComponent()\n    req_all, req_any = split_requirements(requires)\n    d = set(d.keys())\n    req_all = [r for r in req_all if r not in d]\n    req_any = [r for r in req_any if set(r).isdisjoint(d)]\n    if req_all or req_any:\n        return req_all, req_any\n    else:\n        return None", "response": "Get missing requirements for a given function."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef run(components=None, broker=None):\n    components = components or COMPONENTS[GROUPS.single]\n    components = _determine_components(components)\n    broker = broker or Broker()\n\n    for component in run_order(components):\n        start = time.time()\n        try:\n            if component not in broker and component in DELEGATES and is_enabled(component):\n                log.info(\"Trying %s\" % get_name(component))\n                result = DELEGATES[component].process(broker)\n                broker[component] = result\n        except MissingRequirements as mr:\n            if log.isEnabledFor(logging.DEBUG):\n                name = get_name(component)\n                reqs = stringify_requirements(mr.requirements)\n                log.debug(\"%s missing requirements %s\" % (name, reqs))\n            broker.add_exception(component, mr)\n        except SkipComponent:\n            pass\n        except Exception as ex:\n            tb = traceback.format_exc()\n            log.warn(tb)\n            broker.add_exception(component, ex, tb)\n        finally:\n            broker.exec_times[component] = time.time() - start\n            broker.fire_observers(component)\n\n    return broker", "response": "Executes the components in an order that satisfies their dependency graph."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef run_incremental(components=None, broker=None):\n    for graph, _broker in generate_incremental(components, broker):\n        yield run(graph, broker=_broker)", "response": "Yields a generator that yields each subgraph of the given components in an incremental order."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nhandling invocation of the component with positional arguments based on order of dependency declaration.", "response": "def invoke(self, results):\n        \"\"\"\n        Handles invocation of the component. The default implementation invokes\n        it with positional arguments based on order of dependency declaration.\n        \"\"\"\n        args = [results.get(d) for d in self.deps]\n        return self.component(*args)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_missing_dependencies(self, broker):\n        missing_required = [r for r in self.requires if r not in broker]\n        missing_at_least_one = [d for d in self.at_least_one if not set(d).intersection(broker)]\n        if missing_required or missing_at_least_one:\n            return (missing_required, missing_at_least_one)", "response": "Gets required and at - least - one dependencies not provided by the broker."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprocesses the component and return the result.", "response": "def process(self, broker):\n        \"\"\"\n        Ensures dependencies have been met before delegating to `self.invoke`.\n        \"\"\"\n        if any(i in broker for i in IGNORE.get(self.component, [])):\n            raise SkipComponent()\n        missing = self.get_missing_dependencies(broker)\n        if missing:\n            raise MissingRequirements(missing)\n        return self.invoke(broker)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef observer(self, component_type=ComponentType):\n        def inner(func):\n            self.add_observer(func, component_type)\n            return func\n        return inner", "response": "Decorator to add an observer to the broker."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_observer(self, o, component_type=ComponentType):\n\n        self.observers[component_type].add(o)", "response": "Add a callback that will get invoked after each component is called."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning all of the instances of _type.", "response": "def get_by_type(self, _type):\n        \"\"\"\n        Return all of the instances of :class:`ComponentType` ``_type``.\n        \"\"\"\n        r = {}\n        for k, v in self.items():\n            if get_component_type(k) is _type:\n                r[k] = v\n        return r"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the logrotate configuration tree for the current logrotate project.", "response": "def get_tree(root=None):\n    \"\"\"\n    This is a helper function to get a logrotate configuration component for\n    your local machine or an archive. It's for use in interactive sessions.\n    \"\"\"\n    from insights import run\n    return run(LogRotateConfTree, root=root).get(LogRotateConfTree)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfunctioning for formatting content and logging to syslog", "response": "def logit(self, msg, pid, user, cname, priority=None):\n        \"\"\"Function for formatting content and logging to syslog\"\"\"\n\n        if self.stream:\n            print(msg, file=self.stream)\n        elif priority == logging.WARNING:\n            self.logger.warning(\"{0}[pid:{1}] user:{2}: WARNING - {3}\".format(cname, pid, user, msg))\n        elif priority == logging.ERROR:\n            self.logger.error(\"{0}[pid:{1}] user:{2}: ERROR - {3}\".format(cname, pid, user, msg))\n        else:\n            self.logger.info(\"{0}[pid:{1}] user:{2}: INFO - {3}\".format(cname, pid, user, msg))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef log_exceptions(self, c, broker):\n\n        if c in broker.exceptions:\n            ex = broker.exceptions.get(c)\n            ex = \"Exception in {0} - {1}\".format(dr.get_name(c), str(ex))\n            self.logit(ex, self.pid, self.user, \"insights-run\", logging.ERROR)", "response": "Logs exceptions to syslog"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncollect rule information and send to syslog", "response": "def log_rule_info(self):\n        \"\"\"Collects rule information and send to logit function to log to syslog\"\"\"\n\n        for c in sorted(self.broker.get_by_type(rule), key=dr.get_name):\n            v = self.broker[c]\n            _type = v.get(\"type\")\n            if _type:\n                if _type != \"skip\":\n                    msg = \"Running {0} \".format(dr.get_name(c))\n                    self.logit(msg, self.pid, self.user, \"insights-run\", logging.INFO)\n                else:\n                    msg = \"Rule skipped {0} \".format(dr.get_name(c))\n                    self.logit(msg, self.pid, self.user, \"insights-run\", logging.WARNING)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _run_pre_command(self, pre_cmd):\n        '''\n        Run a pre command to get external args for a command\n        '''\n        logger.debug('Executing pre-command: %s', pre_cmd)\n        try:\n            pre_proc = Popen(pre_cmd, stdout=PIPE, stderr=STDOUT, shell=True)\n        except OSError as err:\n            if err.errno == errno.ENOENT:\n                logger.debug('Command %s not found', pre_cmd)\n            return\n        stdout, stderr = pre_proc.communicate()\n        the_return_code = pre_proc.poll()\n        logger.debug(\"Pre-command results:\")\n        logger.debug(\"STDOUT: %s\", stdout)\n        logger.debug(\"STDERR: %s\", stderr)\n        logger.debug(\"Return Code: %s\", the_return_code)\n        if the_return_code != 0:\n            return []\n        if six.PY3:\n            stdout = stdout.decode('utf-8')\n        return stdout.splitlines()", "response": "Run a pre command to get external args for a command."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _parse_file_spec(self, spec):\n        '''\n        Separate wildcard specs into more specs\n        '''\n        # separate wildcard specs into more specs\n        if '*' in spec['file']:\n            expanded_paths = _expand_paths(spec['file'])\n            if not expanded_paths:\n                return []\n            expanded_specs = []\n            for p in expanded_paths:\n                _spec = copy.copy(spec)\n                _spec['file'] = p\n                expanded_specs.append(_spec)\n            return expanded_specs\n\n        else:\n            return [spec]", "response": "Parse a file spec into a list of dicts."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _parse_glob_spec(self, spec):\n        '''\n        Grab globs of things\n        '''\n        some_globs = glob.glob(spec['glob'])\n        if not some_globs:\n            return []\n        el_globs = []\n        for g in some_globs:\n            _spec = copy.copy(spec)\n            _spec['file'] = g\n            el_globs.append(_spec)\n        return el_globs", "response": "Parse globs in the spec and return a list of dictionaries"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _parse_command_spec(self, spec, precmds):\n        '''\n        Run pre_commands\n        '''\n        if 'pre_command' in spec:\n            precmd_alias = spec['pre_command']\n            try:\n                precmd = precmds[precmd_alias]\n\n                if self._blacklist_check(precmd):\n                    raise RuntimeError(\"Command Blacklist: \" + precmd)\n\n                args = self._run_pre_command(precmd)\n                logger.debug('Pre-command results: %s', args)\n\n                expanded_specs = []\n                for arg in args:\n                    _spec = copy.copy(spec)\n                    _spec['command'] = _spec['command'] + ' ' + arg\n                    expanded_specs.append(_spec)\n                return expanded_specs\n            except LookupError:\n                logger.debug('Pre-command %s not found. Skipping %s...',\n                             precmd_alias, spec['command'])\n                return []\n        else:\n            return [spec]", "response": "Parse a command specification and return a list of the command arguments."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef run_collection(self, conf, rm_conf, branch_info):\n        '''\n        Run specs and collect all the data\n        '''\n        if rm_conf is None:\n            rm_conf = {}\n        logger.debug('Beginning to run collection spec...')\n        exclude = None\n        if rm_conf:\n            try:\n                exclude = rm_conf['patterns']\n                logger.warn(\"WARNING: Skipping patterns found in remove.conf\")\n            except LookupError:\n                logger.debug('Patterns section of remove.conf is empty.')\n\n        for c in conf['commands']:\n            # remember hostname archive path\n            if c.get('symbolic_name') == 'hostname':\n                self.hostname_path = os.path.join(\n                    'insights_commands', mangle.mangle_command(c['command']))\n            rm_commands = rm_conf.get('commands', [])\n            if c['command'] in rm_commands or c.get('symbolic_name') in rm_commands:\n                logger.warn(\"WARNING: Skipping command %s\", c['command'])\n            elif self.mountpoint == \"/\" or c.get(\"image\"):\n                cmd_specs = self._parse_command_spec(c, conf['pre_commands'])\n                for s in cmd_specs:\n                    cmd_spec = InsightsCommand(self.config, s, exclude, self.mountpoint)\n                    self.archive.add_to_archive(cmd_spec)\n        for f in conf['files']:\n            rm_files = rm_conf.get('files', [])\n            if f['file'] in rm_files or f.get('symbolic_name') in rm_files:\n                logger.warn(\"WARNING: Skipping file %s\", f['file'])\n            else:\n                file_specs = self._parse_file_spec(f)\n                for s in file_specs:\n                    # filter files post-wildcard parsing\n                    if s['file'] in rm_conf.get('files', []):\n                        logger.warn(\"WARNING: Skipping file %s\", s['file'])\n                    else:\n                        file_spec = InsightsFile(s, exclude, self.mountpoint)\n                        self.archive.add_to_archive(file_spec)\n        if 'globs' in conf:\n            for g in conf['globs']:\n                glob_specs = self._parse_glob_spec(g)\n                for g in glob_specs:\n                    if g['file'] in rm_conf.get('files', []):\n                        logger.warn(\"WARNING: Skipping file %s\", g)\n                    else:\n                        glob_spec = InsightsFile(g, exclude, self.mountpoint)\n                        self.archive.add_to_archive(glob_spec)\n        logger.debug('Spec collection finished.')\n\n        # collect metadata\n        logger.debug('Collecting metadata...')\n        self._write_branch_info(branch_info)\n        logger.debug('Metadata collection finished.')", "response": "Run specs and collect all the data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncleaning the archive and return the archive_dir", "response": "def done(self, conf, rm_conf):\n        \"\"\"\n        Do finalization stuff\n        \"\"\"\n        if self.config.obfuscate:\n            cleaner = SOSCleaner(quiet=True)\n            clean_opts = CleanOptions(\n                self.config, self.archive.tmp_dir, rm_conf, self.hostname_path)\n            fresh = cleaner.clean_report(clean_opts, self.archive.archive_dir)\n            if clean_opts.keyword_file is not None:\n                os.remove(clean_opts.keyword_file.name)\n                logger.warn(\"WARNING: Skipping keywords found in remove.conf\")\n            return fresh[0]\n        return self.archive.create_tar_file()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_content(self, content):\n        self.data = {}\n        self.unparsed_lines = []\n        for line in filter(None, content):\n            split_result = line.split()\n            # Need at least IP address, something, and reachability\n            if len(split_result) < 2:\n                self.unparsed_lines.append({\n                    'line': line,\n                    'reason': \"not enough words\"\n                })\n                continue\n            # Total words needs to be even: beginning + 2*keyvals + ending\n            if len(split_result) % 2 == 1:\n                self.unparsed_lines.append({\n                    'line': line,\n                    'reason': \"odd number of words\"\n                })\n                continue\n            # Don't parse this line if the first thing isn't an\n            # IP address\n            try:\n                addr = ipaddress.ip_address(six.u(split_result[0]))\n            except ValueError:\n                self.unparsed_lines.append({\n                    'line': line,\n                    'reason': \"can't convert address '\" + split_result[0] + \"'\"\n                })\n                continue\n            # Don't parse this line if the last item doesn't seem to be a\n            # neighbour unreachability state\n            if split_result[-1] not in self.VALID_NUD_STATES:\n                self.unparsed_lines.append({\n                    'line': line,\n                    'reason': split_result[-1] + \" is not a valid state\"\n                })\n                continue\n\n            # OK, good to go, split everything in the middle up\n            key_value_content = split_result[1:-1]\n            if len(key_value_content) >= 2:\n                entry = dict((k, v) for k, v in zip(key_value_content[0::2],\n                                                    key_value_content[1::2]))\n            else:\n                entry = {}\n            entry[\"nud\"] = split_result[-1]\n            entry['addr'] = addr  # save the object\n            self.data[split_result[0]] = entry", "response": "Parse the content of the ip neighbor output into a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef tomcat_base(broker):\n        ps = broker[DefaultSpecs.ps_auxww].content\n        results = []\n        findall = re.compile(r\"\\-Dcatalina\\.base=(\\S+)\").findall\n        for p in ps:\n            found = findall(p)\n            if found:\n                # Only get the path which is absolute\n                results.extend(f for f in found if f[0] == '/')\n        return list(set(results))", "response": "Return a list of all base path entries in the Tomcat broker."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncommanding for getting list of image ids", "response": "def docker_image_ids(broker):\n        \"\"\"Command: docker_image_ids\"\"\"\n        images = broker[DefaultSpecs.docker_list_images]\n        try:\n            result = set()\n            for l in images.content[1:]:\n                result.add(l.split(None)[3].strip())\n        except:\n            raise ContentException(\"No docker images.\")\n        if result:\n            return list(result)\n        raise ContentException(\"No docker images.\")"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of HTTPD commands that can be run on a specific HTTPD instance.", "response": "def httpd_cmd(broker):\n        \"\"\"Command: httpd_command\"\"\"\n        ps = broker[DefaultSpecs.ps_auxww].content\n        ps_httpds = set()\n        for p in ps:\n            p_splits = p.split(None, 10)\n            if len(p_splits) >= 11:\n                cmd = p_splits[10].split()[0]\n                # Should compatible with RHEL6\n                # e.g. /usr/sbin/httpd, /usr/sbin/httpd.worker and /usr/sbin/httpd.event\n                #      and SCL's httpd24-httpd\n                if os.path.basename(cmd).startswith('httpd'):\n                    ps_httpds.add(cmd)\n        # Running multiple httpd instances on RHEL is supported\n        # https://access.redhat.com/solutions/21680\n        return list(ps_httpds)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef semid(broker):\n        source = broker[DefaultSpecs.ipcs_s].content\n        results = set()\n        for s in source:\n            s_splits = s.split()\n            # key        semid      owner      perms      nsems\n            # 0x00000000 65536      apache     600        1\n            if len(s_splits) == 5 and s_splits[1].isdigit():\n                results.add(s_splits[1])\n        return results", "response": "Return set of semid entries from source"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sap_sid_nr(broker):\n        insts = broker[DefaultSpecs.saphostctrl_listinstances].content\n        hn = broker[DefaultSpecs.hostname].content[0].split('.')[0].strip()\n        results = set()\n        for ins in insts:\n            ins_splits = ins.split(' - ')\n            # Local Instance\n            if ins_splits[2].strip() == hn:\n                # (sid, nr)\n                results.add((ins_splits[0].split()[-1].lower(), ins_splits[1].strip()))\n        return list(results)", "response": "Get the SID and Instance Number of a specific instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef block(broker):\n        remove = (\".\", \"ram\", \"dm-\", \"loop\")\n        tmp = \"/dev/%s\"\n        return[(tmp % f) for f in os.listdir(\"/sys/block\") if not f.startswith(remove)]", "response": "Path to sys. block directories starting with. or ram dm - or loop"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncommands to install the installed rpms", "response": "def docker_installed_rpms(broker):\n        \"\"\" Command: /usr/bin/rpm -qa --root `%s` --qf `%s`\"\"\"\n        ctx = broker[DockerImageContext]\n        root = ctx.root\n        fmt = DefaultSpecs.rpm_format\n        cmd = \"/usr/bin/rpm -qa --root %s --qf '%s'\" % (root, fmt)\n        result = ctx.shell_out(cmd)\n        return CommandOutputProvider(cmd, ctx, content=result)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef jboss_home(broker):\n        ps = broker[DefaultSpecs.ps_auxww].content\n        results = []\n        findall = re.compile(r\"\\-Djboss\\.home\\.dir=(\\S+)\").findall\n        # JBoss progress command content should contain jboss.home.dir\n        # and any of string ['-D[Standalone]', '-D[Host Controller]', '-D[Server:']\n        for p in ps:\n            if any(i in p for i in ['-D[Standalone]', '-D[Host Controller]', '-D[Server:']):\n                found = findall(p)\n                if found:\n                    # Only get the path which is absolute\n                    results.extend(f for f in found if f[0] == '/')\n        return list(set(results))", "response": "Command: JBoss home progress command content paths"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncommand for getting the JBoss domain server log directory", "response": "def jboss_domain_server_log_dir(broker):\n        \"\"\"Command: JBoss domain server log directory\"\"\"\n        ps = broker[DefaultSpecs.ps_auxww].content\n        results = []\n        findall = re.compile(r\"\\-Djboss\\.server\\.log\\.dir=(\\S+)\").findall\n        # JBoss domain server progress command content should contain jboss.server.log.dir\n        for p in ps:\n            if '-D[Server:' in p:\n                found = findall(p)\n                if found:\n                    # Only get the path which is absolute\n                    results.extend(f for f in found if f[0] == '/')\n        return list(set(results))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncommanding JBoss standalone main config files", "response": "def jboss_standalone_main_config_files(broker):\n        \"\"\"Command: JBoss standalone main config files\"\"\"\n        ps = broker[DefaultSpecs.ps_auxww].content\n        results = []\n        search = re.compile(r\"\\-Djboss\\.server\\.base\\.dir=(\\S+)\").search\n        # JBoss progress command content should contain jboss.home.dir\n        for p in ps:\n            if '-D[Standalone]' in p:\n                match = search(p)\n                # Only get the path which is absolute\n                if match and match.group(1)[0] == \"/\":\n                    main_config_path = match.group(1)\n                    main_config_file = \"standalone.xml\"\n                    if \" -c \" in p:\n                        main_config_file = p.split(\" -c \")[1].split()[0]\n                    elif \"--server-config\" in p:\n                        main_config_file = p.split(\"--server-config=\")[1].split()[0]\n                    results.append(main_config_path + \"/\" + main_config_file)\n        return list(set(results))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef from_dict(self, dirent):\n        # Check that we have at least as much data as the __init__ requires\n        for k in ['perms', 'owner', 'group', 'name', 'dir']:\n            if k not in dirent:\n                raise ValueError(\"Need required key '{k}'\".format(k=k))\n        # Copy all values across\n        for k in dirent:\n            setattr(self, k, dirent[k])\n        # Create perms parts\n        self.perms_owner = self.perms[0:3]\n        self.perms_group = self.perms[3:6]\n        self.perms_other = self.perms[6:9]\n        return self", "response": "Create a new object from a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef owned_by(self, owner, also_check_group=False):\n        if also_check_group:\n            return self.owner == owner and self.group == owner\n        else:\n            return self.owner == owner", "response": "Checks if the specified user or group own the file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if only root user can read the file.", "response": "def only_root_can_read(self, root_group_can_read=True):\n        \"\"\"\n        Checks if only root is allowed to read the file (and anyone else is\n        forbidden from reading). Write and execute bits are not checked. The\n        read bits for root user/group are not checked because root can\n        read/write anything regardless of the read/write permissions.\n\n        When called with ``root_root_group_can_read`` = ``True``:\n\n        * owner must be root\n        * and 'others' permissions must not contain read\n        * and if group owner is not root, the 'group' permissions must not\n          contain read\n\n        Valid cases::\n\n            rwxrwxrwx    owner   ownergroup\n            -------------------------------\n            ???-??-??    root    nonroot\n            ??????-??    root    root\n            r--r-----    root    root\n            r--------    root    nonroot\n            rwxrwx---    root    root\n            rwxrwx-wx    root    root\n\n        Specifically, these cases are NOT valid because the owner can chmod\n        permissions and grant themselves permissions without root's\n        knowledge::\n\n            rwxrwxrwx    owner   ownergroup\n            -------------------------------\n            -??-??-??    nonroot nonroot\n            -??r??-??    nonroot root\n            ---------    nonroot nonroot\n\n        When called with ``root_root_group_can_read`` = ``False``:\n\n        * owner must be root\n        * and 'group' and 'others' permissions must not contain read\n\n        Valid cases::\n\n            rwxrwxrwx    owner   ownergroup\n            -------------------------------\n            ???-??-??    root    ?\n            r--------    root    root\n            r--------    root    nonroot\n            rwx-wx---    root    root\n            rwx-wx---    root    nonroot\n            rwx-wxrwx    root    nonroot\n\n        Specifically, these cases are NOT valid because the owner can chmod\n        permissions and grant themselves permissions without root's\n        knowledge::\n\n            rwxrwxrwx    owner   ownergroup\n            -------------------------------\n            -??-??-??    nonroot nonroot\n            ---------    nonroot nonroot\n\n        Args:\n            root_group_can_read (bool): if set to True, this tests whether the\n            'root' group can also read the file.\n\n        Returns:\n            bool: True if only root user (or optionally root group) can read\n            the file.\n        \"\"\"\n\n        requirements = True  # The final answer is progressively assembled in this variable.\n        requirements &= self.owner == 'root'\n        requirements &= not self.others_can_read()\n        if root_group_can_read:\n            if self.group != 'root':\n                # if group is not root, group must not be able to read\n                requirements &= not self.group_can_read()\n        else:  # root_group_can_read == False\n            requirements &= not self.group_can_read()\n        return requirements"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if only root user can write the file.", "response": "def only_root_can_write(self, root_group_can_write=True):\n        \"\"\"\n        Checks if only root is allowed to write the file (and anyone else is\n        barred from writing). Read and execute bits are not checked. The\n        write bits for root user/group are not checked because root can\n        read/write anything regardless of the read/write permissions.\n\n        When called with ``root_root_group_can_write`` = ``True``:\n\n        * owner must be root\n        * and 'others' permissions must not contain write\n        * and if group owner is not root, the 'group' permissions must not contain write\n\n        Valid cases::\n\n            rwxrwxrwx    owner   ownergroup\n            -------------------------------\n            ????-??-?    root    nonroot\n            ???????-?    root    root\n            -w--w----    root    root\n            -w-------    root    root\n            rwxrwx---    root    root\n            rwxrwxr-x    root    root\n\n        Specifically, these cases are NOT valid because the owner can chmod\n        permissions and grant themselves permissions without root's\n        knowledge::\n\n            rwxrwxrwx    owner   ownergroup\n            -------------------------------\n            ?-??-??-?    nonroot nonroot\n            ?-??w??-?    nonroot root\n            ---------    nonroot nonroot\n\n        When called with ``root_root_group_can_write`` = ``False``:\n\n        * owner must be root\n        * and 'group' and 'others' permissions must not contain write\n\n        Valid cases::\n\n            rwxrwxrwx    owner   ownergroup\n            -------------------------------\n            ????-??-?    root    ?\n            -w-------    root    root\n            -w-------    root    nonroot\n            rwxr-x---    root    root\n            rwxr-x---    root    nonroot\n            rwxr-xrwx    root    nonroot\n\n        Specifically, these cases are NOT valid because the owner can chmod\n        permissions and grant themselves permissions without root's\n        knowledge::\n\n            rwxrwxrwx    owner   ownergroup\n            -------------------------------\n            ?-??-??-?    nonroot nonroot\n            ---------    nonroot nonroot\n\n        Args:\n            root_group_can_write (bool): if set to True, this tests whether\n            'root' group can also write to the file.\n\n        Returns:\n            bool: True if only root user (or optionally root group) can write\n            the file.\n        \"\"\"\n\n        requirements = True  # The final answer is progressively assembled in this variable.\n        requirements &= self.owner == 'root'\n        requirements &= not self.others_can_write()\n        if root_group_can_write:\n            if self.group != 'root':\n                # if group is not root, group must not be able to write\n                requirements &= not self.group_can_write()\n        else:  # root_group_can_write == False\n            requirements &= not self.group_can_write()\n        return requirements"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef all_zero(self):\n        _PERM_NOTHING = '---'\n        return all((\n            self.perms_owner == _PERM_NOTHING,\n            self.perms_group == _PERM_NOTHING,\n            self.perms_other == _PERM_NOTHING,\n        ))", "response": "Checks that all permissions are zero."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_tree(root=None):\n    from insights import run\n    return run(MultipathConfTree, root=root).get(MultipathConfTree)", "response": "Returns a multipath configuration component for a single node."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a multipath configuration tree from initramfs.", "response": "def get_tree_from_initramfs(root=None):\n    \"\"\"\n    This is a helper function to get a multipath configuration(from initramfs\n    image) component for your local machine or an archive. It's for use in\n    interactive sessions.\n    \"\"\"\n    from insights import run\n    return run(MultipathConfTreeInitramfs, root=root).get(MultipathConfTreeInitramfs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a parser for the log entries.", "response": "def _create_parser(cls):\n        \"\"\"\n        Need to check the specific symbol \"/\" in attr_value part as well.\n        I checked some multipath configuraion files from the sosreport and got\n        although there are some more specific symbols like \"-%\", it is enclosed\n        in double quotes and will be accepted. Furthermore, I also checked the\n        source code of \"device-mapper-multipath\" and got if the attr_value in\n        \"multipath.conf\" include a \"whitespace\", it must be enclosed in double\n        quotation marks. So, we could just add one more specific symbol \"/\" to\n        check.\n        ----------------------------------------------------------\n        udev_dir                /dev\n        getuid_callout          \"/sbin/scsi_id -g -u -s /block/%n\"\n        ----------------------------------------------------------\n        \"\"\"\n        section_name = p.Word(p.alphas + \"_\")\n        attr_name = attr_value = p.Word(p.alphanums + \"_/\")\n        LBRACE, RBRACE = map(p.Suppress, \"{}\")\n        attr = p.Group(attr_name + (attr_value | p.quotedString.setParseAction(p.removeQuotes)))\n        attr_list = p.Dict(p.ZeroOrMore(attr))\n        simple_section = p.Group(section_name + LBRACE + attr_list + RBRACE)\n        complex_section = p.Group(section_name + LBRACE + p.OneOrMore(simple_section) + RBRACE)\n        simple_or_complex = p.Dict(simple_section | complex_section)\n        my_conf = p.Group(p.ZeroOrMore(simple_or_complex))\n        my_conf.ignore(\"#\" + p.restOfLine)\n        return my_conf"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _support_diag_dump(self):\n        '''\n        Collect log info for debug\n        '''\n        # check insights config\n        cfg_block = []\n\n        pconn = InsightsConnection(self.config)\n        logger.info('Insights version: %s', get_nvr())\n\n        reg_check = registration_check(pconn)\n        cfg_block.append('Registration check:')\n        for key in reg_check:\n            cfg_block.append(key + ': ' + str(reg_check[key]))\n\n        lastupload = 'never'\n        if os.path.isfile(constants.lastupload_file):\n            with open(constants.lastupload_file) as upl_file:\n                lastupload = upl_file.readline().strip()\n        cfg_block.append('\\nLast successful upload was ' + lastupload)\n\n        cfg_block.append('auto_config: ' + str(self.config.auto_config))\n        if self.config.proxy:\n            obfuscated_proxy = re.sub(r'(.*)(:)(.*)(@.*)',\n                                      r'\\1\\2********\\4',\n                                      self.config.proxy)\n        else:\n            obfuscated_proxy = 'None'\n        cfg_block.append('proxy: ' + obfuscated_proxy)\n\n        logger.info('\\n'.join(cfg_block))\n        logger.info('python-requests: %s', requests.__version__)\n\n        succ = pconn.test_connection()\n        if succ == 0:\n            logger.info('Connection test: PASS\\n')\n        else:\n            logger.info('Connection test: FAIL\\n')\n\n        # run commands\n        commands = ['uname -a',\n                    'cat /etc/redhat-release',\n                    'env',\n                    'sestatus',\n                    'subscription-manager identity',\n                    'systemctl cat insights-client.timer',\n                    'systemctl cat insights-client.service',\n                    'systemctl status insights-client.timer',\n                    'systemctl status insights-client.service']\n        for cmd in commands:\n            logger.info(\"Running command: %s\", cmd)\n            try:\n                proc = Popen(\n                    shlex.split(cmd), shell=False, stdout=PIPE, stderr=STDOUT,\n                    close_fds=True)\n                stdout, stderr = proc.communicate()\n            except OSError as o:\n                if 'systemctl' not in cmd:\n                    # suppress output for systemctl cmd failures\n                    logger.info('Error running command \"%s\": %s', cmd, o)\n            except Exception as e:\n                # unknown error\n                logger.info(\"Process failed: %s\", e)\n            logger.info(\"Process output: \\n%s\", stdout)\n        # check available disk space for /var/tmp\n        tmp_dir = '/var/tmp'\n        dest_dir_stat = os.statvfs(tmp_dir)\n        dest_dir_size = (dest_dir_stat.f_bavail * dest_dir_stat.f_frsize)\n        logger.info('Available space in %s:\\t%s bytes\\t%.1f 1K-blocks\\t%.1f MB',\n                    tmp_dir, dest_dir_size,\n                    dest_dir_size / 1024.0,\n                    (dest_dir_size / 1024.0) / 1024.0)", "response": "Collect log info for debug and debug log info for debug_diag"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_filter(ds, patterns):\n    if not plugins.is_datasource(ds):\n        raise Exception(\"Filters are applicable only to datasources.\")\n\n    delegate = dr.get_delegate(ds)\n\n    if delegate.raw:\n        raise Exception(\"Filters aren't applicable to raw datasources.\")\n\n    if not delegate.filterable:\n        raise Exception(\"Filters aren't applicable to %s.\" % dr.get_name(ds))\n\n    if ds in _CACHE:\n        del _CACHE[ds]\n    if isinstance(patterns, six.string_types):\n        FILTERS[ds].add(patterns)\n    elif isinstance(patterns, list):\n        FILTERS[ds] |= set(patterns)\n    elif isinstance(patterns, set):\n        FILTERS[ds] |= patterns\n    else:\n        raise TypeError(\"patterns must be string, list, or set.\")", "response": "Add a filter or list of filters to a datasource."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_filters(component):\n    def inner(c, filters=None):\n        filters = filters or set()\n        if not ENABLED:\n            return filters\n\n        if not plugins.is_datasource(c):\n            return filters\n\n        if c in FILTERS:\n            filters |= FILTERS[c]\n\n        for d in dr.get_dependents(c):\n            filters |= inner(d, filters)\n        return filters\n\n    if component not in _CACHE:\n        _CACHE[component] = inner(component)\n    return _CACHE[component]", "response": "Returns the set of filters that can be applied to all datasources that implement the given datasource."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef apply_filters(target, lines):\n    filters = get_filters(target)\n    if filters:\n        for l in lines:\n            if any(f in l for f in filters):\n                yield l\n    else:\n        for l in lines:\n            yield l", "response": "Yields the lines of a single in - sequence that match the filters in the source."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef loads(string):\n    d = _loads(string)\n    for k, v in d.items():\n        FILTERS[dr.get_component(k) or k] = set(v)", "response": "Loads the filters dictionary given a string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading the filter list from a file or a stream.", "response": "def load(stream=None):\n    \"\"\"\n    Loads filters from a stream, normally an open file. If one is\n    not passed, filters are loaded from a default location within\n    the project.\n    \"\"\"\n    if stream:\n        loads(stream.read())\n    else:\n        data = pkgutil.get_data(insights.__name__, _filename)\n        return loads(data) if data else None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a string representation of the FILTERS dictionary.", "response": "def dumps():\n    \"\"\"Returns a string representation of the FILTERS dictionary.\"\"\"\n    d = {}\n    for k, v in FILTERS.items():\n        d[dr.get_name(k)] = list(v)\n    return _dumps(d)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndumping a string representation of FILTERS to a stream.", "response": "def dump(stream=None):\n    \"\"\"\n    Dumps a string representation of `FILTERS` to a stream, normally an\n    open file. If none is passed, `FILTERS` is dumped to a default location\n    within the project.\n    \"\"\"\n    if stream:\n        stream.write(dumps())\n    else:\n        path = os.path.join(os.path.dirname(insights.__file__), _filename)\n        with open(path, \"wu\") as f:\n            f.write(dumps())"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _parse_line(sep, line):\n    strs = line.split(sep, 1)\n    return (strs[0].strip(), None) if len(strs) == 1 else (strs[0].strip(), strs[1].strip())", "response": "Parse a grub commands or config line with format cmd opts"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _parse_script(list, line, line_iter):\n    ifIdx = 0\n    while (True):\n        line = next(line_iter)\n        if line.startswith(\"fi\"):\n            if ifIdx == 0:\n                return\n            ifIdx -= 1\n        elif line.startswith(\"if\"):\n            ifIdx += 1", "response": "Parse a bash script from the grub v2 configuration."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse each menuentry in line_iter and add it to conf.", "response": "def _parse_menu_entry(line_iter, cur_line, conf):\n    \"\"\"\n    Parse each `menuentry` that the grub v2 configuration contains\n    * Uses \"_parse_script\" to eliminate bash scripts\n    \"\"\"\n    menu = []\n    conf['menuentry'].append(menu)\n    n, entry = _parse_line(\"menuentry\", cur_line)\n\n    entry_name, v = _parse_line(\"{\", entry)\n    if not entry_name:\n        raise Exception(\"Cannot parse menuentry line: {0}\".format(cur_line))\n\n    menu.append(('menuentry_name', entry_name))\n    if v:\n        menu.append(_parse_cmd(v))\n\n    while (True):\n        line = next(line_iter)\n        if \"{\" in line:\n            n, v = _parse_line(\"{\", line)\n            if v:\n                menu.append(_parse_cmd(v))\n        elif \"}\" in line:\n            n, v = _parse_line(\"}\", line)\n            if n:\n                menu.append(_parse_cmd(n))\n            return\n        elif line.startswith(\"if\"):\n            _parse_script(menu, line, line_iter)\n\n        else:\n            menu.append(_parse_cmd(line))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing the title section of grub v1 config", "response": "def _parse_title(line_iter, cur_line, conf):\n    \"\"\"\n    Parse \"title\" in grub v1 config\n    \"\"\"\n    title = []\n    conf['title'].append(title)\n    title.append(('title_name', cur_line.split('title', 1)[1].strip()))\n    while (True):\n        line = next(line_iter)\n        if line.startswith(\"title \"):\n            return line\n\n        cmd, opt = _parse_cmd(line)\n        title.append((cmd, opt))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses grub configuration file to create a dict with this structure.", "response": "def parse_content(self, content):\n        \"\"\"\n        Parse grub configuration file to create a dict with this structure::\n\n            {\n                \"configs\": [ (name, value), (name, value) ...],\n                \"title\": [\n                    [(title_name, name), (cmd, opt), (cmd, opt) ...],\n                    [(title_name, another_name), ...]\n                ],\n                \"menuentry\": [\n                    [(menuentry_name, its name), (cmd, opt), (cmd, opt) ...],\n                    [(menuentry_name, another_name), ...]\n                ],\n            }\n        \"\"\"\n\n        line_iter = iter(get_active_lines(content))\n        conf = {\"configs\": [], \"title\": [], \"menuentry\": []}\n        line = None\n\n        while (True):\n            try:\n\n                if line is None:\n                    line = next(line_iter)\n\n                if line.startswith('title '):\n                    last_line = _parse_title(line_iter, line, conf)\n                    line = last_line\n                elif line.startswith('menuentry '):\n                    _parse_menu_entry(line_iter, line, conf)\n                    line = None\n                else:\n                    conf[\"configs\"].append(_parse_config(line))\n                    line = None\n\n            except StopIteration:\n                self.data = conf\n                break\n\n        if not self.data.get('title'):\n            self.data.pop('title')\n        if not self.data.get('menuentry'):\n            self.data.pop('menuentry')\n        if not self.data.get('configs'):\n            self.data.pop('configs')\n\n        for line_full in self.data.get('title', []) + self.data.get('menuentry', []):\n            for name, line in line_full:\n                if name == 'menuentry_name' or name == 'title_name':\n                    entry = {}\n                    entry['name'] = line\n                elif entry and name.startswith(('kernel', 'linux')):\n                    entry['cmdline'] = line\n                    self._boot_entries.append(BootEntry(entry))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns True if the kdump IOMMU is enabled False otherwise.", "response": "def is_kdump_iommu_enabled(self):\n        \"\"\"\n        Does any kernel have 'intel_iommu=on' set?\n\n        Returns:\n            (bool): ``True`` when 'intel_iommu=on' is set, otherwise returns ``False``\n        \"\"\"\n\n        for line in self._boot_entries:\n            if line.cmdline and IOMMU in line.cmdline:\n                return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef kernel_initrds(self):\n\n        kernels = []\n        initrds = []\n        name_values = [(k, v) for k, v in self.data.get('configs', [])]\n        for value in self.data.get('title', []) + self.data.get('menuentry', []):\n            name_values.extend(value)\n\n        for name, value in name_values:\n            if name.startswith('module'):\n                if 'vmlinuz' in value:\n                    kernels.append(_parse_kernel_initrds_value(value))\n                elif 'initrd' in value or 'initramfs' in value:\n                    initrds.append(_parse_kernel_initrds_value(value))\n            elif (name.startswith(('kernel', 'linux'))):\n                if 'ipxe.lkrn' in value:\n                    # Machine PXE boots the kernel, assume all is ok\n                    return {}\n                elif 'xen.gz' not in value:\n                    kernels.append(_parse_kernel_initrds_value(value))\n            elif name.startswith('initrd') or name.startswith('initrd16'):\n                initrds.append(_parse_kernel_initrds_value(value))\n\n        return {GRUB_KERNELS: kernels, GRUB_INITRDS: initrds}", "response": "Returns a dict of the kernel and initrd files referenced in GRUB configuration files\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef deserializer(_type):\n\n    def inner(func):\n        name = dr.get_name(_type)\n        if name in DESERIALIZERS:\n            msg = \"%s already has a deserializer registered: %s\"\n            raise Exception(msg % (dr.get_name(name), dr.get_name(DESERIALIZERS[name])))\n        DESERIALIZERS[name] = (_type, func)\n        return func\n    return inner", "response": "Decorator for deserializers.\n\n    A deserializer should accept three parameters: A type, a dictionary, and a\n    path that may contain supplementary data stored by its paired serializer.\n    If the serializer stores supplementary data, the relative path to it should\n    be somewhere in the dict of the second parameter."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _hydrate_one(self, doc):\n        name = doc[\"name\"]\n\n        key = dr.get_component_by_name(name)\n        if key is None:\n            raise ValueError(\"{} is not a loaded component.\".format(name))\n        exec_time = doc[\"exec_time\"]\n        ser_time = doc[\"ser_time\"]\n        results = unmarshal(doc[\"results\"], root=self.data)\n        return (key, results, exec_time, ser_time)", "response": "Deserialize a single object from the database into a tuple."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading a Broker from a previously saved one.", "response": "def hydrate(self, broker=None):\n        \"\"\"\n        Loads a Broker from a previously saved one. A Broker is created if one\n        isn't provided.\n        \"\"\"\n        broker = broker or dr.Broker()\n        for path in glob(os.path.join(self.meta_data, \"*\")):\n            try:\n                with open(path) as f:\n                    doc = ser.load(f)\n                    res = self._hydrate_one(doc)\n                    comp, results, exec_time, ser_time = res\n                    if results:\n                        broker[comp] = results\n                        broker.exec_times[comp] = exec_time + ser_time\n            except Exception as ex:\n                log.warning(ex)\n        return broker"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dehydrate(self, comp, broker):\n        if not self.meta_data:\n            raise Exception(\"Hydration meta_path not set. Can't dehydrate.\")\n\n        if not self.created:\n            fs.ensure_path(self.meta_data, mode=0o770)\n            if self.data:\n                fs.ensure_path(self.data, mode=0o770)\n            self.created = True\n\n        c = comp\n        doc = None\n        try:\n            name = dr.get_name(c)\n            value = broker.get(c)\n            errors = [t for e in broker.exceptions.get(c, [])\n                        for t in broker.tracebacks[e]]\n            doc = {\n                \"name\": name,\n                \"exec_time\": broker.exec_times.get(c),\n                \"errors\": errors\n            }\n\n            try:\n                start = time.time()\n                doc[\"results\"] = marshal(value, root=self.data, pool=self.pool)\n            except Exception:\n                errors.append(traceback.format_exc())\n                log.debug(traceback.format_exc())\n                doc[\"results\"] = None\n            finally:\n                doc[\"ser_time\"] = time.time() - start\n        except Exception as ex:\n            log.exception(ex)\n        else:\n            if doc is not None and (doc[\"results\"] or doc[\"errors\"]):\n                try:\n                    path = os.path.join(self.meta_data, name + \".\" + self.ser_name)\n                    with open(path, \"w\") as f:\n                        ser.dump(doc, f)\n                except Exception as boom:\n                    log.error(\"Could not serialize %s to %s: %r\" % (name, self.ser_name, boom))\n                    if path:\n                        fs.remove(path)", "response": "Dehydrates a component in the given broker to the file system."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a function that hydrates components as they are evaluated.", "response": "def make_persister(self, to_persist):\n        \"\"\"\n        Returns a function that hydrates components as they are evaluated. The\n        function should be registered as an observer on a Broker just before\n        execution.\n\n        Args:\n            to_persist (set): Set of components to persist. Skip everything\n                else.\n        \"\"\"\n\n        if not self.meta_data:\n            raise Exception(\"Root not set. Can't create persister.\")\n\n        def persister(c, broker):\n            if c in to_persist:\n                self.dehydrate(c, broker)\n        return persister"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmapping human readable key names to dictionary while leaving any existing key names.", "response": "def map_keys(pvs, keys):\n    \"\"\"\n    Add human readable key names to dictionary while leaving any existing key names.\n    \"\"\"\n    rs = []\n    for pv in pvs:\n        r = dict((v, None) for k, v in keys.items())\n        for k, v in pv.items():\n            if k in keys:\n                r[keys[k]] = v\n            r[k] = v\n        rs.append(r)\n    return rs"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find_warnings(content):\n    keywords = [k.lower() for k in [\n        \"WARNING\", \"Couldn't find device\", \"Configuration setting\",\n        \"read failed\", \"Was device resized?\", \"Invalid argument\",\n        \"leaked on lvs\", \"Checksum error\", \"is exported\", \"failed.\",\n        \"Invalid metadata\", \"response failed\", \"unknown device\",\n        \"duplicate\", \"not found\", \"Missing device\", \"Internal error\",\n        \"Input/output error\", \"Incorrect metadata\", \"Cannot process volume\",\n        \"No such file or directory\", \"Logging initialised\", \"changed sizes\",\n        \"vsnprintf failed\", \"write failed\", \"correction failed\",\n        \"Failed to write\", \"Couldn't read\", \"marked missing\",\n        \"Attempt to close device\", \"Ignoring supplied major\",\n        \"not match metadata\"\n    ]]\n    for l in content:\n        lower = l.strip().lower()\n        # Avoid hitting keywords inside the data\n        if not lower.startswith('lvm2'):\n            if any(k in lower for k in keywords):\n                yield l", "response": "Find all warning lines that are not part of the data."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_dict(dct):\n    def inner(d):\n        results = []\n        for name, v in d.items():\n            if isinstance(v, dict):\n                results.append(Section(name=name, children=from_dict(v)))\n            elif isinstance(v, list):\n                if not any(isinstance(i, dict) for i in v):\n                    results.append(Directive(name=name, attrs=v))\n                else:\n                    for i in v:\n                        if isinstance(i, dict):\n                            results.append(Section(name=name, children=from_dict(i)))\n                        elif isinstance(i, list):\n                            results.append(Directive(name=name, attrs=i))\n                        else:\n                            results.append(Directive(name=name, attrs=[i]))\n            else:\n                results.append(Directive(name, attrs=[v]))\n        return results\n    return Root(children=inner(dct))", "response": "Convert a dictionary into a configtree."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef __or(funcs, args):\n    results = []\n    for f in funcs:\n        result = f(args)\n        if result:\n            results.extend(result)\n    return results", "response": "Support list sugar for or of two predicates. Used inside select."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a Predicate that returns True if the predicate evaluates to True otherwise False.", "response": "def BinaryBool(pred):\n    \"\"\" Lifts predicates that take an argument into the DSL. \"\"\"\n    class Predicate(Bool):\n        def __init__(self, value, ignore_case=False):\n            self.value = caseless(value) if ignore_case else value\n            self.ignore_case = ignore_case\n\n        def __call__(self, data):\n            if not isinstance(data, list):\n                data = [data]\n            for d in data:\n                try:\n                    if pred(caseless(d) if self.ignore_case else d, self.value):\n                        return True\n                except:\n                    pass\n            return False\n    return Predicate"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef select(*queries, **kwargs):\n    def make_query(*args):\n        def simple_query(nodes):\n            if len(args) == 0:\n                return nodes\n            pred = args[0]\n            results = []\n            if isinstance(pred, list):\n                funcs = [make_query(q) for q in pred]\n                return __or(funcs, nodes)\n            elif isinstance(pred, tuple):\n                name, attrs = pred[0], pred[1:]\n                name_pred = __make_name_pred(name)\n                attrs_pred = __make_attrs_pred(attrs)\n                for n in nodes:\n                    if name_pred(n.name) and attrs_pred(n.attrs):\n                        results.append(n)\n            else:\n                name_pred = __make_name_pred(pred)\n                for n in nodes:\n                    if name_pred(n.name):\n                        results.append(n)\n            return results\n        if len(args) > 1:\n            return __compose(make_query(*args[1:]), simple_query)\n        return simple_query\n\n    def deep_query(query, nodes):\n        \"\"\" Slide the query down the branches. \"\"\"\n        def inner(children):\n            results = []\n            for c in children:\n                if query([c]):\n                    results.append(c)\n                results.extend(inner(c.children))\n            return results\n        return inner(nodes)\n\n    def unique(roots):\n        seen = set()\n        results = []\n        for r in roots:\n            if r not in seen:\n                seen.add(r)\n                results.append(r)\n        return results\n\n    def compiled_query(nodes):\n        \"\"\"\n        This is the compiled query that can be run against a configuration.\n        \"\"\"\n        query = make_query(*queries)\n\n        roots = kwargs.get(\"roots\", True)\n        if kwargs.get(\"deep\", False):\n            results = deep_query(query, nodes)\n            if roots:\n                results = unique([r.root for r in results])\n        elif roots:\n            results = unique([n.root for n in query(nodes)])\n        else:\n            results = query(nodes)\n\n        one = kwargs.get(\"one\")\n        if one is None:\n            return SearchResult(children=results)\n        return results[one] if results else None\n    return compiled_query", "response": "Builds a function that will execute the specified queries against a list of nodes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the first result found anywhere in the configuration.", "response": "def find(self, *queries, **kwargs):\n        \"\"\"\n        Finds the first result found anywhere in the configuration. Pass\n        `one=last` for the last result. Returns `None` if no results are found.\n        \"\"\"\n        kwargs[\"deep\"] = True\n        kwargs[\"roots\"] = False\n        if \"one\" not in kwargs:\n            kwargs[\"one\"] = first\n        return self.select(*queries, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinding all results matching the query anywhere in the configuration.", "response": "def find_all(self, *queries):\n        \"\"\"\n        Find all results matching the query anywhere in the configuration.\n        Returns an empty `SearchResult` if no results are found.\n        \"\"\"\n        return self.select(*queries, deep=True, roots=False)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pad_version(left, right):\n    pair = vcmp(left), vcmp(right)\n\n    mn, mx = min(pair, key=len), max(pair, key=len)\n\n    for idx, c in enumerate(mx):\n\n        try:\n            a = mx[idx]\n            b = mn[idx]\n            if type(a) != type(b):\n                mn.insert(idx, 0)\n        except IndexError:\n            if type(c) is int:\n                mn.append(0)\n            elif isinstance(c, six.string_types):\n                mn.append('')\n            else:\n                raise Exception(\"pad_version failed (%s) (%s)\" % (left, right))\n\n    return pair", "response": "Returns two sequences of the same length so that they can be compared."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _parse_package(cls, package_string):\n        pkg, arch = rsplit(package_string, cls._arch_sep(package_string))\n        if arch not in KNOWN_ARCHITECTURES:\n            pkg, arch = (package_string, None)\n        pkg, release = rsplit(pkg, '-')\n        name, version = rsplit(pkg, '-')\n        epoch, version = version.split(':', 1) if \":\" in version else ['0', version]\n        # oracleasm packages have a dash in their version string, fix that\n        if name.startswith('oracleasm') and name.endswith('.el5'):\n            name, version2 = name.split('-', 1)\n            version = version2 + '-' + version\n        return {\n            'name': name,\n            'version': version,\n            'release': release,\n            'arch': arch,\n            'epoch': epoch\n        }", "response": "Helper method for parsing a package string."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _parse_line(cls, line):\n        try:\n            pkg, rest = line.split(None, 1)\n        except ValueError:\n            rpm = cls._parse_package(line.strip())\n            return rpm\n        rpm = cls._parse_package(pkg)\n        rest = rest.split('\\t')\n        for i, value in enumerate(rest):\n            rpm[cls.SOSREPORT_KEYS[i]] = value\n        return rpm", "response": "Helper method for parsing package line with or without SOS report information."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef package(self):\n        return u'{0}-{1}-{2}'.format(self.name,\n                                     self.version,\n                                     self.release)", "response": "str - > str"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef package_with_epoch(self):\n        return u'{0}-{1}:{2}-{3}'.format(self.name,\n                                         self.epoch,\n                                         self.version,\n                                         self.release)", "response": "Return a string representation of the object with the epoch number."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef source(self):\n        if hasattr(self, 'srpm'):\n            rpm = self.from_package(self.srpm)\n            # Source RPMs don't have epoch for some reason\n            rpm.epoch = self.epoch\n            return rpm", "response": "Returns the source RPM of this RPM object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the absolute name of the module to be imported.", "response": "def _resolve_name(name, package, level):\n    \"\"\"Return the absolute name of the module to be imported.\"\"\"\n    if not hasattr(package, 'rindex'):\n        raise ValueError(\"'package' not set to a string\")\n    dot = len(package)\n    for x in xrange(level, 1, -1):\n        try:\n            dot = package.rindex('.', 0, dot)\n        except ValueError:\n            raise ValueError(\"attempted relative import beyond top-level \"\n                              \"package\")\n    return \"%s.%s\" % (package[:dot], name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nimport a module. The 'package' argument is required when performing a relative import. It specifies the package to use as the anchor point from which to resolve the relative import to an absolute import.", "response": "def import_module(name, package=None):\n    \"\"\"Import a module.\n\n    The 'package' argument is required when performing a relative import. It\n    specifies the package to use as the anchor point from which to resolve the\n    relative import to an absolute import.\n\n    \"\"\"\n    if name.startswith('.'):\n        if not package:\n            raise TypeError(\"relative imports require the 'package' argument\")\n        level = 0\n        for character in name:\n            if character != '.':\n                break\n            level += 1\n        name = _resolve_name(name[level:], package, level)\n    __import__(name)\n    return sys.modules[name]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngiving a dmsetup ls output of dmsetup ls this will return themajor : minor of the device deviceName", "response": "def getMajorMinor(deviceName, dmsetupLs):\n    \"\"\"\n    Given output of dmsetup ls this will return\n    themajor:minor (block name) of the device deviceName\n    \"\"\"\n\n    startingIndex = string.rindex(dmsetupLs, deviceName) + len(deviceName)\n    endingIndex = string.index(dmsetupLs[startingIndex:], \"\\n\") + startingIndex\n    # trim the preceding tab and ()'s\n    newStr = dmsetupLs[startingIndex + 2: endingIndex - 1]\n    return newStr"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _handle_key_value(t_dict, key, value):\n    if key in t_dict:\n        val = t_dict[key]\n        if isinstance(val, str):\n            val = [val]\n        val.append(value)\n        return val\n    return value", "response": "Function to handle key value pair in the dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the first formatter class that matches the given name.", "response": "def get_formatter(name):\n    \"\"\"\n    Looks up a formatter class given a prefix to it.\n    The names are sorted, and the first matching class is returned.\n    \"\"\"\n    for k in sorted(_FORMATTERS):\n        if k.startswith(name):\n            return _FORMATTERS[k]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmangling a command line string into something suitable for use as a filename.", "response": "def mangle_command(command, name_max=255, has_variables=False):\n    \"\"\"\n    Mangle a command line string into something suitable for use as the basename of a filename.\n    At minimum this function must remove slashes, but it also does other things to clean up\n    the basename: removing directory names from the command name, replacing many non-typical\n    characters with undersores, in addition to replacing slashes with dots.\n\n    By default, curly braces, '{' and '}', are replaced with underscore, set 'has_variables'\n    to leave curly braces alone.\n\n    This function was copied from the function that insights-client uses to create the name it uses\n    to capture the output of the command.\n\n    Here, server side, it is used to figure out what file in the archive contains the output of\n    a command.  Server side, the command may contain references to variables (names within\n    matching curly braces) that will be expanded before the name is actually used as a file name.\n\n    To completly mimic the insights-client behavior, curly braces need to be replaced with\n    underscores.  If the command has variable references, the curly braces must be left alone.\n    Set has_variables, to leave curly braces alone.\n\n    This implementation of 'has_variables' assumes that variable names only contain characters\n    that are not replaced by mangle_command.\n    \"\"\"\n    if has_variables:\n        pattern = r\"[^\\w\\-\\.\\/{}]+\"\n    else:\n        pattern = r\"[^\\w\\-\\.\\/]+\"\n\n    mangledname = re.sub(r\"^/(usr/|)(bin|sbin)/\", \"\", command)\n    mangledname = re.sub(pattern, \"_\", mangledname)\n    mangledname = re.sub(r\"/\", \".\", mangledname).strip(\" ._-\")\n    mangledname = mangledname[:name_max]\n    return mangledname"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the set of all options used in all export entries", "response": "def all_options(self):\n        \"\"\"Returns the set of all options used in all export entries\"\"\"\n        items = chain.from_iterable(hosts.values() for hosts in self.data.values())\n        return set(chain.from_iterable(items))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef reconstitute(path, d):\n        deprecated(\n            NFSExportsBase.reconstitute,\n            'Please use the `raw_lines` dictionary property of the parser instance'\n        )\n        return \"  \".join([path] + [\"%s(%s)\" % (host, \",\".join(options))\n                         for host, options in d.items()])", "response": "Reconstitute a line from its parsed value."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ninitializing the session with the appropriate headers and proxies", "response": "def _init_session(self):\n        \"\"\"\n        Set up the session, auth is handled here\n        \"\"\"\n        session = requests.Session()\n        session.headers = {'User-Agent': self.user_agent,\n                           'Accept': 'application/json'}\n        if self.systemid is not None:\n            session.headers.update({'systemid': self.systemid})\n        if self.authmethod == \"BASIC\":\n            session.auth = (self.username, self.password)\n        elif self.authmethod == \"CERT\":\n            cert = rhsmCertificate.certpath()\n            key = rhsmCertificate.keypath()\n            if rhsmCertificate.exists():\n                session.cert = (cert, key)\n            else:\n                logger.error('ERROR: Certificates not found.')\n        session.verify = self.cert_verify\n        session.proxies = self.proxies\n        session.trust_env = False\n        if self.proxy_auth:\n            # HACKY\n            try:\n                # Need to make a request that will fail to get proxies set up\n                net_logger.info(\"GET %s\", self.base_url)\n                session.request(\n                    \"GET\", self.base_url, timeout=self.config.http_timeout)\n            except requests.ConnectionError:\n                pass\n            # Major hack, requests/urllib3 does not make access to\n            # proxy_headers easy\n            proxy_mgr = session.adapters['https://'].proxy_manager[self.proxies['https']]\n            auth_map = {'Proxy-Authorization': self.proxy_auth}\n            proxy_mgr.proxy_headers = auth_map\n            proxy_mgr.connection_pool_kw['_proxy_headers'] = auth_map\n            conns = proxy_mgr.pools._container\n            for conn in conns:\n                connection = conns[conn]\n                connection.proxy_headers = auth_map\n        return session"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting proxies from environment variables or configuration file.", "response": "def get_proxies(self):\n        \"\"\"\n        Determine proxy configuration\n        \"\"\"\n        # Get proxy from ENV or Config\n        proxies = None\n        proxy_auth = None\n        no_proxy = os.environ.get('NO_PROXY')\n        logger.debug(\"NO PROXY: %s\", no_proxy)\n\n        # CONF PROXY TAKES PRECEDENCE OVER ENV PROXY\n        conf_proxy = self.config.proxy\n        if ((conf_proxy is not None and\n             conf_proxy.lower() != 'None'.lower() and\n             conf_proxy != \"\")):\n            if '@' in conf_proxy:\n                scheme = conf_proxy.split(':')[0] + '://'\n                logger.debug(\"Proxy Scheme: %s\", scheme)\n                location = conf_proxy.split('@')[1]\n                logger.debug(\"Proxy Location: %s\", location)\n                username = conf_proxy.split(\n                    '@')[0].split(':')[1].replace('/', '')\n                logger.debug(\"Proxy User: %s\", username)\n                password = conf_proxy.split('@')[0].split(':')[2]\n                proxy_auth = requests.auth._basic_auth_str(username, password)\n                conf_proxy = scheme + location\n            logger.debug(\"CONF Proxy: %s\", conf_proxy)\n            proxies = {\"https\": conf_proxy}\n\n        # HANDLE NO PROXY CONF PROXY EXCEPTION VERBIAGE\n        if no_proxy and conf_proxy:\n            logger.debug(\"You have environment variable NO_PROXY set \"\n                         \"as well as 'proxy' set in your configuration file. \"\n                         \"NO_PROXY environment variable will be ignored.\")\n\n        # IF NO CONF PROXY, GET ENV PROXY AND NO PROXY\n        if proxies is None:\n            env_proxy = os.environ.get('HTTPS_PROXY')\n            if env_proxy:\n                if '@' in env_proxy:\n                    scheme = env_proxy.split(':')[0] + '://'\n                    logger.debug(\"Proxy Scheme: %s\", scheme)\n                    location = env_proxy.split('@')[1]\n                    logger.debug(\"Proxy Location: %s\", location)\n                    username = env_proxy.split('@')[0].split(':')[1].replace('/', '')\n                    logger.debug(\"Proxy User: %s\", username)\n                    password = env_proxy.split('@')[0].split(':')[2]\n                    proxy_auth = requests.auth._basic_auth_str(username, password)\n                    env_proxy = scheme + location\n                logger.debug(\"ENV Proxy: %s\", env_proxy)\n                proxies = {\"https\": env_proxy}\n            if no_proxy:\n                insights_service_host = urlparse(self.base_url).hostname\n                logger.debug('Found NO_PROXY set. Checking NO_PROXY %s against base URL %s.', no_proxy, insights_service_host)\n                for no_proxy_host in no_proxy.split(','):\n                    logger.debug('Checking %s against %s', no_proxy_host, insights_service_host)\n                    if no_proxy_host == '*':\n                        proxies = None\n                        proxy_auth = None\n                        logger.debug('Found NO_PROXY asterisk(*) wildcard, disabling all proxies.')\n                        break\n                    elif no_proxy_host.startswith('.') or no_proxy_host.startswith('*'):\n                        if insights_service_host.endswith(no_proxy_host.replace('*', '')):\n                            proxies = None\n                            proxy_auth = None\n                            logger.debug('Found NO_PROXY range %s matching %s', no_proxy_host, insights_service_host)\n                            break\n                    elif no_proxy_host == insights_service_host:\n                        proxies = None\n                        proxy_auth = None\n                        logger.debug('Found NO_PROXY %s exactly matching %s', no_proxy_host, insights_service_host)\n                        break\n\n        self.proxies = proxies\n        self.proxy_auth = proxy_auth"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef handle_fail_rcs(self, req):\n\n        try:\n            logger.debug(\"HTTP Status Code: %s\", req.status_code)\n            logger.debug(\"HTTP Response Text: %s\", req.text)\n            logger.debug(\"HTTP Response Reason: %s\", req.reason)\n            logger.debug(\"HTTP Response Content: %s\", req.content)\n        except:\n            logger.error(\"Malformed HTTP Request.\")\n\n        # attempt to read the HTTP response JSON message\n        try:\n            logger.debug(\"HTTP Response Message: %s\", req.json()[\"message\"])\n        except:\n            logger.debug(\"No HTTP Response message present.\")\n\n        # handle specific status codes\n        if req.status_code >= 400:\n            logger.info(\"Debug Information:\\nHTTP Status Code: %s\",\n                        req.status_code)\n            logger.info(\"HTTP Status Text: %s\", req.reason)\n            if req.status_code == 401:\n                logger.error(\"Authorization Required.\")\n                logger.error(\"Please ensure correct credentials \"\n                             \"in \" + constants.default_conf_file)\n                logger.debug(\"HTTP Response Text: %s\", req.text)\n            if req.status_code == 402:\n                # failed registration because of entitlement limit hit\n                logger.debug('Registration failed by 402 error.')\n                try:\n                    logger.error(req.json()[\"message\"])\n                except LookupError:\n                    logger.error(\"Got 402 but no message\")\n                    logger.debug(\"HTTP Response Text: %s\", req.text)\n                except:\n                    logger.error(\"Got 402 but no message\")\n                    logger.debug(\"HTTP Response Text: %s\", req.text)\n            if req.status_code == 403 and self.auto_config:\n                # Insights disabled in satellite\n                rhsm_hostname = urlparse(self.base_url).hostname\n                if (rhsm_hostname != 'subscription.rhn.redhat.com' and\n                   rhsm_hostname != 'subscription.rhsm.redhat.com'):\n                    logger.error('Please enable Insights on Satellite server '\n                                 '%s to continue.', rhsm_hostname)\n            if req.status_code == 412:\n                try:\n                    unreg_date = req.json()[\"unregistered_at\"]\n                    logger.error(req.json()[\"message\"])\n                    write_unregistered_file(unreg_date)\n                except LookupError:\n                    unreg_date = \"412, but no unreg_date or message\"\n                    logger.debug(\"HTTP Response Text: %s\", req.text)\n                except:\n                    unreg_date = \"412, but no unreg_date or message\"\n                    logger.debug(\"HTTP Response Text: %s\", req.text)\n            return True\n        return False", "response": "Handle HTTP errors that occur in the response of a failed registration."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets Satellite 5 info from systemid file and store it in branch_info.", "response": "def get_satellite5_info(self, branch_info):\n        \"\"\"\n        Get remote_leaf for Satellite 5 Managed box\n        \"\"\"\n        logger.debug(\n            \"Remote branch not -1 but remote leaf is -1, must be Satellite 5\")\n        if os.path.isfile('/etc/sysconfig/rhn/systemid'):\n            logger.debug(\"Found systemid file\")\n            sat5_conf = ET.parse('/etc/sysconfig/rhn/systemid').getroot()\n            leaf_id = None\n            for member in sat5_conf.getiterator('member'):\n                if member.find('name').text == 'system_id':\n                    logger.debug(\"Found member 'system_id'\")\n                    leaf_id = member.find('value').find(\n                        'string').text.split('ID-')[1]\n                    logger.debug(\"Found leaf id: %s\", leaf_id)\n                    branch_info['remote_leaf'] = leaf_id\n            if leaf_id is None:\n                logger.error(\"Could not determine leaf_id!  Exiting!\")\n                return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_branch_info(self):\n        branch_info = None\n        if os.path.exists(constants.cached_branch_info):\n            # use cached branch info file if less than 10 minutes old\n            #  (failsafe, should be deleted at end of client run normally)\n            logger.debug(u'Reading branch info from cached file.')\n            ctime = datetime.utcfromtimestamp(\n                os.path.getctime(constants.cached_branch_info))\n            if datetime.utcnow() < (ctime + timedelta(minutes=5)):\n                with io.open(constants.cached_branch_info, encoding='utf8', mode='r') as f:\n                    branch_info = json.load(f)\n                return branch_info\n            else:\n                logger.debug(u'Cached branch info is older than 5 minutes.')\n\n        logger.debug(u'Obtaining branch information from %s',\n                     self.branch_info_url)\n        net_logger.info(u'GET %s', self.branch_info_url)\n        response = self.session.get(self.branch_info_url,\n                                    timeout=self.config.http_timeout)\n        logger.debug(u'GET branch_info status: %s', response.status_code)\n        if response.status_code != 200:\n            logger.debug(\"There was an error obtaining branch information.\")\n            logger.debug(u'Bad status from server: %s', response.status_code)\n            logger.debug(\"Assuming default branch information %s\" % self.branch_info)\n            return False\n\n        branch_info = response.json()\n        logger.debug(u'Branch information: %s', json.dumps(branch_info))\n\n        # Determine if we are connected to Satellite 5\n        if ((branch_info[u'remote_branch'] is not -1 and\n             branch_info[u'remote_leaf'] is -1)):\n            self.get_satellite5_info(branch_info)\n\n        logger.debug(u'Saving branch info to file.')\n        with io.open(constants.cached_branch_info, encoding='utf8', mode='w') as f:\n            # json.dump is broke in py2 so use dumps\n            bi_str = json.dumps(branch_info, ensure_ascii=False)\n            f.write(bi_str)\n        self.branch_info = branch_info\n        return branch_info", "response": "Retrieve branch info from Satellite Server and return it."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_system(self, new_machine_id=False):\n        client_hostname = determine_hostname()\n        machine_id = generate_machine_id(new_machine_id)\n\n        branch_info = self.branch_info\n        if not branch_info:\n            return False\n\n        remote_branch = branch_info['remote_branch']\n        remote_leaf = branch_info['remote_leaf']\n\n        data = {'machine_id': machine_id,\n                'remote_branch': remote_branch,\n                'remote_leaf': remote_leaf,\n                'hostname': client_hostname}\n        if self.config.display_name is not None:\n            data['display_name'] = self.config.display_name\n        data = json.dumps(data)\n        post_system_url = self.api_url + '/v1/systems'\n        logger.debug(\"POST System: %s\", post_system_url)\n        logger.debug(data)\n        net_logger.info(\"POST %s\", post_system_url)\n        return self.session.post(post_system_url,\n                                 headers={'Content-Type': 'application/json'},\n                                 data=data)", "response": "Create the machine via the API."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef group_systems(self, group_name, systems):\n        api_group_id = None\n        headers = {'Content-Type': 'application/json'}\n        group_path = self.api_url + '/v1/groups'\n        group_get_path = group_path + ('?display_name=%s' % quote(group_name))\n\n        logger.debug(\"GET group: %s\", group_get_path)\n        net_logger.info(\"GET %s\", group_get_path)\n        get_group = self.session.get(group_get_path)\n        logger.debug(\"GET group status: %s\", get_group.status_code)\n        if get_group.status_code == 200:\n            api_group_id = get_group.json()['id']\n\n        if get_group.status_code == 404:\n            # Group does not exist, POST to create\n            logger.debug(\"POST group\")\n            data = json.dumps({'display_name': group_name})\n            net_logger.info(\"POST\", group_path)\n            post_group = self.session.post(group_path,\n                                           headers=headers,\n                                           data=data)\n            logger.debug(\"POST group status: %s\", post_group.status_code)\n            logger.debug(\"POST Group: %s\", post_group.json())\n            self.handle_fail_rcs(post_group)\n            api_group_id = post_group.json()['id']\n\n        logger.debug(\"PUT group\")\n        data = json.dumps(systems)\n        net_logger.info(\"PUT %s\", group_path + ('/%s/systems' % api_group_id))\n        put_group = self.session.put(group_path +\n                                     ('/%s/systems' % api_group_id),\n                                     headers=headers,\n                                     data=data)\n        logger.debug(\"PUT group status: %d\", put_group.status_code)\n        logger.debug(\"PUT Group: %s\", put_group.json())", "response": "Adds an array of systems to a group."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndoing grouping on register", "response": "def do_group(self):\n        \"\"\"\n        Do grouping on register\n        \"\"\"\n        group_id = self.config.group\n        systems = {'machine_id': generate_machine_id()}\n        self.group_systems(group_id, systems)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _legacy_api_registration_check(self):\n        '''\n        Check registration status through API\n        '''\n        logger.debug('Checking registration status...')\n        machine_id = generate_machine_id()\n        try:\n            url = self.api_url + '/v1/systems/' + machine_id\n            net_logger.info(\"GET %s\", url)\n            res = self.session.get(url, timeout=self.config.http_timeout)\n        except requests.ConnectionError:\n            # can't connect, run connection test\n            logger.error('Connection timed out. Running connection test...')\n            self.test_connection()\n            return False\n        # had to do a quick bugfix changing this around,\n        #   which makes the None-False-True dichotomy seem weird\n        #   TODO: reconsider what gets returned, probably this:\n        #       True for registered\n        #       False for unregistered\n        #       None for system 404\n        try:\n            # check the 'unregistered_at' key of the response\n            unreg_status = json.loads(res.content).get('unregistered_at', 'undefined')\n            # set the global account number\n            self.config.account_number = json.loads(res.content).get('account_number', 'undefined')\n        except ValueError:\n            # bad response, no json object\n            return False\n        if unreg_status == 'undefined':\n            # key not found, machine not yet registered\n            return None\n        elif unreg_status is None:\n            # unregistered_at = null, means this machine IS registered\n            return True\n        else:\n            # machine has been unregistered, this is a timestamp\n            return unreg_status", "response": "Check registration status through API"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a system by machine ID Returns dictStandalone system exists in inventory False system does not exist None system does not exist None system error connection or parsing response", "response": "def _fetch_system_by_machine_id(self):\n        '''\n        Get a system by machine ID\n        Returns\n            dict    system exists in inventory\n            False   system does not exist in inventory\n            None    error connection or parsing response\n        '''\n        machine_id = generate_machine_id()\n        try:\n            url = self.api_url + '/inventory/v1/hosts?insights_id=' + machine_id\n            net_logger.info(\"GET %s\", url)\n            res = self.session.get(url, timeout=self.config.http_timeout)\n        except (requests.ConnectionError, requests.Timeout) as e:\n            logger.error(e)\n            logger.error('The Insights API could not be reached.')\n            return None\n        try:\n            if (self.handle_fail_rcs(res)):\n                return None\n            res_json = json.loads(res.content)\n        except ValueError as e:\n            logger.error(e)\n            logger.error('Could not parse response body.')\n            return None\n        if res_json['total'] == 0:\n            logger.debug('No hosts found with machine ID: %s', machine_id)\n            return False\n        return res_json['results']"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck the registration status of a single system.", "response": "def api_registration_check(self):\n        '''\n            Reach out to the inventory API to check\n            whether a machine exists.\n\n            Returns\n                True    system exists in inventory\n                False   system does not exist in inventory\n                None    error connection or parsing response\n        '''\n        if self.config.legacy_upload:\n            return self._legacy_api_registration_check()\n\n        logger.debug('Checking registration status...')\n        results = self._fetch_system_by_machine_id()\n        if not results:\n            return results\n\n        logger.debug('System found.')\n        logger.debug('Machine ID: %s', results[0]['insights_id'])\n        logger.debug('Inventory ID: %s', results[0]['id'])\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef unregister(self):\n        machine_id = generate_machine_id()\n        try:\n            logger.debug(\"Unregistering %s\", machine_id)\n            url = self.api_url + \"/v1/systems/\" + machine_id\n            net_logger.info(\"DELETE %s\", url)\n            self.session.delete(url)\n            logger.info(\n                \"Successfully unregistered from the Red Hat Insights Service\")\n            return True\n        except requests.ConnectionError as e:\n            logger.debug(e)\n            logger.error(\"Could not unregister this system\")\n            return False", "response": "Unregisters this system from the insights service"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nregister this machine - id and return a message and client hostname.", "response": "def register(self):\n        \"\"\"\n        Register this machine\n        \"\"\"\n        client_hostname = determine_hostname()\n        # This will undo a blacklist\n        logger.debug(\"API: Create system\")\n        system = self.create_system(new_machine_id=False)\n        if system is False:\n            return ('Could not reach the Insights service to register.', '', '', '')\n\n        # If we get a 409, we know we need to generate a new machine-id\n        if system.status_code == 409:\n            system = self.create_system(new_machine_id=True)\n        self.handle_fail_rcs(system)\n\n        logger.debug(\"System: %s\", system.json())\n\n        message = system.headers.get(\"x-rh-message\", \"\")\n\n        # Do grouping\n        if self.config.group is not None:\n            self.do_group()\n\n        # Display registration success messasge to STDOUT and logs\n        if system.status_code == 201:\n            try:\n                system_json = system.json()\n                machine_id = system_json[\"machine_id\"]\n                account_number = system_json[\"account_number\"]\n                logger.info(\"You successfully registered %s to account %s.\" % (machine_id, account_number))\n            except:\n                logger.debug('Received invalid JSON on system registration.')\n                logger.debug('API still indicates valid registration with 201 status code.')\n                logger.debug(system)\n                logger.debug(system.json())\n\n        if self.config.group is not None:\n            return (message, client_hostname, self.config.group, self.config.display_name)\n        elif self.config.display_name is not None:\n            return (message, client_hostname, \"None\", self.config.display_name)\n        else:\n            return (message, client_hostname, \"None\", \"\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _legacy_upload_archive(self, data_collected, duration):\n        '''\n        Do an HTTPS upload of the archive\n        '''\n        file_name = os.path.basename(data_collected)\n        try:\n            from insights.contrib import magic\n            m = magic.open(magic.MAGIC_MIME)\n            m.load()\n            mime_type = m.file(data_collected)\n        except ImportError:\n            magic = None\n            logger.debug('python-magic not installed, using backup function...')\n            from .utilities import magic_plan_b\n            mime_type = magic_plan_b(data_collected)\n\n        files = {\n            'file': (file_name, open(data_collected, 'rb'), mime_type)}\n\n        if self.config.analyze_container:\n            logger.debug('Uploading container, image, mountpoint or tarfile.')\n            upload_url = self.upload_url\n        else:\n            logger.debug('Uploading a host.')\n            upload_url = self.upload_url + '/' + generate_machine_id()\n\n        logger.debug(\"Uploading %s to %s\", data_collected, upload_url)\n\n        headers = {'x-rh-collection-time': str(duration)}\n        net_logger.info(\"POST %s\", upload_url)\n        upload = self.session.post(upload_url, files=files, headers=headers)\n\n        logger.debug(\"Upload status: %s %s %s\",\n                     upload.status_code, upload.reason, upload.text)\n        if upload.status_code in (200, 201):\n            the_json = json.loads(upload.text)\n        else:\n            logger.error(\"Upload archive failed with status code  %s\", upload.status_code)\n            return upload\n        try:\n            self.config.account_number = the_json[\"upload\"][\"account_number\"]\n        except:\n            self.config.account_number = None\n        logger.debug(\"Upload duration: %s\", upload.elapsed)\n        return upload", "response": "Do an HTTPS upload of the archive"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupload the archive to the server and return the url of the archive", "response": "def upload_archive(self, data_collected, content_type, duration):\n        \"\"\"\n        Do an HTTPS Upload of the archive\n        \"\"\"\n        if self.config.legacy_upload:\n            return self._legacy_upload_archive(data_collected, duration)\n        file_name = os.path.basename(data_collected)\n        upload_url = self.upload_url\n        c_facts = {}\n\n        try:\n            c_facts = get_canonical_facts()\n        except Exception as e:\n            logger.debug('Error getting canonical facts: %s', e)\n        if self.config.display_name:\n            # add display_name to canonical facts\n            c_facts['display_name'] = self.config.display_name\n        c_facts = json.dumps(c_facts)\n        logger.debug('Canonical facts collected:\\n%s', c_facts)\n\n        files = {\n            'file': (file_name, open(data_collected, 'rb'), content_type),\n            'metadata': c_facts\n        }\n        logger.debug(\"Uploading %s to %s\", data_collected, upload_url)\n\n        net_logger.info(\"POST %s\", upload_url)\n        upload = self.session.post(upload_url, files=files, headers={})\n\n        logger.debug(\"Upload status: %s %s %s\",\n                     upload.status_code, upload.reason, upload.text)\n        logger.debug('Request ID: %s', upload.headers.get('x-rh-insights-request-id', None))\n        if upload.status_code == 202:\n            # 202 from platform, no json response\n            logger.debug(upload.text)\n            # upload = registration on platform\n            write_registered_file()\n        else:\n            logger.error(\n                \"Upload archive failed with status code  %s\",\n                upload.status_code)\n            return upload\n        logger.debug(\"Upload duration: %s\", upload.elapsed)\n        return upload"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_display_name(self, display_name):\n        '''\n        Set display name of a system independently of upload.\n        '''\n        if self.config.legacy_upload:\n            return self._legacy_set_display_name(display_name)\n\n        system = self._fetch_system_by_machine_id()\n        if not system:\n            return system\n        inventory_id = system[0]['id']\n        req_url = self.base_url + '/inventory/v1/hosts/' + inventory_id\n        try:\n            net_logger.info(\"PATCH %s\", req_url)\n            res = self.session.patch(req_url, json={'display_name': display_name})\n        except (requests.ConnectionError, requests.Timeout) as e:\n            logger.error(e)\n            logger.error('The Insights API could not be reached.')\n            return False\n        if (self.handle_fail_rcs(res)):\n            logger.error('Could not update display name.')\n            return False\n        logger.info('Display name updated to ' + display_name + '.')\n        return True", "response": "Set the display name of a system independently of upload."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a list of diagnosis entries from the server.", "response": "def get_diagnosis(self, remediation_id=None):\n        '''\n            Reach out to the platform and fetch a diagnosis.\n            Spirtual successor to --to-json from the old client.\n        '''\n        # this uses machine id as identifier instead of inventory id\n        diag_url = self.base_url + '/remediations/v1/diagnosis/' + generate_machine_id()\n        params = {}\n        if remediation_id:\n            # validate this?\n            params['remediation'] = remediation_id\n        try:\n            net_logger.info(\"GET %s\", diag_url)\n            res = self.session.get(diag_url, params=params, timeout=self.config.http_timeout)\n        except (requests.ConnectionError, requests.Timeout) as e:\n            logger.error(e)\n            logger.error('The Insights API could not be reached.')\n            return False\n        if (self.handle_fail_rcs(res)):\n            logger.error('Unable to get diagnosis data: %s %s',\n                         res.status_code, res.text)\n            return None\n        return res.json()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating the internal dictionary with the given dictionary.", "response": "def _update_dict(self, dict_):\n        '''\n        Update without allowing undefined options or overwrite of class methods\n        '''\n        dict_ = dict((k, v) for k, v in dict_.items() if (\n                    k not in self._init_attrs))\n\n        # zzz\n        if 'no_gpg' in dict_ and dict_['no_gpg']:\n            dict_['gpg'] = False\n\n        unknown_opts = set(dict_.keys()).difference(set(DEFAULT_OPTS.keys()))\n        if unknown_opts and self._print_errors:\n            # only print error once\n            sys.stdout.write(\n                'WARNING: Unknown options: ' +\n                ', '.join(list(unknown_opts)) + '\\n')\n            if 'no_schedule' in unknown_opts:\n                sys.stdout.write('WARNING: Config option `no_schedule` has '\n                                 'been deprecated. To disable automatic '\n                                 'scheduling for Red Hat Insights, run '\n                                 '`insights-client --disable-schedule`\\n')\n        for u in unknown_opts:\n            dict_.pop(u, None)\n        self.__dict__.update(dict_)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading the environment variables and update the dictionary with the values from the environment variables.", "response": "def _load_env(self):\n        '''\n        Options can be set as environment variables\n        The formula for the key is `\"INSIGHTS_%s\" % key.upper()`\n        In English, that's the uppercase version of the config key with\n        \"INSIGHTS_\" prepended to it.\n        '''\n        def _boolify(v):\n            if v.lower() == 'true':\n                return True\n            elif v.lower() == 'false':\n                return False\n            else:\n                return v\n\n        # put this warning here so the error msg only prints once\n        if os.environ.get('HTTP_PROXY') and self._print_errors:\n            sys.stdout.write('WARNING: HTTP_PROXY is unused by insights-client. Please use HTTPS_PROXY.\\n')\n\n        # ignore these env as they are not config vars\n        ignore = ['INSIGHTS_PHASE']\n\n        insights_env_opts = dict((k.lower().split(\"_\", 1)[1], _boolify(v))\n                                 for k, v in os.environ.items()\n                                 if k.upper().startswith(\"INSIGHTS_\") and\n                                 k.upper() not in ignore)\n\n        for k in ['retries', 'cmd_timeout', 'http_timeout']:\n            if k in insights_env_opts:\n                v = insights_env_opts[k]\n                try:\n                    insights_env_opts[k] = float(v) if k == 'http_timeout' else int(v)\n                except ValueError:\n                    raise ValueError(\n                        'ERROR: Invalid value specified for {0}: {1}.'.format(k, v))\n        self._update_dict(insights_env_opts)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _load_command_line(self, conf_only=False):\n        '''\n        Load config from command line switches.\n        NOTE: Not all config is available on the command line.\n        '''\n        # did we already parse cli (i.e. to get conf file)? don't run twice\n        if self._cli_opts:\n            self._update_dict(self._cli_opts)\n            return\n        parser = argparse.ArgumentParser()\n        debug_grp = parser.add_argument_group('Debug options')\n        platf_grp = parser.add_argument_group('Platform options')\n        cli_options = dict((k, v) for k, v in DEFAULT_OPTS.items() if (\n                       'opt' in v))\n        for _, o in cli_options.items():\n            group = o.pop('group', None)\n            if group == 'debug':\n                g = debug_grp\n            elif group == 'platform':\n                g = platf_grp\n            else:\n                g = parser\n            optnames = o.pop('opt')\n            # use argparse.SUPPRESS as CLI defaults so it won't parse\n            #  options that weren't specified\n            o['default'] = argparse.SUPPRESS\n            g.add_argument(*optnames, **o)\n\n        options = parser.parse_args()\n\n        self._cli_opts = vars(options)\n        if conf_only and 'conf' in self._cli_opts:\n            self._update_dict({'conf': self._cli_opts['conf']})\n            return\n\n        self._update_dict(self._cli_opts)", "response": "Load config from command line switches."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _load_config_file(self, fname=None):\n        '''\n        Load config from config file. If fname is not specified,\n        config is loaded from the file named by InsightsConfig.conf\n        '''\n        parsedconfig = ConfigParser.RawConfigParser()\n        try:\n            parsedconfig.read(fname or self.conf)\n        except ConfigParser.Error:\n            if self._print_errors:\n                sys.stdout.write(\n                    'ERROR: Could not read configuration file, '\n                    'using defaults\\n')\n            return\n        try:\n            if parsedconfig.has_section(constants.app_name):\n                d = dict(parsedconfig.items(constants.app_name))\n            elif parsedconfig.has_section('redhat-access-insights'):\n                d = dict(parsedconfig.items('redhat-access-insights'))\n            else:\n                raise ConfigParser.Error\n        except ConfigParser.Error:\n            if self._print_errors:\n                sys.stdout.write(\n                    'ERROR: Could not read configuration file, '\n                    'using defaults\\n')\n            return\n        for key in d:\n            try:\n                if key == 'retries' or key == 'cmd_timeout':\n                    d[key] = parsedconfig.getint(constants.app_name, key)\n                if key == 'http_timeout':\n                    d[key] = parsedconfig.getfloat(constants.app_name, key)\n                if key in DEFAULT_BOOLS and isinstance(\n                        d[key], six.string_types):\n                    d[key] = parsedconfig.getboolean(constants.app_name, key)\n            except ValueError as e:\n                if self._print_errors:\n                    sys.stdout.write(\n                        'ERROR: {0}.\\nCould not read configuration file, '\n                        'using defaults\\n'.format(e))\n                return\n        self._update_dict(d)", "response": "Load config from config file."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads all configuration files and command line options", "response": "def load_all(self):\n        '''\n        Helper function for actual Insights client use\n        '''\n        # check for custom conf file before loading conf\n        self._load_command_line(conf_only=True)\n        self._load_config_file()\n        self._load_env()\n        self._load_command_line()\n        self._imply_options()\n        self._validate_options()\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _validate_options(self):\n        '''\n        Make sure there are no conflicting or invalid options\n        '''\n        if self.obfuscate_hostname and not self.obfuscate:\n            raise ValueError(\n                'Option `obfuscate_hostname` requires `obfuscate`')\n        if self.analyze_image_id is not None and len(self.analyze_image_id) < 12:\n            raise ValueError(\n                'Image/Container ID must be at least twelve characters long.')\n        if self.enable_schedule and self.disable_schedule:\n            raise ValueError(\n                'Conflicting options: --enable-schedule and --disable-schedule')\n        if self.analyze_container and (self.register or self.unregister):\n            raise ValueError('Registration not supported with '\n                             'image or container analysis.')\n        if self.to_json and self.to_stdout:\n            raise ValueError(\n                'Conflicting options: --to-stdout and --to-json')\n        if self.payload and not self.content_type:\n            raise ValueError(\n                '--payload requires --content-type')\n        if not self.legacy_upload:\n            if self.group:\n                raise ValueError(\n                    '--group is not supported at this time.')\n            if self.analyze_image_id:\n                raise ValueError(\n                    '--analyze-image-id is not supported at this time.')\n            if self.analyze_file:\n                raise ValueError(\n                    '--analyze-file is not supported at this time.')\n            if self.analyze_mountpoint:\n                raise ValueError(\n                    '--analyze-mountpoint is not supported at this time.')\n            if self.analyze_container:\n                raise ValueError(\n                    '--analyze-container is not supported at this time.')", "response": "Validate the options for the current object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dict_deep_merge(tgt, src):\n    for k, v in src.items():\n        if k in tgt:\n            if isinstance(tgt[k], dict) and isinstance(v, dict):\n                dict_deep_merge(tgt[k], v)\n            else:\n                tgt[k].extend(deepcopy(v))\n        else:\n            tgt[k] = deepcopy(v)", "response": "Utility function to merge the source dictionary src to the target dictionary tgt"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nactivates an LVM thin device in the docker pool.", "response": "def _activate_thin_device(name, dm_id, size, pool):\n        \"\"\"\n        Provisions an LVM device-mapper thin device reflecting,\n        DM device id 'dm_id' in the docker pool.\n        \"\"\"\n        table = '0 %d thin /dev/mapper/%s %s' % (int(size) // 512, pool, dm_id)\n        cmd = ['dmsetup', 'create', name, '--table', table]\n        r = util.subp(cmd)\n        if r.return_code != 0:\n            raise MountError('Failed to create thin device: %s' %\n                             r.stderr.decode(sys.getdefaultencoding()))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef remove_thin_device(name, force=False):\n        cmd = ['dmsetup', 'remove', '--retry', name]\n        r = util.subp(cmd)\n        if not force:\n            if r.return_code != 0:\n                raise MountError('Could not remove thin device:\\n%s' %\n                                 r.stderr.decode(sys.getdefaultencoding()).split(\"\\n\")[0])", "response": "Removes a thin device from the system."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck dmsetup to see if a device is already active", "response": "def _is_device_active(device):\n        \"\"\"\n        Checks dmsetup to see if a device is already active\n        \"\"\"\n        cmd = ['dmsetup', 'info', device]\n        dmsetup_info = util.subp(cmd)\n        for dm_line in dmsetup_info.stdout.split(\"\\n\"):\n            line = dm_line.split(':')\n            if ('State' in line[0].strip()) and ('ACTIVE' in line[1].strip()):\n                return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_fs(thin_pathname):\n        cmd = ['lsblk', '-o', 'FSTYPE', '-n', thin_pathname]\n        fs_return = util.subp(cmd)\n        return fs_return.stdout.strip()", "response": "Get the file system type of a given thin pathname"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmounting a local path to a local container.", "response": "def mount_path(source, target, bind=False):\n        \"\"\"\n        Subprocess call to mount dev at path.\n        \"\"\"\n        cmd = ['mount']\n        if bind:\n            cmd.append('--bind')\n        cmd.append(source)\n        cmd.append(target)\n        r = util.subp(cmd)\n        if r.return_code != 0:\n            raise MountError('Could not mount docker container:\\n' +\n                             ' '.join(cmd) + '\\n%s' %\n                             r.stderr.decode(sys.getdefaultencoding()))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nretrieving the device mounted at mntpoint.", "response": "def get_dev_at_mountpoint(mntpoint):\n        \"\"\"\n        Retrieves the device mounted at mntpoint, or raises\n        MountError if none.\n        \"\"\"\n        results = util.subp(['findmnt', '-o', 'SOURCE', mntpoint])\n        if results.return_code != 0:\n            raise MountError('No device mounted at %s' % mntpoint)\n\n        stdout = results.stdout.decode(sys.getdefaultencoding())\n        return stdout.replace('SOURCE\\n', '').strip().split('\\n')[-1]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a temporary container from a given iid.", "response": "def _create_temp_container(self, iid):\n        \"\"\"\n        Create a temporary container from a given iid.\n\n        Temporary containers are marked with a sentinel environment\n        variable so that they can be cleaned on unmount.\n        \"\"\"\n        try:\n            return self.client.create_container(\n                image=iid, command='/bin/true',\n                environment=['_ATOMIC_TEMP_CONTAINER'],\n                detach=True, network_disabled=True)['Id']\n        except docker.errors.APIError as ex:\n            raise MountError('Error creating temporary container:\\n%s' % str(ex))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _clone(self, cid):\n        try:\n            iid = self.client.commit(\n                container=cid,\n                conf={\n                    'Labels': {\n                        'io.projectatomic.Temporary': 'true'\n                    }\n                }\n            )['Id']\n        except docker.errors.APIError as ex:\n            raise MountError(str(ex))\n        self.tmp_image = iid\n        return self._create_temp_container(iid)", "response": "Create a temporary image snapshot from a given cid."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a container uuid for identifier.", "response": "def _identifier_as_cid(self, identifier):\n        \"\"\"\n        Returns a container uuid for identifier.\n\n        If identifier is an image UUID or image tag, create a temporary\n        container and return its uuid.\n        \"\"\"\n        def __cname_matches(container, identifier):\n            return any([n for n in (container['Names'] or [])\n                        if matches(n, '/' + identifier)])\n\n        # Determine if identifier is a container\n        containers = [c['Id'] for c in self.client.containers(all=True)\n                      if (__cname_matches(c, identifier) or\n                          matches(c['Id'], identifier + '*'))]\n\n        if len(containers) > 1:\n            raise SelectionMatchError(identifier, containers)\n        elif len(containers) == 1:\n            c = containers[0]\n            return self._clone(c)\n\n        # Determine if identifier is an image UUID\n        images = [i for i in set(self.client.images(all=True, quiet=True))\n                  if i.startswith(identifier)]\n\n        if len(images) > 1:\n            raise SelectionMatchError(identifier, images)\n        elif len(images) == 1:\n            return self._create_temp_container(images[0])\n\n        # Match image tag.\n        images = util.image_by_name(identifier)\n        if len(images) > 1:\n            tags = [t for i in images for t in i['RepoTags']]\n            raise SelectionMatchError(identifier, tags)\n        elif len(images) == 1:\n            return self._create_temp_container(images[0]['Id'].replace(\"sha256:\", \"\"))\n\n        raise MountError('{} did not match any image or container.'\n                         ''.format(identifier))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef mount(self, identifier):\n\n        driver = self.client.info()['Driver']\n        driver_mount_fn = getattr(self, \"_mount_\" + driver,\n                                  self._unsupported_backend)\n        cid = driver_mount_fn(identifier)\n\n        # Return mount path so it can be later unmounted by path\n        return self.mountpoint, cid", "response": "Mounts a container or image referenced by identifier to the host filesystem."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _mount_devicemapper(self, identifier):\n\n        info = self.client.info()\n\n        # cid is the contaienr_id of the temp container\n        cid = self._identifier_as_cid(identifier)\n\n        cinfo = self.client.inspect_container(cid)\n\n        dm_dev_name, dm_dev_id, dm_dev_size = '', '', ''\n        dm_pool = info['DriverStatus'][0][1]\n\n        try:\n            dm_dev_name = cinfo['GraphDriver']['Data']['DeviceName']\n            dm_dev_id = cinfo['GraphDriver']['Data']['DeviceId']\n            dm_dev_size = cinfo['GraphDriver']['Data']['DeviceSize']\n        except:\n            # TODO: deprecated when GraphDriver patch makes it upstream\n            dm_dev_id, dm_dev_size = DockerMount._no_gd_api_dm(cid)\n            dm_dev_name = dm_pool.replace('pool', cid)\n\n        # grab list of devces\n        dmsetupLs = dmsetupWrap.getDmsetupLs()\n        if dmsetupLs == -1:\n            raise MountError('Error: dmsetup returned non zero error ')\n\n        # ENSURE device exists!\n        if dm_dev_name not in dmsetupLs:\n            # IF device doesn't exist yet we create it!\n            Mount._activate_thin_device(dm_dev_name, dm_dev_id, dm_dev_size,\n                                        dm_pool)\n\n        # check that device is shown in /dev/mapper, if not we can use the\n        # major minor numbers in /dev/block\n        mapperDir = os.path.join('/dev/mapper', dm_dev_name)\n        if os.path.exists(mapperDir):\n            dm_dev_path = mapperDir\n        else:\n            # get new dmsetupLs after device has been created!\n            dmsetupLs = dmsetupWrap.getDmsetupLs()\n            # test if device exists in dmsetupls, if so, get its majorminor found in /dev/block\n            majorMinor = dmsetupWrap.getMajorMinor(dm_dev_name, dmsetupLs)\n            blockDir = os.path.join('/dev/block', majorMinor)\n\n            # FIXME, coudl be due to Virtual box, but occasionally the block device\n            # will not be created by the time we check it exists below, so we\n            # can wait a half a second to let it be created up\n            import time\n            time.sleep(0.1)\n\n            if os.path.exists(blockDir):\n                dm_dev_path = blockDir\n            else:\n                raise MountError('Error: Block device found in dmsetup ls '\n                                 'but not in /dev/mapper/ or /dev/block')\n\n        options = ['ro', 'nosuid', 'nodev']\n        # XFS should get nouuid\n        fstype = Mount._get_fs(dm_dev_path).decode(sys.getdefaultencoding())\n        if fstype.upper() == 'XFS' and 'nouuid' not in options:\n            if 'nouuid' not in options:\n                options.append('nouuid')\n        try:\n            Mount.mount_path(dm_dev_path, self.mountpoint)\n        except MountError as de:\n            self._cleanup_container(cinfo)\n            Mount.remove_thin_device(dm_dev_name)\n            raise de\n\n        # return the temp container ID so we can unmount later\n        return cid", "response": "Mount a devicemapper container."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove a container and clean up its image if necessary.", "response": "def _cleanup_container(self, cinfo):\n        \"\"\"\n        Remove a container and clean up its image if necessary.\n        \"\"\"\n        # I'm not a fan of doing this again here.\n        env = cinfo['Config']['Env']\n        if (env and '_ATOMIC_TEMP_CONTAINER' not in env) or not env:\n            return\n\n        iid = cinfo['Image']\n        self.client.remove_container(cinfo['Id'])\n        try:\n            labels = self.client.inspect_image(iid)['Config']['Labels']\n        except TypeError:\n            labels = {}\n        if labels and 'io.projectatomic.Temporary' in labels:\n            if labels['io.projectatomic.Temporary'] == 'true':\n                self.client.remove_image(iid)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef unmount(self, cid):\n        driver = self.client.info()['Driver']\n        driver_unmount_fn = getattr(self, \"_unmount_\" + driver,\n                                    self._unsupported_backend)\n        driver_unmount_fn(cid)", "response": "Unmounts and cleans - up after a previous mount."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef jboss_standalone_conf_file(broker):\n        log_files = broker[JDRSpecs.jboss_standalone_server_log]\n        if log_files:\n            log_content = log_files[-1].content\n            results = []\n            for line in log_content:\n                if \"sun.java.command =\" in line and \".jdr\" not in line and \"-Djboss.server.base.dir\" in line:\n                    results.append(line)\n            if results:\n                # default is standalone.xml\n                config_xml = 'standalone.xml'\n                java_command = results[-1]\n                if '--server-config' in java_command:\n                    config_xml = java_command.split('--server-config=')[1].split()[0]\n                elif '-c ' in java_command:\n                    config_xml = java_command.split('-c ')[1].split()[0]\n                return [config_xml]\n        return []", "response": "Get which jboss standalone conf file is using from server log"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrule reports a response if there is more than 1 host entry defined in the /etc/hosts file. Arguments: hp (HostParser): Parser object for the custom parser in this module. rhr (RedhatRelease): Parser object for the /etc/redhat-release file.", "response": "def report(hp, rhr):\n    \"\"\"\n    Rule reports a response if there is more than 1 host\n    entry defined in the /etc/hosts file.\n\n    Arguments:\n        hp (HostParser): Parser object for the custom parser in this\n            module.\n        rhr (RedhatRelease): Parser object for the /etc/redhat-release\n            file.\n    \"\"\"\n    if len(hp.hosts) > 1:\n        return make_fail(\"TOO_MANY_HOSTS\", num=len(hp.hosts))\n    return make_pass(\"TOO_MANY_HOSTS\", num=len(hp.hosts))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing the Systemd. ini file and return a dictionary of all the available system resources.", "response": "def parse_systemd_ini(content):\n    \"\"\"\n    .. warning::\n        This function is deprecated, please use :py:class:`SystemdConf` instead.\n\n    Function to parse config format file, the result format is dictionary.\n    \"\"\"\n\n    deprecated(parse_systemd_ini, \"Use the `SystemdConf` class instead.\")\n\n    doc = parse_doc(content)\n\n    dict_all = {}\n    for section in doc:\n        section_dict = {}\n        option_names = set(o.name for o in section)\n        for name in option_names:\n            options = [str(o.value) for o in section[name]]\n            section_dict[name] = options[0] if len(options) == 1 else options\n        dict_all[section.name] = section_dict\n\n    return dict_all"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_bool(s, default=False):\n    if s is None:\n        return default\n    return TRUTH.get(s.lower(), default)", "response": "Parse a string into a boolean value."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef defaults(default=None):\n    def _f(func):\n        @functools.wraps(func)\n        def __f(self, *args, **kwargs):\n            try:\n                return func(self, *args, **kwargs)\n            except Exception:\n                return default\n        return __f\n    return _f", "response": "Decorator that wraps a function and returns default."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks if all keys in one or more items in one or more dicts. Returns True if all keys are present in at least one of the keys dicts otherwise returns False.", "response": "def keys_in(items, *args):\n    \"\"\"\n    Use this utility function to ensure multiple keys are in one or more\n    dicts.  Returns `True` if all keys are present in at least one of the\n    given dicts, otherwise returns `False`.\n\n    :Parameters:\n        - `items`: Iterable of required keys\n        - Variable number of subsequent arguments, each one being a dict to check.\n    \"\"\"\n\n    found = dict((key, False) for key in items)\n    for d in args:\n        for item in items:\n            if not found[item] and item in d:\n                found[item] = True\n    return all(found.values())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef deprecated(func, solution):\n\n    def get_name_line(src):\n        for line in src:\n            if \"@\" not in line:\n                return line.strip()\n\n    path = inspect.getsourcefile(func)\n    src, line_no = inspect.getsourcelines(func)\n    name = get_name_line(src) or \"Unknown\"\n    the_msg = \"<{c}> at {p}:{l} is deprecated: {s}\".format(\n        c=name, p=path, l=line_no, s=solution\n    )\n\n    warnings.warn(the_msg, DeprecationWarning)", "response": "Mark a parser or combiner as deprecated and give a warning to fix it."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_keypair_lines(content, delim='|', kv_sep='='):\n    r = []\n    if content:\n        for row in [line for line in content if line]:\n            item_dict = {}\n            for item in row.split(delim):\n                key, value = [i.strip(\"'\\\"\").strip() for i in item.strip().split(kv_sep)]\n                item_dict[key] = value\n            r.append(item_dict)\n    return r", "response": "Parses a set of lines of content into a list of dicts. Each dictionary is a dictionary where each key - value pair is a set of key - value pairs\n    contained all on one line."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef rsplit(_str, seps):\n    for idx, ch in enumerate(reversed(_str)):\n        if ch in seps:\n            return _str[0:-idx - 1], _str[-idx:]", "response": "Splits _str by the first sep in seps that is found from the right side. Returns a tuple of the first and last elements of _str."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef case_variants(*elements):\n    expanded_list = []\n    for element in elements:\n        low = element.lower()\n        up = element.upper()\n        title = element.title()\n\n        # Inner case conversion, such as `MACs` or `UsePAM` to `Macs` and `UsePam`\n        converted = []\n        for i, letter in enumerate(element):\n            if i == 0:\n                converted.append(letter)\n            else:\n                if element[i - 1].isupper():\n                    converted.append(letter.lower())\n                else:\n                    converted.append(letter)\n        converted = \"\".join(converted)\n\n        for new_element in (element, converted, low, up, title):\n            if new_element not in expanded_list:\n                expanded_list.append(new_element)\n\n    return expanded_list", "response": "This function expands the list of elements in the order they appear in the order they appear in the list."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the log lines that are after the given time stamp.", "response": "def get_after(self, timestamp, s=None):\n        \"\"\"\n        Find all the (available) logs that are after the given time stamp.\n\n        If `s` is not supplied, then all lines are used.  Otherwise, only the\n        lines contain the `s` are used.  `s` can be either a single string or a\n        strings list. For list, all keywords in the list must be found in the\n        line.\n\n        .. note::\n            The time stamp is time type instead of usual datetime type. If\n            a time stamp is not found on the line between square brackets, then\n            it is treated as a continuation of the previous line and is only\n            included if the previous line's timestamp is greater than the\n            timestamp given.  Because continuation lines are only included if a\n            previous line has matched, this means that searching in logs that do\n            not have a time stamp produces no lines.\n\n        Parameters:\n            timestamp(time): log lines after this time are returned.\n            s(str or list): one or more strings to search for.\n                If not supplied, all available lines are searched.\n\n        Yields:\n            Log lines with time stamps after the given time.\n\n        Raises:\n            TypeError: The ``timestamp`` should be in `time` type, otherwise a\n                `TypeError` will be raised.\n        \"\"\"\n        if not isinstance(timestamp, time):\n            raise TypeError(\n                \"get_after needs a time type timestamp, but get '{c}'\".format(\n                    c=timestamp)\n            )\n        including_lines = False\n        search_by_expression = self._valid_search(s)\n        for line in self.lines:\n            # If `s` is not None, keywords must be found in the line\n            if s and not search_by_expression(line):\n                continue\n            # Otherwise, search all lines\n            match = self._line_re.search(line)\n            if match and match.group('timestamp'):\n                # Get logtimestamp and compare to given timestamp\n                l_hh, l_mm, l_ss = match.group('timestamp').split(\":\")\n                logstamp = time(int(l_hh), int(l_mm), int(l_ss))\n                if logstamp >= timestamp:\n                    including_lines = True\n                    yield self._parse_line(line)\n                else:\n                    including_lines = False\n            else:\n                # If we're including lines, add this continuation line\n                if including_lines:\n                    yield self._parse_line(line)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprints the formated progress information for the processed return types", "response": "def progress_bar(self, c, broker):\n        \"\"\"\n        Print the formated progress information for the processed return types\n        \"\"\"\n        v = broker.get(c)\n\n        if v and isinstance(v, dict) and len(v) > 0 and 'type' in v:\n            if v[\"type\"] in self.responses:\n                print(self.responses[v[\"type\"]].color + self.responses[v[\"type\"]].intl + Style.RESET_ALL, end=\"\", file=self.stream)\n            else:\n                print(\".\", end=\"\", file=self.stream)\n        elif c in broker.exceptions:\n            self.counts['exception'] += len(broker.exceptions[c])\n            print(Fore.RED + \"E\" + Style.RESET_ALL, end=\"\", file=self.stream)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef show_tracebacks(self):\n        if self.broker.tracebacks:\n            print(file=self.stream)\n            print(\"Tracebacks:\", file=self.stream)\n            for t in self.broker.tracebacks.values():\n                print(t, file=self.stream)", "response": "Show tracebacks in the console."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef show_description(self):\n\n        def printit(c, v):\n            underline = \"-\" * len(dr.get_name(c))\n            resp = self.responses[v[\"type\"]]\n            name = \"%s[%s] %s%s\" % (resp.color, resp.label, dr.get_name(c), Style.RESET_ALL)\n            print(name, file=self.stream)\n            print(underline, file=self.stream)\n            print(render(c, v), file=self.stream)\n            print(file=self.stream)\n\n        for c in sorted(self.broker.get_by_type(rule), key=dr.get_name):\n            v = self.broker[c]\n            _type = v.get('type')\n            if _type in self.responses:\n                self.counts[_type] += 1\n            if (_type and ((self.fail_only and _type == 'rule') or\n                           ((self.missing and _type == 'skip') or\n                            (not self.fail_only and _type != 'skip')))):\n                printit(c, v)\n        print(file=self.stream)\n\n        self.print_header(\"Rule Execution Summary\", Fore.CYAN)\n        for c in self.counts:\n            print(self.responses[c].color + self.responses[c].title + str(self.counts[c]) + Style.RESET_ALL, file=self.stream)", "response": "Prints the formatted description of the matching return type"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nregisters a new resource in the database.", "response": "def register(config, pconn):\n    \"\"\"\n    Do registration using basic auth\n    \"\"\"\n    username = config.username\n    password = config.password\n    authmethod = config.authmethod\n    auto_config = config.auto_config\n    if not username and not password and not auto_config and authmethod == 'BASIC':\n        logger.debug('Username and password must be defined in configuration file with BASIC authentication method.')\n        return False\n    return pconn.register()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _legacy_handle_registration(config, pconn):\n    '''\n    Handle the registration process\n    Returns:\n        True - machine is registered\n        False - machine is unregistered\n        None - could not reach the API\n    '''\n    logger.debug('Trying registration.')\n    # force-reregister -- remove machine-id files and registration files\n    # before trying to register again\n    if config.reregister:\n        delete_registered_file()\n        delete_unregistered_file()\n        write_to_disk(constants.machine_id_file, delete=True)\n        logger.debug('Re-register set, forcing registration.')\n\n    logger.debug('Machine-id: %s', generate_machine_id(new=config.reregister))\n\n    # check registration with API\n    check = get_registration_status(config, pconn)\n\n    for m in check['messages']:\n        logger.debug(m)\n\n    if check['unreachable']:\n        # Run connection test and exit\n        return None\n\n    if check['status']:\n        # registered in API, resync files\n        if config.register:\n            logger.info('This host has already been registered.')\n        write_registered_file()\n        return True\n\n    if config.register:\n        # register if specified\n        message, hostname, group, display_name = register(config, pconn)\n        if not hostname:\n            # API could not be reached, run connection test and exit\n            logger.error(message)\n            return None\n        if config.display_name is None and config.group is None:\n            logger.info('Successfully registered host %s', hostname)\n        elif config.display_name is None:\n            logger.info('Successfully registered host %s in group %s',\n                        hostname, group)\n        else:\n            logger.info('Successfully registered host %s as %s in group %s',\n                        hostname, display_name, group)\n        if message:\n            logger.info(message)\n        write_registered_file()\n        return True\n    else:\n        # unregistered in API, resync files\n        write_unregistered_file(date=check['unreg_date'])\n        # print messaging and exit\n        if check['unreg_date']:\n            # registered and then unregistered\n            logger.info('This machine has been unregistered. '\n                        'Use --register if you would like to '\n                        're-register this machine.')\n        else:\n            # not yet registered\n            logger.info('This machine has not yet been registered.'\n                        'Use --register to register this machine.')\n        return False", "response": "Handle the registration process."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _legacy_handle_unregistration(config, pconn):\n    check = get_registration_status(config, pconn)\n\n    for m in check['messages']:\n        logger.debug(m)\n\n    if check['unreachable']:\n        # Run connection test and exit\n        return None\n\n    if check['status']:\n        unreg = pconn.unregister()\n    else:\n        unreg = True\n        logger.info('This system is already unregistered.')\n    if unreg:\n        # only set if unreg was successful\n        write_unregistered_file()\n        get_scheduler(config).remove_scheduling()\n    return unreg", "response": "Handle the unregistration of the current system."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nhandle unregistration of a new resource.", "response": "def handle_unregistration(config, pconn):\n    \"\"\"\n    Returns:\n        True - machine was successfully unregistered\n        False - machine could not be unregistered\n        None - could not reach the API\n    \"\"\"\n    if config.legacy_upload:\n        return _legacy_handle_unregistration(config, pconn)\n    unreg = pconn.unregister()\n    if unreg:\n        # only set if unreg was successful\n        write_unregistered_file()\n        get_scheduler(config).remove_scheduling()\n    return unreg"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets branch info for a system returns ( dict )", "response": "def get_branch_info(config, pconn):\n    \"\"\"\n    Get branch info for a system\n    returns (dict): {'remote_branch': -1, 'remote_leaf': -1}\n    \"\"\"\n    # in the case we are running on offline mode\n    # or we are analyzing a running container/image\n    # or tar file, mountpoint, simply return the default branch info\n    if (config.offline or\n            config.analyze_container):\n        return constants.default_branch_info\n    return pconn.branch_info"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef collect(config, pconn):\n    # initialize collection target\n    # tar files\n    if config.analyze_file:\n        logger.debug(\"Client analyzing a compress filesystem.\")\n        target = {'type': 'compressed_file',\n                  'name': os.path.splitext(\n                        os.path.basename(config.analyze_file))[0],\n                  'location': config.analyze_file}\n\n    # mountpoints\n    elif config.analyze_mountpoint:\n        logger.debug(\"Client analyzing a filesystem already mounted.\")\n        target = {'type': 'mountpoint',\n                  'name': os.path.splitext(\n                        os.path.basename(config.analyze_mountpoint))[0],\n                  'location': config.analyze_mountpoint}\n\n    # image\n    elif config.analyze_image_id:\n        logger.debug(\"Client running in image mode.\")\n        logger.debug(\"Scanning for matching image.\")\n\n        from .containers import get_targets\n        targets = get_targets(config)\n        if len(targets) == 0:\n            sys.exit(constants.sig_kill_bad)\n        target = targets[0]\n\n    # host, or inside container\n    else:\n        if config.analyze_container:\n            logger.debug('Client running in container mode.')\n        else:\n            logger.debug(\"Host selected as scanning target.\")\n        target = constants.default_target\n\n    branch_info = get_branch_info(config, pconn)\n    pc = InsightsUploadConf(config)\n    tar_file = None\n\n    collection_rules = pc.get_conf_file()\n    rm_conf = pc.get_rm_conf()\n    if rm_conf:\n        logger.warn(\"WARNING: Excluding data from files\")\n\n    # defaults\n    archive = None\n    container_connection = None\n    mp = None\n    compressed_filesystem = None\n\n    try:\n        # analyze docker images\n        if target['type'] == 'docker_image':\n            from .containers import open_image\n            container_connection = open_image(target['name'])\n            logging_name = 'Docker image ' + target['name']\n\n            if container_connection:\n                mp = container_connection.get_fs()\n            else:\n                logger.error('Could not open %s for analysis', logging_name)\n                return False\n\n        # analyze compressed files\n        elif target['type'] == 'compressed_file':\n            logging_name = 'Compressed file ' + target['name'] + ' at location ' + target['location']\n\n            from .compressed_file import InsightsCompressedFile\n            compressed_filesystem = InsightsCompressedFile(target['location'])\n\n            if compressed_filesystem.is_tarfile is False:\n                logger.debug(\"Could not access compressed tar filesystem.\")\n                return False\n\n            mp = compressed_filesystem.get_filesystem_path()\n\n        # analyze mountpoints\n        elif target['type'] == 'mountpoint':\n\n            logging_name = 'Filesystem ' + target['name'] + ' at location ' + target['location']\n            mp = config.analyze_mountpoint\n\n        # analyze the host\n        elif target['type'] == 'host':\n            logging_name = determine_hostname()\n\n        # nothing found to analyze\n        else:\n            logger.error('Unexpected analysis target: %s', target['type'])\n            return False\n\n        archive = InsightsArchive(compressor=config.compressor,\n                                  target_name=target['name'])\n        atexit.register(_delete_archive_internal, config, archive)\n\n        # determine the target type and begin collection\n        # we infer \"docker_image\" SPEC analysis for certain types\n        if target['type'] in [\"mountpoint\", \"compressed_file\"]:\n            target_type = \"docker_image\"\n        else:\n            target_type = target['type']\n        logger.debug(\"Inferring target_type '%s' for SPEC collection\", target_type)\n        logger.debug(\"Inferred from '%s'\", target['type'])\n        dc = DataCollector(config, archive, mountpoint=mp)\n\n        logger.info('Starting to collect Insights data for %s', logging_name)\n        dc.run_collection(collection_rules, rm_conf, branch_info)\n\n        tar_file = dc.done(collection_rules, rm_conf)\n\n    finally:\n        # called on loop iter end or unexpected exit\n        if container_connection:\n            container_connection.close()\n\n    # cleanup the temporary stuff for analyzing tar files\n    if config.analyze_file is not None and compressed_filesystem is not None:\n        compressed_filesystem.cleanup_temp_filesystem()\n\n    return tar_file", "response": "Collect the contents of a tar file or image."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef validate_gpg_sig(self, path, sig=None):\n        logger.debug(\"Verifying GPG signature of Insights configuration\")\n        if sig is None:\n            sig = path + \".asc\"\n        command = (\"/usr/bin/gpg --no-default-keyring \"\n                   \"--keyring \" + constants.pub_gpg_path +\n                   \" --verify \" + sig + \" \" + path)\n        if not six.PY3:\n            command = command.encode('utf-8', 'ignore')\n        args = shlex.split(command)\n        logger.debug(\"Executing: %s\", args)\n        proc = Popen(\n            args, shell=False, stdout=PIPE, stderr=STDOUT, close_fds=True)\n        stdout, stderr = proc.communicate()\n        logger.debug(\"STDOUT: %s\", stdout)\n        logger.debug(\"STDERR: %s\", stderr)\n        logger.debug(\"Status: %s\", proc.returncode)\n        if proc.returncode:\n            logger.error(\"ERROR: Unable to validate GPG signature: %s\", path)\n            return False\n        else:\n            logger.debug(\"GPG signature verified\")\n            return True", "response": "Validate the signature of the Insights configuration file"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntrying to load json off disk and return the object.", "response": "def try_disk(self, path, gpg=True):\n        \"\"\"\n        Try to load json off disk\n        \"\"\"\n        if not os.path.isfile(path):\n            return\n\n        if not gpg or self.validate_gpg_sig(path):\n            stream = open(path, 'r')\n            json_stream = stream.read()\n            if len(json_stream):\n                try:\n                    json_config = json.loads(json_stream)\n                    return json_config\n                except ValueError:\n                    logger.error(\"ERROR: Invalid JSON in %s\", path)\n                    return False\n            else:\n                logger.warn(\"WARNING: %s was an empty file\", path)\n                return"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_collection_rules(self, raw=False):\n        logger.debug(\"Attemping to download collection rules from %s\",\n                     self.collection_rules_url)\n\n        net_logger.info(\"GET %s\", self.collection_rules_url)\n        try:\n            req = self.conn.session.get(\n                self.collection_rules_url, headers=({'accept': 'text/plain'}))\n\n            if req.status_code == 200:\n                logger.debug(\"Successfully downloaded collection rules\")\n\n                json_response = NamedTemporaryFile()\n                json_response.write(req.text.encode('utf-8'))\n                json_response.file.flush()\n            else:\n                logger.error(\"ERROR: Could not download dynamic configuration\")\n                logger.error(\"Debug Info: \\nConf status: %s\", req.status_code)\n                logger.error(\"Debug Info: \\nConf message: %s\", req.text)\n                return None\n        except requests.ConnectionError as e:\n            logger.error(\n                \"ERROR: Could not download dynamic configuration: %s\", e)\n            return None\n\n        if self.gpg:\n            self.get_collection_rules_gpg(json_response)\n\n        self.write_collection_data(self.collection_rules_file, req.text)\n\n        if raw:\n            return req.text\n        else:\n            return json.loads(req.text)", "response": "Download the collection rules from the device and return the result."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_collection_rules_gpg(self, collection_rules):\n        sig_text = self.fetch_gpg()\n        sig_response = NamedTemporaryFile(suffix=\".asc\")\n        sig_response.write(sig_text.encode('utf-8'))\n        sig_response.file.flush()\n        self.validate_gpg_sig(collection_rules.name, sig_response.name)\n        self.write_collection_data(self.collection_rules_file + \".asc\", sig_text)", "response": "Download the collection rules gpg signature"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef write_collection_data(self, path, data):\n        flags = os.O_WRONLY | os.O_CREAT | os.O_TRUNC\n        fd = os.open(path, flags, 0o600)\n        with os.fdopen(fd, 'w') as dyn_conf_file:\n            dyn_conf_file.write(data)", "response": "Write the data to disk."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_conf_file(self):\n        for conf_file in [self.collection_rules_file, self.fallback_file]:\n            logger.debug(\"trying to read conf from: \" + conf_file)\n            conf = self.try_disk(conf_file, self.gpg)\n\n            if not conf:\n                continue\n\n            version = conf.get('version', None)\n            if version is None:\n                raise ValueError(\"ERROR: Could not find version in json\")\n\n            conf['file'] = conf_file\n            logger.debug(\"Success reading config\")\n            logger.debug(json.dumps(conf))\n            return conf\n\n        raise ValueError(\"ERROR: Unable to download conf or read it from disk!\")", "response": "Get config from local config file first try cache then fallback."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_conf_update(self):\n        dyn_conf = self.get_collection_rules()\n\n        if not dyn_conf:\n            return self.get_conf_file()\n\n        version = dyn_conf.get('version', None)\n        if version is None:\n            raise ValueError(\"ERROR: Could not find version in json\")\n\n        dyn_conf['file'] = self.collection_rules_file\n        logger.debug(\"Success reading config\")\n        config_hash = hashlib.sha1(json.dumps(dyn_conf).encode('utf-8')).hexdigest()\n        logger.debug('sha1 of config: %s', config_hash)\n        return dyn_conf", "response": "Get updated config from URL fallback to local file"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets excluded files config from remove_file.", "response": "def get_rm_conf(self):\n        \"\"\"\n        Get excluded files config from remove_file.\n        \"\"\"\n        if not os.path.isfile(self.remove_file):\n            return None\n\n        # Convert config object into dict\n        parsedconfig = ConfigParser.RawConfigParser()\n        parsedconfig.read(self.remove_file)\n        rm_conf = {}\n\n        for item, value in parsedconfig.items('remove'):\n            if six.PY3:\n                rm_conf[item] = value.strip().encode('utf-8').decode('unicode-escape').split(',')\n            else:\n                rm_conf[item] = value.strip().decode('string-escape').split(',')\n\n        return rm_conf"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nyields a generator of a command's output. For line oriented commands only. Args: command (str or list): a command without pipes. If it's not a list, ``shlex.split`` is applied. stdin (file like object): stream to use as the command's standard input. env (dict): The environment in which to execute the command. PATH should be defined. timeout (int): Amount of time in seconds to give the command to complete. The ``timeout`` utility must be installed to use this feature. Yields: The output stream for the command. It should typically be wrapped in a ``reader``.", "response": "def stream(command, stdin=None, env=os.environ, timeout=None):\n    \"\"\"\n    Yields a generator of a command's output. For line oriented commands only.\n\n    Args:\n        command (str or list): a command without pipes. If it's not a list,\n            ``shlex.split`` is applied.\n        stdin (file like object): stream to use as the command's standard input.\n        env (dict): The environment in which to execute the command. PATH should\n            be defined.\n        timeout (int): Amount of time in seconds to give the command to complete.\n            The ``timeout`` utility must be installed to use this feature.\n\n    Yields:\n        The output stream for the command. It should typically be wrapped in a\n        ``reader``.\n    \"\"\"\n    if not isinstance(command, list):\n        command = shlex.split(command)\n\n    cmd = which(command[0])\n    if cmd is None:\n        path = env.get(\"PATH\", \"\")\n        raise Exception(\"Command [%s] not in PATH [%s]\" % (command[0], path))\n\n    command[0] = cmd\n\n    if timeout:\n        if not timeout_command[0]:\n            raise Exception(\"Timeout specified but timeout command not available.\")\n        command = timeout_command + [str(timeout)] + command\n\n    output = None\n    try:\n        output = Popen(command, env=env, stdin=stdin, **stream_options)\n        yield output.stdout\n    finally:\n        if output:\n            output.wait()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconnects multiple command streams together and yields the final stream.", "response": "def connect(*cmds, **kwargs):\n    \"\"\"\n    Connects multiple command streams together and yields the final stream.\n\n    Args:\n        cmds (list): list of commands to pipe together. Each command will be an\n            input to ``stream``.\n        stdin (file like object): stream to use as the first command's\n            standard input.\n        env (dict): The environment in which to execute the commands. PATH\n            should be defined.\n        timeout (int): Amount of time in seconds to give the pipeline to complete.\n            The ``timeout`` utility must be installed to use this feature.\n\n    Yields:\n        The output stream for the final command in the pipeline. It should\n        typically be wrapped in a ``reader``.\n    \"\"\"\n    stdin = kwargs.get(\"stdin\")\n    env = kwargs.get(\"env\", os.environ)\n    timeout = kwargs.get(\"timeout\")\n    end = len(cmds) - 1\n\n    @contextmanager\n    def inner(idx, inp):\n        with stream(cmds[idx], stdin=inp, env=env, timeout=timeout) as s:\n            if idx == end:\n                yield s\n            else:\n                with inner(idx + 1, s) as c:\n                    yield c\n\n    with inner(0, stdin) as s:\n        yield s"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_non_selinux(parts):\n    links, owner, group, last = parts\n    result = {\n        \"links\": int(links),\n        \"owner\": owner,\n        \"group\": group,\n    }\n\n    # device numbers only go to 256.\n    # If a comma is in the first four characters, the next two elements are\n    # major and minor device numbers. Otherwise, the next element is the size.\n    if \",\" in last[:4]:\n        major, minor, rest = last.split(None, 2)\n        result[\"major\"] = int(major.rstrip(\",\"))\n        result[\"minor\"] = int(minor)\n    else:\n        size, rest = last.split(None, 1)\n        result[\"size\"] = int(size)\n\n    # The date part is always 12 characters regardless of content.\n    result[\"date\"] = rest[:12]\n\n    # Jump over the date and the following space to get the path part.\n    path, link = parse_path(rest[13:])\n    result[\"name\"] = path\n    if link:\n        result[\"link\"] = link\n\n    return result", "response": "Parse a single line of ls output that isn t selinux."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing the selinux info from the ls output line that is the last part of the ls output line.", "response": "def parse_selinux(parts):\n    \"\"\"\n    Parse part of an ls output line that is selinux.\n\n    Args:\n        parts (list): A four element list of strings representing the initial\n            parts of an ls line after the permission bits. The parts are owner\n            group, selinux info, and the path.\n\n    Returns:\n        A dict containing owner, group, se_user, se_role, se_type, se_mls, and\n        name. If the raw name was a symbolic link, link is always included.\n\n    \"\"\"\n\n    owner, group = parts[:2]\n    selinux = parts[2].split(\":\")\n    lsel = len(selinux)\n    path, link = parse_path(parts[-1])\n    result = {\n        \"owner\": owner,\n        \"group\": group,\n        \"se_user\": selinux[0],\n        \"se_role\": selinux[1] if lsel > 1 else None,\n        \"se_type\": selinux[2] if lsel > 2 else None,\n        \"se_mls\": selinux[3] if lsel > 3 else None,\n        \"name\": path\n    }\n    if link:\n        result[\"link\"] = link\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse(lines, root=None):\n    doc = {}\n    entries = []\n    name = None\n    total = None\n    for line in lines:\n        line = line.strip()\n        if not line:\n            continue\n        if line and line[0] == \"/\" and line[-1] == \":\":\n            if name is None:\n                name = line[:-1]\n                if entries:\n                    d = Directory(name, total or len(entries), entries)\n                    doc[root] = d\n                    total = None\n                    entries = []\n            else:\n                d = Directory(name, total or len(entries), entries)\n                doc[name or root] = d\n                total = None\n                entries = []\n                name = line[:-1]\n            continue\n        if line.startswith(\"total\"):\n            total = int(line.split(None, 1)[1])\n            continue\n        entries.append(line)\n    name = name or root\n    doc[name] = Directory(name, total or len(entries), entries)\n    return doc", "response": "Parses a list of lines from ls into a dictionary representing their their\n    components."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of lines or parts of lines that are not commented out .", "response": "def get_active_lines(lines, comment_char=\"#\"):\n    \"\"\"\n    Returns lines, or parts of lines, from content that are not commented out\n    or completely empty.  The resulting lines are all individually stripped.\n\n    This is useful for parsing many config files such as ifcfg.\n\n    Parameters:\n        lines (list): List of strings to parse.\n        comment_char (str): String indicating that all chars following\n            are part of a comment and will be removed from the output.\n\n    Returns:\n        list: List of valid lines remaining in the input.\n\n    Examples:\n        >>> lines = [\n        ... 'First line',\n        ... '   ',\n        ... '# Comment line',\n        ... 'Inline comment # comment',\n        ... '          Whitespace          ',\n        ... 'Last line']\n        >>> get_active_lines(lines)\n        ['First line', 'Inline comment', 'Whitespace', 'Last line']\n    \"\"\"\n    return list(filter(None, (line.split(comment_char, 1)[0].strip() for line in lines)))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing an option list into a dictionary.", "response": "def optlist_to_dict(optlist, opt_sep=',', kv_sep='=', strip_quotes=False):\n    \"\"\"Parse an option list into a dictionary.\n\n    Takes a list of options separated by ``opt_sep`` and places them into\n    a dictionary with the default value of ``True``.  If ``kv_sep`` option\n    is specified then key/value options ``key=value`` are parsed.  Useful\n    for parsing options such as mount options in the format\n    ``rw,ro,rsize=32168,xyz``.\n\n    Parameters:\n        optlist (str): String of options to parse.\n        opt_sep (str): Separater used to split options.\n        kv_sep (str): If not `None` then `optlist` includes key=value pairs\n            to be split, and this str is used to split them.\n        strip_quotes (bool): If set, will remove matching '\"' and '\"'\n            characters from start and end of line.  No quotes are removed\n            from inside the string and mismatched quotes are not removed.\n\n    Returns:\n        dict: Returns a dictionary of names present in the list.  If `kv_sep`\n        is not `None` then the values will be the str on the right-hand side\n        of `kv_sep`.  If `kv_sep` is `None` then each key will have a default\n        value of `True`.\n\n    Examples:\n        >>> optlist = 'rw,ro,rsize=32168,xyz'\n        >>> optlist_to_dict(optlist)\n        {'rw': True, 'ro': True, 'rsize': '32168', 'xyz': True}\n    \"\"\"\n    def make_kv(opt):\n        if kv_sep is not None and kv_sep in opt:\n            k, v = opt.split(kv_sep, 1)\n            k = k.strip()\n            if strip_quotes and v[0] in ('\"', \"'\") and v[-1] == v[0]:\n                return k, v[1:-1]\n            else:\n                return k, v\n        else:\n            return opt, True\n\n    return dict(make_kv(opt) for opt in optlist.split(opt_sep))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef split_kv_pairs(lines, comment_char=\"#\", filter_string=None, split_on=\"=\", use_partition=False, ordered=False):\n    _lines = lines if comment_char is None else get_active_lines(lines, comment_char=comment_char)\n    _lines = _lines if filter_string is None else [l for l in _lines if filter_string in l]\n    kv_pairs = OrderedDict() if ordered else {}\n\n    for line in _lines:\n        if not use_partition:\n            if split_on in line:\n                k, v = line.split(split_on, 1)\n                kv_pairs[k.strip()] = v.strip()\n        else:\n            k, _, v = line.partition(split_on)\n            kv_pairs[k.strip()] = v.strip()\n    return kv_pairs", "response": "Splits a list of lines into key - value pairs."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nyielding a list of strings that are not part of a continuation character at the end of a line.", "response": "def unsplit_lines(lines, cont_char='\\\\', keep_cont_char=False):\n    \"\"\"Recombine lines having a continuation character at end.\n\n    Generator that recombines lines in the list that have the char `cont_char`\n    at the end of a line.  If `cont_char` is found in a line then then\n    next line will be appended to the current line, this will continue for\n    multiple continuation lines until the next line is found with no\n    continuation character at the end.  All lines found will be combined and\n    returned.\n\n    If the `keep_cont_char` option is set to True, the continuation character\n    will be left on the end of the line.  Otherwise, by default, it is removed.\n\n    Parameters:\n        lines (list): List of strings to be evaluated.\n        cont_char (char): Char to search for at end of line. Default is ``\\\\``.\n        keep_cont_char (bool): Whether to keep the continuation on the end of\n            the line.  Defaults to False, which causes the continuation\n            character to be removed.\n\n    Yields:\n        line (str): Yields unsplit lines\n\n    Examples:\n        >>> lines = ['Line one \\\\', '     line one part 2', 'Line two']\n        >>> list(unsplit_lines(lines))\n        ['Line one      line one part 2', 'Line two']\n        >>> list(unsplit_lines(lines, cont_char='2'))\n        ['Line one \\\\', '     line one part Line two']\n        >>> list(unsplit_lines(lines, keep_cont_char=True)\n        ['Line one \\     line one part 2', 'Line two']\n    \"\"\"\n    unsplit_lines = []\n    for line in lines:\n        line = line.rstrip()\n        if line.endswith(cont_char):\n            unsplit_lines.append(line if keep_cont_char else line[:-1])\n        else:\n            yield ''.join(unsplit_lines) + line\n            unsplit_lines = []\n    if unsplit_lines:\n        yield ''.join(unsplit_lines)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef calc_offset(lines, target, invert_search=False):\n    if target and target[0] is not None:\n        for offset, line in enumerate(l.strip() for l in lines):\n            found_any = any([line.startswith(t) for t in target])\n            if not invert_search and found_any:\n                return offset\n            elif invert_search and not(line == '' or found_any):\n                return offset\n\n        # If we get here then we didn't find any of the targets\n        raise ValueError(\"Line containing '{}' was not found in table\".format(','.join(target)))\n    else:\n        # If no target then return index 0\n        return 0", "response": "Function to search for a line in a list starting with a target string."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_fixed_table(table_lines,\n                      heading_ignore=[],\n                      header_substitute=[],\n                      trailing_ignore=[]):\n    \"\"\"\n    Function to parse table data containing column headings in the first row and\n    data in fixed positions in each remaining row of table data.\n    Table columns must not contain spaces within the column name.  Column headings\n    are assumed to be left justified and the column data width is the width of the\n    heading label plus all whitespace to the right of the label.  This function\n    will handle blank columns.\n\n    Arguments:\n        table_lines (list): List of strings with the first line containing column\n            headings separated by spaces, and the remaining lines containing\n            table data in left justified format.\n        heading_ignore (list): Optional list of strings to search for at\n            beginning of line.  All lines before this line will be ignored.\n            If specified then it must be present in the file or `ValueError` will\n            be raised.\n        header_substitute (list): Optional list of tuples containing\n            `(old_string_value, new_string_value)` to be used to modify header\n            values.  If whitespace is present in a column it must be replaced with\n            non-whitespace characters in order for the table to be parsed correctly.\n        trailing_ignore (list): Optional list of strings to look for at the end\n            rows of the content.  Lines starting with these strings will be ignored,\n            thereby truncating the rows of data.\n\n    Returns:\n        list: Returns a list of dict for each row of column data.  Dict keys\n            are the column headings in the same case as input.\n\n    Raises:\n        ValueError: Raised if `heading_ignore` is specified and not found in `table_lines`.\n\n    Sample input::\n\n        Column1    Column2    Column3\n        data1      data 2     data   3\n        data4      data5      data6\n\n    Examples:\n        >>> table_data = parse_fixed_table(table_lines)\n        >>> table_data\n        [{'Column1': 'data1', 'Column2': 'data 2', 'Column3': 'data   3'},\n         {'Column1': 'data4', 'Column2': 'data5', 'Column3': 'data6'}]\n    \"\"\"\n    def calc_column_indices(line, headers):\n        idx = []\n        for h in headers:\n            i = idx[-1] + 1 if idx else 0\n            idx.append(line.index(h, i))\n        return idx\n\n    first_line = calc_offset(table_lines, heading_ignore)\n    try:\n        last_line = len(table_lines) - calc_offset(reversed(table_lines),\n                                                   trailing_ignore,\n                                                   invert_search=True)\n    except ValueError:\n        last_line = len(table_lines)\n\n    header = table_lines[first_line]\n    if header_substitute:\n        for old_val, new_val in header_substitute:\n            header = header.replace(old_val, new_val)\n    col_headers = header.strip().split()\n    col_index = calc_column_indices(header, col_headers)\n\n    table_data = []\n    for line in table_lines[first_line + 1:last_line]:\n        col_data = dict(\n            (col_headers[c], line[col_index[c]:col_index[c + 1]].strip())\n            for c in range(len(col_index) - 1)\n        )\n        col_data[col_headers[-1]] = line[col_index[-1]:].strip()\n        table_data.append(col_data)\n\n    return table_data", "response": "Function to parse a fixed table of data."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_delimited_table(table_lines,\n                          delim=None,\n                          max_splits=-1,\n                          strip=True,\n                          header_delim='same as delimiter',\n                          heading_ignore=None,\n                          header_substitute=None,\n                          trailing_ignore=None,\n                          raw_line_key=None):\n    \"\"\"\n    Parses table-like text.  Uses the first (non-ignored) row as the list of\n    column names, which cannot contain the delimiter.  Fields cannot contain\n    the delimiter but can be blank if a printable delimiter is used.\n\n    Arguments:\n        table_lines (list): List of strings with the first line containing\n            column headings separated by spaces, and the remaining lines\n            containing table data.\n        delim (str): String used in the content to separate fields.  If left\n            as None (the default), white space is used as the field separator.\n        max_splits (int): Maximum number of fields to create by splitting the\n            line.  After this number of fields has been found, the rest of the\n            line is left un-split and may contain the delimiter.  Lines may\n            contain less than this number of fields.\n        strip (bool): If set to `True`, fields and headings will be stripped\n            of leading and trailing space.  If set to `False`, fields and\n            headings will be left as is.  The delimiter is always removed, so\n            strip need not be set if `delim` is set to None (but will not\n            change output in that case).\n        header_delim (str): When set, uses a different delimiter to the\n            content for splitting the header into keywords.  Set to `None`,\n            this will split on white space.  When left at the special value\n            of `'same as delimiter'`, the content delimiter will be used to\n            split the header line as well.\n        heading_ignore (list): Optional list of strings to search for at\n            beginning of line.  All lines before this line will be ignored.\n            If specified then it must be present in the file or `ValueError`\n            will be raised.\n        header_substitute (list): Optional list of tuples containing\n            `(old_string_value, new_string_value)` to be used to modify\n            header values.  If whitespace is present in a column it must be\n            replaced with non-whitespace characters in order for the table to\n            be parsed correctly.\n        trailing_ignore (list): Optional list of strings to look for at the\n            end rows of the content.  Lines starting with these strings will\n            be ignored, thereby truncating the rows of data.\n        raw_line_key (str): Key under which to save the raw line. If None, line\n            is not saved.\n    Returns:\n        list: Returns a list of dictionaries for each row of column data,\n        keyed on the column headings in the same case as input.\n\n    \"\"\"\n    if not table_lines:\n        return []\n    first_line = calc_offset(table_lines, heading_ignore)\n    try:\n        # Ignore everything before the heading in this search\n        last_line = len(table_lines) - calc_offset(\n            reversed(table_lines[first_line + 1:]), trailing_ignore, invert_search=True\n        )\n    except ValueError:\n        # We seem to have run out of content before we found something we\n        # wanted - return an empty list.\n        return []\n\n    if header_delim == 'same as delimiter':\n        header_delim = delim\n    header = table_lines[first_line]\n    if header_substitute:\n        for old_val, new_val in header_substitute:\n            header = header.replace(old_val, new_val)\n\n    content = table_lines[first_line + 1:last_line]\n    headings = [c.strip() if strip else c for c in header.split(header_delim)]\n    r = []\n    for row in content:\n        row = row.strip()\n        if row:\n            rowsplit = row.split(delim, max_splits)\n            if strip:\n                rowsplit = [i.strip() for i in rowsplit]\n            o = dict(zip(headings, rowsplit))\n            if raw_line_key:\n                o[raw_line_key] = row\n            r.append(o)\n    return r", "response": "Parses a delimited table - like text into a list of dicts."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntake a list of dictionaries and finds all the dictionaries where the keys and values match those found in the keyword arguments. Keys in the row data have ' ' and '-' replaced with '_', so they can match the keyword argument parsing. For example, the keyword argument 'fix_up_path' will match a key named 'fix-up path'. In addition, several suffixes can be added to the key name to do partial matching of values: * '__contains' will test whether the data value contains the given value. * '__startswith' tests if the data value starts with the given value * '__lower_value' compares the lower-case version of the data and given values. Arguments: rows (list): A list of dictionaries representing the data to be searched. **kwargs (dict): keyword-value pairs corresponding to the fields that need to be found and their required values in the data rows. Returns: (list): The list of rows that match the search keywords. If no keyword arguments are given, no rows are returned. Examples: >>> rows = [ ... {'domain': 'oracle', 'type': 'soft', 'item': 'nofile', 'value': 1024}, ... {'domain': 'oracle', 'type': 'hard', 'item': 'nofile', 'value': 65536}, ... {'domain': 'oracle', 'type': 'soft', 'item': 'stack', 'value': 10240}, ... {'domain': 'oracle', 'type': 'hard', 'item': 'stack', 'value': 3276}, ... {'domain': 'root', 'type': 'soft', 'item': 'nproc', 'value': -1}] ... >>> keyword_search(rows, domain='root') [{'domain': 'root', 'type': 'soft', 'item': 'nproc', 'value': -1}] >>> keyword_search(rows, item__contains='c') [{'domain': 'oracle', 'type': 'soft', 'item': 'stack', 'value': 10240}, {'domain': 'oracle', 'type': 'hard', 'item': 'stack', 'value': 3276}, {'domain': 'root', 'type': 'soft', 'item': 'nproc', 'value': -1}] >>> keyword_search(rows, domain__startswith='r') [{'domain': 'root', 'type': 'soft', 'item': 'nproc', 'value': -1}]", "response": "def keyword_search(rows, **kwargs):\n    \"\"\"\n    Takes a list of dictionaries and finds all the dictionaries where the\n    keys and values match those found in the keyword arguments.\n\n    Keys in the row data have ' ' and '-' replaced with '_', so they can\n    match the keyword argument parsing.  For example, the keyword argument\n    'fix_up_path' will match a key named 'fix-up path'.\n\n    In addition, several suffixes can be added to the key name to do partial\n    matching of values:\n\n    * '__contains' will test whether the data value contains the given\n      value.\n    * '__startswith' tests if the data value starts with the given value\n    * '__lower_value' compares the lower-case version of the data and given\n      values.\n\n    Arguments:\n        rows (list): A list of dictionaries representing the data to be\n            searched.\n        **kwargs (dict): keyword-value pairs corresponding to the fields that\n            need to be found and their required values in the data rows.\n\n    Returns:\n        (list): The list of rows that match the search keywords.  If no\n        keyword arguments are given, no rows are returned.\n\n    Examples:\n        >>> rows = [\n        ...     {'domain': 'oracle', 'type': 'soft', 'item': 'nofile', 'value': 1024},\n        ...     {'domain': 'oracle', 'type': 'hard', 'item': 'nofile', 'value': 65536},\n        ...     {'domain': 'oracle', 'type': 'soft', 'item': 'stack', 'value': 10240},\n        ...     {'domain': 'oracle', 'type': 'hard', 'item': 'stack', 'value': 3276},\n        ...     {'domain': 'root', 'type': 'soft', 'item': 'nproc', 'value': -1}]\n        ...\n        >>> keyword_search(rows, domain='root')\n        [{'domain': 'root', 'type': 'soft', 'item': 'nproc', 'value': -1}]\n        >>> keyword_search(rows, item__contains='c')\n        [{'domain': 'oracle', 'type': 'soft', 'item': 'stack', 'value': 10240},\n         {'domain': 'oracle', 'type': 'hard', 'item': 'stack', 'value': 3276},\n         {'domain': 'root', 'type': 'soft', 'item': 'nproc', 'value': -1}]\n        >>> keyword_search(rows, domain__startswith='r')\n        [{'domain': 'root', 'type': 'soft', 'item': 'nproc', 'value': -1}]\n    \"\"\"\n    results = []\n    if not kwargs:\n        return results\n\n    # Allows us to transform the key and do lookups like __contains and\n    # __startswith\n    matchers = {\n        'default': lambda s, v: s == v,\n        'contains': lambda s, v: v in s,\n        'startswith': lambda s, v: s.startswith(v),\n        'lower_value': lambda s, v: s.lower() == v.lower(),\n    }\n\n    def key_match(row, key, value):\n        # Translate ' ' and '-' of keys in dict to '_' to match keyword arguments.\n        my_row = {}\n        for my_key, val in row.items():\n            my_row[my_key.replace(' ', '_').replace('-', '_')] = val\n        matcher_fn = matchers['default']\n        if '__' in key:\n            key, matcher = key.split('__', 1)\n            if matcher not in matchers:\n                # put key back the way we found it, matcher fn unchanged\n                key = key + '__' + matcher\n            else:\n                matcher_fn = matchers[matcher]\n        return key in my_row and matcher_fn(my_row[key], value)\n\n    data = []\n    for row in rows:\n        if all(map(lambda kv: key_match(row, kv[0], kv[1]), kwargs.items())):\n            data.append(row)\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncounting the number of exceptions that have been processed by the broker.", "response": "def count_exceptions(self, c, broker):\n        \"\"\"\n        Count exceptions as processing proceeds\n        \"\"\"\n        if c in broker.exceptions:\n            self.counts['exception'] += len(broker.exceptions[c])\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprinting the description of the current object.", "response": "def show_description(self):\n        \"\"\" Prints the formatted response for the matching return type \"\"\"\n        def print_missing(c, v):\n            resp = self.responses[v[\"type\"]]\n            name = \"[%s] %s\" % (resp.label, dr.get_name(c))\n            self.print_header(name, 3)\n            print(file=self.stream)\n            print('*Missing Dependencies*:', file=self.stream)\n            req_all, req_any = v.missing\n            if req_all:\n                print(file=self.stream)\n                print('* Requires:', file=self.stream)\n                for m in req_all:\n                    print('    * {}'.format(dr.get_name(m)), file=self.stream)\n            if req_any:\n                print(file=self.stream)\n                for m in req_any:\n                    print('* At Least One Of:', file=self.stream)\n                    if type(m) == list:\n                        for c in m:\n                            print('    * {}'.format(dr.get_name(c)), file=self.stream)\n                    else:\n                        print('    * {}'.format(dr.get_name(m)), file=self.stream)\n            print(file=self.stream)\n\n        def printit(c, v):\n            print(\"```\", file=self.stream)\n            print(render(c, v), file=self.stream)\n            print(\"```\", file=self.stream)\n            print(file=self.stream)\n\n        for c in sorted(self.broker.get_by_type(rule), key=dr.get_name):\n            v = self.broker[c]\n            _type = v.get('type')\n            if _type in self.responses:\n                self.counts[_type] += 1\n            if _type:\n                if self.missing and _type == 'skip':\n                    print_missing(c, v)\n                elif ((self.fail_only and _type == 'rule') or\n                      (not self.fail_only and _type != 'skip')):\n                    printit(c, v)\n        print(file=self.stream)\n\n        self.print_header(\"Rule Execution Summary\", 2)\n        print(\"```\", file=self.stream)\n        for c in self.counts:\n            print(' ' + self.responses[c].title + str(self.counts[c]), file=self.stream)\n        print(\"```\", file=self.stream)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nclustering rule to process bash and hostname info ``bash`` and ``hostnames`` are Pandas DataFrames for the facts collected for each host in the cluster. See https://pandas.pydata.org/pandas-docs/stable/api.html#dataframe for information on available attributes and methods. Arguments: bash (pandas.DataFrame): Includes facts from ``bash_version`` fact with columns \"name\" and \"version\" and one row per host in the cluster. hostnames (pandas.DataFrame): Includes facts from ``get_hostname`` fact with column \"hostname\" and one row per host in the cluster.", "response": "def bash_rule(bash, hostnames):\n    \"\"\"\n    Cluster rule to process bash and hostname info\n\n    ``bash`` and ``hostnames`` are Pandas DataFrames for the facts collected\n    for each host in the cluster.  See\n    https://pandas.pydata.org/pandas-docs/stable/api.html#dataframe\n    for information on available attributes and methods.\n\n    Arguments:\n        bash (pandas.DataFrame): Includes facts from ``bash_version``\n            fact with columns \"name\" and \"version\" and one row per\n            host in the cluster.\n        hostnames (pandas.DataFrame): Includes facts from ``get_hostname``\n            fact with column \"hostname\" and one row per\n            host in the cluster.\n    \"\"\"\n    if isinstance(bash, dict):\n        return make_fail('bash_rule',\n                         error_message=\"Run this rule with a cluster archive\")\n\n    return make_pass('bash_rule', bash=bash, hostname=hostnames)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a new unnamed tuple with the following items.", "response": "def redhat_release(rh_release, un):\n    \"\"\"\n    .. warning::\n        This combiner methode is deprecated, please use\n        :py:class:`insights.combiners.redhat_release.RedHatRelease` instead.\n\n    Combiner method to check uname and redhat-release for rhel major/minor\n    version.\n\n    Prefer uname to redhat-release.\n\n    Returns:\n        Release: A named tuple with the following items:\n            - major: integer\n            - minor: integer\n\n    Raises:\n        ParseException: If the version can't be determined even though a Uname\n            or RedhatRelease was provided.\n\n    Examples:\n        >>> rh_release.major\n        7\n        >>> rh_release.minor\n        2\n        >>> rh_release\n        Release(major=7, minor=2)\n\n    \"\"\"\n\n    deprecated(redhat_release, \"Use the `RedHatRelease` class instead.\")\n\n    if un and un.release_tuple[0] != -1:\n        return Release(*un.release_tuple)\n\n    if rh_release:\n        return Release(rh_release.major, rh_release.minor)\n\n    raise ParseException(\"Unabled to determine release.\")"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef mangle_command(command, name_max=255):\n    pattern = r\"[^\\w\\-\\.\\/]+\"\n\n    mangledname = re.sub(r\"^/(usr/|)(bin|sbin)/\", \"\", command)\n    mangledname = re.sub(pattern, \"_\", mangledname)\n    mangledname = re.sub(r\"/\", \".\", mangledname).strip(\" ._-\")\n    mangledname = mangledname[:name_max]\n    return mangledname", "response": "Mangle a command line string into something suitable for use as a filename."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef stream(self):\n        st = self._stream()\n        for l in next(st):\n            yield l.rstrip(\"\\n\")", "response": "Returns a generator of lines instead of a list of lines."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a generator of lines instead of a list of lines.", "response": "def _stream(self):\n        \"\"\"\n        Returns a generator of lines instead of a list of lines.\n        \"\"\"\n        if self._exception:\n            raise self._exception\n        try:\n            if self._content:\n                yield self._content\n            else:\n                args = self.create_args()\n                if args:\n                    with streams.connect(*args, env=SAFE_ENV) as s:\n                        yield s\n                else:\n                    with open(self.path, \"rU\") as f:  # universal newlines\n                        yield f\n        except StopIteration:\n            raise\n        except Exception as ex:\n            self._exception = ex\n            raise ContentException(str(ex))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _stream(self):\n        if self._exception:\n            raise self._exception\n        try:\n            if self._content:\n                yield self._content\n            else:\n                args = self.create_args()\n                with self.ctx.connect(*args, env=self.create_env(), timeout=self.timeout) as s:\n                    yield s\n        except StopIteration:\n            raise\n        except Exception as ex:\n            self._exception = ex\n            raise ContentException(str(ex))", "response": "Returns a generator of lines instead of a list of lines."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef marshal(self, o, use_value_list=False):\n\n        if o is None:\n            return\n        elif isinstance(o, dict):\n            if use_value_list:\n                for k, v in o.items():\n                    o[k] = [v]\n            return o\n        elif isinstance(o, six.string_types):\n            if use_value_list:\n                return {o: [True]}\n            else:\n                return {o: True}\n        else:\n            raise TypeError(\"Marshaller doesn't support given type %s\" % type(o))", "response": "Serializes the object o into a dictionary of the appropriate type."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_context(ctx):\n    ctx_cls_name = ctx.get(\"class\", \"insights.core.context.HostContext\")\n    if \".\" not in ctx_cls_name:\n        ctx_cls_name = \"insights.core.context.\" + ctx_cls_name\n    ctx_cls = dr.get_component(ctx_cls_name)\n    ctx_args = ctx.get(\"args\", {})\n    return ctx_cls(**ctx_args)", "response": "Loads and constructs a new context from the specified context."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngives a specification of what to persist generates the corresponding set of components.", "response": "def get_to_persist(persisters):\n    \"\"\"\n    Given a specification of what to persist, generates the corresponding set\n    of components.\n    \"\"\"\n    def specs():\n        for p in persisters:\n            if isinstance(p, dict):\n                yield p[\"name\"], p.get(\"enabled\", True)\n            else:\n                yield p, True\n\n    components = sorted(dr.DELEGATES, key=dr.get_name)\n    names = dict((c, dr.get_name(c)) for c in components)\n\n    results = set()\n    for p, e in specs():\n        for c in components:\n            if names[c].startswith(p):\n                if e:\n                    results.add(c)\n                elif c in results:\n                    results.remove(c)\n    return results"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_archive(path, remove_path=True):\n    root_path = os.path.dirname(path)\n    relative_path = os.path.basename(path)\n    archive_path = path + \".tar.gz\"\n\n    cmd = [[\"tar\", \"-C\", root_path, \"-czf\", archive_path, relative_path]]\n    call(cmd, env=SAFE_ENV)\n    if remove_path:\n        fs.remove(path)\n    return archive_path", "response": "Create a tar. gz of the path using the path basename +. tar. gz"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nyields a ThreadPoolExecutor that yields the pool of the available resources.", "response": "def get_pool(parallel, kwargs):\n    \"\"\"\n    Yields:\n        a ThreadPoolExecutor if parallel is True and `concurrent.futures` exists.\n        `None` otherwise.\n    \"\"\"\n\n    if parallel:\n        try:\n            from concurrent.futures import ThreadPoolExecutor\n            with ThreadPoolExecutor(thread_name_prefix=\"insights-collector-pool\", **kwargs) as pool:\n                yield pool\n        except ImportError:\n            yield None\n    else:\n        yield None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrun is a general interface that is meant for stand alone scripts to use when executing insights components. Args: root (str): None will causes a host collection in which command and file specs are run. A directory or archive path will cause collection from the directory or archive, and only file type specs or those that depend on `insights.core.context.HostArchiveContext` will execute. component (function or class): The component to execute. Will only execute the component and its dependency graph. If None, all components with met dependencies will execute. Returns: broker: object containing the result of the evaluation.", "response": "def _run(broker, graph=None, root=None, context=None, inventory=None):\n    \"\"\"\n    run is a general interface that is meant for stand alone scripts to use\n    when executing insights components.\n\n    Args:\n        root (str): None will causes a host collection in which command and\n            file specs are run. A directory or archive path will cause\n            collection from the directory or archive, and only file type specs\n            or those that depend on `insights.core.context.HostArchiveContext`\n            will execute.\n        component (function or class): The component to execute. Will only execute\n            the component and its dependency graph. If None, all components with\n            met dependencies will execute.\n\n    Returns:\n        broker: object containing the result of the evaluation.\n    \"\"\"\n\n    if not root:\n        context = context or HostContext\n        broker[context] = context()\n        return dr.run(graph, broker=broker)\n\n    if os.path.isdir(root):\n        return process_dir(broker, root, graph, context, inventory=inventory)\n    else:\n        with extract(root) as ex:\n            return process_dir(broker, ex.tmp_dir, graph, context, inventory=inventory)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconfiguring dr and already loaded components with a default enabled value.", "response": "def apply_default_enabled(default_enabled):\n    \"\"\"\n    Configures dr and already loaded components with a default enabled\n    value.\n    \"\"\"\n    for k in dr.ENABLED:\n        dr.ENABLED[k] = default_enabled\n\n    enabled = defaultdict(lambda: default_enabled)\n    enabled.update(dr.ENABLED)\n    dr.ENABLED = enabled"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef apply_configs(config):\n    default_enabled = config.get('default_component_enabled', False)\n    delegate_keys = sorted(dr.DELEGATES, key=dr.get_name)\n    for comp_cfg in config.get('configs', []):\n        name = comp_cfg.get(\"name\")\n        for c in delegate_keys:\n            delegate = dr.DELEGATES[c]\n            cname = dr.get_name(c)\n            if cname.startswith(name):\n                dr.ENABLED[c] = comp_cfg.get(\"enabled\", default_enabled)\n                delegate.metadata.update(comp_cfg.get(\"metadata\", {}))\n                delegate.tags = set(comp_cfg.get(\"tags\", delegate.tags))\n                for k, v in delegate.metadata.items():\n                    if hasattr(c, k):\n                        log.debug(\"Setting %s.%s to %s\", cname, k, v)\n                        setattr(c, k, v)\n                if hasattr(c, \"timeout\"):\n                    c.timeout = comp_cfg.get(\"timeout\", c.timeout)\n            if cname == name:\n                break", "response": "Applies the configuration to the components in the order they appear."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_section(self, section):\n        if section.lower() == \"default\":\n            raise ValueError('Invalid section name: %s' % section)\n\n        if section in self._sections:\n            raise DuplicateSectionError(section)\n        self._sections[section] = self._dict()", "response": "Add a new section to the configuration."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read(self, filenames):\n        if isinstance(filenames, basestring):\n            filenames = [filenames]\n        read_ok = []\n        for filename in filenames:\n            try:\n                fp = open(filename)\n            except IOError:\n                continue\n            self._read(fp, filename)\n            fp.close()\n            read_ok.append(filename)\n        return read_ok", "response": "Read and parse a filename or a list of filenames."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlikes read but the argument must be a file - like object.", "response": "def readfp(self, fp, filename=None):\n        \"\"\"Like read() but the argument must be a file-like object.\n\n        The `fp' argument must have a `readline' method.  Optional\n        second argument is the `filename', which if not given, is\n        taken from fp.name.  If fp has no `name' attribute, `<???>' is\n        used.\n\n        \"\"\"\n        if filename is None:\n            try:\n                filename = fp.name\n            except AttributeError:\n                filename = '<???>'\n        self._read(fp, filename)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write(self, fp):\n        if self._defaults:\n            fp.write(\"[%s]\\n\" % DEFAULTSECT)\n            for (key, value) in self._defaults.items():\n                fp.write(\"%s = %s\\n\" % (key, str(value).replace('\\n', '\\n\\t')))\n            fp.write(\"\\n\")\n        for section in self._sections:\n            fp.write(\"[%s]\\n\" % section)\n            for (key, value) in self._sections[section].items():\n                if key == \"__name__\":\n                    continue\n                if (value is not None) or (self._optcre == self.OPTCRE):\n                    key = \" = \".join((key, str(value).replace('\\n', '\\n\\t')))\n                fp.write(\"%s\\n\" % (key))\n            fp.write(\"\\n\")", "response": "Write an. ini - format representation of the configuration state."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove an option from the specified section.", "response": "def remove_option(self, section, option):\n        \"\"\"Remove an option.\"\"\"\n        if not section or section == DEFAULTSECT:\n            sectdict = self._defaults\n        else:\n            try:\n                sectdict = self._sections[section]\n            except KeyError:\n                raise NoSectionError(section)\n        option = self.optionxform(option)\n        existed = option in sectdict\n        if existed:\n            del sectdict[option]\n        return existed"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _read(self, fp, fpname):\n        cursect = None                        # None, or a dictionary\n        optname = None\n        lineno = 0\n        e = None                              # None, or an exception\n        while True:\n            line = fp.readline()\n            if not line:\n                break\n            lineno = lineno + 1\n            # comment or blank line?\n            if line.strip() == '' or line[0] in '#;':\n                continue\n            if line.split(None, 1)[0].lower() == 'rem' and line[0] in \"rR\":\n                # no leading whitespace\n                continue\n            # continuation line?\n            if line[0].isspace() and cursect is not None and optname:\n                value = line.strip()\n                if value:\n                    cursect[optname].append(value)\n            # a section header or option header?\n            else:\n                # is it a section header?\n                mo = self.SECTCRE.match(line)\n                if mo:\n                    sectname = mo.group('header')\n                    if sectname in self._sections:\n                        cursect = self._sections[sectname]\n                    elif sectname == DEFAULTSECT:\n                        cursect = self._defaults\n                    else:\n                        cursect = self._dict()\n                        cursect['__name__'] = sectname\n                        self._sections[sectname] = cursect\n                    # So sections can't start with a continuation line\n                    optname = None\n                # no section header in the file?\n                elif cursect is None:\n                    raise MissingSectionHeaderError(fpname, lineno, line)\n                # an option line?\n                else:\n                    mo = self._optcre.match(line)\n                    if mo:\n                        optname, vi, optval = mo.group('option', 'vi', 'value')\n                        optname = self.optionxform(optname.rstrip())\n                        # This check is fine because the OPTCRE cannot\n                        # match if it would set optval to None\n                        if optval is not None:\n                            if vi in ('=', ':') and ';' in optval:\n                                # ';' is a comment delimiter only if it follows\n                                # a spacing character\n                                pos = optval.find(';')\n                                if pos != -1 and optval[pos-1].isspace():\n                                    optval = optval[:pos]\n                            optval = optval.strip()\n                            # allow empty values\n                            if optval == '\"\"':\n                                optval = ''\n                            cursect[optname] = [optval]\n                        else:\n                            # valueless option handling\n                            cursect[optname] = optval\n                    else:\n                        # a non-fatal parsing error occurred.  set up the\n                        # exception but keep going. the exception will be\n                        # raised at the end of the file and will contain a\n                        # list of all bogus lines\n                        if not e:\n                            e = ParsingError(fpname)\n                        e.append(lineno, repr(line))\n        # if any parsing errors occurred, raise an exception\n        if e:\n            raise e\n\n        # join the multi-line values collected while reading\n        all_sections = [self._defaults]\n        all_sections.extend(self._sections.values())\n        for options in all_sections:\n            for name, val in options.items():\n                if isinstance(val, list):\n                    options[name] = '\\n'.join(val)", "response": "Parse a sectioned setup file."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget an option value for a given section.", "response": "def get(self, section, option, raw=False, vars=None):\n        \"\"\"Get an option value for a given section.\n\n        If `vars' is provided, it must be a dictionary. The option is looked up\n        in `vars' (if provided), `section', and in `defaults' in that order.\n\n        All % interpolations are expanded in the return values, unless the\n        optional argument `raw' is true. Values for interpolation keys are\n        looked up in the same manner as the option.\n\n        The section DEFAULT is special.\n        \"\"\"\n        sectiondict = {}\n        try:\n            sectiondict = self._sections[section]\n        except KeyError:\n            if section != DEFAULTSECT:\n                raise NoSectionError(section)\n        # Update with the entry specific variables\n        vardict = {}\n        if vars:\n            for key, value in vars.items():\n                vardict[self.optionxform(key)] = value\n        d = _Chainmap(vardict, sectiondict, self._defaults)\n        option = self.optionxform(option)\n        try:\n            value = d[option]\n        except KeyError:\n            raise NoOptionError(option, section)\n\n        if raw or value is None:\n            return value\n        else:\n            return self._interpolate(section, option, value, d)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of tuples with name value for each option in the section.", "response": "def items(self, section, raw=False, vars=None):\n        \"\"\"Return a list of tuples with (name, value) for each option\n        in the section.\n\n        All % interpolations are expanded in the return values, based on the\n        defaults passed into the constructor, unless the optional argument\n        `raw' is true.  Additional substitutions may be provided using the\n        `vars' argument, which must be a dictionary whose contents overrides\n        any pre-existing defaults.\n\n        The section DEFAULT is special.\n        \"\"\"\n        d = self._defaults.copy()\n        try:\n            d.update(self._sections[section])\n        except KeyError:\n            if section != DEFAULTSECT:\n                raise NoSectionError(section)\n        # Update with the entry specific variables\n        if vars:\n            for key, value in vars.items():\n                d[self.optionxform(key)] = value\n        options = d.keys()\n        if \"__name__\" in options:\n            options.remove(\"__name__\")\n        if raw:\n            return [(option, d[option])\n                    for option in options]\n        else:\n            return [(option, self._interpolate(section, option, d[option], d))\n                    for option in options]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nextends ConfigParser. set to allow for string values.", "response": "def set(self, section, option, value=None):\n        \"\"\"Set an option.  Extend ConfigParser.set: check for string values.\"\"\"\n        # The only legal non-string value if we allow valueless\n        # options is None, so we need to check if the value is a\n        # string if:\n        # - we do not allow valueless options, or\n        # - we allow valueless options but the value is not None\n        if self._optcre is self.OPTCRE or value:\n            if not isinstance(value, basestring):\n                raise TypeError(\"option values must be strings\")\n        if value is not None:\n            # check for bad percent signs:\n            # first, replace all \"good\" interpolations\n            tmp_value = value.replace('%%', '')\n            tmp_value = self._interpvar_re.sub('', tmp_value)\n            # then, check if there's a lone percent sign left\n            if '%' in tmp_value:\n                raise ValueError(\"invalid interpolation syntax in %r at \"\n                                \"position %d\" % (value, tmp_value.find('%')))\n        ConfigParser.set(self, section, option, value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndetermine the hostname of the current node.", "response": "def determine_hostname(display_name=None):\n    \"\"\"\n    Find fqdn if we can\n    \"\"\"\n    if display_name:\n        # if display_name is provided, just return the given name\n        return display_name\n    else:\n        socket_gethostname = socket.gethostname()\n        socket_fqdn = socket.getfqdn()\n\n        try:\n            socket_ex = socket.gethostbyname_ex(socket_gethostname)[0]\n        except (LookupError, socket.gaierror):\n            socket_ex = ''\n\n        gethostname_len = len(socket_gethostname)\n        fqdn_len = len(socket_fqdn)\n        ex_len = len(socket_ex)\n\n        if fqdn_len > gethostname_len or ex_len > gethostname_len:\n            if \"localhost\" not in socket_ex and len(socket_ex):\n                return socket_ex\n            if \"localhost\" not in socket_fqdn:\n                return socket_fqdn\n\n        return socket_gethostname"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrite the. unregistered file to disk.", "response": "def write_unregistered_file(date=None):\n    \"\"\"\n    Write .unregistered out to disk\n    \"\"\"\n    delete_registered_file()\n    if date is None:\n        date = get_time()\n    for f in constants.unregistered_files:\n        if os.path.lexists(f):\n            if os.path.islink(f):\n                # kill symlinks and regenerate\n                os.remove(f)\n                write_to_disk(f, content=str(date))\n        else:\n            write_to_disk(f, content=str(date))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef write_to_disk(filename, delete=False, content=get_time()):\n    if not os.path.exists(os.path.dirname(filename)):\n        return\n    if delete:\n        if os.path.lexists(filename):\n            os.remove(filename)\n    else:\n        with open(filename, 'wb') as f:\n            f.write(content.encode('utf-8'))", "response": "Write filename out to disk"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef generate_machine_id(new=False,\n                        destination_file=constants.machine_id_file):\n    \"\"\"\n    Generate a machine-id if /etc/insights-client/machine-id does not exist\n    \"\"\"\n    machine_id = None\n    machine_id_file = None\n    logging_name = 'machine-id'\n\n    if os.path.isfile(destination_file) and not new:\n        logger.debug('Found %s', destination_file)\n        with open(destination_file, 'r') as machine_id_file:\n            machine_id = machine_id_file.read()\n    else:\n        logger.debug('Could not find %s file, creating', logging_name)\n        machine_id = str(uuid.uuid4())\n        logger.debug(\"Creating %s\", destination_file)\n        write_to_disk(destination_file, content=machine_id)\n\n    return str(machine_id).strip()", "response": "Generate a machine - id from a file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef validate_remove_file(remove_file):\n    if not os.path.isfile(remove_file):\n        logger.warn(\"WARN: Remove file does not exist\")\n        return False\n    # Make sure permissions are 600\n    mode = stat.S_IMODE(os.stat(remove_file).st_mode)\n    if not mode == 0o600:\n        logger.error(\"ERROR: Invalid remove file permissions\"\n                     \"Expected 0600 got %s\" % oct(mode))\n        return False\n    else:\n        logger.debug(\"Correct file permissions\")\n\n    if os.path.isfile(remove_file):\n        parsedconfig = RawConfigParser()\n        parsedconfig.read(remove_file)\n        rm_conf = {}\n        for item, value in parsedconfig.items('remove'):\n            rm_conf[item] = value.strip().split(',')\n        # Using print here as this could contain sensitive information\n        logger.debug(\"Remove file parsed contents\")\n        logger.debug(rm_conf)\n    logger.info(\"JSON parsed correctly\")\n    return True", "response": "Validate the remove file"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwrites data to file", "response": "def write_data_to_file(data, filepath):\n    '''\n    Write data to file\n    '''\n    try:\n        os.makedirs(os.path.dirname(filepath), 0o700)\n    except OSError:\n        pass\n\n    write_to_disk(filepath, content=data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef magic_plan_b(filename):\n    '''\n    Use this in instances where\n    python-magic is MIA and can't be installed\n    for whatever reason\n    '''\n    cmd = shlex.split('file --mime-type --mime-encoding ' + filename)\n    stdout, stderr = Popen(cmd, stdout=PIPE).communicate()\n    stdout = stdout.decode(\"utf-8\")\n    mime_str = stdout.split(filename + ': ')[1].strip()\n    return mime_str", "response": "Return the mime - type of a file in MIA format"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef modify_config_file(updates):\n    '''\n    Update the config file with certain things\n    '''\n    cmd = '/bin/sed '\n    for key in updates:\n        cmd = cmd + '-e \\'s/^#*{key}.*=.*$/{key}={value}/\\' '.format(key=key, value=updates[key])\n    cmd = cmd + constants.default_conf_file\n    status = run_command_get_output(cmd)\n    write_to_disk(constants.default_conf_file, content=status['output'])", "response": "Modify the config file with certain things\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsearching for all users running a given process.", "response": "def users(self, proc):\n        \"\"\"\n        Searches for all users running a given command.\n\n        Returns:\n            dict: each username as a key to a list of PIDs (as strings) that\n            are running the given process.\n            ``{}`` if  neither ``USER`` nor ``UID`` is found or ``proc`` is not found.\n\n        .. note::\n           'proc' must match the entire command and arguments.\n        \"\"\"\n        ret = {}\n        if self.first_column in ['USER', 'UID']:\n            for row in self.data:\n                if proc == row[self.command_name]:\n                    if row[self.first_column] not in ret:\n                        ret[row[self.first_column]] = []\n                    ret[row[self.first_column]].append(row[\"PID\"])\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning True if the word proc appears in any of the commands in the table.", "response": "def fuzzy_match(self, proc):\n        \"\"\"\n        Are there any commands that contain the given text?\n\n        Returns:\n            boolean: ``True`` if the word ``proc`` appears in the command column.\n\n        .. note::\n           'proc' can match anywhere in the command path, name or arguments.\n        \"\"\"\n        return any(proc in row[self.command_name] for row in self.data)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef number_occurences(self, proc):\n        return len([True for row in self.data if proc in row[self.command_name]])", "response": "Returns the number of occurencies of commands that contain given text\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cluster_info(cpu, cfg):\n    cpus = cpu.cpu_count\n    pods_per_core = cfg.doc.find(\"pods-per-core\")\n    pods_per_core_int = int(pods_per_core.value) if pods_per_core else PODS_PER_CORE\n    cfg_max_pods = cfg.doc.find(\"max-pods\")\n    cfg_max_pods_int = int(cfg_max_pods.value) if cfg_max_pods else MAX_PODS\n    calc_max_pods = cpus * pods_per_core_int\n\n    return {\n        \"cpu_count\": cpus,\n        \"pods_per_core\": pods_per_core_int,\n        \"pods_per_core_customized\": bool(pods_per_core),\n        \"max_pods\": min(cfg_max_pods_int, calc_max_pods),\n        \"max_pods_customized\": bool(cfg_max_pods)\n    }", "response": "Returns a dictionary of fact information for each host in the cluster."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfunctioning used to create the response for all master node types", "response": "def master_etcd(info, meta, max_pod_cluster, label):\n    \"\"\" Function used to create the response for all master node types \"\"\"\n    nodes = meta.get(label, []) or []\n    info = info[info[\"machine_id\"].isin(nodes)]\n    if info.empty:\n        return\n\n    cpu_factor = max_pod_cluster / 1000.0\n    nocpu_expected = MASTER_MIN_CORE + (max_pod_cluster / 1000.0)\n    bad = info[info[\"cpu_count\"] < nocpu_expected]\n    good = info[info[\"cpu_count\"] >= nocpu_expected]\n    return make_response(\"MASTER_ETCD\",\n                         nocpu_expected=nocpu_expected, cpu_factor=cpu_factor,\n                         bad=bad, good=good, max_pod_cluster=max_pod_cluster,\n                         GREEN=Fore.GREEN, RED=Fore.RED, YELLOW=Fore.YELLOW, NC=Style.RESET_ALL)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfunctions used to create the response for all infra node types", "response": "def infra_nodes(info, meta, max_pod_cluster, label, key):\n    \"\"\" Function used to create the response for all infra node types \"\"\"\n    nodes = meta.get(label, []) or []\n    infos = info[info[\"machine_id\"].isin(nodes)]\n    if infos.empty:\n        return\n    return make_response(key, max_pod_cluster=max_pod_cluster, infos=infos,\n                         GREEN=Fore.GREEN, RED=Fore.RED, YELLOW=Fore.YELLOW, NC=Style.RESET_ALL)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_df_lines(df_content):\n    df_ls = {}\n    df_out = []\n    is_sep = False\n    columns = Record._fields\n    for line in df_content[1:]:  # [1:] -> Skip the header\n        # Stop at 5 splits to avoid splitting spaces in path\n        line_splits = line.rstrip().split(None, 5)\n        if len(line_splits) >= 6:\n            for i, name in enumerate(columns):\n                df_ls[name] = line_splits[i]\n            is_sep = False\n        elif len(line_splits) == 1:\n            # First line of the separated line\n            df_ls[columns[0]] = line_splits[0]\n            is_sep = True\n        elif is_sep and len(line_splits) >= 5:\n            # Re-split to avoid this kind of \"Mounted on\": \"VMware Tools\"\n            line_splits = line.split(None, 4)\n            # Last line of the separated line\n            for i, name in enumerate(columns[1:]):\n                df_ls[name] = line_splits[i]\n            is_sep = False\n        elif not line_splits:  # Skip empty lines (might in sosreport)\n            continue\n        else:\n            raise ParseException(\"Could not parse line '{l}'\".format(l=line))\n        # Only add this record if we've got a line and it's not separated\n        if df_ls and not is_sep:\n            rec = Record(**df_ls)\n            df_out.append(rec)\n            df_ls = {}\n    return df_out", "response": "Parse the contents of each line in df output."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_dir(self, path):\n        try:\n            longest = max(m for m in self.mounts if path.startswith(m))\n            return self.mounts[longest]\n        except ValueError:\n            return None", "response": "Returns the Record object that contains the given path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting all the parameters for a given keyword or parameter.", "response": "def get_param(self, keyword, param=None, default=None):\n        \"\"\"\n        Get all the parameters for a given keyword, or default if keyword or\n        parameter are not present in the configuration.\n\n        This finds every declaration of the given parameter (which is the\n        one which takes effect).  If no parameter is given, then the entire\n        line is treated as the parameter.  There is always at least one\n        element returned - the default, or\n\n        Parameters:\n            keyword(str): The keyword name, e.g. 'tinker' or 'driftfile'\n            param(str): The parameter name, e.g. 'panic' or 'step'.  If not\n                given, all the definitions of that keyword are given.\n            default(str): The default (singular) value if the keyword or\n                parameter is not found.  If not given, None is used.\n\n        Returns:\n            list: All the values of the given parameter, or an empty list if\n            not found.\n        \"\"\"\n        if not keyword or keyword not in self.data:\n            return [default]\n        # keyword in data - if no value, we store None, so return that in a list\n        if self.data[keyword] is None:\n            return [None]\n        # If we're not searching for a particular parameter, just return all\n        # the values for this keyword.\n        if not param:\n            return self.data[keyword]\n\n        found = []\n        for line in self.data[keyword]:\n            # Line has already had keyword removed.\n            words = line.strip().split()\n            if len(words) > 1:\n                # Line has param and value - check param:\n                if words[0] == param:\n                    found.append(words[1])\n            else:\n                found.append(words[0])\n        if found == []:\n            return [default]\n        else:\n            return found"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_last(self, keyword, param=None, default=None):\n        return self.get_param(keyword, param, default)[-1]", "response": "Get the last declaration of a given keyword or default."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _replace_tabs(s, ts=8):\n    result = ''\n    for c in s:\n        if c == '\\t':\n            while True:\n                result += ' '\n                if len(result) % ts == 0:\n                    break\n        else:\n            result += c\n    return result", "response": "Replace tabs in s with tab - stop and keep its original alignment with the tab - stop equals to ts"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nextracts a file into a temporary directory in extract_dir.", "response": "def extract(path, timeout=None, extract_dir=None, content_type=None):\n    \"\"\"\n    Extract path into a temporary directory in `extract_dir`.\n\n    Yields an object containing the temporary path and the content type of the\n    original archive.\n\n    If the extraction takes longer than `timeout` seconds, the temporary path\n    is removed, and an exception is raised.\n    \"\"\"\n    content_type = content_type or content_type_from_file(path)\n    if content_type == \"application/zip\":\n        extractor = ZipExtractor(timeout=timeout)\n    else:\n        extractor = TarExtractor(timeout=timeout)\n\n    try:\n        ctx = extractor.from_path(path, extract_dir=extract_dir, content_type=content_type)\n        content_type = extractor.content_type\n        yield Extraction(ctx.tmp_dir, content_type)\n    finally:\n        if extractor.created_tmp_dir:\n            fs.remove(extractor.tmp_dir, chmod=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfiring if the machine is running Fedora.", "response": "def report(rel):\n    \"\"\"Fires if the machine is running Fedora.\"\"\"\n\n    if \"Fedora\" in rel.product:\n        return make_pass(\"IS_FEDORA\", product=rel.product)\n    else:\n        return make_fail(\"IS_NOT_FEDORA\", product=rel.product)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmaking the regular expression that matches a crontab line.", "response": "def _make_cron_re():\n    \"\"\"\n    Make the regular expression that matches a crontab 'cron' line.\n\n    Each field has a set of allowed values, and can then be in a range, and be\n    listed with dashes.  A range can be stepped with the '/' modifier, and\n    ranges can be in a list.  A field can also be '*', or '*' divided in steps.\n\n    The best way to do this is to have a template for a single field that\n    encapsulates the syntax of that field, regardless of what that field\n    matches.  We then fill in the actual template's value with the pattern\n    that matches that field.  Each field is named, so we can pull them out as\n    a dictionary later.\n    \"\"\"\n    range_ = r\"{val}(?:-{val}(?:/\\d+)?)?\"\n    template = r\"(?P<{name}>\" + \"(?:\\*(?:/\\d+)?|{r}(?:,{r})*)\".format(r=range_) + \")\\s+\"\n    return (\n        r'^\\s*' +\n        template.format(name='minute', val=r'(?:\\d|[012345]\\d)') +\n        template.format(name='hour', val=r'(?:\\d|[01]\\d|2[0123])') +\n        template.format(name='day_of_month', val=r'(?:0?[1-9]|[12]\\d|3[01])') +\n        template.format(name='month', val=r'(?:0?[1-9]|1[012]|jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec)') +\n        template.format(name='day_of_week', val=r'(?:[0-7]|mon|tue|wed|thur|fri|sat|sun)') +\n        r'(?P<command>\\S.*)$'\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses the content of the date and date - utc command.", "response": "def parse_content(self, content):\n        \"\"\"\n        Parses the output of the ``date`` and ``date --utc`` command.\n\n        Sample: Fri Jun 24 09:13:34 CST 2016\n        Sample: Fri Jun 24 09:13:34 UTC 2016\n\n        Attributes\n        ----------\n        datetime: datetime.datetime\n            A native datetime.datetime of the parsed date string\n        timezone: str\n            The string portion of the date string containing the timezone\n\n        Raises:\n            DateParseException: Raised if any exception occurs parsing the\n            content.\n        \"\"\"\n        self.data = get_active_lines(content, comment_char=\"COMMAND>\")[0]\n        parts = self.data.split()\n        if not len(parts) == 6:\n            msg = \"Expected six date parts.  Got [%s]\"\n            raise DateParseException(msg % self.data)\n        try:\n            self.timezone = parts[4]\n            no_tz = ' '.join(parts[:4]) + ' ' + parts[-1]\n            self.datetime = datetime.strptime(no_tz, '%a %b %d %H:%M:%S %Y')\n        except:\n            six.reraise(DateParseException, DateParseException(self.data), sys.exc_info()[2])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nverifying connectivity to satellite server and return the remote leaf node if successful.", "response": "def verify_connectivity(config):\n    \"\"\"\n    Verify connectivity to satellite server\n    \"\"\"\n    logger.debug(\"Verifying Connectivity\")\n    ic = InsightsConnection(config)\n    try:\n        branch_info = ic.get_branch_info()\n    except requests.ConnectionError as e:\n        logger.debug(e)\n        logger.debug(\"Failed to connect to satellite\")\n        return False\n    except LookupError as e:\n        logger.debug(e)\n        logger.debug(\"Failed to parse response from satellite\")\n        return False\n\n    try:\n        remote_leaf = branch_info['remote_leaf']\n        return remote_leaf\n    except LookupError as e:\n        logger.debug(e)\n        logger.debug(\"Failed to find accurate branch_info\")\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset config based on discovered data and return a new config object.", "response": "def set_auto_configuration(config, hostname, ca_cert, proxy, is_satellite):\n    \"\"\"\n    Set config based on discovered data\n    \"\"\"\n    logger.debug(\"Attempting to auto configure!\")\n    logger.debug(\"Attempting to auto configure hostname: %s\", hostname)\n    logger.debug(\"Attempting to auto configure CA cert: %s\", ca_cert)\n    logger.debug(\"Attempting to auto configure proxy: %s\", proxy)\n    saved_base_url = config.base_url\n    if ca_cert is not None:\n        saved_cert_verify = config.cert_verify\n        config.cert_verify = ca_cert\n    if proxy is not None:\n        saved_proxy = config.proxy\n        config.proxy = proxy\n    if is_satellite:\n        # satellite\n        config.base_url = hostname + '/r/insights'\n        if not config.legacy_upload:\n            config.base_url += '/platform'\n        logger.debug('Auto-configured base_url: %s', config.base_url)\n    else:\n        # connected directly to RHSM\n        if config.legacy_upload:\n            config.base_url = hostname + '/r/insights'\n        else:\n            config.base_url = hostname + '/api'\n        logger.debug('Auto-configured base_url: %s', config.base_url)\n        logger.debug('Not connected to Satellite, skipping branch_info')\n        # direct connection to RHSM, skip verify_connectivity\n        return\n\n    if not verify_connectivity(config):\n        logger.warn(\"Could not auto configure, falling back to static config\")\n        logger.warn(\"See %s for additional information\",\n                    constants.default_log_file)\n        config.base_url = saved_base_url\n        if proxy is not None:\n            if saved_proxy is not None and saved_proxy.lower() == 'none':\n                saved_proxy = None\n            config.proxy = saved_proxy\n        if ca_cert is not None:\n            config.cert_verify = saved_cert_verify"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntrying to autoconfigure for Satellite 6 Configuration", "response": "def _try_satellite6_configuration(config):\n    \"\"\"\n    Try to autoconfigure for Satellite 6\n    \"\"\"\n    try:\n        rhsm_config = _importInitConfig()\n\n        logger.debug('Trying to autoconfigure...')\n        cert = open(rhsmCertificate.certpath(), 'r').read()\n        key = open(rhsmCertificate.keypath(), 'r').read()\n        rhsm = rhsmCertificate(key, cert)\n        is_satellite = False\n\n        # This will throw an exception if we are not registered\n        logger.debug('Checking if system is subscription-manager registered')\n        rhsm.getConsumerId()\n        logger.debug('System is subscription-manager registered')\n\n        rhsm_hostname = rhsm_config.get('server', 'hostname')\n        rhsm_hostport = rhsm_config.get('server', 'port')\n        rhsm_proxy_hostname = rhsm_config.get('server', 'proxy_hostname').strip()\n        rhsm_proxy_port = rhsm_config.get('server', 'proxy_port').strip()\n        rhsm_proxy_user = rhsm_config.get('server', 'proxy_user').strip()\n        rhsm_proxy_pass = rhsm_config.get('server', 'proxy_password').strip()\n\n        proxy = None\n\n        if rhsm_proxy_hostname != \"\":\n            logger.debug(\"Found rhsm_proxy_hostname %s\", rhsm_proxy_hostname)\n            proxy = \"http://\"\n            if rhsm_proxy_user != \"\" and rhsm_proxy_pass != \"\":\n                logger.debug(\"Found user and password for rhsm_proxy\")\n                proxy = proxy + rhsm_proxy_user + \":\" + rhsm_proxy_pass + \"@\"\n            proxy = proxy + rhsm_proxy_hostname + ':' + rhsm_proxy_port\n            logger.debug(\"RHSM Proxy: %s\", proxy)\n        logger.debug(\"Found %sHost: %s, Port: %s\",\n                     ('' if _is_rhn_or_rhsm(rhsm_hostname)\n                         else 'Satellite 6 Server '),\n                     rhsm_hostname, rhsm_hostport)\n        rhsm_ca = rhsm_config.get('rhsm', 'repo_ca_cert')\n        logger.debug(\"Found CA: %s\", rhsm_ca)\n        logger.debug(\"Setting authmethod to CERT\")\n        config.authmethod = 'CERT'\n\n        # Directly connected to Red Hat, use cert auth directly with the api\n        if _is_rhn_or_rhsm(rhsm_hostname):\n            # URL changes. my favorite\n            if config.legacy_upload:\n                logger.debug(\"Connected to Red Hat Directly, using cert-api\")\n                rhsm_hostname = 'cert-api.access.redhat.com'\n            else:\n                logger.debug(\"Connected to Red Hat Directly, using cloud.redhat.com\")\n                rhsm_hostname = 'cloud.redhat.com'\n            rhsm_ca = None\n        else:\n            # Set the host path\n            # 'rhsm_hostname' should really be named ~ 'rhsm_host_base_url'\n            rhsm_hostname = rhsm_hostname + ':' + rhsm_hostport + '/redhat_access'\n            is_satellite = True\n\n        logger.debug(\"Trying to set auto_configuration\")\n        set_auto_configuration(config, rhsm_hostname, rhsm_ca, proxy, is_satellite)\n        return True\n    except Exception as e:\n        logger.debug(e)\n        logger.debug('System is NOT subscription-manager registered')\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _try_satellite5_configuration(config):\n    logger.debug(\"Trying Satellite 5 auto_config\")\n    rhn_config = '/etc/sysconfig/rhn/up2date'\n    systemid = '/etc/sysconfig/rhn/systemid'\n    if os.path.isfile(rhn_config):\n        if os.path.isfile(systemid):\n            config.systemid = _read_systemid_file(systemid)\n        else:\n            logger.debug(\"Could not find Satellite 5 systemid file.\")\n            return False\n\n        logger.debug(\"Found Satellite 5 Config\")\n        rhn_conf_file = open(rhn_config, 'r')\n        hostname = None\n        for line in rhn_conf_file:\n            if line.startswith('serverURL='):\n                url = urlparse(line.split('=')[1])\n                hostname = url.netloc + '/redhat_access'\n                logger.debug(\"Found hostname %s\", hostname)\n            if line.startswith('sslCACert='):\n                rhn_ca = line.strip().split('=')[1]\n\n            # Auto discover proxy stuff\n            if line.startswith('enableProxy='):\n                proxy_enabled = line.strip().split('=')[1]\n            if line.startswith('httpProxy='):\n                proxy_host_port = line.strip().split('=')[1]\n            if line.startswith('proxyUser='):\n                proxy_user = line.strip().split('=')[1]\n            if line.startswith('proxyPassword='):\n                proxy_password = line.strip().split('=')[1]\n\n        if hostname:\n            proxy = None\n            if proxy_enabled == \"1\":\n                proxy = \"http://\"\n                if proxy_user != \"\" and proxy_password != \"\":\n                    logger.debug(\"Found user and password for rhn_proxy\")\n                    proxy = proxy + proxy_user + ':' + proxy_password\n                    proxy = proxy + \"@\" + proxy_host_port\n                else:\n                    proxy = proxy + proxy_host_port\n                    logger.debug(\"RHN Proxy: %s\", proxy)\n            set_auto_configuration(config, hostname, rhn_ca, proxy)\n        else:\n            logger.debug(\"Could not find hostname\")\n            return False\n        return True\n    else:\n        logger.debug(\"Could not find rhn config\")\n        return False", "response": "Try to determine Satellite 5 configuration."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntries to auto - configure if we are attached to a satellite.", "response": "def try_auto_configuration(config):\n    \"\"\"\n    Try to auto-configure if we are attached to a sat5/6\n    \"\"\"\n    if config.auto_config and not config.offline:\n        if not _try_satellite6_configuration(config):\n            _try_satellite5_configuration(config)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_chain(self, name, table=\"filter\"):\n        return [r for r in self.rules if r[\"table\"] == table and r[\"chain\"] == name]", "response": "Get the list of rules for a particular chain."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef table_chains(self, table=\"filter\"):\n        return dict((c[\"name\"], self.get_chain(c[\"name\"], table)) for c in self.get_table(table))", "response": "Returns a dictionary where the keys are all the chains for the given table and each values are the set of rules defined for the given chain."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_dom(self):\n        if self.dom is None:\n            return {}\n        else:\n            domain = {}\n            for child in self.dom:\n                if len(child) == 0:\n                    domain[child.tag] = child.text\n                else:\n                    domain[child.tag] = [c.items() for c in child]\n\n            return domain", "response": "Parse xml information in content and return."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fetch(self, force=False):\n        tmpdir = tempfile.mkdtemp()\n        fetch_results = {\n            'core': os.path.join(tmpdir, 'insights-core.egg'),\n            'gpg_sig': os.path.join(tmpdir, 'insights-core.egg.asc')\n        }\n\n        logger.debug(\"Beginning core fetch.\")\n\n        # guess the URLs based on what legacy setting is\n        egg_url = self.config.egg_path\n        egg_gpg_url = self.config.egg_gpg_path\n        if egg_url is None:\n            if self.config.legacy_upload:\n                egg_url = '/v1/static/core/insights-core.egg'\n            else:\n                egg_url = '/static/insights-core.egg'\n        if egg_gpg_url is None:\n            if self.config.legacy_upload:\n                egg_gpg_url = '/v1/static/core/insights-core.egg.asc'\n            else:\n                egg_gpg_url = '/static/insights-core.egg.asc'\n        # run fetch for egg\n        updated = self._fetch(egg_url,\n                              constants.core_etag_file,\n                              fetch_results['core'],\n                              force)\n\n        # if new core was fetched, get new core sig\n        if updated:\n            logger.debug(\"New core was fetched.\")\n            logger.debug(\"Beginning fetch for core gpg signature.\")\n            self._fetch(egg_gpg_url,\n                        constants.core_gpg_sig_etag_file,\n                        fetch_results['gpg_sig'],\n                        force)\n\n            return fetch_results", "response": "fetches the contents of the internal data file for the current version of the core"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfetch the new egg and cache it", "response": "def _fetch(self, path, etag_file, target_path, force):\n        \"\"\"\n            returns (str): path to new egg. None if no update.\n        \"\"\"\n        url = self.connection.base_url + path\n        # Searched for cached etag information\n        current_etag = None\n        if os.path.isfile(etag_file):\n            with open(etag_file, 'r') as fp:\n                current_etag = fp.read().strip()\n                logger.debug('Found etag %s', current_etag)\n\n        # Setup the new request for core retrieval\n        logger.debug('Making request to %s for new core', url)\n\n        # If the etag was found and we are not force fetching\n        # Then add it to the request\n        net_logger.info(\"GET %s\", url)\n        if current_etag and not force:\n            logger.debug('Requesting new file with etag %s', current_etag)\n            etag_headers = {'If-None-Match': current_etag}\n            response = self.session.get(url, headers=etag_headers, timeout=self.config.http_timeout)\n        else:\n            logger.debug('Found no etag or forcing fetch')\n            response = self.session.get(url, timeout=self.config.http_timeout)\n\n        # Debug information\n        logger.debug('Status code: %d', response.status_code)\n        for header, value in response.headers.items():\n            logger.debug('%s: %s', header, value)\n\n        # Debug the ETag\n        logger.debug('ETag: %s', response.request.headers.get('If-None-Match'))\n\n        # If data was received, write the new egg and etag\n        if response.status_code == 200 and len(response.content) > 0:\n\n            # Write the new core\n            with open(target_path, 'wb') as handle:\n                logger.debug('Data received, writing core to %s', target_path)\n                handle.write(response.content)\n\n            # Write the new etag\n            with open(etag_file, 'w') as handle:\n                logger.debug('Cacheing etag to %s', etag_file)\n                handle.write(response.headers['etag'])\n\n            return True\n\n        # Received a 304 not modified\n        # Return nothing\n        elif response.status_code == 304:\n            logger.debug('No data received')\n            logger.debug('Tags match, not updating core')\n\n        # Something unexpected received\n        else:\n            logger.debug('Received Code %s', response.status_code)\n            logger.debug('Not writing new core, or updating etag')\n            logger.debug('Please check config, error reaching %s', url)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nverifying the signature of the egg.", "response": "def verify(self, egg_path, gpg_key=constants.pub_gpg_path):\n        \"\"\"\n            Verifies the GPG signature of the egg.  The signature is assumed to\n            be in the same directory as the egg and named the same as the egg\n            except with an additional \".asc\" extension.\n\n            returns (dict): {'gpg': if the egg checks out,\n                             'stderr': error message if present,\n                             'stdout': stdout,\n                             'rc': return code}\n        \"\"\"\n        # check if the provided files (egg and gpg) actually exist\n        if egg_path and not os.path.isfile(egg_path):\n            the_message = \"Provided egg path %s does not exist, cannot verify.\" % (egg_path)\n            logger.debug(the_message)\n            return {'gpg': False,\n                    'stderr': the_message,\n                    'stdout': the_message,\n                    'rc': 1,\n                    'message': the_message}\n        if self.config.gpg and gpg_key and not os.path.isfile(gpg_key):\n            the_message = (\"Running in GPG mode but cannot find \"\n                            \"file %s to verify against.\" % (gpg_key))\n            logger.debug(the_message)\n            return {'gpg': False,\n                    'stderr': the_message,\n                    'stdout': the_message,\n                    'rc': 1,\n                    'message': the_message}\n\n        # if we are running in no_gpg or not gpg mode then return true\n        if not self.config.gpg:\n            return {'gpg': True,\n                    'stderr': None,\n                    'stdout': None,\n                    'rc': 0}\n\n        # if a valid egg path and gpg were received do the verification\n        if egg_path and gpg_key:\n            cmd_template = '/usr/bin/gpg --verify --keyring %s %s %s'\n            cmd = cmd_template % (gpg_key, egg_path + '.asc', egg_path)\n            logger.debug(cmd)\n            process = Popen(shlex.split(cmd), stdout=PIPE, stderr=PIPE)\n            stdout, stderr = process.communicate()\n            rc = process.returncode\n            logger.debug(\"GPG return code: %s\" % rc)\n            return {'gpg': True if rc == 0 else False,\n                    'stderr': stderr,\n                    'stdout': stdout,\n                    'rc': rc}\n        else:\n            return {'gpg': False,\n                    'stderr': 'Must specify a valid core and gpg key.',\n                    'stdout': 'Must specify a valid core and gpg key.',\n                    'rc': 1}"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef install(self, new_egg, new_egg_gpg_sig):\n\n        # make sure a valid egg was provided\n        if not new_egg:\n            the_message = 'Must provide a valid Core installation path.'\n            logger.debug(the_message)\n            return {'success': False, 'message': the_message}\n\n        # if running in gpg mode, check for valid sig\n        if self.config.gpg and new_egg_gpg_sig is None:\n            the_message = \"Must provide a valid Core GPG installation path.\"\n            logger.debug(the_message)\n            return {'success': False, 'message': the_message}\n\n        # debug\n        logger.debug(\"Installing the new Core %s\", new_egg)\n        if self.config.gpg:\n            logger.debug(\"Installing the new Core GPG Sig %s\", new_egg_gpg_sig)\n\n        # Make sure /var/lib/insights exists\n        try:\n            if not os.path.isdir(constants.insights_core_lib_dir):\n                logger.debug(\"Creating directory %s for the Core.\" %\n                             (constants.insights_core_lib_dir))\n                os.mkdir(constants.insights_core_lib_dir)\n        except OSError:\n            logger.info(\"There was an error creating %s for core installation.\" % (\n                constants.insights_core_lib_dir))\n            raise\n\n        # Copy the NEW (/tmp/insights-core.egg) egg to /var/lib/insights/newest.egg\n        # Additionally, copy NEW (/tmp/insights-core.egg.asc) to /var/lib/insights/newest.egg.asc\n        try:\n            logger.debug(\"Copying %s to %s.\" % (new_egg, constants.insights_core_newest))\n            shutil.copyfile(new_egg, constants.insights_core_newest)\n            shutil.copyfile(new_egg_gpg_sig, constants.insights_core_gpg_sig_newest)\n        except IOError:\n            logger.info(\"There was an error copying the new core from %s to %s.\" % (\n                new_egg, constants.insights_core_newest))\n            raise\n\n        logger.debug(\"The new Insights Core was installed successfully.\")\n        return {'success': True}", "response": "Installs the new egg and the new egg."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates the rules of the current user.", "response": "def update_rules(self):\n        \"\"\"\n            returns (dict): new client rules\n        \"\"\"\n        if self.config.offline or not self.config.auto_update:\n            logger.debug(\"Bypassing rule update due to config \"\n                \"running in offline mode or auto updating turned off.\")\n        else:\n            return client.update_rules(self.config, self.connection)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nuploads the archive at path with content type content_type. Returns the upload status code.", "response": "def upload(self, payload=None, content_type=None):\n        \"\"\"\n            Upload the archive at `path` with content type `content_type`\n            returns (int): upload status code\n        \"\"\"\n        # platform - prefer the value passed in to func over config\n        payload = payload or self.config.payload\n        content_type = content_type or self.config.content_type\n\n        if payload is None:\n            raise ValueError('Specify a file to upload.')\n\n        if not os.path.exists(payload):\n            raise IOError('Cannot upload %s: File does not exist.' % payload)\n\n        upload_results = client.upload(\n            self.config, self.connection, payload, content_type)\n\n        # return api response\n        return upload_results"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef rotate_eggs(self):\n        # make sure the library directory exists\n        if os.path.isdir(constants.insights_core_lib_dir):\n            # make sure the newest.egg exists\n            if os.path.isfile(constants.insights_core_newest):\n                # try copying newest to latest_stable\n                try:\n                    # copy the core\n                    shutil.move(constants.insights_core_newest,\n                             constants.insights_core_last_stable)\n                    # copy the core sig\n                    shutil.move(constants.insights_core_gpg_sig_newest,\n                             constants.insights_core_last_stable_gpg_sig)\n                except IOError:\n                    message = (\"There was a problem copying %s to %s.\" %\n                                (constants.insights_core_newest,\n                                constants.insights_core_last_stable))\n                    logger.debug(message)\n                    raise IOError(message)\n                return True\n            else:\n                message = (\"Cannot copy %s to %s because %s does not exist.\" %\n                            (constants.insights_core_newest,\n                            constants.insights_core_last_stable,\n                            constants.insights_core_newest))\n                logger.debug(message)\n                return False\n        else:\n            logger.debug(\"Cannot copy %s to %s because the %s directory does not exist.\" %\n                (constants.insights_core_newest,\n                    constants.insights_core_last_stable,\n                    constants.insights_core_lib_dir))\n            logger.debug(\"Try installing the Core first.\")\n            return False", "response": "This function copies eggs from newest to latest_stable. eggs from latest to last_stable. eggs"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_last_upload_results(self):\n        if os.path.isfile(constants.last_upload_results_file):\n            logger.debug('Last upload file %s found, reading results.', constants.last_upload_results_file)\n            with open(constants.last_upload_results_file, 'r') as handler:\n                return handler.read()\n        else:\n            logger.debug('Last upload file %s not found, cannot read results', constants.last_upload_results_file)\n            return False", "response": "Reads the last upload json file and returns the last upload json or False"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the JSON of diagnosis data on success None on failure.", "response": "def get_diagnosis(self, remediation_id=None):\n        '''\n            returns JSON of diagnosis data on success, None on failure\n            Optional arg remediation_id to get a particular remediation set.\n        '''\n        if self.config.offline:\n            logger.error('Cannot get diagnosis in offline mode.')\n            return None\n        return self.connection.get_diagnosis(remediation_id)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndeleting the cached branch_info file.", "response": "def delete_cached_branch_info(self):\n        '''\n            Deletes cached branch_info file\n        '''\n        if os.path.isfile(constants.cached_branch_info):\n            logger.debug('Deleting cached branch_info file...')\n            os.remove(constants.cached_branch_info)\n        else:\n            logger.debug('Cached branch_info file does not exist.')"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nclears the local registration for the current machine - id.", "response": "def clear_local_registration(self):\n        '''\n        Deletes dotfiles and machine-id for fresh registration\n        '''\n        delete_registered_file()\n        delete_unregistered_file()\n        write_to_disk(constants.machine_id_file, delete=True)\n        logger.debug('Re-register set, forcing registration.')\n        logger.debug('New machine-id: %s', generate_machine_id(new=True))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef col (loc,strg):\n    s = strg\n    return 1 if loc<len(s) and s[loc] == '\\n' else loc - s.rfind(\"\\n\", 0, loc)", "response": "Returns the current column within a string."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef downcaseTokens(s,l,t):\n    return [ tt.lower() for tt in map(_ustr,t) ]", "response": "Helper parse action to convert tokens to lower case."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef infixNotation( baseExpr, opList, lpar=Suppress('('), rpar=Suppress(')') ):\n    ret = Forward()\n    lastExpr = baseExpr | ( lpar + ret + rpar )\n    for i,operDef in enumerate(opList):\n        opExpr,arity,rightLeftAssoc,pa = (operDef + (None,))[:4]\n        termName = \"%s term\" % opExpr if arity < 3 else \"%s%s term\" % opExpr\n        if arity == 3:\n            if opExpr is None or len(opExpr) != 2:\n                raise ValueError(\"if numterms=3, opExpr must be a tuple or list of two expressions\")\n            opExpr1, opExpr2 = opExpr\n        thisExpr = Forward().setName(termName)\n        if rightLeftAssoc == opAssoc.LEFT:\n            if arity == 1:\n                matchExpr = FollowedBy(lastExpr + opExpr) + Group( lastExpr + OneOrMore( opExpr ) )\n            elif arity == 2:\n                if opExpr is not None:\n                    matchExpr = FollowedBy(lastExpr + opExpr + lastExpr) + Group( lastExpr + OneOrMore( opExpr + lastExpr ) )\n                else:\n                    matchExpr = FollowedBy(lastExpr+lastExpr) + Group( lastExpr + OneOrMore(lastExpr) )\n            elif arity == 3:\n                matchExpr = FollowedBy(lastExpr + opExpr1 + lastExpr + opExpr2 + lastExpr) + \\\n                            Group( lastExpr + opExpr1 + lastExpr + opExpr2 + lastExpr )\n            else:\n                raise ValueError(\"operator must be unary (1), binary (2), or ternary (3)\")\n        elif rightLeftAssoc == opAssoc.RIGHT:\n            if arity == 1:\n                # try to avoid LR with this extra test\n                if not isinstance(opExpr, Optional):\n                    opExpr = Optional(opExpr)\n                matchExpr = FollowedBy(opExpr.expr + thisExpr) + Group( opExpr + thisExpr )\n            elif arity == 2:\n                if opExpr is not None:\n                    matchExpr = FollowedBy(lastExpr + opExpr + thisExpr) + Group( lastExpr + OneOrMore( opExpr + thisExpr ) )\n                else:\n                    matchExpr = FollowedBy(lastExpr + thisExpr) + Group( lastExpr + OneOrMore( thisExpr ) )\n            elif arity == 3:\n                matchExpr = FollowedBy(lastExpr + opExpr1 + thisExpr + opExpr2 + thisExpr) + \\\n                            Group( lastExpr + opExpr1 + thisExpr + opExpr2 + thisExpr )\n            else:\n                raise ValueError(\"operator must be unary (1), binary (2), or ternary (3)\")\n        else:\n            raise ValueError(\"operator must indicate right or left associativity\")\n        if pa:\n            matchExpr.setParseAction( pa )\n        thisExpr <<= ( matchExpr.setName(termName) | lastExpr )\n        lastExpr = thisExpr\n    ret <<= lastExpr\n    return ret", "response": "This method creates a grammar for infixing the nested terms of the specified operators."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nenabling packrat parsing for the given locale.", "response": "def enablePackrat():\n        \"\"\"Enables \"packrat\" parsing, which adds memoizing to the parsing logic.\n           Repeated parse attempts at the same string location (which happens\n           often in many complex grammars) can immediately return a cached value,\n           instead of re-executing parsing/validating code.  Memoizing is done of\n           both valid results and parsing exceptions.\n\n           This speedup may break existing programs that use parse actions that\n           have side-effects.  For this reason, packrat parsing is disabled when\n           you first import pyparsing.  To activate the packrat feature, your\n           program must call the class method C{ParserElement.enablePackrat()}.  If\n           your program uses C{psyco} to \"compile as you go\", you must call\n           C{enablePackrat} before calling C{psyco.full()}.  If you do not do this,\n           Python will crash.  For best results, call C{enablePackrat()} immediately\n           after importing pyparsing.\n        \"\"\"\n        if not ParserElement._packratEnabled:\n            ParserElement._packratEnabled = True\n            ParserElement._parse = ParserElement._parseCache"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nclustering rule to compare ntp.conf files across a cluster ``shas`` is a Pandas DataFrame for the facts for each host by the fact ``ntp_sha256``. See https://pandas.pydata.org/pandas-docs/stable/api.html#dataframe for information on available attributes and methods. ``meta`` is a dictionary that contains the information from the cluster topology file provided by the ``-i`` switch. The dictionary keys are the sections, and the values are a list of the host information provided in the toplolgy file. Arguments: shas (pandas.DataFrame): Includes facts from ``ntp_sha256`` fact with column \"sha\" and one row per host in the cluster. meta (dict): Keys are the sections in the topology file and values are a list of the values in the section.", "response": "def report(shas, meta):\n    \"\"\"\n    Cluster rule to compare ntp.conf files across a cluster\n\n    ``shas`` is a Pandas DataFrame for the facts for each host\n    by the fact ``ntp_sha256``.  See\n    https://pandas.pydata.org/pandas-docs/stable/api.html#dataframe\n    for information on available attributes and methods.\n\n    ``meta`` is a dictionary that contains the information from the\n    cluster topology file provided by the ``-i`` switch.  The dictionary\n    keys are the sections, and the values are a list of the host\n    information provided in the toplolgy file.\n\n    Arguments:\n        shas (pandas.DataFrame): Includes facts from ``ntp_sha256``\n            fact with column \"sha\" and one row per host in the cluster.\n        meta (dict): Keys are the sections in the topology file and\n            values are a list of the values in the section.\n    \"\"\"\n    num_members = meta.num_members\n    uniq = shas.sha.unique()\n    if len(shas) != num_members or len(uniq) != 1:\n        return make_fail(\"DISTINCT_NTP_CONFS\", confs=len(uniq), nodes=num_members)\n\n    return make_pass(\"MATCHING_NTP_CONFS\", nodes=meta['nodes'], servers=meta['servers'])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsubstitute an obfuscated IP for each instance of a given IP in a given line.", "response": "def _sub_ip(self, line):\n        '''\n        This will substitute an obfuscated IP for each instance of a given IP in a file\n        This is called in the self._clean_line function, along with user _sub_* functions to scrub a given\n        line in a file.\n        It scans a given line and if an IP exists, it obfuscates the IP using _ip2db and returns the altered line\n        '''\n        try:\n            pattern = r\"(((\\b25[0-5]|\\b2[0-4][0-9]|\\b1[0-9][0-9]|\\b[1-9][0-9]|\\b[1-9]))(\\.(\\b25[0-5]|\\b2[0-4][0-9]|\\b1[0-9][0-9]|\\b[1-9][0-9]|\\b[0-9])){3})\"\n            ips = [each[0] for each in re.findall(pattern, line)]\n            if len(ips) > 0:\n                for ip in ips:\n                    new_ip = self._ip2db(ip)\n                    self.logger.debug(\"Obfuscating IP - %s > %s\", ip, new_ip)\n                    line = line.replace(ip, new_ip)\n            return line\n        except Exception as e: # pragma: no cover\n            self.logger.exception(e)\n            raise Exception('SubIPError: Unable to Substitute IP Address - %s', ip)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating the report for the obfuscated ip and hostname databases and output csv files", "response": "def _create_ip_report(self):\n        '''\n        this will take the obfuscated ip and hostname databases and output csv files\n        '''\n        try:\n            ip_report_name = os.path.join(self.report_dir, \"%s-ip.csv\" % self.session)\n            self.logger.con_out('Creating IP Report - %s', ip_report_name)\n            ip_report = open(ip_report_name, 'wt')\n            ip_report.write('Obfuscated IP,Original IP\\n')\n            for k,v in self.ip_db.items():\n                ip_report.write('%s,%s\\n' %(self._int2ip(k),self._int2ip(v)))\n            ip_report.close()\n            self.logger.info('Completed IP Report')\n\n            self.ip_report = ip_report_name\n        except Exception as e: # pragma: no cover\n            self.logger.exception(e)\n            raise Exception('CreateReport Error: Error Creating IP Report')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _sub_hostname(self, line):\n        '''\n        This will replace the exact hostname and all instances of the domain name with the obfuscated alternatives.\n        Example:\n        '''\n        try:\n            for od,d in self.dn_db.items():\n                #regex = re.compile(r'\\w*\\.%s' % d)\n                regex = re.compile(r'(?![\\W\\-\\:\\ \\.])[a-zA-Z0-9\\-\\_\\.]*\\.%s' % d)\n                hostnames = [each for each in regex.findall(line)]\n                if len(hostnames) > 0:\n                    for hn in hostnames:\n                        new_hn = self._hn2db(hn)\n                        self.logger.debug(\"Obfuscating FQDN - %s > %s\", hn, new_hn)\n                        line = line.replace(hn, new_hn)\n            if self.hostname:\n                line = line.replace(self.hostname, self._hn2db(self.hostname))  #catch any non-fqdn instances of the system hostname\n\n            return line\n        except Exception as e: # pragma: no cover\n            self.logger.exception(e)\n            raise Exception('SubHostnameError: Unable to Substitute Hostname/Domainname')", "response": "This will replace the exact hostname and all instances of the domain name with obfuscated alternatives."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate the destination environment for the current report", "response": "def _make_dest_env(self):\n        '''\n        This will create the folder in self.report_dir (defaults to /tmp) to store the sanitized files and populate it using shutil\n        These are the files that will be scrubbed\n        '''\n        try:\n            shutil.copytree(self.report, self.dir_path, symlinks=True, ignore=self._skip_file)\n\n        except Exception as e:    #pragma: no cover\n            self.logger.exception(e)\n            raise Exception(\"DestinationEnvironment Error: Cannot Create Destination Environment\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsubstituting keywords on a given line.", "response": "def _sub_keywords(self, line):\n        # this will substitute out any keyword entries on a given line\n        #try:\n        if self.kw_count > 0:    # we have obfuscated keywords to work with\n            for k in self.kw_db.keys():\n                if k in line:\n                    line = line.replace(k, self._kw2db(k))\n                    self.logger.debug(\"Obfuscating Keyword - %s > %s\", k, self._kw2db(k))\n\n        return line\n\n        '''except Exception, e: # pragma: no cover\n            self.logger.exception(e)\n            raise Exception('SubKeywordError: Unable to Substitute Keywords')'''"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding an IP address to the IP database and returns the obfuscated entry, or returns the existing obfuscated IP entry FORMAT: {$obfuscated_ip: $original_ip,}", "response": "def _ip2db(self, ip):\n        '''\n        adds an IP address to the IP database and returns the obfuscated entry, or returns the\n        existing obfuscated IP entry\n        FORMAT:\n        {$obfuscated_ip: $original_ip,}\n        '''\n\n        ip_num = self._ip2int(ip)\n        ip_found = False\n        db = self.ip_db\n        for k,v in db.items():\n            if v == ip_num:\n                ret_ip = self._int2ip(k)\n                ip_found = True\n        if ip_found:                #the entry already existed\n            return ret_ip\n        else:                       #the entry did not already exist\n            if len(self.ip_db) > 0:\n                new_ip = max(db.keys()) + 1\n            else:\n                new_ip = self._ip2int(self.start_ip)\n            db[new_ip] = ip_num\n\n            return self._int2ip(new_ip)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _walk_report(self, folder):\n        '''returns a dictonary of dictionaries in the format {directory_name:[file1,file2,filex]}'''\n\n        dir_list = {}\n        try:\n            for dirName, subdirList, fileList in os.walk(folder):\n                x = []\n                for fname in fileList:\n                    x.append(fname)\n                dir_list[dirName] = x\n\n            return dir_list\n        except Exception as e: # pragma: no cover\n            self.logger.exception(e)\n            raise Exception(\"WalkReport Error: Unable to Walk Report\")", "response": "returns a dictonary of dictionaries in the format directory_name : [ file1 file2 filex ]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _file_list(self, folder):\n        '''returns a list of file names in an sosreport directory'''\n        rtn = []\n        walk = self._walk_report(folder)\n        for key,val in walk.items():\n            for v in val:\n                x=os.path.join(key,v)\n                rtn.append(x)\n\n        self.file_count = len(rtn)  #a count of the files we'll have in the final cleaned sosreport, for reporting\n        return rtn", "response": "returns a list of file names in an sosreport directory"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _clean_line(self, l):\n        '''this will return a line with obfuscations for all possible variables, hostname, ip, etc.'''\n\n        new_line = self._sub_ip(l)                  # IP substitution\n        new_line = self._sub_hostname(new_line)     # Hostname substitution\n        new_line = self._sub_keywords(new_line)     # Keyword Substitution\n\n        return new_line", "response": "this will return a line with obfuscations for all possible variables hostname ip etc."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _clean_file(self, f):\n        '''this will take a given file path, scrub it accordingly, and save a new copy of the file\n        in the same location'''\n        if os.path.exists(f) and not os.path.islink(f):\n            tmp_file = tempfile.TemporaryFile(mode='w+b')\n            try:\n                fh = open(f, 'r')\n                data = fh.readlines()\n                fh.close()\n                if len(data) > 0: #if the file isn't empty:\n                    for l in data:\n                        new_l = self._clean_line(l)\n                        tmp_file.write(new_l.encode('utf-8'))\n\n                    tmp_file.seek(0)\n\n            except Exception as e: # pragma: no cover\n                self.logger.exception(e)\n                raise Exception(\"CleanFile Error: Cannot Open File For Reading - %s\" % f)\n\n            try:\n                if len(data) > 0:\n                    new_fh = open(f, 'wb')\n                    for line in tmp_file:\n                        new_fh.write(line)\n                    new_fh.close()\n            except Exception as e: # pragma: no cover\n                self.logger.exception(e)\n                raise Exception(\"CleanFile Error: Cannot Write to New File - %s\" % f)\n\n            finally:\n                tmp_file.close()", "response": "this will take a given file path scrub it accordingly and save a new copy of the file\n            in the same location"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds extra files to the origin path", "response": "def _add_extra_files(self, files):\n        '''if extra files are to be analyzed with an sosreport, this will add them to the origin path to be analyzed'''\n\n        try:\n            for f in files:\n                self.logger.con_out(\"adding additional file for analysis: %s\"  % f)\n                fname = os.path.basename(f)\n                f_new = os.path.join(self.dir_path, fname)\n                shutil.copyfile(f,f_new)\n        except IOError as e:\n            self.logger.con_out(\"ExtraFileError: %s is not readable or does not exist. Skipping File\" % f)\n            self.logger.exception(e)\n            pass\n        except Exception as e:    # pragma: no cover\n            self.logger.exception(e)\n            raise Exception(\"ExtraFileError: Unable to Process Extra File - %s\" % f)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _clean_files_only(self, files):\n        ''' if a user only wants to process one or more specific files, instead of a full sosreport '''\n        try:\n            if not (os.path.exists(self.origin_path)):\n                self.logger.info(\"Creating Origin Path - %s\" % self.origin_path)\n                os.makedirs(self.origin_path) # create the origin_path directory\n            if not (os.path.exists(self.dir_path)):\n                self.logger.info(\"Creating Directory Path - %s\" % self.dir_path)\n                os.makedirs(self.dir_path)    # create the dir_path directory\n            self._add_extra_files(files)\n\n        except OSError as e: # pragma: no cover\n            if e.errno == errno.EEXIST:\n                pass\n            else:   # pragma: no cover\n                self.logger.exception(e)\n                raise e\n\n        except Exception as e:    # pragma: no cover\n            self.logger.exception(e)\n            raise Exception(\"CleanFilesOnlyError: unable to process\")", "response": "if a user wants to process one or more specific files instead of a full sosreport"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef clean_report(self, options, sosreport): # pragma: no cover\n        '''this is the primary function, to put everything together and analyze an sosreport'''\n\n        if options.report_dir: # override the default location for artifacts (/tmp)\n            if os.path.isdir(options.report_dir):\n                self.report_dir = options.report_dir\n        self.origin_path, self.dir_path, self.session, self.logfile, self.uuid = self._prep_environment()\n        self._start_logging(self.logfile)\n        self._get_disclaimer()\n        if options.domains:\n            self.domains = options.domains\n        if options.keywords:\n            self.keywords = options.keywords\n            self._keywords2db()\n        if not sosreport:\n            if not options.files:\n                raise Exception(\"Error: You must supply either an sosreport and/or files to process\")\n\n            self.logger.con_out(\"No sosreport supplied. Only processing specific files\")\n            self._clean_files_only(options.files)\n\n        else:   # we DO have an sosreport to analyze\n            self.report = self._extract_sosreport(sosreport)\n            self._make_dest_env()   # create the working directory\n            if options.hostname_path:\n                self.hostname, self.domainname = self._get_hostname(options.hostname_path)\n            else:\n                self.hostname, self.domainname = self._get_hostname()\n\n            if options.files:\n                self._add_extra_files(options.files)\n\n            if self.hostname:   # if we have a hostname that's not a None type\n                self.hn_db['host0'] = self.hostname     # we'll prime the hostname pump to clear out a ton of useless logic later\n\n            self._process_hosts_file()  # we'll take a dig through the hosts file and make sure it is as scrubbed as possible\n\n        self._domains2db()\n        files = self._file_list(self.dir_path)\n        self.logger.con_out(\"IP Obfuscation Start Address - %s\", self.start_ip)\n        self.logger.con_out(\"*** SOSCleaner Processing ***\")\n        self.logger.info(\"Working Directory - %s\", self.dir_path)\n        for f in files:\n            self.logger.debug(\"Cleaning %s\", f)\n            self._clean_file(f)\n        self.logger.con_out(\"*** SOSCleaner Statistics ***\")\n        self.logger.con_out(\"IP Addresses Obfuscated - %s\", len(self.ip_db))\n        self.logger.con_out(\"Hostnames Obfuscated - %s\" , len(self.hn_db))\n        self.logger.con_out(\"Domains Obfuscated - %s\" , len(self.dn_db))\n        self.logger.con_out(\"Total Files Analyzed - %s\", self.file_count)\n        self.logger.con_out(\"*** SOSCleaner Artifacts ***\")\n        self._create_reports()\n        self._create_archive()\n\n        return_data = [self.archive_path, self.logfile, self.ip_report]\n        if self.hostname:\n            return_data.append(self.hn_report)\n        if len(self.dn_db) >= 1:\n            return_data.append(self.dn_report)\n\n        return return_data", "response": "this is the primary function to put everything together and analyze an sosreport"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses the content of the log file into a list of dictionaries for each row.", "response": "def parse_content(self, content):\n        \"\"\"\n        Parse the lines given into a list of dictionaries for each row.  This\n        is stored in the ``rows`` attribute.\n\n        If the ``key_field`` property is set, use this to key a ``data``\n        dictionary attribute.\n        \"\"\"\n        self.rows = []\n        if len(content) < 2:\n            self.no_data = True\n            return\n\n        # Parse header, remembering column numbers for data capture.  We use\n        # a finditer to get the positions, and we find by field rather than\n        # splitting on three or more spaces because of this.\n        headers = []\n        field_re = re.compile(r'\\w+(\\s\\w+)*')\n        for match in field_re.finditer(content[0]):\n            headers.append({'name': match.group(), 'start': match.start()})\n\n        # Parse the rest of the line.  Each field starts at the column\n        # given by the header and ends with at least three spaces.\n        for line in content[1:]:\n            # I think the dictionary comprehension version of this is too\n            # complicated for words :-)\n            row = {}\n            for header in headers:\n                value = line[header['start']:].split('   ', 1)[0]\n                if value == '':\n                    value = None\n                row[header['name']] = value\n            self.rows.append(row)\n\n        # If we have a key_field set, construct a data dictionary on it.\n        # Note that duplicates will be overwritten, but we ignore '<none>'.\n        if self.key_field and self.key_field in self.rows[0]:\n            self.data = {}\n            for row in self.rows:\n                k = row[self.key_field]\n                if k is not None and k != '<none>':\n                    self.data[k] = row"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef summarize_address_range(first, last):\n    if (not (isinstance(first, _BaseAddress) and\n             isinstance(last, _BaseAddress))):\n        raise TypeError('first and last must be IP addresses, not networks')\n    if first.version != last.version:\n        raise TypeError(\"%s and %s are not of the same version\" %\n                        (first, last))\n    if first > last:\n        raise ValueError('last IP address must be greater than first')\n\n    if first.version == 4:\n        ip = IPv4Network\n    elif first.version == 6:\n        ip = IPv6Network\n    else:\n        raise ValueError('unknown IP version')\n\n    ip_bits = first._max_prefixlen\n    first_int = first._ip\n    last_int = last._ip\n    while first_int <= last_int:\n        nbits = min(_count_righthand_zero_bits(first_int, ip_bits),\n                    _compat_bit_length(last_int - first_int + 1) - 1)\n        net = ip('%s/%d' % (first, ip_bits - nbits))\n        yield net\n        first_int += 1 << nbits\n        if first_int - 1 == ip._ALL_ONES:\n            break\n        first = first.__class__(first_int)", "response": "Summarize a network range given the first and last IP addresses."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _ip_int_from_prefix(self, prefixlen=None):\n        if prefixlen is None:\n            prefixlen = self._prefixlen\n        return self._ALL_ONES ^ (self._ALL_ONES >> prefixlen)", "response": "Turn the netmask into an integer for comparison."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nturns a prefix length into a dotted decimal string.", "response": "def _ip_string_from_prefix(self, prefixlen=None):\n        \"\"\"Turn a prefix length into a dotted decimal string.\n\n        Args:\n            prefixlen: An integer, the netmask prefix length.\n\n        Returns:\n            A string, the dotted decimal netmask string.\n\n        \"\"\"\n        if not prefixlen:\n            prefixlen = self._prefixlen\n        return self._string_from_ip_int(self._ip_int_from_prefix(prefixlen))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _ip_int_from_string(self, ip_str):\n        if not ip_str:\n            raise AddressValueError('Address cannot be empty')\n\n        octets = ip_str.split('.')\n        if len(octets) != 4:\n            raise AddressValueError(\"Expected 4 octets in %r\" % ip_str)\n\n        try:\n            bvs = map(self._parse_octet, octets)\n            return _compat_int_from_byte_vals(bvs, 'big')\n        except ValueError as exc:\n            raise AddressValueError(\"%s in %r\" % (exc, ip_str))", "response": "Turn the given string into an integer for comparison."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntest if this address is allocated for private networks.", "response": "def is_private(self):\n        \"\"\"Test if this address is allocated for private networks.\n\n        Returns:\n            A boolean, True if the address is reserved per RFC 1918.\n\n        \"\"\"\n        private_10 = IPv4Network('10.0.0.0/8')\n        private_172 = IPv4Network('172.16.0.0/12')\n        private_192 = IPv4Network('192.168.0.0/16')\n        return (self in private_10 or\n                self in private_172 or\n                self in private_192)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntesting if the address is otherwise IETF reserved.", "response": "def is_reserved(self):\n        \"\"\"Test if the address is otherwise IETF reserved.\n\n        Returns:\n            A boolean, True if the address is within one of the\n            reserved IPv6 Network ranges.\n\n        \"\"\"\n        reserved_nets = [IPv6Network('::/8'), IPv6Network('100::/8'),\n                         IPv6Network('200::/7'), IPv6Network('400::/6'),\n                         IPv6Network('800::/5'), IPv6Network('1000::/4'),\n                         IPv6Network('4000::/3'), IPv6Network('6000::/3'),\n                         IPv6Network('8000::/3'), IPv6Network('A000::/3'),\n                         IPv6Network('C000::/3'), IPv6Network('E000::/4'),\n                         IPv6Network('F000::/5'), IPv6Network('F800::/6'),\n                         IPv6Network('FE00::/9')]\n\n        return any(self in x for x in reserved_nets)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _is_valid_netmask(self, prefixlen):\n        try:\n            prefixlen = int(prefixlen)\n        except ValueError:\n            return False\n        return 0 <= prefixlen <= self._max_prefixlen", "response": "Verify that the netmask is a valid IPv6 netmask."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef check_output(self, cmd, timeout=None, keep_rc=False, env=None):\n        return subproc.call(cmd, timeout=timeout or self.timeout,\n                keep_rc=keep_rc, env=env)", "response": "Calls a command and returns the output of the command."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a textual description of the contents of the passed in filename or None if the file is not found.", "response": "def file(self, filename):\n        \"\"\"\n        Returns a textual description of the contents of the argument passed\n        as a filename or None if an error occurred and the MAGIC_ERROR flag\n        is set.  A call to errno() will return the numeric error code.\n        \"\"\"\n        try:  # attempt python3 approach first\n            if isinstance(filename, bytes):\n                bi = filename\n            else:\n                bi = bytes(filename, 'utf-8')\n            return str(_file(self._magic_t, bi), 'utf-8')\n        except:\n            return _file(self._magic_t, filename.encode('utf-8'))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef buffer(self, buf):\n        try:  # attempt python3 approach first\n            return str(_buffer(self._magic_t, buf, len(buf)), 'utf-8')\n        except:\n            return _buffer(self._magic_t, buf, len(buf))", "response": "Returns a textual description of the contents of the passed in buffer or None if an error occurred."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating the archive dir", "response": "def create_archive_dir(self):\n        \"\"\"\n        Create the archive dir\n        \"\"\"\n        archive_dir = os.path.join(self.tmp_dir, self.archive_name)\n        os.makedirs(archive_dir, 0o700)\n        return archive_dir"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_command_dir(self):\n        cmd_dir = os.path.join(self.archive_dir, \"insights_commands\")\n        os.makedirs(cmd_dir, 0o700)\n        return cmd_dir", "response": "Create the command directory"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_full_archive_path(self, path):\n        return os.path.join(self.archive_dir, path.lstrip('/'))", "response": "Returns the full archive path for the given path."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncopy a single file to the archive.", "response": "def _copy_file(self, path):\n        \"\"\"\n        Copy just a single file\n        \"\"\"\n        full_path = self.get_full_archive_path(path)\n        # Try to make the dir, eat exception if it fails\n        try:\n            os.makedirs(os.path.dirname(full_path))\n        except OSError:\n            pass\n        logger.debug(\"Copying %s to %s\", path, full_path)\n        shutil.copyfile(path, full_path)\n        return path"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncopies a single file or regex to a directory", "response": "def copy_file(self, path):\n        \"\"\"\n        Copy a single file or regex, creating the necessary directories\n        \"\"\"\n        if \"*\" in path:\n            paths = _expand_paths(path)\n            if paths:\n                for path in paths:\n                    self._copy_file(path)\n        else:\n            if os.path.isfile(path):\n                return self._copy_file(path)\n            else:\n                logger.debug(\"File %s does not exist\", path)\n                return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating tar file to be compressed", "response": "def create_tar_file(self, full_archive=False):\n        \"\"\"\n        Create tar file to be compressed\n        \"\"\"\n        tar_file_name = os.path.join(self.archive_tmp_dir, self.archive_name)\n        ext = \"\" if self.compressor == \"none\" else \".%s\" % self.compressor\n        tar_file_name = tar_file_name + \".tar\" + ext\n        logger.debug(\"Tar File: \" + tar_file_name)\n        subprocess.call(shlex.split(\"tar c%sfS %s -C %s .\" % (\n            self.get_compression_flag(self.compressor),\n            tar_file_name,\n            # for the docker \"uber archive,\"use archive_dir\n            #   rather than tmp_dir for all the files we tar,\n            #   because all the individual archives are in there\n            self.tmp_dir if not full_archive else self.archive_dir)),\n            stderr=subprocess.PIPE)\n        self.delete_archive_dir()\n        logger.debug(\"Tar File Size: %s\", str(os.path.getsize(tar_file_name)))\n        return tar_file_name"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete_tmp_dir(self):\n        logger.debug(\"Deleting: \" + self.tmp_dir)\n        shutil.rmtree(self.tmp_dir, True)", "response": "Delete the entire tmp dir"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndeletes the entire archive dir", "response": "def delete_archive_dir(self):\n        \"\"\"\n        Delete the entire archive dir\n        \"\"\"\n        logger.debug(\"Deleting: \" + self.archive_dir)\n        shutil.rmtree(self.archive_dir, True)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndelete the temporary directory containing the constructed archive", "response": "def delete_archive_file(self):\n        \"\"\"\n        Delete the directory containing the constructed archive\n        \"\"\"\n        logger.debug(\"Deleting %s\", self.archive_tmp_dir)\n        shutil.rmtree(self.archive_tmp_dir, True)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_to_archive(self, spec):\n        '''\n        Add files and commands to archive\n        Use InsightsSpec.get_output() to get data\n        '''\n        if isinstance(spec, InsightsCommand):\n            archive_path = os.path.join(self.cmd_dir, spec.archive_path.lstrip('/'))\n        if isinstance(spec, InsightsFile):\n            archive_path = self.get_full_archive_path(spec.archive_path.lstrip('/'))\n        output = spec.get_output()\n        if output:\n            write_data_to_file(output, archive_path)", "response": "Add files and commands to archive\n        Use InsightsSpec. get_output to get data\n       "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_metadata_to_archive(self, metadata, meta_path):\n        '''\n        Add metadata to archive\n        '''\n        archive_path = self.get_full_archive_path(meta_path.lstrip('/'))\n        write_data_to_file(metadata, archive_path)", "response": "Add metadata to archive"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(self, url, params={}, headers={}, auth=(), certificate_path=None):\n\n        certificate_path = certificate_path if certificate_path else False\n        return self.session.get(url, params=params, headers=headers, verify=certificate_path, auth=auth,\n                            timeout=self.timeout)", "response": "Returns the response payload from the request to the given URL."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update_headers(self, response):\n        if 'expires' in response.headers and 'cache-control' in response.headers:\n            self.msg = self.server_cache_headers\n            return response.headers\n        else:\n            self.msg = self.default_cache_vars\n            date = parsedate(response.headers['date'])\n            expires = datetime(*date[:6]) + timedelta(0, self.expire_after)\n            response.headers.update({'expires': formatdate(calendar.timegm(expires.timetuple())),\n                                'cache-control': 'public'})\n            return response.headers", "response": "Updates the HTTP response headers with the updated caching headers."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_dmidecode(dmidecode_content, pythonic_keys=False):\n    if len(dmidecode_content) < 3:\n        return {}\n\n    section = None\n    obj = {}\n    current = {}\n\n    buf = \"\\n\".join(dmidecode_content).strip()\n\n    # Some versions of DMIDecode have an extra\n    # level of indentation, as well as slightly\n    # different configuration for each section.\n    if \"\\tDMI type\" in buf:\n        pat = re.compile(\"^\\t\", flags=re.MULTILINE)\n        buf = pat.sub(\"\", buf)\n\n        buf = buf.replace(\"\\nDMI type\", \"DMI type\")\n        buf = buf.replace(\"\\nHandle\", \"\\n\\nHandle\")\n\n    buf = buf.replace(\"\\n\\t\\t\", \"\\t\")\n\n    def fix_key(k):\n        return k.lower().replace(\" \", \"_\") if pythonic_keys else k\n\n    for line in buf.splitlines():\n        nbline = line.strip()\n        if section:\n            if not nbline:\n                # There maybe some sections with the same name, such as:\n                # processor_information\n                if section in obj:\n                    obj[section].append(current)\n                else:\n                    obj[section] = [current]\n                current = {}\n                section = key = None\n                continue\n\n            elif line.startswith(\"\\t\"):\n                if \":\" in line:\n                    key, value = nbline.split(\":\", 1)\n                    key = fix_key(key)\n                    value = value.strip()\n\n                if \"\\t\" in value:\n                    current[key] = list(filter(None, value.split(\"\\t\")))\n                else:\n                    current[key] = value\n            else:\n                section = None\n\n        if not section:\n            # Ignore 'Table at 0xBFFCB000' and similar.\n            if not ('Table' in nbline or 'table' in nbline):\n                section = fix_key(nbline)\n\n    if section in obj:\n        obj[section].append(current)\n    else:\n        obj[section] = [current]\n\n    return obj", "response": "Parses a dmidecode list into a dictionary of dmidecode information."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfunction to parse the output of rhn - schema - version", "response": "def rhn_schema_version(context):\n    \"\"\"\n    Function to parse the output of command ``/usr/bin/rhn-schema-version``.\n\n    Sample input::\n\n        5.6.0.10-2.el6sat\n\n    Examples:\n        >>> db_ver = shared[rhn_schema_version]\n        >>> db_ver\n        '5.6.0.10-2.el6sat'\n\n    \"\"\"\n    if context.content:\n        content = context.content\n        if len(content) == 1 and 'No such' not in content[0]:\n            ver = content[0].strip()\n            if ver:\n                return ver"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef hostname(hn, ft, si):\n\n    if not hn or not hn.fqdn:\n        hn = ft\n\n    if hn and hn.fqdn:\n        fqdn = hn.fqdn\n        hostname = hn.hostname if hn.hostname else fqdn.split(\".\")[0]\n        domain = hn.domain if hn.domain else \".\".join(fqdn.split(\".\")[1:])\n        return Hostname(fqdn, hostname, domain)\n    else:\n        fqdn = si.get(\"profile_name\") if si else None\n        if fqdn:\n            hostname = fqdn.split(\".\")[0]\n            domain = \".\".join(fqdn.split(\".\")[1:])\n            return Hostname(fqdn, hostname, domain)\n\n    raise Exception(\"Unable to get hostname.\")", "response": "Check hostname facter and systemid to get the fqdn hostname and domain components."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntake an open file or a list of lines and returns a ConfigParser object.", "response": "def parse_doc(f, ctx=None, overwrite=False):\n    \"\"\" Accepts an open file or a list of lines. \"\"\"\n    lg = LineGetter(f, comment_marker=(\"#\", \";\"), strip=False)\n    cfg = ConfigParser(ctx).parse_doc(lg)\n    set_defaults(cfg)\n    if overwrite:\n        squash(cfg)\n    return cfg"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\npads out the package and kernel release versions so that they are correct.", "response": "def pad_release(release_to_pad, num_sections=4):\n    '''\n    Pad out package and kernel release versions so that\n    ``LooseVersion`` comparisons will be correct.\n\n    Release versions with less than num_sections will\n    be padded in front of the last section with zeros.\n\n    For example ::\n\n        pad_release(\"390.el6\", 4)\n\n    will return ``390.0.0.el6`` and ::\n\n        pad_release(\"390.11.el6\", 4)\n\n    will return ``390.11.0.el6``.\n\n    If the number of sections of the release to be padded is\n    greater than num_sections, a ``ValueError`` will be raised.\n    '''\n    parts = release_to_pad.split('.')\n\n    if len(parts) > num_sections:\n        raise ValueError(\"Too many sections encountered ({found} > {num} in release string {rel}\".format(\n            found=len(parts), num=num_sections, rel=release_to_pad\n        ))\n\n    pad_count = num_sections - len(parts)\n    return \".\".join(parts[:-1] + ['0'] * pad_count + parts[-1:])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing the output of the alternatives command.", "response": "def parse_content(self, content):\n        \"\"\"\n        Parse the output of the ``alternatives`` command.\n        \"\"\"\n        self.program = None\n        self.status = None\n        self.link = None\n        self.best = None\n        self.paths = []\n        current_path = None\n        # Set up instance variable\n\n        for line in content:\n            words = line.split(None)\n            if ' - status is' in line:\n                # alternatives only displays one program, so finding\n                # this line again is an error.\n                if self.program:\n                    raise ParseException(\n                        \"Program line for {newprog} found in output for {oldprog}\".format(\n                            newprog=words[0], oldprog=self.program\n                        )\n                    )\n                # Set up new program data\n                self.program = words[0]\n                self.status = words[4][:-1]  # remove trailing .\n                self.alternatives = []\n                current_path = {}\n            elif not self.program:\n                # Lines before 'status is' line are ignored\n                continue\n            elif line.startswith(' link currently points to ') and len(words) == 5:\n                # line: ' link currently points to /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.111-1.b15.el7_2.x86_64/jre/bin/java'\n                self.link = words[4]\n            elif ' - priority ' in line and len(words) == 4 and words[3].isdigit():\n                # line: /usr/lib/jvm/jre-1.6.0-ibm.x86_64/bin/java - priority 16091\n                # New path - save current path if set\n                self.paths.append({\n                    'path': words[0],\n                    'priority': int(words[3]),\n                    'slave': {},\n                })\n                current_path = self.paths[-1]\n            elif line.startswith(' slave ') and len(words) == 3 and current_path:\n                # line: ' slave ControlPanel: /usr/lib/jvm/jre-1.6.0-ibm.x86_64/bin/ControlPanel'\n                current_path['slave'][words[1][:-1]] = words[2]  # remove final : from program\n            elif line.startswith(\"Current `best' version is \") and len(words) == 5:\n                # line: 'Current `best' version is /usr/lib/jvm/jre-1.6.0-ibm.x86_64/bin/java.'\n                self.best = words[4][:-1]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef validate_lines(results, bad_lines):\n\n        if results and len(results) == 1:\n            first = results[0]\n            if any(l in first.lower() for l in bad_lines):\n                return False\n        return True", "response": "Validate the results string of the command - get - n - t - i - a - z"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_content(self, content):\n        self.dom = self.xmlns = None\n        self.data = {}\n        # ignore empty xml file\n        if len(content) > 3:\n            self.raw = '\\n'.join(content)\n            self.dom = ET.fromstring(self.raw)\n            self.xmlns = self.dom.tag.strip(\"{\").split(\"}\")[0] if all(c in self.dom.tag for c in [\"{\", \"}\"]) else \"\"\n            self.data = self.parse_dom()", "response": "This function will parse the content of the XML file and set the attributes of the object to the attributes of the object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_elements(self, element, xmlns=None):\n        real_element = \"\"\n        real_xmlns = \"\"\n\n        if xmlns is None:\n            real_xmlns = \"{\" + self.xmlns + \"}\" if self.xmlns else \"\"\n        else:\n            real_xmlns = \"{\" + xmlns + \"}\"\n\n        while \"/\" in element:\n            l = element.split(\"/\", 1)\n            element = l[1]\n            real_element += l[0] + \"/\"\n            if element[0].isalpha() or element[0] == \"_\":\n                real_element += real_xmlns\n\n        real_element += element\n        return self.dom.findall(real_element)", "response": "Returns a list of elements that match the search condition."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nregisters a scanner function that will be called once per - entry for the content of the class.", "response": "def _scan(cls, result_key, scanner):\n        \"\"\"\n        Registers a `scanner` which is a function that will be called once per\n        logical line in a document. A scanners job is to evaluate the content\n        of the line and set a so-called `result_key` on the class to be\n        retrieved later by a rule.\n        \"\"\"\n\n        if result_key in cls.scanner_keys:\n            raise ValueError(\"'%s' is already a registered scanner key\" % result_key)\n\n        cls.scanners.append(scanner)\n        cls.scanner_keys.add(result_key)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef any(cls, result_key, func):\n        def scanner(self, obj):\n            current_value = getattr(self, result_key, None)\n            setattr(self, result_key, current_value or func(obj))\n\n        cls._scan(result_key, scanner)", "response": "Sets the result_key to the output of func if ever returns\n           "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the result_key to an iterable of objects for which func returns True", "response": "def collect(cls, result_key, func):\n        \"\"\"\n        Sets the `result_key` to an iterable of objects for which `func(obj)`\n        returns True\n        \"\"\"\n        def scanner(self, obj):\n            if not getattr(self, result_key, None):\n                setattr(self, result_key, [])\n            rv = func(obj)\n            if rv:\n                getattr(self, result_key).append(rv)\n\n        cls._scan(result_key, scanner)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses the log file content.", "response": "def parse_content(self, content):\n        \"\"\"\n        Use all the defined scanners to search the log file, setting the\n        properties defined in the scanner.\n        \"\"\"\n        self.lines = content\n        for scanner in self.scanners:\n            scanner(self)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _valid_search(self, s):\n        if isinstance(s, six.string_types):\n            return lambda l: s in l\n        elif (isinstance(s, list) and len(s) > 0 and\n              all(isinstance(w, six.string_types) for w in s)):\n            return lambda l: all(w in l for w in s)\n        elif s is not None:\n            raise TypeError('Search items must be given as a string or a list of strings')", "response": "Check this given s is a string or a list of strings."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns all lines that contain s anywhere and wrap them in a list of dicts.", "response": "def get(self, s):\n        \"\"\"\n        Returns all lines that contain `s` anywhere and wrap them in a list of\n        dictionaries.  `s` can be either a single string or a string list. For\n        list, all keywords in the list must be found in each line.\n\n        Parameters:\n            s(str or list): one or more strings to search for.\n\n        Returns:\n            (list): list of dictionaries corresponding to the parsed lines\n            contain the `s`.\n        \"\"\"\n        ret = []\n        search_by_expression = self._valid_search(s)\n        for l in self.lines:\n            if search_by_expression(l):\n                ret.append(self._parse_line(l))\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndefines computed fields based on a string to grep for.", "response": "def scan(cls, result_key, func):\n        \"\"\"\n        Define computed fields based on a string to \"grep for\".  This is\n        preferred to utilizing raw log lines in plugins because computed fields\n        will be serialized, whereas raw log lines will not.\n        \"\"\"\n\n        if result_key in cls.scanner_keys:\n            raise ValueError(\"'%s' is already a registered scanner key\" % result_key)\n\n        def scanner(self):\n            result = func(self)\n            setattr(self, result_key, result)\n\n        cls.scanners.append(scanner)\n        cls.scanner_keys.add(result_key)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a property that is set to true if the given token is found in the log file.", "response": "def token_scan(cls, result_key, token):\n        \"\"\"\n        Define a property that is set to true if the given token is found in\n        the log file.  Uses the __contains__ method of the log file.\n        \"\"\"\n        def _scan(self):\n            return token in self\n\n        cls.scan(result_key, _scan)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef keep_scan(cls, result_key, token):\n        def _scan(self):\n            return self.get(token)\n\n        cls.scan(result_key, _scan)", "response": "Keeps the list of lines that contain the given token."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_after(self, timestamp, s=None):\n        time_format = self.time_format\n\n        # Annoyingly, strptime insists that it get the whole time string and\n        # nothing but the time string.  However, for most logs we only have a\n        # string with the timestamp in it.  We can't just catch the ValueError\n        # because at that point we do not actually have a valid datetime\n        # object.  So we convert the time format string to a regex, use that\n        # to find just the timestamp, and then use strptime on that.  Thanks,\n        # Python.  All these need to cope with different languages and\n        # character sets.  Note that we don't include time zone or other\n        # outputs (e.g. day-of-year) that don't usually occur in time stamps.\n        format_conversion_for = {\n            'a': r'\\w{3}', 'A': r'\\w+',  # Week day name\n            'w': r'[0123456]',  # Week day number\n            'd': r'([0 ][123456789]|[12]\\d|3[01])',  # Day of month\n            'b': r'\\w{3}', 'B': r'\\w+',  # Month name\n            'm': r'([0 ]\\d|1[012])',  # Month number\n            'y': r'\\d{2}', 'Y': r'\\d{4}',  # Year\n            'H': r'([01 ]\\d|2[0123])',  # Hour - 24 hour format\n            'I': r'([0 ]?\\d|1[012])',  # Hour - 12 hour format\n            'p': r'\\w{2}',  # AM / PM\n            'M': r'([012345]\\d)',  # Minutes\n            'S': r'([012345]\\d|60)',  # Seconds, including leap second\n            'f': r'\\d{6}',  # Microseconds\n        }\n\n        # Construct the regex from the time string\n        timefmt_re = re.compile(r'%(\\w)')\n\n        def replacer(match):\n            if match.group(1) in format_conversion_for:\n                return format_conversion_for[match.group(1)]\n            else:\n                raise ParseException(\n                    \"get_after does not understand strptime format '{c}'\".format(\n                        c=match.group(0)\n                    )\n                )\n\n        # Please do not attempt to be tricky and put a regular expression\n        # inside your time format, as we are going to also use it in\n        # strptime too and that may not work out so well.\n\n        # Check time_format - must be string or list.  Set the 'logs_have_year'\n        # flag and timestamp parser function appropriately.\n        # Grab values of dict as a list first\n        if isinstance(time_format, dict):\n            time_format = list(time_format.values())\n        if isinstance(time_format, six.string_types):\n            logs_have_year = ('%Y' in time_format or '%y' in time_format)\n            time_re = re.compile('(' + timefmt_re.sub(replacer, time_format) + ')')\n\n            # Curry strptime with time_format string.\n            def test_parser(logstamp):\n                return datetime.datetime.strptime(logstamp, time_format)\n            parse_fn = test_parser\n        elif isinstance(time_format, list):\n            logs_have_year = all('%Y' in tf or '%y' in tf for tf in time_format)\n            time_re = re.compile('(' + '|'.join(\n                timefmt_re.sub(replacer, tf) for tf in time_format\n            ) + ')')\n\n            def test_all_parsers(logstamp):\n                # One of these must match, because the regex has selected only\n                # strings that will match.\n                for tf in time_format:\n                    try:\n                        ts = datetime.datetime.strptime(logstamp, tf)\n                    except ValueError:\n                        pass\n                return ts\n            parse_fn = test_all_parsers\n        else:\n            raise ParseException(\n                \"get_after does not recognise time formats of type {t}\".format(\n                    t=type(time_format)\n                )\n            )\n\n        # Most logs will appear in string format, but some logs (e.g.\n        # Messages) are available in list-of-dicts format.  So we choose one\n        # of two 'date_compare' functions.  HOWEVER: we still have to check\n        # the string found for a valid date, because log parsing often fails.\n        # Because of generators, we check this per line\n\n        # Now try to find the time stamp in each log line and add lines to\n        # our output if they are currently being included in the log.\n\n        eleven_months = datetime.timedelta(days=330)\n        including_lines = False\n        search_by_expression = self._valid_search(s)\n        for line in self.lines:\n            # If `s` is not None, keywords must be found in the line\n            if s and not search_by_expression(line):\n                continue\n            # Otherwise, search all lines\n            match = time_re.search(line)\n            if match:\n                logstamp = parse_fn(match.group(0))\n                if not logs_have_year:\n                    # Substitute timestamp year for logstamp year\n                    logstamp = logstamp.replace(year=timestamp.year)\n                    if logstamp - timestamp > eleven_months:\n                        # If timestamp in January and log in December, move\n                        # log to previous year\n                        logstamp = logstamp.replace(year=timestamp.year - 1)\n                    elif timestamp - logstamp > eleven_months:\n                        # If timestamp in December and log in January, move\n                        # log to next year\n                        logstamp = logstamp.replace(year=timestamp.year + 1)\n                if logstamp >= timestamp:\n                    # Later - include\n                    including_lines = True\n                    yield self._parse_line(line)\n                else:\n                    # Earlier - start excluding\n                    including_lines = False\n            else:\n                # If we're including lines, add this continuation line\n                if including_lines:\n                    yield self._parse_line(line)", "response": "This method returns all the available log entries that are after the given timestamp."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses a single line of log output into a dict.", "response": "def _parse_line(self, line):\n        \"\"\"\n        Parsed result::\n\n            {'timestamp':'May 18 14:24:14',\n             'procname': 'kernel',\n             'hostname':'lxc-rhel68-sat56',\n             'message': '...',\n             'raw_message': '...: ...'\n            }\n        \"\"\"\n        msg_info = {'raw_message': line}\n        if ': ' in line:\n            info, msg = [i.strip() for i in line.split(': ', 1)]\n            msg_info['message'] = msg\n\n            info_splits = info.split()\n            if len(info_splits) == 5:\n                msg_info['timestamp'] = ' '.join(info_splits[:3])\n                msg_info['hostname'] = info_splits[3]\n                msg_info['procname'] = info_splits[4]\n        return msg_info"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses the content of the config file.", "response": "def parse_content(self, content, allow_no_value=False):\n        \"\"\"Parses content of the config file.\n\n        In child class overload and call super to set flag\n        ``allow_no_values`` and allow keys with no value in\n        config file::\n\n            def parse_content(self, content):\n                super(YourClass, self).parse_content(content,\n                                                     allow_no_values=True)\n        \"\"\"\n        super(IniConfigFile, self).parse_content(content)\n        config = RawConfigParser(allow_no_value=allow_no_value)\n        fp = io.StringIO(u\"\\n\".join(content))\n        config.readfp(fp, filename=self.file_name)\n        self.data = config"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_content(self, content):\n        self.listings = ls_parser.parse(content, self.first_path)\n\n        # No longer need the first path found, if any.\n        delattr(self, 'first_path')", "response": "Parse the content of a log file into a list of lists."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the entry name for a given path.", "response": "def path_entry(self, path):\n        \"\"\"\n        The parsed data given a path, which is separated into its directory\n        and entry name.\n        \"\"\"\n        if path[0] != '/':\n            return None\n        path_parts = path.split('/')\n        # Note that here the first element will be '' because it's before the\n        # first separator.  That's OK, the join puts it back together.\n        directory = '/'.join(path_parts[:-1])\n        name = path_parts[-1]\n        if directory not in self.listings:\n            return None\n        if name not in self.listings[directory]['entries']:\n            return None\n        return self.listings[directory]['entries'][name]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndecomposing a compound name into a registry repo and tag tuple.", "response": "def _decompose(compound_name):\n    \"\"\" '[reg/]repo[:tag]' -> (reg, repo, tag) \"\"\"\n    reg, repo, tag = '', compound_name, ''\n    if '/' in repo:\n        reg, repo = repo.split('/', 1)\n    if ':' in repo:\n        repo, tag = repo.rsplit(':', 1)\n    return reg, repo, tag"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef image_by_name(img_name, images=None):\n    i_reg, i_rep, i_tag = _decompose(img_name)\n\n    # Correct for bash-style matching expressions.\n    if not i_reg:\n        i_reg = '*'\n    if not i_tag:\n        i_tag = '*'\n\n    # If the images were not passed in, go get them.\n    if images is None:\n        c = docker.Client(**kwargs_from_env())\n        images = c.images(all=False)\n\n    valid_images = []\n    for i in images:\n        for t in i['RepoTags']:\n            reg, rep, tag = _decompose(t)\n            if matches(reg, i_reg) \\\n                    and matches(rep, i_rep) \\\n                    and matches(tag, i_tag):\n                valid_images.append(i)\n                break\n            # Some repo after decompose end up with the img_name\n            # at the end.  i.e. rhel7/rsyslog\n            if rep.endswith(img_name):\n                valid_images.append(i)\n                break\n    return valid_images", "response": "Returns a list of image data for images which match img_name. Will\n    optionally take a list of images from a docker. Client. images\n    query to avoid multiple docker queries."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrun a command as a subprocess. Return a triple of return code standard out standard err.", "response": "def subp(cmd):\n    \"\"\"\n    Run a command as a subprocess.\n    Return a triple of return code, standard out, standard err.\n    \"\"\"\n    proc = subprocess.Popen(cmd, stdout=subprocess.PIPE,\n                            stderr=subprocess.PIPE)\n    out, err = proc.communicate()\n    return ReturnTuple(proc.returncode, stdout=out, stderr=err)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprint a summary of the data returned from a CVE scan.", "response": "def print_scan_summary(json_data, names=None):\n    '''\n    Print a summary of the data returned from a\n    CVE scan.\n    '''\n    max_col_width = 50\n    min_width = 15\n\n    def _max_width(data):\n        max_name = 0\n        for name in data:\n            max_name = len(data[name]) if len(data[name]) > max_name \\\n                else max_name\n        # If the max name length is less that max_width\n        if max_name < min_width:\n            max_name = min_width\n\n        # If the man name is greater than the max col leng\n        # we wish to use\n        if max_name > max_col_width:\n            max_name = max_col_width\n\n        return max_name\n\n    clean = True\n\n    if len(names) > 0:\n        max_width = _max_width(names)\n    else:\n        max_width = min_width\n    template = \"{0:\" + str(max_width) + \"}   {1:5} {2:5} {3:5} {4:5}\"\n    sevs = ['critical', 'important', 'moderate', 'low']\n    writeOut(template.format(\"Container/Image\", \"Cri\", \"Imp\", \"Med\", \"Low\"))\n    writeOut(template.format(\"-\" * max_width, \"---\", \"---\", \"---\", \"---\"))\n    res_summary = json_data['results_summary']\n    for image in res_summary.keys():\n        image_res = res_summary[image]\n        if 'msg' in image_res.keys():\n            tmp_tuple = (image_res['msg'], \"\", \"\", \"\", \"\")\n        else:\n            if len(names) < 1:\n                image_name = image[:max_width]\n            else:\n                image_name = names[image][-max_width:]\n                if len(image_name) == max_col_width:\n                    image_name = '...' + image_name[-(len(image_name) - 3):]\n\n            tmp_tuple = tuple([image_name] +\n                              [str(image_res[sev]) for sev in sevs])\n            sev_results = [image_res[sev] for sev in\n                           sevs if image_res[sev] > 0]\n            if len(sev_results) > 0:\n                clean = False\n        writeOut(template.format(*tmp_tuple))\n    writeOut(\"\")\n    return clean"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprints a detailed summary of the data returned from a CVE scan.", "response": "def print_detail_scan_summary(json_data, names=None):\n    '''\n    Print a detailed summary of the data returned from\n    a CVE scan.\n    '''\n    clean = True\n    sevs = ['Critical', 'Important', 'Moderate', 'Low']\n    cve_summary = json_data['host_results']\n    image_template = \"  {0:10}: {1}\"\n    cve_template = \"     {0:10}: {1}\"\n    for image in cve_summary.keys():\n        image_res = cve_summary[image]\n        writeOut(\"\")\n        writeOut(image[:12])\n        if not image_res['isRHEL']:\n            writeOut(image_template.format(\"Result\",\n                                           \"Not based on Red Hat\"\n                                           \"Enterprise Linux\"))\n            continue\n        else:\n            writeOut(image_template.format(\"OS\", image_res['os'].rstrip()))\n            scan_results = image_res['cve_summary']['scan_results']\n\n        for sev in sevs:\n            if sev in scan_results:\n                clean = False\n                writeOut(image_template.format(sev,\n                                               str(scan_results[sev]['num'])))\n                for cve in scan_results[sev]['cves']:\n                        writeOut(cve_template.format(\"CVE\", cve['cve_title']))\n                        writeOut(cve_template.format(\"CVE URL\",\n                                                     cve['cve_ref_url']))\n                        writeOut(cve_template.format(\"RHSA ID\",\n                                                     cve['rhsa_ref_id']))\n                        writeOut(cve_template.format(\"RHSA URL\",\n                                                     cve['rhsa_ref_url']))\n                        writeOut(\"\")\n    return clean"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_mounts_by_path():\n    '''\n    Gets all mounted devices and paths\n    :return: dict of mounted devices and related information by path\n    '''\n    mount_info = []\n    f = open('/proc/mounts', 'r')\n    for line in f:\n        _tmp = line.split(\" \")\n        mount_info.append({'path': _tmp[1],\n                           'device': _tmp[0],\n                           'type': _tmp[2],\n                           'options': _tmp[3]\n                           }\n                          )\n    return mount_info", "response": "Gets all mounted devices and paths by path"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if the provided docker object is currently mounted and should be considered busy", "response": "def is_dock_obj_mounted(docker_obj):\n    '''\n    Check if the provided docker object, which needs to be an ID,\n    is currently mounted and should be considered \"busy\"\n    :param docker_obj: str, must be in ID format\n    :return: bool True or False\n    '''\n    mount_info = get_mounts_by_path()\n    devices = [x['device'] for x in mount_info]\n    # If we can find the ID of the object in the list\n    # of devices which comes from mount, safe to assume\n    # it is busy.\n    return any(docker_obj in x for x in devices)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef call(cmd,\n         timeout=None,\n         signum=signal.SIGKILL,\n         keep_rc=False,\n         encoding=\"utf-8\",\n         env=os.environ):\n    \"\"\"\n    Execute a cmd or list of commands with an optional timeout in seconds.\n\n    If `timeout` is supplied and expires, the process is killed with\n    SIGKILL (kill -9) and an exception is raised. Otherwise, the command\n    output is returned.\n\n    Parameters\n    ----------\n    cmd: str or [[str]]\n        The command(s) to execute\n    timeout: int\n        Seconds before kill is issued to the process\n    signum: int\n        The signal number to issue to the process on timeout\n    keep_rc: bool\n        Whether to return the exit code along with the output\n    encoding: str\n        unicode decoding scheme to use. Default is \"utf-8\"\n    env: dict\n        The environment in which to execute commands. Default is os.environ\n\n    Returns\n    -------\n    str\n        Content of stdout of cmd on success.\n\n    Raises\n    ------\n        CalledProcessError\n            Raised when cmd fails\n    \"\"\"\n\n    if not isinstance(cmd, list):\n        cmd = [cmd]\n\n    p = Pipeline(*cmd, timeout=timeout, signum=signum, env=env)\n    res = p(keep_rc=keep_rc)\n\n    if keep_rc:\n        rc, output = res\n        output = output.decode(encoding, 'ignore')\n        return rc, output\n    return res.decode(encoding, \"ignore\")", "response": "Execute a command in a sequence of commands and return the output of the command."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nexecute the pipeline and writes the results to the supplied output.", "response": "def write(self, output, mode=\"w\", keep_rc=False):\n        \"\"\"\n        Executes the pipeline and writes the results to the supplied output.\n        If output is a filename and the file didn't already exist before trying\n        to write, the file will be removed if an exception is raised.\n\n        Args:\n            output (str or file like object): will create a new file of this\n                name or overwrite an existing file. If output is already a file\n                like object, it is used.\n            mode (str): mode to use when creating or opening the provided file\n                name if it is a string. Ignored if output is a file like object.\n\n        Returns:\n            The final output of the pipeline.\n        Raises:\n            CalledProcessError if any return code in the pipeline is nonzero.\n        \"\"\"\n        if isinstance(output, six.string_types):\n            already_exists = os.path.exists(output)\n            try:\n                with open(output, mode) as f:\n                    p = self._build_pipes(f)\n                    rc = p.wait()\n                    if keep_rc:\n                        return rc\n                    if rc:\n                        raise CalledProcessError(rc, self.cmds[0], \"\")\n            except BaseException as be:\n                if not already_exists and os.path.exists(output):\n                    os.remove(output)\n                six.reraise(be.__class__, be, sys.exc_info()[2])\n        else:\n            p = self._build_pipes(output)\n            rc = p.wait()\n            if keep_rc:\n                return rc\n            if rc:\n                raise CalledProcessError(rc, self.cmds[0], \"\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef process(self, broker):\n        if any(i in broker for i in dr.IGNORE.get(self.component, [])):\n            raise dr.SkipComponent()\n        missing = self.get_missing_dependencies(broker)\n        if missing:\n            return _make_skip(dr.get_name(self.component), missing)\n        r = self.invoke(broker)\n        if r is None:\n            raise dr.SkipComponent()\n        if not isinstance(r, Response):\n            raise Exception(\"rules must return Response objects.\")\n        return r", "response": "Process the component and return the response."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nvalidate expected attributes and constructor keyword arguments.", "response": "def validate_kwargs(self, kwargs):\n        \"\"\"\n        Validates expected subclass attributes and constructor keyword\n        arguments.\n        \"\"\"\n        if not self.response_type:\n            msg = \"response_type must be set on the Response subclass.\"\n            raise ValidationException(msg)\n\n        if (self.key_name and self.key_name in kwargs) or \"type\" in kwargs:\n            name = self.__class__.__name__\n            msg = \"%s is an invalid argument for %s\" % (self.key_name, name)\n            raise ValidationException(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef validate_key(self, key):\n        if not key:\n            name = self.__class__.__name__\n            msg = \"%s response missing %s\" % (name, self.key_name)\n            raise ValidationException(msg, self)\n        elif not isinstance(key, str):\n            msg = \"Response contains invalid %s type\" % self.key_name\n            raise ValidationException(msg, type(key))", "response": "Called if the key_name class attribute is not None."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef adjust_for_length(self, key, r, kwargs):\n        length = len(str(kwargs))\n        if length > settings.defaults[\"max_detail_length\"]:\n            self._log_length_error(key, length)\n            r[\"max_detail_length_error\"] = length\n            return r\n        return kwargs", "response": "Adjusts the response length to a max_detail_length specified in settings."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _log_length_error(self, key, length):\n        extra = {\n            \"max_detail_length\": settings.defaults[\"max_detail_length\"],\n            \"len\": length\n        }\n        if self.key_name:\n            extra[self.key_name] = key\n        msg = \"Length of data in %s is too long.\" % self.__class__.__name__\n        log.error(msg, extra=extra)", "response": "Helper function for logging a length error."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nextracts the real interface name from the path name.", "response": "def extract_iface_name_from_path(path, name):\n    \"\"\"\n    Extract the 'real' interface name from the path name.  Basically this\n    puts the '@' back in the name in place of the underscore, where the name\n    contains a '.' or contains 'macvtap' or 'macvlan'.\n\n    Examples:\n\n    +------------------+-----------------+\n    | real name        | path name       |\n    +==================+=================+\n    | bond0.104\\@bond0 | bond0.104_bond0 |\n    +------------------+-----------------+\n    | __tmp1111        | __tmp1111       |\n    +------------------+-----------------+\n    | macvtap\\@bond0   | macvlan_bond0   |\n    +------------------+-----------------+\n    | prod_bond        | prod_bond       |\n    +------------------+-----------------+\n    \"\"\"\n    if name in path:\n        ifname = os.path.basename(path).split(\"_\", 2)[-1].strip()\n        if \".\" in ifname or \"macvtap\" in ifname or \"macvlan\" in ifname:\n            ifname = ifname.replace(\"_\", \"@\")\n        return ifname"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _parse_oracle(lines):\n    config = {}\n\n    for line in get_active_lines(lines):\n        # Check for NULL in line to begin control char removal\n        if '\\00' in line:\n            line = cleanup.sub('', line)\n        if '=' in line:\n            (key, value) = line.split('=', 1)\n            key = key.strip(whitespace + '\"\\'').lower()\n            if ',' in line:\n                value = [s.strip(whitespace + '\"\\'').lower() for s in value.split(',')]\n            else:\n                value = value.strip(whitespace + '\"\\'').lower()\n            config[key] = value\n\n    return config", "response": "Performs the actual file parsing returning a dict of the config values\n    in a given Oracle DB config file."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses the personalities line of the mdstat file.", "response": "def parse_personalities(personalities_line):\n    \"\"\"Parse the \"personalities\" line of ``/proc/mdstat``.\n\n    Lines are expected to be like:\n\n        Personalities : [linear] [raid0] [raid1] [raid5] [raid4] [raid6]\n\n    If they do not have this format, an error will be raised since it\n    would be considered an unexpected parsing error.\n\n    Parameters\n    ----------\n\n    personalities_line : str\n        A single \"Personalities\" line from an ``/proc/mdstat`` files.\n\n    Returns\n    -------\n        A list of raid \"personalities\" listed on the line.\n    \"\"\"\n    tokens = personalities_line.split()\n    assert tokens.pop(0) == \"Personalities\"\n    assert tokens.pop(0) == \":\"\n\n    personalities = []\n    for token in tokens:\n        assert token.startswith('[') and token.endswith(']')\n        personalities.append(token.strip('[]'))\n\n    return personalities"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_array_start(md_line):\n    components = []\n    tokens = md_line.split()\n    device_name = tokens.pop(0)\n    assert device_name.startswith(\"md\")\n    assert tokens.pop(0) == \":\"\n\n    active_string = tokens.pop(0)\n    active = False\n    if active_string == \"active\":\n        active = True\n    else:\n        assert active_string == \"inactive\"\n\n    raid_read_only_token = tokens.pop(0)\n    auto_read_only = False\n    raid = None\n    if raid_read_only_token == \"(auto-read-only)\":\n        auto_read_only = True\n        raid = tokens.pop(0)\n    elif active:\n        raid = raid_read_only_token\n    else:  # Inactive devices don't list the raid type\n        raid = None\n        tokens.insert(0, raid_read_only_token)\n\n    for token in tokens:\n        subtokens = re.split(r\"\\[|]\", token)\n        assert len(subtokens) > 1\n        comp_name = subtokens[0]\n        assert comp_name\n\n        role = int(subtokens[1])\n\n        device_flag = None\n        if len(subtokens) > 2:\n            device_flag = subtokens[2]\n            if device_flag:\n                device_flag = device_flag.strip('()')\n\n        component_row = {\"device_name\": device_name,\n                         \"raid\": raid,\n                         \"active\": active,\n                         \"auto_read_only\": auto_read_only,\n                         \"component_name\": comp_name,\n                         \"role\": role,\n                         \"device_flag\": device_flag}\n        components.append(component_row)\n    return components", "response": "Parse the initial line of a device array stanza in\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses the array status line and store the keys into the components dictionary.", "response": "def parse_array_status(line, components):\n    \"\"\"\n    Parse the array status line, e.g.::\n\n        1318680576 blocks level 5, 1024k chunk, algorithm 2 [10/10] [UUUUUUUUUU]\n\n    This retrieves the following pieces of information:\n\n    * ``blocks`` - (int) number of blocks in the whole MD device (always present)\n    * ``level`` - (int) if found, the present RAID level\n    * ``chunksize`` - (str) if found, the size of the data chunk in kilobytes\n    * ``algorithm`` - (int) if found, the current algorithm in use.\n\n    Because of the way data is stored per-component and not per-array, this\n    then puts the above keys into each of the component dictionaries in the\n    list we've been given.\n\n    Sample data::\n\n        1250241792 blocks super 1.2 level 5, 64k chunk, algorithm 2 [5/5] [UUUUUU]\n        1465151808 blocks level 5, 64k chunk, algorithm 2 [4/3] [UUU_]\n        136448 blocks [2/2] [UU]\n        6306 blocks super external:imsm<Paste>\n    \"\"\"\n    status_line_re = r'(?P<blocks>\\d+) blocks' + \\\n        r'(?: super (?P<super>\\S+))?' + \\\n        r'(?: level (?P<level>\\d+),)?' + \\\n        r'(?: (?P<chunk>\\d+k) chunk,)?' + \\\n        r'(?: algorithm (?P<algorithm>\\d+))?'\n    # Since we're only called once per line, unless there's a good way to\n    # cache this regular expression in compiled form we're going to have to\n    # compile it each time.\n    status_line_rex = re.compile(status_line_re)\n    match = status_line_rex.search(line)\n    if match:\n        attributes = {'blocks': int(match.group('blocks'))}\n        if match.group('level'):\n            attributes['level'] = int(match.group('level'))\n        if match.group('chunk'):\n            attributes['chunk'] = match.group('chunk')\n        if match.group('algorithm'):\n            attributes['algorithm'] = int(match.group('algorithm'))\n        for comp in components:\n            comp.update(attributes)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse the up indictor string and returns the uptime string if found.", "response": "def parse_upstring(line):\n    \"\"\"\n    Parse the subsequent lines of a device array stanza in ``/proc/mdstat``\n    for the \"up\" indictor string.\n\n    Lines are expected to be like:\n\n        129596288 blocks [2/2] [UU]\n\n    or\n\n        1318680576 blocks level 5, 1024k chunk, algorithm 2 [10/10] [UUU_UUUUUU]\n\n    In particular, this method searchs for the string like ``[UU]`` which\n    indicates whether component devices or up, ``U`` or down, ``_``.\n\n    Parameters\n    ----------\n\n    line : str\n        A single line from a device array stanza.\n\n    Returns\n    -------\n\n        The string containing a series of ``U`` and ``\\_`` characters if\n        found in the string, and ``None`` if the uptime string is not found.\n    \"\"\"\n    UP_STRING_REGEX = r\"\\[(U|_)+]\"\n\n    match = re.search(UP_STRING_REGEX, line)\n    if match:\n        return match.group().strip('[]')\n    else:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef apply_upstring(upstring, component_list):\n    assert len(upstring) == len(component_list)\n\n    def add_up_key(comp_dict, up_indicator):\n        assert up_indicator == 'U' or up_indicator == \"_\"\n        comp_dict['up'] = up_indicator == 'U'\n\n    for comp_dict, up_indicator in zip(component_list, upstring):\n        add_up_key(comp_dict, up_indicator)", "response": "This function applies the upstring to the list of dictionaries that are returned from parse_array_start."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsearching the PAM configuration file by keyword.", "response": "def search(self, **kwargs):\n        \"\"\"\n        Search the pam.d configuration file by keyword.  This is provided by\n        the :func:`insights.parsers.keyword_search` function - see its\n        documentation for more information.\n\n        Searching on the list of PAM configuration entries is exactly like\n        they were dictionaries instead of objects with properties.  In\n        addition, the 'control_flags' property becomes a dictionary of\n        keywords and values, so that 'control_flags__contains' allows\n        searching for a particular control flag.\n\n        Returns:\n            (list): A list of PamConfEntry objects that match the given\n            search criteria.\n        \"\"\"\n        # Because keyword_search takes dicts, and we have objects with complex\n        # properties, we convert them to a list of dicts.\n        # First, store the things we're going to convert.\n        prop_keys = ('service', 'interface', 'module_name', 'module_args')\n        search = []\n        # Can't find a neat way to do this as a comprehension, so it's back\n        # to loops.\n        for obj in self.data:\n            row = {'entry_obj': obj}\n            for key in prop_keys:\n                row[key] = getattr(obj, key)\n            # For hysterical reasons, module_args can contain None if not\n            # defined, but that's non-iterable: replace with ''\n            if row['module_args'] is None:\n                row['module_args'] = ''\n            # Convert control_flags down to key/value dictionary\n            flags = {}\n            for cf in obj.control_flags:\n                flags[cf.flag] = cf.value\n            row['control_flags'] = flags\n            search.append(row)\n        # Now get the result, and just return the entry objects\n        found = []\n        for r in keyword_search(search, **kwargs):\n            found.append(r['entry_obj'])\n        return found"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef remove(path, chmod=False):\n\n    if not os.path.exists(path):\n        return\n\n    if chmod:\n        cmd = \"chmod -R 755 %s\" % path\n        subproc.call(cmd)\n\n    cmd = 'rm -rf \"{p}\"'.format(p=path)\n    subproc.call(cmd)", "response": "Removes a file or directory from the base directory of the current node."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nensures that the path exists in a multiprocessing safe way.", "response": "def ensure_path(path, mode=0o777):\n    \"\"\"Ensure that path exists in a multiprocessing safe way.\n\n    If the path does not exist, recursively create it and its parent\n    directories using the provided mode.  If the path already exists,\n    do nothing.  The umask is cleared to enable the mode to be set,\n    and then reset to the original value after the mode is set.\n\n    Parameters\n    ----------\n    path : str\n        file system path to a non-existent directory\n        that should be created.\n    mode : int\n        octal representation of the mode to use when creating\n        the directory.\n\n    Raises\n    ------\n    OSError\n        If os.makedirs raises an OSError for any reason\n        other than if the directory already exists.\n    \"\"\"\n\n    if path:\n        try:\n            umask = os.umask(000)\n            os.makedirs(path, mode)\n            os.umask(umask)\n        except OSError as e:\n            if e.errno != errno.EEXIST:\n                raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef uptime(ut, facter):\n\n    ut = ut\n    if ut and ut.loadavg:\n        return Uptime(ut.currtime, ut.updays, ut.uphhmm,\n                      ut.users, ut.loadavg, ut.uptime)\n    ft = facter\n    if ft and hasattr(ft, 'uptime_seconds'):\n        import datetime\n        secs = int(ft.uptime_seconds)\n        up_dd = secs // (3600 * 24)\n        up_hh = (secs % (3600 * 24)) // 3600\n        up_mm = (secs % 3600) // 60\n        updays = str(up_dd) if up_dd > 0 else ''\n        uphhmm = '%02d:%02d' % (up_hh, up_mm)\n        up_time = datetime.timedelta(seconds=secs)\n        return Uptime(None, updays, uphhmm, None, None, up_time)\n\n    raise Exception(\"Unable to get uptime information.\")", "response": "Check uptime and facts to get the uptime information."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates Node message from params and system information.", "response": "def get_node(service_name, host_name):\n    \"\"\"Generates Node message from params and system information.\n    \"\"\"\n    return common_pb2.Node(\n        identifier=common_pb2.ProcessIdentifier(\n            host_name=socket.gethostname() if host_name is None\n            else host_name,\n            pid=os.getpid(),\n            start_timestamp=proto_ts_from_datetime(\n                datetime.datetime.utcnow())),\n        library_info=common_pb2.LibraryInfo(\n            language=common_pb2.LibraryInfo.Language.Value('PYTHON'),\n            exporter_version=EXPORTER_VERSION,\n            core_library_version=opencensus_version),\n        service_info=common_pb2.ServiceInfo(name=service_name))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef proto_ts_from_datetime_str(dt):\n\n    ts = Timestamp()\n    if (dt is not None):\n        try:\n            ts.FromJsonString(dt)\n        except ParseError:\n            pass\n    return ts", "response": "Converts string datetime in ISO format to protobuf timestamp."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef start_span(self, name='span'):\n        parent_span = self.current_span()\n\n        # If a span has remote parent span, then the parent_span.span_id\n        # should be the span_id from the request header.\n        if parent_span is None:\n            parent_span = base.NullContextManager(\n                span_id=self.span_context.span_id)\n\n        span = trace_span.Span(\n            name,\n            parent_span=parent_span,\n            context_tracer=self)\n        with self._spans_list_condition:\n            self._spans_list.append(span)\n        self.span_context.span_id = span.span_id\n        execution_context.set_current_span(span)\n        span.start()\n        return span", "response": "Start a span.\n\n        :type name: str\n        :param name: The name of the span.\n\n        :rtype: :class:`~opencensus.trace.span.Span`\n        :returns: The Span object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef end_span(self, *args, **kwargs):\n        cur_span = self.current_span()\n        if cur_span is None and self._spans_list:\n            cur_span = self._spans_list[-1]\n\n        if cur_span is None:\n            logging.warning('No active span, cannot do end_span.')\n            return\n\n        cur_span.finish()\n        self.span_context.span_id = cur_span.parent_span.span_id if \\\n            cur_span.parent_span else None\n\n        if isinstance(cur_span.parent_span, trace_span.Span):\n            execution_context.set_current_span(cur_span.parent_span)\n        else:\n            execution_context.set_current_span(None)\n\n        with self._spans_list_condition:\n            if cur_span in self._spans_list:\n                span_datas = self.get_span_datas(cur_span)\n                self.exporter.export(span_datas)\n                self._spans_list.remove(cur_span)\n\n        return cur_span", "response": "End a span. Update the span_id in SpanContext to the current span's\n        parent span id; Update the current span."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_attribute_to_current_span(self, attribute_key, attribute_value):\n        current_span = self.current_span()\n        current_span.add_attribute(attribute_key, attribute_value)", "response": "Add an attribute to the current span."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_span_datas(self, span):\n        span_datas = [\n            span_data_module.SpanData(\n                name=ss.name,\n                context=self.span_context,\n                span_id=ss.span_id,\n                parent_span_id=ss.parent_span.span_id if\n                ss.parent_span else None,\n                attributes=ss.attributes,\n                start_time=ss.start_time,\n                end_time=ss.end_time,\n                child_span_count=len(ss.children),\n                stack_trace=ss.stack_trace,\n                time_events=ss.time_events,\n                links=ss.links,\n                status=ss.status,\n                same_process_as_parent_span=ss.same_process_as_parent_span,\n                span_kind=ss.span_kind\n            )\n            for ss in span\n        ]\n\n        return span_datas", "response": "Extracts a list of SpanData tuples from a span."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a metric producer.", "response": "def add(self, metric_producer):\n        \"\"\"Add a metric producer.\n\n        :type metric_producer: :class: 'MetricProducer'\n        :param metric_producer: The metric producer to add.\n        \"\"\"\n        if metric_producer is None:\n            raise ValueError\n        with self.mp_lock:\n            self.metric_producers.add(metric_producer)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove a metric producer from the list of available metric types.", "response": "def remove(self, metric_producer):\n        \"\"\"Remove a metric producer.\n\n        :type metric_producer: :class: 'MetricProducer'\n        :param metric_producer: The metric producer to remove.\n        \"\"\"\n        if metric_producer is None:\n            raise ValueError\n        try:\n            with self.mp_lock:\n                self.metric_producers.remove(metric_producer)\n        except KeyError:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_message_event(proto_message, span, message_event_type, message_id=1):\n    span.add_time_event(\n        time_event=time_event.TimeEvent(\n            datetime.utcnow(),\n            message_event=time_event.MessageEvent(\n                message_id,\n                type=message_event_type,\n                uncompressed_size_bytes=proto_message.ByteSize()\n            )\n        )\n    )", "response": "Adds a MessageEvent to the given protobuf\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef wrap_iter_with_message_events(\n    request_or_response_iter,\n    span,\n    message_event_type\n):\n    \"\"\"Wraps a request or response iterator to add message events to the span\n    for each proto message sent or received\n    \"\"\"\n    for message_id, message in enumerate(request_or_response_iter, start=1):\n        add_message_event(\n            proto_message=message,\n            span=span,\n            message_event_type=message_event_type,\n            message_id=message_id\n        )\n        yield message", "response": "Wraps a request or response iterator to add message events to the span\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert the StackFrame object to json format.", "response": "def format_stack_frame_json(self):\n        \"\"\"Convert StackFrame object to json format.\"\"\"\n        stack_frame_json = {}\n        stack_frame_json['function_name'] = get_truncatable_str(\n            self.func_name)\n        stack_frame_json['original_function_name'] = get_truncatable_str(\n            self.original_func_name)\n        stack_frame_json['file_name'] = get_truncatable_str(self.file_name)\n        stack_frame_json['line_number'] = self.line_num\n        stack_frame_json['column_number'] = self.col_num\n        stack_frame_json['load_module'] = {\n            'module': get_truncatable_str(self.load_module),\n            'build_id': get_truncatable_str(self.build_id),\n        }\n        stack_frame_json['source_version'] = get_truncatable_str(\n            self.source_version)\n\n        return stack_frame_json"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninitializing a StackTrace from a python traceback instance", "response": "def from_traceback(cls, tb):\n        \"\"\"Initializes a StackTrace from a python traceback instance\"\"\"\n        stack_trace = cls(\n            stack_trace_hash_id=generate_hash_id_from_traceback(tb)\n        )\n        # use the add_stack_frame so that json formatting is applied\n        for tb_frame_info in traceback.extract_tb(tb):\n            filename, line_num, fn_name, _ = tb_frame_info\n            stack_trace.add_stack_frame(\n                StackFrame(\n                    func_name=fn_name,\n                    original_func_name=fn_name,\n                    file_name=filename,\n                    line_num=line_num,\n                    col_num=0,  # I don't think this is available in python\n                    load_module=filename,\n                    build_id=BUILD_ID,\n                    source_version=SOURCE_VERSION\n                )\n            )\n        return stack_trace"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd StackFrame to frames list.", "response": "def add_stack_frame(self, stack_frame):\n        \"\"\"Add StackFrame to frames list.\"\"\"\n        if len(self.stack_frames) >= MAX_FRAMES:\n            self.dropped_frames_count += 1\n        else:\n            self.stack_frames.append(stack_frame.format_stack_frame_json())"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef format_stack_trace_json(self):\n        stack_trace_json = {}\n\n        if self.stack_frames:\n            stack_trace_json['stack_frames'] = {\n                'frame': self.stack_frames,\n                'dropped_frames_count': self.dropped_frames_count\n            }\n\n        stack_trace_json['stack_trace_hash_id'] = self.stack_trace_hash_id\n\n        return stack_trace_json", "response": "Convert a StackTrace object to json format."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef register_view(self, view):\n        self.measure_to_view_map.register_view(view=view, timestamp=self.time)", "response": "registers the given view"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_view(self, view_name):\n        return self.measure_to_view_map.get_view(view_name=view_name,\n                                                 timestamp=self.time)", "response": "gets the view given the view name"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_items(self):\n        items = [self._queue.get()]\n\n        while len(items) < self._max_batch_size:\n            try:\n                items.append(self._queue.get_nowait())\n            except queue.Empty:\n                break\n\n        return items", "response": "Gets at least one item from a given Queue. Does not mark the items as done."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _thread_main(self):\n        quit_ = False\n\n        while True:\n            items = self._get_items()\n            data = []\n\n            for item in items:\n                if item is _WORKER_TERMINATOR:\n                    quit_ = True\n                    # Continue processing items, don't break, try to process\n                    # all items we got back before quitting.\n                else:\n                    data.extend(item)\n\n            if data:\n                try:\n                    self.exporter.emit(data)\n                except Exception:\n                    logging.exception(\n                        '%s failed to emit data.'\n                        'Dropping %s objects from queue.',\n                        self.exporter.__class__.__name__,\n                        len(data))\n                    pass\n\n            for _ in range(len(items)):\n                self._queue.task_done()\n\n            # self._event is set at exit, at which point we start draining the\n            # queue immediately. If self._event is unset, block for\n            # self.wait_period between each batch of exports.\n            self._event.wait(self._wait_period)\n\n            if quit_:\n                break", "response": "The main function of the worker thread."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nstart the background thread.", "response": "def start(self):\n        \"\"\"Starts the background thread.\n\n        Additionally, this registers a handler for process exit to attempt\n        to send any pending data before shutdown.\n        \"\"\"\n        with self._lock:\n            if self.is_alive:\n                return\n\n            self._thread = threading.Thread(\n                target=self._thread_main, name=_WORKER_THREAD_NAME)\n            self._thread.daemon = True\n            self._thread.start()\n            atexit.register(self._export_pending_data)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef stop(self):\n        if not self.is_alive:\n            return True\n\n        with self._lock:\n            self._queue.put_nowait(_WORKER_TERMINATOR)\n            self._thread.join(timeout=self._grace_period)\n\n            success = not self.is_alive\n            self._thread = None\n\n            return success", "response": "Stops the background thread."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the type and labels of a monitored resource.", "response": "def set_monitored_resource(series, option_resource_type):\n    \"\"\"Set a resource(type and labels) that can be used for monitoring.\n    :param series: TimeSeries object based on view data\n    :param option_resource_type: Resource is an optional field that\n    represents the Stackdriver MonitoredResource type.\n    \"\"\"\n    resource_type = GLOBAL_RESOURCE_TYPE\n\n    if option_resource_type == \"\":\n        resource = monitored_resource.get_instance()\n        if resource is not None:\n            resource_labels = resource.get_labels()\n\n            if resource.get_type() == 'gke_container':\n                resource_type = 'k8s_container'\n                set_attribute_label(series, resource_labels, 'project_id')\n                set_attribute_label(series, resource_labels, 'cluster_name')\n                set_attribute_label(series, resource_labels, 'container_name')\n                set_attribute_label(series, resource_labels, 'namespace_id',\n                                    'namespace_name')\n                set_attribute_label(series, resource_labels, 'pod_id',\n                                    'pod_name')\n                set_attribute_label(series, resource_labels, 'zone',\n                                    'location')\n\n            elif resource.get_type() == 'gce_instance':\n                resource_type = 'gce_instance'\n                set_attribute_label(series, resource_labels, 'project_id')\n                set_attribute_label(series, resource_labels, 'instance_id')\n                set_attribute_label(series, resource_labels, 'zone')\n\n            elif resource.get_type() == 'aws_ec2_instance':\n                resource_type = 'aws_ec2_instance'\n                set_attribute_label(series, resource_labels, 'aws_account')\n                set_attribute_label(series, resource_labels, 'instance_id')\n                set_attribute_label(series, resource_labels, 'region',\n                                    label_value_prefix='aws:')\n    else:\n        resource_type = option_resource_type\n    series.resource.type = resource_type"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_attribute_label(series, resource_labels, attribute_key,\n                        canonical_key=None, label_value_prefix=''):\n    \"\"\"Set a label to timeseries that can be used for monitoring\n    :param series: TimeSeries object based on view data\n    :param resource_labels: collection of labels\n    :param attribute_key: actual label key\n    :param canonical_key: exporter specific label key, Optional\n    :param label_value_prefix: exporter specific label value prefix, Optional\n    \"\"\"\n    if attribute_key in resource_labels:\n        if canonical_key is None:\n            canonical_key = attribute_key\n\n        series.resource.labels[canonical_key] = \\\n            label_value_prefix + resource_labels[attribute_key]", "response": "Set a label to timeseries that can be used for monitoring the resource."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef new_stats_exporter(options=None, interval=None):\n    if options is None:\n        _, project_id = google.auth.default()\n        options = Options(project_id=project_id)\n    if str(options.project_id).strip() == \"\":\n        raise ValueError(ERROR_BLANK_PROJECT_ID)\n\n    ci = client_info.ClientInfo(client_library_version=get_user_agent_slug())\n    client = monitoring_v3.MetricServiceClient(client_info=ci)\n    exporter = StackdriverStatsExporter(client=client, options=options)\n\n    transport.get_exporter_thread(stats.stats, exporter, interval=interval)\n    return exporter", "response": "Create a new StackdriverStatsExporter and running transport thread."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef namespaced_view_name(view_name, metric_prefix):\n    metric_prefix = metric_prefix or \"custom.googleapis.com/opencensus\"\n    return os.path.join(metric_prefix, view_name).replace('\\\\', '/')", "response": "create string to be used as metric type\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef new_label_descriptors(defaults, keys):\n    label_descriptors = []\n    for lk in itertools.chain.from_iterable((defaults.keys(), keys)):\n        label = {}\n        label[\"key\"] = sanitize_label(lk.key)\n        label[\"description\"] = lk.description\n        label_descriptors.append(label)\n\n    return label_descriptors", "response": "create labels for the metric_descriptor\n        that will be sent to Stackdriver Monitoring\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves characters not accepted in labels", "response": "def sanitize_label(text):\n    \"\"\"Remove characters not accepted in labels key\n\n    This replaces any non-word characters (alphanumeric or underscore), with\n    an underscore. It also ensures that the first character is a letter by\n    prepending with 'key' if necessary, and trims the text to 100 characters.\n    \"\"\"\n    if not text:\n        return text\n    text = re.sub('\\\\W+', '_', text)\n    if text[0] in string.digits:\n        text = \"key_\" + text\n    elif text[0] == '_':\n        text = \"key\" + text\n    return text[:100]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting an OC time series to SD series.", "response": "def _convert_series(self, metric, ts):\n        \"\"\"Convert an OC timeseries to a SD series.\"\"\"\n        series = monitoring_v3.types.TimeSeries()\n        series.metric.type = self.get_metric_type(metric.descriptor)\n\n        for lk, lv in self.options.default_monitoring_labels.items():\n            series.metric.labels[lk.key] = lv.value\n\n        for key, val in zip(metric.descriptor.label_keys, ts.label_values):\n            if val.value is not None:\n                safe_key = sanitize_label(key.key)\n                series.metric.labels[safe_key] = val.value\n\n        set_monitored_resource(series, self.options.resource)\n\n        for point in ts.points:\n            sd_point = series.points.add()\n            # this just modifies points, no return\n            self._convert_point(metric, ts, point, sd_point)\n        return series"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _convert_point(self, metric, ts, point, sd_point):\n        if (metric.descriptor.type == metric_descriptor.MetricDescriptorType\n                .CUMULATIVE_DISTRIBUTION):\n\n            sd_dist_val = sd_point.value.distribution_value\n            sd_dist_val.count = point.value.count\n            sd_dist_val.sum_of_squared_deviation =\\\n                point.value.sum_of_squared_deviation\n\n            assert sd_dist_val.bucket_options.explicit_buckets.bounds == []\n            sd_dist_val.bucket_options.explicit_buckets.bounds.extend(\n                [0.0] +\n                list(map(float, point.value.bucket_options.type_.bounds))\n            )\n\n            assert sd_dist_val.bucket_counts == []\n            sd_dist_val.bucket_counts.extend(\n                [0] +\n                [bb.count for bb in point.value.buckets]\n            )\n\n        elif (metric.descriptor.type ==\n              metric_descriptor.MetricDescriptorType.CUMULATIVE_INT64):\n            sd_point.value.int64_value = int(point.value.value)\n\n        elif (metric.descriptor.type ==\n              metric_descriptor.MetricDescriptorType.CUMULATIVE_DOUBLE):\n            sd_point.value.double_value = float(point.value.value)\n\n        elif (metric.descriptor.type ==\n              metric_descriptor.MetricDescriptorType.GAUGE_INT64):\n            sd_point.value.int64_value = int(point.value.value)\n\n        elif (metric.descriptor.type ==\n              metric_descriptor.MetricDescriptorType.GAUGE_DOUBLE):\n            sd_point.value.double_value = float(point.value.value)\n\n        # TODO: handle SUMMARY metrics, #567\n        else:  # pragma: NO COVER\n            raise TypeError(\"Unsupported metric type: {}\"\n                            .format(metric.descriptor.type))\n\n        end = point.timestamp\n        if ts.start_timestamp is None:\n            start = end\n        else:\n            start = datetime.strptime(ts.start_timestamp, EPOCH_PATTERN)\n\n        timestamp_start = (start - EPOCH_DATETIME).total_seconds()\n        timestamp_end = (end - EPOCH_DATETIME).total_seconds()\n\n        sd_point.interval.end_time.seconds = int(timestamp_end)\n\n        secs = sd_point.interval.end_time.seconds\n        sd_point.interval.end_time.nanos = int((timestamp_end - secs) * 1e9)\n\n        start_time = sd_point.interval.start_time\n        start_time.seconds = int(timestamp_start)\n        start_time.nanos = int((timestamp_start - start_time.seconds) * 1e9)", "response": "Convert an OC metric point to a SD point."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting an OC metric descriptor to SD metric descriptor.", "response": "def get_metric_descriptor(self, oc_md):\n        \"\"\"Convert an OC metric descriptor to a SD metric descriptor.\"\"\"\n        try:\n            metric_kind, value_type = OC_MD_TO_SD_TYPE[oc_md.type]\n        except KeyError:\n            raise TypeError(\"Unsupported metric type: {}\".format(oc_md.type))\n\n        if self.options.metric_prefix:\n            display_name_prefix = self.options.metric_prefix\n        else:\n            display_name_prefix = DEFAULT_DISPLAY_NAME_PREFIX\n\n        desc_labels = new_label_descriptors(\n            self.options.default_monitoring_labels, oc_md.label_keys)\n\n        descriptor = monitoring_v3.types.MetricDescriptor(labels=desc_labels)\n        metric_type = self.get_metric_type(oc_md)\n        descriptor.type = metric_type\n        descriptor.metric_kind = metric_kind\n        descriptor.value_type = value_type\n        descriptor.description = oc_md.description\n        descriptor.unit = oc_md.unit\n        descriptor.name = (\"projects/{}/metricDescriptors/{}\"\n                           .format(self.options.project_id, metric_type))\n        descriptor.display_name = (\"{}/{}\"\n                                   .format(display_name_prefix, oc_md.name))\n\n        return descriptor"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nregister a metric descriptor with stackdriver.", "response": "def register_metric_descriptor(self, oc_md):\n        \"\"\"Register a metric descriptor with stackdriver.\"\"\"\n        metric_type = self.get_metric_type(oc_md)\n        with self._md_lock:\n            if metric_type in self._md_cache:\n                return self._md_cache[metric_type]\n\n        descriptor = self.get_metric_descriptor(oc_md)\n        project_name = self.client.project_path(self.options.project_id)\n        sd_md = self.client.create_metric_descriptor(project_name, descriptor)\n        with self._md_lock:\n            self._md_cache[metric_type] = sd_md\n        return sd_md"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_header(self, header):\n        if header is None:\n            return SpanContext()\n\n        try:\n            match = re.search(_TRACE_CONTEXT_HEADER_RE, header)\n        except TypeError:\n            logging.warning(\n                'Header should be str, got {}. Cannot parse the header.'\n                .format(header.__class__.__name__))\n            raise\n\n        if match:\n            trace_id = match.group(1)\n            span_id = match.group(3)\n            trace_options = match.group(5)\n\n            if trace_options is None:\n                trace_options = 1\n\n            span_context = SpanContext(\n                trace_id=trace_id,\n                span_id=span_id,\n                trace_options=TraceOptions(trace_options),\n                from_header=True)\n            return span_context\n        else:\n            logging.warning(\n                'Cannot parse the header {}, generate a new context instead.'\n                .format(header))\n            return SpanContext()", "response": "Generate a SpanContext object from the trace context header."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef from_headers(self, headers):\n        if headers is None:\n            return SpanContext()\n        header = headers.get(_TRACE_CONTEXT_HEADER_NAME)\n        if header is None:\n            return SpanContext()\n        header = str(header.encode('utf-8'))\n        return self.from_header(header)", "response": "Generate a SpanContext object from the HTTP request headers."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_header(self, span_context):\n        trace_id = span_context.trace_id\n        span_id = span_context.span_id\n        trace_options = span_context.trace_options.trace_options_byte\n\n        header = '{}/{};o={}'.format(\n            trace_id,\n            span_id,\n            int(trace_options))\n        return header", "response": "Convert a SpanContext object to a trace context header string."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _extract_annotations_from_span(span):\n    if span.time_events is None:\n        return []\n\n    annotations = []\n    for time_event in span.time_events:\n        annotation = time_event.annotation\n        if not annotation:\n            continue\n\n        event_timestamp_mus = timestamp_to_microseconds(time_event.timestamp)\n        annotations.append({'timestamp': int(round(event_timestamp_mus)),\n                            'value': annotation.description})\n\n    return annotations", "response": "Extract and convert time event annotations to zipkin annotations"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef emit(self, span_datas):\n\n        try:\n            zipkin_spans = self.translate_to_zipkin(span_datas)\n            result = requests.post(\n                url=self.url,\n                data=json.dumps(zipkin_spans),\n                headers=ZIPKIN_HEADERS)\n\n            if result.status_code not in SUCCESS_STATUS_CODE:\n                logging.error(\n                    \"Failed to send spans to Zipkin server! Spans are {}\"\n                    .format(zipkin_spans))\n        except Exception as e:  # pragma: NO COVER\n            logging.error(getattr(e, 'message', e))", "response": "Send SpanData tuples to Zipkin server."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntranslate the opencensus spans to zipkin format spans.", "response": "def translate_to_zipkin(self, span_datas):\n        \"\"\"Translate the opencensus spans to zipkin spans.\n\n        :type span_datas: list of :class:\n            `~opencensus.trace.span_data.SpanData`\n        :param span_datas:\n            SpanData tuples to emit\n\n        :rtype: list\n        :returns: List of zipkin format spans.\n        \"\"\"\n\n        local_endpoint = {\n            'serviceName': self.service_name,\n            'port': self.port,\n        }\n\n        if self.ipv4 is not None:\n            local_endpoint['ipv4'] = self.ipv4\n\n        if self.ipv6 is not None:\n            local_endpoint['ipv6'] = self.ipv6\n\n        zipkin_spans = []\n\n        for span in span_datas:\n            # Timestamp in zipkin spans is int of microseconds.\n            start_timestamp_mus = timestamp_to_microseconds(span.start_time)\n            end_timestamp_mus = timestamp_to_microseconds(span.end_time)\n            duration_mus = end_timestamp_mus - start_timestamp_mus\n\n            zipkin_span = {\n                'traceId': span.context.trace_id,\n                'id': str(span.span_id),\n                'name': span.name,\n                'timestamp': int(round(start_timestamp_mus)),\n                'duration': int(round(duration_mus)),\n                'localEndpoint': local_endpoint,\n                'tags': _extract_tags_from_span(span.attributes),\n                'annotations': _extract_annotations_from_span(span),\n            }\n\n            span_kind = span.span_kind\n            parent_span_id = span.parent_span_id\n\n            if span_kind is not None:\n                kind = SPAN_KIND_MAP.get(span_kind)\n                # Zipkin API for span kind only accept\n                # enum(CLIENT|SERVER|PRODUCER|CONSUMER|Absent)\n                if kind is not None:\n                    zipkin_span['kind'] = kind\n\n            if parent_span_id is not None:\n                zipkin_span['parentId'] = str(parent_span_id)\n\n            zipkin_spans.append(zipkin_span)\n\n        return zipkin_spans"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nregisters the event before cursor execute and after cursor execute to the event listner of the engine.", "response": "def trace_engine(engine):\n    \"\"\"Register the event before cursor execute and after cursor execute\n    to the event listner of the engine.\n    \"\"\"\n    event.listen(engine, 'before_cursor_execute', _before_cursor_execute)\n    event.listen(engine, 'after_cursor_execute', _after_cursor_execute)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nintercepting low - level cursor execute events before execution.", "response": "def _before_cursor_execute(conn, cursor, statement, parameters,\n                           context, executemany):\n    \"\"\"Intercept low-level cursor execute() events before execution.\n    If executemany is True, this is an executemany call, else an execute call.\n\n    Note: If enabled tracing both SQLAlchemy and the database it connected,\n          the communication between SQLAlchemy and the database will also\n          be traced. To avoid the verbose spans, you can just trace SQLAlchemy.\n\n    See: http://docs.sqlalchemy.org/en/latest/core/events.html#sqlalchemy.\n         events.ConnectionEvents.before_cursor_execute\n    \"\"\"\n    # Find out the func name\n    if executemany:\n        query_func = 'executemany'\n    else:\n        query_func = 'execute'\n\n    _tracer = execution_context.get_opencensus_tracer()\n    _span = _tracer.start_span()\n    _span.name = '{}.query'.format(MODULE_NAME)\n    _span.span_kind = span_module.SpanKind.CLIENT\n\n    # Set query statement attribute\n    _tracer.add_attribute_to_current_span(\n        '{}.query'.format(MODULE_NAME), statement)\n\n    # Set query parameters attribute\n    _tracer.add_attribute_to_current_span(\n        '{}.query.parameters'.format(MODULE_NAME), str(parameters))\n\n    # Set query function attribute\n    _tracer.add_attribute_to_current_span(\n        '{}.cursor.method.name'.format(MODULE_NAME),\n        query_func)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nintercepts low - level cursor execute events after execution.", "response": "def _after_cursor_execute(conn, cursor, statement, parameters,\n                          context, executemany):\n    \"\"\"Intercept low-level cursor execute() events after execution.\n    If executemany is True, this is an executemany call, else an execute call.\n\n    See: http://docs.sqlalchemy.org/en/latest/core/events.html#sqlalchemy.\n         events.ConnectionEvents.after_cursor_execute\n    \"\"\"\n    _tracer = execution_context.get_opencensus_tracer()\n    _tracer.end_span()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef check_points_type(self, type_class):\n        for point in self.points:\n            if (point.value is not None\n                    and not isinstance(point.value, type_class)):\n                return False\n        return True", "response": "Check that each point s value is an instance of type_class."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the logging attributes from the opencensus context.", "response": "def get_log_attrs():\n    \"\"\"Get logging attributes from the opencensus context.\n\n    :rtype: :class:`LogAttrs`\n    :return: The current span's trace ID, span ID, and sampling decision.\n    \"\"\"\n    try:\n        tracer = execution_context.get_opencensus_tracer()\n        if tracer is None:\n            raise RuntimeError\n    except Exception:  # noqa\n        _meta_logger.error(\"Failed to get opencensus tracer\")\n        return ATTR_DEFAULTS\n\n    try:\n        trace_id = tracer.span_context.trace_id\n        if trace_id is None:\n            trace_id = ATTR_DEFAULTS.trace_id\n    except Exception:  # noqa\n        _meta_logger.error(\"Failed to get opencensus trace ID\")\n        trace_id = ATTR_DEFAULTS.trace_id\n\n    try:\n        span_id = tracer.span_context.span_id\n        if span_id is None:\n            span_id = ATTR_DEFAULTS.span_id\n    except Exception:  # noqa\n        _meta_logger.error(\"Failed to get opencensus span ID\")\n        span_id = ATTR_DEFAULTS.span_id\n\n    try:\n        sampling_decision = tracer.span_context.trace_options.get_enabled\n        if sampling_decision is None:\n            sampling_decision = ATTR_DEFAULTS.sampling_decision\n    except AttributeError:\n        sampling_decision = ATTR_DEFAULTS.sampling_decision\n    except Exception:  # noqa\n        _meta_logger.error(\"Failed to get opencensus sampling decision\")\n        sampling_decision = ATTR_DEFAULTS.sampling_decision\n\n    return LogAttrs(trace_id, span_id, sampling_decision)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntrace the Google Cloud Client libraries by integrating with the transport level including HTTP and gRPC.", "response": "def trace_integration(tracer=None):\n    \"\"\"Trace the Google Cloud Client libraries by integrating with\n    the transport level including HTTP and gRPC.\n    \"\"\"\n    log.info('Integrated module: {}'.format(MODULE_NAME))\n\n    # Integrate with gRPC\n    trace_grpc(tracer)\n\n    # Integrate with HTTP\n    trace_http(tracer)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef wrap_make_secure_channel(make_secure_channel_func, tracer=None):\n    def call(*args, **kwargs):\n        channel = make_secure_channel_func(*args, **kwargs)\n\n        try:\n            host = kwargs.get('host')\n            tracer_interceptor = OpenCensusClientInterceptor(tracer, host)\n            intercepted_channel = grpc.intercept_channel(\n                channel, tracer_interceptor)\n            return intercepted_channel  # pragma: NO COVER\n        except Exception:\n            log.warning(\n                'Failed to wrap secure channel, '\n                'clientlibs grpc calls not traced.')\n            return channel\n    return call", "response": "Wrap the google. cloud. _helpers. make_secure_channel function to intercept the channel."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef wrap_insecure_channel(insecure_channel_func, tracer=None):\n    def call(*args, **kwargs):\n        channel = insecure_channel_func(*args, **kwargs)\n\n        try:\n            target = kwargs.get('target')\n            tracer_interceptor = OpenCensusClientInterceptor(tracer, target)\n            intercepted_channel = grpc.intercept_channel(\n                channel, tracer_interceptor)\n            return intercepted_channel  # pragma: NO COVER\n        except Exception:\n            log.warning(\n                'Failed to wrap insecure channel, '\n                'clientlibs grpc calls not traced.')\n            return channel\n    return call", "response": "Wrap the grpc. insecure_channel function."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef wrap_create_channel(create_channel_func, tracer=None):\n    def call(*args, **kwargs):\n        channel = create_channel_func(*args, **kwargs)\n\n        try:\n            target = kwargs.get('target')\n            tracer_interceptor = OpenCensusClientInterceptor(tracer, target)\n            intercepted_channel = grpc.intercept_channel(\n                channel, tracer_interceptor)\n            return intercepted_channel  # pragma: NO COVER\n        except Exception:\n            log.warning(\n                'Failed to wrap create_channel, '\n                'clientlibs grpc calls not traced.')\n            return channel\n    return call", "response": "Wrap the google. api_core. grpc_helpers. create_channel function."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _convert_reftype_to_jaeger_reftype(ref):\n    if ref == link_module.Type.CHILD_LINKED_SPAN:\n        return jaeger.SpanRefType.CHILD_OF\n    if ref == link_module.Type.PARENT_LINKED_SPAN:\n        return jaeger.SpanRefType.FOLLOWS_FROM\n    return None", "response": "Convert opencensus reference types to jaeger reference types."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _convert_hex_str_to_int(val):\n    if val is None:\n        return None\n\n    hex_num = int(val, 16)\n    #  ensure it fits into 64-bit\n    if hex_num > 0x7FFFFFFFFFFFFFFF:\n        hex_num -= 0x10000000000000000\n\n    assert -9223372036854775808 <= hex_num <= 9223372036854775807\n    return hex_num", "response": "Convert hexadecimal formatted ids to signed int64"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts the attributes to jaeger tags.", "response": "def _convert_attribute_to_tag(key, attr):\n    \"\"\"Convert the attributes to jaeger tags.\"\"\"\n    if isinstance(attr, bool):\n        return jaeger.Tag(\n            key=key,\n            vBool=attr,\n            vType=jaeger.TagType.BOOL)\n    if isinstance(attr, str):\n        return jaeger.Tag(\n            key=key,\n            vStr=attr,\n            vType=jaeger.TagType.STRING)\n    if isinstance(attr, int):\n        return jaeger.Tag(\n            key=key,\n            vLong=attr,\n            vType=jaeger.TagType.LONG)\n    if isinstance(attr, float):\n        return jaeger.Tag(\n            key=key,\n            vDouble=attr,\n            vType=jaeger.TagType.DOUBLE)\n    logging.warn('Could not serialize attribute \\\n            {}:{} to tag'.format(key, attr))\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef emit(self, span_datas):\n        jaeger_spans = self.translate_to_jaeger(span_datas)\n\n        batch = jaeger.Batch(\n            spans=jaeger_spans,\n            process=jaeger.Process(serviceName=self.service_name))\n\n        if self.collector is not None:\n            self.collector.export(batch)\n        self.agent_client.export(batch)", "response": "Emits the given list of SpanData tuples to the agent."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef translate_to_jaeger(self, span_datas):\n\n        top_span = span_datas[0]\n\n        trace_id = top_span.context.trace_id if top_span.context is not None \\\n            else None\n\n        jaeger_spans = []\n\n        for span in span_datas:\n            start_timestamp_ms = timestamp_to_microseconds(span.start_time)\n            end_timestamp_ms = timestamp_to_microseconds(span.end_time)\n            duration_ms = end_timestamp_ms - start_timestamp_ms\n\n            tags = _extract_tags(span.attributes)\n\n            status = span.status\n            if status is not None:\n                tags.append(jaeger.Tag(\n                    key='status.code',\n                    vType=jaeger.TagType.LONG,\n                    vLong=status.code))\n\n                tags.append(jaeger.Tag(\n                    key='status.message',\n                    vType=jaeger.TagType.STRING,\n                    vStr=status.message))\n\n            refs = _extract_refs_from_span(span)\n            logs = _extract_logs_from_span(span)\n\n            context = span.context\n            flags = None\n            if context is not None:\n                flags = int(context.trace_options.trace_options_byte)\n\n            span_id = span.span_id\n            parent_span_id = span.parent_span_id\n\n            jaeger_span = jaeger.Span(\n                traceIdHigh=_convert_hex_str_to_int(trace_id[0:16]),\n                traceIdLow=_convert_hex_str_to_int(trace_id[16:32]),\n                spanId=_convert_hex_str_to_int(span_id),\n                operationName=span.name,\n                startTime=int(round(start_timestamp_ms)),\n                duration=int(round(duration_ms)),\n                tags=tags,\n                logs=logs,\n                references=refs,\n                flags=flags,\n                parentSpanId=_convert_hex_str_to_int(parent_span_id or '0'))\n\n            jaeger_spans.append(jaeger_span)\n\n        return jaeger_spans", "response": "Translate the spans to Jaeger format."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsubmit batches to Thrift HTTP Server through Binary Protocol.", "response": "def emit(self, batch):\n        \"\"\"Submits batches to Thrift HTTP Server through Binary Protocol.\n\n        :type batch:\n            :class:`~opencensus.ext.jaeger.trace_exporter.gen.jaeger.Batch`\n        :param batch: Object to emit Jaeger spans.\n        \"\"\"\n        try:\n            self.client.submitBatches([batch])\n            # it will call http_transport.flush() and\n            # status code and message will be updated\n            code = self.http_transport.code\n            msg = self.http_transport.message\n            if code >= 300 or code < 200:\n                logging.error(\"Traces cannot be uploaded;\\\n                        HTTP status code: {}, message {}\".format(code, msg))\n        except Exception as e:  # pragma: NO COVER\n            logging.error(getattr(e, 'message', e))\n\n        finally:\n            if self.http_transport.isOpen():\n                self.http_transport.close()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nemit a batch of Jaeger spans.", "response": "def emit(self, batch):\n        \"\"\"\n        :type batch:\n            :class:`~opencensus.ext.jaeger.trace_exporter.gen.jaeger.Batch`\n        :param batch: Object to emit Jaeger spans.\n        \"\"\"\n        udp_socket = None\n        try:\n            self.client._seqid = 0\n            #  truncate and reset the position of BytesIO object\n            self.buffer._buffer.truncate(0)\n            self.buffer._buffer.seek(0)\n            self.client.emitBatch(batch)\n            buff = self.buffer.getvalue()\n            if len(buff) > self.max_packet_size:\n                logging.warn('Data exceeds the max UDP packet size; size {},\\\n                        max {}'.format(len(buff), self.max_packet_size))\n            else:\n                udp_socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n                udp_socket.sendto(buff, self.address)\n\n        except Exception as e:  # pragma: NO COVER\n            logging.error(getattr(e, 'message', e))\n\n        finally:\n            if udp_socket is not None:\n                udp_socket.close()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfunctioning to get the tag values from tags and columns", "response": "def get_tag_values(self, tags, columns):\n        \"\"\"function to get the tag values from tags and columns\"\"\"\n        tag_values = []\n        i = 0\n        while i < len(columns):\n            tag_key = columns[i]\n            if tag_key in tags:\n                tag_values.append(tags.get(tag_key))\n            else:\n                tag_values.append(None)\n            i += 1\n        return tag_values"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef record(self, context, value, timestamp, attachments=None):\n        if context is None:\n            tags = dict()\n        else:\n            tags = context.map\n        tag_values = self.get_tag_values(tags=tags,\n                                         columns=self.view.columns)\n        tuple_vals = tuple(tag_values)\n        if tuple_vals not in self.tag_value_aggregation_data_map:\n            self.tag_value_aggregation_data_map[tuple_vals] = copy.deepcopy(\n                self.view.aggregation.aggregation_data)\n        self.tag_value_aggregation_data_map.get(tuple_vals).\\\n            add_sample(value, timestamp, attachments)", "response": "records the view data against a specific context"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef trace_integration(tracer=None):\n    log.info('Integrated module: {}'.format(MODULE_NAME))\n\n    # Wrap the httplib request function\n    request_func = getattr(\n        httplib.HTTPConnection, HTTPLIB_REQUEST_FUNC)\n    wrapped_request = wrap_httplib_request(request_func)\n    setattr(httplib.HTTPConnection, request_func.__name__, wrapped_request)\n\n    # Wrap the httplib response function\n    response_func = getattr(\n        httplib.HTTPConnection, HTTPLIB_RESPONSE_FUNC)\n    wrapped_response = wrap_httplib_response(response_func)\n    setattr(httplib.HTTPConnection, response_func.__name__, wrapped_response)", "response": "Wrap the httplib to trace."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef wrap_httplib_request(request_func):\n\n    def call(self, method, url, body, headers, *args, **kwargs):\n        _tracer = execution_context.get_opencensus_tracer()\n        blacklist_hostnames = execution_context.get_opencensus_attr(\n            'blacklist_hostnames')\n        dest_url = '{}:{}'.format(self._dns_host, self.port)\n        if utils.disable_tracing_hostname(dest_url, blacklist_hostnames):\n            return request_func(self, method, url, body,\n                                headers, *args, **kwargs)\n        _span = _tracer.start_span()\n        _span.span_kind = span_module.SpanKind.CLIENT\n        _span.name = '[httplib]{}'.format(request_func.__name__)\n\n        # Add the request url to attributes\n        _tracer.add_attribute_to_current_span(HTTP_URL, url)\n\n        # Add the request method to attributes\n        _tracer.add_attribute_to_current_span(HTTP_METHOD, method)\n\n        # Store the current span id to thread local.\n        execution_context.set_opencensus_attr(\n            'httplib/current_span_id', _span.span_id)\n        try:\n            headers = headers.copy()\n            headers.update(_tracer.propagator.to_headers(\n                _span.context_tracer.span_context))\n        except Exception:  # pragma: NO COVER\n            pass\n        return request_func(self, method, url, body, headers, *args, **kwargs)\n\n    return call", "response": "Wrap the httplib request function to trace. Create a new span and update the response later."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwrapping the httplib response function to trace.", "response": "def wrap_httplib_response(response_func):\n    \"\"\"Wrap the httplib response function to trace.\n\n    If there is a corresponding httplib request span, update and close it.\n    If not, return the response.\n    \"\"\"\n\n    def call(self, *args, **kwargs):\n        _tracer = execution_context.get_opencensus_tracer()\n        current_span_id = execution_context.get_opencensus_attr(\n            'httplib/current_span_id')\n\n        span = _tracer.current_span()\n\n        # No corresponding request span is found, request not traced.\n        if not span or span.span_id != current_span_id:\n            return response_func(self, *args, **kwargs)\n\n        result = response_func(self, *args, **kwargs)\n\n        # Add the status code to attributes\n        _tracer.add_attribute_to_current_span(\n            HTTP_STATUS_CODE, str(result.status))\n\n        _tracer.end_span()\n        return result\n\n    return call"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert a list of GaugePoint s into a list of TimeSeries.", "response": "def get_timeseries_list(points, timestamp):\n    \"\"\"Convert a list of `GaugePoint`s into a list of `TimeSeries`.\n\n    Get a :class:`opencensus.metrics.export.time_series.TimeSeries` for each\n    measurement in `points`. Each series contains a single\n    :class:`opencensus.metrics.export.point.Point` that represents the last\n    recorded value of the measurement.\n\n    :type points: list(:class:`GaugePoint`)\n    :param points: The list of measurements to convert.\n\n    :type timestamp: :class:`datetime.datetime`\n    :param timestamp: Recording time to report, usually the current time.\n\n    :rtype: list(:class:`opencensus.metrics.export.time_series.TimeSeries`)\n    :return: A list of one `TimeSeries` for each point in `points`.\n    \"\"\"\n    ts_list = []\n    for lv, gp in points.items():\n        point = point_module.Point(gp.to_point_value(), timestamp)\n        ts_list.append(time_series.TimeSeries(lv, [point], timestamp))\n    return ts_list"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd val to the current value.", "response": "def add(self, val):\n        \"\"\"Add `val` to the current value.\n\n        :type val: int\n        :param val: Value to add.\n        \"\"\"\n        if not isinstance(val, six.integer_types):\n            raise ValueError(\"GaugePointLong only supports integer types\")\n        with self._value_lock:\n            self.value += val"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the current value of the wrapped function and stores the value in the wrapped function.", "response": "def get_value(self):\n        \"\"\"Get the current value of the underlying measurement.\n\n        Calls the tracked function and stores the value in the wrapped\n        measurement as a side-effect.\n\n        :rtype: int, float, or None\n        :return: The current value of the wrapped function, or `None` if it no\n            longer exists.\n        \"\"\"\n        try:\n            val = self.func()()\n        except TypeError:  # The underlying function has been GC'd\n            return None\n\n        self.gauge_point._set(val)\n        return self.gauge_point.get_value()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove the time series for specific label values.", "response": "def remove_time_series(self, label_values):\n        \"\"\"Remove the time series for specific label values.\n\n        :type label_values: list(:class:`LabelValue`)\n        :param label_values: Label values of the time series to remove.\n        \"\"\"\n        if label_values is None:\n            raise ValueError\n        if any(lv is None for lv in label_values):\n            raise ValueError\n        if len(label_values) != self._len_label_keys:\n            raise ValueError\n        self._remove_time_series(label_values)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_metric(self, timestamp):\n        if not self.points:\n            return None\n\n        with self._points_lock:\n            ts_list = get_timeseries_list(self.points, timestamp)\n        return metric.Metric(self.descriptor, ts_list)", "response": "Get a metric including all current time series."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget a mutable measurement for the given set of label values.", "response": "def get_or_create_time_series(self, label_values):\n        \"\"\"Get a mutable measurement for the given set of label values.\n\n        :type label_values: list(:class:`LabelValue`)\n        :param label_values: The measurement's label values.\n\n        :rtype: :class:`GaugePointLong`, :class:`GaugePointDouble`\n            :class:`opencensus.metrics.export.cumulative.CumulativePointLong`,\n            or\n            :class:`opencensus.metrics.export.cumulative.CumulativePointDouble`\n        :return: A mutable point that represents the last value of the\n            measurement.\n        \"\"\"\n        if label_values is None:\n            raise ValueError\n        if any(lv is None for lv in label_values):\n            raise ValueError\n        if len(label_values) != self._len_label_keys:\n            raise ValueError\n        return self._get_or_create_time_series(label_values)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a derived measurement to trac func.", "response": "def create_time_series(self, label_values, func):\n        \"\"\"Create a derived measurement to trac `func`.\n\n        :type label_values: list(:class:`LabelValue`)\n        :param label_values: The measurement's label values.\n\n        :type func: function\n        :param func: The function to track.\n\n        :rtype: :class:`DerivedGaugePoint`\n        :return: A read-only measurement that tracks `func`.\n        \"\"\"\n        if label_values is None:\n            raise ValueError\n        if any(lv is None for lv in label_values):\n            raise ValueError\n        if len(label_values) != self._len_label_keys:\n            raise ValueError\n        if func is None:\n            raise ValueError\n        return self._create_time_series(label_values, func)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates the default derived measurement for this gauge.", "response": "def create_default_time_series(self, func):\n        \"\"\"Create the default derived measurement for this gauge.\n\n        :type func: function\n        :param func: The function to track.\n\n        :rtype: :class:`DerivedGaugePoint`\n        :return: A read-only measurement that tracks `func`.\n        \"\"\"\n        if func is None:\n            raise ValueError\n        return self._create_time_series(self.default_label_values, func)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_gauge(self, gauge):\n        if gauge is None:\n            raise ValueError\n        name = gauge.descriptor.name\n        with self._gauges_lock:\n            if name in self.gauges:\n                raise ValueError(\n                    'Another gauge named \"{}\" is already registered'\n                    .format(name))\n            self.gauges[name] = gauge", "response": "Adds a gauge to the registry. Raises a ValueError if another gauge with the same name already exists in the registry."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_metrics(self):\n        now = datetime.utcnow()\n        metrics = set()\n        for gauge in self.gauges.values():\n            metrics.add(gauge.get_metric(now))\n        return metrics", "response": "Get a metric for each gauge in the registry at the current time."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ninitializing metadata service once and load gcp metadata into map", "response": "def _initialize_metadata_service(cls):\n        \"\"\"Initialize metadata service once and load gcp metadata into map\n        This method should only be called once.\n        \"\"\"\n        if cls.inited:\n            return\n\n        instance_id = cls.get_attribute('instance/id')\n\n        if instance_id is not None:\n            cls.is_running = True\n\n            _GCP_METADATA_MAP['instance_id'] = instance_id\n\n            # fetch attributes from metadata request\n            for attribute_key, attribute_uri in _GCE_ATTRIBUTES.items():\n                if attribute_key not in _GCP_METADATA_MAP:\n                    attribute_value = cls.get_attribute(attribute_uri)\n                    if attribute_value is not None:  # pragma: NO COVER\n                        _GCP_METADATA_MAP[attribute_key] = attribute_value\n\n        cls.inited = True"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfetch the requested instance metadata entry.", "response": "def get_attribute(attribute_uri):\n        \"\"\"\n        Fetch the requested instance metadata entry.\n        :param attribute_uri: attribute_uri: attribute name relative to the\n        computeMetadata/v1 prefix\n        :return:  The value read from the metadata service or None\n        \"\"\"\n        attribute_value = get_request(_GCP_METADATA_URI + attribute_uri,\n                                      _GCP_METADATA_URI_HEADER)\n\n        if attribute_value is not None and isinstance(attribute_value, bytes):\n            # At least in python3, bytes are are returned from\n            # urllib (although the response is text), convert\n            # to a normal string:\n            attribute_value = attribute_value.decode('utf-8')\n\n        transformation = _ATTRIBUTE_URI_TRANSFORMATIONS.get(attribute_uri)\n        if transformation is not None:\n            attribute_value = transformation(attribute_value)\n\n        return attribute_value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_header(self, binary):\n        # If no binary provided, generate a new SpanContext\n        if binary is None:\n            return span_context_module.SpanContext(from_header=False)\n\n        # If cannot parse, return a new SpanContext and ignore the context\n        # from binary.\n        try:\n            data = Header._make(struct.unpack(BINARY_FORMAT, binary))\n        except struct.error:\n            logging.warning(\n                'Cannot parse the incoming binary data {}, '\n                'wrong format. Total bytes length should be {}.'.format(\n                    binary, FORMAT_LENGTH\n                )\n            )\n            return span_context_module.SpanContext(from_header=False)\n\n        # data.trace_id is in bytes with length 16, hexlify it to hex bytes\n        # with length 32, then decode it to hex string using utf-8.\n        trace_id = str(binascii.hexlify(data.trace_id).decode(UTF8))\n        span_id = str(binascii.hexlify(data.span_id).decode(UTF8))\n        trace_options = TraceOptions(data.trace_option)\n\n        span_context = span_context_module.SpanContext(\n                trace_id=trace_id,\n                span_id=span_id,\n                trace_options=trace_options,\n                from_header=True)\n\n        return span_context", "response": "Generate a SpanContext object from the binary data extracted from the trace context header."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_header(self, span_context):\n        trace_id = span_context.trace_id\n        span_id = span_context.span_id\n        trace_options = int(span_context.trace_options.trace_options_byte)\n\n        # If there is no span_id in this context, set it to 0, which is\n        # considered invalid and won't be set as the downstream parent span_id.\n        if span_id is None:\n            span_id = span_context_module.INVALID_SPAN_ID\n\n        # Convert trace_id to bytes with length 16, treat span_id as 64 bit\n        # integer which is unsigned long long type and convert it to bytes with\n        # length 8, trace_option is integer with length 1.\n        return struct.pack(\n            BINARY_FORMAT,\n            VERSION_ID,\n            TRACE_ID_FIELD_ID,\n            binascii.unhexlify(trace_id),\n            SPAN_ID_FIELD_ID,\n            binascii.unhexlify(span_id),\n            TRACE_OPTION_FIELD_ID,\n            trace_options)", "response": "Convert a SpanContext object to binary format."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating a SpanContext object from the information in the carrier.", "response": "def from_carrier(self, carrier):\n        \"\"\"Generate a SpanContext object using the information in the carrier.\n\n        :type carrier: dict\n        :param carrier: The carrier which has the trace_id, span_id, options\n                        information for creating a SpanContext.\n\n        :rtype: :class:`~opencensus.trace.span_context.SpanContext`\n        :returns: SpanContext generated from the carrier.\n        \"\"\"\n        trace_id = None\n        span_id = None\n        trace_options = None\n\n        for key in carrier:\n            key = key.lower()\n            if key == _TRACE_ID_KEY:\n                trace_id = carrier[key]\n            if key == _SPAN_ID_KEY:\n                span_id = carrier[key]\n            if key == _TRACE_OPTIONS_KEY:\n                trace_options = bool(carrier[key])\n\n        if trace_options is None:\n            trace_options = DEFAULT_TRACE_OPTIONS\n\n        return SpanContext(\n            trace_id=trace_id,\n            span_id=span_id,\n            trace_options=TraceOptions(trace_options),\n            from_header=True)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef to_carrier(self, span_context, carrier):\n        carrier[_TRACE_ID_KEY] = str(span_context.trace_id)\n\n        if span_context.span_id is not None:\n            carrier[_SPAN_ID_KEY] = str(span_context.span_id)\n\n        carrier[_TRACE_OPTIONS_KEY] = str(\n            span_context.trace_options.trace_options_byte)\n\n        return carrier", "response": "Inject the SpanContext fields to carrier dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates a SpanContext object from HTTP request headers.", "response": "def from_headers(self, headers):\n        \"\"\"Generate a SpanContext object from B3 propagation headers.\n\n        :type headers: dict\n        :param headers: HTTP request headers.\n\n        :rtype: :class:`~opencensus.trace.span_context.SpanContext`\n        :returns: SpanContext generated from B3 propagation headers.\n        \"\"\"\n        if headers is None:\n            return SpanContext(from_header=False)\n\n        trace_id, span_id, sampled = None, None, None\n\n        state = headers.get(_STATE_HEADER_KEY)\n        if state:\n            fields = state.split('-', 4)\n\n            if len(fields) == 1:\n                sampled = fields[0]\n            elif len(fields) == 2:\n                trace_id, span_id = fields\n            elif len(fields) == 3:\n                trace_id, span_id, sampled = fields\n            elif len(fields) == 4:\n                trace_id, span_id, sampled, _parent_span_id = fields\n            else:\n                return SpanContext(from_header=False)\n        else:\n            trace_id = headers.get(_TRACE_ID_KEY)\n            span_id = headers.get(_SPAN_ID_KEY)\n            sampled = headers.get(_SAMPLED_KEY)\n\n        if sampled is not None:\n            # The specification encodes an enabled tracing decision as \"1\".\n            # In the wild pre-standard implementations might still send \"true\".\n            # \"d\" is set in the single header case when debugging is enabled.\n            sampled = sampled.lower() in ('1', 'd', 'true')\n        else:\n            # If there's no incoming sampling decision, it was deferred to us.\n            # Even though we set it to False here, we might still sample\n            # depending on the tracer configuration.\n            sampled = False\n\n        trace_options = TraceOptions()\n        trace_options.set_enabled(sampled)\n\n        # TraceId and SpanId headers both have to exist\n        if not trace_id or not span_id:\n            return SpanContext(trace_options=trace_options)\n\n        # Convert 64-bit trace ids to 128-bit\n        if len(trace_id) == 16:\n            trace_id = '0'*16 + trace_id\n\n        span_context = SpanContext(\n            trace_id=trace_id,\n            span_id=span_id,\n            trace_options=trace_options,\n            from_header=True\n        )\n\n        return span_context"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_headers(self, span_context):\n\n        if not span_context.span_id:\n            span_id = INVALID_SPAN_ID\n        else:\n            span_id = span_context.span_id\n\n        sampled = span_context.trace_options.enabled\n\n        return {\n            _TRACE_ID_KEY: span_context.trace_id,\n            _SPAN_ID_KEY: span_id,\n            _SAMPLED_KEY: '1' if sampled else '0'\n        }", "response": "Convert a SpanContext object to B3 propagation headers."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck the format of the span_id to ensure it is 16 - character hexagonal and returns the Span_id.", "response": "def _check_span_id(self, span_id):\n        \"\"\"Check the format of the span_id to ensure it is 16-character hex\n        value representing a 64-bit number. If span_id is invalid, logs a\n        warning message and returns None\n\n        :type span_id: str\n        :param span_id: Identifier for the span, unique within a span.\n\n        :rtype: str\n        :returns: Span_id for the current span.\n        \"\"\"\n        if span_id is None:\n            return None\n        assert isinstance(span_id, six.string_types)\n\n        if span_id is INVALID_SPAN_ID:\n            logging.warning(\n                'Span_id {} is invalid (cannot be all zero)'.format(span_id))\n            self.from_header = False\n            return None\n\n        match = SPAN_ID_PATTERN.match(span_id)\n\n        if match:\n            return span_id\n        else:\n            logging.warning(\n                'Span_id {} does not the match the '\n                'required format'.format(span_id))\n            self.from_header = False\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck the format of the trace_id to ensure it is 32 - character hexagonal and returns a random trace id.", "response": "def _check_trace_id(self, trace_id):\n        \"\"\"Check the format of the trace_id to ensure it is 32-character hex\n        value representing a 128-bit number. If trace_id is invalid, returns a\n        randomly generated trace id\n\n        :type trace_id: str\n        :param trace_id:\n\n        :rtype: str\n        :returns: Trace_id for the current context.\n        \"\"\"\n        assert isinstance(trace_id, six.string_types)\n\n        if trace_id is _INVALID_TRACE_ID:\n            logging.warning(\n                'Trace_id {} is invalid (cannot be all zero), '\n                'generating a new one.'.format(trace_id))\n            self.from_header = False\n            return generate_trace_id()\n\n        match = TRACE_ID_PATTERN.match(trace_id)\n\n        if match:\n            return trace_id\n        else:\n            logging.warning(\n                'Trace_id {} does not the match the required format,'\n                'generating a new one instead.'.format(trace_id))\n            self.from_header = False\n            return generate_trace_id()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nstarts a span. :type name: str :param name: The name of the span. :rtype: :class:`~opencensus.trace.trace_span.Span` :returns: The Span object.", "response": "def start_span(self, name='span'):\n        \"\"\"Start a span.\n\n        :type name: str\n        :param name: The name of the span.\n\n        :rtype: :class:`~opencensus.trace.trace_span.Span`\n        :returns: The Span object.\n        \"\"\"\n        span = trace_span.BlankSpan(name, context_tracer=self)\n        return span"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert a Status object to json format.", "response": "def format_status_json(self):\n        \"\"\"Convert a Status object to json format.\"\"\"\n        status_json = {}\n\n        status_json['code'] = self.code\n        status_json['message'] = self.message\n\n        if self.details is not None:\n            status_json['details'] = self.details\n\n        return status_json"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate a SpanContext object from the HTTP request headers.", "response": "def from_headers(self, headers):\n        \"\"\"Generate a SpanContext object using the W3C Distributed Tracing headers.\n\n        :type headers: dict\n        :param headers: HTTP request headers.\n\n        :rtype: :class:`~opencensus.trace.span_context.SpanContext`\n        :returns: SpanContext generated from the trace context header.\n        \"\"\"\n        if headers is None:\n            return SpanContext()\n\n        header = headers.get(_TRACEPARENT_HEADER_NAME)\n        if header is None:\n            return SpanContext()\n\n        match = re.search(_TRACEPARENT_HEADER_FORMAT_RE, header)\n        if not match:\n            return SpanContext()\n\n        version = match.group(1)\n        trace_id = match.group(2)\n        span_id = match.group(3)\n        trace_options = match.group(4)\n\n        if trace_id == '0' * 32 or span_id == '0' * 16:\n            return SpanContext()\n\n        if version == '00':\n            if match.group(5):\n                return SpanContext()\n        if version == 'ff':\n            return SpanContext()\n\n        span_context = SpanContext(\n            trace_id=trace_id,\n            span_id=span_id,\n            trace_options=TraceOptions(trace_options),\n            from_header=True)\n\n        header = headers.get(_TRACESTATE_HEADER_NAME)\n        if header is None:\n            return span_context\n        try:\n            tracestate = TracestateStringFormatter().from_string(header)\n            if tracestate.is_valid():\n                span_context.tracestate = \\\n                    TracestateStringFormatter().from_string(header)\n        except ValueError:\n            pass\n        return span_context"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef to_headers(self, span_context):\n        trace_id = span_context.trace_id\n        span_id = span_context.span_id\n        trace_options = span_context.trace_options.enabled\n\n        # Convert the trace options\n        trace_options = '01' if trace_options else '00'\n\n        headers = {\n            _TRACEPARENT_HEADER_NAME: '00-{}-{}-{}'.format(\n                trace_id,\n                span_id,\n                trace_options\n            ),\n        }\n        tracestate = span_context.tracestate\n        if tracestate:\n            headers[_TRACESTATE_HEADER_NAME] = \\\n                TracestateStringFormatter().to_string(tracestate)\n        return headers", "response": "Convert a SpanContext object to W3C Distributed Tracing headers."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_truncatable_str(str_to_convert):\n    truncated, truncated_byte_count = check_str_length(\n        str_to_convert, MAX_LENGTH)\n\n    result = {\n        'value': truncated,\n        'truncated_byte_count': truncated_byte_count,\n    }\n    return result", "response": "Truncate a string if exceed limit and record the truncated bytes\n    count."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef check_str_length(str_to_check, limit=MAX_LENGTH):\n    str_bytes = str_to_check.encode(UTF8)\n    str_len = len(str_bytes)\n    truncated_byte_count = 0\n\n    if str_len > limit:\n        truncated_byte_count = str_len - limit\n        str_bytes = str_bytes[:limit]\n\n    result = str(str_bytes.decode(UTF8, errors='ignore'))\n\n    return (result, truncated_byte_count)", "response": "Checks the length of a string. If exceeded limit truncate it."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting a timestamp string into a microseconds value", "response": "def timestamp_to_microseconds(timestamp):\n    \"\"\"Convert a timestamp string into a microseconds value\n    :param timestamp\n    :return time in microseconds\n    \"\"\"\n    timestamp_str = datetime.datetime.strptime(timestamp, ISO_DATETIME_REGEX)\n    epoch_time_secs = calendar.timegm(timestamp_str.timetuple())\n    epoch_time_mus = epoch_time_secs * 1e6 + timestamp_str.microsecond\n    return epoch_time_mus"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget an iterator over unique items of ible.", "response": "def iuniq(ible):\n    \"\"\"Get an iterator over unique items of `ible`.\"\"\"\n    items = set()\n    for item in ible:\n        if item not in items:\n            items.add(item)\n            yield item"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsplitting ible into multiple lists of length length.", "response": "def window(ible, length):\n    \"\"\"Split `ible` into multiple lists of length `length`.\n\n    >>> list(window(range(5), 2))\n    [[0, 1], [2, 3], [4]]\n    \"\"\"\n    if length <= 0:  # pragma: NO COVER\n        raise ValueError\n    ible = iter(ible)\n    while True:\n        elts = [xx for ii, xx in zip(range(length), ible)]\n        if elts:\n            yield elts\n        else:\n            break"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget a weak reference to bound or unbound func.", "response": "def get_weakref(func):\n    \"\"\"Get a weak reference to bound or unbound `func`.\n\n    If `func` is unbound (i.e. has no __self__ attr) get a weakref.ref,\n    otherwise get a wrapper that simulates weakref.ref.\n    \"\"\"\n    if func is None:\n        raise ValueError\n    if not hasattr(func, '__self__'):\n        return weakref.ref(func)\n    return WeakMethod(func)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwrapping the mysql conn object with TraceConnection.", "response": "def wrap_conn(conn_func):\n    \"\"\"Wrap the mysql conn object with TraceConnection.\"\"\"\n    def call(*args, **kwargs):\n        try:\n            conn = conn_func(*args, **kwargs)\n            cursor_func = getattr(conn, CURSOR_WRAP_METHOD)\n            wrapped = wrap_cursor(cursor_func)\n            setattr(conn, cursor_func.__name__, wrapped)\n            return conn\n        except Exception:  # pragma: NO COVER\n            logging.warning('Fail to wrap conn, mysql not traced.')\n            return conn_func(*args, **kwargs)\n    return call"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef measure_int_put(self, measure, value):\n        if value < 0:\n            # Should be an error in a later release.\n            logger.warning(\"Cannot record negative values\")\n        self._measurement_map[measure] = value", "response": "associates the measure of type Int with the given value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nassociate the measure of type Float with the given value", "response": "def measure_float_put(self, measure, value):\n        \"\"\"associates the measure of type Float with the given value\"\"\"\n        if value < 0:\n            # Should be an error in a later release.\n            logger.warning(\"Cannot record negative values\")\n        self._measurement_map[measure] = value"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef measure_put_attachment(self, key, value):\n        if self._attachments is None:\n            self._attachments = dict()\n\n        if key is None or not isinstance(key, str):\n            raise TypeError('attachment key should not be '\n                            'empty and should be a string')\n        if value is None or not isinstance(value, str):\n            raise TypeError('attachment value should not be '\n                            'empty and should be a string')\n\n        self._attachments[key] = value", "response": "Associate the contextual information of an Exemplar to this MeasureMap\n            Contextual information is represented as key - value string pairs."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nrecords all the measurements at the same time with a tag_map.", "response": "def record(self, tags=None):\n        \"\"\"records all the measures at the same time with a tag_map.\n        tag_map could either be explicitly passed to the method, or implicitly\n        read from current runtime context.\n        \"\"\"\n        if tags is None:\n            tags = TagContext.get()\n        if self._invalid:\n            logger.warning(\"Measurement map has included negative value \"\n                           \"measurements, refusing to record\")\n            return\n        for measure, value in self.measurement_map.items():\n            if value < 0:\n                self._invalid = True\n                logger.warning(\"Dropping values, value to record must be \"\n                               \"non-negative\")\n                logger.info(\"Measure '{}' has negative value ({}), refusing \"\n                            \"to record measurements from {}\"\n                            .format(measure.name, value, self))\n                return\n\n        self.measure_to_view_map.record(\n                tags=tags,\n                measurement_map=self.measurement_map,\n                timestamp=utils.to_iso_str(),\n                attachments=self.attachments\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a child span for the current span and append it to the child_spans list.", "response": "def span(self, name='child_span'):\n        \"\"\"Create a child span for the current span and append it to the child\n        spans list.\n\n        :type name: str\n        :param name: (Optional) The name of the child span.\n\n        :rtype: :class: `~opencensus.trace.blankspan.BlankSpan`\n        :returns: A child Span to be added to the current span.\n        \"\"\"\n        child_span = BlankSpan(name, parent_span=self)\n        self._child_spans.append(child_span)\n        return child_span"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef translate_to_trace_proto(span_data):\n\n    if not span_data:\n        return None\n\n    pb_span = trace_pb2.Span(\n        name=trace_pb2.TruncatableString(value=span_data.name),\n        kind=span_data.span_kind,\n        trace_id=hex_str_to_bytes_str(span_data.context.trace_id),\n        span_id=hex_str_to_bytes_str(span_data.span_id),\n        parent_span_id=hex_str_to_bytes_str(span_data.parent_span_id)\n        if span_data.parent_span_id is not None else None,\n        start_time=ocagent_utils.proto_ts_from_datetime_str(\n            span_data.start_time),\n        end_time=ocagent_utils.proto_ts_from_datetime_str(span_data.end_time),\n        status=trace_pb2.Status(\n            code=span_data.status.code,\n            message=span_data.status.message)\n        if span_data.status is not None else None,\n        same_process_as_parent_span=BoolValue(\n            value=span_data.same_process_as_parent_span)\n        if span_data.same_process_as_parent_span is not None\n        else None,\n        child_span_count=UInt32Value(value=span_data.child_span_count)\n        if span_data.child_span_count is not None else None)\n\n    # attributes\n    if span_data.attributes is not None:\n        for attribute_key, attribute_value \\\n                in span_data.attributes.items():\n            add_proto_attribute_value(\n                pb_span.attributes,\n                attribute_key,\n                attribute_value)\n\n    # time events\n    if span_data.time_events is not None:\n        for span_data_event in span_data.time_events:\n            if span_data_event.message_event is not None:\n                pb_event = pb_span.time_events.time_event.add()\n                pb_event.time.FromJsonString(span_data_event.timestamp)\n                set_proto_message_event(\n                    pb_event.message_event,\n                    span_data_event.message_event)\n            elif span_data_event.annotation is not None:\n                pb_event = pb_span.time_events.time_event.add()\n                pb_event.time.FromJsonString(span_data_event.timestamp)\n                set_proto_annotation(\n                    pb_event.annotation,\n                    span_data_event.annotation)\n\n    # links\n    if span_data.links is not None:\n        for link in span_data.links:\n            pb_link = pb_span.links.link.add(\n                trace_id=hex_str_to_bytes_str(link.trace_id),\n                span_id=hex_str_to_bytes_str(link.span_id),\n                type=link.type)\n\n            if link.attributes is not None and \\\n                    link.attributes.attributes is not None:\n                for attribute_key, attribute_value \\\n                        in link.attributes.attributes.items():\n                    add_proto_attribute_value(\n                        pb_link.attributes,\n                        attribute_key,\n                        attribute_value)\n\n    # tracestate\n    if span_data.context.tracestate is not None:\n        for (key, value) in span_data.context.tracestate.items():\n            pb_span.tracestate.entries.add(key=key, value=value)\n\n    return pb_span", "response": "Translates the opencensus spans to protobuf spans."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_proto_message_event(\n        pb_message_event,\n        span_data_message_event):\n    \"\"\"Sets properties on the protobuf message event.\n\n    :type pb_message_event:\n        :class: `~opencensus.proto.trace.Span.TimeEvent.MessageEvent`\n    :param pb_message_event: protobuf message event\n\n    :type span_data_message_event:\n        :class: `~opencensus.trace.time_event.MessageEvent`\n    :param span_data_message_event: opencensus message event\n    \"\"\"\n\n    pb_message_event.type = span_data_message_event.type\n    pb_message_event.id = span_data_message_event.id\n    pb_message_event.uncompressed_size = \\\n        span_data_message_event.uncompressed_size_bytes\n    pb_message_event.compressed_size = \\\n        span_data_message_event.compressed_size_bytes", "response": "Sets the properties on the protobuf message event."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets properties on the protobuf Span annotation.", "response": "def set_proto_annotation(pb_annotation, span_data_annotation):\n    \"\"\"Sets properties on the protobuf Span annotation.\n\n    :type pb_annotation:\n        :class: `~opencensus.proto.trace.Span.TimeEvent.Annotation`\n    :param pb_annotation: protobuf annotation\n\n    :type span_data_annotation:\n        :class: `~opencensus.trace.time_event.Annotation`\n    :param span_data_annotation: opencensus annotation\n\n    \"\"\"\n\n    pb_annotation.description.value = span_data_annotation.description\n    if span_data_annotation.attributes is not None \\\n            and span_data_annotation.attributes.attributes is not None:\n        for attribute_key, attribute_value in \\\n                span_data_annotation.attributes.attributes.items():\n            add_proto_attribute_value(\n                pb_annotation.attributes,\n                attribute_key,\n                attribute_value)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd the value of the protobuf attribute to the internal list of the available attributes.", "response": "def add_proto_attribute_value(\n        pb_attributes,\n        attribute_key,\n        attribute_value):\n    \"\"\"Sets string, int, boolean or float value on protobuf\n        span, link or annotation attributes.\n\n    :type pb_attributes:\n        :class: `~opencensus.proto.trace.Span.Attributes`\n    :param pb_attributes: protobuf Span's attributes property\n\n    :type attribute_key: str\n    :param attribute_key: attribute key to set\n\n    :type attribute_value: str or int or bool or float\n    :param attribute_value: attribute value\n    \"\"\"\n\n    if isinstance(attribute_value, bool):\n        pb_attributes.attribute_map[attribute_key].\\\n            bool_value = attribute_value\n    elif isinstance(attribute_value, int):\n        pb_attributes.attribute_map[attribute_key].\\\n            int_value = attribute_value\n    elif isinstance(attribute_value, str):\n        pb_attributes.attribute_map[attribute_key].\\\n            string_value.value = attribute_value\n    elif isinstance(attribute_value, float):\n        pb_attributes.attribute_map[attribute_key].\\\n            double_value = attribute_value\n    else:\n        pb_attributes.attribute_map[attribute_key].\\\n            string_value.value = str(attribute_value)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nemit the given list of SpanData tuples to the agent.", "response": "def emit(self, span_datas):\n        \"\"\"\n        :type span_datas: list of :class:\n            `~opencensus.trace.span_data.SpanData`\n        :param list of opencensus.trace.span_data.SpanData span_datas:\n            SpanData tuples to emit\n        \"\"\"\n\n        try:\n\n            # TODO: keep the stream alive.\n            # The stream is terminated after iteration completes.\n            # To keep it alive, we can enqueue proto spans here\n            # and asyncronously read them and send to the agent.\n            responses = self.client.Export(\n                self.generate_span_requests(span_datas))\n\n            # read response\n            for _ in responses:\n                pass\n\n        except grpc.RpcError:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef generate_span_requests(self, span_datas):\n\n        pb_spans = [\n            utils.translate_to_trace_proto(span_data)\n            for span_data in span_datas\n        ]\n\n        # TODO: send node once per channel\n        yield trace_service_pb2.ExportTraceServiceRequest(\n            node=self.node,\n            spans=pb_spans)", "response": "Generator that returns a list of export requests."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_config(self, config):\n\n        # do not allow updating config simultaneously\n        lock = Lock()\n        with lock:\n            # TODO: keep the stream alive.\n            # The stream is terminated after iteration completes.\n            # To keep it alive, we can enqueue proto configs here\n            # and asyncronously read them and send to the agent.\n            config_responses = self.client.Config(\n                self.generate_config_request(config))\n\n            agent_config = next(config_responses)\n            return agent_config", "response": "Sends a TraceConfig to the agent and gets the agent s config in reply."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _set_default_configs(user_settings, default):\n    for key in default:\n        if key not in user_settings:\n            user_settings[key] = default[key]\n\n    return user_settings", "response": "Set the default value to user settings."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nemits the legacy trace json for the current set of tags.", "response": "def emit(self, span_datas):\n        \"\"\"\n        :type span_datas: list of :class:\n            `~opencensus.trace.span_data.SpanData`\n        :param list of opencensus.trace.span_data.SpanData span_datas:\n            SpanData tuples to emit\n        \"\"\"\n        # convert to the legacy trace json for easier refactoring\n        # TODO: refactor this to use the span data directly\n        legacy_trace_json = span_data.format_legacy_trace_json(span_datas)\n        self.logger.info(legacy_trace_json)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef format_link_json(self):\n        link_json = {}\n        link_json['trace_id'] = self.trace_id\n        link_json['span_id'] = self.span_id\n        link_json['type'] = self.type\n\n        if self.attributes is not None:\n            link_json['attributes'] = self.attributes\n\n        return link_json", "response": "Convert a Link object to json format."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _wrap_rpc_behavior(handler, fn):\n    if handler is None:\n        return None\n\n    if handler.request_streaming and handler.response_streaming:\n        behavior_fn = handler.stream_stream\n        handler_factory = grpc.stream_stream_rpc_method_handler\n    elif handler.request_streaming and not handler.response_streaming:\n        behavior_fn = handler.stream_unary\n        handler_factory = grpc.stream_unary_rpc_method_handler\n    elif not handler.request_streaming and handler.response_streaming:\n        behavior_fn = handler.unary_stream\n        handler_factory = grpc.unary_stream_rpc_method_handler\n    else:\n        behavior_fn = handler.unary_unary\n        handler_factory = grpc.unary_unary_rpc_method_handler\n\n    return handler_factory(\n        fn(behavior_fn, handler.request_streaming,\n           handler.response_streaming),\n        request_deserializer=handler.request_deserializer,\n        response_serializer=handler.response_serializer\n    )", "response": "Returns a new rpc handler that wraps the given function"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_span_name(servicer_context):\n    method_name = servicer_context._rpc_event.call_details.method[1:]\n    if isinstance(method_name, bytes):\n        method_name = method_name.decode('utf-8')\n    method_name = method_name.replace('/', '.')\n    return '{}.{}'.format(RECV_PREFIX, method_name)", "response": "Generates a span name based off of the RPC request info."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns an exporter that exports stats to Prometheus.", "response": "def new_stats_exporter(option):\n    \"\"\" new_stats_exporter returns an exporter\n    that exports stats to Prometheus.\n    \"\"\"\n    if option.namespace == \"\":\n        raise ValueError(\"Namespace can not be empty string.\")\n\n    collector = new_collector(option)\n\n    exporter = PrometheusStatsExporter(options=option,\n                                       gatherer=option.registry,\n                                       collector=collector)\n    return exporter"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_view_name(namespace, view):\n    name = \"\"\n    if namespace != \"\":\n        name = namespace + \"_\"\n    return sanitize(name + view.name)", "response": "create the name for the view"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef register_view(self, view):\n        v_name = get_view_name(self.options.namespace, view)\n\n        if v_name not in self.registered_views:\n            desc = {'name': v_name,\n                    'documentation': view.description,\n                    'labels': list(map(sanitize, view.columns))}\n            self.registered_views[v_name] = desc\n            self.registry.register(self)", "response": "Register a view in the registry."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_view_data(self, view_data):\n        self.register_view(view_data.view)\n        v_name = get_view_name(self.options.namespace, view_data.view)\n        self.view_name_to_data_map[v_name] = view_data", "response": "Add view data object to be sent to server"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_metric(self, desc, tag_values, agg_data):\n        metric_name = desc['name']\n        metric_description = desc['documentation']\n        label_keys = desc['labels']\n\n        assert(len(tag_values) == len(label_keys))\n        # Prometheus requires that all tag values be strings hence\n        # the need to cast none to the empty string before exporting. See\n        # https://github.com/census-instrumentation/opencensus-python/issues/480\n        tag_values = [tv if tv else \"\" for tv in tag_values]\n\n        if isinstance(agg_data, aggregation_data_module.CountAggregationData):\n            metric = CounterMetricFamily(name=metric_name,\n                                         documentation=metric_description,\n                                         labels=label_keys)\n            metric.add_metric(labels=tag_values,\n                              value=agg_data.count_data)\n            return metric\n\n        elif isinstance(agg_data,\n                        aggregation_data_module.DistributionAggregationData):\n\n            assert(agg_data.bounds == sorted(agg_data.bounds))\n            # buckets are a list of buckets. Each bucket is another list with\n            # a pair of bucket name and value, or a triple of bucket name,\n            # value, and exemplar. buckets need to be in order.\n            buckets = []\n            cum_count = 0  # Prometheus buckets expect cumulative count.\n            for ii, bound in enumerate(agg_data.bounds):\n                cum_count += agg_data.counts_per_bucket[ii]\n                bucket = [str(bound), cum_count]\n                buckets.append(bucket)\n            # Prometheus requires buckets to be sorted, and +Inf present.\n            # In OpenCensus we don't have +Inf in the bucket bonds so need to\n            # append it here.\n            buckets.append([\"+Inf\", agg_data.count_data])\n            metric = HistogramMetricFamily(name=metric_name,\n                                           documentation=metric_description,\n                                           labels=label_keys)\n            metric.add_metric(labels=tag_values,\n                              buckets=buckets,\n                              sum_value=agg_data.sum,)\n            return metric\n\n        elif isinstance(agg_data,\n                        aggregation_data_module.SumAggregationDataFloat):\n            metric = UnknownMetricFamily(name=metric_name,\n                                         documentation=metric_description,\n                                         labels=label_keys)\n            metric.add_metric(labels=tag_values,\n                              value=agg_data.sum_data)\n            return metric\n\n        elif isinstance(agg_data,\n                        aggregation_data_module.LastValueAggregationData):\n            metric = GaugeMetricFamily(name=metric_name,\n                                       documentation=metric_description,\n                                       labels=label_keys)\n            metric.add_metric(labels=tag_values,\n                              value=agg_data.value)\n            return metric\n\n        else:\n            raise ValueError(\"unsupported aggregation type %s\"\n                             % type(agg_data))", "response": "Translate the data that OpenCensus create\n        to Prometheus Metric object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncollecting fetches the statistics from OpenCensus and delivers them as Prometheus Metrics.", "response": "def collect(self):  # pragma: NO COVER\n        \"\"\"Collect fetches the statistics from OpenCensus\n        and delivers them as Prometheus Metrics.\n        Collect is invoked every time a prometheus.Gatherer is run\n        for example when the HTTP endpoint is invoked by Prometheus.\n        \"\"\"\n        for v_name, view_data in self.view_name_to_data_map.items():\n            if v_name not in self.registered_views:\n                continue\n            desc = self.registered_views[v_name]\n            for tag_values in view_data.tag_value_aggregation_data_map:\n                agg_data = view_data.tag_value_aggregation_data_map[tag_values]\n                metric = self.to_metric(desc, tag_values, agg_data)\n                yield metric"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nemits the view data to the Prometheus collector.", "response": "def emit(self, view_data):  # pragma: NO COVER\n        \"\"\" Emit exports to the Prometheus if view data has one or more rows.\n        Each OpenCensus AggregationData will be converted to\n        corresponding Prometheus Metric: SumData will be converted\n        to Untyped Metric, CountData will be a Counter Metric\n        DistributionData will be a Histogram Metric.\n        \"\"\"\n\n        for v_data in view_data:\n            if v_data.tag_value_aggregation_data_map:\n                self.collector.add_view_data(v_data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef serve_http(self):\n        start_http_server(port=self.options.port,\n                          addr=str(self.options.address))", "response": "Serve the Prometheus endpoint."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef format_time_event_json(self):\n        time_event = {}\n        time_event['time'] = self.timestamp\n\n        if self.annotation is not None:\n            time_event['annotation'] = self.annotation.format_annotation_json()\n\n        if self.message_event is not None:\n            time_event['message_event'] = \\\n                self.message_event.format_message_event_json()\n\n        return time_event", "response": "Convert a TimeEvent object to json format."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn True if the trace_id should be sampled False otherwise.", "response": "def should_sample(self, trace_id):\n        \"\"\"Make the sampling decision based on the lower 8 bytes of the trace\n        ID. If the value is less than the bound, return True, else False.\n\n        :type trace_id: str\n        :param trace_id: Trace ID of the current trace.\n\n        :rtype: bool\n        :returns: The sampling decision.\n        \"\"\"\n        lower_long = get_lower_long_from_trace_id(trace_id)\n        bound = self.rate * MAX_VALUE\n\n        if lower_long <= bound:\n            return True\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add(self, val):\n        if not isinstance(val, six.integer_types):\n            raise ValueError(\"CumulativePointLong only supports integer types\")\n        if val > 0:\n            super(CumulativePointLong, self).add(val)", "response": "Add val to the current value if it s positive. Return without adding if val is not positive."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning True if the context should be sampled False otherwise.", "response": "def should_sample(self):\n        \"\"\"Determine whether to sample this request or not.\n        If the context enables tracing, return True.\n        Else follow the decision of the sampler.\n\n        :rtype: bool\n        :returns: Whether to trace the request or not.\n        \"\"\"\n        return self.span_context.trace_options.enabled \\\n            or self.sampler.should_sample(self.span_context.trace_id)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a tracer according to the sampling decision.", "response": "def get_tracer(self):\n        \"\"\"Return a tracer according to the sampling decision.\"\"\"\n        sampled = self.should_sample()\n\n        if sampled:\n            self.span_context.trace_options.set_enabled(True)\n            return context_tracer.ContextTracer(\n                exporter=self.exporter,\n                span_context=self.span_context)\n        else:\n            return noop_tracer.NoopTracer()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef trace_decorator(self):\n\n        def decorator(func):\n\n            def wrapper(*args, **kwargs):\n                self.tracer.start_span(name=func.__name__)\n                return_value = func(*args, **kwargs)\n                self.tracer.end_span()\n                return return_value\n\n            return wrapper\n\n        return decorator", "response": "Decorator to trace a function."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_monitored_resource_attributes(span):\n    resource = monitored_resource.get_instance()\n    if resource is not None:\n        resource_type = resource.get_type()\n        resource_labels = resource.get_labels()\n\n        if resource_type == 'gke_container':\n            resource_type = 'k8s_container'\n            set_attribute_label(span, resource_type, resource_labels,\n                                'project_id')\n            set_attribute_label(span, resource_type, resource_labels,\n                                'cluster_name')\n            set_attribute_label(span, resource_type, resource_labels,\n                                'container_name')\n            set_attribute_label(span, resource_type, resource_labels,\n                                'namespace_id', 'namespace_name')\n            set_attribute_label(span, resource_type, resource_labels,\n                                'pod_id', 'pod_name')\n            set_attribute_label(span, resource_type, resource_labels,\n                                'zone', 'location')\n\n        elif resource_type == 'gce_instance':\n            set_attribute_label(span, resource_type, resource_labels,\n                                'project_id')\n            set_attribute_label(span, resource_type, resource_labels,\n                                'instance_id')\n            set_attribute_label(span, resource_type, resource_labels,\n                                'zone')\n\n        elif resource_type == 'aws_ec2_instance':\n            set_attribute_label(span, resource_type, resource_labels,\n                                'aws_account')\n            set_attribute_label(span, resource_type, resource_labels,\n                                'instance_id')\n            set_attribute_label(span, resource_type, resource_labels,\n                                'region', label_value_prefix='aws:')", "response": "Set labels to span that can be used for tracing."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset a label to span that can be used for tracing.", "response": "def set_attribute_label(span, resource_type, resource_labels, attribute_key,\n                        canonical_key=None, label_value_prefix=''):\n    \"\"\"Set a label to span that can be used for tracing.\n    :param span: Span object\n    :param resource_type: resource type\n    :param resource_labels: collection of labels\n    :param attribute_key: actual label key\n    :param canonical_key: exporter specific label key, Optional\n    :param label_value_prefix: exporter specific label value prefix, Optional\n    \"\"\"\n\n    if attribute_key in resource_labels:\n        if canonical_key is None:\n            canonical_key = attribute_key\n\n        pair = {RESOURCE_LABEL % (resource_type, canonical_key):\n                label_value_prefix + resource_labels[attribute_key]\n                }\n        pair_attrs = Attributes(pair).format_attributes_json()\\\n            .get('attributeMap')\n\n        _update_attr_map(span, pair_attrs)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_common_attributes(span):\n    common = {\n        attributes_helper.COMMON_ATTRIBUTES.get('AGENT'): AGENT,\n    }\n    common_attrs = Attributes(common)\\\n        .format_attributes_json()\\\n        .get('attributeMap')\n\n    _update_attr_map(span, common_attrs)", "response": "Set the common attributes."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the GAE environment common attributes.", "response": "def set_gae_attributes(span):\n    \"\"\"Set the GAE environment common attributes.\"\"\"\n    for env_var, attribute_key in GAE_ATTRIBUTES.items():\n        attribute_value = os.environ.get(env_var)\n\n        if attribute_value is not None:\n            pair = {attribute_key: attribute_value}\n            pair_attrs = Attributes(pair)\\\n                .format_attributes_json()\\\n                .get('attributeMap')\n\n            _update_attr_map(span, pair_attrs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef emit(self, span_datas):\n        project = 'projects/{}'.format(self.project_id)\n\n        # Map each span data to it's corresponding trace id\n        trace_span_map = defaultdict(list)\n        for sd in span_datas:\n            trace_span_map[sd.context.trace_id] += [sd]\n\n        stackdriver_spans = []\n        # Write spans to Stackdriver\n        for _, sds in trace_span_map.items():\n            # convert to the legacy trace json for easier refactoring\n            # TODO: refactor this to use the span data directly\n            trace = span_data.format_legacy_trace_json(sds)\n            stackdriver_spans.extend(self.translate_to_stackdriver(trace))\n\n        self.client.batch_write_spans(project, {'spans': stackdriver_spans})", "response": "Emit the list of SpanData tuples to Stackdriver."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntranslate the spans json to Stackdriver format.", "response": "def translate_to_stackdriver(self, trace):\n        \"\"\"Translate the spans json to Stackdriver format.\n\n        See: https://cloud.google.com/trace/docs/reference/v2/rest/v2/\n             projects.traces/batchWrite\n\n        :type trace: dict\n        :param trace: Trace dictionary\n\n        :rtype: dict\n        :returns: Spans in Google Cloud StackDriver Trace format.\n        \"\"\"\n        set_attributes(trace)\n        spans_json = trace.get('spans')\n        trace_id = trace.get('traceId')\n\n        for span in spans_json:\n            span_name = 'projects/{}/traces/{}/spans/{}'.format(\n                self.project_id, trace_id, span.get('spanId'))\n\n            span_json = {\n                'name': span_name,\n                'displayName': span.get('displayName'),\n                'startTime': span.get('startTime'),\n                'endTime': span.get('endTime'),\n                'spanId': str(span.get('spanId')),\n                'attributes': self.map_attributes(span.get('attributes')),\n                'links': span.get('links'),\n                'status': span.get('status'),\n                'stackTrace': span.get('stackTrace'),\n                'timeEvents': span.get('timeEvents'),\n                'sameProcessAsParentSpan': span.get('sameProcessAsParentSpan'),\n                'childSpanCount': span.get('childSpanCount')\n            }\n\n            if span.get('parentSpanId') is not None:\n                parent_span_id = str(span.get('parentSpanId'))\n                span_json['parentSpanId'] = parent_span_id\n\n            yield span_json"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef merge_resources(resource_list):\n    if not resource_list:\n        raise ValueError\n    rtype = None\n    for rr in resource_list:\n        if rr.type:\n            rtype = rr.type\n            break\n    labels = {}\n    for rr in reversed(resource_list):\n        labels.update(rr.labels)\n    return Resource(rtype, labels)", "response": "Merge multiple resources into a single resource."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check_ascii_256(string):\n    if string is None:\n        return\n    if len(string) > 256:\n        raise ValueError(\"Value is longer than 256 characters\")\n    bad_char = _NON_PRINTABLE_ASCII.search(string)\n    if bad_char:\n        raise ValueError(u'Character \"{}\" at position {} is not printable '\n                         'ASCII'\n                         .format(\n                             string[bad_char.start():bad_char.end()],\n                             bad_char.start()))", "response": "Checks that string is printable ASCII and at most 256 characters."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse the labels string into a dictionary of key - value pairs.", "response": "def parse_labels(labels_str):\n    \"\"\"Parse label keys and values following the Resource spec.\n\n    >>> parse_labels(\"k=v\")\n    {'k': 'v'}\n    >>> parse_labels(\"k1=v1, k2=v2\")\n    {'k1': 'v1', 'k2': 'v2'}\n    >>> parse_labels(\"k1='v1,=z1'\")\n    {'k1': 'v1,=z1'}\n    \"\"\"\n    if not _LABELS_RE.match(labels_str):\n        return None\n    labels = {}\n    for kv in _KV_RE.finditer(labels_str):\n        gd = kv.groupdict()\n        key = unquote(gd['key'])\n        if key in labels:\n            logger.warning('Duplicate label key \"%s\"', key)\n        labels[key] = unquote(gd['val'])\n    return labels"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a Resource from environment variables.", "response": "def get_from_env():\n    \"\"\"Get a Resource from environment variables.\n\n    :rtype: :class:`Resource`\n    :return: A resource with type and labels from the environment.\n    \"\"\"\n    type_env = os.getenv(OC_RESOURCE_TYPE)\n    if type_env is None:\n        return None\n    type_env = type_env.strip()\n\n    labels_env = os.getenv(OC_RESOURCE_LABELS)\n    if labels_env is None:\n        return Resource(type_env)\n\n    labels = parse_labels(labels_env)\n\n    return Resource(type_env, labels)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nenable tracing on the selected integrations.", "response": "def trace_integrations(integrations, tracer=None):\n    \"\"\"Enable tracing on the selected integrations.\n    :type integrations: list\n    :param integrations: The integrations to be traced.\n    \"\"\"\n    integrated = []\n\n    for item in integrations:\n        module_name = 'opencensus.ext.{}.trace'.format(item)\n        try:\n            module = importlib.import_module(module_name)\n            module.trace_integration(tracer=tracer)\n            integrated.append(item)\n        except Exception as e:\n            log.warning('Failed to integrate module: {}'.format(module_name))\n            log.warning('{}'.format(e))\n\n    return integrated"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef apply(self, snapshot):\n\n        for name in snapshot:\n            setattr(self, name, snapshot[name])", "response": "Set the current context from a given snapshot dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef snapshot(self):\n\n        return dict((n, self._slots[n].get()) for n in self._slots.keys())", "response": "Return a dictionary of current slots by reference."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a function that will apply the current context to the provided func.", "response": "def with_current_context(self, func):\n        \"\"\"Capture the current context and apply it to the provided func\"\"\"\n\n        caller_context = self.snapshot()\n\n        def call_with_current_context(*args, **kwargs):\n            try:\n                backup_context = self.snapshot()\n                self.apply(caller_context)\n                return func(*args, **kwargs)\n            finally:\n                self.apply(backup_context)\n\n        return call_with_current_context"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _initialize_aws_identity_document(cls):\n\n        if cls.inited:\n            return\n\n        content = get_request(_AWS_INSTANCE_IDENTITY_DOCUMENT_URI)\n        if content is not None:\n            content = json.loads(content)\n            for env_var, attribute_key in _AWS_ATTRIBUTES.items():\n                attribute_value = content.get(env_var)\n                if attribute_value is not None:\n                    aws_metadata_map[attribute_key] = attribute_value\n\n            cls.is_running = True\n\n        cls.inited = True", "response": "This method attempts to establish an HTTP connection to the AWS instance\n        identity document url and stores the data in the local map."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a MetricDescriptor for this view.", "response": "def get_metric_descriptor(self):\n        \"\"\"Get a MetricDescriptor for this view.\n\n        Lazily creates a MetricDescriptor for metrics conversion.\n\n        :rtype: :class:\n                `opencensus.metrics.export.metric_descriptor.MetricDescriptor`\n        :return: A converted Metric.\n        \"\"\"  # noqa\n        with self._md_cache_lock:\n            if self._metric_descriptor is None:\n                self._metric_descriptor = metric_descriptor.MetricDescriptor(\n                    self.name,\n                    self.description,\n                    self.measure.unit,\n                    metric_utils.get_metric_type(self.measure,\n                                                 self.aggregation),\n                    # TODO: add label key description\n                    [label_key.LabelKey(tk, \"\") for tk in self.columns])\n        return self._metric_descriptor"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a new worker thread and attach it to the stats exporter.", "response": "def new_stats_exporter(service_name,\n                       hostname=None,\n                       endpoint=None,\n                       interval=None):\n    \"\"\"Create a new worker thread and attach the exporter to it.\n\n    :type endpoint: str\n    :param endpoint: address of the opencensus service.\n\n    :type service_name: str\n    :param service_name: name of the service\n\n    :type host_name: str\n    :param host_name: name of the host (machine or host name)\n\n    :type interval: int or float\n    :param interval: Seconds between export calls.\n    \"\"\"\n    endpoint = utils.DEFAULT_ENDPOINT if endpoint is None else endpoint\n    exporter = StatsExporter(\n        ExportRpcHandler(_create_stub(endpoint), service_name, hostname))\n\n    transport.get_exporter_thread(stats.stats, exporter, interval)\n    return exporter"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nexport given metrics to target metric service.", "response": "def export_metrics(self, metrics):\n        \"\"\" Exports given metrics to target metric service.\n        \"\"\"\n        metric_protos = []\n        for metric in metrics:\n            metric_protos.append(_get_metric_proto(metric))\n\n        self._rpc_handler.send(\n            metrics_service_pb2.ExportMetricsServiceRequest(\n                metrics=metric_protos))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndispatch incoming request on rpc.", "response": "def send(self, request):\n        \"\"\"Dispatches incoming request on rpc.\n\n        Initializes rpc if necessary and dispatches incoming request.  If a rpc\n        error is thrown, this function will attempt to recreate the stream and\n        retry sending given request once.\n\n        :type request: class:\n          `~.metrics_service_pb2.ExportMetricsServiceRequest`\n        :param request: incoming export request\n        \"\"\"\n        if not self._initialized:\n            self._initialize(request)\n            return\n\n        try:\n            self._rpc.send(request)\n        except grpc.RpcError as e:\n            logging.info('Found rpc error %s', e, exc_info=True)\n            # If stream has closed due to error, attempt to reopen with the\n            # incoming request.\n            self._initialize(request)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _initialize(self, request):\n\n        # Add node information on the first request dispatched on a stream.\n        request.node.MergeFrom(self._node)\n        request.resource.MergeFrom(self._resource)\n        self._initial_request = request\n\n        self._rpc.open()\n        self._initialized = True", "response": "Initializes the exporter rpc stream."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef trace_integration(tracer=None):\n    log.info('Integrated module: {}'.format(MODULE_NAME))\n    conn_func = getattr(psycopg2, CONN_WRAP_METHOD)\n    conn_module = inspect.getmodule(conn_func)\n    setattr(conn_module, conn_func.__name__, connect)", "response": "Wrap the mysql connector to trace it."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef connect(*args, **kwargs):\n    kwargs['cursor_factory'] = TraceCursor\n    conn = pg_connect(*args, **kwargs)\n    return conn", "response": "Create database connection, use TraceCursor as the cursor_factory."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts a legacy SpanData object into a dictionary.", "response": "def _format_legacy_span_json(span_data):\n    \"\"\"\n    :param SpanData span_data: SpanData object to convert\n    :rtype: dict\n    :return: Dictionary representing the Span\n    \"\"\"\n    span_json = {\n        'displayName': utils.get_truncatable_str(span_data.name),\n        'spanId': span_data.span_id,\n        'startTime': span_data.start_time,\n        'endTime': span_data.end_time,\n        'childSpanCount': span_data.child_span_count,\n        'kind': span_data.span_kind\n    }\n\n    if span_data.parent_span_id is not None:\n        span_json['parentSpanId'] = span_data.parent_span_id\n\n    if span_data.attributes:\n        span_json['attributes'] = attributes.Attributes(\n            span_data.attributes).format_attributes_json()\n\n    if span_data.stack_trace is not None:\n        span_json['stackTrace'] = \\\n            span_data.stack_trace.format_stack_trace_json()\n\n    if span_data.time_events:\n        span_json['timeEvents'] = {\n            'timeEvent': [time_event.format_time_event_json()\n                          for time_event in span_data.time_events]\n        }\n\n    if span_data.links:\n        span_json['links'] = {\n            'link': [\n                link.format_link_json() for link in span_data.links]\n        }\n\n    if span_data.status is not None:\n        span_json['status'] = span_data.status.format_status_json()\n\n    if span_data.same_process_as_parent_span is not None:\n        span_json['sameProcessAsParentSpan'] = \\\n            span_data.same_process_as_parent_span\n\n    return span_json"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef format_legacy_trace_json(span_datas):\n    if not span_datas:\n        return {}\n    top_span = span_datas[0]\n    assert isinstance(top_span, SpanData)\n    trace_id = top_span.context.trace_id if top_span.context is not None \\\n        else None\n    assert trace_id is not None\n    return {\n        'traceId': trace_id,\n        'spans': [_format_legacy_span_json(sd) for sd in span_datas],\n    }", "response": "Formats a list of SpanData tuples into the legacy trace dictionary for backwards compatibility"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_view(self, view_name, timestamp):\n        view = self._registered_views.get(view_name)\n        if view is None:\n            return None\n\n        view_data_list = self._measure_to_view_data_list_map.get(\n            view.measure.name)\n\n        if not view_data_list:\n            return None\n\n        for view_data in view_data_list:\n            if view_data.view.name == view_name:\n                break\n        else:\n            return None\n\n        return self.copy_and_finalize_view_data(view_data)", "response": "get the View Data from the given View name and timestamp"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nregister the view s measure name to View Datas given a view", "response": "def register_view(self, view, timestamp):\n        \"\"\"registers the view's measure name to View Datas given a view\"\"\"\n        if len(self.exporters) > 0:\n            try:\n                for e in self.exporters:\n                    e.on_register_view(view)\n            except AttributeError:\n                pass\n\n        self._exported_views = None\n        existing_view = self._registered_views.get(view.name)\n        if existing_view is not None:\n            if existing_view == view:\n                # ignore the views that are already registered\n                return\n            else:\n                logging.warning(\n                    \"A different view with the same name is already registered\"\n                )  # pragma: NO COVER\n        measure = view.measure\n        registered_measure = self._registered_measures.get(measure.name)\n        if registered_measure is not None and registered_measure != measure:\n            logging.warning(\n                \"A different measure with the same name is already registered\")\n        self._registered_views[view.name] = view\n        if registered_measure is None:\n            self._registered_measures[measure.name] = measure\n        self._measure_to_view_data_list_map[view.measure.name].append(\n            view_data_module.ViewData(view=view, start_time=timestamp,\n                                      end_time=timestamp))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrecording stats with a set of tags", "response": "def record(self, tags, measurement_map, timestamp, attachments=None):\n        \"\"\"records stats with a set of tags\"\"\"\n        assert all(vv >= 0 for vv in measurement_map.values())\n        for measure, value in measurement_map.items():\n            if measure != self._registered_measures.get(measure.name):\n                return\n            view_datas = []\n            for measure_name, view_data_list \\\n                    in self._measure_to_view_data_list_map.items():\n                if measure_name == measure.name:\n                    view_datas.extend(view_data_list)\n            for view_data in view_datas:\n                view_data.record(\n                    context=tags, value=value, timestamp=timestamp,\n                    attachments=attachments)\n            self.export(view_datas)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nexports view datas to registered exporters", "response": "def export(self, view_datas):\n        \"\"\"export view datas to registered exporters\"\"\"\n        view_datas_copy = \\\n            [self.copy_and_finalize_view_data(vd) for vd in view_datas]\n        if len(self.exporters) > 0:\n            for e in self.exporters:\n                try:\n                    e.export(view_datas_copy)\n                except AttributeError:\n                    pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a Metric for each registered view.", "response": "def get_metrics(self, timestamp):\n        \"\"\"Get a Metric for each registered view.\n\n        Convert each registered view's associated `ViewData` into a `Metric` to\n        be exported.\n\n        :type timestamp: :class: `datetime.datetime`\n        :param timestamp: The timestamp to use for metric conversions, usually\n        the current time.\n\n        :rtype: Iterator[:class: `opencensus.metrics.export.metric.Metric`]\n        \"\"\"\n        for vdl in self._measure_to_view_data_list_map.values():\n            for vd in vdl:\n                metric = metric_utils.view_data_to_metric(vd, timestamp)\n                if metric is not None:\n                    yield metric"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntransmitting the data envelopes to the ingestion service.", "response": "def _transmit(self, envelopes):\n        \"\"\"\n        Transmit the data envelopes to the ingestion service.\n        Return a negative value for partial success or non-retryable failure.\n        Return 0 if all envelopes have been successfully ingested.\n        Return the next retry time in seconds for retryable failure.\n        This function should never throw exception.\n        \"\"\"\n        if not envelopes:\n            return 0\n        # TODO: prevent requests being tracked\n        blacklist_hostnames = execution_context.get_opencensus_attr(\n            'blacklist_hostnames',\n        )\n        execution_context.set_opencensus_attr(\n            'blacklist_hostnames',\n            ['dc.services.visualstudio.com'],\n        )\n        try:\n            response = requests.post(\n                url=self.options.endpoint,\n                data=json.dumps(envelopes),\n                headers={\n                    'Accept': 'application/json',\n                    'Content-Type': 'application/json; charset=utf-8',\n                },\n                timeout=self.options.timeout,\n            )\n        except Exception as ex:  # TODO: consider RequestException\n            logger.warning('Transient client side error %s.', ex)\n            # client side error (retryable)\n            return self.options.minimum_retry_interval\n        finally:\n            execution_context.set_opencensus_attr(\n                'blacklist_hostnames',\n                blacklist_hostnames,\n            )\n        text = 'N/A'\n        data = None\n        try:\n            text = response.text\n        except Exception as ex:\n            logger.warning('Error while reading response body %s.', ex)\n        else:\n            try:\n                data = json.loads(text)\n            except Exception:\n                pass\n        if response.status_code == 200:\n            logger.info('Transmission succeeded: %s.', text)\n            return 0\n        if response.status_code == 206:  # Partial Content\n            # TODO: store the unsent data\n            if data:\n                try:\n                    resend_envelopes = []\n                    for error in data['errors']:\n                        if error['statusCode'] in (\n                                429,  # Too Many Requests\n                                500,  # Internal Server Error\n                                503,  # Service Unavailable\n                        ):\n                            resend_envelopes.append(envelopes[error['index']])\n                        else:\n                            logger.error(\n                                'Data drop %s: %s %s.',\n                                error['statusCode'],\n                                error['message'],\n                                envelopes[error['index']],\n                            )\n                    if resend_envelopes:\n                        self.storage.put(resend_envelopes)\n                except Exception as ex:\n                    logger.error(\n                        'Error while processing %s: %s %s.',\n                        response.status_code,\n                        text,\n                        ex,\n                    )\n                return -response.status_code\n            # cannot parse response body, fallback to retry\n        if response.status_code in (\n                206,  # Partial Content\n                429,  # Too Many Requests\n                500,  # Internal Server Error\n                503,  # Service Unavailable\n        ):\n            logger.warning(\n                'Transient server side error %s: %s.',\n                response.status_code,\n                text,\n            )\n            # server side error (retryable)\n            return self.options.minimum_retry_interval\n        logger.error(\n            'Non-retryable server side error %s: %s.',\n            response.status_code,\n            text,\n        )\n        # server side error (non-retryable)\n        return -response.status_code"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nemitting the list of SpanData tuples to the store.", "response": "def emit(self, span_datas):\n        \"\"\"\n        :type span_datas: list of :class:\n            `~opencensus.trace.span_data.SpanData`\n        :param list of opencensus.trace.span_data.SpanData span_datas:\n            SpanData tuples to emit\n        \"\"\"\n        envelopes = [self.span_data_to_envelope(sd) for sd in span_datas]\n        result = self._transmit(envelopes)\n        if result > 0:\n            self.storage.put(envelopes, result)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a resource based on the application environment.", "response": "def get_instance():\n    \"\"\"Get a resource based on the application environment.\n\n    Returns a `Resource` configured for the current environment, or None if the\n    environment is unknown or unsupported.\n\n    :rtype: :class:`opencensus.common.resource.Resource` or None\n    :return: A `Resource` configured for the current environment.\n    \"\"\"\n    resources = []\n    env_resource = resource.get_from_env()\n    if env_resource is not None:\n        resources.append(env_resource)\n\n    if k8s_utils.is_k8s_environment():\n        resources.append(resource.Resource(\n            _K8S_CONTAINER, k8s_utils.get_k8s_metadata()))\n\n    if is_gce_environment():\n        resources.append(resource.Resource(\n            _GCE_INSTANCE,\n            gcp_metadata_config.GcpMetadataConfig().get_gce_metadata()))\n    elif is_aws_environment():\n        resources.append(resource.Resource(\n            _AWS_EC2_INSTANCE,\n            (aws_identity_doc_utils.AwsIdentityDocumentUtils()\n             .get_aws_metadata())))\n\n    if not resources:\n        return None\n    return resource.merge_resources(resources)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef unit(session, py):\n\n    # Run unit tests against all supported versions of Python.\n    session.interpreter = 'python{}'.format(py)\n\n    # Install all test dependencies.\n    session.install('-r', 'requirements-test.txt')\n\n    # Install dev packages.\n    _install_dev_packages(session)\n\n    # Run py.test against the unit tests.\n    session.run(\n        'py.test',\n        '--quiet',\n        '--cov=opencensus',\n        '--cov=context',\n        '--cov=contrib',\n        '--cov-append',\n        '--cov-config=.coveragerc',\n        '--cov-report=',\n        '--cov-fail-under=97',\n        'tests/unit/',\n        'context/',\n        'contrib/',\n        *session.posargs\n    )", "response": "Run the unit test suite."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrun the system test suite.", "response": "def system(session, py):\n    \"\"\"Run the system test suite.\"\"\"\n\n    # Sanity check: Only run system tests if the environment variable is set.\n    if not os.environ.get('GOOGLE_APPLICATION_CREDENTIALS', ''):\n        session.skip('Credentials must be set via environment variable.')\n\n    # Run the system tests against latest Python 2 and Python 3 only.\n    session.interpreter = 'python{}'.format(py)\n\n    # Set the virtualenv dirname.\n    session.virtualenv_dirname = 'sys-' + py\n\n    # Install all test dependencies.\n    session.install('-r', 'requirements-test.txt')\n\n    # Install dev packages into the virtualenv's dist-packages.\n    _install_dev_packages(session)\n\n    # Run py.test against the system tests.\n    session.run(\n        'py.test',\n        '-s',\n        'tests/system/',\n        *session.posargs\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef lint(session):\n    session.interpreter = 'python3.6'\n    session.install('flake8')\n\n    # Install dev packages.\n    _install_dev_packages(session)\n\n    session.run(\n        'flake8',\n        '--exclude=contrib/opencensus-ext-ocagent/opencensus/ext/ocagent/trace_exporter/gen/',\n        'context/', 'contrib/', 'opencensus/', 'tests/', 'examples/')", "response": "Run flake8.\n    Returns a failure if flake8 finds linting errors or sufficiently\n    serious code quality issues."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nruns the final coverage report.", "response": "def cover(session):\n    \"\"\"Run the final coverage report.\n    This outputs the coverage report aggregating coverage from the unit\n    test runs (not system test runs), and then erases coverage data.\n    \"\"\"\n    session.interpreter = 'python3.6'\n    session.install('coverage', 'pytest-cov')\n    session.run('coverage', 'report', '--show-missing', '--fail-under=100')\n    session.run('coverage', 'erase')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nintegrate with pymongo to trace it using event listener.", "response": "def trace_integration(tracer=None):\n    \"\"\"Integrate with pymongo to trace it using event listener.\"\"\"\n    log.info('Integrated module: {}'.format(MODULE_NAME))\n    monitoring.register(MongoCommandListener(tracer=tracer))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_request(request_url, request_headers=dict()):\n    request = Request(request_url)\n    for key, val in request_headers.items():\n        request.add_header(key, val)\n\n    try:\n        response = urlopen(request, timeout=_REQUEST_TIMEOUT)\n        response_content = response.read()\n    except (HTTPError, URLError, socket.timeout):\n        response_content = None\n\n    return response_content", "response": "Execute http get request on given request_url with optional headers\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef trace_integration(tracer=None):\n    log.info('Integrated module: {}'.format(MODULE_NAME))\n\n    if tracer is not None:\n        # The execution_context tracer should never be None - if it has not\n        # been set it returns a no-op tracer. Most code in this library does\n        # not handle None being used in the execution context.\n        execution_context.set_opencensus_tracer(tracer)\n\n    # Wrap the requests functions\n    for func in REQUESTS_WRAP_METHODS:\n        requests_func = getattr(requests, func)\n        wrapped = wrap_requests(requests_func)\n        setattr(requests, requests_func.__name__, wrapped)\n\n    # Wrap Session class\n    wrapt.wrap_function_wrapper(\n        MODULE_NAME, 'Session.request', wrap_session_request)", "response": "Wrap the requests library to trace it."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwrapping the requests function to trace it.", "response": "def wrap_requests(requests_func):\n    \"\"\"Wrap the requests function to trace it.\"\"\"\n    def call(url, *args, **kwargs):\n        blacklist_hostnames = execution_context.get_opencensus_attr(\n            'blacklist_hostnames')\n        parsed_url = urlparse(url)\n        if parsed_url.port is None:\n            dest_url = parsed_url.hostname\n        else:\n            dest_url = '{}:{}'.format(parsed_url.hostname, parsed_url.port)\n        if utils.disable_tracing_hostname(dest_url, blacklist_hostnames):\n            return requests_func(url, *args, **kwargs)\n\n        _tracer = execution_context.get_opencensus_tracer()\n        _span = _tracer.start_span()\n        _span.name = '[requests]{}'.format(requests_func.__name__)\n        _span.span_kind = span_module.SpanKind.CLIENT\n\n        # Add the requests url to attributes\n        _tracer.add_attribute_to_current_span(HTTP_URL, url)\n\n        result = requests_func(url, *args, **kwargs)\n\n        # Add the status code to attributes\n        _tracer.add_attribute_to_current_span(\n            HTTP_STATUS_CODE, str(result.status_code))\n\n        _tracer.end_span()\n        return result\n\n    return call"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwraps the session function to trace it.", "response": "def wrap_session_request(wrapped, instance, args, kwargs):\n    \"\"\"Wrap the session function to trace it.\"\"\"\n    method = kwargs.get('method') or args[0]\n    url = kwargs.get('url') or args[1]\n\n    blacklist_hostnames = execution_context.get_opencensus_attr(\n        'blacklist_hostnames')\n    parsed_url = urlparse(url)\n    if parsed_url.port is None:\n        dest_url = parsed_url.hostname\n    else:\n        dest_url = '{}:{}'.format(parsed_url.hostname, parsed_url.port)\n    if utils.disable_tracing_hostname(dest_url, blacklist_hostnames):\n        return wrapped(*args, **kwargs)\n\n    _tracer = execution_context.get_opencensus_tracer()\n    _span = _tracer.start_span()\n\n    _span.name = '[requests]{}'.format(method)\n    _span.span_kind = span_module.SpanKind.CLIENT\n\n    try:\n        tracer_headers = _tracer.propagator.to_headers(\n            _tracer.span_context)\n        kwargs.setdefault('headers', {}).update(\n            tracer_headers)\n    except Exception:  # pragma: NO COVER\n        pass\n\n    # Add the requests url to attributes\n    _tracer.add_attribute_to_current_span(HTTP_URL, url)\n\n    result = wrapped(*args, **kwargs)\n\n    # Add the status code to attributes\n    _tracer.add_attribute_to_current_span(\n        HTTP_STATUS_CODE, str(result.status_code))\n\n    _tracer.end_span()\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the corresponding metric type for the given stats type.", "response": "def get_metric_type(measure, aggregation):\n    \"\"\"Get the corresponding metric type for the given stats type.\n\n    :type measure: (:class: '~opencensus.stats.measure.BaseMeasure')\n    :param measure: the measure for which to find a metric type\n\n    :type aggregation: (:class:\n    '~opencensus.stats.aggregation.BaseAggregation')\n    :param aggregation: the aggregation for which to find a metric type\n    \"\"\"\n    if aggregation.aggregation_type == aggregation_module.Type.NONE:\n        raise ValueError(\"aggregation type must not be NONE\")\n    assert isinstance(aggregation,\n                      AGGREGATION_TYPE_MAP[aggregation.aggregation_type])\n\n    if aggregation.aggregation_type == aggregation_module.Type.SUM:\n        if isinstance(measure, measure_module.MeasureInt):\n            return metric_descriptor.MetricDescriptorType.CUMULATIVE_INT64\n        elif isinstance(measure, measure_module.MeasureFloat):\n            return metric_descriptor.MetricDescriptorType.CUMULATIVE_DOUBLE\n        else:\n            raise ValueError\n    elif aggregation.aggregation_type == aggregation_module.Type.COUNT:\n        return metric_descriptor.MetricDescriptorType.CUMULATIVE_INT64\n    elif aggregation.aggregation_type == aggregation_module.Type.DISTRIBUTION:\n        return metric_descriptor.MetricDescriptorType.CUMULATIVE_DISTRIBUTION\n    elif aggregation.aggregation_type == aggregation_module.Type.LASTVALUE:\n        if isinstance(measure, measure_module.MeasureInt):\n            return metric_descriptor.MetricDescriptorType.GAUGE_INT64\n        elif isinstance(measure, measure_module.MeasureFloat):\n            return metric_descriptor.MetricDescriptorType.GAUGE_DOUBLE\n        else:\n            raise ValueError\n    else:\n        raise AssertionError"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_gauge(md_type):\n    if md_type not in metric_descriptor.MetricDescriptorType:\n        raise ValueError  # pragma: NO COVER\n\n    return md_type in {\n        metric_descriptor.MetricDescriptorType.GAUGE_INT64,\n        metric_descriptor.MetricDescriptorType.GAUGE_DOUBLE,\n        metric_descriptor.MetricDescriptorType.GAUGE_DISTRIBUTION\n    }", "response": "Checks if a given MetricDescriptorType value is a gauge."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts a ViewData to a Metric at time timestamp.", "response": "def view_data_to_metric(view_data, timestamp):\n    \"\"\"Convert a ViewData to a Metric at time `timestamp`.\n\n    :type view_data: :class: `opencensus.stats.view_data.ViewData`\n    :param view_data: The ViewData to convert.\n\n    :type timestamp: :class: `datetime.datetime`\n    :param timestamp: The time to set on the metric's point's aggregation,\n    usually the current time.\n\n    :rtype: :class: `opencensus.metrics.export.metric.Metric`\n    :return: A converted Metric.\n    \"\"\"\n    if not view_data.tag_value_aggregation_data_map:\n        return None\n\n    md = view_data.view.get_metric_descriptor()\n\n    # TODO: implement gauges\n    if is_gauge(md.type):\n        ts_start = None  # pragma: NO COVER\n    else:\n        ts_start = view_data.start_time\n\n    ts_list = []\n    for tag_vals, agg_data in view_data.tag_value_aggregation_data_map.items():\n        label_values = get_label_values(tag_vals)\n        point = agg_data.to_point(timestamp)\n        ts_list.append(time_series.TimeSeries(label_values, [point], ts_start))\n    return metric.Metric(md, ts_list)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _set_django_attributes(span, request):\n    django_user = getattr(request, 'user', None)\n\n    if django_user is None:\n        return\n\n    user_id = django_user.pk\n    try:\n        user_name = django_user.get_username()\n    except AttributeError:\n        # AnonymousUser in some older versions of Django doesn't implement\n        # get_username\n        return\n\n    # User id is the django autofield for User model as the primary key\n    if user_id is not None:\n        span.add_attribute('django.user.id', str(user_id))\n\n    if user_name is not None:\n        span.add_attribute('django.user.name', str(user_name))", "response": "Set the django related attributes."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef process_request(self, request):\n        # Do not trace if the url is blacklisted\n        if utils.disable_tracing_url(request.path, self.blacklist_paths):\n            return\n\n        # Add the request to thread local\n        execution_context.set_opencensus_attr(\n            REQUEST_THREAD_LOCAL_KEY,\n            request)\n\n        execution_context.set_opencensus_attr(\n            'blacklist_hostnames',\n            self.blacklist_hostnames)\n\n        try:\n            # Start tracing this request\n            span_context = self.propagator.from_headers(\n                _DjangoMetaWrapper(_get_django_request().META))\n\n            # Reload the tracer with the new span context\n            tracer = tracer_module.Tracer(\n                span_context=span_context,\n                sampler=self.sampler,\n                exporter=self.exporter,\n                propagator=self.propagator)\n\n            # Span name is being set at process_view\n            span = tracer.start_span()\n            span.span_kind = span_module.SpanKind.SERVER\n            tracer.add_attribute_to_current_span(\n                attribute_key=HTTP_METHOD,\n                attribute_value=request.method)\n            tracer.add_attribute_to_current_span(\n                attribute_key=HTTP_URL,\n                attribute_value=str(request.path))\n\n            # Add the span to thread local\n            # in some cases (exceptions, timeouts) currentspan in\n            # response event will be one of a child spans.\n            # let's keep reference to 'django' span and\n            # use it in response event\n            execution_context.set_opencensus_attr(\n                SPAN_THREAD_LOCAL_KEY,\n                span)\n\n        except Exception:  # pragma: NO COVER\n            log.error('Failed to trace request', exc_info=True)", "response": "Called on each request before Django decides which view to execute."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprocesses the view function.", "response": "def process_view(self, request, view_func, *args, **kwargs):\n        \"\"\"Process view is executed before the view function, here we get the\n        function name add set it as the span name.\n        \"\"\"\n\n        # Do not trace if the url is blacklisted\n        if utils.disable_tracing_url(request.path, self.blacklist_paths):\n            return\n\n        try:\n            # Get the current span and set the span name to the current\n            # function name of the request.\n            tracer = _get_current_tracer()\n            span = tracer.current_span()\n            span.name = utils.get_func_name(view_func)\n        except Exception:  # pragma: NO COVER\n            log.error('Failed to trace request', exc_info=True)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef format_span_json(span):\n    span_json = {\n        'displayName': utils.get_truncatable_str(span.name),\n        'spanId': span.span_id,\n        'startTime': span.start_time,\n        'endTime': span.end_time,\n        'childSpanCount': len(span._child_spans)\n    }\n\n    parent_span_id = None\n\n    if span.parent_span is not None:\n        parent_span_id = span.parent_span.span_id\n\n    if parent_span_id is not None:\n        span_json['parentSpanId'] = parent_span_id\n\n    if span.attributes:\n        span_json['attributes'] = attributes.Attributes(\n            span.attributes).format_attributes_json()\n\n    if span.stack_trace is not None:\n        span_json['stackTrace'] = span.stack_trace.format_stack_trace_json()\n\n    if span.time_events:\n        span_json['timeEvents'] = {\n            'timeEvent': [time_event.format_time_event_json()\n                          for time_event in span.time_events]\n        }\n\n    if span.links:\n        span_json['links'] = {\n            'link': [\n                link.format_link_json() for link in span.links]\n        }\n\n    if span.status is not None:\n        span_json['status'] = span.status.format_status_json()\n\n    if span.same_process_as_parent_span is not None:\n        span_json['sameProcessAsParentSpan'] = \\\n            span.same_process_as_parent_span\n\n    return span_json", "response": "Helper to format a Span in JSON format."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef span(self, name='child_span'):\n        child_span = Span(name, parent_span=self)\n        self._child_spans.append(child_span)\n        return child_span", "response": "Create a child span for the current span and append it to the child_spans list."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_annotation(self, description, **attrs):\n        at = attributes.Attributes(attrs)\n        self.add_time_event(time_event_module.TimeEvent(datetime.utcnow(),\n                            time_event_module.Annotation(description, at)))", "response": "Add an annotation to the span."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a TimeEvent object to the internal list of time events.", "response": "def add_time_event(self, time_event):\n        \"\"\"Add a TimeEvent.\n\n        :type time_event: :class: `~opencensus.trace.time_event.TimeEvent`\n        :param time_event: A TimeEvent object.\n        \"\"\"\n        if isinstance(time_event, time_event_module.TimeEvent):\n            self.time_events.append(time_event)\n        else:\n            raise TypeError(\"Type Error: received {}, but requires TimeEvent.\".\n                            format(type(time_event).__name__))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a Link. :type link: :class: `~opencensus.trace.link.Link` :param link: A Link object.", "response": "def add_link(self, link):\n        \"\"\"Add a Link.\n\n        :type link: :class: `~opencensus.trace.link.Link`\n        :param link: A Link object.\n        \"\"\"\n        if isinstance(link, link_module.Link):\n            self.links.append(link)\n        else:\n            raise TypeError(\"Type Error: received {}, but requires Link.\".\n                            format(type(link).__name__))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef trace_integration(tracer=None):\n    logging.info('Integrated module: {}'.format(MODULE_NAME))\n    conn_func = getattr(pymysql, CONN_WRAP_METHOD)\n    conn_module = inspect.getmodule(conn_func)\n    wrapped = trace.wrap_conn(conn_func)\n    setattr(conn_module, CONN_WRAP_METHOD, wrapped)", "response": "Wrap the mysql connector to trace it."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck that point value types match the descriptor type.", "response": "def _check_type(self):\n        \"\"\"Check that point value types match the descriptor type.\"\"\"\n        check_type = metric_descriptor.MetricDescriptorType.to_type_class(\n            self.descriptor.type)\n        for ts in self.time_series:\n            if not ts.check_points_type(check_type):\n                raise ValueError(\"Invalid point value type\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks that starting timestamp exists for cumulative metrics.", "response": "def _check_start_timestamp(self):\n        \"\"\"Check that starting timestamp exists for cumulative metrics.\"\"\"\n        if self.descriptor.type in (\n                metric_descriptor.MetricDescriptorType.CUMULATIVE_INT64,\n                metric_descriptor.MetricDescriptorType.CUMULATIVE_DOUBLE,\n                metric_descriptor.MetricDescriptorType.CUMULATIVE_DISTRIBUTION,\n        ):\n            for ts in self.time_series:\n                if ts.start_timestamp is None:\n                    raise ValueError(\"time_series.start_timestamp must exist \"\n                                     \"for cumulative metrics\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck if the boundaries are in ascending order", "response": "def is_valid_boundaries(self, boundaries):\n        \"\"\"checks if the boundaries are in ascending order\"\"\"\n        if boundaries is not None:\n            min_ = boundaries[0]\n            for value in boundaries:\n                if value < min_:\n                    return False\n                else:\n                    min_ = value\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_exporter_thread(metric_producer, exporter, interval=None):\n    weak_get = utils.get_weakref(metric_producer.get_metrics)\n    weak_export = utils.get_weakref(exporter.export_metrics)\n\n    def export_all():\n        get = weak_get()\n        if get is None:\n            raise TransportError(\"Metric producer is not available\")\n        export = weak_export()\n        if export is None:\n            raise TransportError(\"Metric exporter is not available\")\n        export(get())\n\n    tt = MetricExporterTask(interval, export_all)\n    tt.start()\n    return tt", "response": "Get a running task that periodically exports metrics."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a name which includes the module name and function name.", "response": "def get_func_name(func):\n    \"\"\"Return a name which includes the module name and function name.\"\"\"\n    func_name = getattr(func, '__name__', func.__class__.__name__)\n    module_name = func.__module__\n\n    if module_name is not None:\n        module_name = func.__module__\n        return '{}.{}'.format(module_name, func_name)\n\n    return func_name"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndisable tracing on the provided blacklist paths.", "response": "def disable_tracing_url(url, blacklist_paths=None):\n    \"\"\"Disable tracing on the provided blacklist paths, by default not tracing\n    the health check request.\n\n    If the url path starts with the blacklisted path, return True.\n\n    :type blacklist_paths: list\n    :param blacklist_paths: Paths that not tracing.\n\n    :rtype: bool\n    :returns: True if not tracing, False if tracing.\n    \"\"\"\n    if blacklist_paths is None:\n        blacklist_paths = DEFAULT_BLACKLIST_PATHS\n\n    # Remove the 'https?|ftp://' if exists\n    url = re.sub(URL_PATTERN, '', url)\n\n    # Split the url by the first '/' and get the path part\n    url_path = url.split('/', 1)[1]\n\n    for path in blacklist_paths:\n        if url_path.startswith(path):\n            return True\n\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndisable tracing for the provided blacklist URLs by default not tracing the exporter url.", "response": "def disable_tracing_hostname(url, blacklist_hostnames=None):\n    \"\"\"Disable tracing for the provided blacklist URLs, by default not tracing\n    the exporter url.\n\n    If the url path starts with the blacklisted path, return True.\n\n    :type blacklist_hostnames: list\n    :param blacklist_hostnames: URL that not tracing.\n\n    :rtype: bool\n    :returns: True if not tracing, False if tracing.\n    \"\"\"\n    if blacklist_hostnames is None:\n        # Exporter host_name are not traced by default\n        _tracer = execution_context.get_opencensus_tracer()\n        try:\n            blacklist_hostnames = [\n                '{}:{}'.format(\n                    _tracer.exporter.host_name,\n                    _tracer.exporter.port\n                )\n            ]\n        except(AttributeError):\n            blacklist_hostnames = []\n\n    return url in blacklist_hostnames"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nupdating the last bit of the trace options byte str.", "response": "def set_enabled(self, enabled):\n        \"\"\"Update the last bit of the trace options byte str.\n\n        :type enabled: bool\n        :param enabled: Whether enable tracing in this span context or not.\n        \"\"\"\n        enabled_bit = '1' if enabled else '0'\n        self.trace_options_byte = str(\n            self.trace_options_byte)[:-1] + enabled_bit\n        self.enabled = self.get_enabled"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef emit(self, span_datas):\n        with open(self.file_name, self.file_mode) as file:\n            # convert to the legacy trace json for easier refactoring\n            # TODO: refactor this to use the span data directly\n            legacy_trace_json = span_data.format_legacy_trace_json(span_datas)\n            trace_str = json.dumps(legacy_trace_json)\n            file.write(trace_str)", "response": "Emit the trace json to the file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_k8s_metadata():\n    k8s_metadata = {}\n\n    gcp_cluster = (gcp_metadata_config.GcpMetadataConfig\n                   .get_attribute(gcp_metadata_config.CLUSTER_NAME_KEY))\n    if gcp_cluster is not None:\n        k8s_metadata[CLUSTER_NAME_KEY] = gcp_cluster\n\n    for attribute_key, attribute_env in _K8S_ENV_ATTRIBUTES.items():\n        attribute_value = os.environ.get(attribute_env)\n        if attribute_value is not None:\n            k8s_metadata[attribute_key] = attribute_value\n\n    return k8s_metadata", "response": "Get kubernetes container metadata as on GCP GKE."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef insert(self, key, value):\n        if key in self.map:\n            return\n\n        try:\n            tag_key = TagKey(key)\n            tag_val = TagValue(value)\n            self.map[tag_key] = tag_val\n        except ValueError:\n            raise", "response": "Inserts a key and value into the map if the map does not already contain the key."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate the value of a key in the map by updating the value of a key in the map", "response": "def update(self, key, value):\n        \"\"\"Updates the map by updating the value of a key\n\n        :type key: :class: '~opencensus.tags.tag_key.TagKey'\n        :param key: A tag key to be updated\n\n        :type value: :class: '~opencensus.tags.tag_value.TagValue'\n        :param value: The value to update the key to in the map\n\n        \"\"\"\n        if key in self.map:\n            self.map[key] = value"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrap threading functions to trace.", "response": "def trace_integration(tracer=None):\n    \"\"\"Wrap threading functions to trace.\"\"\"\n    log.info(\"Integrated module: {}\".format(MODULE_NAME))\n    # Wrap the threading start function\n    start_func = getattr(threading.Thread, \"start\")\n    setattr(\n        threading.Thread, start_func.__name__, wrap_threading_start(start_func)\n    )\n\n    # Wrap the threading run function\n    run_func = getattr(threading.Thread, \"run\")\n    setattr(threading.Thread, run_func.__name__, wrap_threading_run(run_func))\n\n    # Wrap the threading run function\n    apply_async_func = getattr(pool.Pool, \"apply_async\")\n    setattr(\n        pool.Pool,\n        apply_async_func.__name__,\n        wrap_apply_async(apply_async_func),\n    )\n\n    # Wrap the threading run function\n    submit_func = getattr(futures.ThreadPoolExecutor, \"submit\")\n    setattr(\n        futures.ThreadPoolExecutor,\n        submit_func.__name__,\n        wrap_submit(submit_func),\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef wrap_threading_start(start_func):\n\n    def call(self):\n        self._opencensus_context = (\n            execution_context.get_opencensus_full_context()\n        )\n        return start_func(self)\n\n    return call", "response": "Wrap the start function from thread."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef wrap_threading_run(run_func):\n\n    def call(self):\n        execution_context.set_opencensus_full_context(\n            *self._opencensus_context\n        )\n        return run_func(self)\n\n    return call", "response": "Wrap the run function from thread."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwrapping the apply_async function of multiprocessing. pools. Get the function that will be called and wrap it then add the opencensus context.", "response": "def wrap_apply_async(apply_async_func):\n    \"\"\"Wrap the apply_async function of multiprocessing.pools. Get the function\n    that will be called and wrap it then add the opencensus context.\"\"\"\n\n    def call(self, func, args=(), kwds={}, **kwargs):\n        wrapped_func = wrap_task_func(func)\n        _tracer = execution_context.get_opencensus_tracer()\n        propagator = binary_format.BinaryFormatPropagator()\n\n        wrapped_kwargs = {}\n        wrapped_kwargs[\"span_context_binary\"] = propagator.to_header(\n            _tracer.span_context\n        )\n        wrapped_kwargs[\"kwds\"] = kwds\n        wrapped_kwargs[\"sampler\"] = _tracer.sampler\n        wrapped_kwargs[\"exporter\"] = _tracer.exporter\n        wrapped_kwargs[\"propagator\"] = _tracer.propagator\n\n        return apply_async_func(\n            self, wrapped_func, args=args, kwds=wrapped_kwargs, **kwargs\n        )\n\n    return call"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwraps the apply_async function of multiprocessing. pools. Get the function that will be called and wrap it then add the opencensus context.", "response": "def wrap_submit(submit_func):\n    \"\"\"Wrap the apply_async function of multiprocessing.pools. Get the function\n    that will be called and wrap it then add the opencensus context.\"\"\"\n\n    def call(self, func, *args, **kwargs):\n        wrapped_func = wrap_task_func(func)\n        _tracer = execution_context.get_opencensus_tracer()\n        propagator = binary_format.BinaryFormatPropagator()\n\n        wrapped_kwargs = {}\n        wrapped_kwargs[\"span_context_binary\"] = propagator.to_header(\n            _tracer.span_context\n        )\n        wrapped_kwargs[\"kwds\"] = kwargs\n        wrapped_kwargs[\"sampler\"] = _tracer.sampler\n        wrapped_kwargs[\"exporter\"] = _tracer.exporter\n        wrapped_kwargs[\"propagator\"] = _tracer.propagator\n\n        return submit_func(self, wrapped_func, *args, **wrapped_kwargs)\n\n    return call"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef format_attributes_json(self):\n        attributes_json = {}\n\n        for key, value in self.attributes.items():\n            key = utils.check_str_length(key)[0]\n            value = _format_attribute_value(value)\n\n            if value is not None:\n                attributes_json[key] = value\n\n        result = {\n            'attributeMap': attributes_json\n        }\n\n        return result", "response": "Convert the Attributes object to json format."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_point(self, timestamp):\n        return point.Point(value.ValueDouble(self.sum_data), timestamp)", "response": "Get a Point conversion of this aggregation."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_point(self, timestamp):\n        return point.Point(value.ValueLong(self.count_data), timestamp)", "response": "Get a Point conversion of this aggregation."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a sample to the Distribution Aggregation Data", "response": "def add_sample(self, value, timestamp, attachments):\n        \"\"\"Adding a sample to Distribution Aggregation Data\"\"\"\n        self._count_data += 1\n        bucket = self.increment_bucket_count(value)\n\n        if attachments is not None and self.exemplars is not None:\n            self.exemplars[bucket] = Exemplar(value, timestamp, attachments)\n        if self.count_data == 1:\n            self._mean_data = value\n            return\n\n        old_mean = self._mean_data\n        self._mean_data = self._mean_data + (\n            (value - self._mean_data) / self._count_data)\n        self._sum_of_sqd_deviations = self._sum_of_sqd_deviations + (\n            (value - old_mean) * (value - self._mean_data))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef increment_bucket_count(self, value):\n        if len(self._bounds) == 0:\n            self._counts_per_bucket[0] += 1\n            return 0\n\n        for ii, bb in enumerate(self._bounds):\n            if value < bb:\n                self._counts_per_bucket[ii] += 1\n                return ii\n        else:\n            last_bucket_index = len(self._bounds)\n            self._counts_per_bucket[last_bucket_index] += 1\n            return last_bucket_index", "response": "Increment the bucket count based on a given value from the user"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget a Point conversion of this aggregation. This method creates a :class: `opencensus.metrics.export.point.Point` with a :class: `opencensus.metrics.export.value.ValueDistribution` value, and creates buckets and exemplars for that distribution from the appropriate classes in the `metrics` package. If the distribution doesn't have a histogram (i.e. `bounds` is empty) the converted point's `buckets` attribute will be null. :type timestamp: :class: `datetime.datetime` :param timestamp: The time to report the point as having been recorded. :rtype: :class: `opencensus.metrics.export.point.Point` :return: a :class: `opencensus.metrics.export.value.ValueDistribution` -valued Point.", "response": "def to_point(self, timestamp):\n        \"\"\"Get a Point conversion of this aggregation.\n\n        This method creates a :class: `opencensus.metrics.export.point.Point`\n        with a :class: `opencensus.metrics.export.value.ValueDistribution`\n        value, and creates buckets and exemplars for that distribution from the\n        appropriate classes in the `metrics` package. If the distribution\n        doesn't have a histogram (i.e. `bounds` is empty) the converted point's\n        `buckets` attribute will be null.\n\n        :type timestamp: :class: `datetime.datetime`\n        :param timestamp: The time to report the point as having been recorded.\n\n        :rtype: :class: `opencensus.metrics.export.point.Point`\n        :return: a :class: `opencensus.metrics.export.value.ValueDistribution`\n        -valued Point.\n        \"\"\"\n        if self.bounds:\n            bucket_options = value.BucketOptions(value.Explicit(self.bounds))\n            buckets = [None] * len(self.counts_per_bucket)\n            for ii, count in enumerate(self.counts_per_bucket):\n                stat_ex = self.exemplars.get(ii) if self.exemplars else None\n                if stat_ex is not None:\n                    metric_ex = value.Exemplar(stat_ex.value,\n                                               stat_ex.timestamp,\n                                               copy.copy(stat_ex.attachments))\n                    buckets[ii] = value.Bucket(count, metric_ex)\n                else:\n                    buckets[ii] = value.Bucket(count)\n\n        else:\n            bucket_options = value.BucketOptions()\n            buckets = None\n        return point.Point(\n            value.ValueDistribution(\n                count=self.count_data,\n                sum_=self.sum,\n                sum_of_squared_deviation=self.sum_of_sqd_deviations,\n                bucket_options=bucket_options,\n                buckets=buckets\n            ),\n            timestamp\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef rss_parse(self, response):\n        # get last_update zip url\n        match = re.match(re_export, response.text)\n        if match:\n            last_update_zip_url = match.group(1)\n            # fetch zip file\n            r = requests.get(last_update_zip_url)\n            # unzip\n            z = zipfile.ZipFile(io.BytesIO(r.content))\n            extracted = z.namelist()\n            z.extractall('/tmp')\n            csv_file_path = '/tmp/%s' % extracted[0]\n            # read csv to get all urls\n            urls = set()  # set to remove duplicates\n            with open(csv_file_path) as csv_file:\n                csv_reader = csv.reader(csv_file, delimiter='\\t')\n                for row in csv_reader:\n                    urls.add(row[-1])\n            # rm the file\n            os.remove(csv_file_path)\n            for url in urls:\n                yield scrapy.Request(url, lambda resp: self.article_parse(\n                    resp, 'gdelt'))", "response": "Parse the response from the RSS feed and return a generator of scrapy. Request objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef article_parse(self, response, rss_title=None):\n        if not self.helper.parse_crawler.content_type(response):\n            return\n\n        yield self.helper.parse_crawler.pass_to_pipeline_if_article(\n            response, self.ignored_allowed_domain, self.original_url,\n            rss_title)", "response": "Checks if the response is an article and passes it to the pipeline."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a single crawler as in library mode.", "response": "def create_as_library(cls, url):\n        \"\"\"\n        Creates a single crawler as in library mode. Crawling will start immediately.\n        :param url:\n        :return:\n        \"\"\"\n        site = {\n            \"crawler\": \"Download\",\n            \"url\": url\n        }\n        cfg_file_path = os.path.dirname(__file__) + os.path.sep + 'config' + os.path.sep + 'config_lib.cfg'\n        return cls(cfg_file_path, site, 0, False, False, True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update_jobdir(self, site):\n        working_path = self.cfg.get_working_path()\n        if not working_path.endswith(\"/\"):\n            working_path += \"/\"\n        jobdirname = self.__scrapy_options[\"JOBDIRNAME\"]\n        if not jobdirname.endswith(\"/\"):\n            jobdirname += \"/\"\n\n        site_string = ''.join(site[\"url\"]) + self.crawler_name\n        hashed = hashlib.md5(site_string.encode('utf-8'))\n\n        self.__scrapy_options[\"JOBDIR\"] = working_path + jobdirname + hashed.hexdigest()", "response": "Update the JOBDIR in the crawler with the site dict extracted from the json file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_crawler(self, crawler, url):\n        checked_crawlers = []\n        while crawler is not None and crawler not in checked_crawlers:\n            checked_crawlers.append(crawler)\n            current = self.get_crawler_class(crawler)\n            if hasattr(current, \"supports_site\"):\n                supports_site = getattr(current, \"supports_site\")\n                if callable(supports_site):\n                    if supports_site(url):\n                        self.log.debug(\"Using crawler %s for %s.\",\n                                       crawler, url)\n                        return current\n                    elif (crawler in self.cfg_crawler[\"fallbacks\"] and\n                                  self.cfg_crawler[\"fallbacks\"][crawler] is not None):\n                        self.log.warn(\"Crawler %s not supported by %s. \"\n                                      \"Trying to fall back.\", crawler, url)\n                        crawler = self.cfg_crawler[\"fallbacks\"][crawler]\n                    else:\n                        self.log.error(\"No crawlers (incl. fallbacks) \"\n                                       \"found for url %s.\", url)\n                        raise RuntimeError(\"No crawler found. Quit.\")\n            else:\n                self.log.warning(\"The crawler %s has no \"\n                                 \"supports_site-method defined\", crawler)\n                return current\n        self.log.error(\"Could not fall back since you created a fall back \"\n                       \"loop for %s in the config file.\", crawler)\n        sys.exit(1)", "response": "Checks if a crawler supports a website and falls back to the fallbacks defined in the config file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the class of the crawler with the given name.", "response": "def get_crawler_class(self, crawler):\n        \"\"\"\n        Searches through the modules in self.__crawer_module for a crawler with\n        the name passed along.\n\n        :param str crawler: Name of the crawler to load\n        :rtype: crawler-class\n        \"\"\"\n        settings = Settings()\n        settings.set('SPIDER_MODULES', [self.__crawer_module])\n        spider_loader = SpiderLoader(settings)\n        return spider_loader.load(crawler)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads the given crawler with the given url.", "response": "def load_crawler(self, crawler, url, ignore_regex):\n        \"\"\"\n        Loads the given crawler with the given url.\n\n        :param class crawler: class of the crawler to load\n        :param str url: url to start the crawler with\n        :param regex ignore_regex: to be able to ignore urls that match this\n                                   regex code\n        \"\"\"\n        self.process = CrawlerProcess(self.cfg.get_scrapy_options())\n        self.process.crawl(\n            crawler,\n            self.helper,\n            url=url,\n            config=self.cfg,\n            ignore_regex=ignore_regex)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef remove_jobdir_if_not_resume(self):\n        jobdir = self.__scrapy_options[\"JOBDIR\"]\n\n        if (not self.shall_resume or self.daemonize) \\\n                and os.path.exists(jobdir):\n            shutil.rmtree(jobdir)\n\n            self.log.info(\"Removed \" + jobdir + \" since '--resume' was not passed to\"\n                                                \" initial.py or this crawler was daemonized.\")", "response": "This method removes the jobdir if the resume option is not passed to the initial. py script."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the language of the extracted article by analyzing metatags and inspecting the visible text with langdetect", "response": "def _language(self, item):\n        \"\"\"Returns the language of the extracted article by analyzing metatags and inspecting the visible text\n        with langdetect\"\"\"\n\n        response = item['spider_response'].body\n        root = html.fromstring(response)\n\n        # Check for lang-attributes\n        lang = root.get('lang')\n\n        if lang is None:\n            lang = root.get('xml:lang')\n\n        # Check for general meta tags\n        if lang is None:\n            meta = root.cssselect('meta[name=\"language\"]')\n            if len(meta) > 0:\n                lang = meta[0].get('content')\n\n        # Check for open graph tags\n        if lang is None:\n            meta = root.cssselect('meta[property=\"og:locale\"]')\n            if len(meta) > 0:\n                lang = meta[0].get('content')\n\n        # Look for <article> elements and inspect the one with the largest payload with langdetect\n        if lang is None:\n            article_list = []\n            for article in root.xpath('//article'):\n                article_list.append(re.sub(r'\\s+', ' ', article.text_content().strip()))\n                if len(article_list) > 0:\n                    lang = detect(max(article_list))\n\n        # Analyze the whole body with langdetect\n        if lang is None:\n            try:\n                lang = detect(root.text_content().strip())\n            except LangDetectException:\n                pass\n\n        # Try to normalize output\n        if lang is not None:\n            # First search for suitable locale in the original output\n            matches = self.langcode_pattern.search(lang)\n            if matches is not None:\n                lang = matches.group(0)\n            else:\n                # If no match was found, normalize the original output and search again\n                normalized = locale.normalize(re.split(r'\\s|;|,', lang.strip())[0])\n                matches = self.langcode_pattern.search(normalized)\n                if matches is not None:\n                    lang = matches.group(0)\n\n        return lang"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nextracting relevant information from a WARC record.", "response": "def from_warc(warc_record):\n        \"\"\"\n        Extracts relevant information from a WARC record. This function does not invoke scrapy but only uses the article\n        extractor.\n        :return:\n        \"\"\"\n        html = str(warc_record.raw_stream.read())\n        url = warc_record.rec_headers.get_header('WARC-Target-URI')\n        download_date = warc_record.rec_headers.get_header('WARC-Date')\n        article = NewsPlease.from_html(html, url=url, download_date=download_date)\n        return article"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_html(html, url=None, download_date=None):\n        extractor = article_extractor.Extractor(\n            ['newspaper_extractor', 'readability_extractor', 'date_extractor', 'lang_detect_extractor'])\n\n        title_encoded = ''.encode()\n        if not url:\n            url = ''\n\n        # if an url was given, we can use that as the filename\n        filename = urllib.parse.quote_plus(url) + '.json'\n\n        item = NewscrawlerItem()\n        item['spider_response'] = DotMap()\n        item['spider_response'].body = html\n        item['url'] = url\n        item['source_domain'] = urllib.parse.urlparse(url).hostname.encode() if url != '' else ''.encode()\n        item['html_title'] = title_encoded\n        item['rss_title'] = title_encoded\n        item['local_path'] = None\n        item['filename'] = filename\n        item['download_date'] = download_date\n        item['modified_date'] = None\n        item = extractor.extract(item)\n\n        tmp_article = ExtractedInformationStorage.extract_relevant_info(item)\n        final_article = ExtractedInformationStorage.convert_to_class(tmp_article)\n        return final_article", "response": "Extracts relevant information from an HTML page given as a string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef from_url(url, timeout=None):\n        articles = NewsPlease.from_urls([url], timeout=timeout)\n        if url in articles.keys():\n            return articles[url]\n        else:\n            return None", "response": "Reads the url and extracts relevant information."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngives a list of URLs and a timeout returns a dictionary containing the relevant information as keys and corresponding values.", "response": "def from_urls(urls, timeout=None):\n        \"\"\"\n        Crawls articles from the urls and extracts relevant information.\n        :param urls:\n        :param timeout: in seconds, if None, the urllib default is used\n        :return: A dict containing given URLs as keys, and extracted information as corresponding values.\n        \"\"\"\n        results = {}\n        download_date = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n\n        if len(urls) == 0:\n            # Nested blocks of code should not be left empty.\n            # When a block contains a comment, this block is not considered to be empty\n            pass\n        elif len(urls) == 1:\n            url = urls[0]\n            html = SimpleCrawler.fetch_url(url, timeout=timeout)\n            results[url] = NewsPlease.from_html(html, url, download_date)\n        else:\n            results = SimpleCrawler.fetch_urls(urls)\n            for url in results:\n                results[url] = NewsPlease.from_html(results[url], url, download_date)\n\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading the contents of a file containing URLs and extracts relevant information.", "response": "def from_file(path):\n        \"\"\"\n        Crawls articles from the urls and extracts relevant information.\n        :param path: path to file containing urls (each line contains one URL)\n        :return: A dict containing given URLs as keys, and extracted information as corresponding values.\n        \"\"\"\n        with open(path) as f:\n            content = f.readlines()\n        content = [x.strip() for x in content]\n        urls = list(filter(None, content))\n\n        return NewsPlease.from_urls(urls)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse the response and pass it to the pipeline.", "response": "def parse(self, response):\n        \"\"\"\n        Passes the response to the pipeline.\n\n        :param obj response: The scrapy response\n        \"\"\"\n        if not self.helper.parse_crawler.content_type(response):\n            return\n\n        yield self.helper.parse_crawler.pass_to_pipeline(\n            response,\n            self.helper.url_extractor.get_allowed_domain(response.url)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _fetch_url(url, is_threaded, timeout=None):\n        headers = {'User-Agent': 'Mozilla/5.0'}\n        req = urllib.request.Request(url, None, headers)\n        html = urllib.request.urlopen(req, data=None, timeout=timeout).read()\n\n        if is_threaded:\n            SimpleCrawler._results[url] = html\n\n        return html", "response": "Fetches the html content of the url and saves it in _results\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fetch_urls(urls, timeout=None):\n        threads = [threading.Thread(target=SimpleCrawler._fetch_url, args=(url, True, timeout)) for url in urls]\n        for thread in threads:\n            thread.start()\n        for thread in threads:\n            thread.join()\n\n        results = copy.deepcopy(SimpleCrawler._results)\n        SimpleCrawler._results = {}\n        return results", "response": "Fetch all given urls in parallel. Returns when all requests are processed."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef extract(self, item, list_article_candidate):\n\n        # Save extracted languages in list\n        languages_extracted = []\n\n        # Save the extracted language of newspaper in extra variable, because newspaper extract meta-language\n        # which is very accurate.\n        language_newspaper = None\n\n        for article_candidate in list_article_candidate:\n\n            if article_candidate.language is not None:\n                languages_extracted.append(article_candidate.language)\n\n                if article_candidate.extractor == \"newspaper\":\n                    language_newspaper = article_candidate.language\n\n        if not languages_extracted:\n            return None\n\n        # Create a set of the extracted languages, so every lang appears once\n        languages_extracted_set = set(languages_extracted)\n\n        # Count how often every language has been extracted\n        languages_extracted_number = []\n\n        for language in languages_extracted_set:\n            languages_extracted_number.append((languages_extracted.count(language), language))\n\n        if not (languages_extracted_number):\n            return None\n\n        # If there is no favorite language, return the language extracted by newspaper\n        if max(languages_extracted_number)[0] == min(languages_extracted_number)[0] and language_newspaper is not None:\n            return language_newspaper\n\n        if languages_extracted_number:\n            return (max(languages_extracted_number))[1]\n        else:\n            return None", "response": "Compares how often any language was detected and returns the most frequently detected language."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef extract(self, item, list_article_candidate):\n        list_publish_date = []\n\n        for article_candidate in list_article_candidate:\n            if article_candidate.publish_date != None:\n                list_publish_date.append((article_candidate.publish_date, article_candidate.extractor))\n\n        # If there is no value in the list, return None.\n        if len(list_publish_date) == 0:\n            return None\n\n        # If there are more options than one, return the result from date_extractor.\n        list_date_extractor = [x for x in list_publish_date if x[1] == \"date_extractor\"]\n        if len(list_date_extractor) == 0:\n\n            # If there is no date extracted by date_extractor, return the first result of list_publish_date.\n            return list_publish_date[0][0]\n        else:\n            return list_date_extractor[0][0]", "response": "Compares the extracted publish dates."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndetermine if the response s meta data contains the keyword article", "response": "def meta_contains_article_keyword(self, response, site_dict):\n        \"\"\"\n        Determines wether the response's meta data contains the keyword\n        'article'\n\n        :param obj response: The scrapy response\n        :param dict site_dict: The site object from the JSON-File\n\n        :return bool: Determines wether the reponse's meta data contains the\n                      keyword 'article'\n        \"\"\"\n        contains_meta = response.xpath('//meta') \\\n            .re('(= ?[\"\\'][^\"\\']*article[^\"\\']*[\"\\'])')\n\n        if not contains_meta:\n            return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if the site contains a meta - tag which contains property = og : type and content = article", "response": "def og_type(response, site_dict):\n        \"\"\"\n        Check if the site contains a meta-tag which contains\n        property=\"og:type\" and content=\"article\"\n\n        :param obj response: The scrapy response\n        :param dict site_dict: The site object from the JSON-File\n\n        :return bool: True if the tag is contained.\n        \"\"\"\n        og_type_article = response.xpath('//meta') \\\n            .re('(property=[\"\\']og:type[\"\\'].*content=[\"\\']article[\"\\'])|'\n                '(content=[\"\\']article[\"\\'].*property=[\"\\']og:type[\"\\'])')\n        if not og_type_article:\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks how many of the headlines on the site contain links.", "response": "def linked_headlines(self, response, site_dict, check_self=False):\n        \"\"\"\n        Checks how many of the headlines on the site contain links.\n\n        :param obj response: The scrapy response\n        :param dict site_dict: The site object from the JSON-File\n        :param bool check_self: Check headlines/\n                                headlines_containing_link_to_same_domain\n                                instead of headline/headline_containing_link\n\n        :return float: ratio headlines/headlines_containing_link\n        \"\"\"\n        h_all = 0\n        h_linked = 0\n        domain = UrlExtractor.get_allowed_domain(site_dict[\"url\"], False)\n\n        # This regex checks, if a link containing site_domain as domain\n        # is contained in a string.\n        site_regex = r\"href=[\\\"'][^\\/]*\\/\\/(?:[^\\\"']*\\.|)%s[\\\"'\\/]\" % domain\n        for i in range(1, 7):\n            for headline in response.xpath('//h%s' % i).extract():\n                h_all += 1\n                if \"href\" in headline and (\n                            not check_self or re.search(site_regex, headline)\n                        is not None):\n                    h_linked += 1\n\n        self.log.debug(\"Linked headlines test: headlines = %s, linked = %s\",\n                       h_all, h_linked)\n\n        min_headlines = self.cfg_heuristics[\"min_headlines_for_linked_test\"]\n        if min_headlines > h_all:\n            self.log.debug(\"Linked headlines test: Not enough headlines \"\n                           \"(%s < %s): Passing!\", h_all, min_headlines)\n            return True\n\n        return float(h_linked) / float(h_all)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndetermining if the response s url is not from a subdomain.", "response": "def is_not_from_subdomain(self, response, site_dict):\n        \"\"\"\n        Ensures the response's url isn't from a subdomain.\n\n        :param obj response: The scrapy response\n        :param dict site_dict: The site object from the JSON-File\n\n        :return bool: Determines if the response's url is from a subdomain\n        \"\"\"\n\n        root_url = re.sub(re_url_root, '', site_dict[\"url\"])\n        return UrlExtractor.get_allowed_domain(response.url) == root_url"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef extract(self, item, list_article_candidate):\n        list_description = []\n\n        \"\"\" The descriptions of the article candidates and the respective extractors are saved\n        in a tuple in list_description.\n        \"\"\"\n        for article_candidate in list_article_candidate:\n            if article_candidate.description != None:\n                list_description.append((article_candidate.description, article_candidate.extractor))\n\n        # If there is no value in the list, return None.\n        if len(list_description) == 0:\n            return None\n\n        # If there are more options than one, return the result from newspaper.\n        list_newspaper = [x for x in list_description if x[1] == \"newspaper\"]\n        if len(list_newspaper) == 0:\n\n            # If there is no description extracted by newspaper, return the first result of list_description.\n            return list_description[0][0]\n        else:\n            return list_newspaper[0][0]", "response": "Compares the extracted descriptions and returns the most likely description."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing the response and pass it to the pipeline.", "response": "def parse(self, response):\n        \"\"\"\n        Checks any given response on being an article and if positiv,\n        passes the response to the pipeline.\n\n        :param obj response: The scrapy response\n        \"\"\"\n        if not self.helper.parse_crawler.content_type(response):\n            return\n\n        yield self.helper.parse_crawler.pass_to_pipeline_if_article(\n            response, self.allowed_domains[0], self.original_url)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprocessing an item from the database and store it in the database.", "response": "def process_item(self, item, spider):\n        \"\"\"\n        Store item data in DB.\n        First determine if a version of the article already exists,\n          if so then 'migrate' the older version to the archive table.\n        Second store the new article in the current version table\n        \"\"\"\n\n        # Set defaults\n        version = 1\n        ancestor = 0\n\n        # Search the CurrentVersion table for an old version of the article\n        try:\n            self.cursor.execute(self.compare_versions, (item['url'],))\n        except (pymysql.err.OperationalError, pymysql.ProgrammingError, pymysql.InternalError,\n                pymysql.IntegrityError, TypeError) as error:\n            self.log.error(\"Something went wrong in query: %s\", error)\n\n        # Save the result of the query. Must be done before the add,\n        # otherwise the result will be overwritten in the buffer\n        old_version = self.cursor.fetchone()\n\n        if old_version is not None:\n            old_version_list = {\n                'db_id': old_version[0],\n                'local_path': old_version[1],\n                'modified_date': old_version[2],\n                'download_date': old_version[3],\n                'source_domain': old_version[4],\n                'url': old_version[5],\n                'html_title': old_version[6],\n                'ancestor': old_version[7],\n                'descendant': old_version[8],\n                'version': old_version[9],\n                'rss_title': old_version[10], }\n\n            # Update the version number and the ancestor variable for later references\n            version = (old_version[9] + 1)\n            ancestor = old_version[0]\n\n        # Add the new version of the article to the CurrentVersion table\n        current_version_list = {\n            'local_path': item['local_path'],\n            'modified_date': item['modified_date'],\n            'download_date': item['download_date'],\n            'source_domain': item['source_domain'],\n            'url': item['url'],\n            'html_title': item['html_title'],\n            'ancestor': ancestor,\n            'descendant': 0,\n            'version': version,\n            'rss_title': item['rss_title'], }\n\n        try:\n            self.cursor.execute(self.insert_current, current_version_list)\n            self.conn.commit()\n            self.log.info(\"Article inserted into the database.\")\n        except (pymysql.err.OperationalError, pymysql.ProgrammingError, pymysql.InternalError,\n                pymysql.IntegrityError, TypeError) as error:\n            self.log.error(\"Something went wrong in commit: %s\", error)\n\n        # Move the old version from the CurrentVersion table to the ArchiveVersions table\n        if old_version is not None:\n            # Set descendant attribute\n            try:\n                old_version_list['descendant'] = self.cursor.lastrowid\n            except (pymysql.err.OperationalError, pymysql.ProgrammingError, pymysql.InternalError,\n                    pymysql.IntegrityError, TypeError) as error:\n                self.log.error(\"Something went wrong in id query: %s\", error)\n\n            # Delete the old version of the article from the CurrentVersion table\n            try:\n                self.cursor.execute(self.delete_from_current, old_version_list['db_id'])\n                self.conn.commit()\n            except (pymysql.err.OperationalError, pymysql.ProgrammingError, pymysql.InternalError,\n                    pymysql.IntegrityError, TypeError) as error:\n                self.log.error(\"Something went wrong in delete: %s\", error)\n\n            # Add the old version to the ArchiveVersion table\n            try:\n                self.cursor.execute(self.insert_archive, old_version_list)\n                self.conn.commit()\n                self.log.info(\"Moved old version of an article to the archive.\")\n            except (pymysql.err.OperationalError, pymysql.ProgrammingError, pymysql.InternalError,\n                    pymysql.IntegrityError, TypeError) as error:\n                self.log.error(\"Something went wrong in archive: %s\", error)\n\n        return item"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef extract_relevant_info(item):\n        article = {\n            'authors': item['article_author'],\n            'date_download': item['download_date'],\n            'date_modify': item['modified_date'],\n            'date_publish': item['article_publish_date'],\n            'description': item['article_description'],\n            'filename': item['filename'],\n            'image_url': item['article_image'],\n            'language': item['article_language'],\n            'localpath': item['local_path'],\n            'title': item['article_title'],\n            'title_page': ExtractedInformationStorage.ensure_str(item['html_title']),\n            'title_rss': ExtractedInformationStorage.ensure_str(item['rss_title']),\n            'source_domain': ExtractedInformationStorage.ensure_str(item['source_domain']),\n            'text': item['article_text'],\n            'url': item['url']\n        }\n\n        # clean values\n        for key in article:\n            value = article[key]\n            if isinstance(value, str) and not value:\n                article[key] = None\n\n        return article", "response": "extracts from an item only fields that we want to output as extracted information"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwriting out to file.", "response": "def close_spider(self, _spider):\n        \"\"\"\n        Write out to file\n        \"\"\"\n        self.df['date_download'] = pd.to_datetime(\n            self.df['date_download'], errors='coerce', infer_datetime_format=True\n        )\n        self.df['date_modify'] = pd.to_datetime(\n            self.df['date_modify'], errors='coerce', infer_datetime_format=True\n        )\n        self.df['date_publish'] = pd.to_datetime(\n            self.df['date_publish'], errors='coerce', infer_datetime_format=True\n        )\n        self.df.to_pickle(self.full_path)\n        self.log.info(\"Wrote to Pandas to %s\", self.full_path)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the publish_date of the extracted article.", "response": "def _publish_date(self, item):\n        \"\"\"Returns the publish_date of the extracted article.\"\"\"\n\n        url = item['url']\n        html = deepcopy(item['spider_response'].body)\n        publish_date = None\n\n        try:\n            if html is None:\n                request = urllib2.Request(url)\n                # Using a browser user agent, decreases the change of sites blocking this request - just a suggestion\n                # request.add_header('User-Agent', 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko)\n                # Chrome/41.0.2228.0 Safari/537.36')\n                html = urllib2.build_opener().open(request).read()\n\n            html = BeautifulSoup(html, \"lxml\")\n\n            publish_date = self._extract_from_json(html)\n            if publish_date is None:\n                publish_date = self._extract_from_meta(html)\n            if publish_date is None:\n                publish_date = self._extract_from_html_tag(html)\n            if publish_date is None:\n                publish_date = self._extract_from_url(url)\n        except Exception as e:\n            # print(e.message, e.args)\n            pass\n\n        return publish_date"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _extract_from_url(self, url):\n\n        # Regex by Newspaper3k  - https://github.com/codelucas/newspaper/blob/master/newspaper/urls.py\n        m = re.search(re_pub_date, url)\n        if m:\n            return self.parse_date_str(m.group(0))\n        return None", "response": "Try to extract from the article URL - simple but might work as a fallback"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse(self, response):\n        if not self.helper.parse_crawler.content_type(response):\n            return\n\n        for request in self.helper.parse_crawler \\\n                .recursive_requests(response, self, self.ignore_regex,\n                                    self.ignore_file_extensions):\n            yield request\n\n        yield self.helper.parse_crawler.pass_to_pipeline_if_article(\n            response, self.allowed_domains[0], self.original_url)", "response": "Parse the response and yield the request objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves html - tags from extracted data.", "response": "def delete_tags(self, arg):\n        \"\"\"Removes html-tags from extracted data.\n\n        :param arg: A string, the string which shall be cleaned\n        :return: A string, the cleaned string\n        \"\"\"\n\n        if len(arg) > 0:\n            raw = html.fromstring(arg)\n            return raw.text_content().strip()\n\n        return arg"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef delete_whitespaces(self, arg):\n        # Deletes whitespaces after a newline\n        arg = re.sub(re_newline_spc, '', arg)\n        # Deletes every whitespace, tabulator, newline at the beginning of the string\n        arg = re.sub(re_starting_whitespc, '', arg)\n        # Deletes whitespace or tabulator if followed by whitespace or tabulator\n        arg = re.sub(re_multi_spc_tab, '', arg)\n        #  Deletes newline if it is followed by an other one\n        arg = re.sub(re_double_newline, '', arg)\n        # Deletes newlines and whitespaces at the end of the string\n        arg = re.sub(re_ending_spc_newline, '', arg)\n        return arg", "response": "Removes newlines tabs and whitespaces at the beginning and end of the string which shell be cleaned\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef do_cleaning(self, arg):\n        if arg is not None:\n            if isinstance(arg, list):\n                newlist = []\n                for entry in arg:\n                    newlist.append(self.do_cleaning(entry))\n                return newlist\n            else:\n                if sys.version_info[0] < 3:\n                    arg = unicode(arg)\n                else:\n                    arg = str(arg)\n                arg = self.delete_tags(arg)\n                arg = self.delete_whitespaces(arg)\n                return arg\n        else:\n            return None", "response": "Does the actual cleaning by using the delete methods above."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\niterating over each article_candidate and cleans every extracted data. :param list_article_candidates: A list, the list of ArticleCandidate-Objects which have been extracted :return: A list, the list with the cleaned ArticleCandidate-Objects", "response": "def clean(self, list_article_candidates):\n        \"\"\"Iterates over each article_candidate and cleans every extracted data.\n\n        :param list_article_candidates: A list, the list of ArticleCandidate-Objects which have been extracted\n        :return: A list, the list with the cleaned ArticleCandidate-Objects\n        \"\"\"\n        # Save cleaned article_candidates in results.\n        results = []\n\n        for article_candidate in list_article_candidates:\n            article_candidate.title = self.do_cleaning(article_candidate.title)\n            article_candidate.description = self.do_cleaning(article_candidate.description)\n            article_candidate.text = self.do_cleaning(article_candidate.text)\n            article_candidate.topimage = self.do_cleaning(article_candidate.topimage)\n            article_candidate.author = self.do_cleaning(article_candidate.author)\n            article_candidate.publish_date = self.do_cleaning(article_candidate.publish_date)\n\n            results.append(article_candidate)\n\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting a serializable dict of the instance of this class.", "response": "def get_serializable_dict(self):\n        \"\"\"\n        Get a serializable dict of the instance of this class.\n        :return:\n        \"\"\"\n        tmp = self.get_dict()\n        tmp['date_download'] = str(tmp['date_download'])\n        tmp['date_modify'] = str(tmp['date_modify'])\n        tmp['date_publish'] = str(tmp['date_publish'])\n        return tmp"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_dict(self):\n        return {\n            'authors': self.authors,\n            'date_download': self.date_download,\n            'date_modify': self.date_modify,\n            'date_publish': self.date_publish,\n            'description': self.description,\n            'filename': self.filename,\n            'image_url': self.image_url,\n            'language': self.language,\n            'localpath': self.localpath,\n            'source_domain': self.source_domain,\n            'text': self.text,\n            'title': self.title,\n            'title_page': self.title_page,\n            'title_rss': self.title_rss,\n            'url': self.url\n        }", "response": "Get the dict of the instance of this class."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompare the article candidates using the different submodules and saves the best results in the new ArticleCandidate object", "response": "def compare(self, item, article_candidates):\n        \"\"\"Compares the article candidates using the different submodules and saves the best results in\n        new ArticleCandidate object\n\n        :param item: The NewscrawlerItem related to the ArticleCandidates\n        :param article_candidates: The list of ArticleCandidate-Objects which have been extracted\n        :return: An ArticleCandidate-object containing the best results\n        \"\"\"\n\n        result = ArticleCandidate()\n\n        result.title = self.comparer_title.extract(item, article_candidates)\n        result.description = self.comparer_desciption.extract(item, article_candidates)\n        result.text = self.comparer_text.extract(item, article_candidates)\n        result.topimage = self.comparer_topimage.extract(item, article_candidates)\n        result.author = self.comparer_author.extract(item, article_candidates)\n        result.publish_date = self.comparer_date.extract(item, article_candidates)\n        result.language = self.comparer_language.extract(item, article_candidates)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nextract the Rss Feed and initiates crawling it. :param obj response: The scrapy response", "response": "def parse(self, response):\n        \"\"\"\n        Extracts the Rss Feed and initiates crawling it.\n\n        :param obj response: The scrapy response\n        \"\"\"\n        yield scrapy.Request(self.helper.url_extractor.get_rss_url(response),\n                             callback=self.rss_parse)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nextract all article links and initiates crawling them.", "response": "def rss_parse(self, response):\n        \"\"\"\n        Extracts all article links and initiates crawling them.\n\n        :param obj response: The scrapy response\n        \"\"\"\n        for item in response.xpath('//item'):\n            for url in item.xpath('link/text()').extract():\n                yield scrapy.Request(url, lambda resp: self.article_parse(\n                    resp, item.xpath('title/text()').extract()[0]))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef supports_site(url):\n\n        # Follow redirects\n        opener = urllib2.build_opener(urllib2.HTTPRedirectHandler)\n        redirect = opener.open(url).url\n        response = urllib2.urlopen(redirect).read()\n\n        # Check if a standard rss feed exists\n        return re.search(re_rss, response.decode('utf-8')) is not None", "response": "Rss Crawler are supported if by every site containing an rss feed."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the path to the pretty file for the given article.", "response": "def __get_pretty_filepath(path, article):\n    \"\"\"\n    Pretty might be an euphemism, but this function tries to avoid too long filenames, while keeping some structure.\n    :param path:\n    :param name:\n    :return:\n    \"\"\"\n    short_filename = hashlib.sha256(article.filename.encode()).hexdigest()\n    sub_dir = article.source_domain\n    final_path = path + sub_dir + '/'\n    if not os.path.exists(final_path):\n        os.makedirs(final_path)\n    return final_path + short_filename + '.json'"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef on_valid_article_extracted(article):\n    # do whatever you need to do with the article (e.g., save it to disk, store it in ElasticSearch, etc.)\n    with open(__get_pretty_filepath(my_local_download_dir_article, article), 'w') as outfile:\n        if my_json_export_style == 0:\n            json.dump(article.__dict__, outfile, default=str, separators=(',', ':'))\n        elif my_json_export_style == 1:\n            json.dump(article.__dict__, outfile, default=str, indent=4, sort_keys=True)", "response": "This function is invoked when an article is extracted from the archived data and satisfies the filter criteria."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndetermine the url s domain.", "response": "def get_allowed_domain(url, allow_subdomains=True):\n        \"\"\"\n        Determines the url's domain.\n\n        :param str url: the url to extract the allowed domain from\n        :param bool allow_subdomains: determines wether to include subdomains\n        :return str: subdomains.domain.topleveldomain or domain.topleveldomain\n        \"\"\"\n        if allow_subdomains:\n            return re.sub(re_www, '', re.search(r'[^/]+\\.[^/]+', url).group(0))\n        else:\n            return re.search(re_domain, UrlExtractor.get_allowed_domain(url)).group(0)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_subdomain(url):\n        allowed_domain = UrlExtractor.get_allowed_domain(url)\n        return allowed_domain[:len(allowed_domain) - len(\n            UrlExtractor.get_allowed_domain(url, False))]", "response": "Determines the domain s subdomains."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef follow_redirects(url):\n        opener = urllib2.build_opener(urllib2.HTTPRedirectHandler)\n        return opener.open(url).url", "response": "Follow redirects to the url and return the actual address of the url"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the robots. txt from the url and return the robot. txt s address.", "response": "def get_sitemap_url(url, allow_subdomains):\n        \"\"\"\n        Determines the domain's robot.txt\n\n        :param str url: the url to work on\n        :param bool allow_subdomains: Determines if the robot.txt may be the\n                                      subdomain's\n        :return: the robot.txt's address\n        :raises Exception: if there's no robot.txt on the site's domain\n        \"\"\"\n        if allow_subdomains:\n            redirect = UrlExtractor.follow_redirects(\n                \"http://\" + UrlExtractor.get_allowed_domain(url)\n            )\n        else:\n            redirect = UrlExtractor.follow_redirects(\n                \"http://\" +\n                UrlExtractor.get_allowed_domain(url, False)\n            )\n        redirect = UrlExtractor.follow_redirects(url)\n\n        # Get robots.txt\n        parsed = urlparse(redirect)\n        if allow_subdomains:\n            url_netloc = parsed.netloc\n        else:\n            url_netloc = UrlExtractor.get_allowed_domain(\n                parsed.netloc, False)\n\n        robots = '{url.scheme}://{url_netloc}/robots.txt'.format(\n            url=parsed, url_netloc=url_netloc)\n\n        try:\n            urllib2.urlopen(robots)\n            return robots\n        except:\n            if allow_subdomains:\n                return UrlExtractor.get_sitemap_url(url, False)\n            else:\n                raise Exception('Fatal: no robots.txt found.')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if a sitemap is set in the robots. txt.", "response": "def sitemap_check(url):\n        \"\"\"\n        Sitemap-Crawler are supported by every site which have a\n        Sitemap set in the robots.txt.\n\n        :param str url: the url to work on\n        :return bool: Determines if Sitemap is set in the site's robots.txt\n        \"\"\"\n        response = urllib2.urlopen(UrlExtractor.get_sitemap_url(url, True))\n\n        # Check if \"Sitemap\" is set\n        return \"Sitemap:\" in response.read().decode('utf-8')"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndetermine the url s directory string.", "response": "def get_url_directory_string(url):\n        \"\"\"\n        Determines the url's directory string.\n\n        :param str url: the url to extract the directory string from\n        :return str: the directory string on the server\n        \"\"\"\n        domain = UrlExtractor.get_allowed_domain(url)\n\n        splitted_url = url.split('/')\n\n        # the following commented list comprehension could replace\n        # the following for, if not and break statement\n        # index = [index for index in range(len(splitted_url))\n        #          if not re.search(domain, splitted_url[index]) is None][0]\n        for index in range(len(splitted_url)):\n            if not re.search(domain, splitted_url[index]) is None:\n                if splitted_url[-1] is \"\":\n                    splitted_url = splitted_url[index + 1:-2]\n                else:\n                    splitted_url = splitted_url[index + 1:-1]\n                break\n\n        return '_'.join(splitted_url)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_url_file_name(url):\n        url_root_ext = os.path.splitext(url)\n\n        if len(url_root_ext[1]) <= MAX_FILE_EXTENSION_LENGTH:\n            return os.path.split(url_root_ext[0])[1]\n        else:\n            return os.path.split(url)[1]", "response": "Determines the url s file name."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading the config - file and stores it in self. config.", "response": "def load_config(self):\n        \"\"\"\n        Loads the config-file\n        \"\"\"\n        self.__config = {}\n\n        # Parse sections, its options and put it in self.config.\n        for section in self.sections:\n\n            self.__config[section] = {}\n            options = self.parser.options(section)\n\n            # Parse options of each section\n            for option in options:\n\n                try:\n                    opt = self.parser \\\n                        .get(section, option)\n                    try:\n                        self.__config[section][option] = literal_eval(opt)\n                    except (SyntaxError, ValueError):\n                        self.__config[section][option] = opt\n                        self.log_output.append(\n                            {\"level\": \"debug\",\n                             \"msg\": \"Option not literal_eval-parsable\"\n                                    \" (maybe string): [{0}] {1}\"\n                                 .format(section, option)})\n\n                    if self.__config[section][option] == -1:\n                        self.log_output.append(\n                            {\"level\": \"debug\",\n                             \"msg\": \"Skipping: [%s] %s\" % (section, option)}\n                        )\n                except ConfigParser.NoOptionError as exc:\n                    self.log_output.append(\n                        {\"level\": \"error\",\n                         \"msg\": \"Exception on [%s] %s: %s\"\n                                % (section, option, exc)}\n                    )\n                    self.__config[section][option] = None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of all options listed in the config section Scrapy", "response": "def get_scrapy_options(self):\n        \"\"\"\n        :return: all options listed in the config section 'Scrapy'\n        \"\"\"\n        if self.__scrapy_options is None:\n            self.__scrapy_options = {}\n            options = self.section(\"Scrapy\")\n\n            for key, value in options.items():\n                self.__scrapy_options[key.upper()] = value\n        return self.__scrapy_options"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nhandling logging for the current log - level.", "response": "def handle_logging(self):\n        \"\"\"\n        To allow devs to log as early as possible, logging will already be\n        handled here\n        \"\"\"\n\n        configure_logging(self.get_scrapy_options())\n\n        # Disable duplicates\n        self.__scrapy_options[\"LOG_ENABLED\"] = False\n\n        # Now, after log-level is correctly set, lets log them.\n        for msg in self.log_output:\n            if msg[\"level\"] is \"error\":\n                self.log.error(msg[\"msg\"])\n            elif msg[\"level\"] is \"info\":\n                self.log.info(msg[\"msg\"])\n            elif msg[\"level\"] is \"debug\":\n                self.log.debug(msg[\"msg\"])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the option from the config.", "response": "def option(self, option):\n        \"\"\"\n        Gets the option, set_section needs to be set before.\n\n        :param option (string): The option to get.\n        :return mixed: The option from from the config.\n        \"\"\"\n        if self.__current_section is None:\n            raise RuntimeError('No section set in option-getting')\n        return self.__config[self.__current_section][option]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the working path for the current user.", "response": "def get_working_path(self):\n        \"\"\"\n        Gets the working path. If the path starts with a ~, this will be replaced by the current user's home path.\n        :return:\n        \"\"\"\n        self.set_section('Files')\n        raw_path = self.option(\"working_path\")\n        if raw_path.startswith('~'):\n            raw_path = os.path.expanduser('~') + raw_path[1:]\n\n        return raw_path"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_url_array(self):\n        urlarray = []\n        for urlobjects in self.__json_object[\"base_urls\"]:\n            urlarray.append(urlobjects[\"url\"])\n        return urlarray", "response": "Get all url - objects in an array"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef find_matches(self, list_title):\n        list_title_matches = []\n        # Generate every possible tuple of titles and safe the matched string in a list.\n        for a, b, in itertools.combinations(list_title, 2):\n            if a == b:\n                list_title_matches.append(a)\n\n        return list_title_matches", "response": "Checks if there are any matches between extracted titles and the matched titles."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nextract the most frequently extracted title from the list.", "response": "def extract_match(self, list_title_matches):\n        \"\"\"Extract the title with the most matches from the list.\n\n        :param list_title_matches: A list, the extracted titles which match with others\n        :return: A string, the most frequently extracted title.\n        \"\"\"\n        # Create a set of the extracted titles\n        list_title_matches_set = set(list_title_matches)\n\n        list_title_count = []\n        # Count how often a title was matched and safe as tuple in list.\n        for match in list_title_matches_set:\n            list_title_count.append((list_title_matches.count(match), match))\n\n        if list_title_count and max(list_title_count)[0] != min(list_title_count)[0]:\n            return max(list_title_count)[1]\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef extract(self, item, list_article_candidate):\n        list_title = []\n\n        # Save every title from the candidates in list_title.\n        for article_candidate in list_article_candidate:\n            if article_candidate.title is not None:\n                list_title.append(article_candidate.title)\n\n        if not list_title:\n            return None\n\n        # Creates a list with matched titles\n        list_title_matches = self.find_matches(list_title)\n        # Extract title with the most matches\n        matched_title = self.extract_match(list_title_matches)\n\n        # Returns the matched title if there is one, else returns the shortest title\n        if matched_title:\n            return matched_title\n        else:\n            if list_title_matches:\n                return self.choose_shortest_title(set(list_title_matches))\n            else:\n                return self.choose_shortest_title(list_title)", "response": "Compares the extracted titles."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading in the log file that contains a list of all previously extracted WARC urls", "response": "def __get_list_of_fully_extracted_warc_urls():\n    \"\"\"\n    Reads in the log file that contains a list of all previously, fully extracted WARC urls\n    :return:\n    \"\"\"\n    if not os.path.isfile(__log_pathname_fully_extracted_warcs):\n        return []\n\n    with open(__log_pathname_fully_extracted_warcs) as log_file:\n        list_warcs = log_file.readlines()\n    # remove break lines\n    list_warcs = [x.strip() for x in list_warcs]\n\n    return list_warcs"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstarts a CommonCrawlExtractor for the given WARC download URL.", "response": "def __start_commoncrawl_extractor(warc_download_url, callback_on_article_extracted=None, valid_hosts=None,\n                                  start_date=None, end_date=None,\n                                  strict_date=True, reuse_previously_downloaded_files=True,\n                                  local_download_dir_warc=None,\n                                  continue_after_error=True, show_download_progress=False,\n                                  log_level=logging.ERROR,\n                                  delete_warc_after_extraction=True,\n                                  continue_process=True,\n                                  log_pathname_fully_extracted_warcs=None):\n    \"\"\"\n    Starts a single CommonCrawlExtractor\n    :param warc_download_url:\n    :param callback_on_article_extracted:\n    :param valid_hosts:\n    :param start_date:\n    :param end_date:\n    :param strict_date:\n    :param reuse_previously_downloaded_files:\n    :param local_download_dir_warc:\n    :param continue_after_error:\n    :param show_download_progress:\n    :param log_level:\n    :return:\n    \"\"\"\n    commoncrawl_extractor = CommonCrawlExtractor()\n    commoncrawl_extractor.extract_from_commoncrawl(warc_download_url, callback_on_article_extracted,\n                                                   valid_hosts=valid_hosts,\n                                                   start_date=start_date, end_date=end_date,\n                                                   strict_date=strict_date,\n                                                   reuse_previously_downloaded_files=reuse_previously_downloaded_files,\n                                                   local_download_dir_warc=local_download_dir_warc,\n                                                   continue_after_error=continue_after_error,\n                                                   show_download_progress=show_download_progress,\n                                                   log_level=log_level,\n                                                   delete_warc_after_extraction=delete_warc_after_extraction,\n                                                   log_pathname_fully_extracted_warcs=__log_pathname_fully_extracted_warcs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef crawl_from_commoncrawl(callback_on_article_extracted, valid_hosts=None, start_date=None, end_date=None,\n                           strict_date=True, reuse_previously_downloaded_files=True, local_download_dir_warc=None,\n                           continue_after_error=True, show_download_progress=False,\n                           number_of_extraction_processes=4, log_level=logging.ERROR,\n                           delete_warc_after_extraction=True, continue_process=True):\n    \"\"\"\n    Crawl and extract articles form the news crawl provided by commoncrawl.org. For each article that was extracted\n    successfully the callback function callback_on_article_extracted is invoked where the first parameter is the\n    article object.\n    :param continue_process:\n    :param delete_warc_after_extraction:\n    :param number_of_extraction_processes:\n    :param callback_on_article_extracted:\n    :param valid_hosts:\n    :param start_date:\n    :param end_date:\n    :param strict_date:\n    :param reuse_previously_downloaded_files:\n    :param local_download_dir_warc:\n    :param continue_after_error:\n    :param show_download_progress:\n    :param log_level:\n    :return:\n    \"\"\"\n    __setup(local_download_dir_warc, log_level)\n\n    cc_news_crawl_names = __get_remote_index()\n    __logger.info('found %i files at commoncrawl.org', len(cc_news_crawl_names))\n\n    # multiprocessing (iterate the list of crawl_names, and for each: download and process it)\n    __logger.info('creating extraction process pool with %i processes', number_of_extraction_processes)\n    warc_download_urls = []\n    fully_extracted_warc_urls = __get_list_of_fully_extracted_warc_urls()\n    for name in cc_news_crawl_names:\n        warc_download_url = __get_download_url(name)\n        if continue_process:\n            # check if the current WARC has already been fully extracted (assuming that the filter criteria have not\n            # been changed!)\n            if warc_download_url in fully_extracted_warc_urls:\n                __logger.info('skipping WARC because fully extracted: %s' % warc_download_url)\n                pass\n            else:\n                warc_download_urls.append(warc_download_url)\n\n        else:\n            # if not continue process, then always add\n            warc_download_urls.append(warc_download_url)\n\n    # run the crawler in the current, single process if number of extraction processes is set to 1\n    if number_of_extraction_processes > 1:\n        with Pool(number_of_extraction_processes) as extraction_process_pool:\n            extraction_process_pool.map(partial(__start_commoncrawl_extractor,\n                                                callback_on_article_extracted=callback_on_article_extracted,\n                                                valid_hosts=valid_hosts,\n                                                start_date=start_date, end_date=end_date,\n                                                strict_date=strict_date,\n                                                reuse_previously_downloaded_files=reuse_previously_downloaded_files,\n                                                local_download_dir_warc=local_download_dir_warc,\n                                                continue_after_error=continue_after_error,\n                                                show_download_progress=show_download_progress,\n                                                log_level=log_level,\n                                                delete_warc_after_extraction=delete_warc_after_extraction,\n                                                log_pathname_fully_extracted_warcs=__log_pathname_fully_extracted_warcs),\n                                        warc_download_urls)\n    else:\n        for warc_download_url in warc_download_urls:\n            __start_commoncrawl_extractor(warc_download_url,\n                                          callback_on_article_extracted=callback_on_article_extracted,\n                                          valid_hosts=valid_hosts,\n                                          start_date=start_date, end_date=end_date,\n                                          strict_date=strict_date,\n                                          reuse_previously_downloaded_files=reuse_previously_downloaded_files,\n                                          local_download_dir_warc=local_download_dir_warc,\n                                          continue_after_error=continue_after_error,\n                                          show_download_progress=show_download_progress,\n                                          log_level=log_level,\n                                          delete_warc_after_extraction=delete_warc_after_extraction,\n                                          log_pathname_fully_extracted_warcs=__log_pathname_fully_extracted_warcs)", "response": "Crawl and extract articles from commoncrawl. org."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cli(cfg_file_path, resume, reset_elasticsearch, reset_mysql, reset_json, reset_all, no_confirm):\n    \"A generic news crawler and extractor.\"\n\n    if reset_all:\n        reset_elasticsearch = True\n        reset_json = True\n        reset_mysql = True\n\n    if cfg_file_path and not cfg_file_path.endswith(os.path.sep):\n        cfg_file_path += os.path.sep\n\n    NewsPleaseLauncher(cfg_file_path, resume, reset_elasticsearch, reset_json, reset_mysql, no_confirm)", "response": "A generic news crawler and extractor."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the stop handler for the current process.", "response": "def set_stop_handler(self):\n        \"\"\"\n        Initializes functions that are invoked when the user or OS wants to kill this process.\n        :return:\n        \"\"\"\n        signal.signal(signal.SIGTERM, self.graceful_stop)\n        signal.signal(signal.SIGABRT, self.graceful_stop)\n        signal.signal(signal.SIGINT, self.graceful_stop)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmanage all crawlers threads and limites the number of parallel crawlers running threads.", "response": "def manage_crawlers(self):\n        \"\"\"\n        Manages all crawlers, threads and limites the number of parallel\n        running threads.\n        \"\"\"\n        sites = self.json.get_site_objects()\n        for index, site in enumerate(sites):\n            if \"daemonize\" in site:\n                self.daemon_list.add_daemon(index, site[\"daemonize\"])\n            elif \"additional_rss_daemon\" in site:\n                self.daemon_list.add_daemon(index,\n                                            site[\"additional_rss_daemon\"])\n                self.crawler_list.append_item(index)\n            else:\n                self.crawler_list.append_item(index)\n\n        num_threads = self.cfg.section('Crawler')[\n            'number_of_parallel_crawlers']\n        if self.crawler_list.len() < num_threads:\n            num_threads = self.crawler_list.len()\n\n        for _ in range(num_threads):\n            thread = threading.Thread(target=self.manage_crawler,\n                                      args=(),\n                                      kwargs={})\n            self.threads.append(thread)\n            thread.start()\n\n        num_daemons = self.cfg.section('Crawler')['number_of_parallel_daemons']\n        if self.daemon_list.len() < num_daemons:\n            num_daemons = self.daemon_list.len()\n\n        for _ in range(num_daemons):\n            thread_daemonized = threading.Thread(target=self.manage_daemon,\n                                                 args=(),\n                                                 kwargs={})\n            self.threads_daemonized.append(thread_daemonized)\n            thread_daemonized.start()\n\n        while not self.shutdown:\n            try:\n                time.sleep(10)\n                # if we are not in daemon mode and no crawler is running any longer,\n                # all articles have been crawled and the tool can shut down\n                if self.daemon_list.len() == 0 and self.number_of_active_crawlers == 0:\n                    self.graceful_stop()\n                    break\n\n            except IOError:\n                # This exception will only occur on kill-process on windows.\n                # The process should be killed, thus this exception is\n                # irrelevant.\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmanage a normal crawler thread.", "response": "def manage_crawler(self):\n        \"\"\"\n        Manages a normal crawler thread.\n\n        When a crawler finished, it loads another one if there are still sites\n        to crawl.\n        \"\"\"\n        index = True\n        self.number_of_active_crawlers += 1\n        while not self.shutdown and index is not None:\n            index = self.crawler_list.get_next_item()\n            if index is None:\n                self.number_of_active_crawlers -= 1\n                break\n\n            self.start_crawler(index)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef manage_daemon(self):\n        while not self.shutdown:\n            # next scheduled daemon, tuple (time, index)\n            item = self.daemon_list.get_next_item()\n            cur = time.time()\n            pajama_time = item[0] - cur\n            if pajama_time > 0:\n                self.thread_event.wait(pajama_time)\n            if not self.shutdown:\n                self.start_crawler(item[1], daemonize=True)", "response": "Manages a daemonized crawler thread."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nstarting a crawler from the input - array.", "response": "def start_crawler(self, index, daemonize=False):\n        \"\"\"\n        Starts a crawler from the input-array.\n\n        :param int index: The array-index of the site\n        :param int daemonize: Bool if the crawler is supposed to be daemonized\n                              (to delete the JOBDIR)\n        \"\"\"\n        call_process = [sys.executable,\n                        self.__single_crawler,\n                        self.cfg_file_path,\n                        self.json_file_path,\n                        \"%s\" % index,\n                        \"%s\" % self.shall_resume,\n                        \"%s\" % daemonize]\n\n        self.log.debug(\"Calling Process: %s\", call_process)\n\n        crawler = Popen(call_process,\n                        stderr=None,\n                        stdout=None)\n        crawler.communicate()\n        self.crawlers.append(crawler)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef init_config_file_path_if_empty(self):\n\n        if os.path.exists(self.cfg_directory_path):\n            return\n\n        user_choice = 'n'\n        if self.no_confirm:\n            user_choice = 'y'\n        else:\n            sys.stdout.write(\n                \"Config directory does not exist at '\" + os.path.abspath(self.cfg_directory_path) + \"'. \"\n                + \"Should a default configuration be created at this path? [Y/n] \")\n            if sys.version_info[0] < 3:\n                user_choice = raw_input()\n            else:\n                user_choice = input()\n            user_choice = user_choice.lower().replace(\"yes\", \"y\").replace(\"no\", \"n\")\n\n        if not user_choice or user_choice == '':  # the default is yes\n            user_choice = \"y\"\n        if \"y\" not in user_choice and \"n\" not in user_choice:\n            sys.stderr.write(\"Wrong input, aborting.\")\n            sys.exit(1)\n        if \"n\" in user_choice:\n            sys.stdout.write(\"Config file will not be created. Terminating.\")\n            sys.exit(1)\n\n        # copy the default config file to the new path\n        copy_tree(os.environ['CColon'] + os.path.sep + 'config', self.cfg_directory_path)\n        return", "response": "This function will initialize the config file path if it does not exist and the default config file is created at the path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_expanded_path(self, path):\n        if path.startswith('~'):\n            return os.path.expanduser('~') + path[1:]\n        else:\n            return path", "response": "Expand a path that starts with ~ to an absolute path"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_abs_file_path(self, rel_file_path,\n                          quit_on_error=None, check_relative_to_path=True):\n        \"\"\"\n        Returns the absolute file path of the given [relative] file path\n        to either this script or to the config file.\n\n        May throw a RuntimeError if quit_on_error is True.\n\n        :param str rel_file_path: relative file path\n        :param bool quit_on_error: determines if the script may throw an\n                                   exception\n        :return str: absolute file path of the given relative file path\n        :raises RuntimeError: if the file path does not exist and\n                              quit_on_error is True\n        \"\"\"\n        if self.cfg_file_path is not None and \\\n                check_relative_to_path and \\\n                not self.cfg.section('Files')['relative_to_start_processes_file']:\n            script_dir = os.path.dirname(self.cfg_file_path)\n        else:\n            # absolute dir this script is in\n            script_dir = os.path.dirname(__file__)\n\n        abs_file_path = os.path.abspath(\n            os.path.join(script_dir, rel_file_path))\n\n        if not os.path.exists(abs_file_path):\n            self.log.error(abs_file_path + \" does not exist.\")\n            if quit_on_error is True:\n                raise RuntimeError(\"Imported file not found. Quit.\")\n\n        return abs_file_path", "response": "Returns the absolute file path of the given relative file path."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef reset_mysql(self):\n\n        confirm = self.no_confirm\n\n        print(\"\"\"\nCleanup MySQL database:\n    This will truncate all tables and reset the whole database.\n\"\"\")\n\n        if not confirm:\n            confirm = 'yes' in builtins.input(\n                \"\"\"\n    Do you really want to do this? Write 'yes' to confirm: {yes}\"\"\"\n                    .format(yes='yes' if confirm else ''))\n\n        if not confirm:\n            print(\"Did not type yes. Thus aborting.\")\n            return\n\n        print(\"Resetting database...\")\n\n        try:\n            # initialize DB connection\n            self.conn = pymysql.connect(host=self.mysql[\"host\"],\n                                        port=self.mysql[\"port\"],\n                                        db=self.mysql[\"db\"],\n                                        user=self.mysql[\"username\"],\n                                        passwd=self.mysql[\"password\"])\n            self.cursor = self.conn.cursor()\n\n            self.cursor.execute(\"TRUNCATE TABLE CurrentVersions\")\n            self.cursor.execute(\"TRUNCATE TABLE ArchiveVersions\")\n            self.conn.close()\n        except (pymysql.err.OperationalError, pymysql.ProgrammingError, pymysql.InternalError,\n                pymysql.IntegrityError, TypeError) as error:\n            self.log.error(\"Database reset error: %s\", error)", "response": "Reset the MySQL database."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef reset_elasticsearch(self):\n\n        print(\"\"\"\nCleanup Elasticsearch database:\n    This will truncate all tables and reset the whole Elasticsearch database.\n              \"\"\")\n\n        confirm = self.no_confirm\n\n        if not confirm:\n            confirm = 'yes' in builtins.input(\n                \"\"\"\nDo you really want to do this? Write 'yes' to confirm: {yes}\"\"\"\n                    .format(yes='yes' if confirm else ''))\n\n        if not confirm:\n            print(\"Did not type yes. Thus aborting.\")\n            return\n\n        try:\n            # initialize DB connection\n            es = Elasticsearch([self.elasticsearch[\"host\"]],\n                               http_auth=(self.elasticsearch[\"username\"], self.elasticsearch[\"secret\"]),\n                               port=self.elasticsearch[\"port\"],\n                               use_ssl=self.elasticsearch[\"use_ca_certificates\"],\n                               verify_certs=self.elasticsearch[\"use_ca_certificates\"],\n                               ca_certs=self.elasticsearch[\"ca_cert_path\"],\n                               client_cert=self.elasticsearch[\"client_cert_path\"],\n                               client_key=self.elasticsearch[\"client_key_path\"])\n\n            print(\"Resetting Elasticsearch database...\")\n            es.indices.delete(index=self.elasticsearch[\"index_current\"], ignore=[400, 404])\n            es.indices.delete(index=self.elasticsearch[\"index_archive\"], ignore=[400, 404])\n        except ConnectionError as error:\n            self.log.error(\"Failed to connect to Elasticsearch. \"\n                           \"Please check if the database is running and the config is correct: %s\" % error)", "response": "Reset the Elasticsearch database."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nresets the local data directory and all contents of the file.", "response": "def reset_files(self):\n        \"\"\"\n        Resets the local data directory.\n        \"\"\"\n        confirm = self.no_confirm\n\n        path = SavepathParser.get_base_path(\n            SavepathParser.get_abs_path_static(\n                self.cfg.section(\"Files\")[\"local_data_directory\"],\n                os.path.dirname(self.cfg_file_path)\n            )\n        )\n\n        print(\"\"\"\nCleanup files:\n    This will delete {path} and all its contents.\n\"\"\".format(path=path))\n\n        if not confirm:\n            confirm = 'yes' in builtins.input(\n                \"\"\"\n    Do you really want to do this? Write 'yes' to confirm: {yes}\"\"\"\n                    .format(yes='yes' if confirm else ''))\n\n        if not confirm:\n            print(\"Did not type yes. Thus aborting.\")\n            return\n\n        print(\"Removing: {}\".format(path))\n\n        try:\n            shutil.rmtree(path)\n        except OSError as error:\n            if not os.path.exists(path):\n                self.log.error(\"%s does not exist.\", path)\n            self.log.error(error)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntaking a regex match and returns the timestamp formated with strftime", "response": "def time_replacer(match, timestamp):\n        \"\"\"\n        Transforms the timestamp to the format the regex match determines.\n\n        :param str match: the regex match\n        :param time timestamp: the timestamp to format with match.group(1)\n        :return str: the timestamp formated with strftime the way the\n                     regex-match within the first set of braces defines\n        \"\"\"\n        # match.group(0) = entire match\n        # match.group(1) = match in braces #1\n        return time.strftime(match.group(1), time.gmtime(timestamp))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef append_md5_if_too_long(component, size):\n\n        if len(component) > size:\n            if size > 32:\n                component_size = size - 32 - 1\n                return \"%s_%s\" % (component[:component_size],\n                                  hashlib.md5(component.encode('utf-8')).hexdigest())\n            else:\n                return hashlib.md5(component.encode('utf-8')).hexdigest()[:size]\n        else:\n            return component", "response": "Trims the component if it is longer than size and appends the component s md5."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nevaluates the savepath for the given url.", "response": "def get_savepath(self, url, savepath=None):\n        \"\"\"\n        Evaluates the savepath with the help of the given url.\n\n        :param str url: url to evaluate the savepath with\n        :return str: the evaluated savepath for the given url\n        \"\"\"\n        timestamp = int(time.time())\n\n        if not savepath:\n            savepath = self.cfg_savepath\n\n        # lambda is used for lazy evaluation\n        savepath = re.sub(re_working_path, lambda match: self.working_path, savepath)\n\n        savepath = re.sub(\n            re_time_dl, lambda match: SavepathParser.time_replacer(match, timestamp),\n            savepath\n        )\n        savepath = re.sub(re_timstamp_dl, str(timestamp), savepath)\n\n        savepath = re.sub(\n            re_domain, lambda match: UrlExtractor.get_allowed_domain(url, False)\n            [:int(match.group(1))], savepath\n        )\n        savepath = re.sub(\n            re_appendmd5_domain, lambda match: SavepathParser.append_md5_if_too_long(\n                UrlExtractor.get_allowed_domain(url, False), int(match.group(1))\n            ), savepath\n        )\n        savepath = re.sub(\n            re_md5_domain, lambda match: hashlib.md5(\n                UrlExtractor.get_allowed_domain(url, False).encode('utf-8')\n            ).hexdigest()[:int(match.group(1))], savepath\n        )\n\n        savepath = re.sub(\n            re_full_domain, lambda match: UrlExtractor.get_allowed_domain(url)\n            [:int(match.group(1))], savepath\n        )\n        savepath = re.sub(\n            re_appendmd5_full_domain, lambda match: SavepathParser.append_md5_if_too_long(\n                UrlExtractor.get_allowed_domain(url), int(match.group(1))\n            ), savepath\n        )\n        savepath = re.sub(\n            re_md5_full_domain, lambda match: hashlib.md5(\n                UrlExtractor.get_allowed_domain(url).encode('utf-8')\n            ).hexdigest()[:int(match.group(1))], savepath\n        )\n\n        savepath = re.sub(\n            re_subdomains, lambda match: UrlExtractor.get_subdomain(url)\n            [:int(match.group(1))], savepath\n        )\n        savepath = re.sub(\n            re_appendmd5_subdomains, lambda match: SavepathParser.\n            append_md5_if_too_long(UrlExtractor.get_subdomain(url), int(match.group(1))),\n            savepath\n        )\n        savepath = re.sub(\n            re_md5_subdomains, lambda match: hashlib.md5(\n                UrlExtractor.get_subdomain(url).encode('utf-8')\n            ).hexdigest()[:int(match.group(1))], savepath\n        )\n\n        savepath = re.sub(\n            re_url_dir, lambda match: UrlExtractor.get_url_directory_string(url)\n            [:int(match.group(1))], savepath\n        )\n        savepath = re.sub(\n            re_appendmd5_url_dir, lambda match: SavepathParser.append_md5_if_too_long(\n                UrlExtractor.get_url_directory_string(url), int(match.group(1))\n            ), savepath\n        )\n        savepath = re.sub(\n            re_md5_url_dir, lambda match: hashlib.md5(\n                UrlExtractor.get_url_directory_string(url).encode('utf-8')\n            ).hexdigest()[:int(match.group(1))], savepath\n        )\n\n        savepath = re.sub(\n            re_url_file, lambda match: UrlExtractor.get_url_file_name(url)\n            [:int(match.group(1))], savepath\n        )\n        savepath = re.sub(\n            re_md5_url_file, lambda match: hashlib.md5(\n                UrlExtractor.get_url_file_name(url).encode('utf-8')\n            ).hexdigest()[:int(match.group(1))], savepath\n        )\n\n        abs_savepath = self.get_abs_path(savepath)\n\n        savepath = re.sub(\n            re_max_url_file, lambda match: UrlExtractor.get_url_file_name(url)\n            [:SavepathParser.get_max_url_file_name_length(abs_savepath)], savepath\n        )\n        savepath = re.sub(\n            re_appendmd5_max_url_file, lambda match: SavepathParser.\n            append_md5_if_too_long(\n                UrlExtractor.get_url_file_name(url),\n                SavepathParser.get_max_url_file_name_length(abs_savepath)\n            ), savepath\n        )\n\n        # ensure the savepath doesn't contain any invalid characters\n        return SavepathParser.remove_not_allowed_chars(savepath)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef remove_not_allowed_chars(savepath):\n        split_savepath = os.path.splitdrive(savepath)\n        # https://msdn.microsoft.com/en-us/library/aa365247.aspx\n        savepath_without_invalid_chars = re.sub(r'<|>|:|\\\"|\\||\\?|\\*', '_',\n                                                split_savepath[1])\n        return split_savepath[0] + savepath_without_invalid_chars", "response": "Removes invalid filepath characters from the savepath."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_abs_path_static(savepath, relative_to_path):\n        if os.path.isabs(savepath):\n            return os.path.abspath(savepath)\n        else:\n            return os.path.abspath(\n                os.path.join(relative_to_path, (savepath))\n            )", "response": "Returns an absolute path to the file path that should be used for the static file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndetermining the longest possible beginning of a path that does not contain a % - Symbol.", "response": "def get_base_path(path):\n        \"\"\"\n        Determines the longest possible beginning of a path that does not\n        contain a %-Symbol.\n\n        /this/is/a/pa%th would become /this/is/a\n\n        :param str path: the path to get the base from\n        :return: the path's base\n        \"\"\"\n        if \"%\" not in path:\n            return path\n\n        path = os.path.split(path)[0]\n\n        while \"%\" in path:\n            path = os.path.split(path)[0]\n\n        return path"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_formatted_relative_path(self, path):\n        if self.format_relative_path and \\\n                (path.startswith('./') or path.startswith('.\\\\')):\n            return path[2:]\n        else:\n            return path", "response": "Formats the path to not start with a leading. or. \\"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndetermining the maximum length for any max... parts.", "response": "def get_max_url_file_name_length(savepath):\n        \"\"\"\n        Determines the max length for any max... parts.\n\n        :param str savepath: absolute savepath to work on\n        :return: max. allowed number of chars for any of the max... parts\n        \"\"\"\n        number_occurrences = savepath.count('%max_url_file_name')\n        number_occurrences += savepath.count('%appendmd5_max_url_file_name')\n\n        savepath_copy = savepath\n        size_without_max_url_file_name = len(\n            savepath_copy.replace('%max_url_file_name', '')\n                .replace('%appendmd5_max_url_file_name', '')\n        )\n\n        # Windows: max file path length is 260 characters including\n        # NULL (string end)\n        max_size = 260 - 1 - size_without_max_url_file_name\n        max_size_per_occurrence = max_size / number_occurrences\n\n        return max_size_per_occurrence"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef extract(self, item):\n\n        doc = Document(deepcopy(item['spider_response'].body))\n        description = doc.summary()\n\n        article_candidate = ArticleCandidate()\n        article_candidate.extractor = self._name\n        article_candidate.title = doc.short_title()\n        article_candidate.description = description\n        article_candidate.text = self._text(item)\n        article_candidate.topimage = self._topimage(item)\n        article_candidate.author = self._author(item)\n        article_candidate.publish_date = self._publish_date(item)\n        article_candidate.language = self._language(item)\n\n        return article_candidate", "response": "Creates an ArticleCandidate containing the article title and text."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nruns the HTML - response trough a list of initialized extractors a cleaner and compares the results.", "response": "def extract(self, item):\n        \"\"\"Runs the HTML-response trough a list of initialized extractors, a cleaner and compares the results.\n\n        :param item: NewscrawlerItem to be processed.\n        :return: An updated NewscrawlerItem including the results of the extraction\n        \"\"\"\n\n        article_candidates = []\n\n        for extractor in self.extractor_list:\n            article_candidates.append(extractor.extract(item))\n\n        article_candidates = self.cleaner.clean(article_candidates)\n        article = self.comparer.compare(item, article_candidates)\n\n        item['article_title'] = article.title\n        item['article_description'] = article.description\n        item['article_text'] = article.text\n        item['article_image'] = article.topimage\n        item['article_author'] = article.author\n        item['article_publish_date'] = article.publish_date\n        item['article_language'] = article.language\n\n        return item"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __setup(self):\n        if not os.path.exists(self.__local_download_dir_warc):\n            os.makedirs(self.__local_download_dir_warc)\n\n        # make loggers quite\n        configure_logging({\"LOG_LEVEL\": \"ERROR\"})\n        logging.getLogger('requests').setLevel(logging.CRITICAL)\n        logging.getLogger('readability').setLevel(logging.CRITICAL)\n        logging.getLogger('PIL').setLevel(logging.CRITICAL)\n        logging.getLogger('newspaper').setLevel(logging.CRITICAL)\n        logging.getLogger('newsplease').setLevel(logging.CRITICAL)\n        logging.getLogger('urllib3').setLevel(logging.CRITICAL)\n\n        # set own logger\n        logging.basicConfig(level=self.__log_level)\n        self.__logger = logging.getLogger(__name__)\n        self.__logger.setLevel(self.__log_level)", "response": "Setup the logger and local download directory."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __register_fully_extracted_warc_file(self, warc_url):\n        with open(self.__log_pathname_fully_extracted_warcs, 'a') as log_file:\n            log_file.write(warc_url + '\\n')", "response": "Registers the URL warc_url in the log file for fully extracted WARC URLs"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __filter_record(self, warc_record, article=None):\n        # filter by host\n        if self.__filter_valid_hosts:\n            url = warc_record.rec_headers.get_header('WARC-Target-URI')\n\n            # very simple check, check if one of the required host names is contained in the url of the WARC transaction\n            # better would be to extract the host name from the WARC transaction Target URI and then check for equality\n            # because currently something like g.co?forward_url=facebook.com would yield a positive filter test for\n            # facebook.com even though the actual host is g.co\n            for valid_host in self.__filter_valid_hosts:\n                if valid_host in url:\n                    break\n            else:\n                return False, article\n\n        # filter by date\n        if self.__filter_start_date or self.__filter_end_date:\n            if not article:\n                article = NewsPlease.from_warc(warc_record)\n\n            publishing_date = self.__get_publishing_date(warc_record, article)\n            if not publishing_date:\n                if self.__filter_strict_date:\n                    return False, article\n            else:  # here we for sure have a date\n                # is article published too early?\n                if self.__filter_start_date and publishing_date < self.__filter_start_date:\n                    return False, article\n                if self.__filter_end_date and publishing_date > self.__filter_end_date:\n                    return False, article\n\n        return True, article", "response": "Filter the record by hosts and publishing date."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __get_remote_index(self):\n        # cleanup\n        subprocess.getoutput(\"rm tmpaws.txt\")\n        # get the remote info\n        cmd = \"aws s3 ls --recursive s3://commoncrawl/crawl-data/CC-NEWS/ --no-sign-request > tmpaws.txt && \" \\\n              \"awk '{ print $4 }' tmpaws.txt && \" \\\n              \"rm tmpaws.txt\"\n        self.__logger.info('executing: %s', cmd)\n        stdout_data = subprocess.getoutput(cmd)\n        print(stdout_data)\n\n        lines = stdout_data.splitlines()\n        return lines", "response": "Gets the index of news crawl files from commoncrawl. org and returns an array of names\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprints some download progress information about the entry in the cache.", "response": "def __on_download_progress_update(self, blocknum, blocksize, totalsize):\n        \"\"\"\n        Prints some download progress information\n        :param blocknum:\n        :param blocksize:\n        :param totalsize:\n        :return:\n        \"\"\"\n        if not self.__show_download_progress:\n            return\n\n        readsofar = blocknum * blocksize\n        if totalsize > 0:\n            s = \"\\r%s / %s\" % (size(readsofar), size(totalsize))\n            sys.stdout.write(s)\n            if readsofar >= totalsize:  # near the end\n                sys.stderr.write(\"\\r\")\n        else:  # total size is unknown\n            sys.stdout.write(\"\\rread %s\" % (size(readsofar)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __download(self, url):\n        local_filename = urllib.parse.quote_plus(url)\n        local_filepath = os.path.join(self.__local_download_dir_warc, local_filename)\n\n        if os.path.isfile(local_filepath) and self.__reuse_previously_downloaded_files:\n            self.__logger.info(\"found local file %s, not downloading again due to configuration\", local_filepath)\n            return local_filepath\n        else:\n            # cleanup\n            try:\n                os.remove(local_filepath)\n            except OSError:\n                pass\n\n            # download\n            self.__logger.info('downloading %s (local: %s)', url, local_filepath)\n            urllib.request.urlretrieve(url, local_filepath, reporthook=self.__on_download_progress_update)\n            self.__logger.info('download completed, local file: %s', local_filepath)\n            return local_filepath", "response": "Download and save a file locally."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\niterates all transactions in one WARC file and for each transaction tries to extract an article object. Afterwards, each article is checked against the filter criteria and if all are passed, the function on_valid_article_extracted is invoked with the article object. :param path_name: :return:", "response": "def __process_warc_gz_file(self, path_name):\n        \"\"\"\n        Iterates all transactions in one WARC file and for each transaction tries to extract an article object.\n        Afterwards, each article is checked against the filter criteria and if all are passed, the function\n        on_valid_article_extracted is invoked with the article object.\n        :param path_name:\n        :return:\n        \"\"\"\n        counter_article_total = 0\n        counter_article_passed = 0\n        counter_article_discarded = 0\n        start_time = time.time()\n\n        with open(path_name, 'rb') as stream:\n            for record in ArchiveIterator(stream):\n                # try:\n                if record.rec_type == 'response':\n                    counter_article_total += 1\n\n                    # if the article passes filter tests, we notify the user\n                    filter_pass, article = self.__filter_record(record)\n                    if filter_pass:\n                        counter_article_passed += 1\n\n                        if not article:\n                            article = NewsPlease.from_warc(record)\n\n                        self.__logger.info('article pass (%s; %s; %s)', article.source_domain, article.date_publish,\n                                           article.title)\n                        self.__callback_on_article_extracted(article)\n                    else:\n                        counter_article_discarded += 1\n\n                        if article:\n                            self.__logger.info('article discard (%s; %s; %s)', article.source_domain,\n                                               article.date_publish,\n                                               article.title)\n                        else:\n                            self.__logger.info('article discard (%s)',\n                                               record.rec_headers.get_header('WARC-Target-URI'))\n\n                    if counter_article_total % 10 == 0:\n                        elapsed_secs = time.time() - start_time\n                        secs_per_article = elapsed_secs / counter_article_total\n                        self.__logger.info('statistics')\n                        self.__logger.info('pass = %i, discard = %i, total = %i', counter_article_passed,\n                                           counter_article_discarded, counter_article_total)\n                        self.__logger.info('extraction from current WARC file started %s; %f s/article',\n                                           human(start_time), secs_per_article)\n                        # except:\n                        #    if self.__continue_after_error:\n                        #        self.__logger.error('Unexpected error: %s', sys.exc_info()[0])\n                        #        pass\n                        #    else:\n                        #        raise\n\n        # cleanup\n        if self.__delete_warc_after_extraction:\n            os.remove(path_name)\n\n        self.__register_fully_extracted_warc_file(self.__warc_download_url)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __run(self):\n        self.__setup()\n\n        local_path_name = self.__download(self.__warc_download_url)\n        self.__process_warc_gz_file(local_path_name)", "response": "Main execution method for the entry point of the WARC file extraction process the WARC file and process the archive."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef extract_from_commoncrawl(self, warc_download_url, callback_on_article_extracted, valid_hosts=None,\n                                 start_date=None, end_date=None,\n                                 strict_date=True, reuse_previously_downloaded_files=True, local_download_dir_warc=None,\n                                 continue_after_error=True, show_download_progress=False,\n                                 log_level=logging.ERROR, delete_warc_after_extraction=True,\n                                 log_pathname_fully_extracted_warcs=None):\n        \"\"\"\n        Crawl and extract articles form the news crawl provided by commoncrawl.org. For each article that was extracted\n        successfully the callback function callback_on_article_extracted is invoked where the first parameter is the\n        article object.\n        :param log_pathname_fully_extracted_warcs:\n        :param delete_warc_after_extraction:\n        :param warc_download_url:\n        :param callback_on_article_extracted:\n        :param valid_hosts:\n        :param start_date:\n        :param end_date:\n        :param strict_date:\n        :param reuse_previously_downloaded_files:\n        :param local_download_dir_warc:\n        :param continue_after_error:\n        :param show_download_progress:\n        :param log_level:\n        :return:\n        \"\"\"\n        self.__warc_download_url = warc_download_url\n        self.__filter_valid_hosts = valid_hosts\n        self.__filter_start_date = start_date\n        self.__filter_end_date = end_date\n        self.__filter_strict_date = strict_date\n        if local_download_dir_warc:\n            self.__local_download_dir_warc = local_download_dir_warc\n        self.__reuse_previously_downloaded_files = reuse_previously_downloaded_files\n        self.__continue_after_error = continue_after_error\n        self.__callback_on_article_extracted = callback_on_article_extracted\n        self.__show_download_progress = show_download_progress\n        self.__log_level = log_level\n        self.__delete_warc_after_extraction = delete_warc_after_extraction\n        self.__log_pathname_fully_extracted_warcs = log_pathname_fully_extracted_warcs\n\n        self.__run()", "response": "This method extracts the news from a commoncrawl. org URL."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pass_to_pipeline_if_article(\n            self,\n            response,\n            source_domain,\n            original_url,\n            rss_title=None\n    ):\n        \"\"\"\n        Responsible for passing a NewscrawlerItem to the pipeline if the\n        response contains an article.\n\n        :param obj response: the scrapy response to work on\n        :param str source_domain: the response's domain as set for the crawler\n        :param str original_url: the url set in the json file\n        :param str rss_title: the title extracted by an rssCrawler\n        :return NewscrawlerItem: NewscrawlerItem to pass to the pipeline\n        \"\"\"\n        if self.helper.heuristics.is_article(response, original_url):\n            return self.pass_to_pipeline(\n                response, source_domain, rss_title=None)", "response": "Pass a NewscrawlerItem to the pipeline if the response contains an article."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef recursive_requests(response, spider, ignore_regex='',\n                           ignore_file_extensions='pdf'):\n        \"\"\"\n        Manages recursive requests.\n        Determines urls to recursivly crawl if they do not match certain file\n        extensions and do not match a certain regex set in the config file.\n\n        :param obj response: the response to extract any urls from\n        :param obj spider: the crawler the callback should be called on\n        :param str ignore_regex: a regex that should that any extracted url\n                                 shouldn't match\n        :param str ignore_file_extensions: a regex of file extensions that the\n                                           end of any url may not match\n        :return list: Scrapy Requests\n        \"\"\"\n        # Recursivly crawl all URLs on the current page\n        # that do not point to irrelevant file types\n        # or contain any of the given ignore_regex regexes\n        return [\n            scrapy.Request(response.urljoin(href), callback=spider.parse)\n            for href in response.css(\"a::attr('href')\").extract() if re.match(\n                r'.*\\.' + ignore_file_extensions +\n                r'$', response.urljoin(href), re.IGNORECASE\n            ) is None\n            and len(re.match(ignore_regex, response.urljoin(href)).group(0)) == 0\n        ]", "response": "Returns a list of Scrapy Requests that are recursively crawlable."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndetermining if the response is of the correct type.", "response": "def content_type(self, response):\n        \"\"\"\n        Ensures the response is of type\n\n        :param obj response: The scrapy response\n        :return bool: Determines wether the response is of the correct type\n        \"\"\"\n        if not re_html.match(response.headers.get('Content-Type').decode('utf-8')):\n            self.log.warn(\n                \"Dropped: %s's content is not of type \"\n                \"text/html but %s\", response.url, response.headers.get('Content-Type')\n            )\n            return False\n        else:\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncomparing the extracted top images.", "response": "def extract(self, item, list_article_candidate):\n        \"\"\"Compares the extracted top images.\n\n        :param item: The corresponding NewscrawlerItem\n        :param list_article_candidate: A list, the list of ArticleCandidate-Objects which have been extracted\n        :return: A string (url), the most likely top image\n        \"\"\"\n        list_topimage = []\n\n        for article_candidate in list_article_candidate:\n            if article_candidate.topimage is not None:\n                # Changes a relative path of an image to the absolute path of the given url.\n                article_candidate.topimage = self.image_absoulte_path(item['url'], article_candidate.topimage)\n                list_topimage.append((article_candidate.topimage, article_candidate.extractor))\n\n        # If there is no value in the list, return None.\n        if len(list_topimage) == 0:\n            return None\n\n        # If there are more options than one, return the result from newspaper.\n        list_newspaper = [x for x in list_topimage if x[1] == \"newspaper\"]\n        if len(list_newspaper) == 0:\n\n            # If there is no topimage extracted by newspaper, return the first result of list_topimage.\n            return list_topimage[0][0]\n        else:\n            return list_newspaper[0][0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef image_absoulte_path(self, url, image):\n        if not re.match(re_http, image):\n            topimage = urljoin(url, image)\n            return topimage\n        return image", "response": "returns the absolute path of the image"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef extract(self, item, article_candidate_list):\n        list_text = []\n\n        # The minimal number of words a text needs to have\n        min_number_words = 15\n\n        # The texts of the article candidates and the respective extractors are saved in a tuple in list_text.\n        for article_candidate in article_candidate_list:\n            if article_candidate.text != None:\n                list_text.append((article_candidate.text, article_candidate.extractor))\n\n        # Remove texts that are shorter than min_number_words.\n        for text_tuple in list_text:\n            if len(text_tuple[0].split()) < min_number_words:\n                list_text.remove(text_tuple)\n\n        # If there is no value in the list, return None.\n        if len(list_text) == 0:\n            return None\n\n        # If there is only one solution, return it.\n        if len(list_text) < 2:\n            return list_text[0][0]\n        else:\n\n            # If there is more than one solution, do the following:\n\n            # Create a list which holds triple of the score and the two extractors\n            list_score = []\n\n            # Compare every text with all other texts at least once\n            for a, b, in itertools.combinations(list_text, 2):\n\n                # Create sets from the texts\n                set_a = set(a[0].split())\n                set_b = set(b[0].split())\n                symmetric_difference_a_b = set_a ^ set_b\n                intersection_a_b = set_a & set_b\n\n                # Replace 0 with -1 in order to elude division by zero\n                if intersection_a_b == 0:\n                    intersection_a_b = -1\n\n                # Create the score. It divides the number of words which are not in both texts by the number of words which\n                # are in both texts and subtracts the result from 1. The closer to 1 the more similiar they are.\n                score = 1 - ((len(symmetric_difference_a_b)) / (2 * len(intersection_a_b)))\n                list_score.append((score, a[1], b[1]))\n\n            # Find out which is the highest score\n            best_score = max(list_score, key=lambda item: item[0])\n\n            # If one of the solutions is newspaper return it\n            if \"newspaper\" in best_score:\n                return (list(filter(lambda x: x[1] == \"newspaper\", list_text))[0][0])\n            else:\n                # If not, return the text that is longer\n\n                # A list that holds the extracted texts and their extractors which were most similar\n                top_candidates = []\n                for tuple in list_text:\n                    if tuple[1] == best_score[1] or tuple[1] == best_score[2]:\n                        top_candidates.append(tuple)\n\n                if len(top_candidates[0][0]) > len(top_candidates[1][0]):\n                    return (top_candidates[0][0])\n                else:\n                    return (top_candidates[1][0])", "response": "Compares the extracted texts and returns the most likely text."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntesting if the given response is an article by calling and checking the site - specific config and sitelist. json duplicates.", "response": "def is_article(self, response, url):\n        \"\"\"\n        Tests if the given response is an article by calling and checking\n        the heuristics set in config.cfg and sitelist.json\n\n        :param obj response: The response of the site.\n        :param str url: The base_url (needed to get the site-specific config\n                        from the JSON-file)\n        :return bool: true if the heuristics match the site as an article\n        \"\"\"\n        site = self.__sites_object[url]\n        heuristics = self.__get_enabled_heuristics(url)\n\n        self.log.info(\"Checking site: %s\", response.url)\n\n        statement = self.__get_condition(url)\n        self.log.debug(\"Condition (original): %s\", statement)\n\n        for heuristic, condition in heuristics.items():\n            heuristic_func = getattr(self, heuristic)\n            result = heuristic_func(response, site)\n            check = self.__evaluate_result(result, condition)\n            statement = re.sub(r\"\\b%s\\b\" % heuristic, str(check), statement)\n\n            self.log.debug(\"Checking heuristic (%s)\"\n                           \" result (%s) on condition (%s): %s\",\n                           heuristic, result, condition, check)\n\n        self.log.debug(\"Condition (evaluated): %s\", statement)\n        is_article = eval(statement)\n        self.log.debug(\"Article accepted: %s\", is_article)\n        return is_article"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the condition for a url and validates it.", "response": "def __get_condition(self, url):\n        \"\"\"\n        Gets the condition for a url and validates it.\n\n        :param str url: The url to get the condition for\n        \"\"\"\n        if self.__heuristics_condition is not None:\n            return self.__heuristics_condition\n        if \"pass_heuristics_condition\" in self.__sites_object[url]:\n            condition = \\\n                self.__sites_object[url][\"pass_heuristics_condition\"]\n        else:\n            condition = \\\n                self.cfg_heuristics[\"pass_heuristics_condition\"]\n\n        # Because the condition will be eval-ed (Yeah, eval is evil, BUT only\n        # when not filtered properly), we are filtering it here.\n        # Anyway, if that filter-method is not perfect: This is not any\n        # random user-input thats evaled. This is (hopefully still when you\n        # read this) not a webtool, where you need to filter everything 100%\n        # properly.\n        disalloweds = condition\n        heuristics = self.__get_enabled_heuristics(url)\n\n        for allowed in self.__condition_allowed:\n            disalloweds = disalloweds.replace(allowed, \" \")\n\n        for heuristic, _ in heuristics.items():\n            disalloweds = re.sub(r\"\\b%s\\b\" % heuristic, \" \", disalloweds)\n\n        disalloweds = disalloweds.split(\" \")\n        for disallowed in disalloweds:\n            if disallowed != \"\":\n                self.log.error(\"Misconfiguration: In the condition,\"\n                               \" an unknown heuristic was found and\"\n                               \" will be ignored: %s\", disallowed)\n                condition = re.sub(r\"\\b%s\\b\" % disallowed, \"True\", condition)\n\n        self.__heuristics_condition = condition\n        # Now condition should just consits of not, and, or, (, ), and all\n        # enabled heuristics.\n        return condition"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nevaluating a result of a heuristic with the condition string.", "response": "def __evaluate_result(self, result, condition):\n        \"\"\"\n        Evaluates a result of a heuristic\n        with the condition given in the config.\n\n        :param mixed result: The result of the heuristic\n        :param mixed condition: The condition string to evaluate on the result\n        :return bool: Whether the heuristic result matches the condition\n        \"\"\"\n\n        # If result is bool this means, that the heuristic\n        # is bool as well or has a special situation\n        # (for example some condition [e.g. in config] is [not] met, thus\n        #  just pass it)\n        if isinstance(result, bool):\n            return result\n\n        # Check if the condition is a String condition,\n        # allowing <=, >=, <, >, = conditions or string\n        # when they start with \" or '\n        if isinstance(condition, basestring):\n\n            # Check if result should match a string\n            if (condition.startswith(\"'\") and condition.endswith(\"'\")) or \\\n                    (condition.startswith('\"') and condition.endswith('\"')):\n                if isinstance(result, basestring):\n                    self.log.debug(\"Condition %s recognized as string.\",\n                                   condition)\n                    return result == condition[1:-1]\n                return self.__evaluation_error(\n                    result, condition, \"Result not string\")\n\n            # Only number-comparision following\n            if not isinstance(result, (float, int)):\n                return self.__evaluation_error(\n                    result, condition, \"Result not number on comparision\")\n\n            # Check if result should match a number\n            if condition.startswith(\"=\"):\n                number = self.__try_parse_number(condition[1:])\n                if isinstance(number, bool):\n                    return self.__evaluation_error(\n                        result, condition, \"Number not parsable (=)\")\n                return result == number\n\n            # Check if result should be >= then a number\n            if condition.startswith(\">=\"):\n                number = self.__try_parse_number(condition[2:])\n                if isinstance(number, bool):\n                    return self.__evaluation_error(\n                        result, condition, \"Number not parsable (>=)\")\n                return result >= number\n\n            # Check if result should be <= then a number\n            if condition.startswith(\"<=\"):\n                number = self.__try_parse_number(condition[2:])\n                if isinstance(number, bool):\n                    return self.__evaluation_error(\n                        result, condition, \"Number not parsable (<=)\")\n                return result <= number\n\n            # Check if result should be > then a number\n            if condition.startswith(\">\"):\n                number = self.__try_parse_number(condition[1:])\n                if isinstance(number, bool):\n                    return self.__evaluation_error(\n                        result, condition, \"Number not parsable (>)\")\n                return result > number\n\n            # Check if result should be < then a number\n            if condition.startswith(\"<\"):\n                number = self.__try_parse_number(condition[1:])\n                if isinstance(number, bool):\n                    return self.__evaluation_error(\n                        result, condition, \"Number not parsable (<)\")\n                return result < number\n\n            # Check if result should be equal a number\n            number = self.__try_parse_number(condition)\n            if isinstance(number, bool):\n                return self.__evaluation_error(\n                    result, condition, \"Number not parsable\")\n            return result == number\n\n        # Check if the condition is a number and matches the result\n        if isinstance(condition, (float, int)) and isinstance(result, (float, int)):\n            return condition == result\n\n        return self.__evaluation_error(result, condition, \"Unknown\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntries to parse a string to a number else return False.", "response": "def __try_parse_number(self, string):\n        \"\"\"Try to parse a string to a number, else return False.\"\"\"\n        try:\n            return int(string)\n        except ValueError:\n            try:\n                return float(string)\n            except ValueError:\n                return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the enabled heuristics for a site.", "response": "def __get_enabled_heuristics(self, url):\n        \"\"\"\n        Get the enabled heuristics for a site, merging the default and the\n        overwrite together.\n        The config will only be read once and the merged site-config will be\n        cached.\n\n        :param str url: The url to get the heuristics for.\n        \"\"\"\n        if url in self.__sites_heuristics:\n            return self.__sites_heuristics[url]\n\n        site = self.__sites_object[url]\n        heuristics = dict(self.cfg_heuristics[\"enabled_heuristics\"])\n        if \"overwrite_heuristics\" in site:\n            for heuristic, value in site[\"overwrite_heuristics\"].items():\n                if value is False and heuristic in heuristics:\n                    del heuristics[heuristic]\n                else:\n                    heuristics[heuristic] = value\n        self.__sites_heuristics[site[\"url\"]] = heuristics\n\n        self.log.debug(\n            \"Enabled heuristics for %s: %s\", site[\"url\"], heuristics\n        )\n\n        return heuristics"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef extract(self, item):\n\n        article_candidate = ArticleCandidate()\n        article_candidate.extractor = self._name()\n        article_candidate.title = self._title(item)\n        article_candidate.description = self._description(item)\n        article_candidate.text = self._text(item)\n        article_candidate.topimage = self._topimage(item)\n        article_candidate.author = self._author(item)\n        article_candidate.publish_date = self._publish_date(item)\n        article_candidate.language = self._language(item)\n\n        return article_candidate", "response": "Executes all implemented functions on the given article and returns an ArticleCandidate object containing the recovered data."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef extract(self, item):\n        article_candidate = ArticleCandidate()\n        article_candidate.extractor = self._name()\n\n        article = Article('')\n        article.set_html(item['spider_response'].body)\n        article.parse()\n        article_candidate.title = article.title\n        article_candidate.description = article.meta_description\n        article_candidate.text = article.text\n        article_candidate.topimage = article.top_image\n        article_candidate.author = article.authors\n        if article.publish_date is not None:\n            try:\n                article_candidate.publish_date = article.publish_date.strftime('%Y-%m-%d %H:%M:%S')\n            except ValueError as exception:\n                self.log.debug('%s: Newspaper failed to extract the date in the supported format,'\n                              'Publishing date set to None' % item['url'])\n        article_candidate.language = article.meta_lang\n\n        return article_candidate", "response": "Creates an instance of Article with the results of the HTML - Code and returns an ArticleCandidate with the results of the HTML - Code parsing the HTML - Code."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef extract(self, item, list_article_candidate):\n        list_author = []\n\n        # The authors of the ArticleCandidates and the respective extractors are saved in a tuple in list_author.\n        for article_candidate in list_article_candidate:\n            if (article_candidate.author is not None) and (article_candidate.author != '[]'):\n                list_author.append((article_candidate.author, article_candidate.extractor))\n\n        # If there is no value in the list, return None.\n        if len(list_author) == 0:\n            return None\n\n        # If there are more options than one, return the result from newspaper.\n        list_newspaper = [x for x in list_author if x[1] == \"newspaper\"]\n        if len(list_newspaper) == 0:\n\n            # If there is no author extracted by newspaper, return the first result of list_author.\n            return list_author[0][0]\n        else:\n            return list_newspaper[0][0]", "response": "Compares the extracted authors."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets prefix of the class", "response": "def __setPrefix(self):\n        '''\u83b7\u53d6\u7a0b\u5e8f\u8fd0\u884c\u7684\u8def\u5f84\uff0c\u4ee5\u6b64\u6765\u786e\u5b9amodels\u7684\u7edd\u5bf9\u8def\u5f84\u4ee5\u53ca\u5176\u4ed6\u8d44\u6e90\u6587\u4ef6\u7684\u8def\u5f84'''\n        __prefix = \"\"\n        if(self.__model_path_char is not None):\n            __prefix = self.__model_path_char\n            if(__prefix[-1] != \"/\"):\n                __prefix = __prefix + \"/\"\n        else:\n            __prefix = os.path.dirname(os.path.realpath(__file__))+\"/models/\"\n        return __prefix"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __cutWithOutMethod(self, oiraw, cut_method, text = True):\n        '''\u5206\u8bcd\uff0c\u5148\u5c06\u539f\u59cb\u53e5\u5b50split\u4e3a\u4e00\u4e2a\u6570\u7ec4\uff0c\u4e4b\u540e\u904d\u5386\u6bcf\u4e00\u884c\uff0c\u8c03\u7528\u5bf9\u5355\u884c\u5206\u8bcd\u7684\u51fd\u6570\uff08\u6709\u4e24\u79cd\uff09\u3002\n        text=True\u4f1a\u8fd4\u56de\u5206\u8bcd\u597d\u7684\u5b57\u7b26\u4e32\uff0c\u4e3aFalse\u5219\u4f1a\u8fd4\u56de\u4e00\u4e2a\u4e8c\u4f4d\u6570\u7ec4\u65b9\u4fbf\u7528\u6237\u505a\u540e\u7eed\u5904\u7406\u3002\n        \u51fd\u6570\u4e2d\u6709\u4e00\u4e9b\u7ec6\u8282\u5904\u7406\u4e3b\u8981\u662f\u7528\u4e8e\u89c4\u8303\u8f93\u51fa\u683c\u5f0f'''\n        oiraw = oiraw.split('\\n')\n        txt = \"\"\n        array = []\n        if(text):\n            for line in oiraw:\n                if(self.__seg_only):\n                    temp_txt = reduce(lambda x, y: x + ' ' + y if y != \" \" else x, cut_method(line), '') + '\\n'\n                else:\n                    temp_txt = reduce(lambda x, y: x + ' ' + \"\".join(y), cut_method(line), '') + '\\n'\n                txt += temp_txt[1:]\n            return txt[:-1]\n        else:\n            for line in oiraw:\n                if(line):\n                    if(self.__seg_only):\n                        array += (reduce(lambda x, y: x + [[y, '']], cut_method(line), []))\n                    else:\n                        array += (reduce(lambda x, y: x + [[y[0], y[2]]], cut_method(line), []))\n                array += [['\\n', '']]\n            return array[:-1]", "response": "cutWithOutMethod - cuts the content of the file"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrunning loop for all the user input", "response": "def run(self):\n        '''\u547d\u4ee4\u884c\u4ea4\u4e92\u7a0b\u5e8f'''\n        while(True):\n            oiraw = cInput()\n            if(len(oiraw) < 1):\n                break\n            cutted = self.cut(oiraw, text = True)\n            print(cutted)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncutting raw string into list of strings", "response": "def __cutRaw(self, oiraw, maxLength):\n        '''\u73b0\u5c06\u53e5\u5b50\u6309\u53e5\u5b50\u5b8c\u7ed3\u7b26\u53f7\u5207\u5206\uff0c\u5982\u679c\u5207\u5206\u5b8c\u540e\u4e00\u4e2a\u53e5\u5b50\u957f\u5ea6\u8d85\u8fc7\u9650\u5b9a\u503c\n        \uff0c\u518d\u5bf9\u8be5\u53e5\u5b50\u8fdb\u884c\u5207\u5206'''\n        vec = []\n        m = re.findall(u\".*?[\u3002\uff1f\uff01\uff1b;!?]\", oiraw)\n        num, l, last = 0, 0, 0\n        for i in range(len(m)):\n            if(num + len(m[i]) >= maxLength):\n                vec.append(\"\".join(m[last:i]))\n                last = i\n                num = len(m[i])\n            else:\n                num += len(m[i])\n            l += len(m[i])\n        if(len(oiraw)-l + num >= maxLength):\n            vec.append(\"\".join(m[last:len(m)]))\n            vec.append(oiraw[l:])\n        else:\n            vec.append(oiraw[l-num:])\n        return vec"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nopen a Windows named pipe.", "response": "def _asyncio_open_serial_windows(path):\n    \"\"\"\n    Open a windows named pipe\n\n    :returns: An IO like object\n    \"\"\"\n\n    try:\n        yield from wait_for_named_pipe_creation(path)\n    except asyncio.TimeoutError:\n        raise NodeError('Pipe file \"{}\" is missing'.format(path))\n    return WindowsPipe(path)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _asyncio_open_serial_unix(path):\n\n    try:\n        # wait for VM to create the pipe file.\n        yield from wait_for_file_creation(path)\n    except asyncio.TimeoutError:\n        raise NodeError('Pipe file \"{}\" is missing'.format(path))\n\n    output = SerialReaderWriterProtocol()\n    try:\n        yield from asyncio.get_event_loop().create_unix_connection(lambda: output, path)\n    except ConnectionRefusedError:\n        raise NodeError('Can\\'t open pipe file \"{}\"'.format(path))\n    return output", "response": "Open a unix socket or a windows named pipe."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating the link on the nodes", "response": "def create(self):\n        \"\"\"\n        Create the link on the nodes\n        \"\"\"\n\n        node1 = self._nodes[0][\"node\"]\n        adapter_number1 = self._nodes[0][\"adapter_number\"]\n        port_number1 = self._nodes[0][\"port_number\"]\n        node2 = self._nodes[1][\"node\"]\n        adapter_number2 = self._nodes[1][\"adapter_number\"]\n        port_number2 = self._nodes[1][\"port_number\"]\n\n        # Get an IP allowing communication between both host\n        try:\n            (node1_host, node2_host) = yield from node1.compute.get_ip_on_same_subnet(node2.compute)\n        except ValueError as e:\n            raise aiohttp.web.HTTPConflict(text=str(e))\n\n        # Reserve a UDP port on both side\n        response = yield from node1.compute.post(\"/projects/{}/ports/udp\".format(self._project.id))\n        self._node1_port = response.json[\"udp_port\"]\n        response = yield from node2.compute.post(\"/projects/{}/ports/udp\".format(self._project.id))\n        self._node2_port = response.json[\"udp_port\"]\n\n        node1_filters = {}\n        node2_filters = {}\n        filter_node = self._get_filter_node()\n        if filter_node == node1:\n            node1_filters = self.get_active_filters()\n        elif filter_node == node2:\n            node2_filters = self.get_active_filters()\n\n        # Create the tunnel on both side\n        self._link_data.append({\n            \"lport\": self._node1_port,\n            \"rhost\": node2_host,\n            \"rport\": self._node2_port,\n            \"type\": \"nio_udp\",\n            \"filters\": node1_filters\n        })\n        yield from node1.post(\"/adapters/{adapter_number}/ports/{port_number}/nio\".format(adapter_number=adapter_number1, port_number=port_number1), data=self._link_data[0], timeout=120)\n\n        self._link_data.append({\n            \"lport\": self._node2_port,\n            \"rhost\": node1_host,\n            \"rport\": self._node1_port,\n            \"type\": \"nio_udp\",\n            \"filters\": node2_filters\n        })\n        try:\n            yield from node2.post(\"/adapters/{adapter_number}/ports/{port_number}/nio\".format(adapter_number=adapter_number2, port_number=port_number2), data=self._link_data[1], timeout=120)\n        except Exception as e:\n            # We clean the first NIO\n            yield from node1.delete(\"/adapters/{adapter_number}/ports/{port_number}/nio\".format(adapter_number=adapter_number1, port_number=port_number1), timeout=120)\n            raise e\n        self._created = True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndeleting the link and free the resources", "response": "def delete(self):\n        \"\"\"\n        Delete the link and free the resources\n        \"\"\"\n        if not self._created:\n            return\n        try:\n            node1 = self._nodes[0][\"node\"]\n            adapter_number1 = self._nodes[0][\"adapter_number\"]\n            port_number1 = self._nodes[0][\"port_number\"]\n        except IndexError:\n            return\n        try:\n            yield from node1.delete(\"/adapters/{adapter_number}/ports/{port_number}/nio\".format(adapter_number=adapter_number1, port_number=port_number1), timeout=120)\n        # If the node is already delete (user selected multiple element and delete all in the same time)\n        except aiohttp.web.HTTPNotFound:\n            pass\n\n        try:\n            node2 = self._nodes[1][\"node\"]\n            adapter_number2 = self._nodes[1][\"adapter_number\"]\n            port_number2 = self._nodes[1][\"port_number\"]\n        except IndexError:\n            return\n        try:\n            yield from node2.delete(\"/adapters/{adapter_number}/ports/{port_number}/nio\".format(adapter_number=adapter_number2, port_number=port_number2), timeout=120)\n        # If the node is already delete (user selected multiple element and delete all in the same time)\n        except aiohttp.web.HTTPNotFound:\n            pass\n        yield from super().delete()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef start_capture(self, data_link_type=\"DLT_EN10MB\", capture_file_name=None):\n        if not capture_file_name:\n            capture_file_name = self.default_capture_file_name()\n        self._capture_node = self._choose_capture_side()\n        data = {\n            \"capture_file_name\": capture_file_name,\n            \"data_link_type\": data_link_type\n        }\n        yield from self._capture_node[\"node\"].post(\"/adapters/{adapter_number}/ports/{port_number}/start_capture\".format(adapter_number=self._capture_node[\"adapter_number\"], port_number=self._capture_node[\"port_number\"]), data=data)\n        yield from super().start_capture(data_link_type=data_link_type, capture_file_name=capture_file_name)", "response": "Start capture on a link."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef stop_capture(self):\n        if self._capture_node:\n            yield from self._capture_node[\"node\"].post(\"/adapters/{adapter_number}/ports/{port_number}/stop_capture\".format(adapter_number=self._capture_node[\"adapter_number\"], port_number=self._capture_node[\"port_number\"]))\n            self._capture_node = None\n        yield from super().stop_capture()", "response": "Stop capture on a link"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchooses the best candidate node that should run capture on the best candidate.", "response": "def _choose_capture_side(self):\n        \"\"\"\n        Run capture on the best candidate.\n\n        The ideal candidate is a node who on controller server and always\n        running (capture will not be cut off)\n\n        :returns: Node where the capture should run\n        \"\"\"\n\n        ALWAYS_RUNNING_NODES_TYPE = (\"cloud\", \"nat\", \"ethernet_switch\", \"ethernet_hub\")\n\n        for node in self._nodes:\n            if node[\"node\"].compute.id == \"local\" and node[\"node\"].node_type in ALWAYS_RUNNING_NODES_TYPE and node[\"node\"].status == \"started\":\n                return node\n\n        for node in self._nodes:\n            if node[\"node\"].node_type in ALWAYS_RUNNING_NODES_TYPE and node[\"node\"].status == \"started\":\n                return node\n\n        for node in self._nodes:\n            if node[\"node\"].compute.id == \"local\" and node[\"node\"].status == \"started\":\n                return node\n\n        for node in self._nodes:\n            if node[\"node\"].node_type and node[\"node\"].status == \"started\":\n                return node\n\n        raise aiohttp.web.HTTPConflict(text=\"Cannot capture because there is no running device on this link\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a FileStream of the Pcap from the compute node", "response": "def read_pcap_from_source(self):\n        \"\"\"\n        Return a FileStream of the Pcap from the compute node\n        \"\"\"\n        if self._capture_node:\n            compute = self._capture_node[\"node\"].compute\n            return compute.stream_file(self._project, \"tmp/captures/\" + self._capture_file_name)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncall when a node is updated by the link", "response": "def node_updated(self, node):\n        \"\"\"\n        Called when a node member of the link is updated\n        \"\"\"\n        if self._capture_node and node == self._capture_node[\"node\"] and node.status != \"started\":\n            yield from self.stop_capture()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_networking_file():\n\n    pairs = dict()\n    allocated_subnets = []\n    try:\n        with open(VMWARE_NETWORKING_FILE, \"r\", encoding=\"utf-8\") as f:\n            version = f.readline()\n            for line in f.read().splitlines():\n                try:\n                    _, key, value = line.split(' ', 3)\n                    key = key.strip()\n                    value = value.strip()\n                    pairs[key] = value\n                    if key.endswith(\"HOSTONLY_SUBNET\"):\n                        allocated_subnets.append(value)\n                except ValueError:\n                    raise SystemExit(\"Error while parsing {}\".format(VMWARE_NETWORKING_FILE))\n    except OSError as e:\n        raise SystemExit(\"Cannot open {}: {}\".format(VMWARE_NETWORKING_FILE, e))\n    return version, pairs, allocated_subnets", "response": "Parse the VMware networking file and return a dict of version pairs and allocated subnet list."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef write_networking_file(version, pairs):\n\n    vmnets = OrderedDict(sorted(pairs.items(), key=lambda t: t[0]))\n    try:\n        with open(VMWARE_NETWORKING_FILE, \"w\", encoding=\"utf-8\") as f:\n            f.write(version)\n            for key, value in vmnets.items():\n                f.write(\"answer {} {}\\n\".format(key, value))\n    except OSError as e:\n        raise SystemExit(\"Cannot open {}: {}\".format(VMWARE_NETWORKING_FILE, e))\n\n    # restart VMware networking service\n    if sys.platform.startswith(\"darwin\"):\n        if not os.path.exists(\"/Applications/VMware Fusion.app/Contents/Library/vmnet-cli\"):\n            raise SystemExit(\"VMware Fusion is not installed in Applications\")\n        os.system(r\"/Applications/VMware\\ Fusion.app/Contents/Library/vmnet-cli --configure\")\n        os.system(r\"/Applications/VMware\\ Fusion.app/Contents/Library/vmnet-cli --stop\")\n        os.system(r\"/Applications/VMware\\ Fusion.app/Contents/Library/vmnet-cli --start\")\n    else:\n        os.system(\"vmware-networks --stop\")\n        os.system(\"vmware-networks --start\")", "response": "Write the VMware networking file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_vmnet_range(start, end):\n\n    class Range(argparse.Action):\n\n        def __call__(self, parser, args, values, option_string=None):\n            if len(values) != 2:\n                raise argparse.ArgumentTypeError(\"vmnet range must consist of 2 numbers\")\n            if not start <= values[0] or not values[1] <= end:\n                raise argparse.ArgumentTypeError(\"vmnet range must be between {} and {}\".format(start, end))\n            setattr(args, self.dest, values)\n    return Range", "response": "Parse the vmnet range on the command line."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsending data back to the client", "response": "def send(self, data):\n        \"\"\"\n        Sending data back to client\n        :return:\n        \"\"\"\n        data = data.decode().replace(\"\\n\", \"\\r\\n\")\n        self.writer.write(data.encode())"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets a reader or None if another reader is already reading.", "response": "def _get_reader(self, network_reader):\n        \"\"\"\n        Get a reader or None if another reader is already reading.\n        \"\"\"\n        with (yield from self._lock):\n            if self._reader_process is None:\n                self._reader_process = network_reader\n            if self._reader:\n                if self._reader_process == network_reader:\n                    self._current_read = asyncio.async(self._reader.read(READ_SIZE))\n                    return self._current_read\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _read(self, cmd, buffer, location, reader):\n        try:\n            op = buffer[location]\n            cmd.append(op)\n            return op\n        except IndexError:\n            op = yield from reader.read(1)\n            buffer.extend(op)\n            cmd.append(buffer[location])\n            return op", "response": "Reads next op from the buffer or reader."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nhandling NAWS and NAWS negotiation commands", "response": "def _negotiate(self, data, connection):\n        \"\"\" Performs negotiation commands\"\"\"\n\n        command, payload = data[0], data[1:]\n        if command == NAWS:\n            if len(payload) == 4:\n                columns, rows = struct.unpack(str('!HH'), bytes(payload))\n                connection.window_size_changed(columns, rows)\n            else:\n                log.warning('Wrong number of NAWS bytes')\n        else:\n            log.debug(\"Not supported negotiation sequence, received {} bytes\", len(data))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _IAC_parser(self, buf, network_reader, network_writer, connection):\n\n\n        skip_to = 0\n        while True:\n            # Locate an IAC to process\n            iac_loc = buf.find(IAC, skip_to)\n            if iac_loc < 0:\n                break\n\n            # Get the TELNET command\n            iac_cmd = bytearray([IAC])\n            try:\n                iac_cmd.append(buf[iac_loc + 1])\n            except IndexError:\n                d = yield from network_reader.read(1)\n                buf.extend(d)\n                iac_cmd.append(buf[iac_loc + 1])\n\n            # Is this just a 2-byte TELNET command?\n            if iac_cmd[1] not in [WILL, WONT, DO, DONT, SB]:\n                if iac_cmd[1] == AYT:\n                    log.debug(\"Telnet server received Are-You-There (AYT)\")\n                    network_writer.write(b'\\r\\nYour Are-You-There received. I am here.\\r\\n')\n                elif iac_cmd[1] == IAC:\n                    # It's data, not an IAC\n                    iac_cmd.pop()\n                    # This prevents the 0xff from being\n                    # interrupted as yet another IAC\n                    skip_to = iac_loc + 1\n                    log.debug(\"Received IAC IAC\")\n                elif iac_cmd[1] == NOP:\n                    pass\n                else:\n                    log.debug(\"Unhandled telnet command: \"\n                              \"{0:#x} {1:#x}\".format(*iac_cmd))\n            elif iac_cmd[1] == SB:  # starts negotiation commands\n                negotiation = []\n                for pos in range(2, self.MAX_NEGOTIATION_READ):\n                    op = yield from self._read(iac_cmd, buf, iac_loc + pos, network_reader)\n                    negotiation.append(op)\n                    if op == SE:\n                        # ends negotiation commands\n                        break\n\n                # SE command is followed by IAC, remove the last two operations from stack\n                self._negotiate(negotiation[0:-2], connection)\n\n            # This must be a 3-byte TELNET command\n            else:\n                try:\n                    iac_cmd.append(buf[iac_loc + 2])\n                except IndexError:\n                    d = yield from network_reader.read(1)\n                    buf.extend(d)\n                    iac_cmd.append(buf[iac_loc + 2])\n                # We do ECHO, SGA, and BINARY. Period.\n                if iac_cmd[1] == DO:\n                    if iac_cmd[2] not in [ECHO, SGA, BINARY]:\n                        network_writer.write(bytes([IAC, WONT, iac_cmd[2]]))\n                        log.debug(\"Telnet WON'T {:#x}\".format(iac_cmd[2]))\n                    else:\n                        if iac_cmd[2] == SGA:\n                            if self._binary:\n                                network_writer.write(bytes([IAC, WILL, iac_cmd[2]]))\n                            else:\n                                network_writer.write(bytes([IAC, WONT, iac_cmd[2]]))\n                                log.debug(\"Telnet WON'T {:#x}\".format(iac_cmd[2]))\n\n                elif iac_cmd[1] == DONT:\n                    log.debug(\"Unhandled DONT telnet command: \"\n                              \"{0:#x} {1:#x} {2:#x}\".format(*iac_cmd))\n                elif iac_cmd[1] == WILL:\n                    if iac_cmd[2] not in [BINARY, NAWS]:\n                        log.debug(\"Unhandled WILL telnet command: \"\n                                  \"{0:#x} {1:#x} {2:#x}\".format(*iac_cmd))\n                elif iac_cmd[1] == WONT:\n                    log.debug(\"Unhandled WONT telnet command: \"\n                              \"{0:#x} {1:#x} {2:#x}\".format(*iac_cmd))\n                else:\n                    log.debug(\"Unhandled telnet command: \"\n                              \"{0:#x} {1:#x} {2:#x}\".format(*iac_cmd))\n\n            # Remove the entire TELNET command from the buffer\n            buf = buf.replace(iac_cmd, b'', 1)\n\n            yield from network_writer.drain()\n\n        # Return the new copy of the buffer, minus telnet commands\n        return buf", "response": "Parses the buffer and processes any IAC commands and returns a generator that yields the result."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(cls):\n        stats = {}\n        cur_time = time.time()\n        # minimum interval for getting CPU and memory statistics\n        if cur_time < cls._last_measurement or \\\n           cur_time > cls._last_measurement + 1.9:\n            cls._last_measurement = cur_time\n            # Non blocking call to get cpu usage. First call will return 0\n            cls._last_cpu_percent = psutil.cpu_percent(interval=None)\n            cls._last_mem_percent = psutil.virtual_memory().percent\n        stats[\"cpu_usage_percent\"] = cls._last_cpu_percent\n        stats[\"memory_usage_percent\"] = cls._last_mem_percent\n        return stats", "response": "Get ping statistics for a specific object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nclose the connection to this hypervisor.", "response": "def close(self):\n        \"\"\"\n        Closes the connection to this hypervisor (but leave it running).\n        \"\"\"\n\n        yield from self.send(\"hypervisor close\")\n        self._writer.close()\n        self._reader, self._writer = None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef stop(self):\n\n        try:\n            # try to properly stop the hypervisor\n            yield from self.send(\"hypervisor stop\")\n        except UbridgeError:\n            pass\n        try:\n            if self._writer is not None:\n                yield from self._writer.drain()\n                self._writer.close()\n        except OSError as e:\n            log.debug(\"Stopping hypervisor {}:{} {}\".format(self._host, self._port, e))\n        self._reader = self._writer = None", "response": "Stops the current hypervisor."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsend a command to the uBridge hypervisor.", "response": "def send(self, command):\n        \"\"\"\n        Sends commands to this hypervisor.\n\n        :param command: a uBridge hypervisor command\n\n        :returns: results as a list\n        \"\"\"\n\n        # uBridge responses are of the form:\n        #   1xx yyyyyy\\r\\n\n        #   1xx yyyyyy\\r\\n\n        #   ...\n        #   100-yyyy\\r\\n\n        # or\n        #   2xx-yyyy\\r\\n\n        #\n        # Where 1xx is a code from 100-199 for a success or 200-299 for an error\n        # The result might be multiple lines and might be less than the buffer size\n        # but still have more data. The only thing we know for sure is the last line\n        # will begin with '100-' or a '2xx-' and end with '\\r\\n'\n\n        if self._writer is None or self._reader is None:\n            raise UbridgeError(\"Not connected\")\n\n        try:\n            command = command.strip() + '\\n'\n            log.debug(\"sending {}\".format(command))\n            self._writer.write(command.encode())\n            yield from self._writer.drain()\n        except OSError as e:\n            raise UbridgeError(\"Lost communication with {host}:{port} :{error}, Dynamips process running: {run}\"\n                               .format(host=self._host, port=self._port, error=e, run=self.is_running()))\n\n        # Now retrieve the result\n        data = []\n        buf = ''\n        retries = 0\n        max_retries = 10\n        while True:\n            try:\n                try:\n                    chunk = yield from self._reader.read(1024)\n                except asyncio.CancelledError:\n                    # task has been canceled but continue to read\n                    # any remaining data sent by the hypervisor\n                    continue\n                except ConnectionResetError as e:\n                    # Sometimes WinError 64 (ERROR_NETNAME_DELETED) is returned here on Windows.\n                    # These happen if connection reset is received before IOCP could complete\n                    # a previous operation. Ignore and try again....\n                    log.warning(\"Connection reset received while reading uBridge response: {}\".format(e))\n                    continue\n                if not chunk:\n                    if retries > max_retries:\n                        raise UbridgeError(\"No data returned from {host}:{port}, uBridge process running: {run}\"\n                                            .format(host=self._host, port=self._port, run=self.is_running()))\n                    else:\n                        retries += 1\n                        yield from asyncio.sleep(0.1)\n                        continue\n                retries = 0\n                buf += chunk.decode(\"utf-8\")\n            except OSError as e:\n                raise UbridgeError(\"Lost communication with {host}:{port} :{error}, uBridge process running: {run}\"\n                                   .format(host=self._host, port=self._port, error=e, run=self.is_running()))\n\n            # If the buffer doesn't end in '\\n' then we can't be done\n            try:\n                if buf[-1] != '\\n':\n                    continue\n            except IndexError:\n                raise UbridgeError(\"Could not communicate with {host}:{port}, uBridge process running: {run}\"\n                                   .format(host=self._host, port=self._port, run=self.is_running()))\n\n            data += buf.split('\\r\\n')\n            if data[-1] == '':\n                data.pop()\n            buf = ''\n\n            # Does it contain an error code?\n            if self.error_re.search(data[-1]):\n                raise UbridgeError(data[-1][4:])\n\n            # Or does the last line begin with '100-'? Then we are done!\n            if data[-1][:4] == '100-':\n                data[-1] = data[-1][4:]\n                if data[-1] == 'OK':\n                    data.pop()\n                break\n\n        # Remove success responses codes\n        for index in range(len(data)):\n            if self.success_re.search(data[index]):\n                data[index] = data[index][4:]\n\n        log.debug(\"returned result {}\".format(data))\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a queue of notifications using Python s with", "response": "def queue(self):\n        \"\"\"\n        Get a queue of notifications\n\n        Use it with Python with\n        \"\"\"\n        queue = NotificationQueue()\n        self._listeners.add(queue)\n        yield queue\n        self._listeners.remove(queue)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef emit(self, action, event, **kwargs):\n        for listener in self._listeners:\n            listener.put_nowait((action, event, kwargs))", "response": "Send an event to all the client listening for notifications\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef instance():\n\n        if not hasattr(NotificationManager, '_instance') or NotificationManager._instance is None:\n            NotificationManager._instance = NotificationManager()\n        return NotificationManager._instance", "response": "Singleton to return only on instance of NotificationManager."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses the request body and raise HTTP errors in case of problems", "response": "def parse_request(request, input_schema, raw):\n    \"\"\"Parse body of request and raise HTTP errors in case of problems\"\"\"\n\n    request.json = {}\n    if not raw:\n        body = yield from request.read()\n        if body:\n            try:\n                request.json = json.loads(body.decode('utf-8'))\n            except ValueError as e:\n                request.json = {\"malformed_json\": body.decode('utf-8')}\n                raise aiohttp.web.HTTPBadRequest(text=\"Invalid JSON {}\".format(e))\n\n    # Parse the query string\n    if len(request.query_string) > 0:\n        for (k, v) in urllib.parse.parse_qs(request.query_string).items():\n            request.json[k] = v[0]\n\n    if input_schema:\n        try:\n            jsonschema.validate(request.json, input_schema)\n        except jsonschema.ValidationError as e:\n            log.error(\"Invalid input query. JSON schema error: {}\".format(e.message))\n            raise aiohttp.web.HTTPBadRequest(text=\"Invalid JSON: {} in schema: {}\".format(\n                e.message,\n                json.dumps(e.schema)))\n\n    return request"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nasking user for authentication", "response": "def authenticate(cls, request, route, server_config):\n        \"\"\"\n        Ask user for authentication\n\n        :returns: Response if you need to auth the user otherwise None\n        \"\"\"\n        if not server_config.getboolean(\"auth\", False):\n            return\n\n        user = server_config.get(\"user\", \"\").strip()\n        password = server_config.get(\"password\", \"\").strip()\n\n        if len(user) == 0:\n            return\n\n        if \"AUTHORIZATION\" in request.headers:\n            if request.headers[\"AUTHORIZATION\"] == aiohttp.helpers.BasicAuth(user, password, \"utf-8\").encode():\n                return\n\n        log.error(\"Invalid auth. Username should %s\", user)\n\n        response = Response(request=request, route=route)\n        response.set_status(401)\n        response.headers[\"WWW-Authenticate\"] = 'Basic realm=\"GNS3 server\"'\n        # Force close the keep alive. Work around a Qt issue where Qt timeout instead of handling the 401\n        # this happen only for the first query send by the client.\n        response.force_close()\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets a new entry from the cache.", "response": "def get(self, timeout):\n        \"\"\"\n        When timeout is expire we send a ping notification with server information\n        \"\"\"\n\n        # At first get we return a ping so the client immediately receives data\n        if self._first:\n            self._first = False\n            return (\"ping\", PingStats.get(), {})\n\n        try:\n            (action, msg, kwargs) = yield from asyncio.wait_for(super().get(), timeout)\n        except asyncio.futures.TimeoutError:\n            return (\"ping\", PingStats.get(), {})\n        return (action, msg, kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget a message as a JSON string", "response": "def get_json(self, timeout):\n        \"\"\"\n        Get a message as a JSON\n        \"\"\"\n        (action, msg, kwargs) = yield from self.get(timeout)\n        if hasattr(msg, \"__json__\"):\n            msg = {\"action\": action, \"event\": msg.__json__()}\n        else:\n            msg = {\"action\": action, \"event\": msg}\n        msg.update(kwargs)\n        return json.dumps(msg, sort_keys=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef close(self):\n\n        if not (yield from super().close()):\n            return False\n\n        nio = self._ethernet_adapter.get_nio(0)\n        if isinstance(nio, NIOUDP):\n            self.manager.port_manager.release_udp_port(nio.lport, self._project)\n\n        if self._local_udp_tunnel:\n            self.manager.port_manager.release_udp_port(self._local_udp_tunnel[0].lport, self._project)\n            self.manager.port_manager.release_udp_port(self._local_udp_tunnel[1].lport, self._project)\n            self._local_udp_tunnel = None\n\n        yield from self._stop_ubridge()\n\n        if self.is_running():\n            self._terminate_process()\n\n        return True", "response": "Closes this VPCS VM."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _check_requirements(self):\n\n        path = self._vpcs_path()\n        if not path:\n            raise VPCSError(\"No path to a VPCS executable has been set\")\n\n        # This raise an error if ubridge is not available\n        self.ubridge_path\n\n        if not os.path.isfile(path):\n            raise VPCSError(\"VPCS program '{}' is not accessible\".format(path))\n\n        if not os.access(path, os.X_OK):\n            raise VPCSError(\"VPCS program '{}' is not executable\".format(path))\n\n        yield from self._check_vpcs_version()", "response": "Check if the VPCS executable is available with the correct version."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _vpcs_path(self):\n\n        search_path = self._manager.config.get_section_config(\"VPCS\").get(\"vpcs_path\", \"vpcs\")\n        path = shutil.which(search_path)\n        # shutil.which return None if the path doesn't exists\n        if not path:\n            return search_path\n        return path", "response": "Returns the path to the VPCS executable."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the name of this VPCS VM.", "response": "def name(self, new_name):\n        \"\"\"\n        Sets the name of this VPCS VM.\n\n        :param new_name: name\n        \"\"\"\n\n        if self.script_file:\n            content = self.startup_script\n            content = content.replace(self._name, new_name)\n            escaped_name = new_name.replace('\\\\', '')\n            content = re.sub(r\"^set pcname .+$\", \"set pcname \" + escaped_name, content, flags=re.MULTILINE)\n            self.startup_script = content\n\n        super(VPCSVM, VPCSVM).name.__set__(self, new_name)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the content of the current startup script", "response": "def startup_script(self):\n        \"\"\"\n        Returns the content of the current startup script\n        \"\"\"\n\n        script_file = self.script_file\n        if script_file is None:\n            return None\n\n        try:\n            with open(script_file, \"rb\") as f:\n                return f.read().decode(\"utf-8\", errors=\"replace\")\n        except OSError as e:\n            raise VPCSError('Cannot read the startup script file \"{}\": {}'.format(script_file, e))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef startup_script(self, startup_script):\n\n        try:\n            startup_script_path = os.path.join(self.working_dir, 'startup.vpc')\n            with open(startup_script_path, \"w+\", encoding='utf-8') as f:\n                if startup_script is None:\n                    f.write('')\n                else:\n                    startup_script = startup_script.replace(\"%h\", self._name)\n                    f.write(startup_script)\n        except OSError as e:\n            raise VPCSError('Cannot write the startup script file \"{}\": {}'.format(startup_script_path, e))", "response": "Updates the startup script."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _check_vpcs_version(self):\n        try:\n            output = yield from subprocess_check_output(self._vpcs_path(), \"-v\", cwd=self.working_dir)\n            match = re.search(\"Welcome to Virtual PC Simulator, version ([0-9a-z\\.]+)\", output)\n            if match:\n                version = match.group(1)\n                self._vpcs_version = parse_version(version)\n                if self._vpcs_version < parse_version(\"0.6.1\"):\n                    raise VPCSError(\"VPCS executable version must be >= 0.6.1 but not a 0.8\")\n            else:\n                raise VPCSError(\"Could not determine the VPCS version for {}\".format(self._vpcs_path()))\n        except (OSError, subprocess.SubprocessError) as e:\n            raise VPCSError(\"Error while looking for the VPCS version: {}\".format(e))", "response": "Checks if the VPCS executable version is >= 0. 8b and < = 0. 6. 1."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef start(self):\n\n        yield from self._check_requirements()\n        if not self.is_running():\n            nio = self._ethernet_adapter.get_nio(0)\n            command = self._build_command()\n            try:\n                log.info(\"Starting VPCS: {}\".format(command))\n                self._vpcs_stdout_file = os.path.join(self.working_dir, \"vpcs.log\")\n                log.info(\"Logging to {}\".format(self._vpcs_stdout_file))\n                flags = 0\n                if sys.platform.startswith(\"win32\"):\n                    flags = subprocess.CREATE_NEW_PROCESS_GROUP\n                with open(self._vpcs_stdout_file, \"w\", encoding=\"utf-8\") as fd:\n                    self.command_line = ' '.join(command)\n                    self._process = yield from asyncio.create_subprocess_exec(*command,\n                                                                              stdout=fd,\n                                                                              stderr=subprocess.STDOUT,\n                                                                              cwd=self.working_dir,\n                                                                              creationflags=flags)\n                    monitor_process(self._process, self._termination_callback)\n\n                yield from self._start_ubridge()\n                if nio:\n                    yield from self.add_ubridge_udp_connection(\"VPCS-{}\".format(self._id), self._local_udp_tunnel[1], nio)\n\n                yield from self.start_wrap_console()\n\n                log.info(\"VPCS instance {} started PID={}\".format(self.name, self._process.pid))\n                self._started = True\n                self.status = \"started\"\n            except (OSError, subprocess.SubprocessError) as e:\n                vpcs_stdout = self.read_vpcs_stdout()\n                log.error(\"Could not start VPCS {}: {}\\n{}\".format(self._vpcs_path(), e, vpcs_stdout))\n                raise VPCSError(\"Could not start VPCS {}: {}\\n{}\".format(self._vpcs_path(), e, vpcs_stdout))", "response": "Starts the VPCS process."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalling when the process has stopped.", "response": "def _termination_callback(self, returncode):\n        \"\"\"\n        Called when the process has stopped.\n\n        :param returncode: Process returncode\n        \"\"\"\n        if self._started:\n            log.info(\"VPCS process has stopped, return code: %d\", returncode)\n            self._started = False\n            self.status = \"stopped\"\n            self._process = None\n            if returncode != 0:\n                self.project.emit(\"log.error\", {\"message\": \"VPCS process has stopped, return code: {}\\n{}\".format(returncode, self.read_vpcs_stdout())})"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nstop the VPCS process.", "response": "def stop(self):\n        \"\"\"\n        Stops the VPCS process.\n        \"\"\"\n\n        yield from self._stop_ubridge()\n        if self.is_running():\n            self._terminate_process()\n            if self._process.returncode is None:\n                try:\n                    yield from wait_for_process_termination(self._process, timeout=3)\n                except asyncio.TimeoutError:\n                    if self._process.returncode is None:\n                        try:\n                            self._process.kill()\n                        except OSError as e:\n                            log.error(\"Cannot stop the VPCS process: {}\".format(e))\n                        if self._process.returncode is None:\n                            log.warn('VPCS VM \"{}\" with PID={} is still running'.format(self._name, self._process.pid))\n\n        self._process = None\n        self._started = False\n        yield from super().stop()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nterminates the process if running", "response": "def _terminate_process(self):\n        \"\"\"\n        Terminate the process if running\n        \"\"\"\n\n        log.info(\"Stopping VPCS instance {} PID={}\".format(self.name, self._process.pid))\n        if sys.platform.startswith(\"win32\"):\n            self._process.send_signal(signal.CTRL_BREAK_EVENT)\n        else:\n            try:\n                self._process.terminate()\n            # Sometime the process may already be dead when we garbage collect\n            except ProcessLookupError:\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreads the standard output of the VPCS process. Only use when the process has stopped and crashed.", "response": "def read_vpcs_stdout(self):\n        \"\"\"\n        Reads the standard output of the VPCS process.\n        Only use when the process has been stopped or has crashed.\n        \"\"\"\n\n        output = \"\"\n        if self._vpcs_stdout_file:\n            try:\n                with open(self._vpcs_stdout_file, \"rb\") as file:\n                    output = file.read().decode(\"utf-8\", errors=\"replace\")\n            except OSError as e:\n                log.warn(\"Could not read {}: {}\".format(self._vpcs_stdout_file, e))\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef port_add_nio_binding(self, port_number, nio):\n\n        if not self._ethernet_adapter.port_exists(port_number):\n            raise VPCSError(\"Port {port_number} doesn't exist in adapter {adapter}\".format(adapter=self._ethernet_adapter,\n                                                                                           port_number=port_number))\n\n        if self.is_running():\n            yield from self.add_ubridge_udp_connection(\"VPCS-{}\".format(self._id), self._local_udp_tunnel[1], nio)\n\n        self._ethernet_adapter.add_nio(port_number, nio)\n        log.info('VPCS \"{name}\" [{id}]: {nio} added to port {port_number}'.format(name=self._name,\n                                                                                  id=self.id,\n                                                                                  nio=nio,\n                                                                                  port_number=port_number))\n\n        return nio", "response": "Adds a NIO binding to a port."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove a port NIO binding.", "response": "def port_remove_nio_binding(self, port_number):\n        \"\"\"\n        Removes a port NIO binding.\n\n        :param port_number: port number\n\n        :returns: NIO instance\n        \"\"\"\n\n        if not self._ethernet_adapter.port_exists(port_number):\n            raise VPCSError(\"Port {port_number} doesn't exist in adapter {adapter}\".format(adapter=self._ethernet_adapter,\n                                                                                           port_number=port_number))\n\n        if self.is_running():\n            yield from self._ubridge_send(\"bridge delete {name}\".format(name=\"VPCS-{}\".format(self._id)))\n\n        nio = self._ethernet_adapter.get_nio(port_number)\n        if isinstance(nio, NIOUDP):\n            self.manager.port_manager.release_udp_port(nio.lport, self._project)\n        self._ethernet_adapter.remove_nio(port_number)\n\n        log.info('VPCS \"{name}\" [{id}]: {nio} removed from port {port_number}'.format(name=self._name,\n                                                                                      id=self.id,\n                                                                                      nio=nio,\n                                                                                      port_number=port_number))\n        return nio"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstarts a packet capture on the specified port.", "response": "def start_capture(self, port_number, output_file):\n        \"\"\"\n        Starts a packet capture.\n\n        :param port_number: port number\n        :param output_file: PCAP destination file for the capture\n        \"\"\"\n\n        if not self._ethernet_adapter.port_exists(port_number):\n            raise VPCSError(\"Port {port_number} doesn't exist in adapter {adapter}\".format(adapter=self._ethernet_adapter,\n                                                                                           port_number=port_number))\n\n        nio = self._ethernet_adapter.get_nio(0)\n\n        if not nio:\n            raise VPCSError(\"Port {} is not connected\".format(port_number))\n\n        if nio.capturing:\n            raise VPCSError(\"Packet capture is already activated on port {port_number}\".format(port_number=port_number))\n\n        nio.startPacketCapture(output_file)\n\n        if self.ubridge:\n            yield from self._ubridge_send('bridge start_capture {name} \"{output_file}\"'.format(name=\"VPCS-{}\".format(self._id),\n                                                                                               output_file=output_file))\n\n        log.info(\"VPCS '{name}' [{id}]: starting packet capture on port {port_number}\".format(name=self.name,\n                                                                                              id=self.id,\n                                                                                              port_number=port_number))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef stop_capture(self, port_number):\n\n        if not self._ethernet_adapter.port_exists(port_number):\n            raise VPCSError(\"Port {port_number} doesn't exist in adapter {adapter}\".format(adapter=self._ethernet_adapter,\n                                                                                           port_number=port_number))\n\n        nio = self._ethernet_adapter.get_nio(0)\n\n        if not nio:\n            raise VPCSError(\"Port {} is not connected\".format(port_number))\n\n        nio.stopPacketCapture()\n\n        if self.ubridge:\n            yield from self._ubridge_send('bridge stop_capture {name}'.format(name=\"VPCS-{}\".format(self._id)))\n\n        log.info(\"VPCS '{name}' [{id}]: stopping packet capture on port {port_number}\".format(name=self.name,\n                                                                                              id=self.id,\n                                                                                              port_number=port_number))", "response": "Stops a packet capture."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _build_command(self):\n\n        command = [self._vpcs_path()]\n        command.extend([\"-p\", str(self._internal_console_port)])  # listen to console port\n        command.extend([\"-m\", str(self._manager.get_mac_id(self.id))])   # the unique ID is used to set the MAC address offset\n        command.extend([\"-i\", \"1\"])  # option to start only one VPC instance\n        command.extend([\"-F\"])  # option to avoid the daemonization of VPCS\n        if self._vpcs_version >= parse_version(\"0.8b\"):\n            command.extend([\"-R\"])  # disable the relay feature of VPCS (starting with VPCS 0.8)\n        else:\n            log.warn(\"The VPCS relay feature could not be disabled because the VPCS version is below 0.8b\")\n\n        # use the local UDP tunnel to uBridge instead\n        if not self._local_udp_tunnel:\n            self._local_udp_tunnel = self._create_local_udp_tunnel()\n        nio = self._local_udp_tunnel[0]\n        if nio:\n\n            if isinstance(nio, NIOUDP):\n                # UDP tunnel\n                command.extend([\"-s\", str(nio.lport)])  # source UDP port\n                command.extend([\"-c\", str(nio.rport)])  # destination UDP port\n                try:\n                    command.extend([\"-t\", socket.gethostbyname(nio.rhost)])  # destination host, we need to resolve the hostname because VPCS doesn't support it\n                except socket.gaierror as e:\n                    raise VPCSError(\"Can't resolve hostname {}\".format(nio.rhost))\n\n            elif isinstance(nio, NIOTAP):\n                # FIXME: remove old code\n                # TAP interface\n                command.extend([\"-e\"])\n                command.extend([\"-d\", nio.tap_device])\n\n        if self.script_file:\n            command.extend([os.path.basename(self.script_file)])\n        return command", "response": "Build the command line for the VPCS process."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the startup script file for this VPCS VM.", "response": "def script_file(self):\n        \"\"\"\n        Returns the startup script file for this VPCS VM.\n\n        :returns: path to startup script file\n        \"\"\"\n\n        # use the default VPCS file if it exists\n        path = os.path.join(self.working_dir, 'startup.vpc')\n        if os.path.exists(path):\n            return path\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_windows_interfaces():\n\n    import win32com.client\n    import pywintypes\n\n    interfaces = []\n    try:\n        locator = win32com.client.Dispatch(\"WbemScripting.SWbemLocator\")\n        service = locator.ConnectServer(\".\", \"root\\cimv2\")\n        network_configs = service.InstancesOf(\"Win32_NetworkAdapterConfiguration\")\n        # more info on Win32_NetworkAdapter: http://msdn.microsoft.com/en-us/library/aa394216%28v=vs.85%29.aspx\n        for adapter in service.InstancesOf(\"Win32_NetworkAdapter\"):\n            if adapter.NetConnectionStatus == 2 or adapter.NetConnectionStatus == 7:\n                # adapter is connected or media disconnected\n                ip_address = \"\"\n                netmask = \"\"\n                for network_config in network_configs:\n                    if network_config.InterfaceIndex == adapter.InterfaceIndex:\n                        if network_config.IPAddress:\n                            # get the first IPv4 address only\n                            ip_address = network_config.IPAddress[0]\n                            netmask = network_config.IPSubnet[0]\n                        break\n                npf_interface = \"\\\\Device\\\\NPF_{guid}\".format(guid=adapter.GUID)\n                interfaces.append({\"id\": npf_interface,\n                                   \"name\": adapter.NetConnectionID,\n                                   \"ip_address\": ip_address,\n                                   \"mac_address\": adapter.MACAddress,\n                                   \"netcard\": adapter.name,\n                                   \"netmask\": netmask,\n                                   \"type\": \"ethernet\"})\n    except (AttributeError, pywintypes.com_error):\n        log.warn(\"Could not use the COM service to retrieve interface info, trying using the registry...\")\n        return _get_windows_interfaces_from_registry()\n\n    return interfaces", "response": "Get Windows interfaces from the COM service."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef has_netmask(interface_name):\n    for interface in interfaces():\n        if interface[\"name\"] == interface_name:\n            if interface[\"netmask\"] and len(interface[\"netmask\"]) > 0:\n                return True\n            return False\n    return False", "response": "Checks if an interface has a netmask."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking if an interface is up.", "response": "def is_interface_up(interface):\n    \"\"\"\n    Checks if an interface is up.\n\n    :param interface: interface name\n\n    :returns: boolean\n    \"\"\"\n\n    if sys.platform.startswith(\"linux\"):\n\n        if interface not in psutil.net_if_addrs():\n            return False\n\n        import fcntl\n        SIOCGIFFLAGS = 0x8913\n        try:\n            with socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as s:\n                result = fcntl.ioctl(s.fileno(), SIOCGIFFLAGS, interface + '\\0' * 256)\n                flags, = struct.unpack('H', result[16:18])\n                if flags & 1:  # check if the up bit is set\n                    return True\n            return False\n        except OSError as e:\n            raise aiohttp.web.HTTPInternalServerError(text=\"Exception when checking if {} is up: {}\".format(interface, e))\n    else:\n        # TODO: Windows & OSX support\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the network interfaces on this server.", "response": "def interfaces():\n    \"\"\"\n    Gets the network interfaces on this server.\n\n    :returns: list of network interfaces\n    \"\"\"\n\n    results = []\n    if not sys.platform.startswith(\"win\"):\n        net_if_addrs = psutil.net_if_addrs()\n        for interface in sorted(net_if_addrs.keys()):\n            ip_address = \"\"\n            mac_address = \"\"\n            netmask = \"\"\n            interface_type = \"ethernet\"\n            for addr in net_if_addrs[interface]:\n                # get the first available IPv4 address only\n                if addr.family == socket.AF_INET:\n                    ip_address = addr.address\n                    netmask = addr.netmask\n                if addr.family == psutil.AF_LINK:\n                    mac_address = addr.address\n            if interface.startswith(\"tap\"):\n                # found no way to reliably detect a TAP interface\n                interface_type = \"tap\"\n            results.append({\"id\": interface,\n                            \"name\": interface,\n                            \"ip_address\": ip_address,\n                            \"netmask\": netmask,\n                            \"mac_address\": mac_address,\n                            \"type\": interface_type})\n    else:\n        try:\n            service_installed = True\n            if not _check_windows_service(\"npf\") and not _check_windows_service(\"npcap\"):\n                service_installed = False\n            else:\n                results = get_windows_interfaces()\n        except ImportError:\n            message = \"pywin32 module is not installed, please install it on the server to get the available interface names\"\n            raise aiohttp.web.HTTPInternalServerError(text=message)\n        except Exception as e:\n            log.error(\"uncaught exception {type}\".format(type=type(e)), exc_info=1)\n            raise aiohttp.web.HTTPInternalServerError(text=\"uncaught exception: {}\".format(e))\n\n        if service_installed is False:\n            raise aiohttp.web.HTTPInternalServerError(text=\"The Winpcap or Npcap is not installed or running\")\n\n    # This interface have special behavior\n    for result in results:\n        result[\"special\"] = False\n        for special_interface in (\"lo\", \"vmnet\", \"vboxnet\", \"docker\", \"lxcbr\",\n                                  \"virbr\", \"ovs-system\", \"veth\", \"fw\", \"p2p\",\n                                  \"bridge\", \"vmware\", \"virtualbox\", \"gns3\"):\n            if result[\"name\"].lower().startswith(special_interface):\n                result[\"special\"] = True\n        for special_interface in (\"-nic\"):\n            if result[\"name\"].lower().endswith(special_interface):\n                result[\"special\"] = True\n    return results"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _set_vcpus_ram(self, vcpus, ram):\n\n        # memory must be a multiple of 4 (VMware requirement)\n        if ram % 4 != 0:\n            raise GNS3VMError(\"Allocated memory {} for the GNS3 VM must be a multiple of 4\".format(ram))\n\n        available_vcpus = psutil.cpu_count(logical=False)\n        if vcpus > available_vcpus:\n            raise GNS3VMError(\"You have allocated too many vCPUs for the GNS3 VM! (max available is {} vCPUs)\".format(available_vcpus))\n\n        try:\n            pairs = VMware.parse_vmware_file(self._vmx_path)\n            pairs[\"numvcpus\"] = str(vcpus)\n            pairs[\"memsize\"] = str(ram)\n            VMware.write_vmx_file(self._vmx_path, pairs)\n            log.info(\"GNS3 VM vCPU count set to {} and RAM amount set to {}\".format(vcpus, ram))\n        except OSError as e:\n            raise GNS3VMError('Could not read/write VMware VMX file \"{}\": {}'.format(self._vmx_path, e))", "response": "Sets the number of vCPU cores and amount of RAM for the GNS3 VM."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef list(self):\n        try:\n            return (yield from self._vmware_manager.list_vms())\n        except VMwareError as e:\n            raise GNS3VMError(\"Could not list VMware VMs: {}\".format(str(e)))", "response": "List all VMware VMs in this VM."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef start(self):\n\n        vms = yield from self.list()\n        for vm in vms:\n            if vm[\"vmname\"] == self.vmname:\n                self._vmx_path = vm[\"vmx_path\"]\n                break\n\n        # check we have a valid VMX file path\n        if not self._vmx_path:\n            raise GNS3VMError(\"VMWare VM {} not found\".format(self.vmname))\n        if not os.path.exists(self._vmx_path):\n            raise GNS3VMError(\"VMware VMX file {} doesn't exist\".format(self._vmx_path))\n\n        # check if the VMware guest tools are installed\n        vmware_tools_state = yield from self._execute(\"checkToolsState\", [self._vmx_path])\n        if vmware_tools_state not in (\"installed\", \"running\"):\n            raise GNS3VMError(\"VMware tools are not installed in {}\".format(self.vmname))\n\n        try:\n            running = yield from self._is_running()\n        except VMwareError as e:\n            raise GNS3VMError(\"Could not list VMware VMs: {}\".format(str(e)))\n        if not running:\n            log.info(\"Update GNS3 VM settings\")\n            # set the number of vCPUs and amount of RAM\n            yield from self._set_vcpus_ram(self.vcpus, self.ram)\n            yield from self._set_extra_options()\n\n            # start the VM\n            args = [self._vmx_path]\n            if self._headless:\n                args.extend([\"nogui\"])\n            yield from self._execute(\"start\", args)\n            log.info(\"GNS3 VM has been started\")\n\n        # get the guest IP address (first adapter only)\n        trial = 120\n        guest_ip_address = \"\"\n        log.info(\"Waiting for GNS3 VM IP\")\n        while True:\n            guest_ip_address = yield from self._execute(\"readVariable\", [self._vmx_path, \"guestVar\", \"gns3.eth0\"], timeout=120, log_level=logging.DEBUG)\n            guest_ip_address = guest_ip_address.strip()\n            if len(guest_ip_address) != 0:\n                break\n            trial -= 1\n            # If ip not found fallback on old method\n            if trial == 0:\n                log.warning(\"No IP found for the VM via readVariable fallback to getGuestIPAddress\")\n                guest_ip_address = yield from self._execute(\"getGuestIPAddress\", [self._vmx_path, \"-wait\"], timeout=120)\n                break\n            yield from asyncio.sleep(1)\n        self.ip_address = guest_ip_address\n        log.info(\"GNS3 VM IP address set to {}\".format(guest_ip_address))\n        self.running = True", "response": "Starts the GNS3 VM."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsuspend the GNS3 VM.", "response": "def suspend(self):\n        \"\"\"\n        Suspend the GNS3 VM.\n        \"\"\"\n\n        if self._vmx_path is None:\n            raise GNS3VMError(\"No VMX path configured, can't suspend the VM\")\n        try:\n            yield from self._execute(\"suspend\", [self._vmx_path])\n        except GNS3VMError as e:\n            log.warning(\"Error when suspending the VM: {}\".format(str(e)))\n        log.info(\"GNS3 VM has been suspended\")\n        self.running = False"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads from the VMware VMX file corresponding to this VM.", "response": "def _read_vmx_file(self):\n        \"\"\"\n        Reads from the VMware VMX file corresponding to this VM.\n        \"\"\"\n\n        try:\n            self._vmx_pairs = self.manager.parse_vmware_file(self._vmx_path)\n        except OSError as e:\n            raise VMwareError('Could not read VMware VMX file \"{}\": {}'.format(self._vmx_path, e))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _write_vmx_file(self):\n\n        try:\n            self.manager.write_vmx_file(self._vmx_path, self._vmx_pairs)\n        except OSError as e:\n            raise VMwareError('Could not write VMware VMX file \"{}\": {}'.format(self._vmx_path, e))", "response": "Writes the set of pairs to the VMware VMX file corresponding to this VM."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _check_duplicate_linked_clone(self):\n        trial = 0\n\n        while True:\n            found = False\n            for node in self.manager.nodes:\n                if node != self and node.vmx_path == self._vmx_path:\n                    found = True\n                    if node.project != self.project:\n                        if trial >= 30:\n                            raise VMwareError(\"Sorry a node without the linked clone setting enabled can only be used once on your server.\\n{} is already used by {} in project {}\".format(self.vmx_path, node.name, self.project.name))\n                    else:\n                        if trial >= 5:\n                            raise VMwareError(\"Sorry a node without the linked clone setting enabled can only be used once on your server.\\n{} is already used by {} in this project\".format(self.vmx_path, node.name))\n            if not found:\n                return\n            trial += 1\n            yield from asyncio.sleep(1)", "response": "Checks if there is a duplicate linked clone for this VM."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create(self):\n        if not self.linked_clone:\n            yield from self._check_duplicate_linked_clone()\n\n        yield from self.manager.check_vmrun_version()\n        if self.linked_clone and not os.path.exists(os.path.join(self.working_dir, os.path.basename(self._vmx_path))):\n            if self.manager.host_type == \"player\":\n                raise VMwareError(\"Linked clones are not supported by VMware Player\")\n            # create the base snapshot for linked clones\n            base_snapshot_name = \"GNS3 Linked Base for clones\"\n            vmsd_path = os.path.splitext(self._vmx_path)[0] + \".vmsd\"\n            if not os.path.exists(vmsd_path):\n                raise VMwareError(\"{} doesn't not exist\".format(vmsd_path))\n            try:\n                vmsd_pairs = self.manager.parse_vmware_file(vmsd_path)\n            except OSError as e:\n                raise VMwareError('Could not read VMware VMSD file \"{}\": {}'.format(vmsd_path, e))\n            gns3_snapshot_exists = False\n            for value in vmsd_pairs.values():\n                if value == base_snapshot_name:\n                    gns3_snapshot_exists = True\n                    break\n            if not gns3_snapshot_exists:\n                log.info(\"Creating snapshot '{}'\".format(base_snapshot_name))\n                yield from self._control_vm(\"snapshot\", base_snapshot_name)\n\n            # create the linked clone based on the base snapshot\n            new_vmx_path = os.path.join(self.working_dir, self.name + \".vmx\")\n            yield from self._control_vm(\"clone\",\n                                        new_vmx_path,\n                                        \"linked\",\n                                        \"-snapshot={}\".format(base_snapshot_name),\n                                        \"-cloneName={}\".format(self.name))\n\n            try:\n                vmsd_pairs = self.manager.parse_vmware_file(vmsd_path)\n            except OSError as e:\n                raise VMwareError('Could not read VMware VMSD file \"{}\": {}'.format(vmsd_path, e))\n\n            snapshot_name = None\n            for name, value in vmsd_pairs.items():\n                if value == base_snapshot_name:\n                    snapshot_name = name.split(\".\", 1)[0]\n                    break\n\n            if snapshot_name is None:\n                raise VMwareError(\"Could not find the linked base snapshot in {}\".format(vmsd_path))\n\n            num_clones_entry = \"{}.numClones\".format(snapshot_name)\n            if num_clones_entry in vmsd_pairs:\n                try:\n                    nb_of_clones = int(vmsd_pairs[num_clones_entry])\n                except ValueError:\n                    raise VMwareError(\"Value of {} in {} is not a number\".format(num_clones_entry, vmsd_path))\n                vmsd_pairs[num_clones_entry] = str(nb_of_clones - 1)\n\n                for clone_nb in range(0, nb_of_clones):\n                    clone_entry = \"{}.clone{}\".format(snapshot_name, clone_nb)\n                    if clone_entry in vmsd_pairs:\n                        del vmsd_pairs[clone_entry]\n\n                try:\n                    self.manager.write_vmware_file(vmsd_path, vmsd_pairs)\n                except OSError as e:\n                    raise VMwareError('Could not write VMware VMSD file \"{}\": {}'.format(vmsd_path, e))\n\n            # update the VMX file path\n            self._vmx_path = new_vmx_path", "response": "Creates this VM and handle linked clones."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_network_options(self):\n\n        # first some sanity checks\n        for adapter_number in range(0, self._adapters):\n\n            # we want the vmnet interface to be connected when starting the VM\n            connected = \"ethernet{}.startConnected\".format(adapter_number)\n            if self._get_vmx_setting(connected):\n                del self._vmx_pairs[connected]\n\n        # then configure VMware network adapters\n        self.manager.refresh_vmnet_list()\n        for adapter_number in range(0, self._adapters):\n\n            # add/update the interface\n            if self._adapter_type == \"default\":\n                # force default to e1000 because some guest OS don't detect the adapter (i.e. Windows 2012 server)\n                # when 'virtualdev' is not set in the VMX file.\n                adapter_type = \"e1000\"\n            else:\n                adapter_type = self._adapter_type\n            ethernet_adapter = {\"ethernet{}.present\".format(adapter_number): \"TRUE\",\n                                \"ethernet{}.addresstype\".format(adapter_number): \"generated\",\n                                \"ethernet{}.generatedaddressoffset\".format(adapter_number): \"0\",\n                                \"ethernet{}.virtualdev\".format(adapter_number): adapter_type}\n            self._vmx_pairs.update(ethernet_adapter)\n\n            connection_type = \"ethernet{}.connectiontype\".format(adapter_number)\n            if not self._use_any_adapter and connection_type in self._vmx_pairs and self._vmx_pairs[connection_type] in (\"nat\", \"bridged\", \"hostonly\"):\n                continue\n\n            self._vmx_pairs[\"ethernet{}.connectiontype\".format(adapter_number)] = \"custom\"\n            # make sure we have a vmnet per adapter if we use uBridge\n            allocate_vmnet = False\n\n            # first check if a vmnet is already assigned to the adapter\n            vnet = \"ethernet{}.vnet\".format(adapter_number)\n            if vnet in self._vmx_pairs:\n                vmnet = os.path.basename(self._vmx_pairs[vnet])\n                if self.manager.is_managed_vmnet(vmnet) or vmnet in (\"vmnet0\", \"vmnet1\", \"vmnet8\"):\n                    # vmnet already managed, try to allocate a new one\n                    allocate_vmnet = True\n            else:\n                # otherwise allocate a new one\n                allocate_vmnet = True\n\n            if allocate_vmnet:\n                try:\n                    vmnet = self.manager.allocate_vmnet()\n                except BaseException:\n                    # clear everything up in case of error (e.g. no enough vmnets)\n                    self._vmnets.clear()\n                    raise\n\n            # mark the vmnet managed by us\n            if vmnet not in self._vmnets:\n                self._vmnets.append(vmnet)\n            self._vmx_pairs[\"ethernet{}.vnet\".format(adapter_number)] = vmnet\n\n        # disable remaining network adapters\n        for adapter_number in range(self._adapters, self._maximum_adapters):\n            if self._get_vmx_setting(\"ethernet{}.present\".format(adapter_number), \"TRUE\"):\n                log.debug(\"disabling remaining adapter {}\".format(adapter_number))\n                self._vmx_pairs[\"ethernet{}.startconnected\".format(adapter_number)] = \"FALSE\"", "response": "Set up VMware network options."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the vnet will use in ubridge", "response": "def _get_vnet(self, adapter_number):\n        \"\"\"\n        Return the vnet will use in ubridge\n        \"\"\"\n        vnet = \"ethernet{}.vnet\".format(adapter_number)\n        if vnet not in self._vmx_pairs:\n            raise VMwareError(\"vnet {} not in VMX file\".format(vnet))\n        return vnet"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a connection to uBridge.", "response": "def _add_ubridge_connection(self, nio, adapter_number):\n        \"\"\"\n        Creates a connection in uBridge.\n\n        :param nio: NIO instance\n        :param adapter_number: adapter number\n        \"\"\"\n\n        vnet = self._get_vnet(adapter_number)\n        yield from self._ubridge_send(\"bridge create {name}\".format(name=vnet))\n        vmnet_interface = os.path.basename(self._vmx_pairs[vnet])\n\n        if sys.platform.startswith(\"darwin\"):\n            # special case on OSX, we cannot bind VMnet interfaces using the libpcap\n            yield from self._ubridge_send('bridge add_nio_fusion_vmnet {name} \"{interface}\"'.format(name=vnet, interface=vmnet_interface))\n        else:\n            block_host_traffic = self.manager.config.get_section_config(\"VMware\").getboolean(\"block_host_traffic\", False)\n            yield from self._add_ubridge_ethernet_connection(vnet, vmnet_interface, block_host_traffic)\n\n        if isinstance(nio, NIOUDP):\n            yield from self._ubridge_send('bridge add_nio_udp {name} {lport} {rhost} {rport}'.format(name=vnet,\n                                                                                                     lport=nio.lport,\n                                                                                                     rhost=nio.rhost,\n                                                                                                     rport=nio.rport))\n\n        if nio.capturing:\n            yield from self._ubridge_send('bridge start_capture {name} \"{pcap_file}\"'.format(name=vnet, pcap_file=nio.pcap_output_file))\n\n        yield from self._ubridge_send('bridge start {name}'.format(name=vnet))\n        yield from self._ubridge_apply_filters(vnet, nio.filters)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates a connection in uBridge.", "response": "def _update_ubridge_connection(self, adapter_number, nio):\n        \"\"\"\n        Update a connection in uBridge.\n\n        :param nio: NIO instance\n        :param adapter_number: adapter number\n        \"\"\"\n        try:\n            bridge_name = self._get_vnet(adapter_number)\n        except VMwareError:\n            return  # vnet not yet available\n        yield from self._ubridge_apply_filters(bridge_name, nio.filters)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _delete_ubridge_connection(self, adapter_number):\n\n        vnet = \"ethernet{}.vnet\".format(adapter_number)\n        if vnet not in self._vmx_pairs:\n            raise VMwareError(\"vnet {} not in VMX file\".format(vnet))\n        yield from self._ubridge_send(\"bridge delete {name}\".format(name=vnet))", "response": "Deletes a connection in uBridge."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _start_ubridge_capture(self, adapter_number, output_file):\n\n        vnet = \"ethernet{}.vnet\".format(adapter_number)\n        if vnet not in self._vmx_pairs:\n            raise VMwareError(\"vnet {} not in VMX file\".format(vnet))\n        if not self._ubridge_hypervisor:\n            raise VMwareError(\"Cannot start the packet capture: uBridge is not running\")\n        yield from self._ubridge_send('bridge start_capture {name} \"{output_file}\"'.format(name=vnet,\n                                                                                           output_file=output_file))", "response": "Start a packet capture in uBridge."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _stop_ubridge_capture(self, adapter_number):\n\n        vnet = \"ethernet{}.vnet\".format(adapter_number)\n        if vnet not in self._vmx_pairs:\n            raise VMwareError(\"vnet {} not in VMX file\".format(vnet))\n        if not self._ubridge_hypervisor:\n            raise VMwareError(\"Cannot stop the packet capture: uBridge is not running\")\n        yield from self._ubridge_send(\"bridge stop_capture {name}\".format(name=vnet))", "response": "Stops a packet capture in uBridge."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nstart this VMware VM.", "response": "def start(self):\n        \"\"\"\n        Starts this VMware VM.\n        \"\"\"\n\n        if self.status == \"started\":\n            return\n\n        if (yield from self.is_running()):\n            raise VMwareError(\"The VM is already running in VMware\")\n\n        ubridge_path = self.ubridge_path\n        if not ubridge_path or not os.path.isfile(ubridge_path):\n            raise VMwareError(\"ubridge is necessary to start a VMware VM\")\n\n        yield from self._start_ubridge()\n        self._read_vmx_file()\n        # check if there is enough RAM to run\n        if \"memsize\" in self._vmx_pairs:\n            self.check_available_ram(int(self._vmx_pairs[\"memsize\"]))\n        self._set_network_options()\n        self._set_serial_console()\n        self._write_vmx_file()\n\n        if self._headless:\n            yield from self._control_vm(\"start\", \"nogui\")\n        else:\n            yield from self._control_vm(\"start\")\n\n        try:\n            if self._ubridge_hypervisor:\n                for adapter_number in range(0, self._adapters):\n                    nio = self._ethernet_adapters[adapter_number].get_nio(0)\n                    if nio:\n                        yield from self._add_ubridge_connection(nio, adapter_number)\n\n            yield from self._start_console()\n        except VMwareError:\n            yield from self.stop()\n            raise\n\n        if self._get_vmx_setting(\"vhv.enable\", \"TRUE\"):\n            self._hw_virtualization = True\n\n        self._started = True\n        self.status = \"started\"\n        log.info(\"VMware VM '{name}' [{id}] started\".format(name=self.name, id=self.id))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstopping this VMware VM.", "response": "def stop(self):\n        \"\"\"\n        Stops this VMware VM.\n        \"\"\"\n\n        self._hw_virtualization = False\n        yield from self._stop_remote_console()\n        yield from self._stop_ubridge()\n\n        try:\n            if (yield from self.is_running()):\n                if self.acpi_shutdown:\n                    # use ACPI to shutdown the VM\n                    yield from self._control_vm(\"stop\", \"soft\")\n                else:\n                    yield from self._control_vm(\"stop\")\n        finally:\n            self._started = False\n            self.status = \"stopped\"\n\n            self._read_vmx_file()\n            self._vmnets.clear()\n            # remove the adapters managed by GNS3\n            for adapter_number in range(0, self._adapters):\n                vnet = \"ethernet{}.vnet\".format(adapter_number)\n                if self._get_vmx_setting(vnet) or self._get_vmx_setting(\"ethernet{}.connectiontype\".format(adapter_number)) is None:\n                    if vnet in self._vmx_pairs:\n                        vmnet = os.path.basename(self._vmx_pairs[vnet])\n                        if not self.manager.is_managed_vmnet(vmnet):\n                            continue\n                    log.debug(\"removing adapter {}\".format(adapter_number))\n                    self._vmx_pairs[vnet] = \"vmnet1\"\n                    self._vmx_pairs[\"ethernet{}.connectiontype\".format(adapter_number)] = \"custom\"\n\n            # re-enable any remaining network adapters\n            for adapter_number in range(self._adapters, self._maximum_adapters):\n                if self._get_vmx_setting(\"ethernet{}.present\".format(adapter_number), \"TRUE\"):\n                    log.debug(\"enabling remaining adapter {}\".format(adapter_number))\n                    self._vmx_pairs[\"ethernet{}.startconnected\".format(adapter_number)] = \"TRUE\"\n            self._write_vmx_file()\n\n        yield from super().stop()\n        log.info(\"VMware VM '{name}' [{id}] stopped\".format(name=self.name, id=self.id))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsuspends this VMware VM.", "response": "def suspend(self):\n        \"\"\"\n        Suspends this VMware VM.\n        \"\"\"\n\n        if self.manager.host_type != \"ws\":\n            raise VMwareError(\"Pausing a VM is only supported by VMware Workstation\")\n        yield from self._control_vm(\"pause\")\n        self.status = \"suspended\"\n        log.info(\"VMware VM '{name}' [{id}] paused\".format(name=self.name, id=self.id))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef close(self):\n\n        if not (yield from super().close()):\n            return False\n\n        for adapter in self._ethernet_adapters.values():\n            if adapter is not None:\n                for nio in adapter.ports.values():\n                    if nio and isinstance(nio, NIOUDP):\n                        self.manager.port_manager.release_udp_port(nio.lport, self._project)\n        try:\n            self.acpi_shutdown = False\n            yield from self.stop()\n        except VMwareError:\n            pass\n\n        if self.linked_clone:\n            yield from self.manager.remove_from_vmware_inventory(self._vmx_path)", "response": "Closes this VMware VM."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef headless(self, headless):\n\n        if headless:\n            log.info(\"VMware VM '{name}' [{id}] has enabled the headless mode\".format(name=self.name, id=self.id))\n        else:\n            log.info(\"VMware VM '{name}' [{id}] has disabled the headless mode\".format(name=self.name, id=self.id))\n        self._headless = headless", "response": "Sets either the VM will start in headless mode or disabled."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the path to the vmx file.", "response": "def vmx_path(self, vmx_path):\n        \"\"\"\n        Sets the path to the vmx file.\n\n        :param vmx_path: VMware vmx file\n        \"\"\"\n\n        log.info(\"VMware VM '{name}' [{id}] has set the vmx file path to '{vmx}'\".format(name=self.name, id=self.id, vmx=vmx_path))\n        self._vmx_path = vmx_path"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef adapters(self, adapters):\n\n        # VMware VMs are limited to 10 adapters\n        if adapters > 10:\n            raise VMwareError(\"Number of adapters above the maximum supported of 10\")\n\n        self._ethernet_adapters.clear()\n        for adapter_number in range(0, adapters):\n            self._ethernet_adapters[adapter_number] = EthernetAdapter()\n\n        self._adapters = len(self._ethernet_adapters)\n        log.info(\"VMware VM '{name}' [{id}] has changed the number of Ethernet adapters to {adapters}\".format(name=self.name,\n                                                                                                              id=self.id,\n                                                                                                              adapters=adapters))", "response": "Sets the number of Ethernet adapters for this VMware VM instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the adapter type for this VMware VM instance.", "response": "def adapter_type(self, adapter_type):\n        \"\"\"\n        Sets the adapter type for this VMware VM instance.\n\n        :param adapter_type: adapter type (string)\n        \"\"\"\n\n        self._adapter_type = adapter_type\n        log.info(\"VMware VM '{name}' [{id}]: adapter type changed to {adapter_type}\".format(name=self.name,\n                                                                                            id=self.id,\n                                                                                            adapter_type=adapter_type))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset whether or not the VM is allowed to use any VMware adapter on this instance.", "response": "def use_any_adapter(self, use_any_adapter):\n        \"\"\"\n        Allows GNS3 to use any VMware adapter on this instance.\n\n        :param use_any_adapter: boolean\n        \"\"\"\n\n        if use_any_adapter:\n            log.info(\"VMware VM '{name}' [{id}] is allowed to use any adapter\".format(name=self.name, id=self.id))\n        else:\n            log.info(\"VMware VM '{name}' [{id}] is not allowed to use any adapter\".format(name=self.name, id=self.id))\n        self._use_any_adapter = use_any_adapter"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef adapter_add_nio_binding(self, adapter_number, nio):\n\n        try:\n            adapter = self._ethernet_adapters[adapter_number]\n        except IndexError:\n            raise VMwareError(\"Adapter {adapter_number} doesn't exist on VMware VM '{name}'\".format(name=self.name,\n                                                                                                    adapter_number=adapter_number))\n\n        self._read_vmx_file()\n        # check if trying to connect to a nat, bridged or host-only adapter\n        if self._get_vmx_setting(\"ethernet{}.present\".format(adapter_number), \"TRUE\"):\n            # check for the connection type\n            connection_type = \"ethernet{}.connectiontype\".format(adapter_number)\n            if connection_type in self._vmx_pairs and self._vmx_pairs[connection_type] in (\"nat\", \"bridged\", \"hostonly\"):\n                if not self._use_any_adapter:\n                    raise VMwareError(\"Attachment '{attachment}' is already configured on network adapter {adapter_number}. \"\n                                      \"Please remove it or allow VMware VM '{name}' to use any adapter.\".format(attachment=self._vmx_pairs[connection_type],\n                                                                                                                adapter_number=adapter_number,\n                                                                                                                name=self.name))\n                elif (yield from self.is_running()):\n                    raise VMwareError(\"Attachment '{attachment}' is configured on network adapter {adapter_number}. \"\n                                      \"Please stop VMware VM '{name}' to link to this adapter and allow GNS3 to change the attachment type.\".format(attachment=self._vmx_pairs[connection_type],\n                                                                                                                                                    adapter_number=adapter_number,\n                                                                                                                                                    name=self.name))\n\n        adapter.add_nio(0, nio)\n        if self._started and self._ubridge_hypervisor:\n            yield from self._add_ubridge_connection(nio, adapter_number)\n\n        log.info(\"VMware VM '{name}' [{id}]: {nio} added to adapter {adapter_number}\".format(name=self.name,\n                                                                                             id=self.id,\n                                                                                             nio=nio,\n                                                                                             adapter_number=adapter_number))", "response": "Adds a NIO binding to an adapter."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef adapter_update_nio_binding(self, adapter_number, nio):\n\n        if self._ubridge_hypervisor:\n            try:\n                yield from self._update_ubridge_connection(adapter_number, nio)\n            except IndexError:\n                raise VMwareError('Adapter {adapter_number} does not exist on VMware VM \"{name}\"'.format(\n                    name=self._name,\n                    adapter_number=adapter_number\n                ))", "response": "Updates a port NIO binding."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef adapter_remove_nio_binding(self, adapter_number):\n\n        try:\n            adapter = self._ethernet_adapters[adapter_number]\n        except IndexError:\n            raise VMwareError(\"Adapter {adapter_number} doesn't exist on VMware VM '{name}'\".format(name=self.name,\n                                                                                                    adapter_number=adapter_number))\n\n        nio = adapter.get_nio(0)\n        if isinstance(nio, NIOUDP):\n            self.manager.port_manager.release_udp_port(nio.lport, self._project)\n        adapter.remove_nio(0)\n        if self._started and self._ubridge_hypervisor:\n            yield from self._delete_ubridge_connection(adapter_number)\n\n        log.info(\"VMware VM '{name}' [{id}]: {nio} removed from adapter {adapter_number}\".format(name=self.name,\n                                                                                                 id=self.id,\n                                                                                                 nio=nio,\n                                                                                                 adapter_number=adapter_number))\n\n        return nio", "response": "Removes an adapter NIO binding."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_pipe_name(self):\n\n        if sys.platform.startswith(\"win\"):\n            pipe_name = r\"\\\\.\\pipe\\gns3_vmware\\{}\".format(self.id)\n        else:\n            pipe_name = os.path.join(tempfile.gettempdir(), \"gns3_vmware\", \"{}\".format(self.id))\n            try:\n                os.makedirs(os.path.dirname(pipe_name), exist_ok=True)\n            except OSError as e:\n                raise VMwareError(\"Could not create the VMware pipe directory: {}\".format(e))\n        return pipe_name", "response": "Returns the pipe name to create a serial connection."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _set_serial_console(self):\n\n        pipe_name = self._get_pipe_name()\n        serial_port = {\"serial0.present\": \"TRUE\",\n                       \"serial0.filetype\": \"pipe\",\n                       \"serial0.filename\": pipe_name,\n                       \"serial0.pipe.endpoint\": \"server\",\n                       \"serial0.startconnected\": \"TRUE\"}\n        self._vmx_pairs.update(serial_port)", "response": "Sets the serial console connection for this VMX."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstarts remote console support for this VM.", "response": "def _start_console(self):\n        \"\"\"\n        Starts remote console support for this VM.\n        \"\"\"\n        self._remote_pipe = yield from asyncio_open_serial(self._get_pipe_name())\n        server = AsyncioTelnetServer(reader=self._remote_pipe,\n                                     writer=self._remote_pipe,\n                                     binary=True,\n                                     echo=True)\n        self._telnet_server = yield from asyncio.start_server(server.run, self._manager.port_manager.console_host, self.console)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstops remote console support for this VM.", "response": "def _stop_remote_console(self):\n        \"\"\"\n        Stops remote console support for this VM.\n        \"\"\"\n        if self._telnet_server:\n            self._telnet_server.close()\n            yield from self._telnet_server.wait_closed()\n            self._remote_pipe.close()\n            self._telnet_server = None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef start_capture(self, adapter_number, output_file):\n\n        try:\n            adapter = self._ethernet_adapters[adapter_number]\n        except KeyError:\n            raise VMwareError(\"Adapter {adapter_number} doesn't exist on VMware VM '{name}'\".format(name=self.name,\n                                                                                                    adapter_number=adapter_number))\n\n        nio = adapter.get_nio(0)\n\n        if not nio:\n            raise VMwareError(\"Adapter {} is not connected\".format(adapter_number))\n\n        if nio.capturing:\n            raise VMwareError(\"Packet capture is already activated on adapter {adapter_number}\".format(adapter_number=adapter_number))\n\n        nio.startPacketCapture(output_file)\n\n        if self._started:\n            yield from self._start_ubridge_capture(adapter_number, output_file)\n\n        log.info(\"VMware VM '{name}' [{id}]: starting packet capture on adapter {adapter_number}\".format(name=self.name,\n                                                                                                         id=self.id,\n                                                                                                         adapter_number=adapter_number))", "response": "Starts a packet capture on the specified adapter."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nstopping a packet capture on the specified adapter.", "response": "def stop_capture(self, adapter_number):\n        \"\"\"\n        Stops a packet capture.\n\n        :param adapter_number: adapter number\n        \"\"\"\n\n        try:\n            adapter = self._ethernet_adapters[adapter_number]\n        except KeyError:\n            raise VMwareError(\"Adapter {adapter_number} doesn't exist on VMware VM '{name}'\".format(name=self.name,\n                                                                                                    adapter_number=adapter_number))\n\n        nio = adapter.get_nio(0)\n\n        if not nio:\n            raise VMwareError(\"Adapter {} is not connected\".format(adapter_number))\n\n        nio.stopPacketCapture()\n\n        if self._started:\n            yield from self._stop_ubridge_capture(adapter_number)\n\n        log.info(\"VMware VM '{name}' [{id}]: stopping packet capture on adapter {adapter_number}\".format(name=self.name,\n                                                                                                         id=self.id,\n                                                                                                         adapter_number=adapter_number))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_default_project_directory():\n\n    server_config = Config.instance().get_section_config(\"Server\")\n    path = os.path.expanduser(server_config.get(\"projects_path\", \"~/GNS3/projects\"))\n    path = os.path.normpath(path)\n    try:\n        os.makedirs(path, exist_ok=True)\n    except OSError as e:\n        raise aiohttp.web.HTTPInternalServerError(text=\"Could not create project directory: {}\".format(e))\n    return path", "response": "Return the default project directory depending of the operating system"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef check_path_allowed(path):\n\n    config = Config.instance().get_section_config(\"Server\")\n\n    project_directory = get_default_project_directory()\n    if len(os.path.commonprefix([project_directory, path])) == len(project_directory):\n        return\n\n    if \"local\" in config and config.getboolean(\"local\") is False:\n        raise aiohttp.web.HTTPForbidden(text=\"The path is not allowed\")", "response": "Check if the path is allowed in the project directories"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ports_mapping(self, ports):\n        if ports != self._ports:\n            if len(self._mappings) > 0:\n                raise NodeError(\"Can't modify a hub already connected.\")\n\n            port_number = 0\n            for port in ports:\n                port[\"name\"] = \"Ethernet{}\".format(port_number)\n                port[\"port_number\"] = port_number\n                port_number += 1\n\n            self._ports = ports", "response": "Set the ports on this hub."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_nio(self, nio, port_number):\n\n        if port_number not in [port[\"port_number\"] for port in self._ports]:\n            raise DynamipsError(\"Port {} doesn't exist\".format(port_number))\n\n        if port_number in self._mappings:\n            raise DynamipsError(\"Port {} isn't free\".format(port_number))\n\n        yield from Bridge.add_nio(self, nio)\n\n        log.info('Ethernet hub \"{name}\" [{id}]: NIO {nio} bound to port {port}'.format(name=self._name,\n                                                                                       id=self._id,\n                                                                                       nio=nio,\n                                                                                       port=port_number))\n        self._mappings[port_number] = nio", "response": "Adds a NIO as new port on this hub."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef remove_nio(self, port_number):\n\n        if port_number not in self._mappings:\n            raise DynamipsError(\"Port {} is not allocated\".format(port_number))\n\n        nio = self._mappings[port_number]\n        if isinstance(nio, NIOUDP):\n            self.manager.port_manager.release_udp_port(nio.lport, self._project)\n        yield from Bridge.remove_nio(self, nio)\n\n        log.info('Ethernet hub \"{name}\" [{id}]: NIO {nio} removed from port {port}'.format(name=self._name,\n                                                                                           id=self._id,\n                                                                                           nio=nio,\n                                                                                           port=port_number))\n\n        del self._mappings[port_number]\n        return nio", "response": "Removes the specified NIO as member of this hub."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nstarting a packet capture.", "response": "def start_capture(self, port_number, output_file, data_link_type=\"DLT_EN10MB\"):\n        \"\"\"\n        Starts a packet capture.\n\n        :param port_number: allocated port number\n        :param output_file: PCAP destination file for the capture\n        :param data_link_type: PCAP data link type (DLT_*), default is DLT_EN10MB\n        \"\"\"\n\n        if port_number not in self._mappings:\n            raise DynamipsError(\"Port {} is not allocated\".format(port_number))\n\n        nio = self._mappings[port_number]\n\n        data_link_type = data_link_type.lower()\n        if data_link_type.startswith(\"dlt_\"):\n            data_link_type = data_link_type[4:]\n\n        if nio.input_filter[0] is not None and nio.output_filter[0] is not None:\n            raise DynamipsError(\"Port {} has already a filter applied\".format(port_number))\n\n        yield from nio.bind_filter(\"both\", \"capture\")\n        yield from nio.setup_filter(\"both\", '{} \"{}\"'.format(data_link_type, output_file))\n\n        log.info('Ethernet hub \"{name}\" [{id}]: starting packet capture on port {port}'.format(name=self._name,\n                                                                                               id=self._id,\n                                                                                               port=port_number))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef stop_capture(self, port_number):\n\n        if port_number not in self._mappings:\n            raise DynamipsError(\"Port {} is not allocated\".format(port_number))\n\n        nio = self._mappings[port_number]\n        yield from nio.unbind_filter(\"both\")\n        log.info('Ethernet hub \"{name}\" [{id}]: stopping packet capture on port {port}'.format(name=self._name,\n                                                                                               id=self._id,\n                                                                                               port=port_number))", "response": "Stops a packet capture."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef port_manager(self):\n        if self._port_manager is None:\n            self._port_manager = PortManager.instance()\n        return self._port_manager", "response": "Returns the port manager."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_node(self, node_id, project_id=None):\n\n        if project_id:\n            # check the project_id exists\n            project = ProjectManager.instance().get_project(project_id)\n\n        try:\n            UUID(node_id, version=4)\n        except ValueError:\n            raise aiohttp.web.HTTPBadRequest(text=\"Node ID {} is not a valid UUID\".format(node_id))\n\n        if node_id not in self._nodes:\n            raise aiohttp.web.HTTPNotFound(text=\"Node ID {} doesn't exist\".format(node_id))\n\n        node = self._nodes[node_id]\n        if project_id:\n            if node.project.id != project.id:\n                raise aiohttp.web.HTTPNotFound(text=\"Project ID {} doesn't belong to node {}\".format(project_id, node.name))\n\n        return node", "response": "Returns a Node instance."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef convert_old_project(self, project, legacy_id, name):\n\n        new_id = str(uuid4())\n        legacy_project_files_path = os.path.join(project.path, \"{}-files\".format(project.name))\n        new_project_files_path = os.path.join(project.path, \"project-files\")\n        if os.path.exists(legacy_project_files_path) and not os.path.exists(new_project_files_path):\n            # move the project files\n            log.info(\"Converting old project...\")\n            try:\n                log.info('Moving \"{}\" to \"{}\"'.format(legacy_project_files_path, new_project_files_path))\n                yield from wait_run_in_executor(shutil.move, legacy_project_files_path, new_project_files_path)\n            except OSError as e:\n                raise aiohttp.web.HTTPInternalServerError(text=\"Could not move project files directory: {} to {} {}\".format(legacy_project_files_path,\n                                                                                                                            new_project_files_path, e))\n\n        if project.is_local() is False:\n            legacy_remote_project_path = os.path.join(project.location, project.name, self.module_name.lower())\n            new_remote_project_path = os.path.join(project.path, \"project-files\", self.module_name.lower())\n            if os.path.exists(legacy_remote_project_path) and not os.path.exists(new_remote_project_path):\n                # move the legacy remote project (remote servers only)\n                log.info(\"Converting old remote project...\")\n                try:\n                    log.info('Moving \"{}\" to \"{}\"'.format(legacy_remote_project_path, new_remote_project_path))\n                    yield from wait_run_in_executor(shutil.move, legacy_remote_project_path, new_remote_project_path)\n                except OSError as e:\n                    raise aiohttp.web.HTTPInternalServerError(text=\"Could not move directory: {} to {} {}\".format(legacy_remote_project_path,\n                                                                                                                  new_remote_project_path, e))\n\n        if hasattr(self, \"get_legacy_vm_workdir\"):\n            # rename old project node working dir\n            log.info(\"Converting old node working directory...\")\n            legacy_vm_dir = self.get_legacy_vm_workdir(legacy_id, name)\n            legacy_vm_working_path = os.path.join(new_project_files_path, legacy_vm_dir)\n            new_vm_working_path = os.path.join(new_project_files_path, self.module_name.lower(), new_id)\n            if os.path.exists(legacy_vm_working_path) and not os.path.exists(new_vm_working_path):\n                try:\n                    log.info('Moving \"{}\" to \"{}\"'.format(legacy_vm_working_path, new_vm_working_path))\n                    yield from wait_run_in_executor(shutil.move, legacy_vm_working_path, new_vm_working_path)\n                except OSError as e:\n                    raise aiohttp.web.HTTPInternalServerError(text=\"Could not move vm working directory: {} to {} {}\".format(legacy_vm_working_path,\n                                                                                                                             new_vm_working_path, e))\n\n        return new_id", "response": "Convert old project to new one."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_node(self, name, project_id, node_id, *args, **kwargs):\n\n        if node_id in self._nodes:\n            return self._nodes[node_id]\n\n        project = ProjectManager.instance().get_project(project_id)\n        if node_id and isinstance(node_id, int):\n            # old project\n            with (yield from BaseManager._convert_lock):\n                node_id = yield from self.convert_old_project(project, node_id, name)\n\n        if not node_id:\n            node_id = str(uuid4())\n\n        node = self._NODE_CLASS(name, node_id, project, self, *args, **kwargs)\n        if asyncio.iscoroutinefunction(node.create):\n            yield from node.create()\n        else:\n            node.create()\n        self._nodes[node.id] = node\n        project.add_node(node)\n        return node", "response": "Create a new node in the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef duplicate_node(self, source_node_id, destination_node_id):\n        source_node = self.get_node(source_node_id)\n        destination_node = self.get_node(destination_node_id)\n\n        # Some node don't have working dir like switch\n        if not hasattr(destination_node, \"working_dir\"):\n            return destination_node\n\n        destination_dir = destination_node.working_dir\n        try:\n            shutil.rmtree(destination_dir)\n            shutil.copytree(source_node.working_dir, destination_dir)\n        except OSError as e:\n            raise aiohttp.web.HTTPConflict(text=\"Can't duplicate node data: {}\".format(e))\n\n        # We force a refresh of the name. This force the rewrite\n        # of some configuration files\n        node_name = destination_node.name\n        destination_node.name = node_name + str(uuid4())\n        destination_node.name = node_name\n\n        return destination_node", "response": "Duplicate a node instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef close_node(self, node_id):\n\n        node = self.get_node(node_id)\n        if asyncio.iscoroutinefunction(node.close):\n            yield from node.close()\n        else:\n            node.close()\n        return node", "response": "Closes a node with the given identifier."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef project_closed(self, project):\n\n        for node in project.nodes:\n            if node.id in self._nodes:\n                del self._nodes[node.id]", "response": "Called when a project is closed."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndeleting a node. The node working directory will be destroyed when a commit is received. :param node_id: Node identifier :returns: Node instance", "response": "def delete_node(self, node_id):\n        \"\"\"\n        Delete a node. The node working directory will be destroyed when a commit is received.\n\n        :param node_id: Node identifier\n        :returns: Node instance\n        \"\"\"\n\n        node = None\n        try:\n            node = self.get_node(node_id)\n            yield from self.close_node(node_id)\n        finally:\n            if node:\n                node.project.emit(\"node.deleted\", node)\n                yield from node.project.remove_node(node)\n        if node.id in self._nodes:\n            del self._nodes[node.id]\n        return node"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef has_privileged_access(executable):\n\n        if sys.platform.startswith(\"win\"):\n            # do not check anything on Windows\n            return True\n\n        if sys.platform.startswith(\"darwin\"):\n            if os.stat(executable).st_uid == 0:\n                return True\n\n        if os.geteuid() == 0:\n            # we are root, so we should have privileged access.\n            return True\n\n        if os.stat(executable).st_uid == 0 and (os.stat(executable).st_mode & stat.S_ISUID or os.stat(executable).st_mode & stat.S_ISGID):\n            # the executable has set UID bit.\n            return True\n\n        # test if the executable has the CAP_NET_RAW capability (Linux only)\n        try:\n            if sys.platform.startswith(\"linux\") and \"security.capability\" in os.listxattr(executable):\n                caps = os.getxattr(executable, \"security.capability\")\n                # test the 2nd byte and check if the 13th bit (CAP_NET_RAW) is set\n                if struct.unpack(\"<IIIII\", caps)[1] & 1 << 13:\n                    return True\n        except (AttributeError, OSError) as e:\n            log.error(\"could not determine if CAP_NET_RAW capability is set for {}: {}\".format(executable, e))\n\n        return False", "response": "Check if an executable has the right to attach to Ethernet and TAP adapters."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new NIO object based on the NIO settings.", "response": "def create_nio(self, nio_settings):\n        \"\"\"\n        Creates a new NIO.\n\n        :param nio_settings: information to create the NIO\n\n        :returns: a NIO object\n        \"\"\"\n\n        nio = None\n        if nio_settings[\"type\"] == \"nio_udp\":\n            lport = nio_settings[\"lport\"]\n            rhost = nio_settings[\"rhost\"]\n            rport = nio_settings[\"rport\"]\n            try:\n                info = socket.getaddrinfo(rhost, rport, socket.AF_UNSPEC, socket.SOCK_DGRAM, 0, socket.AI_PASSIVE)\n                if not info:\n                    raise aiohttp.web.HTTPInternalServerError(text=\"getaddrinfo returns an empty list on {}:{}\".format(rhost, rport))\n                for res in info:\n                    af, socktype, proto, _, sa = res\n                    with socket.socket(af, socktype, proto) as sock:\n                        sock.connect(sa)\n            except OSError as e:\n                raise aiohttp.web.HTTPInternalServerError(text=\"Could not create an UDP connection to {}:{}: {}\".format(rhost, rport, e))\n            filters = nio_settings.get(\"filters\", {})\n            nio = NIOUDP(lport, rhost, rport, filters)\n        elif nio_settings[\"type\"] == \"nio_tap\":\n            tap_device = nio_settings[\"tap_device\"]\n            # if not is_interface_up(tap_device):\n            #    raise aiohttp.web.HTTPConflict(text=\"TAP interface {} does not exist or is down\".format(tap_device))\n            # FIXME: check for permissions on tap device\n            # if not self.has_privileged_access(executable):\n            #    raise aiohttp.web.HTTPForbidden(text=\"{} has no privileged access to {}.\".format(executable, tap_device))\n            nio = NIOTAP(tap_device)\n        elif nio_settings[\"type\"] in (\"nio_generic_ethernet\", \"nio_ethernet\"):\n            ethernet_device = nio_settings[\"ethernet_device\"]\n            if not is_interface_up(ethernet_device):\n                raise aiohttp.web.HTTPConflict(text=\"Ethernet interface {} does not exist or is down\".format(ethernet_device))\n            nio = NIOEthernet(ethernet_device)\n        assert nio is not None\n        return nio"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_abs_image_path(self, path):\n\n        if not path:\n            return \"\"\n        orig_path = path\n\n        server_config = self.config.get_section_config(\"Server\")\n        img_directory = self.get_images_directory()\n\n        # Windows path should not be send to a unix server\n        if not sys.platform.startswith(\"win\"):\n            if re.match(r\"^[A-Z]:\", path) is not None:\n                raise NodeError(\"{} is not allowed on this remote server. Please use only a filename in {}.\".format(path, img_directory))\n\n        if not os.path.isabs(path):\n            for directory in images_directories(self._NODE_TYPE):\n                path = self._recursive_search_file_in_directory(directory, orig_path)\n                if path:\n                    return force_unix_path(path)\n\n            # Not found we try the default directory\n            s = os.path.split(orig_path)\n            path = force_unix_path(os.path.join(img_directory, *s))\n            if os.path.exists(path):\n                return path\n            raise ImageMissingError(orig_path)\n\n        # For non local server we disallow using absolute path outside image directory\n        if server_config.getboolean(\"local\", False) is True:\n            path = force_unix_path(path)\n            if os.path.exists(path):\n                return path\n            raise ImageMissingError(orig_path)\n\n        path = force_unix_path(path)\n        for directory in images_directories(self._NODE_TYPE):\n            if os.path.commonprefix([directory, path]) == directory:\n                if os.path.exists(path):\n                    return path\n                raise ImageMissingError(orig_path)\n        raise NodeError(\"{} is not allowed on this remote server. Please use only a filename in {}.\".format(path, img_directory))", "response": "Get the absolute path of an image."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsearching for a file in directory and is subdirectories :returns: Path or None if not found", "response": "def _recursive_search_file_in_directory(self, directory, searched_file):\n        \"\"\"\n        Search for a file in directory and is subdirectories\n\n        :returns: Path or None if not found\n        \"\"\"\n        s = os.path.split(searched_file)\n\n        for root, dirs, files in os.walk(directory):\n            for file in files:\n                # If filename is the same\n                if s[1] == file and (s[0] == '' or s[0] == os.path.basename(root)):\n                    path = os.path.normpath(os.path.join(root, s[1]))\n                    if os.path.exists(path):\n                        return path\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting a path relative to images directory path", "response": "def get_relative_image_path(self, path):\n        \"\"\"\n        Get a path relative to images directory path\n        or an abspath if the path is not located inside\n        image directory\n\n        :param path: file path\n        :return: file path\n        \"\"\"\n\n        if not path:\n            return \"\"\n        path = force_unix_path(self.get_abs_image_path(path))\n\n        img_directory = self.get_images_directory()\n\n        for directory in images_directories(self._NODE_TYPE):\n            if os.path.commonprefix([directory, path]) == directory:\n                relpath = os.path.relpath(path, directory)\n                # We don't allow to recurse search from the top image directory just for image type directory (compatibility with old releases)\n                if os.sep not in relpath or directory == img_directory:\n                    return relpath\n        return path"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list_images(self):\n\n        try:\n            return list_images(self._NODE_TYPE)\n        except OSError as e:\n            raise aiohttp.web.HTTPConflict(text=\"Can not list images {}\".format(e))", "response": "Returns the list of available images for this node type"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nstarts the Dynamips hypervisor process.", "response": "def start(self):\n        \"\"\"\n        Starts the Dynamips hypervisor process.\n        \"\"\"\n\n        self._command = self._build_command()\n        env = os.environ.copy()\n        if sys.platform.startswith(\"win\"):\n            # add the Npcap directory to $PATH to force Dynamips to use npcap DLL instead of Winpcap (if installed)\n            system_root = os.path.join(os.path.expandvars(\"%SystemRoot%\"), \"System32\", \"Npcap\")\n            if os.path.isdir(system_root):\n                env[\"PATH\"] = system_root + ';' + env[\"PATH\"]\n        try:\n            log.info(\"Starting Dynamips: {}\".format(self._command))\n            self._stdout_file = os.path.join(self.working_dir, \"dynamips_i{}_stdout.txt\".format(self._id))\n            log.info(\"Dynamips process logging to {}\".format(self._stdout_file))\n            with open(self._stdout_file, \"w\", encoding=\"utf-8\") as fd:\n                self._process = yield from asyncio.create_subprocess_exec(*self._command,\n                                                                          stdout=fd,\n                                                                          stderr=subprocess.STDOUT,\n                                                                          cwd=self._working_dir,\n                                                                          env=env)\n            log.info(\"Dynamips process started PID={}\".format(self._process.pid))\n            self._started = True\n        except (OSError, subprocess.SubprocessError) as e:\n            log.error(\"Could not start Dynamips: {}\".format(e))\n            raise DynamipsError(\"Could not start Dynamips: {}\".format(e))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef stop(self):\n\n        if self.is_running():\n            log.info(\"Stopping Dynamips process PID={}\".format(self._process.pid))\n            yield from DynamipsHypervisor.stop(self)\n            # give some time for the hypervisor to properly stop.\n            # time to delete UNIX NIOs for instance.\n            yield from asyncio.sleep(0.01)\n            try:\n                yield from wait_for_process_termination(self._process, timeout=3)\n            except asyncio.TimeoutError:\n                if self._process.returncode is None:\n                    log.warn(\"Dynamips process {} is still running... killing it\".format(self._process.pid))\n                    try:\n                        self._process.kill()\n                    except OSError as e:\n                        log.error(\"Cannot stop the Dynamips process: {}\".format(e))\n                    if self._process.returncode is None:\n                        log.warn('Dynamips hypervisor with PID={} is still running'.format(self._process.pid))\n\n        if self._stdout_file and os.access(self._stdout_file, os.W_OK):\n            try:\n                os.remove(self._stdout_file)\n            except OSError as e:\n                log.warning(\"could not delete temporary Dynamips log file: {}\".format(e))\n        self._started = False", "response": "Stops the Dynamips process."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads the standard output of the Dynamips process. Only use when the process has stopped or crashed.", "response": "def read_stdout(self):\n        \"\"\"\n        Reads the standard output of the Dynamips process.\n        Only use when the process has been stopped or has crashed.\n        \"\"\"\n\n        output = \"\"\n        if self._stdout_file and os.access(self._stdout_file, os.R_OK):\n            try:\n                with open(self._stdout_file, \"rb\") as file:\n                    output = file.read().decode(\"utf-8\", errors=\"replace\")\n            except OSError as e:\n                log.warn(\"could not read {}: {}\".format(self._stdout_file, e))\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _build_command(self):\n\n        command = [self._path]\n        command.extend([\"-N1\"])  # use instance IDs for filenames\n        command.extend([\"-l\", \"dynamips_i{}_log.txt\".format(self._id)])  # log file\n        # Dynamips cannot listen for hypervisor commands and for console connections on\n        # 2 different IP addresses.\n        # See https://github.com/GNS3/dynamips/issues/62\n        if self._console_host != \"0.0.0.0\" and self._console_host != \"::\":\n            command.extend([\"-H\", \"{}:{}\".format(self._host, self._port)])\n        else:\n            command.extend([\"-H\", str(self._port)])\n        return command", "response": "Build the command to start the Dynamips hypervisor process."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninstalls a WIC on this adapter.", "response": "def install_wic(self, wic_slot_id, wic):\n        \"\"\"\n        Installs a WIC on this adapter.\n\n        :param wic_slot_id: WIC slot ID (integer)\n        :param wic: WIC instance\n        \"\"\"\n\n        self._wics[wic_slot_id] = wic\n\n        # Dynamips WICs ports start on a multiple of 16 + port number\n        # WIC1 port 1 = 16, WIC1 port 2 = 17\n        # WIC2 port 1 = 32, WIC2 port 2 = 33\n        # WIC3 port 1 = 48, WIC3 port 2 = 49\n        base = 16 * (wic_slot_id + 1)\n        for wic_port in range(0, wic.interfaces):\n            port_number = base + wic_port\n            self._ports[port_number] = None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update_filters(self, filters):\n        new_filters = {}\n        for (filter, values) in filters.items():\n            new_values = []\n            for value in values:\n                if isinstance(value, str):\n                    new_values.append(value.strip(\"\\n \"))\n                else:\n                    new_values.append(int(value))\n            values = new_values\n            if len(values) != 0 and values[0] != 0 and values[0] != '':\n                new_filters[filter] = values\n\n        if new_filters != self.filters:\n            self._filters = new_filters\n            if self._created:\n                yield from self.update()\n                self._project.controller.notification.emit(\"link.updated\", self.__json__())\n                self._project.dump()", "response": "Modify the filters list."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_node(self, node, adapter_number, port_number, label=None, dump=True):\n\n        port = node.get_port(adapter_number, port_number)\n        if port is None:\n            raise aiohttp.web.HTTPNotFound(text=\"Port {}/{} for {} not found\".format(adapter_number, port_number, node.name))\n        if port.link is not None:\n            raise aiohttp.web.HTTPConflict(text=\"Port is already used\")\n\n        self._link_type = port.link_type\n\n        for other_node in self._nodes:\n            if other_node[\"node\"] == node:\n                raise aiohttp.web.HTTPConflict(text=\"Cannot connect to itself\")\n\n            if node.node_type in [\"nat\", \"cloud\"]:\n                if other_node[\"node\"].node_type in [\"nat\", \"cloud\"]:\n                    raise aiohttp.web.HTTPConflict(text=\"It's not allowed to connect a {} to a {}\".format(other_node[\"node\"].node_type, node.node_type))\n\n            # Check if user is not connecting serial => ethernet\n            other_port = other_node[\"node\"].get_port(other_node[\"adapter_number\"], other_node[\"port_number\"])\n            if other_port is None:\n                raise aiohttp.web.HTTPNotFound(text=\"Port {}/{} for {} not found\".format(other_node[\"adapter_number\"], other_node[\"port_number\"], other_node[\"node\"].name))\n            if port.link_type != other_port.link_type:\n                raise aiohttp.web.HTTPConflict(text=\"It's not allowed to connect a {} to a {}\".format(other_port.link_type, port.link_type))\n\n        if label is None:\n            label = {\n                \"x\": -10,\n                \"y\": -10,\n                \"rotation\": 0,\n                \"text\": html.escape(\"{}/{}\".format(adapter_number, port_number)),\n                \"style\": \"font-size: 10; font-style: Verdana\"\n            }\n\n        self._nodes.append({\n            \"node\": node,\n            \"adapter_number\": adapter_number,\n            \"port_number\": port_number,\n            \"port\": port,\n            \"label\": label\n        })\n\n        if len(self._nodes) == 2:\n            yield from self.create()\n            for n in self._nodes:\n                n[\"node\"].add_link(self)\n                n[\"port\"].link = self\n            self._created = True\n            self._project.controller.notification.emit(\"link.created\", self.__json__())\n\n        if dump:\n            self._project.dump()", "response": "Adds a node to the link."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef start_capture(self, data_link_type=\"DLT_EN10MB\", capture_file_name=None):\n\n        self._capturing = True\n        self._capture_file_name = capture_file_name\n        self._streaming_pcap = asyncio.async(self._start_streaming_pcap())\n        self._project.controller.notification.emit(\"link.updated\", self.__json__())", "response": "Start capture on the link."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstarts streaming a PCAP file.", "response": "def _start_streaming_pcap(self):\n        \"\"\"\n        Dump a pcap file on disk\n        \"\"\"\n\n        if os.path.exists(self.capture_file_path):\n            try:\n                os.remove(self.capture_file_path)\n            except OSError as e:\n                raise aiohttp.web.HTTPConflict(text=\"Could not delete old capture file '{}': {}\".format(self.capture_file_path, e))\n\n        try:\n            stream_content = yield from self.read_pcap_from_source()\n        except aiohttp.web.HTTPException as e:\n            error_msg = \"Could not stream PCAP file: error {}: {}\".format(e.status, e.text)\n            log.error(error_msg)\n            self._capturing = False\n            self._project.notification.emit(\"log.error\", {\"message\": error_msg})\n            self._project.controller.notification.emit(\"link.updated\", self.__json__())\n\n        with stream_content as stream:\n            try:\n                with open(self.capture_file_path, \"wb\") as f:\n                    while self._capturing:\n                        # We read 1 bytes by 1 otherwise the remaining data is not read if the traffic stops\n                        data = yield from stream.read(1)\n                        if data:\n                            f.write(data)\n                            # Flush to disk otherwise the live is not really live\n                            f.flush()\n                        else:\n                            break\n            except OSError as e:\n                raise aiohttp.web.HTTPConflict(text=\"Could not write capture file '{}': {}\".format(self.capture_file_path, e))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nstop capture on the link", "response": "def stop_capture(self):\n        \"\"\"\n        Stop capture on the link\n        \"\"\"\n\n        self._capturing = False\n        self._project.controller.notification.emit(\"link.updated\", self.__json__())"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef default_capture_file_name(self):\n\n        capture_file_name = \"{}_{}-{}_to_{}_{}-{}\".format(self._nodes[0][\"node\"].name,\n                                                          self._nodes[0][\"adapter_number\"],\n                                                          self._nodes[0][\"port_number\"],\n                                                          self._nodes[1][\"node\"].name,\n                                                          self._nodes[1][\"adapter_number\"],\n                                                          self._nodes[1][\"port_number\"])\n        return re.sub(\"[^0-9A-Za-z_-]\", \"\", capture_file_name) + \".pcap\"", "response": "Returns the default capture file name for a link."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef capture_file_path(self):\n\n        if self._capture_file_name:\n            return os.path.join(self._project.captures_directory, self._capture_file_name)\n        else:\n            return None", "response": "Get the path of the capture file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconnect to the Dynamips hypervisor.", "response": "def connect(self, timeout=10):\n        \"\"\"\n        Connects to the hypervisor.\n        \"\"\"\n\n        # connect to a local address by default\n        # if listening to all addresses (IPv4 or IPv6)\n        if self._host == \"0.0.0.0\":\n            host = \"127.0.0.1\"\n        elif self._host == \"::\":\n            host = \"::1\"\n        else:\n            host = self._host\n\n        begin = time.time()\n        connection_success = False\n        last_exception = None\n        while time.time() - begin < timeout:\n            yield from asyncio.sleep(0.01)\n            try:\n                self._reader, self._writer = yield from asyncio.wait_for(asyncio.open_connection(host, self._port), timeout=1)\n            except (asyncio.TimeoutError, OSError) as e:\n                last_exception = e\n                continue\n            connection_success = True\n            break\n\n        if not connection_success:\n            raise DynamipsError(\"Couldn't connect to hypervisor on {}:{} :{}\".format(host, self._port, last_exception))\n        else:\n            log.info(\"Connected to Dynamips hypervisor after {:.4f} seconds\".format(time.time() - begin))\n\n        try:\n            version = yield from self.send(\"hypervisor version\")\n            self._version = version[0].split(\"-\", 1)[0]\n        except IndexError:\n            self._version = \"Unknown\"\n\n        # this forces to send the working dir to Dynamips\n        yield from self.set_working_dir(self._working_dir)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_working_dir(self, working_dir):\n\n        # encase working_dir in quotes to protect spaces in the path\n        yield from self.send('hypervisor working_dir \"{}\"'.format(working_dir))\n        self._working_dir = working_dir\n        log.debug(\"Working directory set to {}\".format(self._working_dir))", "response": "Sets the working directory for this hypervisor."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_telnet_shell(shell, loop=None):\n\n    if loop is None:\n        loop = asyncio.get_event_loop()\n\n    def factory(reader, writer):\n        return ShellConnection(reader, writer, shell, loop)\n\n    return AsyncioTelnetServer(binary=True, echo=True, naws=True, connection_factory=factory)", "response": "Create a telnet frontend with a telnet frontend"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_stdin_shell(shell, loop=None):\n    @asyncio.coroutine\n    def feed_stdin(loop, reader, shell):\n        history = InMemoryHistory()\n        completer = WordCompleter([name for name, _ in shell.get_commands()], ignore_case=True)\n        while True:\n            line = yield from prompt(\n                \">\", patch_stdout=True, return_asyncio_coroutine=True, history=history, completer=completer)\n            line += '\\n'\n            reader.feed_data(line.encode())\n\n    @asyncio.coroutine\n    def read_stdout(writer):\n        while True:\n            c = yield from writer.read(1)\n            print(c.decode(), end='')\n            sys.stdout.flush()\n\n    reader = asyncio.StreamReader()\n    writer = asyncio.StreamReader()\n    shell.reader = reader\n    shell.writer = writer\n    if loop is None:\n        loop = asyncio.get_event_loop()\n\n    reader_task = loop.create_task(feed_stdin(loop, reader, shell))\n    writer_task = loop.create_task(read_stdout(writer))\n    shell_task = loop.create_task(shell.run())\n    return asyncio.gather(shell_task, writer_task, reader_task)", "response": "Run a shell application with a stdin frontend"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef help(self, *args):\n        res = ''\n        if len(args) == 0:\n            res = 'Help:\\n'\n        for name, value in inspect.getmembers(self):\n            if not inspect.isgeneratorfunction(value):\n                continue\n            if name.startswith('_') or (len(args) and name != args[0]) or name == 'run':\n                continue\n            doc = inspect.getdoc(value)\n            res += name\n            if len(args) and doc:\n                res += ': ' + doc\n            elif doc:\n                res += ': ' + doc.split('\\n')[0]\n            res += '\\n'\n        if len(args) == 0:\n            res += '\\nhelp command for details about a command\\n'\n        return res", "response": "Show help for the current user"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of tuples that can be used to execute the current command.", "response": "def get_commands(self):\n        \"\"\"\n        Returns commands available to execute\n        :return: list of (name, doc) tuples\n        \"\"\"\n        commands = []\n        for name, value in inspect.getmembers(self):\n            if not inspect.isgeneratorfunction(value):\n                continue\n            if name.startswith('_') or name == 'run':\n                continue\n            doc = inspect.getdoc(value)\n            commands.append((name, doc))\n        return commands"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef reset(self):\n        self._cli.reset()\n        self._cli.buffers[DEFAULT_BUFFER].reset()\n        self._cli.renderer.request_absolute_cursor_position()\n        self._cli._redraw()", "response": "Resets the terminal screen"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a Project instance.", "response": "def get_project(self, project_id):\n        \"\"\"\n        Returns a Project instance.\n\n        :param project_id: Project identifier\n\n        :returns: Project instance\n        \"\"\"\n\n        try:\n            UUID(project_id, version=4)\n        except ValueError:\n            raise aiohttp.web.HTTPBadRequest(text=\"Project ID {} is not a valid UUID\".format(project_id))\n\n        if project_id not in self._projects:\n            raise aiohttp.web.HTTPNotFound(text=\"Project ID {} doesn't exist\".format(project_id))\n        return self._projects[project_id]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _check_available_disk_space(self, project):\n\n        try:\n            used_disk_space = psutil.disk_usage(project.path).percent\n        except FileNotFoundError:\n            log.warning('Could not find \"{}\" when checking for used disk space'.format(project.path))\n            return\n        # send a warning if used disk space is >= 90%\n        if used_disk_space >= 90:\n            message = 'Only {}% or less of disk space detected in \"{}\" on \"{}\"'.format(used_disk_space,\n                                                                                       project.path,\n                                                                                       platform.node())\n            log.warning(message)\n            project.emit(\"log.warning\", {\"message\": message})", "response": "Check if disk space is getting low."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a project and keep a reference to it in the project manager.", "response": "def create_project(self, name=None, project_id=None, path=None):\n        \"\"\"\n        Create a project and keep a references to it in project manager.\n\n        See documentation of Project for arguments\n        \"\"\"\n\n        if project_id is not None and project_id in self._projects:\n            return self._projects[project_id]\n        project = Project(name=name, project_id=project_id, path=path)\n        self._check_available_disk_space(project)\n        self._projects[project.id] = project\n        return project"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving a Project instance from the list of projects in use.", "response": "def remove_project(self, project_id):\n        \"\"\"\n        Removes a Project instance from the list of projects in use.\n\n        :param project_id: Project identifier\n        \"\"\"\n\n        if project_id not in self._projects:\n            raise aiohttp.web.HTTPNotFound(text=\"Project ID {} doesn't exist\".format(project_id))\n        del self._projects[project_id]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check_hardware_virtualization(self, source_node):\n\n        for project in self._projects.values():\n            for node in project.nodes:\n                if node == source_node:\n                    continue\n                if node.hw_virtualization and node.__class__.__name__ != source_node.__class__.__name__:\n                    return False\n        return True", "response": "Checks if hardware virtualization can be used."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the ports on this cloud.", "response": "def ports_mapping(self, ports):\n        \"\"\"\n        Set the ports on this cloud.\n\n        :param ports: ports info\n        \"\"\"\n\n        if ports != self._ports_mapping:\n            if len(self._nios) > 0:\n                raise NodeError(\"Can't modify a cloud already connected.\")\n\n            port_number = 0\n            for port in ports:\n                port[\"port_number\"] = port_number\n                port_number += 1\n\n            self._ports_mapping = ports"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a connection to uBridge.", "response": "def _add_ubridge_connection(self, nio, port_number):\n        \"\"\"\n        Creates a connection in uBridge.\n\n        :param nio: NIO instance\n        :param port_number: port number\n        \"\"\"\n\n        port_info = None\n        for port in self._ports_mapping:\n            if port[\"port_number\"] == port_number:\n                port_info = port\n                break\n\n        if not port_info:\n            raise NodeError(\"Port {port_number} doesn't exist on cloud '{name}'\".format(name=self.name,\n                                                                                        port_number=port_number))\n\n        bridge_name = \"{}-{}\".format(self._id, port_number)\n        yield from self._ubridge_send(\"bridge create {name}\".format(name=bridge_name))\n        if not isinstance(nio, NIOUDP):\n            raise NodeError(\"Source NIO is not UDP\")\n        yield from self._ubridge_send('bridge add_nio_udp {name} {lport} {rhost} {rport}'.format(name=bridge_name,\n                                                                                                 lport=nio.lport,\n                                                                                                 rhost=nio.rhost,\n                                                                                                 rport=nio.rport))\n\n        yield from self._ubridge_apply_filters(bridge_name, nio.filters)\n        if port_info[\"type\"] in (\"ethernet\", \"tap\"):\n\n            if sys.platform.startswith(\"win\"):\n                yield from self._add_ubridge_ethernet_connection(bridge_name, port_info[\"interface\"])\n\n            else:\n\n                if port_info[\"type\"] == \"ethernet\":\n                    network_interfaces = [interface[\"name\"] for interface in self._interfaces()]\n                    if not port_info[\"interface\"] in network_interfaces:\n                        raise NodeError(\"Interface '{}' could not be found on this system\".format(port_info[\"interface\"]))\n\n                    if sys.platform.startswith(\"linux\"):\n                        yield from self._add_linux_ethernet(port_info, bridge_name)\n                    elif sys.platform.startswith(\"darwin\"):\n                        yield from self._add_osx_ethernet(port_info, bridge_name)\n                    else:\n                        yield from self._add_windows_ethernet(port_info, bridge_name)\n\n                elif port_info[\"type\"] == \"tap\":\n                    yield from self._ubridge_send('bridge add_nio_tap {name} \"{interface}\"'.format(name=bridge_name, interface=port_info[\"interface\"]))\n\n        elif port_info[\"type\"] == \"udp\":\n            yield from self._ubridge_send('bridge add_nio_udp {name} {lport} {rhost} {rport}'.format(name=bridge_name,\n                                                                                                     lport=port_info[\"lport\"],\n                                                                                                     rhost=port_info[\"rhost\"],\n                                                                                                     rport=port_info[\"rport\"]))\n\n        if nio.capturing:\n            yield from self._ubridge_send('bridge start_capture {name} \"{pcap_file}\"'.format(name=bridge_name,\n                                                                                             pcap_file=nio.pcap_output_file))\n\n        yield from self._ubridge_send('bridge start {name}'.format(name=bridge_name))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a new ethernet bridge to the Linux ethernet interface.", "response": "def _add_linux_ethernet(self, port_info, bridge_name):\n        \"\"\"\n        Use raw sockets on Linux.\n\n        If interface is a bridge we connect a tap to it\n        \"\"\"\n        interface = port_info[\"interface\"]\n        if gns3server.utils.interfaces.is_interface_bridge(interface):\n\n            network_interfaces = [interface[\"name\"] for interface in self._interfaces()]\n            i = 0\n            while True:\n                tap = \"gns3tap{}-{}\".format(i, port_info[\"port_number\"])\n                if tap not in network_interfaces:\n                    break\n                i += 1\n\n            yield from self._ubridge_send('bridge add_nio_tap \"{name}\" \"{interface}\"'.format(name=bridge_name, interface=tap))\n            yield from self._ubridge_send('brctl addif \"{interface}\" \"{tap}\"'.format(tap=tap, interface=interface))\n        else:\n            yield from self._ubridge_send('bridge add_nio_linux_raw {name} \"{interface}\"'.format(name=bridge_name, interface=interface))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_nio(self, nio, port_number):\n\n        if port_number in self._nios:\n            raise NodeError(\"Port {} isn't free\".format(port_number))\n\n        log.info('Cloud \"{name}\" [{id}]: NIO {nio} bound to port {port}'.format(name=self._name,\n                                                                                id=self._id,\n                                                                                nio=nio,\n                                                                                port=port_number))\n        try:\n            yield from self.start()\n            yield from self._add_ubridge_connection(nio, port_number)\n            self._nios[port_number] = nio\n        except NodeError as e:\n            self.project.emit(\"log.error\", {\"message\": str(e)})\n            yield from self._stop_ubridge()\n            self.status = \"stopped\"\n            self._nios[port_number] = nio\n        # Cleanup stuff\n        except UbridgeError as e:\n            self.project.emit(\"log.error\", {\"message\": str(e)})\n            yield from self._stop_ubridge()\n            self.status = \"stopped\"\n            self._nios[port_number] = nio", "response": "Adds a NIO instance as new port on this cloud."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update_nio(self, port_number, nio):\n\n        bridge_name = \"{}-{}\".format(self._id, port_number)\n        if self._ubridge_hypervisor and self._ubridge_hypervisor.is_running():\n            yield from self._ubridge_apply_filters(bridge_name, nio.filters)", "response": "Update an NIO instance on this node."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _delete_ubridge_connection(self, port_number):\n\n        bridge_name = \"{}-{}\".format(self._id, port_number)\n        yield from self._ubridge_send(\"bridge delete {name}\".format(name=bridge_name))", "response": "Deletes a connection in uBridge."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef remove_nio(self, port_number):\n\n        if port_number not in self._nios:\n            raise NodeError(\"Port {} is not allocated\".format(port_number))\n\n        nio = self._nios[port_number]\n        if isinstance(nio, NIOUDP):\n            self.manager.port_manager.release_udp_port(nio.lport, self._project)\n\n        log.info('Cloud \"{name}\" [{id}]: NIO {nio} removed from port {port}'.format(name=self._name,\n                                                                                    id=self._id,\n                                                                                    nio=nio,\n                                                                                    port=port_number))\n\n        del self._nios[port_number]\n        if self._ubridge_hypervisor and self._ubridge_hypervisor.is_running():\n            yield from self._delete_ubridge_connection(port_number)\n        yield from self.start()\n        return nio", "response": "Removes the specified NIO as member of cloud."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nstart a packet capture on the specified port.", "response": "def start_capture(self, port_number, output_file, data_link_type=\"DLT_EN10MB\"):\n        \"\"\"\n        Starts a packet capture.\n\n        :param port_number: allocated port number\n        :param output_file: PCAP destination file for the capture\n        :param data_link_type: PCAP data link type (DLT_*), default is DLT_EN10MB\n        \"\"\"\n\n        if not [port[\"port_number\"] for port in self._ports_mapping if port_number == port[\"port_number\"]]:\n            raise NodeError(\"Port {port_number} doesn't exist on cloud '{name}'\".format(name=self.name,\n                                                                                        port_number=port_number))\n\n        if port_number not in self._nios:\n            raise NodeError(\"Port {} is not connected\".format(port_number))\n\n        nio = self._nios[port_number]\n\n        if nio.capturing:\n            raise NodeError(\"Packet capture is already activated on port {port_number}\".format(port_number=port_number))\n        nio.startPacketCapture(output_file)\n        bridge_name = \"{}-{}\".format(self._id, port_number)\n        yield from self._ubridge_send('bridge start_capture {name} \"{output_file}\"'.format(name=bridge_name,\n                                                                                           output_file=output_file))\n        log.info(\"Cloud '{name}' [{id}]: starting packet capture on port {port_number}\".format(name=self.name,\n                                                                                               id=self.id,\n                                                                                               port_number=port_number))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nstopping a packet capture.", "response": "def stop_capture(self, port_number):\n        \"\"\"\n        Stops a packet capture.\n\n        :param port_number: allocated port number\n        \"\"\"\n\n        if not [port[\"port_number\"] for port in self._ports_mapping if port_number == port[\"port_number\"]]:\n            raise NodeError(\"Port {port_number} doesn't exist on cloud '{name}'\".format(name=self.name,\n                                                                                        port_number=port_number))\n\n        if port_number not in self._nios:\n            raise NodeError(\"Port {} is not connected\".format(port_number))\n\n        nio = self._nios[port_number]\n        nio.stopPacketCapture()\n        bridge_name = \"{}-{}\".format(self._id, port_number)\n        yield from self._ubridge_send(\"bridge stop_capture {name}\".format(name=bridge_name))\n\n        log.info(\"Cloud'{name}' [{id}]: stopping packet capture on port {port_number}\".format(name=self.name,\n                                                                                              id=self.id,\n                                                                                              port_number=port_number))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if this application runs with a correct locale and attempts to fix it if it is not.", "response": "def locale_check():\n    \"\"\"\n    Checks if this application runs with a correct locale (i.e. supports UTF-8 encoding) and attempt to fix\n    if this is not the case.\n\n    This is to prevent UnicodeEncodeError with unicode paths when using standard library I/O operation\n    methods (e.g. os.stat() or os.path.*) which rely on the system or user locale.\n\n    More information can be found there: http://seasonofcode.com/posts/unicode-i-o-and-locales-in-python.html\n    or there: http://robjwells.com/post/61198832297/get-your-us-ascii-out-of-my-face\n    \"\"\"\n\n    # no need to check on Windows or when this application is frozen\n    if sys.platform.startswith(\"win\") or hasattr(sys, \"frozen\"):\n        return\n\n    language = encoding = None\n    try:\n        language, encoding = locale.getlocale()\n    except ValueError as e:\n        log.error(\"Could not determine the current locale: {}\".format(e))\n    if not language and not encoding:\n        try:\n            log.warning(\"Could not find a default locale, switching to C.UTF-8...\")\n            locale.setlocale(locale.LC_ALL, (\"C\", \"UTF-8\"))\n        except locale.Error as e:\n            log.error(\"Could not switch to the C.UTF-8 locale: {}\".format(e))\n            raise SystemExit\n    elif encoding != \"UTF-8\":\n        log.warning(\"Your locale {}.{} encoding is not UTF-8, switching to the UTF-8 version...\".format(language, encoding))\n        try:\n            locale.setlocale(locale.LC_ALL, (language, \"UTF-8\"))\n        except locale.Error as e:\n            log.error(\"Could not set an UTF-8 encoding for the {} locale: {}\".format(language, e))\n            raise SystemExit\n    else:\n        log.info(\"Current locale is {}.{}\".format(language, encoding))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse command line arguments and override local configuration", "response": "def parse_arguments(argv):\n    \"\"\"\n    Parse command line arguments and override local configuration\n\n    :params args: Array of command line arguments\n    \"\"\"\n\n    parser = argparse.ArgumentParser(description=\"GNS3 server version {}\".format(__version__))\n    parser.add_argument(\"-v\", \"--version\", help=\"show the version\", action=\"version\", version=__version__)\n    parser.add_argument(\"--host\", help=\"run on the given host/IP address\")\n    parser.add_argument(\"--port\", help=\"run on the given port\", type=int)\n    parser.add_argument(\"--ssl\", action=\"store_true\", help=\"run in SSL mode\")\n    parser.add_argument(\"--no-ubridge\", action=\"store_false\", help=\"do not use ubridge to handle node connections\")\n    parser.add_argument(\"--config\", help=\"Configuration file\")\n    parser.add_argument(\"--certfile\", help=\"SSL cert file\")\n    parser.add_argument(\"--certkey\", help=\"SSL key file\")\n    parser.add_argument(\"--record\", help=\"save curl requests into a file (for developers)\")\n    parser.add_argument(\"-L\", \"--local\", action=\"store_true\", help=\"local mode (allows some insecure operations)\")\n    parser.add_argument(\"-A\", \"--allow\", action=\"store_true\", help=\"allow remote connections to local console ports\")\n    parser.add_argument(\"-q\", \"--quiet\", action=\"store_true\", help=\"do not show logs on stdout\")\n    parser.add_argument(\"-d\", \"--debug\", action=\"store_true\", help=\"show debug logs\")\n    parser.add_argument(\"--shell\", action=\"store_true\", help=\"start a shell inside the server (debugging purpose only you need to install ptpython before)\")\n    parser.add_argument(\"--log\", help=\"send output to logfile instead of console\")\n    parser.add_argument(\"--daemon\", action=\"store_true\", help=\"start as a daemon\")\n    parser.add_argument(\"--pid\", help=\"store process pid\")\n    parser.add_argument(\"--profile\", help=\"Settings profile (blank will use default settings files)\")\n\n    args = parser.parse_args(argv)\n    if args.config:\n        Config.instance(files=[args.config], profile=args.profile)\n    else:\n        Config.instance(profile=args.profile)\n\n    config = Config.instance().get_section_config(\"Server\")\n    defaults = {\n        \"host\": config.get(\"host\", \"0.0.0.0\"),\n        \"port\": config.get(\"port\", 3080),\n        \"ssl\": config.getboolean(\"ssl\", False),\n        \"certfile\": config.get(\"certfile\", \"\"),\n        \"certkey\": config.get(\"certkey\", \"\"),\n        \"record\": config.get(\"record\", \"\"),\n        \"local\": config.getboolean(\"local\", False),\n        \"allow\": config.getboolean(\"allow_remote_console\", False),\n        \"quiet\": config.getboolean(\"quiet\", False),\n        \"debug\": config.getboolean(\"debug\", False),\n        \"logfile\": config.getboolean(\"logfile\", \"\")\n    }\n\n    parser.set_defaults(**defaults)\n    return parser.parse_args(argv)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pid_lock(path):\n\n    if os.path.exists(path):\n        pid = None\n        try:\n            with open(path) as f:\n                try:\n                    pid = int(f.read())\n                    os.kill(pid, 0)  # kill returns an error if the process is not running\n                except (OSError, SystemError, ValueError):\n                    pid = None\n        except OSError as e:\n            log.critical(\"Can't open pid file %s: %s\", pid, str(e))\n            sys.exit(1)\n\n        if pid:\n            log.critical(\"GNS3 is already running pid: %d\", pid)\n            sys.exit(1)\n\n    try:\n        with open(path, 'w+') as f:\n            f.write(str(os.getpid()))\n    except OSError as e:\n        log.critical(\"Can't write pid file %s: %s\", path, str(e))\n        sys.exit(1)", "response": "Write the file in a file on the system."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nkill all processes in the GNS3 session.", "response": "def kill_ghosts():\n    \"\"\"\n    Kill process from previous GNS3 session\n    \"\"\"\n    detect_process = [\"vpcs\", \"ubridge\", \"dynamips\"]\n    for proc in psutil.process_iter():\n        try:\n            name = proc.name().lower().split(\".\")[0]\n            if name in detect_process:\n                proc.kill()\n                log.warning(\"Killed ghost process %s\", name)\n        except (psutil.NoSuchProcess, psutil.AccessDenied):\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef qemu_path(self, qemu_path):\n\n        if qemu_path and os.pathsep not in qemu_path:\n            if sys.platform.startswith(\"win\") and \".exe\" not in qemu_path.lower():\n                qemu_path += \"w.exe\"\n            new_qemu_path = shutil.which(qemu_path, path=os.pathsep.join(self._manager.paths_list()))\n            if new_qemu_path is None:\n                raise QemuError(\"QEMU binary path {} is not found in the path\".format(qemu_path))\n            qemu_path = new_qemu_path\n\n        self._check_qemu_path(qemu_path)\n        self._qemu_path = qemu_path\n        self._platform = os.path.basename(qemu_path)\n        if self._platform == \"qemu-kvm\":\n            self._platform = \"x86_64\"\n        else:\n            qemu_bin = os.path.basename(qemu_path)\n            qemu_bin = re.sub(r'(w)?\\.(exe|EXE)$', '', qemu_bin)\n            # Old version of GNS3 provide a binary named qemu.exe\n            if qemu_bin == \"qemu\":\n                self._platform = \"i386\"\n            else:\n                self._platform = re.sub(r'^qemu-system-(.*)$', r'\\1', qemu_bin, re.IGNORECASE)\n        if self._platform.split(\".\")[0] not in QEMU_PLATFORMS:\n            raise QemuError(\"Platform {} is unknown\".format(self._platform))\n        log.info('QEMU VM \"{name}\" [{id}] has set the QEMU path to {qemu_path}'.format(name=self._name,\n                                                                                       id=self._id,\n                                                                                       qemu_path=qemu_path))", "response": "Sets the QEMU binary path this QEMU VM is located in."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _disk_setter(self, variable, value):\n        value = self.manager.get_abs_image_path(value)\n        if not self.linked_clone:\n            for node in self.manager.nodes:\n                if node != self and getattr(node, variable) == value:\n                    raise QemuError(\"Sorry a node without the linked base setting enabled can only be used once on your server. {} is already used by {}\".format(value, node.name))\n        setattr(self, \"_\" + variable, value)\n        log.info('QEMU VM \"{name}\" [{id}] has set the QEMU {variable} path to {disk_image}'.format(name=self._name,\n                                                                                                   variable=variable,\n                                                                                                   id=self._id,\n                                                                                                   disk_image=value))", "response": "Set the value of the disk image for this class"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef hda_disk_interface(self, hda_disk_interface):\n\n        self._hda_disk_interface = hda_disk_interface\n        log.info('QEMU VM \"{name}\" [{id}] has set the QEMU hda disk interface to {interface}'.format(name=self._name,\n                                                                                                     id=self._id,\n                                                                                                     interface=self._hda_disk_interface))", "response": "Sets the hda disk interface for this QEMU VM."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the hda disk interface for this QEMU VM.", "response": "def hdb_disk_interface(self, hdb_disk_interface):\n        \"\"\"\n        Sets the hda disk interface for this QEMU VM.\n\n        :param hdb_disk_interface: QEMU hdb disk interface\n        \"\"\"\n\n        self._hdb_disk_interface = hdb_disk_interface\n        log.info('QEMU VM \"{name}\" [{id}] has set the QEMU hdb disk interface to {interface}'.format(name=self._name,\n                                                                                                     id=self._id,\n                                                                                                     interface=self._hdb_disk_interface))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef hdc_disk_interface(self, hdc_disk_interface):\n\n        self._hdc_disk_interface = hdc_disk_interface\n        log.info('QEMU VM \"{name}\" [{id}] has set the QEMU hdc disk interface to {interface}'.format(name=self._name,\n                                                                                                     id=self._id,\n                                                                                                     interface=self._hdc_disk_interface))", "response": "Sets the hdc disk interface for this QEMU VM."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef hdd_disk_interface(self, hdd_disk_interface):\n\n        self._hdd_disk_interface = hdd_disk_interface\n        log.info('QEMU VM \"{name}\" [{id}] has set the QEMU hdd disk interface to {interface}'.format(name=self._name,\n                                                                                                     id=self._id,\n                                                                                                     interface=self._hdd_disk_interface))", "response": "Sets the hdd disk interface for this QEMU VM."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef cdrom_image(self, cdrom_image):\n        self._cdrom_image = self.manager.get_abs_image_path(cdrom_image)\n        log.info('QEMU VM \"{name}\" [{id}] has set the QEMU cdrom image path to {cdrom_image}'.format(name=self._name,\n                                                                                                     id=self._id,\n                                                                                                     cdrom_image=self._cdrom_image))", "response": "Sets the cdrom image for this QEMU VM."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef bios_image(self, bios_image):\n        self._bios_image = self.manager.get_abs_image_path(bios_image)\n        log.info('QEMU VM \"{name}\" [{id}] has set the QEMU bios image path to {bios_image}'.format(name=self._name,\n                                                                                                   id=self._id,\n                                                                                                   bios_image=self._bios_image))", "response": "Sets the bios image for this QEMU VM."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef boot_priority(self, boot_priority):\n\n        self._boot_priority = boot_priority\n        log.info('QEMU VM \"{name}\" [{id}] has set the boot priority to {boot_priority}'.format(name=self._name,\n                                                                                               id=self._id,\n                                                                                               boot_priority=self._boot_priority))", "response": "Sets the boot priority for this QEMU VM."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the number of Ethernet adapters for this QEMU VM.", "response": "def adapters(self, adapters):\n        \"\"\"\n        Sets the number of Ethernet adapters for this QEMU VM.\n\n        :param adapters: number of adapters\n        \"\"\"\n\n        self._ethernet_adapters.clear()\n        for adapter_number in range(0, adapters):\n            self._ethernet_adapters.append(EthernetAdapter())\n\n        log.info('QEMU VM \"{name}\" [{id}]: number of Ethernet adapters changed to {adapters}'.format(name=self._name,\n                                                                                                     id=self._id,\n                                                                                                     adapters=adapters))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the MAC address for this QEMU VM.", "response": "def mac_address(self, mac_address):\n        \"\"\"\n        Sets the MAC address for this QEMU VM.\n\n        :param mac_address: MAC address\n        \"\"\"\n\n        if not mac_address:\n            # use the node UUID to generate a random MAC address\n            self._mac_address = \"52:%s:%s:%s:%s:00\" % (self.project.id[-4:-2], self.project.id[-2:], self.id[-4:-2], self.id[-2:])\n        else:\n            self._mac_address = mac_address\n\n        log.info('QEMU VM \"{name}\" [{id}]: MAC address changed to {mac_addr}'.format(name=self._name,\n                                                                                     id=self._id,\n                                                                                     mac_addr=self._mac_address))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef legacy_networking(self, legacy_networking):\n\n        if legacy_networking:\n            log.info('QEMU VM \"{name}\" [{id}] has enabled legacy networking'.format(name=self._name, id=self._id))\n        else:\n            log.info('QEMU VM \"{name}\" [{id}] has disabled legacy networking'.format(name=self._name, id=self._id))\n        self._legacy_networking = legacy_networking", "response": "Sets whether legacy networking commands are used."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef acpi_shutdown(self, acpi_shutdown):\n\n        if acpi_shutdown:\n            log.info('QEMU VM \"{name}\" [{id}] has enabled ACPI shutdown'.format(name=self._name, id=self._id))\n        else:\n            log.info('QEMU VM \"{name}\" [{id}] has disabled ACPI shutdown'.format(name=self._name, id=self._id))\n        self._acpi_shutdown = acpi_shutdown", "response": "Sets whether or not this QEMU VM can be ACPI shutdown."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the percentage of CPU allowed.", "response": "def cpu_throttling(self, cpu_throttling):\n        \"\"\"\n        Sets the percentage of CPU allowed.\n\n        :param cpu_throttling: integer\n        \"\"\"\n\n        log.info('QEMU VM \"{name}\" [{id}] has set the percentage of CPU allowed to {cpu}'.format(name=self._name,\n                                                                                                 id=self._id,\n                                                                                                 cpu=cpu_throttling))\n        self._cpu_throttling = cpu_throttling\n        self._stop_cpulimit()\n        if cpu_throttling:\n            self._set_cpu_throttling()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the process priority.", "response": "def process_priority(self, process_priority):\n        \"\"\"\n        Sets the process priority.\n\n        :param process_priority: string\n        \"\"\"\n\n        log.info('QEMU VM \"{name}\" [{id}] has set the process priority to {priority}'.format(name=self._name,\n                                                                                             id=self._id,\n                                                                                             priority=process_priority))\n        self._process_priority = process_priority"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cpus(self, cpus):\n\n        log.info('QEMU VM \"{name}\" [{id}] has set the number of vCPUs to {cpus}'.format(name=self._name, id=self._id, cpus=cpus))\n        self._cpus = cpus", "response": "Sets the number of vCPUs this QEMU VM is using."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef options(self, options):\n\n        log.info('QEMU VM \"{name}\" [{id}] has set the QEMU options to {options}'.format(name=self._name,\n                                                                                        id=self._id,\n                                                                                        options=options))\n\n        if not sys.platform.startswith(\"linux\"):\n            if \"-no-kvm\" in options:\n                options = options.replace(\"-no-kvm\", \"\")\n            if \"-enable-kvm\" in options:\n                options = options.replace(\"-enable-kvm\", \"\")\n        elif \"-icount\" in options and (\"-no-kvm\" not in options):\n            # automatically add the -no-kvm option if -icount is detected\n            # to help with the migration of ASA VMs created before version 1.4\n            options = \"-no-kvm \" + options\n        self._options = options.strip()", "response": "Sets the options for this QEMU VM."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the initrd path for this QEMU VM.", "response": "def initrd(self, initrd):\n        \"\"\"\n        Sets the initrd path for this QEMU VM.\n\n        :param initrd: QEMU initrd path\n        \"\"\"\n\n        initrd = self.manager.get_abs_image_path(initrd)\n\n        log.info('QEMU VM \"{name}\" [{id}] has set the QEMU initrd path to {initrd}'.format(name=self._name,\n                                                                                           id=self._id,\n                                                                                           initrd=initrd))\n        if \"asa\" in initrd:\n            self.project.emit(\"log.warning\", {\"message\": \"Warning ASA 8 is not supported by GNS3 and Cisco, you need to use ASAv. Depending of your hardware and OS this could not work or you could be limited to one instance. If ASA 8 is not booting their is no GNS3 solution, you need to upgrade to ASAv.\"})\n        self._initrd = initrd"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef kernel_image(self, kernel_image):\n\n        kernel_image = self.manager.get_abs_image_path(kernel_image)\n        log.info('QEMU VM \"{name}\" [{id}] has set the QEMU kernel image path to {kernel_image}'.format(name=self._name,\n                                                                                                       id=self._id,\n                                                                                                       kernel_image=kernel_image))\n        self._kernel_image = kernel_image", "response": "Sets the kernel image path for this QEMU VM."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef kernel_command_line(self, kernel_command_line):\n\n        log.info('QEMU VM \"{name}\" [{id}] has set the QEMU kernel command line to {kernel_command_line}'.format(name=self._name,\n                                                                                                                id=self._id,\n                                                                                                                kernel_command_line=kernel_command_line))\n        self._kernel_command_line = kernel_command_line", "response": "Sets the kernel command line for this QEMU VM."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _set_process_priority(self):\n\n        if self._process_priority == \"normal\":\n            return\n\n        if sys.platform.startswith(\"win\"):\n            try:\n                import win32api\n                import win32con\n                import win32process\n            except ImportError:\n                log.error(\"pywin32 must be installed to change the priority class for QEMU VM {}\".format(self._name))\n            else:\n                log.info(\"Setting QEMU VM {} priority class to {}\".format(self._name, self._process_priority))\n                handle = win32api.OpenProcess(win32con.PROCESS_ALL_ACCESS, 0, self._process.pid)\n                if self._process_priority == \"realtime\":\n                    priority = win32process.REALTIME_PRIORITY_CLASS\n                elif self._process_priority == \"very high\":\n                    priority = win32process.HIGH_PRIORITY_CLASS\n                elif self._process_priority == \"high\":\n                    priority = win32process.ABOVE_NORMAL_PRIORITY_CLASS\n                elif self._process_priority == \"low\":\n                    priority = win32process.BELOW_NORMAL_PRIORITY_CLASS\n                elif self._process_priority == \"very low\":\n                    priority = win32process.IDLE_PRIORITY_CLASS\n                else:\n                    priority = win32process.NORMAL_PRIORITY_CLASS\n                try:\n                    win32process.SetPriorityClass(handle, priority)\n                except win32process.error as e:\n                    log.error('Could not change process priority for QEMU VM \"{}\": {}'.format(self._name, e))\n        else:\n            if self._process_priority == \"realtime\":\n                priority = -20\n            elif self._process_priority == \"very high\":\n                priority = -15\n            elif self._process_priority == \"high\":\n                priority = -5\n            elif self._process_priority == \"low\":\n                priority = 5\n            elif self._process_priority == \"very low\":\n                priority = 19\n            else:\n                priority = 0\n            try:\n                process = yield from asyncio.create_subprocess_exec('renice', '-n', str(priority), '-p', str(self._process.pid))\n                yield from process.wait()\n            except (OSError, subprocess.SubprocessError) as e:\n                log.error('Could not change process priority for QEMU VM \"{}\": {}'.format(self._name, e))", "response": "Changes the process priority for this QEMU VM."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nstopping the cpulimit process.", "response": "def _stop_cpulimit(self):\n        \"\"\"\n        Stops the cpulimit process.\n        \"\"\"\n\n        if self._cpulimit_process and self._cpulimit_process.returncode is None:\n            self._cpulimit_process.kill()\n            try:\n                self._process.wait(3)\n            except subprocess.TimeoutExpired:\n                log.error(\"Could not kill cpulimit process {}\".format(self._cpulimit_process.pid))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _set_cpu_throttling(self):\n\n        if not self.is_running():\n            return\n\n        try:\n            if sys.platform.startswith(\"win\") and hasattr(sys, \"frozen\"):\n                cpulimit_exec = os.path.join(os.path.dirname(os.path.abspath(sys.executable)), \"cpulimit\", \"cpulimit.exe\")\n            else:\n                cpulimit_exec = \"cpulimit\"\n            subprocess.Popen([cpulimit_exec, \"--lazy\", \"--pid={}\".format(self._process.pid), \"--limit={}\".format(self._cpu_throttling)], cwd=self.working_dir)\n            log.info(\"CPU throttled to {}%\".format(self._cpu_throttling))\n        except FileNotFoundError:\n            raise QemuError(\"cpulimit could not be found, please install it or deactivate CPU throttling\")\n        except (OSError, subprocess.SubprocessError) as e:\n            raise QemuError(\"Could not throttle CPU: {}\".format(e))", "response": "Sets the CPU throttling for the current QEMU process."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef start(self):\n\n        with (yield from self._execute_lock):\n            if self.is_running():\n                # resume the VM if it is paused\n                yield from self.resume()\n                return\n\n            if self._manager.config.get_section_config(\"Qemu\").getboolean(\"monitor\", True):\n                try:\n                    info = socket.getaddrinfo(self._monitor_host, 0, socket.AF_UNSPEC, socket.SOCK_STREAM, 0, socket.AI_PASSIVE)\n                    if not info:\n                        raise QemuError(\"getaddrinfo returns an empty list on {}\".format(self._monitor_host))\n                    for res in info:\n                        af, socktype, proto, _, sa = res\n                        # let the OS find an unused port for the Qemu monitor\n                        with socket.socket(af, socktype, proto) as sock:\n                            sock.bind(sa)\n                            self._monitor = sock.getsockname()[1]\n                except OSError as e:\n                    raise QemuError(\"Could not find free port for the Qemu monitor: {}\".format(e))\n\n            # check if there is enough RAM to run\n            self.check_available_ram(self.ram)\n\n            command = yield from self._build_command()\n            command_string = \" \".join(shlex.quote(s) for s in command)\n            try:\n                log.info(\"Starting QEMU with: {}\".format(command_string))\n                self._stdout_file = os.path.join(self.working_dir, \"qemu.log\")\n                log.info(\"logging to {}\".format(self._stdout_file))\n                with open(self._stdout_file, \"w\", encoding=\"utf-8\") as fd:\n                    fd.write(\"Start QEMU with {}\\n\\nExecution log:\\n\".format(command_string))\n                    self.command_line = ' '.join(command)\n                    self._process = yield from asyncio.create_subprocess_exec(*command,\n                                                                              stdout=fd,\n                                                                              stderr=subprocess.STDOUT,\n                                                                              cwd=self.working_dir)\n\n                yield from self._start_ubridge()\n                for adapter_number, adapter in enumerate(self._ethernet_adapters):\n                    nio = adapter.get_nio(0)\n                    if nio:\n                        yield from self.add_ubridge_udp_connection(\"QEMU-{}-{}\".format(self._id, adapter_number),\n                                                                   self._local_udp_tunnels[adapter_number][1],\n                                                                   nio)\n\n                log.info('QEMU VM \"{}\" started PID={}'.format(self._name, self._process.pid))\n                self.status = \"started\"\n                monitor_process(self._process, self._termination_callback)\n            except (OSError, subprocess.SubprocessError, UnicodeEncodeError) as e:\n                stdout = self.read_stdout()\n                log.error(\"Could not start QEMU {}: {}\\n{}\".format(self.qemu_path, e, stdout))\n                raise QemuError(\"Could not start QEMU {}: {}\\n{}\".format(self.qemu_path, e, stdout))\n\n            yield from self._set_process_priority()\n            if self._cpu_throttling:\n                self._set_cpu_throttling()\n\n            if \"-enable-kvm\" in command_string:\n                self._hw_virtualization = True\n        try:\n            yield from self.start_wrap_console()\n        except OSError as e:\n            raise QemuError(\"Could not start QEMU console {}\\n\".format(e))", "response": "Starts this QEMU VM."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _termination_callback(self, returncode):\n\n        if self.started:\n            log.info(\"QEMU process has stopped, return code: %d\", returncode)\n            yield from self.stop()\n            # A return code of 1 seem fine on Windows\n            if returncode != 0 and (returncode != 1 or not sys.platform.startswith(\"win\")):\n                self.project.emit(\"log.error\", {\"message\": \"QEMU process has stopped, return code: {}\\n{}\".format(returncode, self.read_stdout())})", "response": "Called when the process has stopped."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef stop(self):\n\n        yield from self._stop_ubridge()\n        with (yield from self._execute_lock):\n            # stop the QEMU process\n            self._hw_virtualization = False\n            if self.is_running():\n                log.info('Stopping QEMU VM \"{}\" PID={}'.format(self._name, self._process.pid))\n                try:\n                    if self.acpi_shutdown:\n                        yield from self._control_vm(\"system_powerdown\")\n                        yield from gns3server.utils.asyncio.wait_for_process_termination(self._process, timeout=30)\n                    else:\n                        self._process.terminate()\n                        yield from gns3server.utils.asyncio.wait_for_process_termination(self._process, timeout=3)\n                except ProcessLookupError:\n                    pass\n                except asyncio.TimeoutError:\n                    if self._process:\n                        try:\n                            self._process.kill()\n                        except ProcessLookupError:\n                            pass\n                        if self._process.returncode is None:\n                            log.warn('QEMU VM \"{}\" PID={} is still running'.format(self._name, self._process.pid))\n            self._process = None\n            self._stop_cpulimit()\n            yield from super().stop()", "response": "Stops this QEMU VM."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _control_vm(self, command, expected=None):\n\n        result = None\n        if self.is_running() and self._monitor:\n            log.debug(\"Execute QEMU monitor command: {}\".format(command))\n            try:\n                log.info(\"Connecting to Qemu monitor on {}:{}\".format(self._monitor_host, self._monitor))\n                reader, writer = yield from asyncio.open_connection(self._monitor_host, self._monitor)\n            except OSError as e:\n                log.warn(\"Could not connect to QEMU monitor: {}\".format(e))\n                return result\n            try:\n                writer.write(command.encode('ascii') + b\"\\n\")\n            except OSError as e:\n                log.warn(\"Could not write to QEMU monitor: {}\".format(e))\n                writer.close()\n                return result\n            if expected:\n                try:\n                    while result is None:\n                        line = yield from reader.readline()\n                        if not line:\n                            break\n                        for expect in expected:\n                            if expect in line:\n                                result = line.decode(\"utf-8\").strip()\n                                break\n                except EOFError as e:\n                    log.warn(\"Could not read from QEMU monitor: {}\".format(e))\n            writer.close()\n        return result", "response": "Executes a command with QEMU monitor when this VM is running."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nclosing this QEMU VM.", "response": "def close(self):\n        \"\"\"\n        Closes this QEMU VM.\n        \"\"\"\n\n        if not (yield from super().close()):\n            return False\n\n        self.acpi_shutdown = False\n        yield from self.stop()\n\n        for adapter in self._ethernet_adapters:\n            if adapter is not None:\n                for nio in adapter.ports.values():\n                    if nio and isinstance(nio, NIOUDP):\n                        self.manager.port_manager.release_udp_port(nio.lport, self._project)\n\n        for udp_tunnel in self._local_udp_tunnels.values():\n            self.manager.port_manager.release_udp_port(udp_tunnel[0].lport, self._project)\n            self.manager.port_manager.release_udp_port(udp_tunnel[1].lport, self._project)\n        self._local_udp_tunnels = {}"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns this VM suspend status.", "response": "def _get_vm_status(self):\n        \"\"\"\n        Returns this VM suspend status.\n\n        Status are extracted from:\n          https://github.com/qemu/qemu/blob/master/qapi-schema.json#L152\n\n        :returns: status (string)\n        \"\"\"\n\n        result = yield from self._control_vm(\"info status\", [\n            b\"debug\", b\"inmigrate\", b\"internal-error\", b\"io-error\",\n            b\"paused\", b\"postmigrate\", b\"prelaunch\", b\"finish-migrate\",\n            b\"restore-vm\", b\"running\", b\"save-vm\", b\"shutdown\", b\"suspended\",\n            b\"watchdog\", b\"guest-panicked\"\n        ])\n        if result is None:\n            return result\n        status = result.rsplit(' ', 1)[1]\n        if status == \"running\" or status == \"prelaunch\":\n            self.status = \"started\"\n        elif status == \"suspended\":\n            self.status = \"suspended\"\n        elif status == \"shutdown\":\n            self.status = \"stopped\"\n        return status"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsuspends this QEMU VM.", "response": "def suspend(self):\n        \"\"\"\n        Suspends this QEMU VM.\n        \"\"\"\n\n        if self.is_running():\n            vm_status = yield from self._get_vm_status()\n            if vm_status is None:\n                raise QemuError(\"Suspending a QEMU VM is not supported\")\n            elif vm_status == \"running\" or vm_status == \"prelaunch\":\n                yield from self._control_vm(\"stop\")\n                self.status = \"suspended\"\n                log.debug(\"QEMU VM has been suspended\")\n            else:\n                log.info(\"QEMU VM is not running to be suspended, current status is {}\".format(vm_status))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nresuming this QEMU VM.", "response": "def resume(self):\n        \"\"\"\n        Resumes this QEMU VM.\n        \"\"\"\n\n        vm_status = yield from self._get_vm_status()\n        if vm_status is None:\n            raise QemuError(\"Resuming a QEMU VM is not supported\")\n        elif vm_status == \"paused\":\n            yield from self._control_vm(\"cont\")\n            log.debug(\"QEMU VM has been resumed\")\n        else:\n            log.info(\"QEMU VM is not paused to be resumed, current status is {}\".format(vm_status))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd a port NIO binding to the specified adapter.", "response": "def adapter_add_nio_binding(self, adapter_number, nio):\n        \"\"\"\n        Adds a port NIO binding.\n\n        :param adapter_number: adapter number\n        :param nio: NIO instance to add to the adapter\n        \"\"\"\n\n        try:\n            adapter = self._ethernet_adapters[adapter_number]\n        except IndexError:\n            raise QemuError('Adapter {adapter_number} does not exist on QEMU VM \"{name}\"'.format(name=self._name,\n                                                                                                 adapter_number=adapter_number))\n\n        if self.is_running():\n            try:\n                yield from self.add_ubridge_udp_connection(\"QEMU-{}-{}\".format(self._id, adapter_number),\n                                                           self._local_udp_tunnels[adapter_number][1],\n                                                           nio)\n            except (IndexError, KeyError):\n                raise QemuError('Adapter {adapter_number} does not exist on QEMU VM \"{name}\"'.format(name=self._name,\n                                                                                                     adapter_number=adapter_number))\n\n        adapter.add_nio(0, nio)\n        log.info('QEMU VM \"{name}\" [{id}]: {nio} added to adapter {adapter_number}'.format(name=self._name,\n                                                                                           id=self._id,\n                                                                                           nio=nio,\n                                                                                           adapter_number=adapter_number))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef adapter_remove_nio_binding(self, adapter_number):\n\n        try:\n            adapter = self._ethernet_adapters[adapter_number]\n        except IndexError:\n            raise QemuError('Adapter {adapter_number} does not exist on QEMU VM \"{name}\"'.format(name=self._name,\n                                                                                                 adapter_number=adapter_number))\n\n        if self.is_running():\n            yield from self._ubridge_send(\"bridge delete {name}\".format(name=\"QEMU-{}-{}\".format(self._id, adapter_number)))\n\n        nio = adapter.get_nio(0)\n        if isinstance(nio, NIOUDP):\n            self.manager.port_manager.release_udp_port(nio.lport, self._project)\n        adapter.remove_nio(0)\n\n        log.info('QEMU VM \"{name}\" [{id}]: {nio} removed from adapter {adapter_number}'.format(name=self._name,\n                                                                                               id=self._id,\n                                                                                               nio=nio,\n                                                                                               adapter_number=adapter_number))\n        return nio", "response": "Removes a port NIO binding."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstarting a packet capture on the specified adapter.", "response": "def start_capture(self, adapter_number, output_file):\n        \"\"\"\n        Starts a packet capture.\n\n        :param adapter_number: adapter number\n        :param output_file: PCAP destination file for the capture\n        \"\"\"\n\n        try:\n            adapter = self._ethernet_adapters[adapter_number]\n        except IndexError:\n            raise QemuError('Adapter {adapter_number} does not exist on QEMU VM \"{name}\"'.format(name=self._name,\n                                                                                                 adapter_number=adapter_number))\n\n        nio = adapter.get_nio(0)\n\n        if not nio:\n            raise QemuError(\"Adapter {} is not connected\".format(adapter_number))\n\n        if nio.capturing:\n            raise QemuError(\"Packet capture is already activated on adapter {adapter_number}\".format(adapter_number=adapter_number))\n\n        nio.startPacketCapture(output_file)\n\n        if self.ubridge:\n            yield from self._ubridge_send('bridge start_capture {name} \"{output_file}\"'.format(name=\"QEMU-{}-{}\".format(self._id, adapter_number),\n                                                                                               output_file=output_file))\n\n        log.info(\"QEMU VM '{name}' [{id}]: starting packet capture on adapter {adapter_number}\".format(name=self.name,\n                                                                                                       id=self.id,\n                                                                                                       adapter_number=adapter_number))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef stop_capture(self, adapter_number):\n\n        try:\n            adapter = self._ethernet_adapters[adapter_number]\n        except IndexError:\n            raise QemuError('Adapter {adapter_number} does not exist on QEMU VM \"{name}\"'.format(name=self._name,\n                                                                                                 adapter_number=adapter_number))\n        nio = adapter.get_nio(0)\n\n        if not nio:\n            raise QemuError(\"Adapter {} is not connected\".format(adapter_number))\n\n        nio.stopPacketCapture()\n\n        if self.ubridge:\n            yield from self._ubridge_send('bridge stop_capture {name}'.format(name=\"QEMU-{}-{}\".format(self._id, adapter_number)))\n\n        log.info(\"QEMU VM '{name}' [{id}]: stopping packet capture on adapter {adapter_number}\".format(name=self.name,\n                                                                                                       id=self.id,\n                                                                                                       adapter_number=adapter_number))", "response": "Stops a packet capture on the specified adapter."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread the standard output of the QEMU process.", "response": "def read_stdout(self):\n        \"\"\"\n        Reads the standard output of the QEMU process.\n        Only use when the process has been stopped or has crashed.\n        \"\"\"\n\n        output = \"\"\n        if self._stdout_file:\n            try:\n                with open(self._stdout_file, \"rb\") as file:\n                    output = file.read().decode(\"utf-8\", errors=\"replace\")\n            except OSError as e:\n                log.warning(\"Could not read {}: {}\".format(self._stdout_file, e))\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread the standard output of the QEMU - IMG process.", "response": "def read_qemu_img_stdout(self):\n        \"\"\"\n        Reads the standard output of the QEMU-IMG process.\n        \"\"\"\n\n        output = \"\"\n        if self._qemu_img_stdout_file:\n            try:\n                with open(self._qemu_img_stdout_file, \"rb\") as file:\n                    output = file.read().decode(\"utf-8\", errors=\"replace\")\n            except OSError as e:\n                log.warning(\"Could not read {}: {}\".format(self._qemu_img_stdout_file, e))\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_running(self):\n\n        if self._process:\n            if self._process.returncode is None:\n                return True\n            else:\n                self._process = None\n        return False", "response": "Checks if the QEMU process is running"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsearch the qemu - img binary in the same binary of the qemu binary of the qemu binary of the qemu binary and return the path to that binary.", "response": "def _get_qemu_img(self):\n        \"\"\"\n        Search the qemu-img binary in the same binary of the qemu binary\n        for avoiding version incompatibily.\n\n        :returns: qemu-img path or raise an error\n        \"\"\"\n        qemu_img_path = \"\"\n        qemu_path_dir = os.path.dirname(self.qemu_path)\n        try:\n            for f in os.listdir(qemu_path_dir):\n                if f.startswith(\"qemu-img\"):\n                    qemu_img_path = os.path.join(qemu_path_dir, f)\n        except OSError as e:\n            raise QemuError(\"Error while looking for qemu-img in {}: {}\".format(qemu_path_dir, e))\n\n        if not qemu_img_path:\n            raise QemuError(\"Could not find qemu-img in {}\".format(qemu_path_dir))\n\n        return qemu_img_path"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _graphic(self):\n\n        if sys.platform.startswith(\"win\"):\n            return []\n        if len(os.environ.get(\"DISPLAY\", \"\")) > 0:\n            return []\n        if \"-nographic\" not in self._options:\n            return [\"-nographic\"]\n        return []", "response": "Returns a list of graphic options depending on the OS"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if we can run qemu with KVM", "response": "def _run_with_kvm(self, qemu_path, options):\n        \"\"\"\n        Check if we could run qemu with KVM\n\n        :param qemu_path: Path to qemu\n        :param options: String of qemu user options\n        :returns: Boolean True if we need to enable KVM\n        \"\"\"\n\n        if sys.platform.startswith(\"linux\") and self.manager.config.get_section_config(\"Qemu\").getboolean(\"enable_kvm\", True) \\\n                and \"-no-kvm\" not in options:\n\n            # Turn OFF kvm for non x86 architectures\n            if os.path.basename(qemu_path) not in [\"qemu-system-x86_64\", \"qemu-system-i386\", \"qemu-kvm\"]:\n                return False\n\n            if not os.path.exists(\"/dev/kvm\"):\n                if self.manager.config.get_section_config(\"Qemu\").getboolean(\"require_kvm\", True):\n                    raise QemuError(\"KVM acceleration cannot be used (/dev/kvm doesn't exist). You can turn off KVM support in the gns3_server.conf by adding enable_kvm = false to the [Qemu] section.\")\n                else:\n                    return False\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _build_command(self):\n\n        additional_options = self._options.strip()\n        additional_options = additional_options.replace(\"%vm-name%\", '\"' + self._name.replace('\"', '\\\\\"') + '\"')\n        additional_options = additional_options.replace(\"%vm-id%\", self._id)\n        additional_options = additional_options.replace(\"%project-id%\", self.project.id)\n        additional_options = additional_options.replace(\"%project-path%\", '\"' + self.project.path.replace('\"', '\\\\\"') + '\"')\n        command = [self.qemu_path]\n        command.extend([\"-name\", self._name])\n        command.extend([\"-m\", \"{}M\".format(self._ram)])\n        command.extend([\"-smp\", \"cpus={}\".format(self._cpus)])\n        if self._run_with_kvm(self.qemu_path, self._options):\n            command.extend([\"-enable-kvm\"])\n            version = yield from self.manager.get_qemu_version(self.qemu_path)\n            # Issue on some combo Intel CPU + KVM + Qemu 2.4.0\n            # https://github.com/GNS3/gns3-server/issues/685\n            if version and parse_version(version) >= parse_version(\"2.4.0\") and self.platform == \"x86_64\":\n                command.extend([\"-machine\", \"smm=off\"])\n        command.extend([\"-boot\", \"order={}\".format(self._boot_priority)])\n        command.extend(self._bios_option())\n        command.extend(self._cdrom_option())\n        command.extend((yield from self._disk_options()))\n        command.extend(self._linux_boot_options())\n        if \"-uuid\" not in additional_options:\n            command.extend([\"-uuid\", self._id])\n        if self._console_type == \"telnet\":\n            command.extend(self._serial_options())\n        elif self._console_type == \"vnc\":\n            command.extend(self._vnc_options())\n        elif self._console_type == \"spice\":\n            command.extend(self._spice_options())\n        else:\n            raise QemuError(\"Console type {} is unknown\".format(self._console_type))\n        command.extend(self._monitor_options())\n        command.extend((yield from self._network_options()))\n        command.extend(self._graphic())\n        if additional_options:\n            try:\n                command.extend(shlex.split(additional_options))\n            except ValueError as e:\n                raise QemuError(\"Invalid additional options: {} error {}\".format(additional_options, e))\n        return command", "response": "Build the command to start the QEMU process."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _setup_chassis(self):\n\n        self._create_slots(2)\n        self._slots[0] = self.integrated_adapters[self._chassis]()", "response": "Sets up the router with the corresponding chassis."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of engines supported by GNS3 for the GNS3VM .", "response": "def engine_list(self):\n        \"\"\"\n        :returns: Return list of engines supported by GNS3 for the GNS3VM\n        \"\"\"\n\n        download_url = \"https://github.com/GNS3/gns3-gui/releases/download/v{version}/GNS3.VM.VMware.Workstation.{version}.zip\".format(version=__version__)\n        vmware_informations = {\n            \"engine_id\": \"vmware\",\n            \"description\": 'VMware is the recommended choice for best performances.<br>The GNS3 VM can be <a href=\"{}\">downloaded here</a>.'.format(download_url),\n            \"support_when_exit\": True,\n            \"support_headless\": True,\n            \"support_ram\": True\n        }\n        if sys.platform.startswith(\"darwin\"):\n            vmware_informations[\"name\"] = \"VMware Fusion\"\n        else:\n            vmware_informations[\"name\"] = \"VMware Workstation / Player\"\n\n        download_url = \"https://github.com/GNS3/gns3-gui/releases/download/v{version}/GNS3.VM.VirtualBox.{version}.zip\".format(version=__version__)\n        virtualbox_informations = {\n            \"engine_id\": \"virtualbox\",\n            \"name\": \"VirtualBox\",\n            \"description\": 'VirtualBox doesn\\'t support nested virtualization, this means running Qemu based VM could be very slow.<br>The GNS3 VM can be <a href=\"{}\">downloaded here</a>'.format(download_url),\n            \"support_when_exit\": True,\n            \"support_headless\": True,\n            \"support_ram\": True\n        }\n\n        remote_informations = {\n            \"engine_id\": \"remote\",\n            \"name\": \"Remote\",\n            \"description\": \"Use a remote GNS3 server as the GNS3 VM.\",\n            \"support_when_exit\": False,\n            \"support_headless\": False,\n            \"support_ram\": False\n        }\n\n        return [\n            vmware_informations,\n            virtualbox_informations,\n            remote_informations\n        ]"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates the settings and will restart the VM if require is True", "response": "def update_settings(self, settings):\n        \"\"\"\n        Update settings and will restart the VM if require\n        \"\"\"\n        new_settings = copy.copy(self._settings)\n        new_settings.update(settings)\n        if self.settings != new_settings:\n            yield from self._stop()\n            self._settings = settings\n            self._controller.save()\n            if self.enable:\n                yield from self.start()\n        else:\n            # When user fix something on his system and try again\n            if self.enable and not self.current_engine().running:\n                yield from self.start()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload an engine from the GNS3 VM.", "response": "def _get_engine(self, engine):\n        \"\"\"\n        Load an engine\n        \"\"\"\n        if engine in self._engines:\n            return self._engines[engine]\n\n        if engine == \"vmware\":\n            self._engines[\"vmware\"] = VMwareGNS3VM(self._controller)\n            return self._engines[\"vmware\"]\n        elif engine == \"virtualbox\":\n            self._engines[\"virtualbox\"] = VirtualBoxGNS3VM(self._controller)\n            return self._engines[\"virtualbox\"]\n        elif engine == \"remote\":\n            self._engines[\"remote\"] = RemoteGNS3VM(self._controller)\n            return self._engines[\"remote\"]\n        raise NotImplementedError(\"The engine {} for the GNS3 VM is not supported\".format(engine))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlist VMS for an engine", "response": "def list(self, engine):\n        \"\"\"\n        List VMS for an engine\n        \"\"\"\n        engine = self._get_engine(engine)\n        vms = []\n        try:\n            for vm in (yield from engine.list()):\n                vms.append({\"vmname\": vm[\"vmname\"]})\n        except GNS3VMError as e:\n            # We raise error only if user activated the GNS3 VM\n            # otherwise you have noise when VMware is not installed\n            if self.enable:\n                raise e\n        return vms"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nstarting the GNS3 VM.", "response": "def start(self):\n        \"\"\"\n        Start the GNS3 VM\n        \"\"\"\n        engine = self.current_engine()\n        if not engine.running:\n            if self._settings[\"vmname\"] is None:\n                return\n            log.info(\"Start the GNS3 VM\")\n            engine.vmname = self._settings[\"vmname\"]\n            engine.ram = self._settings[\"ram\"]\n            engine.vcpus = self._settings[\"vcpus\"]\n            engine.headless = self._settings[\"headless\"]\n            compute = yield from self._controller.add_compute(compute_id=\"vm\",\n                                                              name=\"GNS3 VM is starting ({})\".format(engine.vmname),\n                                                              host=None,\n                                                              force=True,\n                                                              connect=False)\n\n            try:\n                yield from engine.start()\n            except Exception as e:\n                yield from self._controller.delete_compute(\"vm\")\n                log.error(\"Can't start the GNS3 VM: {}\".format(str(e)))\n                yield from compute.update(name=\"GNS3 VM ({})\".format(engine.vmname))\n                raise e\n            yield from compute.connect()  # we can connect now that the VM has started\n            yield from compute.update(name=\"GNS3 VM ({})\".format(engine.vmname),\n                                      protocol=self.protocol,\n                                      host=self.ip_address,\n                                      port=self.port,\n                                      user=self.user,\n                                      password=self.password)\n\n            # check if the VM is in the same subnet as the local server, start 10 seconds later to give\n            # some time for the compute in the VM to be ready for requests\n            asyncio.get_event_loop().call_later(10, lambda: asyncio.async(self._check_network(compute)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _check_network(self, compute):\n\n        try:\n            vm_interfaces = yield from compute.interfaces()\n            vm_interface_netmask = None\n            for interface in vm_interfaces:\n                if interface[\"ip_address\"] == self.ip_address:\n                    vm_interface_netmask = interface[\"netmask\"]\n                    break\n            if vm_interface_netmask:\n                vm_network = ipaddress.ip_interface(\"{}/{}\".format(compute.host_ip, vm_interface_netmask)).network\n                for compute_id in self._controller.computes:\n                    if compute_id == \"local\":\n                        compute = self._controller.get_compute(compute_id)\n                        interfaces = yield from compute.interfaces()\n                        netmask = None\n                        for interface in interfaces:\n                            if interface[\"ip_address\"] == compute.host_ip:\n                                netmask = interface[\"netmask\"]\n                                break\n                        if netmask:\n                            compute_network = ipaddress.ip_interface(\"{}/{}\".format(compute.host_ip, netmask)).network\n                            if vm_network.compare_networks(compute_network) != 0:\n                                msg = \"The GNS3 VM ({}) is not on the same network as the {} server ({}), please make sure the local server binding is in the same network as the GNS3 VM\".format(\n                                    vm_network, compute_id, compute_network)\n                                self._controller.notification.emit(\"log.warning\", {\"message\": msg})\n        except ComputeError as e:\n            log.warning(\"Could not check the VM is in the same subnet as the local server: {}\".format(e))", "response": "Check that the VM is in the same subnet as the local server."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _suspend(self):\n        engine = self.current_engine()\n        if \"vm\" in self._controller.computes:\n            yield from self._controller.delete_compute(\"vm\")\n        if engine.running:\n            log.info(\"Suspend the GNS3 VM\")\n            yield from engine.suspend()", "response": "Suspend the GNS3 VM"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nstop the GNS3 VM", "response": "def _stop(self):\n        \"\"\"\n        Stop the GNS3 VM\n        \"\"\"\n        engine = self.current_engine()\n        if \"vm\" in self._controller.computes:\n            yield from self._controller.delete_compute(\"vm\")\n        if engine.running:\n            log.info(\"Stop the GNS3 VM\")\n            yield from engine.stop()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _convert_before_2_0_0_b3(self, dynamips_id):\n        dynamips_dir = self.project.module_working_directory(self.manager.module_name.lower())\n        for path in glob.glob(os.path.join(glob.escape(dynamips_dir), \"configs\", \"i{}_*\".format(dynamips_id))):\n            dst = os.path.join(self._working_directory, \"configs\", os.path.basename(path))\n            if not os.path.exists(dst):\n                try:\n                    shutil.move(path, dst)\n                except OSError as e:\n                    raise DynamipsError(\"Can't move {}: {}\".format(path, str(e)))\n        for path in glob.glob(os.path.join(glob.escape(dynamips_dir), \"*_i{}_*\".format(dynamips_id))):\n            dst = os.path.join(self._working_directory, os.path.basename(path))\n            if not os.path.exists(dst):\n                try:\n                    shutil.move(path, dst)\n                except OSError as e:\n                    raise DynamipsError(\"Can't move {}: {}\".format(path, str(e)))", "response": "Convert the file from the node to the topology."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the status of this router.", "response": "def get_status(self):\n        \"\"\"\n        Returns the status of this router\n\n        :returns: inactive, shutting down, running or suspended.\n        \"\"\"\n\n        status = yield from self._hypervisor.send('vm get_status \"{name}\"'.format(name=self._name))\n        if len(status) == 0:\n            raise DynamipsError(\"Can't get vm {name} status\".format(name=self._name))\n        return self._status[int(status[0])]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef start(self):\n\n        status = yield from self.get_status()\n        if status == \"suspended\":\n            yield from self.resume()\n        elif status == \"inactive\":\n\n            if not os.path.isfile(self._image) or not os.path.exists(self._image):\n                if os.path.islink(self._image):\n                    raise DynamipsError('IOS image \"{}\" linked to \"{}\" is not accessible'.format(self._image, os.path.realpath(self._image)))\n                else:\n                    raise DynamipsError('IOS image \"{}\" is not accessible'.format(self._image))\n\n            try:\n                with open(self._image, \"rb\") as f:\n                    # read the first 7 bytes of the file.\n                    elf_header_start = f.read(7)\n            except OSError as e:\n                raise DynamipsError('Cannot read ELF header for IOS image \"{}\": {}'.format(self._image, e))\n\n            # IOS images must start with the ELF magic number, be 32-bit, big endian and have an ELF version of 1\n            if elf_header_start != b'\\x7fELF\\x01\\x02\\x01':\n                raise DynamipsError('\"{}\" is not a valid IOS image'.format(self._image))\n\n            # check if there is enough RAM to run\n            if not self._ghost_flag:\n                self.check_available_ram(self.ram)\n\n            # config paths are relative to the working directory configured on Dynamips hypervisor\n            startup_config_path = os.path.join(\"configs\", \"i{}_startup-config.cfg\".format(self._dynamips_id))\n            private_config_path = os.path.join(\"configs\", \"i{}_private-config.cfg\".format(self._dynamips_id))\n\n            if not os.path.exists(os.path.join(self._working_directory, private_config_path)) or \\\n               not os.path.getsize(os.path.join(self._working_directory, private_config_path)):\n                # an empty private-config can prevent a router to boot.\n                private_config_path = ''\n\n            yield from self._hypervisor.send('vm set_config \"{name}\" \"{startup}\" \"{private}\"'.format(\n                name=self._name,\n                startup=startup_config_path,\n                private=private_config_path))\n            yield from self._hypervisor.send('vm start \"{name}\"'.format(name=self._name))\n            self.status = \"started\"\n            log.info('router \"{name}\" [{id}] has been started'.format(name=self._name, id=self._id))\n\n            self._memory_watcher = FileWatcher(self._memory_files(), self._memory_changed, strategy='hash', delay=30)\n            monitor_process(self._hypervisor.process, self._termination_callback)", "response": "Starts this router.\n        At least the IOS image must be set before it can start."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalls when the process has stopped.", "response": "def _termination_callback(self, returncode):\n        \"\"\"\n        Called when the process has stopped.\n\n        :param returncode: Process returncode\n        \"\"\"\n\n        if self.status == \"started\":\n            self.status = \"stopped\"\n            log.info(\"Dynamips hypervisor process has stopped, return code: %d\", returncode)\n            if returncode != 0:\n                self.project.emit(\"log.error\", {\"message\": \"Dynamips hypervisor process has stopped, return code: {}\\n{}\".format(returncode, self._hypervisor.read_stdout())})"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the debug level for this router.", "response": "def set_debug_level(self, level):\n        \"\"\"\n        Sets the debug level for this router (default is 0).\n\n        :param level: level number\n        \"\"\"\n\n        yield from self._hypervisor.send('vm set_debug_level \"{name}\" {level}'.format(name=self._name, level=level))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the IOS image for this router.", "response": "def set_image(self, image):\n        \"\"\"\n        Sets the IOS image for this router.\n        There is no default.\n\n        :param image: path to IOS image file\n        \"\"\"\n\n        image = self.manager.get_abs_image_path(image)\n\n        yield from self._hypervisor.send('vm set_ios \"{name}\" \"{image}\"'.format(name=self._name, image=image))\n\n        log.info('Router \"{name}\" [{id}]: has a new IOS image set: \"{image}\"'.format(name=self._name,\n                                                                                     id=self._id,\n                                                                                     image=image))\n\n        self._image = image"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets amount of RAM allocated to this router.", "response": "def set_ram(self, ram):\n        \"\"\"\n        Sets amount of RAM allocated to this router\n\n        :param ram: amount of RAM in Mbytes (integer)\n        \"\"\"\n\n        if self._ram == ram:\n            return\n\n        yield from self._hypervisor.send('vm set_ram \"{name}\" {ram}'.format(name=self._name, ram=ram))\n        log.info('Router \"{name}\" [{id}]: RAM updated from {old_ram}MB to {new_ram}MB'.format(name=self._name,\n                                                                                              id=self._id,\n                                                                                              old_ram=self._ram,\n                                                                                              new_ram=ram))\n        self._ram = ram"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_nvram(self, nvram):\n\n        if self._nvram == nvram:\n            return\n\n        yield from self._hypervisor.send('vm set_nvram \"{name}\" {nvram}'.format(name=self._name, nvram=nvram))\n        log.info('Router \"{name}\" [{id}]: NVRAM updated from {old_nvram}KB to {new_nvram}KB'.format(name=self._name,\n                                                                                                    id=self._id,\n                                                                                                    old_nvram=self._nvram,\n                                                                                                    new_nvram=nvram))\n        self._nvram = nvram", "response": "Sets the amount of NVRAM allocated to this router."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the memory mapping for this router.", "response": "def set_mmap(self, mmap):\n        \"\"\"\n        Enable/Disable use of a mapped file to simulate router memory.\n        By default, a mapped file is used. This is a bit slower, but requires less memory.\n\n        :param mmap: activate/deactivate mmap (boolean)\n        \"\"\"\n\n        if mmap:\n            flag = 1\n        else:\n            flag = 0\n\n        yield from self._hypervisor.send('vm set_ram_mmap \"{name}\" {mmap}'.format(name=self._name, mmap=flag))\n\n        if mmap:\n            log.info('Router \"{name}\" [{id}]: mmap enabled'.format(name=self._name, id=self._id))\n        else:\n            log.info('Router \"{name}\" [{id}]: mmap disabled'.format(name=self._name, id=self._id))\n        self._mmap = mmap"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_sparsemem(self, sparsemem):\n\n        if sparsemem:\n            flag = 1\n        else:\n            flag = 0\n        yield from self._hypervisor.send('vm set_sparse_mem \"{name}\" {sparsemem}'.format(name=self._name, sparsemem=flag))\n\n        if sparsemem:\n            log.info('Router \"{name}\" [{id}]: sparse memory enabled'.format(name=self._name, id=self._id))\n        else:\n            log.info('Router \"{name}\" [{id}]: sparse memory disabled'.format(name=self._name, id=self._id))\n        self._sparsemem = sparsemem", "response": "Sets the sparse memory for this router."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_clock_divisor(self, clock_divisor):\n\n        yield from self._hypervisor.send('vm set_clock_divisor \"{name}\" {clock}'.format(name=self._name, clock=clock_divisor))\n        log.info('Router \"{name}\" [{id}]: clock divisor updated from {old_clock} to {new_clock}'.format(name=self._name,\n                                                                                                        id=self._id,\n                                                                                                        old_clock=self._clock_divisor,\n                                                                                                        new_clock=clock_divisor))\n        self._clock_divisor = clock_divisor", "response": "Sets the clock divisor value."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the idle PC value.", "response": "def set_idlepc(self, idlepc):\n        \"\"\"\n        Sets the idle Pointer Counter (PC)\n\n        :param idlepc: idlepc value (string)\n        \"\"\"\n\n        if not idlepc:\n            idlepc = \"0x0\"\n\n        is_running = yield from self.is_running()\n        if not is_running:\n            # router is not running\n            yield from self._hypervisor.send('vm set_idle_pc \"{name}\" {idlepc}'.format(name=self._name, idlepc=idlepc))\n        else:\n            yield from self._hypervisor.send('vm set_idle_pc_online \"{name}\" 0 {idlepc}'.format(name=self._name, idlepc=idlepc))\n\n        log.info('Router \"{name}\" [{id}]: idle-PC set to {idlepc}'.format(name=self._name, id=self._id, idlepc=idlepc))\n        self._idlepc = idlepc"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_idle_pc_prop(self):\n\n        is_running = yield from self.is_running()\n        was_auto_started = False\n        if not is_running:\n            yield from self.start()\n            was_auto_started = True\n            yield from asyncio.sleep(20)  # leave time to the router to boot\n\n        log.info('Router \"{name}\" [{id}] has started calculating Idle-PC values'.format(name=self._name, id=self._id))\n        begin = time.time()\n        idlepcs = yield from self._hypervisor.send('vm get_idle_pc_prop \"{}\" 0'.format(self._name))\n        log.info('Router \"{name}\" [{id}] has finished calculating Idle-PC values after {time:.4f} seconds'.format(name=self._name,\n                                                                                                                  id=self._id,\n                                                                                                                  time=time.time() - begin))\n        if was_auto_started:\n            yield from self.stop()\n        return idlepcs", "response": "Gets the idle PC proposals."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef show_idle_pc_prop(self):\n\n        is_running = yield from self.is_running()\n        if not is_running:\n            # router is not running\n            raise DynamipsError('Router \"{name}\" is not running'.format(name=self._name))\n\n        proposals = yield from self._hypervisor.send('vm show_idle_pc_prop \"{}\" 0'.format(self._name))\n        return proposals", "response": "Dumps the idle PC proposals ( previously generated."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the idle max value for the CPU.", "response": "def set_idlemax(self, idlemax):\n        \"\"\"\n        Sets CPU idle max value\n\n        :param idlemax: idle max value (integer)\n        \"\"\"\n\n        is_running = yield from self.is_running()\n        if is_running:  # router is running\n            yield from self._hypervisor.send('vm set_idle_max \"{name}\" 0 {idlemax}'.format(name=self._name, idlemax=idlemax))\n\n        log.info('Router \"{name}\" [{id}]: idlemax updated from {old_idlemax} to {new_idlemax}'.format(name=self._name,\n                                                                                                      id=self._id,\n                                                                                                      old_idlemax=self._idlemax,\n                                                                                                      new_idlemax=idlemax))\n\n        self._idlemax = idlemax"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_idlesleep(self, idlesleep):\n\n        is_running = yield from self.is_running()\n        if is_running:  # router is running\n            yield from self._hypervisor.send('vm set_idle_sleep_time \"{name}\" 0 {idlesleep}'.format(name=self._name,\n                                                                                                    idlesleep=idlesleep))\n\n        log.info('Router \"{name}\" [{id}]: idlesleep updated from {old_idlesleep} to {new_idlesleep}'.format(name=self._name,\n                                                                                                            id=self._id,\n                                                                                                            old_idlesleep=self._idlesleep,\n                                                                                                            new_idlesleep=idlesleep))\n\n        self._idlesleep = idlesleep", "response": "Sets CPU idle sleep time value."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the ghost file for this router.", "response": "def set_ghost_file(self, ghost_file):\n        \"\"\"\n        Sets ghost RAM file\n\n        :ghost_file: path to ghost file\n        \"\"\"\n\n        yield from self._hypervisor.send('vm set_ghost_file \"{name}\" {ghost_file}'.format(name=self._name,\n                                                                                          ghost_file=shlex.quote(ghost_file)))\n\n        log.info('Router \"{name}\" [{id}]: ghost file set to {ghost_file}'.format(name=self._name,\n                                                                                 id=self._id,\n                                                                                 ghost_file=ghost_file))\n\n        self._ghost_file = ghost_file"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a properly formatted ghost file name.", "response": "def formatted_ghost_file(self):\n        \"\"\"\n        Returns a properly formatted ghost file name.\n\n        :returns: formatted ghost_file name (string)\n        \"\"\"\n\n        # replace specials characters in 'drive:\\filename' in Linux and Dynamips in MS Windows or viceversa.\n        ghost_file = \"{}-{}.ghost\".format(os.path.basename(self._image), self._ram)\n        ghost_file = ghost_file.replace('\\\\', '-').replace('/', '-').replace(':', '-')\n        return ghost_file"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_ghost_status(self, ghost_status):\n\n        yield from self._hypervisor.send('vm set_ghost_status \"{name}\" {ghost_status}'.format(name=self._name,\n                                                                                              ghost_status=ghost_status))\n\n        log.info('Router \"{name}\" [{id}]: ghost status set to {ghost_status}'.format(name=self._name,\n                                                                                     id=self._id,\n                                                                                     ghost_status=ghost_status))\n        self._ghost_status = ghost_status", "response": "Sets the ghost status of the current router."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the exec area value.", "response": "def set_exec_area(self, exec_area):\n        \"\"\"\n        Sets the exec area value.\n        The exec area is a pool of host memory used to store pages\n        translated by the JIT (they contain the native code\n        corresponding to MIPS code pages).\n\n        :param exec_area: exec area value (integer)\n        \"\"\"\n\n        yield from self._hypervisor.send('vm set_exec_area \"{name}\" {exec_area}'.format(name=self._name,\n                                                                                        exec_area=exec_area))\n\n        log.info('Router \"{name}\" [{id}]: exec area updated from {old_exec}MB to {new_exec}MB'.format(name=self._name,\n                                                                                                      id=self._id,\n                                                                                                      old_exec=self._exec_area,\n                                                                                                      new_exec=exec_area))\n        self._exec_area = exec_area"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_disk0(self, disk0):\n\n        yield from self._hypervisor.send('vm set_disk0 \"{name}\" {disk0}'.format(name=self._name, disk0=disk0))\n\n        log.info('Router \"{name}\" [{id}]: disk0 updated from {old_disk0}MB to {new_disk0}MB'.format(name=self._name,\n                                                                                                    id=self._id,\n                                                                                                    old_disk0=self._disk0,\n                                                                                                    new_disk0=disk0))\n        self._disk0 = disk0", "response": "Sets the size of the PCMCIA disk0."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the size of PCMCIA disk1.", "response": "def set_disk1(self, disk1):\n        \"\"\"\n        Sets the size (MB) for PCMCIA disk1.\n\n        :param disk1: disk1 size (integer)\n        \"\"\"\n\n        yield from self._hypervisor.send('vm set_disk1 \"{name}\" {disk1}'.format(name=self._name, disk1=disk1))\n\n        log.info('Router \"{name}\" [{id}]: disk1 updated from {old_disk1}MB to {new_disk1}MB'.format(name=self._name,\n                                                                                                    id=self._id,\n                                                                                                    old_disk1=self._disk1,\n                                                                                                    new_disk1=disk1))\n        self._disk1 = disk1"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting auto delete disks on the related resource.", "response": "def set_auto_delete_disks(self, auto_delete_disks):\n        \"\"\"\n        Enable/disable use of auto delete disks\n\n        :param auto_delete_disks: activate/deactivate auto delete disks (boolean)\n        \"\"\"\n\n        if auto_delete_disks:\n            log.info('Router \"{name}\" [{id}]: auto delete disks enabled'.format(name=self._name, id=self._id))\n        else:\n            log.info('Router \"{name}\" [{id}]: auto delete disks disabled'.format(name=self._name, id=self._id))\n        self._auto_delete_disks = auto_delete_disks"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_console(self, console):\n\n        self.console = console\n        yield from self._hypervisor.send('vm set_con_tcp_port \"{name}\" {console}'.format(name=self._name, console=self.console))", "response": "Sets the TCP console port."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the TCP auxiliary port.", "response": "def set_aux(self, aux):\n        \"\"\"\n        Sets the TCP auxiliary port.\n\n        :param aux: console auxiliary port (integer)\n        \"\"\"\n\n        self.aux = aux\n        yield from self._hypervisor.send('vm set_aux_tcp_port \"{name}\" {aux}'.format(name=self._name, aux=aux))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the CPU usage in seconds.", "response": "def get_cpu_usage(self, cpu_id=0):\n        \"\"\"\n        Shows cpu usage in seconds, \"cpu_id\" is ignored.\n\n        :returns: cpu usage in seconds\n        \"\"\"\n\n        cpu_usage = yield from self._hypervisor.send('vm cpu_usage \"{name}\" {cpu_id}'.format(name=self._name, cpu_id=cpu_id))\n        return int(cpu_usage[0])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the MAC address of the current resource.", "response": "def set_mac_addr(self, mac_addr):\n        \"\"\"\n        Sets the MAC address.\n\n        :param mac_addr: a MAC address (hexadecimal format: hh:hh:hh:hh:hh:hh)\n        \"\"\"\n\n        yield from self._hypervisor.send('{platform} set_mac_addr \"{name}\" {mac_addr}'.format(platform=self._platform,\n                                                                                              name=self._name,\n                                                                                              mac_addr=mac_addr))\n\n        log.info('Router \"{name}\" [{id}]: MAC address updated from {old_mac} to {new_mac}'.format(name=self._name,\n                                                                                                  id=self._id,\n                                                                                                  old_mac=self._mac_addr,\n                                                                                                  new_mac=mac_addr))\n        self._mac_addr = mac_addr"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_system_id(self, system_id):\n\n        yield from self._hypervisor.send('{platform} set_system_id \"{name}\" {system_id}'.format(platform=self._platform,\n                                                                                                name=self._name,\n                                                                                                system_id=system_id))\n\n        log.info('Router \"{name}\" [{id}]: system ID updated from {old_id} to {new_id}'.format(name=self._name,\n                                                                                              id=self._id,\n                                                                                              old_id=self._system_id,\n                                                                                              new_id=system_id))\n        self._system_id = system_id", "response": "Sets the system ID of the router."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the slot bindings.", "response": "def get_slot_bindings(self):\n        \"\"\"\n        Returns slot bindings.\n\n        :returns: slot bindings (adapter names) list\n        \"\"\"\n\n        slot_bindings = yield from self._hypervisor.send('vm slot_bindings \"{}\"'.format(self._name))\n        return slot_bindings"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a slot binding to a router.", "response": "def slot_add_binding(self, slot_number, adapter):\n        \"\"\"\n        Adds a slot binding (a module into a slot).\n\n        :param slot_number: slot number\n        :param adapter: device to add in the corresponding slot\n        \"\"\"\n\n        try:\n            slot = self._slots[slot_number]\n        except IndexError:\n            raise DynamipsError('Slot {slot_number} does not exist on router \"{name}\"'.format(name=self._name, slot_number=slot_number))\n\n        if slot is not None:\n            current_adapter = slot\n            raise DynamipsError('Slot {slot_number} is already occupied by adapter {adapter} on router \"{name}\"'.format(name=self._name,\n                                                                                                                        slot_number=slot_number,\n                                                                                                                        adapter=current_adapter))\n\n        is_running = yield from self.is_running()\n\n        # Only c7200, c3600 and c3745 (NM-4T only) support new adapter while running\n        if is_running and not ((self._platform == 'c7200' and not str(adapter).startswith('C7200'))\n                               and not (self._platform == 'c3600' and self.chassis == '3660')\n                               and not (self._platform == 'c3745' and adapter == 'NM-4T')):\n            raise DynamipsError('Adapter {adapter} cannot be added while router \"{name}\" is running'.format(adapter=adapter,\n                                                                                                            name=self._name))\n\n        yield from self._hypervisor.send('vm slot_add_binding \"{name}\" {slot_number} 0 {adapter}'.format(name=self._name,\n                                                                                                         slot_number=slot_number,\n                                                                                                         adapter=adapter))\n\n        log.info('Router \"{name}\" [{id}]: adapter {adapter} inserted into slot {slot_number}'.format(name=self._name,\n                                                                                                     id=self._id,\n                                                                                                     adapter=adapter,\n                                                                                                     slot_number=slot_number))\n\n        self._slots[slot_number] = adapter\n\n        # Generate an OIR event if the router is running\n        if is_running:\n\n            yield from self._hypervisor.send('vm slot_oir_start \"{name}\" {slot_number} 0'.format(name=self._name,\n                                                                                                 slot_number=slot_number))\n\n            log.info('Router \"{name}\" [{id}]: OIR start event sent to slot {slot_number}'.format(name=self._name,\n                                                                                                 id=self._id,\n                                                                                                 slot_number=slot_number))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_slot_nio_bindings(self, slot_number):\n\n        nio_bindings = yield from self._hypervisor.send('vm slot_nio_bindings \"{name}\" {slot_number}'.format(name=self._name,\n                                                                                                             slot_number=slot_number))\n        return nio_bindings", "response": "Returns the NIO bindings for the specified slot."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef slot_add_nio_binding(self, slot_number, port_number, nio):\n\n        try:\n            adapter = self._slots[slot_number]\n        except IndexError:\n            raise DynamipsError('Slot {slot_number} does not exist on router \"{name}\"'.format(name=self._name,\n                                                                                              slot_number=slot_number))\n\n        if adapter is None:\n            raise DynamipsError(\"Adapter is missing in slot {slot_number}\".format(slot_number=slot_number))\n\n        if not adapter.port_exists(port_number):\n            raise DynamipsError(\"Port {port_number} does not exist in adapter {adapter}\".format(adapter=adapter,\n                                                                                                port_number=port_number))\n\n        try:\n            yield from self._hypervisor.send('vm slot_add_nio_binding \"{name}\" {slot_number} {port_number} {nio}'.format(name=self._name,\n                                                                                                                         slot_number=slot_number,\n                                                                                                                         port_number=port_number,\n                                                                                                                         nio=nio))\n        except DynamipsError:\n            # in case of error try to remove and add the nio binding\n            yield from self._hypervisor.send('vm slot_remove_nio_binding \"{name}\" {slot_number} {port_number}'.format(name=self._name,\n                                                                                                                      slot_number=slot_number,\n                                                                                                                      port_number=port_number))\n            yield from self._hypervisor.send('vm slot_add_nio_binding \"{name}\" {slot_number} {port_number} {nio}'.format(name=self._name,\n                                                                                                                         slot_number=slot_number,\n                                                                                                                         port_number=port_number,\n                                                                                                                         nio=nio))\n\n        log.info('Router \"{name}\" [{id}]: NIO {nio_name} bound to port {slot_number}/{port_number}'.format(name=self._name,\n                                                                                                           id=self._id,\n                                                                                                           nio_name=nio.name,\n                                                                                                           slot_number=slot_number,\n                                                                                                           port_number=port_number))\n\n        yield from self.slot_enable_nio(slot_number, port_number)\n        adapter.add_nio(port_number, nio)", "response": "Adds a slot NIO binding."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove a slot NIO binding.", "response": "def slot_remove_nio_binding(self, slot_number, port_number):\n        \"\"\"\n        Removes a slot NIO binding.\n\n        :param slot_number: slot number\n        :param port_number: port number\n\n        :returns: removed NIO instance\n        \"\"\"\n\n        try:\n            adapter = self._slots[slot_number]\n        except IndexError:\n            raise DynamipsError('Slot {slot_number} does not exist on router \"{name}\"'.format(name=self._name,\n                                                                                              slot_number=slot_number))\n\n        if adapter is None:\n            raise DynamipsError(\"Adapter is missing in slot {slot_number}\".format(slot_number=slot_number))\n\n        if not adapter.port_exists(port_number):\n            raise DynamipsError(\"Port {port_number} does not exist in adapter {adapter}\".format(adapter=adapter,\n                                                                                                port_number=port_number))\n\n        yield from self.slot_disable_nio(slot_number, port_number)\n        yield from self._hypervisor.send('vm slot_remove_nio_binding \"{name}\" {slot_number} {port_number}'.format(name=self._name,\n                                                                                                                  slot_number=slot_number,\n                                                                                                                  port_number=port_number))\n\n        nio = adapter.get_nio(port_number)\n        if nio is None:\n            return\n        yield from nio.close()\n        adapter.remove_nio(port_number)\n\n        log.info('Router \"{name}\" [{id}]: NIO {nio_name} removed from port {slot_number}/{port_number}'.format(name=self._name,\n                                                                                                               id=self._id,\n                                                                                                               nio_name=nio.name,\n                                                                                                               slot_number=slot_number,\n                                                                                                               port_number=port_number))\n\n        return nio"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nenables a slot NIO binding.", "response": "def slot_enable_nio(self, slot_number, port_number):\n        \"\"\"\n        Enables a slot NIO binding.\n\n        :param slot_number: slot number\n        :param port_number: port number\n        \"\"\"\n\n        is_running = yield from self.is_running()\n        if is_running:  # running router\n            yield from self._hypervisor.send('vm slot_enable_nio \"{name}\" {slot_number} {port_number}'.format(name=self._name,\n                                                                                                              slot_number=slot_number,\n                                                                                                              port_number=port_number))\n\n            log.info('Router \"{name}\" [{id}]: NIO enabled on port {slot_number}/{port_number}'.format(name=self._name,\n                                                                                                      id=self._id,\n                                                                                                      slot_number=slot_number,\n                                                                                                      port_number=port_number))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef start_capture(self, slot_number, port_number, output_file, data_link_type=\"DLT_EN10MB\"):\n\n        try:\n            open(output_file, 'w+').close()\n        except OSError as e:\n            raise DynamipsError('Can not write capture to \"{}\": {}'.format(output_file, str(e)))\n\n        try:\n            adapter = self._slots[slot_number]\n        except IndexError:\n            raise DynamipsError('Slot {slot_number} does not exist on router \"{name}\"'.format(name=self._name,\n                                                                                              slot_number=slot_number))\n        if not adapter.port_exists(port_number):\n            raise DynamipsError(\"Port {port_number} does not exist in adapter {adapter}\".format(adapter=adapter,\n                                                                                                port_number=port_number))\n\n        data_link_type = data_link_type.lower()\n        if data_link_type.startswith(\"dlt_\"):\n            data_link_type = data_link_type[4:]\n\n        nio = adapter.get_nio(port_number)\n\n        if not nio:\n            raise DynamipsError(\"Port {slot_number}/{port_number} is not connected\".format(slot_number=slot_number,\n                                                                                           port_number=port_number))\n\n        if nio.input_filter[0] is not None and nio.output_filter[0] is not None:\n            raise DynamipsError(\"Port {port_number} has already a filter applied on {adapter}\".format(adapter=adapter,\n                                                                                                      port_number=port_number))\n\n        yield from nio.bind_filter(\"both\", \"capture\")\n        yield from nio.setup_filter(\"both\", '{} \"{}\"'.format(data_link_type, output_file))\n\n        log.info('Router \"{name}\" [{id}]: starting packet capture on port {slot_number}/{port_number}'.format(name=self._name,\n                                                                                                              id=self._id,\n                                                                                                              nio_name=nio.name,\n                                                                                                              slot_number=slot_number,\n                                                                                                              port_number=port_number))", "response": "Start a packet capture."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nstopping a packet capture.", "response": "def stop_capture(self, slot_number, port_number):\n        \"\"\"\n        Stops a packet capture.\n\n        :param slot_number: slot number\n        :param port_number: port number\n        \"\"\"\n\n        try:\n            adapter = self._slots[slot_number]\n        except IndexError:\n            raise DynamipsError('Slot {slot_number} does not exist on router \"{name}\"'.format(name=self._name,\n                                                                                              slot_number=slot_number))\n        if not adapter.port_exists(port_number):\n            raise DynamipsError(\"Port {port_number} does not exist in adapter {adapter}\".format(adapter=adapter,\n                                                                                                port_number=port_number))\n\n        nio = adapter.get_nio(port_number)\n\n        if not nio:\n            raise DynamipsError(\"Port {slot_number}/{port_number} is not connected\".format(slot_number=slot_number,\n                                                                                           port_number=port_number))\n\n        yield from nio.unbind_filter(\"both\")\n\n        log.info('Router \"{name}\" [{id}]: stopping packet capture on port {slot_number}/{port_number}'.format(name=self._name,\n                                                                                                              id=self._id,\n                                                                                                              nio_name=nio.name,\n                                                                                                              slot_number=slot_number,\n                                                                                                              port_number=port_number))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef startup_config_path(self):\n        return os.path.join(self._working_directory, \"configs\", \"i{}_startup-config.cfg\".format(self._dynamips_id))", "response": "Returns the path of the startup config file for the current instance of the resource."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the path of the private config file for the given resource.", "response": "def private_config_path(self):\n        \"\"\"\n        :returns: Path of the private config\n        \"\"\"\n        return os.path.join(self._working_directory, \"configs\", \"i{}_private-config.cfg\".format(self._dynamips_id))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_name(self, new_name):\n\n        # change the hostname in the startup-config\n        if os.path.isfile(self.startup_config_path):\n            try:\n                with open(self.startup_config_path, \"r+\", encoding=\"utf-8\", errors=\"replace\") as f:\n                    old_config = f.read()\n                    new_config = re.sub(r\"^hostname .+$\", \"hostname \" + new_name, old_config, flags=re.MULTILINE)\n                    f.seek(0)\n                    f.write(new_config)\n            except OSError as e:\n                raise DynamipsError(\"Could not amend the configuration {}: {}\".format(self.startup_config_path, e))\n\n        # change the hostname in the private-config\n        if os.path.isfile(self.private_config_path):\n            try:\n                with open(self.private_config_path, \"r+\", encoding=\"utf-8\", errors=\"replace\") as f:\n                    old_config = f.read()\n                    new_config = old_config.replace(self.name, new_name)\n                    f.seek(0)\n                    f.write(new_config)\n            except OSError as e:\n                raise DynamipsError(\"Could not amend the configuration {}: {}\".format(self.private_config_path, e))\n\n        yield from self._hypervisor.send('vm rename \"{name}\" \"{new_name}\"'.format(name=self._name, new_name=new_name))\n        log.info('Router \"{name}\" [{id}]: renamed to \"{new_name}\"'.format(name=self._name, id=self._id, new_name=new_name))\n        self._name = new_name", "response": "Renames this router.\n\n        :param new_name: new name string"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nextracting the contents of the config files and returns the base64 encoded startup - config and private - config.", "response": "def extract_config(self):\n        \"\"\"\n        Gets the contents of the config files\n        startup-config and private-config from NVRAM.\n\n        :returns: tuple (startup-config, private-config) base64 encoded\n        \"\"\"\n\n        try:\n            reply = yield from self._hypervisor.send('vm extract_config \"{}\"'.format(self._name))\n        except DynamipsError:\n            # for some reason Dynamips gets frozen when it does not find the magic number in the NVRAM file.\n            return None, None\n        reply = reply[0].rsplit(' ', 2)[-2:]\n        startup_config = reply[0][1:-1]  # get statup-config and remove single quotes\n        private_config = reply[1][1:-1]  # get private-config and remove single quotes\n        return startup_config, private_config"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef save_configs(self):\n\n        try:\n            config_path = os.path.join(self._working_directory, \"configs\")\n            os.makedirs(config_path, exist_ok=True)\n        except OSError as e:\n            raise DynamipsError(\"Could could not create configuration directory {}: {}\".format(config_path, e))\n\n        startup_config_base64, private_config_base64 = yield from self.extract_config()\n        if startup_config_base64:\n            startup_config = self.startup_config_path\n            try:\n                config = base64.b64decode(startup_config_base64).decode(\"utf-8\", errors=\"replace\")\n                config = \"!\\n\" + config.replace(\"\\r\", \"\")\n                config_path = os.path.join(self._working_directory, startup_config)\n                with open(config_path, \"wb\") as f:\n                    log.info(\"saving startup-config to {}\".format(startup_config))\n                    f.write(config.encode(\"utf-8\"))\n            except (binascii.Error, OSError) as e:\n                raise DynamipsError(\"Could not save the startup configuration {}: {}\".format(config_path, e))\n\n        if private_config_base64 and base64.b64decode(private_config_base64) != b'\\nkerberos password \\nend\\n':\n            private_config = self.private_config_path\n            try:\n                config = base64.b64decode(private_config_base64).decode(\"utf-8\", errors=\"replace\")\n                config_path = os.path.join(self._working_directory, private_config)\n                with open(config_path, \"wb\") as f:\n                    log.info(\"saving private-config to {}\".format(private_config))\n                    f.write(config.encode(\"utf-8\"))\n            except (binascii.Error, OSError) as e:\n                raise DynamipsError(\"Could not save the private configuration {}: {}\".format(config_path, e))", "response": "Saves the startup - config and private - config to files."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete(self):\n        try:\n            yield from wait_run_in_executor(shutil.rmtree, self._working_directory)\n        except OSError as e:\n            log.warn(\"Could not delete file {}\".format(e))\n\n        self.manager.release_dynamips_id(self._project.id, self._dynamips_id)", "response": "Delete this VM (including all its files)."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef clean_delete(self):\n\n        yield from self._hypervisor.send('vm clean_delete \"{}\"'.format(self._name))\n        self._hypervisor.devices.remove(self)\n        try:\n            yield from wait_run_in_executor(shutil.rmtree, self._working_directory)\n        except OSError as e:\n            log.warn(\"Could not delete file {}\".format(e))\n        log.info('Router \"{name}\" [{id}] has been deleted (including associated files)'.format(name=self._name, id=self._id))", "response": "Deletes this router & associated files."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_version(version):\n\n    release_type_found = False\n    version_infos = re.split('(\\.|[a-z]+)', version)\n    version = []\n    for info in version_infos:\n        if info == '.' or len(info) == 0:\n            continue\n        try:\n            info = int(info)\n            # We pad with zero to compare only on string\n            # This avoid issue when comparing version with different length\n            version.append(\"%06d\" % (info,))\n        except ValueError:\n            # Force to a version with three number\n            if len(version) == 1:\n                version.append(\"00000\")\n            if len(version) == 2:\n                version.append(\"000000\")\n            # We want rc to be at lower level than dev version\n            if info == 'rc':\n                info = 'c'\n            version.append(info)\n            release_type_found = True\n    if release_type_found is False:\n        # Force to a version with three number\n        if len(version) == 1:\n            version.append(\"00000\")\n        if len(version) == 2:\n            version.append(\"000000\")\n        version.append(\"final\")\n    return tuple(version)", "response": "Parse a version string into a comparable tuple."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_state(self):\n\n        result = yield from self._execute(\"showvminfo\", [self._vmname, \"--machinereadable\"])\n        for info in result.splitlines():\n            if '=' in info:\n                name, value = info.split('=', 1)\n                if name == \"VMState\":\n                    return value.strip('\"')\n        return \"unknown\"", "response": "Returns the VM state of the current user."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlook for an interface with a specific network backend.", "response": "def _look_for_interface(self, network_backend):\n        \"\"\"\n        Look for an interface with a specific network backend.\n\n        :returns: interface number or -1 if none is found\n        \"\"\"\n\n        result = yield from self._execute(\"showvminfo\", [self._vmname, \"--machinereadable\"])\n        interface = -1\n        for info in result.splitlines():\n            if '=' in info:\n                name, value = info.split('=', 1)\n                if name.startswith(\"nic\") and value.strip('\"') == network_backend:\n                    try:\n                        interface = int(name[3:])\n                        break\n                    except ValueError:\n                        continue\n        return interface"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nlook for the VirtualBox network name associated with a host only interface.", "response": "def _look_for_vboxnet(self, interface_number):\n        \"\"\"\n        Look for the VirtualBox network name associated with a host only interface.\n\n        :returns: None or vboxnet name\n        \"\"\"\n\n        result = yield from self._execute(\"showvminfo\", [self._vmname, \"--machinereadable\"])\n        for info in result.splitlines():\n            if '=' in info:\n                name, value = info.split('=', 1)\n                if name == \"hostonlyadapter{}\".format(interface_number):\n                    return value.strip('\"')\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _check_dhcp_server(self, vboxnet):\n\n        properties = yield from self._execute(\"list\", [\"dhcpservers\"])\n        flag_dhcp_server_found = False\n        for prop in properties.splitlines():\n            try:\n                name, value = prop.split(':', 1)\n            except ValueError:\n                continue\n            if name.strip() == \"NetworkName\" and value.strip().endswith(vboxnet):\n                flag_dhcp_server_found = True\n            if flag_dhcp_server_found and name.strip() == \"Enabled\":\n                if value.strip() == \"Yes\":\n                    return True\n        return False", "response": "Check if the DHCP server associated with a vboxnet is enabled."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if the NAT port forwarding rule exists.", "response": "def _check_vbox_port_forwarding(self):\n        \"\"\"\n        Checks if the NAT port forwarding rule exists.\n\n        :returns: boolean\n        \"\"\"\n\n        result = yield from self._execute(\"showvminfo\", [self._vmname, \"--machinereadable\"])\n        for info in result.splitlines():\n            if '=' in info:\n                name, value = info.split('=', 1)\n                if name.startswith(\"Forwarding\") and value.strip('\"').startswith(\"GNS3VM\"):\n                    return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nstart the GNS3 VM.", "response": "def start(self):\n        \"\"\"\n        Start the GNS3 VM.\n        \"\"\"\n\n        # get a NAT interface number\n        nat_interface_number = yield from self._look_for_interface(\"nat\")\n        if nat_interface_number < 0:\n            raise GNS3VMError(\"The GNS3 VM: {} must have a NAT interface configured in order to start\".format(self.vmname))\n\n        hostonly_interface_number = yield from self._look_for_interface(\"hostonly\")\n        if hostonly_interface_number < 0:\n            raise GNS3VMError(\"The GNS3 VM: {} must have a host only interface configured in order to start\".format(self.vmname))\n\n        vboxnet = yield from self._look_for_vboxnet(hostonly_interface_number)\n        if vboxnet is None:\n            raise GNS3VMError(\"VirtualBox host-only network could not be found for interface {} on GNS3 VM\".format(hostonly_interface_number))\n\n        if not (yield from self._check_dhcp_server(vboxnet)):\n            raise GNS3VMError(\"DHCP must be enabled on VirtualBox host-only network: {} for GNS3 VM\".format(vboxnet))\n\n        vm_state = yield from self._get_state()\n        log.info('\"{}\" state is {}'.format(self._vmname, vm_state))\n\n        if vm_state == \"poweroff\":\n            yield from self.set_vcpus(self.vcpus)\n            yield from self.set_ram(self.ram)\n\n        if vm_state in (\"poweroff\", \"saved\"):\n            # start the VM if it is not running\n            args = [self._vmname]\n            if self._headless:\n                args.extend([\"--type\", \"headless\"])\n            yield from self._execute(\"startvm\", args)\n        elif vm_state == \"paused\":\n            args = [self._vmname, \"resume\"]\n            yield from self._execute(\"controlvm\", args)\n        ip_address = \"127.0.0.1\"\n        try:\n            # get a random port on localhost\n            with socket.socket() as s:\n                s.bind((ip_address, 0))\n                api_port = s.getsockname()[1]\n        except OSError as e:\n            raise GNS3VMError(\"Error while getting random port: {}\".format(e))\n\n        if (yield from self._check_vbox_port_forwarding()):\n            # delete the GNS3VM NAT port forwarding rule if it exists\n            log.info(\"Removing GNS3VM NAT port forwarding rule from interface {}\".format(nat_interface_number))\n            yield from self._execute(\"controlvm\", [self._vmname, \"natpf{}\".format(nat_interface_number), \"delete\", \"GNS3VM\"])\n\n        # add a GNS3VM NAT port forwarding rule to redirect 127.0.0.1 with random port to port 3080 in the VM\n        log.info(\"Adding GNS3VM NAT port forwarding rule with port {} to interface {}\".format(api_port, nat_interface_number))\n        yield from self._execute(\"controlvm\", [self._vmname, \"natpf{}\".format(nat_interface_number),\n                                               \"GNS3VM,tcp,{},{},,3080\".format(ip_address, api_port)])\n\n        self.ip_address = yield from self._get_ip(hostonly_interface_number, api_port)\n        self.port = 3080\n        log.info(\"GNS3 VM has been started with IP {}\".format(self.ip_address))\n        self.running = True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_ip(self, hostonly_interface_number, api_port):\n        remaining_try = 300\n        while remaining_try > 0:\n            json_data = None\n            session = aiohttp.ClientSession()\n            try:\n                resp = None\n                resp = yield from session.get('http://127.0.0.1:{}/v2/compute/network/interfaces'.format(api_port))\n            except (OSError, aiohttp.ClientError, TimeoutError, asyncio.TimeoutError):\n                pass\n\n            if resp:\n                if resp.status < 300:\n                    try:\n                        json_data = yield from resp.json()\n                    except ValueError:\n                        pass\n                resp.close()\n\n            session.close()\n\n            if json_data:\n                for interface in json_data:\n                    if \"name\" in interface and interface[\"name\"] == \"eth{}\".format(hostonly_interface_number - 1):\n                        if \"ip_address\" in interface and len(interface[\"ip_address\"]) > 0:\n                            return interface[\"ip_address\"]\n            remaining_try -= 1\n            yield from asyncio.sleep(1)\n        raise GNS3VMError(\"Could not get the GNS3 VM ip make sure the VM receive an IP from VirtualBox\")", "response": "Get the IP from VirtualBox."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsuspend the GNS3 VM.", "response": "def suspend(self):\n        \"\"\"\n        Suspend the GNS3 VM.\n        \"\"\"\n\n        yield from self._execute(\"controlvm\", [self._vmname, \"savestate\"], timeout=3)\n        log.info(\"GNS3 VM has been suspend\")\n        self.running = False"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nstops the GNS3 VM.", "response": "def stop(self):\n        \"\"\"\n        Stops the GNS3 VM.\n        \"\"\"\n\n        vm_state = yield from self._get_state()\n        if vm_state == \"poweroff\":\n            self.running = False\n            return\n\n        yield from self._execute(\"controlvm\", [self._vmname, \"acpipowerbutton\"], timeout=3)\n        trial = 120\n        while True:\n            try:\n                vm_state = yield from self._get_state()\n            # During a small amount of time the command will fail\n            except GNS3VMError:\n                vm_state = \"running\"\n            if vm_state == \"poweroff\":\n                break\n            trial -= 1\n            if trial == 0:\n                yield from self._execute(\"controlvm\", [self._vmname, \"poweroff\"], timeout=3)\n                break\n            yield from asyncio.sleep(1)\n\n        log.info(\"GNS3 VM has been stopped\")\n        self.running = False"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the number of vCPU cores for the GNS3 VM.", "response": "def set_vcpus(self, vcpus):\n        \"\"\"\n        Set the number of vCPU cores for the GNS3 VM.\n\n        :param vcpus: number of vCPU cores\n        \"\"\"\n\n        yield from self._execute(\"modifyvm\", [self._vmname, \"--cpus\", str(vcpus)], timeout=3)\n        log.info(\"GNS3 VM vCPU count set to {}\".format(vcpus))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_ram(self, ram):\n\n        yield from self._execute(\"modifyvm\", [self._vmname, \"--memory\", str(ram)], timeout=3)\n        log.info(\"GNS3 VM RAM amount set to {}\".format(ram))", "response": "Set the amount of RAM for the GNS3 VM."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef console_host(self, new_host):\n        server_config = Config.instance().get_section_config(\"Server\")\n        remote_console_connections = server_config.getboolean(\"allow_remote_console\")\n        if remote_console_connections:\n            log.warning(\"Remote console connections are allowed\")\n            self._console_host = \"0.0.0.0\"\n        else:\n            self._console_host = new_host", "response": "If allow remote connection we need to bind console host to 0.0.0.0"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef find_unused_port(start_port, end_port, host=\"127.0.0.1\", socket_type=\"TCP\", ignore_ports=None):\n\n        if end_port < start_port:\n            raise HTTPConflict(text=\"Invalid port range {}-{}\".format(start_port, end_port))\n\n        last_exception = None\n        for port in range(start_port, end_port + 1):\n            if ignore_ports and (port in ignore_ports or port in BANNED_PORTS):\n                continue\n\n            try:\n                PortManager._check_port(host, port, socket_type)\n                if host != \"0.0.0.0\":\n                    PortManager._check_port(\"0.0.0.0\", port, socket_type)\n                return port\n            except OSError as e:\n                last_exception = e\n                if port + 1 == end_port:\n                    break\n                else:\n                    continue\n\n        raise HTTPConflict(text=\"Could not find a free port between {} and {} on host {}, last exception: {}\".format(start_port,\n                                                                                                                     end_port,\n                                                                                                                     host,\n                                                                                                                     last_exception))", "response": "Finds an unused port in a range."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _check_port(host, port, socket_type):\n        if socket_type == \"UDP\":\n            socket_type = socket.SOCK_DGRAM\n        else:\n            socket_type = socket.SOCK_STREAM\n\n        for res in socket.getaddrinfo(host, port, socket.AF_UNSPEC, socket_type, 0, socket.AI_PASSIVE):\n            af, socktype, proto, _, sa = res\n            with socket.socket(af, socktype, proto) as s:\n                s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n                s.bind(sa)  # the port is available if bind is a success\n            return True", "response": "Check if an a port is available and raise an OSError if it is not available."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets an available TCP port and reserve it", "response": "def get_free_tcp_port(self, project, port_range_start=None, port_range_end=None):\n        \"\"\"\n        Get an available TCP port and reserve it\n\n        :param project: Project instance\n        \"\"\"\n\n        # use the default range is not specific one is given\n        if port_range_start is None and port_range_end is None:\n            port_range_start = self._console_port_range[0]\n            port_range_end = self._console_port_range[1]\n\n        port = self.find_unused_port(port_range_start,\n                                     port_range_end,\n                                     host=self._console_host,\n                                     socket_type=\"TCP\",\n                                     ignore_ports=self._used_tcp_ports)\n\n        self._used_tcp_ports.add(port)\n        project.record_tcp_port(port)\n        log.debug(\"TCP port {} has been allocated\".format(port))\n        return port"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef reserve_tcp_port(self, port, project, port_range_start=None, port_range_end=None):\n\n        # use the default range is not specific one is given\n        if port_range_start is None and port_range_end is None:\n            port_range_start = self._console_port_range[0]\n            port_range_end = self._console_port_range[1]\n\n        if port in self._used_tcp_ports:\n            old_port = port\n            port = self.get_free_tcp_port(project, port_range_start=port_range_start, port_range_end=port_range_end)\n            msg = \"TCP port {} already in use on host {}. Port has been replaced by {}\".format(old_port, self._console_host, port)\n            log.debug(msg)\n            #project.emit(\"log.warning\", {\"message\": msg})\n            return port\n        if port < port_range_start or port > port_range_end:\n            old_port = port\n            port = self.get_free_tcp_port(project, port_range_start=port_range_start, port_range_end=port_range_end)\n            msg = \"TCP port {} is outside the range {}-{} on host {}. Port has been replaced by {}\".format(old_port, port_range_start, port_range_end, self._console_host, port)\n            log.debug(msg)\n            #project.emit(\"log.warning\", {\"message\": msg})\n            return port\n        try:\n            PortManager._check_port(self._console_host, port, \"TCP\")\n        except OSError:\n            old_port = port\n            port = self.get_free_tcp_port(project, port_range_start=port_range_start, port_range_end=port_range_end)\n            msg = \"TCP port {} already in use on host {}. Port has been replaced by {}\".format(old_port, self._console_host, port)\n            log.debug(msg)\n            #project.emit(\"log.warning\", {\"message\": msg})\n            return port\n\n        self._used_tcp_ports.add(port)\n        project.record_tcp_port(port)\n        log.debug(\"TCP port {} has been reserved\".format(port))\n        return port", "response": "Reserve a specific TCP port number. If not available replace it by another."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef release_tcp_port(self, port, project):\n\n        if port in self._used_tcp_ports:\n            self._used_tcp_ports.remove(port)\n            project.remove_tcp_port(port)\n            log.debug(\"TCP port {} has been released\".format(port))", "response": "Release a specific TCP port number."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_free_udp_port(self, project):\n        port = self.find_unused_port(self._udp_port_range[0],\n                                     self._udp_port_range[1],\n                                     host=self._udp_host,\n                                     socket_type=\"UDP\",\n                                     ignore_ports=self._used_udp_ports)\n\n        self._used_udp_ports.add(port)\n        project.record_udp_port(port)\n        log.debug(\"UDP port {} has been allocated\".format(port))\n        return port", "response": "Get an available UDP port and reserve it"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreserves a specific UDP port number.", "response": "def reserve_udp_port(self, port, project):\n        \"\"\"\n        Reserve a specific UDP port number\n\n        :param port: UDP port number\n        :param project: Project instance\n        \"\"\"\n\n        if port in self._used_udp_ports:\n            raise HTTPConflict(text=\"UDP port {} already in use on host {}\".format(port, self._console_host))\n        if port < self._udp_port_range[0] or port > self._udp_port_range[1]:\n            raise HTTPConflict(text=\"UDP port {} is outside the range {}-{}\".format(port, self._udp_port_range[0], self._udp_port_range[1]))\n        self._used_udp_ports.add(port)\n        project.record_udp_port(port)\n        log.debug(\"UDP port {} has been reserved\".format(port))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreleasing a specific UDP port number.", "response": "def release_udp_port(self, port, project):\n        \"\"\"\n        Release a specific UDP port number\n\n        :param port: UDP port number\n        :param project: Project instance\n        \"\"\"\n\n        if port in self._used_udp_ports:\n            self._used_udp_ports.remove(port)\n            project.remove_udp_port(port)\n            log.debug(\"UDP port {} has been released\".format(port))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new IOU VM.", "response": "def create_node(self, *args, **kwargs):\n        \"\"\"\n        Creates a new IOU VM.\n\n        :returns: IOUVM instance\n        \"\"\"\n\n        with (yield from self._iou_id_lock):\n            # wait for a node to be completely created before adding a new one\n            # this is important otherwise we allocate the same application ID\n            # when creating multiple IOU node at the same time\n            application_id = get_next_application_id(self.nodes)\n            node = yield from super().create_node(*args, application_id=application_id, **kwargs)\n        return node"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate all possible link of a node in a node list", "response": "async def create_link(project, nodes):\n    \"\"\"\n    Create all possible link of a node\n    \"\"\"\n    node1 = random.choice(list(nodes.values()))\n\n    for port in range(0, 8):\n        node2 = random.choice(list(nodes.values()))\n\n        if node1 == node2:\n            continue\n\n        data = {\"nodes\":\n                [\n                    {\n                        \"adapter_number\": 0,\n                        \"node_id\": node1[\"node_id\"],\n                        \"port_number\": port\n                    },\n                    {\n                        \"adapter_number\": 0,\n                        \"node_id\": node2[\"node_id\"],\n                        \"port_number\": port\n                    }\n                ]\n                }\n        try:\n            await post(\"/projects/{}/links\".format(project[\"project_id\"]), body=data)\n        except (HTTPConflict, HTTPNotFound):\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwait for all tasks to finish and raise exceptions.", "response": "def join(self):\n        \"\"\"\n        Wait for all task to finish\n        \"\"\"\n        pending = set()\n        exceptions = set()\n        while len(self._tasks) > 0 or len(pending) > 0:\n            while len(self._tasks) > 0 and len(pending) < self._concurrency:\n                task, args, kwargs = self._tasks.pop(0)\n                pending.add(task(*args, **kwargs))\n            (done, pending) = yield from asyncio.wait(pending, return_when=asyncio.FIRST_COMPLETED)\n            for task in done:\n                if task.exception():\n                    exceptions.add(task.exception())\n        if len(exceptions) > 0:\n            raise exceptions.pop()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nstart capture of the current set of PCAPs for the current set of attributes.", "response": "def startPacketCapture(self, pcap_output_file, pcap_data_link_type=\"DLT_EN10MB\"):\n        \"\"\"\n        :param pcap_output_file: PCAP destination file for the capture\n        :param pcap_data_link_type: PCAP data link type (DLT_*), default is DLT_EN10MB\n        \"\"\"\n\n        self._capturing = True\n        self._pcap_output_file = pcap_output_file\n        self._pcap_data_link_type = pcap_data_link_type"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the name of this node.", "response": "def name(self, new_name):\n        \"\"\"\n        Sets the name of this node.\n\n        :param new_name: name\n        \"\"\"\n\n        log.info(\"{module}: {name} [{id}] renamed to {new_name}\".format(module=self.manager.module_name,\n                                                                        name=self.name,\n                                                                        id=self.id,\n                                                                        new_name=new_name))\n        self._name = new_name"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete(self):\n        def set_rw(operation, name, exc):\n            os.chmod(name, stat.S_IWRITE)\n\n        directory = self.project.node_working_directory(self)\n        if os.path.exists(directory):\n            try:\n                yield from wait_run_in_executor(shutil.rmtree, directory, onerror=set_rw)\n            except OSError as e:\n                raise aiohttp.web.HTTPInternalServerError(text=\"Could not delete the node working directory: {}\".format(e))", "response": "Delete the node s data."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nstop the node process.", "response": "def stop(self):\n        \"\"\"\n        Stop the node process.\n        \"\"\"\n        if self._wrapper_telnet_server:\n            self._wrapper_telnet_server.close()\n            yield from self._wrapper_telnet_server.wait_closed()\n        self.status = \"stopped\""}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nclose the node process.", "response": "def close(self):\n        \"\"\"\n        Close the node process.\n        \"\"\"\n\n        if self._closed:\n            return False\n\n        log.info(\"{module}: '{name}' [{id}]: is closing\".format(module=self.manager.module_name,\n                                                                name=self.name,\n                                                                id=self.id))\n\n        if self._console:\n            self._manager.port_manager.release_tcp_port(self._console, self._project)\n            self._console = None\n        if self._wrap_console:\n            self._manager.port_manager.release_tcp_port(self._internal_console_port, self._project)\n            self._internal_console_port = None\n\n        if self._aux:\n            self._manager.port_manager.release_tcp_port(self._aux, self._project)\n            self._aux = None\n\n        self._closed = True\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nstart a telnet proxy for the console.", "response": "def start_wrap_console(self):\n        \"\"\"\n        Start a telnet proxy for the console allowing multiple client\n        connected at the same time\n        \"\"\"\n        if not self._wrap_console or self._console_type != \"telnet\":\n            return\n        remaining_trial = 60\n        while True:\n            try:\n                (reader, writer) = yield from asyncio.open_connection(host=\"127.0.0.1\", port=self._internal_console_port)\n                break\n            except (OSError, ConnectionRefusedError) as e:\n                if remaining_trial <= 0:\n                    raise e\n            yield from asyncio.sleep(0.1)\n            remaining_trial -= 1\n        yield from AsyncioTelnetServer.write_client_intro(writer, echo=True)\n        server = AsyncioTelnetServer(reader=reader, writer=writer, binary=True, echo=True)\n        self._wrapper_telnet_server = yield from asyncio.start_server(server.run, self._manager.port_manager.console_host, self.console)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchanging the aux port of the current instance", "response": "def aux(self, aux):\n        \"\"\"\n        Changes the aux port\n\n        :params aux: Console port (integer) or None to free the port\n        \"\"\"\n\n        if aux == self._aux:\n            return\n\n        if self._aux:\n            self._manager.port_manager.release_tcp_port(self._aux, self._project)\n            self._aux = None\n        if aux is not None:\n            self._aux = self._manager.port_manager.reserve_tcp_port(aux, self._project)\n            log.info(\"{module}: '{name}' [{id}]: aux port set to {port}\".format(module=self.manager.module_name,\n                                                                                name=self.name,\n                                                                                id=self.id,\n                                                                                port=aux))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef console(self, console):\n\n        if console == self._console:\n            return\n\n        if self._console_type == \"vnc\" and console is not None and console < 5900:\n            raise NodeError(\"VNC console require a port superior or equal to 5900 currently it's {}\".format(console))\n\n        if self._console:\n            self._manager.port_manager.release_tcp_port(self._console, self._project)\n            self._console = None\n        if console is not None:\n            if self.console_type == \"vnc\":\n                self._console = self._manager.port_manager.reserve_tcp_port(console, self._project, port_range_start=5900, port_range_end=6000)\n            else:\n                self._console = self._manager.port_manager.reserve_tcp_port(console, self._project)\n\n            log.info(\"{module}: '{name}' [{id}]: console port set to {port}\".format(module=self.manager.module_name,\n                                                                                    name=self.name,\n                                                                                    id=self.id,\n                                                                                    port=console))", "response": "Changes the console port of this node."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef console_type(self, console_type):\n\n        if console_type != self._console_type:\n            # get a new port if the console type change\n            self._manager.port_manager.release_tcp_port(self._console, self._project)\n            if console_type == \"vnc\":\n                # VNC is a special case and the range must be 5900-6000\n                self._console = self._manager.port_manager.get_free_tcp_port(self._project, 5900, 6000)\n            else:\n                self._console = self._manager.port_manager.get_free_tcp_port(self._project)\n\n        self._console_type = console_type\n        log.info(\"{module}: '{name}' [{id}]: console type set to {console_type}\".format(module=self.manager.module_name,\n                                                                                        name=self.name,\n                                                                                        id=self.id,\n                                                                                        console_type=console_type))", "response": "Sets the console type for this node."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the uBridge hypervisor instance.", "response": "def ubridge(self):\n        \"\"\"\n        Returns the uBridge hypervisor.\n\n        :returns: instance of uBridge\n        \"\"\"\n\n        if self._ubridge_hypervisor and not self._ubridge_hypervisor.is_running():\n            self._ubridge_hypervisor = None\n        return self._ubridge_hypervisor"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ubridge_path(self):\n\n        path = self._manager.config.get_section_config(\"Server\").get(\"ubridge_path\", \"ubridge\")\n        path = shutil.which(path)\n        return path", "response": "Returns the uBridge executable path."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _ubridge_send(self, command):\n\n        if not self._ubridge_hypervisor or not self._ubridge_hypervisor.is_running():\n            yield from self._start_ubridge()\n        if not self._ubridge_hypervisor or not self._ubridge_hypervisor.is_running():\n            raise NodeError(\"Cannot send command '{}': uBridge is not running\".format(command))\n        try:\n            yield from self._ubridge_hypervisor.send(command)\n        except UbridgeError as e:\n            raise UbridgeError(\"{}: {}\".format(e, self._ubridge_hypervisor.read_stdout()))", "response": "Sends a command to uBridge."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nstart uBridge (handles connections to and from this node).", "response": "def _start_ubridge(self):\n        \"\"\"\n        Starts uBridge (handles connections to and from this node).\n        \"\"\"\n\n        # Prevent us to start multiple ubridge\n        if self._ubridge_hypervisor and self._ubridge_hypervisor.is_running():\n            return\n\n        if self.ubridge_path is None:\n            raise NodeError(\"uBridge is not available, path doesn't exist, or you just installed GNS3 and need to restart your user session to refresh user permissions.\")\n\n        if not self._manager.has_privileged_access(self.ubridge_path):\n            raise NodeError(\"uBridge requires root access or the capability to interact with network adapters\")\n\n        server_config = self._manager.config.get_section_config(\"Server\")\n        server_host = server_config.get(\"host\")\n        if not self.ubridge:\n            self._ubridge_hypervisor = Hypervisor(self._project, self.ubridge_path, self.working_dir, server_host)\n        log.info(\"Starting new uBridge hypervisor {}:{}\".format(self._ubridge_hypervisor.host, self._ubridge_hypervisor.port))\n        yield from self._ubridge_hypervisor.start()\n        if self._ubridge_hypervisor:\n            log.info(\"Hypervisor {}:{} has successfully started\".format(self._ubridge_hypervisor.host, self._ubridge_hypervisor.port))\n            yield from self._ubridge_hypervisor.connect()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_ubridge_udp_connection(self, bridge_name, source_nio, destination_nio):\n\n        yield from self._ubridge_send(\"bridge create {name}\".format(name=bridge_name))\n\n        if not isinstance(destination_nio, NIOUDP):\n            raise NodeError(\"Destination NIO is not UDP\")\n\n        yield from self._ubridge_send('bridge add_nio_udp {name} {lport} {rhost} {rport}'.format(name=bridge_name,\n                                                                                                 lport=source_nio.lport,\n                                                                                                 rhost=source_nio.rhost,\n                                                                                                 rport=source_nio.rport))\n\n        yield from self._ubridge_send('bridge add_nio_udp {name} {lport} {rhost} {rport}'.format(name=bridge_name,\n                                                                                                 lport=destination_nio.lport,\n                                                                                                 rhost=destination_nio.rhost,\n                                                                                                 rport=destination_nio.rport))\n\n        if destination_nio.capturing:\n            yield from self._ubridge_send('bridge start_capture {name} \"{pcap_file}\"'.format(name=bridge_name,\n                                                                                             pcap_file=destination_nio.pcap_output_file))\n\n        yield from self._ubridge_send('bridge start {name}'.format(name=bridge_name))\n        yield from self._ubridge_apply_filters(bridge_name, destination_nio.filters)", "response": "Adds an UDP connection to the uBridge."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ubridge_delete_bridge(self, name):\n        if self.ubridge:\n            yield from self._ubridge_send(\"bridge delete {name}\".format(name=name))", "response": "Delete a bridge with this name"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\napplies packet filters to uBridge", "response": "def _ubridge_apply_filters(self, bridge_name, filters):\n        \"\"\"\n        Apply packet filters\n\n        :param bridge_name: bridge name in uBridge\n        :param filters: Array of filter dictionary\n        \"\"\"\n        yield from self._ubridge_send('bridge reset_packet_filters ' + bridge_name)\n        for packet_filter in self._build_filter_list(filters):\n            cmd = 'bridge add_packet_filter {} {}'.format(bridge_name, packet_filter)\n            try:\n                yield from self._ubridge_send(cmd)\n            except UbridgeError as e:\n                match = re.search(\"Cannot compile filter '(.*)': syntax error\", str(e))\n                if match:\n                    message = \"Warning: ignoring BPF packet filter '{}' due to syntax error\".format(self.name, match.group(1))\n                    log.warning(message)\n                    self.project.emit(\"log.warning\", {\"message\": message})\n                else:\n                    raise"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _build_filter_list(self, filters):\n        i = 0\n        for (filter_type, values) in filters.items():\n            if isinstance(values[0], str):\n                for line in values[0].split('\\n'):\n                    line = line.strip()\n                    yield \"{filter_name} {filter_type} {filter_value}\".format(\n                        filter_name=\"filter\" + str(i),\n                        filter_type=filter_type,\n                        filter_value='\"{}\" {}'.format(line, \" \".join([str(v) for v in values[1:]]))).strip()\n                    i += 1\n            else:\n                yield \"{filter_name} {filter_type} {filter_value}\".format(\n                    filter_name=\"filter\" + str(i),\n                    filter_type=filter_type,\n                    filter_value=\" \".join([str(v) for v in values]))\n                i += 1", "response": "Build a list of filter names and values."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _add_ubridge_ethernet_connection(self, bridge_name, ethernet_interface, block_host_traffic=False):\n\n        if sys.platform.startswith(\"linux\") and block_host_traffic is False:\n            # on Linux we use RAW sockets by default excepting if host traffic must be blocked\n            yield from self._ubridge_send('bridge add_nio_linux_raw {name} \"{interface}\"'.format(name=bridge_name, interface=ethernet_interface))\n        elif sys.platform.startswith(\"win\"):\n            # on Windows we use Winpcap/Npcap\n            windows_interfaces = interfaces()\n            npf_id = None\n            source_mac = None\n            for interface in windows_interfaces:\n                # Winpcap/Npcap uses a NPF ID to identify an interface on Windows\n                if \"netcard\" in interface and ethernet_interface in interface[\"netcard\"]:\n                    npf_id = interface[\"id\"]\n                    source_mac = interface[\"mac_address\"]\n                elif ethernet_interface in interface[\"name\"]:\n                    npf_id = interface[\"id\"]\n                    source_mac = interface[\"mac_address\"]\n            if npf_id:\n                yield from self._ubridge_send('bridge add_nio_ethernet {name} \"{interface}\"'.format(name=bridge_name,\n                                                                                                    interface=npf_id))\n            else:\n                raise NodeError(\"Could not find NPF id for interface {}\".format(ethernet_interface))\n\n            if block_host_traffic:\n                if source_mac:\n                    yield from self._ubridge_send('bridge set_pcap_filter {name} \"not ether src {mac}\"'.format(name=bridge_name, mac=source_mac))\n                    log.info('PCAP filter applied on \"{interface}\" for source MAC {mac}'.format(interface=ethernet_interface, mac=source_mac))\n                else:\n                    log.warning(\"Could not block host network traffic on {} (no MAC address found)\".format(ethernet_interface))\n        else:\n            # on other platforms we just rely on the pcap library\n            yield from self._ubridge_send('bridge add_nio_ethernet {name} \"{interface}\"'.format(name=bridge_name, interface=ethernet_interface))\n            source_mac = None\n            for interface in interfaces():\n                if interface[\"name\"] == ethernet_interface:\n                    source_mac = interface[\"mac_address\"]\n            if source_mac:\n                yield from self._ubridge_send('bridge set_pcap_filter {name} \"not ether src {mac}\"'.format(name=bridge_name, mac=source_mac))\n                log.info('PCAP filter applied on \"{interface}\" for source MAC {mac}'.format(interface=ethernet_interface, mac=source_mac))", "response": "Add an ethernet connection to a bridge."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _create_local_udp_tunnel(self):\n\n        m = PortManager.instance()\n        lport = m.get_free_udp_port(self.project)\n        rport = m.get_free_udp_port(self.project)\n        source_nio_settings = {'lport': lport, 'rhost': '127.0.0.1', 'rport': rport, 'type': 'nio_udp'}\n        destination_nio_settings = {'lport': rport, 'rhost': '127.0.0.1', 'rport': lport, 'type': 'nio_udp'}\n        source_nio = self.manager.create_nio(source_nio_settings)\n        destination_nio = self.manager.create_nio(destination_nio_settings)\n        log.info(\"{module}: '{name}' [{id}]:local UDP tunnel created between port {port1} and {port2}\".format(module=self.manager.module_name,\n                                                                                                              name=self.name,\n                                                                                                              id=self.id,\n                                                                                                              port1=lport,\n                                                                                                              port2=rport))\n        return source_nio, destination_nio", "response": "Creates a local UDP tunnel between two NIOs."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if the requested amount of RAM is available on the system.", "response": "def check_available_ram(self, requested_ram):\n        \"\"\"\n        Sends a warning notification if there is not enough RAM on the system to allocate requested RAM.\n\n        :param requested_ram: requested amount of RAM in MB\n        \"\"\"\n\n        available_ram = int(psutil.virtual_memory().available / (1024 * 1024))\n        percentage_left = psutil.virtual_memory().percent\n        if requested_ram > available_ram:\n            message = '\"{}\" requires {}MB of RAM to run but there is only {}MB - {}% of RAM left on \"{}\"'.format(self.name,\n                                                                                                                 requested_ram,\n                                                                                                                 available_ram,\n                                                                                                                 percentage_left,\n                                                                                                                 platform.node())\n            self.project.emit(\"log.warning\", {\"message\": message})"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the path to the base image file if it s a linked clone.", "response": "def backing_file(self):\n        \"\"\"\n        When using linked clone this will return the path to the base image\n\n        :returns: None if it's not a linked clone, the path otherwise\n        \"\"\"\n\n        with open(self._path, 'rb') as f:\n            f.seek(self.backing_file_offset)\n            content = f.read(self.backing_file_size)\n\n        path = content.decode()\n        if len(path) == 0:\n            return None\n        return path"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef rebase(self, qemu_img, base_image):\n\n        if not os.path.exists(base_image):\n            raise FileNotFoundError(base_image)\n        command = [qemu_img, \"rebase\", \"-u\", \"-b\", base_image, self._path]\n        process = yield from asyncio.create_subprocess_exec(*command)\n        retcode = yield from process.wait()\n        if retcode != 0:\n            raise Qcow2Error(\"Could not rebase the image\")\n        self._reload()", "response": "Rebase a linked clone in order to use the correct disk"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef qt_font_to_style(font, color):\n    if font is None:\n        font = \"TypeWriter,10,-1,5,75,0,0,0,0,0\"\n    font_info = font.split(\",\")\n    style = \"font-family: {};font-size: {};\".format(font_info[0], font_info[1])\n    if font_info[4] == \"75\":\n        style += \"font-weight: bold;\"\n    if font_info[5] == \"1\":\n        style += \"font-style: italic;\"\n\n    if color is None:\n        color = \"000000\"\n    if len(color) == 9:\n        style += \"fill: #\" + color[-6:] + \";\"\n        style += \"fill-opacity: {};\".format(round(1.0 / 255 * int(color[:3][-2:], base=16), 2))\n    else:\n        style += \"fill: #\" + color[-6:] + \";\"\n        style += \"fill-opacity: {};\".format(1.0)\n    return style", "response": "Convert a Qt font to CSS style"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef list(self):\n\n        res = []\n\n        for compute in self._controller.computes.values():\n            if compute.id not in [\"local\", \"vm\"]:\n                res.append({\"vmname\": compute.name})\n        return res", "response": "List all VMs that are not local"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nstarting the GNS3 VM.", "response": "def start(self):\n        \"\"\"\n        Starts the GNS3 VM.\n        \"\"\"\n\n        if not self.vmname:\n            return\n        vm_compute = None\n        for compute in self._controller.computes.values():\n            if compute.name == self.vmname:\n                self.running = True\n                self.protocol = compute.protocol\n                self.ip_address = compute.host\n                self.port = compute.port\n                self.user = compute.user\n                self.password = compute.password\n                return\n        raise GNS3VMError(\"Can't start the GNS3 VM remote VM {} not found\".format(self.vmname))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_dynamips_id(self, project_id):\n        self._dynamips_ids.setdefault(project_id, set())\n        for dynamips_id in range(1, 4097):\n            if dynamips_id not in self._dynamips_ids[project_id]:\n                self._dynamips_ids[project_id].add(dynamips_id)\n                return dynamips_id\n        raise DynamipsError(\"Maximum number of Dynamips instances reached\")", "response": "returns a free dynamips id"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef take_dynamips_id(self, project_id, dynamips_id):\n        self._dynamips_ids.setdefault(project_id, set())\n        if dynamips_id in self._dynamips_ids[project_id]:\n            raise DynamipsError(\"Dynamips identifier {} is already used by another router\".format(dynamips_id))\n        self._dynamips_ids[project_id].add(dynamips_id)", "response": "Reserve a dynamips id and add it to the set of available dynamips ids."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreleases a Dynamips id from the cache.", "response": "def release_dynamips_id(self, project_id, dynamips_id):\n        \"\"\"\n        A Dynamips id can be reused by another VM\n\n        :param project_id: UUID of the project\n        :param dynamips_id: Asked id\n        \"\"\"\n        self._dynamips_ids.setdefault(project_id, set())\n        if dynamips_id in self._dynamips_ids[project_id]:\n            self._dynamips_ids[project_id].remove(dynamips_id)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalls when a project is about to be closed.", "response": "def project_closing(self, project):\n        \"\"\"\n        Called when a project is about to be closed.\n\n        :param project: Project instance\n        \"\"\"\n\n        yield from super().project_closing(project)\n        # delete the Dynamips devices corresponding to the project\n        tasks = []\n        for device in self._devices.values():\n            if device.project.id == project.id:\n                tasks.append(asyncio.async(device.delete()))\n\n        if tasks:\n            done, _ = yield from asyncio.wait(tasks)\n            for future in done:\n                try:\n                    future.result()\n                except (Exception, GeneratorExit) as e:\n                    log.error(\"Could not delete device {}\".format(e), exc_info=1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalls when a project is closed.", "response": "def project_closed(self, project):\n        \"\"\"\n        Called when a project is closed.\n\n        :param project: Project instance\n        \"\"\"\n        yield from super().project_closed(project)\n        # delete useless Dynamips files\n        project_dir = project.module_working_path(self.module_name.lower())\n\n        files = glob.glob(os.path.join(glob.escape(project_dir), \"*.ghost\"))\n        files += glob.glob(os.path.join(glob.escape(project_dir), \"*\", \"*_lock\"))\n        files += glob.glob(os.path.join(glob.escape(project_dir), \"*_log.txt\"))\n        files += glob.glob(os.path.join(glob.escape(project_dir), \"*_stdout.txt\"))\n        files += glob.glob(os.path.join(glob.escape(project_dir), \"ilt_*\"))\n        files += glob.glob(os.path.join(glob.escape(project_dir), \"*\", \"c[0-9][0-9][0-9][0-9]_i[0-9]*_rommon_vars\"))\n        files += glob.glob(os.path.join(glob.escape(project_dir), \"*\", \"c[0-9][0-9][0-9][0-9]_i[0-9]*_log.txt\"))\n        for file in files:\n            try:\n                log.debug(\"Deleting file {}\".format(file))\n                if file in self._ghost_files:\n                    self._ghost_files.remove(file)\n                yield from wait_run_in_executor(os.remove, file)\n            except OSError as e:\n                log.warn(\"Could not delete file {}: {}\".format(file, e))\n                continue\n\n        # Release the dynamips ids if we want to reload the same project\n        # later\n        if project.id in self._dynamips_ids:\n            del self._dynamips_ids[project.id]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef start_new_hypervisor(self, working_dir=None):\n\n        if not self._dynamips_path:\n            self.find_dynamips()\n\n        if not working_dir:\n            working_dir = tempfile.gettempdir()\n\n        # FIXME: hypervisor should always listen to 127.0.0.1\n        # See https://github.com/GNS3/dynamips/issues/62\n        server_config = self.config.get_section_config(\"Server\")\n        server_host = server_config.get(\"host\")\n\n        try:\n            info = socket.getaddrinfo(server_host, 0, socket.AF_UNSPEC, socket.SOCK_STREAM, 0, socket.AI_PASSIVE)\n            if not info:\n                raise DynamipsError(\"getaddrinfo returns an empty list on {}\".format(server_host))\n            for res in info:\n                af, socktype, proto, _, sa = res\n                # let the OS find an unused port for the Dynamips hypervisor\n                with socket.socket(af, socktype, proto) as sock:\n                    sock.bind(sa)\n                    port = sock.getsockname()[1]\n                    break\n        except OSError as e:\n            raise DynamipsError(\"Could not find free port for the Dynamips hypervisor: {}\".format(e))\n\n        port_manager = PortManager.instance()\n        hypervisor = Hypervisor(self._dynamips_path, working_dir, server_host, port, port_manager.console_host)\n\n        log.info(\"Creating new hypervisor {}:{} with working directory {}\".format(hypervisor.host, hypervisor.port, working_dir))\n        yield from hypervisor.start()\n        log.info(\"Hypervisor {}:{} has successfully started\".format(hypervisor.host, hypervisor.port))\n        yield from hypervisor.connect()\n        if parse_version(hypervisor.version) < parse_version('0.2.11'):\n            raise DynamipsError(\"Dynamips version must be >= 0.2.11, detected version is {}\".format(hypervisor.version))\n\n        return hypervisor", "response": "Starts a new Dynamips process and starts it."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new NIO object and returns it.", "response": "def create_nio(self, node, nio_settings):\n        \"\"\"\n        Creates a new NIO.\n\n        :param node: Dynamips node instance\n        :param nio_settings: information to create the NIO\n\n        :returns: a NIO object\n        \"\"\"\n\n        nio = None\n        if nio_settings[\"type\"] == \"nio_udp\":\n            lport = nio_settings[\"lport\"]\n            rhost = nio_settings[\"rhost\"]\n            rport = nio_settings[\"rport\"]\n            try:\n                info = socket.getaddrinfo(rhost, rport, socket.AF_UNSPEC, socket.SOCK_DGRAM, 0, socket.AI_PASSIVE)\n                if not info:\n                    raise DynamipsError(\"getaddrinfo returns an empty list on {}:{}\".format(rhost, rport))\n                for res in info:\n                    af, socktype, proto, _, sa = res\n                    with socket.socket(af, socktype, proto) as sock:\n                        sock.connect(sa)\n            except OSError as e:\n                raise DynamipsError(\"Could not create an UDP connection to {}:{}: {}\".format(rhost, rport, e))\n            nio = NIOUDP(node, lport, rhost, rport, nio_settings.get(\"filters\", {}))\n        elif nio_settings[\"type\"] == \"nio_generic_ethernet\":\n            ethernet_device = nio_settings[\"ethernet_device\"]\n            if sys.platform.startswith(\"win\"):\n                # replace the interface name by the GUID on Windows\n                windows_interfaces = interfaces()\n                npf_interface = None\n                for interface in windows_interfaces:\n                    if interface[\"name\"] == ethernet_device:\n                        npf_interface = interface[\"id\"]\n                if not npf_interface:\n                    raise DynamipsError(\"Could not find interface {} on this host\".format(ethernet_device))\n                else:\n                    ethernet_device = npf_interface\n            if not is_interface_up(ethernet_device):\n                raise aiohttp.web.HTTPConflict(text=\"Ethernet interface {} is down\".format(ethernet_device))\n            nio = NIOGenericEthernet(node.hypervisor, ethernet_device)\n        elif nio_settings[\"type\"] == \"nio_linux_ethernet\":\n            if sys.platform.startswith(\"win\"):\n                raise DynamipsError(\"This NIO type is not supported on Windows\")\n            ethernet_device = nio_settings[\"ethernet_device\"]\n            nio = NIOLinuxEthernet(node.hypervisor, ethernet_device)\n        elif nio_settings[\"type\"] == \"nio_tap\":\n            tap_device = nio_settings[\"tap_device\"]\n            nio = NIOTAP(node.hypervisor, tap_device)\n            if not is_interface_up(tap_device):\n                # test after the TAP interface has been created (if it doesn't exist yet)\n                raise aiohttp.web.HTTPConflict(text=\"TAP interface {} is down\".format(tap_device))\n        elif nio_settings[\"type\"] == \"nio_unix\":\n            local_file = nio_settings[\"local_file\"]\n            remote_file = nio_settings[\"remote_file\"]\n            nio = NIOUNIX(node.hypervisor, local_file, remote_file)\n        elif nio_settings[\"type\"] == \"nio_vde\":\n            control_file = nio_settings[\"control_file\"]\n            local_file = nio_settings[\"local_file\"]\n            nio = NIOVDE(node.hypervisor, control_file, local_file)\n        elif nio_settings[\"type\"] == \"nio_null\":\n            nio = NIONull(node.hypervisor)\n        else:\n            raise aiohttp.web.HTTPConflict(text=\"NIO of type {} is not supported\".format(nio_settings[\"type\"]))\n\n        yield from nio.create()\n        return nio"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the ghost IOS support for this module.", "response": "def _set_ghost_ios(self, vm):\n        \"\"\"\n        Manages Ghost IOS support.\n\n        :param vm: VM instance\n        \"\"\"\n\n        if not vm.mmap:\n            raise DynamipsError(\"mmap support is required to enable ghost IOS support\")\n\n        if vm.platform == \"c7200\" and vm.npe == \"npe-g2\":\n            log.warning(\"Ghost IOS is not supported for c7200 with NPE-G2\")\n            return\n\n        ghost_file = vm.formatted_ghost_file()\n\n        module_workdir = vm.project.module_working_directory(self.module_name.lower())\n        ghost_file_path = os.path.join(module_workdir, ghost_file)\n        if ghost_file_path not in self._ghost_files:\n            # create a new ghost IOS instance\n            ghost_id = str(uuid4())\n            ghost = Router(\"ghost-\" + ghost_file, ghost_id, vm.project, vm.manager, platform=vm.platform, hypervisor=vm.hypervisor, ghost_flag=True)\n            try:\n                yield from ghost.create()\n                yield from ghost.set_image(vm.image)\n                yield from ghost.set_ghost_status(1)\n                yield from ghost.set_ghost_file(ghost_file_path)\n                yield from ghost.set_ram(vm.ram)\n                try:\n                    yield from ghost.start()\n                    yield from ghost.stop()\n                    self._ghost_files.add(ghost_file_path)\n                except DynamipsError:\n                    raise\n                finally:\n                    yield from ghost.clean_delete()\n            except DynamipsError as e:\n                log.warn(\"Could not create ghost instance: {}\".format(e))\n\n        if vm.ghost_file != ghost_file and os.path.isfile(ghost_file_path):\n            # set the ghost file to the router\n            yield from vm.set_ghost_status(2)\n            yield from vm.set_ghost_file(ghost_file_path)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update_vm_settings(self, vm, settings):\n\n        for name, value in settings.items():\n            if hasattr(vm, name) and getattr(vm, name) != value:\n                if hasattr(vm, \"set_{}\".format(name)):\n                    setter = getattr(vm, \"set_{}\".format(name))\n                    yield from setter(value)\n            elif name.startswith(\"slot\") and value in ADAPTER_MATRIX:\n                slot_id = int(name[-1])\n                adapter_name = value\n                adapter = ADAPTER_MATRIX[adapter_name]()\n                try:\n                    if vm.slots[slot_id] and not isinstance(vm.slots[slot_id], type(adapter)):\n                        yield from vm.slot_remove_binding(slot_id)\n                    if not isinstance(vm.slots[slot_id], type(adapter)):\n                        yield from vm.slot_add_binding(slot_id, adapter)\n                except IndexError:\n                    raise DynamipsError(\"Slot {} doesn't exist on this router\".format(slot_id))\n            elif name.startswith(\"slot\") and (value is None or value is \"\"):\n                slot_id = int(name[-1])\n                try:\n                    if vm.slots[slot_id]:\n                        yield from vm.slot_remove_binding(slot_id)\n                except IndexError:\n                    raise DynamipsError(\"Slot {} doesn't exist on this router\".format(slot_id))\n            elif name.startswith(\"wic\") and value in WIC_MATRIX:\n                wic_slot_id = int(name[-1])\n                wic_name = value\n                wic = WIC_MATRIX[wic_name]()\n                try:\n                    if vm.slots[0].wics[wic_slot_id] and not isinstance(vm.slots[0].wics[wic_slot_id], type(wic)):\n                        yield from vm.uninstall_wic(wic_slot_id)\n                    if not isinstance(vm.slots[0].wics[wic_slot_id], type(wic)):\n                        yield from vm.install_wic(wic_slot_id, wic)\n                except IndexError:\n                    raise DynamipsError(\"WIC slot {} doesn't exist on this router\".format(wic_slot_id))\n            elif name.startswith(\"wic\") and (value is None or value is \"\"):\n                wic_slot_id = int(name[-1])\n                try:\n                    if vm.slots[0].wics and vm.slots[0].wics[wic_slot_id]:\n                        yield from vm.uninstall_wic(wic_slot_id)\n                except IndexError:\n                    raise DynamipsError(\"WIC slot {} doesn't exist on this router\".format(wic_slot_id))\n\n        mmap_support = self.config.get_section_config(\"Dynamips\").getboolean(\"mmap_support\", True)\n        if mmap_support is False:\n            yield from vm.set_mmap(False)\n\n        sparse_memory_support = self.config.get_section_config(\"Dynamips\").getboolean(\"sparse_memory_support\", True)\n        if sparse_memory_support is False:\n            yield from vm.set_sparsemem(False)\n\n        # update the configs if needed\n        yield from self.set_vm_configs(vm, settings)", "response": "Updates the VM settings."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_vm_configs(self, vm, settings):\n\n        startup_config_content = settings.get(\"startup_config_content\")\n        if startup_config_content:\n            self._create_config(vm, vm.startup_config_path, startup_config_content)\n        private_config_content = settings.get(\"private_config_content\")\n        if private_config_content:\n            self._create_config(vm, vm.private_config_path, private_config_content)", "response": "Set VM configs from pushed content or existing config files."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _create_config(self, vm, path, content=None):\n\n        log.info(\"Creating config file {}\".format(path))\n        config_dir = os.path.dirname(path)\n        try:\n            os.makedirs(config_dir, exist_ok=True)\n        except OSError as e:\n            raise DynamipsError(\"Could not create Dynamips configs directory: {}\".format(e))\n\n        if content is None or len(content) == 0:\n            content = \"!\\n\"\n            if os.path.exists(path):\n                return\n\n        try:\n            with open(path, \"wb\") as f:\n                if content:\n                    content = \"!\\n\" + content.replace(\"\\r\", \"\")\n                    content = content.replace('%h', vm.name)\n                    f.write(content.encode(\"utf-8\"))\n        except OSError as e:\n            raise DynamipsError(\"Could not create config file '{}': {}\".format(path, e))\n\n        return os.path.join(\"configs\", os.path.basename(path))", "response": "Creates a config file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef auto_idlepc(self, vm):\n\n        yield from vm.set_idlepc(\"0x0\")\n        was_auto_started = False\n        try:\n            status = yield from vm.get_status()\n            if status != \"running\":\n                yield from vm.start()\n                was_auto_started = True\n                yield from asyncio.sleep(20)  # leave time to the router to boot\n            validated_idlepc = None\n            idlepcs = yield from vm.get_idle_pc_prop()\n            if not idlepcs:\n                raise DynamipsError(\"No Idle-PC values found\")\n\n            for idlepc in idlepcs:\n                match = re.search(r\"^0x[0-9a-f]{8}$\", idlepc.split()[0])\n                if not match:\n                   continue\n                yield from vm.set_idlepc(idlepc.split()[0])\n                log.debug(\"Auto Idle-PC: trying idle-PC value {}\".format(vm.idlepc))\n                start_time = time.time()\n                initial_cpu_usage = yield from vm.get_cpu_usage()\n                log.debug(\"Auto Idle-PC: initial CPU usage is {}%\".format(initial_cpu_usage))\n                yield from asyncio.sleep(3)  # wait 3 seconds to probe the cpu again\n                elapsed_time = time.time() - start_time\n                cpu_usage = yield from vm.get_cpu_usage()\n                cpu_elapsed_usage = cpu_usage - initial_cpu_usage\n                cpu_usage = abs(cpu_elapsed_usage * 100.0 / elapsed_time)\n                if cpu_usage > 100:\n                    cpu_usage = 100\n                log.debug(\"Auto Idle-PC: CPU usage is {}% after {:.2} seconds\".format(cpu_usage, elapsed_time))\n                if cpu_usage < 70:\n                    validated_idlepc = vm.idlepc\n                    log.debug(\"Auto Idle-PC: idle-PC value {} has been validated\".format(validated_idlepc))\n                    break\n\n            if validated_idlepc is None:\n                raise DynamipsError(\"Sorry, no idle-pc value was suitable\")\n\n        except DynamipsError:\n            raise\n        finally:\n            if was_auto_started:\n                yield from vm.stop()\n        return validated_idlepc", "response": "Try to find the best possible idle - PC value."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef duplicate_node(self, source_node_id, destination_node_id):\n\n        source_node = self.get_node(source_node_id)\n        destination_node = self.get_node(destination_node_id)\n\n        # Not a Dynamips router\n        if not hasattr(source_node, \"startup_config_path\"):\n            return (yield from super().duplicate_node(source_node_id, destination_node_id))\n\n        try:\n            with open(source_node.startup_config_path) as f:\n                startup_config = f.read()\n        except OSError:\n            startup_config = None\n        try:\n            with open(source_node.private_config_path) as f:\n                private_config = f.read()\n        except OSError:\n            private_config = None\n        yield from self.set_vm_configs(destination_node, {\n            \"startup_config_content\": startup_config,\n            \"private_config_content\": private_config\n        })\n\n        # Force refresh of the name in configuration files\n        new_name = destination_node.name\n        yield from destination_node.set_name(source_node.name)\n        yield from destination_node.set_name(new_name)\n        return destination_node", "response": "Duplicate a node\n\n        :param node_id: Node identifier\n        :returns: New node instance"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef write_documentation(self, doc_type):\n        for handler_name in sorted(self._documentation):\n            if \"controller.\" in handler_name:\n                server_type = \"controller\"\n            elif \"compute\" in handler_name:\n                server_type = \"compute\"\n            else:\n                server_type = \"root\"\n\n            if doc_type != server_type:\n                continue\n\n            print(\"Build {}\".format(handler_name))\n\n            for path in sorted(self._documentation[handler_name]):\n\n                api_version = self._documentation[handler_name][path][\"api_version\"]\n                if api_version is None:\n                    continue\n\n                filename = self._file_path(path)\n                handler_doc = self._documentation[handler_name][path]\n                handler = handler_name.replace(server_type + \".\", \"\")\n\n                self._create_handler_directory(handler, api_version, server_type)\n                with open(\"{}/api/v{}/{}/{}/{}.rst\".format(self._directory, api_version, server_type, handler, filename), 'w+') as f:\n                    f.write('{}\\n------------------------------------------------------------------------------------------------------------------------------------------\\n\\n'.format(path))\n                    f.write('.. contents::\\n')\n                    for method in handler_doc[\"methods\"]:\n                        f.write('\\n{} {}\\n'.format(method[\"method\"], path.replace(\"{\", '**{').replace(\"}\", \"}**\")))\n                        f.write('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n')\n                        f.write('{}\\n\\n'.format(method[\"description\"]))\n\n                        if len(method[\"parameters\"]) > 0:\n                            f.write(\"Parameters\\n**********\\n\")\n                            for parameter in method[\"parameters\"]:\n                                desc = method[\"parameters\"][parameter]\n                                f.write(\"- **{}**: {}\\n\".format(parameter, desc))\n                            f.write(\"\\n\")\n\n                        f.write(\"Response status codes\\n**********************\\n\")\n                        for code in method[\"status_codes\"]:\n                            desc = method[\"status_codes\"][code]\n                            f.write(\"- **{}**: {}\\n\".format(code, desc))\n                        f.write(\"\\n\")\n\n                        if \"properties\" in method[\"input_schema\"]:\n                            f.write(\"Input\\n*******\\n\")\n                            self._write_definitions(f, method[\"input_schema\"])\n                            self._write_json_schema(f, method[\"input_schema\"])\n\n                        if \"properties\" in method[\"output_schema\"]:\n                            f.write(\"Output\\n*******\\n\")\n                            self._write_json_schema(f, method[\"output_schema\"])\n\n                        self._include_query_example(f, method, path, api_version, server_type)", "response": "Builds all the doc page for all the handlers"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a directory for the handler and add an index inside", "response": "def _create_handler_directory(self, handler_name, api_version, server_type):\n        \"\"\"Create a directory for the handler and add an index inside\"\"\"\n\n        directory = \"{}/api/v{}/{}/{}\".format(self._directory, api_version, server_type, handler_name)\n        os.makedirs(directory, exist_ok=True)\n\n        with open(\"{}/api/v{}/{}/{}.rst\".format(self._directory, api_version, server_type, handler_name), \"w+\") as f:\n            f.write(handler_name.replace(\"api.\", \"\").replace(\"_\", \" \", ).capitalize())\n            f.write(\"\\n-----------------------------\\n\\n\")\n            f.write(\".. toctree::\\n   :glob:\\n   :maxdepth: 2\\n\\n   {}/*\\n\".format(handler_name))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninclude the sample session example in documentation", "response": "def _include_query_example(self, f, method, path, api_version, server_type):\n        \"\"\"If a sample session is available we include it in documentation\"\"\"\n        m = method[\"method\"].lower()\n        query_path = \"{}_{}_{}.txt\".format(server_type, m, self._file_path(path))\n        if os.path.isfile(os.path.join(self._directory, \"api\", \"examples\", query_path)):\n            f.write(\"Sample session\\n***************\\n\")\n            f.write(\"\\n\\n.. literalinclude:: ../../../examples/{}\\n\\n\".format(query_path))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrite the JSON schema of the object to the file f.", "response": "def _write_json_schema_object(self, f, obj):\n        \"\"\"\n            obj is current object in JSON schema\n            schema is the whole schema including definitions\n        \"\"\"\n        for name in sorted(obj.get(\"properties\", {})):\n            prop = obj[\"properties\"][name]\n            mandatory = \" \"\n            if name in obj.get(\"required\", []):\n                mandatory = \"&#10004;\"\n\n            if \"enum\" in prop:\n                field_type = \"enum\"\n                prop['description'] = \"Possible values: {}\".format(', '.join(map(lambda a: a or \"null\", prop['enum'])))\n            else:\n                field_type = prop.get(\"type\", \"\")\n\n            # Resolve oneOf relation to their human type.\n            if field_type == 'object' and 'oneOf' in prop:\n                field_type = ', '.join(map(lambda p: p['$ref'].split('/').pop(), prop['oneOf']))\n\n            f.write(\"    <tr><td>{}</td>\\\n                    <td>{}</td> \\\n                    <td>{}</td> \\\n                    <td>{}</td> \\\n                    </tr>\\n\".format(\n                name,\n                mandatory,\n                field_type,\n                prop.get(\"description\", \"\")\n            ))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _setup_chassis(self):\n\n        if self._chassis == \"3620\":\n            self._create_slots(2)\n        elif self._chassis == \"3640\":\n            self._create_slots(4)\n        elif self._chassis == \"3660\":\n            self._create_slots(7)\n            self._slots[0] = Leopard_2FE()", "response": "Sets up the router with the corresponding chassis."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_iomem(self, iomem):\n\n        yield from self._hypervisor.send('c3600 set_iomem \"{name}\" {size}'.format(name=self._name, size=iomem))\n\n        log.info('Router \"{name}\" [{id}]: I/O memory updated from {old_iomem}% to {new_iomem}%'.format(name=self._name,\n                                                                                                       id=self._id,\n                                                                                                       old_iomem=self._iomem,\n                                                                                                       new_iomem=iomem))\n        self._iomem = iomem", "response": "Sets the iomem size for this router."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef interfaces(self):\n        if not self._interfaces_cache:\n            response = yield from self.get(\"/network/interfaces\")\n            self._interfaces_cache = response.json\n        return self._interfaces_cache", "response": "Get the list of network interfaces on compute\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread a file from a project and download it", "response": "def download_file(self, project, path):\n        \"\"\"\n        Read file of a project and download it\n\n        :param project: A project object\n        :param path: The path of the file in the project\n        :returns: A file stream\n        \"\"\"\n\n        url = self._getUrl(\"/projects/{}/files/{}\".format(project.id, path))\n        response = yield from self._session().request(\"GET\", url, auth=self._auth)\n        if response.status == 404:\n            raise aiohttp.web.HTTPNotFound(text=\"{} not found on compute\".format(path))\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef download_image(self, image_type, image):\n\n        url = self._getUrl(\"/{}/images/{}\".format(image_type, image))\n        response = yield from self._session().request(\"GET\", url, auth=self._auth)\n        if response.status == 404:\n            raise aiohttp.web.HTTPNotFound(text=\"{} not found on compute\".format(image))\n        return response", "response": "Read file of a project and download it\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads a file from the compute and stream it.", "response": "def stream_file(self, project, path):\n        \"\"\"\n        Read file of a project and stream it\n\n        :param project: A project object\n        :param path: The path of the file in the project\n        :returns: A file stream\n        \"\"\"\n\n        # Due to Python 3.4 limitation we can't use with and asyncio\n        # https://www.python.org/dev/peps/pep-0492/\n        # that why we wrap the answer\n        class StreamResponse:\n\n            def __init__(self, response):\n                self._response = response\n\n            def __enter__(self):\n                return self._response.content\n\n            def __exit__(self):\n                self._response.close()\n\n        url = self._getUrl(\"/projects/{}/stream/{}\".format(project.id, path))\n        response = yield from self._session().request(\"GET\", url, auth=self._auth, timeout=None)\n        if response.status == 404:\n            raise aiohttp.web.HTTPNotFound(text=\"{} not found on compute\".format(path))\n        elif response.status == 403:\n            raise aiohttp.web.HTTPForbidden(text=\"forbidden to open {} on compute\".format(path))\n        elif response.status != 200:\n            raise aiohttp.web.HTTPInternalServerError(text=\"Unexpected error {}: {}: while opening {} on compute\".format(response.status,\n                                                                                                                         response.reason,\n                                                                                                                         path))\n        return StreamResponse(response)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsend a HTTP query to the compute.", "response": "def http_query(self, method, path, data=None, dont_connect=False, **kwargs):\n        \"\"\"\n        :param dont_connect: If true do not reconnect if not connected\n        \"\"\"\n\n        if not self._connected and not dont_connect:\n            if self._id == \"vm\" and not self._controller.gns3vm.running:\n                yield from self._controller.gns3vm.start()\n            yield from self.connect()\n        if not self._connected and not dont_connect:\n            raise ComputeError(\"Cannot connect to compute '{}' with request {} {}\".format(self._name, method, path))\n        response = yield from self._run_http_query(method, path, data=data, **kwargs)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconnect to the remote server.", "response": "def connect(self):\n        \"\"\"\n        Check if remote server is accessible\n        \"\"\"\n\n        if not self._connected and not self._closed:\n            try:\n                log.info(\"Connecting to compute '{}'\".format(self._id))\n                response = yield from self._run_http_query(\"GET\", \"/capabilities\")\n            except ComputeError as e:\n                # Try to reconnect after 2 seconds if server unavailable only if not during tests (otherwise we create a ressources usage bomb)\n                if not hasattr(sys, \"_called_from_test\") or not sys._called_from_test:\n                    self._connection_failure += 1\n                    # After 5 failure we close the project using the compute to avoid sync issues\n                    if self._connection_failure == 5:\n                        log.warning(\"Cannot connect to compute '{}': {}\".format(self._id, e))\n                        yield from self._controller.close_compute_projects(self)\n                    asyncio.get_event_loop().call_later(2, lambda: asyncio.async(self._try_reconnect()))\n                return\n            except aiohttp.web.HTTPNotFound:\n                raise aiohttp.web.HTTPConflict(text=\"The server {} is not a GNS3 server or it's a 1.X server\".format(self._id))\n            except aiohttp.web.HTTPUnauthorized:\n                raise aiohttp.web.HTTPConflict(text=\"Invalid auth for server {}\".format(self._id))\n            except aiohttp.web.HTTPServiceUnavailable:\n                raise aiohttp.web.HTTPConflict(text=\"The server {} is unavailable\".format(self._id))\n            except ValueError:\n                raise aiohttp.web.HTTPConflict(text=\"Invalid server url for server {}\".format(self._id))\n\n            if \"version\" not in response.json:\n                self._http_session.close()\n                raise aiohttp.web.HTTPConflict(text=\"The server {} is not a GNS3 server\".format(self._id))\n            self._capabilities = response.json\n            if parse_version(__version__)[:2] != parse_version(response.json[\"version\"])[:2]:\n                self._http_session.close()\n                raise aiohttp.web.HTTPConflict(text=\"The server {} versions are not compatible {} != {}\".format(self._id, __version__, response.json[\"version\"]))\n\n            self._notifications = asyncio.gather(self._connect_notification())\n            self._connected = True\n            self._connection_failure = 0\n            self._controller.notification.emit(\"compute.updated\", self.__json__())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconnecting to the notification stream and dispatch events.", "response": "def _connect_notification(self):\n        \"\"\"\n        Connect to the notification stream\n        \"\"\"\n        try:\n            self._ws = yield from self._session().ws_connect(self._getUrl(\"/notifications/ws\"), auth=self._auth)\n        except (aiohttp.WSServerHandshakeError, aiohttp.ClientResponseError):\n            self._ws = None\n        while self._ws is not None:\n            try:\n                response = yield from self._ws.receive()\n            except aiohttp.WSServerHandshakeError:\n                self._ws = None\n                break\n            if response.tp == aiohttp.WSMsgType.closed or response.tp == aiohttp.WSMsgType.error or response.data is None:\n                self._connected = False\n                break\n            msg = json.loads(response.data)\n            action = msg.pop(\"action\")\n            event = msg.pop(\"event\")\n\n            if action == \"ping\":\n                self._cpu_usage_percent = event[\"cpu_usage_percent\"]\n                self._memory_usage_percent = event[\"memory_usage_percent\"]\n                self._controller.notification.emit(\"compute.updated\", self.__json__())\n            else:\n                yield from self._controller.notification.dispatch(action, event, compute_id=self.id)\n        if self._ws:\n            yield from self._ws.close()\n\n        # Try to reconnect after 1 seconds if server unavailable only if not during tests (otherwise we create a ressources usage bomb)\n        if not hasattr(sys, \"_called_from_test\") or not sys._called_from_test:\n            asyncio.get_event_loop().call_later(1, lambda: asyncio.async(self.connect()))\n        self._ws = None\n        self._cpu_usage_percent = None\n        self._memory_usage_percent = None\n        self._controller.notification.emit(\"compute.updated\", self.__json__())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nforwarding a call to the emulator on compute", "response": "def forward(self, method, type, path, data=None):\n        \"\"\"\n        Forward a call to the emulator on compute\n        \"\"\"\n        try:\n            action = \"/{}/{}\".format(type, path)\n            res = yield from self.http_query(method, action, data=data, timeout=None)\n        except aiohttp.ServerDisconnectedError:\n            log.error(\"Connection lost to %s during %s %s\", self._id, method, action)\n            raise aiohttp.web.HTTPGatewayTimeout()\n        return res.json"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the list of images available for this type on controller and on the compute node.", "response": "def images(self, type):\n        \"\"\"\n        Return the list of images available for this type on controller\n        and on the compute node.\n        \"\"\"\n        images = []\n\n        res = yield from self.http_query(\"GET\", \"/{}/images\".format(type), timeout=None)\n        images = res.json\n\n        try:\n            if type in [\"qemu\", \"dynamips\", \"iou\"]:\n                for local_image in list_images(type):\n                    if local_image['filename'] not in [i['filename'] for i in images]:\n                        images.append(local_image)\n                images = sorted(images, key=itemgetter('filename'))\n            else:\n                images = sorted(images, key=itemgetter('image'))\n        except OSError as e:\n            raise ComputeError(\"Can't list images: {}\".format(str(e)))\n        return images"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlist files in the project on computes", "response": "def list_files(self, project):\n        \"\"\"\n        List files in the project on computes\n        \"\"\"\n        path = \"/projects/{}/files\".format(project.id)\n        res = yield from self.http_query(\"GET\", path, timeout=120)\n        return res.json"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntry to find the best ip for communication from one compute to another compute.", "response": "def get_ip_on_same_subnet(self, other_compute):\n        \"\"\"\n        Try to found the best ip for communication from one compute\n        to another\n\n        :returns: Tuple (ip_for_this_compute, ip_for_other_compute)\n        \"\"\"\n        if other_compute == self:\n            return (self.host_ip, self.host_ip)\n\n        # Perhaps the user has correct network gateway, we trust him\n        if (self.host_ip not in ('0.0.0.0', '127.0.0.1') and other_compute.host_ip not in ('0.0.0.0', '127.0.0.1')):\n            return (self.host_ip, other_compute.host_ip)\n\n        this_compute_interfaces = yield from self.interfaces()\n        other_compute_interfaces = yield from other_compute.interfaces()\n\n        # Sort interface to put the compute host in first position\n        # we guess that if user specified this host it could have a reason (VMware Nat / Host only interface)\n        this_compute_interfaces = sorted(this_compute_interfaces, key=lambda i: i[\"ip_address\"] != self.host_ip)\n        other_compute_interfaces = sorted(other_compute_interfaces, key=lambda i: i[\"ip_address\"] != other_compute.host_ip)\n\n        for this_interface in this_compute_interfaces:\n            # Skip if no ip or no netmask (vbox when stopped set a null netmask)\n            if len(this_interface[\"ip_address\"]) == 0 or this_interface[\"netmask\"] is None:\n                continue\n            # Ignore 169.254 network because it's for Windows special purpose\n            if this_interface[\"ip_address\"].startswith(\"169.254.\"):\n                continue\n\n            this_network = ipaddress.ip_network(\"{}/{}\".format(this_interface[\"ip_address\"], this_interface[\"netmask\"]), strict=False)\n\n            for other_interface in other_compute_interfaces:\n                if len(other_interface[\"ip_address\"]) == 0 or other_interface[\"netmask\"] is None:\n                    continue\n\n                # Avoid stuff like 127.0.0.1\n                if other_interface[\"ip_address\"] == this_interface[\"ip_address\"]:\n                    continue\n\n                other_network = ipaddress.ip_network(\"{}/{}\".format(other_interface[\"ip_address\"], other_interface[\"netmask\"]), strict=False)\n                if this_network.overlaps(other_network):\n                    return (this_interface[\"ip_address\"], other_interface[\"ip_address\"])\n\n        raise ValueError(\"No common subnet for compute {} and {}\".format(self.name, other_compute.name))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding a NIO instance as new port on Frame Relay switch.", "response": "def add_nio(self, nio, port_number):\n        \"\"\"\n        Adds a NIO as new port on Frame Relay switch.\n\n        :param nio: NIO instance to add\n        :param port_number: port to allocate for the NIO\n        \"\"\"\n\n        if port_number in self._nios:\n            raise DynamipsError(\"Port {} isn't free\".format(port_number))\n\n        log.info('Frame Relay switch \"{name}\" [{id}]: NIO {nio} bound to port {port}'.format(name=self._name,\n                                                                                             id=self._id,\n                                                                                             nio=nio,\n                                                                                             port=port_number))\n\n        self._nios[port_number] = nio\n        yield from self.set_mappings(self._mappings)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove the specified NIO as member of this Frame Relay switch.", "response": "def remove_nio(self, port_number):\n        \"\"\"\n        Removes the specified NIO as member of this Frame Relay switch.\n\n        :param port_number: allocated port number\n\n        :returns: the NIO that was bound to the allocated port\n        \"\"\"\n\n        if port_number not in self._nios:\n            raise DynamipsError(\"Port {} is not allocated\".format(port_number))\n\n        # remove VCs mapped with the port\n        for source, destination in self._active_mappings.copy().items():\n            source_port, source_dlci = source\n            destination_port, destination_dlci = destination\n            if port_number == source_port:\n                log.info('Frame Relay switch \"{name}\" [{id}]: unmapping VC between port {source_port} DLCI {source_dlci} and port {destination_port} DLCI {destination_dlci}'.format(name=self._name,\n                                                                                                                                                                                     id=self._id,\n                                                                                                                                                                                     source_port=source_port,\n                                                                                                                                                                                     source_dlci=source_dlci,\n                                                                                                                                                                                     destination_port=destination_port,\n                                                                                                                                                                                     destination_dlci=destination_dlci))\n                yield from self.unmap_vc(source_port, source_dlci, destination_port, destination_dlci)\n                yield from self.unmap_vc(destination_port, destination_dlci, source_port, source_dlci)\n\n        nio = self._nios[port_number]\n        if isinstance(nio, NIOUDP):\n            self.manager.port_manager.release_udp_port(nio.lport, self._project)\n\n        log.info('Frame Relay switch \"{name}\" [{id}]: NIO {nio} removed from port {port}'.format(name=self._name,\n                                                                                                 id=self._id,\n                                                                                                 nio=nio,\n                                                                                                 port=port_number))\n\n        del self._nios[port_number]\n        return nio"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\napplies VC mappings between source and destination ports.", "response": "def set_mappings(self, mappings):\n        \"\"\"\n        Applies VC mappings\n\n        :param mappings: mappings (dict)\n        \"\"\"\n\n        for source, destination in mappings.items():\n            if not isinstance(source, str) or not isinstance(destination, str):\n                raise DynamipsError(\"Invalid Frame-Relay mappings\")\n            source_port, source_dlci = map(int, source.split(':'))\n            destination_port, destination_dlci = map(int, destination.split(':'))\n            if self.has_port(destination_port):\n                if (source_port, source_dlci) not in self._active_mappings and (destination_port, destination_dlci) not in self._active_mappings:\n                    log.info('Frame Relay switch \"{name}\" [{id}]: mapping VC between port {source_port} DLCI {source_dlci} and port {destination_port} DLCI {destination_dlci}'.format(name=self._name,\n                                                                                                                                                                                       id=self._id,\n                                                                                                                                                                                       source_port=source_port,\n                                                                                                                                                                                       source_dlci=source_dlci,\n                                                                                                                                                                                       destination_port=destination_port,\n                                                                                                                                                                                       destination_dlci=destination_dlci))\n\n                    yield from self.map_vc(source_port, source_dlci, destination_port, destination_dlci)\n                    yield from self.map_vc(destination_port, destination_dlci, source_port, source_dlci)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef unmap_vc(self, port1, dlci1, port2, dlci2):\n\n        if port1 not in self._nios:\n            raise DynamipsError(\"Port {} is not allocated\".format(port1))\n\n        if port2 not in self._nios:\n            raise DynamipsError(\"Port {} is not allocated\".format(port2))\n\n        nio1 = self._nios[port1]\n        nio2 = self._nios[port2]\n\n        yield from self._hypervisor.send('frsw delete_vc \"{name}\" {input_nio} {input_dlci} {output_nio} {output_dlci}'.format(name=self._name,\n                                                                                                                              input_nio=nio1,\n                                                                                                                              input_dlci=dlci1,\n                                                                                                                              output_nio=nio2,\n                                                                                                                              output_dlci=dlci2))\n\n        log.info('Frame Relay switch \"{name}\" [{id}]: VC from port {port1} DLCI {dlci1} to port {port2} DLCI {dlci2} deleted'.format(name=self._name,\n                                                                                                                                     id=self._id,\n                                                                                                                                     port1=port1,\n                                                                                                                                     dlci1=dlci1,\n                                                                                                                                     port2=port2,\n                                                                                                                                     dlci2=dlci2))\n        del self._active_mappings[(port1, dlci1)]", "response": "Deletes a Virtual Circuit connection between two ports."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef main():\n\n    if not sys.platform.startswith(\"win\"):\n        if \"--daemon\" in sys.argv:\n            daemonize()\n    from gns3server.run import run\n    run()", "response": "Entry point for GNS3 server\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_free_display_port(self):\n        display = 100\n        if not os.path.exists(\"/tmp/.X11-unix/\"):\n            return display\n        while True:\n            if not os.path.exists(\"/tmp/.X11-unix/X{}\".format(display)):\n                return display\n            display += 1", "response": "Search a free display port and return the first available one."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_container_state(self):\n        try:\n            result = yield from self.manager.query(\"GET\", \"containers/{}/json\".format(self._cid))\n        except DockerError:\n            return \"exited\"\n\n        if result[\"State\"][\"Paused\"]:\n            return \"paused\"\n        if result[\"State\"][\"Running\"]:\n            return \"running\"\n        return \"exited\"", "response": "Returns the state of the container."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the dictionary of information about the container image", "response": "def _get_image_information(self):\n        \"\"\"\n        :returns: Dictionary information about the container image\n        \"\"\"\n        result = yield from self.manager.query(\"GET\", \"images/{}/json\".format(self._image))\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmounting the local folders that we need to map to local folders", "response": "def _mount_binds(self, image_infos):\n        \"\"\"\n        :returns: Return the path that we need to map to local folders\n        \"\"\"\n        ressources = get_resource(\"compute/docker/resources\")\n        if not os.path.exists(ressources):\n            raise DockerError(\"{} is missing can't start Docker containers\".format(ressources))\n        binds = [\"{}:/gns3:ro\".format(ressources)]\n\n        # We mount our own etc/network\n        network_config = self._create_network_config()\n        binds.append(\"{}:/gns3volumes/etc/network:rw\".format(network_config))\n\n        self._volumes = [\"/etc/network\"]\n\n        volumes = image_infos.get(\"Config\", {}).get(\"Volumes\")\n        if volumes is None:\n            return binds\n        for volume in volumes.keys():\n            source = os.path.join(self.working_dir, os.path.relpath(volume, \"/\"))\n            os.makedirs(source, exist_ok=True)\n            binds.append(\"{}:/gns3volumes{}\".format(source, volume))\n            self._volumes.append(volume)\n\n        return binds"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _create_network_config(self):\n        path = os.path.join(self.working_dir, \"etc\", \"network\")\n        os.makedirs(path, exist_ok=True)\n        open(os.path.join(path, \".gns3_perms\"), 'a').close()\n        os.makedirs(os.path.join(path, \"if-up.d\"), exist_ok=True)\n        os.makedirs(os.path.join(path, \"if-down.d\"), exist_ok=True)\n        os.makedirs(os.path.join(path, \"if-pre-up.d\"), exist_ok=True)\n        os.makedirs(os.path.join(path, \"if-post-down.d\"), exist_ok=True)\n\n        if not os.path.exists(os.path.join(path, \"interfaces\")):\n            with open(os.path.join(path, \"interfaces\"), \"w+\") as f:\n                f.write(\"\"\"#\n# This is a sample network config uncomment lines to configure the network\n#\n\n\"\"\")\n                for adapter in range(0, self.adapters):\n                    f.write(\"\"\"\n# Static config for eth{adapter}\n#auto eth{adapter}\n#iface eth{adapter} inet static\n#\\taddress 192.168.{adapter}.2\n#\\tnetmask 255.255.255.0\n#\\tgateway 192.168.{adapter}.1\n#\\tup echo nameserver 192.168.{adapter}.1 > /etc/resolv.conf\n\n# DHCP config for eth{adapter}\n# auto eth{adapter}\n# iface eth{adapter} inet dhcp\"\"\".format(adapter=adapter))\n        return path", "response": "Create the network config file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create(self):\n\n        try:\n            image_infos = yield from self._get_image_information()\n        except DockerHttp404Error:\n            log.info(\"Image %s is missing pulling it from docker hub\", self._image)\n            yield from self.pull_image(self._image)\n            image_infos = yield from self._get_image_information()\n            if image_infos is None:\n                raise DockerError(\"Can't get image informations, please try again.\")\n\n        params = {\n            \"Hostname\": self._name,\n            \"Name\": self._name,\n            \"Image\": self._image,\n            \"NetworkDisabled\": True,\n            \"Tty\": True,\n            \"OpenStdin\": True,\n            \"StdinOnce\": False,\n            \"HostConfig\": {\n                \"CapAdd\": [\"ALL\"],\n                \"Privileged\": True,\n                \"Binds\": self._mount_binds(image_infos)\n            },\n            \"Volumes\": {},\n            \"Env\": [\"container=docker\"],  # Systemd compliant: https://github.com/GNS3/gns3-server/issues/573\n            \"Cmd\": [],\n            \"Entrypoint\": image_infos.get(\"Config\", {\"Entrypoint\": []})[\"Entrypoint\"]\n        }\n\n        if params[\"Entrypoint\"] is None:\n            params[\"Entrypoint\"] = []\n        if self._start_command:\n            params[\"Cmd\"] = shlex.split(self._start_command)\n        if len(params[\"Cmd\"]) == 0:\n            params[\"Cmd\"] = image_infos.get(\"Config\", {\"Cmd\": []})[\"Cmd\"]\n            if params[\"Cmd\"] is None:\n                params[\"Cmd\"] = []\n        if len(params[\"Cmd\"]) == 0 and len(params[\"Entrypoint\"]) == 0:\n            params[\"Cmd\"] = [\"/bin/sh\"]\n        params[\"Entrypoint\"].insert(0, \"/gns3/init.sh\")  # FIXME /gns3/init.sh is not found?\n\n        # Give the information to the container on how many interface should be inside\n        params[\"Env\"].append(\"GNS3_MAX_ETHERNET=eth{}\".format(self.adapters - 1))\n        # Give the information to the container the list of volume path mounted\n        params[\"Env\"].append(\"GNS3_VOLUMES={}\".format(\":\".join(self._volumes)))\n\n        if self._environment:\n            for e in self._environment.strip().split(\"\\n\"):\n                e = e.strip()\n                if not e.startswith(\"GNS3_\"):\n                    params[\"Env\"].append(e)\n\n        if self._console_type == \"vnc\":\n            yield from self._start_vnc()\n            params[\"Env\"].append(\"QT_GRAPHICSSYSTEM=native\")  # To fix a Qt issue: https://github.com/GNS3/gns3-server/issues/556\n            params[\"Env\"].append(\"DISPLAY=:{}\".format(self._display))\n            params[\"HostConfig\"][\"Binds\"].append(\"/tmp/.X11-unix/:/tmp/.X11-unix/\")\n\n        result = yield from self.manager.query(\"POST\", \"containers/create\", data=params)\n        self._cid = result['Id']\n        log.info(\"Docker container '{name}' [{id}] created\".format(\n            name=self._name, id=self._id))\n        return True", "response": "Creates the Docker container."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update(self):\n        # We need to save the console and state and restore it\n        console = self.console\n        aux = self.aux\n        state = yield from self._get_container_state()\n\n        yield from self.reset()\n        yield from self.create()\n        self.console = console\n        self.aux = aux\n        if state == \"running\":\n            yield from self.start()", "response": "Update the current container with the new settings."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nstarting this Docker container.", "response": "def start(self):\n        \"\"\"Starts this Docker container.\"\"\"\n\n        try:\n            state = yield from self._get_container_state()\n        except DockerHttp404Error:\n            raise DockerError(\"Docker container '{name}' with ID {cid} does not exist or is not ready yet. Please try again in a few seconds.\".format(name=self.name,\n                                                                                                                                                      cid=self._cid))\n        if state == \"paused\":\n            yield from self.unpause()\n        elif state == \"running\":\n            return\n        else:\n            yield from self._clean_servers()\n\n            yield from self.manager.query(\"POST\", \"containers/{}/start\".format(self._cid))\n            self._namespace = yield from self._get_namespace()\n\n            yield from self._start_ubridge()\n\n            for adapter_number in range(0, self.adapters):\n                nio = self._ethernet_adapters[adapter_number].get_nio(0)\n                with (yield from self.manager.ubridge_lock):\n                    try:\n                        yield from self._add_ubridge_connection(nio, adapter_number)\n                    except UbridgeNamespaceError:\n                        log.error(\"Container %s failed to start\", self.name)\n                        yield from self.stop()\n\n                        # The container can crash soon after the start, this means we can not move the interface to the container namespace\n                        logdata = yield from self._get_log()\n                        for line in logdata.split('\\n'):\n                            log.error(line)\n                        raise DockerError(logdata)\n\n            if self.console_type == \"telnet\":\n                yield from self._start_console()\n            elif self.console_type == \"http\" or self.console_type == \"https\":\n                yield from self._start_http()\n\n            if self.allocate_aux:\n                yield from self._start_aux()\n\n        self.status = \"started\"\n        log.info(\"Docker container '{name}' [{image}] started listen for {console_type} on {console}\".format(name=self._name,\n                                                                                                             image=self._image,\n                                                                                                             console=self.console,\n                                                                                                             console_type=self.console_type))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _start_aux(self):\n\n        # We can not use the API because docker doesn't expose a websocket api for exec\n        # https://github.com/GNS3/gns3-gui/issues/1039\n        process = yield from asyncio.subprocess.create_subprocess_exec(\n            \"docker\", \"exec\", \"-i\", self._cid, \"/gns3/bin/busybox\", \"script\", \"-qfc\", \"while true; do TERM=vt100 /gns3/bin/busybox sh; done\", \"/dev/null\",\n            stdout=asyncio.subprocess.PIPE,\n            stderr=asyncio.subprocess.STDOUT,\n            stdin=asyncio.subprocess.PIPE)\n        server = AsyncioTelnetServer(reader=process.stdout, writer=process.stdin, binary=True, echo=True)\n        self._telnet_servers.append((yield from asyncio.start_server(server.run, self._manager.port_manager.console_host, self.aux)))\n        log.debug(\"Docker container '%s' started listen for auxilary telnet on %d\", self.name, self.aux)", "response": "Start an auxilary console"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfixing permissions and ownership on the containers", "response": "def _fix_permissions(self):\n        \"\"\"\n        Because docker run as root we need to fix permission and ownership to allow user to interact\n        with it from their filesystem and do operation like file delete\n        \"\"\"\n\n        state = yield from self._get_container_state()\n        if state == \"stopped\" or state == \"exited\":\n            # We need to restart it to fix permissions\n            yield from self.manager.query(\"POST\", \"containers/{}/start\".format(self._cid))\n\n        for volume in self._volumes:\n            log.debug(\"Docker container '{name}' [{image}] fix ownership on {path}\".format(\n                name=self._name, image=self._image, path=volume))\n            process = yield from asyncio.subprocess.create_subprocess_exec(\n                \"docker\",\n                \"exec\",\n                self._cid,\n                \"/gns3/bin/busybox\",\n                \"sh\",\n                \"-c\",\n                \"(\"\n                \"/gns3/bin/busybox find \\\"{path}\\\" -depth -print0\"\n                \" | /gns3/bin/busybox xargs -0 /gns3/bin/busybox stat -c '%a:%u:%g:%n' > \\\"{path}/.gns3_perms\\\"\"\n                \")\"\n                \" && /gns3/bin/busybox chmod -R u+rX \\\"{path}\\\"\"\n                \" && /gns3/bin/busybox chown {uid}:{gid} -R \\\"{path}\\\"\"\n                .format(uid=os.getuid(), gid=os.getgid(), path=volume),\n            )\n            yield from process.wait()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _start_vnc(self):\n\n        self._display = self._get_free_display_port()\n        if shutil.which(\"Xvfb\") is None or shutil.which(\"x11vnc\") is None:\n            raise DockerError(\"Please install Xvfb and x11vnc before using the VNC support\")\n        self._xvfb_process = yield from asyncio.create_subprocess_exec(\"Xvfb\", \"-nolisten\", \"tcp\", \":{}\".format(self._display), \"-screen\", \"0\", self._console_resolution + \"x16\")\n        # We pass a port for TCPV6 due to a crash in X11VNC if not here: https://github.com/GNS3/gns3-server/issues/569\n        self._x11vnc_process = yield from asyncio.create_subprocess_exec(\"x11vnc\", \"-forever\", \"-nopw\", \"-shared\", \"-geometry\", self._console_resolution, \"-display\", \"WAIT:{}\".format(self._display), \"-rfbport\", str(self.console), \"-rfbportv6\", str(self.console), \"-noncache\", \"-listen\", self._manager.port_manager.console_host)\n\n        x11_socket = os.path.join(\"/tmp/.X11-unix/\", \"X{}\".format(self._display))\n        yield from wait_for_file_creation(x11_socket)", "response": "Start a VNC server for this container."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nstarting an HTTP tunnel to the console.", "response": "def _start_http(self):\n        \"\"\"\n        Start an HTTP tunnel to container localhost. It's not perfect\n        but the only way we have to inject network packet is using nc.\n        \"\"\"\n        log.debug(\"Forward HTTP for %s to %d\", self.name, self._console_http_port)\n        command = [\"docker\", \"exec\", \"-i\", self._cid, \"/gns3/bin/busybox\", \"nc\", \"127.0.0.1\", str(self._console_http_port)]\n        # We replace host and port in the server answer otherwise some link could be broken\n        server = AsyncioRawCommandServer(command, replaces=[\n            (\n                '://127.0.0.1'.encode(),  # {{HOST}} mean client host\n                '://{{HOST}}'.encode(),\n            ),\n            (\n                ':{}'.format(self._console_http_port).encode(),\n                ':{}'.format(self.console).encode(),\n            )\n        ])\n        self._telnet_servers.append((yield from asyncio.start_server(server.run, self._manager.port_manager.console_host, self.console)))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _start_console(self):\n\n        class InputStream:\n\n            def __init__(self):\n                self._data = b\"\"\n\n            def write(self, data):\n                self._data += data\n\n            @asyncio.coroutine\n            def drain(self):\n                if not self.ws.closed:\n                    self.ws.send_bytes(self._data)\n                self._data = b\"\"\n\n        output_stream = asyncio.StreamReader()\n        input_stream = InputStream()\n\n        telnet = AsyncioTelnetServer(reader=output_stream, writer=input_stream, echo=True)\n        self._telnet_servers.append((yield from asyncio.start_server(telnet.run, self._manager.port_manager.console_host, self.console)))\n\n        self._console_websocket = yield from self.manager.websocket_query(\"containers/{}/attach/ws?stream=1&stdin=1&stdout=1&stderr=1\".format(self._cid))\n        input_stream.ws = self._console_websocket\n\n        output_stream.feed_data(self.name.encode() + b\" console is now available... Press RETURN to get started.\\r\\n\")\n\n        asyncio.async(self._read_console_output(self._console_websocket, output_stream))", "response": "Start streaming the console via telnet"}
